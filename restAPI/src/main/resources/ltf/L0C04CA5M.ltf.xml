<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CA5M" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="5141" raw_text_md5="52ca9a736eee3788bd3ffd1497c68528">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="55">
<ORIGINAL_TEXT>Study lacks evidence on masks, isn’t linked to Stanford</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="5">Study</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="7" end_char="11">lacks</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="13" end_char="20">evidence</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="22" end_char="23">on</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="25" end_char="29">masks</TOKEN>
<TOKEN id="token-0-5" pos="punct" morph="none" start_char="30" end_char="30">,</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="32" end_char="36">isn’t</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="38" end_char="43">linked</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="45" end_char="46">to</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="48" end_char="55">Stanford</TOKEN>
</SEG>
<SEG id="segment-1" start_char="59" end_char="208">
<ORIGINAL_TEXT>CLAIM: A Stanford University study published on the National Institutes of Health website proves face masks are absolutely worthless against COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="59" end_char="63">CLAIM</TOKEN>
<TOKEN id="token-1-1" pos="punct" morph="none" start_char="64" end_char="64">:</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="66" end_char="66">A</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="68" end_char="75">Stanford</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="77" end_char="86">University</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="88" end_char="92">study</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="94" end_char="102">published</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="104" end_char="105">on</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="107" end_char="109">the</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="111" end_char="118">National</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="120" end_char="129">Institutes</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="131" end_char="132">of</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="134" end_char="139">Health</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="141" end_char="147">website</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="149" end_char="154">proves</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="156" end_char="159">face</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="161" end_char="165">masks</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="167" end_char="169">are</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="171" end_char="180">absolutely</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="182" end_char="190">worthless</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="192" end_char="198">against</TOKEN>
<TOKEN id="token-1-21" pos="unknown" morph="none" start_char="200" end_char="207">COVID-19</TOKEN>
<TOKEN id="token-1-22" pos="punct" morph="none" start_char="208" end_char="208">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="211" end_char="233">
<ORIGINAL_TEXT>AP’S ASSESSMENT: False.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="211" end_char="214">AP’S</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="216" end_char="225">ASSESSMENT</TOKEN>
<TOKEN id="token-2-2" pos="punct" morph="none" start_char="226" end_char="226">:</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="228" end_char="232">False</TOKEN>
<TOKEN id="token-2-4" pos="punct" morph="none" start_char="233" end_char="233">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="235" end_char="381">
<ORIGINAL_TEXT>This study is not affiliated with Stanford University, nor does the author work for the Veterans Affairs Palo Alto Health Care System as he claims.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="235" end_char="238">This</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="240" end_char="244">study</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="246" end_char="247">is</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="249" end_char="251">not</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="253" end_char="262">affiliated</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="264" end_char="267">with</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="269" end_char="276">Stanford</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="278" end_char="287">University</TOKEN>
<TOKEN id="token-3-8" pos="punct" morph="none" start_char="288" end_char="288">,</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="290" end_char="292">nor</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="294" end_char="297">does</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="299" end_char="301">the</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="303" end_char="308">author</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="310" end_char="313">work</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="315" end_char="317">for</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="319" end_char="321">the</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="323" end_char="330">Veterans</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="332" end_char="338">Affairs</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="340" end_char="343">Palo</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="345" end_char="348">Alto</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="350" end_char="355">Health</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="357" end_char="360">Care</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="362" end_char="367">System</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="369" end_char="370">as</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="372" end_char="373">he</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="375" end_char="380">claims</TOKEN>
<TOKEN id="token-3-26" pos="punct" morph="none" start_char="381" end_char="381">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="383" end_char="483">
<ORIGINAL_TEXT>The study presents a hypothesis that includes false claims about the health effects of wearing masks.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="383" end_char="385">The</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="387" end_char="391">study</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="393" end_char="400">presents</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="402" end_char="402">a</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="404" end_char="413">hypothesis</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="415" end_char="418">that</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="420" end_char="427">includes</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="429" end_char="433">false</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="435" end_char="440">claims</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="442" end_char="446">about</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="448" end_char="450">the</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="452" end_char="457">health</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="459" end_char="465">effects</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="467" end_char="468">of</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="470" end_char="476">wearing</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="478" end_char="482">masks</TOKEN>
<TOKEN id="token-4-16" pos="punct" morph="none" start_char="483" end_char="483">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="485" end_char="714">
<ORIGINAL_TEXT>The U.S. Centers for Disease Control and Prevention continues to recommend wearing face coverings to reduce the spread of COVID-19, as research shows they can block the transmission of respiratory droplets, which spread the virus.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="485" end_char="487">The</TOKEN>
<TOKEN id="token-5-1" pos="unknown" morph="none" start_char="489" end_char="491">U.S</TOKEN>
<TOKEN id="token-5-2" pos="punct" morph="none" start_char="492" end_char="492">.</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="494" end_char="500">Centers</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="502" end_char="504">for</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="506" end_char="512">Disease</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="514" end_char="520">Control</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="522" end_char="524">and</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="526" end_char="535">Prevention</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="537" end_char="545">continues</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="547" end_char="548">to</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="550" end_char="558">recommend</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="560" end_char="566">wearing</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="568" end_char="571">face</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="573" end_char="581">coverings</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="583" end_char="584">to</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="586" end_char="591">reduce</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="593" end_char="595">the</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="597" end_char="602">spread</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="604" end_char="605">of</TOKEN>
<TOKEN id="token-5-20" pos="unknown" morph="none" start_char="607" end_char="614">COVID-19</TOKEN>
<TOKEN id="token-5-21" pos="punct" morph="none" start_char="615" end_char="615">,</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="617" end_char="618">as</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="620" end_char="627">research</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="629" end_char="633">shows</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="635" end_char="638">they</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="640" end_char="642">can</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="644" end_char="648">block</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="650" end_char="652">the</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="654" end_char="665">transmission</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="667" end_char="668">of</TOKEN>
<TOKEN id="token-5-31" pos="word" morph="none" start_char="670" end_char="680">respiratory</TOKEN>
<TOKEN id="token-5-32" pos="word" morph="none" start_char="682" end_char="689">droplets</TOKEN>
<TOKEN id="token-5-33" pos="punct" morph="none" start_char="690" end_char="690">,</TOKEN>
<TOKEN id="token-5-34" pos="word" morph="none" start_char="692" end_char="696">which</TOKEN>
<TOKEN id="token-5-35" pos="word" morph="none" start_char="698" end_char="703">spread</TOKEN>
<TOKEN id="token-5-36" pos="word" morph="none" start_char="705" end_char="707">the</TOKEN>
<TOKEN id="token-5-37" pos="word" morph="none" start_char="709" end_char="713">virus</TOKEN>
<TOKEN id="token-5-38" pos="punct" morph="none" start_char="714" end_char="714">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="717" end_char="955">
<ORIGINAL_TEXT>THE FACTS: Websites and social media users ranging from political candidates to health influencers are falsely claiming a study published on a digital research repository came from Stanford University and proves face masks are ineffective.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="717" end_char="719">THE</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="721" end_char="725">FACTS</TOKEN>
<TOKEN id="token-6-2" pos="punct" morph="none" start_char="726" end_char="726">:</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="728" end_char="735">Websites</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="737" end_char="739">and</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="741" end_char="746">social</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="748" end_char="752">media</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="754" end_char="758">users</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="760" end_char="766">ranging</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="768" end_char="771">from</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="773" end_char="781">political</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="783" end_char="792">candidates</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="794" end_char="795">to</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="797" end_char="802">health</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="804" end_char="814">influencers</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="816" end_char="818">are</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="820" end_char="826">falsely</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="828" end_char="835">claiming</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="837" end_char="837">a</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="839" end_char="843">study</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="845" end_char="853">published</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="855" end_char="856">on</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="858" end_char="858">a</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="860" end_char="866">digital</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="868" end_char="875">research</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="877" end_char="886">repository</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="888" end_char="891">came</TOKEN>
<TOKEN id="token-6-27" pos="word" morph="none" start_char="893" end_char="896">from</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="898" end_char="905">Stanford</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="907" end_char="916">University</TOKEN>
<TOKEN id="token-6-30" pos="word" morph="none" start_char="918" end_char="920">and</TOKEN>
<TOKEN id="token-6-31" pos="word" morph="none" start_char="922" end_char="927">proves</TOKEN>
<TOKEN id="token-6-32" pos="word" morph="none" start_char="929" end_char="932">face</TOKEN>
<TOKEN id="token-6-33" pos="word" morph="none" start_char="934" end_char="938">masks</TOKEN>
<TOKEN id="token-6-34" pos="word" morph="none" start_char="940" end_char="942">are</TOKEN>
<TOKEN id="token-6-35" pos="word" morph="none" start_char="944" end_char="954">ineffective</TOKEN>
<TOKEN id="token-6-36" pos="punct" morph="none" start_char="955" end_char="955">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="958" end_char="1177">
<ORIGINAL_TEXT>In reality, the study is not affiliated with Stanford and is based on debunked claims about face masks, including the false notion that wearing a face covering decreases oxygen levels and increases carbon dioxide levels.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="958" end_char="959">In</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="961" end_char="967">reality</TOKEN>
<TOKEN id="token-7-2" pos="punct" morph="none" start_char="968" end_char="968">,</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="970" end_char="972">the</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="974" end_char="978">study</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="980" end_char="981">is</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="983" end_char="985">not</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="987" end_char="996">affiliated</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="998" end_char="1001">with</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="1003" end_char="1010">Stanford</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="1012" end_char="1014">and</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="1016" end_char="1017">is</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="1019" end_char="1023">based</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="1025" end_char="1026">on</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="1028" end_char="1035">debunked</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="1037" end_char="1042">claims</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="1044" end_char="1048">about</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="1050" end_char="1053">face</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="1055" end_char="1059">masks</TOKEN>
<TOKEN id="token-7-19" pos="punct" morph="none" start_char="1060" end_char="1060">,</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="1062" end_char="1070">including</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="1072" end_char="1074">the</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="1076" end_char="1080">false</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="1082" end_char="1087">notion</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="1089" end_char="1092">that</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="1094" end_char="1100">wearing</TOKEN>
<TOKEN id="token-7-26" pos="word" morph="none" start_char="1102" end_char="1102">a</TOKEN>
<TOKEN id="token-7-27" pos="word" morph="none" start_char="1104" end_char="1107">face</TOKEN>
<TOKEN id="token-7-28" pos="word" morph="none" start_char="1109" end_char="1116">covering</TOKEN>
<TOKEN id="token-7-29" pos="word" morph="none" start_char="1118" end_char="1126">decreases</TOKEN>
<TOKEN id="token-7-30" pos="word" morph="none" start_char="1128" end_char="1133">oxygen</TOKEN>
<TOKEN id="token-7-31" pos="word" morph="none" start_char="1135" end_char="1140">levels</TOKEN>
<TOKEN id="token-7-32" pos="word" morph="none" start_char="1142" end_char="1144">and</TOKEN>
<TOKEN id="token-7-33" pos="word" morph="none" start_char="1146" end_char="1154">increases</TOKEN>
<TOKEN id="token-7-34" pos="word" morph="none" start_char="1156" end_char="1161">carbon</TOKEN>
<TOKEN id="token-7-35" pos="word" morph="none" start_char="1163" end_char="1169">dioxide</TOKEN>
<TOKEN id="token-7-36" pos="word" morph="none" start_char="1171" end_char="1176">levels</TOKEN>
<TOKEN id="token-7-37" pos="punct" morph="none" start_char="1177" end_char="1177">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1180" end_char="1326">
<ORIGINAL_TEXT>"Stanford peer review study on masks says they basically do not work for C-19," the local North Dakota TV show POVNow posted on Facebook on Monday.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="punct" morph="none" start_char="1180" end_char="1180">"</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1181" end_char="1188">Stanford</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1190" end_char="1193">peer</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1195" end_char="1200">review</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1202" end_char="1206">study</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1208" end_char="1209">on</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1211" end_char="1215">masks</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1217" end_char="1220">says</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1222" end_char="1225">they</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1227" end_char="1235">basically</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1237" end_char="1238">do</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1240" end_char="1242">not</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1244" end_char="1247">work</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1249" end_char="1251">for</TOKEN>
<TOKEN id="token-8-14" pos="unknown" morph="none" start_char="1253" end_char="1256">C-19</TOKEN>
<TOKEN id="token-8-15" pos="punct" morph="none" start_char="1257" end_char="1258">,"</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1260" end_char="1262">the</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1264" end_char="1268">local</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1270" end_char="1274">North</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1276" end_char="1281">Dakota</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="1283" end_char="1284">TV</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="1286" end_char="1289">show</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="1291" end_char="1296">POVNow</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="1298" end_char="1303">posted</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="1305" end_char="1306">on</TOKEN>
<TOKEN id="token-8-25" pos="word" morph="none" start_char="1308" end_char="1315">Facebook</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="1317" end_char="1318">on</TOKEN>
<TOKEN id="token-8-27" pos="word" morph="none" start_char="1320" end_char="1325">Monday</TOKEN>
<TOKEN id="token-8-28" pos="punct" morph="none" start_char="1326" end_char="1326">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1329" end_char="1596">
<ORIGINAL_TEXT>"A recent Stanford study released by the NCBI, which is under the National Institutes of Health, showed that masks do absolutely nothing to help prevent the spread of COVID-19 and their use is even harmful," read a story on the conservative website The Gateway Pundit.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="punct" morph="none" start_char="1329" end_char="1329">"</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1330" end_char="1330">A</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1332" end_char="1337">recent</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1339" end_char="1346">Stanford</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1348" end_char="1352">study</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1354" end_char="1361">released</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1363" end_char="1364">by</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1366" end_char="1368">the</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1370" end_char="1373">NCBI</TOKEN>
<TOKEN id="token-9-9" pos="punct" morph="none" start_char="1374" end_char="1374">,</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1376" end_char="1380">which</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1382" end_char="1383">is</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1385" end_char="1389">under</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1391" end_char="1393">the</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1395" end_char="1402">National</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1404" end_char="1413">Institutes</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1415" end_char="1416">of</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1418" end_char="1423">Health</TOKEN>
<TOKEN id="token-9-18" pos="punct" morph="none" start_char="1424" end_char="1424">,</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1426" end_char="1431">showed</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1433" end_char="1436">that</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1438" end_char="1442">masks</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1444" end_char="1445">do</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1447" end_char="1456">absolutely</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1458" end_char="1464">nothing</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1466" end_char="1467">to</TOKEN>
<TOKEN id="token-9-26" pos="word" morph="none" start_char="1469" end_char="1472">help</TOKEN>
<TOKEN id="token-9-27" pos="word" morph="none" start_char="1474" end_char="1480">prevent</TOKEN>
<TOKEN id="token-9-28" pos="word" morph="none" start_char="1482" end_char="1484">the</TOKEN>
<TOKEN id="token-9-29" pos="word" morph="none" start_char="1486" end_char="1491">spread</TOKEN>
<TOKEN id="token-9-30" pos="word" morph="none" start_char="1493" end_char="1494">of</TOKEN>
<TOKEN id="token-9-31" pos="unknown" morph="none" start_char="1496" end_char="1503">COVID-19</TOKEN>
<TOKEN id="token-9-32" pos="word" morph="none" start_char="1505" end_char="1507">and</TOKEN>
<TOKEN id="token-9-33" pos="word" morph="none" start_char="1509" end_char="1513">their</TOKEN>
<TOKEN id="token-9-34" pos="word" morph="none" start_char="1515" end_char="1517">use</TOKEN>
<TOKEN id="token-9-35" pos="word" morph="none" start_char="1519" end_char="1520">is</TOKEN>
<TOKEN id="token-9-36" pos="word" morph="none" start_char="1522" end_char="1525">even</TOKEN>
<TOKEN id="token-9-37" pos="word" morph="none" start_char="1527" end_char="1533">harmful</TOKEN>
<TOKEN id="token-9-38" pos="punct" morph="none" start_char="1534" end_char="1535">,"</TOKEN>
<TOKEN id="token-9-39" pos="word" morph="none" start_char="1537" end_char="1540">read</TOKEN>
<TOKEN id="token-9-40" pos="word" morph="none" start_char="1542" end_char="1542">a</TOKEN>
<TOKEN id="token-9-41" pos="word" morph="none" start_char="1544" end_char="1548">story</TOKEN>
<TOKEN id="token-9-42" pos="word" morph="none" start_char="1550" end_char="1551">on</TOKEN>
<TOKEN id="token-9-43" pos="word" morph="none" start_char="1553" end_char="1555">the</TOKEN>
<TOKEN id="token-9-44" pos="word" morph="none" start_char="1557" end_char="1568">conservative</TOKEN>
<TOKEN id="token-9-45" pos="word" morph="none" start_char="1570" end_char="1576">website</TOKEN>
<TOKEN id="token-9-46" pos="word" morph="none" start_char="1578" end_char="1580">The</TOKEN>
<TOKEN id="token-9-47" pos="word" morph="none" start_char="1582" end_char="1588">Gateway</TOKEN>
<TOKEN id="token-9-48" pos="word" morph="none" start_char="1590" end_char="1595">Pundit</TOKEN>
<TOKEN id="token-9-49" pos="punct" morph="none" start_char="1596" end_char="1596">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1598" end_char="1729">
<ORIGINAL_TEXT>The story was shared widely on Facebook and Twitter this week, including by Josh Mandel, a Republican U.S. Senate candidate in Ohio.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1598" end_char="1600">The</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1602" end_char="1606">story</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1608" end_char="1610">was</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1612" end_char="1617">shared</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1619" end_char="1624">widely</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1626" end_char="1627">on</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1629" end_char="1636">Facebook</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1638" end_char="1640">and</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1642" end_char="1648">Twitter</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1650" end_char="1653">this</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1655" end_char="1658">week</TOKEN>
<TOKEN id="token-10-11" pos="punct" morph="none" start_char="1659" end_char="1659">,</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1661" end_char="1669">including</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1671" end_char="1672">by</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1674" end_char="1677">Josh</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1679" end_char="1684">Mandel</TOKEN>
<TOKEN id="token-10-16" pos="punct" morph="none" start_char="1685" end_char="1685">,</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1687" end_char="1687">a</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1689" end_char="1698">Republican</TOKEN>
<TOKEN id="token-10-19" pos="unknown" morph="none" start_char="1700" end_char="1702">U.S</TOKEN>
<TOKEN id="token-10-20" pos="punct" morph="none" start_char="1703" end_char="1703">.</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1705" end_char="1710">Senate</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1712" end_char="1720">candidate</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1722" end_char="1723">in</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1725" end_char="1728">Ohio</TOKEN>
<TOKEN id="token-10-25" pos="punct" morph="none" start_char="1729" end_char="1729">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1732" end_char="1959">
<ORIGINAL_TEXT>The study, titled "Facemasks in the COVID-19 era: A health hypothesis," claims that "scientific evidence supporting facemasks’ efficacy is lacking" while "adverse physiological, psychological and health effects are established."</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1732" end_char="1734">The</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1736" end_char="1740">study</TOKEN>
<TOKEN id="token-11-2" pos="punct" morph="none" start_char="1741" end_char="1741">,</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1743" end_char="1748">titled</TOKEN>
<TOKEN id="token-11-4" pos="punct" morph="none" start_char="1750" end_char="1750">"</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1751" end_char="1759">Facemasks</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1761" end_char="1762">in</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1764" end_char="1766">the</TOKEN>
<TOKEN id="token-11-8" pos="unknown" morph="none" start_char="1768" end_char="1775">COVID-19</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1777" end_char="1779">era</TOKEN>
<TOKEN id="token-11-10" pos="punct" morph="none" start_char="1780" end_char="1780">:</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1782" end_char="1782">A</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1784" end_char="1789">health</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1791" end_char="1800">hypothesis</TOKEN>
<TOKEN id="token-11-14" pos="punct" morph="none" start_char="1801" end_char="1802">,"</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1804" end_char="1809">claims</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1811" end_char="1814">that</TOKEN>
<TOKEN id="token-11-17" pos="punct" morph="none" start_char="1816" end_char="1816">"</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1817" end_char="1826">scientific</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="1828" end_char="1835">evidence</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1837" end_char="1846">supporting</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="1848" end_char="1856">facemasks</TOKEN>
<TOKEN id="token-11-22" pos="punct" morph="none" start_char="1857" end_char="1857">’</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="1859" end_char="1866">efficacy</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="1868" end_char="1869">is</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="1871" end_char="1877">lacking</TOKEN>
<TOKEN id="token-11-26" pos="punct" morph="none" start_char="1878" end_char="1878">"</TOKEN>
<TOKEN id="token-11-27" pos="word" morph="none" start_char="1880" end_char="1884">while</TOKEN>
<TOKEN id="token-11-28" pos="punct" morph="none" start_char="1886" end_char="1886">"</TOKEN>
<TOKEN id="token-11-29" pos="word" morph="none" start_char="1887" end_char="1893">adverse</TOKEN>
<TOKEN id="token-11-30" pos="word" morph="none" start_char="1895" end_char="1907">physiological</TOKEN>
<TOKEN id="token-11-31" pos="punct" morph="none" start_char="1908" end_char="1908">,</TOKEN>
<TOKEN id="token-11-32" pos="word" morph="none" start_char="1910" end_char="1922">psychological</TOKEN>
<TOKEN id="token-11-33" pos="word" morph="none" start_char="1924" end_char="1926">and</TOKEN>
<TOKEN id="token-11-34" pos="word" morph="none" start_char="1928" end_char="1933">health</TOKEN>
<TOKEN id="token-11-35" pos="word" morph="none" start_char="1935" end_char="1941">effects</TOKEN>
<TOKEN id="token-11-36" pos="word" morph="none" start_char="1943" end_char="1945">are</TOKEN>
<TOKEN id="token-11-37" pos="word" morph="none" start_char="1947" end_char="1957">established</TOKEN>
<TOKEN id="token-11-38" pos="punct" morph="none" start_char="1958" end_char="1959">."</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1961" end_char="2153">
<ORIGINAL_TEXT>It makes a variety of claims about negative health impacts of masks, including the false claim that wearing a face mask restricts breathing, leading to the conditions hypoxemia and hypercapnia.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1961" end_char="1962">It</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1964" end_char="1968">makes</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1970" end_char="1970">a</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1972" end_char="1978">variety</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1980" end_char="1981">of</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1983" end_char="1988">claims</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1990" end_char="1994">about</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1996" end_char="2003">negative</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="2005" end_char="2010">health</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="2012" end_char="2018">impacts</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="2020" end_char="2021">of</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="2023" end_char="2027">masks</TOKEN>
<TOKEN id="token-12-12" pos="punct" morph="none" start_char="2028" end_char="2028">,</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="2030" end_char="2038">including</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="2040" end_char="2042">the</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="2044" end_char="2048">false</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="2050" end_char="2054">claim</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="2056" end_char="2059">that</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="2061" end_char="2067">wearing</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="2069" end_char="2069">a</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="2071" end_char="2074">face</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="2076" end_char="2079">mask</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="2081" end_char="2089">restricts</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="2091" end_char="2099">breathing</TOKEN>
<TOKEN id="token-12-24" pos="punct" morph="none" start_char="2100" end_char="2100">,</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="2102" end_char="2108">leading</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="2110" end_char="2111">to</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="2113" end_char="2115">the</TOKEN>
<TOKEN id="token-12-28" pos="word" morph="none" start_char="2117" end_char="2126">conditions</TOKEN>
<TOKEN id="token-12-29" pos="word" morph="none" start_char="2128" end_char="2136">hypoxemia</TOKEN>
<TOKEN id="token-12-30" pos="word" morph="none" start_char="2138" end_char="2140">and</TOKEN>
<TOKEN id="token-12-31" pos="word" morph="none" start_char="2142" end_char="2152">hypercapnia</TOKEN>
<TOKEN id="token-12-32" pos="punct" morph="none" start_char="2153" end_char="2153">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="2156" end_char="2329">
<ORIGINAL_TEXT>Many doctors have taken to social media to debunk claims about oxygen levels and masks, and The Associated Press also has previously debunked false claims about health risks.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="2156" end_char="2159">Many</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="2161" end_char="2167">doctors</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="2169" end_char="2172">have</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="2174" end_char="2178">taken</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="2180" end_char="2181">to</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="2183" end_char="2188">social</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="2190" end_char="2194">media</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="2196" end_char="2197">to</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="2199" end_char="2204">debunk</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="2206" end_char="2211">claims</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="2213" end_char="2217">about</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="2219" end_char="2224">oxygen</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="2226" end_char="2231">levels</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="2233" end_char="2235">and</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="2237" end_char="2241">masks</TOKEN>
<TOKEN id="token-13-15" pos="punct" morph="none" start_char="2242" end_char="2242">,</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="2244" end_char="2246">and</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="2248" end_char="2250">The</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="2252" end_char="2261">Associated</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="2263" end_char="2267">Press</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="2269" end_char="2272">also</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="2274" end_char="2276">has</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="2278" end_char="2287">previously</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="2289" end_char="2296">debunked</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="2298" end_char="2302">false</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="2304" end_char="2309">claims</TOKEN>
<TOKEN id="token-13-26" pos="word" morph="none" start_char="2311" end_char="2315">about</TOKEN>
<TOKEN id="token-13-27" pos="word" morph="none" start_char="2317" end_char="2322">health</TOKEN>
<TOKEN id="token-13-28" pos="word" morph="none" start_char="2324" end_char="2328">risks</TOKEN>
<TOKEN id="token-13-29" pos="punct" morph="none" start_char="2329" end_char="2329">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="2332" end_char="2334">
<ORIGINAL_TEXT>Dr.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="2332" end_char="2333">Dr</TOKEN>
<TOKEN id="token-14-1" pos="punct" morph="none" start_char="2334" end_char="2334">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="2336" end_char="2515">
<ORIGINAL_TEXT>Michael Niederman, a pulmonologist at Weill Cornell Medicine, previously told the AP that wearing masks does not decrease oxygen levels, nor does it increase carbon dioxide levels.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="2336" end_char="2342">Michael</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="2344" end_char="2352">Niederman</TOKEN>
<TOKEN id="token-15-2" pos="punct" morph="none" start_char="2353" end_char="2353">,</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="2355" end_char="2355">a</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="2357" end_char="2369">pulmonologist</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="2371" end_char="2372">at</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="2374" end_char="2378">Weill</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="2380" end_char="2386">Cornell</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="2388" end_char="2395">Medicine</TOKEN>
<TOKEN id="token-15-9" pos="punct" morph="none" start_char="2396" end_char="2396">,</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="2398" end_char="2407">previously</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="2409" end_char="2412">told</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="2414" end_char="2416">the</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="2418" end_char="2419">AP</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="2421" end_char="2424">that</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="2426" end_char="2432">wearing</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="2434" end_char="2438">masks</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="2440" end_char="2443">does</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="2445" end_char="2447">not</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="2449" end_char="2456">decrease</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="2458" end_char="2463">oxygen</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="2465" end_char="2470">levels</TOKEN>
<TOKEN id="token-15-22" pos="punct" morph="none" start_char="2471" end_char="2471">,</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="2473" end_char="2475">nor</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="2477" end_char="2480">does</TOKEN>
<TOKEN id="token-15-25" pos="word" morph="none" start_char="2482" end_char="2483">it</TOKEN>
<TOKEN id="token-15-26" pos="word" morph="none" start_char="2485" end_char="2492">increase</TOKEN>
<TOKEN id="token-15-27" pos="word" morph="none" start_char="2494" end_char="2499">carbon</TOKEN>
<TOKEN id="token-15-28" pos="word" morph="none" start_char="2501" end_char="2507">dioxide</TOKEN>
<TOKEN id="token-15-29" pos="word" morph="none" start_char="2509" end_char="2514">levels</TOKEN>
<TOKEN id="token-15-30" pos="punct" morph="none" start_char="2515" end_char="2515">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="2517" end_char="2750">
<ORIGINAL_TEXT>Dr. Russell Buhr, a pulmonary and critical care physician at UCLA Health, said gas molecules are much smaller than the pores in the material so there is no significant restriction keeping the gas from moving through the mask material.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="2517" end_char="2518">Dr</TOKEN>
<TOKEN id="token-16-1" pos="punct" morph="none" start_char="2519" end_char="2519">.</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="2521" end_char="2527">Russell</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="2529" end_char="2532">Buhr</TOKEN>
<TOKEN id="token-16-4" pos="punct" morph="none" start_char="2533" end_char="2533">,</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="2535" end_char="2535">a</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="2537" end_char="2545">pulmonary</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="2547" end_char="2549">and</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="2551" end_char="2558">critical</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="2560" end_char="2563">care</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="2565" end_char="2573">physician</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="2575" end_char="2576">at</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="2578" end_char="2581">UCLA</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="2583" end_char="2588">Health</TOKEN>
<TOKEN id="token-16-14" pos="punct" morph="none" start_char="2589" end_char="2589">,</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="2591" end_char="2594">said</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="2596" end_char="2598">gas</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="2600" end_char="2608">molecules</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="2610" end_char="2612">are</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="2614" end_char="2617">much</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="2619" end_char="2625">smaller</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="2627" end_char="2630">than</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="2632" end_char="2634">the</TOKEN>
<TOKEN id="token-16-23" pos="word" morph="none" start_char="2636" end_char="2640">pores</TOKEN>
<TOKEN id="token-16-24" pos="word" morph="none" start_char="2642" end_char="2643">in</TOKEN>
<TOKEN id="token-16-25" pos="word" morph="none" start_char="2645" end_char="2647">the</TOKEN>
<TOKEN id="token-16-26" pos="word" morph="none" start_char="2649" end_char="2656">material</TOKEN>
<TOKEN id="token-16-27" pos="word" morph="none" start_char="2658" end_char="2659">so</TOKEN>
<TOKEN id="token-16-28" pos="word" morph="none" start_char="2661" end_char="2665">there</TOKEN>
<TOKEN id="token-16-29" pos="word" morph="none" start_char="2667" end_char="2668">is</TOKEN>
<TOKEN id="token-16-30" pos="word" morph="none" start_char="2670" end_char="2671">no</TOKEN>
<TOKEN id="token-16-31" pos="word" morph="none" start_char="2673" end_char="2683">significant</TOKEN>
<TOKEN id="token-16-32" pos="word" morph="none" start_char="2685" end_char="2695">restriction</TOKEN>
<TOKEN id="token-16-33" pos="word" morph="none" start_char="2697" end_char="2703">keeping</TOKEN>
<TOKEN id="token-16-34" pos="word" morph="none" start_char="2705" end_char="2707">the</TOKEN>
<TOKEN id="token-16-35" pos="word" morph="none" start_char="2709" end_char="2711">gas</TOKEN>
<TOKEN id="token-16-36" pos="word" morph="none" start_char="2713" end_char="2716">from</TOKEN>
<TOKEN id="token-16-37" pos="word" morph="none" start_char="2718" end_char="2723">moving</TOKEN>
<TOKEN id="token-16-38" pos="word" morph="none" start_char="2725" end_char="2731">through</TOKEN>
<TOKEN id="token-16-39" pos="word" morph="none" start_char="2733" end_char="2735">the</TOKEN>
<TOKEN id="token-16-40" pos="word" morph="none" start_char="2737" end_char="2740">mask</TOKEN>
<TOKEN id="token-16-41" pos="word" morph="none" start_char="2742" end_char="2749">material</TOKEN>
<TOKEN id="token-16-42" pos="punct" morph="none" start_char="2750" end_char="2750">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2753" end_char="2877">
<ORIGINAL_TEXT>The study also claimed there was a lack of evidence for the effectiveness of face masks in preventing the spread of COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2753" end_char="2755">The</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2757" end_char="2761">study</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2763" end_char="2766">also</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2768" end_char="2774">claimed</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2776" end_char="2780">there</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2782" end_char="2784">was</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2786" end_char="2786">a</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2788" end_char="2791">lack</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2793" end_char="2794">of</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2796" end_char="2803">evidence</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2805" end_char="2807">for</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2809" end_char="2811">the</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2813" end_char="2825">effectiveness</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2827" end_char="2828">of</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2830" end_char="2833">face</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2835" end_char="2839">masks</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="2841" end_char="2842">in</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="2844" end_char="2853">preventing</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="2855" end_char="2857">the</TOKEN>
<TOKEN id="token-17-19" pos="word" morph="none" start_char="2859" end_char="2864">spread</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="2866" end_char="2867">of</TOKEN>
<TOKEN id="token-17-21" pos="unknown" morph="none" start_char="2869" end_char="2876">COVID-19</TOKEN>
<TOKEN id="token-17-22" pos="punct" morph="none" start_char="2877" end_char="2877">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2879" end_char="2988">
<ORIGINAL_TEXT>In fact, a recent study added strong evidence that statewide mask mandates slow the spread of the coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2879" end_char="2880">In</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2882" end_char="2885">fact</TOKEN>
<TOKEN id="token-18-2" pos="punct" morph="none" start_char="2886" end_char="2886">,</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2888" end_char="2888">a</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2890" end_char="2895">recent</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2897" end_char="2901">study</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2903" end_char="2907">added</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2909" end_char="2914">strong</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2916" end_char="2923">evidence</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="2925" end_char="2928">that</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="2930" end_char="2938">statewide</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="2940" end_char="2943">mask</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2945" end_char="2952">mandates</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="2954" end_char="2957">slow</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="2959" end_char="2961">the</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="2963" end_char="2968">spread</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="2970" end_char="2971">of</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="2973" end_char="2975">the</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="2977" end_char="2987">coronavirus</TOKEN>
<TOKEN id="token-18-19" pos="punct" morph="none" start_char="2988" end_char="2988">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2990" end_char="3155">
<ORIGINAL_TEXT>Research shows masks block virus particles from spreading from infected people who wear them, and can even provide some protection to uninfected people who wear them.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2990" end_char="2997">Research</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2999" end_char="3003">shows</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="3005" end_char="3009">masks</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="3011" end_char="3015">block</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="3017" end_char="3021">virus</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="3023" end_char="3031">particles</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="3033" end_char="3036">from</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="3038" end_char="3046">spreading</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="3048" end_char="3051">from</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="3053" end_char="3060">infected</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="3062" end_char="3067">people</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="3069" end_char="3071">who</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="3073" end_char="3076">wear</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="3078" end_char="3081">them</TOKEN>
<TOKEN id="token-19-14" pos="punct" morph="none" start_char="3082" end_char="3082">,</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="3084" end_char="3086">and</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="3088" end_char="3090">can</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="3092" end_char="3095">even</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="3097" end_char="3103">provide</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="3105" end_char="3108">some</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="3110" end_char="3119">protection</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="3121" end_char="3122">to</TOKEN>
<TOKEN id="token-19-22" pos="word" morph="none" start_char="3124" end_char="3133">uninfected</TOKEN>
<TOKEN id="token-19-23" pos="word" morph="none" start_char="3135" end_char="3140">people</TOKEN>
<TOKEN id="token-19-24" pos="word" morph="none" start_char="3142" end_char="3144">who</TOKEN>
<TOKEN id="token-19-25" pos="word" morph="none" start_char="3146" end_char="3149">wear</TOKEN>
<TOKEN id="token-19-26" pos="word" morph="none" start_char="3151" end_char="3154">them</TOKEN>
<TOKEN id="token-19-27" pos="punct" morph="none" start_char="3155" end_char="3155">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="3158" end_char="3342">
<ORIGINAL_TEXT>The study circulating online this week was first published in November in the journal "Medical Hypotheses," which writes that its purpose is to "publish interesting theoretical papers."</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="3158" end_char="3160">The</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="3162" end_char="3166">study</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="3168" end_char="3178">circulating</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="3180" end_char="3185">online</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="3187" end_char="3190">this</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="3192" end_char="3195">week</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="3197" end_char="3199">was</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="3201" end_char="3205">first</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="3207" end_char="3215">published</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="3217" end_char="3218">in</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="3220" end_char="3227">November</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="3229" end_char="3230">in</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="3232" end_char="3234">the</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="3236" end_char="3242">journal</TOKEN>
<TOKEN id="token-20-14" pos="punct" morph="none" start_char="3244" end_char="3244">"</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="3245" end_char="3251">Medical</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="3253" end_char="3262">Hypotheses</TOKEN>
<TOKEN id="token-20-17" pos="punct" morph="none" start_char="3263" end_char="3264">,"</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="3266" end_char="3270">which</TOKEN>
<TOKEN id="token-20-19" pos="word" morph="none" start_char="3272" end_char="3277">writes</TOKEN>
<TOKEN id="token-20-20" pos="word" morph="none" start_char="3279" end_char="3282">that</TOKEN>
<TOKEN id="token-20-21" pos="word" morph="none" start_char="3284" end_char="3286">its</TOKEN>
<TOKEN id="token-20-22" pos="word" morph="none" start_char="3288" end_char="3294">purpose</TOKEN>
<TOKEN id="token-20-23" pos="word" morph="none" start_char="3296" end_char="3297">is</TOKEN>
<TOKEN id="token-20-24" pos="word" morph="none" start_char="3299" end_char="3300">to</TOKEN>
<TOKEN id="token-20-25" pos="punct" morph="none" start_char="3302" end_char="3302">"</TOKEN>
<TOKEN id="token-20-26" pos="word" morph="none" start_char="3303" end_char="3309">publish</TOKEN>
<TOKEN id="token-20-27" pos="word" morph="none" start_char="3311" end_char="3321">interesting</TOKEN>
<TOKEN id="token-20-28" pos="word" morph="none" start_char="3323" end_char="3333">theoretical</TOKEN>
<TOKEN id="token-20-29" pos="word" morph="none" start_char="3335" end_char="3340">papers</TOKEN>
<TOKEN id="token-20-30" pos="punct" morph="none" start_char="3341" end_char="3342">."</TOKEN>
</SEG>
<SEG id="segment-21" start_char="3344" end_char="3463">
<ORIGINAL_TEXT>Articles submitted to the journal are not meant to prove findings using primary data, but instead to advance hypotheses.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="3344" end_char="3351">Articles</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="3353" end_char="3361">submitted</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="3363" end_char="3364">to</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="3366" end_char="3368">the</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="3370" end_char="3376">journal</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="3378" end_char="3380">are</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="3382" end_char="3384">not</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="3386" end_char="3390">meant</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="3392" end_char="3393">to</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="3395" end_char="3399">prove</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="3401" end_char="3408">findings</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="3410" end_char="3414">using</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="3416" end_char="3422">primary</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="3424" end_char="3427">data</TOKEN>
<TOKEN id="token-21-14" pos="punct" morph="none" start_char="3428" end_char="3428">,</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="3430" end_char="3432">but</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="3434" end_char="3440">instead</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="3442" end_char="3443">to</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="3445" end_char="3451">advance</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="3453" end_char="3462">hypotheses</TOKEN>
<TOKEN id="token-21-20" pos="punct" morph="none" start_char="3463" end_char="3463">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="3466" end_char="3631">
<ORIGINAL_TEXT>The journal has a "long history of publishing fringe science and hypotheses," according to David Gorski, a surgical oncologist who blogs about medical misinformation.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="3466" end_char="3468">The</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="3470" end_char="3476">journal</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="3478" end_char="3480">has</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="3482" end_char="3482">a</TOKEN>
<TOKEN id="token-22-4" pos="punct" morph="none" start_char="3484" end_char="3484">"</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="3485" end_char="3488">long</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="3490" end_char="3496">history</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="3498" end_char="3499">of</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="3501" end_char="3510">publishing</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="3512" end_char="3517">fringe</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="3519" end_char="3525">science</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="3527" end_char="3529">and</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="3531" end_char="3540">hypotheses</TOKEN>
<TOKEN id="token-22-13" pos="punct" morph="none" start_char="3541" end_char="3542">,"</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="3544" end_char="3552">according</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="3554" end_char="3555">to</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="3557" end_char="3561">David</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="3563" end_char="3568">Gorski</TOKEN>
<TOKEN id="token-22-18" pos="punct" morph="none" start_char="3569" end_char="3569">,</TOKEN>
<TOKEN id="token-22-19" pos="word" morph="none" start_char="3571" end_char="3571">a</TOKEN>
<TOKEN id="token-22-20" pos="word" morph="none" start_char="3573" end_char="3580">surgical</TOKEN>
<TOKEN id="token-22-21" pos="word" morph="none" start_char="3582" end_char="3591">oncologist</TOKEN>
<TOKEN id="token-22-22" pos="word" morph="none" start_char="3593" end_char="3595">who</TOKEN>
<TOKEN id="token-22-23" pos="word" morph="none" start_char="3597" end_char="3601">blogs</TOKEN>
<TOKEN id="token-22-24" pos="word" morph="none" start_char="3603" end_char="3607">about</TOKEN>
<TOKEN id="token-22-25" pos="word" morph="none" start_char="3609" end_char="3615">medical</TOKEN>
<TOKEN id="token-22-26" pos="word" morph="none" start_char="3617" end_char="3630">misinformation</TOKEN>
<TOKEN id="token-22-27" pos="punct" morph="none" start_char="3631" end_char="3631">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="3634" end_char="3741">
<ORIGINAL_TEXT>"Even ‘peer-reviewed,’ this journal is still publishing very low quality speculative articles," Gorski said.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="punct" morph="none" start_char="3634" end_char="3634">"</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="3635" end_char="3638">Even</TOKEN>
<TOKEN id="token-23-2" pos="punct" morph="none" start_char="3640" end_char="3640">‘</TOKEN>
<TOKEN id="token-23-3" pos="unknown" morph="none" start_char="3641" end_char="3653">peer-reviewed</TOKEN>
<TOKEN id="token-23-4" pos="punct" morph="none" start_char="3654" end_char="3655">,’</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="3657" end_char="3660">this</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="3662" end_char="3668">journal</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="3670" end_char="3671">is</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="3673" end_char="3677">still</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="3679" end_char="3688">publishing</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="3690" end_char="3693">very</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="3695" end_char="3697">low</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="3699" end_char="3705">quality</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="3707" end_char="3717">speculative</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="3719" end_char="3726">articles</TOKEN>
<TOKEN id="token-23-15" pos="punct" morph="none" start_char="3727" end_char="3728">,"</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="3730" end_char="3735">Gorski</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="3737" end_char="3740">said</TOKEN>
<TOKEN id="token-23-18" pos="punct" morph="none" start_char="3741" end_char="3741">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="3744" end_char="3929">
<ORIGINAL_TEXT>The study’s author, Baruch Vainshelboim, is listed in the study as being affiliated with the cardiology division at the Veterans Affairs Palo Alto Health Care System/Stanford University.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="3744" end_char="3746">The</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="3748" end_char="3754">study’s</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="3756" end_char="3761">author</TOKEN>
<TOKEN id="token-24-3" pos="punct" morph="none" start_char="3762" end_char="3762">,</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="3764" end_char="3769">Baruch</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="3771" end_char="3782">Vainshelboim</TOKEN>
<TOKEN id="token-24-6" pos="punct" morph="none" start_char="3783" end_char="3783">,</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="3785" end_char="3786">is</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="3788" end_char="3793">listed</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="3795" end_char="3796">in</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="3798" end_char="3800">the</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="3802" end_char="3806">study</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="3808" end_char="3809">as</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="3811" end_char="3815">being</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="3817" end_char="3826">affiliated</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="3828" end_char="3831">with</TOKEN>
<TOKEN id="token-24-16" pos="word" morph="none" start_char="3833" end_char="3835">the</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="3837" end_char="3846">cardiology</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="3848" end_char="3855">division</TOKEN>
<TOKEN id="token-24-19" pos="word" morph="none" start_char="3857" end_char="3858">at</TOKEN>
<TOKEN id="token-24-20" pos="word" morph="none" start_char="3860" end_char="3862">the</TOKEN>
<TOKEN id="token-24-21" pos="word" morph="none" start_char="3864" end_char="3871">Veterans</TOKEN>
<TOKEN id="token-24-22" pos="word" morph="none" start_char="3873" end_char="3879">Affairs</TOKEN>
<TOKEN id="token-24-23" pos="word" morph="none" start_char="3881" end_char="3884">Palo</TOKEN>
<TOKEN id="token-24-24" pos="word" morph="none" start_char="3886" end_char="3889">Alto</TOKEN>
<TOKEN id="token-24-25" pos="word" morph="none" start_char="3891" end_char="3896">Health</TOKEN>
<TOKEN id="token-24-26" pos="word" morph="none" start_char="3898" end_char="3901">Care</TOKEN>
<TOKEN id="token-24-27" pos="unknown" morph="none" start_char="3903" end_char="3917">System/Stanford</TOKEN>
<TOKEN id="token-24-28" pos="word" morph="none" start_char="3919" end_char="3928">University</TOKEN>
<TOKEN id="token-24-29" pos="punct" morph="none" start_char="3929" end_char="3929">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="3932" end_char="4059">
<ORIGINAL_TEXT>However, a representative for the VA Palo Alto Health Care System told the AP in an email that Vainshelboim does not work there.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="3932" end_char="3938">However</TOKEN>
<TOKEN id="token-25-1" pos="punct" morph="none" start_char="3939" end_char="3939">,</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="3941" end_char="3941">a</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="3943" end_char="3956">representative</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="3958" end_char="3960">for</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="3962" end_char="3964">the</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="3966" end_char="3967">VA</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="3969" end_char="3972">Palo</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="3974" end_char="3977">Alto</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="3979" end_char="3984">Health</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="3986" end_char="3989">Care</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="3991" end_char="3996">System</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="3998" end_char="4001">told</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="4003" end_char="4005">the</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="4007" end_char="4008">AP</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="4010" end_char="4011">in</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="4013" end_char="4014">an</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="4016" end_char="4020">email</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="4022" end_char="4025">that</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="4027" end_char="4038">Vainshelboim</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="4040" end_char="4043">does</TOKEN>
<TOKEN id="token-25-21" pos="word" morph="none" start_char="4045" end_char="4047">not</TOKEN>
<TOKEN id="token-25-22" pos="word" morph="none" start_char="4049" end_char="4052">work</TOKEN>
<TOKEN id="token-25-23" pos="word" morph="none" start_char="4054" end_char="4058">there</TOKEN>
<TOKEN id="token-25-24" pos="punct" morph="none" start_char="4059" end_char="4059">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="4062" end_char="4191">
<ORIGINAL_TEXT>"I can confirm this person is not one of our physicians," wrote Michael Hill-Jackson, a public affairs specialist with the system.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="punct" morph="none" start_char="4062" end_char="4062">"</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="4063" end_char="4063">I</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="4065" end_char="4067">can</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="4069" end_char="4075">confirm</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="4077" end_char="4080">this</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="4082" end_char="4087">person</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="4089" end_char="4090">is</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="4092" end_char="4094">not</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="4096" end_char="4098">one</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="4100" end_char="4101">of</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="4103" end_char="4105">our</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="4107" end_char="4116">physicians</TOKEN>
<TOKEN id="token-26-12" pos="punct" morph="none" start_char="4117" end_char="4118">,"</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="4120" end_char="4124">wrote</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="4126" end_char="4132">Michael</TOKEN>
<TOKEN id="token-26-15" pos="unknown" morph="none" start_char="4134" end_char="4145">Hill-Jackson</TOKEN>
<TOKEN id="token-26-16" pos="punct" morph="none" start_char="4146" end_char="4146">,</TOKEN>
<TOKEN id="token-26-17" pos="word" morph="none" start_char="4148" end_char="4148">a</TOKEN>
<TOKEN id="token-26-18" pos="word" morph="none" start_char="4150" end_char="4155">public</TOKEN>
<TOKEN id="token-26-19" pos="word" morph="none" start_char="4157" end_char="4163">affairs</TOKEN>
<TOKEN id="token-26-20" pos="word" morph="none" start_char="4165" end_char="4174">specialist</TOKEN>
<TOKEN id="token-26-21" pos="word" morph="none" start_char="4176" end_char="4179">with</TOKEN>
<TOKEN id="token-26-22" pos="word" morph="none" start_char="4181" end_char="4183">the</TOKEN>
<TOKEN id="token-26-23" pos="word" morph="none" start_char="4185" end_char="4190">system</TOKEN>
<TOKEN id="token-26-24" pos="punct" morph="none" start_char="4191" end_char="4191">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="4193" end_char="4272">
<ORIGINAL_TEXT>"I do not see him in our system and our Cardiology team has never heard of him."</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="punct" morph="none" start_char="4193" end_char="4193">"</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="4194" end_char="4194">I</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="4196" end_char="4197">do</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="4199" end_char="4201">not</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="4203" end_char="4205">see</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="4207" end_char="4209">him</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="4211" end_char="4212">in</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="4214" end_char="4216">our</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="4218" end_char="4223">system</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="4225" end_char="4227">and</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="4229" end_char="4231">our</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="4233" end_char="4242">Cardiology</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="4244" end_char="4247">team</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="4249" end_char="4251">has</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="4253" end_char="4257">never</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="4259" end_char="4263">heard</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="4265" end_char="4266">of</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="4268" end_char="4270">him</TOKEN>
<TOKEN id="token-27-18" pos="punct" morph="none" start_char="4271" end_char="4272">."</TOKEN>
</SEG>
<SEG id="segment-28" start_char="4275" end_char="4428">
<ORIGINAL_TEXT>Vainshelboim also does not work for Stanford, according to Julie Greicius, senior director of external communications for the university’s medical school.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="4275" end_char="4286">Vainshelboim</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="4288" end_char="4291">also</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="4293" end_char="4296">does</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="4298" end_char="4300">not</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="4302" end_char="4305">work</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="4307" end_char="4309">for</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="4311" end_char="4318">Stanford</TOKEN>
<TOKEN id="token-28-7" pos="punct" morph="none" start_char="4319" end_char="4319">,</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="4321" end_char="4329">according</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="4331" end_char="4332">to</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="4334" end_char="4338">Julie</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="4340" end_char="4347">Greicius</TOKEN>
<TOKEN id="token-28-12" pos="punct" morph="none" start_char="4348" end_char="4348">,</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="4350" end_char="4355">senior</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="4357" end_char="4364">director</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="4366" end_char="4367">of</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="4369" end_char="4376">external</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="4378" end_char="4391">communications</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="4393" end_char="4395">for</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="4397" end_char="4399">the</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="4401" end_char="4412">university’s</TOKEN>
<TOKEN id="token-28-21" pos="word" morph="none" start_char="4414" end_char="4420">medical</TOKEN>
<TOKEN id="token-28-22" pos="word" morph="none" start_char="4422" end_char="4427">school</TOKEN>
<TOKEN id="token-28-23" pos="punct" morph="none" start_char="4428" end_char="4428">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="4431" end_char="4529">
<ORIGINAL_TEXT>"Stanford University has never employed Baruch Vainshelboim," Greicius wrote in an email to the AP.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="punct" morph="none" start_char="4431" end_char="4431">"</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="4432" end_char="4439">Stanford</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="4441" end_char="4450">University</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="4452" end_char="4454">has</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="4456" end_char="4460">never</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="4462" end_char="4469">employed</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="4471" end_char="4476">Baruch</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="4478" end_char="4489">Vainshelboim</TOKEN>
<TOKEN id="token-29-8" pos="punct" morph="none" start_char="4490" end_char="4491">,"</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="4493" end_char="4500">Greicius</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="4502" end_char="4506">wrote</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="4508" end_char="4509">in</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="4511" end_char="4512">an</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="4514" end_char="4518">email</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="4520" end_char="4521">to</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="4523" end_char="4525">the</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="4527" end_char="4528">AP</TOKEN>
<TOKEN id="token-29-17" pos="punct" morph="none" start_char="4529" end_char="4529">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="4531" end_char="4643">
<ORIGINAL_TEXT>"Several years ago (2015), he was a visiting scholar at Stanford for a year, on matters unrelated to this paper."</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="punct" morph="none" start_char="4531" end_char="4531">"</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="4532" end_char="4538">Several</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="4540" end_char="4544">years</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="4546" end_char="4548">ago</TOKEN>
<TOKEN id="token-30-4" pos="punct" morph="none" start_char="4550" end_char="4550">(</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="4551" end_char="4554">2015</TOKEN>
<TOKEN id="token-30-6" pos="punct" morph="none" start_char="4555" end_char="4556">),</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="4558" end_char="4559">he</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="4561" end_char="4563">was</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="4565" end_char="4565">a</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="4567" end_char="4574">visiting</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="4576" end_char="4582">scholar</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="4584" end_char="4585">at</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="4587" end_char="4594">Stanford</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="4596" end_char="4598">for</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="4600" end_char="4600">a</TOKEN>
<TOKEN id="token-30-16" pos="word" morph="none" start_char="4602" end_char="4605">year</TOKEN>
<TOKEN id="token-30-17" pos="punct" morph="none" start_char="4606" end_char="4606">,</TOKEN>
<TOKEN id="token-30-18" pos="word" morph="none" start_char="4608" end_char="4609">on</TOKEN>
<TOKEN id="token-30-19" pos="word" morph="none" start_char="4611" end_char="4617">matters</TOKEN>
<TOKEN id="token-30-20" pos="word" morph="none" start_char="4619" end_char="4627">unrelated</TOKEN>
<TOKEN id="token-30-21" pos="word" morph="none" start_char="4629" end_char="4630">to</TOKEN>
<TOKEN id="token-30-22" pos="word" morph="none" start_char="4632" end_char="4635">this</TOKEN>
<TOKEN id="token-30-23" pos="word" morph="none" start_char="4637" end_char="4641">paper</TOKEN>
<TOKEN id="token-30-24" pos="punct" morph="none" start_char="4642" end_char="4643">."</TOKEN>
</SEG>
<SEG id="segment-31" start_char="4646" end_char="4808">
<ORIGINAL_TEXT>Vainshelboim, who lists himself on LinkedIn as a clinical exercise physiologist and does not list any current employment, did not respond to a request for comment.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="4646" end_char="4657">Vainshelboim</TOKEN>
<TOKEN id="token-31-1" pos="punct" morph="none" start_char="4658" end_char="4658">,</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="4660" end_char="4662">who</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="4664" end_char="4668">lists</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="4670" end_char="4676">himself</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="4678" end_char="4679">on</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="4681" end_char="4688">LinkedIn</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="4690" end_char="4691">as</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="4693" end_char="4693">a</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="4695" end_char="4702">clinical</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="4704" end_char="4711">exercise</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="4713" end_char="4724">physiologist</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="4726" end_char="4728">and</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="4730" end_char="4733">does</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="4735" end_char="4737">not</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="4739" end_char="4742">list</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="4744" end_char="4746">any</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="4748" end_char="4754">current</TOKEN>
<TOKEN id="token-31-18" pos="word" morph="none" start_char="4756" end_char="4765">employment</TOKEN>
<TOKEN id="token-31-19" pos="punct" morph="none" start_char="4766" end_char="4766">,</TOKEN>
<TOKEN id="token-31-20" pos="word" morph="none" start_char="4768" end_char="4770">did</TOKEN>
<TOKEN id="token-31-21" pos="word" morph="none" start_char="4772" end_char="4774">not</TOKEN>
<TOKEN id="token-31-22" pos="word" morph="none" start_char="4776" end_char="4782">respond</TOKEN>
<TOKEN id="token-31-23" pos="word" morph="none" start_char="4784" end_char="4785">to</TOKEN>
<TOKEN id="token-31-24" pos="word" morph="none" start_char="4787" end_char="4787">a</TOKEN>
<TOKEN id="token-31-25" pos="word" morph="none" start_char="4789" end_char="4795">request</TOKEN>
<TOKEN id="token-31-26" pos="word" morph="none" start_char="4797" end_char="4799">for</TOKEN>
<TOKEN id="token-31-27" pos="word" morph="none" start_char="4801" end_char="4807">comment</TOKEN>
<TOKEN id="token-31-28" pos="punct" morph="none" start_char="4808" end_char="4808">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="4811" end_char="4813">
<ORIGINAL_TEXT>___</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="4811" end_char="4813">___</TOKEN>
</SEG>
<SEG id="segment-33" start_char="4816" end_char="5028">
<ORIGINAL_TEXT>This is part of The Associated Press’ ongoing effort to fact-check misinformation that is shared widely online, including work with Facebook to identify and reduce the circulation of false stories on the platform.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="4816" end_char="4819">This</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="4821" end_char="4822">is</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="4824" end_char="4827">part</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="4829" end_char="4830">of</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="4832" end_char="4834">The</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="4836" end_char="4845">Associated</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="4847" end_char="4851">Press</TOKEN>
<TOKEN id="token-33-7" pos="punct" morph="none" start_char="4852" end_char="4852">’</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="4854" end_char="4860">ongoing</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="4862" end_char="4867">effort</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="4869" end_char="4870">to</TOKEN>
<TOKEN id="token-33-11" pos="unknown" morph="none" start_char="4872" end_char="4881">fact-check</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="4883" end_char="4896">misinformation</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="4898" end_char="4901">that</TOKEN>
<TOKEN id="token-33-14" pos="word" morph="none" start_char="4903" end_char="4904">is</TOKEN>
<TOKEN id="token-33-15" pos="word" morph="none" start_char="4906" end_char="4911">shared</TOKEN>
<TOKEN id="token-33-16" pos="word" morph="none" start_char="4913" end_char="4918">widely</TOKEN>
<TOKEN id="token-33-17" pos="word" morph="none" start_char="4920" end_char="4925">online</TOKEN>
<TOKEN id="token-33-18" pos="punct" morph="none" start_char="4926" end_char="4926">,</TOKEN>
<TOKEN id="token-33-19" pos="word" morph="none" start_char="4928" end_char="4936">including</TOKEN>
<TOKEN id="token-33-20" pos="word" morph="none" start_char="4938" end_char="4941">work</TOKEN>
<TOKEN id="token-33-21" pos="word" morph="none" start_char="4943" end_char="4946">with</TOKEN>
<TOKEN id="token-33-22" pos="word" morph="none" start_char="4948" end_char="4955">Facebook</TOKEN>
<TOKEN id="token-33-23" pos="word" morph="none" start_char="4957" end_char="4958">to</TOKEN>
<TOKEN id="token-33-24" pos="word" morph="none" start_char="4960" end_char="4967">identify</TOKEN>
<TOKEN id="token-33-25" pos="word" morph="none" start_char="4969" end_char="4971">and</TOKEN>
<TOKEN id="token-33-26" pos="word" morph="none" start_char="4973" end_char="4978">reduce</TOKEN>
<TOKEN id="token-33-27" pos="word" morph="none" start_char="4980" end_char="4982">the</TOKEN>
<TOKEN id="token-33-28" pos="word" morph="none" start_char="4984" end_char="4994">circulation</TOKEN>
<TOKEN id="token-33-29" pos="word" morph="none" start_char="4996" end_char="4997">of</TOKEN>
<TOKEN id="token-33-30" pos="word" morph="none" start_char="4999" end_char="5003">false</TOKEN>
<TOKEN id="token-33-31" pos="word" morph="none" start_char="5005" end_char="5011">stories</TOKEN>
<TOKEN id="token-33-32" pos="word" morph="none" start_char="5013" end_char="5014">on</TOKEN>
<TOKEN id="token-33-33" pos="word" morph="none" start_char="5016" end_char="5018">the</TOKEN>
<TOKEN id="token-33-34" pos="word" morph="none" start_char="5020" end_char="5027">platform</TOKEN>
<TOKEN id="token-33-35" pos="punct" morph="none" start_char="5028" end_char="5028">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="5031" end_char="5137">
<ORIGINAL_TEXT>Here’s more information on Facebook’s fact-checking program: https://www.facebook.com/help/1952307158131536</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="5031" end_char="5036">Here’s</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="5038" end_char="5041">more</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="5043" end_char="5053">information</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="5055" end_char="5056">on</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="5058" end_char="5067">Facebook’s</TOKEN>
<TOKEN id="token-34-5" pos="unknown" morph="none" start_char="5069" end_char="5081">fact-checking</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="5083" end_char="5089">program</TOKEN>
<TOKEN id="token-34-7" pos="punct" morph="none" start_char="5090" end_char="5090">:</TOKEN>
<TOKEN id="token-34-8" pos="url" morph="none" start_char="5092" end_char="5137">https://www.facebook.com/help/1952307158131536</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
