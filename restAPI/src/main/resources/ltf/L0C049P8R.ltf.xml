<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="ukr">
<DOC id="L0C049P8R" lang="ukr" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="4419" raw_text_md5="a2f4b59b0ea063a7696002ca1c6bc312">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="77">
<ORIGINAL_TEXT>One-third of Americans think government hiding virus cure despite no evidence</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="unknown" morph="none" start_char="1" end_char="9">One-third</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="11" end_char="12">of</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="14" end_char="22">Americans</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="24" end_char="28">think</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="30" end_char="39">government</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="41" end_char="46">hiding</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="48" end_char="52">virus</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="54" end_char="57">cure</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="59" end_char="65">despite</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="67" end_char="68">no</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="70" end_char="77">evidence</TOKEN>
</SEG>
<SEG id="segment-1" start_char="81" end_char="216">
<ORIGINAL_TEXT>SUSPICIOUS Americans reckon a coronavirus vaccine has been created, but that it's being "withheld from the public", a joint study shows.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="81" end_char="90">SUSPICIOUS</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="92" end_char="100">Americans</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="102" end_char="107">reckon</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="109" end_char="109">a</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="111" end_char="121">coronavirus</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="123" end_char="129">vaccine</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="131" end_char="133">has</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="135" end_char="138">been</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="140" end_char="146">created</TOKEN>
<TOKEN id="token-1-9" pos="punct" morph="none" start_char="147" end_char="147">,</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="149" end_char="151">but</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="153" end_char="156">that</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="158" end_char="161">it's</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="163" end_char="167">being</TOKEN>
<TOKEN id="token-1-14" pos="punct" morph="none" start_char="169" end_char="169">"</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="170" end_char="177">withheld</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="179" end_char="182">from</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="184" end_char="186">the</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="188" end_char="193">public</TOKEN>
<TOKEN id="token-1-19" pos="punct" morph="none" start_char="194" end_char="195">",</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="197" end_char="197">a</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="199" end_char="203">joint</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="205" end_char="209">study</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="211" end_char="215">shows</TOKEN>
<TOKEN id="token-1-24" pos="punct" morph="none" start_char="216" end_char="216">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="219" end_char="364">
<ORIGINAL_TEXT>Nearly one-third of those surveyed believe a vaccine already exists to prevent the bug, while nearly half maintain the virus was created in a lab.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="219" end_char="224">Nearly</TOKEN>
<TOKEN id="token-2-1" pos="unknown" morph="none" start_char="226" end_char="234">one-third</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="236" end_char="237">of</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="239" end_char="243">those</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="245" end_char="252">surveyed</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="254" end_char="260">believe</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="262" end_char="262">a</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="264" end_char="270">vaccine</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="272" end_char="278">already</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="280" end_char="285">exists</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="287" end_char="288">to</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="290" end_char="296">prevent</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="298" end_char="300">the</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="302" end_char="304">bug</TOKEN>
<TOKEN id="token-2-14" pos="punct" morph="none" start_char="305" end_char="305">,</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="307" end_char="311">while</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="313" end_char="318">nearly</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="320" end_char="323">half</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="325" end_char="332">maintain</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="334" end_char="336">the</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="338" end_char="342">virus</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="344" end_char="346">was</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="348" end_char="354">created</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="356" end_char="357">in</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="359" end_char="359">a</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="361" end_char="363">lab</TOKEN>
<TOKEN id="token-2-26" pos="punct" morph="none" start_char="364" end_char="364">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="367" end_char="428">
<ORIGINAL_TEXT>More than 80 Covid-19 vaccine trials underway across the world</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="367" end_char="370">More</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="372" end_char="375">than</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="377" end_char="378">80</TOKEN>
<TOKEN id="token-3-3" pos="unknown" morph="none" start_char="380" end_char="387">Covid-19</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="389" end_char="395">vaccine</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="397" end_char="402">trials</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="404" end_char="411">underway</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="413" end_char="418">across</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="420" end_char="422">the</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="424" end_char="428">world</TOKEN>
</SEG>
<SEG id="segment-4" start_char="432" end_char="544">
<ORIGINAL_TEXT>The Democracy Fund and UCLA Nationscape Project, along with USA Today, quizzed 6,300 Americans from April 2 to 8.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="432" end_char="434">The</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="436" end_char="444">Democracy</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="446" end_char="449">Fund</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="451" end_char="453">and</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="455" end_char="458">UCLA</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="460" end_char="470">Nationscape</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="472" end_char="478">Project</TOKEN>
<TOKEN id="token-4-7" pos="punct" morph="none" start_char="479" end_char="479">,</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="481" end_char="485">along</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="487" end_char="490">with</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="492" end_char="494">USA</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="496" end_char="500">Today</TOKEN>
<TOKEN id="token-4-12" pos="punct" morph="none" start_char="501" end_char="501">,</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="503" end_char="509">quizzed</TOKEN>
<TOKEN id="token-4-14" pos="unknown" morph="none" start_char="511" end_char="515">6,300</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="517" end_char="525">Americans</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="527" end_char="530">from</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="532" end_char="536">April</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="538" end_char="538">2</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="540" end_char="541">to</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="543" end_char="543">8</TOKEN>
<TOKEN id="token-4-21" pos="punct" morph="none" start_char="544" end_char="544">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="547" end_char="714">
<ORIGINAL_TEXT>Shockingly, their survey found that nearly 50 per cent of respondents refuse to believe the official death toll, which has already soared to more than 54,000 in the US.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="547" end_char="556">Shockingly</TOKEN>
<TOKEN id="token-5-1" pos="punct" morph="none" start_char="557" end_char="557">,</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="559" end_char="563">their</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="565" end_char="570">survey</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="572" end_char="576">found</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="578" end_char="581">that</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="583" end_char="588">nearly</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="590" end_char="591">50</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="593" end_char="595">per</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="597" end_char="600">cent</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="602" end_char="603">of</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="605" end_char="615">respondents</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="617" end_char="622">refuse</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="624" end_char="625">to</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="627" end_char="633">believe</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="635" end_char="637">the</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="639" end_char="646">official</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="648" end_char="652">death</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="654" end_char="657">toll</TOKEN>
<TOKEN id="token-5-19" pos="punct" morph="none" start_char="658" end_char="658">,</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="660" end_char="664">which</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="666" end_char="668">has</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="670" end_char="676">already</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="678" end_char="683">soared</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="685" end_char="686">to</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="688" end_char="691">more</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="693" end_char="696">than</TOKEN>
<TOKEN id="token-5-27" pos="unknown" morph="none" start_char="698" end_char="703">54,000</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="705" end_char="706">in</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="708" end_char="710">the</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="712" end_char="713">US</TOKEN>
<TOKEN id="token-5-31" pos="punct" morph="none" start_char="714" end_char="714">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="717" end_char="849">
<ORIGINAL_TEXT>Des Moines Register said the results showed people have a lot of mistrust in health officials and the government during the pandemic.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="717" end_char="719">Des</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="721" end_char="726">Moines</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="728" end_char="735">Register</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="737" end_char="740">said</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="742" end_char="744">the</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="746" end_char="752">results</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="754" end_char="759">showed</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="761" end_char="766">people</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="768" end_char="771">have</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="773" end_char="773">a</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="775" end_char="777">lot</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="779" end_char="780">of</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="782" end_char="789">mistrust</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="791" end_char="792">in</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="794" end_char="799">health</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="801" end_char="809">officials</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="811" end_char="813">and</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="815" end_char="817">the</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="819" end_char="828">government</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="830" end_char="835">during</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="837" end_char="839">the</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="841" end_char="848">pandemic</TOKEN>
<TOKEN id="token-6-22" pos="punct" morph="none" start_char="849" end_char="849">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="852" end_char="1014">
<ORIGINAL_TEXT>Twenty-nine per cent said it was either probably or definitely true that a vaccine preventing coronavirus infection exists, but was being withheld from the public.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="unknown" morph="none" start_char="852" end_char="862">Twenty-nine</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="864" end_char="866">per</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="868" end_char="871">cent</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="873" end_char="876">said</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="878" end_char="879">it</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="881" end_char="883">was</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="885" end_char="890">either</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="892" end_char="899">probably</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="901" end_char="902">or</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="904" end_char="913">definitely</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="915" end_char="918">true</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="920" end_char="923">that</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="925" end_char="925">a</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="927" end_char="933">vaccine</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="935" end_char="944">preventing</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="946" end_char="956">coronavirus</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="958" end_char="966">infection</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="968" end_char="973">exists</TOKEN>
<TOKEN id="token-7-18" pos="punct" morph="none" start_char="974" end_char="974">,</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="976" end_char="978">but</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="980" end_char="982">was</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="984" end_char="988">being</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="990" end_char="997">withheld</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="999" end_char="1002">from</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="1004" end_char="1006">the</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="1008" end_char="1013">public</TOKEN>
<TOKEN id="token-7-26" pos="punct" morph="none" start_char="1014" end_char="1014">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1017" end_char="1147">
<ORIGINAL_TEXT>And 32 per cent of respondents maintained that cures to beat Covid-19 infections exist but are also not being shared with patients.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1017" end_char="1019">And</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1021" end_char="1022">32</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1024" end_char="1026">per</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1028" end_char="1031">cent</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1033" end_char="1034">of</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1036" end_char="1046">respondents</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1048" end_char="1057">maintained</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1059" end_char="1062">that</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1064" end_char="1068">cures</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1070" end_char="1071">to</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1073" end_char="1076">beat</TOKEN>
<TOKEN id="token-8-11" pos="unknown" morph="none" start_char="1078" end_char="1085">Covid-19</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1087" end_char="1096">infections</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1098" end_char="1102">exist</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1104" end_char="1106">but</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1108" end_char="1110">are</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1112" end_char="1115">also</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1117" end_char="1119">not</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1121" end_char="1125">being</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1127" end_char="1132">shared</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="1134" end_char="1137">with</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="1139" end_char="1146">patients</TOKEN>
<TOKEN id="token-8-22" pos="punct" morph="none" start_char="1147" end_char="1147">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1150" end_char="1224">
<ORIGINAL_TEXT>However, about seven out of ten Americans said those statements were false.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1150" end_char="1156">However</TOKEN>
<TOKEN id="token-9-1" pos="punct" morph="none" start_char="1157" end_char="1157">,</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1159" end_char="1163">about</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1165" end_char="1169">seven</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1171" end_char="1173">out</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1175" end_char="1176">of</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1178" end_char="1180">ten</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1182" end_char="1190">Americans</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1192" end_char="1195">said</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1197" end_char="1201">those</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1203" end_char="1212">statements</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1214" end_char="1217">were</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1219" end_char="1223">false</TOKEN>
<TOKEN id="token-9-13" pos="punct" morph="none" start_char="1224" end_char="1224">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1227" end_char="1255">
<ORIGINAL_TEXT>To believe or not to believe?</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1227" end_char="1228">To</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1230" end_char="1236">believe</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1238" end_char="1239">or</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1241" end_char="1243">not</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1245" end_char="1246">to</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1248" end_char="1254">believe</TOKEN>
<TOKEN id="token-10-6" pos="punct" morph="none" start_char="1255" end_char="1255">?</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1257" end_char="1335">
<ORIGINAL_TEXT>There's a strong core of Americans who reckon the coronavirus cure is out there</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1257" end_char="1263">There's</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1265" end_char="1265">a</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1267" end_char="1272">strong</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1274" end_char="1277">core</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1279" end_char="1280">of</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1282" end_char="1290">Americans</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1292" end_char="1294">who</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1296" end_char="1301">reckon</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1303" end_char="1305">the</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1307" end_char="1317">coronavirus</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1319" end_char="1322">cure</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1324" end_char="1325">is</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1327" end_char="1329">out</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1331" end_char="1335">there</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1339" end_char="1536">
<ORIGINAL_TEXT>Robert Griffin, research director for the Democracy Fund Voter Study Group, said: "To see about a third of people give that some level of, 'Yeah, that might be true,' that was pretty shocking to me.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1339" end_char="1344">Robert</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1346" end_char="1352">Griffin</TOKEN>
<TOKEN id="token-12-2" pos="punct" morph="none" start_char="1353" end_char="1353">,</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1355" end_char="1362">research</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1364" end_char="1371">director</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1373" end_char="1375">for</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1377" end_char="1379">the</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1381" end_char="1389">Democracy</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1391" end_char="1394">Fund</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1396" end_char="1400">Voter</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1402" end_char="1406">Study</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1408" end_char="1412">Group</TOKEN>
<TOKEN id="token-12-12" pos="punct" morph="none" start_char="1413" end_char="1413">,</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1415" end_char="1418">said</TOKEN>
<TOKEN id="token-12-14" pos="punct" morph="none" start_char="1419" end_char="1419">:</TOKEN>
<TOKEN id="token-12-15" pos="punct" morph="none" start_char="1421" end_char="1421">"</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1422" end_char="1423">To</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1425" end_char="1427">see</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1429" end_char="1433">about</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1435" end_char="1435">a</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1437" end_char="1441">third</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1443" end_char="1444">of</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1446" end_char="1451">people</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="1453" end_char="1456">give</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="1458" end_char="1461">that</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="1463" end_char="1466">some</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="1468" end_char="1472">level</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="1474" end_char="1475">of</TOKEN>
<TOKEN id="token-12-28" pos="punct" morph="none" start_char="1476" end_char="1476">,</TOKEN>
<TOKEN id="token-12-29" pos="punct" morph="none" start_char="1478" end_char="1478">'</TOKEN>
<TOKEN id="token-12-30" pos="word" morph="none" start_char="1479" end_char="1482">Yeah</TOKEN>
<TOKEN id="token-12-31" pos="punct" morph="none" start_char="1483" end_char="1483">,</TOKEN>
<TOKEN id="token-12-32" pos="word" morph="none" start_char="1485" end_char="1488">that</TOKEN>
<TOKEN id="token-12-33" pos="word" morph="none" start_char="1490" end_char="1494">might</TOKEN>
<TOKEN id="token-12-34" pos="word" morph="none" start_char="1496" end_char="1497">be</TOKEN>
<TOKEN id="token-12-35" pos="word" morph="none" start_char="1499" end_char="1502">true</TOKEN>
<TOKEN id="token-12-36" pos="punct" morph="none" start_char="1503" end_char="1504">,'</TOKEN>
<TOKEN id="token-12-37" pos="word" morph="none" start_char="1506" end_char="1509">that</TOKEN>
<TOKEN id="token-12-38" pos="word" morph="none" start_char="1511" end_char="1513">was</TOKEN>
<TOKEN id="token-12-39" pos="word" morph="none" start_char="1515" end_char="1520">pretty</TOKEN>
<TOKEN id="token-12-40" pos="word" morph="none" start_char="1522" end_char="1529">shocking</TOKEN>
<TOKEN id="token-12-41" pos="word" morph="none" start_char="1531" end_char="1532">to</TOKEN>
<TOKEN id="token-12-42" pos="word" morph="none" start_char="1534" end_char="1535">me</TOKEN>
<TOKEN id="token-12-43" pos="punct" morph="none" start_char="1536" end_char="1536">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1539" end_char="1609">
<ORIGINAL_TEXT>"That's a pretty dark type of thought to be floating around the public.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="punct" morph="none" start_char="1539" end_char="1539">"</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1540" end_char="1545">That's</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1547" end_char="1547">a</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1549" end_char="1554">pretty</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1556" end_char="1559">dark</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1561" end_char="1564">type</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1566" end_char="1567">of</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1569" end_char="1575">thought</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1577" end_char="1578">to</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1580" end_char="1581">be</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1583" end_char="1590">floating</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1592" end_char="1597">around</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1599" end_char="1601">the</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1603" end_char="1608">public</TOKEN>
<TOKEN id="token-13-14" pos="punct" morph="none" start_char="1609" end_char="1609">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1612" end_char="1694">
<ORIGINAL_TEXT>"There's an undercurrent of a lack of trust in society, a lack of trust in elites."</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="punct" morph="none" start_char="1612" end_char="1612">"</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1613" end_char="1619">There's</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1621" end_char="1622">an</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1624" end_char="1635">undercurrent</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1637" end_char="1638">of</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1640" end_char="1640">a</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1642" end_char="1645">lack</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1647" end_char="1648">of</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1650" end_char="1654">trust</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1656" end_char="1657">in</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1659" end_char="1665">society</TOKEN>
<TOKEN id="token-14-11" pos="punct" morph="none" start_char="1666" end_char="1666">,</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1668" end_char="1668">a</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1670" end_char="1673">lack</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="1675" end_char="1676">of</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1678" end_char="1682">trust</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1684" end_char="1685">in</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="1687" end_char="1692">elites</TOKEN>
<TOKEN id="token-14-18" pos="punct" morph="none" start_char="1693" end_char="1694">."</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1697" end_char="1800">
<ORIGINAL_TEXT>Interestingly, the survey found that 44 per cent believed the coronavirus was probably created in a lab.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1697" end_char="1709">Interestingly</TOKEN>
<TOKEN id="token-15-1" pos="punct" morph="none" start_char="1710" end_char="1710">,</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1712" end_char="1714">the</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1716" end_char="1721">survey</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1723" end_char="1727">found</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1729" end_char="1732">that</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1734" end_char="1735">44</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1737" end_char="1739">per</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1741" end_char="1744">cent</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1746" end_char="1753">believed</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1755" end_char="1757">the</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1759" end_char="1769">coronavirus</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1771" end_char="1773">was</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1775" end_char="1782">probably</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1784" end_char="1790">created</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="1792" end_char="1793">in</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="1795" end_char="1795">a</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="1797" end_char="1799">lab</TOKEN>
<TOKEN id="token-15-18" pos="punct" morph="none" start_char="1800" end_char="1800">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1803" end_char="1862">
<ORIGINAL_TEXT>Griffin told the Register: "The key word there is 'created'.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1803" end_char="1809">Griffin</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1811" end_char="1814">told</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1816" end_char="1818">the</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1820" end_char="1827">Register</TOKEN>
<TOKEN id="token-16-4" pos="punct" morph="none" start_char="1828" end_char="1828">:</TOKEN>
<TOKEN id="token-16-5" pos="punct" morph="none" start_char="1830" end_char="1830">"</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1831" end_char="1833">The</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1835" end_char="1837">key</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1839" end_char="1842">word</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="1844" end_char="1848">there</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="1850" end_char="1851">is</TOKEN>
<TOKEN id="token-16-11" pos="punct" morph="none" start_char="1853" end_char="1853">'</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="1854" end_char="1860">created</TOKEN>
<TOKEN id="token-16-13" pos="punct" morph="none" start_char="1861" end_char="1862">'.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1864" end_char="1915">
<ORIGINAL_TEXT>It is a question that points toward intentionality."</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1864" end_char="1865">It</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1867" end_char="1868">is</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="1870" end_char="1870">a</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="1872" end_char="1879">question</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="1881" end_char="1884">that</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="1886" end_char="1891">points</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="1893" end_char="1898">toward</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="1900" end_char="1913">intentionality</TOKEN>
<TOKEN id="token-17-8" pos="punct" morph="none" start_char="1914" end_char="1915">."</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1918" end_char="1935">
<ORIGINAL_TEXT>Connection to bats</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="1918" end_char="1927">Connection</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="1929" end_char="1930">to</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="1932" end_char="1935">bats</TOKEN>
</SEG>
<SEG id="segment-19" start_char="1939" end_char="2134">
<ORIGINAL_TEXT>Yet the World Health Organization (WHO) said on Tuesday that all available evidence suggests the coronavirus originated in bats in China late last year and it was not manipulated or made in a lab.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="1939" end_char="1941">Yet</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="1943" end_char="1945">the</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="1947" end_char="1951">World</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="1953" end_char="1958">Health</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="1960" end_char="1971">Organization</TOKEN>
<TOKEN id="token-19-5" pos="punct" morph="none" start_char="1973" end_char="1973">(</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="1974" end_char="1976">WHO</TOKEN>
<TOKEN id="token-19-7" pos="punct" morph="none" start_char="1977" end_char="1977">)</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="1979" end_char="1982">said</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="1984" end_char="1985">on</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="1987" end_char="1993">Tuesday</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="1995" end_char="1998">that</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="2000" end_char="2002">all</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="2004" end_char="2012">available</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="2014" end_char="2021">evidence</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="2023" end_char="2030">suggests</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="2032" end_char="2034">the</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="2036" end_char="2046">coronavirus</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="2048" end_char="2057">originated</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="2059" end_char="2060">in</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="2062" end_char="2065">bats</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="2067" end_char="2068">in</TOKEN>
<TOKEN id="token-19-22" pos="word" morph="none" start_char="2070" end_char="2074">China</TOKEN>
<TOKEN id="token-19-23" pos="word" morph="none" start_char="2076" end_char="2079">late</TOKEN>
<TOKEN id="token-19-24" pos="word" morph="none" start_char="2081" end_char="2084">last</TOKEN>
<TOKEN id="token-19-25" pos="word" morph="none" start_char="2086" end_char="2089">year</TOKEN>
<TOKEN id="token-19-26" pos="word" morph="none" start_char="2091" end_char="2093">and</TOKEN>
<TOKEN id="token-19-27" pos="word" morph="none" start_char="2095" end_char="2096">it</TOKEN>
<TOKEN id="token-19-28" pos="word" morph="none" start_char="2098" end_char="2100">was</TOKEN>
<TOKEN id="token-19-29" pos="word" morph="none" start_char="2102" end_char="2104">not</TOKEN>
<TOKEN id="token-19-30" pos="word" morph="none" start_char="2106" end_char="2116">manipulated</TOKEN>
<TOKEN id="token-19-31" pos="word" morph="none" start_char="2118" end_char="2119">or</TOKEN>
<TOKEN id="token-19-32" pos="word" morph="none" start_char="2121" end_char="2124">made</TOKEN>
<TOKEN id="token-19-33" pos="word" morph="none" start_char="2126" end_char="2127">in</TOKEN>
<TOKEN id="token-19-34" pos="word" morph="none" start_char="2129" end_char="2129">a</TOKEN>
<TOKEN id="token-19-35" pos="word" morph="none" start_char="2131" end_char="2133">lab</TOKEN>
<TOKEN id="token-19-36" pos="punct" morph="none" start_char="2134" end_char="2134">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2137" end_char="2288">
<ORIGINAL_TEXT>US President Donald Trump said last week that his government was trying to determine whether the new bug emanated from a lab in Wuhan, in central China.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2137" end_char="2138">US</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2140" end_char="2148">President</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2150" end_char="2155">Donald</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2157" end_char="2161">Trump</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2163" end_char="2166">said</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2168" end_char="2171">last</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2173" end_char="2176">week</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2178" end_char="2181">that</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="2183" end_char="2185">his</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2187" end_char="2196">government</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2198" end_char="2200">was</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="2202" end_char="2207">trying</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="2209" end_char="2210">to</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="2212" end_char="2220">determine</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="2222" end_char="2228">whether</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="2230" end_char="2232">the</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="2234" end_char="2236">new</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="2238" end_char="2240">bug</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="2242" end_char="2249">emanated</TOKEN>
<TOKEN id="token-20-19" pos="word" morph="none" start_char="2251" end_char="2254">from</TOKEN>
<TOKEN id="token-20-20" pos="word" morph="none" start_char="2256" end_char="2256">a</TOKEN>
<TOKEN id="token-20-21" pos="word" morph="none" start_char="2258" end_char="2260">lab</TOKEN>
<TOKEN id="token-20-22" pos="word" morph="none" start_char="2262" end_char="2263">in</TOKEN>
<TOKEN id="token-20-23" pos="word" morph="none" start_char="2265" end_char="2269">Wuhan</TOKEN>
<TOKEN id="token-20-24" pos="punct" morph="none" start_char="2270" end_char="2270">,</TOKEN>
<TOKEN id="token-20-25" pos="word" morph="none" start_char="2272" end_char="2273">in</TOKEN>
<TOKEN id="token-20-26" pos="word" morph="none" start_char="2275" end_char="2281">central</TOKEN>
<TOKEN id="token-20-27" pos="word" morph="none" start_char="2283" end_char="2287">China</TOKEN>
<TOKEN id="token-20-28" pos="punct" morph="none" start_char="2288" end_char="2288">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2291" end_char="2483">
<ORIGINAL_TEXT>WHO spokeswoman Fadela Chaib told a Geneva news briefing: "All available evidence suggests the virus has an animal origin and is not manipulated or constructed virus in a lab or somewhere else.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2291" end_char="2293">WHO</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2295" end_char="2305">spokeswoman</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2307" end_char="2312">Fadela</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2314" end_char="2318">Chaib</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2320" end_char="2323">told</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="2325" end_char="2325">a</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2327" end_char="2332">Geneva</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="2334" end_char="2337">news</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="2339" end_char="2346">briefing</TOKEN>
<TOKEN id="token-21-9" pos="punct" morph="none" start_char="2347" end_char="2347">:</TOKEN>
<TOKEN id="token-21-10" pos="punct" morph="none" start_char="2349" end_char="2349">"</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="2350" end_char="2352">All</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="2354" end_char="2362">available</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="2364" end_char="2371">evidence</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="2373" end_char="2380">suggests</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="2382" end_char="2384">the</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="2386" end_char="2390">virus</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="2392" end_char="2394">has</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="2396" end_char="2397">an</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="2399" end_char="2404">animal</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="2406" end_char="2411">origin</TOKEN>
<TOKEN id="token-21-21" pos="word" morph="none" start_char="2413" end_char="2415">and</TOKEN>
<TOKEN id="token-21-22" pos="word" morph="none" start_char="2417" end_char="2418">is</TOKEN>
<TOKEN id="token-21-23" pos="word" morph="none" start_char="2420" end_char="2422">not</TOKEN>
<TOKEN id="token-21-24" pos="word" morph="none" start_char="2424" end_char="2434">manipulated</TOKEN>
<TOKEN id="token-21-25" pos="word" morph="none" start_char="2436" end_char="2437">or</TOKEN>
<TOKEN id="token-21-26" pos="word" morph="none" start_char="2439" end_char="2449">constructed</TOKEN>
<TOKEN id="token-21-27" pos="word" morph="none" start_char="2451" end_char="2455">virus</TOKEN>
<TOKEN id="token-21-28" pos="word" morph="none" start_char="2457" end_char="2458">in</TOKEN>
<TOKEN id="token-21-29" pos="word" morph="none" start_char="2460" end_char="2460">a</TOKEN>
<TOKEN id="token-21-30" pos="word" morph="none" start_char="2462" end_char="2464">lab</TOKEN>
<TOKEN id="token-21-31" pos="word" morph="none" start_char="2466" end_char="2467">or</TOKEN>
<TOKEN id="token-21-32" pos="word" morph="none" start_char="2469" end_char="2477">somewhere</TOKEN>
<TOKEN id="token-21-33" pos="word" morph="none" start_char="2479" end_char="2482">else</TOKEN>
<TOKEN id="token-21-34" pos="punct" morph="none" start_char="2483" end_char="2483">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2486" end_char="2545">
<ORIGINAL_TEXT>"It is probable, likely that the virus is of animal origin."</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="punct" morph="none" start_char="2486" end_char="2486">"</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2487" end_char="2488">It</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2490" end_char="2491">is</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2493" end_char="2500">probable</TOKEN>
<TOKEN id="token-22-4" pos="punct" morph="none" start_char="2501" end_char="2501">,</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2503" end_char="2508">likely</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2510" end_char="2513">that</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2515" end_char="2517">the</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="2519" end_char="2523">virus</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="2525" end_char="2526">is</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="2528" end_char="2529">of</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="2531" end_char="2536">animal</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="2538" end_char="2543">origin</TOKEN>
<TOKEN id="token-22-13" pos="punct" morph="none" start_char="2544" end_char="2545">."</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2548" end_char="2563">
<ORIGINAL_TEXT>Scores of trials</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2548" end_char="2553">Scores</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2555" end_char="2556">of</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2558" end_char="2563">trials</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2567" end_char="2680">
<ORIGINAL_TEXT>The joint survey findings comes despite reports of more than 80 Covid-19 vaccine trials underway across the world.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="2567" end_char="2569">The</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="2571" end_char="2575">joint</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="2577" end_char="2582">survey</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="2584" end_char="2591">findings</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="2593" end_char="2597">comes</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="2599" end_char="2605">despite</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="2607" end_char="2613">reports</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="2615" end_char="2616">of</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="2618" end_char="2621">more</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="2623" end_char="2626">than</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="2628" end_char="2629">80</TOKEN>
<TOKEN id="token-24-11" pos="unknown" morph="none" start_char="2631" end_char="2638">Covid-19</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="2640" end_char="2646">vaccine</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="2648" end_char="2653">trials</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="2655" end_char="2662">underway</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="2664" end_char="2669">across</TOKEN>
<TOKEN id="token-24-16" pos="word" morph="none" start_char="2671" end_char="2673">the</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="2675" end_char="2679">world</TOKEN>
<TOKEN id="token-24-18" pos="punct" morph="none" start_char="2680" end_char="2680">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2683" end_char="2872">
<ORIGINAL_TEXT>Adam Kleczkowski Professor of Mathematics and Statistics, University of Strathclyde in Glasgow, Scotland, told The Conversation that vaccinating everyone "is neither practical nor feasible".</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="2683" end_char="2686">Adam</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="2688" end_char="2698">Kleczkowski</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="2700" end_char="2708">Professor</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="2710" end_char="2711">of</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="2713" end_char="2723">Mathematics</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="2725" end_char="2727">and</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="2729" end_char="2738">Statistics</TOKEN>
<TOKEN id="token-25-7" pos="punct" morph="none" start_char="2739" end_char="2739">,</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="2741" end_char="2750">University</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="2752" end_char="2753">of</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="2755" end_char="2765">Strathclyde</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="2767" end_char="2768">in</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="2770" end_char="2776">Glasgow</TOKEN>
<TOKEN id="token-25-13" pos="punct" morph="none" start_char="2777" end_char="2777">,</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="2779" end_char="2786">Scotland</TOKEN>
<TOKEN id="token-25-15" pos="punct" morph="none" start_char="2787" end_char="2787">,</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="2789" end_char="2792">told</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="2794" end_char="2796">The</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="2798" end_char="2809">Conversation</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="2811" end_char="2814">that</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="2816" end_char="2826">vaccinating</TOKEN>
<TOKEN id="token-25-21" pos="word" morph="none" start_char="2828" end_char="2835">everyone</TOKEN>
<TOKEN id="token-25-22" pos="punct" morph="none" start_char="2837" end_char="2837">"</TOKEN>
<TOKEN id="token-25-23" pos="word" morph="none" start_char="2838" end_char="2839">is</TOKEN>
<TOKEN id="token-25-24" pos="word" morph="none" start_char="2841" end_char="2847">neither</TOKEN>
<TOKEN id="token-25-25" pos="word" morph="none" start_char="2849" end_char="2857">practical</TOKEN>
<TOKEN id="token-25-26" pos="word" morph="none" start_char="2859" end_char="2861">nor</TOKEN>
<TOKEN id="token-25-27" pos="word" morph="none" start_char="2863" end_char="2870">feasible</TOKEN>
<TOKEN id="token-25-28" pos="punct" morph="none" start_char="2871" end_char="2872">".</TOKEN>
</SEG>
<SEG id="segment-26" start_char="2875" end_char="2996">
<ORIGINAL_TEXT>"Mathematical modelling and data from vaccination programmes suggest that we don’t need to vaccinate everybody," he added.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="punct" morph="none" start_char="2875" end_char="2875">"</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="2876" end_char="2887">Mathematical</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="2889" end_char="2897">modelling</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="2899" end_char="2901">and</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="2903" end_char="2906">data</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="2908" end_char="2911">from</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="2913" end_char="2923">vaccination</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="2925" end_char="2934">programmes</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="2936" end_char="2942">suggest</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="2944" end_char="2947">that</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="2949" end_char="2950">we</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="2952" end_char="2956">don’t</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="2958" end_char="2961">need</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="2963" end_char="2964">to</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="2966" end_char="2974">vaccinate</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="2976" end_char="2984">everybody</TOKEN>
<TOKEN id="token-26-16" pos="punct" morph="none" start_char="2985" end_char="2986">,"</TOKEN>
<TOKEN id="token-26-17" pos="word" morph="none" start_char="2988" end_char="2989">he</TOKEN>
<TOKEN id="token-26-18" pos="word" morph="none" start_char="2991" end_char="2995">added</TOKEN>
<TOKEN id="token-26-19" pos="punct" morph="none" start_char="2996" end_char="2996">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="2999" end_char="3154">
<ORIGINAL_TEXT>Scientists believe that, to stop the bug spreading further, and to make it slowly die out, "about 50-to-70 per cent of the population needs to be resistant.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="2999" end_char="3008">Scientists</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="3010" end_char="3016">believe</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="3018" end_char="3021">that</TOKEN>
<TOKEN id="token-27-3" pos="punct" morph="none" start_char="3022" end_char="3022">,</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="3024" end_char="3025">to</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="3027" end_char="3030">stop</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="3032" end_char="3034">the</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="3036" end_char="3038">bug</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="3040" end_char="3048">spreading</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="3050" end_char="3056">further</TOKEN>
<TOKEN id="token-27-10" pos="punct" morph="none" start_char="3057" end_char="3057">,</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="3059" end_char="3061">and</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="3063" end_char="3064">to</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="3066" end_char="3069">make</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="3071" end_char="3072">it</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="3074" end_char="3079">slowly</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="3081" end_char="3083">die</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="3085" end_char="3087">out</TOKEN>
<TOKEN id="token-27-18" pos="punct" morph="none" start_char="3088" end_char="3088">,</TOKEN>
<TOKEN id="token-27-19" pos="punct" morph="none" start_char="3090" end_char="3090">"</TOKEN>
<TOKEN id="token-27-20" pos="word" morph="none" start_char="3091" end_char="3095">about</TOKEN>
<TOKEN id="token-27-21" pos="unknown" morph="none" start_char="3097" end_char="3104">50-to-70</TOKEN>
<TOKEN id="token-27-22" pos="word" morph="none" start_char="3106" end_char="3108">per</TOKEN>
<TOKEN id="token-27-23" pos="word" morph="none" start_char="3110" end_char="3113">cent</TOKEN>
<TOKEN id="token-27-24" pos="word" morph="none" start_char="3115" end_char="3116">of</TOKEN>
<TOKEN id="token-27-25" pos="word" morph="none" start_char="3118" end_char="3120">the</TOKEN>
<TOKEN id="token-27-26" pos="word" morph="none" start_char="3122" end_char="3131">population</TOKEN>
<TOKEN id="token-27-27" pos="word" morph="none" start_char="3133" end_char="3137">needs</TOKEN>
<TOKEN id="token-27-28" pos="word" morph="none" start_char="3139" end_char="3140">to</TOKEN>
<TOKEN id="token-27-29" pos="word" morph="none" start_char="3142" end_char="3143">be</TOKEN>
<TOKEN id="token-27-30" pos="word" morph="none" start_char="3145" end_char="3153">resistant</TOKEN>
<TOKEN id="token-27-31" pos="punct" morph="none" start_char="3154" end_char="3154">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3157" end_char="3272">
<ORIGINAL_TEXT>"An even higher proportion is needed if we want the eradication to proceed quicker and to prevent further outbreaks.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="punct" morph="none" start_char="3157" end_char="3157">"</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="3158" end_char="3159">An</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="3161" end_char="3164">even</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="3166" end_char="3171">higher</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="3173" end_char="3182">proportion</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="3184" end_char="3185">is</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="3187" end_char="3192">needed</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="3194" end_char="3195">if</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="3197" end_char="3198">we</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="3200" end_char="3203">want</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="3205" end_char="3207">the</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="3209" end_char="3219">eradication</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="3221" end_char="3222">to</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="3224" end_char="3230">proceed</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="3232" end_char="3238">quicker</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="3240" end_char="3242">and</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="3244" end_char="3245">to</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="3247" end_char="3253">prevent</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="3255" end_char="3261">further</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="3263" end_char="3271">outbreaks</TOKEN>
<TOKEN id="token-28-20" pos="punct" morph="none" start_char="3272" end_char="3272">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3275" end_char="3335">
<ORIGINAL_TEXT>"Some people will have developed immunity to the coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="punct" morph="none" start_char="3275" end_char="3275">"</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="3276" end_char="3279">Some</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="3281" end_char="3286">people</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="3288" end_char="3291">will</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="3293" end_char="3296">have</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="3298" end_char="3306">developed</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="3308" end_char="3315">immunity</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="3317" end_char="3318">to</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="3320" end_char="3322">the</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="3324" end_char="3334">coronavirus</TOKEN>
<TOKEN id="token-29-10" pos="punct" morph="none" start_char="3335" end_char="3335">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3338" end_char="3475">
<ORIGINAL_TEXT>"But the number of people who have developed antibodies as a result of having had the disease is still far too low to reach herd immunity.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="punct" morph="none" start_char="3338" end_char="3338">"</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="3339" end_char="3341">But</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="3343" end_char="3345">the</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="3347" end_char="3352">number</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="3354" end_char="3355">of</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="3357" end_char="3362">people</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="3364" end_char="3366">who</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="3368" end_char="3371">have</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="3373" end_char="3381">developed</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="3383" end_char="3392">antibodies</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="3394" end_char="3395">as</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="3397" end_char="3397">a</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="3399" end_char="3404">result</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="3406" end_char="3407">of</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="3409" end_char="3414">having</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="3416" end_char="3418">had</TOKEN>
<TOKEN id="token-30-16" pos="word" morph="none" start_char="3420" end_char="3422">the</TOKEN>
<TOKEN id="token-30-17" pos="word" morph="none" start_char="3424" end_char="3430">disease</TOKEN>
<TOKEN id="token-30-18" pos="word" morph="none" start_char="3432" end_char="3433">is</TOKEN>
<TOKEN id="token-30-19" pos="word" morph="none" start_char="3435" end_char="3439">still</TOKEN>
<TOKEN id="token-30-20" pos="word" morph="none" start_char="3441" end_char="3443">far</TOKEN>
<TOKEN id="token-30-21" pos="word" morph="none" start_char="3445" end_char="3447">too</TOKEN>
<TOKEN id="token-30-22" pos="word" morph="none" start_char="3449" end_char="3451">low</TOKEN>
<TOKEN id="token-30-23" pos="word" morph="none" start_char="3453" end_char="3454">to</TOKEN>
<TOKEN id="token-30-24" pos="word" morph="none" start_char="3456" end_char="3460">reach</TOKEN>
<TOKEN id="token-30-25" pos="word" morph="none" start_char="3462" end_char="3465">herd</TOKEN>
<TOKEN id="token-30-26" pos="word" morph="none" start_char="3467" end_char="3474">immunity</TOKEN>
<TOKEN id="token-30-27" pos="punct" morph="none" start_char="3475" end_char="3475">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="3478" end_char="3581">
<ORIGINAL_TEXT>"The remaining protection would need to be achieved with a mass vaccination programme," said the expert.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="punct" morph="none" start_char="3478" end_char="3478">"</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="3479" end_char="3481">The</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="3483" end_char="3491">remaining</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="3493" end_char="3502">protection</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="3504" end_char="3508">would</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="3510" end_char="3513">need</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="3515" end_char="3516">to</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="3518" end_char="3519">be</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="3521" end_char="3528">achieved</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="3530" end_char="3533">with</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="3535" end_char="3535">a</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="3537" end_char="3540">mass</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="3542" end_char="3552">vaccination</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="3554" end_char="3562">programme</TOKEN>
<TOKEN id="token-31-14" pos="punct" morph="none" start_char="3563" end_char="3564">,"</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="3566" end_char="3569">said</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="3571" end_char="3573">the</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="3575" end_char="3580">expert</TOKEN>
<TOKEN id="token-31-18" pos="punct" morph="none" start_char="3581" end_char="3581">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="3584" end_char="3719">
<ORIGINAL_TEXT>In the US, Novavax has identified a coronavirus vaccine candidate and is accelerating initiation of its first-in-human trial to mid-May.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="3584" end_char="3585">In</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="3587" end_char="3589">the</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="3591" end_char="3592">US</TOKEN>
<TOKEN id="token-32-3" pos="punct" morph="none" start_char="3593" end_char="3593">,</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="3595" end_char="3601">Novavax</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="3603" end_char="3605">has</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="3607" end_char="3616">identified</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="3618" end_char="3618">a</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="3620" end_char="3630">coronavirus</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="3632" end_char="3638">vaccine</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="3640" end_char="3648">candidate</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="3650" end_char="3652">and</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="3654" end_char="3655">is</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="3657" end_char="3668">accelerating</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="3670" end_char="3679">initiation</TOKEN>
<TOKEN id="token-32-15" pos="word" morph="none" start_char="3681" end_char="3682">of</TOKEN>
<TOKEN id="token-32-16" pos="word" morph="none" start_char="3684" end_char="3686">its</TOKEN>
<TOKEN id="token-32-17" pos="unknown" morph="none" start_char="3688" end_char="3701">first-in-human</TOKEN>
<TOKEN id="token-32-18" pos="word" morph="none" start_char="3703" end_char="3707">trial</TOKEN>
<TOKEN id="token-32-19" pos="word" morph="none" start_char="3709" end_char="3710">to</TOKEN>
<TOKEN id="token-32-20" pos="unknown" morph="none" start_char="3712" end_char="3718">mid-May</TOKEN>
<TOKEN id="token-32-21" pos="punct" morph="none" start_char="3719" end_char="3719">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="3722" end_char="3955">
<ORIGINAL_TEXT>The late-stage biotechnology company, which develops next-generation vaccines for serious infectious diseases, recently announced it has identified a coronavirus vaccine candidate, NVX-CoV2373, using Novavax’s nanoparticle technology.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="3722" end_char="3724">The</TOKEN>
<TOKEN id="token-33-1" pos="unknown" morph="none" start_char="3726" end_char="3735">late-stage</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="3737" end_char="3749">biotechnology</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="3751" end_char="3757">company</TOKEN>
<TOKEN id="token-33-4" pos="punct" morph="none" start_char="3758" end_char="3758">,</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="3760" end_char="3764">which</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="3766" end_char="3773">develops</TOKEN>
<TOKEN id="token-33-7" pos="unknown" morph="none" start_char="3775" end_char="3789">next-generation</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="3791" end_char="3798">vaccines</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="3800" end_char="3802">for</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="3804" end_char="3810">serious</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="3812" end_char="3821">infectious</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="3823" end_char="3830">diseases</TOKEN>
<TOKEN id="token-33-13" pos="punct" morph="none" start_char="3831" end_char="3831">,</TOKEN>
<TOKEN id="token-33-14" pos="word" morph="none" start_char="3833" end_char="3840">recently</TOKEN>
<TOKEN id="token-33-15" pos="word" morph="none" start_char="3842" end_char="3850">announced</TOKEN>
<TOKEN id="token-33-16" pos="word" morph="none" start_char="3852" end_char="3853">it</TOKEN>
<TOKEN id="token-33-17" pos="word" morph="none" start_char="3855" end_char="3857">has</TOKEN>
<TOKEN id="token-33-18" pos="word" morph="none" start_char="3859" end_char="3868">identified</TOKEN>
<TOKEN id="token-33-19" pos="word" morph="none" start_char="3870" end_char="3870">a</TOKEN>
<TOKEN id="token-33-20" pos="word" morph="none" start_char="3872" end_char="3882">coronavirus</TOKEN>
<TOKEN id="token-33-21" pos="word" morph="none" start_char="3884" end_char="3890">vaccine</TOKEN>
<TOKEN id="token-33-22" pos="word" morph="none" start_char="3892" end_char="3900">candidate</TOKEN>
<TOKEN id="token-33-23" pos="punct" morph="none" start_char="3901" end_char="3901">,</TOKEN>
<TOKEN id="token-33-24" pos="unknown" morph="none" start_char="3903" end_char="3913">NVX-CoV2373</TOKEN>
<TOKEN id="token-33-25" pos="punct" morph="none" start_char="3914" end_char="3914">,</TOKEN>
<TOKEN id="token-33-26" pos="word" morph="none" start_char="3916" end_char="3920">using</TOKEN>
<TOKEN id="token-33-27" pos="word" morph="none" start_char="3922" end_char="3930">Novavax’s</TOKEN>
<TOKEN id="token-33-28" pos="word" morph="none" start_char="3932" end_char="3943">nanoparticle</TOKEN>
<TOKEN id="token-33-29" pos="word" morph="none" start_char="3945" end_char="3954">technology</TOKEN>
<TOKEN id="token-33-30" pos="punct" morph="none" start_char="3955" end_char="3955">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="3958" end_char="4166">
<ORIGINAL_TEXT>Matthew Frieman, Associate Professor at the University of Maryland School of Medicine, said there was "strong evidence that the vaccine created by Novavax has the potential to be highly immunogenic in humans".</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="3958" end_char="3964">Matthew</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="3966" end_char="3972">Frieman</TOKEN>
<TOKEN id="token-34-2" pos="punct" morph="none" start_char="3973" end_char="3973">,</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="3975" end_char="3983">Associate</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="3985" end_char="3993">Professor</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="3995" end_char="3996">at</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="3998" end_char="4000">the</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="4002" end_char="4011">University</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="4013" end_char="4014">of</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="4016" end_char="4023">Maryland</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="4025" end_char="4030">School</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="4032" end_char="4033">of</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="4035" end_char="4042">Medicine</TOKEN>
<TOKEN id="token-34-13" pos="punct" morph="none" start_char="4043" end_char="4043">,</TOKEN>
<TOKEN id="token-34-14" pos="word" morph="none" start_char="4045" end_char="4048">said</TOKEN>
<TOKEN id="token-34-15" pos="word" morph="none" start_char="4050" end_char="4054">there</TOKEN>
<TOKEN id="token-34-16" pos="word" morph="none" start_char="4056" end_char="4058">was</TOKEN>
<TOKEN id="token-34-17" pos="punct" morph="none" start_char="4060" end_char="4060">"</TOKEN>
<TOKEN id="token-34-18" pos="word" morph="none" start_char="4061" end_char="4066">strong</TOKEN>
<TOKEN id="token-34-19" pos="word" morph="none" start_char="4068" end_char="4075">evidence</TOKEN>
<TOKEN id="token-34-20" pos="word" morph="none" start_char="4077" end_char="4080">that</TOKEN>
<TOKEN id="token-34-21" pos="word" morph="none" start_char="4082" end_char="4084">the</TOKEN>
<TOKEN id="token-34-22" pos="word" morph="none" start_char="4086" end_char="4092">vaccine</TOKEN>
<TOKEN id="token-34-23" pos="word" morph="none" start_char="4094" end_char="4100">created</TOKEN>
<TOKEN id="token-34-24" pos="word" morph="none" start_char="4102" end_char="4103">by</TOKEN>
<TOKEN id="token-34-25" pos="word" morph="none" start_char="4105" end_char="4111">Novavax</TOKEN>
<TOKEN id="token-34-26" pos="word" morph="none" start_char="4113" end_char="4115">has</TOKEN>
<TOKEN id="token-34-27" pos="word" morph="none" start_char="4117" end_char="4119">the</TOKEN>
<TOKEN id="token-34-28" pos="word" morph="none" start_char="4121" end_char="4129">potential</TOKEN>
<TOKEN id="token-34-29" pos="word" morph="none" start_char="4131" end_char="4132">to</TOKEN>
<TOKEN id="token-34-30" pos="word" morph="none" start_char="4134" end_char="4135">be</TOKEN>
<TOKEN id="token-34-31" pos="word" morph="none" start_char="4137" end_char="4142">highly</TOKEN>
<TOKEN id="token-34-32" pos="word" morph="none" start_char="4144" end_char="4154">immunogenic</TOKEN>
<TOKEN id="token-34-33" pos="word" morph="none" start_char="4156" end_char="4157">in</TOKEN>
<TOKEN id="token-34-34" pos="word" morph="none" start_char="4159" end_char="4164">humans</TOKEN>
<TOKEN id="token-34-35" pos="punct" morph="none" start_char="4165" end_char="4166">".</TOKEN>
</SEG>
<SEG id="segment-35" start_char="4169" end_char="4298">
<ORIGINAL_TEXT>He said - if the trial is successful - it "could lead to protection from Covid-19 and help to control the spread of this disease."</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="4169" end_char="4170">He</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="4172" end_char="4175">said</TOKEN>
<TOKEN id="token-35-2" pos="punct" morph="none" start_char="4177" end_char="4177">-</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="4179" end_char="4180">if</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="4182" end_char="4184">the</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="4186" end_char="4190">trial</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="4192" end_char="4193">is</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="4195" end_char="4204">successful</TOKEN>
<TOKEN id="token-35-8" pos="punct" morph="none" start_char="4206" end_char="4206">-</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="4208" end_char="4209">it</TOKEN>
<TOKEN id="token-35-10" pos="punct" morph="none" start_char="4211" end_char="4211">"</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="4212" end_char="4216">could</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="4218" end_char="4221">lead</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="4223" end_char="4224">to</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="4226" end_char="4235">protection</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="4237" end_char="4240">from</TOKEN>
<TOKEN id="token-35-16" pos="unknown" morph="none" start_char="4242" end_char="4249">Covid-19</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="4251" end_char="4253">and</TOKEN>
<TOKEN id="token-35-18" pos="word" morph="none" start_char="4255" end_char="4258">help</TOKEN>
<TOKEN id="token-35-19" pos="word" morph="none" start_char="4260" end_char="4261">to</TOKEN>
<TOKEN id="token-35-20" pos="word" morph="none" start_char="4263" end_char="4269">control</TOKEN>
<TOKEN id="token-35-21" pos="word" morph="none" start_char="4271" end_char="4273">the</TOKEN>
<TOKEN id="token-35-22" pos="word" morph="none" start_char="4275" end_char="4280">spread</TOKEN>
<TOKEN id="token-35-23" pos="word" morph="none" start_char="4282" end_char="4283">of</TOKEN>
<TOKEN id="token-35-24" pos="word" morph="none" start_char="4285" end_char="4288">this</TOKEN>
<TOKEN id="token-35-25" pos="word" morph="none" start_char="4290" end_char="4296">disease</TOKEN>
<TOKEN id="token-35-26" pos="punct" morph="none" start_char="4297" end_char="4298">."</TOKEN>
</SEG>
<SEG id="segment-36" start_char="4301" end_char="4415">
<ORIGINAL_TEXT>Researchers across the globe are trying their best to create the perfect vaccine to protect people against Covid-19</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="4301" end_char="4311">Researchers</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="4313" end_char="4318">across</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="4320" end_char="4322">the</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="4324" end_char="4328">globe</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="4330" end_char="4332">are</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="4334" end_char="4339">trying</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="4341" end_char="4345">their</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="4347" end_char="4350">best</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="4352" end_char="4353">to</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="4355" end_char="4360">create</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="4362" end_char="4364">the</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="4366" end_char="4372">perfect</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="4374" end_char="4380">vaccine</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="4382" end_char="4383">to</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="4385" end_char="4391">protect</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="4393" end_char="4398">people</TOKEN>
<TOKEN id="token-36-16" pos="word" morph="none" start_char="4400" end_char="4406">against</TOKEN>
<TOKEN id="token-36-17" pos="unknown" morph="none" start_char="4408" end_char="4415">Covid-19</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
