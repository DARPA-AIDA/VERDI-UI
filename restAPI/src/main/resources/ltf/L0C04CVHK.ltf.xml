<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CVHK" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="5864" raw_text_md5="072c4ae393d4ec68025c29ff27811619">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="56">
<ORIGINAL_TEXT>Singapore reveals Covid privacy data available to police</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="9">Singapore</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="11" end_char="17">reveals</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="19" end_char="23">Covid</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="25" end_char="31">privacy</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="33" end_char="36">data</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="38" end_char="46">available</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="48" end_char="49">to</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="51" end_char="56">police</TOKEN>
</SEG>
<SEG id="segment-1" start_char="60" end_char="127">
<ORIGINAL_TEXT>image captionSingapore's Covid app is widely used across the country</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="60" end_char="64">image</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="66" end_char="83">captionSingapore's</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="85" end_char="89">Covid</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="91" end_char="93">app</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="95" end_char="96">is</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="98" end_char="103">widely</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="105" end_char="108">used</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="110" end_char="115">across</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="117" end_char="119">the</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="121" end_char="127">country</TOKEN>
</SEG>
<SEG id="segment-2" start_char="131" end_char="268">
<ORIGINAL_TEXT>Singapore has admitted data from its Covid contact tracing programme can also be accessed by police, reversing earlier privacy assurances.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="131" end_char="139">Singapore</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="141" end_char="143">has</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="145" end_char="152">admitted</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="154" end_char="157">data</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="159" end_char="162">from</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="164" end_char="166">its</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="168" end_char="172">Covid</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="174" end_char="180">contact</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="182" end_char="188">tracing</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="190" end_char="198">programme</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="200" end_char="202">can</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="204" end_char="207">also</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="209" end_char="210">be</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="212" end_char="219">accessed</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="221" end_char="222">by</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="224" end_char="229">police</TOKEN>
<TOKEN id="token-2-16" pos="punct" morph="none" start_char="230" end_char="230">,</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="232" end_char="240">reversing</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="242" end_char="248">earlier</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="250" end_char="256">privacy</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="258" end_char="267">assurances</TOKEN>
<TOKEN id="token-2-21" pos="punct" morph="none" start_char="268" end_char="268">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="271" end_char="382">
<ORIGINAL_TEXT>Officials had previously explicitly ruled out the data would be used for anything other than the virus tracking.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="271" end_char="279">Officials</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="281" end_char="283">had</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="285" end_char="294">previously</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="296" end_char="305">explicitly</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="307" end_char="311">ruled</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="313" end_char="315">out</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="317" end_char="319">the</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="321" end_char="324">data</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="326" end_char="330">would</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="332" end_char="333">be</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="335" end_char="338">used</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="340" end_char="342">for</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="344" end_char="351">anything</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="353" end_char="357">other</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="359" end_char="362">than</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="364" end_char="366">the</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="368" end_char="372">virus</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="374" end_char="381">tracking</TOKEN>
<TOKEN id="token-3-18" pos="punct" morph="none" start_char="382" end_char="382">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="385" end_char="484">
<ORIGINAL_TEXT>But parliament was told on Monday it could also be used "for the purpose of criminal investigation".</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="385" end_char="387">But</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="389" end_char="398">parliament</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="400" end_char="402">was</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="404" end_char="407">told</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="409" end_char="410">on</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="412" end_char="417">Monday</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="419" end_char="420">it</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="422" end_char="426">could</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="428" end_char="431">also</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="433" end_char="434">be</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="436" end_char="439">used</TOKEN>
<TOKEN id="token-4-11" pos="punct" morph="none" start_char="441" end_char="441">"</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="442" end_char="444">for</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="446" end_char="448">the</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="450" end_char="456">purpose</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="458" end_char="459">of</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="461" end_char="468">criminal</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="470" end_char="482">investigation</TOKEN>
<TOKEN id="token-4-18" pos="punct" morph="none" start_char="483" end_char="484">".</TOKEN>
</SEG>
<SEG id="segment-5" start_char="487" end_char="597">
<ORIGINAL_TEXT>Close to 80% of residents are signed up to the TraceTogether programme, which is used to check in to locations.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="487" end_char="491">Close</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="493" end_char="494">to</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="496" end_char="497">80</TOKEN>
<TOKEN id="token-5-3" pos="punct" morph="none" start_char="498" end_char="498">%</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="500" end_char="501">of</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="503" end_char="511">residents</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="513" end_char="515">are</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="517" end_char="522">signed</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="524" end_char="525">up</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="527" end_char="528">to</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="530" end_char="532">the</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="534" end_char="546">TraceTogether</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="548" end_char="556">programme</TOKEN>
<TOKEN id="token-5-13" pos="punct" morph="none" start_char="557" end_char="557">,</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="559" end_char="563">which</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="565" end_char="566">is</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="568" end_char="571">used</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="573" end_char="574">to</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="576" end_char="580">check</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="582" end_char="583">in</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="585" end_char="586">to</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="588" end_char="596">locations</TOKEN>
<TOKEN id="token-5-22" pos="punct" morph="none" start_char="597" end_char="597">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="600" end_char="740">
<ORIGINAL_TEXT>The voluntary take up increased after it was announced it would soon be needed to access anything from the supermarket to your place of work.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="600" end_char="602">The</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="604" end_char="612">voluntary</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="614" end_char="617">take</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="619" end_char="620">up</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="622" end_char="630">increased</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="632" end_char="636">after</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="638" end_char="639">it</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="641" end_char="643">was</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="645" end_char="653">announced</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="655" end_char="656">it</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="658" end_char="662">would</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="664" end_char="667">soon</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="669" end_char="670">be</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="672" end_char="677">needed</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="679" end_char="680">to</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="682" end_char="687">access</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="689" end_char="696">anything</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="698" end_char="701">from</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="703" end_char="705">the</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="707" end_char="717">supermarket</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="719" end_char="720">to</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="722" end_char="725">your</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="727" end_char="731">place</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="733" end_char="734">of</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="736" end_char="739">work</TOKEN>
<TOKEN id="token-6-25" pos="punct" morph="none" start_char="740" end_char="740">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="743" end_char="876">
<ORIGINAL_TEXT>The TraceTogether programme, which uses either a smartphone app or a bluetooth token, also monitors who you have been in contact with.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="743" end_char="745">The</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="747" end_char="759">TraceTogether</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="761" end_char="769">programme</TOKEN>
<TOKEN id="token-7-3" pos="punct" morph="none" start_char="770" end_char="770">,</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="772" end_char="776">which</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="778" end_char="781">uses</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="783" end_char="788">either</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="790" end_char="790">a</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="792" end_char="801">smartphone</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="803" end_char="805">app</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="807" end_char="808">or</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="810" end_char="810">a</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="812" end_char="820">bluetooth</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="822" end_char="826">token</TOKEN>
<TOKEN id="token-7-14" pos="punct" morph="none" start_char="827" end_char="827">,</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="829" end_char="832">also</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="834" end_char="841">monitors</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="843" end_char="845">who</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="847" end_char="849">you</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="851" end_char="854">have</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="856" end_char="859">been</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="861" end_char="862">in</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="864" end_char="870">contact</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="872" end_char="875">with</TOKEN>
<TOKEN id="token-7-24" pos="punct" morph="none" start_char="876" end_char="876">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="879" end_char="1000">
<ORIGINAL_TEXT>If someone tests positive with the virus, the data allows tracers to swiftly contact anyone that might have been infected.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="879" end_char="880">If</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="882" end_char="888">someone</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="890" end_char="894">tests</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="896" end_char="903">positive</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="905" end_char="908">with</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="910" end_char="912">the</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="914" end_char="918">virus</TOKEN>
<TOKEN id="token-8-7" pos="punct" morph="none" start_char="919" end_char="919">,</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="921" end_char="923">the</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="925" end_char="928">data</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="930" end_char="935">allows</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="937" end_char="943">tracers</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="945" end_char="946">to</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="948" end_char="954">swiftly</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="956" end_char="962">contact</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="964" end_char="969">anyone</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="971" end_char="974">that</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="976" end_char="980">might</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="982" end_char="985">have</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="987" end_char="990">been</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="992" end_char="999">infected</TOKEN>
<TOKEN id="token-8-21" pos="punct" morph="none" start_char="1000" end_char="1000">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1002" end_char="1138">
<ORIGINAL_TEXT>This prompted concerns over privacy - fears which have been echoed across the world as other countries rolled out their own tracing apps.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1002" end_char="1005">This</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1007" end_char="1014">prompted</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1016" end_char="1023">concerns</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1025" end_char="1028">over</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1030" end_char="1036">privacy</TOKEN>
<TOKEN id="token-9-5" pos="punct" morph="none" start_char="1038" end_char="1038">-</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1040" end_char="1044">fears</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1046" end_char="1050">which</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1052" end_char="1055">have</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1057" end_char="1060">been</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1062" end_char="1067">echoed</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1069" end_char="1074">across</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1076" end_char="1078">the</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1080" end_char="1084">world</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1086" end_char="1087">as</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1089" end_char="1093">other</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1095" end_char="1103">countries</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1105" end_char="1110">rolled</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1112" end_char="1114">out</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1116" end_char="1120">their</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1122" end_char="1124">own</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1126" end_char="1132">tracing</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1134" end_char="1137">apps</TOKEN>
<TOKEN id="token-9-23" pos="punct" morph="none" start_char="1138" end_char="1138">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1141" end_char="1386">
<ORIGINAL_TEXT>To encourage people to enrol, Singaporean authorities promised the data would never be used for any other purpose, saying "the data will never be accessed, unless the user tests positive for Covid-19 and is contacted by the contact tracing team".</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1141" end_char="1142">To</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1144" end_char="1152">encourage</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1154" end_char="1159">people</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1161" end_char="1162">to</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1164" end_char="1168">enrol</TOKEN>
<TOKEN id="token-10-5" pos="punct" morph="none" start_char="1169" end_char="1169">,</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1171" end_char="1181">Singaporean</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1183" end_char="1193">authorities</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1195" end_char="1202">promised</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1204" end_char="1206">the</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1208" end_char="1211">data</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1213" end_char="1217">would</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1219" end_char="1223">never</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1225" end_char="1226">be</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1228" end_char="1231">used</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1233" end_char="1235">for</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1237" end_char="1239">any</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1241" end_char="1245">other</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1247" end_char="1253">purpose</TOKEN>
<TOKEN id="token-10-19" pos="punct" morph="none" start_char="1254" end_char="1254">,</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1256" end_char="1261">saying</TOKEN>
<TOKEN id="token-10-21" pos="punct" morph="none" start_char="1263" end_char="1263">"</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1264" end_char="1266">the</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1268" end_char="1271">data</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1273" end_char="1276">will</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="1278" end_char="1282">never</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="1284" end_char="1285">be</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="1287" end_char="1294">accessed</TOKEN>
<TOKEN id="token-10-28" pos="punct" morph="none" start_char="1295" end_char="1295">,</TOKEN>
<TOKEN id="token-10-29" pos="word" morph="none" start_char="1297" end_char="1302">unless</TOKEN>
<TOKEN id="token-10-30" pos="word" morph="none" start_char="1304" end_char="1306">the</TOKEN>
<TOKEN id="token-10-31" pos="word" morph="none" start_char="1308" end_char="1311">user</TOKEN>
<TOKEN id="token-10-32" pos="word" morph="none" start_char="1313" end_char="1317">tests</TOKEN>
<TOKEN id="token-10-33" pos="word" morph="none" start_char="1319" end_char="1326">positive</TOKEN>
<TOKEN id="token-10-34" pos="word" morph="none" start_char="1328" end_char="1330">for</TOKEN>
<TOKEN id="token-10-35" pos="unknown" morph="none" start_char="1332" end_char="1339">Covid-19</TOKEN>
<TOKEN id="token-10-36" pos="word" morph="none" start_char="1341" end_char="1343">and</TOKEN>
<TOKEN id="token-10-37" pos="word" morph="none" start_char="1345" end_char="1346">is</TOKEN>
<TOKEN id="token-10-38" pos="word" morph="none" start_char="1348" end_char="1356">contacted</TOKEN>
<TOKEN id="token-10-39" pos="word" morph="none" start_char="1358" end_char="1359">by</TOKEN>
<TOKEN id="token-10-40" pos="word" morph="none" start_char="1361" end_char="1363">the</TOKEN>
<TOKEN id="token-10-41" pos="word" morph="none" start_char="1365" end_char="1371">contact</TOKEN>
<TOKEN id="token-10-42" pos="word" morph="none" start_char="1373" end_char="1379">tracing</TOKEN>
<TOKEN id="token-10-43" pos="word" morph="none" start_char="1381" end_char="1384">team</TOKEN>
<TOKEN id="token-10-44" pos="punct" morph="none" start_char="1385" end_char="1386">".</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1389" end_char="1678">
<ORIGINAL_TEXT>But Minister of State for Home Affairs Desmond Tan told parliament on Monday that it can in fact also be used "for the purpose of criminal investigation", adding that "otherwise, TraceTogether data is to be used only for contact tracing and for the purpose of fighting the Covid situation".</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1389" end_char="1391">But</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1393" end_char="1400">Minister</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1402" end_char="1403">of</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1405" end_char="1409">State</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1411" end_char="1413">for</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1415" end_char="1418">Home</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1420" end_char="1426">Affairs</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1428" end_char="1434">Desmond</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1436" end_char="1438">Tan</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1440" end_char="1443">told</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1445" end_char="1454">parliament</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1456" end_char="1457">on</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1459" end_char="1464">Monday</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1466" end_char="1469">that</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1471" end_char="1472">it</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1474" end_char="1476">can</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1478" end_char="1479">in</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1481" end_char="1484">fact</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1486" end_char="1489">also</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="1491" end_char="1492">be</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1494" end_char="1497">used</TOKEN>
<TOKEN id="token-11-21" pos="punct" morph="none" start_char="1499" end_char="1499">"</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="1500" end_char="1502">for</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="1504" end_char="1506">the</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="1508" end_char="1514">purpose</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="1516" end_char="1517">of</TOKEN>
<TOKEN id="token-11-26" pos="word" morph="none" start_char="1519" end_char="1526">criminal</TOKEN>
<TOKEN id="token-11-27" pos="word" morph="none" start_char="1528" end_char="1540">investigation</TOKEN>
<TOKEN id="token-11-28" pos="punct" morph="none" start_char="1541" end_char="1542">",</TOKEN>
<TOKEN id="token-11-29" pos="word" morph="none" start_char="1544" end_char="1549">adding</TOKEN>
<TOKEN id="token-11-30" pos="word" morph="none" start_char="1551" end_char="1554">that</TOKEN>
<TOKEN id="token-11-31" pos="punct" morph="none" start_char="1556" end_char="1556">"</TOKEN>
<TOKEN id="token-11-32" pos="word" morph="none" start_char="1557" end_char="1565">otherwise</TOKEN>
<TOKEN id="token-11-33" pos="punct" morph="none" start_char="1566" end_char="1566">,</TOKEN>
<TOKEN id="token-11-34" pos="word" morph="none" start_char="1568" end_char="1580">TraceTogether</TOKEN>
<TOKEN id="token-11-35" pos="word" morph="none" start_char="1582" end_char="1585">data</TOKEN>
<TOKEN id="token-11-36" pos="word" morph="none" start_char="1587" end_char="1588">is</TOKEN>
<TOKEN id="token-11-37" pos="word" morph="none" start_char="1590" end_char="1591">to</TOKEN>
<TOKEN id="token-11-38" pos="word" morph="none" start_char="1593" end_char="1594">be</TOKEN>
<TOKEN id="token-11-39" pos="word" morph="none" start_char="1596" end_char="1599">used</TOKEN>
<TOKEN id="token-11-40" pos="word" morph="none" start_char="1601" end_char="1604">only</TOKEN>
<TOKEN id="token-11-41" pos="word" morph="none" start_char="1606" end_char="1608">for</TOKEN>
<TOKEN id="token-11-42" pos="word" morph="none" start_char="1610" end_char="1616">contact</TOKEN>
<TOKEN id="token-11-43" pos="word" morph="none" start_char="1618" end_char="1624">tracing</TOKEN>
<TOKEN id="token-11-44" pos="word" morph="none" start_char="1626" end_char="1628">and</TOKEN>
<TOKEN id="token-11-45" pos="word" morph="none" start_char="1630" end_char="1632">for</TOKEN>
<TOKEN id="token-11-46" pos="word" morph="none" start_char="1634" end_char="1636">the</TOKEN>
<TOKEN id="token-11-47" pos="word" morph="none" start_char="1638" end_char="1644">purpose</TOKEN>
<TOKEN id="token-11-48" pos="word" morph="none" start_char="1646" end_char="1647">of</TOKEN>
<TOKEN id="token-11-49" pos="word" morph="none" start_char="1649" end_char="1656">fighting</TOKEN>
<TOKEN id="token-11-50" pos="word" morph="none" start_char="1658" end_char="1660">the</TOKEN>
<TOKEN id="token-11-51" pos="word" morph="none" start_char="1662" end_char="1666">Covid</TOKEN>
<TOKEN id="token-11-52" pos="word" morph="none" start_char="1668" end_char="1676">situation</TOKEN>
<TOKEN id="token-11-53" pos="punct" morph="none" start_char="1677" end_char="1678">".</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1683" end_char="1867">
<ORIGINAL_TEXT>However, the privacy statement on the TraceTogether site was then updated on the same day to state that "the Criminal Procedure Code applies to all data under Singapore's jurisdiction".</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1683" end_char="1689">However</TOKEN>
<TOKEN id="token-12-1" pos="punct" morph="none" start_char="1690" end_char="1690">,</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1692" end_char="1694">the</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1696" end_char="1702">privacy</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1704" end_char="1712">statement</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1714" end_char="1715">on</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1717" end_char="1719">the</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1721" end_char="1733">TraceTogether</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1735" end_char="1738">site</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1740" end_char="1742">was</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1744" end_char="1747">then</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1749" end_char="1755">updated</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1757" end_char="1758">on</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1760" end_char="1762">the</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1764" end_char="1767">same</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1769" end_char="1771">day</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1773" end_char="1774">to</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1776" end_char="1780">state</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1782" end_char="1785">that</TOKEN>
<TOKEN id="token-12-19" pos="punct" morph="none" start_char="1787" end_char="1787">"</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1788" end_char="1790">the</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1792" end_char="1799">Criminal</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1801" end_char="1809">Procedure</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="1811" end_char="1814">Code</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="1816" end_char="1822">applies</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="1824" end_char="1825">to</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="1827" end_char="1829">all</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="1831" end_char="1834">data</TOKEN>
<TOKEN id="token-12-28" pos="word" morph="none" start_char="1836" end_char="1840">under</TOKEN>
<TOKEN id="token-12-29" pos="word" morph="none" start_char="1842" end_char="1852">Singapore's</TOKEN>
<TOKEN id="token-12-30" pos="word" morph="none" start_char="1854" end_char="1865">jurisdiction</TOKEN>
<TOKEN id="token-12-31" pos="punct" morph="none" start_char="1866" end_char="1867">".</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1870" end_char="1933">
<ORIGINAL_TEXT>"Also, we want to be transparent with you," the statement reads.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="punct" morph="none" start_char="1870" end_char="1870">"</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1871" end_char="1874">Also</TOKEN>
<TOKEN id="token-13-2" pos="punct" morph="none" start_char="1875" end_char="1875">,</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1877" end_char="1878">we</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1880" end_char="1883">want</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1885" end_char="1886">to</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1888" end_char="1889">be</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1891" end_char="1901">transparent</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1903" end_char="1906">with</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1908" end_char="1910">you</TOKEN>
<TOKEN id="token-13-10" pos="punct" morph="none" start_char="1911" end_char="1912">,"</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1914" end_char="1916">the</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1918" end_char="1926">statement</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1928" end_char="1932">reads</TOKEN>
<TOKEN id="token-13-14" pos="punct" morph="none" start_char="1933" end_char="1933">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1935" end_char="2041">
<ORIGINAL_TEXT>"TraceTogether data may be used in circumstances where citizen safety and security is or has been affected.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="punct" morph="none" start_char="1935" end_char="1935">"</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1936" end_char="1948">TraceTogether</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1950" end_char="1953">data</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1955" end_char="1957">may</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1959" end_char="1960">be</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1962" end_char="1965">used</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1967" end_char="1968">in</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1970" end_char="1982">circumstances</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1984" end_char="1988">where</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1990" end_char="1996">citizen</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1998" end_char="2003">safety</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="2005" end_char="2007">and</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="2009" end_char="2016">security</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="2018" end_char="2019">is</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="2021" end_char="2022">or</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="2024" end_char="2026">has</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="2028" end_char="2031">been</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="2033" end_char="2040">affected</TOKEN>
<TOKEN id="token-14-18" pos="punct" morph="none" start_char="2041" end_char="2041">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="2044" end_char="2203">
<ORIGINAL_TEXT>"The Singapore Police Force is empowered under the Criminal Procedure Code (CPC) to obtain any data, including TraceTogether data, for criminal investigations."</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="punct" morph="none" start_char="2044" end_char="2044">"</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="2045" end_char="2047">The</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="2049" end_char="2057">Singapore</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="2059" end_char="2064">Police</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="2066" end_char="2070">Force</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="2072" end_char="2073">is</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="2075" end_char="2083">empowered</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="2085" end_char="2089">under</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="2091" end_char="2093">the</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="2095" end_char="2102">Criminal</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="2104" end_char="2112">Procedure</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="2114" end_char="2117">Code</TOKEN>
<TOKEN id="token-15-12" pos="punct" morph="none" start_char="2119" end_char="2119">(</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="2120" end_char="2122">CPC</TOKEN>
<TOKEN id="token-15-14" pos="punct" morph="none" start_char="2123" end_char="2123">)</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="2125" end_char="2126">to</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="2128" end_char="2133">obtain</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="2135" end_char="2137">any</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="2139" end_char="2142">data</TOKEN>
<TOKEN id="token-15-19" pos="punct" morph="none" start_char="2143" end_char="2143">,</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="2145" end_char="2153">including</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="2155" end_char="2167">TraceTogether</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="2169" end_char="2172">data</TOKEN>
<TOKEN id="token-15-23" pos="punct" morph="none" start_char="2173" end_char="2173">,</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="2175" end_char="2177">for</TOKEN>
<TOKEN id="token-15-25" pos="word" morph="none" start_char="2179" end_char="2186">criminal</TOKEN>
<TOKEN id="token-15-26" pos="word" morph="none" start_char="2188" end_char="2201">investigations</TOKEN>
<TOKEN id="token-15-27" pos="punct" morph="none" start_char="2202" end_char="2203">."</TOKEN>
</SEG>
<SEG id="segment-16" start_char="2206" end_char="2239">
<ORIGINAL_TEXT>'Only for criminal investigations'</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="punct" morph="none" start_char="2206" end_char="2206">'</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="2207" end_char="2210">Only</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="2212" end_char="2214">for</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="2216" end_char="2223">criminal</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="2225" end_char="2238">investigations</TOKEN>
<TOKEN id="token-16-5" pos="punct" morph="none" start_char="2239" end_char="2239">'</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2243" end_char="2427">
<ORIGINAL_TEXT>On Tuesday, the country's Minister for Foreign Affairs, Vivian Balakrishnan, clarified that it was not just TraceTogether data that was used in cases of serious criminal investigations.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2243" end_char="2244">On</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2246" end_char="2252">Tuesday</TOKEN>
<TOKEN id="token-17-2" pos="punct" morph="none" start_char="2253" end_char="2253">,</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2255" end_char="2257">the</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2259" end_char="2267">country's</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2269" end_char="2276">Minister</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2278" end_char="2280">for</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2282" end_char="2288">Foreign</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2290" end_char="2296">Affairs</TOKEN>
<TOKEN id="token-17-9" pos="punct" morph="none" start_char="2297" end_char="2297">,</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2299" end_char="2304">Vivian</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2306" end_char="2317">Balakrishnan</TOKEN>
<TOKEN id="token-17-12" pos="punct" morph="none" start_char="2318" end_char="2318">,</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2320" end_char="2328">clarified</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2330" end_char="2333">that</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2335" end_char="2336">it</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="2338" end_char="2340">was</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="2342" end_char="2344">not</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="2346" end_char="2349">just</TOKEN>
<TOKEN id="token-17-19" pos="word" morph="none" start_char="2351" end_char="2363">TraceTogether</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="2365" end_char="2368">data</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="2370" end_char="2373">that</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="2375" end_char="2377">was</TOKEN>
<TOKEN id="token-17-23" pos="word" morph="none" start_char="2379" end_char="2382">used</TOKEN>
<TOKEN id="token-17-24" pos="word" morph="none" start_char="2384" end_char="2385">in</TOKEN>
<TOKEN id="token-17-25" pos="word" morph="none" start_char="2387" end_char="2391">cases</TOKEN>
<TOKEN id="token-17-26" pos="word" morph="none" start_char="2393" end_char="2394">of</TOKEN>
<TOKEN id="token-17-27" pos="word" morph="none" start_char="2396" end_char="2402">serious</TOKEN>
<TOKEN id="token-17-28" pos="word" morph="none" start_char="2404" end_char="2411">criminal</TOKEN>
<TOKEN id="token-17-29" pos="word" morph="none" start_char="2413" end_char="2426">investigations</TOKEN>
<TOKEN id="token-17-30" pos="punct" morph="none" start_char="2427" end_char="2427">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2430" end_char="2580">
<ORIGINAL_TEXT>He said under the CPC, "other forms of sensitive data like phone or banking records" would also have their privacy regulations overruled in such cases.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2430" end_char="2431">He</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2433" end_char="2436">said</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2438" end_char="2442">under</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2444" end_char="2446">the</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2448" end_char="2450">CPC</TOKEN>
<TOKEN id="token-18-5" pos="punct" morph="none" start_char="2451" end_char="2451">,</TOKEN>
<TOKEN id="token-18-6" pos="punct" morph="none" start_char="2453" end_char="2453">"</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2454" end_char="2458">other</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2460" end_char="2464">forms</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="2466" end_char="2467">of</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="2469" end_char="2477">sensitive</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="2479" end_char="2482">data</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2484" end_char="2487">like</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="2489" end_char="2493">phone</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="2495" end_char="2496">or</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="2498" end_char="2504">banking</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="2506" end_char="2512">records</TOKEN>
<TOKEN id="token-18-17" pos="punct" morph="none" start_char="2513" end_char="2513">"</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="2515" end_char="2519">would</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="2521" end_char="2524">also</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="2526" end_char="2529">have</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="2531" end_char="2535">their</TOKEN>
<TOKEN id="token-18-22" pos="word" morph="none" start_char="2537" end_char="2543">privacy</TOKEN>
<TOKEN id="token-18-23" pos="word" morph="none" start_char="2545" end_char="2555">regulations</TOKEN>
<TOKEN id="token-18-24" pos="word" morph="none" start_char="2557" end_char="2565">overruled</TOKEN>
<TOKEN id="token-18-25" pos="word" morph="none" start_char="2567" end_char="2568">in</TOKEN>
<TOKEN id="token-18-26" pos="word" morph="none" start_char="2570" end_char="2573">such</TOKEN>
<TOKEN id="token-18-27" pos="word" morph="none" start_char="2575" end_char="2579">cases</TOKEN>
<TOKEN id="token-18-28" pos="punct" morph="none" start_char="2580" end_char="2580">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2583" end_char="2724">
<ORIGINAL_TEXT>Mr Balakrishnan added that to his knowledge, police had so far only once accessed contact tracing data, in the case of a murder investigation.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2583" end_char="2584">Mr</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2586" end_char="2597">Balakrishnan</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2599" end_char="2603">added</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2605" end_char="2608">that</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2610" end_char="2611">to</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2613" end_char="2615">his</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2617" end_char="2625">knowledge</TOKEN>
<TOKEN id="token-19-7" pos="punct" morph="none" start_char="2626" end_char="2626">,</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2628" end_char="2633">police</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="2635" end_char="2637">had</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="2639" end_char="2640">so</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="2642" end_char="2644">far</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="2646" end_char="2649">only</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="2651" end_char="2654">once</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="2656" end_char="2663">accessed</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="2665" end_char="2671">contact</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="2673" end_char="2679">tracing</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="2681" end_char="2684">data</TOKEN>
<TOKEN id="token-19-18" pos="punct" morph="none" start_char="2685" end_char="2685">,</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="2687" end_char="2688">in</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="2690" end_char="2692">the</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="2694" end_char="2697">case</TOKEN>
<TOKEN id="token-19-22" pos="word" morph="none" start_char="2699" end_char="2700">of</TOKEN>
<TOKEN id="token-19-23" pos="word" morph="none" start_char="2702" end_char="2702">a</TOKEN>
<TOKEN id="token-19-24" pos="word" morph="none" start_char="2704" end_char="2709">murder</TOKEN>
<TOKEN id="token-19-25" pos="word" morph="none" start_char="2711" end_char="2723">investigation</TOKEN>
<TOKEN id="token-19-26" pos="punct" morph="none" start_char="2724" end_char="2724">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2727" end_char="2899">
<ORIGINAL_TEXT>The minister stressed though that "once the pandemic is over and there will no longer be a need for contact tracing, we will happily stand down the TraceTogether programme."</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2727" end_char="2729">The</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2731" end_char="2738">minister</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2740" end_char="2747">stressed</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2749" end_char="2754">though</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2756" end_char="2759">that</TOKEN>
<TOKEN id="token-20-5" pos="punct" morph="none" start_char="2761" end_char="2761">"</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2762" end_char="2765">once</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2767" end_char="2769">the</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="2771" end_char="2778">pandemic</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2780" end_char="2781">is</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2783" end_char="2786">over</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="2788" end_char="2790">and</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="2792" end_char="2796">there</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="2798" end_char="2801">will</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="2803" end_char="2804">no</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="2806" end_char="2811">longer</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="2813" end_char="2814">be</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="2816" end_char="2816">a</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="2818" end_char="2821">need</TOKEN>
<TOKEN id="token-20-19" pos="word" morph="none" start_char="2823" end_char="2825">for</TOKEN>
<TOKEN id="token-20-20" pos="word" morph="none" start_char="2827" end_char="2833">contact</TOKEN>
<TOKEN id="token-20-21" pos="word" morph="none" start_char="2835" end_char="2841">tracing</TOKEN>
<TOKEN id="token-20-22" pos="punct" morph="none" start_char="2842" end_char="2842">,</TOKEN>
<TOKEN id="token-20-23" pos="word" morph="none" start_char="2844" end_char="2845">we</TOKEN>
<TOKEN id="token-20-24" pos="word" morph="none" start_char="2847" end_char="2850">will</TOKEN>
<TOKEN id="token-20-25" pos="word" morph="none" start_char="2852" end_char="2858">happily</TOKEN>
<TOKEN id="token-20-26" pos="word" morph="none" start_char="2860" end_char="2864">stand</TOKEN>
<TOKEN id="token-20-27" pos="word" morph="none" start_char="2866" end_char="2869">down</TOKEN>
<TOKEN id="token-20-28" pos="word" morph="none" start_char="2871" end_char="2873">the</TOKEN>
<TOKEN id="token-20-29" pos="word" morph="none" start_char="2875" end_char="2887">TraceTogether</TOKEN>
<TOKEN id="token-20-30" pos="word" morph="none" start_char="2889" end_char="2897">programme</TOKEN>
<TOKEN id="token-20-31" pos="punct" morph="none" start_char="2898" end_char="2899">."</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2902" end_char="3068">
<ORIGINAL_TEXT>Monday's announcement though sparked some controversy on social media, with people calling out the government and some users posting that they had now deleted the app.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2902" end_char="2909">Monday's</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2911" end_char="2922">announcement</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2924" end_char="2929">though</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2931" end_char="2937">sparked</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2939" end_char="2942">some</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="2944" end_char="2954">controversy</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2956" end_char="2957">on</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="2959" end_char="2964">social</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="2966" end_char="2970">media</TOKEN>
<TOKEN id="token-21-9" pos="punct" morph="none" start_char="2971" end_char="2971">,</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="2973" end_char="2976">with</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="2978" end_char="2983">people</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="2985" end_char="2991">calling</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="2993" end_char="2995">out</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="2997" end_char="2999">the</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="3001" end_char="3010">government</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="3012" end_char="3014">and</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="3016" end_char="3019">some</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="3021" end_char="3025">users</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="3027" end_char="3033">posting</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="3035" end_char="3038">that</TOKEN>
<TOKEN id="token-21-21" pos="word" morph="none" start_char="3040" end_char="3043">they</TOKEN>
<TOKEN id="token-21-22" pos="word" morph="none" start_char="3045" end_char="3047">had</TOKEN>
<TOKEN id="token-21-23" pos="word" morph="none" start_char="3049" end_char="3051">now</TOKEN>
<TOKEN id="token-21-24" pos="word" morph="none" start_char="3053" end_char="3059">deleted</TOKEN>
<TOKEN id="token-21-25" pos="word" morph="none" start_char="3061" end_char="3063">the</TOKEN>
<TOKEN id="token-21-26" pos="word" morph="none" start_char="3065" end_char="3067">app</TOKEN>
<TOKEN id="token-21-27" pos="punct" morph="none" start_char="3068" end_char="3068">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="3072" end_char="3151">
<ORIGINAL_TEXT>today’s mood: pic.twitter.com/SmjzIAVe1x— prEEtipls (@plspreeti) January 4, 2021</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="3072" end_char="3078">today’s</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="3080" end_char="3083">mood</TOKEN>
<TOKEN id="token-22-2" pos="punct" morph="none" start_char="3084" end_char="3084">:</TOKEN>
<TOKEN id="token-22-3" pos="unknown" morph="none" start_char="3086" end_char="3111">pic.twitter.com/SmjzIAVe1x</TOKEN>
<TOKEN id="token-22-4" pos="punct" morph="none" start_char="3112" end_char="3112">—</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="3114" end_char="3122">prEEtipls</TOKEN>
<TOKEN id="token-22-6" pos="punct" morph="none" start_char="3124" end_char="3125">(@</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="3126" end_char="3134">plspreeti</TOKEN>
<TOKEN id="token-22-8" pos="punct" morph="none" start_char="3135" end_char="3135">)</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="3137" end_char="3143">January</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="3145" end_char="3145">4</TOKEN>
<TOKEN id="token-22-11" pos="punct" morph="none" start_char="3146" end_char="3146">,</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="3148" end_char="3151">2021</TOKEN>
</SEG>
<SEG id="segment-23" start_char="3155" end_char="3245">
<ORIGINAL_TEXT>The BBC is not responsible for the content of external sites.View original tweet on Twitter</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="3155" end_char="3157">The</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="3159" end_char="3161">BBC</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="3163" end_char="3164">is</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="3166" end_char="3168">not</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="3170" end_char="3180">responsible</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="3182" end_char="3184">for</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="3186" end_char="3188">the</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="3190" end_char="3196">content</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="3198" end_char="3199">of</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="3201" end_char="3208">external</TOKEN>
<TOKEN id="token-23-10" pos="unknown" morph="none" start_char="3210" end_char="3219">sites.View</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="3221" end_char="3228">original</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="3230" end_char="3234">tweet</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="3236" end_char="3237">on</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="3239" end_char="3245">Twitter</TOKEN>
</SEG>
<SEG id="segment-24" start_char="3249" end_char="3349">
<ORIGINAL_TEXT>"I'm disappointed, but not at all surprised," local journalist and activist Kirsten Han told the BBC.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="punct" morph="none" start_char="3249" end_char="3249">"</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="3250" end_char="3252">I'm</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="3254" end_char="3265">disappointed</TOKEN>
<TOKEN id="token-24-3" pos="punct" morph="none" start_char="3266" end_char="3266">,</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="3268" end_char="3270">but</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="3272" end_char="3274">not</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="3276" end_char="3277">at</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="3279" end_char="3281">all</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="3283" end_char="3291">surprised</TOKEN>
<TOKEN id="token-24-9" pos="punct" morph="none" start_char="3292" end_char="3293">,"</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="3295" end_char="3299">local</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="3301" end_char="3310">journalist</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="3312" end_char="3314">and</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="3316" end_char="3323">activist</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="3325" end_char="3331">Kirsten</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="3333" end_char="3335">Han</TOKEN>
<TOKEN id="token-24-16" pos="word" morph="none" start_char="3337" end_char="3340">told</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="3342" end_char="3344">the</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="3346" end_char="3348">BBC</TOKEN>
<TOKEN id="token-24-19" pos="punct" morph="none" start_char="3349" end_char="3349">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="3351" end_char="3556">
<ORIGINAL_TEXT>"This is actually something that I've been flagging as a concern since the earlier days of TraceTogether - and was sometimes told that I was just a paranoid fearmonger undermining efforts to fight Covid-19.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="punct" morph="none" start_char="3351" end_char="3351">"</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="3352" end_char="3355">This</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="3357" end_char="3358">is</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="3360" end_char="3367">actually</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="3369" end_char="3377">something</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="3379" end_char="3382">that</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="3384" end_char="3387">I've</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="3389" end_char="3392">been</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="3394" end_char="3401">flagging</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="3403" end_char="3404">as</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="3406" end_char="3406">a</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="3408" end_char="3414">concern</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="3416" end_char="3420">since</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="3422" end_char="3424">the</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="3426" end_char="3432">earlier</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="3434" end_char="3437">days</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="3439" end_char="3440">of</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="3442" end_char="3454">TraceTogether</TOKEN>
<TOKEN id="token-25-18" pos="punct" morph="none" start_char="3456" end_char="3456">-</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="3458" end_char="3460">and</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="3462" end_char="3464">was</TOKEN>
<TOKEN id="token-25-21" pos="word" morph="none" start_char="3466" end_char="3474">sometimes</TOKEN>
<TOKEN id="token-25-22" pos="word" morph="none" start_char="3476" end_char="3479">told</TOKEN>
<TOKEN id="token-25-23" pos="word" morph="none" start_char="3481" end_char="3484">that</TOKEN>
<TOKEN id="token-25-24" pos="word" morph="none" start_char="3486" end_char="3486">I</TOKEN>
<TOKEN id="token-25-25" pos="word" morph="none" start_char="3488" end_char="3490">was</TOKEN>
<TOKEN id="token-25-26" pos="word" morph="none" start_char="3492" end_char="3495">just</TOKEN>
<TOKEN id="token-25-27" pos="word" morph="none" start_char="3497" end_char="3497">a</TOKEN>
<TOKEN id="token-25-28" pos="word" morph="none" start_char="3499" end_char="3506">paranoid</TOKEN>
<TOKEN id="token-25-29" pos="word" morph="none" start_char="3508" end_char="3517">fearmonger</TOKEN>
<TOKEN id="token-25-30" pos="word" morph="none" start_char="3519" end_char="3529">undermining</TOKEN>
<TOKEN id="token-25-31" pos="word" morph="none" start_char="3531" end_char="3537">efforts</TOKEN>
<TOKEN id="token-25-32" pos="word" morph="none" start_char="3539" end_char="3540">to</TOKEN>
<TOKEN id="token-25-33" pos="word" morph="none" start_char="3542" end_char="3546">fight</TOKEN>
<TOKEN id="token-25-34" pos="unknown" morph="none" start_char="3548" end_char="3555">Covid-19</TOKEN>
<TOKEN id="token-25-35" pos="punct" morph="none" start_char="3556" end_char="3556">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="3559" end_char="3612">
<ORIGINAL_TEXT>"It doesn't feel good at all to discover I was right."</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="punct" morph="none" start_char="3559" end_char="3559">"</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="3560" end_char="3561">It</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="3563" end_char="3569">doesn't</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="3571" end_char="3574">feel</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="3576" end_char="3579">good</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="3581" end_char="3582">at</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="3584" end_char="3586">all</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="3588" end_char="3589">to</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="3591" end_char="3598">discover</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="3600" end_char="3600">I</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="3602" end_char="3604">was</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="3606" end_char="3610">right</TOKEN>
<TOKEN id="token-26-12" pos="punct" morph="none" start_char="3611" end_char="3612">."</TOKEN>
</SEG>
<SEG id="segment-27" start_char="3615" end_char="3635">
<ORIGINAL_TEXT>Eroding public trust?</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="3615" end_char="3621">Eroding</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="3623" end_char="3628">public</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="3630" end_char="3634">trust</TOKEN>
<TOKEN id="token-27-3" pos="punct" morph="none" start_char="3635" end_char="3635">?</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3639" end_char="3809">
<ORIGINAL_TEXT>"I think why most people are so angry about this is not that they feel like they're constantly being watched," one Singaporean, who did not want to be named, told the BBC.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="punct" morph="none" start_char="3639" end_char="3639">"</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="3640" end_char="3640">I</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="3642" end_char="3646">think</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="3648" end_char="3650">why</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="3652" end_char="3655">most</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="3657" end_char="3662">people</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="3664" end_char="3666">are</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="3668" end_char="3669">so</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="3671" end_char="3675">angry</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="3677" end_char="3681">about</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="3683" end_char="3686">this</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="3688" end_char="3689">is</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="3691" end_char="3693">not</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="3695" end_char="3698">that</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="3700" end_char="3703">they</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="3705" end_char="3708">feel</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="3710" end_char="3713">like</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="3715" end_char="3721">they're</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="3723" end_char="3732">constantly</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="3734" end_char="3738">being</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="3740" end_char="3746">watched</TOKEN>
<TOKEN id="token-28-21" pos="punct" morph="none" start_char="3747" end_char="3748">,"</TOKEN>
<TOKEN id="token-28-22" pos="word" morph="none" start_char="3750" end_char="3752">one</TOKEN>
<TOKEN id="token-28-23" pos="word" morph="none" start_char="3754" end_char="3764">Singaporean</TOKEN>
<TOKEN id="token-28-24" pos="punct" morph="none" start_char="3765" end_char="3765">,</TOKEN>
<TOKEN id="token-28-25" pos="word" morph="none" start_char="3767" end_char="3769">who</TOKEN>
<TOKEN id="token-28-26" pos="word" morph="none" start_char="3771" end_char="3773">did</TOKEN>
<TOKEN id="token-28-27" pos="word" morph="none" start_char="3775" end_char="3777">not</TOKEN>
<TOKEN id="token-28-28" pos="word" morph="none" start_char="3779" end_char="3782">want</TOKEN>
<TOKEN id="token-28-29" pos="word" morph="none" start_char="3784" end_char="3785">to</TOKEN>
<TOKEN id="token-28-30" pos="word" morph="none" start_char="3787" end_char="3788">be</TOKEN>
<TOKEN id="token-28-31" pos="word" morph="none" start_char="3790" end_char="3794">named</TOKEN>
<TOKEN id="token-28-32" pos="punct" morph="none" start_char="3795" end_char="3795">,</TOKEN>
<TOKEN id="token-28-33" pos="word" morph="none" start_char="3797" end_char="3800">told</TOKEN>
<TOKEN id="token-28-34" pos="word" morph="none" start_char="3802" end_char="3804">the</TOKEN>
<TOKEN id="token-28-35" pos="word" morph="none" start_char="3806" end_char="3808">BBC</TOKEN>
<TOKEN id="token-28-36" pos="punct" morph="none" start_char="3809" end_char="3809">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3811" end_char="3862">
<ORIGINAL_TEXT>"We already have that through other means like CCTV.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="punct" morph="none" start_char="3811" end_char="3811">"</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="3812" end_char="3813">We</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="3815" end_char="3821">already</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="3823" end_char="3826">have</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="3828" end_char="3831">that</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="3833" end_char="3839">through</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="3841" end_char="3845">other</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="3847" end_char="3851">means</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="3853" end_char="3856">like</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="3858" end_char="3861">CCTV</TOKEN>
<TOKEN id="token-29-10" pos="punct" morph="none" start_char="3862" end_char="3862">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3865" end_char="3916">
<ORIGINAL_TEXT>"It's more that they feel like they've been cheated.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="punct" morph="none" start_char="3865" end_char="3865">"</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="3866" end_char="3869">It's</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="3871" end_char="3874">more</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="3876" end_char="3879">that</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="3881" end_char="3884">they</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="3886" end_char="3889">feel</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="3891" end_char="3894">like</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="3896" end_char="3902">they've</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="3904" end_char="3907">been</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="3909" end_char="3915">cheated</TOKEN>
<TOKEN id="token-30-10" pos="punct" morph="none" start_char="3916" end_char="3916">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="3918" end_char="4065">
<ORIGINAL_TEXT>The government had assured us many times that TraceTogether would only be used for contact tracing, but now they've suddenly added this new caveat."</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="3918" end_char="3920">The</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="3922" end_char="3931">government</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="3933" end_char="3935">had</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="3937" end_char="3943">assured</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="3945" end_char="3946">us</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="3948" end_char="3951">many</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="3953" end_char="3957">times</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="3959" end_char="3962">that</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="3964" end_char="3976">TraceTogether</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="3978" end_char="3982">would</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="3984" end_char="3987">only</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="3989" end_char="3990">be</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="3992" end_char="3995">used</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="3997" end_char="3999">for</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="4001" end_char="4007">contact</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="4009" end_char="4015">tracing</TOKEN>
<TOKEN id="token-31-16" pos="punct" morph="none" start_char="4016" end_char="4016">,</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="4018" end_char="4020">but</TOKEN>
<TOKEN id="token-31-18" pos="word" morph="none" start_char="4022" end_char="4024">now</TOKEN>
<TOKEN id="token-31-19" pos="word" morph="none" start_char="4026" end_char="4032">they've</TOKEN>
<TOKEN id="token-31-20" pos="word" morph="none" start_char="4034" end_char="4041">suddenly</TOKEN>
<TOKEN id="token-31-21" pos="word" morph="none" start_char="4043" end_char="4047">added</TOKEN>
<TOKEN id="token-31-22" pos="word" morph="none" start_char="4049" end_char="4052">this</TOKEN>
<TOKEN id="token-31-23" pos="word" morph="none" start_char="4054" end_char="4056">new</TOKEN>
<TOKEN id="token-31-24" pos="word" morph="none" start_char="4058" end_char="4063">caveat</TOKEN>
<TOKEN id="token-31-25" pos="punct" morph="none" start_char="4064" end_char="4065">."</TOKEN>
</SEG>
<SEG id="segment-32" start_char="4068" end_char="4180">
<ORIGINAL_TEXT>Another person told the BBC they wished they could delete the app, but daily life would be impossible without it.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="4068" end_char="4074">Another</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="4076" end_char="4081">person</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="4083" end_char="4086">told</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="4088" end_char="4090">the</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="4092" end_char="4094">BBC</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="4096" end_char="4099">they</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="4101" end_char="4106">wished</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="4108" end_char="4111">they</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="4113" end_char="4117">could</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="4119" end_char="4124">delete</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="4126" end_char="4128">the</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="4130" end_char="4132">app</TOKEN>
<TOKEN id="token-32-12" pos="punct" morph="none" start_char="4133" end_char="4133">,</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="4135" end_char="4137">but</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="4139" end_char="4143">daily</TOKEN>
<TOKEN id="token-32-15" pos="word" morph="none" start_char="4145" end_char="4148">life</TOKEN>
<TOKEN id="token-32-16" pos="word" morph="none" start_char="4150" end_char="4154">would</TOKEN>
<TOKEN id="token-32-17" pos="word" morph="none" start_char="4156" end_char="4157">be</TOKEN>
<TOKEN id="token-32-18" pos="word" morph="none" start_char="4159" end_char="4168">impossible</TOKEN>
<TOKEN id="token-32-19" pos="word" morph="none" start_char="4170" end_char="4176">without</TOKEN>
<TOKEN id="token-32-20" pos="word" morph="none" start_char="4178" end_char="4179">it</TOKEN>
<TOKEN id="token-32-21" pos="punct" morph="none" start_char="4180" end_char="4180">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="4183" end_char="4299">
<ORIGINAL_TEXT>"So I'm just going to disable my Bluetooth for TraceTogether from now on, unless I have to use it to enter somewhere.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="punct" morph="none" start_char="4183" end_char="4183">"</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="4184" end_char="4185">So</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="4187" end_char="4189">I'm</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="4191" end_char="4194">just</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="4196" end_char="4200">going</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="4202" end_char="4203">to</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="4205" end_char="4211">disable</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="4213" end_char="4214">my</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="4216" end_char="4224">Bluetooth</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="4226" end_char="4228">for</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="4230" end_char="4242">TraceTogether</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="4244" end_char="4247">from</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="4249" end_char="4251">now</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="4253" end_char="4254">on</TOKEN>
<TOKEN id="token-33-14" pos="punct" morph="none" start_char="4255" end_char="4255">,</TOKEN>
<TOKEN id="token-33-15" pos="word" morph="none" start_char="4257" end_char="4262">unless</TOKEN>
<TOKEN id="token-33-16" pos="word" morph="none" start_char="4264" end_char="4264">I</TOKEN>
<TOKEN id="token-33-17" pos="word" morph="none" start_char="4266" end_char="4269">have</TOKEN>
<TOKEN id="token-33-18" pos="word" morph="none" start_char="4271" end_char="4272">to</TOKEN>
<TOKEN id="token-33-19" pos="word" morph="none" start_char="4274" end_char="4276">use</TOKEN>
<TOKEN id="token-33-20" pos="word" morph="none" start_char="4278" end_char="4279">it</TOKEN>
<TOKEN id="token-33-21" pos="word" morph="none" start_char="4281" end_char="4282">to</TOKEN>
<TOKEN id="token-33-22" pos="word" morph="none" start_char="4284" end_char="4288">enter</TOKEN>
<TOKEN id="token-33-23" pos="word" morph="none" start_char="4290" end_char="4298">somewhere</TOKEN>
<TOKEN id="token-33-24" pos="punct" morph="none" start_char="4299" end_char="4299">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="4301" end_char="4407">
<ORIGINAL_TEXT>If the app is not only going to be used for contact tracing, then it's too much of an invasion of privacy."</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="4301" end_char="4302">If</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="4304" end_char="4306">the</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="4308" end_char="4310">app</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="4312" end_char="4313">is</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="4315" end_char="4317">not</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="4319" end_char="4322">only</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="4324" end_char="4328">going</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="4330" end_char="4331">to</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="4333" end_char="4334">be</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="4336" end_char="4339">used</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="4341" end_char="4343">for</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="4345" end_char="4351">contact</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="4353" end_char="4359">tracing</TOKEN>
<TOKEN id="token-34-13" pos="punct" morph="none" start_char="4360" end_char="4360">,</TOKEN>
<TOKEN id="token-34-14" pos="word" morph="none" start_char="4362" end_char="4365">then</TOKEN>
<TOKEN id="token-34-15" pos="word" morph="none" start_char="4367" end_char="4370">it's</TOKEN>
<TOKEN id="token-34-16" pos="word" morph="none" start_char="4372" end_char="4374">too</TOKEN>
<TOKEN id="token-34-17" pos="word" morph="none" start_char="4376" end_char="4379">much</TOKEN>
<TOKEN id="token-34-18" pos="word" morph="none" start_char="4381" end_char="4382">of</TOKEN>
<TOKEN id="token-34-19" pos="word" morph="none" start_char="4384" end_char="4385">an</TOKEN>
<TOKEN id="token-34-20" pos="word" morph="none" start_char="4387" end_char="4394">invasion</TOKEN>
<TOKEN id="token-34-21" pos="word" morph="none" start_char="4396" end_char="4397">of</TOKEN>
<TOKEN id="token-34-22" pos="word" morph="none" start_char="4399" end_char="4405">privacy</TOKEN>
<TOKEN id="token-34-23" pos="punct" morph="none" start_char="4406" end_char="4407">."</TOKEN>
</SEG>
<SEG id="segment-35" start_char="4410" end_char="4534">
<ORIGINAL_TEXT>Australian privacy watchdog Digital Rights Watch, told the BBC they were "extremely concerned" about the news from Singapore.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="4410" end_char="4419">Australian</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="4421" end_char="4427">privacy</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="4429" end_char="4436">watchdog</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="4438" end_char="4444">Digital</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="4446" end_char="4451">Rights</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="4453" end_char="4457">Watch</TOKEN>
<TOKEN id="token-35-6" pos="punct" morph="none" start_char="4458" end_char="4458">,</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="4460" end_char="4463">told</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="4465" end_char="4467">the</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="4469" end_char="4471">BBC</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="4473" end_char="4476">they</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="4478" end_char="4481">were</TOKEN>
<TOKEN id="token-35-12" pos="punct" morph="none" start_char="4483" end_char="4483">"</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="4484" end_char="4492">extremely</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="4494" end_char="4502">concerned</TOKEN>
<TOKEN id="token-35-15" pos="punct" morph="none" start_char="4503" end_char="4503">"</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="4505" end_char="4509">about</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="4511" end_char="4513">the</TOKEN>
<TOKEN id="token-35-18" pos="word" morph="none" start_char="4515" end_char="4518">news</TOKEN>
<TOKEN id="token-35-19" pos="word" morph="none" start_char="4520" end_char="4523">from</TOKEN>
<TOKEN id="token-35-20" pos="word" morph="none" start_char="4525" end_char="4533">Singapore</TOKEN>
<TOKEN id="token-35-21" pos="punct" morph="none" start_char="4534" end_char="4534">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="4537" end_char="4693">
<ORIGINAL_TEXT>"This is the worst case scenario that privacy advocates have warned about since the start of the pandemic," Programme Director Lucie Krahulcova told the BBC.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="punct" morph="none" start_char="4537" end_char="4537">"</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="4538" end_char="4541">This</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="4543" end_char="4544">is</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="4546" end_char="4548">the</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="4550" end_char="4554">worst</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="4556" end_char="4559">case</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="4561" end_char="4568">scenario</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="4570" end_char="4573">that</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="4575" end_char="4581">privacy</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="4583" end_char="4591">advocates</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="4593" end_char="4596">have</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="4598" end_char="4603">warned</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="4605" end_char="4609">about</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="4611" end_char="4615">since</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="4617" end_char="4619">the</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="4621" end_char="4625">start</TOKEN>
<TOKEN id="token-36-16" pos="word" morph="none" start_char="4627" end_char="4628">of</TOKEN>
<TOKEN id="token-36-17" pos="word" morph="none" start_char="4630" end_char="4632">the</TOKEN>
<TOKEN id="token-36-18" pos="word" morph="none" start_char="4634" end_char="4641">pandemic</TOKEN>
<TOKEN id="token-36-19" pos="punct" morph="none" start_char="4642" end_char="4643">,"</TOKEN>
<TOKEN id="token-36-20" pos="word" morph="none" start_char="4645" end_char="4653">Programme</TOKEN>
<TOKEN id="token-36-21" pos="word" morph="none" start_char="4655" end_char="4662">Director</TOKEN>
<TOKEN id="token-36-22" pos="word" morph="none" start_char="4664" end_char="4668">Lucie</TOKEN>
<TOKEN id="token-36-23" pos="word" morph="none" start_char="4670" end_char="4679">Krahulcova</TOKEN>
<TOKEN id="token-36-24" pos="word" morph="none" start_char="4681" end_char="4684">told</TOKEN>
<TOKEN id="token-36-25" pos="word" morph="none" start_char="4686" end_char="4688">the</TOKEN>
<TOKEN id="token-36-26" pos="word" morph="none" start_char="4690" end_char="4692">BBC</TOKEN>
<TOKEN id="token-36-27" pos="punct" morph="none" start_char="4693" end_char="4693">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="4695" end_char="4800">
<ORIGINAL_TEXT>"Such an approach will erode public trust in future health responses and therefore impede their efficacy."</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="punct" morph="none" start_char="4695" end_char="4695">"</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="4696" end_char="4699">Such</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="4701" end_char="4702">an</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="4704" end_char="4711">approach</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="4713" end_char="4716">will</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="4718" end_char="4722">erode</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="4724" end_char="4729">public</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="4731" end_char="4735">trust</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="4737" end_char="4738">in</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="4740" end_char="4745">future</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="4747" end_char="4752">health</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="4754" end_char="4762">responses</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="4764" end_char="4766">and</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="4768" end_char="4776">therefore</TOKEN>
<TOKEN id="token-37-14" pos="word" morph="none" start_char="4778" end_char="4783">impede</TOKEN>
<TOKEN id="token-37-15" pos="word" morph="none" start_char="4785" end_char="4789">their</TOKEN>
<TOKEN id="token-37-16" pos="word" morph="none" start_char="4791" end_char="4798">efficacy</TOKEN>
<TOKEN id="token-37-17" pos="punct" morph="none" start_char="4799" end_char="4800">."</TOKEN>
</SEG>
<SEG id="segment-38" start_char="4803" end_char="4943">
<ORIGINAL_TEXT>Like most countries, Australia has rolled out its own contact tracing app but uptake has been sluggish precisely because of privacy concerns.</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="4803" end_char="4806">Like</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="4808" end_char="4811">most</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="4813" end_char="4821">countries</TOKEN>
<TOKEN id="token-38-3" pos="punct" morph="none" start_char="4822" end_char="4822">,</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="4824" end_char="4832">Australia</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="4834" end_char="4836">has</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="4838" end_char="4843">rolled</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="4845" end_char="4847">out</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="4849" end_char="4851">its</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="4853" end_char="4855">own</TOKEN>
<TOKEN id="token-38-10" pos="word" morph="none" start_char="4857" end_char="4863">contact</TOKEN>
<TOKEN id="token-38-11" pos="word" morph="none" start_char="4865" end_char="4871">tracing</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="4873" end_char="4875">app</TOKEN>
<TOKEN id="token-38-13" pos="word" morph="none" start_char="4877" end_char="4879">but</TOKEN>
<TOKEN id="token-38-14" pos="word" morph="none" start_char="4881" end_char="4886">uptake</TOKEN>
<TOKEN id="token-38-15" pos="word" morph="none" start_char="4888" end_char="4890">has</TOKEN>
<TOKEN id="token-38-16" pos="word" morph="none" start_char="4892" end_char="4895">been</TOKEN>
<TOKEN id="token-38-17" pos="word" morph="none" start_char="4897" end_char="4904">sluggish</TOKEN>
<TOKEN id="token-38-18" pos="word" morph="none" start_char="4906" end_char="4914">precisely</TOKEN>
<TOKEN id="token-38-19" pos="word" morph="none" start_char="4916" end_char="4922">because</TOKEN>
<TOKEN id="token-38-20" pos="word" morph="none" start_char="4924" end_char="4925">of</TOKEN>
<TOKEN id="token-38-21" pos="word" morph="none" start_char="4927" end_char="4933">privacy</TOKEN>
<TOKEN id="token-38-22" pos="word" morph="none" start_char="4935" end_char="4942">concerns</TOKEN>
<TOKEN id="token-38-23" pos="punct" morph="none" start_char="4943" end_char="4943">.</TOKEN>
</SEG>
<SEG id="segment-39" start_char="4946" end_char="4995">
<ORIGINAL_TEXT>Singapore schoolchildren must use Covid-trace tech</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="4946" end_char="4954">Singapore</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="4956" end_char="4969">schoolchildren</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="4971" end_char="4974">must</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="4976" end_char="4978">use</TOKEN>
<TOKEN id="token-39-4" pos="unknown" morph="none" start_char="4980" end_char="4990">Covid-trace</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="4992" end_char="4995">tech</TOKEN>
</SEG>
<SEG id="segment-40" start_char="4998" end_char="5046">
<ORIGINAL_TEXT>Why Singapore turned to wearable virus-trace tech</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="4998" end_char="5000">Why</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="5002" end_char="5010">Singapore</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="5012" end_char="5017">turned</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="5019" end_char="5020">to</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="5022" end_char="5029">wearable</TOKEN>
<TOKEN id="token-40-5" pos="unknown" morph="none" start_char="5031" end_char="5041">virus-trace</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="5043" end_char="5046">tech</TOKEN>
</SEG>
<SEG id="segment-41" start_char="5050" end_char="5154">
<ORIGINAL_TEXT>Singapore was among the first countries to introduce a contact tracing app nationally in March last year.</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="5050" end_char="5058">Singapore</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="5060" end_char="5062">was</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="5064" end_char="5068">among</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="5070" end_char="5072">the</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="5074" end_char="5078">first</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="5080" end_char="5088">countries</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="5090" end_char="5091">to</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="5093" end_char="5101">introduce</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="5103" end_char="5103">a</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="5105" end_char="5111">contact</TOKEN>
<TOKEN id="token-41-10" pos="word" morph="none" start_char="5113" end_char="5119">tracing</TOKEN>
<TOKEN id="token-41-11" pos="word" morph="none" start_char="5121" end_char="5123">app</TOKEN>
<TOKEN id="token-41-12" pos="word" morph="none" start_char="5125" end_char="5134">nationally</TOKEN>
<TOKEN id="token-41-13" pos="word" morph="none" start_char="5136" end_char="5137">in</TOKEN>
<TOKEN id="token-41-14" pos="word" morph="none" start_char="5139" end_char="5143">March</TOKEN>
<TOKEN id="token-41-15" pos="word" morph="none" start_char="5145" end_char="5148">last</TOKEN>
<TOKEN id="token-41-16" pos="word" morph="none" start_char="5150" end_char="5153">year</TOKEN>
<TOKEN id="token-41-17" pos="punct" morph="none" start_char="5154" end_char="5154">.</TOKEN>
</SEG>
<SEG id="segment-42" start_char="5157" end_char="5289">
<ORIGINAL_TEXT>The introduction of the token in June had sparked a rare backlash against the government over concerns the device would be mandatory.</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="5157" end_char="5159">The</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="5161" end_char="5172">introduction</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="5174" end_char="5175">of</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="5177" end_char="5179">the</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="5181" end_char="5185">token</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="5187" end_char="5188">in</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="5190" end_char="5193">June</TOKEN>
<TOKEN id="token-42-7" pos="word" morph="none" start_char="5195" end_char="5197">had</TOKEN>
<TOKEN id="token-42-8" pos="word" morph="none" start_char="5199" end_char="5205">sparked</TOKEN>
<TOKEN id="token-42-9" pos="word" morph="none" start_char="5207" end_char="5207">a</TOKEN>
<TOKEN id="token-42-10" pos="word" morph="none" start_char="5209" end_char="5212">rare</TOKEN>
<TOKEN id="token-42-11" pos="word" morph="none" start_char="5214" end_char="5221">backlash</TOKEN>
<TOKEN id="token-42-12" pos="word" morph="none" start_char="5223" end_char="5229">against</TOKEN>
<TOKEN id="token-42-13" pos="word" morph="none" start_char="5231" end_char="5233">the</TOKEN>
<TOKEN id="token-42-14" pos="word" morph="none" start_char="5235" end_char="5244">government</TOKEN>
<TOKEN id="token-42-15" pos="word" morph="none" start_char="5246" end_char="5249">over</TOKEN>
<TOKEN id="token-42-16" pos="word" morph="none" start_char="5251" end_char="5258">concerns</TOKEN>
<TOKEN id="token-42-17" pos="word" morph="none" start_char="5260" end_char="5262">the</TOKEN>
<TOKEN id="token-42-18" pos="word" morph="none" start_char="5264" end_char="5269">device</TOKEN>
<TOKEN id="token-42-19" pos="word" morph="none" start_char="5271" end_char="5275">would</TOKEN>
<TOKEN id="token-42-20" pos="word" morph="none" start_char="5277" end_char="5278">be</TOKEN>
<TOKEN id="token-42-21" pos="word" morph="none" start_char="5280" end_char="5288">mandatory</TOKEN>
<TOKEN id="token-42-22" pos="punct" morph="none" start_char="5289" end_char="5289">.</TOKEN>
</SEG>
<SEG id="segment-43" start_char="5291" end_char="5381">
<ORIGINAL_TEXT>An online petition calling for it to be ditched has gathered some 55,000 signatures so far.</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="5291" end_char="5292">An</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="5294" end_char="5299">online</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="5301" end_char="5308">petition</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="5310" end_char="5316">calling</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="5318" end_char="5320">for</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="5322" end_char="5323">it</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="5325" end_char="5326">to</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="5328" end_char="5329">be</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="5331" end_char="5337">ditched</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="5339" end_char="5341">has</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="5343" end_char="5350">gathered</TOKEN>
<TOKEN id="token-43-11" pos="word" morph="none" start_char="5352" end_char="5355">some</TOKEN>
<TOKEN id="token-43-12" pos="unknown" morph="none" start_char="5357" end_char="5362">55,000</TOKEN>
<TOKEN id="token-43-13" pos="word" morph="none" start_char="5364" end_char="5373">signatures</TOKEN>
<TOKEN id="token-43-14" pos="word" morph="none" start_char="5375" end_char="5376">so</TOKEN>
<TOKEN id="token-43-15" pos="word" morph="none" start_char="5378" end_char="5380">far</TOKEN>
<TOKEN id="token-43-16" pos="punct" morph="none" start_char="5381" end_char="5381">.</TOKEN>
</SEG>
<SEG id="segment-44" start_char="5384" end_char="5469">
<ORIGINAL_TEXT>Singapore has been been one of the most successful countries in tackling the pandemic.</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="5384" end_char="5392">Singapore</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="5394" end_char="5396">has</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="5398" end_char="5401">been</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="5403" end_char="5406">been</TOKEN>
<TOKEN id="token-44-4" pos="word" morph="none" start_char="5408" end_char="5410">one</TOKEN>
<TOKEN id="token-44-5" pos="word" morph="none" start_char="5412" end_char="5413">of</TOKEN>
<TOKEN id="token-44-6" pos="word" morph="none" start_char="5415" end_char="5417">the</TOKEN>
<TOKEN id="token-44-7" pos="word" morph="none" start_char="5419" end_char="5422">most</TOKEN>
<TOKEN id="token-44-8" pos="word" morph="none" start_char="5424" end_char="5433">successful</TOKEN>
<TOKEN id="token-44-9" pos="word" morph="none" start_char="5435" end_char="5443">countries</TOKEN>
<TOKEN id="token-44-10" pos="word" morph="none" start_char="5445" end_char="5446">in</TOKEN>
<TOKEN id="token-44-11" pos="word" morph="none" start_char="5448" end_char="5455">tackling</TOKEN>
<TOKEN id="token-44-12" pos="word" morph="none" start_char="5457" end_char="5459">the</TOKEN>
<TOKEN id="token-44-13" pos="word" morph="none" start_char="5461" end_char="5468">pandemic</TOKEN>
<TOKEN id="token-44-14" pos="punct" morph="none" start_char="5469" end_char="5469">.</TOKEN>
</SEG>
<SEG id="segment-45" start_char="5471" end_char="5586">
<ORIGINAL_TEXT>Despite a big outbreak among its foreign workers early on, local infection rates have for months been close to zero.</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="5471" end_char="5477">Despite</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="5479" end_char="5479">a</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="5481" end_char="5483">big</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="5485" end_char="5492">outbreak</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="5494" end_char="5498">among</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="5500" end_char="5502">its</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="5504" end_char="5510">foreign</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="5512" end_char="5518">workers</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="5520" end_char="5524">early</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="5526" end_char="5527">on</TOKEN>
<TOKEN id="token-45-10" pos="punct" morph="none" start_char="5528" end_char="5528">,</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="5530" end_char="5534">local</TOKEN>
<TOKEN id="token-45-12" pos="word" morph="none" start_char="5536" end_char="5544">infection</TOKEN>
<TOKEN id="token-45-13" pos="word" morph="none" start_char="5546" end_char="5550">rates</TOKEN>
<TOKEN id="token-45-14" pos="word" morph="none" start_char="5552" end_char="5555">have</TOKEN>
<TOKEN id="token-45-15" pos="word" morph="none" start_char="5557" end_char="5559">for</TOKEN>
<TOKEN id="token-45-16" pos="word" morph="none" start_char="5561" end_char="5566">months</TOKEN>
<TOKEN id="token-45-17" pos="word" morph="none" start_char="5568" end_char="5571">been</TOKEN>
<TOKEN id="token-45-18" pos="word" morph="none" start_char="5573" end_char="5577">close</TOKEN>
<TOKEN id="token-45-19" pos="word" morph="none" start_char="5579" end_char="5580">to</TOKEN>
<TOKEN id="token-45-20" pos="word" morph="none" start_char="5582" end_char="5585">zero</TOKEN>
<TOKEN id="token-45-21" pos="punct" morph="none" start_char="5586" end_char="5586">.</TOKEN>
</SEG>
<SEG id="segment-46" start_char="5591" end_char="5645">
<ORIGINAL_TEXT>Singapore rolled out its Covid tracing tokens last June</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="5591" end_char="5599">Singapore</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="5601" end_char="5606">rolled</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="5608" end_char="5610">out</TOKEN>
<TOKEN id="token-46-3" pos="word" morph="none" start_char="5612" end_char="5614">its</TOKEN>
<TOKEN id="token-46-4" pos="word" morph="none" start_char="5616" end_char="5620">Covid</TOKEN>
<TOKEN id="token-46-5" pos="word" morph="none" start_char="5622" end_char="5628">tracing</TOKEN>
<TOKEN id="token-46-6" pos="word" morph="none" start_char="5630" end_char="5635">tokens</TOKEN>
<TOKEN id="token-46-7" pos="word" morph="none" start_char="5637" end_char="5640">last</TOKEN>
<TOKEN id="token-46-8" pos="word" morph="none" start_char="5642" end_char="5645">June</TOKEN>
</SEG>
<SEG id="segment-47" start_char="5649" end_char="5662">
<ORIGINAL_TEXT>Related Topics</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="5649" end_char="5655">Related</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="5657" end_char="5662">Topics</TOKEN>
</SEG>
<SEG id="segment-48" start_char="5666" end_char="5672">
<ORIGINAL_TEXT>Privacy</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="5666" end_char="5672">Privacy</TOKEN>
</SEG>
<SEG id="segment-49" start_char="5675" end_char="5683">
<ORIGINAL_TEXT>Singapore</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="5675" end_char="5683">Singapore</TOKEN>
</SEG>
<SEG id="segment-50" start_char="5686" end_char="5705">
<ORIGINAL_TEXT>Coronavirus pandemic</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="5686" end_char="5696">Coronavirus</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="5698" end_char="5705">pandemic</TOKEN>
</SEG>
<SEG id="segment-51" start_char="5709" end_char="5726">
<ORIGINAL_TEXT>More on this story</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="word" morph="none" start_char="5709" end_char="5712">More</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="5714" end_char="5715">on</TOKEN>
<TOKEN id="token-51-2" pos="word" morph="none" start_char="5717" end_char="5720">this</TOKEN>
<TOKEN id="token-51-3" pos="word" morph="none" start_char="5722" end_char="5726">story</TOKEN>
</SEG>
<SEG id="segment-52" start_char="5730" end_char="5779">
<ORIGINAL_TEXT>Singapore schoolchildren must use Covid-trace tech</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="5730" end_char="5738">Singapore</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="5740" end_char="5753">schoolchildren</TOKEN>
<TOKEN id="token-52-2" pos="word" morph="none" start_char="5755" end_char="5758">must</TOKEN>
<TOKEN id="token-52-3" pos="word" morph="none" start_char="5760" end_char="5762">use</TOKEN>
<TOKEN id="token-52-4" pos="unknown" morph="none" start_char="5764" end_char="5774">Covid-trace</TOKEN>
<TOKEN id="token-52-5" pos="word" morph="none" start_char="5776" end_char="5779">tech</TOKEN>
</SEG>
<SEG id="segment-53" start_char="5782" end_char="5796">
<ORIGINAL_TEXT>3 November 2020</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="word" morph="none" start_char="5782" end_char="5782">3</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="5784" end_char="5791">November</TOKEN>
<TOKEN id="token-53-2" pos="word" morph="none" start_char="5793" end_char="5796">2020</TOKEN>
</SEG>
<SEG id="segment-54" start_char="5799" end_char="5847">
<ORIGINAL_TEXT>Why Singapore turned to wearable virus-trace tech</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="word" morph="none" start_char="5799" end_char="5801">Why</TOKEN>
<TOKEN id="token-54-1" pos="word" morph="none" start_char="5803" end_char="5811">Singapore</TOKEN>
<TOKEN id="token-54-2" pos="word" morph="none" start_char="5813" end_char="5818">turned</TOKEN>
<TOKEN id="token-54-3" pos="word" morph="none" start_char="5820" end_char="5821">to</TOKEN>
<TOKEN id="token-54-4" pos="word" morph="none" start_char="5823" end_char="5830">wearable</TOKEN>
<TOKEN id="token-54-5" pos="unknown" morph="none" start_char="5832" end_char="5842">virus-trace</TOKEN>
<TOKEN id="token-54-6" pos="word" morph="none" start_char="5844" end_char="5847">tech</TOKEN>
</SEG>
<SEG id="segment-55" start_char="5850" end_char="5860">
<ORIGINAL_TEXT>5 July 2020</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="word" morph="none" start_char="5850" end_char="5850">5</TOKEN>
<TOKEN id="token-55-1" pos="word" morph="none" start_char="5852" end_char="5855">July</TOKEN>
<TOKEN id="token-55-2" pos="word" morph="none" start_char="5857" end_char="5860">2020</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
