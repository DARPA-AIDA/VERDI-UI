<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="eng">
<DOC id="L0C049DZM" lang="eng" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="2947" raw_text_md5="84c9f2fe3f4dd413e65f4a9598cfda12">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="76">
<ORIGINAL_TEXT>Experts: Accusation that Covid-19 virus originates in lab is false and wrong</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="7">Experts</TOKEN>
<TOKEN id="token-0-1" pos="punct" morph="none" start_char="8" end_char="8">:</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="10" end_char="19">Accusation</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="21" end_char="24">that</TOKEN>
<TOKEN id="token-0-4" pos="unknown" morph="none" start_char="26" end_char="33">Covid-19</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="35" end_char="39">virus</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="41" end_char="50">originates</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="52" end_char="53">in</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="55" end_char="57">lab</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="59" end_char="60">is</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="62" end_char="66">false</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="68" end_char="70">and</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="72" end_char="76">wrong</TOKEN>
</SEG>
<SEG id="segment-1" start_char="80" end_char="102">
<ORIGINAL_TEXT>file79kl6b2jn4hhgvz3aa1</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="80" end_char="102">file79kl6b2jn4hhgvz3aa1</TOKEN>
</SEG>
<SEG id="segment-2" start_char="106" end_char="315">
<ORIGINAL_TEXT>BEIJING: The accusations that the Covid-19 (coronavirus) outbreak causing the pandemic was created in the laboratory or in a laboratory in China's Wuhan are false and wrong, several French scientists have said.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="106" end_char="112">BEIJING</TOKEN>
<TOKEN id="token-2-1" pos="punct" morph="none" start_char="113" end_char="113">:</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="115" end_char="117">The</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="119" end_char="129">accusations</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="131" end_char="134">that</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="136" end_char="138">the</TOKEN>
<TOKEN id="token-2-6" pos="unknown" morph="none" start_char="140" end_char="147">Covid-19</TOKEN>
<TOKEN id="token-2-7" pos="punct" morph="none" start_char="149" end_char="149">(</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="150" end_char="160">coronavirus</TOKEN>
<TOKEN id="token-2-9" pos="punct" morph="none" start_char="161" end_char="161">)</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="163" end_char="170">outbreak</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="172" end_char="178">causing</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="180" end_char="182">the</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="184" end_char="191">pandemic</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="193" end_char="195">was</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="197" end_char="203">created</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="205" end_char="206">in</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="208" end_char="210">the</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="212" end_char="221">laboratory</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="223" end_char="224">or</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="226" end_char="227">in</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="229" end_char="229">a</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="231" end_char="240">laboratory</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="242" end_char="243">in</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="245" end_char="251">China's</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="253" end_char="257">Wuhan</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="259" end_char="261">are</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="263" end_char="267">false</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="269" end_char="271">and</TOKEN>
<TOKEN id="token-2-29" pos="word" morph="none" start_char="273" end_char="277">wrong</TOKEN>
<TOKEN id="token-2-30" pos="punct" morph="none" start_char="278" end_char="278">,</TOKEN>
<TOKEN id="token-2-31" pos="word" morph="none" start_char="280" end_char="286">several</TOKEN>
<TOKEN id="token-2-32" pos="word" morph="none" start_char="288" end_char="293">French</TOKEN>
<TOKEN id="token-2-33" pos="word" morph="none" start_char="295" end_char="304">scientists</TOKEN>
<TOKEN id="token-2-34" pos="word" morph="none" start_char="306" end_char="309">have</TOKEN>
<TOKEN id="token-2-35" pos="word" morph="none" start_char="311" end_char="314">said</TOKEN>
<TOKEN id="token-2-36" pos="punct" morph="none" start_char="315" end_char="315">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="318" end_char="593">
<ORIGINAL_TEXT>Driven by a malicious intention of scapegoating China to cover up the lax US response to Covid-19, US Secretary of State Mike Pompeo has been repeatedly calling the novel coronavirus "Chinese virus" or "Wuhan virus" in public, largely accountable for the virus disinformation.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="318" end_char="323">Driven</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="325" end_char="326">by</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="328" end_char="328">a</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="330" end_char="338">malicious</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="340" end_char="348">intention</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="350" end_char="351">of</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="353" end_char="364">scapegoating</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="366" end_char="370">China</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="372" end_char="373">to</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="375" end_char="379">cover</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="381" end_char="382">up</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="384" end_char="386">the</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="388" end_char="390">lax</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="392" end_char="393">US</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="395" end_char="402">response</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="404" end_char="405">to</TOKEN>
<TOKEN id="token-3-16" pos="unknown" morph="none" start_char="407" end_char="414">Covid-19</TOKEN>
<TOKEN id="token-3-17" pos="punct" morph="none" start_char="415" end_char="415">,</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="417" end_char="418">US</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="420" end_char="428">Secretary</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="430" end_char="431">of</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="433" end_char="437">State</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="439" end_char="442">Mike</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="444" end_char="449">Pompeo</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="451" end_char="453">has</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="455" end_char="458">been</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="460" end_char="469">repeatedly</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="471" end_char="477">calling</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="479" end_char="481">the</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="483" end_char="487">novel</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="489" end_char="499">coronavirus</TOKEN>
<TOKEN id="token-3-31" pos="punct" morph="none" start_char="501" end_char="501">"</TOKEN>
<TOKEN id="token-3-32" pos="word" morph="none" start_char="502" end_char="508">Chinese</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="510" end_char="514">virus</TOKEN>
<TOKEN id="token-3-34" pos="punct" morph="none" start_char="515" end_char="515">"</TOKEN>
<TOKEN id="token-3-35" pos="word" morph="none" start_char="517" end_char="518">or</TOKEN>
<TOKEN id="token-3-36" pos="punct" morph="none" start_char="520" end_char="520">"</TOKEN>
<TOKEN id="token-3-37" pos="word" morph="none" start_char="521" end_char="525">Wuhan</TOKEN>
<TOKEN id="token-3-38" pos="word" morph="none" start_char="527" end_char="531">virus</TOKEN>
<TOKEN id="token-3-39" pos="punct" morph="none" start_char="532" end_char="532">"</TOKEN>
<TOKEN id="token-3-40" pos="word" morph="none" start_char="534" end_char="535">in</TOKEN>
<TOKEN id="token-3-41" pos="word" morph="none" start_char="537" end_char="542">public</TOKEN>
<TOKEN id="token-3-42" pos="punct" morph="none" start_char="543" end_char="543">,</TOKEN>
<TOKEN id="token-3-43" pos="word" morph="none" start_char="545" end_char="551">largely</TOKEN>
<TOKEN id="token-3-44" pos="word" morph="none" start_char="553" end_char="563">accountable</TOKEN>
<TOKEN id="token-3-45" pos="word" morph="none" start_char="565" end_char="567">for</TOKEN>
<TOKEN id="token-3-46" pos="word" morph="none" start_char="569" end_char="571">the</TOKEN>
<TOKEN id="token-3-47" pos="word" morph="none" start_char="573" end_char="577">virus</TOKEN>
<TOKEN id="token-3-48" pos="word" morph="none" start_char="579" end_char="592">disinformation</TOKEN>
<TOKEN id="token-3-49" pos="punct" morph="none" start_char="593" end_char="593">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="596" end_char="719">
<ORIGINAL_TEXT>"What we do know is we know that this virus originated in Wuhan, China," said Pompeo in a comment requested by the Fox News.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="punct" morph="none" start_char="596" end_char="596">"</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="597" end_char="600">What</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="602" end_char="603">we</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="605" end_char="606">do</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="608" end_char="611">know</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="613" end_char="614">is</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="616" end_char="617">we</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="619" end_char="622">know</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="624" end_char="627">that</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="629" end_char="632">this</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="634" end_char="638">virus</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="640" end_char="649">originated</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="651" end_char="652">in</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="654" end_char="658">Wuhan</TOKEN>
<TOKEN id="token-4-14" pos="punct" morph="none" start_char="659" end_char="659">,</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="661" end_char="665">China</TOKEN>
<TOKEN id="token-4-16" pos="punct" morph="none" start_char="666" end_char="667">,"</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="669" end_char="672">said</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="674" end_char="679">Pompeo</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="681" end_char="682">in</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="684" end_char="684">a</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="686" end_char="692">comment</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="694" end_char="702">requested</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="704" end_char="705">by</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="707" end_char="709">the</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="711" end_char="713">Fox</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="715" end_char="718">News</TOKEN>
<TOKEN id="token-4-27" pos="punct" morph="none" start_char="719" end_char="719">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="721" end_char="779">
<ORIGINAL_TEXT>"The US government is working diligently to figure it out."</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="punct" morph="none" start_char="721" end_char="721">"</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="722" end_char="724">The</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="726" end_char="727">US</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="729" end_char="738">government</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="740" end_char="741">is</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="743" end_char="749">working</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="751" end_char="760">diligently</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="762" end_char="763">to</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="765" end_char="770">figure</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="772" end_char="773">it</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="775" end_char="777">out</TOKEN>
<TOKEN id="token-5-11" pos="punct" morph="none" start_char="778" end_char="779">."</TOKEN>
</SEG>
<SEG id="segment-6" start_char="782" end_char="924">
<ORIGINAL_TEXT>Luc Montagnier, a French Nobel prize winning virologist in 2008, told French media last week that "there was manipulation around this virus ...</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="782" end_char="784">Luc</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="786" end_char="795">Montagnier</TOKEN>
<TOKEN id="token-6-2" pos="punct" morph="none" start_char="796" end_char="796">,</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="798" end_char="798">a</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="800" end_char="805">French</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="807" end_char="811">Nobel</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="813" end_char="817">prize</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="819" end_char="825">winning</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="827" end_char="836">virologist</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="838" end_char="839">in</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="841" end_char="844">2008</TOKEN>
<TOKEN id="token-6-11" pos="punct" morph="none" start_char="845" end_char="845">,</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="847" end_char="850">told</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="852" end_char="857">French</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="859" end_char="863">media</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="865" end_char="868">last</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="870" end_char="873">week</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="875" end_char="878">that</TOKEN>
<TOKEN id="token-6-18" pos="punct" morph="none" start_char="880" end_char="880">"</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="881" end_char="885">there</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="887" end_char="889">was</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="891" end_char="902">manipulation</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="904" end_char="909">around</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="911" end_char="914">this</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="916" end_char="920">virus</TOKEN>
<TOKEN id="token-6-25" pos="punct" morph="none" start_char="922" end_char="924">...</TOKEN>
</SEG>
<SEG id="segment-7" start_char="926" end_char="943">
<ORIGINAL_TEXT>It is not natural.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="926" end_char="927">It</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="929" end_char="930">is</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="932" end_char="934">not</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="936" end_char="942">natural</TOKEN>
<TOKEN id="token-7-4" pos="punct" morph="none" start_char="943" end_char="943">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="945" end_char="1001">
<ORIGINAL_TEXT>It's the work of professionals, of molecular biologists."</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="945" end_char="948">It's</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="950" end_char="952">the</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="954" end_char="957">work</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="959" end_char="960">of</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="962" end_char="974">professionals</TOKEN>
<TOKEN id="token-8-5" pos="punct" morph="none" start_char="975" end_char="975">,</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="977" end_char="978">of</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="980" end_char="988">molecular</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="990" end_char="999">biologists</TOKEN>
<TOKEN id="token-8-9" pos="punct" morph="none" start_char="1000" end_char="1001">."</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1004" end_char="1090">
<ORIGINAL_TEXT>In response, several French scientists have recently refuted the remarks by Montagnier.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1004" end_char="1005">In</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1007" end_char="1014">response</TOKEN>
<TOKEN id="token-9-2" pos="punct" morph="none" start_char="1015" end_char="1015">,</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1017" end_char="1023">several</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1025" end_char="1030">French</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1032" end_char="1041">scientists</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1043" end_char="1046">have</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1048" end_char="1055">recently</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1057" end_char="1063">refuted</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1065" end_char="1067">the</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1069" end_char="1075">remarks</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1077" end_char="1078">by</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1080" end_char="1089">Montagnier</TOKEN>
<TOKEN id="token-9-13" pos="punct" morph="none" start_char="1090" end_char="1090">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1093" end_char="1410">
<ORIGINAL_TEXT>The hypothesis that a virus was created in a lab in Wuhan sounded "a conspiracy vision that does not relate to the real science," said Jean-Francois Delfraissy, an immunologist and head of the scientific council that advises the French government on the Covid-19 pandemic, when interviewed by French television BFM TV.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1093" end_char="1095">The</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1097" end_char="1106">hypothesis</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1108" end_char="1111">that</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1113" end_char="1113">a</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1115" end_char="1119">virus</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1121" end_char="1123">was</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1125" end_char="1131">created</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1133" end_char="1134">in</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1136" end_char="1136">a</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1138" end_char="1140">lab</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1142" end_char="1143">in</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1145" end_char="1149">Wuhan</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1151" end_char="1157">sounded</TOKEN>
<TOKEN id="token-10-13" pos="punct" morph="none" start_char="1159" end_char="1159">"</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1160" end_char="1160">a</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1162" end_char="1171">conspiracy</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1173" end_char="1178">vision</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1180" end_char="1183">that</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1185" end_char="1188">does</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1190" end_char="1192">not</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1194" end_char="1199">relate</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1201" end_char="1202">to</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1204" end_char="1206">the</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1208" end_char="1211">real</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1213" end_char="1219">science</TOKEN>
<TOKEN id="token-10-25" pos="punct" morph="none" start_char="1220" end_char="1221">,"</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="1223" end_char="1226">said</TOKEN>
<TOKEN id="token-10-27" pos="unknown" morph="none" start_char="1228" end_char="1240">Jean-Francois</TOKEN>
<TOKEN id="token-10-28" pos="word" morph="none" start_char="1242" end_char="1251">Delfraissy</TOKEN>
<TOKEN id="token-10-29" pos="punct" morph="none" start_char="1252" end_char="1252">,</TOKEN>
<TOKEN id="token-10-30" pos="word" morph="none" start_char="1254" end_char="1255">an</TOKEN>
<TOKEN id="token-10-31" pos="word" morph="none" start_char="1257" end_char="1268">immunologist</TOKEN>
<TOKEN id="token-10-32" pos="word" morph="none" start_char="1270" end_char="1272">and</TOKEN>
<TOKEN id="token-10-33" pos="word" morph="none" start_char="1274" end_char="1277">head</TOKEN>
<TOKEN id="token-10-34" pos="word" morph="none" start_char="1279" end_char="1280">of</TOKEN>
<TOKEN id="token-10-35" pos="word" morph="none" start_char="1282" end_char="1284">the</TOKEN>
<TOKEN id="token-10-36" pos="word" morph="none" start_char="1286" end_char="1295">scientific</TOKEN>
<TOKEN id="token-10-37" pos="word" morph="none" start_char="1297" end_char="1303">council</TOKEN>
<TOKEN id="token-10-38" pos="word" morph="none" start_char="1305" end_char="1308">that</TOKEN>
<TOKEN id="token-10-39" pos="word" morph="none" start_char="1310" end_char="1316">advises</TOKEN>
<TOKEN id="token-10-40" pos="word" morph="none" start_char="1318" end_char="1320">the</TOKEN>
<TOKEN id="token-10-41" pos="word" morph="none" start_char="1322" end_char="1327">French</TOKEN>
<TOKEN id="token-10-42" pos="word" morph="none" start_char="1329" end_char="1338">government</TOKEN>
<TOKEN id="token-10-43" pos="word" morph="none" start_char="1340" end_char="1341">on</TOKEN>
<TOKEN id="token-10-44" pos="word" morph="none" start_char="1343" end_char="1345">the</TOKEN>
<TOKEN id="token-10-45" pos="unknown" morph="none" start_char="1347" end_char="1354">Covid-19</TOKEN>
<TOKEN id="token-10-46" pos="word" morph="none" start_char="1356" end_char="1363">pandemic</TOKEN>
<TOKEN id="token-10-47" pos="punct" morph="none" start_char="1364" end_char="1364">,</TOKEN>
<TOKEN id="token-10-48" pos="word" morph="none" start_char="1366" end_char="1369">when</TOKEN>
<TOKEN id="token-10-49" pos="word" morph="none" start_char="1371" end_char="1381">interviewed</TOKEN>
<TOKEN id="token-10-50" pos="word" morph="none" start_char="1383" end_char="1384">by</TOKEN>
<TOKEN id="token-10-51" pos="word" morph="none" start_char="1386" end_char="1391">French</TOKEN>
<TOKEN id="token-10-52" pos="word" morph="none" start_char="1393" end_char="1402">television</TOKEN>
<TOKEN id="token-10-53" pos="word" morph="none" start_char="1404" end_char="1406">BFM</TOKEN>
<TOKEN id="token-10-54" pos="word" morph="none" start_char="1408" end_char="1409">TV</TOKEN>
<TOKEN id="token-10-55" pos="punct" morph="none" start_char="1410" end_char="1410">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1413" end_char="1488">
<ORIGINAL_TEXT>"Everyone in the scientific community agrees that Covid-19 is a coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="punct" morph="none" start_char="1413" end_char="1413">"</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1414" end_char="1421">Everyone</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1423" end_char="1424">in</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1426" end_char="1428">the</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1430" end_char="1439">scientific</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1441" end_char="1449">community</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1451" end_char="1456">agrees</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1458" end_char="1461">that</TOKEN>
<TOKEN id="token-11-8" pos="unknown" morph="none" start_char="1463" end_char="1470">Covid-19</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1472" end_char="1473">is</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1475" end_char="1475">a</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1477" end_char="1487">coronavirus</TOKEN>
<TOKEN id="token-11-12" pos="punct" morph="none" start_char="1488" end_char="1488">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1490" end_char="1630">
<ORIGINAL_TEXT>From time to time there are coronaviruses different from the others, as are SARS and MERS with a pathogenicity which has appeared," he added.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1490" end_char="1493">From</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1495" end_char="1498">time</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1500" end_char="1501">to</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1503" end_char="1506">time</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1508" end_char="1512">there</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1514" end_char="1516">are</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1518" end_char="1530">coronaviruses</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1532" end_char="1540">different</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1542" end_char="1545">from</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1547" end_char="1549">the</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1551" end_char="1556">others</TOKEN>
<TOKEN id="token-12-11" pos="punct" morph="none" start_char="1557" end_char="1557">,</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1559" end_char="1560">as</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1562" end_char="1564">are</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1566" end_char="1569">SARS</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1571" end_char="1573">and</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1575" end_char="1578">MERS</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1580" end_char="1583">with</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1585" end_char="1585">a</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1587" end_char="1599">pathogenicity</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1601" end_char="1605">which</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1607" end_char="1609">has</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1611" end_char="1618">appeared</TOKEN>
<TOKEN id="token-12-23" pos="punct" morph="none" start_char="1619" end_char="1620">,"</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="1622" end_char="1623">he</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="1625" end_char="1629">added</TOKEN>
<TOKEN id="token-12-26" pos="punct" morph="none" start_char="1630" end_char="1630">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1633" end_char="1802">
<ORIGINAL_TEXT>Both Severe Acute Respiratory Syndrome (SARS) and Middle East Respiratory Syndrome (MERS) are caused by coronaviruses, and the Covid-19 virus is also known as SARS-CoV-2.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1633" end_char="1636">Both</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1638" end_char="1643">Severe</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1645" end_char="1649">Acute</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1651" end_char="1661">Respiratory</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1663" end_char="1670">Syndrome</TOKEN>
<TOKEN id="token-13-5" pos="punct" morph="none" start_char="1672" end_char="1672">(</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1673" end_char="1676">SARS</TOKEN>
<TOKEN id="token-13-7" pos="punct" morph="none" start_char="1677" end_char="1677">)</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1679" end_char="1681">and</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1683" end_char="1688">Middle</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1690" end_char="1693">East</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1695" end_char="1705">Respiratory</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1707" end_char="1714">Syndrome</TOKEN>
<TOKEN id="token-13-13" pos="punct" morph="none" start_char="1716" end_char="1716">(</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1717" end_char="1720">MERS</TOKEN>
<TOKEN id="token-13-15" pos="punct" morph="none" start_char="1721" end_char="1721">)</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1723" end_char="1725">are</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1727" end_char="1732">caused</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1734" end_char="1735">by</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1737" end_char="1749">coronaviruses</TOKEN>
<TOKEN id="token-13-20" pos="punct" morph="none" start_char="1750" end_char="1750">,</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="1752" end_char="1754">and</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="1756" end_char="1758">the</TOKEN>
<TOKEN id="token-13-23" pos="unknown" morph="none" start_char="1760" end_char="1767">Covid-19</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="1769" end_char="1773">virus</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="1775" end_char="1776">is</TOKEN>
<TOKEN id="token-13-26" pos="word" morph="none" start_char="1778" end_char="1781">also</TOKEN>
<TOKEN id="token-13-27" pos="word" morph="none" start_char="1783" end_char="1787">known</TOKEN>
<TOKEN id="token-13-28" pos="word" morph="none" start_char="1789" end_char="1790">as</TOKEN>
<TOKEN id="token-13-29" pos="unknown" morph="none" start_char="1792" end_char="1801">SARS-CoV-2</TOKEN>
<TOKEN id="token-13-30" pos="punct" morph="none" start_char="1802" end_char="1802">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1805" end_char="1879">
<ORIGINAL_TEXT>"The world of viruses is a world in perpetual evolution," Delfraissy noted.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="punct" morph="none" start_char="1805" end_char="1805">"</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1806" end_char="1808">The</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1810" end_char="1814">world</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1816" end_char="1817">of</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1819" end_char="1825">viruses</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1827" end_char="1828">is</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1830" end_char="1830">a</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1832" end_char="1836">world</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1838" end_char="1839">in</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1841" end_char="1849">perpetual</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1851" end_char="1859">evolution</TOKEN>
<TOKEN id="token-14-11" pos="punct" morph="none" start_char="1860" end_char="1861">,"</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1863" end_char="1872">Delfraissy</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1874" end_char="1878">noted</TOKEN>
<TOKEN id="token-14-14" pos="punct" morph="none" start_char="1879" end_char="1879">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1882" end_char="2074">
<ORIGINAL_TEXT>According to Olivier Schwartz, head of the virus and immunity department of France's Pasteur Institute, studies have shown clearly that the novel coronavirus was not man-made in the laboratory.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1882" end_char="1890">According</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1892" end_char="1893">to</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1895" end_char="1901">Olivier</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1903" end_char="1910">Schwartz</TOKEN>
<TOKEN id="token-15-4" pos="punct" morph="none" start_char="1911" end_char="1911">,</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1913" end_char="1916">head</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1918" end_char="1919">of</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1921" end_char="1923">the</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1925" end_char="1929">virus</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1931" end_char="1933">and</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1935" end_char="1942">immunity</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1944" end_char="1953">department</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1955" end_char="1956">of</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1958" end_char="1965">France's</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1967" end_char="1973">Pasteur</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="1975" end_char="1983">Institute</TOKEN>
<TOKEN id="token-15-16" pos="punct" morph="none" start_char="1984" end_char="1984">,</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="1986" end_char="1992">studies</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="1994" end_char="1997">have</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="1999" end_char="2003">shown</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="2005" end_char="2011">clearly</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="2013" end_char="2016">that</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="2018" end_char="2020">the</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="2022" end_char="2026">novel</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="2028" end_char="2038">coronavirus</TOKEN>
<TOKEN id="token-15-25" pos="word" morph="none" start_char="2040" end_char="2042">was</TOKEN>
<TOKEN id="token-15-26" pos="word" morph="none" start_char="2044" end_char="2046">not</TOKEN>
<TOKEN id="token-15-27" pos="unknown" morph="none" start_char="2048" end_char="2055">man-made</TOKEN>
<TOKEN id="token-15-28" pos="word" morph="none" start_char="2057" end_char="2058">in</TOKEN>
<TOKEN id="token-15-29" pos="word" morph="none" start_char="2060" end_char="2062">the</TOKEN>
<TOKEN id="token-15-30" pos="word" morph="none" start_char="2064" end_char="2073">laboratory</TOKEN>
<TOKEN id="token-15-31" pos="punct" morph="none" start_char="2074" end_char="2074">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="2077" end_char="2202">
<ORIGINAL_TEXT>"Professor Montagnier spreads whimsical theories," he told the French weekly L'Obs, previously known as Le Nouvel Observateur.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="punct" morph="none" start_char="2077" end_char="2077">"</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="2078" end_char="2086">Professor</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="2088" end_char="2097">Montagnier</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="2099" end_char="2105">spreads</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="2107" end_char="2115">whimsical</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="2117" end_char="2124">theories</TOKEN>
<TOKEN id="token-16-6" pos="punct" morph="none" start_char="2125" end_char="2126">,"</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="2128" end_char="2129">he</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="2131" end_char="2134">told</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="2136" end_char="2138">the</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="2140" end_char="2145">French</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="2147" end_char="2152">weekly</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="2154" end_char="2158">L'Obs</TOKEN>
<TOKEN id="token-16-13" pos="punct" morph="none" start_char="2159" end_char="2159">,</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="2161" end_char="2170">previously</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="2172" end_char="2176">known</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="2178" end_char="2179">as</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="2181" end_char="2182">Le</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="2184" end_char="2189">Nouvel</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="2191" end_char="2201">Observateur</TOKEN>
<TOKEN id="token-16-20" pos="punct" morph="none" start_char="2202" end_char="2202">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2205" end_char="2295">
<ORIGINAL_TEXT>"Sars-CoV-2, the virus that causes the Covid-19 disease, was not created in the laboratory.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="punct" morph="none" start_char="2205" end_char="2205">"</TOKEN>
<TOKEN id="token-17-1" pos="unknown" morph="none" start_char="2206" end_char="2215">Sars-CoV-2</TOKEN>
<TOKEN id="token-17-2" pos="punct" morph="none" start_char="2216" end_char="2216">,</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2218" end_char="2220">the</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2222" end_char="2226">virus</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2228" end_char="2231">that</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2233" end_char="2238">causes</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2240" end_char="2242">the</TOKEN>
<TOKEN id="token-17-8" pos="unknown" morph="none" start_char="2244" end_char="2251">Covid-19</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2253" end_char="2259">disease</TOKEN>
<TOKEN id="token-17-10" pos="punct" morph="none" start_char="2260" end_char="2260">,</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2262" end_char="2264">was</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2266" end_char="2268">not</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2270" end_char="2276">created</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2278" end_char="2279">in</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2281" end_char="2283">the</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="2285" end_char="2294">laboratory</TOKEN>
<TOKEN id="token-17-17" pos="punct" morph="none" start_char="2295" end_char="2295">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2297" end_char="2491">
<ORIGINAL_TEXT>We see this by studying the genetic heritage of the virus, which has been sequenced by Chinese teams and then verified in many other laboratories, including the Pasteur Institute," said Schwartz.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2297" end_char="2298">We</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2300" end_char="2302">see</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2304" end_char="2307">this</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2309" end_char="2310">by</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2312" end_char="2319">studying</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2321" end_char="2323">the</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2325" end_char="2331">genetic</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2333" end_char="2340">heritage</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2342" end_char="2343">of</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="2345" end_char="2347">the</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="2349" end_char="2353">virus</TOKEN>
<TOKEN id="token-18-11" pos="punct" morph="none" start_char="2354" end_char="2354">,</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2356" end_char="2360">which</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="2362" end_char="2364">has</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="2366" end_char="2369">been</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="2371" end_char="2379">sequenced</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="2381" end_char="2382">by</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="2384" end_char="2390">Chinese</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="2392" end_char="2396">teams</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="2398" end_char="2400">and</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="2402" end_char="2405">then</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="2407" end_char="2414">verified</TOKEN>
<TOKEN id="token-18-22" pos="word" morph="none" start_char="2416" end_char="2417">in</TOKEN>
<TOKEN id="token-18-23" pos="word" morph="none" start_char="2419" end_char="2422">many</TOKEN>
<TOKEN id="token-18-24" pos="word" morph="none" start_char="2424" end_char="2428">other</TOKEN>
<TOKEN id="token-18-25" pos="word" morph="none" start_char="2430" end_char="2441">laboratories</TOKEN>
<TOKEN id="token-18-26" pos="punct" morph="none" start_char="2442" end_char="2442">,</TOKEN>
<TOKEN id="token-18-27" pos="word" morph="none" start_char="2444" end_char="2452">including</TOKEN>
<TOKEN id="token-18-28" pos="word" morph="none" start_char="2454" end_char="2456">the</TOKEN>
<TOKEN id="token-18-29" pos="word" morph="none" start_char="2458" end_char="2464">Pasteur</TOKEN>
<TOKEN id="token-18-30" pos="word" morph="none" start_char="2466" end_char="2474">Institute</TOKEN>
<TOKEN id="token-18-31" pos="punct" morph="none" start_char="2475" end_char="2476">,"</TOKEN>
<TOKEN id="token-18-32" pos="word" morph="none" start_char="2478" end_char="2481">said</TOKEN>
<TOKEN id="token-18-33" pos="word" morph="none" start_char="2483" end_char="2490">Schwartz</TOKEN>
<TOKEN id="token-18-34" pos="punct" morph="none" start_char="2491" end_char="2491">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2494" end_char="2552">
<ORIGINAL_TEXT>"This virus is clearly part of the coronavirus family tree.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="punct" morph="none" start_char="2494" end_char="2494">"</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2495" end_char="2498">This</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2500" end_char="2504">virus</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2506" end_char="2507">is</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2509" end_char="2515">clearly</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2517" end_char="2520">part</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2522" end_char="2523">of</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2525" end_char="2527">the</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2529" end_char="2539">coronavirus</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="2541" end_char="2546">family</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="2548" end_char="2551">tree</TOKEN>
<TOKEN id="token-19-11" pos="punct" morph="none" start_char="2552" end_char="2552">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2554" end_char="2626">
<ORIGINAL_TEXT>It is close to Sars-CoV-1, with which it has 80% homology," he explained.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2554" end_char="2555">It</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2557" end_char="2558">is</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2560" end_char="2564">close</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2566" end_char="2567">to</TOKEN>
<TOKEN id="token-20-4" pos="unknown" morph="none" start_char="2569" end_char="2578">Sars-CoV-1</TOKEN>
<TOKEN id="token-20-5" pos="punct" morph="none" start_char="2579" end_char="2579">,</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2581" end_char="2584">with</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2586" end_char="2590">which</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="2592" end_char="2593">it</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2595" end_char="2597">has</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2599" end_char="2600">80</TOKEN>
<TOKEN id="token-20-11" pos="punct" morph="none" start_char="2601" end_char="2601">%</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="2603" end_char="2610">homology</TOKEN>
<TOKEN id="token-20-13" pos="punct" morph="none" start_char="2611" end_char="2612">,"</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="2614" end_char="2615">he</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="2617" end_char="2625">explained</TOKEN>
<TOKEN id="token-20-16" pos="punct" morph="none" start_char="2626" end_char="2626">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2629" end_char="2725">
<ORIGINAL_TEXT>"Above all, the same virus is found in different animals, in particular the pangolin and the bat.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="punct" morph="none" start_char="2629" end_char="2629">"</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2630" end_char="2634">Above</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2636" end_char="2638">all</TOKEN>
<TOKEN id="token-21-3" pos="punct" morph="none" start_char="2639" end_char="2639">,</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2641" end_char="2643">the</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="2645" end_char="2648">same</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2650" end_char="2654">virus</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="2656" end_char="2657">is</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="2659" end_char="2663">found</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="2665" end_char="2666">in</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="2668" end_char="2676">different</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="2678" end_char="2684">animals</TOKEN>
<TOKEN id="token-21-12" pos="punct" morph="none" start_char="2685" end_char="2685">,</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="2687" end_char="2688">in</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="2690" end_char="2699">particular</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="2701" end_char="2703">the</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="2705" end_char="2712">pangolin</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="2714" end_char="2716">and</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="2718" end_char="2720">the</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="2722" end_char="2724">bat</TOKEN>
<TOKEN id="token-21-20" pos="punct" morph="none" start_char="2725" end_char="2725">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2728" end_char="2790">
<ORIGINAL_TEXT>"And there, the percentage of similarities is greater than 95%.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="punct" morph="none" start_char="2728" end_char="2728">"</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2729" end_char="2731">And</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2733" end_char="2737">there</TOKEN>
<TOKEN id="token-22-3" pos="punct" morph="none" start_char="2738" end_char="2738">,</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2740" end_char="2742">the</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2744" end_char="2753">percentage</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2755" end_char="2756">of</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2758" end_char="2769">similarities</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="2771" end_char="2772">is</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="2774" end_char="2780">greater</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="2782" end_char="2785">than</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="2787" end_char="2788">95</TOKEN>
<TOKEN id="token-22-12" pos="punct" morph="none" start_char="2789" end_char="2790">%.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2792" end_char="2915">
<ORIGINAL_TEXT>So, by drawing up the family tree of this virus, we know that it is derived from viruses that circulate in nature," he said.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2792" end_char="2793">So</TOKEN>
<TOKEN id="token-23-1" pos="punct" morph="none" start_char="2794" end_char="2794">,</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2796" end_char="2797">by</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2799" end_char="2805">drawing</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="2807" end_char="2808">up</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="2810" end_char="2812">the</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="2814" end_char="2819">family</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="2821" end_char="2824">tree</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="2826" end_char="2827">of</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="2829" end_char="2832">this</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="2834" end_char="2838">virus</TOKEN>
<TOKEN id="token-23-11" pos="punct" morph="none" start_char="2839" end_char="2839">,</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="2841" end_char="2842">we</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="2844" end_char="2847">know</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="2849" end_char="2852">that</TOKEN>
<TOKEN id="token-23-15" pos="word" morph="none" start_char="2854" end_char="2855">it</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="2857" end_char="2858">is</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="2860" end_char="2866">derived</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="2868" end_char="2871">from</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="2873" end_char="2879">viruses</TOKEN>
<TOKEN id="token-23-20" pos="word" morph="none" start_char="2881" end_char="2884">that</TOKEN>
<TOKEN id="token-23-21" pos="word" morph="none" start_char="2886" end_char="2894">circulate</TOKEN>
<TOKEN id="token-23-22" pos="word" morph="none" start_char="2896" end_char="2897">in</TOKEN>
<TOKEN id="token-23-23" pos="word" morph="none" start_char="2899" end_char="2904">nature</TOKEN>
<TOKEN id="token-23-24" pos="punct" morph="none" start_char="2905" end_char="2906">,"</TOKEN>
<TOKEN id="token-23-25" pos="word" morph="none" start_char="2908" end_char="2909">he</TOKEN>
<TOKEN id="token-23-26" pos="word" morph="none" start_char="2911" end_char="2914">said</TOKEN>
<TOKEN id="token-23-27" pos="punct" morph="none" start_char="2915" end_char="2915">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2917" end_char="2943">
<ORIGINAL_TEXT>- Xinhua/Asian News Network</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="punct" morph="none" start_char="2917" end_char="2917">-</TOKEN>
<TOKEN id="token-24-1" pos="unknown" morph="none" start_char="2919" end_char="2930">Xinhua/Asian</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="2932" end_char="2935">News</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="2937" end_char="2943">Network</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
