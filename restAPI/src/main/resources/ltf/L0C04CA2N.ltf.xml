<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CA2N" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="8565" raw_text_md5="ee5a987222de2cf21f567d9fb5ecb69f">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="61">
<ORIGINAL_TEXT>Social Media Posts Spread Bogus Coronavirus Conspiracy Theory</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="6">Social</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="8" end_char="12">Media</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="14" end_char="18">Posts</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="20" end_char="25">Spread</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="27" end_char="31">Bogus</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="33" end_char="43">Coronavirus</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="45" end_char="54">Conspiracy</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="56" end_char="61">Theory</TOKEN>
</SEG>
<SEG id="segment-1" start_char="65" end_char="74">
<ORIGINAL_TEXT>Quick Take</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="65" end_char="69">Quick</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="71" end_char="74">Take</TOKEN>
</SEG>
<SEG id="segment-2" start_char="78" end_char="174">
<ORIGINAL_TEXT>Multiple social media posts are spreading a bogus conspiracy theory about the deadly Wuhan virus.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="78" end_char="85">Multiple</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="87" end_char="92">social</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="94" end_char="98">media</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="100" end_char="104">posts</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="106" end_char="108">are</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="110" end_char="118">spreading</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="120" end_char="120">a</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="122" end_char="126">bogus</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="128" end_char="137">conspiracy</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="139" end_char="144">theory</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="146" end_char="150">about</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="152" end_char="154">the</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="156" end_char="161">deadly</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="163" end_char="167">Wuhan</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="169" end_char="173">virus</TOKEN>
<TOKEN id="token-2-15" pos="punct" morph="none" start_char="174" end_char="174">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="176" end_char="267">
<ORIGINAL_TEXT>The posts falsely claim that the virus has been patented and a vaccine is already available.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="176" end_char="178">The</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="180" end_char="184">posts</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="186" end_char="192">falsely</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="194" end_char="198">claim</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="200" end_char="203">that</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="205" end_char="207">the</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="209" end_char="213">virus</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="215" end_char="217">has</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="219" end_char="222">been</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="224" end_char="231">patented</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="233" end_char="235">and</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="237" end_char="237">a</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="239" end_char="245">vaccine</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="247" end_char="248">is</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="250" end_char="256">already</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="258" end_char="266">available</TOKEN>
<TOKEN id="token-3-16" pos="punct" morph="none" start_char="267" end_char="267">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="269" end_char="345">
<ORIGINAL_TEXT>That’s not true; the patents the posts refer to pertain to different viruses.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="269" end_char="274">That’s</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="276" end_char="278">not</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="280" end_char="283">true</TOKEN>
<TOKEN id="token-4-3" pos="punct" morph="none" start_char="284" end_char="284">;</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="286" end_char="288">the</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="290" end_char="296">patents</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="298" end_char="300">the</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="302" end_char="306">posts</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="308" end_char="312">refer</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="314" end_char="315">to</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="317" end_char="323">pertain</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="325" end_char="326">to</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="328" end_char="336">different</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="338" end_char="344">viruses</TOKEN>
<TOKEN id="token-4-14" pos="punct" morph="none" start_char="345" end_char="345">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="348" end_char="357">
<ORIGINAL_TEXT>Full Story</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="348" end_char="351">Full</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="353" end_char="357">Story</TOKEN>
</SEG>
<SEG id="segment-6" start_char="361" end_char="525">
<ORIGINAL_TEXT>Following the outbreak of a respiratory disease caused by a new coronavirus in Wuhan, China in December 2019, and the announcement of the first American case on Jan.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="361" end_char="369">Following</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="371" end_char="373">the</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="375" end_char="382">outbreak</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="384" end_char="385">of</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="387" end_char="387">a</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="389" end_char="399">respiratory</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="401" end_char="407">disease</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="409" end_char="414">caused</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="416" end_char="417">by</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="419" end_char="419">a</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="421" end_char="423">new</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="425" end_char="435">coronavirus</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="437" end_char="438">in</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="440" end_char="444">Wuhan</TOKEN>
<TOKEN id="token-6-14" pos="punct" morph="none" start_char="445" end_char="445">,</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="447" end_char="451">China</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="453" end_char="454">in</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="456" end_char="463">December</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="465" end_char="468">2019</TOKEN>
<TOKEN id="token-6-19" pos="punct" morph="none" start_char="469" end_char="469">,</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="471" end_char="473">and</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="475" end_char="477">the</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="479" end_char="490">announcement</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="492" end_char="493">of</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="495" end_char="497">the</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="499" end_char="503">first</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="505" end_char="512">American</TOKEN>
<TOKEN id="token-6-27" pos="word" morph="none" start_char="514" end_char="517">case</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="519" end_char="520">on</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="522" end_char="524">Jan</TOKEN>
<TOKEN id="token-6-30" pos="punct" morph="none" start_char="525" end_char="525">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="527" end_char="629">
<ORIGINAL_TEXT>21, several groups and individuals are circulating false rumors on Facebook about the mystery pathogen.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="527" end_char="528">21</TOKEN>
<TOKEN id="token-7-1" pos="punct" morph="none" start_char="529" end_char="529">,</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="531" end_char="537">several</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="539" end_char="544">groups</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="546" end_char="548">and</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="550" end_char="560">individuals</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="562" end_char="564">are</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="566" end_char="576">circulating</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="578" end_char="582">false</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="584" end_char="589">rumors</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="591" end_char="592">on</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="594" end_char="601">Facebook</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="603" end_char="607">about</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="609" end_char="611">the</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="613" end_char="619">mystery</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="621" end_char="628">pathogen</TOKEN>
<TOKEN id="token-7-16" pos="punct" morph="none" start_char="629" end_char="629">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="632" end_char="780">
<ORIGINAL_TEXT>Numerous posts claim the virus has been patented — and some even suggest, incorrectly, that the virus was made in a lab and a vaccine already exists.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="632" end_char="639">Numerous</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="641" end_char="645">posts</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="647" end_char="651">claim</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="653" end_char="655">the</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="657" end_char="661">virus</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="663" end_char="665">has</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="667" end_char="670">been</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="672" end_char="679">patented</TOKEN>
<TOKEN id="token-8-8" pos="punct" morph="none" start_char="681" end_char="681">—</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="683" end_char="685">and</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="687" end_char="690">some</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="692" end_char="695">even</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="697" end_char="703">suggest</TOKEN>
<TOKEN id="token-8-13" pos="punct" morph="none" start_char="704" end_char="704">,</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="706" end_char="716">incorrectly</TOKEN>
<TOKEN id="token-8-15" pos="punct" morph="none" start_char="717" end_char="717">,</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="719" end_char="722">that</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="724" end_char="726">the</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="728" end_char="732">virus</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="734" end_char="736">was</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="738" end_char="741">made</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="743" end_char="744">in</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="746" end_char="746">a</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="748" end_char="750">lab</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="752" end_char="754">and</TOKEN>
<TOKEN id="token-8-25" pos="word" morph="none" start_char="756" end_char="756">a</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="758" end_char="764">vaccine</TOKEN>
<TOKEN id="token-8-27" pos="word" morph="none" start_char="766" end_char="772">already</TOKEN>
<TOKEN id="token-8-28" pos="word" morph="none" start_char="774" end_char="779">exists</TOKEN>
<TOKEN id="token-8-29" pos="punct" morph="none" start_char="780" end_char="780">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="783" end_char="897">
<ORIGINAL_TEXT>"The new fad disease called the ‘coronavirus’ is sweeping headlines," one Facebook post, taken from Twitter, reads.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="punct" morph="none" start_char="783" end_char="783">"</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="784" end_char="786">The</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="788" end_char="790">new</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="792" end_char="794">fad</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="796" end_char="802">disease</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="804" end_char="809">called</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="811" end_char="813">the</TOKEN>
<TOKEN id="token-9-7" pos="punct" morph="none" start_char="815" end_char="815">‘</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="816" end_char="826">coronavirus</TOKEN>
<TOKEN id="token-9-9" pos="punct" morph="none" start_char="827" end_char="827">’</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="829" end_char="830">is</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="832" end_char="839">sweeping</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="841" end_char="849">headlines</TOKEN>
<TOKEN id="token-9-13" pos="punct" morph="none" start_char="850" end_char="851">,"</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="853" end_char="855">one</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="857" end_char="864">Facebook</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="866" end_char="869">post</TOKEN>
<TOKEN id="token-9-17" pos="punct" morph="none" start_char="870" end_char="870">,</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="872" end_char="876">taken</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="878" end_char="881">from</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="883" end_char="889">Twitter</TOKEN>
<TOKEN id="token-9-21" pos="punct" morph="none" start_char="890" end_char="890">,</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="892" end_char="896">reads</TOKEN>
<TOKEN id="token-9-23" pos="punct" morph="none" start_char="897" end_char="897">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="899" end_char="991">
<ORIGINAL_TEXT>"Funny enough, there was a patent for the coronavirus was filed in 2015 and granted in 2018."</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="punct" morph="none" start_char="899" end_char="899">"</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="900" end_char="904">Funny</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="906" end_char="911">enough</TOKEN>
<TOKEN id="token-10-3" pos="punct" morph="none" start_char="912" end_char="912">,</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="914" end_char="918">there</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="920" end_char="922">was</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="924" end_char="924">a</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="926" end_char="931">patent</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="933" end_char="935">for</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="937" end_char="939">the</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="941" end_char="951">coronavirus</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="953" end_char="955">was</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="957" end_char="961">filed</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="963" end_char="964">in</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="966" end_char="969">2015</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="971" end_char="973">and</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="975" end_char="981">granted</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="983" end_char="984">in</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="986" end_char="989">2018</TOKEN>
<TOKEN id="token-10-19" pos="punct" morph="none" start_char="990" end_char="991">."</TOKEN>
</SEG>
<SEG id="segment-11" start_char="994" end_char="1189">
<ORIGINAL_TEXT>Another, which was shared by others, and is part of a series of false coronavirus posts, proclaims that the virus is "‘new’ yet it was lab created and patented in 2015 (in development since 03’)."</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="994" end_char="1000">Another</TOKEN>
<TOKEN id="token-11-1" pos="punct" morph="none" start_char="1001" end_char="1001">,</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1003" end_char="1007">which</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1009" end_char="1011">was</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1013" end_char="1018">shared</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1020" end_char="1021">by</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1023" end_char="1028">others</TOKEN>
<TOKEN id="token-11-7" pos="punct" morph="none" start_char="1029" end_char="1029">,</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1031" end_char="1033">and</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1035" end_char="1036">is</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1038" end_char="1041">part</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1043" end_char="1044">of</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1046" end_char="1046">a</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1048" end_char="1053">series</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1055" end_char="1056">of</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1058" end_char="1062">false</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1064" end_char="1074">coronavirus</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1076" end_char="1080">posts</TOKEN>
<TOKEN id="token-11-18" pos="punct" morph="none" start_char="1081" end_char="1081">,</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="1083" end_char="1091">proclaims</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1093" end_char="1096">that</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="1098" end_char="1100">the</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="1102" end_char="1106">virus</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="1108" end_char="1109">is</TOKEN>
<TOKEN id="token-11-24" pos="punct" morph="none" start_char="1111" end_char="1112">"‘</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="1113" end_char="1115">new</TOKEN>
<TOKEN id="token-11-26" pos="punct" morph="none" start_char="1116" end_char="1116">’</TOKEN>
<TOKEN id="token-11-27" pos="word" morph="none" start_char="1118" end_char="1120">yet</TOKEN>
<TOKEN id="token-11-28" pos="word" morph="none" start_char="1122" end_char="1123">it</TOKEN>
<TOKEN id="token-11-29" pos="word" morph="none" start_char="1125" end_char="1127">was</TOKEN>
<TOKEN id="token-11-30" pos="word" morph="none" start_char="1129" end_char="1131">lab</TOKEN>
<TOKEN id="token-11-31" pos="word" morph="none" start_char="1133" end_char="1139">created</TOKEN>
<TOKEN id="token-11-32" pos="word" morph="none" start_char="1141" end_char="1143">and</TOKEN>
<TOKEN id="token-11-33" pos="word" morph="none" start_char="1145" end_char="1152">patented</TOKEN>
<TOKEN id="token-11-34" pos="word" morph="none" start_char="1154" end_char="1155">in</TOKEN>
<TOKEN id="token-11-35" pos="word" morph="none" start_char="1157" end_char="1160">2015</TOKEN>
<TOKEN id="token-11-36" pos="punct" morph="none" start_char="1162" end_char="1162">(</TOKEN>
<TOKEN id="token-11-37" pos="word" morph="none" start_char="1163" end_char="1164">in</TOKEN>
<TOKEN id="token-11-38" pos="word" morph="none" start_char="1166" end_char="1176">development</TOKEN>
<TOKEN id="token-11-39" pos="word" morph="none" start_char="1178" end_char="1182">since</TOKEN>
<TOKEN id="token-11-40" pos="word" morph="none" start_char="1184" end_char="1185">03</TOKEN>
<TOKEN id="token-11-41" pos="punct" morph="none" start_char="1186" end_char="1189">’)."</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1192" end_char="1233">
<ORIGINAL_TEXT>Yet another proposes a similar conspiracy.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1192" end_char="1194">Yet</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1196" end_char="1202">another</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1204" end_char="1211">proposes</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1213" end_char="1213">a</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1215" end_char="1221">similar</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1223" end_char="1232">conspiracy</TOKEN>
<TOKEN id="token-12-6" pos="punct" morph="none" start_char="1233" end_char="1233">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1235" end_char="1317">
<ORIGINAL_TEXT>"So.. patent on this ‘new’ Corona virus expired on the 22nd, today," the post says.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="punct" morph="none" start_char="1235" end_char="1235">"</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1236" end_char="1237">So</TOKEN>
<TOKEN id="token-13-2" pos="punct" morph="none" start_char="1238" end_char="1239">..</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1241" end_char="1246">patent</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1248" end_char="1249">on</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1251" end_char="1254">this</TOKEN>
<TOKEN id="token-13-6" pos="punct" morph="none" start_char="1256" end_char="1256">‘</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1257" end_char="1259">new</TOKEN>
<TOKEN id="token-13-8" pos="punct" morph="none" start_char="1260" end_char="1260">’</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1262" end_char="1267">Corona</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1269" end_char="1273">virus</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1275" end_char="1281">expired</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1283" end_char="1284">on</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1286" end_char="1288">the</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1290" end_char="1293">22nd</TOKEN>
<TOKEN id="token-13-15" pos="punct" morph="none" start_char="1294" end_char="1294">,</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1296" end_char="1300">today</TOKEN>
<TOKEN id="token-13-17" pos="punct" morph="none" start_char="1301" end_char="1302">,"</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1304" end_char="1306">the</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1308" end_char="1311">post</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1313" end_char="1316">says</TOKEN>
<TOKEN id="token-13-21" pos="punct" morph="none" start_char="1317" end_char="1317">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1319" end_char="1345">
<ORIGINAL_TEXT>"We have a sudden outbreak.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="punct" morph="none" start_char="1319" end_char="1319">"</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1320" end_char="1321">We</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1323" end_char="1326">have</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1328" end_char="1328">a</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1330" end_char="1335">sudden</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1337" end_char="1344">outbreak</TOKEN>
<TOKEN id="token-14-6" pos="punct" morph="none" start_char="1345" end_char="1345">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1347" end_char="1393">
<ORIGINAL_TEXT>There’s magically already a vaccine available."</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1347" end_char="1353">There’s</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1355" end_char="1363">magically</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1365" end_char="1371">already</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1373" end_char="1373">a</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1375" end_char="1381">vaccine</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1383" end_char="1391">available</TOKEN>
<TOKEN id="token-15-6" pos="punct" morph="none" start_char="1392" end_char="1393">."</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1396" end_char="1546">
<ORIGINAL_TEXT>In fact, there is no vaccine yet available for the new coronavirus, which for now goes by the unwieldy moniker of 2019 novel coronavirus, or 2019-nCoV.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1396" end_char="1397">In</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1399" end_char="1402">fact</TOKEN>
<TOKEN id="token-16-2" pos="punct" morph="none" start_char="1403" end_char="1403">,</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1405" end_char="1409">there</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1411" end_char="1412">is</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1414" end_char="1415">no</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1417" end_char="1423">vaccine</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1425" end_char="1427">yet</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1429" end_char="1437">available</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="1439" end_char="1441">for</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="1443" end_char="1445">the</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="1447" end_char="1449">new</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="1451" end_char="1461">coronavirus</TOKEN>
<TOKEN id="token-16-13" pos="punct" morph="none" start_char="1462" end_char="1462">,</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="1464" end_char="1468">which</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="1470" end_char="1472">for</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="1474" end_char="1476">now</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="1478" end_char="1481">goes</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="1483" end_char="1484">by</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="1486" end_char="1488">the</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="1490" end_char="1497">unwieldy</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="1499" end_char="1505">moniker</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="1507" end_char="1508">of</TOKEN>
<TOKEN id="token-16-23" pos="word" morph="none" start_char="1510" end_char="1513">2019</TOKEN>
<TOKEN id="token-16-24" pos="word" morph="none" start_char="1515" end_char="1519">novel</TOKEN>
<TOKEN id="token-16-25" pos="word" morph="none" start_char="1521" end_char="1531">coronavirus</TOKEN>
<TOKEN id="token-16-26" pos="punct" morph="none" start_char="1532" end_char="1532">,</TOKEN>
<TOKEN id="token-16-27" pos="word" morph="none" start_char="1534" end_char="1535">or</TOKEN>
<TOKEN id="token-16-28" pos="unknown" morph="none" start_char="1537" end_char="1545">2019-nCoV</TOKEN>
<TOKEN id="token-16-29" pos="punct" morph="none" start_char="1546" end_char="1546">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1548" end_char="1603">
<ORIGINAL_TEXT>And there is no patent related to the new virus, either.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1548" end_char="1550">And</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1552" end_char="1556">there</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="1558" end_char="1559">is</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="1561" end_char="1562">no</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="1564" end_char="1569">patent</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="1571" end_char="1577">related</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="1579" end_char="1580">to</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="1582" end_char="1584">the</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="1586" end_char="1588">new</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="1590" end_char="1594">virus</TOKEN>
<TOKEN id="token-17-10" pos="punct" morph="none" start_char="1595" end_char="1595">,</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="1597" end_char="1602">either</TOKEN>
<TOKEN id="token-17-12" pos="punct" morph="none" start_char="1603" end_char="1603">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1606" end_char="1706">
<ORIGINAL_TEXT>All of the posts link to patents that are related to two different viruses in the coronavirus family.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="1606" end_char="1608">All</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="1610" end_char="1611">of</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="1613" end_char="1615">the</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="1617" end_char="1621">posts</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="1623" end_char="1626">link</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="1628" end_char="1629">to</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="1631" end_char="1637">patents</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="1639" end_char="1642">that</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="1644" end_char="1646">are</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="1648" end_char="1654">related</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="1656" end_char="1657">to</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="1659" end_char="1661">two</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="1663" end_char="1671">different</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="1673" end_char="1679">viruses</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="1681" end_char="1682">in</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="1684" end_char="1686">the</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="1688" end_char="1698">coronavirus</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="1700" end_char="1705">family</TOKEN>
<TOKEN id="token-18-18" pos="punct" morph="none" start_char="1706" end_char="1706">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="1709" end_char="1912">
<ORIGINAL_TEXT>Coronaviruses are a group of viruses that tend to cause respiratory illnesses in humans and a variety of other illnesses in animals, the Centers for Disease Control and Prevention explains on its website.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="1709" end_char="1721">Coronaviruses</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="1723" end_char="1725">are</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="1727" end_char="1727">a</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="1729" end_char="1733">group</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="1735" end_char="1736">of</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="1738" end_char="1744">viruses</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="1746" end_char="1749">that</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="1751" end_char="1754">tend</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="1756" end_char="1757">to</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="1759" end_char="1763">cause</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="1765" end_char="1775">respiratory</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="1777" end_char="1785">illnesses</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="1787" end_char="1788">in</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="1790" end_char="1795">humans</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="1797" end_char="1799">and</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="1801" end_char="1801">a</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="1803" end_char="1809">variety</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="1811" end_char="1812">of</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="1814" end_char="1818">other</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="1820" end_char="1828">illnesses</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="1830" end_char="1831">in</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="1833" end_char="1839">animals</TOKEN>
<TOKEN id="token-19-22" pos="punct" morph="none" start_char="1840" end_char="1840">,</TOKEN>
<TOKEN id="token-19-23" pos="word" morph="none" start_char="1842" end_char="1844">the</TOKEN>
<TOKEN id="token-19-24" pos="word" morph="none" start_char="1846" end_char="1852">Centers</TOKEN>
<TOKEN id="token-19-25" pos="word" morph="none" start_char="1854" end_char="1856">for</TOKEN>
<TOKEN id="token-19-26" pos="word" morph="none" start_char="1858" end_char="1864">Disease</TOKEN>
<TOKEN id="token-19-27" pos="word" morph="none" start_char="1866" end_char="1872">Control</TOKEN>
<TOKEN id="token-19-28" pos="word" morph="none" start_char="1874" end_char="1876">and</TOKEN>
<TOKEN id="token-19-29" pos="word" morph="none" start_char="1878" end_char="1887">Prevention</TOKEN>
<TOKEN id="token-19-30" pos="word" morph="none" start_char="1889" end_char="1896">explains</TOKEN>
<TOKEN id="token-19-31" pos="word" morph="none" start_char="1898" end_char="1899">on</TOKEN>
<TOKEN id="token-19-32" pos="word" morph="none" start_char="1901" end_char="1903">its</TOKEN>
<TOKEN id="token-19-33" pos="word" morph="none" start_char="1905" end_char="1911">website</TOKEN>
<TOKEN id="token-19-34" pos="punct" morph="none" start_char="1912" end_char="1912">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="1914" end_char="2020">
<ORIGINAL_TEXT>The name comes from the crown, or corona-like appearance of infective viruses when seen under a microscope.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="1914" end_char="1916">The</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="1918" end_char="1921">name</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="1923" end_char="1927">comes</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="1929" end_char="1932">from</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="1934" end_char="1936">the</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="1938" end_char="1942">crown</TOKEN>
<TOKEN id="token-20-6" pos="punct" morph="none" start_char="1943" end_char="1943">,</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="1945" end_char="1946">or</TOKEN>
<TOKEN id="token-20-8" pos="unknown" morph="none" start_char="1948" end_char="1958">corona-like</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="1960" end_char="1969">appearance</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="1971" end_char="1972">of</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="1974" end_char="1982">infective</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="1984" end_char="1990">viruses</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="1992" end_char="1995">when</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="1997" end_char="2000">seen</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="2002" end_char="2006">under</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="2008" end_char="2008">a</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="2010" end_char="2019">microscope</TOKEN>
<TOKEN id="token-20-18" pos="punct" morph="none" start_char="2020" end_char="2020">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2023" end_char="2231">
<ORIGINAL_TEXT>One patent is for a genetic sequence of the virus that causes SARS, or severe acute respiratory syndrome, a disease that spread to dozens of countries in 2003, sickening more than 8,000 people and killing 774.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2023" end_char="2025">One</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2027" end_char="2032">patent</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2034" end_char="2035">is</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2037" end_char="2039">for</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2041" end_char="2041">a</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="2043" end_char="2049">genetic</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2051" end_char="2058">sequence</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="2060" end_char="2061">of</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="2063" end_char="2065">the</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="2067" end_char="2071">virus</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="2073" end_char="2076">that</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="2078" end_char="2083">causes</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="2085" end_char="2088">SARS</TOKEN>
<TOKEN id="token-21-13" pos="punct" morph="none" start_char="2089" end_char="2089">,</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="2091" end_char="2092">or</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="2094" end_char="2099">severe</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="2101" end_char="2105">acute</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="2107" end_char="2117">respiratory</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="2119" end_char="2126">syndrome</TOKEN>
<TOKEN id="token-21-19" pos="punct" morph="none" start_char="2127" end_char="2127">,</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="2129" end_char="2129">a</TOKEN>
<TOKEN id="token-21-21" pos="word" morph="none" start_char="2131" end_char="2137">disease</TOKEN>
<TOKEN id="token-21-22" pos="word" morph="none" start_char="2139" end_char="2142">that</TOKEN>
<TOKEN id="token-21-23" pos="word" morph="none" start_char="2144" end_char="2149">spread</TOKEN>
<TOKEN id="token-21-24" pos="word" morph="none" start_char="2151" end_char="2152">to</TOKEN>
<TOKEN id="token-21-25" pos="word" morph="none" start_char="2154" end_char="2159">dozens</TOKEN>
<TOKEN id="token-21-26" pos="word" morph="none" start_char="2161" end_char="2162">of</TOKEN>
<TOKEN id="token-21-27" pos="word" morph="none" start_char="2164" end_char="2172">countries</TOKEN>
<TOKEN id="token-21-28" pos="word" morph="none" start_char="2174" end_char="2175">in</TOKEN>
<TOKEN id="token-21-29" pos="word" morph="none" start_char="2177" end_char="2180">2003</TOKEN>
<TOKEN id="token-21-30" pos="punct" morph="none" start_char="2181" end_char="2181">,</TOKEN>
<TOKEN id="token-21-31" pos="word" morph="none" start_char="2183" end_char="2191">sickening</TOKEN>
<TOKEN id="token-21-32" pos="word" morph="none" start_char="2193" end_char="2196">more</TOKEN>
<TOKEN id="token-21-33" pos="word" morph="none" start_char="2198" end_char="2201">than</TOKEN>
<TOKEN id="token-21-34" pos="unknown" morph="none" start_char="2203" end_char="2207">8,000</TOKEN>
<TOKEN id="token-21-35" pos="word" morph="none" start_char="2209" end_char="2214">people</TOKEN>
<TOKEN id="token-21-36" pos="word" morph="none" start_char="2216" end_char="2218">and</TOKEN>
<TOKEN id="token-21-37" pos="word" morph="none" start_char="2220" end_char="2226">killing</TOKEN>
<TOKEN id="token-21-38" pos="word" morph="none" start_char="2228" end_char="2230">774</TOKEN>
<TOKEN id="token-21-39" pos="punct" morph="none" start_char="2231" end_char="2231">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2234" end_char="2436">
<ORIGINAL_TEXT>"The sequencing was done at the CDC during the SARS outbreak and they were the ones that filed the patent," Matthew Frieman, a coronavirus researcher at the University of Maryland, explained in an email.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="punct" morph="none" start_char="2234" end_char="2234">"</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2235" end_char="2237">The</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2239" end_char="2248">sequencing</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2250" end_char="2252">was</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2254" end_char="2257">done</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2259" end_char="2260">at</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2262" end_char="2264">the</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2266" end_char="2268">CDC</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="2270" end_char="2275">during</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="2277" end_char="2279">the</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="2281" end_char="2284">SARS</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="2286" end_char="2293">outbreak</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="2295" end_char="2297">and</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="2299" end_char="2302">they</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="2304" end_char="2307">were</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="2309" end_char="2311">the</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="2313" end_char="2316">ones</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="2318" end_char="2321">that</TOKEN>
<TOKEN id="token-22-18" pos="word" morph="none" start_char="2323" end_char="2327">filed</TOKEN>
<TOKEN id="token-22-19" pos="word" morph="none" start_char="2329" end_char="2331">the</TOKEN>
<TOKEN id="token-22-20" pos="word" morph="none" start_char="2333" end_char="2338">patent</TOKEN>
<TOKEN id="token-22-21" pos="punct" morph="none" start_char="2339" end_char="2340">,"</TOKEN>
<TOKEN id="token-22-22" pos="word" morph="none" start_char="2342" end_char="2348">Matthew</TOKEN>
<TOKEN id="token-22-23" pos="word" morph="none" start_char="2350" end_char="2356">Frieman</TOKEN>
<TOKEN id="token-22-24" pos="punct" morph="none" start_char="2357" end_char="2357">,</TOKEN>
<TOKEN id="token-22-25" pos="word" morph="none" start_char="2359" end_char="2359">a</TOKEN>
<TOKEN id="token-22-26" pos="word" morph="none" start_char="2361" end_char="2371">coronavirus</TOKEN>
<TOKEN id="token-22-27" pos="word" morph="none" start_char="2373" end_char="2382">researcher</TOKEN>
<TOKEN id="token-22-28" pos="word" morph="none" start_char="2384" end_char="2385">at</TOKEN>
<TOKEN id="token-22-29" pos="word" morph="none" start_char="2387" end_char="2389">the</TOKEN>
<TOKEN id="token-22-30" pos="word" morph="none" start_char="2391" end_char="2400">University</TOKEN>
<TOKEN id="token-22-31" pos="word" morph="none" start_char="2402" end_char="2403">of</TOKEN>
<TOKEN id="token-22-32" pos="word" morph="none" start_char="2405" end_char="2412">Maryland</TOKEN>
<TOKEN id="token-22-33" pos="punct" morph="none" start_char="2413" end_char="2413">,</TOKEN>
<TOKEN id="token-22-34" pos="word" morph="none" start_char="2415" end_char="2423">explained</TOKEN>
<TOKEN id="token-22-35" pos="word" morph="none" start_char="2425" end_char="2426">in</TOKEN>
<TOKEN id="token-22-36" pos="word" morph="none" start_char="2428" end_char="2429">an</TOKEN>
<TOKEN id="token-22-37" pos="word" morph="none" start_char="2431" end_char="2435">email</TOKEN>
<TOKEN id="token-22-38" pos="punct" morph="none" start_char="2436" end_char="2436">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2439" end_char="2591">
<ORIGINAL_TEXT>The CDC told the Associated Press in 2003 that the agency was claiming ownership to ensure access, and to prevent others from controlling the technology.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2439" end_char="2441">The</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2443" end_char="2445">CDC</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2447" end_char="2450">told</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2452" end_char="2454">the</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="2456" end_char="2465">Associated</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="2467" end_char="2471">Press</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="2473" end_char="2474">in</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="2476" end_char="2479">2003</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="2481" end_char="2484">that</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="2486" end_char="2488">the</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="2490" end_char="2495">agency</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="2497" end_char="2499">was</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="2501" end_char="2508">claiming</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="2510" end_char="2518">ownership</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="2520" end_char="2521">to</TOKEN>
<TOKEN id="token-23-15" pos="word" morph="none" start_char="2523" end_char="2528">ensure</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="2530" end_char="2535">access</TOKEN>
<TOKEN id="token-23-17" pos="punct" morph="none" start_char="2536" end_char="2536">,</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="2538" end_char="2540">and</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="2542" end_char="2543">to</TOKEN>
<TOKEN id="token-23-20" pos="word" morph="none" start_char="2545" end_char="2551">prevent</TOKEN>
<TOKEN id="token-23-21" pos="word" morph="none" start_char="2553" end_char="2558">others</TOKEN>
<TOKEN id="token-23-22" pos="word" morph="none" start_char="2560" end_char="2563">from</TOKEN>
<TOKEN id="token-23-23" pos="word" morph="none" start_char="2565" end_char="2575">controlling</TOKEN>
<TOKEN id="token-23-24" pos="word" morph="none" start_char="2577" end_char="2579">the</TOKEN>
<TOKEN id="token-23-25" pos="word" morph="none" start_char="2581" end_char="2590">technology</TOKEN>
<TOKEN id="token-23-26" pos="punct" morph="none" start_char="2591" end_char="2591">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2593" end_char="2804">
<ORIGINAL_TEXT>In a phone interview, Columbia law professor Harold Edgar told us that following a U.S. Supreme Court case decided in 2013, U.S. patent law no longer allows for patents on viral sequences as they exist in nature.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="2593" end_char="2594">In</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="2596" end_char="2596">a</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="2598" end_char="2602">phone</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="2604" end_char="2612">interview</TOKEN>
<TOKEN id="token-24-4" pos="punct" morph="none" start_char="2613" end_char="2613">,</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="2615" end_char="2622">Columbia</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="2624" end_char="2626">law</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="2628" end_char="2636">professor</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="2638" end_char="2643">Harold</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="2645" end_char="2649">Edgar</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="2651" end_char="2654">told</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="2656" end_char="2657">us</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="2659" end_char="2662">that</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="2664" end_char="2672">following</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="2674" end_char="2674">a</TOKEN>
<TOKEN id="token-24-15" pos="unknown" morph="none" start_char="2676" end_char="2678">U.S</TOKEN>
<TOKEN id="token-24-16" pos="punct" morph="none" start_char="2679" end_char="2679">.</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="2681" end_char="2687">Supreme</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="2689" end_char="2693">Court</TOKEN>
<TOKEN id="token-24-19" pos="word" morph="none" start_char="2695" end_char="2698">case</TOKEN>
<TOKEN id="token-24-20" pos="word" morph="none" start_char="2700" end_char="2706">decided</TOKEN>
<TOKEN id="token-24-21" pos="word" morph="none" start_char="2708" end_char="2709">in</TOKEN>
<TOKEN id="token-24-22" pos="word" morph="none" start_char="2711" end_char="2714">2013</TOKEN>
<TOKEN id="token-24-23" pos="punct" morph="none" start_char="2715" end_char="2715">,</TOKEN>
<TOKEN id="token-24-24" pos="unknown" morph="none" start_char="2717" end_char="2719">U.S</TOKEN>
<TOKEN id="token-24-25" pos="punct" morph="none" start_char="2720" end_char="2720">.</TOKEN>
<TOKEN id="token-24-26" pos="word" morph="none" start_char="2722" end_char="2727">patent</TOKEN>
<TOKEN id="token-24-27" pos="word" morph="none" start_char="2729" end_char="2731">law</TOKEN>
<TOKEN id="token-24-28" pos="word" morph="none" start_char="2733" end_char="2734">no</TOKEN>
<TOKEN id="token-24-29" pos="word" morph="none" start_char="2736" end_char="2741">longer</TOKEN>
<TOKEN id="token-24-30" pos="word" morph="none" start_char="2743" end_char="2748">allows</TOKEN>
<TOKEN id="token-24-31" pos="word" morph="none" start_char="2750" end_char="2752">for</TOKEN>
<TOKEN id="token-24-32" pos="word" morph="none" start_char="2754" end_char="2760">patents</TOKEN>
<TOKEN id="token-24-33" pos="word" morph="none" start_char="2762" end_char="2763">on</TOKEN>
<TOKEN id="token-24-34" pos="word" morph="none" start_char="2765" end_char="2769">viral</TOKEN>
<TOKEN id="token-24-35" pos="word" morph="none" start_char="2771" end_char="2779">sequences</TOKEN>
<TOKEN id="token-24-36" pos="word" morph="none" start_char="2781" end_char="2782">as</TOKEN>
<TOKEN id="token-24-37" pos="word" morph="none" start_char="2784" end_char="2787">they</TOKEN>
<TOKEN id="token-24-38" pos="word" morph="none" start_char="2789" end_char="2793">exist</TOKEN>
<TOKEN id="token-24-39" pos="word" morph="none" start_char="2795" end_char="2796">in</TOKEN>
<TOKEN id="token-24-40" pos="word" morph="none" start_char="2798" end_char="2803">nature</TOKEN>
<TOKEN id="token-24-41" pos="punct" morph="none" start_char="2804" end_char="2804">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2807" end_char="2948">
<ORIGINAL_TEXT>The other supposedly related patent is for a mutated form of avian infectious bronchitis virus, or IBV, which infects poultry, but not people.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="2807" end_char="2809">The</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="2811" end_char="2815">other</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="2817" end_char="2826">supposedly</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="2828" end_char="2834">related</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="2836" end_char="2841">patent</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="2843" end_char="2844">is</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="2846" end_char="2848">for</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="2850" end_char="2850">a</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="2852" end_char="2858">mutated</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="2860" end_char="2863">form</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="2865" end_char="2866">of</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="2868" end_char="2872">avian</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="2874" end_char="2883">infectious</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="2885" end_char="2894">bronchitis</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="2896" end_char="2900">virus</TOKEN>
<TOKEN id="token-25-15" pos="punct" morph="none" start_char="2901" end_char="2901">,</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="2903" end_char="2904">or</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="2906" end_char="2908">IBV</TOKEN>
<TOKEN id="token-25-18" pos="punct" morph="none" start_char="2909" end_char="2909">,</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="2911" end_char="2915">which</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="2917" end_char="2923">infects</TOKEN>
<TOKEN id="token-25-21" pos="word" morph="none" start_char="2925" end_char="2931">poultry</TOKEN>
<TOKEN id="token-25-22" pos="punct" morph="none" start_char="2932" end_char="2932">,</TOKEN>
<TOKEN id="token-25-23" pos="word" morph="none" start_char="2934" end_char="2936">but</TOKEN>
<TOKEN id="token-25-24" pos="word" morph="none" start_char="2938" end_char="2940">not</TOKEN>
<TOKEN id="token-25-25" pos="word" morph="none" start_char="2942" end_char="2947">people</TOKEN>
<TOKEN id="token-25-26" pos="punct" morph="none" start_char="2948" end_char="2948">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="2950" end_char="3101">
<ORIGINAL_TEXT>The patent was filed by the Pirbright Institute, a research institute in the U.K. whose mission is to prevent and control "viral diseases of livestock."</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="2950" end_char="2952">The</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="2954" end_char="2959">patent</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="2961" end_char="2963">was</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="2965" end_char="2969">filed</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="2971" end_char="2972">by</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="2974" end_char="2976">the</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="2978" end_char="2986">Pirbright</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="2988" end_char="2996">Institute</TOKEN>
<TOKEN id="token-26-8" pos="punct" morph="none" start_char="2997" end_char="2997">,</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="2999" end_char="2999">a</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="3001" end_char="3008">research</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="3010" end_char="3018">institute</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="3020" end_char="3021">in</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="3023" end_char="3025">the</TOKEN>
<TOKEN id="token-26-14" pos="unknown" morph="none" start_char="3027" end_char="3029">U.K</TOKEN>
<TOKEN id="token-26-15" pos="punct" morph="none" start_char="3030" end_char="3030">.</TOKEN>
<TOKEN id="token-26-16" pos="word" morph="none" start_char="3032" end_char="3036">whose</TOKEN>
<TOKEN id="token-26-17" pos="word" morph="none" start_char="3038" end_char="3044">mission</TOKEN>
<TOKEN id="token-26-18" pos="word" morph="none" start_char="3046" end_char="3047">is</TOKEN>
<TOKEN id="token-26-19" pos="word" morph="none" start_char="3049" end_char="3050">to</TOKEN>
<TOKEN id="token-26-20" pos="word" morph="none" start_char="3052" end_char="3058">prevent</TOKEN>
<TOKEN id="token-26-21" pos="word" morph="none" start_char="3060" end_char="3062">and</TOKEN>
<TOKEN id="token-26-22" pos="word" morph="none" start_char="3064" end_char="3070">control</TOKEN>
<TOKEN id="token-26-23" pos="punct" morph="none" start_char="3072" end_char="3072">"</TOKEN>
<TOKEN id="token-26-24" pos="word" morph="none" start_char="3073" end_char="3077">viral</TOKEN>
<TOKEN id="token-26-25" pos="word" morph="none" start_char="3079" end_char="3086">diseases</TOKEN>
<TOKEN id="token-26-26" pos="word" morph="none" start_char="3088" end_char="3089">of</TOKEN>
<TOKEN id="token-26-27" pos="word" morph="none" start_char="3091" end_char="3099">livestock</TOKEN>
<TOKEN id="token-26-28" pos="punct" morph="none" start_char="3100" end_char="3101">."</TOKEN>
</SEG>
<SEG id="segment-27" start_char="3103" end_char="3240">
<ORIGINAL_TEXT>The mutations were created to attenuate, or weaken, the virus, so that it could be used as a vaccine to protect chickens from the disease.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="3103" end_char="3105">The</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="3107" end_char="3115">mutations</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="3117" end_char="3120">were</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="3122" end_char="3128">created</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="3130" end_char="3131">to</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="3133" end_char="3141">attenuate</TOKEN>
<TOKEN id="token-27-6" pos="punct" morph="none" start_char="3142" end_char="3142">,</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="3144" end_char="3145">or</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="3147" end_char="3152">weaken</TOKEN>
<TOKEN id="token-27-9" pos="punct" morph="none" start_char="3153" end_char="3153">,</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="3155" end_char="3157">the</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="3159" end_char="3163">virus</TOKEN>
<TOKEN id="token-27-12" pos="punct" morph="none" start_char="3164" end_char="3164">,</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="3166" end_char="3167">so</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="3169" end_char="3172">that</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="3174" end_char="3175">it</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="3177" end_char="3181">could</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="3183" end_char="3184">be</TOKEN>
<TOKEN id="token-27-18" pos="word" morph="none" start_char="3186" end_char="3189">used</TOKEN>
<TOKEN id="token-27-19" pos="word" morph="none" start_char="3191" end_char="3192">as</TOKEN>
<TOKEN id="token-27-20" pos="word" morph="none" start_char="3194" end_char="3194">a</TOKEN>
<TOKEN id="token-27-21" pos="word" morph="none" start_char="3196" end_char="3202">vaccine</TOKEN>
<TOKEN id="token-27-22" pos="word" morph="none" start_char="3204" end_char="3205">to</TOKEN>
<TOKEN id="token-27-23" pos="word" morph="none" start_char="3207" end_char="3213">protect</TOKEN>
<TOKEN id="token-27-24" pos="word" morph="none" start_char="3215" end_char="3222">chickens</TOKEN>
<TOKEN id="token-27-25" pos="word" morph="none" start_char="3224" end_char="3227">from</TOKEN>
<TOKEN id="token-27-26" pos="word" morph="none" start_char="3229" end_char="3231">the</TOKEN>
<TOKEN id="token-27-27" pos="word" morph="none" start_char="3233" end_char="3239">disease</TOKEN>
<TOKEN id="token-27-28" pos="punct" morph="none" start_char="3240" end_char="3240">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3243" end_char="3323">
<ORIGINAL_TEXT>"Neither of these has anything to do with the new 2019-nCoV virus," said Frieman.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="punct" morph="none" start_char="3243" end_char="3243">"</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="3244" end_char="3250">Neither</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="3252" end_char="3253">of</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="3255" end_char="3259">these</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="3261" end_char="3263">has</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="3265" end_char="3272">anything</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="3274" end_char="3275">to</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="3277" end_char="3278">do</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="3280" end_char="3283">with</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="3285" end_char="3287">the</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="3289" end_char="3291">new</TOKEN>
<TOKEN id="token-28-11" pos="unknown" morph="none" start_char="3293" end_char="3301">2019-nCoV</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="3303" end_char="3307">virus</TOKEN>
<TOKEN id="token-28-13" pos="punct" morph="none" start_char="3308" end_char="3309">,"</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="3311" end_char="3314">said</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="3316" end_char="3322">Frieman</TOKEN>
<TOKEN id="token-28-16" pos="punct" morph="none" start_char="3323" end_char="3323">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3325" end_char="3441">
<ORIGINAL_TEXT>"This is clearly a bogus theory that this virus was created in a lab, patented and has a vaccine already made to it."</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="punct" morph="none" start_char="3325" end_char="3325">"</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="3326" end_char="3329">This</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="3331" end_char="3332">is</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="3334" end_char="3340">clearly</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="3342" end_char="3342">a</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="3344" end_char="3348">bogus</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="3350" end_char="3355">theory</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="3357" end_char="3360">that</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="3362" end_char="3365">this</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="3367" end_char="3371">virus</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="3373" end_char="3375">was</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="3377" end_char="3383">created</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="3385" end_char="3386">in</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="3388" end_char="3388">a</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="3390" end_char="3392">lab</TOKEN>
<TOKEN id="token-29-15" pos="punct" morph="none" start_char="3393" end_char="3393">,</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="3395" end_char="3402">patented</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="3404" end_char="3406">and</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="3408" end_char="3410">has</TOKEN>
<TOKEN id="token-29-19" pos="word" morph="none" start_char="3412" end_char="3412">a</TOKEN>
<TOKEN id="token-29-20" pos="word" morph="none" start_char="3414" end_char="3420">vaccine</TOKEN>
<TOKEN id="token-29-21" pos="word" morph="none" start_char="3422" end_char="3428">already</TOKEN>
<TOKEN id="token-29-22" pos="word" morph="none" start_char="3430" end_char="3433">made</TOKEN>
<TOKEN id="token-29-23" pos="word" morph="none" start_char="3435" end_char="3436">to</TOKEN>
<TOKEN id="token-29-24" pos="word" morph="none" start_char="3438" end_char="3439">it</TOKEN>
<TOKEN id="token-29-25" pos="punct" morph="none" start_char="3440" end_char="3441">."</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3444" end_char="3545">
<ORIGINAL_TEXT>Researchers are still working to understand the origin, spread and severity of the latest coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="3444" end_char="3454">Researchers</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="3456" end_char="3458">are</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="3460" end_char="3464">still</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="3466" end_char="3472">working</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="3474" end_char="3475">to</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="3477" end_char="3486">understand</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="3488" end_char="3490">the</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="3492" end_char="3497">origin</TOKEN>
<TOKEN id="token-30-8" pos="punct" morph="none" start_char="3498" end_char="3498">,</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="3500" end_char="3505">spread</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="3507" end_char="3509">and</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="3511" end_char="3518">severity</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="3520" end_char="3521">of</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="3523" end_char="3525">the</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="3527" end_char="3532">latest</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="3534" end_char="3544">coronavirus</TOKEN>
<TOKEN id="token-30-16" pos="punct" morph="none" start_char="3545" end_char="3545">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="3547" end_char="3645">
<ORIGINAL_TEXT>The outbreak began in early December in Wuhan, a city of around 11 million people in central China.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="3547" end_char="3549">The</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="3551" end_char="3558">outbreak</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="3560" end_char="3564">began</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="3566" end_char="3567">in</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="3569" end_char="3573">early</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="3575" end_char="3582">December</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="3584" end_char="3585">in</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="3587" end_char="3591">Wuhan</TOKEN>
<TOKEN id="token-31-8" pos="punct" morph="none" start_char="3592" end_char="3592">,</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="3594" end_char="3594">a</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="3596" end_char="3599">city</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="3601" end_char="3602">of</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="3604" end_char="3609">around</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="3611" end_char="3612">11</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="3614" end_char="3620">million</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="3622" end_char="3627">people</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="3629" end_char="3630">in</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="3632" end_char="3638">central</TOKEN>
<TOKEN id="token-31-18" pos="word" morph="none" start_char="3640" end_char="3644">China</TOKEN>
<TOKEN id="token-31-19" pos="punct" morph="none" start_char="3645" end_char="3645">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="3648" end_char="3793">
<ORIGINAL_TEXT>Evidence suggests the virus likely spilled over to humans from an as-yet-unidentified animal, as has happened in the past for other coronaviruses.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="3648" end_char="3655">Evidence</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="3657" end_char="3664">suggests</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="3666" end_char="3668">the</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="3670" end_char="3674">virus</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="3676" end_char="3681">likely</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="3683" end_char="3689">spilled</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="3691" end_char="3694">over</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="3696" end_char="3697">to</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="3699" end_char="3704">humans</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="3706" end_char="3709">from</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="3711" end_char="3712">an</TOKEN>
<TOKEN id="token-32-11" pos="unknown" morph="none" start_char="3714" end_char="3732">as-yet-unidentified</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="3734" end_char="3739">animal</TOKEN>
<TOKEN id="token-32-13" pos="punct" morph="none" start_char="3740" end_char="3740">,</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="3742" end_char="3743">as</TOKEN>
<TOKEN id="token-32-15" pos="word" morph="none" start_char="3745" end_char="3747">has</TOKEN>
<TOKEN id="token-32-16" pos="word" morph="none" start_char="3749" end_char="3756">happened</TOKEN>
<TOKEN id="token-32-17" pos="word" morph="none" start_char="3758" end_char="3759">in</TOKEN>
<TOKEN id="token-32-18" pos="word" morph="none" start_char="3761" end_char="3763">the</TOKEN>
<TOKEN id="token-32-19" pos="word" morph="none" start_char="3765" end_char="3768">past</TOKEN>
<TOKEN id="token-32-20" pos="word" morph="none" start_char="3770" end_char="3772">for</TOKEN>
<TOKEN id="token-32-21" pos="word" morph="none" start_char="3774" end_char="3778">other</TOKEN>
<TOKEN id="token-32-22" pos="word" morph="none" start_char="3780" end_char="3792">coronaviruses</TOKEN>
<TOKEN id="token-32-23" pos="punct" morph="none" start_char="3793" end_char="3793">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="3795" end_char="3947">
<ORIGINAL_TEXT>The SARS virus, for instance, is thought to have come from bats, and then spread to humans through civets, a cat-like animal eaten as a delicacy in Asia.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="3795" end_char="3797">The</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="3799" end_char="3802">SARS</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="3804" end_char="3808">virus</TOKEN>
<TOKEN id="token-33-3" pos="punct" morph="none" start_char="3809" end_char="3809">,</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="3811" end_char="3813">for</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="3815" end_char="3822">instance</TOKEN>
<TOKEN id="token-33-6" pos="punct" morph="none" start_char="3823" end_char="3823">,</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="3825" end_char="3826">is</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="3828" end_char="3834">thought</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="3836" end_char="3837">to</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="3839" end_char="3842">have</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="3844" end_char="3847">come</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="3849" end_char="3852">from</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="3854" end_char="3857">bats</TOKEN>
<TOKEN id="token-33-14" pos="punct" morph="none" start_char="3858" end_char="3858">,</TOKEN>
<TOKEN id="token-33-15" pos="word" morph="none" start_char="3860" end_char="3862">and</TOKEN>
<TOKEN id="token-33-16" pos="word" morph="none" start_char="3864" end_char="3867">then</TOKEN>
<TOKEN id="token-33-17" pos="word" morph="none" start_char="3869" end_char="3874">spread</TOKEN>
<TOKEN id="token-33-18" pos="word" morph="none" start_char="3876" end_char="3877">to</TOKEN>
<TOKEN id="token-33-19" pos="word" morph="none" start_char="3879" end_char="3884">humans</TOKEN>
<TOKEN id="token-33-20" pos="word" morph="none" start_char="3886" end_char="3892">through</TOKEN>
<TOKEN id="token-33-21" pos="word" morph="none" start_char="3894" end_char="3899">civets</TOKEN>
<TOKEN id="token-33-22" pos="punct" morph="none" start_char="3900" end_char="3900">,</TOKEN>
<TOKEN id="token-33-23" pos="word" morph="none" start_char="3902" end_char="3902">a</TOKEN>
<TOKEN id="token-33-24" pos="unknown" morph="none" start_char="3904" end_char="3911">cat-like</TOKEN>
<TOKEN id="token-33-25" pos="word" morph="none" start_char="3913" end_char="3918">animal</TOKEN>
<TOKEN id="token-33-26" pos="word" morph="none" start_char="3920" end_char="3924">eaten</TOKEN>
<TOKEN id="token-33-27" pos="word" morph="none" start_char="3926" end_char="3927">as</TOKEN>
<TOKEN id="token-33-28" pos="word" morph="none" start_char="3929" end_char="3929">a</TOKEN>
<TOKEN id="token-33-29" pos="word" morph="none" start_char="3931" end_char="3938">delicacy</TOKEN>
<TOKEN id="token-33-30" pos="word" morph="none" start_char="3940" end_char="3941">in</TOKEN>
<TOKEN id="token-33-31" pos="word" morph="none" start_char="3943" end_char="3946">Asia</TOKEN>
<TOKEN id="token-33-32" pos="punct" morph="none" start_char="3947" end_char="3947">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="3949" end_char="4017">
<ORIGINAL_TEXT>The SARS virus then proved to be transmissible from person to person.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="3949" end_char="3951">The</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="3953" end_char="3956">SARS</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="3958" end_char="3962">virus</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="3964" end_char="3967">then</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="3969" end_char="3974">proved</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="3976" end_char="3977">to</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="3979" end_char="3980">be</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="3982" end_char="3994">transmissible</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="3996" end_char="3999">from</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="4001" end_char="4006">person</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="4008" end_char="4009">to</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="4011" end_char="4016">person</TOKEN>
<TOKEN id="token-34-12" pos="punct" morph="none" start_char="4017" end_char="4017">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="4020" end_char="4204">
<ORIGINAL_TEXT>A similar story played out in 2012 with the virus responsible for Middle East Respiratory Syndrome, or MERS, which may also have originated in bats, and then spread to humans via camel.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="4020" end_char="4020">A</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="4022" end_char="4028">similar</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="4030" end_char="4034">story</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="4036" end_char="4041">played</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="4043" end_char="4045">out</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="4047" end_char="4048">in</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="4050" end_char="4053">2012</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="4055" end_char="4058">with</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="4060" end_char="4062">the</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="4064" end_char="4068">virus</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="4070" end_char="4080">responsible</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="4082" end_char="4084">for</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="4086" end_char="4091">Middle</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="4093" end_char="4096">East</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="4098" end_char="4108">Respiratory</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="4110" end_char="4117">Syndrome</TOKEN>
<TOKEN id="token-35-16" pos="punct" morph="none" start_char="4118" end_char="4118">,</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="4120" end_char="4121">or</TOKEN>
<TOKEN id="token-35-18" pos="word" morph="none" start_char="4123" end_char="4126">MERS</TOKEN>
<TOKEN id="token-35-19" pos="punct" morph="none" start_char="4127" end_char="4127">,</TOKEN>
<TOKEN id="token-35-20" pos="word" morph="none" start_char="4129" end_char="4133">which</TOKEN>
<TOKEN id="token-35-21" pos="word" morph="none" start_char="4135" end_char="4137">may</TOKEN>
<TOKEN id="token-35-22" pos="word" morph="none" start_char="4139" end_char="4142">also</TOKEN>
<TOKEN id="token-35-23" pos="word" morph="none" start_char="4144" end_char="4147">have</TOKEN>
<TOKEN id="token-35-24" pos="word" morph="none" start_char="4149" end_char="4158">originated</TOKEN>
<TOKEN id="token-35-25" pos="word" morph="none" start_char="4160" end_char="4161">in</TOKEN>
<TOKEN id="token-35-26" pos="word" morph="none" start_char="4163" end_char="4166">bats</TOKEN>
<TOKEN id="token-35-27" pos="punct" morph="none" start_char="4167" end_char="4167">,</TOKEN>
<TOKEN id="token-35-28" pos="word" morph="none" start_char="4169" end_char="4171">and</TOKEN>
<TOKEN id="token-35-29" pos="word" morph="none" start_char="4173" end_char="4176">then</TOKEN>
<TOKEN id="token-35-30" pos="word" morph="none" start_char="4178" end_char="4183">spread</TOKEN>
<TOKEN id="token-35-31" pos="word" morph="none" start_char="4185" end_char="4186">to</TOKEN>
<TOKEN id="token-35-32" pos="word" morph="none" start_char="4188" end_char="4193">humans</TOKEN>
<TOKEN id="token-35-33" pos="word" morph="none" start_char="4195" end_char="4197">via</TOKEN>
<TOKEN id="token-35-34" pos="word" morph="none" start_char="4199" end_char="4203">camel</TOKEN>
<TOKEN id="token-35-35" pos="punct" morph="none" start_char="4204" end_char="4204">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="4207" end_char="4360">
<ORIGINAL_TEXT>Cases of the new respiratory illness were first reported in people who had connections to a fish market in Wuhan that also sold a variety of live animals.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="4207" end_char="4211">Cases</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="4213" end_char="4214">of</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="4216" end_char="4218">the</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="4220" end_char="4222">new</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="4224" end_char="4234">respiratory</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="4236" end_char="4242">illness</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="4244" end_char="4247">were</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="4249" end_char="4253">first</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="4255" end_char="4262">reported</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="4264" end_char="4265">in</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="4267" end_char="4272">people</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="4274" end_char="4276">who</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="4278" end_char="4280">had</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="4282" end_char="4292">connections</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="4294" end_char="4295">to</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="4297" end_char="4297">a</TOKEN>
<TOKEN id="token-36-16" pos="word" morph="none" start_char="4299" end_char="4302">fish</TOKEN>
<TOKEN id="token-36-17" pos="word" morph="none" start_char="4304" end_char="4309">market</TOKEN>
<TOKEN id="token-36-18" pos="word" morph="none" start_char="4311" end_char="4312">in</TOKEN>
<TOKEN id="token-36-19" pos="word" morph="none" start_char="4314" end_char="4318">Wuhan</TOKEN>
<TOKEN id="token-36-20" pos="word" morph="none" start_char="4320" end_char="4323">that</TOKEN>
<TOKEN id="token-36-21" pos="word" morph="none" start_char="4325" end_char="4328">also</TOKEN>
<TOKEN id="token-36-22" pos="word" morph="none" start_char="4330" end_char="4333">sold</TOKEN>
<TOKEN id="token-36-23" pos="word" morph="none" start_char="4335" end_char="4335">a</TOKEN>
<TOKEN id="token-36-24" pos="word" morph="none" start_char="4337" end_char="4343">variety</TOKEN>
<TOKEN id="token-36-25" pos="word" morph="none" start_char="4345" end_char="4346">of</TOKEN>
<TOKEN id="token-36-26" pos="word" morph="none" start_char="4348" end_char="4351">live</TOKEN>
<TOKEN id="token-36-27" pos="word" morph="none" start_char="4353" end_char="4359">animals</TOKEN>
<TOKEN id="token-36-28" pos="punct" morph="none" start_char="4360" end_char="4360">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="4362" end_char="4442">
<ORIGINAL_TEXT>National Institute of Allergy and Infectious Diseases director Anthony Fauci told</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="4362" end_char="4369">National</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="4371" end_char="4379">Institute</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="4381" end_char="4382">of</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="4384" end_char="4390">Allergy</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="4392" end_char="4394">and</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="4396" end_char="4405">Infectious</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="4407" end_char="4414">Diseases</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="4416" end_char="4423">director</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="4425" end_char="4431">Anthony</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="4433" end_char="4437">Fauci</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="4439" end_char="4442">told</TOKEN>
</SEG>
<SEG id="segment-38" start_char="4445" end_char="4463">
<ORIGINAL_TEXT>Scientific American</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="4445" end_char="4454">Scientific</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="4456" end_char="4463">American</TOKEN>
</SEG>
<SEG id="segment-39" start_char="4466" end_char="4472">
<ORIGINAL_TEXT>on Jan.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="4466" end_char="4467">on</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="4469" end_char="4471">Jan</TOKEN>
<TOKEN id="token-39-2" pos="punct" morph="none" start_char="4472" end_char="4472">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="4474" end_char="4534">
<ORIGINAL_TEXT>22 that the new virus "almost certainly" came from an animal.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="4474" end_char="4475">22</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="4477" end_char="4480">that</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="4482" end_char="4484">the</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="4486" end_char="4488">new</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="4490" end_char="4494">virus</TOKEN>
<TOKEN id="token-40-5" pos="punct" morph="none" start_char="4496" end_char="4496">"</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="4497" end_char="4502">almost</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="4504" end_char="4512">certainly</TOKEN>
<TOKEN id="token-40-8" pos="punct" morph="none" start_char="4513" end_char="4513">"</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="4515" end_char="4518">came</TOKEN>
<TOKEN id="token-40-10" pos="word" morph="none" start_char="4520" end_char="4523">from</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="4525" end_char="4526">an</TOKEN>
<TOKEN id="token-40-12" pos="word" morph="none" start_char="4528" end_char="4533">animal</TOKEN>
<TOKEN id="token-40-13" pos="punct" morph="none" start_char="4534" end_char="4534">.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="4537" end_char="4661">
<ORIGINAL_TEXT>It is now clear that the new coronavirus can also pass from person to person, although it is not known how easily it spreads.</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="4537" end_char="4538">It</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="4540" end_char="4541">is</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="4543" end_char="4545">now</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="4547" end_char="4551">clear</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="4553" end_char="4556">that</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="4558" end_char="4560">the</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="4562" end_char="4564">new</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="4566" end_char="4576">coronavirus</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="4578" end_char="4580">can</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="4582" end_char="4585">also</TOKEN>
<TOKEN id="token-41-10" pos="word" morph="none" start_char="4587" end_char="4590">pass</TOKEN>
<TOKEN id="token-41-11" pos="word" morph="none" start_char="4592" end_char="4595">from</TOKEN>
<TOKEN id="token-41-12" pos="word" morph="none" start_char="4597" end_char="4602">person</TOKEN>
<TOKEN id="token-41-13" pos="word" morph="none" start_char="4604" end_char="4605">to</TOKEN>
<TOKEN id="token-41-14" pos="word" morph="none" start_char="4607" end_char="4612">person</TOKEN>
<TOKEN id="token-41-15" pos="punct" morph="none" start_char="4613" end_char="4613">,</TOKEN>
<TOKEN id="token-41-16" pos="word" morph="none" start_char="4615" end_char="4622">although</TOKEN>
<TOKEN id="token-41-17" pos="word" morph="none" start_char="4624" end_char="4625">it</TOKEN>
<TOKEN id="token-41-18" pos="word" morph="none" start_char="4627" end_char="4628">is</TOKEN>
<TOKEN id="token-41-19" pos="word" morph="none" start_char="4630" end_char="4632">not</TOKEN>
<TOKEN id="token-41-20" pos="word" morph="none" start_char="4634" end_char="4638">known</TOKEN>
<TOKEN id="token-41-21" pos="word" morph="none" start_char="4640" end_char="4642">how</TOKEN>
<TOKEN id="token-41-22" pos="word" morph="none" start_char="4644" end_char="4649">easily</TOKEN>
<TOKEN id="token-41-23" pos="word" morph="none" start_char="4651" end_char="4652">it</TOKEN>
<TOKEN id="token-41-24" pos="word" morph="none" start_char="4654" end_char="4660">spreads</TOKEN>
<TOKEN id="token-41-25" pos="punct" morph="none" start_char="4661" end_char="4661">.</TOKEN>
</SEG>
<SEG id="segment-42" start_char="4663" end_char="4776">
<ORIGINAL_TEXT>It’s possible the disease may not be as severe as SARS, but health officials say it is too early to know for sure.</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="4663" end_char="4666">It’s</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="4668" end_char="4675">possible</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="4677" end_char="4679">the</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="4681" end_char="4687">disease</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="4689" end_char="4691">may</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="4693" end_char="4695">not</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="4697" end_char="4698">be</TOKEN>
<TOKEN id="token-42-7" pos="word" morph="none" start_char="4700" end_char="4701">as</TOKEN>
<TOKEN id="token-42-8" pos="word" morph="none" start_char="4703" end_char="4708">severe</TOKEN>
<TOKEN id="token-42-9" pos="word" morph="none" start_char="4710" end_char="4711">as</TOKEN>
<TOKEN id="token-42-10" pos="word" morph="none" start_char="4713" end_char="4716">SARS</TOKEN>
<TOKEN id="token-42-11" pos="punct" morph="none" start_char="4717" end_char="4717">,</TOKEN>
<TOKEN id="token-42-12" pos="word" morph="none" start_char="4719" end_char="4721">but</TOKEN>
<TOKEN id="token-42-13" pos="word" morph="none" start_char="4723" end_char="4728">health</TOKEN>
<TOKEN id="token-42-14" pos="word" morph="none" start_char="4730" end_char="4738">officials</TOKEN>
<TOKEN id="token-42-15" pos="word" morph="none" start_char="4740" end_char="4742">say</TOKEN>
<TOKEN id="token-42-16" pos="word" morph="none" start_char="4744" end_char="4745">it</TOKEN>
<TOKEN id="token-42-17" pos="word" morph="none" start_char="4747" end_char="4748">is</TOKEN>
<TOKEN id="token-42-18" pos="word" morph="none" start_char="4750" end_char="4752">too</TOKEN>
<TOKEN id="token-42-19" pos="word" morph="none" start_char="4754" end_char="4758">early</TOKEN>
<TOKEN id="token-42-20" pos="word" morph="none" start_char="4760" end_char="4761">to</TOKEN>
<TOKEN id="token-42-21" pos="word" morph="none" start_char="4763" end_char="4766">know</TOKEN>
<TOKEN id="token-42-22" pos="word" morph="none" start_char="4768" end_char="4770">for</TOKEN>
<TOKEN id="token-42-23" pos="word" morph="none" start_char="4772" end_char="4775">sure</TOKEN>
<TOKEN id="token-42-24" pos="punct" morph="none" start_char="4776" end_char="4776">.</TOKEN>
</SEG>
<SEG id="segment-43" start_char="4778" end_char="4831">
<ORIGINAL_TEXT>Symptoms include fever, cough and shortness of breath.</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="4778" end_char="4785">Symptoms</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="4787" end_char="4793">include</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="4795" end_char="4799">fever</TOKEN>
<TOKEN id="token-43-3" pos="punct" morph="none" start_char="4800" end_char="4800">,</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="4802" end_char="4806">cough</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="4808" end_char="4810">and</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="4812" end_char="4820">shortness</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="4822" end_char="4823">of</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="4825" end_char="4830">breath</TOKEN>
<TOKEN id="token-43-9" pos="punct" morph="none" start_char="4831" end_char="4831">.</TOKEN>
</SEG>
<SEG id="segment-44" start_char="4834" end_char="4849">
<ORIGINAL_TEXT>As of early Jan.</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="4834" end_char="4835">As</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="4837" end_char="4838">of</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="4840" end_char="4844">early</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="4846" end_char="4848">Jan</TOKEN>
<TOKEN id="token-44-4" pos="punct" morph="none" start_char="4849" end_char="4849">.</TOKEN>
</SEG>
<SEG id="segment-45" start_char="4851" end_char="4942">
<ORIGINAL_TEXT>24, at least 26 people have died, all in China, out of nearly 900 confirmed cases worldwide.</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="4851" end_char="4852">24</TOKEN>
<TOKEN id="token-45-1" pos="punct" morph="none" start_char="4853" end_char="4853">,</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="4855" end_char="4856">at</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="4858" end_char="4862">least</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="4864" end_char="4865">26</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="4867" end_char="4872">people</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="4874" end_char="4877">have</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="4879" end_char="4882">died</TOKEN>
<TOKEN id="token-45-8" pos="punct" morph="none" start_char="4883" end_char="4883">,</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="4885" end_char="4887">all</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="4889" end_char="4890">in</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="4892" end_char="4896">China</TOKEN>
<TOKEN id="token-45-12" pos="punct" morph="none" start_char="4897" end_char="4897">,</TOKEN>
<TOKEN id="token-45-13" pos="word" morph="none" start_char="4899" end_char="4901">out</TOKEN>
<TOKEN id="token-45-14" pos="word" morph="none" start_char="4903" end_char="4904">of</TOKEN>
<TOKEN id="token-45-15" pos="word" morph="none" start_char="4906" end_char="4911">nearly</TOKEN>
<TOKEN id="token-45-16" pos="word" morph="none" start_char="4913" end_char="4915">900</TOKEN>
<TOKEN id="token-45-17" pos="word" morph="none" start_char="4917" end_char="4925">confirmed</TOKEN>
<TOKEN id="token-45-18" pos="word" morph="none" start_char="4927" end_char="4931">cases</TOKEN>
<TOKEN id="token-45-19" pos="word" morph="none" start_char="4933" end_char="4941">worldwide</TOKEN>
<TOKEN id="token-45-20" pos="punct" morph="none" start_char="4942" end_char="4942">.</TOKEN>
</SEG>
<SEG id="segment-46" start_char="4944" end_char="5031">
<ORIGINAL_TEXT>Deaths have primarily occurred in older people or those who had other health conditions.</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="4944" end_char="4949">Deaths</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="4951" end_char="4954">have</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="4956" end_char="4964">primarily</TOKEN>
<TOKEN id="token-46-3" pos="word" morph="none" start_char="4966" end_char="4973">occurred</TOKEN>
<TOKEN id="token-46-4" pos="word" morph="none" start_char="4975" end_char="4976">in</TOKEN>
<TOKEN id="token-46-5" pos="word" morph="none" start_char="4978" end_char="4982">older</TOKEN>
<TOKEN id="token-46-6" pos="word" morph="none" start_char="4984" end_char="4989">people</TOKEN>
<TOKEN id="token-46-7" pos="word" morph="none" start_char="4991" end_char="4992">or</TOKEN>
<TOKEN id="token-46-8" pos="word" morph="none" start_char="4994" end_char="4998">those</TOKEN>
<TOKEN id="token-46-9" pos="word" morph="none" start_char="5000" end_char="5002">who</TOKEN>
<TOKEN id="token-46-10" pos="word" morph="none" start_char="5004" end_char="5006">had</TOKEN>
<TOKEN id="token-46-11" pos="word" morph="none" start_char="5008" end_char="5012">other</TOKEN>
<TOKEN id="token-46-12" pos="word" morph="none" start_char="5014" end_char="5019">health</TOKEN>
<TOKEN id="token-46-13" pos="word" morph="none" start_char="5021" end_char="5030">conditions</TOKEN>
<TOKEN id="token-46-14" pos="punct" morph="none" start_char="5031" end_char="5031">.</TOKEN>
</SEG>
<SEG id="segment-47" start_char="5033" end_char="5105">
<ORIGINAL_TEXT>Cases have also been reported in Thailand, Taiwan, Japan and South Korea.</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="5033" end_char="5037">Cases</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="5039" end_char="5042">have</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="5044" end_char="5047">also</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="5049" end_char="5052">been</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="5054" end_char="5061">reported</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="5063" end_char="5064">in</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="5066" end_char="5073">Thailand</TOKEN>
<TOKEN id="token-47-7" pos="punct" morph="none" start_char="5074" end_char="5074">,</TOKEN>
<TOKEN id="token-47-8" pos="word" morph="none" start_char="5076" end_char="5081">Taiwan</TOKEN>
<TOKEN id="token-47-9" pos="punct" morph="none" start_char="5082" end_char="5082">,</TOKEN>
<TOKEN id="token-47-10" pos="word" morph="none" start_char="5084" end_char="5088">Japan</TOKEN>
<TOKEN id="token-47-11" pos="word" morph="none" start_char="5090" end_char="5092">and</TOKEN>
<TOKEN id="token-47-12" pos="word" morph="none" start_char="5094" end_char="5098">South</TOKEN>
<TOKEN id="token-47-13" pos="word" morph="none" start_char="5100" end_char="5104">Korea</TOKEN>
<TOKEN id="token-47-14" pos="punct" morph="none" start_char="5105" end_char="5105">.</TOKEN>
</SEG>
<SEG id="segment-48" start_char="5107" end_char="5203">
<ORIGINAL_TEXT>The U.S. patient had recently traveled from Wuhan and is in good condition, according to the CDC.</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="5107" end_char="5109">The</TOKEN>
<TOKEN id="token-48-1" pos="unknown" morph="none" start_char="5111" end_char="5113">U.S</TOKEN>
<TOKEN id="token-48-2" pos="punct" morph="none" start_char="5114" end_char="5114">.</TOKEN>
<TOKEN id="token-48-3" pos="word" morph="none" start_char="5116" end_char="5122">patient</TOKEN>
<TOKEN id="token-48-4" pos="word" morph="none" start_char="5124" end_char="5126">had</TOKEN>
<TOKEN id="token-48-5" pos="word" morph="none" start_char="5128" end_char="5135">recently</TOKEN>
<TOKEN id="token-48-6" pos="word" morph="none" start_char="5137" end_char="5144">traveled</TOKEN>
<TOKEN id="token-48-7" pos="word" morph="none" start_char="5146" end_char="5149">from</TOKEN>
<TOKEN id="token-48-8" pos="word" morph="none" start_char="5151" end_char="5155">Wuhan</TOKEN>
<TOKEN id="token-48-9" pos="word" morph="none" start_char="5157" end_char="5159">and</TOKEN>
<TOKEN id="token-48-10" pos="word" morph="none" start_char="5161" end_char="5162">is</TOKEN>
<TOKEN id="token-48-11" pos="word" morph="none" start_char="5164" end_char="5165">in</TOKEN>
<TOKEN id="token-48-12" pos="word" morph="none" start_char="5167" end_char="5170">good</TOKEN>
<TOKEN id="token-48-13" pos="word" morph="none" start_char="5172" end_char="5180">condition</TOKEN>
<TOKEN id="token-48-14" pos="punct" morph="none" start_char="5181" end_char="5181">,</TOKEN>
<TOKEN id="token-48-15" pos="word" morph="none" start_char="5183" end_char="5191">according</TOKEN>
<TOKEN id="token-48-16" pos="word" morph="none" start_char="5193" end_char="5194">to</TOKEN>
<TOKEN id="token-48-17" pos="word" morph="none" start_char="5196" end_char="5198">the</TOKEN>
<TOKEN id="token-48-18" pos="word" morph="none" start_char="5200" end_char="5202">CDC</TOKEN>
<TOKEN id="token-48-19" pos="punct" morph="none" start_char="5203" end_char="5203">.</TOKEN>
</SEG>
<SEG id="segment-49" start_char="5206" end_char="5321">
<ORIGINAL_TEXT>As for a vaccine, the CDC says it is already working on one with the NIH, but that it is still early in the process.</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="5206" end_char="5207">As</TOKEN>
<TOKEN id="token-49-1" pos="word" morph="none" start_char="5209" end_char="5211">for</TOKEN>
<TOKEN id="token-49-2" pos="word" morph="none" start_char="5213" end_char="5213">a</TOKEN>
<TOKEN id="token-49-3" pos="word" morph="none" start_char="5215" end_char="5221">vaccine</TOKEN>
<TOKEN id="token-49-4" pos="punct" morph="none" start_char="5222" end_char="5222">,</TOKEN>
<TOKEN id="token-49-5" pos="word" morph="none" start_char="5224" end_char="5226">the</TOKEN>
<TOKEN id="token-49-6" pos="word" morph="none" start_char="5228" end_char="5230">CDC</TOKEN>
<TOKEN id="token-49-7" pos="word" morph="none" start_char="5232" end_char="5235">says</TOKEN>
<TOKEN id="token-49-8" pos="word" morph="none" start_char="5237" end_char="5238">it</TOKEN>
<TOKEN id="token-49-9" pos="word" morph="none" start_char="5240" end_char="5241">is</TOKEN>
<TOKEN id="token-49-10" pos="word" morph="none" start_char="5243" end_char="5249">already</TOKEN>
<TOKEN id="token-49-11" pos="word" morph="none" start_char="5251" end_char="5257">working</TOKEN>
<TOKEN id="token-49-12" pos="word" morph="none" start_char="5259" end_char="5260">on</TOKEN>
<TOKEN id="token-49-13" pos="word" morph="none" start_char="5262" end_char="5264">one</TOKEN>
<TOKEN id="token-49-14" pos="word" morph="none" start_char="5266" end_char="5269">with</TOKEN>
<TOKEN id="token-49-15" pos="word" morph="none" start_char="5271" end_char="5273">the</TOKEN>
<TOKEN id="token-49-16" pos="word" morph="none" start_char="5275" end_char="5277">NIH</TOKEN>
<TOKEN id="token-49-17" pos="punct" morph="none" start_char="5278" end_char="5278">,</TOKEN>
<TOKEN id="token-49-18" pos="word" morph="none" start_char="5280" end_char="5282">but</TOKEN>
<TOKEN id="token-49-19" pos="word" morph="none" start_char="5284" end_char="5287">that</TOKEN>
<TOKEN id="token-49-20" pos="word" morph="none" start_char="5289" end_char="5290">it</TOKEN>
<TOKEN id="token-49-21" pos="word" morph="none" start_char="5292" end_char="5293">is</TOKEN>
<TOKEN id="token-49-22" pos="word" morph="none" start_char="5295" end_char="5299">still</TOKEN>
<TOKEN id="token-49-23" pos="word" morph="none" start_char="5301" end_char="5305">early</TOKEN>
<TOKEN id="token-49-24" pos="word" morph="none" start_char="5307" end_char="5308">in</TOKEN>
<TOKEN id="token-49-25" pos="word" morph="none" start_char="5310" end_char="5312">the</TOKEN>
<TOKEN id="token-49-26" pos="word" morph="none" start_char="5314" end_char="5320">process</TOKEN>
<TOKEN id="token-49-27" pos="punct" morph="none" start_char="5321" end_char="5321">.</TOKEN>
</SEG>
<SEG id="segment-50" start_char="5323" end_char="5344">
<ORIGINAL_TEXT>Fauci explained in his</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="5323" end_char="5327">Fauci</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="5329" end_char="5337">explained</TOKEN>
<TOKEN id="token-50-2" pos="word" morph="none" start_char="5339" end_char="5340">in</TOKEN>
<TOKEN id="token-50-3" pos="word" morph="none" start_char="5342" end_char="5344">his</TOKEN>
</SEG>
<SEG id="segment-51" start_char="5347" end_char="5365">
<ORIGINAL_TEXT>Scientific American</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="word" morph="none" start_char="5347" end_char="5356">Scientific</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="5358" end_char="5365">American</TOKEN>
</SEG>
<SEG id="segment-52" start_char="5368" end_char="5480">
<ORIGINAL_TEXT>interview that the agency is partnering with Moderna, a biotech company, to create a messenger RNA-based vaccine.</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="5368" end_char="5376">interview</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="5378" end_char="5381">that</TOKEN>
<TOKEN id="token-52-2" pos="word" morph="none" start_char="5383" end_char="5385">the</TOKEN>
<TOKEN id="token-52-3" pos="word" morph="none" start_char="5387" end_char="5392">agency</TOKEN>
<TOKEN id="token-52-4" pos="word" morph="none" start_char="5394" end_char="5395">is</TOKEN>
<TOKEN id="token-52-5" pos="word" morph="none" start_char="5397" end_char="5406">partnering</TOKEN>
<TOKEN id="token-52-6" pos="word" morph="none" start_char="5408" end_char="5411">with</TOKEN>
<TOKEN id="token-52-7" pos="word" morph="none" start_char="5413" end_char="5419">Moderna</TOKEN>
<TOKEN id="token-52-8" pos="punct" morph="none" start_char="5420" end_char="5420">,</TOKEN>
<TOKEN id="token-52-9" pos="word" morph="none" start_char="5422" end_char="5422">a</TOKEN>
<TOKEN id="token-52-10" pos="word" morph="none" start_char="5424" end_char="5430">biotech</TOKEN>
<TOKEN id="token-52-11" pos="word" morph="none" start_char="5432" end_char="5438">company</TOKEN>
<TOKEN id="token-52-12" pos="punct" morph="none" start_char="5439" end_char="5439">,</TOKEN>
<TOKEN id="token-52-13" pos="word" morph="none" start_char="5441" end_char="5442">to</TOKEN>
<TOKEN id="token-52-14" pos="word" morph="none" start_char="5444" end_char="5449">create</TOKEN>
<TOKEN id="token-52-15" pos="word" morph="none" start_char="5451" end_char="5451">a</TOKEN>
<TOKEN id="token-52-16" pos="word" morph="none" start_char="5453" end_char="5461">messenger</TOKEN>
<TOKEN id="token-52-17" pos="unknown" morph="none" start_char="5463" end_char="5471">RNA-based</TOKEN>
<TOKEN id="token-52-18" pos="word" morph="none" start_char="5473" end_char="5479">vaccine</TOKEN>
<TOKEN id="token-52-19" pos="punct" morph="none" start_char="5480" end_char="5480">.</TOKEN>
</SEG>
<SEG id="segment-53" start_char="5483" end_char="5582">
<ORIGINAL_TEXT>"We will likely have a candidate in early phase I trials for safety in about three months," he said.</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="punct" morph="none" start_char="5483" end_char="5483">"</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="5484" end_char="5485">We</TOKEN>
<TOKEN id="token-53-2" pos="word" morph="none" start_char="5487" end_char="5490">will</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="5492" end_char="5497">likely</TOKEN>
<TOKEN id="token-53-4" pos="word" morph="none" start_char="5499" end_char="5502">have</TOKEN>
<TOKEN id="token-53-5" pos="word" morph="none" start_char="5504" end_char="5504">a</TOKEN>
<TOKEN id="token-53-6" pos="word" morph="none" start_char="5506" end_char="5514">candidate</TOKEN>
<TOKEN id="token-53-7" pos="word" morph="none" start_char="5516" end_char="5517">in</TOKEN>
<TOKEN id="token-53-8" pos="word" morph="none" start_char="5519" end_char="5523">early</TOKEN>
<TOKEN id="token-53-9" pos="word" morph="none" start_char="5525" end_char="5529">phase</TOKEN>
<TOKEN id="token-53-10" pos="word" morph="none" start_char="5531" end_char="5531">I</TOKEN>
<TOKEN id="token-53-11" pos="word" morph="none" start_char="5533" end_char="5538">trials</TOKEN>
<TOKEN id="token-53-12" pos="word" morph="none" start_char="5540" end_char="5542">for</TOKEN>
<TOKEN id="token-53-13" pos="word" morph="none" start_char="5544" end_char="5549">safety</TOKEN>
<TOKEN id="token-53-14" pos="word" morph="none" start_char="5551" end_char="5552">in</TOKEN>
<TOKEN id="token-53-15" pos="word" morph="none" start_char="5554" end_char="5558">about</TOKEN>
<TOKEN id="token-53-16" pos="word" morph="none" start_char="5560" end_char="5564">three</TOKEN>
<TOKEN id="token-53-17" pos="word" morph="none" start_char="5566" end_char="5571">months</TOKEN>
<TOKEN id="token-53-18" pos="punct" morph="none" start_char="5572" end_char="5573">,"</TOKEN>
<TOKEN id="token-53-19" pos="word" morph="none" start_char="5575" end_char="5576">he</TOKEN>
<TOKEN id="token-53-20" pos="word" morph="none" start_char="5578" end_char="5581">said</TOKEN>
<TOKEN id="token-53-21" pos="punct" morph="none" start_char="5582" end_char="5582">.</TOKEN>
</SEG>
<SEG id="segment-54" start_char="5584" end_char="5709">
<ORIGINAL_TEXT>"That doesn’t mean we will have a vaccine ready for use in three months; even in an emergency, that would take a year or more.</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="punct" morph="none" start_char="5584" end_char="5584">"</TOKEN>
<TOKEN id="token-54-1" pos="word" morph="none" start_char="5585" end_char="5588">That</TOKEN>
<TOKEN id="token-54-2" pos="word" morph="none" start_char="5590" end_char="5596">doesn’t</TOKEN>
<TOKEN id="token-54-3" pos="word" morph="none" start_char="5598" end_char="5601">mean</TOKEN>
<TOKEN id="token-54-4" pos="word" morph="none" start_char="5603" end_char="5604">we</TOKEN>
<TOKEN id="token-54-5" pos="word" morph="none" start_char="5606" end_char="5609">will</TOKEN>
<TOKEN id="token-54-6" pos="word" morph="none" start_char="5611" end_char="5614">have</TOKEN>
<TOKEN id="token-54-7" pos="word" morph="none" start_char="5616" end_char="5616">a</TOKEN>
<TOKEN id="token-54-8" pos="word" morph="none" start_char="5618" end_char="5624">vaccine</TOKEN>
<TOKEN id="token-54-9" pos="word" morph="none" start_char="5626" end_char="5630">ready</TOKEN>
<TOKEN id="token-54-10" pos="word" morph="none" start_char="5632" end_char="5634">for</TOKEN>
<TOKEN id="token-54-11" pos="word" morph="none" start_char="5636" end_char="5638">use</TOKEN>
<TOKEN id="token-54-12" pos="word" morph="none" start_char="5640" end_char="5641">in</TOKEN>
<TOKEN id="token-54-13" pos="word" morph="none" start_char="5643" end_char="5647">three</TOKEN>
<TOKEN id="token-54-14" pos="word" morph="none" start_char="5649" end_char="5654">months</TOKEN>
<TOKEN id="token-54-15" pos="punct" morph="none" start_char="5655" end_char="5655">;</TOKEN>
<TOKEN id="token-54-16" pos="word" morph="none" start_char="5657" end_char="5660">even</TOKEN>
<TOKEN id="token-54-17" pos="word" morph="none" start_char="5662" end_char="5663">in</TOKEN>
<TOKEN id="token-54-18" pos="word" morph="none" start_char="5665" end_char="5666">an</TOKEN>
<TOKEN id="token-54-19" pos="word" morph="none" start_char="5668" end_char="5676">emergency</TOKEN>
<TOKEN id="token-54-20" pos="punct" morph="none" start_char="5677" end_char="5677">,</TOKEN>
<TOKEN id="token-54-21" pos="word" morph="none" start_char="5679" end_char="5682">that</TOKEN>
<TOKEN id="token-54-22" pos="word" morph="none" start_char="5684" end_char="5688">would</TOKEN>
<TOKEN id="token-54-23" pos="word" morph="none" start_char="5690" end_char="5693">take</TOKEN>
<TOKEN id="token-54-24" pos="word" morph="none" start_char="5695" end_char="5695">a</TOKEN>
<TOKEN id="token-54-25" pos="word" morph="none" start_char="5697" end_char="5700">year</TOKEN>
<TOKEN id="token-54-26" pos="word" morph="none" start_char="5702" end_char="5703">or</TOKEN>
<TOKEN id="token-54-27" pos="word" morph="none" start_char="5705" end_char="5708">more</TOKEN>
<TOKEN id="token-54-28" pos="punct" morph="none" start_char="5709" end_char="5709">.</TOKEN>
</SEG>
<SEG id="segment-55" start_char="5711" end_char="5735">
<ORIGINAL_TEXT>But we’re already on it."</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="word" morph="none" start_char="5711" end_char="5713">But</TOKEN>
<TOKEN id="token-55-1" pos="word" morph="none" start_char="5715" end_char="5719">we’re</TOKEN>
<TOKEN id="token-55-2" pos="word" morph="none" start_char="5721" end_char="5727">already</TOKEN>
<TOKEN id="token-55-3" pos="word" morph="none" start_char="5729" end_char="5730">on</TOKEN>
<TOKEN id="token-55-4" pos="word" morph="none" start_char="5732" end_char="5733">it</TOKEN>
<TOKEN id="token-55-5" pos="punct" morph="none" start_char="5734" end_char="5735">."</TOKEN>
</SEG>
<SEG id="segment-56" start_char="5738" end_char="6023">
<ORIGINAL_TEXT>So while efforts have begun to make a vaccine, in part thanks to Chinese researchers who have already shared the sequence of the new virus, it is not true that a vaccine already exists — just as claims that the virus previously had a patent and was manufactured in a lab are also false.</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="5738" end_char="5739">So</TOKEN>
<TOKEN id="token-56-1" pos="word" morph="none" start_char="5741" end_char="5745">while</TOKEN>
<TOKEN id="token-56-2" pos="word" morph="none" start_char="5747" end_char="5753">efforts</TOKEN>
<TOKEN id="token-56-3" pos="word" morph="none" start_char="5755" end_char="5758">have</TOKEN>
<TOKEN id="token-56-4" pos="word" morph="none" start_char="5760" end_char="5764">begun</TOKEN>
<TOKEN id="token-56-5" pos="word" morph="none" start_char="5766" end_char="5767">to</TOKEN>
<TOKEN id="token-56-6" pos="word" morph="none" start_char="5769" end_char="5772">make</TOKEN>
<TOKEN id="token-56-7" pos="word" morph="none" start_char="5774" end_char="5774">a</TOKEN>
<TOKEN id="token-56-8" pos="word" morph="none" start_char="5776" end_char="5782">vaccine</TOKEN>
<TOKEN id="token-56-9" pos="punct" morph="none" start_char="5783" end_char="5783">,</TOKEN>
<TOKEN id="token-56-10" pos="word" morph="none" start_char="5785" end_char="5786">in</TOKEN>
<TOKEN id="token-56-11" pos="word" morph="none" start_char="5788" end_char="5791">part</TOKEN>
<TOKEN id="token-56-12" pos="word" morph="none" start_char="5793" end_char="5798">thanks</TOKEN>
<TOKEN id="token-56-13" pos="word" morph="none" start_char="5800" end_char="5801">to</TOKEN>
<TOKEN id="token-56-14" pos="word" morph="none" start_char="5803" end_char="5809">Chinese</TOKEN>
<TOKEN id="token-56-15" pos="word" morph="none" start_char="5811" end_char="5821">researchers</TOKEN>
<TOKEN id="token-56-16" pos="word" morph="none" start_char="5823" end_char="5825">who</TOKEN>
<TOKEN id="token-56-17" pos="word" morph="none" start_char="5827" end_char="5830">have</TOKEN>
<TOKEN id="token-56-18" pos="word" morph="none" start_char="5832" end_char="5838">already</TOKEN>
<TOKEN id="token-56-19" pos="word" morph="none" start_char="5840" end_char="5845">shared</TOKEN>
<TOKEN id="token-56-20" pos="word" morph="none" start_char="5847" end_char="5849">the</TOKEN>
<TOKEN id="token-56-21" pos="word" morph="none" start_char="5851" end_char="5858">sequence</TOKEN>
<TOKEN id="token-56-22" pos="word" morph="none" start_char="5860" end_char="5861">of</TOKEN>
<TOKEN id="token-56-23" pos="word" morph="none" start_char="5863" end_char="5865">the</TOKEN>
<TOKEN id="token-56-24" pos="word" morph="none" start_char="5867" end_char="5869">new</TOKEN>
<TOKEN id="token-56-25" pos="word" morph="none" start_char="5871" end_char="5875">virus</TOKEN>
<TOKEN id="token-56-26" pos="punct" morph="none" start_char="5876" end_char="5876">,</TOKEN>
<TOKEN id="token-56-27" pos="word" morph="none" start_char="5878" end_char="5879">it</TOKEN>
<TOKEN id="token-56-28" pos="word" morph="none" start_char="5881" end_char="5882">is</TOKEN>
<TOKEN id="token-56-29" pos="word" morph="none" start_char="5884" end_char="5886">not</TOKEN>
<TOKEN id="token-56-30" pos="word" morph="none" start_char="5888" end_char="5891">true</TOKEN>
<TOKEN id="token-56-31" pos="word" morph="none" start_char="5893" end_char="5896">that</TOKEN>
<TOKEN id="token-56-32" pos="word" morph="none" start_char="5898" end_char="5898">a</TOKEN>
<TOKEN id="token-56-33" pos="word" morph="none" start_char="5900" end_char="5906">vaccine</TOKEN>
<TOKEN id="token-56-34" pos="word" morph="none" start_char="5908" end_char="5914">already</TOKEN>
<TOKEN id="token-56-35" pos="word" morph="none" start_char="5916" end_char="5921">exists</TOKEN>
<TOKEN id="token-56-36" pos="punct" morph="none" start_char="5923" end_char="5923">—</TOKEN>
<TOKEN id="token-56-37" pos="word" morph="none" start_char="5925" end_char="5928">just</TOKEN>
<TOKEN id="token-56-38" pos="word" morph="none" start_char="5930" end_char="5931">as</TOKEN>
<TOKEN id="token-56-39" pos="word" morph="none" start_char="5933" end_char="5938">claims</TOKEN>
<TOKEN id="token-56-40" pos="word" morph="none" start_char="5940" end_char="5943">that</TOKEN>
<TOKEN id="token-56-41" pos="word" morph="none" start_char="5945" end_char="5947">the</TOKEN>
<TOKEN id="token-56-42" pos="word" morph="none" start_char="5949" end_char="5953">virus</TOKEN>
<TOKEN id="token-56-43" pos="word" morph="none" start_char="5955" end_char="5964">previously</TOKEN>
<TOKEN id="token-56-44" pos="word" morph="none" start_char="5966" end_char="5968">had</TOKEN>
<TOKEN id="token-56-45" pos="word" morph="none" start_char="5970" end_char="5970">a</TOKEN>
<TOKEN id="token-56-46" pos="word" morph="none" start_char="5972" end_char="5977">patent</TOKEN>
<TOKEN id="token-56-47" pos="word" morph="none" start_char="5979" end_char="5981">and</TOKEN>
<TOKEN id="token-56-48" pos="word" morph="none" start_char="5983" end_char="5985">was</TOKEN>
<TOKEN id="token-56-49" pos="word" morph="none" start_char="5987" end_char="5998">manufactured</TOKEN>
<TOKEN id="token-56-50" pos="word" morph="none" start_char="6000" end_char="6001">in</TOKEN>
<TOKEN id="token-56-51" pos="word" morph="none" start_char="6003" end_char="6003">a</TOKEN>
<TOKEN id="token-56-52" pos="word" morph="none" start_char="6005" end_char="6007">lab</TOKEN>
<TOKEN id="token-56-53" pos="word" morph="none" start_char="6009" end_char="6011">are</TOKEN>
<TOKEN id="token-56-54" pos="word" morph="none" start_char="6013" end_char="6016">also</TOKEN>
<TOKEN id="token-56-55" pos="word" morph="none" start_char="6018" end_char="6022">false</TOKEN>
<TOKEN id="token-56-56" pos="punct" morph="none" start_char="6023" end_char="6023">.</TOKEN>
</SEG>
<SEG id="segment-57" start_char="6026" end_char="6085">
<ORIGINAL_TEXT>Editor’s note: FactCheck.org is one of several organizations</ORIGINAL_TEXT>
<TOKEN id="token-57-0" pos="word" morph="none" start_char="6026" end_char="6033">Editor’s</TOKEN>
<TOKEN id="token-57-1" pos="word" morph="none" start_char="6035" end_char="6038">note</TOKEN>
<TOKEN id="token-57-2" pos="punct" morph="none" start_char="6039" end_char="6039">:</TOKEN>
<TOKEN id="token-57-3" pos="unknown" morph="none" start_char="6041" end_char="6053">FactCheck.org</TOKEN>
<TOKEN id="token-57-4" pos="word" morph="none" start_char="6055" end_char="6056">is</TOKEN>
<TOKEN id="token-57-5" pos="word" morph="none" start_char="6058" end_char="6060">one</TOKEN>
<TOKEN id="token-57-6" pos="word" morph="none" start_char="6062" end_char="6063">of</TOKEN>
<TOKEN id="token-57-7" pos="word" morph="none" start_char="6065" end_char="6071">several</TOKEN>
<TOKEN id="token-57-8" pos="word" morph="none" start_char="6073" end_char="6085">organizations</TOKEN>
</SEG>
<SEG id="segment-58" start_char="6088" end_char="6108">
<ORIGINAL_TEXT>working with Facebook</ORIGINAL_TEXT>
<TOKEN id="token-58-0" pos="word" morph="none" start_char="6088" end_char="6094">working</TOKEN>
<TOKEN id="token-58-1" pos="word" morph="none" start_char="6096" end_char="6099">with</TOKEN>
<TOKEN id="token-58-2" pos="word" morph="none" start_char="6101" end_char="6108">Facebook</TOKEN>
</SEG>
<SEG id="segment-59" start_char="6111" end_char="6158">
<ORIGINAL_TEXT>to debunk misinformation shared on social media.</ORIGINAL_TEXT>
<TOKEN id="token-59-0" pos="word" morph="none" start_char="6111" end_char="6112">to</TOKEN>
<TOKEN id="token-59-1" pos="word" morph="none" start_char="6114" end_char="6119">debunk</TOKEN>
<TOKEN id="token-59-2" pos="word" morph="none" start_char="6121" end_char="6134">misinformation</TOKEN>
<TOKEN id="token-59-3" pos="word" morph="none" start_char="6136" end_char="6141">shared</TOKEN>
<TOKEN id="token-59-4" pos="word" morph="none" start_char="6143" end_char="6144">on</TOKEN>
<TOKEN id="token-59-5" pos="word" morph="none" start_char="6146" end_char="6151">social</TOKEN>
<TOKEN id="token-59-6" pos="word" morph="none" start_char="6153" end_char="6157">media</TOKEN>
<TOKEN id="token-59-7" pos="punct" morph="none" start_char="6158" end_char="6158">.</TOKEN>
</SEG>
<SEG id="segment-60" start_char="6160" end_char="6198">
<ORIGINAL_TEXT>Our previous stories can be found here.</ORIGINAL_TEXT>
<TOKEN id="token-60-0" pos="word" morph="none" start_char="6160" end_char="6162">Our</TOKEN>
<TOKEN id="token-60-1" pos="word" morph="none" start_char="6164" end_char="6171">previous</TOKEN>
<TOKEN id="token-60-2" pos="word" morph="none" start_char="6173" end_char="6179">stories</TOKEN>
<TOKEN id="token-60-3" pos="word" morph="none" start_char="6181" end_char="6183">can</TOKEN>
<TOKEN id="token-60-4" pos="word" morph="none" start_char="6185" end_char="6186">be</TOKEN>
<TOKEN id="token-60-5" pos="word" morph="none" start_char="6188" end_char="6192">found</TOKEN>
<TOKEN id="token-60-6" pos="word" morph="none" start_char="6194" end_char="6197">here</TOKEN>
<TOKEN id="token-60-7" pos="punct" morph="none" start_char="6198" end_char="6198">.</TOKEN>
</SEG>
<SEG id="segment-61" start_char="6202" end_char="6208">
<ORIGINAL_TEXT>Sources</ORIGINAL_TEXT>
<TOKEN id="token-61-0" pos="word" morph="none" start_char="6202" end_char="6208">Sources</TOKEN>
</SEG>
<SEG id="segment-62" start_char="6212" end_char="6291">
<ORIGINAL_TEXT>"First Travel-related Case of 2019 Novel Coronavirus Detected in United States."</ORIGINAL_TEXT>
<TOKEN id="token-62-0" pos="punct" morph="none" start_char="6212" end_char="6212">"</TOKEN>
<TOKEN id="token-62-1" pos="word" morph="none" start_char="6213" end_char="6217">First</TOKEN>
<TOKEN id="token-62-2" pos="unknown" morph="none" start_char="6219" end_char="6232">Travel-related</TOKEN>
<TOKEN id="token-62-3" pos="word" morph="none" start_char="6234" end_char="6237">Case</TOKEN>
<TOKEN id="token-62-4" pos="word" morph="none" start_char="6239" end_char="6240">of</TOKEN>
<TOKEN id="token-62-5" pos="word" morph="none" start_char="6242" end_char="6245">2019</TOKEN>
<TOKEN id="token-62-6" pos="word" morph="none" start_char="6247" end_char="6251">Novel</TOKEN>
<TOKEN id="token-62-7" pos="word" morph="none" start_char="6253" end_char="6263">Coronavirus</TOKEN>
<TOKEN id="token-62-8" pos="word" morph="none" start_char="6265" end_char="6272">Detected</TOKEN>
<TOKEN id="token-62-9" pos="word" morph="none" start_char="6274" end_char="6275">in</TOKEN>
<TOKEN id="token-62-10" pos="word" morph="none" start_char="6277" end_char="6282">United</TOKEN>
<TOKEN id="token-62-11" pos="word" morph="none" start_char="6284" end_char="6289">States</TOKEN>
<TOKEN id="token-62-12" pos="punct" morph="none" start_char="6290" end_char="6291">."</TOKEN>
</SEG>
<SEG id="segment-63" start_char="6293" end_char="6306">
<ORIGINAL_TEXT>Press release.</ORIGINAL_TEXT>
<TOKEN id="token-63-0" pos="word" morph="none" start_char="6293" end_char="6297">Press</TOKEN>
<TOKEN id="token-63-1" pos="word" morph="none" start_char="6299" end_char="6305">release</TOKEN>
<TOKEN id="token-63-2" pos="punct" morph="none" start_char="6306" end_char="6306">.</TOKEN>
</SEG>
<SEG id="segment-64" start_char="6308" end_char="6311">
<ORIGINAL_TEXT>CDC.</ORIGINAL_TEXT>
<TOKEN id="token-64-0" pos="word" morph="none" start_char="6308" end_char="6310">CDC</TOKEN>
<TOKEN id="token-64-1" pos="punct" morph="none" start_char="6311" end_char="6311">.</TOKEN>
</SEG>
<SEG id="segment-65" start_char="6313" end_char="6324">
<ORIGINAL_TEXT>21 Jan 2020.</ORIGINAL_TEXT>
<TOKEN id="token-65-0" pos="word" morph="none" start_char="6313" end_char="6314">21</TOKEN>
<TOKEN id="token-65-1" pos="word" morph="none" start_char="6316" end_char="6318">Jan</TOKEN>
<TOKEN id="token-65-2" pos="word" morph="none" start_char="6320" end_char="6323">2020</TOKEN>
<TOKEN id="token-65-3" pos="punct" morph="none" start_char="6324" end_char="6324">.</TOKEN>
</SEG>
<SEG id="segment-66" start_char="6327" end_char="6339">
<ORIGINAL_TEXT>Lewis, Tayna.</ORIGINAL_TEXT>
<TOKEN id="token-66-0" pos="word" morph="none" start_char="6327" end_char="6331">Lewis</TOKEN>
<TOKEN id="token-66-1" pos="punct" morph="none" start_char="6332" end_char="6332">,</TOKEN>
<TOKEN id="token-66-2" pos="word" morph="none" start_char="6334" end_char="6338">Tayna</TOKEN>
<TOKEN id="token-66-3" pos="punct" morph="none" start_char="6339" end_char="6339">.</TOKEN>
</SEG>
<SEG id="segment-67" start_char="6341" end_char="6419">
<ORIGINAL_TEXT>"Infectious Disease Expert Discusses What We Know about the New Chinese Virus."</ORIGINAL_TEXT>
<TOKEN id="token-67-0" pos="punct" morph="none" start_char="6341" end_char="6341">"</TOKEN>
<TOKEN id="token-67-1" pos="word" morph="none" start_char="6342" end_char="6351">Infectious</TOKEN>
<TOKEN id="token-67-2" pos="word" morph="none" start_char="6353" end_char="6359">Disease</TOKEN>
<TOKEN id="token-67-3" pos="word" morph="none" start_char="6361" end_char="6366">Expert</TOKEN>
<TOKEN id="token-67-4" pos="word" morph="none" start_char="6368" end_char="6376">Discusses</TOKEN>
<TOKEN id="token-67-5" pos="word" morph="none" start_char="6378" end_char="6381">What</TOKEN>
<TOKEN id="token-67-6" pos="word" morph="none" start_char="6383" end_char="6384">We</TOKEN>
<TOKEN id="token-67-7" pos="word" morph="none" start_char="6386" end_char="6389">Know</TOKEN>
<TOKEN id="token-67-8" pos="word" morph="none" start_char="6391" end_char="6395">about</TOKEN>
<TOKEN id="token-67-9" pos="word" morph="none" start_char="6397" end_char="6399">the</TOKEN>
<TOKEN id="token-67-10" pos="word" morph="none" start_char="6401" end_char="6403">New</TOKEN>
<TOKEN id="token-67-11" pos="word" morph="none" start_char="6405" end_char="6411">Chinese</TOKEN>
<TOKEN id="token-67-12" pos="word" morph="none" start_char="6413" end_char="6417">Virus</TOKEN>
<TOKEN id="token-67-13" pos="punct" morph="none" start_char="6418" end_char="6419">."</TOKEN>
</SEG>
<SEG id="segment-68" start_char="6421" end_char="6440">
<ORIGINAL_TEXT>Scientific American.</ORIGINAL_TEXT>
<TOKEN id="token-68-0" pos="word" morph="none" start_char="6421" end_char="6430">Scientific</TOKEN>
<TOKEN id="token-68-1" pos="word" morph="none" start_char="6432" end_char="6439">American</TOKEN>
<TOKEN id="token-68-2" pos="punct" morph="none" start_char="6440" end_char="6440">.</TOKEN>
</SEG>
<SEG id="segment-69" start_char="6442" end_char="6453">
<ORIGINAL_TEXT>22 Jan 2020.</ORIGINAL_TEXT>
<TOKEN id="token-69-0" pos="word" morph="none" start_char="6442" end_char="6443">22</TOKEN>
<TOKEN id="token-69-1" pos="word" morph="none" start_char="6445" end_char="6447">Jan</TOKEN>
<TOKEN id="token-69-2" pos="word" morph="none" start_char="6449" end_char="6452">2020</TOKEN>
<TOKEN id="token-69-3" pos="punct" morph="none" start_char="6453" end_char="6453">.</TOKEN>
</SEG>
<SEG id="segment-70" start_char="6456" end_char="6472">
<ORIGINAL_TEXT>Branswell, Helen.</ORIGINAL_TEXT>
<TOKEN id="token-70-0" pos="word" morph="none" start_char="6456" end_char="6464">Branswell</TOKEN>
<TOKEN id="token-70-1" pos="punct" morph="none" start_char="6465" end_char="6465">,</TOKEN>
<TOKEN id="token-70-2" pos="word" morph="none" start_char="6467" end_char="6471">Helen</TOKEN>
<TOKEN id="token-70-3" pos="punct" morph="none" start_char="6472" end_char="6472">.</TOKEN>
</SEG>
<SEG id="segment-71" start_char="6474" end_char="6494">
<ORIGINAL_TEXT>"It’s been sequenced.</ORIGINAL_TEXT>
<TOKEN id="token-71-0" pos="punct" morph="none" start_char="6474" end_char="6474">"</TOKEN>
<TOKEN id="token-71-1" pos="word" morph="none" start_char="6475" end_char="6478">It’s</TOKEN>
<TOKEN id="token-71-2" pos="word" morph="none" start_char="6480" end_char="6483">been</TOKEN>
<TOKEN id="token-71-3" pos="word" morph="none" start_char="6485" end_char="6493">sequenced</TOKEN>
<TOKEN id="token-71-4" pos="punct" morph="none" start_char="6494" end_char="6494">.</TOKEN>
</SEG>
<SEG id="segment-72" start_char="6496" end_char="6522">
<ORIGINAL_TEXT>It’s spread across borders.</ORIGINAL_TEXT>
<TOKEN id="token-72-0" pos="word" morph="none" start_char="6496" end_char="6499">It’s</TOKEN>
<TOKEN id="token-72-1" pos="word" morph="none" start_char="6501" end_char="6506">spread</TOKEN>
<TOKEN id="token-72-2" pos="word" morph="none" start_char="6508" end_char="6513">across</TOKEN>
<TOKEN id="token-72-3" pos="word" morph="none" start_char="6515" end_char="6521">borders</TOKEN>
<TOKEN id="token-72-4" pos="punct" morph="none" start_char="6522" end_char="6522">.</TOKEN>
</SEG>
<SEG id="segment-73" start_char="6524" end_char="6573">
<ORIGINAL_TEXT>Now the new pneumonia-causing virus needs a name."</ORIGINAL_TEXT>
<TOKEN id="token-73-0" pos="word" morph="none" start_char="6524" end_char="6526">Now</TOKEN>
<TOKEN id="token-73-1" pos="word" morph="none" start_char="6528" end_char="6530">the</TOKEN>
<TOKEN id="token-73-2" pos="word" morph="none" start_char="6532" end_char="6534">new</TOKEN>
<TOKEN id="token-73-3" pos="unknown" morph="none" start_char="6536" end_char="6552">pneumonia-causing</TOKEN>
<TOKEN id="token-73-4" pos="word" morph="none" start_char="6554" end_char="6558">virus</TOKEN>
<TOKEN id="token-73-5" pos="word" morph="none" start_char="6560" end_char="6564">needs</TOKEN>
<TOKEN id="token-73-6" pos="word" morph="none" start_char="6566" end_char="6566">a</TOKEN>
<TOKEN id="token-73-7" pos="word" morph="none" start_char="6568" end_char="6571">name</TOKEN>
<TOKEN id="token-73-8" pos="punct" morph="none" start_char="6572" end_char="6573">."</TOKEN>
</SEG>
<SEG id="segment-74" start_char="6575" end_char="6579">
<ORIGINAL_TEXT>STAT.</ORIGINAL_TEXT>
<TOKEN id="token-74-0" pos="word" morph="none" start_char="6575" end_char="6578">STAT</TOKEN>
<TOKEN id="token-74-1" pos="punct" morph="none" start_char="6579" end_char="6579">.</TOKEN>
</SEG>
<SEG id="segment-75" start_char="6581" end_char="6592">
<ORIGINAL_TEXT>23 Jan 2020.</ORIGINAL_TEXT>
<TOKEN id="token-75-0" pos="word" morph="none" start_char="6581" end_char="6582">23</TOKEN>
<TOKEN id="token-75-1" pos="word" morph="none" start_char="6584" end_char="6586">Jan</TOKEN>
<TOKEN id="token-75-2" pos="word" morph="none" start_char="6588" end_char="6591">2020</TOKEN>
<TOKEN id="token-75-3" pos="punct" morph="none" start_char="6592" end_char="6592">.</TOKEN>
</SEG>
<SEG id="segment-76" start_char="6595" end_char="6631">
<ORIGINAL_TEXT>2019 Novel Coronavirus, Wuhan, China.</ORIGINAL_TEXT>
<TOKEN id="token-76-0" pos="word" morph="none" start_char="6595" end_char="6598">2019</TOKEN>
<TOKEN id="token-76-1" pos="word" morph="none" start_char="6600" end_char="6604">Novel</TOKEN>
<TOKEN id="token-76-2" pos="word" morph="none" start_char="6606" end_char="6616">Coronavirus</TOKEN>
<TOKEN id="token-76-3" pos="punct" morph="none" start_char="6617" end_char="6617">,</TOKEN>
<TOKEN id="token-76-4" pos="word" morph="none" start_char="6619" end_char="6623">Wuhan</TOKEN>
<TOKEN id="token-76-5" pos="punct" morph="none" start_char="6624" end_char="6624">,</TOKEN>
<TOKEN id="token-76-6" pos="word" morph="none" start_char="6626" end_char="6630">China</TOKEN>
<TOKEN id="token-76-7" pos="punct" morph="none" start_char="6631" end_char="6631">.</TOKEN>
</SEG>
<SEG id="segment-77" start_char="6633" end_char="6636">
<ORIGINAL_TEXT>CDC.</ORIGINAL_TEXT>
<TOKEN id="token-77-0" pos="word" morph="none" start_char="6633" end_char="6635">CDC</TOKEN>
<TOKEN id="token-77-1" pos="punct" morph="none" start_char="6636" end_char="6636">.</TOKEN>
</SEG>
<SEG id="segment-78" start_char="6638" end_char="6658">
<ORIGINAL_TEXT>Accessed 23 Jan 2020.</ORIGINAL_TEXT>
<TOKEN id="token-78-0" pos="word" morph="none" start_char="6638" end_char="6645">Accessed</TOKEN>
<TOKEN id="token-78-1" pos="word" morph="none" start_char="6647" end_char="6648">23</TOKEN>
<TOKEN id="token-78-2" pos="word" morph="none" start_char="6650" end_char="6652">Jan</TOKEN>
<TOKEN id="token-78-3" pos="word" morph="none" start_char="6654" end_char="6657">2020</TOKEN>
<TOKEN id="token-78-4" pos="punct" morph="none" start_char="6658" end_char="6658">.</TOKEN>
</SEG>
<SEG id="segment-79" start_char="6661" end_char="6701">
<ORIGINAL_TEXT>Severe Acute Respiratory Syndrome (SARS).</ORIGINAL_TEXT>
<TOKEN id="token-79-0" pos="word" morph="none" start_char="6661" end_char="6666">Severe</TOKEN>
<TOKEN id="token-79-1" pos="word" morph="none" start_char="6668" end_char="6672">Acute</TOKEN>
<TOKEN id="token-79-2" pos="word" morph="none" start_char="6674" end_char="6684">Respiratory</TOKEN>
<TOKEN id="token-79-3" pos="word" morph="none" start_char="6686" end_char="6693">Syndrome</TOKEN>
<TOKEN id="token-79-4" pos="punct" morph="none" start_char="6695" end_char="6695">(</TOKEN>
<TOKEN id="token-79-5" pos="word" morph="none" start_char="6696" end_char="6699">SARS</TOKEN>
<TOKEN id="token-79-6" pos="punct" morph="none" start_char="6700" end_char="6701">).</TOKEN>
</SEG>
<SEG id="segment-80" start_char="6703" end_char="6706">
<ORIGINAL_TEXT>CDC.</ORIGINAL_TEXT>
<TOKEN id="token-80-0" pos="word" morph="none" start_char="6703" end_char="6705">CDC</TOKEN>
<TOKEN id="token-80-1" pos="punct" morph="none" start_char="6706" end_char="6706">.</TOKEN>
</SEG>
<SEG id="segment-81" start_char="6708" end_char="6728">
<ORIGINAL_TEXT>Accessed 23 Jan 2020.</ORIGINAL_TEXT>
<TOKEN id="token-81-0" pos="word" morph="none" start_char="6708" end_char="6715">Accessed</TOKEN>
<TOKEN id="token-81-1" pos="word" morph="none" start_char="6717" end_char="6718">23</TOKEN>
<TOKEN id="token-81-2" pos="word" morph="none" start_char="6720" end_char="6722">Jan</TOKEN>
<TOKEN id="token-81-3" pos="word" morph="none" start_char="6724" end_char="6727">2020</TOKEN>
<TOKEN id="token-81-4" pos="punct" morph="none" start_char="6728" end_char="6728">.</TOKEN>
</SEG>
<SEG id="segment-82" start_char="6731" end_char="6742">
<ORIGINAL_TEXT>Coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-82-0" pos="word" morph="none" start_char="6731" end_char="6741">Coronavirus</TOKEN>
<TOKEN id="token-82-1" pos="punct" morph="none" start_char="6742" end_char="6742">.</TOKEN>
</SEG>
<SEG id="segment-83" start_char="6744" end_char="6747">
<ORIGINAL_TEXT>CDC.</ORIGINAL_TEXT>
<TOKEN id="token-83-0" pos="word" morph="none" start_char="6744" end_char="6746">CDC</TOKEN>
<TOKEN id="token-83-1" pos="punct" morph="none" start_char="6747" end_char="6747">.</TOKEN>
</SEG>
<SEG id="segment-84" start_char="6749" end_char="6769">
<ORIGINAL_TEXT>Accessed 23 Jan 2020.</ORIGINAL_TEXT>
<TOKEN id="token-84-0" pos="word" morph="none" start_char="6749" end_char="6756">Accessed</TOKEN>
<TOKEN id="token-84-1" pos="word" morph="none" start_char="6758" end_char="6759">23</TOKEN>
<TOKEN id="token-84-2" pos="word" morph="none" start_char="6761" end_char="6763">Jan</TOKEN>
<TOKEN id="token-84-3" pos="word" morph="none" start_char="6765" end_char="6768">2020</TOKEN>
<TOKEN id="token-84-4" pos="punct" morph="none" start_char="6769" end_char="6769">.</TOKEN>
</SEG>
<SEG id="segment-85" start_char="6772" end_char="6804">
<ORIGINAL_TEXT>Coronavirus isolated from humans.</ORIGINAL_TEXT>
<TOKEN id="token-85-0" pos="word" morph="none" start_char="6772" end_char="6782">Coronavirus</TOKEN>
<TOKEN id="token-85-1" pos="word" morph="none" start_char="6784" end_char="6791">isolated</TOKEN>
<TOKEN id="token-85-2" pos="word" morph="none" start_char="6793" end_char="6796">from</TOKEN>
<TOKEN id="token-85-3" pos="word" morph="none" start_char="6798" end_char="6803">humans</TOKEN>
<TOKEN id="token-85-4" pos="punct" morph="none" start_char="6804" end_char="6804">.</TOKEN>
</SEG>
<SEG id="segment-86" start_char="6806" end_char="6821">
<ORIGINAL_TEXT>U.S. Patent, no.</ORIGINAL_TEXT>
<TOKEN id="token-86-0" pos="unknown" morph="none" start_char="6806" end_char="6808">U.S</TOKEN>
<TOKEN id="token-86-1" pos="punct" morph="none" start_char="6809" end_char="6809">.</TOKEN>
<TOKEN id="token-86-2" pos="word" morph="none" start_char="6811" end_char="6816">Patent</TOKEN>
<TOKEN id="token-86-3" pos="punct" morph="none" start_char="6817" end_char="6817">,</TOKEN>
<TOKEN id="token-86-4" pos="word" morph="none" start_char="6819" end_char="6820">no</TOKEN>
<TOKEN id="token-86-5" pos="punct" morph="none" start_char="6821" end_char="6821">.</TOKEN>
</SEG>
<SEG id="segment-87" start_char="6823" end_char="6832">
<ORIGINAL_TEXT>7220852B1.</ORIGINAL_TEXT>
<TOKEN id="token-87-0" pos="word" morph="none" start_char="6823" end_char="6831">7220852B1</TOKEN>
<TOKEN id="token-87-1" pos="punct" morph="none" start_char="6832" end_char="6832">.</TOKEN>
</SEG>
<SEG id="segment-88" start_char="6835" end_char="6848">
<ORIGINAL_TEXT>Bickerton, et.</ORIGINAL_TEXT>
<TOKEN id="token-88-0" pos="word" morph="none" start_char="6835" end_char="6843">Bickerton</TOKEN>
<TOKEN id="token-88-1" pos="punct" morph="none" start_char="6844" end_char="6844">,</TOKEN>
<TOKEN id="token-88-2" pos="word" morph="none" start_char="6846" end_char="6847">et</TOKEN>
<TOKEN id="token-88-3" pos="punct" morph="none" start_char="6848" end_char="6848">.</TOKEN>
</SEG>
<SEG id="segment-89" start_char="6850" end_char="6852">
<ORIGINAL_TEXT>al.</ORIGINAL_TEXT>
<TOKEN id="token-89-0" pos="word" morph="none" start_char="6850" end_char="6851">al</TOKEN>
<TOKEN id="token-89-1" pos="punct" morph="none" start_char="6852" end_char="6852">.</TOKEN>
</SEG>
<SEG id="segment-90" start_char="6854" end_char="6869">
<ORIGINAL_TEXT>U.S. Patent, no.</ORIGINAL_TEXT>
<TOKEN id="token-90-0" pos="unknown" morph="none" start_char="6854" end_char="6856">U.S</TOKEN>
<TOKEN id="token-90-1" pos="punct" morph="none" start_char="6857" end_char="6857">.</TOKEN>
<TOKEN id="token-90-2" pos="word" morph="none" start_char="6859" end_char="6864">Patent</TOKEN>
<TOKEN id="token-90-3" pos="punct" morph="none" start_char="6865" end_char="6865">,</TOKEN>
<TOKEN id="token-90-4" pos="word" morph="none" start_char="6867" end_char="6868">no</TOKEN>
<TOKEN id="token-90-5" pos="punct" morph="none" start_char="6869" end_char="6869">.</TOKEN>
</SEG>
<SEG id="segment-91" start_char="6871" end_char="6879">
<ORIGINAL_TEXT>10130701.</ORIGINAL_TEXT>
<TOKEN id="token-91-0" pos="word" morph="none" start_char="6871" end_char="6878">10130701</TOKEN>
<TOKEN id="token-91-1" pos="punct" morph="none" start_char="6879" end_char="6879">.</TOKEN>
</SEG>
<SEG id="segment-92" start_char="6881" end_char="6885">
<ORIGINAL_TEXT>2018.</ORIGINAL_TEXT>
<TOKEN id="token-92-0" pos="word" morph="none" start_char="6881" end_char="6884">2018</TOKEN>
<TOKEN id="token-92-1" pos="punct" morph="none" start_char="6885" end_char="6885">.</TOKEN>
</SEG>
<SEG id="segment-93" start_char="6888" end_char="6904">
<ORIGINAL_TEXT>Frieman, Matthew.</ORIGINAL_TEXT>
<TOKEN id="token-93-0" pos="word" morph="none" start_char="6888" end_char="6894">Frieman</TOKEN>
<TOKEN id="token-93-1" pos="punct" morph="none" start_char="6895" end_char="6895">,</TOKEN>
<TOKEN id="token-93-2" pos="word" morph="none" start_char="6897" end_char="6903">Matthew</TOKEN>
<TOKEN id="token-93-3" pos="punct" morph="none" start_char="6904" end_char="6904">.</TOKEN>
</SEG>
<SEG id="segment-94" start_char="6906" end_char="6997">
<ORIGINAL_TEXT>Associate Professor, Microbiology and Immunology, University of Maryland School of Medicine.</ORIGINAL_TEXT>
<TOKEN id="token-94-0" pos="word" morph="none" start_char="6906" end_char="6914">Associate</TOKEN>
<TOKEN id="token-94-1" pos="word" morph="none" start_char="6916" end_char="6924">Professor</TOKEN>
<TOKEN id="token-94-2" pos="punct" morph="none" start_char="6925" end_char="6925">,</TOKEN>
<TOKEN id="token-94-3" pos="word" morph="none" start_char="6927" end_char="6938">Microbiology</TOKEN>
<TOKEN id="token-94-4" pos="word" morph="none" start_char="6940" end_char="6942">and</TOKEN>
<TOKEN id="token-94-5" pos="word" morph="none" start_char="6944" end_char="6953">Immunology</TOKEN>
<TOKEN id="token-94-6" pos="punct" morph="none" start_char="6954" end_char="6954">,</TOKEN>
<TOKEN id="token-94-7" pos="word" morph="none" start_char="6956" end_char="6965">University</TOKEN>
<TOKEN id="token-94-8" pos="word" morph="none" start_char="6967" end_char="6968">of</TOKEN>
<TOKEN id="token-94-9" pos="word" morph="none" start_char="6970" end_char="6977">Maryland</TOKEN>
<TOKEN id="token-94-10" pos="word" morph="none" start_char="6979" end_char="6984">School</TOKEN>
<TOKEN id="token-94-11" pos="word" morph="none" start_char="6986" end_char="6987">of</TOKEN>
<TOKEN id="token-94-12" pos="word" morph="none" start_char="6989" end_char="6996">Medicine</TOKEN>
<TOKEN id="token-94-13" pos="punct" morph="none" start_char="6997" end_char="6997">.</TOKEN>
</SEG>
<SEG id="segment-95" start_char="6999" end_char="7026">
<ORIGINAL_TEXT>Email sent to FactCheck.org.</ORIGINAL_TEXT>
<TOKEN id="token-95-0" pos="word" morph="none" start_char="6999" end_char="7003">Email</TOKEN>
<TOKEN id="token-95-1" pos="word" morph="none" start_char="7005" end_char="7008">sent</TOKEN>
<TOKEN id="token-95-2" pos="word" morph="none" start_char="7010" end_char="7011">to</TOKEN>
<TOKEN id="token-95-3" pos="unknown" morph="none" start_char="7013" end_char="7025">FactCheck.org</TOKEN>
<TOKEN id="token-95-4" pos="punct" morph="none" start_char="7026" end_char="7026">.</TOKEN>
</SEG>
<SEG id="segment-96" start_char="7028" end_char="7039">
<ORIGINAL_TEXT>22 Jan 2020.</ORIGINAL_TEXT>
<TOKEN id="token-96-0" pos="word" morph="none" start_char="7028" end_char="7029">22</TOKEN>
<TOKEN id="token-96-1" pos="word" morph="none" start_char="7031" end_char="7033">Jan</TOKEN>
<TOKEN id="token-96-2" pos="word" morph="none" start_char="7035" end_char="7038">2020</TOKEN>
<TOKEN id="token-96-3" pos="punct" morph="none" start_char="7039" end_char="7039">.</TOKEN>
</SEG>
<SEG id="segment-97" start_char="7042" end_char="7080">
<ORIGINAL_TEXT>"Scientists race to patent SARS virus."</ORIGINAL_TEXT>
<TOKEN id="token-97-0" pos="punct" morph="none" start_char="7042" end_char="7042">"</TOKEN>
<TOKEN id="token-97-1" pos="word" morph="none" start_char="7043" end_char="7052">Scientists</TOKEN>
<TOKEN id="token-97-2" pos="word" morph="none" start_char="7054" end_char="7057">race</TOKEN>
<TOKEN id="token-97-3" pos="word" morph="none" start_char="7059" end_char="7060">to</TOKEN>
<TOKEN id="token-97-4" pos="word" morph="none" start_char="7062" end_char="7067">patent</TOKEN>
<TOKEN id="token-97-5" pos="word" morph="none" start_char="7069" end_char="7072">SARS</TOKEN>
<TOKEN id="token-97-6" pos="word" morph="none" start_char="7074" end_char="7078">virus</TOKEN>
<TOKEN id="token-97-7" pos="punct" morph="none" start_char="7079" end_char="7080">."</TOKEN>
</SEG>
<SEG id="segment-98" start_char="7082" end_char="7098">
<ORIGINAL_TEXT>Associated Press.</ORIGINAL_TEXT>
<TOKEN id="token-98-0" pos="word" morph="none" start_char="7082" end_char="7091">Associated</TOKEN>
<TOKEN id="token-98-1" pos="word" morph="none" start_char="7093" end_char="7097">Press</TOKEN>
<TOKEN id="token-98-2" pos="punct" morph="none" start_char="7098" end_char="7098">.</TOKEN>
</SEG>
<SEG id="segment-99" start_char="7100" end_char="7118">
<ORIGINAL_TEXT>Updated 4 Nov 2003.</ORIGINAL_TEXT>
<TOKEN id="token-99-0" pos="word" morph="none" start_char="7100" end_char="7106">Updated</TOKEN>
<TOKEN id="token-99-1" pos="word" morph="none" start_char="7108" end_char="7108">4</TOKEN>
<TOKEN id="token-99-2" pos="word" morph="none" start_char="7110" end_char="7112">Nov</TOKEN>
<TOKEN id="token-99-3" pos="word" morph="none" start_char="7114" end_char="7117">2003</TOKEN>
<TOKEN id="token-99-4" pos="punct" morph="none" start_char="7118" end_char="7118">.</TOKEN>
</SEG>
<SEG id="segment-100" start_char="7121" end_char="7134">
<ORIGINAL_TEXT>Edgar, Harold.</ORIGINAL_TEXT>
<TOKEN id="token-100-0" pos="word" morph="none" start_char="7121" end_char="7125">Edgar</TOKEN>
<TOKEN id="token-100-1" pos="punct" morph="none" start_char="7126" end_char="7126">,</TOKEN>
<TOKEN id="token-100-2" pos="word" morph="none" start_char="7128" end_char="7133">Harold</TOKEN>
<TOKEN id="token-100-3" pos="punct" morph="none" start_char="7134" end_char="7134">.</TOKEN>
</SEG>
<SEG id="segment-101" start_char="7136" end_char="7220">
<ORIGINAL_TEXT>Julius Silver Professor Emeritus of Law, Science and Technology, Columbia Law School.</ORIGINAL_TEXT>
<TOKEN id="token-101-0" pos="word" morph="none" start_char="7136" end_char="7141">Julius</TOKEN>
<TOKEN id="token-101-1" pos="word" morph="none" start_char="7143" end_char="7148">Silver</TOKEN>
<TOKEN id="token-101-2" pos="word" morph="none" start_char="7150" end_char="7158">Professor</TOKEN>
<TOKEN id="token-101-3" pos="word" morph="none" start_char="7160" end_char="7167">Emeritus</TOKEN>
<TOKEN id="token-101-4" pos="word" morph="none" start_char="7169" end_char="7170">of</TOKEN>
<TOKEN id="token-101-5" pos="word" morph="none" start_char="7172" end_char="7174">Law</TOKEN>
<TOKEN id="token-101-6" pos="punct" morph="none" start_char="7175" end_char="7175">,</TOKEN>
<TOKEN id="token-101-7" pos="word" morph="none" start_char="7177" end_char="7183">Science</TOKEN>
<TOKEN id="token-101-8" pos="word" morph="none" start_char="7185" end_char="7187">and</TOKEN>
<TOKEN id="token-101-9" pos="word" morph="none" start_char="7189" end_char="7198">Technology</TOKEN>
<TOKEN id="token-101-10" pos="punct" morph="none" start_char="7199" end_char="7199">,</TOKEN>
<TOKEN id="token-101-11" pos="word" morph="none" start_char="7201" end_char="7208">Columbia</TOKEN>
<TOKEN id="token-101-12" pos="word" morph="none" start_char="7210" end_char="7212">Law</TOKEN>
<TOKEN id="token-101-13" pos="word" morph="none" start_char="7214" end_char="7219">School</TOKEN>
<TOKEN id="token-101-14" pos="punct" morph="none" start_char="7220" end_char="7220">.</TOKEN>
</SEG>
<SEG id="segment-102" start_char="7222" end_char="7250">
<ORIGINAL_TEXT>Interview with FactCheck.org.</ORIGINAL_TEXT>
<TOKEN id="token-102-0" pos="word" morph="none" start_char="7222" end_char="7230">Interview</TOKEN>
<TOKEN id="token-102-1" pos="word" morph="none" start_char="7232" end_char="7235">with</TOKEN>
<TOKEN id="token-102-2" pos="unknown" morph="none" start_char="7237" end_char="7249">FactCheck.org</TOKEN>
<TOKEN id="token-102-3" pos="punct" morph="none" start_char="7250" end_char="7250">.</TOKEN>
</SEG>
<SEG id="segment-103" start_char="7252" end_char="7263">
<ORIGINAL_TEXT>23 Jan 2020.</ORIGINAL_TEXT>
<TOKEN id="token-103-0" pos="word" morph="none" start_char="7252" end_char="7253">23</TOKEN>
<TOKEN id="token-103-1" pos="word" morph="none" start_char="7255" end_char="7257">Jan</TOKEN>
<TOKEN id="token-103-2" pos="word" morph="none" start_char="7259" end_char="7262">2020</TOKEN>
<TOKEN id="token-103-3" pos="punct" morph="none" start_char="7263" end_char="7263">.</TOKEN>
</SEG>
<SEG id="segment-104" start_char="7266" end_char="7299">
<ORIGINAL_TEXT>Novel Coronavirus in Wuhan, China.</ORIGINAL_TEXT>
<TOKEN id="token-104-0" pos="word" morph="none" start_char="7266" end_char="7270">Novel</TOKEN>
<TOKEN id="token-104-1" pos="word" morph="none" start_char="7272" end_char="7282">Coronavirus</TOKEN>
<TOKEN id="token-104-2" pos="word" morph="none" start_char="7284" end_char="7285">in</TOKEN>
<TOKEN id="token-104-3" pos="word" morph="none" start_char="7287" end_char="7291">Wuhan</TOKEN>
<TOKEN id="token-104-4" pos="punct" morph="none" start_char="7292" end_char="7292">,</TOKEN>
<TOKEN id="token-104-5" pos="word" morph="none" start_char="7294" end_char="7298">China</TOKEN>
<TOKEN id="token-104-6" pos="punct" morph="none" start_char="7299" end_char="7299">.</TOKEN>
</SEG>
<SEG id="segment-105" start_char="7301" end_char="7304">
<ORIGINAL_TEXT>CDC.</ORIGINAL_TEXT>
<TOKEN id="token-105-0" pos="word" morph="none" start_char="7301" end_char="7303">CDC</TOKEN>
<TOKEN id="token-105-1" pos="punct" morph="none" start_char="7304" end_char="7304">.</TOKEN>
</SEG>
<SEG id="segment-106" start_char="7306" end_char="7326">
<ORIGINAL_TEXT>Accessed 23 Jan 2020.</ORIGINAL_TEXT>
<TOKEN id="token-106-0" pos="word" morph="none" start_char="7306" end_char="7313">Accessed</TOKEN>
<TOKEN id="token-106-1" pos="word" morph="none" start_char="7315" end_char="7316">23</TOKEN>
<TOKEN id="token-106-2" pos="word" morph="none" start_char="7318" end_char="7320">Jan</TOKEN>
<TOKEN id="token-106-3" pos="word" morph="none" start_char="7322" end_char="7325">2020</TOKEN>
<TOKEN id="token-106-4" pos="punct" morph="none" start_char="7326" end_char="7326">.</TOKEN>
</SEG>
<SEG id="segment-107" start_char="7329" end_char="7357">
<ORIGINAL_TEXT>Davies, Will and Stephen Tan.</ORIGINAL_TEXT>
<TOKEN id="token-107-0" pos="word" morph="none" start_char="7329" end_char="7334">Davies</TOKEN>
<TOKEN id="token-107-1" pos="punct" morph="none" start_char="7335" end_char="7335">,</TOKEN>
<TOKEN id="token-107-2" pos="word" morph="none" start_char="7337" end_char="7340">Will</TOKEN>
<TOKEN id="token-107-3" pos="word" morph="none" start_char="7342" end_char="7344">and</TOKEN>
<TOKEN id="token-107-4" pos="word" morph="none" start_char="7346" end_char="7352">Stephen</TOKEN>
<TOKEN id="token-107-5" pos="word" morph="none" start_char="7354" end_char="7356">Tan</TOKEN>
<TOKEN id="token-107-6" pos="punct" morph="none" start_char="7357" end_char="7357">.</TOKEN>
</SEG>
<SEG id="segment-108" start_char="7359" end_char="7417">
<ORIGINAL_TEXT>"The Age, Sex and Symptoms of All the Coronavirus Victims."</ORIGINAL_TEXT>
<TOKEN id="token-108-0" pos="punct" morph="none" start_char="7359" end_char="7359">"</TOKEN>
<TOKEN id="token-108-1" pos="word" morph="none" start_char="7360" end_char="7362">The</TOKEN>
<TOKEN id="token-108-2" pos="word" morph="none" start_char="7364" end_char="7366">Age</TOKEN>
<TOKEN id="token-108-3" pos="punct" morph="none" start_char="7367" end_char="7367">,</TOKEN>
<TOKEN id="token-108-4" pos="word" morph="none" start_char="7369" end_char="7371">Sex</TOKEN>
<TOKEN id="token-108-5" pos="word" morph="none" start_char="7373" end_char="7375">and</TOKEN>
<TOKEN id="token-108-6" pos="word" morph="none" start_char="7377" end_char="7384">Symptoms</TOKEN>
<TOKEN id="token-108-7" pos="word" morph="none" start_char="7386" end_char="7387">of</TOKEN>
<TOKEN id="token-108-8" pos="word" morph="none" start_char="7389" end_char="7391">All</TOKEN>
<TOKEN id="token-108-9" pos="word" morph="none" start_char="7393" end_char="7395">the</TOKEN>
<TOKEN id="token-108-10" pos="word" morph="none" start_char="7397" end_char="7407">Coronavirus</TOKEN>
<TOKEN id="token-108-11" pos="word" morph="none" start_char="7409" end_char="7415">Victims</TOKEN>
<TOKEN id="token-108-12" pos="punct" morph="none" start_char="7416" end_char="7417">."</TOKEN>
</SEG>
<SEG id="segment-109" start_char="7419" end_char="7428">
<ORIGINAL_TEXT>Bloomberg.</ORIGINAL_TEXT>
<TOKEN id="token-109-0" pos="word" morph="none" start_char="7419" end_char="7427">Bloomberg</TOKEN>
<TOKEN id="token-109-1" pos="punct" morph="none" start_char="7428" end_char="7428">.</TOKEN>
</SEG>
<SEG id="segment-110" start_char="7430" end_char="7462">
<ORIGINAL_TEXT>22 Jan 2020, updated 23 Jan 2020.</ORIGINAL_TEXT>
<TOKEN id="token-110-0" pos="word" morph="none" start_char="7430" end_char="7431">22</TOKEN>
<TOKEN id="token-110-1" pos="word" morph="none" start_char="7433" end_char="7435">Jan</TOKEN>
<TOKEN id="token-110-2" pos="word" morph="none" start_char="7437" end_char="7440">2020</TOKEN>
<TOKEN id="token-110-3" pos="punct" morph="none" start_char="7441" end_char="7441">,</TOKEN>
<TOKEN id="token-110-4" pos="word" morph="none" start_char="7443" end_char="7449">updated</TOKEN>
<TOKEN id="token-110-5" pos="word" morph="none" start_char="7451" end_char="7452">23</TOKEN>
<TOKEN id="token-110-6" pos="word" morph="none" start_char="7454" end_char="7456">Jan</TOKEN>
<TOKEN id="token-110-7" pos="word" morph="none" start_char="7458" end_char="7461">2020</TOKEN>
<TOKEN id="token-110-8" pos="punct" morph="none" start_char="7462" end_char="7462">.</TOKEN>
</SEG>
<SEG id="segment-111" start_char="7465" end_char="7477">
<ORIGINAL_TEXT>Taylor, Adam.</ORIGINAL_TEXT>
<TOKEN id="token-111-0" pos="word" morph="none" start_char="7465" end_char="7470">Taylor</TOKEN>
<TOKEN id="token-111-1" pos="punct" morph="none" start_char="7471" end_char="7471">,</TOKEN>
<TOKEN id="token-111-2" pos="word" morph="none" start_char="7473" end_char="7476">Adam</TOKEN>
<TOKEN id="token-111-3" pos="punct" morph="none" start_char="7477" end_char="7477">.</TOKEN>
</SEG>
<SEG id="segment-112" start_char="7479" end_char="7547">
<ORIGINAL_TEXT>"Wuhan: The Chinese mega-city at the center of coronavirus outbreak."</ORIGINAL_TEXT>
<TOKEN id="token-112-0" pos="punct" morph="none" start_char="7479" end_char="7479">"</TOKEN>
<TOKEN id="token-112-1" pos="word" morph="none" start_char="7480" end_char="7484">Wuhan</TOKEN>
<TOKEN id="token-112-2" pos="punct" morph="none" start_char="7485" end_char="7485">:</TOKEN>
<TOKEN id="token-112-3" pos="word" morph="none" start_char="7487" end_char="7489">The</TOKEN>
<TOKEN id="token-112-4" pos="word" morph="none" start_char="7491" end_char="7497">Chinese</TOKEN>
<TOKEN id="token-112-5" pos="unknown" morph="none" start_char="7499" end_char="7507">mega-city</TOKEN>
<TOKEN id="token-112-6" pos="word" morph="none" start_char="7509" end_char="7510">at</TOKEN>
<TOKEN id="token-112-7" pos="word" morph="none" start_char="7512" end_char="7514">the</TOKEN>
<TOKEN id="token-112-8" pos="word" morph="none" start_char="7516" end_char="7521">center</TOKEN>
<TOKEN id="token-112-9" pos="word" morph="none" start_char="7523" end_char="7524">of</TOKEN>
<TOKEN id="token-112-10" pos="word" morph="none" start_char="7526" end_char="7536">coronavirus</TOKEN>
<TOKEN id="token-112-11" pos="word" morph="none" start_char="7538" end_char="7545">outbreak</TOKEN>
<TOKEN id="token-112-12" pos="punct" morph="none" start_char="7546" end_char="7547">."</TOKEN>
</SEG>
<SEG id="segment-113" start_char="7549" end_char="7564">
<ORIGINAL_TEXT>Washington Post.</ORIGINAL_TEXT>
<TOKEN id="token-113-0" pos="word" morph="none" start_char="7549" end_char="7558">Washington</TOKEN>
<TOKEN id="token-113-1" pos="word" morph="none" start_char="7560" end_char="7563">Post</TOKEN>
<TOKEN id="token-113-2" pos="punct" morph="none" start_char="7564" end_char="7564">.</TOKEN>
</SEG>
<SEG id="segment-114" start_char="7566" end_char="7577">
<ORIGINAL_TEXT>23 Jan 2020.</ORIGINAL_TEXT>
<TOKEN id="token-114-0" pos="word" morph="none" start_char="7566" end_char="7567">23</TOKEN>
<TOKEN id="token-114-1" pos="word" morph="none" start_char="7569" end_char="7571">Jan</TOKEN>
<TOKEN id="token-114-2" pos="word" morph="none" start_char="7573" end_char="7576">2020</TOKEN>
<TOKEN id="token-114-3" pos="punct" morph="none" start_char="7577" end_char="7577">.</TOKEN>
</SEG>
<SEG id="segment-115" start_char="7580" end_char="7632">
<ORIGINAL_TEXT>Jackwood, Mark W. "Infectious Bronchitis in Poultry."</ORIGINAL_TEXT>
<TOKEN id="token-115-0" pos="word" morph="none" start_char="7580" end_char="7587">Jackwood</TOKEN>
<TOKEN id="token-115-1" pos="punct" morph="none" start_char="7588" end_char="7588">,</TOKEN>
<TOKEN id="token-115-2" pos="word" morph="none" start_char="7590" end_char="7593">Mark</TOKEN>
<TOKEN id="token-115-3" pos="word" morph="none" start_char="7595" end_char="7595">W</TOKEN>
<TOKEN id="token-115-4" pos="punct" morph="none" start_char="7596" end_char="7596">.</TOKEN>
<TOKEN id="token-115-5" pos="punct" morph="none" start_char="7598" end_char="7598">"</TOKEN>
<TOKEN id="token-115-6" pos="word" morph="none" start_char="7599" end_char="7608">Infectious</TOKEN>
<TOKEN id="token-115-7" pos="word" morph="none" start_char="7610" end_char="7619">Bronchitis</TOKEN>
<TOKEN id="token-115-8" pos="word" morph="none" start_char="7621" end_char="7622">in</TOKEN>
<TOKEN id="token-115-9" pos="word" morph="none" start_char="7624" end_char="7630">Poultry</TOKEN>
<TOKEN id="token-115-10" pos="punct" morph="none" start_char="7631" end_char="7632">."</TOKEN>
</SEG>
<SEG id="segment-116" start_char="7634" end_char="7657">
<ORIGINAL_TEXT>Merck Veterinary Manual.</ORIGINAL_TEXT>
<TOKEN id="token-116-0" pos="word" morph="none" start_char="7634" end_char="7638">Merck</TOKEN>
<TOKEN id="token-116-1" pos="word" morph="none" start_char="7640" end_char="7649">Veterinary</TOKEN>
<TOKEN id="token-116-2" pos="word" morph="none" start_char="7651" end_char="7656">Manual</TOKEN>
<TOKEN id="token-116-3" pos="punct" morph="none" start_char="7657" end_char="7657">.</TOKEN>
</SEG>
<SEG id="segment-117" start_char="7659" end_char="7679">
<ORIGINAL_TEXT>Accessed 23 Jan 2020.</ORIGINAL_TEXT>
<TOKEN id="token-117-0" pos="word" morph="none" start_char="7659" end_char="7666">Accessed</TOKEN>
<TOKEN id="token-117-1" pos="word" morph="none" start_char="7668" end_char="7669">23</TOKEN>
<TOKEN id="token-117-2" pos="word" morph="none" start_char="7671" end_char="7673">Jan</TOKEN>
<TOKEN id="token-117-3" pos="word" morph="none" start_char="7675" end_char="7678">2020</TOKEN>
<TOKEN id="token-117-4" pos="punct" morph="none" start_char="7679" end_char="7679">.</TOKEN>
</SEG>
<SEG id="segment-118" start_char="7682" end_char="7722">
<ORIGINAL_TEXT>SARS (Severe Acute Respiratory Syndrome).</ORIGINAL_TEXT>
<TOKEN id="token-118-0" pos="word" morph="none" start_char="7682" end_char="7685">SARS</TOKEN>
<TOKEN id="token-118-1" pos="punct" morph="none" start_char="7687" end_char="7687">(</TOKEN>
<TOKEN id="token-118-2" pos="word" morph="none" start_char="7688" end_char="7693">Severe</TOKEN>
<TOKEN id="token-118-3" pos="word" morph="none" start_char="7695" end_char="7699">Acute</TOKEN>
<TOKEN id="token-118-4" pos="word" morph="none" start_char="7701" end_char="7711">Respiratory</TOKEN>
<TOKEN id="token-118-5" pos="word" morph="none" start_char="7713" end_char="7720">Syndrome</TOKEN>
<TOKEN id="token-118-6" pos="punct" morph="none" start_char="7721" end_char="7722">).</TOKEN>
</SEG>
<SEG id="segment-119" start_char="7724" end_char="7749">
<ORIGINAL_TEXT>World Health Organization.</ORIGINAL_TEXT>
<TOKEN id="token-119-0" pos="word" morph="none" start_char="7724" end_char="7728">World</TOKEN>
<TOKEN id="token-119-1" pos="word" morph="none" start_char="7730" end_char="7735">Health</TOKEN>
<TOKEN id="token-119-2" pos="word" morph="none" start_char="7737" end_char="7748">Organization</TOKEN>
<TOKEN id="token-119-3" pos="punct" morph="none" start_char="7749" end_char="7749">.</TOKEN>
</SEG>
<SEG id="segment-120" start_char="7751" end_char="7771">
<ORIGINAL_TEXT>Accessed 23 Jan 2020.</ORIGINAL_TEXT>
<TOKEN id="token-120-0" pos="word" morph="none" start_char="7751" end_char="7758">Accessed</TOKEN>
<TOKEN id="token-120-1" pos="word" morph="none" start_char="7760" end_char="7761">23</TOKEN>
<TOKEN id="token-120-2" pos="word" morph="none" start_char="7763" end_char="7765">Jan</TOKEN>
<TOKEN id="token-120-3" pos="word" morph="none" start_char="7767" end_char="7770">2020</TOKEN>
<TOKEN id="token-120-4" pos="punct" morph="none" start_char="7771" end_char="7771">.</TOKEN>
</SEG>
<SEG id="segment-121" start_char="7774" end_char="7803">
<ORIGINAL_TEXT>Sample, Ian and John Gittings.</ORIGINAL_TEXT>
<TOKEN id="token-121-0" pos="word" morph="none" start_char="7774" end_char="7779">Sample</TOKEN>
<TOKEN id="token-121-1" pos="punct" morph="none" start_char="7780" end_char="7780">,</TOKEN>
<TOKEN id="token-121-2" pos="word" morph="none" start_char="7782" end_char="7784">Ian</TOKEN>
<TOKEN id="token-121-3" pos="word" morph="none" start_char="7786" end_char="7788">and</TOKEN>
<TOKEN id="token-121-4" pos="word" morph="none" start_char="7790" end_char="7793">John</TOKEN>
<TOKEN id="token-121-5" pos="word" morph="none" start_char="7795" end_char="7802">Gittings</TOKEN>
<TOKEN id="token-121-6" pos="punct" morph="none" start_char="7803" end_char="7803">.</TOKEN>
</SEG>
<SEG id="segment-122" start_char="7805" end_char="7870">
<ORIGINAL_TEXT>"In China the civet cat is a delicacy – and may have caused Sars."</ORIGINAL_TEXT>
<TOKEN id="token-122-0" pos="punct" morph="none" start_char="7805" end_char="7805">"</TOKEN>
<TOKEN id="token-122-1" pos="word" morph="none" start_char="7806" end_char="7807">In</TOKEN>
<TOKEN id="token-122-2" pos="word" morph="none" start_char="7809" end_char="7813">China</TOKEN>
<TOKEN id="token-122-3" pos="word" morph="none" start_char="7815" end_char="7817">the</TOKEN>
<TOKEN id="token-122-4" pos="word" morph="none" start_char="7819" end_char="7823">civet</TOKEN>
<TOKEN id="token-122-5" pos="word" morph="none" start_char="7825" end_char="7827">cat</TOKEN>
<TOKEN id="token-122-6" pos="word" morph="none" start_char="7829" end_char="7830">is</TOKEN>
<TOKEN id="token-122-7" pos="word" morph="none" start_char="7832" end_char="7832">a</TOKEN>
<TOKEN id="token-122-8" pos="word" morph="none" start_char="7834" end_char="7841">delicacy</TOKEN>
<TOKEN id="token-122-9" pos="punct" morph="none" start_char="7843" end_char="7843">–</TOKEN>
<TOKEN id="token-122-10" pos="word" morph="none" start_char="7845" end_char="7847">and</TOKEN>
<TOKEN id="token-122-11" pos="word" morph="none" start_char="7849" end_char="7851">may</TOKEN>
<TOKEN id="token-122-12" pos="word" morph="none" start_char="7853" end_char="7856">have</TOKEN>
<TOKEN id="token-122-13" pos="word" morph="none" start_char="7858" end_char="7863">caused</TOKEN>
<TOKEN id="token-122-14" pos="word" morph="none" start_char="7865" end_char="7868">Sars</TOKEN>
<TOKEN id="token-122-15" pos="punct" morph="none" start_char="7869" end_char="7870">."</TOKEN>
</SEG>
<SEG id="segment-123" start_char="7872" end_char="7884">
<ORIGINAL_TEXT>The Guardian.</ORIGINAL_TEXT>
<TOKEN id="token-123-0" pos="word" morph="none" start_char="7872" end_char="7874">The</TOKEN>
<TOKEN id="token-123-1" pos="word" morph="none" start_char="7876" end_char="7883">Guardian</TOKEN>
<TOKEN id="token-123-2" pos="punct" morph="none" start_char="7884" end_char="7884">.</TOKEN>
</SEG>
<SEG id="segment-124" start_char="7886" end_char="7897">
<ORIGINAL_TEXT>23 May 2003.</ORIGINAL_TEXT>
<TOKEN id="token-124-0" pos="word" morph="none" start_char="7886" end_char="7887">23</TOKEN>
<TOKEN id="token-124-1" pos="word" morph="none" start_char="7889" end_char="7891">May</TOKEN>
<TOKEN id="token-124-2" pos="word" morph="none" start_char="7893" end_char="7896">2003</TOKEN>
<TOKEN id="token-124-3" pos="punct" morph="none" start_char="7897" end_char="7897">.</TOKEN>
</SEG>
<SEG id="segment-125" start_char="7900" end_char="7939">
<ORIGINAL_TEXT>Middle East Respiratory Syndrome (MERS).</ORIGINAL_TEXT>
<TOKEN id="token-125-0" pos="word" morph="none" start_char="7900" end_char="7905">Middle</TOKEN>
<TOKEN id="token-125-1" pos="word" morph="none" start_char="7907" end_char="7910">East</TOKEN>
<TOKEN id="token-125-2" pos="word" morph="none" start_char="7912" end_char="7922">Respiratory</TOKEN>
<TOKEN id="token-125-3" pos="word" morph="none" start_char="7924" end_char="7931">Syndrome</TOKEN>
<TOKEN id="token-125-4" pos="punct" morph="none" start_char="7933" end_char="7933">(</TOKEN>
<TOKEN id="token-125-5" pos="word" morph="none" start_char="7934" end_char="7937">MERS</TOKEN>
<TOKEN id="token-125-6" pos="punct" morph="none" start_char="7938" end_char="7939">).</TOKEN>
</SEG>
<SEG id="segment-126" start_char="7941" end_char="7944">
<ORIGINAL_TEXT>CDC.</ORIGINAL_TEXT>
<TOKEN id="token-126-0" pos="word" morph="none" start_char="7941" end_char="7943">CDC</TOKEN>
<TOKEN id="token-126-1" pos="punct" morph="none" start_char="7944" end_char="7944">.</TOKEN>
</SEG>
<SEG id="segment-127" start_char="7946" end_char="7966">
<ORIGINAL_TEXT>Accessed 23 Jan 2020.</ORIGINAL_TEXT>
<TOKEN id="token-127-0" pos="word" morph="none" start_char="7946" end_char="7953">Accessed</TOKEN>
<TOKEN id="token-127-1" pos="word" morph="none" start_char="7955" end_char="7956">23</TOKEN>
<TOKEN id="token-127-2" pos="word" morph="none" start_char="7958" end_char="7960">Jan</TOKEN>
<TOKEN id="token-127-3" pos="word" morph="none" start_char="7962" end_char="7965">2020</TOKEN>
<TOKEN id="token-127-4" pos="punct" morph="none" start_char="7966" end_char="7966">.</TOKEN>
</SEG>
<SEG id="segment-128" start_char="7969" end_char="8054">
<ORIGINAL_TEXT>Frequently asked questions on Middle East respiratory syndrome coronavirus (MERS‐CoV).</ORIGINAL_TEXT>
<TOKEN id="token-128-0" pos="word" morph="none" start_char="7969" end_char="7978">Frequently</TOKEN>
<TOKEN id="token-128-1" pos="word" morph="none" start_char="7980" end_char="7984">asked</TOKEN>
<TOKEN id="token-128-2" pos="word" morph="none" start_char="7986" end_char="7994">questions</TOKEN>
<TOKEN id="token-128-3" pos="word" morph="none" start_char="7996" end_char="7997">on</TOKEN>
<TOKEN id="token-128-4" pos="word" morph="none" start_char="7999" end_char="8004">Middle</TOKEN>
<TOKEN id="token-128-5" pos="word" morph="none" start_char="8006" end_char="8009">East</TOKEN>
<TOKEN id="token-128-6" pos="word" morph="none" start_char="8011" end_char="8021">respiratory</TOKEN>
<TOKEN id="token-128-7" pos="word" morph="none" start_char="8023" end_char="8030">syndrome</TOKEN>
<TOKEN id="token-128-8" pos="word" morph="none" start_char="8032" end_char="8042">coronavirus</TOKEN>
<TOKEN id="token-128-9" pos="punct" morph="none" start_char="8044" end_char="8044">(</TOKEN>
<TOKEN id="token-128-10" pos="unknown" morph="none" start_char="8045" end_char="8052">MERS‐CoV</TOKEN>
<TOKEN id="token-128-11" pos="punct" morph="none" start_char="8053" end_char="8054">).</TOKEN>
</SEG>
<SEG id="segment-129" start_char="8056" end_char="8081">
<ORIGINAL_TEXT>World Health Organization.</ORIGINAL_TEXT>
<TOKEN id="token-129-0" pos="word" morph="none" start_char="8056" end_char="8060">World</TOKEN>
<TOKEN id="token-129-1" pos="word" morph="none" start_char="8062" end_char="8067">Health</TOKEN>
<TOKEN id="token-129-2" pos="word" morph="none" start_char="8069" end_char="8080">Organization</TOKEN>
<TOKEN id="token-129-3" pos="punct" morph="none" start_char="8081" end_char="8081">.</TOKEN>
</SEG>
<SEG id="segment-130" start_char="8083" end_char="8102">
<ORIGINAL_TEXT>Updated 21 Jan 2019.</ORIGINAL_TEXT>
<TOKEN id="token-130-0" pos="word" morph="none" start_char="8083" end_char="8089">Updated</TOKEN>
<TOKEN id="token-130-1" pos="word" morph="none" start_char="8091" end_char="8092">21</TOKEN>
<TOKEN id="token-130-2" pos="word" morph="none" start_char="8094" end_char="8096">Jan</TOKEN>
<TOKEN id="token-130-3" pos="word" morph="none" start_char="8098" end_char="8101">2019</TOKEN>
<TOKEN id="token-130-4" pos="punct" morph="none" start_char="8102" end_char="8102">.</TOKEN>
</SEG>
<SEG id="segment-131" start_char="8105" end_char="8160">
<ORIGINAL_TEXT>Middle East respiratory syndrome coronavirus (MERS-CoV).</ORIGINAL_TEXT>
<TOKEN id="token-131-0" pos="word" morph="none" start_char="8105" end_char="8110">Middle</TOKEN>
<TOKEN id="token-131-1" pos="word" morph="none" start_char="8112" end_char="8115">East</TOKEN>
<TOKEN id="token-131-2" pos="word" morph="none" start_char="8117" end_char="8127">respiratory</TOKEN>
<TOKEN id="token-131-3" pos="word" morph="none" start_char="8129" end_char="8136">syndrome</TOKEN>
<TOKEN id="token-131-4" pos="word" morph="none" start_char="8138" end_char="8148">coronavirus</TOKEN>
<TOKEN id="token-131-5" pos="punct" morph="none" start_char="8150" end_char="8150">(</TOKEN>
<TOKEN id="token-131-6" pos="unknown" morph="none" start_char="8151" end_char="8158">MERS-CoV</TOKEN>
<TOKEN id="token-131-7" pos="punct" morph="none" start_char="8159" end_char="8160">).</TOKEN>
</SEG>
<SEG id="segment-132" start_char="8162" end_char="8187">
<ORIGINAL_TEXT>World Health Organization.</ORIGINAL_TEXT>
<TOKEN id="token-132-0" pos="word" morph="none" start_char="8162" end_char="8166">World</TOKEN>
<TOKEN id="token-132-1" pos="word" morph="none" start_char="8168" end_char="8173">Health</TOKEN>
<TOKEN id="token-132-2" pos="word" morph="none" start_char="8175" end_char="8186">Organization</TOKEN>
<TOKEN id="token-132-3" pos="punct" morph="none" start_char="8187" end_char="8187">.</TOKEN>
</SEG>
<SEG id="segment-133" start_char="8189" end_char="8200">
<ORIGINAL_TEXT>11 Mar 2019.</ORIGINAL_TEXT>
<TOKEN id="token-133-0" pos="word" morph="none" start_char="8189" end_char="8190">11</TOKEN>
<TOKEN id="token-133-1" pos="word" morph="none" start_char="8192" end_char="8194">Mar</TOKEN>
<TOKEN id="token-133-2" pos="word" morph="none" start_char="8196" end_char="8199">2019</TOKEN>
<TOKEN id="token-133-3" pos="punct" morph="none" start_char="8200" end_char="8200">.</TOKEN>
</SEG>
<SEG id="segment-134" start_char="8203" end_char="8330">
<ORIGINAL_TEXT>"Moderna Announces Funding Award from CEPI to Accelerate Development of Messenger RNA (mRNA) Vaccine Against Novel Coronavirus."</ORIGINAL_TEXT>
<TOKEN id="token-134-0" pos="punct" morph="none" start_char="8203" end_char="8203">"</TOKEN>
<TOKEN id="token-134-1" pos="word" morph="none" start_char="8204" end_char="8210">Moderna</TOKEN>
<TOKEN id="token-134-2" pos="word" morph="none" start_char="8212" end_char="8220">Announces</TOKEN>
<TOKEN id="token-134-3" pos="word" morph="none" start_char="8222" end_char="8228">Funding</TOKEN>
<TOKEN id="token-134-4" pos="word" morph="none" start_char="8230" end_char="8234">Award</TOKEN>
<TOKEN id="token-134-5" pos="word" morph="none" start_char="8236" end_char="8239">from</TOKEN>
<TOKEN id="token-134-6" pos="word" morph="none" start_char="8241" end_char="8244">CEPI</TOKEN>
<TOKEN id="token-134-7" pos="word" morph="none" start_char="8246" end_char="8247">to</TOKEN>
<TOKEN id="token-134-8" pos="word" morph="none" start_char="8249" end_char="8258">Accelerate</TOKEN>
<TOKEN id="token-134-9" pos="word" morph="none" start_char="8260" end_char="8270">Development</TOKEN>
<TOKEN id="token-134-10" pos="word" morph="none" start_char="8272" end_char="8273">of</TOKEN>
<TOKEN id="token-134-11" pos="word" morph="none" start_char="8275" end_char="8283">Messenger</TOKEN>
<TOKEN id="token-134-12" pos="word" morph="none" start_char="8285" end_char="8287">RNA</TOKEN>
<TOKEN id="token-134-13" pos="punct" morph="none" start_char="8289" end_char="8289">(</TOKEN>
<TOKEN id="token-134-14" pos="word" morph="none" start_char="8290" end_char="8293">mRNA</TOKEN>
<TOKEN id="token-134-15" pos="punct" morph="none" start_char="8294" end_char="8294">)</TOKEN>
<TOKEN id="token-134-16" pos="word" morph="none" start_char="8296" end_char="8302">Vaccine</TOKEN>
<TOKEN id="token-134-17" pos="word" morph="none" start_char="8304" end_char="8310">Against</TOKEN>
<TOKEN id="token-134-18" pos="word" morph="none" start_char="8312" end_char="8316">Novel</TOKEN>
<TOKEN id="token-134-19" pos="word" morph="none" start_char="8318" end_char="8328">Coronavirus</TOKEN>
<TOKEN id="token-134-20" pos="punct" morph="none" start_char="8329" end_char="8330">."</TOKEN>
</SEG>
<SEG id="segment-135" start_char="8332" end_char="8345">
<ORIGINAL_TEXT>Press release.</ORIGINAL_TEXT>
<TOKEN id="token-135-0" pos="word" morph="none" start_char="8332" end_char="8336">Press</TOKEN>
<TOKEN id="token-135-1" pos="word" morph="none" start_char="8338" end_char="8344">release</TOKEN>
<TOKEN id="token-135-2" pos="punct" morph="none" start_char="8345" end_char="8345">.</TOKEN>
</SEG>
<SEG id="segment-136" start_char="8347" end_char="8354">
<ORIGINAL_TEXT>Moderna.</ORIGINAL_TEXT>
<TOKEN id="token-136-0" pos="word" morph="none" start_char="8347" end_char="8353">Moderna</TOKEN>
<TOKEN id="token-136-1" pos="punct" morph="none" start_char="8354" end_char="8354">.</TOKEN>
</SEG>
<SEG id="segment-137" start_char="8356" end_char="8367">
<ORIGINAL_TEXT>23 Jan 2020.</ORIGINAL_TEXT>
<TOKEN id="token-137-0" pos="word" morph="none" start_char="8356" end_char="8357">23</TOKEN>
<TOKEN id="token-137-1" pos="word" morph="none" start_char="8359" end_char="8361">Jan</TOKEN>
<TOKEN id="token-137-2" pos="word" morph="none" start_char="8363" end_char="8366">2020</TOKEN>
<TOKEN id="token-137-3" pos="punct" morph="none" start_char="8367" end_char="8367">.</TOKEN>
</SEG>
<SEG id="segment-138" start_char="8370" end_char="8428">
<ORIGINAL_TEXT>Transcript of Update on 2019 Novel Coronavirus (2019-nCoV).</ORIGINAL_TEXT>
<TOKEN id="token-138-0" pos="word" morph="none" start_char="8370" end_char="8379">Transcript</TOKEN>
<TOKEN id="token-138-1" pos="word" morph="none" start_char="8381" end_char="8382">of</TOKEN>
<TOKEN id="token-138-2" pos="word" morph="none" start_char="8384" end_char="8389">Update</TOKEN>
<TOKEN id="token-138-3" pos="word" morph="none" start_char="8391" end_char="8392">on</TOKEN>
<TOKEN id="token-138-4" pos="word" morph="none" start_char="8394" end_char="8397">2019</TOKEN>
<TOKEN id="token-138-5" pos="word" morph="none" start_char="8399" end_char="8403">Novel</TOKEN>
<TOKEN id="token-138-6" pos="word" morph="none" start_char="8405" end_char="8415">Coronavirus</TOKEN>
<TOKEN id="token-138-7" pos="punct" morph="none" start_char="8417" end_char="8417">(</TOKEN>
<TOKEN id="token-138-8" pos="unknown" morph="none" start_char="8418" end_char="8426">2019-nCoV</TOKEN>
<TOKEN id="token-138-9" pos="punct" morph="none" start_char="8427" end_char="8428">).</TOKEN>
</SEG>
<SEG id="segment-139" start_char="8430" end_char="8433">
<ORIGINAL_TEXT>CDC.</ORIGINAL_TEXT>
<TOKEN id="token-139-0" pos="word" morph="none" start_char="8430" end_char="8432">CDC</TOKEN>
<TOKEN id="token-139-1" pos="punct" morph="none" start_char="8433" end_char="8433">.</TOKEN>
</SEG>
<SEG id="segment-140" start_char="8435" end_char="8446">
<ORIGINAL_TEXT>21 Jan 2020.</ORIGINAL_TEXT>
<TOKEN id="token-140-0" pos="word" morph="none" start_char="8435" end_char="8436">21</TOKEN>
<TOKEN id="token-140-1" pos="word" morph="none" start_char="8438" end_char="8440">Jan</TOKEN>
<TOKEN id="token-140-2" pos="word" morph="none" start_char="8442" end_char="8445">2020</TOKEN>
<TOKEN id="token-140-3" pos="punct" morph="none" start_char="8446" end_char="8446">.</TOKEN>
</SEG>
<SEG id="segment-141" start_char="8449" end_char="8491">
<ORIGINAL_TEXT>Wuhan Coronavirus (2019-nCoV) Global Cases.</ORIGINAL_TEXT>
<TOKEN id="token-141-0" pos="word" morph="none" start_char="8449" end_char="8453">Wuhan</TOKEN>
<TOKEN id="token-141-1" pos="word" morph="none" start_char="8455" end_char="8465">Coronavirus</TOKEN>
<TOKEN id="token-141-2" pos="punct" morph="none" start_char="8467" end_char="8467">(</TOKEN>
<TOKEN id="token-141-3" pos="unknown" morph="none" start_char="8468" end_char="8476">2019-nCoV</TOKEN>
<TOKEN id="token-141-4" pos="punct" morph="none" start_char="8477" end_char="8477">)</TOKEN>
<TOKEN id="token-141-5" pos="word" morph="none" start_char="8479" end_char="8484">Global</TOKEN>
<TOKEN id="token-141-6" pos="word" morph="none" start_char="8486" end_char="8490">Cases</TOKEN>
<TOKEN id="token-141-7" pos="punct" morph="none" start_char="8491" end_char="8491">.</TOKEN>
</SEG>
<SEG id="segment-142" start_char="8493" end_char="8539">
<ORIGINAL_TEXT>Data visualization by Johns Hopkins University.</ORIGINAL_TEXT>
<TOKEN id="token-142-0" pos="word" morph="none" start_char="8493" end_char="8496">Data</TOKEN>
<TOKEN id="token-142-1" pos="word" morph="none" start_char="8498" end_char="8510">visualization</TOKEN>
<TOKEN id="token-142-2" pos="word" morph="none" start_char="8512" end_char="8513">by</TOKEN>
<TOKEN id="token-142-3" pos="word" morph="none" start_char="8515" end_char="8519">Johns</TOKEN>
<TOKEN id="token-142-4" pos="word" morph="none" start_char="8521" end_char="8527">Hopkins</TOKEN>
<TOKEN id="token-142-5" pos="word" morph="none" start_char="8529" end_char="8538">University</TOKEN>
<TOKEN id="token-142-6" pos="punct" morph="none" start_char="8539" end_char="8539">.</TOKEN>
</SEG>
<SEG id="segment-143" start_char="8541" end_char="8561">
<ORIGINAL_TEXT>Accessed 24 Jan 2020.</ORIGINAL_TEXT>
<TOKEN id="token-143-0" pos="word" morph="none" start_char="8541" end_char="8548">Accessed</TOKEN>
<TOKEN id="token-143-1" pos="word" morph="none" start_char="8550" end_char="8551">24</TOKEN>
<TOKEN id="token-143-2" pos="word" morph="none" start_char="8553" end_char="8555">Jan</TOKEN>
<TOKEN id="token-143-3" pos="word" morph="none" start_char="8557" end_char="8560">2020</TOKEN>
<TOKEN id="token-143-4" pos="punct" morph="none" start_char="8561" end_char="8561">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
