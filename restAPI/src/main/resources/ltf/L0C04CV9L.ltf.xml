<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CV9L" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="4446" raw_text_md5="886168c32ceeca3ad0c6a02d153840ac">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="82">
<ORIGINAL_TEXT>La ivermectina no alivia los síntomas leves de la COVID-19, según un nuevo estudio</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="2">La</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="4" end_char="14">ivermectina</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="16" end_char="17">no</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="19" end_char="24">alivia</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="26" end_char="28">los</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="30" end_char="37">síntomas</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="39" end_char="43">leves</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="45" end_char="46">de</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="48" end_char="49">la</TOKEN>
<TOKEN id="token-0-9" pos="unknown" morph="none" start_char="51" end_char="58">COVID-19</TOKEN>
<TOKEN id="token-0-10" pos="punct" morph="none" start_char="59" end_char="59">,</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="61" end_char="65">según</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="67" end_char="68">un</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="70" end_char="74">nuevo</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="76" end_char="82">estudio</TOKEN>
</SEG>
<SEG id="segment-1" start_char="86" end_char="397">
<ORIGINAL_TEXT>La ivermectina, un fármaco antiparasitario controversial que ha sido presentado como un tratamiento potencial contra la COVID-19, no acorta el tiempo de recuperación en las personas con casos leves de la enfermedad, de acuerdo con un ensayo aleatorio controlado publicado el jueves en la revista científica JAMA.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="86" end_char="87">La</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="89" end_char="99">ivermectina</TOKEN>
<TOKEN id="token-1-2" pos="punct" morph="none" start_char="100" end_char="100">,</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="102" end_char="103">un</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="105" end_char="111">fármaco</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="113" end_char="127">antiparasitario</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="129" end_char="141">controversial</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="143" end_char="145">que</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="147" end_char="148">ha</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="150" end_char="153">sido</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="155" end_char="164">presentado</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="166" end_char="169">como</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="171" end_char="172">un</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="174" end_char="184">tratamiento</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="186" end_char="194">potencial</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="196" end_char="201">contra</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="203" end_char="204">la</TOKEN>
<TOKEN id="token-1-17" pos="unknown" morph="none" start_char="206" end_char="213">COVID-19</TOKEN>
<TOKEN id="token-1-18" pos="punct" morph="none" start_char="214" end_char="214">,</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="216" end_char="217">no</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="219" end_char="224">acorta</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="226" end_char="227">el</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="229" end_char="234">tiempo</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="236" end_char="237">de</TOKEN>
<TOKEN id="token-1-24" pos="word" morph="none" start_char="239" end_char="250">recuperación</TOKEN>
<TOKEN id="token-1-25" pos="word" morph="none" start_char="252" end_char="253">en</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="255" end_char="257">las</TOKEN>
<TOKEN id="token-1-27" pos="word" morph="none" start_char="259" end_char="266">personas</TOKEN>
<TOKEN id="token-1-28" pos="word" morph="none" start_char="268" end_char="270">con</TOKEN>
<TOKEN id="token-1-29" pos="word" morph="none" start_char="272" end_char="276">casos</TOKEN>
<TOKEN id="token-1-30" pos="word" morph="none" start_char="278" end_char="282">leves</TOKEN>
<TOKEN id="token-1-31" pos="word" morph="none" start_char="284" end_char="285">de</TOKEN>
<TOKEN id="token-1-32" pos="word" morph="none" start_char="287" end_char="288">la</TOKEN>
<TOKEN id="token-1-33" pos="word" morph="none" start_char="290" end_char="299">enfermedad</TOKEN>
<TOKEN id="token-1-34" pos="punct" morph="none" start_char="300" end_char="300">,</TOKEN>
<TOKEN id="token-1-35" pos="word" morph="none" start_char="302" end_char="303">de</TOKEN>
<TOKEN id="token-1-36" pos="word" morph="none" start_char="305" end_char="311">acuerdo</TOKEN>
<TOKEN id="token-1-37" pos="word" morph="none" start_char="313" end_char="315">con</TOKEN>
<TOKEN id="token-1-38" pos="word" morph="none" start_char="317" end_char="318">un</TOKEN>
<TOKEN id="token-1-39" pos="word" morph="none" start_char="320" end_char="325">ensayo</TOKEN>
<TOKEN id="token-1-40" pos="word" morph="none" start_char="327" end_char="335">aleatorio</TOKEN>
<TOKEN id="token-1-41" pos="word" morph="none" start_char="337" end_char="346">controlado</TOKEN>
<TOKEN id="token-1-42" pos="word" morph="none" start_char="348" end_char="356">publicado</TOKEN>
<TOKEN id="token-1-43" pos="word" morph="none" start_char="358" end_char="359">el</TOKEN>
<TOKEN id="token-1-44" pos="word" morph="none" start_char="361" end_char="366">jueves</TOKEN>
<TOKEN id="token-1-45" pos="word" morph="none" start_char="368" end_char="369">en</TOKEN>
<TOKEN id="token-1-46" pos="word" morph="none" start_char="371" end_char="372">la</TOKEN>
<TOKEN id="token-1-47" pos="word" morph="none" start_char="374" end_char="380">revista</TOKEN>
<TOKEN id="token-1-48" pos="word" morph="none" start_char="382" end_char="391">científica</TOKEN>
<TOKEN id="token-1-49" pos="word" morph="none" start_char="393" end_char="396">JAMA</TOKEN>
<TOKEN id="token-1-50" pos="punct" morph="none" start_char="397" end_char="397">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="400" end_char="583">
<ORIGINAL_TEXT>La ivermectina suele utilizarse para tratar los gusanos parasitarios tanto en personas como en animales pero la evidencia científica de su eficacia contra el coronavirus es muy escasa.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="400" end_char="401">La</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="403" end_char="413">ivermectina</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="415" end_char="419">suele</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="421" end_char="430">utilizarse</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="432" end_char="435">para</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="437" end_char="442">tratar</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="444" end_char="446">los</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="448" end_char="454">gusanos</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="456" end_char="467">parasitarios</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="469" end_char="473">tanto</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="475" end_char="476">en</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="478" end_char="485">personas</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="487" end_char="490">como</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="492" end_char="493">en</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="495" end_char="502">animales</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="504" end_char="507">pero</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="509" end_char="510">la</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="512" end_char="520">evidencia</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="522" end_char="531">científica</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="533" end_char="534">de</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="536" end_char="537">su</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="539" end_char="546">eficacia</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="548" end_char="553">contra</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="555" end_char="556">el</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="558" end_char="568">coronavirus</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="570" end_char="571">es</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="573" end_char="575">muy</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="577" end_char="582">escasa</TOKEN>
<TOKEN id="token-2-28" pos="punct" morph="none" start_char="583" end_char="583">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="585" end_char="689">
<ORIGINAL_TEXT>Algunos estudios han indicado que el fármaco puede prevenir que varios virus se repliquen en las células.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="585" end_char="591">Algunos</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="593" end_char="600">estudios</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="602" end_char="604">han</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="606" end_char="613">indicado</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="615" end_char="617">que</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="619" end_char="620">el</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="622" end_char="628">fármaco</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="630" end_char="634">puede</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="636" end_char="643">prevenir</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="645" end_char="647">que</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="649" end_char="654">varios</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="656" end_char="660">virus</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="662" end_char="663">se</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="665" end_char="673">repliquen</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="675" end_char="676">en</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="678" end_char="680">las</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="682" end_char="688">células</TOKEN>
<TOKEN id="token-3-17" pos="punct" morph="none" start_char="689" end_char="689">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="691" end_char="861">
<ORIGINAL_TEXT>Y el año pasado, investigadores en Australia encontraron que, en dosis elevadas, en cultivos celulares, la ivermectina suprimió el SARS-CoV-2, el virus que causa la covid.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="691" end_char="691">Y</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="693" end_char="694">el</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="696" end_char="698">año</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="700" end_char="705">pasado</TOKEN>
<TOKEN id="token-4-4" pos="punct" morph="none" start_char="706" end_char="706">,</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="708" end_char="721">investigadores</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="723" end_char="724">en</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="726" end_char="734">Australia</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="736" end_char="746">encontraron</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="748" end_char="750">que</TOKEN>
<TOKEN id="token-4-10" pos="punct" morph="none" start_char="751" end_char="751">,</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="753" end_char="754">en</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="756" end_char="760">dosis</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="762" end_char="769">elevadas</TOKEN>
<TOKEN id="token-4-14" pos="punct" morph="none" start_char="770" end_char="770">,</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="772" end_char="773">en</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="775" end_char="782">cultivos</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="784" end_char="792">celulares</TOKEN>
<TOKEN id="token-4-18" pos="punct" morph="none" start_char="793" end_char="793">,</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="795" end_char="796">la</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="798" end_char="808">ivermectina</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="810" end_char="817">suprimió</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="819" end_char="820">el</TOKEN>
<TOKEN id="token-4-23" pos="unknown" morph="none" start_char="822" end_char="831">SARS-CoV-2</TOKEN>
<TOKEN id="token-4-24" pos="punct" morph="none" start_char="832" end_char="832">,</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="834" end_char="835">el</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="837" end_char="841">virus</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="843" end_char="845">que</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="847" end_char="851">causa</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="853" end_char="854">la</TOKEN>
<TOKEN id="token-4-30" pos="word" morph="none" start_char="856" end_char="860">covid</TOKEN>
<TOKEN id="token-4-31" pos="punct" morph="none" start_char="861" end_char="861">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="864" end_char="965">
<ORIGINAL_TEXT>Dichos hallazgos alentaron el uso del medicamento contra la COVID-19, especialmente en América Latina.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="864" end_char="869">Dichos</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="871" end_char="879">hallazgos</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="881" end_char="889">alentaron</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="891" end_char="892">el</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="894" end_char="896">uso</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="898" end_char="900">del</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="902" end_char="912">medicamento</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="914" end_char="919">contra</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="921" end_char="922">la</TOKEN>
<TOKEN id="token-5-9" pos="unknown" morph="none" start_char="924" end_char="931">COVID-19</TOKEN>
<TOKEN id="token-5-10" pos="punct" morph="none" start_char="932" end_char="932">,</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="934" end_char="946">especialmente</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="948" end_char="949">en</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="951" end_char="957">América</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="959" end_char="964">Latina</TOKEN>
<TOKEN id="token-5-15" pos="punct" morph="none" start_char="965" end_char="965">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="968" end_char="1171">
<ORIGINAL_TEXT>"La ivermectina se está usando actualmente ampliamente", dijo Eduardo López Medina, médico e investigador del Centro de Enfermedades Infecciosas Pediátricas en Cali, Colombia, que dirigió el nuevo ensayo.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="punct" morph="none" start_char="968" end_char="968">"</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="969" end_char="970">La</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="972" end_char="982">ivermectina</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="984" end_char="985">se</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="987" end_char="990">está</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="992" end_char="997">usando</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="999" end_char="1009">actualmente</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="1011" end_char="1021">ampliamente</TOKEN>
<TOKEN id="token-6-8" pos="punct" morph="none" start_char="1022" end_char="1023">",</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="1025" end_char="1028">dijo</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="1030" end_char="1036">Eduardo</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="1038" end_char="1042">López</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="1044" end_char="1049">Medina</TOKEN>
<TOKEN id="token-6-13" pos="punct" morph="none" start_char="1050" end_char="1050">,</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="1052" end_char="1057">médico</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="1059" end_char="1059">e</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="1061" end_char="1072">investigador</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="1074" end_char="1076">del</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="1078" end_char="1083">Centro</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="1085" end_char="1086">de</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="1088" end_char="1099">Enfermedades</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="1101" end_char="1111">Infecciosas</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="1113" end_char="1123">Pediátricas</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="1125" end_char="1126">en</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="1128" end_char="1131">Cali</TOKEN>
<TOKEN id="token-6-25" pos="punct" morph="none" start_char="1132" end_char="1132">,</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="1134" end_char="1141">Colombia</TOKEN>
<TOKEN id="token-6-27" pos="punct" morph="none" start_char="1142" end_char="1142">,</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="1144" end_char="1146">que</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="1148" end_char="1154">dirigió</TOKEN>
<TOKEN id="token-6-30" pos="word" morph="none" start_char="1156" end_char="1157">el</TOKEN>
<TOKEN id="token-6-31" pos="word" morph="none" start_char="1159" end_char="1163">nuevo</TOKEN>
<TOKEN id="token-6-32" pos="word" morph="none" start_char="1165" end_char="1170">ensayo</TOKEN>
<TOKEN id="token-6-33" pos="punct" morph="none" start_char="1171" end_char="1171">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="1173" end_char="1305">
<ORIGINAL_TEXT>"En muchos países en las Américas y en otras partes del mundo forma parte de los lineamientos nacionales de tratamiento de la covid".</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="punct" morph="none" start_char="1173" end_char="1173">"</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="1174" end_char="1175">En</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="1177" end_char="1182">muchos</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="1184" end_char="1189">países</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="1191" end_char="1192">en</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="1194" end_char="1196">las</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="1198" end_char="1205">Américas</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="1207" end_char="1207">y</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="1209" end_char="1210">en</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="1212" end_char="1216">otras</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="1218" end_char="1223">partes</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="1225" end_char="1227">del</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="1229" end_char="1233">mundo</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="1235" end_char="1239">forma</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="1241" end_char="1245">parte</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="1247" end_char="1248">de</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="1250" end_char="1252">los</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="1254" end_char="1265">lineamientos</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="1267" end_char="1276">nacionales</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="1278" end_char="1279">de</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="1281" end_char="1291">tratamiento</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="1293" end_char="1294">de</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="1296" end_char="1297">la</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="1299" end_char="1303">covid</TOKEN>
<TOKEN id="token-7-24" pos="punct" morph="none" start_char="1304" end_char="1305">".</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1308" end_char="1343">
<ORIGINAL_TEXT>Pero el fármaco ha causado división.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1308" end_char="1311">Pero</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1313" end_char="1314">el</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1316" end_char="1322">fármaco</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1324" end_char="1325">ha</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1327" end_char="1333">causado</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1335" end_char="1342">división</TOKEN>
<TOKEN id="token-8-6" pos="punct" morph="none" start_char="1343" end_char="1343">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1345" end_char="1526">
<ORIGINAL_TEXT>Aunque algunos científicos creen que tiene potencial, otros sospechan que para inhibir efectivamente al coronavirus se requieren dosis extremadamente altas y posiblemente peligrosas.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1345" end_char="1350">Aunque</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1352" end_char="1358">algunos</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1360" end_char="1370">científicos</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1372" end_char="1376">creen</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1378" end_char="1380">que</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1382" end_char="1386">tiene</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1388" end_char="1396">potencial</TOKEN>
<TOKEN id="token-9-7" pos="punct" morph="none" start_char="1397" end_char="1397">,</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1399" end_char="1403">otros</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1405" end_char="1413">sospechan</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1415" end_char="1417">que</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1419" end_char="1422">para</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1424" end_char="1430">inhibir</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1432" end_char="1444">efectivamente</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1446" end_char="1447">al</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1449" end_char="1459">coronavirus</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1461" end_char="1462">se</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1464" end_char="1472">requieren</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1474" end_char="1478">dosis</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1480" end_char="1493">extremadamente</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1495" end_char="1499">altas</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1501" end_char="1501">y</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1503" end_char="1514">posiblemente</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1516" end_char="1525">peligrosas</TOKEN>
<TOKEN id="token-9-24" pos="punct" morph="none" start_char="1526" end_char="1526">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1528" end_char="1797">
<ORIGINAL_TEXT>Los funcionarios de salud también temen que las personas, desesperadas por conseguir tratamientos para el coronavirus, puedan tomar versiones del medicamento que han sido formuladas para mascotas, ya que se emplea regularmente para prevenir dirofilariasis en los perros.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1528" end_char="1530">Los</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1532" end_char="1543">funcionarios</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1545" end_char="1546">de</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1548" end_char="1552">salud</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1554" end_char="1560">también</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1562" end_char="1566">temen</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1568" end_char="1570">que</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1572" end_char="1574">las</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1576" end_char="1583">personas</TOKEN>
<TOKEN id="token-10-9" pos="punct" morph="none" start_char="1584" end_char="1584">,</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1586" end_char="1597">desesperadas</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1599" end_char="1601">por</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1603" end_char="1611">conseguir</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1613" end_char="1624">tratamientos</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1626" end_char="1629">para</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1631" end_char="1632">el</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1634" end_char="1644">coronavirus</TOKEN>
<TOKEN id="token-10-17" pos="punct" morph="none" start_char="1645" end_char="1645">,</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1647" end_char="1652">puedan</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1654" end_char="1658">tomar</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1660" end_char="1668">versiones</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1670" end_char="1672">del</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1674" end_char="1684">medicamento</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1686" end_char="1688">que</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1690" end_char="1692">han</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="1694" end_char="1697">sido</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="1699" end_char="1708">formuladas</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="1710" end_char="1713">para</TOKEN>
<TOKEN id="token-10-28" pos="word" morph="none" start_char="1715" end_char="1722">mascotas</TOKEN>
<TOKEN id="token-10-29" pos="punct" morph="none" start_char="1723" end_char="1723">,</TOKEN>
<TOKEN id="token-10-30" pos="word" morph="none" start_char="1725" end_char="1726">ya</TOKEN>
<TOKEN id="token-10-31" pos="word" morph="none" start_char="1728" end_char="1730">que</TOKEN>
<TOKEN id="token-10-32" pos="word" morph="none" start_char="1732" end_char="1733">se</TOKEN>
<TOKEN id="token-10-33" pos="word" morph="none" start_char="1735" end_char="1740">emplea</TOKEN>
<TOKEN id="token-10-34" pos="word" morph="none" start_char="1742" end_char="1753">regularmente</TOKEN>
<TOKEN id="token-10-35" pos="word" morph="none" start_char="1755" end_char="1758">para</TOKEN>
<TOKEN id="token-10-36" pos="word" morph="none" start_char="1760" end_char="1767">prevenir</TOKEN>
<TOKEN id="token-10-37" pos="word" morph="none" start_char="1769" end_char="1782">dirofilariasis</TOKEN>
<TOKEN id="token-10-38" pos="word" morph="none" start_char="1784" end_char="1785">en</TOKEN>
<TOKEN id="token-10-39" pos="word" morph="none" start_char="1787" end_char="1789">los</TOKEN>
<TOKEN id="token-10-40" pos="word" morph="none" start_char="1791" end_char="1796">perros</TOKEN>
<TOKEN id="token-10-41" pos="punct" morph="none" start_char="1797" end_char="1797">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1800" end_char="2000">
<ORIGINAL_TEXT>"Ha habido muchas opiniones opuestas sobre esto, a veces opiniones extremadamente opuestas", dijo Carlos Chaccour, investigador del Instituto Barcelona para Salud Global que no participó en el estudio.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="punct" morph="none" start_char="1800" end_char="1800">"</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1801" end_char="1802">Ha</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1804" end_char="1809">habido</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1811" end_char="1816">muchas</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1818" end_char="1826">opiniones</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1828" end_char="1835">opuestas</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1837" end_char="1841">sobre</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1843" end_char="1846">esto</TOKEN>
<TOKEN id="token-11-8" pos="punct" morph="none" start_char="1847" end_char="1847">,</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1849" end_char="1849">a</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1851" end_char="1855">veces</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1857" end_char="1865">opiniones</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1867" end_char="1880">extremadamente</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1882" end_char="1889">opuestas</TOKEN>
<TOKEN id="token-11-14" pos="punct" morph="none" start_char="1890" end_char="1891">",</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1893" end_char="1896">dijo</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1898" end_char="1903">Carlos</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1905" end_char="1912">Chaccour</TOKEN>
<TOKEN id="token-11-18" pos="punct" morph="none" start_char="1913" end_char="1913">,</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="1915" end_char="1926">investigador</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1928" end_char="1930">del</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="1932" end_char="1940">Instituto</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="1942" end_char="1950">Barcelona</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="1952" end_char="1955">para</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="1957" end_char="1961">Salud</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="1963" end_char="1968">Global</TOKEN>
<TOKEN id="token-11-26" pos="word" morph="none" start_char="1970" end_char="1972">que</TOKEN>
<TOKEN id="token-11-27" pos="word" morph="none" start_char="1974" end_char="1975">no</TOKEN>
<TOKEN id="token-11-28" pos="word" morph="none" start_char="1977" end_char="1985">participó</TOKEN>
<TOKEN id="token-11-29" pos="word" morph="none" start_char="1987" end_char="1988">en</TOKEN>
<TOKEN id="token-11-30" pos="word" morph="none" start_char="1990" end_char="1991">el</TOKEN>
<TOKEN id="token-11-31" pos="word" morph="none" start_char="1993" end_char="1999">estudio</TOKEN>
<TOKEN id="token-11-32" pos="punct" morph="none" start_char="2000" end_char="2000">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="2002" end_char="2055">
<ORIGINAL_TEXT>"Creo que se ha convertido en otra hidroxicloroquina".</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="punct" morph="none" start_char="2002" end_char="2002">"</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="2003" end_char="2006">Creo</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="2008" end_char="2010">que</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="2012" end_char="2013">se</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="2015" end_char="2016">ha</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="2018" end_char="2027">convertido</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="2029" end_char="2030">en</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="2032" end_char="2035">otra</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="2037" end_char="2053">hidroxicloroquina</TOKEN>
<TOKEN id="token-12-9" pos="punct" morph="none" start_char="2054" end_char="2055">".</TOKEN>
</SEG>
<SEG id="segment-13" start_char="2058" end_char="2162">
<ORIGINAL_TEXT>Pero ni sus defensores ni sus críticos han tenido muchos datos rigurosos para apoyar sus puntos de vista.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="2058" end_char="2061">Pero</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="2063" end_char="2064">ni</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="2066" end_char="2068">sus</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="2070" end_char="2079">defensores</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="2081" end_char="2082">ni</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="2084" end_char="2086">sus</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="2088" end_char="2095">críticos</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="2097" end_char="2099">han</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="2101" end_char="2106">tenido</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="2108" end_char="2113">muchos</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="2115" end_char="2119">datos</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="2121" end_char="2129">rigurosos</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="2131" end_char="2134">para</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="2136" end_char="2141">apoyar</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="2143" end_char="2145">sus</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="2147" end_char="2152">puntos</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="2154" end_char="2155">de</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="2157" end_char="2161">vista</TOKEN>
<TOKEN id="token-13-18" pos="punct" morph="none" start_char="2162" end_char="2162">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="2164" end_char="2300">
<ORIGINAL_TEXT>Existen pocos ensayos bien controlados de la efectividad del medicamento contra la COVID-19, aunque se esperan más en los próximos meses.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="2164" end_char="2170">Existen</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="2172" end_char="2176">pocos</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="2178" end_char="2184">ensayos</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="2186" end_char="2189">bien</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="2191" end_char="2201">controlados</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="2203" end_char="2204">de</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="2206" end_char="2207">la</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="2209" end_char="2219">efectividad</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="2221" end_char="2223">del</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="2225" end_char="2235">medicamento</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="2237" end_char="2242">contra</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="2244" end_char="2245">la</TOKEN>
<TOKEN id="token-14-12" pos="unknown" morph="none" start_char="2247" end_char="2254">COVID-19</TOKEN>
<TOKEN id="token-14-13" pos="punct" morph="none" start_char="2255" end_char="2255">,</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="2257" end_char="2262">aunque</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="2264" end_char="2265">se</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="2267" end_char="2273">esperan</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="2275" end_char="2277">más</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="2279" end_char="2280">en</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="2282" end_char="2284">los</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="2286" end_char="2293">próximos</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="2295" end_char="2299">meses</TOKEN>
<TOKEN id="token-14-22" pos="punct" morph="none" start_char="2300" end_char="2300">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="2302" end_char="2510">
<ORIGINAL_TEXT>Y los lineamientos de tratamiento de los Institutos Nacionales de Salud de Estados Unidos advierten que no hay suficiente evidencia "para recomendar o desaconsejar" el uso del fármaco en pacientes de COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="2302" end_char="2302">Y</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="2304" end_char="2306">los</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="2308" end_char="2319">lineamientos</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="2321" end_char="2322">de</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="2324" end_char="2334">tratamiento</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="2336" end_char="2337">de</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="2339" end_char="2341">los</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="2343" end_char="2352">Institutos</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="2354" end_char="2363">Nacionales</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="2365" end_char="2366">de</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="2368" end_char="2372">Salud</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="2374" end_char="2375">de</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="2377" end_char="2383">Estados</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="2385" end_char="2390">Unidos</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="2392" end_char="2400">advierten</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="2402" end_char="2404">que</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="2406" end_char="2407">no</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="2409" end_char="2411">hay</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="2413" end_char="2422">suficiente</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="2424" end_char="2432">evidencia</TOKEN>
<TOKEN id="token-15-20" pos="punct" morph="none" start_char="2434" end_char="2434">"</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="2435" end_char="2438">para</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="2440" end_char="2449">recomendar</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="2451" end_char="2451">o</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="2453" end_char="2464">desaconsejar</TOKEN>
<TOKEN id="token-15-25" pos="punct" morph="none" start_char="2465" end_char="2465">"</TOKEN>
<TOKEN id="token-15-26" pos="word" morph="none" start_char="2467" end_char="2468">el</TOKEN>
<TOKEN id="token-15-27" pos="word" morph="none" start_char="2470" end_char="2472">uso</TOKEN>
<TOKEN id="token-15-28" pos="word" morph="none" start_char="2474" end_char="2476">del</TOKEN>
<TOKEN id="token-15-29" pos="word" morph="none" start_char="2478" end_char="2484">fármaco</TOKEN>
<TOKEN id="token-15-30" pos="word" morph="none" start_char="2486" end_char="2487">en</TOKEN>
<TOKEN id="token-15-31" pos="word" morph="none" start_char="2489" end_char="2497">pacientes</TOKEN>
<TOKEN id="token-15-32" pos="word" morph="none" start_char="2499" end_char="2500">de</TOKEN>
<TOKEN id="token-15-33" pos="unknown" morph="none" start_char="2502" end_char="2509">COVID-19</TOKEN>
<TOKEN id="token-15-34" pos="punct" morph="none" start_char="2510" end_char="2510">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="2513" end_char="2734">
<ORIGINAL_TEXT>En el nuevo estudio, López Medina y sus colegas asignaron aleatoriamente a más de 400 personas que recientemente habían desarrollado síntomas leves de COVID-19 que tomaran un esquema de cinco días de ivermectina o placebo.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="2513" end_char="2514">En</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="2516" end_char="2517">el</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="2519" end_char="2523">nuevo</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="2525" end_char="2531">estudio</TOKEN>
<TOKEN id="token-16-4" pos="punct" morph="none" start_char="2532" end_char="2532">,</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="2534" end_char="2538">López</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="2540" end_char="2545">Medina</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="2547" end_char="2547">y</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="2549" end_char="2551">sus</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="2553" end_char="2559">colegas</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="2561" end_char="2569">asignaron</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="2571" end_char="2584">aleatoriamente</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="2586" end_char="2586">a</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="2588" end_char="2590">más</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="2592" end_char="2593">de</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="2595" end_char="2597">400</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="2599" end_char="2606">personas</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="2608" end_char="2610">que</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="2612" end_char="2624">recientemente</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="2626" end_char="2631">habían</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="2633" end_char="2644">desarrollado</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="2646" end_char="2653">síntomas</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="2655" end_char="2659">leves</TOKEN>
<TOKEN id="token-16-23" pos="word" morph="none" start_char="2661" end_char="2662">de</TOKEN>
<TOKEN id="token-16-24" pos="unknown" morph="none" start_char="2664" end_char="2671">COVID-19</TOKEN>
<TOKEN id="token-16-25" pos="word" morph="none" start_char="2673" end_char="2675">que</TOKEN>
<TOKEN id="token-16-26" pos="word" morph="none" start_char="2677" end_char="2683">tomaran</TOKEN>
<TOKEN id="token-16-27" pos="word" morph="none" start_char="2685" end_char="2686">un</TOKEN>
<TOKEN id="token-16-28" pos="word" morph="none" start_char="2688" end_char="2694">esquema</TOKEN>
<TOKEN id="token-16-29" pos="word" morph="none" start_char="2696" end_char="2697">de</TOKEN>
<TOKEN id="token-16-30" pos="word" morph="none" start_char="2699" end_char="2703">cinco</TOKEN>
<TOKEN id="token-16-31" pos="word" morph="none" start_char="2705" end_char="2708">días</TOKEN>
<TOKEN id="token-16-32" pos="word" morph="none" start_char="2710" end_char="2711">de</TOKEN>
<TOKEN id="token-16-33" pos="word" morph="none" start_char="2713" end_char="2723">ivermectina</TOKEN>
<TOKEN id="token-16-34" pos="word" morph="none" start_char="2725" end_char="2725">o</TOKEN>
<TOKEN id="token-16-35" pos="word" morph="none" start_char="2727" end_char="2733">placebo</TOKEN>
<TOKEN id="token-16-36" pos="punct" morph="none" start_char="2734" end_char="2734">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2736" end_char="2957">
<ORIGINAL_TEXT>Encontraron que los síntomas de covid duraron alrededor de 10 días en las personas que recibieron el fármaco, en comparación con los 12 días de quienes recibieron el placebo, una diferencia estadísticamente insignificante.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2736" end_char="2746">Encontraron</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2748" end_char="2750">que</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2752" end_char="2754">los</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2756" end_char="2763">síntomas</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2765" end_char="2766">de</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2768" end_char="2772">covid</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2774" end_char="2780">duraron</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2782" end_char="2790">alrededor</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2792" end_char="2793">de</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2795" end_char="2796">10</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2798" end_char="2801">días</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2803" end_char="2804">en</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2806" end_char="2808">las</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2810" end_char="2817">personas</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2819" end_char="2821">que</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2823" end_char="2832">recibieron</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="2834" end_char="2835">el</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="2837" end_char="2843">fármaco</TOKEN>
<TOKEN id="token-17-18" pos="punct" morph="none" start_char="2844" end_char="2844">,</TOKEN>
<TOKEN id="token-17-19" pos="word" morph="none" start_char="2846" end_char="2847">en</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="2849" end_char="2859">comparación</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="2861" end_char="2863">con</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="2865" end_char="2867">los</TOKEN>
<TOKEN id="token-17-23" pos="word" morph="none" start_char="2869" end_char="2870">12</TOKEN>
<TOKEN id="token-17-24" pos="word" morph="none" start_char="2872" end_char="2875">días</TOKEN>
<TOKEN id="token-17-25" pos="word" morph="none" start_char="2877" end_char="2878">de</TOKEN>
<TOKEN id="token-17-26" pos="word" morph="none" start_char="2880" end_char="2886">quienes</TOKEN>
<TOKEN id="token-17-27" pos="word" morph="none" start_char="2888" end_char="2897">recibieron</TOKEN>
<TOKEN id="token-17-28" pos="word" morph="none" start_char="2899" end_char="2900">el</TOKEN>
<TOKEN id="token-17-29" pos="word" morph="none" start_char="2902" end_char="2908">placebo</TOKEN>
<TOKEN id="token-17-30" pos="punct" morph="none" start_char="2909" end_char="2909">,</TOKEN>
<TOKEN id="token-17-31" pos="word" morph="none" start_char="2911" end_char="2913">una</TOKEN>
<TOKEN id="token-17-32" pos="word" morph="none" start_char="2915" end_char="2924">diferencia</TOKEN>
<TOKEN id="token-17-33" pos="word" morph="none" start_char="2926" end_char="2941">estadísticamente</TOKEN>
<TOKEN id="token-17-34" pos="word" morph="none" start_char="2943" end_char="2956">insignificante</TOKEN>
<TOKEN id="token-17-35" pos="punct" morph="none" start_char="2957" end_char="2957">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2960" end_char="3186">
<ORIGINAL_TEXT>El nuevo ensayo añade datos clínicos muy necesarios para el debate sobre el uso de la ivermectina como tratamiento de la COVID-19, dijo Regina Rabinovich, médica e investigadora de salud global en la Escuela de Salud Pública T.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2960" end_char="2961">El</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2963" end_char="2967">nuevo</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2969" end_char="2974">ensayo</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2976" end_char="2980">añade</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2982" end_char="2986">datos</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2988" end_char="2995">clínicos</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2997" end_char="2999">muy</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="3001" end_char="3010">necesarios</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="3012" end_char="3015">para</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="3017" end_char="3018">el</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="3020" end_char="3025">debate</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="3027" end_char="3031">sobre</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="3033" end_char="3034">el</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="3036" end_char="3038">uso</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="3040" end_char="3041">de</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="3043" end_char="3044">la</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="3046" end_char="3056">ivermectina</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="3058" end_char="3061">como</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="3063" end_char="3073">tratamiento</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="3075" end_char="3076">de</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="3078" end_char="3079">la</TOKEN>
<TOKEN id="token-18-21" pos="unknown" morph="none" start_char="3081" end_char="3088">COVID-19</TOKEN>
<TOKEN id="token-18-22" pos="punct" morph="none" start_char="3089" end_char="3089">,</TOKEN>
<TOKEN id="token-18-23" pos="word" morph="none" start_char="3091" end_char="3094">dijo</TOKEN>
<TOKEN id="token-18-24" pos="word" morph="none" start_char="3096" end_char="3101">Regina</TOKEN>
<TOKEN id="token-18-25" pos="word" morph="none" start_char="3103" end_char="3112">Rabinovich</TOKEN>
<TOKEN id="token-18-26" pos="punct" morph="none" start_char="3113" end_char="3113">,</TOKEN>
<TOKEN id="token-18-27" pos="word" morph="none" start_char="3115" end_char="3120">médica</TOKEN>
<TOKEN id="token-18-28" pos="word" morph="none" start_char="3122" end_char="3122">e</TOKEN>
<TOKEN id="token-18-29" pos="word" morph="none" start_char="3124" end_char="3136">investigadora</TOKEN>
<TOKEN id="token-18-30" pos="word" morph="none" start_char="3138" end_char="3139">de</TOKEN>
<TOKEN id="token-18-31" pos="word" morph="none" start_char="3141" end_char="3145">salud</TOKEN>
<TOKEN id="token-18-32" pos="word" morph="none" start_char="3147" end_char="3152">global</TOKEN>
<TOKEN id="token-18-33" pos="word" morph="none" start_char="3154" end_char="3155">en</TOKEN>
<TOKEN id="token-18-34" pos="word" morph="none" start_char="3157" end_char="3158">la</TOKEN>
<TOKEN id="token-18-35" pos="word" morph="none" start_char="3160" end_char="3166">Escuela</TOKEN>
<TOKEN id="token-18-36" pos="word" morph="none" start_char="3168" end_char="3169">de</TOKEN>
<TOKEN id="token-18-37" pos="word" morph="none" start_char="3171" end_char="3175">Salud</TOKEN>
<TOKEN id="token-18-38" pos="word" morph="none" start_char="3177" end_char="3183">Pública</TOKEN>
<TOKEN id="token-18-39" pos="word" morph="none" start_char="3185" end_char="3185">T</TOKEN>
<TOKEN id="token-18-40" pos="punct" morph="none" start_char="3186" end_char="3186">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="3188" end_char="3238">
<ORIGINAL_TEXT>H. Chan de Harvard, que no participó en el estudio.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="3188" end_char="3188">H</TOKEN>
<TOKEN id="token-19-1" pos="punct" morph="none" start_char="3189" end_char="3189">.</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="3191" end_char="3194">Chan</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="3196" end_char="3197">de</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="3199" end_char="3205">Harvard</TOKEN>
<TOKEN id="token-19-5" pos="punct" morph="none" start_char="3206" end_char="3206">,</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="3208" end_char="3210">que</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="3212" end_char="3213">no</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="3215" end_char="3223">participó</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="3225" end_char="3226">en</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="3228" end_char="3229">el</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="3231" end_char="3237">estudio</TOKEN>
<TOKEN id="token-19-12" pos="punct" morph="none" start_char="3238" end_char="3238">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="3241" end_char="3427">
<ORIGINAL_TEXT>Pero observó que el ensayo era relativamente pequeño y no responde a la pregunta clínica más urgente que es si la ivermectina es capaz de prevenir enfermar de gravedad o evitar la muerte.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="3241" end_char="3244">Pero</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="3246" end_char="3252">observó</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="3254" end_char="3256">que</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="3258" end_char="3259">el</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="3261" end_char="3266">ensayo</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="3268" end_char="3270">era</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="3272" end_char="3284">relativamente</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="3286" end_char="3292">pequeño</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="3294" end_char="3294">y</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="3296" end_char="3297">no</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="3299" end_char="3306">responde</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="3308" end_char="3308">a</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="3310" end_char="3311">la</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="3313" end_char="3320">pregunta</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="3322" end_char="3328">clínica</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="3330" end_char="3332">más</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="3334" end_char="3340">urgente</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="3342" end_char="3344">que</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="3346" end_char="3347">es</TOKEN>
<TOKEN id="token-20-19" pos="word" morph="none" start_char="3349" end_char="3350">si</TOKEN>
<TOKEN id="token-20-20" pos="word" morph="none" start_char="3352" end_char="3353">la</TOKEN>
<TOKEN id="token-20-21" pos="word" morph="none" start_char="3355" end_char="3365">ivermectina</TOKEN>
<TOKEN id="token-20-22" pos="word" morph="none" start_char="3367" end_char="3368">es</TOKEN>
<TOKEN id="token-20-23" pos="word" morph="none" start_char="3370" end_char="3374">capaz</TOKEN>
<TOKEN id="token-20-24" pos="word" morph="none" start_char="3376" end_char="3377">de</TOKEN>
<TOKEN id="token-20-25" pos="word" morph="none" start_char="3379" end_char="3386">prevenir</TOKEN>
<TOKEN id="token-20-26" pos="word" morph="none" start_char="3388" end_char="3395">enfermar</TOKEN>
<TOKEN id="token-20-27" pos="word" morph="none" start_char="3397" end_char="3398">de</TOKEN>
<TOKEN id="token-20-28" pos="word" morph="none" start_char="3400" end_char="3407">gravedad</TOKEN>
<TOKEN id="token-20-29" pos="word" morph="none" start_char="3409" end_char="3409">o</TOKEN>
<TOKEN id="token-20-30" pos="word" morph="none" start_char="3411" end_char="3416">evitar</TOKEN>
<TOKEN id="token-20-31" pos="word" morph="none" start_char="3418" end_char="3419">la</TOKEN>
<TOKEN id="token-20-32" pos="word" morph="none" start_char="3421" end_char="3426">muerte</TOKEN>
<TOKEN id="token-20-33" pos="punct" morph="none" start_char="3427" end_char="3427">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="3429" end_char="3540">
<ORIGINAL_TEXT>"La duración de los síntomas puede que no sea el parámetro más importante ni clínico ni de salud pública", dijo.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="punct" morph="none" start_char="3429" end_char="3429">"</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="3430" end_char="3431">La</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="3433" end_char="3440">duración</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="3442" end_char="3443">de</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="3445" end_char="3447">los</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="3449" end_char="3456">síntomas</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="3458" end_char="3462">puede</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="3464" end_char="3466">que</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="3468" end_char="3469">no</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="3471" end_char="3473">sea</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="3475" end_char="3476">el</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="3478" end_char="3486">parámetro</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="3488" end_char="3490">más</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="3492" end_char="3501">importante</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="3503" end_char="3504">ni</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="3506" end_char="3512">clínico</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="3514" end_char="3515">ni</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="3517" end_char="3518">de</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="3520" end_char="3524">salud</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="3526" end_char="3532">pública</TOKEN>
<TOKEN id="token-21-20" pos="punct" morph="none" start_char="3533" end_char="3534">",</TOKEN>
<TOKEN id="token-21-21" pos="word" morph="none" start_char="3536" end_char="3539">dijo</TOKEN>
<TOKEN id="token-21-22" pos="punct" morph="none" start_char="3540" end_char="3540">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="3543" end_char="3800">
<ORIGINAL_TEXT>Los investigadores encontraron que siete pacientes del grupo placebo se deterioraron después de participar en el ensayo en comparación con cuatro del grupo de la ivermectina, pero los números eran muy pequeños como para llegar a una conclusión significativa.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="3543" end_char="3545">Los</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="3547" end_char="3560">investigadores</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="3562" end_char="3572">encontraron</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="3574" end_char="3576">que</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="3578" end_char="3582">siete</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="3584" end_char="3592">pacientes</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="3594" end_char="3596">del</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="3598" end_char="3602">grupo</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="3604" end_char="3610">placebo</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="3612" end_char="3613">se</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="3615" end_char="3626">deterioraron</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="3628" end_char="3634">después</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="3636" end_char="3637">de</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="3639" end_char="3648">participar</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="3650" end_char="3651">en</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="3653" end_char="3654">el</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="3656" end_char="3661">ensayo</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="3663" end_char="3664">en</TOKEN>
<TOKEN id="token-22-18" pos="word" morph="none" start_char="3666" end_char="3676">comparación</TOKEN>
<TOKEN id="token-22-19" pos="word" morph="none" start_char="3678" end_char="3680">con</TOKEN>
<TOKEN id="token-22-20" pos="word" morph="none" start_char="3682" end_char="3687">cuatro</TOKEN>
<TOKEN id="token-22-21" pos="word" morph="none" start_char="3689" end_char="3691">del</TOKEN>
<TOKEN id="token-22-22" pos="word" morph="none" start_char="3693" end_char="3697">grupo</TOKEN>
<TOKEN id="token-22-23" pos="word" morph="none" start_char="3699" end_char="3700">de</TOKEN>
<TOKEN id="token-22-24" pos="word" morph="none" start_char="3702" end_char="3703">la</TOKEN>
<TOKEN id="token-22-25" pos="word" morph="none" start_char="3705" end_char="3715">ivermectina</TOKEN>
<TOKEN id="token-22-26" pos="punct" morph="none" start_char="3716" end_char="3716">,</TOKEN>
<TOKEN id="token-22-27" pos="word" morph="none" start_char="3718" end_char="3721">pero</TOKEN>
<TOKEN id="token-22-28" pos="word" morph="none" start_char="3723" end_char="3725">los</TOKEN>
<TOKEN id="token-22-29" pos="word" morph="none" start_char="3727" end_char="3733">números</TOKEN>
<TOKEN id="token-22-30" pos="word" morph="none" start_char="3735" end_char="3738">eran</TOKEN>
<TOKEN id="token-22-31" pos="word" morph="none" start_char="3740" end_char="3742">muy</TOKEN>
<TOKEN id="token-22-32" pos="word" morph="none" start_char="3744" end_char="3751">pequeños</TOKEN>
<TOKEN id="token-22-33" pos="word" morph="none" start_char="3753" end_char="3756">como</TOKEN>
<TOKEN id="token-22-34" pos="word" morph="none" start_char="3758" end_char="3761">para</TOKEN>
<TOKEN id="token-22-35" pos="word" morph="none" start_char="3763" end_char="3768">llegar</TOKEN>
<TOKEN id="token-22-36" pos="word" morph="none" start_char="3770" end_char="3770">a</TOKEN>
<TOKEN id="token-22-37" pos="word" morph="none" start_char="3772" end_char="3774">una</TOKEN>
<TOKEN id="token-22-38" pos="word" morph="none" start_char="3776" end_char="3785">conclusión</TOKEN>
<TOKEN id="token-22-39" pos="word" morph="none" start_char="3787" end_char="3799">significativa</TOKEN>
<TOKEN id="token-22-40" pos="punct" morph="none" start_char="3800" end_char="3800">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="3803" end_char="3911">
<ORIGINAL_TEXT>"Hubo una pequeña señal ahí, y sería interesante ver si esa señal que vimos es real o no", dijo López Medina.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="punct" morph="none" start_char="3803" end_char="3803">"</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="3804" end_char="3807">Hubo</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="3809" end_char="3811">una</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="3813" end_char="3819">pequeña</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="3821" end_char="3825">señal</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="3827" end_char="3829">ahí</TOKEN>
<TOKEN id="token-23-6" pos="punct" morph="none" start_char="3830" end_char="3830">,</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="3832" end_char="3832">y</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="3834" end_char="3838">sería</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="3840" end_char="3850">interesante</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="3852" end_char="3854">ver</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="3856" end_char="3857">si</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="3859" end_char="3861">esa</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="3863" end_char="3867">señal</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="3869" end_char="3871">que</TOKEN>
<TOKEN id="token-23-15" pos="word" morph="none" start_char="3873" end_char="3877">vimos</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="3879" end_char="3880">es</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="3882" end_char="3885">real</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="3887" end_char="3887">o</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="3889" end_char="3890">no</TOKEN>
<TOKEN id="token-23-20" pos="punct" morph="none" start_char="3891" end_char="3892">",</TOKEN>
<TOKEN id="token-23-21" pos="word" morph="none" start_char="3894" end_char="3897">dijo</TOKEN>
<TOKEN id="token-23-22" pos="word" morph="none" start_char="3899" end_char="3903">López</TOKEN>
<TOKEN id="token-23-23" pos="word" morph="none" start_char="3905" end_char="3910">Medina</TOKEN>
<TOKEN id="token-23-24" pos="punct" morph="none" start_char="3911" end_char="3911">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="3913" end_char="3966">
<ORIGINAL_TEXT>"Pero eso tendría que responderse en un ensayo mayor".</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="punct" morph="none" start_char="3913" end_char="3913">"</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="3914" end_char="3917">Pero</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="3919" end_char="3921">eso</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="3923" end_char="3929">tendría</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="3931" end_char="3933">que</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="3935" end_char="3945">responderse</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="3947" end_char="3948">en</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="3950" end_char="3951">un</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="3953" end_char="3958">ensayo</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="3960" end_char="3964">mayor</TOKEN>
<TOKEN id="token-24-10" pos="punct" morph="none" start_char="3965" end_char="3966">".</TOKEN>
</SEG>
<SEG id="segment-25" start_char="3969" end_char="4177">
<ORIGINAL_TEXT>López Medina también comentó que la población del estudio era relativamente joven y saludable, con una edad promedio de 37 años y pocas de las comorbilidades que pueden hacer que la COVID-19 sea más peligrosa.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="3969" end_char="3973">López</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="3975" end_char="3980">Medina</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="3982" end_char="3988">también</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="3990" end_char="3996">comentó</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="3998" end_char="4000">que</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="4002" end_char="4003">la</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="4005" end_char="4013">población</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="4015" end_char="4017">del</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="4019" end_char="4025">estudio</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="4027" end_char="4029">era</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="4031" end_char="4043">relativamente</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="4045" end_char="4049">joven</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="4051" end_char="4051">y</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="4053" end_char="4061">saludable</TOKEN>
<TOKEN id="token-25-14" pos="punct" morph="none" start_char="4062" end_char="4062">,</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="4064" end_char="4066">con</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="4068" end_char="4070">una</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="4072" end_char="4075">edad</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="4077" end_char="4084">promedio</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="4086" end_char="4087">de</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="4089" end_char="4090">37</TOKEN>
<TOKEN id="token-25-21" pos="word" morph="none" start_char="4092" end_char="4095">años</TOKEN>
<TOKEN id="token-25-22" pos="word" morph="none" start_char="4097" end_char="4097">y</TOKEN>
<TOKEN id="token-25-23" pos="word" morph="none" start_char="4099" end_char="4103">pocas</TOKEN>
<TOKEN id="token-25-24" pos="word" morph="none" start_char="4105" end_char="4106">de</TOKEN>
<TOKEN id="token-25-25" pos="word" morph="none" start_char="4108" end_char="4110">las</TOKEN>
<TOKEN id="token-25-26" pos="word" morph="none" start_char="4112" end_char="4125">comorbilidades</TOKEN>
<TOKEN id="token-25-27" pos="word" morph="none" start_char="4127" end_char="4129">que</TOKEN>
<TOKEN id="token-25-28" pos="word" morph="none" start_char="4131" end_char="4136">pueden</TOKEN>
<TOKEN id="token-25-29" pos="word" morph="none" start_char="4138" end_char="4142">hacer</TOKEN>
<TOKEN id="token-25-30" pos="word" morph="none" start_char="4144" end_char="4146">que</TOKEN>
<TOKEN id="token-25-31" pos="word" morph="none" start_char="4148" end_char="4149">la</TOKEN>
<TOKEN id="token-25-32" pos="unknown" morph="none" start_char="4151" end_char="4158">COVID-19</TOKEN>
<TOKEN id="token-25-33" pos="word" morph="none" start_char="4160" end_char="4162">sea</TOKEN>
<TOKEN id="token-25-34" pos="word" morph="none" start_char="4164" end_char="4166">más</TOKEN>
<TOKEN id="token-25-35" pos="word" morph="none" start_char="4168" end_char="4176">peligrosa</TOKEN>
<TOKEN id="token-25-36" pos="punct" morph="none" start_char="4177" end_char="4177">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="4180" end_char="4385">
<ORIGINAL_TEXT>Actualmente se llevan a cabo ensayos mayores, que podrían dar respuestas más definitivas, dijo Rabinovich, quien comentó que ella era "totalmente neutral" respecto a la utilidad potencial de la ivermectina.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="4180" end_char="4190">Actualmente</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="4192" end_char="4193">se</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="4195" end_char="4200">llevan</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="4202" end_char="4202">a</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="4204" end_char="4207">cabo</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="4209" end_char="4215">ensayos</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="4217" end_char="4223">mayores</TOKEN>
<TOKEN id="token-26-7" pos="punct" morph="none" start_char="4224" end_char="4224">,</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="4226" end_char="4228">que</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="4230" end_char="4236">podrían</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="4238" end_char="4240">dar</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="4242" end_char="4251">respuestas</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="4253" end_char="4255">más</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="4257" end_char="4267">definitivas</TOKEN>
<TOKEN id="token-26-14" pos="punct" morph="none" start_char="4268" end_char="4268">,</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="4270" end_char="4273">dijo</TOKEN>
<TOKEN id="token-26-16" pos="word" morph="none" start_char="4275" end_char="4284">Rabinovich</TOKEN>
<TOKEN id="token-26-17" pos="punct" morph="none" start_char="4285" end_char="4285">,</TOKEN>
<TOKEN id="token-26-18" pos="word" morph="none" start_char="4287" end_char="4291">quien</TOKEN>
<TOKEN id="token-26-19" pos="word" morph="none" start_char="4293" end_char="4299">comentó</TOKEN>
<TOKEN id="token-26-20" pos="word" morph="none" start_char="4301" end_char="4303">que</TOKEN>
<TOKEN id="token-26-21" pos="word" morph="none" start_char="4305" end_char="4308">ella</TOKEN>
<TOKEN id="token-26-22" pos="word" morph="none" start_char="4310" end_char="4312">era</TOKEN>
<TOKEN id="token-26-23" pos="punct" morph="none" start_char="4314" end_char="4314">"</TOKEN>
<TOKEN id="token-26-24" pos="word" morph="none" start_char="4315" end_char="4324">totalmente</TOKEN>
<TOKEN id="token-26-25" pos="word" morph="none" start_char="4326" end_char="4332">neutral</TOKEN>
<TOKEN id="token-26-26" pos="punct" morph="none" start_char="4333" end_char="4333">"</TOKEN>
<TOKEN id="token-26-27" pos="word" morph="none" start_char="4335" end_char="4342">respecto</TOKEN>
<TOKEN id="token-26-28" pos="word" morph="none" start_char="4344" end_char="4344">a</TOKEN>
<TOKEN id="token-26-29" pos="word" morph="none" start_char="4346" end_char="4347">la</TOKEN>
<TOKEN id="token-26-30" pos="word" morph="none" start_char="4349" end_char="4356">utilidad</TOKEN>
<TOKEN id="token-26-31" pos="word" morph="none" start_char="4358" end_char="4366">potencial</TOKEN>
<TOKEN id="token-26-32" pos="word" morph="none" start_char="4368" end_char="4369">de</TOKEN>
<TOKEN id="token-26-33" pos="word" morph="none" start_char="4371" end_char="4372">la</TOKEN>
<TOKEN id="token-26-34" pos="word" morph="none" start_char="4374" end_char="4384">ivermectina</TOKEN>
<TOKEN id="token-26-35" pos="punct" morph="none" start_char="4385" end_char="4385">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="4387" end_char="4442">
<ORIGINAL_TEXT>"Solo quiero datos porque hay un gran caos en el campo".</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="punct" morph="none" start_char="4387" end_char="4387">"</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="4388" end_char="4391">Solo</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="4393" end_char="4398">quiero</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="4400" end_char="4404">datos</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="4406" end_char="4411">porque</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="4413" end_char="4415">hay</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="4417" end_char="4418">un</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="4420" end_char="4423">gran</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="4425" end_char="4428">caos</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="4430" end_char="4431">en</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="4433" end_char="4434">el</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="4436" end_char="4440">campo</TOKEN>
<TOKEN id="token-27-12" pos="punct" morph="none" start_char="4441" end_char="4442">".</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
