<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="ukr">
<DOC id="L0C049PHP" lang="ukr" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="4068" raw_text_md5="edaf2ea2ba22ace4741afeae967f4cb2">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="67">
<ORIGINAL_TEXT>Fact Checking: ¿Te puedes contagiar de coronavirus con un test PCR?</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="4">Fact</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="6" end_char="13">Checking</TOKEN>
<TOKEN id="token-0-2" pos="punct" morph="none" start_char="14" end_char="14">:</TOKEN>
<TOKEN id="token-0-3" pos="punct" morph="none" start_char="16" end_char="16">¿</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="17" end_char="18">Te</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="20" end_char="25">puedes</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="27" end_char="35">contagiar</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="37" end_char="38">de</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="40" end_char="50">coronavirus</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="52" end_char="54">con</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="56" end_char="57">un</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="59" end_char="62">test</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="64" end_char="66">PCR</TOKEN>
<TOKEN id="token-0-13" pos="punct" morph="none" start_char="67" end_char="67">?</TOKEN>
</SEG>
<SEG id="segment-1" start_char="69" end_char="170">
<ORIGINAL_TEXT>¿Personas asintomáticas no pueden transmitir el Covid-19, por lo que no es necesario usar mascarillas?</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="punct" morph="none" start_char="69" end_char="69">¿</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="70" end_char="77">Personas</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="79" end_char="91">asintomáticas</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="93" end_char="94">no</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="96" end_char="101">pueden</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="103" end_char="112">transmitir</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="114" end_char="115">el</TOKEN>
<TOKEN id="token-1-7" pos="unknown" morph="none" start_char="117" end_char="124">Covid-19</TOKEN>
<TOKEN id="token-1-8" pos="punct" morph="none" start_char="125" end_char="125">,</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="127" end_char="129">por</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="131" end_char="132">lo</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="134" end_char="136">que</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="138" end_char="139">no</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="141" end_char="142">es</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="144" end_char="152">necesario</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="154" end_char="157">usar</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="159" end_char="169">mascarillas</TOKEN>
<TOKEN id="token-1-17" pos="punct" morph="none" start_char="170" end_char="170">?</TOKEN>
</SEG>
<SEG id="segment-2" start_char="174" end_char="186">
<ORIGINAL_TEXT>Foto: Reuters</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="174" end_char="177">Foto</TOKEN>
<TOKEN id="token-2-1" pos="punct" morph="none" start_char="178" end_char="178">:</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="180" end_char="186">Reuters</TOKEN>
</SEG>
<SEG id="segment-3" start_char="190" end_char="444">
<ORIGINAL_TEXT>"Nos están enfermando a través de la prueba, según te sacan una muestra, pero más bien en la prueba te están metiendo el V1RU5", se lee en una publicación en Facebook, que incluye la portada de un artículo titulado "Nanorobot encontrado en la prueba PCR".</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="punct" morph="none" start_char="190" end_char="190">"</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="191" end_char="193">Nos</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="195" end_char="199">están</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="201" end_char="210">enfermando</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="212" end_char="212">a</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="214" end_char="219">través</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="221" end_char="222">de</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="224" end_char="225">la</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="227" end_char="232">prueba</TOKEN>
<TOKEN id="token-3-9" pos="punct" morph="none" start_char="233" end_char="233">,</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="235" end_char="239">según</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="241" end_char="242">te</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="244" end_char="248">sacan</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="250" end_char="252">una</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="254" end_char="260">muestra</TOKEN>
<TOKEN id="token-3-15" pos="punct" morph="none" start_char="261" end_char="261">,</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="263" end_char="266">pero</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="268" end_char="270">más</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="272" end_char="275">bien</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="277" end_char="278">en</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="280" end_char="281">la</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="283" end_char="288">prueba</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="290" end_char="291">te</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="293" end_char="297">están</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="299" end_char="306">metiendo</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="308" end_char="309">el</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="311" end_char="315">V1RU5</TOKEN>
<TOKEN id="token-3-27" pos="punct" morph="none" start_char="316" end_char="317">",</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="319" end_char="320">se</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="322" end_char="324">lee</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="326" end_char="327">en</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="329" end_char="331">una</TOKEN>
<TOKEN id="token-3-32" pos="word" morph="none" start_char="333" end_char="343">publicación</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="345" end_char="346">en</TOKEN>
<TOKEN id="token-3-34" pos="word" morph="none" start_char="348" end_char="355">Facebook</TOKEN>
<TOKEN id="token-3-35" pos="punct" morph="none" start_char="356" end_char="356">,</TOKEN>
<TOKEN id="token-3-36" pos="word" morph="none" start_char="358" end_char="360">que</TOKEN>
<TOKEN id="token-3-37" pos="word" morph="none" start_char="362" end_char="368">incluye</TOKEN>
<TOKEN id="token-3-38" pos="word" morph="none" start_char="370" end_char="371">la</TOKEN>
<TOKEN id="token-3-39" pos="word" morph="none" start_char="373" end_char="379">portada</TOKEN>
<TOKEN id="token-3-40" pos="word" morph="none" start_char="381" end_char="382">de</TOKEN>
<TOKEN id="token-3-41" pos="word" morph="none" start_char="384" end_char="385">un</TOKEN>
<TOKEN id="token-3-42" pos="word" morph="none" start_char="387" end_char="394">artículo</TOKEN>
<TOKEN id="token-3-43" pos="word" morph="none" start_char="396" end_char="403">titulado</TOKEN>
<TOKEN id="token-3-44" pos="punct" morph="none" start_char="405" end_char="405">"</TOKEN>
<TOKEN id="token-3-45" pos="word" morph="none" start_char="406" end_char="414">Nanorobot</TOKEN>
<TOKEN id="token-3-46" pos="word" morph="none" start_char="416" end_char="425">encontrado</TOKEN>
<TOKEN id="token-3-47" pos="word" morph="none" start_char="427" end_char="428">en</TOKEN>
<TOKEN id="token-3-48" pos="word" morph="none" start_char="430" end_char="431">la</TOKEN>
<TOKEN id="token-3-49" pos="word" morph="none" start_char="433" end_char="438">prueba</TOKEN>
<TOKEN id="token-3-50" pos="word" morph="none" start_char="440" end_char="442">PCR</TOKEN>
<TOKEN id="token-3-51" pos="punct" morph="none" start_char="443" end_char="444">".</TOKEN>
</SEG>
<SEG id="segment-4" start_char="447" end_char="650">
<ORIGINAL_TEXT>Con respecto a la publicación viralizada sobre el descubrimiento de nanorobots en las pruebas de PCR, Nicolás Muena, investigador de la Fundación Ciencia Vida, afirma que hay muchos errores en la noticia.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="447" end_char="449">Con</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="451" end_char="458">respecto</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="460" end_char="460">a</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="462" end_char="463">la</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="465" end_char="475">publicación</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="477" end_char="486">viralizada</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="488" end_char="492">sobre</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="494" end_char="495">el</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="497" end_char="510">descubrimiento</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="512" end_char="513">de</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="515" end_char="524">nanorobots</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="526" end_char="527">en</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="529" end_char="531">las</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="533" end_char="539">pruebas</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="541" end_char="542">de</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="544" end_char="546">PCR</TOKEN>
<TOKEN id="token-4-16" pos="punct" morph="none" start_char="547" end_char="547">,</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="549" end_char="555">Nicolás</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="557" end_char="561">Muena</TOKEN>
<TOKEN id="token-4-19" pos="punct" morph="none" start_char="562" end_char="562">,</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="564" end_char="575">investigador</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="577" end_char="578">de</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="580" end_char="581">la</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="583" end_char="591">Fundación</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="593" end_char="599">Ciencia</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="601" end_char="604">Vida</TOKEN>
<TOKEN id="token-4-26" pos="punct" morph="none" start_char="605" end_char="605">,</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="607" end_char="612">afirma</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="614" end_char="616">que</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="618" end_char="620">hay</TOKEN>
<TOKEN id="token-4-30" pos="word" morph="none" start_char="622" end_char="627">muchos</TOKEN>
<TOKEN id="token-4-31" pos="word" morph="none" start_char="629" end_char="635">errores</TOKEN>
<TOKEN id="token-4-32" pos="word" morph="none" start_char="637" end_char="638">en</TOKEN>
<TOKEN id="token-4-33" pos="word" morph="none" start_char="640" end_char="641">la</TOKEN>
<TOKEN id="token-4-34" pos="word" morph="none" start_char="643" end_char="649">noticia</TOKEN>
<TOKEN id="token-4-35" pos="punct" morph="none" start_char="650" end_char="650">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="653" end_char="694">
<ORIGINAL_TEXT>Uno es sobre estos supuestos "nanorobots".</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="653" end_char="655">Uno</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="657" end_char="658">es</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="660" end_char="664">sobre</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="666" end_char="670">estos</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="672" end_char="680">supuestos</TOKEN>
<TOKEN id="token-5-5" pos="punct" morph="none" start_char="682" end_char="682">"</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="683" end_char="692">nanorobots</TOKEN>
<TOKEN id="token-5-7" pos="punct" morph="none" start_char="693" end_char="694">".</TOKEN>
</SEG>
<SEG id="segment-6" start_char="696" end_char="890">
<ORIGINAL_TEXT>Muena sostiene que este sería un concepto más asociado a la ciencia ficción, como la ilustración que acompaña a la publicación que no posee las dimensiones mencionadas en el cuerpo de la noticia.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="696" end_char="700">Muena</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="702" end_char="709">sostiene</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="711" end_char="713">que</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="715" end_char="718">este</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="720" end_char="724">sería</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="726" end_char="727">un</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="729" end_char="736">concepto</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="738" end_char="740">más</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="742" end_char="749">asociado</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="751" end_char="751">a</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="753" end_char="754">la</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="756" end_char="762">ciencia</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="764" end_char="770">ficción</TOKEN>
<TOKEN id="token-6-13" pos="punct" morph="none" start_char="771" end_char="771">,</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="773" end_char="776">como</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="778" end_char="779">la</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="781" end_char="791">ilustración</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="793" end_char="795">que</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="797" end_char="804">acompaña</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="806" end_char="806">a</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="808" end_char="809">la</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="811" end_char="821">publicación</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="823" end_char="825">que</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="827" end_char="828">no</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="830" end_char="834">posee</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="836" end_char="838">las</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="840" end_char="850">dimensiones</TOKEN>
<TOKEN id="token-6-27" pos="word" morph="none" start_char="852" end_char="862">mencionadas</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="864" end_char="865">en</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="867" end_char="868">el</TOKEN>
<TOKEN id="token-6-30" pos="word" morph="none" start_char="870" end_char="875">cuerpo</TOKEN>
<TOKEN id="token-6-31" pos="word" morph="none" start_char="877" end_char="878">de</TOKEN>
<TOKEN id="token-6-32" pos="word" morph="none" start_char="880" end_char="881">la</TOKEN>
<TOKEN id="token-6-33" pos="word" morph="none" start_char="883" end_char="889">noticia</TOKEN>
<TOKEN id="token-6-34" pos="punct" morph="none" start_char="890" end_char="890">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="892" end_char="931">
<ORIGINAL_TEXT>Lo más "parecido" sería la nanomedicina.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="892" end_char="893">Lo</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="895" end_char="897">más</TOKEN>
<TOKEN id="token-7-2" pos="punct" morph="none" start_char="899" end_char="899">"</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="900" end_char="907">parecido</TOKEN>
<TOKEN id="token-7-4" pos="punct" morph="none" start_char="908" end_char="908">"</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="910" end_char="914">sería</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="916" end_char="917">la</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="919" end_char="930">nanomedicina</TOKEN>
<TOKEN id="token-7-8" pos="punct" morph="none" start_char="931" end_char="931">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="934" end_char="1196">
<ORIGINAL_TEXT>Roberto Olivares, jefe de Infectología de Clínica Dávila, señala que lamentablemente hay muchas personas en redes sociales, "que quizás por ignorancia, inconsciencia e irresponsabilidad, difunden noticias que son falsas, y no tienen ningún fundamento científico".</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="934" end_char="940">Roberto</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="942" end_char="949">Olivares</TOKEN>
<TOKEN id="token-8-2" pos="punct" morph="none" start_char="950" end_char="950">,</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="952" end_char="955">jefe</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="957" end_char="958">de</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="960" end_char="971">Infectología</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="973" end_char="974">de</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="976" end_char="982">Clínica</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="984" end_char="989">Dávila</TOKEN>
<TOKEN id="token-8-9" pos="punct" morph="none" start_char="990" end_char="990">,</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="992" end_char="997">señala</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="999" end_char="1001">que</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1003" end_char="1017">lamentablemente</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1019" end_char="1021">hay</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1023" end_char="1028">muchas</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1030" end_char="1037">personas</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1039" end_char="1040">en</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1042" end_char="1046">redes</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1048" end_char="1055">sociales</TOKEN>
<TOKEN id="token-8-19" pos="punct" morph="none" start_char="1056" end_char="1056">,</TOKEN>
<TOKEN id="token-8-20" pos="punct" morph="none" start_char="1058" end_char="1058">"</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="1059" end_char="1061">que</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="1063" end_char="1068">quizás</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="1070" end_char="1072">por</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="1074" end_char="1083">ignorancia</TOKEN>
<TOKEN id="token-8-25" pos="punct" morph="none" start_char="1084" end_char="1084">,</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="1086" end_char="1098">inconsciencia</TOKEN>
<TOKEN id="token-8-27" pos="word" morph="none" start_char="1100" end_char="1100">e</TOKEN>
<TOKEN id="token-8-28" pos="word" morph="none" start_char="1102" end_char="1118">irresponsabilidad</TOKEN>
<TOKEN id="token-8-29" pos="punct" morph="none" start_char="1119" end_char="1119">,</TOKEN>
<TOKEN id="token-8-30" pos="word" morph="none" start_char="1121" end_char="1128">difunden</TOKEN>
<TOKEN id="token-8-31" pos="word" morph="none" start_char="1130" end_char="1137">noticias</TOKEN>
<TOKEN id="token-8-32" pos="word" morph="none" start_char="1139" end_char="1141">que</TOKEN>
<TOKEN id="token-8-33" pos="word" morph="none" start_char="1143" end_char="1145">son</TOKEN>
<TOKEN id="token-8-34" pos="word" morph="none" start_char="1147" end_char="1152">falsas</TOKEN>
<TOKEN id="token-8-35" pos="punct" morph="none" start_char="1153" end_char="1153">,</TOKEN>
<TOKEN id="token-8-36" pos="word" morph="none" start_char="1155" end_char="1155">y</TOKEN>
<TOKEN id="token-8-37" pos="word" morph="none" start_char="1157" end_char="1158">no</TOKEN>
<TOKEN id="token-8-38" pos="word" morph="none" start_char="1160" end_char="1165">tienen</TOKEN>
<TOKEN id="token-8-39" pos="word" morph="none" start_char="1167" end_char="1172">ningún</TOKEN>
<TOKEN id="token-8-40" pos="word" morph="none" start_char="1174" end_char="1183">fundamento</TOKEN>
<TOKEN id="token-8-41" pos="word" morph="none" start_char="1185" end_char="1194">científico</TOKEN>
<TOKEN id="token-8-42" pos="punct" morph="none" start_char="1195" end_char="1196">".</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1199" end_char="1448">
<ORIGINAL_TEXT>Sin embargo, indica el investigador de Ciencia Vida, esta área no estaría relacionada con "robots", sino, más bien con proteínas, nanopartículas lipídicas, que nunca alcanzarían dimensiones tan pequeñas como las descritas en la nota (2,5 nanómetros).</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1199" end_char="1201">Sin</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1203" end_char="1209">embargo</TOKEN>
<TOKEN id="token-9-2" pos="punct" morph="none" start_char="1210" end_char="1210">,</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1212" end_char="1217">indica</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1219" end_char="1220">el</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1222" end_char="1233">investigador</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1235" end_char="1236">de</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1238" end_char="1244">Ciencia</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1246" end_char="1249">Vida</TOKEN>
<TOKEN id="token-9-9" pos="punct" morph="none" start_char="1250" end_char="1250">,</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1252" end_char="1255">esta</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1257" end_char="1260">área</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1262" end_char="1263">no</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1265" end_char="1271">estaría</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1273" end_char="1283">relacionada</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1285" end_char="1287">con</TOKEN>
<TOKEN id="token-9-16" pos="punct" morph="none" start_char="1289" end_char="1289">"</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1290" end_char="1295">robots</TOKEN>
<TOKEN id="token-9-18" pos="punct" morph="none" start_char="1296" end_char="1297">",</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1299" end_char="1302">sino</TOKEN>
<TOKEN id="token-9-20" pos="punct" morph="none" start_char="1303" end_char="1303">,</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1305" end_char="1307">más</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1309" end_char="1312">bien</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1314" end_char="1316">con</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1318" end_char="1326">proteínas</TOKEN>
<TOKEN id="token-9-25" pos="punct" morph="none" start_char="1327" end_char="1327">,</TOKEN>
<TOKEN id="token-9-26" pos="word" morph="none" start_char="1329" end_char="1342">nanopartículas</TOKEN>
<TOKEN id="token-9-27" pos="word" morph="none" start_char="1344" end_char="1352">lipídicas</TOKEN>
<TOKEN id="token-9-28" pos="punct" morph="none" start_char="1353" end_char="1353">,</TOKEN>
<TOKEN id="token-9-29" pos="word" morph="none" start_char="1355" end_char="1357">que</TOKEN>
<TOKEN id="token-9-30" pos="word" morph="none" start_char="1359" end_char="1363">nunca</TOKEN>
<TOKEN id="token-9-31" pos="word" morph="none" start_char="1365" end_char="1375">alcanzarían</TOKEN>
<TOKEN id="token-9-32" pos="word" morph="none" start_char="1377" end_char="1387">dimensiones</TOKEN>
<TOKEN id="token-9-33" pos="word" morph="none" start_char="1389" end_char="1391">tan</TOKEN>
<TOKEN id="token-9-34" pos="word" morph="none" start_char="1393" end_char="1400">pequeñas</TOKEN>
<TOKEN id="token-9-35" pos="word" morph="none" start_char="1402" end_char="1405">como</TOKEN>
<TOKEN id="token-9-36" pos="word" morph="none" start_char="1407" end_char="1409">las</TOKEN>
<TOKEN id="token-9-37" pos="word" morph="none" start_char="1411" end_char="1419">descritas</TOKEN>
<TOKEN id="token-9-38" pos="word" morph="none" start_char="1421" end_char="1422">en</TOKEN>
<TOKEN id="token-9-39" pos="word" morph="none" start_char="1424" end_char="1425">la</TOKEN>
<TOKEN id="token-9-40" pos="word" morph="none" start_char="1427" end_char="1430">nota</TOKEN>
<TOKEN id="token-9-41" pos="punct" morph="none" start_char="1432" end_char="1432">(</TOKEN>
<TOKEN id="token-9-42" pos="unknown" morph="none" start_char="1433" end_char="1435">2,5</TOKEN>
<TOKEN id="token-9-43" pos="word" morph="none" start_char="1437" end_char="1446">nanómetros</TOKEN>
<TOKEN id="token-9-44" pos="punct" morph="none" start_char="1447" end_char="1448">).</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1450" end_char="1500">
<ORIGINAL_TEXT>"Es demasiado chico, incluso para la nanomedicina".</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="punct" morph="none" start_char="1450" end_char="1450">"</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1451" end_char="1452">Es</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1454" end_char="1462">demasiado</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1464" end_char="1468">chico</TOKEN>
<TOKEN id="token-10-4" pos="punct" morph="none" start_char="1469" end_char="1469">,</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1471" end_char="1477">incluso</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1479" end_char="1482">para</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1484" end_char="1485">la</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1487" end_char="1498">nanomedicina</TOKEN>
<TOKEN id="token-10-9" pos="punct" morph="none" start_char="1499" end_char="1500">".</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1503" end_char="1640">
<ORIGINAL_TEXT>Olivares señala que no ha visto publicado en ningún portal de noticias serio, "que puedan estar introduciendo nanorobots, osea es delirio.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1503" end_char="1510">Olivares</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1512" end_char="1517">señala</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1519" end_char="1521">que</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1523" end_char="1524">no</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1526" end_char="1527">ha</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1529" end_char="1533">visto</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1535" end_char="1543">publicado</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1545" end_char="1546">en</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1548" end_char="1553">ningún</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1555" end_char="1560">portal</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1562" end_char="1563">de</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1565" end_char="1572">noticias</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1574" end_char="1578">serio</TOKEN>
<TOKEN id="token-11-13" pos="punct" morph="none" start_char="1579" end_char="1579">,</TOKEN>
<TOKEN id="token-11-14" pos="punct" morph="none" start_char="1581" end_char="1581">"</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1582" end_char="1584">que</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1586" end_char="1591">puedan</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1593" end_char="1597">estar</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1599" end_char="1611">introduciendo</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="1613" end_char="1622">nanorobots</TOKEN>
<TOKEN id="token-11-20" pos="punct" morph="none" start_char="1623" end_char="1623">,</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="1625" end_char="1628">osea</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="1630" end_char="1631">es</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="1633" end_char="1639">delirio</TOKEN>
<TOKEN id="token-11-24" pos="punct" morph="none" start_char="1640" end_char="1640">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1642" end_char="1691">
<ORIGINAL_TEXT>Ni siquiera es una noticia falsa, ya es delirante.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1642" end_char="1643">Ni</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1645" end_char="1652">siquiera</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1654" end_char="1655">es</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1657" end_char="1659">una</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1661" end_char="1667">noticia</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1669" end_char="1673">falsa</TOKEN>
<TOKEN id="token-12-6" pos="punct" morph="none" start_char="1674" end_char="1674">,</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1676" end_char="1677">ya</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1679" end_char="1680">es</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1682" end_char="1690">delirante</TOKEN>
<TOKEN id="token-12-10" pos="punct" morph="none" start_char="1691" end_char="1691">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1693" end_char="1839">
<ORIGINAL_TEXT>Hay que tener mucho cuidado de dónde se obtiene la información, ya que estamos inundados de noticias como ésta, que confunden a la opinión pública.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1693" end_char="1695">Hay</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1697" end_char="1699">que</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1701" end_char="1705">tener</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1707" end_char="1711">mucho</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1713" end_char="1719">cuidado</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1721" end_char="1722">de</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1724" end_char="1728">dónde</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1730" end_char="1731">se</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1733" end_char="1739">obtiene</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1741" end_char="1742">la</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1744" end_char="1754">información</TOKEN>
<TOKEN id="token-13-11" pos="punct" morph="none" start_char="1755" end_char="1755">,</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1757" end_char="1758">ya</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1760" end_char="1762">que</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1764" end_char="1770">estamos</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1772" end_char="1780">inundados</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1782" end_char="1783">de</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1785" end_char="1792">noticias</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1794" end_char="1797">como</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1799" end_char="1802">ésta</TOKEN>
<TOKEN id="token-13-20" pos="punct" morph="none" start_char="1803" end_char="1803">,</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="1805" end_char="1807">que</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="1809" end_char="1817">confunden</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="1819" end_char="1819">a</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="1821" end_char="1822">la</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="1824" end_char="1830">opinión</TOKEN>
<TOKEN id="token-13-26" pos="word" morph="none" start_char="1832" end_char="1838">pública</TOKEN>
<TOKEN id="token-13-27" pos="punct" morph="none" start_char="1839" end_char="1839">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1841" end_char="1907">
<ORIGINAL_TEXT>Todo esto es falso y tampoco hay evidencia seria que lo demuestre".</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1841" end_char="1844">Todo</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1846" end_char="1849">esto</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1851" end_char="1852">es</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1854" end_char="1858">falso</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1860" end_char="1860">y</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1862" end_char="1868">tampoco</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1870" end_char="1872">hay</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1874" end_char="1882">evidencia</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1884" end_char="1888">seria</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1890" end_char="1892">que</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1894" end_char="1895">lo</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1897" end_char="1905">demuestre</TOKEN>
<TOKEN id="token-14-12" pos="punct" morph="none" start_char="1906" end_char="1907">".</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1910" end_char="1987">
<ORIGINAL_TEXT>Fact Checking: ¿Personas que reciben vacuna forman parte de un ensayo clínico?</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1910" end_char="1913">Fact</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1915" end_char="1922">Checking</TOKEN>
<TOKEN id="token-15-2" pos="punct" morph="none" start_char="1923" end_char="1923">:</TOKEN>
<TOKEN id="token-15-3" pos="punct" morph="none" start_char="1925" end_char="1925">¿</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1926" end_char="1933">Personas</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1935" end_char="1937">que</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1939" end_char="1945">reciben</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1947" end_char="1952">vacuna</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1954" end_char="1959">forman</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1961" end_char="1965">parte</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1967" end_char="1968">de</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1970" end_char="1971">un</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1973" end_char="1978">ensayo</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1980" end_char="1986">clínico</TOKEN>
<TOKEN id="token-15-14" pos="punct" morph="none" start_char="1987" end_char="1987">?</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1989" end_char="2039">
<ORIGINAL_TEXT>¿El fin de la pandemia está cerca y sin vacunación?</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="punct" morph="none" start_char="1989" end_char="1989">¿</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1990" end_char="1991">El</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1993" end_char="1995">fin</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1997" end_char="1998">de</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="2000" end_char="2001">la</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="2003" end_char="2010">pandemia</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="2012" end_char="2015">está</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="2017" end_char="2021">cerca</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="2023" end_char="2023">y</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="2025" end_char="2027">sin</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="2029" end_char="2038">vacunación</TOKEN>
<TOKEN id="token-16-11" pos="punct" morph="none" start_char="2039" end_char="2039">?</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2043" end_char="2348">
<ORIGINAL_TEXT>Además, en el punto donde señala que se habrían encontrado en la prueba PCR, Muena advierte que es imposible que el hisopo pueda romper la barrera hematoencefálica como se menciona en la publicación, y esto tampoco sería fácil, ya que esta barrera es muy selectiva sobre lo que pasa o no por su estructura.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2043" end_char="2048">Además</TOKEN>
<TOKEN id="token-17-1" pos="punct" morph="none" start_char="2049" end_char="2049">,</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2051" end_char="2052">en</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2054" end_char="2055">el</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2057" end_char="2061">punto</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2063" end_char="2067">donde</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2069" end_char="2074">señala</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2076" end_char="2078">que</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2080" end_char="2081">se</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2083" end_char="2089">habrían</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2091" end_char="2100">encontrado</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2102" end_char="2103">en</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2105" end_char="2106">la</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2108" end_char="2113">prueba</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2115" end_char="2117">PCR</TOKEN>
<TOKEN id="token-17-15" pos="punct" morph="none" start_char="2118" end_char="2118">,</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="2120" end_char="2124">Muena</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="2126" end_char="2133">advierte</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="2135" end_char="2137">que</TOKEN>
<TOKEN id="token-17-19" pos="word" morph="none" start_char="2139" end_char="2140">es</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="2142" end_char="2150">imposible</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="2152" end_char="2154">que</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="2156" end_char="2157">el</TOKEN>
<TOKEN id="token-17-23" pos="word" morph="none" start_char="2159" end_char="2164">hisopo</TOKEN>
<TOKEN id="token-17-24" pos="word" morph="none" start_char="2166" end_char="2170">pueda</TOKEN>
<TOKEN id="token-17-25" pos="word" morph="none" start_char="2172" end_char="2177">romper</TOKEN>
<TOKEN id="token-17-26" pos="word" morph="none" start_char="2179" end_char="2180">la</TOKEN>
<TOKEN id="token-17-27" pos="word" morph="none" start_char="2182" end_char="2188">barrera</TOKEN>
<TOKEN id="token-17-28" pos="word" morph="none" start_char="2190" end_char="2205">hematoencefálica</TOKEN>
<TOKEN id="token-17-29" pos="word" morph="none" start_char="2207" end_char="2210">como</TOKEN>
<TOKEN id="token-17-30" pos="word" morph="none" start_char="2212" end_char="2213">se</TOKEN>
<TOKEN id="token-17-31" pos="word" morph="none" start_char="2215" end_char="2222">menciona</TOKEN>
<TOKEN id="token-17-32" pos="word" morph="none" start_char="2224" end_char="2225">en</TOKEN>
<TOKEN id="token-17-33" pos="word" morph="none" start_char="2227" end_char="2228">la</TOKEN>
<TOKEN id="token-17-34" pos="word" morph="none" start_char="2230" end_char="2240">publicación</TOKEN>
<TOKEN id="token-17-35" pos="punct" morph="none" start_char="2241" end_char="2241">,</TOKEN>
<TOKEN id="token-17-36" pos="word" morph="none" start_char="2243" end_char="2243">y</TOKEN>
<TOKEN id="token-17-37" pos="word" morph="none" start_char="2245" end_char="2248">esto</TOKEN>
<TOKEN id="token-17-38" pos="word" morph="none" start_char="2250" end_char="2256">tampoco</TOKEN>
<TOKEN id="token-17-39" pos="word" morph="none" start_char="2258" end_char="2262">sería</TOKEN>
<TOKEN id="token-17-40" pos="word" morph="none" start_char="2264" end_char="2268">fácil</TOKEN>
<TOKEN id="token-17-41" pos="punct" morph="none" start_char="2269" end_char="2269">,</TOKEN>
<TOKEN id="token-17-42" pos="word" morph="none" start_char="2271" end_char="2272">ya</TOKEN>
<TOKEN id="token-17-43" pos="word" morph="none" start_char="2274" end_char="2276">que</TOKEN>
<TOKEN id="token-17-44" pos="word" morph="none" start_char="2278" end_char="2281">esta</TOKEN>
<TOKEN id="token-17-45" pos="word" morph="none" start_char="2283" end_char="2289">barrera</TOKEN>
<TOKEN id="token-17-46" pos="word" morph="none" start_char="2291" end_char="2292">es</TOKEN>
<TOKEN id="token-17-47" pos="word" morph="none" start_char="2294" end_char="2296">muy</TOKEN>
<TOKEN id="token-17-48" pos="word" morph="none" start_char="2298" end_char="2306">selectiva</TOKEN>
<TOKEN id="token-17-49" pos="word" morph="none" start_char="2308" end_char="2312">sobre</TOKEN>
<TOKEN id="token-17-50" pos="word" morph="none" start_char="2314" end_char="2315">lo</TOKEN>
<TOKEN id="token-17-51" pos="word" morph="none" start_char="2317" end_char="2319">que</TOKEN>
<TOKEN id="token-17-52" pos="word" morph="none" start_char="2321" end_char="2324">pasa</TOKEN>
<TOKEN id="token-17-53" pos="word" morph="none" start_char="2326" end_char="2326">o</TOKEN>
<TOKEN id="token-17-54" pos="word" morph="none" start_char="2328" end_char="2329">no</TOKEN>
<TOKEN id="token-17-55" pos="word" morph="none" start_char="2331" end_char="2333">por</TOKEN>
<TOKEN id="token-17-56" pos="word" morph="none" start_char="2335" end_char="2336">su</TOKEN>
<TOKEN id="token-17-57" pos="word" morph="none" start_char="2338" end_char="2347">estructura</TOKEN>
<TOKEN id="token-17-58" pos="punct" morph="none" start_char="2348" end_char="2348">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2351" end_char="2600">
<ORIGINAL_TEXT>"Me niego a participar en una conspiración médica que dice que usar una máscara (mascarilla) es saludable y todos pretendemos que las personas sanas están enfermas y pueden enfermarnos a todos", es el texto que se ha difundido por las redes sociales.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="punct" morph="none" start_char="2351" end_char="2351">"</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2352" end_char="2353">Me</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2355" end_char="2359">niego</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2361" end_char="2361">a</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2363" end_char="2372">participar</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2374" end_char="2375">en</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2377" end_char="2379">una</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2381" end_char="2392">conspiración</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2394" end_char="2399">médica</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="2401" end_char="2403">que</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="2405" end_char="2408">dice</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="2410" end_char="2412">que</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2414" end_char="2417">usar</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="2419" end_char="2421">una</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="2423" end_char="2429">máscara</TOKEN>
<TOKEN id="token-18-15" pos="punct" morph="none" start_char="2431" end_char="2431">(</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="2432" end_char="2441">mascarilla</TOKEN>
<TOKEN id="token-18-17" pos="punct" morph="none" start_char="2442" end_char="2442">)</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="2444" end_char="2445">es</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="2447" end_char="2455">saludable</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="2457" end_char="2457">y</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="2459" end_char="2463">todos</TOKEN>
<TOKEN id="token-18-22" pos="word" morph="none" start_char="2465" end_char="2475">pretendemos</TOKEN>
<TOKEN id="token-18-23" pos="word" morph="none" start_char="2477" end_char="2479">que</TOKEN>
<TOKEN id="token-18-24" pos="word" morph="none" start_char="2481" end_char="2483">las</TOKEN>
<TOKEN id="token-18-25" pos="word" morph="none" start_char="2485" end_char="2492">personas</TOKEN>
<TOKEN id="token-18-26" pos="word" morph="none" start_char="2494" end_char="2498">sanas</TOKEN>
<TOKEN id="token-18-27" pos="word" morph="none" start_char="2500" end_char="2504">están</TOKEN>
<TOKEN id="token-18-28" pos="word" morph="none" start_char="2506" end_char="2513">enfermas</TOKEN>
<TOKEN id="token-18-29" pos="word" morph="none" start_char="2515" end_char="2515">y</TOKEN>
<TOKEN id="token-18-30" pos="word" morph="none" start_char="2517" end_char="2522">pueden</TOKEN>
<TOKEN id="token-18-31" pos="word" morph="none" start_char="2524" end_char="2534">enfermarnos</TOKEN>
<TOKEN id="token-18-32" pos="word" morph="none" start_char="2536" end_char="2536">a</TOKEN>
<TOKEN id="token-18-33" pos="word" morph="none" start_char="2538" end_char="2542">todos</TOKEN>
<TOKEN id="token-18-34" pos="punct" morph="none" start_char="2543" end_char="2544">",</TOKEN>
<TOKEN id="token-18-35" pos="word" morph="none" start_char="2546" end_char="2547">es</TOKEN>
<TOKEN id="token-18-36" pos="word" morph="none" start_char="2549" end_char="2550">el</TOKEN>
<TOKEN id="token-18-37" pos="word" morph="none" start_char="2552" end_char="2556">texto</TOKEN>
<TOKEN id="token-18-38" pos="word" morph="none" start_char="2558" end_char="2560">que</TOKEN>
<TOKEN id="token-18-39" pos="word" morph="none" start_char="2562" end_char="2563">se</TOKEN>
<TOKEN id="token-18-40" pos="word" morph="none" start_char="2565" end_char="2566">ha</TOKEN>
<TOKEN id="token-18-41" pos="word" morph="none" start_char="2568" end_char="2576">difundido</TOKEN>
<TOKEN id="token-18-42" pos="word" morph="none" start_char="2578" end_char="2580">por</TOKEN>
<TOKEN id="token-18-43" pos="word" morph="none" start_char="2582" end_char="2584">las</TOKEN>
<TOKEN id="token-18-44" pos="word" morph="none" start_char="2586" end_char="2590">redes</TOKEN>
<TOKEN id="token-18-45" pos="word" morph="none" start_char="2592" end_char="2599">sociales</TOKEN>
<TOKEN id="token-18-46" pos="punct" morph="none" start_char="2600" end_char="2600">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2603" end_char="3033">
<ORIGINAL_TEXT>Ignacio Silva, infectólogo y académico de la Dirección de Postgrados de la Facultad de Medicina de la U. de Santiago indica que la afirmación no es correcta, ya que se ha demostrado en distintas publicaciones científicas que aproximadamente un tercio de las personas infectadas por Covid-19 son asintomáticas, convirtiendo a los asintomáticos en agentes claves en la cadena de transmisión, porque son los más difíciles de rastrear.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2603" end_char="2609">Ignacio</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2611" end_char="2615">Silva</TOKEN>
<TOKEN id="token-19-2" pos="punct" morph="none" start_char="2616" end_char="2616">,</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2618" end_char="2628">infectólogo</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2630" end_char="2630">y</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2632" end_char="2640">académico</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2642" end_char="2643">de</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2645" end_char="2646">la</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2648" end_char="2656">Dirección</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="2658" end_char="2659">de</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="2661" end_char="2670">Postgrados</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="2672" end_char="2673">de</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="2675" end_char="2676">la</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="2678" end_char="2685">Facultad</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="2687" end_char="2688">de</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="2690" end_char="2697">Medicina</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="2699" end_char="2700">de</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="2702" end_char="2703">la</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="2705" end_char="2705">U</TOKEN>
<TOKEN id="token-19-19" pos="punct" morph="none" start_char="2706" end_char="2706">.</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="2708" end_char="2709">de</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="2711" end_char="2718">Santiago</TOKEN>
<TOKEN id="token-19-22" pos="word" morph="none" start_char="2720" end_char="2725">indica</TOKEN>
<TOKEN id="token-19-23" pos="word" morph="none" start_char="2727" end_char="2729">que</TOKEN>
<TOKEN id="token-19-24" pos="word" morph="none" start_char="2731" end_char="2732">la</TOKEN>
<TOKEN id="token-19-25" pos="word" morph="none" start_char="2734" end_char="2743">afirmación</TOKEN>
<TOKEN id="token-19-26" pos="word" morph="none" start_char="2745" end_char="2746">no</TOKEN>
<TOKEN id="token-19-27" pos="word" morph="none" start_char="2748" end_char="2749">es</TOKEN>
<TOKEN id="token-19-28" pos="word" morph="none" start_char="2751" end_char="2758">correcta</TOKEN>
<TOKEN id="token-19-29" pos="punct" morph="none" start_char="2759" end_char="2759">,</TOKEN>
<TOKEN id="token-19-30" pos="word" morph="none" start_char="2761" end_char="2762">ya</TOKEN>
<TOKEN id="token-19-31" pos="word" morph="none" start_char="2764" end_char="2766">que</TOKEN>
<TOKEN id="token-19-32" pos="word" morph="none" start_char="2768" end_char="2769">se</TOKEN>
<TOKEN id="token-19-33" pos="word" morph="none" start_char="2771" end_char="2772">ha</TOKEN>
<TOKEN id="token-19-34" pos="word" morph="none" start_char="2774" end_char="2783">demostrado</TOKEN>
<TOKEN id="token-19-35" pos="word" morph="none" start_char="2785" end_char="2786">en</TOKEN>
<TOKEN id="token-19-36" pos="word" morph="none" start_char="2788" end_char="2796">distintas</TOKEN>
<TOKEN id="token-19-37" pos="word" morph="none" start_char="2798" end_char="2810">publicaciones</TOKEN>
<TOKEN id="token-19-38" pos="word" morph="none" start_char="2812" end_char="2822">científicas</TOKEN>
<TOKEN id="token-19-39" pos="word" morph="none" start_char="2824" end_char="2826">que</TOKEN>
<TOKEN id="token-19-40" pos="word" morph="none" start_char="2828" end_char="2842">aproximadamente</TOKEN>
<TOKEN id="token-19-41" pos="word" morph="none" start_char="2844" end_char="2845">un</TOKEN>
<TOKEN id="token-19-42" pos="word" morph="none" start_char="2847" end_char="2852">tercio</TOKEN>
<TOKEN id="token-19-43" pos="word" morph="none" start_char="2854" end_char="2855">de</TOKEN>
<TOKEN id="token-19-44" pos="word" morph="none" start_char="2857" end_char="2859">las</TOKEN>
<TOKEN id="token-19-45" pos="word" morph="none" start_char="2861" end_char="2868">personas</TOKEN>
<TOKEN id="token-19-46" pos="word" morph="none" start_char="2870" end_char="2879">infectadas</TOKEN>
<TOKEN id="token-19-47" pos="word" morph="none" start_char="2881" end_char="2883">por</TOKEN>
<TOKEN id="token-19-48" pos="unknown" morph="none" start_char="2885" end_char="2892">Covid-19</TOKEN>
<TOKEN id="token-19-49" pos="word" morph="none" start_char="2894" end_char="2896">son</TOKEN>
<TOKEN id="token-19-50" pos="word" morph="none" start_char="2898" end_char="2910">asintomáticas</TOKEN>
<TOKEN id="token-19-51" pos="punct" morph="none" start_char="2911" end_char="2911">,</TOKEN>
<TOKEN id="token-19-52" pos="word" morph="none" start_char="2913" end_char="2924">convirtiendo</TOKEN>
<TOKEN id="token-19-53" pos="word" morph="none" start_char="2926" end_char="2926">a</TOKEN>
<TOKEN id="token-19-54" pos="word" morph="none" start_char="2928" end_char="2930">los</TOKEN>
<TOKEN id="token-19-55" pos="word" morph="none" start_char="2932" end_char="2944">asintomáticos</TOKEN>
<TOKEN id="token-19-56" pos="word" morph="none" start_char="2946" end_char="2947">en</TOKEN>
<TOKEN id="token-19-57" pos="word" morph="none" start_char="2949" end_char="2955">agentes</TOKEN>
<TOKEN id="token-19-58" pos="word" morph="none" start_char="2957" end_char="2962">claves</TOKEN>
<TOKEN id="token-19-59" pos="word" morph="none" start_char="2964" end_char="2965">en</TOKEN>
<TOKEN id="token-19-60" pos="word" morph="none" start_char="2967" end_char="2968">la</TOKEN>
<TOKEN id="token-19-61" pos="word" morph="none" start_char="2970" end_char="2975">cadena</TOKEN>
<TOKEN id="token-19-62" pos="word" morph="none" start_char="2977" end_char="2978">de</TOKEN>
<TOKEN id="token-19-63" pos="word" morph="none" start_char="2980" end_char="2990">transmisión</TOKEN>
<TOKEN id="token-19-64" pos="punct" morph="none" start_char="2991" end_char="2991">,</TOKEN>
<TOKEN id="token-19-65" pos="word" morph="none" start_char="2993" end_char="2998">porque</TOKEN>
<TOKEN id="token-19-66" pos="word" morph="none" start_char="3000" end_char="3002">son</TOKEN>
<TOKEN id="token-19-67" pos="word" morph="none" start_char="3004" end_char="3006">los</TOKEN>
<TOKEN id="token-19-68" pos="word" morph="none" start_char="3008" end_char="3010">más</TOKEN>
<TOKEN id="token-19-69" pos="word" morph="none" start_char="3012" end_char="3020">difíciles</TOKEN>
<TOKEN id="token-19-70" pos="word" morph="none" start_char="3022" end_char="3023">de</TOKEN>
<TOKEN id="token-19-71" pos="word" morph="none" start_char="3025" end_char="3032">rastrear</TOKEN>
<TOKEN id="token-19-72" pos="punct" morph="none" start_char="3033" end_char="3033">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="3036" end_char="3065">
<ORIGINAL_TEXT>Olivares concuerda, "es falso.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="3036" end_char="3043">Olivares</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="3045" end_char="3053">concuerda</TOKEN>
<TOKEN id="token-20-2" pos="punct" morph="none" start_char="3054" end_char="3054">,</TOKEN>
<TOKEN id="token-20-3" pos="punct" morph="none" start_char="3056" end_char="3056">"</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="3057" end_char="3058">es</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="3060" end_char="3064">falso</TOKEN>
<TOKEN id="token-20-6" pos="punct" morph="none" start_char="3065" end_char="3065">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="3067" end_char="3224">
<ORIGINAL_TEXT>Puede que eventualmente la capacidad o eficiencia de transmisión sea menor que el sintomático, pero eso no quiere decir que no puedan transmitir la infección.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="3067" end_char="3071">Puede</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="3073" end_char="3075">que</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="3077" end_char="3089">eventualmente</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="3091" end_char="3092">la</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="3094" end_char="3102">capacidad</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="3104" end_char="3104">o</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="3106" end_char="3115">eficiencia</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="3117" end_char="3118">de</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="3120" end_char="3130">transmisión</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="3132" end_char="3134">sea</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="3136" end_char="3140">menor</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="3142" end_char="3144">que</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="3146" end_char="3147">el</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="3149" end_char="3159">sintomático</TOKEN>
<TOKEN id="token-21-14" pos="punct" morph="none" start_char="3160" end_char="3160">,</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="3162" end_char="3165">pero</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="3167" end_char="3169">eso</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="3171" end_char="3172">no</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="3174" end_char="3179">quiere</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="3181" end_char="3185">decir</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="3187" end_char="3189">que</TOKEN>
<TOKEN id="token-21-21" pos="word" morph="none" start_char="3191" end_char="3192">no</TOKEN>
<TOKEN id="token-21-22" pos="word" morph="none" start_char="3194" end_char="3199">puedan</TOKEN>
<TOKEN id="token-21-23" pos="word" morph="none" start_char="3201" end_char="3210">transmitir</TOKEN>
<TOKEN id="token-21-24" pos="word" morph="none" start_char="3212" end_char="3213">la</TOKEN>
<TOKEN id="token-21-25" pos="word" morph="none" start_char="3215" end_char="3223">infección</TOKEN>
<TOKEN id="token-21-26" pos="punct" morph="none" start_char="3224" end_char="3224">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="3226" end_char="3472">
<ORIGINAL_TEXT>Ya sabemos que es un virus que tiene una alta capacidad de ser transmitido, así que por lo tanto, hay mucha evidencia y trabajos serios, donde se demuestra que una de las mejores armas para cuidarnos y evitar la infección, es el uso de mascarilla.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="3226" end_char="3227">Ya</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="3229" end_char="3235">sabemos</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="3237" end_char="3239">que</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="3241" end_char="3242">es</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="3244" end_char="3245">un</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="3247" end_char="3251">virus</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="3253" end_char="3255">que</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="3257" end_char="3261">tiene</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="3263" end_char="3265">una</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="3267" end_char="3270">alta</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="3272" end_char="3280">capacidad</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="3282" end_char="3283">de</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="3285" end_char="3287">ser</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="3289" end_char="3299">transmitido</TOKEN>
<TOKEN id="token-22-14" pos="punct" morph="none" start_char="3300" end_char="3300">,</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="3302" end_char="3304">así</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="3306" end_char="3308">que</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="3310" end_char="3312">por</TOKEN>
<TOKEN id="token-22-18" pos="word" morph="none" start_char="3314" end_char="3315">lo</TOKEN>
<TOKEN id="token-22-19" pos="word" morph="none" start_char="3317" end_char="3321">tanto</TOKEN>
<TOKEN id="token-22-20" pos="punct" morph="none" start_char="3322" end_char="3322">,</TOKEN>
<TOKEN id="token-22-21" pos="word" morph="none" start_char="3324" end_char="3326">hay</TOKEN>
<TOKEN id="token-22-22" pos="word" morph="none" start_char="3328" end_char="3332">mucha</TOKEN>
<TOKEN id="token-22-23" pos="word" morph="none" start_char="3334" end_char="3342">evidencia</TOKEN>
<TOKEN id="token-22-24" pos="word" morph="none" start_char="3344" end_char="3344">y</TOKEN>
<TOKEN id="token-22-25" pos="word" morph="none" start_char="3346" end_char="3353">trabajos</TOKEN>
<TOKEN id="token-22-26" pos="word" morph="none" start_char="3355" end_char="3360">serios</TOKEN>
<TOKEN id="token-22-27" pos="punct" morph="none" start_char="3361" end_char="3361">,</TOKEN>
<TOKEN id="token-22-28" pos="word" morph="none" start_char="3363" end_char="3367">donde</TOKEN>
<TOKEN id="token-22-29" pos="word" morph="none" start_char="3369" end_char="3370">se</TOKEN>
<TOKEN id="token-22-30" pos="word" morph="none" start_char="3372" end_char="3380">demuestra</TOKEN>
<TOKEN id="token-22-31" pos="word" morph="none" start_char="3382" end_char="3384">que</TOKEN>
<TOKEN id="token-22-32" pos="word" morph="none" start_char="3386" end_char="3388">una</TOKEN>
<TOKEN id="token-22-33" pos="word" morph="none" start_char="3390" end_char="3391">de</TOKEN>
<TOKEN id="token-22-34" pos="word" morph="none" start_char="3393" end_char="3395">las</TOKEN>
<TOKEN id="token-22-35" pos="word" morph="none" start_char="3397" end_char="3403">mejores</TOKEN>
<TOKEN id="token-22-36" pos="word" morph="none" start_char="3405" end_char="3409">armas</TOKEN>
<TOKEN id="token-22-37" pos="word" morph="none" start_char="3411" end_char="3414">para</TOKEN>
<TOKEN id="token-22-38" pos="word" morph="none" start_char="3416" end_char="3424">cuidarnos</TOKEN>
<TOKEN id="token-22-39" pos="word" morph="none" start_char="3426" end_char="3426">y</TOKEN>
<TOKEN id="token-22-40" pos="word" morph="none" start_char="3428" end_char="3433">evitar</TOKEN>
<TOKEN id="token-22-41" pos="word" morph="none" start_char="3435" end_char="3436">la</TOKEN>
<TOKEN id="token-22-42" pos="word" morph="none" start_char="3438" end_char="3446">infección</TOKEN>
<TOKEN id="token-22-43" pos="punct" morph="none" start_char="3447" end_char="3447">,</TOKEN>
<TOKEN id="token-22-44" pos="word" morph="none" start_char="3449" end_char="3450">es</TOKEN>
<TOKEN id="token-22-45" pos="word" morph="none" start_char="3452" end_char="3453">el</TOKEN>
<TOKEN id="token-22-46" pos="word" morph="none" start_char="3455" end_char="3457">uso</TOKEN>
<TOKEN id="token-22-47" pos="word" morph="none" start_char="3459" end_char="3460">de</TOKEN>
<TOKEN id="token-22-48" pos="word" morph="none" start_char="3462" end_char="3471">mascarilla</TOKEN>
<TOKEN id="token-22-49" pos="punct" morph="none" start_char="3472" end_char="3472">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="3474" end_char="3512">
<ORIGINAL_TEXT>Es una de las herramientas más útiles".</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="3474" end_char="3475">Es</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="3477" end_char="3479">una</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="3481" end_char="3482">de</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="3484" end_char="3486">las</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="3488" end_char="3499">herramientas</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="3501" end_char="3503">más</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="3505" end_char="3510">útiles</TOKEN>
<TOKEN id="token-23-7" pos="punct" morph="none" start_char="3511" end_char="3512">".</TOKEN>
</SEG>
<SEG id="segment-24" start_char="3515" end_char="3668">
<ORIGINAL_TEXT>Es por esto, sostiene Silva, que se hace muy importante el uso de mascarillas en todo momento, y más en estas personas que creen que no están contagiadas.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="3515" end_char="3516">Es</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="3518" end_char="3520">por</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="3522" end_char="3525">esto</TOKEN>
<TOKEN id="token-24-3" pos="punct" morph="none" start_char="3526" end_char="3526">,</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="3528" end_char="3535">sostiene</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="3537" end_char="3541">Silva</TOKEN>
<TOKEN id="token-24-6" pos="punct" morph="none" start_char="3542" end_char="3542">,</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="3544" end_char="3546">que</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="3548" end_char="3549">se</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="3551" end_char="3554">hace</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="3556" end_char="3558">muy</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="3560" end_char="3569">importante</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="3571" end_char="3572">el</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="3574" end_char="3576">uso</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="3578" end_char="3579">de</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="3581" end_char="3591">mascarillas</TOKEN>
<TOKEN id="token-24-16" pos="word" morph="none" start_char="3593" end_char="3594">en</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="3596" end_char="3599">todo</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="3601" end_char="3607">momento</TOKEN>
<TOKEN id="token-24-19" pos="punct" morph="none" start_char="3608" end_char="3608">,</TOKEN>
<TOKEN id="token-24-20" pos="word" morph="none" start_char="3610" end_char="3610">y</TOKEN>
<TOKEN id="token-24-21" pos="word" morph="none" start_char="3612" end_char="3614">más</TOKEN>
<TOKEN id="token-24-22" pos="word" morph="none" start_char="3616" end_char="3617">en</TOKEN>
<TOKEN id="token-24-23" pos="word" morph="none" start_char="3619" end_char="3623">estas</TOKEN>
<TOKEN id="token-24-24" pos="word" morph="none" start_char="3625" end_char="3632">personas</TOKEN>
<TOKEN id="token-24-25" pos="word" morph="none" start_char="3634" end_char="3636">que</TOKEN>
<TOKEN id="token-24-26" pos="word" morph="none" start_char="3638" end_char="3642">creen</TOKEN>
<TOKEN id="token-24-27" pos="word" morph="none" start_char="3644" end_char="3646">que</TOKEN>
<TOKEN id="token-24-28" pos="word" morph="none" start_char="3648" end_char="3649">no</TOKEN>
<TOKEN id="token-24-29" pos="word" morph="none" start_char="3651" end_char="3655">están</TOKEN>
<TOKEN id="token-24-30" pos="word" morph="none" start_char="3657" end_char="3667">contagiadas</TOKEN>
<TOKEN id="token-24-31" pos="punct" morph="none" start_char="3668" end_char="3668">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="3671" end_char="3905">
<ORIGINAL_TEXT>Además, con respecto a lo que continuaba en el mensaje difundido en redes sociales, sobre lo "poco sano" que sería usarlas, el académico de la Usach asegura que su uso es una de las medidas que más nos ha ayudado a detener la pandemia.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="3671" end_char="3676">Además</TOKEN>
<TOKEN id="token-25-1" pos="punct" morph="none" start_char="3677" end_char="3677">,</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="3679" end_char="3681">con</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="3683" end_char="3690">respecto</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="3692" end_char="3692">a</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="3694" end_char="3695">lo</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="3697" end_char="3699">que</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="3701" end_char="3710">continuaba</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="3712" end_char="3713">en</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="3715" end_char="3716">el</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="3718" end_char="3724">mensaje</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="3726" end_char="3734">difundido</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="3736" end_char="3737">en</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="3739" end_char="3743">redes</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="3745" end_char="3752">sociales</TOKEN>
<TOKEN id="token-25-15" pos="punct" morph="none" start_char="3753" end_char="3753">,</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="3755" end_char="3759">sobre</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="3761" end_char="3762">lo</TOKEN>
<TOKEN id="token-25-18" pos="punct" morph="none" start_char="3764" end_char="3764">"</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="3765" end_char="3768">poco</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="3770" end_char="3773">sano</TOKEN>
<TOKEN id="token-25-21" pos="punct" morph="none" start_char="3774" end_char="3774">"</TOKEN>
<TOKEN id="token-25-22" pos="word" morph="none" start_char="3776" end_char="3778">que</TOKEN>
<TOKEN id="token-25-23" pos="word" morph="none" start_char="3780" end_char="3784">sería</TOKEN>
<TOKEN id="token-25-24" pos="word" morph="none" start_char="3786" end_char="3792">usarlas</TOKEN>
<TOKEN id="token-25-25" pos="punct" morph="none" start_char="3793" end_char="3793">,</TOKEN>
<TOKEN id="token-25-26" pos="word" morph="none" start_char="3795" end_char="3796">el</TOKEN>
<TOKEN id="token-25-27" pos="word" morph="none" start_char="3798" end_char="3806">académico</TOKEN>
<TOKEN id="token-25-28" pos="word" morph="none" start_char="3808" end_char="3809">de</TOKEN>
<TOKEN id="token-25-29" pos="word" morph="none" start_char="3811" end_char="3812">la</TOKEN>
<TOKEN id="token-25-30" pos="word" morph="none" start_char="3814" end_char="3818">Usach</TOKEN>
<TOKEN id="token-25-31" pos="word" morph="none" start_char="3820" end_char="3826">asegura</TOKEN>
<TOKEN id="token-25-32" pos="word" morph="none" start_char="3828" end_char="3830">que</TOKEN>
<TOKEN id="token-25-33" pos="word" morph="none" start_char="3832" end_char="3833">su</TOKEN>
<TOKEN id="token-25-34" pos="word" morph="none" start_char="3835" end_char="3837">uso</TOKEN>
<TOKEN id="token-25-35" pos="word" morph="none" start_char="3839" end_char="3840">es</TOKEN>
<TOKEN id="token-25-36" pos="word" morph="none" start_char="3842" end_char="3844">una</TOKEN>
<TOKEN id="token-25-37" pos="word" morph="none" start_char="3846" end_char="3847">de</TOKEN>
<TOKEN id="token-25-38" pos="word" morph="none" start_char="3849" end_char="3851">las</TOKEN>
<TOKEN id="token-25-39" pos="word" morph="none" start_char="3853" end_char="3859">medidas</TOKEN>
<TOKEN id="token-25-40" pos="word" morph="none" start_char="3861" end_char="3863">que</TOKEN>
<TOKEN id="token-25-41" pos="word" morph="none" start_char="3865" end_char="3867">más</TOKEN>
<TOKEN id="token-25-42" pos="word" morph="none" start_char="3869" end_char="3871">nos</TOKEN>
<TOKEN id="token-25-43" pos="word" morph="none" start_char="3873" end_char="3874">ha</TOKEN>
<TOKEN id="token-25-44" pos="word" morph="none" start_char="3876" end_char="3882">ayudado</TOKEN>
<TOKEN id="token-25-45" pos="word" morph="none" start_char="3884" end_char="3884">a</TOKEN>
<TOKEN id="token-25-46" pos="word" morph="none" start_char="3886" end_char="3892">detener</TOKEN>
<TOKEN id="token-25-47" pos="word" morph="none" start_char="3894" end_char="3895">la</TOKEN>
<TOKEN id="token-25-48" pos="word" morph="none" start_char="3897" end_char="3904">pandemia</TOKEN>
<TOKEN id="token-25-49" pos="punct" morph="none" start_char="3905" end_char="3905">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="3907" end_char="4064">
<ORIGINAL_TEXT>Agrega que son extremadamente seguras, sobre todo en adultos, y no generan ninguna complicación en relación a otras enfermedades o a problemas de oxigenación.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="3907" end_char="3912">Agrega</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="3914" end_char="3916">que</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="3918" end_char="3920">son</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="3922" end_char="3935">extremadamente</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="3937" end_char="3943">seguras</TOKEN>
<TOKEN id="token-26-5" pos="punct" morph="none" start_char="3944" end_char="3944">,</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="3946" end_char="3950">sobre</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="3952" end_char="3955">todo</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="3957" end_char="3958">en</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="3960" end_char="3966">adultos</TOKEN>
<TOKEN id="token-26-10" pos="punct" morph="none" start_char="3967" end_char="3967">,</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="3969" end_char="3969">y</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="3971" end_char="3972">no</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="3974" end_char="3980">generan</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="3982" end_char="3988">ninguna</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="3990" end_char="4001">complicación</TOKEN>
<TOKEN id="token-26-16" pos="word" morph="none" start_char="4003" end_char="4004">en</TOKEN>
<TOKEN id="token-26-17" pos="word" morph="none" start_char="4006" end_char="4013">relación</TOKEN>
<TOKEN id="token-26-18" pos="word" morph="none" start_char="4015" end_char="4015">a</TOKEN>
<TOKEN id="token-26-19" pos="word" morph="none" start_char="4017" end_char="4021">otras</TOKEN>
<TOKEN id="token-26-20" pos="word" morph="none" start_char="4023" end_char="4034">enfermedades</TOKEN>
<TOKEN id="token-26-21" pos="word" morph="none" start_char="4036" end_char="4036">o</TOKEN>
<TOKEN id="token-26-22" pos="word" morph="none" start_char="4038" end_char="4038">a</TOKEN>
<TOKEN id="token-26-23" pos="word" morph="none" start_char="4040" end_char="4048">problemas</TOKEN>
<TOKEN id="token-26-24" pos="word" morph="none" start_char="4050" end_char="4051">de</TOKEN>
<TOKEN id="token-26-25" pos="word" morph="none" start_char="4053" end_char="4063">oxigenación</TOKEN>
<TOKEN id="token-26-26" pos="punct" morph="none" start_char="4064" end_char="4064">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
