<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATFQ" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="4729" raw_text_md5="1c65b4560d900411ec02c10c9f4de716">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="111">
<ORIGINAL_TEXT>Immunity for YEARS or DECADES: Covid resistance may last much longer than previously thought, says new research</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="8">Immunity</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="10" end_char="12">for</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="14" end_char="18">YEARS</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="20" end_char="21">or</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="23" end_char="29">DECADES</TOKEN>
<TOKEN id="token-0-5" pos="punct" morph="none" start_char="30" end_char="30">:</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="32" end_char="36">Covid</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="38" end_char="47">resistance</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="49" end_char="51">may</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="53" end_char="56">last</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="58" end_char="61">much</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="63" end_char="68">longer</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="70" end_char="73">than</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="75" end_char="84">previously</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="86" end_char="92">thought</TOKEN>
<TOKEN id="token-0-15" pos="punct" morph="none" start_char="93" end_char="93">,</TOKEN>
<TOKEN id="token-0-16" pos="word" morph="none" start_char="95" end_char="98">says</TOKEN>
<TOKEN id="token-0-17" pos="word" morph="none" start_char="100" end_char="102">new</TOKEN>
<TOKEN id="token-0-18" pos="word" morph="none" start_char="104" end_char="111">research</TOKEN>
</SEG>
<SEG id="segment-1" start_char="115" end_char="127">
<ORIGINAL_TEXT>Get short URL</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="115" end_char="117">Get</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="119" end_char="123">short</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="125" end_char="127">URL</TOKEN>
</SEG>
<SEG id="segment-2" start_char="130" end_char="227">
<ORIGINAL_TEXT>Clinical trial of tests for the coronavirus disease (COVID-19) antibodies, at Keele University, UK</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="130" end_char="137">Clinical</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="139" end_char="143">trial</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="145" end_char="146">of</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="148" end_char="152">tests</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="154" end_char="156">for</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="158" end_char="160">the</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="162" end_char="172">coronavirus</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="174" end_char="180">disease</TOKEN>
<TOKEN id="token-2-8" pos="punct" morph="none" start_char="182" end_char="182">(</TOKEN>
<TOKEN id="token-2-9" pos="unknown" morph="none" start_char="183" end_char="190">COVID-19</TOKEN>
<TOKEN id="token-2-10" pos="punct" morph="none" start_char="191" end_char="191">)</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="193" end_char="202">antibodies</TOKEN>
<TOKEN id="token-2-12" pos="punct" morph="none" start_char="203" end_char="203">,</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="205" end_char="206">at</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="208" end_char="212">Keele</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="214" end_char="223">University</TOKEN>
<TOKEN id="token-2-16" pos="punct" morph="none" start_char="224" end_char="224">,</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="226" end_char="227">UK</TOKEN>
</SEG>
<SEG id="segment-3" start_char="231" end_char="239">
<ORIGINAL_TEXT>© Reuters</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="unknown" morph="none" start_char="231" end_char="231">©</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="233" end_char="239">Reuters</TOKEN>
</SEG>
<SEG id="segment-4" start_char="242" end_char="311">
<ORIGINAL_TEXT>By Peter Andrews, Irish science journalist and writer based in London.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="242" end_char="243">By</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="245" end_char="249">Peter</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="251" end_char="257">Andrews</TOKEN>
<TOKEN id="token-4-3" pos="punct" morph="none" start_char="258" end_char="258">,</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="260" end_char="264">Irish</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="266" end_char="272">science</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="274" end_char="283">journalist</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="285" end_char="287">and</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="289" end_char="294">writer</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="296" end_char="300">based</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="302" end_char="303">in</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="305" end_char="310">London</TOKEN>
<TOKEN id="token-4-12" pos="punct" morph="none" start_char="311" end_char="311">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="313" end_char="425">
<ORIGINAL_TEXT>He has a background in the life sciences, and graduated from the University of Glasgow with a degree in genetics.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="313" end_char="314">He</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="316" end_char="318">has</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="320" end_char="320">a</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="322" end_char="331">background</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="333" end_char="334">in</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="336" end_char="338">the</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="340" end_char="343">life</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="345" end_char="352">sciences</TOKEN>
<TOKEN id="token-5-8" pos="punct" morph="none" start_char="353" end_char="353">,</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="355" end_char="357">and</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="359" end_char="367">graduated</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="369" end_char="372">from</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="374" end_char="376">the</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="378" end_char="387">University</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="389" end_char="390">of</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="392" end_char="398">Glasgow</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="400" end_char="403">with</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="405" end_char="405">a</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="407" end_char="412">degree</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="414" end_char="415">in</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="417" end_char="424">genetics</TOKEN>
<TOKEN id="token-5-21" pos="punct" morph="none" start_char="425" end_char="425">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="429" end_char="588">
<ORIGINAL_TEXT>According to a small but significant study, immunity to coronavirus after infection appears to last a long time, boosting hopes of a successful vaccine rollout.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="429" end_char="437">According</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="439" end_char="440">to</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="442" end_char="442">a</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="444" end_char="448">small</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="450" end_char="452">but</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="454" end_char="464">significant</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="466" end_char="470">study</TOKEN>
<TOKEN id="token-6-7" pos="punct" morph="none" start_char="471" end_char="471">,</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="473" end_char="480">immunity</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="482" end_char="483">to</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="485" end_char="495">coronavirus</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="497" end_char="501">after</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="503" end_char="511">infection</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="513" end_char="519">appears</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="521" end_char="522">to</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="524" end_char="527">last</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="529" end_char="529">a</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="531" end_char="534">long</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="536" end_char="539">time</TOKEN>
<TOKEN id="token-6-19" pos="punct" morph="none" start_char="540" end_char="540">,</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="542" end_char="549">boosting</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="551" end_char="555">hopes</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="557" end_char="558">of</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="560" end_char="560">a</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="562" end_char="571">successful</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="573" end_char="579">vaccine</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="581" end_char="587">rollout</TOKEN>
<TOKEN id="token-6-27" pos="punct" morph="none" start_char="588" end_char="588">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="590" end_char="638">
<ORIGINAL_TEXT>But why were earlier indications of this ignored?</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="590" end_char="592">But</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="594" end_char="596">why</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="598" end_char="601">were</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="603" end_char="609">earlier</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="611" end_char="621">indications</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="623" end_char="624">of</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="626" end_char="629">this</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="631" end_char="637">ignored</TOKEN>
<TOKEN id="token-7-8" pos="punct" morph="none" start_char="638" end_char="638">?</TOKEN>
</SEG>
<SEG id="segment-8" start_char="641" end_char="788">
<ORIGINAL_TEXT>The new study, which is small and has not yet been peer reviewed or published by a journal, has been shared online, on the pre-print server bioRxiv.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="641" end_char="643">The</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="645" end_char="647">new</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="649" end_char="653">study</TOKEN>
<TOKEN id="token-8-3" pos="punct" morph="none" start_char="654" end_char="654">,</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="656" end_char="660">which</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="662" end_char="663">is</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="665" end_char="669">small</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="671" end_char="673">and</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="675" end_char="677">has</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="679" end_char="681">not</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="683" end_char="685">yet</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="687" end_char="690">been</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="692" end_char="695">peer</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="697" end_char="704">reviewed</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="706" end_char="707">or</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="709" end_char="717">published</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="719" end_char="720">by</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="722" end_char="722">a</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="724" end_char="730">journal</TOKEN>
<TOKEN id="token-8-19" pos="punct" morph="none" start_char="731" end_char="731">,</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="733" end_char="735">has</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="737" end_char="740">been</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="742" end_char="747">shared</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="749" end_char="754">online</TOKEN>
<TOKEN id="token-8-24" pos="punct" morph="none" start_char="755" end_char="755">,</TOKEN>
<TOKEN id="token-8-25" pos="word" morph="none" start_char="757" end_char="758">on</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="760" end_char="762">the</TOKEN>
<TOKEN id="token-8-27" pos="unknown" morph="none" start_char="764" end_char="772">pre-print</TOKEN>
<TOKEN id="token-8-28" pos="word" morph="none" start_char="774" end_char="779">server</TOKEN>
<TOKEN id="token-8-29" pos="word" morph="none" start_char="781" end_char="787">bioRxiv</TOKEN>
<TOKEN id="token-8-30" pos="punct" morph="none" start_char="788" end_char="788">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="790" end_char="899">
<ORIGINAL_TEXT>Despite its relative dearth of credentials at this early stage, it’s being heralded by the New York Times as "</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="790" end_char="796">Despite</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="798" end_char="800">its</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="802" end_char="809">relative</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="811" end_char="816">dearth</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="818" end_char="819">of</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="821" end_char="831">credentials</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="833" end_char="834">at</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="836" end_char="839">this</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="841" end_char="845">early</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="847" end_char="851">stage</TOKEN>
<TOKEN id="token-9-10" pos="punct" morph="none" start_char="852" end_char="852">,</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="854" end_char="857">it’s</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="859" end_char="863">being</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="865" end_char="872">heralded</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="874" end_char="875">by</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="877" end_char="879">the</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="881" end_char="883">New</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="885" end_char="888">York</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="890" end_char="894">Times</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="896" end_char="897">as</TOKEN>
<TOKEN id="token-9-20" pos="punct" morph="none" start_char="899" end_char="899">"</TOKEN>
</SEG>
<SEG id="segment-10" start_char="902" end_char="990">
<ORIGINAL_TEXT>the most comprehensive and long-ranging study of immune memory to the coronavirus to date</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="902" end_char="904">the</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="906" end_char="909">most</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="911" end_char="923">comprehensive</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="925" end_char="927">and</TOKEN>
<TOKEN id="token-10-4" pos="unknown" morph="none" start_char="929" end_char="940">long-ranging</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="942" end_char="946">study</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="948" end_char="949">of</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="951" end_char="956">immune</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="958" end_char="963">memory</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="965" end_char="966">to</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="968" end_char="970">the</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="972" end_char="982">coronavirus</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="984" end_char="985">to</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="987" end_char="990">date</TOKEN>
</SEG>
<SEG id="segment-11" start_char="993" end_char="994">
<ORIGINAL_TEXT>."</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="punct" morph="none" start_char="993" end_char="994">."</TOKEN>
</SEG>
<SEG id="segment-12" start_char="996" end_char="1215">
<ORIGINAL_TEXT>High praise, indeed; and it’s warranted, as the study looks beyond just antibodies to analyse all forms of resistance to Covid: namely, T cells and B cells – that is, white blood cells that combat all forms of infection.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="996" end_char="999">High</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1001" end_char="1006">praise</TOKEN>
<TOKEN id="token-12-2" pos="punct" morph="none" start_char="1007" end_char="1007">,</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1009" end_char="1014">indeed</TOKEN>
<TOKEN id="token-12-4" pos="punct" morph="none" start_char="1015" end_char="1015">;</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1017" end_char="1019">and</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1021" end_char="1024">it’s</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1026" end_char="1034">warranted</TOKEN>
<TOKEN id="token-12-8" pos="punct" morph="none" start_char="1035" end_char="1035">,</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1037" end_char="1038">as</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1040" end_char="1042">the</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1044" end_char="1048">study</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1050" end_char="1054">looks</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1056" end_char="1061">beyond</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1063" end_char="1066">just</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1068" end_char="1077">antibodies</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1079" end_char="1080">to</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1082" end_char="1088">analyse</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1090" end_char="1092">all</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1094" end_char="1098">forms</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1100" end_char="1101">of</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1103" end_char="1112">resistance</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1114" end_char="1115">to</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="1117" end_char="1121">Covid</TOKEN>
<TOKEN id="token-12-24" pos="punct" morph="none" start_char="1122" end_char="1122">:</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="1124" end_char="1129">namely</TOKEN>
<TOKEN id="token-12-26" pos="punct" morph="none" start_char="1130" end_char="1130">,</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="1132" end_char="1132">T</TOKEN>
<TOKEN id="token-12-28" pos="word" morph="none" start_char="1134" end_char="1138">cells</TOKEN>
<TOKEN id="token-12-29" pos="word" morph="none" start_char="1140" end_char="1142">and</TOKEN>
<TOKEN id="token-12-30" pos="word" morph="none" start_char="1144" end_char="1144">B</TOKEN>
<TOKEN id="token-12-31" pos="word" morph="none" start_char="1146" end_char="1150">cells</TOKEN>
<TOKEN id="token-12-32" pos="punct" morph="none" start_char="1152" end_char="1152">–</TOKEN>
<TOKEN id="token-12-33" pos="word" morph="none" start_char="1154" end_char="1157">that</TOKEN>
<TOKEN id="token-12-34" pos="word" morph="none" start_char="1159" end_char="1160">is</TOKEN>
<TOKEN id="token-12-35" pos="punct" morph="none" start_char="1161" end_char="1161">,</TOKEN>
<TOKEN id="token-12-36" pos="word" morph="none" start_char="1163" end_char="1167">white</TOKEN>
<TOKEN id="token-12-37" pos="word" morph="none" start_char="1169" end_char="1173">blood</TOKEN>
<TOKEN id="token-12-38" pos="word" morph="none" start_char="1175" end_char="1179">cells</TOKEN>
<TOKEN id="token-12-39" pos="word" morph="none" start_char="1181" end_char="1184">that</TOKEN>
<TOKEN id="token-12-40" pos="word" morph="none" start_char="1186" end_char="1191">combat</TOKEN>
<TOKEN id="token-12-41" pos="word" morph="none" start_char="1193" end_char="1195">all</TOKEN>
<TOKEN id="token-12-42" pos="word" morph="none" start_char="1197" end_char="1201">forms</TOKEN>
<TOKEN id="token-12-43" pos="word" morph="none" start_char="1203" end_char="1204">of</TOKEN>
<TOKEN id="token-12-44" pos="word" morph="none" start_char="1206" end_char="1214">infection</TOKEN>
<TOKEN id="token-12-45" pos="punct" morph="none" start_char="1215" end_char="1215">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1218" end_char="1340">
<ORIGINAL_TEXT>The study, co-led by the La Jolla Institute for Immunology, in California, looked at 185 people who had Covid and survived.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1218" end_char="1220">The</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1222" end_char="1226">study</TOKEN>
<TOKEN id="token-13-2" pos="punct" morph="none" start_char="1227" end_char="1227">,</TOKEN>
<TOKEN id="token-13-3" pos="unknown" morph="none" start_char="1229" end_char="1234">co-led</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1236" end_char="1237">by</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1239" end_char="1241">the</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1243" end_char="1244">La</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1246" end_char="1250">Jolla</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1252" end_char="1260">Institute</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1262" end_char="1264">for</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1266" end_char="1275">Immunology</TOKEN>
<TOKEN id="token-13-11" pos="punct" morph="none" start_char="1276" end_char="1276">,</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1278" end_char="1279">in</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1281" end_char="1290">California</TOKEN>
<TOKEN id="token-13-14" pos="punct" morph="none" start_char="1291" end_char="1291">,</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1293" end_char="1298">looked</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1300" end_char="1301">at</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1303" end_char="1305">185</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1307" end_char="1312">people</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1314" end_char="1316">who</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1318" end_char="1320">had</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="1322" end_char="1326">Covid</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="1328" end_char="1330">and</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="1332" end_char="1339">survived</TOKEN>
<TOKEN id="token-13-24" pos="punct" morph="none" start_char="1340" end_char="1340">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1342" end_char="1539">
<ORIGINAL_TEXT>It revealed that, although their antibody levels began to fall off six to eight months after infection, consistent with previous findings, they had abundant and robust levels of T cells and B cells.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1342" end_char="1343">It</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1345" end_char="1352">revealed</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1354" end_char="1357">that</TOKEN>
<TOKEN id="token-14-3" pos="punct" morph="none" start_char="1358" end_char="1358">,</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1360" end_char="1367">although</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1369" end_char="1373">their</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1375" end_char="1382">antibody</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1384" end_char="1389">levels</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1391" end_char="1395">began</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1397" end_char="1398">to</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1400" end_char="1403">fall</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1405" end_char="1407">off</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1409" end_char="1411">six</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1413" end_char="1414">to</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="1416" end_char="1420">eight</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1422" end_char="1427">months</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1429" end_char="1433">after</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="1435" end_char="1443">infection</TOKEN>
<TOKEN id="token-14-18" pos="punct" morph="none" start_char="1444" end_char="1444">,</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="1446" end_char="1455">consistent</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="1457" end_char="1460">with</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="1462" end_char="1469">previous</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="1471" end_char="1478">findings</TOKEN>
<TOKEN id="token-14-23" pos="punct" morph="none" start_char="1479" end_char="1479">,</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="1481" end_char="1484">they</TOKEN>
<TOKEN id="token-14-25" pos="word" morph="none" start_char="1486" end_char="1488">had</TOKEN>
<TOKEN id="token-14-26" pos="word" morph="none" start_char="1490" end_char="1497">abundant</TOKEN>
<TOKEN id="token-14-27" pos="word" morph="none" start_char="1499" end_char="1501">and</TOKEN>
<TOKEN id="token-14-28" pos="word" morph="none" start_char="1503" end_char="1508">robust</TOKEN>
<TOKEN id="token-14-29" pos="word" morph="none" start_char="1510" end_char="1515">levels</TOKEN>
<TOKEN id="token-14-30" pos="word" morph="none" start_char="1517" end_char="1518">of</TOKEN>
<TOKEN id="token-14-31" pos="word" morph="none" start_char="1520" end_char="1520">T</TOKEN>
<TOKEN id="token-14-32" pos="word" morph="none" start_char="1522" end_char="1526">cells</TOKEN>
<TOKEN id="token-14-33" pos="word" morph="none" start_char="1528" end_char="1530">and</TOKEN>
<TOKEN id="token-14-34" pos="word" morph="none" start_char="1532" end_char="1532">B</TOKEN>
<TOKEN id="token-14-35" pos="word" morph="none" start_char="1534" end_char="1538">cells</TOKEN>
<TOKEN id="token-14-36" pos="punct" morph="none" start_char="1539" end_char="1539">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1541" end_char="1609">
<ORIGINAL_TEXT>In fact, B cells kept increasing after infection for reasons unknown.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1541" end_char="1542">In</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1544" end_char="1547">fact</TOKEN>
<TOKEN id="token-15-2" pos="punct" morph="none" start_char="1548" end_char="1548">,</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1550" end_char="1550">B</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1552" end_char="1556">cells</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1558" end_char="1561">kept</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1563" end_char="1572">increasing</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1574" end_char="1578">after</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1580" end_char="1588">infection</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1590" end_char="1592">for</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1594" end_char="1600">reasons</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1602" end_char="1608">unknown</TOKEN>
<TOKEN id="token-15-12" pos="punct" morph="none" start_char="1609" end_char="1609">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1611" end_char="1687">
<ORIGINAL_TEXT>The levels found in the subjects’ blood would, according to a study leader, "</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1611" end_char="1613">The</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1615" end_char="1620">levels</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1622" end_char="1626">found</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1628" end_char="1629">in</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1631" end_char="1633">the</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1635" end_char="1642">subjects</TOKEN>
<TOKEN id="token-16-6" pos="punct" morph="none" start_char="1643" end_char="1643">’</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1645" end_char="1649">blood</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1651" end_char="1655">would</TOKEN>
<TOKEN id="token-16-9" pos="punct" morph="none" start_char="1656" end_char="1656">,</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="1658" end_char="1666">according</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="1668" end_char="1669">to</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="1671" end_char="1671">a</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="1673" end_char="1677">study</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="1679" end_char="1684">leader</TOKEN>
<TOKEN id="token-16-15" pos="punct" morph="none" start_char="1685" end_char="1685">,</TOKEN>
<TOKEN id="token-16-16" pos="punct" morph="none" start_char="1687" end_char="1687">"</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1690" end_char="1797">
<ORIGINAL_TEXT>likely prevent the vast majority of people from getting hospitalized disease, severe disease, for many years</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1690" end_char="1695">likely</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1697" end_char="1703">prevent</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="1705" end_char="1707">the</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="1709" end_char="1712">vast</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="1714" end_char="1721">majority</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="1723" end_char="1724">of</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="1726" end_char="1731">people</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="1733" end_char="1736">from</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="1738" end_char="1744">getting</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="1746" end_char="1757">hospitalized</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="1759" end_char="1765">disease</TOKEN>
<TOKEN id="token-17-11" pos="punct" morph="none" start_char="1766" end_char="1766">,</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="1768" end_char="1773">severe</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="1775" end_char="1781">disease</TOKEN>
<TOKEN id="token-17-14" pos="punct" morph="none" start_char="1782" end_char="1782">,</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="1784" end_char="1786">for</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="1788" end_char="1791">many</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="1793" end_char="1797">years</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1800" end_char="1802">
<ORIGINAL_TEXT>.’’</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="punct" morph="none" start_char="1800" end_char="1802">.’’</TOKEN>
</SEG>
<SEG id="segment-19" start_char="1807" end_char="1830">
<ORIGINAL_TEXT>Why the sudden interest?</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="1807" end_char="1809">Why</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="1811" end_char="1813">the</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="1815" end_char="1820">sudden</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="1822" end_char="1829">interest</TOKEN>
<TOKEN id="token-19-4" pos="punct" morph="none" start_char="1830" end_char="1830">?</TOKEN>
</SEG>
<SEG id="segment-20" start_char="1834" end_char="1949">
<ORIGINAL_TEXT>The NYT and the rest of the mainstream media seem to finally be relinquishing their obsession with antibody studies.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="1834" end_char="1836">The</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="1838" end_char="1840">NYT</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="1842" end_char="1844">and</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="1846" end_char="1848">the</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="1850" end_char="1853">rest</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="1855" end_char="1856">of</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="1858" end_char="1860">the</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="1862" end_char="1871">mainstream</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="1873" end_char="1877">media</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="1879" end_char="1882">seem</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="1884" end_char="1885">to</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="1887" end_char="1893">finally</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="1895" end_char="1896">be</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="1898" end_char="1910">relinquishing</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="1912" end_char="1916">their</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="1918" end_char="1926">obsession</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="1928" end_char="1931">with</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="1933" end_char="1940">antibody</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="1942" end_char="1948">studies</TOKEN>
<TOKEN id="token-20-19" pos="punct" morph="none" start_char="1949" end_char="1949">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="1951" end_char="2088">
<ORIGINAL_TEXT>In the past, they have considered this fluffy test, riddled with unknowns, as the only way to determine whether a person is immune or not.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="1951" end_char="1952">In</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="1954" end_char="1956">the</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="1958" end_char="1961">past</TOKEN>
<TOKEN id="token-21-3" pos="punct" morph="none" start_char="1962" end_char="1962">,</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="1964" end_char="1967">they</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="1969" end_char="1972">have</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="1974" end_char="1983">considered</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="1985" end_char="1988">this</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="1990" end_char="1995">fluffy</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="1997" end_char="2000">test</TOKEN>
<TOKEN id="token-21-10" pos="punct" morph="none" start_char="2001" end_char="2001">,</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="2003" end_char="2009">riddled</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="2011" end_char="2014">with</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="2016" end_char="2023">unknowns</TOKEN>
<TOKEN id="token-21-14" pos="punct" morph="none" start_char="2024" end_char="2024">,</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="2026" end_char="2027">as</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="2029" end_char="2031">the</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="2033" end_char="2036">only</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="2038" end_char="2040">way</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="2042" end_char="2043">to</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="2045" end_char="2053">determine</TOKEN>
<TOKEN id="token-21-21" pos="word" morph="none" start_char="2055" end_char="2061">whether</TOKEN>
<TOKEN id="token-21-22" pos="word" morph="none" start_char="2063" end_char="2063">a</TOKEN>
<TOKEN id="token-21-23" pos="word" morph="none" start_char="2065" end_char="2070">person</TOKEN>
<TOKEN id="token-21-24" pos="word" morph="none" start_char="2072" end_char="2073">is</TOKEN>
<TOKEN id="token-21-25" pos="word" morph="none" start_char="2075" end_char="2080">immune</TOKEN>
<TOKEN id="token-21-26" pos="word" morph="none" start_char="2082" end_char="2083">or</TOKEN>
<TOKEN id="token-21-27" pos="word" morph="none" start_char="2085" end_char="2087">not</TOKEN>
<TOKEN id="token-21-28" pos="punct" morph="none" start_char="2088" end_char="2088">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2090" end_char="2200">
<ORIGINAL_TEXT>But their lack of interest in T cell immunity doesn’t mean that many top scientists haven’t been discussing it.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2090" end_char="2092">But</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2094" end_char="2098">their</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2100" end_char="2103">lack</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2105" end_char="2106">of</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2108" end_char="2115">interest</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2117" end_char="2118">in</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2120" end_char="2120">T</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2122" end_char="2125">cell</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="2127" end_char="2134">immunity</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="2136" end_char="2142">doesn’t</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="2144" end_char="2147">mean</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="2149" end_char="2152">that</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="2154" end_char="2157">many</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="2159" end_char="2161">top</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="2163" end_char="2172">scientists</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="2174" end_char="2180">haven’t</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="2182" end_char="2185">been</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="2187" end_char="2196">discussing</TOKEN>
<TOKEN id="token-22-18" pos="word" morph="none" start_char="2198" end_char="2199">it</TOKEN>
<TOKEN id="token-22-19" pos="punct" morph="none" start_char="2200" end_char="2200">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2203" end_char="2436">
<ORIGINAL_TEXT>For instance, in an interview last month with James Delingpole, the outspoken Dr Mike Yeadon, a staunch opponent of the prevailing Covid strategy, gave an in-depth account of why the absence of antibodies does not imply vulnerability.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2203" end_char="2205">For</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2207" end_char="2214">instance</TOKEN>
<TOKEN id="token-23-2" pos="punct" morph="none" start_char="2215" end_char="2215">,</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2217" end_char="2218">in</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="2220" end_char="2221">an</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="2223" end_char="2231">interview</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="2233" end_char="2236">last</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="2238" end_char="2242">month</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="2244" end_char="2247">with</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="2249" end_char="2253">James</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="2255" end_char="2264">Delingpole</TOKEN>
<TOKEN id="token-23-11" pos="punct" morph="none" start_char="2265" end_char="2265">,</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="2267" end_char="2269">the</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="2271" end_char="2279">outspoken</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="2281" end_char="2282">Dr</TOKEN>
<TOKEN id="token-23-15" pos="word" morph="none" start_char="2284" end_char="2287">Mike</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="2289" end_char="2294">Yeadon</TOKEN>
<TOKEN id="token-23-17" pos="punct" morph="none" start_char="2295" end_char="2295">,</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="2297" end_char="2297">a</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="2299" end_char="2305">staunch</TOKEN>
<TOKEN id="token-23-20" pos="word" morph="none" start_char="2307" end_char="2314">opponent</TOKEN>
<TOKEN id="token-23-21" pos="word" morph="none" start_char="2316" end_char="2317">of</TOKEN>
<TOKEN id="token-23-22" pos="word" morph="none" start_char="2319" end_char="2321">the</TOKEN>
<TOKEN id="token-23-23" pos="word" morph="none" start_char="2323" end_char="2332">prevailing</TOKEN>
<TOKEN id="token-23-24" pos="word" morph="none" start_char="2334" end_char="2338">Covid</TOKEN>
<TOKEN id="token-23-25" pos="word" morph="none" start_char="2340" end_char="2347">strategy</TOKEN>
<TOKEN id="token-23-26" pos="punct" morph="none" start_char="2348" end_char="2348">,</TOKEN>
<TOKEN id="token-23-27" pos="word" morph="none" start_char="2350" end_char="2353">gave</TOKEN>
<TOKEN id="token-23-28" pos="word" morph="none" start_char="2355" end_char="2356">an</TOKEN>
<TOKEN id="token-23-29" pos="unknown" morph="none" start_char="2358" end_char="2365">in-depth</TOKEN>
<TOKEN id="token-23-30" pos="word" morph="none" start_char="2367" end_char="2373">account</TOKEN>
<TOKEN id="token-23-31" pos="word" morph="none" start_char="2375" end_char="2376">of</TOKEN>
<TOKEN id="token-23-32" pos="word" morph="none" start_char="2378" end_char="2380">why</TOKEN>
<TOKEN id="token-23-33" pos="word" morph="none" start_char="2382" end_char="2384">the</TOKEN>
<TOKEN id="token-23-34" pos="word" morph="none" start_char="2386" end_char="2392">absence</TOKEN>
<TOKEN id="token-23-35" pos="word" morph="none" start_char="2394" end_char="2395">of</TOKEN>
<TOKEN id="token-23-36" pos="word" morph="none" start_char="2397" end_char="2406">antibodies</TOKEN>
<TOKEN id="token-23-37" pos="word" morph="none" start_char="2408" end_char="2411">does</TOKEN>
<TOKEN id="token-23-38" pos="word" morph="none" start_char="2413" end_char="2415">not</TOKEN>
<TOKEN id="token-23-39" pos="word" morph="none" start_char="2417" end_char="2421">imply</TOKEN>
<TOKEN id="token-23-40" pos="word" morph="none" start_char="2423" end_char="2435">vulnerability</TOKEN>
<TOKEN id="token-23-41" pos="punct" morph="none" start_char="2436" end_char="2436">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2438" end_char="2539">
<ORIGINAL_TEXT>Dr Yeadon is adamant that, as with other coronaviruses, immunity to Covid lasts years, if not decades.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="2438" end_char="2439">Dr</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="2441" end_char="2446">Yeadon</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="2448" end_char="2449">is</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="2451" end_char="2457">adamant</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="2459" end_char="2462">that</TOKEN>
<TOKEN id="token-24-5" pos="punct" morph="none" start_char="2463" end_char="2463">,</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="2465" end_char="2466">as</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="2468" end_char="2471">with</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="2473" end_char="2477">other</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="2479" end_char="2491">coronaviruses</TOKEN>
<TOKEN id="token-24-10" pos="punct" morph="none" start_char="2492" end_char="2492">,</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="2494" end_char="2501">immunity</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="2503" end_char="2504">to</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="2506" end_char="2510">Covid</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="2512" end_char="2516">lasts</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="2518" end_char="2522">years</TOKEN>
<TOKEN id="token-24-16" pos="punct" morph="none" start_char="2523" end_char="2523">,</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="2525" end_char="2526">if</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="2528" end_char="2530">not</TOKEN>
<TOKEN id="token-24-19" pos="word" morph="none" start_char="2532" end_char="2538">decades</TOKEN>
<TOKEN id="token-24-20" pos="punct" morph="none" start_char="2539" end_char="2539">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2541" end_char="2661">
<ORIGINAL_TEXT>He says there was never any reason to doubt that immunity would last this long; it is simply how our immune systems work.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="2541" end_char="2542">He</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="2544" end_char="2547">says</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="2549" end_char="2553">there</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="2555" end_char="2557">was</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="2559" end_char="2563">never</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="2565" end_char="2567">any</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="2569" end_char="2574">reason</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="2576" end_char="2577">to</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="2579" end_char="2583">doubt</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="2585" end_char="2588">that</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="2590" end_char="2597">immunity</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="2599" end_char="2603">would</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="2605" end_char="2608">last</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="2610" end_char="2613">this</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="2615" end_char="2618">long</TOKEN>
<TOKEN id="token-25-15" pos="punct" morph="none" start_char="2619" end_char="2619">;</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="2621" end_char="2622">it</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="2624" end_char="2625">is</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="2627" end_char="2632">simply</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="2634" end_char="2636">how</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="2638" end_char="2640">our</TOKEN>
<TOKEN id="token-25-21" pos="word" morph="none" start_char="2642" end_char="2647">immune</TOKEN>
<TOKEN id="token-25-22" pos="word" morph="none" start_char="2649" end_char="2655">systems</TOKEN>
<TOKEN id="token-25-23" pos="word" morph="none" start_char="2657" end_char="2660">work</TOKEN>
<TOKEN id="token-25-24" pos="punct" morph="none" start_char="2661" end_char="2661">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="2664" end_char="2782">
<ORIGINAL_TEXT>Dr Yeadon is treated as something of a crank by the scientific establishment, of course – but completely without cause.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="2664" end_char="2665">Dr</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="2667" end_char="2672">Yeadon</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="2674" end_char="2675">is</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="2677" end_char="2683">treated</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="2685" end_char="2686">as</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="2688" end_char="2696">something</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="2698" end_char="2699">of</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="2701" end_char="2701">a</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="2703" end_char="2707">crank</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="2709" end_char="2710">by</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="2712" end_char="2714">the</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="2716" end_char="2725">scientific</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="2727" end_char="2739">establishment</TOKEN>
<TOKEN id="token-26-13" pos="punct" morph="none" start_char="2740" end_char="2740">,</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="2742" end_char="2743">of</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="2745" end_char="2750">course</TOKEN>
<TOKEN id="token-26-16" pos="punct" morph="none" start_char="2752" end_char="2752">–</TOKEN>
<TOKEN id="token-26-17" pos="word" morph="none" start_char="2754" end_char="2756">but</TOKEN>
<TOKEN id="token-26-18" pos="word" morph="none" start_char="2758" end_char="2767">completely</TOKEN>
<TOKEN id="token-26-19" pos="word" morph="none" start_char="2769" end_char="2775">without</TOKEN>
<TOKEN id="token-26-20" pos="word" morph="none" start_char="2777" end_char="2781">cause</TOKEN>
<TOKEN id="token-26-21" pos="punct" morph="none" start_char="2782" end_char="2782">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="2784" end_char="2998">
<ORIGINAL_TEXT>The man’s credentials are impeccable: he has a degree in biochemistry and toxicology, and a research-based PhD in respiratory pharmacology; is a former scientific adviser to Pfizer; and started his own biotech firm.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="2784" end_char="2786">The</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="2788" end_char="2792">man’s</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="2794" end_char="2804">credentials</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="2806" end_char="2808">are</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="2810" end_char="2819">impeccable</TOKEN>
<TOKEN id="token-27-5" pos="punct" morph="none" start_char="2820" end_char="2820">:</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="2822" end_char="2823">he</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="2825" end_char="2827">has</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="2829" end_char="2829">a</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="2831" end_char="2836">degree</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="2838" end_char="2839">in</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="2841" end_char="2852">biochemistry</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="2854" end_char="2856">and</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="2858" end_char="2867">toxicology</TOKEN>
<TOKEN id="token-27-14" pos="punct" morph="none" start_char="2868" end_char="2868">,</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="2870" end_char="2872">and</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="2874" end_char="2874">a</TOKEN>
<TOKEN id="token-27-17" pos="unknown" morph="none" start_char="2876" end_char="2889">research-based</TOKEN>
<TOKEN id="token-27-18" pos="word" morph="none" start_char="2891" end_char="2893">PhD</TOKEN>
<TOKEN id="token-27-19" pos="word" morph="none" start_char="2895" end_char="2896">in</TOKEN>
<TOKEN id="token-27-20" pos="word" morph="none" start_char="2898" end_char="2908">respiratory</TOKEN>
<TOKEN id="token-27-21" pos="word" morph="none" start_char="2910" end_char="2921">pharmacology</TOKEN>
<TOKEN id="token-27-22" pos="punct" morph="none" start_char="2922" end_char="2922">;</TOKEN>
<TOKEN id="token-27-23" pos="word" morph="none" start_char="2924" end_char="2925">is</TOKEN>
<TOKEN id="token-27-24" pos="word" morph="none" start_char="2927" end_char="2927">a</TOKEN>
<TOKEN id="token-27-25" pos="word" morph="none" start_char="2929" end_char="2934">former</TOKEN>
<TOKEN id="token-27-26" pos="word" morph="none" start_char="2936" end_char="2945">scientific</TOKEN>
<TOKEN id="token-27-27" pos="word" morph="none" start_char="2947" end_char="2953">adviser</TOKEN>
<TOKEN id="token-27-28" pos="word" morph="none" start_char="2955" end_char="2956">to</TOKEN>
<TOKEN id="token-27-29" pos="word" morph="none" start_char="2958" end_char="2963">Pfizer</TOKEN>
<TOKEN id="token-27-30" pos="punct" morph="none" start_char="2964" end_char="2964">;</TOKEN>
<TOKEN id="token-27-31" pos="word" morph="none" start_char="2966" end_char="2968">and</TOKEN>
<TOKEN id="token-27-32" pos="word" morph="none" start_char="2970" end_char="2976">started</TOKEN>
<TOKEN id="token-27-33" pos="word" morph="none" start_char="2978" end_char="2980">his</TOKEN>
<TOKEN id="token-27-34" pos="word" morph="none" start_char="2982" end_char="2984">own</TOKEN>
<TOKEN id="token-27-35" pos="word" morph="none" start_char="2986" end_char="2992">biotech</TOKEN>
<TOKEN id="token-27-36" pos="word" morph="none" start_char="2994" end_char="2997">firm</TOKEN>
<TOKEN id="token-27-37" pos="punct" morph="none" start_char="2998" end_char="2998">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3000" end_char="3089">
<ORIGINAL_TEXT>Thankfully, he is gaining traction among some quarters of the media now, but far too late.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="3000" end_char="3009">Thankfully</TOKEN>
<TOKEN id="token-28-1" pos="punct" morph="none" start_char="3010" end_char="3010">,</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="3012" end_char="3013">he</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="3015" end_char="3016">is</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="3018" end_char="3024">gaining</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="3026" end_char="3033">traction</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="3035" end_char="3039">among</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="3041" end_char="3044">some</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="3046" end_char="3053">quarters</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="3055" end_char="3056">of</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="3058" end_char="3060">the</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="3062" end_char="3066">media</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="3068" end_char="3070">now</TOKEN>
<TOKEN id="token-28-13" pos="punct" morph="none" start_char="3071" end_char="3071">,</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="3073" end_char="3075">but</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="3077" end_char="3079">far</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="3081" end_char="3083">too</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="3085" end_char="3088">late</TOKEN>
<TOKEN id="token-28-18" pos="punct" morph="none" start_char="3089" end_char="3089">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3092" end_char="3111">
<ORIGINAL_TEXT>Big Pharma’s big day</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="3092" end_char="3094">Big</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="3096" end_char="3103">Pharma’s</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="3105" end_char="3107">big</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="3109" end_char="3111">day</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3115" end_char="3266">
<ORIGINAL_TEXT>This news, if it survives the peer review process, will be grist to the mill of pharmaceutical companies and politicians, as well as many ordinary folk.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="3115" end_char="3118">This</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="3120" end_char="3123">news</TOKEN>
<TOKEN id="token-30-2" pos="punct" morph="none" start_char="3124" end_char="3124">,</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="3126" end_char="3127">if</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="3129" end_char="3130">it</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="3132" end_char="3139">survives</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="3141" end_char="3143">the</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="3145" end_char="3148">peer</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="3150" end_char="3155">review</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="3157" end_char="3163">process</TOKEN>
<TOKEN id="token-30-10" pos="punct" morph="none" start_char="3164" end_char="3164">,</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="3166" end_char="3169">will</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="3171" end_char="3172">be</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="3174" end_char="3178">grist</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="3180" end_char="3181">to</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="3183" end_char="3185">the</TOKEN>
<TOKEN id="token-30-16" pos="word" morph="none" start_char="3187" end_char="3190">mill</TOKEN>
<TOKEN id="token-30-17" pos="word" morph="none" start_char="3192" end_char="3193">of</TOKEN>
<TOKEN id="token-30-18" pos="word" morph="none" start_char="3195" end_char="3208">pharmaceutical</TOKEN>
<TOKEN id="token-30-19" pos="word" morph="none" start_char="3210" end_char="3218">companies</TOKEN>
<TOKEN id="token-30-20" pos="word" morph="none" start_char="3220" end_char="3222">and</TOKEN>
<TOKEN id="token-30-21" pos="word" morph="none" start_char="3224" end_char="3234">politicians</TOKEN>
<TOKEN id="token-30-22" pos="punct" morph="none" start_char="3235" end_char="3235">,</TOKEN>
<TOKEN id="token-30-23" pos="word" morph="none" start_char="3237" end_char="3238">as</TOKEN>
<TOKEN id="token-30-24" pos="word" morph="none" start_char="3240" end_char="3243">well</TOKEN>
<TOKEN id="token-30-25" pos="word" morph="none" start_char="3245" end_char="3246">as</TOKEN>
<TOKEN id="token-30-26" pos="word" morph="none" start_char="3248" end_char="3251">many</TOKEN>
<TOKEN id="token-30-27" pos="word" morph="none" start_char="3253" end_char="3260">ordinary</TOKEN>
<TOKEN id="token-30-28" pos="word" morph="none" start_char="3262" end_char="3265">folk</TOKEN>
<TOKEN id="token-30-29" pos="punct" morph="none" start_char="3266" end_char="3266">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="3268" end_char="3415">
<ORIGINAL_TEXT>It is hard to blame people for hoping for an end to this pandemic as soon as possible – even, or perhaps especially, if that means being vaccinated.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="3268" end_char="3269">It</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="3271" end_char="3272">is</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="3274" end_char="3277">hard</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="3279" end_char="3280">to</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="3282" end_char="3286">blame</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="3288" end_char="3293">people</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="3295" end_char="3297">for</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="3299" end_char="3304">hoping</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="3306" end_char="3308">for</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="3310" end_char="3311">an</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="3313" end_char="3315">end</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="3317" end_char="3318">to</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="3320" end_char="3323">this</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="3325" end_char="3332">pandemic</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="3334" end_char="3335">as</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="3337" end_char="3340">soon</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="3342" end_char="3343">as</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="3345" end_char="3352">possible</TOKEN>
<TOKEN id="token-31-18" pos="punct" morph="none" start_char="3354" end_char="3354">–</TOKEN>
<TOKEN id="token-31-19" pos="word" morph="none" start_char="3356" end_char="3359">even</TOKEN>
<TOKEN id="token-31-20" pos="punct" morph="none" start_char="3360" end_char="3360">,</TOKEN>
<TOKEN id="token-31-21" pos="word" morph="none" start_char="3362" end_char="3363">or</TOKEN>
<TOKEN id="token-31-22" pos="word" morph="none" start_char="3365" end_char="3371">perhaps</TOKEN>
<TOKEN id="token-31-23" pos="word" morph="none" start_char="3373" end_char="3382">especially</TOKEN>
<TOKEN id="token-31-24" pos="punct" morph="none" start_char="3383" end_char="3383">,</TOKEN>
<TOKEN id="token-31-25" pos="word" morph="none" start_char="3385" end_char="3386">if</TOKEN>
<TOKEN id="token-31-26" pos="word" morph="none" start_char="3388" end_char="3391">that</TOKEN>
<TOKEN id="token-31-27" pos="word" morph="none" start_char="3393" end_char="3397">means</TOKEN>
<TOKEN id="token-31-28" pos="word" morph="none" start_char="3399" end_char="3403">being</TOKEN>
<TOKEN id="token-31-29" pos="word" morph="none" start_char="3405" end_char="3414">vaccinated</TOKEN>
<TOKEN id="token-31-30" pos="punct" morph="none" start_char="3415" end_char="3415">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="3417" end_char="3552">
<ORIGINAL_TEXT>Immunity lasting years means an initial population-wide rollout would justify a full return to normality (at least, one would think so).</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="3417" end_char="3424">Immunity</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="3426" end_char="3432">lasting</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="3434" end_char="3438">years</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="3440" end_char="3444">means</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="3446" end_char="3447">an</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="3449" end_char="3455">initial</TOKEN>
<TOKEN id="token-32-6" pos="unknown" morph="none" start_char="3457" end_char="3471">population-wide</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="3473" end_char="3479">rollout</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="3481" end_char="3485">would</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="3487" end_char="3493">justify</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="3495" end_char="3495">a</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="3497" end_char="3500">full</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="3502" end_char="3507">return</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="3509" end_char="3510">to</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="3512" end_char="3520">normality</TOKEN>
<TOKEN id="token-32-15" pos="punct" morph="none" start_char="3522" end_char="3522">(</TOKEN>
<TOKEN id="token-32-16" pos="word" morph="none" start_char="3523" end_char="3524">at</TOKEN>
<TOKEN id="token-32-17" pos="word" morph="none" start_char="3526" end_char="3530">least</TOKEN>
<TOKEN id="token-32-18" pos="punct" morph="none" start_char="3531" end_char="3531">,</TOKEN>
<TOKEN id="token-32-19" pos="word" morph="none" start_char="3533" end_char="3535">one</TOKEN>
<TOKEN id="token-32-20" pos="word" morph="none" start_char="3537" end_char="3541">would</TOKEN>
<TOKEN id="token-32-21" pos="word" morph="none" start_char="3543" end_char="3547">think</TOKEN>
<TOKEN id="token-32-22" pos="word" morph="none" start_char="3549" end_char="3550">so</TOKEN>
<TOKEN id="token-32-23" pos="punct" morph="none" start_char="3551" end_char="3552">).</TOKEN>
</SEG>
<SEG id="segment-33" start_char="3554" end_char="3704">
<ORIGINAL_TEXT>If, as was feared until now, boosters were required after only a few months, it would cast major doubt on mass vaccination being the route out of this.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="3554" end_char="3555">If</TOKEN>
<TOKEN id="token-33-1" pos="punct" morph="none" start_char="3556" end_char="3556">,</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="3558" end_char="3559">as</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="3561" end_char="3563">was</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="3565" end_char="3570">feared</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="3572" end_char="3576">until</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="3578" end_char="3580">now</TOKEN>
<TOKEN id="token-33-7" pos="punct" morph="none" start_char="3581" end_char="3581">,</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="3583" end_char="3590">boosters</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="3592" end_char="3595">were</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="3597" end_char="3604">required</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="3606" end_char="3610">after</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="3612" end_char="3615">only</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="3617" end_char="3617">a</TOKEN>
<TOKEN id="token-33-14" pos="word" morph="none" start_char="3619" end_char="3621">few</TOKEN>
<TOKEN id="token-33-15" pos="word" morph="none" start_char="3623" end_char="3628">months</TOKEN>
<TOKEN id="token-33-16" pos="punct" morph="none" start_char="3629" end_char="3629">,</TOKEN>
<TOKEN id="token-33-17" pos="word" morph="none" start_char="3631" end_char="3632">it</TOKEN>
<TOKEN id="token-33-18" pos="word" morph="none" start_char="3634" end_char="3638">would</TOKEN>
<TOKEN id="token-33-19" pos="word" morph="none" start_char="3640" end_char="3643">cast</TOKEN>
<TOKEN id="token-33-20" pos="word" morph="none" start_char="3645" end_char="3649">major</TOKEN>
<TOKEN id="token-33-21" pos="word" morph="none" start_char="3651" end_char="3655">doubt</TOKEN>
<TOKEN id="token-33-22" pos="word" morph="none" start_char="3657" end_char="3658">on</TOKEN>
<TOKEN id="token-33-23" pos="word" morph="none" start_char="3660" end_char="3663">mass</TOKEN>
<TOKEN id="token-33-24" pos="word" morph="none" start_char="3665" end_char="3675">vaccination</TOKEN>
<TOKEN id="token-33-25" pos="word" morph="none" start_char="3677" end_char="3681">being</TOKEN>
<TOKEN id="token-33-26" pos="word" morph="none" start_char="3683" end_char="3685">the</TOKEN>
<TOKEN id="token-33-27" pos="word" morph="none" start_char="3687" end_char="3691">route</TOKEN>
<TOKEN id="token-33-28" pos="word" morph="none" start_char="3693" end_char="3695">out</TOKEN>
<TOKEN id="token-33-29" pos="word" morph="none" start_char="3697" end_char="3698">of</TOKEN>
<TOKEN id="token-33-30" pos="word" morph="none" start_char="3700" end_char="3703">this</TOKEN>
<TOKEN id="token-33-31" pos="punct" morph="none" start_char="3704" end_char="3704">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="3707" end_char="3812">
<ORIGINAL_TEXT>Plans on ice: Freezers logistics are the reasons Pfizer's vaccine is all hype, and won’t be a magic bullet</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="3707" end_char="3711">Plans</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="3713" end_char="3714">on</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="3716" end_char="3718">ice</TOKEN>
<TOKEN id="token-34-3" pos="punct" morph="none" start_char="3719" end_char="3719">:</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="3721" end_char="3728">Freezers</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="3730" end_char="3738">logistics</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="3740" end_char="3742">are</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="3744" end_char="3746">the</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="3748" end_char="3754">reasons</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="3756" end_char="3763">Pfizer's</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="3765" end_char="3771">vaccine</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="3773" end_char="3774">is</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="3776" end_char="3778">all</TOKEN>
<TOKEN id="token-34-13" pos="word" morph="none" start_char="3780" end_char="3783">hype</TOKEN>
<TOKEN id="token-34-14" pos="punct" morph="none" start_char="3784" end_char="3784">,</TOKEN>
<TOKEN id="token-34-15" pos="word" morph="none" start_char="3786" end_char="3788">and</TOKEN>
<TOKEN id="token-34-16" pos="word" morph="none" start_char="3790" end_char="3794">won’t</TOKEN>
<TOKEN id="token-34-17" pos="word" morph="none" start_char="3796" end_char="3797">be</TOKEN>
<TOKEN id="token-34-18" pos="word" morph="none" start_char="3799" end_char="3799">a</TOKEN>
<TOKEN id="token-34-19" pos="word" morph="none" start_char="3801" end_char="3805">magic</TOKEN>
<TOKEN id="token-34-20" pos="word" morph="none" start_char="3807" end_char="3812">bullet</TOKEN>
</SEG>
<SEG id="segment-35" start_char="3815" end_char="4020">
<ORIGINAL_TEXT>In fact, if one were being very cynical, one might marvel at the timing of these studies showing T cell immunity, just as we are inundated with proclamations of the first vaccines showing promising results.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="3815" end_char="3816">In</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="3818" end_char="3821">fact</TOKEN>
<TOKEN id="token-35-2" pos="punct" morph="none" start_char="3822" end_char="3822">,</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="3824" end_char="3825">if</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="3827" end_char="3829">one</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="3831" end_char="3834">were</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="3836" end_char="3840">being</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="3842" end_char="3845">very</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="3847" end_char="3853">cynical</TOKEN>
<TOKEN id="token-35-9" pos="punct" morph="none" start_char="3854" end_char="3854">,</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="3856" end_char="3858">one</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="3860" end_char="3864">might</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="3866" end_char="3871">marvel</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="3873" end_char="3874">at</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="3876" end_char="3878">the</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="3880" end_char="3885">timing</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="3887" end_char="3888">of</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="3890" end_char="3894">these</TOKEN>
<TOKEN id="token-35-18" pos="word" morph="none" start_char="3896" end_char="3902">studies</TOKEN>
<TOKEN id="token-35-19" pos="word" morph="none" start_char="3904" end_char="3910">showing</TOKEN>
<TOKEN id="token-35-20" pos="word" morph="none" start_char="3912" end_char="3912">T</TOKEN>
<TOKEN id="token-35-21" pos="word" morph="none" start_char="3914" end_char="3917">cell</TOKEN>
<TOKEN id="token-35-22" pos="word" morph="none" start_char="3919" end_char="3926">immunity</TOKEN>
<TOKEN id="token-35-23" pos="punct" morph="none" start_char="3927" end_char="3927">,</TOKEN>
<TOKEN id="token-35-24" pos="word" morph="none" start_char="3929" end_char="3932">just</TOKEN>
<TOKEN id="token-35-25" pos="word" morph="none" start_char="3934" end_char="3935">as</TOKEN>
<TOKEN id="token-35-26" pos="word" morph="none" start_char="3937" end_char="3938">we</TOKEN>
<TOKEN id="token-35-27" pos="word" morph="none" start_char="3940" end_char="3942">are</TOKEN>
<TOKEN id="token-35-28" pos="word" morph="none" start_char="3944" end_char="3952">inundated</TOKEN>
<TOKEN id="token-35-29" pos="word" morph="none" start_char="3954" end_char="3957">with</TOKEN>
<TOKEN id="token-35-30" pos="word" morph="none" start_char="3959" end_char="3971">proclamations</TOKEN>
<TOKEN id="token-35-31" pos="word" morph="none" start_char="3973" end_char="3974">of</TOKEN>
<TOKEN id="token-35-32" pos="word" morph="none" start_char="3976" end_char="3978">the</TOKEN>
<TOKEN id="token-35-33" pos="word" morph="none" start_char="3980" end_char="3984">first</TOKEN>
<TOKEN id="token-35-34" pos="word" morph="none" start_char="3986" end_char="3993">vaccines</TOKEN>
<TOKEN id="token-35-35" pos="word" morph="none" start_char="3995" end_char="4001">showing</TOKEN>
<TOKEN id="token-35-36" pos="word" morph="none" start_char="4003" end_char="4011">promising</TOKEN>
<TOKEN id="token-35-37" pos="word" morph="none" start_char="4013" end_char="4019">results</TOKEN>
<TOKEN id="token-35-38" pos="punct" morph="none" start_char="4020" end_char="4020">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="4022" end_char="4230">
<ORIGINAL_TEXT>The notion that only antibodies correspond to immunity has never been widely held by any scientists, but you wouldn’t think that, if you’d witnessed the past nine months of public relations and media coverage.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="4022" end_char="4024">The</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="4026" end_char="4031">notion</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="4033" end_char="4036">that</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="4038" end_char="4041">only</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="4043" end_char="4052">antibodies</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="4054" end_char="4063">correspond</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="4065" end_char="4066">to</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="4068" end_char="4075">immunity</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="4077" end_char="4079">has</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="4081" end_char="4085">never</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="4087" end_char="4090">been</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="4092" end_char="4097">widely</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="4099" end_char="4102">held</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="4104" end_char="4105">by</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="4107" end_char="4109">any</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="4111" end_char="4120">scientists</TOKEN>
<TOKEN id="token-36-16" pos="punct" morph="none" start_char="4121" end_char="4121">,</TOKEN>
<TOKEN id="token-36-17" pos="word" morph="none" start_char="4123" end_char="4125">but</TOKEN>
<TOKEN id="token-36-18" pos="word" morph="none" start_char="4127" end_char="4129">you</TOKEN>
<TOKEN id="token-36-19" pos="word" morph="none" start_char="4131" end_char="4138">wouldn’t</TOKEN>
<TOKEN id="token-36-20" pos="word" morph="none" start_char="4140" end_char="4144">think</TOKEN>
<TOKEN id="token-36-21" pos="word" morph="none" start_char="4146" end_char="4149">that</TOKEN>
<TOKEN id="token-36-22" pos="punct" morph="none" start_char="4150" end_char="4150">,</TOKEN>
<TOKEN id="token-36-23" pos="word" morph="none" start_char="4152" end_char="4153">if</TOKEN>
<TOKEN id="token-36-24" pos="word" morph="none" start_char="4155" end_char="4159">you’d</TOKEN>
<TOKEN id="token-36-25" pos="word" morph="none" start_char="4161" end_char="4169">witnessed</TOKEN>
<TOKEN id="token-36-26" pos="word" morph="none" start_char="4171" end_char="4173">the</TOKEN>
<TOKEN id="token-36-27" pos="word" morph="none" start_char="4175" end_char="4178">past</TOKEN>
<TOKEN id="token-36-28" pos="word" morph="none" start_char="4180" end_char="4183">nine</TOKEN>
<TOKEN id="token-36-29" pos="word" morph="none" start_char="4185" end_char="4190">months</TOKEN>
<TOKEN id="token-36-30" pos="word" morph="none" start_char="4192" end_char="4193">of</TOKEN>
<TOKEN id="token-36-31" pos="word" morph="none" start_char="4195" end_char="4200">public</TOKEN>
<TOKEN id="token-36-32" pos="word" morph="none" start_char="4202" end_char="4210">relations</TOKEN>
<TOKEN id="token-36-33" pos="word" morph="none" start_char="4212" end_char="4214">and</TOKEN>
<TOKEN id="token-36-34" pos="word" morph="none" start_char="4216" end_char="4220">media</TOKEN>
<TOKEN id="token-36-35" pos="word" morph="none" start_char="4222" end_char="4229">coverage</TOKEN>
<TOKEN id="token-36-36" pos="punct" morph="none" start_char="4230" end_char="4230">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="4233" end_char="4353">
<ORIGINAL_TEXT>In any case, it looks as though the Pfizers and Modernas of this world got the results they needed when they needed them.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="4233" end_char="4234">In</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="4236" end_char="4238">any</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="4240" end_char="4243">case</TOKEN>
<TOKEN id="token-37-3" pos="punct" morph="none" start_char="4244" end_char="4244">,</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="4246" end_char="4247">it</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="4249" end_char="4253">looks</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="4255" end_char="4256">as</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="4258" end_char="4263">though</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="4265" end_char="4267">the</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="4269" end_char="4275">Pfizers</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="4277" end_char="4279">and</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="4281" end_char="4288">Modernas</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="4290" end_char="4291">of</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="4293" end_char="4296">this</TOKEN>
<TOKEN id="token-37-14" pos="word" morph="none" start_char="4298" end_char="4302">world</TOKEN>
<TOKEN id="token-37-15" pos="word" morph="none" start_char="4304" end_char="4306">got</TOKEN>
<TOKEN id="token-37-16" pos="word" morph="none" start_char="4308" end_char="4310">the</TOKEN>
<TOKEN id="token-37-17" pos="word" morph="none" start_char="4312" end_char="4318">results</TOKEN>
<TOKEN id="token-37-18" pos="word" morph="none" start_char="4320" end_char="4323">they</TOKEN>
<TOKEN id="token-37-19" pos="word" morph="none" start_char="4325" end_char="4330">needed</TOKEN>
<TOKEN id="token-37-20" pos="word" morph="none" start_char="4332" end_char="4335">when</TOKEN>
<TOKEN id="token-37-21" pos="word" morph="none" start_char="4337" end_char="4340">they</TOKEN>
<TOKEN id="token-37-22" pos="word" morph="none" start_char="4342" end_char="4347">needed</TOKEN>
<TOKEN id="token-37-23" pos="word" morph="none" start_char="4349" end_char="4352">them</TOKEN>
<TOKEN id="token-37-24" pos="punct" morph="none" start_char="4353" end_char="4353">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="4355" end_char="4483">
<ORIGINAL_TEXT>Prepare for an avalanche of ‘explainers’ on how T cell immunity works, and why it’s so optimistic for the prospects of a vaccine.</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="4355" end_char="4361">Prepare</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="4363" end_char="4365">for</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="4367" end_char="4368">an</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="4370" end_char="4378">avalanche</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="4380" end_char="4381">of</TOKEN>
<TOKEN id="token-38-5" pos="punct" morph="none" start_char="4383" end_char="4383">‘</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="4384" end_char="4393">explainers</TOKEN>
<TOKEN id="token-38-7" pos="punct" morph="none" start_char="4394" end_char="4394">’</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="4396" end_char="4397">on</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="4399" end_char="4401">how</TOKEN>
<TOKEN id="token-38-10" pos="word" morph="none" start_char="4403" end_char="4403">T</TOKEN>
<TOKEN id="token-38-11" pos="word" morph="none" start_char="4405" end_char="4408">cell</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="4410" end_char="4417">immunity</TOKEN>
<TOKEN id="token-38-13" pos="word" morph="none" start_char="4419" end_char="4423">works</TOKEN>
<TOKEN id="token-38-14" pos="punct" morph="none" start_char="4424" end_char="4424">,</TOKEN>
<TOKEN id="token-38-15" pos="word" morph="none" start_char="4426" end_char="4428">and</TOKEN>
<TOKEN id="token-38-16" pos="word" morph="none" start_char="4430" end_char="4432">why</TOKEN>
<TOKEN id="token-38-17" pos="word" morph="none" start_char="4434" end_char="4437">it’s</TOKEN>
<TOKEN id="token-38-18" pos="word" morph="none" start_char="4439" end_char="4440">so</TOKEN>
<TOKEN id="token-38-19" pos="word" morph="none" start_char="4442" end_char="4451">optimistic</TOKEN>
<TOKEN id="token-38-20" pos="word" morph="none" start_char="4453" end_char="4455">for</TOKEN>
<TOKEN id="token-38-21" pos="word" morph="none" start_char="4457" end_char="4459">the</TOKEN>
<TOKEN id="token-38-22" pos="word" morph="none" start_char="4461" end_char="4469">prospects</TOKEN>
<TOKEN id="token-38-23" pos="word" morph="none" start_char="4471" end_char="4472">of</TOKEN>
<TOKEN id="token-38-24" pos="word" morph="none" start_char="4474" end_char="4474">a</TOKEN>
<TOKEN id="token-38-25" pos="word" morph="none" start_char="4476" end_char="4482">vaccine</TOKEN>
<TOKEN id="token-38-26" pos="punct" morph="none" start_char="4483" end_char="4483">.</TOKEN>
</SEG>
<SEG id="segment-39" start_char="4485" end_char="4666">
<ORIGINAL_TEXT>But if you’re hoping for a wider discussion of whether previous infection might make vaccination redundant, or whether mass T cell testing might be an option, don’t hold your breath.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="4485" end_char="4487">But</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="4489" end_char="4490">if</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="4492" end_char="4497">you’re</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="4499" end_char="4504">hoping</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="4506" end_char="4508">for</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="4510" end_char="4510">a</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="4512" end_char="4516">wider</TOKEN>
<TOKEN id="token-39-7" pos="word" morph="none" start_char="4518" end_char="4527">discussion</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="4529" end_char="4530">of</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="4532" end_char="4538">whether</TOKEN>
<TOKEN id="token-39-10" pos="word" morph="none" start_char="4540" end_char="4547">previous</TOKEN>
<TOKEN id="token-39-11" pos="word" morph="none" start_char="4549" end_char="4557">infection</TOKEN>
<TOKEN id="token-39-12" pos="word" morph="none" start_char="4559" end_char="4563">might</TOKEN>
<TOKEN id="token-39-13" pos="word" morph="none" start_char="4565" end_char="4568">make</TOKEN>
<TOKEN id="token-39-14" pos="word" morph="none" start_char="4570" end_char="4580">vaccination</TOKEN>
<TOKEN id="token-39-15" pos="word" morph="none" start_char="4582" end_char="4590">redundant</TOKEN>
<TOKEN id="token-39-16" pos="punct" morph="none" start_char="4591" end_char="4591">,</TOKEN>
<TOKEN id="token-39-17" pos="word" morph="none" start_char="4593" end_char="4594">or</TOKEN>
<TOKEN id="token-39-18" pos="word" morph="none" start_char="4596" end_char="4602">whether</TOKEN>
<TOKEN id="token-39-19" pos="word" morph="none" start_char="4604" end_char="4607">mass</TOKEN>
<TOKEN id="token-39-20" pos="word" morph="none" start_char="4609" end_char="4609">T</TOKEN>
<TOKEN id="token-39-21" pos="word" morph="none" start_char="4611" end_char="4614">cell</TOKEN>
<TOKEN id="token-39-22" pos="word" morph="none" start_char="4616" end_char="4622">testing</TOKEN>
<TOKEN id="token-39-23" pos="word" morph="none" start_char="4624" end_char="4628">might</TOKEN>
<TOKEN id="token-39-24" pos="word" morph="none" start_char="4630" end_char="4631">be</TOKEN>
<TOKEN id="token-39-25" pos="word" morph="none" start_char="4633" end_char="4634">an</TOKEN>
<TOKEN id="token-39-26" pos="word" morph="none" start_char="4636" end_char="4641">option</TOKEN>
<TOKEN id="token-39-27" pos="punct" morph="none" start_char="4642" end_char="4642">,</TOKEN>
<TOKEN id="token-39-28" pos="word" morph="none" start_char="4644" end_char="4648">don’t</TOKEN>
<TOKEN id="token-39-29" pos="word" morph="none" start_char="4650" end_char="4653">hold</TOKEN>
<TOKEN id="token-39-30" pos="word" morph="none" start_char="4655" end_char="4658">your</TOKEN>
<TOKEN id="token-39-31" pos="word" morph="none" start_char="4660" end_char="4665">breath</TOKEN>
<TOKEN id="token-39-32" pos="punct" morph="none" start_char="4666" end_char="4666">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="4669" end_char="4707">
<ORIGINAL_TEXT>Think your friends would be interested?</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="4669" end_char="4673">Think</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="4675" end_char="4678">your</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="4680" end_char="4686">friends</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="4688" end_char="4692">would</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="4694" end_char="4695">be</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="4697" end_char="4706">interested</TOKEN>
<TOKEN id="token-40-6" pos="punct" morph="none" start_char="4707" end_char="4707">?</TOKEN>
</SEG>
<SEG id="segment-41" start_char="4709" end_char="4725">
<ORIGINAL_TEXT>Share this story!</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="4709" end_char="4713">Share</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="4715" end_char="4718">this</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="4720" end_char="4724">story</TOKEN>
<TOKEN id="token-41-3" pos="punct" morph="none" start_char="4725" end_char="4725">!</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
