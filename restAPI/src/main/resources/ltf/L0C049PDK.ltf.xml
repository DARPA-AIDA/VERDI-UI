<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="ukr">
<DOC id="L0C049PDK" lang="ukr" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="17987" raw_text_md5="ef1e64b8a3b71d355b3f05d33a8e8277">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="59">
<ORIGINAL_TEXT>Did coronavirus originate in Chinese government laboratory?</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="3">Did</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="5" end_char="15">coronavirus</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="17" end_char="25">originate</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="27" end_char="28">in</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="30" end_char="36">Chinese</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="38" end_char="47">government</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="49" end_char="58">laboratory</TOKEN>
<TOKEN id="token-0-7" pos="punct" morph="none" start_char="59" end_char="59">?</TOKEN>
</SEG>
<SEG id="segment-1" start_char="61" end_char="96">
<ORIGINAL_TEXT>Chinese Scientists believe "it did."</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="61" end_char="67">Chinese</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="69" end_char="78">Scientists</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="80" end_char="86">believe</TOKEN>
<TOKEN id="token-1-3" pos="punct" morph="none" start_char="88" end_char="88">"</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="89" end_char="90">it</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="92" end_char="94">did</TOKEN>
<TOKEN id="token-1-6" pos="punct" morph="none" start_char="95" end_char="96">."</TOKEN>
</SEG>
<SEG id="segment-2" start_char="100" end_char="151">
<ORIGINAL_TEXT>(Had to truncate the title because it was too long.)</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="punct" morph="none" start_char="100" end_char="100">(</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="101" end_char="103">Had</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="105" end_char="106">to</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="108" end_char="115">truncate</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="117" end_char="119">the</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="121" end_char="125">title</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="127" end_char="133">because</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="135" end_char="136">it</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="138" end_char="140">was</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="142" end_char="144">too</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="146" end_char="149">long</TOKEN>
<TOKEN id="token-2-11" pos="punct" morph="none" start_char="150" end_char="151">.)</TOKEN>
</SEG>
<SEG id="segment-3" start_char="154" end_char="290">
<ORIGINAL_TEXT>Chinese scientists believe the deadly coronavirus may have started life in a research facility just 300 yards from the Wuhan fish market.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="154" end_char="160">Chinese</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="162" end_char="171">scientists</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="173" end_char="179">believe</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="181" end_char="183">the</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="185" end_char="190">deadly</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="192" end_char="202">coronavirus</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="204" end_char="206">may</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="208" end_char="211">have</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="213" end_char="219">started</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="221" end_char="224">life</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="226" end_char="227">in</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="229" end_char="229">a</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="231" end_char="238">research</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="240" end_char="247">facility</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="249" end_char="252">just</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="254" end_char="256">300</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="258" end_char="262">yards</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="264" end_char="267">from</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="269" end_char="271">the</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="273" end_char="277">Wuhan</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="279" end_char="282">fish</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="284" end_char="289">market</TOKEN>
<TOKEN id="token-3-22" pos="punct" morph="none" start_char="290" end_char="290">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="292" end_char="483">
<ORIGINAL_TEXT>A new bombshell paper from the Beijing-sponsored South China University of Technology says that the Wuhan Center for Disease Control (WHCDC) could have spawned the contagion in Hubei province.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="292" end_char="292">A</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="294" end_char="296">new</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="298" end_char="306">bombshell</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="308" end_char="312">paper</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="314" end_char="317">from</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="319" end_char="321">the</TOKEN>
<TOKEN id="token-4-6" pos="unknown" morph="none" start_char="323" end_char="339">Beijing-sponsored</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="341" end_char="345">South</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="347" end_char="351">China</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="353" end_char="362">University</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="364" end_char="365">of</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="367" end_char="376">Technology</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="378" end_char="381">says</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="383" end_char="386">that</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="388" end_char="390">the</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="392" end_char="396">Wuhan</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="398" end_char="403">Center</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="405" end_char="407">for</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="409" end_char="415">Disease</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="417" end_char="423">Control</TOKEN>
<TOKEN id="token-4-20" pos="punct" morph="none" start_char="425" end_char="425">(</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="426" end_char="430">WHCDC</TOKEN>
<TOKEN id="token-4-22" pos="punct" morph="none" start_char="431" end_char="431">)</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="433" end_char="437">could</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="439" end_char="442">have</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="444" end_char="450">spawned</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="452" end_char="454">the</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="456" end_char="464">contagion</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="466" end_char="467">in</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="469" end_char="473">Hubei</TOKEN>
<TOKEN id="token-4-30" pos="word" morph="none" start_char="475" end_char="482">province</TOKEN>
<TOKEN id="token-4-31" pos="punct" morph="none" start_char="483" end_char="483">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="485" end_char="657">
<ORIGINAL_TEXT>'The possible origins of 2019-nCoV coronavirus,' penned by scholars Botao Xiao and Lei Xiao claims the WHCDC kept disease-ridden animals in laboratories, including 605 bats.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="punct" morph="none" start_char="485" end_char="485">'</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="486" end_char="488">The</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="490" end_char="497">possible</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="499" end_char="505">origins</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="507" end_char="508">of</TOKEN>
<TOKEN id="token-5-5" pos="unknown" morph="none" start_char="510" end_char="518">2019-nCoV</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="520" end_char="530">coronavirus</TOKEN>
<TOKEN id="token-5-7" pos="punct" morph="none" start_char="531" end_char="532">,'</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="534" end_char="539">penned</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="541" end_char="542">by</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="544" end_char="551">scholars</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="553" end_char="557">Botao</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="559" end_char="562">Xiao</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="564" end_char="566">and</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="568" end_char="570">Lei</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="572" end_char="575">Xiao</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="577" end_char="582">claims</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="584" end_char="586">the</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="588" end_char="592">WHCDC</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="594" end_char="597">kept</TOKEN>
<TOKEN id="token-5-20" pos="unknown" morph="none" start_char="599" end_char="612">disease-ridden</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="614" end_char="620">animals</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="622" end_char="623">in</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="625" end_char="636">laboratories</TOKEN>
<TOKEN id="token-5-24" pos="punct" morph="none" start_char="637" end_char="637">,</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="639" end_char="647">including</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="649" end_char="651">605</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="653" end_char="656">bats</TOKEN>
<TOKEN id="token-5-28" pos="punct" morph="none" start_char="657" end_char="657">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="659" end_char="783">
<ORIGINAL_TEXT>It also mentions that bats - which are linked to coronavirus - once attacked a researcher and 'blood of bat was on his skin.'</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="659" end_char="660">It</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="662" end_char="665">also</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="667" end_char="674">mentions</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="676" end_char="679">that</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="681" end_char="684">bats</TOKEN>
<TOKEN id="token-6-5" pos="punct" morph="none" start_char="686" end_char="686">-</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="688" end_char="692">which</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="694" end_char="696">are</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="698" end_char="703">linked</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="705" end_char="706">to</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="708" end_char="718">coronavirus</TOKEN>
<TOKEN id="token-6-11" pos="punct" morph="none" start_char="720" end_char="720">-</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="722" end_char="725">once</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="727" end_char="734">attacked</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="736" end_char="736">a</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="738" end_char="747">researcher</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="749" end_char="751">and</TOKEN>
<TOKEN id="token-6-17" pos="punct" morph="none" start_char="753" end_char="753">'</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="754" end_char="758">blood</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="760" end_char="761">of</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="763" end_char="765">bat</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="767" end_char="769">was</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="771" end_char="772">on</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="774" end_char="776">his</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="778" end_char="781">skin</TOKEN>
<TOKEN id="token-6-25" pos="punct" morph="none" start_char="782" end_char="783">.'</TOKEN>
</SEG>
<SEG id="segment-7" start_char="785" end_char="787">
<ORIGINAL_TEXT>...</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="punct" morph="none" start_char="785" end_char="787">...</TOKEN>
</SEG>
<SEG id="segment-8" start_char="790" end_char="848">
<ORIGINAL_TEXT>Did coronavirus originate in Chinese government laboratory?</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="790" end_char="792">Did</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="794" end_char="804">coronavirus</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="806" end_char="814">originate</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="816" end_char="817">in</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="819" end_char="825">Chinese</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="827" end_char="836">government</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="838" end_char="847">laboratory</TOKEN>
<TOKEN id="token-8-7" pos="punct" morph="none" start_char="848" end_char="848">?</TOKEN>
</SEG>
<SEG id="segment-9" start_char="850" end_char="955">
<ORIGINAL_TEXT>Scientists believe killer disease may have begun in research facility 300 yards from Wuhan wet fish market</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="850" end_char="859">Scientists</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="861" end_char="867">believe</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="869" end_char="874">killer</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="876" end_char="882">disease</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="884" end_char="886">may</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="888" end_char="891">have</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="893" end_char="897">begun</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="899" end_char="900">in</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="902" end_char="909">research</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="911" end_char="918">facility</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="920" end_char="922">300</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="924" end_char="928">yards</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="930" end_char="933">from</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="935" end_char="939">Wuhan</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="941" end_char="943">wet</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="945" end_char="948">fish</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="950" end_char="955">market</TOKEN>
</SEG>
<SEG id="segment-10" start_char="958" end_char="1312">
<ORIGINAL_TEXT>Despite the lies being told by the Chinese government, which now is trying to blame the U.S. for COVID-19, in fact a "Beijing-sponsored South China University of Technology study" concluded that the COVID-19 virus was in fact caused by an accident, in which bats infected with the virus attacked a researcher and "blood of a bat was on skin of researcher.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="958" end_char="964">Despite</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="966" end_char="968">the</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="970" end_char="973">lies</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="975" end_char="979">being</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="981" end_char="984">told</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="986" end_char="987">by</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="989" end_char="991">the</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="993" end_char="999">Chinese</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1001" end_char="1010">government</TOKEN>
<TOKEN id="token-10-9" pos="punct" morph="none" start_char="1011" end_char="1011">,</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1013" end_char="1017">which</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1019" end_char="1021">now</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1023" end_char="1024">is</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1026" end_char="1031">trying</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1033" end_char="1034">to</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1036" end_char="1040">blame</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1042" end_char="1044">the</TOKEN>
<TOKEN id="token-10-17" pos="unknown" morph="none" start_char="1046" end_char="1048">U.S</TOKEN>
<TOKEN id="token-10-18" pos="punct" morph="none" start_char="1049" end_char="1049">.</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1051" end_char="1053">for</TOKEN>
<TOKEN id="token-10-20" pos="unknown" morph="none" start_char="1055" end_char="1062">COVID-19</TOKEN>
<TOKEN id="token-10-21" pos="punct" morph="none" start_char="1063" end_char="1063">,</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1065" end_char="1066">in</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1068" end_char="1071">fact</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1073" end_char="1073">a</TOKEN>
<TOKEN id="token-10-25" pos="punct" morph="none" start_char="1075" end_char="1075">"</TOKEN>
<TOKEN id="token-10-26" pos="unknown" morph="none" start_char="1076" end_char="1092">Beijing-sponsored</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="1094" end_char="1098">South</TOKEN>
<TOKEN id="token-10-28" pos="word" morph="none" start_char="1100" end_char="1104">China</TOKEN>
<TOKEN id="token-10-29" pos="word" morph="none" start_char="1106" end_char="1115">University</TOKEN>
<TOKEN id="token-10-30" pos="word" morph="none" start_char="1117" end_char="1118">of</TOKEN>
<TOKEN id="token-10-31" pos="word" morph="none" start_char="1120" end_char="1129">Technology</TOKEN>
<TOKEN id="token-10-32" pos="word" morph="none" start_char="1131" end_char="1135">study</TOKEN>
<TOKEN id="token-10-33" pos="punct" morph="none" start_char="1136" end_char="1136">"</TOKEN>
<TOKEN id="token-10-34" pos="word" morph="none" start_char="1138" end_char="1146">concluded</TOKEN>
<TOKEN id="token-10-35" pos="word" morph="none" start_char="1148" end_char="1151">that</TOKEN>
<TOKEN id="token-10-36" pos="word" morph="none" start_char="1153" end_char="1155">the</TOKEN>
<TOKEN id="token-10-37" pos="unknown" morph="none" start_char="1157" end_char="1164">COVID-19</TOKEN>
<TOKEN id="token-10-38" pos="word" morph="none" start_char="1166" end_char="1170">virus</TOKEN>
<TOKEN id="token-10-39" pos="word" morph="none" start_char="1172" end_char="1174">was</TOKEN>
<TOKEN id="token-10-40" pos="word" morph="none" start_char="1176" end_char="1177">in</TOKEN>
<TOKEN id="token-10-41" pos="word" morph="none" start_char="1179" end_char="1182">fact</TOKEN>
<TOKEN id="token-10-42" pos="word" morph="none" start_char="1184" end_char="1189">caused</TOKEN>
<TOKEN id="token-10-43" pos="word" morph="none" start_char="1191" end_char="1192">by</TOKEN>
<TOKEN id="token-10-44" pos="word" morph="none" start_char="1194" end_char="1195">an</TOKEN>
<TOKEN id="token-10-45" pos="word" morph="none" start_char="1197" end_char="1204">accident</TOKEN>
<TOKEN id="token-10-46" pos="punct" morph="none" start_char="1205" end_char="1205">,</TOKEN>
<TOKEN id="token-10-47" pos="word" morph="none" start_char="1207" end_char="1208">in</TOKEN>
<TOKEN id="token-10-48" pos="word" morph="none" start_char="1210" end_char="1214">which</TOKEN>
<TOKEN id="token-10-49" pos="word" morph="none" start_char="1216" end_char="1219">bats</TOKEN>
<TOKEN id="token-10-50" pos="word" morph="none" start_char="1221" end_char="1228">infected</TOKEN>
<TOKEN id="token-10-51" pos="word" morph="none" start_char="1230" end_char="1233">with</TOKEN>
<TOKEN id="token-10-52" pos="word" morph="none" start_char="1235" end_char="1237">the</TOKEN>
<TOKEN id="token-10-53" pos="word" morph="none" start_char="1239" end_char="1243">virus</TOKEN>
<TOKEN id="token-10-54" pos="word" morph="none" start_char="1245" end_char="1252">attacked</TOKEN>
<TOKEN id="token-10-55" pos="word" morph="none" start_char="1254" end_char="1254">a</TOKEN>
<TOKEN id="token-10-56" pos="word" morph="none" start_char="1256" end_char="1265">researcher</TOKEN>
<TOKEN id="token-10-57" pos="word" morph="none" start_char="1267" end_char="1269">and</TOKEN>
<TOKEN id="token-10-58" pos="punct" morph="none" start_char="1271" end_char="1271">"</TOKEN>
<TOKEN id="token-10-59" pos="word" morph="none" start_char="1272" end_char="1276">blood</TOKEN>
<TOKEN id="token-10-60" pos="word" morph="none" start_char="1278" end_char="1279">of</TOKEN>
<TOKEN id="token-10-61" pos="word" morph="none" start_char="1281" end_char="1281">a</TOKEN>
<TOKEN id="token-10-62" pos="word" morph="none" start_char="1283" end_char="1285">bat</TOKEN>
<TOKEN id="token-10-63" pos="word" morph="none" start_char="1287" end_char="1289">was</TOKEN>
<TOKEN id="token-10-64" pos="word" morph="none" start_char="1291" end_char="1292">on</TOKEN>
<TOKEN id="token-10-65" pos="word" morph="none" start_char="1294" end_char="1297">skin</TOKEN>
<TOKEN id="token-10-66" pos="word" morph="none" start_char="1299" end_char="1300">of</TOKEN>
<TOKEN id="token-10-67" pos="word" morph="none" start_char="1302" end_char="1311">researcher</TOKEN>
<TOKEN id="token-10-68" pos="punct" morph="none" start_char="1312" end_char="1312">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1315" end_char="1482">
<ORIGINAL_TEXT>According to the study, the accident occurred in a research facility at the "Wuhan Center for Disease Control and prevention" just 300 yards from the Wuhan fish market.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1315" end_char="1323">According</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1325" end_char="1326">to</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1328" end_char="1330">the</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1332" end_char="1336">study</TOKEN>
<TOKEN id="token-11-4" pos="punct" morph="none" start_char="1337" end_char="1337">,</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1339" end_char="1341">the</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1343" end_char="1350">accident</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1352" end_char="1359">occurred</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1361" end_char="1362">in</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1364" end_char="1364">a</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1366" end_char="1373">research</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1375" end_char="1382">facility</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1384" end_char="1385">at</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1387" end_char="1389">the</TOKEN>
<TOKEN id="token-11-14" pos="punct" morph="none" start_char="1391" end_char="1391">"</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1392" end_char="1396">Wuhan</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1398" end_char="1403">Center</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1405" end_char="1407">for</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1409" end_char="1415">Disease</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="1417" end_char="1423">Control</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1425" end_char="1427">and</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="1429" end_char="1438">prevention</TOKEN>
<TOKEN id="token-11-22" pos="punct" morph="none" start_char="1439" end_char="1439">"</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="1441" end_char="1444">just</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="1446" end_char="1448">300</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="1450" end_char="1454">yards</TOKEN>
<TOKEN id="token-11-26" pos="word" morph="none" start_char="1456" end_char="1459">from</TOKEN>
<TOKEN id="token-11-27" pos="word" morph="none" start_char="1461" end_char="1463">the</TOKEN>
<TOKEN id="token-11-28" pos="word" morph="none" start_char="1465" end_char="1469">Wuhan</TOKEN>
<TOKEN id="token-11-29" pos="word" morph="none" start_char="1471" end_char="1474">fish</TOKEN>
<TOKEN id="token-11-30" pos="word" morph="none" start_char="1476" end_char="1481">market</TOKEN>
<TOKEN id="token-11-31" pos="punct" morph="none" start_char="1482" end_char="1482">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1485" end_char="1655">
<ORIGINAL_TEXT>So folks, despite all the lies that even the western left-wing media themselves, and the Chinese government, have been claiming this virus is a Wuhan/Chinese caused virus.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1485" end_char="1486">So</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1488" end_char="1492">folks</TOKEN>
<TOKEN id="token-12-2" pos="punct" morph="none" start_char="1493" end_char="1493">,</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1495" end_char="1501">despite</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1503" end_char="1505">all</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1507" end_char="1509">the</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1511" end_char="1514">lies</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1516" end_char="1519">that</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1521" end_char="1524">even</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1526" end_char="1528">the</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1530" end_char="1536">western</TOKEN>
<TOKEN id="token-12-11" pos="unknown" morph="none" start_char="1538" end_char="1546">left-wing</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1548" end_char="1552">media</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1554" end_char="1563">themselves</TOKEN>
<TOKEN id="token-12-14" pos="punct" morph="none" start_char="1564" end_char="1564">,</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1566" end_char="1568">and</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1570" end_char="1572">the</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1574" end_char="1580">Chinese</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1582" end_char="1591">government</TOKEN>
<TOKEN id="token-12-19" pos="punct" morph="none" start_char="1592" end_char="1592">,</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1594" end_char="1597">have</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1599" end_char="1602">been</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1604" end_char="1611">claiming</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="1613" end_char="1616">this</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="1618" end_char="1622">virus</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="1624" end_char="1625">is</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="1627" end_char="1627">a</TOKEN>
<TOKEN id="token-12-27" pos="unknown" morph="none" start_char="1629" end_char="1641">Wuhan/Chinese</TOKEN>
<TOKEN id="token-12-28" pos="word" morph="none" start_char="1643" end_char="1648">caused</TOKEN>
<TOKEN id="token-12-29" pos="word" morph="none" start_char="1650" end_char="1654">virus</TOKEN>
<TOKEN id="token-12-30" pos="punct" morph="none" start_char="1655" end_char="1655">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1658" end_char="1730">
<ORIGINAL_TEXT>edit on 12-3-2020 by ElectricUniverse because: correct comment and title.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1658" end_char="1661">edit</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1663" end_char="1664">on</TOKEN>
<TOKEN id="token-13-2" pos="unknown" morph="none" start_char="1666" end_char="1674">12-3-2020</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1676" end_char="1677">by</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1679" end_char="1694">ElectricUniverse</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1696" end_char="1702">because</TOKEN>
<TOKEN id="token-13-6" pos="punct" morph="none" start_char="1703" end_char="1703">:</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1705" end_char="1711">correct</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1713" end_char="1719">comment</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1721" end_char="1723">and</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1725" end_char="1729">title</TOKEN>
<TOKEN id="token-13-11" pos="punct" morph="none" start_char="1730" end_char="1730">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1734" end_char="1768">
<ORIGINAL_TEXT>Man, that article is purely hearsy.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1734" end_char="1736">Man</TOKEN>
<TOKEN id="token-14-1" pos="punct" morph="none" start_char="1737" end_char="1737">,</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1739" end_char="1742">that</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1744" end_char="1750">article</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1752" end_char="1753">is</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1755" end_char="1760">purely</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1762" end_char="1767">hearsy</TOKEN>
<TOKEN id="token-14-7" pos="punct" morph="none" start_char="1768" end_char="1768">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1770" end_char="1848">
<ORIGINAL_TEXT>The DailyMail and other sites that mention this "bombshell" say the same thing.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1770" end_char="1772">The</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1774" end_char="1782">DailyMail</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1784" end_char="1786">and</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1788" end_char="1792">other</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1794" end_char="1798">sites</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1800" end_char="1803">that</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1805" end_char="1811">mention</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1813" end_char="1816">this</TOKEN>
<TOKEN id="token-15-8" pos="punct" morph="none" start_char="1818" end_char="1818">"</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1819" end_char="1827">bombshell</TOKEN>
<TOKEN id="token-15-10" pos="punct" morph="none" start_char="1828" end_char="1828">"</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1830" end_char="1832">say</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1834" end_char="1836">the</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1838" end_char="1841">same</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1843" end_char="1847">thing</TOKEN>
<TOKEN id="token-15-15" pos="punct" morph="none" start_char="1848" end_char="1848">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1851" end_char="1879">
<ORIGINAL_TEXT>Without linking to the paper.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1851" end_char="1857">Without</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1859" end_char="1865">linking</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1867" end_char="1868">to</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1870" end_char="1872">the</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1874" end_char="1878">paper</TOKEN>
<TOKEN id="token-16-5" pos="punct" morph="none" start_char="1879" end_char="1879">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1881" end_char="1948">
<ORIGINAL_TEXT>This is fake news till we can get a legitimate source for the paper.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1881" end_char="1884">This</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1886" end_char="1887">is</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="1889" end_char="1892">fake</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="1894" end_char="1897">news</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="1899" end_char="1902">till</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="1904" end_char="1905">we</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="1907" end_char="1909">can</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="1911" end_char="1913">get</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="1915" end_char="1915">a</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="1917" end_char="1926">legitimate</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="1928" end_char="1933">source</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="1935" end_char="1937">for</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="1939" end_char="1941">the</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="1943" end_char="1947">paper</TOKEN>
<TOKEN id="token-17-14" pos="punct" morph="none" start_char="1948" end_char="1948">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1951" end_char="1977">
<ORIGINAL_TEXT>Or the actual paper itself.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="1951" end_char="1952">Or</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="1954" end_char="1956">the</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="1958" end_char="1963">actual</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="1965" end_char="1969">paper</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="1971" end_char="1976">itself</TOKEN>
<TOKEN id="token-18-5" pos="punct" morph="none" start_char="1977" end_char="1977">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="1980" end_char="1999">
<ORIGINAL_TEXT>Nevermind, found it!</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="1980" end_char="1988">Nevermind</TOKEN>
<TOKEN id="token-19-1" pos="punct" morph="none" start_char="1989" end_char="1989">,</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="1991" end_char="1995">found</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="1997" end_char="1998">it</TOKEN>
<TOKEN id="token-19-4" pos="punct" morph="none" start_char="1999" end_char="1999">!</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2001" end_char="2045">
<ORIGINAL_TEXT>The possible origins of 2019-nCoV coronavirus</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2001" end_char="2003">The</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2005" end_char="2012">possible</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2014" end_char="2020">origins</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2022" end_char="2023">of</TOKEN>
<TOKEN id="token-20-4" pos="unknown" morph="none" start_char="2025" end_char="2033">2019-nCoV</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2035" end_char="2045">coronavirus</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2049" end_char="2069">
<ORIGINAL_TEXT>a reply to: cenpuppie</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2049" end_char="2049">a</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2051" end_char="2055">reply</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2057" end_char="2058">to</TOKEN>
<TOKEN id="token-21-3" pos="punct" morph="none" start_char="2059" end_char="2059">:</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2061" end_char="2069">cenpuppie</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2072" end_char="2120">
<ORIGINAL_TEXT>I also wonder about the provenance of this paper.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2072" end_char="2072">I</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2074" end_char="2077">also</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2079" end_char="2084">wonder</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2086" end_char="2090">about</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2092" end_char="2094">the</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2096" end_char="2105">provenance</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2107" end_char="2108">of</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2110" end_char="2113">this</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="2115" end_char="2119">paper</TOKEN>
<TOKEN id="token-22-9" pos="punct" morph="none" start_char="2120" end_char="2120">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2122" end_char="2190">
<ORIGINAL_TEXT>Is clien.net an official forum for distribution of research in China?</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2122" end_char="2123">Is</TOKEN>
<TOKEN id="token-23-1" pos="unknown" morph="none" start_char="2125" end_char="2133">clien.net</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2135" end_char="2136">an</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2138" end_char="2145">official</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="2147" end_char="2151">forum</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="2153" end_char="2155">for</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="2157" end_char="2168">distribution</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="2170" end_char="2171">of</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="2173" end_char="2180">research</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="2182" end_char="2183">in</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="2185" end_char="2189">China</TOKEN>
<TOKEN id="token-23-11" pos="punct" morph="none" start_char="2190" end_char="2190">?</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2192" end_char="2246">
<ORIGINAL_TEXT>(I can't see anything implying that in a brief search.)</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="punct" morph="none" start_char="2192" end_char="2192">(</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="2193" end_char="2193">I</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="2195" end_char="2199">can't</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="2201" end_char="2203">see</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="2205" end_char="2212">anything</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="2214" end_char="2221">implying</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="2223" end_char="2226">that</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="2228" end_char="2229">in</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="2231" end_char="2231">a</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="2233" end_char="2237">brief</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="2239" end_char="2244">search</TOKEN>
<TOKEN id="token-24-11" pos="punct" morph="none" start_char="2245" end_char="2246">.)</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2249" end_char="2307">
<ORIGINAL_TEXT>Just wondering if this document isn't something fraudulent.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="2249" end_char="2252">Just</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="2254" end_char="2262">wondering</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="2264" end_char="2265">if</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="2267" end_char="2270">this</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="2272" end_char="2279">document</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="2281" end_char="2285">isn't</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="2287" end_char="2295">something</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="2297" end_char="2306">fraudulent</TOKEN>
<TOKEN id="token-25-8" pos="punct" morph="none" start_char="2307" end_char="2307">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="2309" end_char="2376">
<ORIGINAL_TEXT>Hard to believe the CCP would be okay with that kind of speculation.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="2309" end_char="2312">Hard</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="2314" end_char="2315">to</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="2317" end_char="2323">believe</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="2325" end_char="2327">the</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="2329" end_char="2331">CCP</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="2333" end_char="2337">would</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="2339" end_char="2340">be</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="2342" end_char="2345">okay</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="2347" end_char="2350">with</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="2352" end_char="2355">that</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="2357" end_char="2360">kind</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="2362" end_char="2363">of</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="2365" end_char="2375">speculation</TOKEN>
<TOKEN id="token-26-13" pos="punct" morph="none" start_char="2376" end_char="2376">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="2379" end_char="2384">
<ORIGINAL_TEXT>Cheers</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="2379" end_char="2384">Cheers</TOKEN>
</SEG>
<SEG id="segment-28" start_char="2388" end_char="2527">
<ORIGINAL_TEXT>Or the Chinese in Wuhan province are dirty hamsters and this is the natural result of poor food preparation and lack of sanitary conditions.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="2388" end_char="2389">Or</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="2391" end_char="2393">the</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="2395" end_char="2401">Chinese</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="2403" end_char="2404">in</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="2406" end_char="2410">Wuhan</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="2412" end_char="2419">province</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="2421" end_char="2423">are</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="2425" end_char="2429">dirty</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="2431" end_char="2438">hamsters</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="2440" end_char="2442">and</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="2444" end_char="2447">this</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="2449" end_char="2450">is</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="2452" end_char="2454">the</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="2456" end_char="2462">natural</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="2464" end_char="2469">result</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="2471" end_char="2472">of</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="2474" end_char="2477">poor</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="2479" end_char="2482">food</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="2484" end_char="2494">preparation</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="2496" end_char="2498">and</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="2500" end_char="2503">lack</TOKEN>
<TOKEN id="token-28-21" pos="word" morph="none" start_char="2505" end_char="2506">of</TOKEN>
<TOKEN id="token-28-22" pos="word" morph="none" start_char="2508" end_char="2515">sanitary</TOKEN>
<TOKEN id="token-28-23" pos="word" morph="none" start_char="2517" end_char="2526">conditions</TOKEN>
<TOKEN id="token-28-24" pos="punct" morph="none" start_char="2527" end_char="2527">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="2531" end_char="2795">
<ORIGINAL_TEXT>Corona virus was first discovered in the 1960s, fair to say the military in many countries have tried to weaponise it, maybe the Chinese succeeded, maybe the Americans did, one thing is for sure the daily fail and other infotainment agencies don't have the answers.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="2531" end_char="2536">Corona</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="2538" end_char="2542">virus</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="2544" end_char="2546">was</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="2548" end_char="2552">first</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="2554" end_char="2563">discovered</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="2565" end_char="2566">in</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="2568" end_char="2570">the</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="2572" end_char="2576">1960s</TOKEN>
<TOKEN id="token-29-8" pos="punct" morph="none" start_char="2577" end_char="2577">,</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="2579" end_char="2582">fair</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="2584" end_char="2585">to</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="2587" end_char="2589">say</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="2591" end_char="2593">the</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="2595" end_char="2602">military</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="2604" end_char="2605">in</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="2607" end_char="2610">many</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="2612" end_char="2620">countries</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="2622" end_char="2625">have</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="2627" end_char="2631">tried</TOKEN>
<TOKEN id="token-29-19" pos="word" morph="none" start_char="2633" end_char="2634">to</TOKEN>
<TOKEN id="token-29-20" pos="word" morph="none" start_char="2636" end_char="2644">weaponise</TOKEN>
<TOKEN id="token-29-21" pos="word" morph="none" start_char="2646" end_char="2647">it</TOKEN>
<TOKEN id="token-29-22" pos="punct" morph="none" start_char="2648" end_char="2648">,</TOKEN>
<TOKEN id="token-29-23" pos="word" morph="none" start_char="2650" end_char="2654">maybe</TOKEN>
<TOKEN id="token-29-24" pos="word" morph="none" start_char="2656" end_char="2658">the</TOKEN>
<TOKEN id="token-29-25" pos="word" morph="none" start_char="2660" end_char="2666">Chinese</TOKEN>
<TOKEN id="token-29-26" pos="word" morph="none" start_char="2668" end_char="2676">succeeded</TOKEN>
<TOKEN id="token-29-27" pos="punct" morph="none" start_char="2677" end_char="2677">,</TOKEN>
<TOKEN id="token-29-28" pos="word" morph="none" start_char="2679" end_char="2683">maybe</TOKEN>
<TOKEN id="token-29-29" pos="word" morph="none" start_char="2685" end_char="2687">the</TOKEN>
<TOKEN id="token-29-30" pos="word" morph="none" start_char="2689" end_char="2697">Americans</TOKEN>
<TOKEN id="token-29-31" pos="word" morph="none" start_char="2699" end_char="2701">did</TOKEN>
<TOKEN id="token-29-32" pos="punct" morph="none" start_char="2702" end_char="2702">,</TOKEN>
<TOKEN id="token-29-33" pos="word" morph="none" start_char="2704" end_char="2706">one</TOKEN>
<TOKEN id="token-29-34" pos="word" morph="none" start_char="2708" end_char="2712">thing</TOKEN>
<TOKEN id="token-29-35" pos="word" morph="none" start_char="2714" end_char="2715">is</TOKEN>
<TOKEN id="token-29-36" pos="word" morph="none" start_char="2717" end_char="2719">for</TOKEN>
<TOKEN id="token-29-37" pos="word" morph="none" start_char="2721" end_char="2724">sure</TOKEN>
<TOKEN id="token-29-38" pos="word" morph="none" start_char="2726" end_char="2728">the</TOKEN>
<TOKEN id="token-29-39" pos="word" morph="none" start_char="2730" end_char="2734">daily</TOKEN>
<TOKEN id="token-29-40" pos="word" morph="none" start_char="2736" end_char="2739">fail</TOKEN>
<TOKEN id="token-29-41" pos="word" morph="none" start_char="2741" end_char="2743">and</TOKEN>
<TOKEN id="token-29-42" pos="word" morph="none" start_char="2745" end_char="2749">other</TOKEN>
<TOKEN id="token-29-43" pos="word" morph="none" start_char="2751" end_char="2762">infotainment</TOKEN>
<TOKEN id="token-29-44" pos="word" morph="none" start_char="2764" end_char="2771">agencies</TOKEN>
<TOKEN id="token-29-45" pos="word" morph="none" start_char="2773" end_char="2777">don't</TOKEN>
<TOKEN id="token-29-46" pos="word" morph="none" start_char="2779" end_char="2782">have</TOKEN>
<TOKEN id="token-29-47" pos="word" morph="none" start_char="2784" end_char="2786">the</TOKEN>
<TOKEN id="token-29-48" pos="word" morph="none" start_char="2788" end_char="2794">answers</TOKEN>
<TOKEN id="token-29-49" pos="punct" morph="none" start_char="2795" end_char="2795">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="2799" end_char="2837">
<ORIGINAL_TEXT>This strain was planted by you know who</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="2799" end_char="2802">This</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="2804" end_char="2809">strain</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="2811" end_char="2813">was</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="2815" end_char="2821">planted</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="2823" end_char="2824">by</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="2826" end_char="2828">you</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="2830" end_char="2833">know</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="2835" end_char="2837">who</TOKEN>
</SEG>
<SEG id="segment-31" start_char="2841" end_char="2927">
<ORIGINAL_TEXT>I am no authority on this, but aren't there genetic markers when a virus is engineered?</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="2841" end_char="2841">I</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="2843" end_char="2844">am</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="2846" end_char="2847">no</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="2849" end_char="2857">authority</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="2859" end_char="2860">on</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="2862" end_char="2865">this</TOKEN>
<TOKEN id="token-31-6" pos="punct" morph="none" start_char="2866" end_char="2866">,</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="2868" end_char="2870">but</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="2872" end_char="2877">aren't</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="2879" end_char="2883">there</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="2885" end_char="2891">genetic</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="2893" end_char="2899">markers</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="2901" end_char="2904">when</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="2906" end_char="2906">a</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="2908" end_char="2912">virus</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="2914" end_char="2915">is</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="2917" end_char="2926">engineered</TOKEN>
<TOKEN id="token-31-17" pos="punct" morph="none" start_char="2927" end_char="2927">?</TOKEN>
</SEG>
<SEG id="segment-32" start_char="2929" end_char="3012">
<ORIGINAL_TEXT>With this many people looking at it I would think someone would have noticed by now.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="2929" end_char="2932">With</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="2934" end_char="2937">this</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="2939" end_char="2942">many</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="2944" end_char="2949">people</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="2951" end_char="2957">looking</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="2959" end_char="2960">at</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="2962" end_char="2963">it</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="2965" end_char="2965">I</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="2967" end_char="2971">would</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="2973" end_char="2977">think</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="2979" end_char="2985">someone</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="2987" end_char="2991">would</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="2993" end_char="2996">have</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="2998" end_char="3004">noticed</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="3006" end_char="3007">by</TOKEN>
<TOKEN id="token-32-15" pos="word" morph="none" start_char="3009" end_char="3011">now</TOKEN>
<TOKEN id="token-32-16" pos="punct" morph="none" start_char="3012" end_char="3012">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="3016" end_char="3043">
<ORIGINAL_TEXT>a reply to: ElectricUniverse</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="3016" end_char="3016">a</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="3018" end_char="3022">reply</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="3024" end_char="3025">to</TOKEN>
<TOKEN id="token-33-3" pos="punct" morph="none" start_char="3026" end_char="3026">:</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="3028" end_char="3043">ElectricUniverse</TOKEN>
</SEG>
<SEG id="segment-34" start_char="3046" end_char="3071">
<ORIGINAL_TEXT>I can't say I'm surprised.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="3046" end_char="3046">I</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="3048" end_char="3052">can't</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="3054" end_char="3056">say</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="3058" end_char="3060">I'm</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="3062" end_char="3070">surprised</TOKEN>
<TOKEN id="token-34-5" pos="punct" morph="none" start_char="3071" end_char="3071">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="3073" end_char="3115">
<ORIGINAL_TEXT>As I noted in this really excellent thread.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="3073" end_char="3074">As</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="3076" end_char="3076">I</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="3078" end_char="3082">noted</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="3084" end_char="3085">in</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="3087" end_char="3090">this</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="3092" end_char="3097">really</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="3099" end_char="3107">excellent</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="3109" end_char="3114">thread</TOKEN>
<TOKEN id="token-35-8" pos="punct" morph="none" start_char="3115" end_char="3115">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="3118" end_char="3234">
<ORIGINAL_TEXT>unless our collective Minitruths can compile a story that it wasn't actually the Chinese.....don't rule that one out.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="3118" end_char="3123">unless</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="3125" end_char="3127">our</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="3129" end_char="3138">collective</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="3140" end_char="3149">Minitruths</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="3151" end_char="3153">can</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="3155" end_char="3161">compile</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="3163" end_char="3163">a</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="3165" end_char="3169">story</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="3171" end_char="3174">that</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="3176" end_char="3177">it</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="3179" end_char="3184">wasn't</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="3186" end_char="3193">actually</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="3195" end_char="3197">the</TOKEN>
<TOKEN id="token-36-13" pos="unknown" morph="none" start_char="3199" end_char="3215">Chinese.....don't</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="3217" end_char="3220">rule</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="3222" end_char="3225">that</TOKEN>
<TOKEN id="token-36-16" pos="word" morph="none" start_char="3227" end_char="3229">one</TOKEN>
<TOKEN id="token-36-17" pos="word" morph="none" start_char="3231" end_char="3233">out</TOKEN>
<TOKEN id="token-36-18" pos="punct" morph="none" start_char="3234" end_char="3234">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="3237" end_char="3376">
<ORIGINAL_TEXT>While that may not be an absolutely prefect suggestion, it nevertheless points to some fairly hardcore back peddling as outlined in your OP.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="3237" end_char="3241">While</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="3243" end_char="3246">that</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="3248" end_char="3250">may</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="3252" end_char="3254">not</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="3256" end_char="3257">be</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="3259" end_char="3260">an</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="3262" end_char="3271">absolutely</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="3273" end_char="3279">prefect</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="3281" end_char="3290">suggestion</TOKEN>
<TOKEN id="token-37-9" pos="punct" morph="none" start_char="3291" end_char="3291">,</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="3293" end_char="3294">it</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="3296" end_char="3307">nevertheless</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="3309" end_char="3314">points</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="3316" end_char="3317">to</TOKEN>
<TOKEN id="token-37-14" pos="word" morph="none" start_char="3319" end_char="3322">some</TOKEN>
<TOKEN id="token-37-15" pos="word" morph="none" start_char="3324" end_char="3329">fairly</TOKEN>
<TOKEN id="token-37-16" pos="word" morph="none" start_char="3331" end_char="3338">hardcore</TOKEN>
<TOKEN id="token-37-17" pos="word" morph="none" start_char="3340" end_char="3343">back</TOKEN>
<TOKEN id="token-37-18" pos="word" morph="none" start_char="3345" end_char="3352">peddling</TOKEN>
<TOKEN id="token-37-19" pos="word" morph="none" start_char="3354" end_char="3355">as</TOKEN>
<TOKEN id="token-37-20" pos="word" morph="none" start_char="3357" end_char="3364">outlined</TOKEN>
<TOKEN id="token-37-21" pos="word" morph="none" start_char="3366" end_char="3367">in</TOKEN>
<TOKEN id="token-37-22" pos="word" morph="none" start_char="3369" end_char="3372">your</TOKEN>
<TOKEN id="token-37-23" pos="word" morph="none" start_char="3374" end_char="3375">OP</TOKEN>
<TOKEN id="token-37-24" pos="punct" morph="none" start_char="3376" end_char="3376">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="3380" end_char="3552">
<ORIGINAL_TEXT>The same month as the out break Wuhan Biosafety Lab was granted level 4 status meaning it had approval for the highest most deadly of virus's including Ebola and bioweapons.</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="3380" end_char="3382">The</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="3384" end_char="3387">same</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="3389" end_char="3393">month</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="3395" end_char="3396">as</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="3398" end_char="3400">the</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="3402" end_char="3404">out</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="3406" end_char="3410">break</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="3412" end_char="3416">Wuhan</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="3418" end_char="3426">Biosafety</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="3428" end_char="3430">Lab</TOKEN>
<TOKEN id="token-38-10" pos="word" morph="none" start_char="3432" end_char="3434">was</TOKEN>
<TOKEN id="token-38-11" pos="word" morph="none" start_char="3436" end_char="3442">granted</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="3444" end_char="3448">level</TOKEN>
<TOKEN id="token-38-13" pos="word" morph="none" start_char="3450" end_char="3450">4</TOKEN>
<TOKEN id="token-38-14" pos="word" morph="none" start_char="3452" end_char="3457">status</TOKEN>
<TOKEN id="token-38-15" pos="word" morph="none" start_char="3459" end_char="3465">meaning</TOKEN>
<TOKEN id="token-38-16" pos="word" morph="none" start_char="3467" end_char="3468">it</TOKEN>
<TOKEN id="token-38-17" pos="word" morph="none" start_char="3470" end_char="3472">had</TOKEN>
<TOKEN id="token-38-18" pos="word" morph="none" start_char="3474" end_char="3481">approval</TOKEN>
<TOKEN id="token-38-19" pos="word" morph="none" start_char="3483" end_char="3485">for</TOKEN>
<TOKEN id="token-38-20" pos="word" morph="none" start_char="3487" end_char="3489">the</TOKEN>
<TOKEN id="token-38-21" pos="word" morph="none" start_char="3491" end_char="3497">highest</TOKEN>
<TOKEN id="token-38-22" pos="word" morph="none" start_char="3499" end_char="3502">most</TOKEN>
<TOKEN id="token-38-23" pos="word" morph="none" start_char="3504" end_char="3509">deadly</TOKEN>
<TOKEN id="token-38-24" pos="word" morph="none" start_char="3511" end_char="3512">of</TOKEN>
<TOKEN id="token-38-25" pos="word" morph="none" start_char="3514" end_char="3520">virus's</TOKEN>
<TOKEN id="token-38-26" pos="word" morph="none" start_char="3522" end_char="3530">including</TOKEN>
<TOKEN id="token-38-27" pos="word" morph="none" start_char="3532" end_char="3536">Ebola</TOKEN>
<TOKEN id="token-38-28" pos="word" morph="none" start_char="3538" end_char="3540">and</TOKEN>
<TOKEN id="token-38-29" pos="word" morph="none" start_char="3542" end_char="3551">bioweapons</TOKEN>
<TOKEN id="token-38-30" pos="punct" morph="none" start_char="3552" end_char="3552">.</TOKEN>
</SEG>
<SEG id="segment-39" start_char="3554" end_char="3636">
<ORIGINAL_TEXT>Make of that what you will but to me this was either an accident or perhaps a test.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="3554" end_char="3557">Make</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="3559" end_char="3560">of</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="3562" end_char="3565">that</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="3567" end_char="3570">what</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="3572" end_char="3574">you</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="3576" end_char="3579">will</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="3581" end_char="3583">but</TOKEN>
<TOKEN id="token-39-7" pos="word" morph="none" start_char="3585" end_char="3586">to</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="3588" end_char="3589">me</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="3591" end_char="3594">this</TOKEN>
<TOKEN id="token-39-10" pos="word" morph="none" start_char="3596" end_char="3598">was</TOKEN>
<TOKEN id="token-39-11" pos="word" morph="none" start_char="3600" end_char="3605">either</TOKEN>
<TOKEN id="token-39-12" pos="word" morph="none" start_char="3607" end_char="3608">an</TOKEN>
<TOKEN id="token-39-13" pos="word" morph="none" start_char="3610" end_char="3617">accident</TOKEN>
<TOKEN id="token-39-14" pos="word" morph="none" start_char="3619" end_char="3620">or</TOKEN>
<TOKEN id="token-39-15" pos="word" morph="none" start_char="3622" end_char="3628">perhaps</TOKEN>
<TOKEN id="token-39-16" pos="word" morph="none" start_char="3630" end_char="3630">a</TOKEN>
<TOKEN id="token-39-17" pos="word" morph="none" start_char="3632" end_char="3635">test</TOKEN>
<TOKEN id="token-39-18" pos="punct" morph="none" start_char="3636" end_char="3636">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="3638" end_char="3792">
<ORIGINAL_TEXT>So far the Chinese have blamed bats, pangolins and dogs and as we all know, the information released from Chinese Government sources are far from reliable.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="3638" end_char="3639">So</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="3641" end_char="3643">far</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="3645" end_char="3647">the</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="3649" end_char="3655">Chinese</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="3657" end_char="3660">have</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="3662" end_char="3667">blamed</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="3669" end_char="3672">bats</TOKEN>
<TOKEN id="token-40-7" pos="punct" morph="none" start_char="3673" end_char="3673">,</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="3675" end_char="3683">pangolins</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="3685" end_char="3687">and</TOKEN>
<TOKEN id="token-40-10" pos="word" morph="none" start_char="3689" end_char="3692">dogs</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="3694" end_char="3696">and</TOKEN>
<TOKEN id="token-40-12" pos="word" morph="none" start_char="3698" end_char="3699">as</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="3701" end_char="3702">we</TOKEN>
<TOKEN id="token-40-14" pos="word" morph="none" start_char="3704" end_char="3706">all</TOKEN>
<TOKEN id="token-40-15" pos="word" morph="none" start_char="3708" end_char="3711">know</TOKEN>
<TOKEN id="token-40-16" pos="punct" morph="none" start_char="3712" end_char="3712">,</TOKEN>
<TOKEN id="token-40-17" pos="word" morph="none" start_char="3714" end_char="3716">the</TOKEN>
<TOKEN id="token-40-18" pos="word" morph="none" start_char="3718" end_char="3728">information</TOKEN>
<TOKEN id="token-40-19" pos="word" morph="none" start_char="3730" end_char="3737">released</TOKEN>
<TOKEN id="token-40-20" pos="word" morph="none" start_char="3739" end_char="3742">from</TOKEN>
<TOKEN id="token-40-21" pos="word" morph="none" start_char="3744" end_char="3750">Chinese</TOKEN>
<TOKEN id="token-40-22" pos="word" morph="none" start_char="3752" end_char="3761">Government</TOKEN>
<TOKEN id="token-40-23" pos="word" morph="none" start_char="3763" end_char="3769">sources</TOKEN>
<TOKEN id="token-40-24" pos="word" morph="none" start_char="3771" end_char="3773">are</TOKEN>
<TOKEN id="token-40-25" pos="word" morph="none" start_char="3775" end_char="3777">far</TOKEN>
<TOKEN id="token-40-26" pos="word" morph="none" start_char="3779" end_char="3782">from</TOKEN>
<TOKEN id="token-40-27" pos="word" morph="none" start_char="3784" end_char="3791">reliable</TOKEN>
<TOKEN id="token-40-28" pos="punct" morph="none" start_char="3792" end_char="3792">.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="3795" end_char="3918">
<ORIGINAL_TEXT>Let's also not forget that the SARS virus escaped multiple times from Bejing Laboratories so their track record isn't great!</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="3795" end_char="3799">Let's</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="3801" end_char="3804">also</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="3806" end_char="3808">not</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="3810" end_char="3815">forget</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="3817" end_char="3820">that</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="3822" end_char="3824">the</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="3826" end_char="3829">SARS</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="3831" end_char="3835">virus</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="3837" end_char="3843">escaped</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="3845" end_char="3852">multiple</TOKEN>
<TOKEN id="token-41-10" pos="word" morph="none" start_char="3854" end_char="3858">times</TOKEN>
<TOKEN id="token-41-11" pos="word" morph="none" start_char="3860" end_char="3863">from</TOKEN>
<TOKEN id="token-41-12" pos="word" morph="none" start_char="3865" end_char="3870">Bejing</TOKEN>
<TOKEN id="token-41-13" pos="word" morph="none" start_char="3872" end_char="3883">Laboratories</TOKEN>
<TOKEN id="token-41-14" pos="word" morph="none" start_char="3885" end_char="3886">so</TOKEN>
<TOKEN id="token-41-15" pos="word" morph="none" start_char="3888" end_char="3892">their</TOKEN>
<TOKEN id="token-41-16" pos="word" morph="none" start_char="3894" end_char="3898">track</TOKEN>
<TOKEN id="token-41-17" pos="word" morph="none" start_char="3900" end_char="3905">record</TOKEN>
<TOKEN id="token-41-18" pos="word" morph="none" start_char="3907" end_char="3911">isn't</TOKEN>
<TOKEN id="token-41-19" pos="word" morph="none" start_char="3913" end_char="3917">great</TOKEN>
<TOKEN id="token-41-20" pos="punct" morph="none" start_char="3918" end_char="3918">!</TOKEN>
</SEG>
<SEG id="segment-42" start_char="3922" end_char="3949">
<ORIGINAL_TEXT>a reply to: ElectricUniverse</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="3922" end_char="3922">a</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="3924" end_char="3928">reply</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="3930" end_char="3931">to</TOKEN>
<TOKEN id="token-42-3" pos="punct" morph="none" start_char="3932" end_char="3932">:</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="3934" end_char="3949">ElectricUniverse</TOKEN>
</SEG>
<SEG id="segment-43" start_char="3952" end_char="4192">
<ORIGINAL_TEXT>QUESTIONABLE SOURCE A questionable source exhibits one or more of the following: extreme bias, consistent promotion of propaganda/conspiracies, poor or no sourcing to credible information, a complete lack of transparency and/or is fake news.</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="3952" end_char="3963">QUESTIONABLE</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="3965" end_char="3970">SOURCE</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="3972" end_char="3972">A</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="3974" end_char="3985">questionable</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="3987" end_char="3992">source</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="3994" end_char="4001">exhibits</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="4003" end_char="4005">one</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="4007" end_char="4008">or</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="4010" end_char="4013">more</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="4015" end_char="4016">of</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="4018" end_char="4020">the</TOKEN>
<TOKEN id="token-43-11" pos="word" morph="none" start_char="4022" end_char="4030">following</TOKEN>
<TOKEN id="token-43-12" pos="punct" morph="none" start_char="4031" end_char="4031">:</TOKEN>
<TOKEN id="token-43-13" pos="word" morph="none" start_char="4033" end_char="4039">extreme</TOKEN>
<TOKEN id="token-43-14" pos="word" morph="none" start_char="4041" end_char="4044">bias</TOKEN>
<TOKEN id="token-43-15" pos="punct" morph="none" start_char="4045" end_char="4045">,</TOKEN>
<TOKEN id="token-43-16" pos="word" morph="none" start_char="4047" end_char="4056">consistent</TOKEN>
<TOKEN id="token-43-17" pos="word" morph="none" start_char="4058" end_char="4066">promotion</TOKEN>
<TOKEN id="token-43-18" pos="word" morph="none" start_char="4068" end_char="4069">of</TOKEN>
<TOKEN id="token-43-19" pos="unknown" morph="none" start_char="4071" end_char="4093">propaganda/conspiracies</TOKEN>
<TOKEN id="token-43-20" pos="punct" morph="none" start_char="4094" end_char="4094">,</TOKEN>
<TOKEN id="token-43-21" pos="word" morph="none" start_char="4096" end_char="4099">poor</TOKEN>
<TOKEN id="token-43-22" pos="word" morph="none" start_char="4101" end_char="4102">or</TOKEN>
<TOKEN id="token-43-23" pos="word" morph="none" start_char="4104" end_char="4105">no</TOKEN>
<TOKEN id="token-43-24" pos="word" morph="none" start_char="4107" end_char="4114">sourcing</TOKEN>
<TOKEN id="token-43-25" pos="word" morph="none" start_char="4116" end_char="4117">to</TOKEN>
<TOKEN id="token-43-26" pos="word" morph="none" start_char="4119" end_char="4126">credible</TOKEN>
<TOKEN id="token-43-27" pos="word" morph="none" start_char="4128" end_char="4138">information</TOKEN>
<TOKEN id="token-43-28" pos="punct" morph="none" start_char="4139" end_char="4139">,</TOKEN>
<TOKEN id="token-43-29" pos="word" morph="none" start_char="4141" end_char="4141">a</TOKEN>
<TOKEN id="token-43-30" pos="word" morph="none" start_char="4143" end_char="4150">complete</TOKEN>
<TOKEN id="token-43-31" pos="word" morph="none" start_char="4152" end_char="4155">lack</TOKEN>
<TOKEN id="token-43-32" pos="word" morph="none" start_char="4157" end_char="4158">of</TOKEN>
<TOKEN id="token-43-33" pos="word" morph="none" start_char="4160" end_char="4171">transparency</TOKEN>
<TOKEN id="token-43-34" pos="unknown" morph="none" start_char="4173" end_char="4178">and/or</TOKEN>
<TOKEN id="token-43-35" pos="word" morph="none" start_char="4180" end_char="4181">is</TOKEN>
<TOKEN id="token-43-36" pos="word" morph="none" start_char="4183" end_char="4186">fake</TOKEN>
<TOKEN id="token-43-37" pos="word" morph="none" start_char="4188" end_char="4191">news</TOKEN>
<TOKEN id="token-43-38" pos="punct" morph="none" start_char="4192" end_char="4192">.</TOKEN>
</SEG>
<SEG id="segment-44" start_char="4194" end_char="4321">
<ORIGINAL_TEXT>Fake News is the deliberate attempt to publish hoaxes and/or disinformation for the purpose of profit or influence (Learn More).</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="4194" end_char="4197">Fake</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="4199" end_char="4202">News</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="4204" end_char="4205">is</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="4207" end_char="4209">the</TOKEN>
<TOKEN id="token-44-4" pos="word" morph="none" start_char="4211" end_char="4220">deliberate</TOKEN>
<TOKEN id="token-44-5" pos="word" morph="none" start_char="4222" end_char="4228">attempt</TOKEN>
<TOKEN id="token-44-6" pos="word" morph="none" start_char="4230" end_char="4231">to</TOKEN>
<TOKEN id="token-44-7" pos="word" morph="none" start_char="4233" end_char="4239">publish</TOKEN>
<TOKEN id="token-44-8" pos="word" morph="none" start_char="4241" end_char="4246">hoaxes</TOKEN>
<TOKEN id="token-44-9" pos="unknown" morph="none" start_char="4248" end_char="4253">and/or</TOKEN>
<TOKEN id="token-44-10" pos="word" morph="none" start_char="4255" end_char="4268">disinformation</TOKEN>
<TOKEN id="token-44-11" pos="word" morph="none" start_char="4270" end_char="4272">for</TOKEN>
<TOKEN id="token-44-12" pos="word" morph="none" start_char="4274" end_char="4276">the</TOKEN>
<TOKEN id="token-44-13" pos="word" morph="none" start_char="4278" end_char="4284">purpose</TOKEN>
<TOKEN id="token-44-14" pos="word" morph="none" start_char="4286" end_char="4287">of</TOKEN>
<TOKEN id="token-44-15" pos="word" morph="none" start_char="4289" end_char="4294">profit</TOKEN>
<TOKEN id="token-44-16" pos="word" morph="none" start_char="4296" end_char="4297">or</TOKEN>
<TOKEN id="token-44-17" pos="word" morph="none" start_char="4299" end_char="4307">influence</TOKEN>
<TOKEN id="token-44-18" pos="punct" morph="none" start_char="4309" end_char="4309">(</TOKEN>
<TOKEN id="token-44-19" pos="word" morph="none" start_char="4310" end_char="4314">Learn</TOKEN>
<TOKEN id="token-44-20" pos="word" morph="none" start_char="4316" end_char="4319">More</TOKEN>
<TOKEN id="token-44-21" pos="punct" morph="none" start_char="4320" end_char="4321">).</TOKEN>
</SEG>
<SEG id="segment-45" start_char="4323" end_char="4442">
<ORIGINAL_TEXT>Sources listed in the Questionable Category may be very untrustworthy and should be fact checked on a per article basis.</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="4323" end_char="4329">Sources</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="4331" end_char="4336">listed</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="4338" end_char="4339">in</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="4341" end_char="4343">the</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="4345" end_char="4356">Questionable</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="4358" end_char="4365">Category</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="4367" end_char="4369">may</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="4371" end_char="4372">be</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="4374" end_char="4377">very</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="4379" end_char="4391">untrustworthy</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="4393" end_char="4395">and</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="4397" end_char="4402">should</TOKEN>
<TOKEN id="token-45-12" pos="word" morph="none" start_char="4404" end_char="4405">be</TOKEN>
<TOKEN id="token-45-13" pos="word" morph="none" start_char="4407" end_char="4410">fact</TOKEN>
<TOKEN id="token-45-14" pos="word" morph="none" start_char="4412" end_char="4418">checked</TOKEN>
<TOKEN id="token-45-15" pos="word" morph="none" start_char="4420" end_char="4421">on</TOKEN>
<TOKEN id="token-45-16" pos="word" morph="none" start_char="4423" end_char="4423">a</TOKEN>
<TOKEN id="token-45-17" pos="word" morph="none" start_char="4425" end_char="4427">per</TOKEN>
<TOKEN id="token-45-18" pos="word" morph="none" start_char="4429" end_char="4435">article</TOKEN>
<TOKEN id="token-45-19" pos="word" morph="none" start_char="4437" end_char="4441">basis</TOKEN>
<TOKEN id="token-45-20" pos="punct" morph="none" start_char="4442" end_char="4442">.</TOKEN>
</SEG>
<SEG id="segment-46" start_char="4444" end_char="4574">
<ORIGINAL_TEXT>Please note sources on this list are not considered fake news unless specifically written in the reasoning section for that source.</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="4444" end_char="4449">Please</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="4451" end_char="4454">note</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="4456" end_char="4462">sources</TOKEN>
<TOKEN id="token-46-3" pos="word" morph="none" start_char="4464" end_char="4465">on</TOKEN>
<TOKEN id="token-46-4" pos="word" morph="none" start_char="4467" end_char="4470">this</TOKEN>
<TOKEN id="token-46-5" pos="word" morph="none" start_char="4472" end_char="4475">list</TOKEN>
<TOKEN id="token-46-6" pos="word" morph="none" start_char="4477" end_char="4479">are</TOKEN>
<TOKEN id="token-46-7" pos="word" morph="none" start_char="4481" end_char="4483">not</TOKEN>
<TOKEN id="token-46-8" pos="word" morph="none" start_char="4485" end_char="4494">considered</TOKEN>
<TOKEN id="token-46-9" pos="word" morph="none" start_char="4496" end_char="4499">fake</TOKEN>
<TOKEN id="token-46-10" pos="word" morph="none" start_char="4501" end_char="4504">news</TOKEN>
<TOKEN id="token-46-11" pos="word" morph="none" start_char="4506" end_char="4511">unless</TOKEN>
<TOKEN id="token-46-12" pos="word" morph="none" start_char="4513" end_char="4524">specifically</TOKEN>
<TOKEN id="token-46-13" pos="word" morph="none" start_char="4526" end_char="4532">written</TOKEN>
<TOKEN id="token-46-14" pos="word" morph="none" start_char="4534" end_char="4535">in</TOKEN>
<TOKEN id="token-46-15" pos="word" morph="none" start_char="4537" end_char="4539">the</TOKEN>
<TOKEN id="token-46-16" pos="word" morph="none" start_char="4541" end_char="4549">reasoning</TOKEN>
<TOKEN id="token-46-17" pos="word" morph="none" start_char="4551" end_char="4557">section</TOKEN>
<TOKEN id="token-46-18" pos="word" morph="none" start_char="4559" end_char="4561">for</TOKEN>
<TOKEN id="token-46-19" pos="word" morph="none" start_char="4563" end_char="4566">that</TOKEN>
<TOKEN id="token-46-20" pos="word" morph="none" start_char="4568" end_char="4573">source</TOKEN>
<TOKEN id="token-46-21" pos="punct" morph="none" start_char="4574" end_char="4574">.</TOKEN>
</SEG>
<SEG id="segment-47" start_char="4576" end_char="4604">
<ORIGINAL_TEXT>See all Questionable sources.</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="4576" end_char="4578">See</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="4580" end_char="4582">all</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="4584" end_char="4595">Questionable</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="4597" end_char="4603">sources</TOKEN>
<TOKEN id="token-47-4" pos="punct" morph="none" start_char="4604" end_char="4604">.</TOKEN>
</SEG>
<SEG id="segment-48" start_char="4606" end_char="4714">
<ORIGINAL_TEXT>Overall, we rate Daily Mail Questionable due to numerous failed fact checks and poor sourcing of information.</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="4606" end_char="4612">Overall</TOKEN>
<TOKEN id="token-48-1" pos="punct" morph="none" start_char="4613" end_char="4613">,</TOKEN>
<TOKEN id="token-48-2" pos="word" morph="none" start_char="4615" end_char="4616">we</TOKEN>
<TOKEN id="token-48-3" pos="word" morph="none" start_char="4618" end_char="4621">rate</TOKEN>
<TOKEN id="token-48-4" pos="word" morph="none" start_char="4623" end_char="4627">Daily</TOKEN>
<TOKEN id="token-48-5" pos="word" morph="none" start_char="4629" end_char="4632">Mail</TOKEN>
<TOKEN id="token-48-6" pos="word" morph="none" start_char="4634" end_char="4645">Questionable</TOKEN>
<TOKEN id="token-48-7" pos="word" morph="none" start_char="4647" end_char="4649">due</TOKEN>
<TOKEN id="token-48-8" pos="word" morph="none" start_char="4651" end_char="4652">to</TOKEN>
<TOKEN id="token-48-9" pos="word" morph="none" start_char="4654" end_char="4661">numerous</TOKEN>
<TOKEN id="token-48-10" pos="word" morph="none" start_char="4663" end_char="4668">failed</TOKEN>
<TOKEN id="token-48-11" pos="word" morph="none" start_char="4670" end_char="4673">fact</TOKEN>
<TOKEN id="token-48-12" pos="word" morph="none" start_char="4675" end_char="4680">checks</TOKEN>
<TOKEN id="token-48-13" pos="word" morph="none" start_char="4682" end_char="4684">and</TOKEN>
<TOKEN id="token-48-14" pos="word" morph="none" start_char="4686" end_char="4689">poor</TOKEN>
<TOKEN id="token-48-15" pos="word" morph="none" start_char="4691" end_char="4698">sourcing</TOKEN>
<TOKEN id="token-48-16" pos="word" morph="none" start_char="4700" end_char="4701">of</TOKEN>
<TOKEN id="token-48-17" pos="word" morph="none" start_char="4703" end_char="4713">information</TOKEN>
<TOKEN id="token-48-18" pos="punct" morph="none" start_char="4714" end_char="4714">.</TOKEN>
</SEG>
<SEG id="segment-49" start_char="4716" end_char="4725">
<ORIGINAL_TEXT>Daily Mail</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="4716" end_char="4720">Daily</TOKEN>
<TOKEN id="token-49-1" pos="word" morph="none" start_char="4722" end_char="4725">Mail</TOKEN>
</SEG>
<SEG id="segment-50" start_char="4728" end_char="4760">
<ORIGINAL_TEXT>please, a super market tabloid???</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="4728" end_char="4733">please</TOKEN>
<TOKEN id="token-50-1" pos="punct" morph="none" start_char="4734" end_char="4734">,</TOKEN>
<TOKEN id="token-50-2" pos="word" morph="none" start_char="4736" end_char="4736">a</TOKEN>
<TOKEN id="token-50-3" pos="word" morph="none" start_char="4738" end_char="4742">super</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="4744" end_char="4749">market</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="4751" end_char="4757">tabloid</TOKEN>
<TOKEN id="token-50-6" pos="punct" morph="none" start_char="4758" end_char="4760">???</TOKEN>
</SEG>
<SEG id="segment-51" start_char="4763" end_char="4824">
<ORIGINAL_TEXT>edit on 13-3-2020 by hounddoghowlie because: (no reason given)</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="word" morph="none" start_char="4763" end_char="4766">edit</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="4768" end_char="4769">on</TOKEN>
<TOKEN id="token-51-2" pos="unknown" morph="none" start_char="4771" end_char="4779">13-3-2020</TOKEN>
<TOKEN id="token-51-3" pos="word" morph="none" start_char="4781" end_char="4782">by</TOKEN>
<TOKEN id="token-51-4" pos="word" morph="none" start_char="4784" end_char="4797">hounddoghowlie</TOKEN>
<TOKEN id="token-51-5" pos="word" morph="none" start_char="4799" end_char="4805">because</TOKEN>
<TOKEN id="token-51-6" pos="punct" morph="none" start_char="4806" end_char="4806">:</TOKEN>
<TOKEN id="token-51-7" pos="punct" morph="none" start_char="4808" end_char="4808">(</TOKEN>
<TOKEN id="token-51-8" pos="word" morph="none" start_char="4809" end_char="4810">no</TOKEN>
<TOKEN id="token-51-9" pos="word" morph="none" start_char="4812" end_char="4817">reason</TOKEN>
<TOKEN id="token-51-10" pos="word" morph="none" start_char="4819" end_char="4823">given</TOKEN>
<TOKEN id="token-51-11" pos="punct" morph="none" start_char="4824" end_char="4824">)</TOKEN>
</SEG>
<SEG id="segment-52" start_char="4829" end_char="5041">
<ORIGINAL_TEXT>originally posted by: PhyllidaDavenport The same month as the out break Wuhan Biosafety Lab was granted level 4 status meaning it had approval for the highest most deadly of virus's including Ebola and bioweapons.</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="4829" end_char="4838">originally</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="4840" end_char="4845">posted</TOKEN>
<TOKEN id="token-52-2" pos="word" morph="none" start_char="4847" end_char="4848">by</TOKEN>
<TOKEN id="token-52-3" pos="punct" morph="none" start_char="4849" end_char="4849">:</TOKEN>
<TOKEN id="token-52-4" pos="word" morph="none" start_char="4851" end_char="4867">PhyllidaDavenport</TOKEN>
<TOKEN id="token-52-5" pos="word" morph="none" start_char="4869" end_char="4871">The</TOKEN>
<TOKEN id="token-52-6" pos="word" morph="none" start_char="4873" end_char="4876">same</TOKEN>
<TOKEN id="token-52-7" pos="word" morph="none" start_char="4878" end_char="4882">month</TOKEN>
<TOKEN id="token-52-8" pos="word" morph="none" start_char="4884" end_char="4885">as</TOKEN>
<TOKEN id="token-52-9" pos="word" morph="none" start_char="4887" end_char="4889">the</TOKEN>
<TOKEN id="token-52-10" pos="word" morph="none" start_char="4891" end_char="4893">out</TOKEN>
<TOKEN id="token-52-11" pos="word" morph="none" start_char="4895" end_char="4899">break</TOKEN>
<TOKEN id="token-52-12" pos="word" morph="none" start_char="4901" end_char="4905">Wuhan</TOKEN>
<TOKEN id="token-52-13" pos="word" morph="none" start_char="4907" end_char="4915">Biosafety</TOKEN>
<TOKEN id="token-52-14" pos="word" morph="none" start_char="4917" end_char="4919">Lab</TOKEN>
<TOKEN id="token-52-15" pos="word" morph="none" start_char="4921" end_char="4923">was</TOKEN>
<TOKEN id="token-52-16" pos="word" morph="none" start_char="4925" end_char="4931">granted</TOKEN>
<TOKEN id="token-52-17" pos="word" morph="none" start_char="4933" end_char="4937">level</TOKEN>
<TOKEN id="token-52-18" pos="word" morph="none" start_char="4939" end_char="4939">4</TOKEN>
<TOKEN id="token-52-19" pos="word" morph="none" start_char="4941" end_char="4946">status</TOKEN>
<TOKEN id="token-52-20" pos="word" morph="none" start_char="4948" end_char="4954">meaning</TOKEN>
<TOKEN id="token-52-21" pos="word" morph="none" start_char="4956" end_char="4957">it</TOKEN>
<TOKEN id="token-52-22" pos="word" morph="none" start_char="4959" end_char="4961">had</TOKEN>
<TOKEN id="token-52-23" pos="word" morph="none" start_char="4963" end_char="4970">approval</TOKEN>
<TOKEN id="token-52-24" pos="word" morph="none" start_char="4972" end_char="4974">for</TOKEN>
<TOKEN id="token-52-25" pos="word" morph="none" start_char="4976" end_char="4978">the</TOKEN>
<TOKEN id="token-52-26" pos="word" morph="none" start_char="4980" end_char="4986">highest</TOKEN>
<TOKEN id="token-52-27" pos="word" morph="none" start_char="4988" end_char="4991">most</TOKEN>
<TOKEN id="token-52-28" pos="word" morph="none" start_char="4993" end_char="4998">deadly</TOKEN>
<TOKEN id="token-52-29" pos="word" morph="none" start_char="5000" end_char="5001">of</TOKEN>
<TOKEN id="token-52-30" pos="word" morph="none" start_char="5003" end_char="5009">virus's</TOKEN>
<TOKEN id="token-52-31" pos="word" morph="none" start_char="5011" end_char="5019">including</TOKEN>
<TOKEN id="token-52-32" pos="word" morph="none" start_char="5021" end_char="5025">Ebola</TOKEN>
<TOKEN id="token-52-33" pos="word" morph="none" start_char="5027" end_char="5029">and</TOKEN>
<TOKEN id="token-52-34" pos="word" morph="none" start_char="5031" end_char="5040">bioweapons</TOKEN>
<TOKEN id="token-52-35" pos="punct" morph="none" start_char="5041" end_char="5041">.</TOKEN>
</SEG>
<SEG id="segment-53" start_char="5043" end_char="5125">
<ORIGINAL_TEXT>Make of that what you will but to me this was either an accident or perhaps a test.</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="word" morph="none" start_char="5043" end_char="5046">Make</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="5048" end_char="5049">of</TOKEN>
<TOKEN id="token-53-2" pos="word" morph="none" start_char="5051" end_char="5054">that</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="5056" end_char="5059">what</TOKEN>
<TOKEN id="token-53-4" pos="word" morph="none" start_char="5061" end_char="5063">you</TOKEN>
<TOKEN id="token-53-5" pos="word" morph="none" start_char="5065" end_char="5068">will</TOKEN>
<TOKEN id="token-53-6" pos="word" morph="none" start_char="5070" end_char="5072">but</TOKEN>
<TOKEN id="token-53-7" pos="word" morph="none" start_char="5074" end_char="5075">to</TOKEN>
<TOKEN id="token-53-8" pos="word" morph="none" start_char="5077" end_char="5078">me</TOKEN>
<TOKEN id="token-53-9" pos="word" morph="none" start_char="5080" end_char="5083">this</TOKEN>
<TOKEN id="token-53-10" pos="word" morph="none" start_char="5085" end_char="5087">was</TOKEN>
<TOKEN id="token-53-11" pos="word" morph="none" start_char="5089" end_char="5094">either</TOKEN>
<TOKEN id="token-53-12" pos="word" morph="none" start_char="5096" end_char="5097">an</TOKEN>
<TOKEN id="token-53-13" pos="word" morph="none" start_char="5099" end_char="5106">accident</TOKEN>
<TOKEN id="token-53-14" pos="word" morph="none" start_char="5108" end_char="5109">or</TOKEN>
<TOKEN id="token-53-15" pos="word" morph="none" start_char="5111" end_char="5117">perhaps</TOKEN>
<TOKEN id="token-53-16" pos="word" morph="none" start_char="5119" end_char="5119">a</TOKEN>
<TOKEN id="token-53-17" pos="word" morph="none" start_char="5121" end_char="5124">test</TOKEN>
<TOKEN id="token-53-18" pos="punct" morph="none" start_char="5125" end_char="5125">.</TOKEN>
</SEG>
<SEG id="segment-54" start_char="5127" end_char="5281">
<ORIGINAL_TEXT>So far the Chinese have blamed bats, pangolins and dogs and as we all know, the information released from Chinese Government sources are far from reliable.</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="word" morph="none" start_char="5127" end_char="5128">So</TOKEN>
<TOKEN id="token-54-1" pos="word" morph="none" start_char="5130" end_char="5132">far</TOKEN>
<TOKEN id="token-54-2" pos="word" morph="none" start_char="5134" end_char="5136">the</TOKEN>
<TOKEN id="token-54-3" pos="word" morph="none" start_char="5138" end_char="5144">Chinese</TOKEN>
<TOKEN id="token-54-4" pos="word" morph="none" start_char="5146" end_char="5149">have</TOKEN>
<TOKEN id="token-54-5" pos="word" morph="none" start_char="5151" end_char="5156">blamed</TOKEN>
<TOKEN id="token-54-6" pos="word" morph="none" start_char="5158" end_char="5161">bats</TOKEN>
<TOKEN id="token-54-7" pos="punct" morph="none" start_char="5162" end_char="5162">,</TOKEN>
<TOKEN id="token-54-8" pos="word" morph="none" start_char="5164" end_char="5172">pangolins</TOKEN>
<TOKEN id="token-54-9" pos="word" morph="none" start_char="5174" end_char="5176">and</TOKEN>
<TOKEN id="token-54-10" pos="word" morph="none" start_char="5178" end_char="5181">dogs</TOKEN>
<TOKEN id="token-54-11" pos="word" morph="none" start_char="5183" end_char="5185">and</TOKEN>
<TOKEN id="token-54-12" pos="word" morph="none" start_char="5187" end_char="5188">as</TOKEN>
<TOKEN id="token-54-13" pos="word" morph="none" start_char="5190" end_char="5191">we</TOKEN>
<TOKEN id="token-54-14" pos="word" morph="none" start_char="5193" end_char="5195">all</TOKEN>
<TOKEN id="token-54-15" pos="word" morph="none" start_char="5197" end_char="5200">know</TOKEN>
<TOKEN id="token-54-16" pos="punct" morph="none" start_char="5201" end_char="5201">,</TOKEN>
<TOKEN id="token-54-17" pos="word" morph="none" start_char="5203" end_char="5205">the</TOKEN>
<TOKEN id="token-54-18" pos="word" morph="none" start_char="5207" end_char="5217">information</TOKEN>
<TOKEN id="token-54-19" pos="word" morph="none" start_char="5219" end_char="5226">released</TOKEN>
<TOKEN id="token-54-20" pos="word" morph="none" start_char="5228" end_char="5231">from</TOKEN>
<TOKEN id="token-54-21" pos="word" morph="none" start_char="5233" end_char="5239">Chinese</TOKEN>
<TOKEN id="token-54-22" pos="word" morph="none" start_char="5241" end_char="5250">Government</TOKEN>
<TOKEN id="token-54-23" pos="word" morph="none" start_char="5252" end_char="5258">sources</TOKEN>
<TOKEN id="token-54-24" pos="word" morph="none" start_char="5260" end_char="5262">are</TOKEN>
<TOKEN id="token-54-25" pos="word" morph="none" start_char="5264" end_char="5266">far</TOKEN>
<TOKEN id="token-54-26" pos="word" morph="none" start_char="5268" end_char="5271">from</TOKEN>
<TOKEN id="token-54-27" pos="word" morph="none" start_char="5273" end_char="5280">reliable</TOKEN>
<TOKEN id="token-54-28" pos="punct" morph="none" start_char="5281" end_char="5281">.</TOKEN>
</SEG>
<SEG id="segment-55" start_char="5283" end_char="5406">
<ORIGINAL_TEXT>Let's also not forget that the SARS virus escaped multiple times from Bejing Laboratories so their track record isn't great!</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="word" morph="none" start_char="5283" end_char="5287">Let's</TOKEN>
<TOKEN id="token-55-1" pos="word" morph="none" start_char="5289" end_char="5292">also</TOKEN>
<TOKEN id="token-55-2" pos="word" morph="none" start_char="5294" end_char="5296">not</TOKEN>
<TOKEN id="token-55-3" pos="word" morph="none" start_char="5298" end_char="5303">forget</TOKEN>
<TOKEN id="token-55-4" pos="word" morph="none" start_char="5305" end_char="5308">that</TOKEN>
<TOKEN id="token-55-5" pos="word" morph="none" start_char="5310" end_char="5312">the</TOKEN>
<TOKEN id="token-55-6" pos="word" morph="none" start_char="5314" end_char="5317">SARS</TOKEN>
<TOKEN id="token-55-7" pos="word" morph="none" start_char="5319" end_char="5323">virus</TOKEN>
<TOKEN id="token-55-8" pos="word" morph="none" start_char="5325" end_char="5331">escaped</TOKEN>
<TOKEN id="token-55-9" pos="word" morph="none" start_char="5333" end_char="5340">multiple</TOKEN>
<TOKEN id="token-55-10" pos="word" morph="none" start_char="5342" end_char="5346">times</TOKEN>
<TOKEN id="token-55-11" pos="word" morph="none" start_char="5348" end_char="5351">from</TOKEN>
<TOKEN id="token-55-12" pos="word" morph="none" start_char="5353" end_char="5358">Bejing</TOKEN>
<TOKEN id="token-55-13" pos="word" morph="none" start_char="5360" end_char="5371">Laboratories</TOKEN>
<TOKEN id="token-55-14" pos="word" morph="none" start_char="5373" end_char="5374">so</TOKEN>
<TOKEN id="token-55-15" pos="word" morph="none" start_char="5376" end_char="5380">their</TOKEN>
<TOKEN id="token-55-16" pos="word" morph="none" start_char="5382" end_char="5386">track</TOKEN>
<TOKEN id="token-55-17" pos="word" morph="none" start_char="5388" end_char="5393">record</TOKEN>
<TOKEN id="token-55-18" pos="word" morph="none" start_char="5395" end_char="5399">isn't</TOKEN>
<TOKEN id="token-55-19" pos="word" morph="none" start_char="5401" end_char="5405">great</TOKEN>
<TOKEN id="token-55-20" pos="punct" morph="none" start_char="5406" end_char="5406">!</TOKEN>
</SEG>
<SEG id="segment-56" start_char="5409" end_char="5524">
<ORIGINAL_TEXT>This virus has an almost perfect tool-set in terms of debilitating and eliminating humans who are weak, ill and old.</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="5409" end_char="5412">This</TOKEN>
<TOKEN id="token-56-1" pos="word" morph="none" start_char="5414" end_char="5418">virus</TOKEN>
<TOKEN id="token-56-2" pos="word" morph="none" start_char="5420" end_char="5422">has</TOKEN>
<TOKEN id="token-56-3" pos="word" morph="none" start_char="5424" end_char="5425">an</TOKEN>
<TOKEN id="token-56-4" pos="word" morph="none" start_char="5427" end_char="5432">almost</TOKEN>
<TOKEN id="token-56-5" pos="word" morph="none" start_char="5434" end_char="5440">perfect</TOKEN>
<TOKEN id="token-56-6" pos="unknown" morph="none" start_char="5442" end_char="5449">tool-set</TOKEN>
<TOKEN id="token-56-7" pos="word" morph="none" start_char="5451" end_char="5452">in</TOKEN>
<TOKEN id="token-56-8" pos="word" morph="none" start_char="5454" end_char="5458">terms</TOKEN>
<TOKEN id="token-56-9" pos="word" morph="none" start_char="5460" end_char="5461">of</TOKEN>
<TOKEN id="token-56-10" pos="word" morph="none" start_char="5463" end_char="5474">debilitating</TOKEN>
<TOKEN id="token-56-11" pos="word" morph="none" start_char="5476" end_char="5478">and</TOKEN>
<TOKEN id="token-56-12" pos="word" morph="none" start_char="5480" end_char="5490">eliminating</TOKEN>
<TOKEN id="token-56-13" pos="word" morph="none" start_char="5492" end_char="5497">humans</TOKEN>
<TOKEN id="token-56-14" pos="word" morph="none" start_char="5499" end_char="5501">who</TOKEN>
<TOKEN id="token-56-15" pos="word" morph="none" start_char="5503" end_char="5505">are</TOKEN>
<TOKEN id="token-56-16" pos="word" morph="none" start_char="5507" end_char="5510">weak</TOKEN>
<TOKEN id="token-56-17" pos="punct" morph="none" start_char="5511" end_char="5511">,</TOKEN>
<TOKEN id="token-56-18" pos="word" morph="none" start_char="5513" end_char="5515">ill</TOKEN>
<TOKEN id="token-56-19" pos="word" morph="none" start_char="5517" end_char="5519">and</TOKEN>
<TOKEN id="token-56-20" pos="word" morph="none" start_char="5521" end_char="5523">old</TOKEN>
<TOKEN id="token-56-21" pos="punct" morph="none" start_char="5524" end_char="5524">.</TOKEN>
</SEG>
<SEG id="segment-57" start_char="5526" end_char="5566">
<ORIGINAL_TEXT>Not all of which is yet fully understood.</ORIGINAL_TEXT>
<TOKEN id="token-57-0" pos="word" morph="none" start_char="5526" end_char="5528">Not</TOKEN>
<TOKEN id="token-57-1" pos="word" morph="none" start_char="5530" end_char="5532">all</TOKEN>
<TOKEN id="token-57-2" pos="word" morph="none" start_char="5534" end_char="5535">of</TOKEN>
<TOKEN id="token-57-3" pos="word" morph="none" start_char="5537" end_char="5541">which</TOKEN>
<TOKEN id="token-57-4" pos="word" morph="none" start_char="5543" end_char="5544">is</TOKEN>
<TOKEN id="token-57-5" pos="word" morph="none" start_char="5546" end_char="5548">yet</TOKEN>
<TOKEN id="token-57-6" pos="word" morph="none" start_char="5550" end_char="5554">fully</TOKEN>
<TOKEN id="token-57-7" pos="word" morph="none" start_char="5556" end_char="5565">understood</TOKEN>
<TOKEN id="token-57-8" pos="punct" morph="none" start_char="5566" end_char="5566">.</TOKEN>
</SEG>
<SEG id="segment-58" start_char="5568" end_char="5667">
<ORIGINAL_TEXT>Its almost perfect as a depop BW which smacks of intelligent design rather than natural coincidence!</ORIGINAL_TEXT>
<TOKEN id="token-58-0" pos="word" morph="none" start_char="5568" end_char="5570">Its</TOKEN>
<TOKEN id="token-58-1" pos="word" morph="none" start_char="5572" end_char="5577">almost</TOKEN>
<TOKEN id="token-58-2" pos="word" morph="none" start_char="5579" end_char="5585">perfect</TOKEN>
<TOKEN id="token-58-3" pos="word" morph="none" start_char="5587" end_char="5588">as</TOKEN>
<TOKEN id="token-58-4" pos="word" morph="none" start_char="5590" end_char="5590">a</TOKEN>
<TOKEN id="token-58-5" pos="word" morph="none" start_char="5592" end_char="5596">depop</TOKEN>
<TOKEN id="token-58-6" pos="word" morph="none" start_char="5598" end_char="5599">BW</TOKEN>
<TOKEN id="token-58-7" pos="word" morph="none" start_char="5601" end_char="5605">which</TOKEN>
<TOKEN id="token-58-8" pos="word" morph="none" start_char="5607" end_char="5612">smacks</TOKEN>
<TOKEN id="token-58-9" pos="word" morph="none" start_char="5614" end_char="5615">of</TOKEN>
<TOKEN id="token-58-10" pos="word" morph="none" start_char="5617" end_char="5627">intelligent</TOKEN>
<TOKEN id="token-58-11" pos="word" morph="none" start_char="5629" end_char="5634">design</TOKEN>
<TOKEN id="token-58-12" pos="word" morph="none" start_char="5636" end_char="5641">rather</TOKEN>
<TOKEN id="token-58-13" pos="word" morph="none" start_char="5643" end_char="5646">than</TOKEN>
<TOKEN id="token-58-14" pos="word" morph="none" start_char="5648" end_char="5654">natural</TOKEN>
<TOKEN id="token-58-15" pos="word" morph="none" start_char="5656" end_char="5666">coincidence</TOKEN>
<TOKEN id="token-58-16" pos="punct" morph="none" start_char="5667" end_char="5667">!</TOKEN>
</SEG>
<SEG id="segment-59" start_char="5669" end_char="5733">
<ORIGINAL_TEXT>The question is, was it an accident or deliberate by the Chinese?</ORIGINAL_TEXT>
<TOKEN id="token-59-0" pos="word" morph="none" start_char="5669" end_char="5671">The</TOKEN>
<TOKEN id="token-59-1" pos="word" morph="none" start_char="5673" end_char="5680">question</TOKEN>
<TOKEN id="token-59-2" pos="word" morph="none" start_char="5682" end_char="5683">is</TOKEN>
<TOKEN id="token-59-3" pos="punct" morph="none" start_char="5684" end_char="5684">,</TOKEN>
<TOKEN id="token-59-4" pos="word" morph="none" start_char="5686" end_char="5688">was</TOKEN>
<TOKEN id="token-59-5" pos="word" morph="none" start_char="5690" end_char="5691">it</TOKEN>
<TOKEN id="token-59-6" pos="word" morph="none" start_char="5693" end_char="5694">an</TOKEN>
<TOKEN id="token-59-7" pos="word" morph="none" start_char="5696" end_char="5703">accident</TOKEN>
<TOKEN id="token-59-8" pos="word" morph="none" start_char="5705" end_char="5706">or</TOKEN>
<TOKEN id="token-59-9" pos="word" morph="none" start_char="5708" end_char="5717">deliberate</TOKEN>
<TOKEN id="token-59-10" pos="word" morph="none" start_char="5719" end_char="5720">by</TOKEN>
<TOKEN id="token-59-11" pos="word" morph="none" start_char="5722" end_char="5724">the</TOKEN>
<TOKEN id="token-59-12" pos="word" morph="none" start_char="5726" end_char="5732">Chinese</TOKEN>
<TOKEN id="token-59-13" pos="punct" morph="none" start_char="5733" end_char="5733">?</TOKEN>
</SEG>
<SEG id="segment-60" start_char="5735" end_char="5765">
<ORIGINAL_TEXT>do they already have a vaccine?</ORIGINAL_TEXT>
<TOKEN id="token-60-0" pos="word" morph="none" start_char="5735" end_char="5736">do</TOKEN>
<TOKEN id="token-60-1" pos="word" morph="none" start_char="5738" end_char="5741">they</TOKEN>
<TOKEN id="token-60-2" pos="word" morph="none" start_char="5743" end_char="5749">already</TOKEN>
<TOKEN id="token-60-3" pos="word" morph="none" start_char="5751" end_char="5754">have</TOKEN>
<TOKEN id="token-60-4" pos="word" morph="none" start_char="5756" end_char="5756">a</TOKEN>
<TOKEN id="token-60-5" pos="word" morph="none" start_char="5758" end_char="5764">vaccine</TOKEN>
<TOKEN id="token-60-6" pos="punct" morph="none" start_char="5765" end_char="5765">?</TOKEN>
</SEG>
<SEG id="segment-61" start_char="5767" end_char="5840">
<ORIGINAL_TEXT>Or was it done deliberately by another and do they already have a vaccine.</ORIGINAL_TEXT>
<TOKEN id="token-61-0" pos="word" morph="none" start_char="5767" end_char="5768">Or</TOKEN>
<TOKEN id="token-61-1" pos="word" morph="none" start_char="5770" end_char="5772">was</TOKEN>
<TOKEN id="token-61-2" pos="word" morph="none" start_char="5774" end_char="5775">it</TOKEN>
<TOKEN id="token-61-3" pos="word" morph="none" start_char="5777" end_char="5780">done</TOKEN>
<TOKEN id="token-61-4" pos="word" morph="none" start_char="5782" end_char="5793">deliberately</TOKEN>
<TOKEN id="token-61-5" pos="word" morph="none" start_char="5795" end_char="5796">by</TOKEN>
<TOKEN id="token-61-6" pos="word" morph="none" start_char="5798" end_char="5804">another</TOKEN>
<TOKEN id="token-61-7" pos="word" morph="none" start_char="5806" end_char="5808">and</TOKEN>
<TOKEN id="token-61-8" pos="word" morph="none" start_char="5810" end_char="5811">do</TOKEN>
<TOKEN id="token-61-9" pos="word" morph="none" start_char="5813" end_char="5816">they</TOKEN>
<TOKEN id="token-61-10" pos="word" morph="none" start_char="5818" end_char="5824">already</TOKEN>
<TOKEN id="token-61-11" pos="word" morph="none" start_char="5826" end_char="5829">have</TOKEN>
<TOKEN id="token-61-12" pos="word" morph="none" start_char="5831" end_char="5831">a</TOKEN>
<TOKEN id="token-61-13" pos="word" morph="none" start_char="5833" end_char="5839">vaccine</TOKEN>
<TOKEN id="token-61-14" pos="punct" morph="none" start_char="5840" end_char="5840">.</TOKEN>
</SEG>
<SEG id="segment-62" start_char="5843" end_char="5890">
<ORIGINAL_TEXT>This TOOL of a virus is worse than people think!</ORIGINAL_TEXT>
<TOKEN id="token-62-0" pos="word" morph="none" start_char="5843" end_char="5846">This</TOKEN>
<TOKEN id="token-62-1" pos="word" morph="none" start_char="5848" end_char="5851">TOOL</TOKEN>
<TOKEN id="token-62-2" pos="word" morph="none" start_char="5853" end_char="5854">of</TOKEN>
<TOKEN id="token-62-3" pos="word" morph="none" start_char="5856" end_char="5856">a</TOKEN>
<TOKEN id="token-62-4" pos="word" morph="none" start_char="5858" end_char="5862">virus</TOKEN>
<TOKEN id="token-62-5" pos="word" morph="none" start_char="5864" end_char="5865">is</TOKEN>
<TOKEN id="token-62-6" pos="word" morph="none" start_char="5867" end_char="5871">worse</TOKEN>
<TOKEN id="token-62-7" pos="word" morph="none" start_char="5873" end_char="5876">than</TOKEN>
<TOKEN id="token-62-8" pos="word" morph="none" start_char="5878" end_char="5883">people</TOKEN>
<TOKEN id="token-62-9" pos="word" morph="none" start_char="5885" end_char="5889">think</TOKEN>
<TOKEN id="token-62-10" pos="punct" morph="none" start_char="5890" end_char="5890">!</TOKEN>
</SEG>
<SEG id="segment-63" start_char="5892" end_char="5909">
<ORIGINAL_TEXT>Natural - hogwash!</ORIGINAL_TEXT>
<TOKEN id="token-63-0" pos="word" morph="none" start_char="5892" end_char="5898">Natural</TOKEN>
<TOKEN id="token-63-1" pos="punct" morph="none" start_char="5900" end_char="5900">-</TOKEN>
<TOKEN id="token-63-2" pos="word" morph="none" start_char="5902" end_char="5908">hogwash</TOKEN>
<TOKEN id="token-63-3" pos="punct" morph="none" start_char="5909" end_char="5909">!</TOKEN>
</SEG>
<SEG id="segment-64" start_char="5915" end_char="5982">
<ORIGINAL_TEXT>originally posted by: Miccey This strain was planted by you know who</ORIGINAL_TEXT>
<TOKEN id="token-64-0" pos="word" morph="none" start_char="5915" end_char="5924">originally</TOKEN>
<TOKEN id="token-64-1" pos="word" morph="none" start_char="5926" end_char="5931">posted</TOKEN>
<TOKEN id="token-64-2" pos="word" morph="none" start_char="5933" end_char="5934">by</TOKEN>
<TOKEN id="token-64-3" pos="punct" morph="none" start_char="5935" end_char="5935">:</TOKEN>
<TOKEN id="token-64-4" pos="word" morph="none" start_char="5937" end_char="5942">Miccey</TOKEN>
<TOKEN id="token-64-5" pos="word" morph="none" start_char="5944" end_char="5947">This</TOKEN>
<TOKEN id="token-64-6" pos="word" morph="none" start_char="5949" end_char="5954">strain</TOKEN>
<TOKEN id="token-64-7" pos="word" morph="none" start_char="5956" end_char="5958">was</TOKEN>
<TOKEN id="token-64-8" pos="word" morph="none" start_char="5960" end_char="5966">planted</TOKEN>
<TOKEN id="token-64-9" pos="word" morph="none" start_char="5968" end_char="5969">by</TOKEN>
<TOKEN id="token-64-10" pos="word" morph="none" start_char="5971" end_char="5973">you</TOKEN>
<TOKEN id="token-64-11" pos="word" morph="none" start_char="5975" end_char="5978">know</TOKEN>
<TOKEN id="token-64-12" pos="word" morph="none" start_char="5980" end_char="5982">who</TOKEN>
</SEG>
<SEG id="segment-65" start_char="5985" end_char="6000">
<ORIGINAL_TEXT>Hilery Clinton !</ORIGINAL_TEXT>
<TOKEN id="token-65-0" pos="word" morph="none" start_char="5985" end_char="5990">Hilery</TOKEN>
<TOKEN id="token-65-1" pos="word" morph="none" start_char="5992" end_char="5998">Clinton</TOKEN>
<TOKEN id="token-65-2" pos="punct" morph="none" start_char="6000" end_char="6000">!</TOKEN>
</SEG>
<SEG id="segment-66" start_char="6002" end_char="6037">
<ORIGINAL_TEXT>she just can not stop killing peope.</ORIGINAL_TEXT>
<TOKEN id="token-66-0" pos="word" morph="none" start_char="6002" end_char="6004">she</TOKEN>
<TOKEN id="token-66-1" pos="word" morph="none" start_char="6006" end_char="6009">just</TOKEN>
<TOKEN id="token-66-2" pos="word" morph="none" start_char="6011" end_char="6013">can</TOKEN>
<TOKEN id="token-66-3" pos="word" morph="none" start_char="6015" end_char="6017">not</TOKEN>
<TOKEN id="token-66-4" pos="word" morph="none" start_char="6019" end_char="6022">stop</TOKEN>
<TOKEN id="token-66-5" pos="word" morph="none" start_char="6024" end_char="6030">killing</TOKEN>
<TOKEN id="token-66-6" pos="word" morph="none" start_char="6032" end_char="6036">peope</TOKEN>
<TOKEN id="token-66-7" pos="punct" morph="none" start_char="6037" end_char="6037">.</TOKEN>
</SEG>
<SEG id="segment-67" start_char="6042" end_char="6069">
<ORIGINAL_TEXT>a reply to: ElectricUniverse</ORIGINAL_TEXT>
<TOKEN id="token-67-0" pos="word" morph="none" start_char="6042" end_char="6042">a</TOKEN>
<TOKEN id="token-67-1" pos="word" morph="none" start_char="6044" end_char="6048">reply</TOKEN>
<TOKEN id="token-67-2" pos="word" morph="none" start_char="6050" end_char="6051">to</TOKEN>
<TOKEN id="token-67-3" pos="punct" morph="none" start_char="6052" end_char="6052">:</TOKEN>
<TOKEN id="token-67-4" pos="word" morph="none" start_char="6054" end_char="6069">ElectricUniverse</TOKEN>
</SEG>
<SEG id="segment-68" start_char="6072" end_char="6152">
<ORIGINAL_TEXT>Notice the words "could have" and "possibility" reported in the original article.</ORIGINAL_TEXT>
<TOKEN id="token-68-0" pos="word" morph="none" start_char="6072" end_char="6077">Notice</TOKEN>
<TOKEN id="token-68-1" pos="word" morph="none" start_char="6079" end_char="6081">the</TOKEN>
<TOKEN id="token-68-2" pos="word" morph="none" start_char="6083" end_char="6087">words</TOKEN>
<TOKEN id="token-68-3" pos="punct" morph="none" start_char="6089" end_char="6089">"</TOKEN>
<TOKEN id="token-68-4" pos="word" morph="none" start_char="6090" end_char="6094">could</TOKEN>
<TOKEN id="token-68-5" pos="word" morph="none" start_char="6096" end_char="6099">have</TOKEN>
<TOKEN id="token-68-6" pos="punct" morph="none" start_char="6100" end_char="6100">"</TOKEN>
<TOKEN id="token-68-7" pos="word" morph="none" start_char="6102" end_char="6104">and</TOKEN>
<TOKEN id="token-68-8" pos="punct" morph="none" start_char="6106" end_char="6106">"</TOKEN>
<TOKEN id="token-68-9" pos="word" morph="none" start_char="6107" end_char="6117">possibility</TOKEN>
<TOKEN id="token-68-10" pos="punct" morph="none" start_char="6118" end_char="6118">"</TOKEN>
<TOKEN id="token-68-11" pos="word" morph="none" start_char="6120" end_char="6127">reported</TOKEN>
<TOKEN id="token-68-12" pos="word" morph="none" start_char="6129" end_char="6130">in</TOKEN>
<TOKEN id="token-68-13" pos="word" morph="none" start_char="6132" end_char="6134">the</TOKEN>
<TOKEN id="token-68-14" pos="word" morph="none" start_char="6136" end_char="6143">original</TOKEN>
<TOKEN id="token-68-15" pos="word" morph="none" start_char="6145" end_char="6151">article</TOKEN>
<TOKEN id="token-68-16" pos="punct" morph="none" start_char="6152" end_char="6152">.</TOKEN>
</SEG>
<SEG id="segment-69" start_char="6154" end_char="6194">
<ORIGINAL_TEXT>Nowhere does it say they "believe it did"</ORIGINAL_TEXT>
<TOKEN id="token-69-0" pos="word" morph="none" start_char="6154" end_char="6160">Nowhere</TOKEN>
<TOKEN id="token-69-1" pos="word" morph="none" start_char="6162" end_char="6165">does</TOKEN>
<TOKEN id="token-69-2" pos="word" morph="none" start_char="6167" end_char="6168">it</TOKEN>
<TOKEN id="token-69-3" pos="word" morph="none" start_char="6170" end_char="6172">say</TOKEN>
<TOKEN id="token-69-4" pos="word" morph="none" start_char="6174" end_char="6177">they</TOKEN>
<TOKEN id="token-69-5" pos="punct" morph="none" start_char="6179" end_char="6179">"</TOKEN>
<TOKEN id="token-69-6" pos="word" morph="none" start_char="6180" end_char="6186">believe</TOKEN>
<TOKEN id="token-69-7" pos="word" morph="none" start_char="6188" end_char="6189">it</TOKEN>
<TOKEN id="token-69-8" pos="word" morph="none" start_char="6191" end_char="6193">did</TOKEN>
<TOKEN id="token-69-9" pos="punct" morph="none" start_char="6194" end_char="6194">"</TOKEN>
</SEG>
<SEG id="segment-70" start_char="6197" end_char="6289">
<ORIGINAL_TEXT>And it is from the "Daily Mail" , which apparently is taking up the "Enquirer" brand of news.</ORIGINAL_TEXT>
<TOKEN id="token-70-0" pos="word" morph="none" start_char="6197" end_char="6199">And</TOKEN>
<TOKEN id="token-70-1" pos="word" morph="none" start_char="6201" end_char="6202">it</TOKEN>
<TOKEN id="token-70-2" pos="word" morph="none" start_char="6204" end_char="6205">is</TOKEN>
<TOKEN id="token-70-3" pos="word" morph="none" start_char="6207" end_char="6210">from</TOKEN>
<TOKEN id="token-70-4" pos="word" morph="none" start_char="6212" end_char="6214">the</TOKEN>
<TOKEN id="token-70-5" pos="punct" morph="none" start_char="6216" end_char="6216">"</TOKEN>
<TOKEN id="token-70-6" pos="word" morph="none" start_char="6217" end_char="6221">Daily</TOKEN>
<TOKEN id="token-70-7" pos="word" morph="none" start_char="6223" end_char="6226">Mail</TOKEN>
<TOKEN id="token-70-8" pos="punct" morph="none" start_char="6227" end_char="6227">"</TOKEN>
<TOKEN id="token-70-9" pos="punct" morph="none" start_char="6229" end_char="6229">,</TOKEN>
<TOKEN id="token-70-10" pos="word" morph="none" start_char="6231" end_char="6235">which</TOKEN>
<TOKEN id="token-70-11" pos="word" morph="none" start_char="6237" end_char="6246">apparently</TOKEN>
<TOKEN id="token-70-12" pos="word" morph="none" start_char="6248" end_char="6249">is</TOKEN>
<TOKEN id="token-70-13" pos="word" morph="none" start_char="6251" end_char="6256">taking</TOKEN>
<TOKEN id="token-70-14" pos="word" morph="none" start_char="6258" end_char="6259">up</TOKEN>
<TOKEN id="token-70-15" pos="word" morph="none" start_char="6261" end_char="6263">the</TOKEN>
<TOKEN id="token-70-16" pos="punct" morph="none" start_char="6265" end_char="6265">"</TOKEN>
<TOKEN id="token-70-17" pos="word" morph="none" start_char="6266" end_char="6273">Enquirer</TOKEN>
<TOKEN id="token-70-18" pos="punct" morph="none" start_char="6274" end_char="6274">"</TOKEN>
<TOKEN id="token-70-19" pos="word" morph="none" start_char="6276" end_char="6280">brand</TOKEN>
<TOKEN id="token-70-20" pos="word" morph="none" start_char="6282" end_char="6283">of</TOKEN>
<TOKEN id="token-70-21" pos="word" morph="none" start_char="6285" end_char="6288">news</TOKEN>
<TOKEN id="token-70-22" pos="punct" morph="none" start_char="6289" end_char="6289">.</TOKEN>
</SEG>
<SEG id="segment-71" start_char="6292" end_char="6344">
<ORIGINAL_TEXT>edit on 3/13/20 by Gothmog because: (no reason given)</ORIGINAL_TEXT>
<TOKEN id="token-71-0" pos="word" morph="none" start_char="6292" end_char="6295">edit</TOKEN>
<TOKEN id="token-71-1" pos="word" morph="none" start_char="6297" end_char="6298">on</TOKEN>
<TOKEN id="token-71-2" pos="unknown" morph="none" start_char="6300" end_char="6306">3/13/20</TOKEN>
<TOKEN id="token-71-3" pos="word" morph="none" start_char="6308" end_char="6309">by</TOKEN>
<TOKEN id="token-71-4" pos="word" morph="none" start_char="6311" end_char="6317">Gothmog</TOKEN>
<TOKEN id="token-71-5" pos="word" morph="none" start_char="6319" end_char="6325">because</TOKEN>
<TOKEN id="token-71-6" pos="punct" morph="none" start_char="6326" end_char="6326">:</TOKEN>
<TOKEN id="token-71-7" pos="punct" morph="none" start_char="6328" end_char="6328">(</TOKEN>
<TOKEN id="token-71-8" pos="word" morph="none" start_char="6329" end_char="6330">no</TOKEN>
<TOKEN id="token-71-9" pos="word" morph="none" start_char="6332" end_char="6337">reason</TOKEN>
<TOKEN id="token-71-10" pos="word" morph="none" start_char="6339" end_char="6343">given</TOKEN>
<TOKEN id="token-71-11" pos="punct" morph="none" start_char="6344" end_char="6344">)</TOKEN>
</SEG>
<SEG id="segment-72" start_char="6348" end_char="6420">
<ORIGINAL_TEXT>well i forgot that some people consider super market tabloids hot sheets.</ORIGINAL_TEXT>
<TOKEN id="token-72-0" pos="word" morph="none" start_char="6348" end_char="6351">well</TOKEN>
<TOKEN id="token-72-1" pos="word" morph="none" start_char="6353" end_char="6353">i</TOKEN>
<TOKEN id="token-72-2" pos="word" morph="none" start_char="6355" end_char="6360">forgot</TOKEN>
<TOKEN id="token-72-3" pos="word" morph="none" start_char="6362" end_char="6365">that</TOKEN>
<TOKEN id="token-72-4" pos="word" morph="none" start_char="6367" end_char="6370">some</TOKEN>
<TOKEN id="token-72-5" pos="word" morph="none" start_char="6372" end_char="6377">people</TOKEN>
<TOKEN id="token-72-6" pos="word" morph="none" start_char="6379" end_char="6386">consider</TOKEN>
<TOKEN id="token-72-7" pos="word" morph="none" start_char="6388" end_char="6392">super</TOKEN>
<TOKEN id="token-72-8" pos="word" morph="none" start_char="6394" end_char="6399">market</TOKEN>
<TOKEN id="token-72-9" pos="word" morph="none" start_char="6401" end_char="6408">tabloids</TOKEN>
<TOKEN id="token-72-10" pos="word" morph="none" start_char="6410" end_char="6412">hot</TOKEN>
<TOKEN id="token-72-11" pos="word" morph="none" start_char="6414" end_char="6419">sheets</TOKEN>
<TOKEN id="token-72-12" pos="punct" morph="none" start_char="6420" end_char="6420">.</TOKEN>
</SEG>
<SEG id="segment-73" start_char="6424" end_char="6451">
<ORIGINAL_TEXT>a reply to: ElectricUniverse</ORIGINAL_TEXT>
<TOKEN id="token-73-0" pos="word" morph="none" start_char="6424" end_char="6424">a</TOKEN>
<TOKEN id="token-73-1" pos="word" morph="none" start_char="6426" end_char="6430">reply</TOKEN>
<TOKEN id="token-73-2" pos="word" morph="none" start_char="6432" end_char="6433">to</TOKEN>
<TOKEN id="token-73-3" pos="punct" morph="none" start_char="6434" end_char="6434">:</TOKEN>
<TOKEN id="token-73-4" pos="word" morph="none" start_char="6436" end_char="6451">ElectricUniverse</TOKEN>
</SEG>
<SEG id="segment-74" start_char="6454" end_char="6470">
<ORIGINAL_TEXT>Of course it did.</ORIGINAL_TEXT>
<TOKEN id="token-74-0" pos="word" morph="none" start_char="6454" end_char="6455">Of</TOKEN>
<TOKEN id="token-74-1" pos="word" morph="none" start_char="6457" end_char="6462">course</TOKEN>
<TOKEN id="token-74-2" pos="word" morph="none" start_char="6464" end_char="6465">it</TOKEN>
<TOKEN id="token-74-3" pos="word" morph="none" start_char="6467" end_char="6469">did</TOKEN>
<TOKEN id="token-74-4" pos="punct" morph="none" start_char="6470" end_char="6470">.</TOKEN>
</SEG>
<SEG id="segment-75" start_char="6472" end_char="6543">
<ORIGINAL_TEXT>It started near a bioweapon facility and several bioresearch facilities.</ORIGINAL_TEXT>
<TOKEN id="token-75-0" pos="word" morph="none" start_char="6472" end_char="6473">It</TOKEN>
<TOKEN id="token-75-1" pos="word" morph="none" start_char="6475" end_char="6481">started</TOKEN>
<TOKEN id="token-75-2" pos="word" morph="none" start_char="6483" end_char="6486">near</TOKEN>
<TOKEN id="token-75-3" pos="word" morph="none" start_char="6488" end_char="6488">a</TOKEN>
<TOKEN id="token-75-4" pos="word" morph="none" start_char="6490" end_char="6498">bioweapon</TOKEN>
<TOKEN id="token-75-5" pos="word" morph="none" start_char="6500" end_char="6507">facility</TOKEN>
<TOKEN id="token-75-6" pos="word" morph="none" start_char="6509" end_char="6511">and</TOKEN>
<TOKEN id="token-75-7" pos="word" morph="none" start_char="6513" end_char="6519">several</TOKEN>
<TOKEN id="token-75-8" pos="word" morph="none" start_char="6521" end_char="6531">bioresearch</TOKEN>
<TOKEN id="token-75-9" pos="word" morph="none" start_char="6533" end_char="6542">facilities</TOKEN>
<TOKEN id="token-75-10" pos="punct" morph="none" start_char="6543" end_char="6543">.</TOKEN>
</SEG>
<SEG id="segment-76" start_char="6545" end_char="6578">
<ORIGINAL_TEXT>Too much a coincidence to dismiss.</ORIGINAL_TEXT>
<TOKEN id="token-76-0" pos="word" morph="none" start_char="6545" end_char="6547">Too</TOKEN>
<TOKEN id="token-76-1" pos="word" morph="none" start_char="6549" end_char="6552">much</TOKEN>
<TOKEN id="token-76-2" pos="word" morph="none" start_char="6554" end_char="6554">a</TOKEN>
<TOKEN id="token-76-3" pos="word" morph="none" start_char="6556" end_char="6566">coincidence</TOKEN>
<TOKEN id="token-76-4" pos="word" morph="none" start_char="6568" end_char="6569">to</TOKEN>
<TOKEN id="token-76-5" pos="word" morph="none" start_char="6571" end_char="6577">dismiss</TOKEN>
<TOKEN id="token-76-6" pos="punct" morph="none" start_char="6578" end_char="6578">.</TOKEN>
</SEG>
<SEG id="segment-77" start_char="6580" end_char="6656">
<ORIGINAL_TEXT>Especially since the virus is truly beneficial to Chinese society as a whole.</ORIGINAL_TEXT>
<TOKEN id="token-77-0" pos="word" morph="none" start_char="6580" end_char="6589">Especially</TOKEN>
<TOKEN id="token-77-1" pos="word" morph="none" start_char="6591" end_char="6595">since</TOKEN>
<TOKEN id="token-77-2" pos="word" morph="none" start_char="6597" end_char="6599">the</TOKEN>
<TOKEN id="token-77-3" pos="word" morph="none" start_char="6601" end_char="6605">virus</TOKEN>
<TOKEN id="token-77-4" pos="word" morph="none" start_char="6607" end_char="6608">is</TOKEN>
<TOKEN id="token-77-5" pos="word" morph="none" start_char="6610" end_char="6614">truly</TOKEN>
<TOKEN id="token-77-6" pos="word" morph="none" start_char="6616" end_char="6625">beneficial</TOKEN>
<TOKEN id="token-77-7" pos="word" morph="none" start_char="6627" end_char="6628">to</TOKEN>
<TOKEN id="token-77-8" pos="word" morph="none" start_char="6630" end_char="6636">Chinese</TOKEN>
<TOKEN id="token-77-9" pos="word" morph="none" start_char="6638" end_char="6644">society</TOKEN>
<TOKEN id="token-77-10" pos="word" morph="none" start_char="6646" end_char="6647">as</TOKEN>
<TOKEN id="token-77-11" pos="word" morph="none" start_char="6649" end_char="6649">a</TOKEN>
<TOKEN id="token-77-12" pos="word" morph="none" start_char="6651" end_char="6655">whole</TOKEN>
<TOKEN id="token-77-13" pos="punct" morph="none" start_char="6656" end_char="6656">.</TOKEN>
</SEG>
<SEG id="segment-78" start_char="6659" end_char="6713">
<ORIGINAL_TEXT>China is a communist country, individuals mean nothing.</ORIGINAL_TEXT>
<TOKEN id="token-78-0" pos="word" morph="none" start_char="6659" end_char="6663">China</TOKEN>
<TOKEN id="token-78-1" pos="word" morph="none" start_char="6665" end_char="6666">is</TOKEN>
<TOKEN id="token-78-2" pos="word" morph="none" start_char="6668" end_char="6668">a</TOKEN>
<TOKEN id="token-78-3" pos="word" morph="none" start_char="6670" end_char="6678">communist</TOKEN>
<TOKEN id="token-78-4" pos="word" morph="none" start_char="6680" end_char="6686">country</TOKEN>
<TOKEN id="token-78-5" pos="punct" morph="none" start_char="6687" end_char="6687">,</TOKEN>
<TOKEN id="token-78-6" pos="word" morph="none" start_char="6689" end_char="6699">individuals</TOKEN>
<TOKEN id="token-78-7" pos="word" morph="none" start_char="6701" end_char="6704">mean</TOKEN>
<TOKEN id="token-78-8" pos="word" morph="none" start_char="6706" end_char="6712">nothing</TOKEN>
<TOKEN id="token-78-9" pos="punct" morph="none" start_char="6713" end_char="6713">.</TOKEN>
</SEG>
<SEG id="segment-79" start_char="6715" end_char="6779">
<ORIGINAL_TEXT>Everything is done for the good of the whole, society as a whole.</ORIGINAL_TEXT>
<TOKEN id="token-79-0" pos="word" morph="none" start_char="6715" end_char="6724">Everything</TOKEN>
<TOKEN id="token-79-1" pos="word" morph="none" start_char="6726" end_char="6727">is</TOKEN>
<TOKEN id="token-79-2" pos="word" morph="none" start_char="6729" end_char="6732">done</TOKEN>
<TOKEN id="token-79-3" pos="word" morph="none" start_char="6734" end_char="6736">for</TOKEN>
<TOKEN id="token-79-4" pos="word" morph="none" start_char="6738" end_char="6740">the</TOKEN>
<TOKEN id="token-79-5" pos="word" morph="none" start_char="6742" end_char="6745">good</TOKEN>
<TOKEN id="token-79-6" pos="word" morph="none" start_char="6747" end_char="6748">of</TOKEN>
<TOKEN id="token-79-7" pos="word" morph="none" start_char="6750" end_char="6752">the</TOKEN>
<TOKEN id="token-79-8" pos="word" morph="none" start_char="6754" end_char="6758">whole</TOKEN>
<TOKEN id="token-79-9" pos="punct" morph="none" start_char="6759" end_char="6759">,</TOKEN>
<TOKEN id="token-79-10" pos="word" morph="none" start_char="6761" end_char="6767">society</TOKEN>
<TOKEN id="token-79-11" pos="word" morph="none" start_char="6769" end_char="6770">as</TOKEN>
<TOKEN id="token-79-12" pos="word" morph="none" start_char="6772" end_char="6772">a</TOKEN>
<TOKEN id="token-79-13" pos="word" morph="none" start_char="6774" end_char="6778">whole</TOKEN>
<TOKEN id="token-79-14" pos="punct" morph="none" start_char="6779" end_char="6779">.</TOKEN>
</SEG>
<SEG id="segment-80" start_char="6782" end_char="6832">
<ORIGINAL_TEXT>They have a enormous problem with too many elderly.</ORIGINAL_TEXT>
<TOKEN id="token-80-0" pos="word" morph="none" start_char="6782" end_char="6785">They</TOKEN>
<TOKEN id="token-80-1" pos="word" morph="none" start_char="6787" end_char="6790">have</TOKEN>
<TOKEN id="token-80-2" pos="word" morph="none" start_char="6792" end_char="6792">a</TOKEN>
<TOKEN id="token-80-3" pos="word" morph="none" start_char="6794" end_char="6801">enormous</TOKEN>
<TOKEN id="token-80-4" pos="word" morph="none" start_char="6803" end_char="6809">problem</TOKEN>
<TOKEN id="token-80-5" pos="word" morph="none" start_char="6811" end_char="6814">with</TOKEN>
<TOKEN id="token-80-6" pos="word" morph="none" start_char="6816" end_char="6818">too</TOKEN>
<TOKEN id="token-80-7" pos="word" morph="none" start_char="6820" end_char="6823">many</TOKEN>
<TOKEN id="token-80-8" pos="word" morph="none" start_char="6825" end_char="6831">elderly</TOKEN>
<TOKEN id="token-80-9" pos="punct" morph="none" start_char="6832" end_char="6832">.</TOKEN>
</SEG>
<SEG id="segment-81" start_char="6834" end_char="6868">
<ORIGINAL_TEXT>This is due their one child policy.</ORIGINAL_TEXT>
<TOKEN id="token-81-0" pos="word" morph="none" start_char="6834" end_char="6837">This</TOKEN>
<TOKEN id="token-81-1" pos="word" morph="none" start_char="6839" end_char="6840">is</TOKEN>
<TOKEN id="token-81-2" pos="word" morph="none" start_char="6842" end_char="6844">due</TOKEN>
<TOKEN id="token-81-3" pos="word" morph="none" start_char="6846" end_char="6850">their</TOKEN>
<TOKEN id="token-81-4" pos="word" morph="none" start_char="6852" end_char="6854">one</TOKEN>
<TOKEN id="token-81-5" pos="word" morph="none" start_char="6856" end_char="6860">child</TOKEN>
<TOKEN id="token-81-6" pos="word" morph="none" start_char="6862" end_char="6867">policy</TOKEN>
<TOKEN id="token-81-7" pos="punct" morph="none" start_char="6868" end_char="6868">.</TOKEN>
</SEG>
<SEG id="segment-82" start_char="6870" end_char="7025">
<ORIGINAL_TEXT>Right now on average a couple is supporting themselves, their child/ren, and FOUR other adults, this is their culture- no to few facilities for the elderly.</ORIGINAL_TEXT>
<TOKEN id="token-82-0" pos="word" morph="none" start_char="6870" end_char="6874">Right</TOKEN>
<TOKEN id="token-82-1" pos="word" morph="none" start_char="6876" end_char="6878">now</TOKEN>
<TOKEN id="token-82-2" pos="word" morph="none" start_char="6880" end_char="6881">on</TOKEN>
<TOKEN id="token-82-3" pos="word" morph="none" start_char="6883" end_char="6889">average</TOKEN>
<TOKEN id="token-82-4" pos="word" morph="none" start_char="6891" end_char="6891">a</TOKEN>
<TOKEN id="token-82-5" pos="word" morph="none" start_char="6893" end_char="6898">couple</TOKEN>
<TOKEN id="token-82-6" pos="word" morph="none" start_char="6900" end_char="6901">is</TOKEN>
<TOKEN id="token-82-7" pos="word" morph="none" start_char="6903" end_char="6912">supporting</TOKEN>
<TOKEN id="token-82-8" pos="word" morph="none" start_char="6914" end_char="6923">themselves</TOKEN>
<TOKEN id="token-82-9" pos="punct" morph="none" start_char="6924" end_char="6924">,</TOKEN>
<TOKEN id="token-82-10" pos="word" morph="none" start_char="6926" end_char="6930">their</TOKEN>
<TOKEN id="token-82-11" pos="unknown" morph="none" start_char="6932" end_char="6940">child/ren</TOKEN>
<TOKEN id="token-82-12" pos="punct" morph="none" start_char="6941" end_char="6941">,</TOKEN>
<TOKEN id="token-82-13" pos="word" morph="none" start_char="6943" end_char="6945">and</TOKEN>
<TOKEN id="token-82-14" pos="word" morph="none" start_char="6947" end_char="6950">FOUR</TOKEN>
<TOKEN id="token-82-15" pos="word" morph="none" start_char="6952" end_char="6956">other</TOKEN>
<TOKEN id="token-82-16" pos="word" morph="none" start_char="6958" end_char="6963">adults</TOKEN>
<TOKEN id="token-82-17" pos="punct" morph="none" start_char="6964" end_char="6964">,</TOKEN>
<TOKEN id="token-82-18" pos="word" morph="none" start_char="6966" end_char="6969">this</TOKEN>
<TOKEN id="token-82-19" pos="word" morph="none" start_char="6971" end_char="6972">is</TOKEN>
<TOKEN id="token-82-20" pos="word" morph="none" start_char="6974" end_char="6978">their</TOKEN>
<TOKEN id="token-82-21" pos="word" morph="none" start_char="6980" end_char="6986">culture</TOKEN>
<TOKEN id="token-82-22" pos="punct" morph="none" start_char="6987" end_char="6987">-</TOKEN>
<TOKEN id="token-82-23" pos="word" morph="none" start_char="6989" end_char="6990">no</TOKEN>
<TOKEN id="token-82-24" pos="word" morph="none" start_char="6992" end_char="6993">to</TOKEN>
<TOKEN id="token-82-25" pos="word" morph="none" start_char="6995" end_char="6997">few</TOKEN>
<TOKEN id="token-82-26" pos="word" morph="none" start_char="6999" end_char="7008">facilities</TOKEN>
<TOKEN id="token-82-27" pos="word" morph="none" start_char="7010" end_char="7012">for</TOKEN>
<TOKEN id="token-82-28" pos="word" morph="none" start_char="7014" end_char="7016">the</TOKEN>
<TOKEN id="token-82-29" pos="word" morph="none" start_char="7018" end_char="7024">elderly</TOKEN>
<TOKEN id="token-82-30" pos="punct" morph="none" start_char="7025" end_char="7025">.</TOKEN>
</SEG>
<SEG id="segment-83" start_char="7028" end_char="7109">
<ORIGINAL_TEXT>This virus is specifically designed to kill the elderly and not harm young people.</ORIGINAL_TEXT>
<TOKEN id="token-83-0" pos="word" morph="none" start_char="7028" end_char="7031">This</TOKEN>
<TOKEN id="token-83-1" pos="word" morph="none" start_char="7033" end_char="7037">virus</TOKEN>
<TOKEN id="token-83-2" pos="word" morph="none" start_char="7039" end_char="7040">is</TOKEN>
<TOKEN id="token-83-3" pos="word" morph="none" start_char="7042" end_char="7053">specifically</TOKEN>
<TOKEN id="token-83-4" pos="word" morph="none" start_char="7055" end_char="7062">designed</TOKEN>
<TOKEN id="token-83-5" pos="word" morph="none" start_char="7064" end_char="7065">to</TOKEN>
<TOKEN id="token-83-6" pos="word" morph="none" start_char="7067" end_char="7070">kill</TOKEN>
<TOKEN id="token-83-7" pos="word" morph="none" start_char="7072" end_char="7074">the</TOKEN>
<TOKEN id="token-83-8" pos="word" morph="none" start_char="7076" end_char="7082">elderly</TOKEN>
<TOKEN id="token-83-9" pos="word" morph="none" start_char="7084" end_char="7086">and</TOKEN>
<TOKEN id="token-83-10" pos="word" morph="none" start_char="7088" end_char="7090">not</TOKEN>
<TOKEN id="token-83-11" pos="word" morph="none" start_char="7092" end_char="7095">harm</TOKEN>
<TOKEN id="token-83-12" pos="word" morph="none" start_char="7097" end_char="7101">young</TOKEN>
<TOKEN id="token-83-13" pos="word" morph="none" start_char="7103" end_char="7108">people</TOKEN>
<TOKEN id="token-83-14" pos="punct" morph="none" start_char="7109" end_char="7109">.</TOKEN>
</SEG>
<SEG id="segment-84" start_char="7111" end_char="7181">
<ORIGINAL_TEXT>An excellent way to genocide the elderly without looking like they did.</ORIGINAL_TEXT>
<TOKEN id="token-84-0" pos="word" morph="none" start_char="7111" end_char="7112">An</TOKEN>
<TOKEN id="token-84-1" pos="word" morph="none" start_char="7114" end_char="7122">excellent</TOKEN>
<TOKEN id="token-84-2" pos="word" morph="none" start_char="7124" end_char="7126">way</TOKEN>
<TOKEN id="token-84-3" pos="word" morph="none" start_char="7128" end_char="7129">to</TOKEN>
<TOKEN id="token-84-4" pos="word" morph="none" start_char="7131" end_char="7138">genocide</TOKEN>
<TOKEN id="token-84-5" pos="word" morph="none" start_char="7140" end_char="7142">the</TOKEN>
<TOKEN id="token-84-6" pos="word" morph="none" start_char="7144" end_char="7150">elderly</TOKEN>
<TOKEN id="token-84-7" pos="word" morph="none" start_char="7152" end_char="7158">without</TOKEN>
<TOKEN id="token-84-8" pos="word" morph="none" start_char="7160" end_char="7166">looking</TOKEN>
<TOKEN id="token-84-9" pos="word" morph="none" start_char="7168" end_char="7171">like</TOKEN>
<TOKEN id="token-84-10" pos="word" morph="none" start_char="7173" end_char="7176">they</TOKEN>
<TOKEN id="token-84-11" pos="word" morph="none" start_char="7178" end_char="7180">did</TOKEN>
<TOKEN id="token-84-12" pos="punct" morph="none" start_char="7181" end_char="7181">.</TOKEN>
</SEG>
<SEG id="segment-85" start_char="7184" end_char="7337">
<ORIGINAL_TEXT>There are always outliers who die from any virus, like health workers forced by the government to work 24/7 without rest or minimal rest for weeks on end.</ORIGINAL_TEXT>
<TOKEN id="token-85-0" pos="word" morph="none" start_char="7184" end_char="7188">There</TOKEN>
<TOKEN id="token-85-1" pos="word" morph="none" start_char="7190" end_char="7192">are</TOKEN>
<TOKEN id="token-85-2" pos="word" morph="none" start_char="7194" end_char="7199">always</TOKEN>
<TOKEN id="token-85-3" pos="word" morph="none" start_char="7201" end_char="7208">outliers</TOKEN>
<TOKEN id="token-85-4" pos="word" morph="none" start_char="7210" end_char="7212">who</TOKEN>
<TOKEN id="token-85-5" pos="word" morph="none" start_char="7214" end_char="7216">die</TOKEN>
<TOKEN id="token-85-6" pos="word" morph="none" start_char="7218" end_char="7221">from</TOKEN>
<TOKEN id="token-85-7" pos="word" morph="none" start_char="7223" end_char="7225">any</TOKEN>
<TOKEN id="token-85-8" pos="word" morph="none" start_char="7227" end_char="7231">virus</TOKEN>
<TOKEN id="token-85-9" pos="punct" morph="none" start_char="7232" end_char="7232">,</TOKEN>
<TOKEN id="token-85-10" pos="word" morph="none" start_char="7234" end_char="7237">like</TOKEN>
<TOKEN id="token-85-11" pos="word" morph="none" start_char="7239" end_char="7244">health</TOKEN>
<TOKEN id="token-85-12" pos="word" morph="none" start_char="7246" end_char="7252">workers</TOKEN>
<TOKEN id="token-85-13" pos="word" morph="none" start_char="7254" end_char="7259">forced</TOKEN>
<TOKEN id="token-85-14" pos="word" morph="none" start_char="7261" end_char="7262">by</TOKEN>
<TOKEN id="token-85-15" pos="word" morph="none" start_char="7264" end_char="7266">the</TOKEN>
<TOKEN id="token-85-16" pos="word" morph="none" start_char="7268" end_char="7277">government</TOKEN>
<TOKEN id="token-85-17" pos="word" morph="none" start_char="7279" end_char="7280">to</TOKEN>
<TOKEN id="token-85-18" pos="word" morph="none" start_char="7282" end_char="7285">work</TOKEN>
<TOKEN id="token-85-19" pos="unknown" morph="none" start_char="7287" end_char="7290">24/7</TOKEN>
<TOKEN id="token-85-20" pos="word" morph="none" start_char="7292" end_char="7298">without</TOKEN>
<TOKEN id="token-85-21" pos="word" morph="none" start_char="7300" end_char="7303">rest</TOKEN>
<TOKEN id="token-85-22" pos="word" morph="none" start_char="7305" end_char="7306">or</TOKEN>
<TOKEN id="token-85-23" pos="word" morph="none" start_char="7308" end_char="7314">minimal</TOKEN>
<TOKEN id="token-85-24" pos="word" morph="none" start_char="7316" end_char="7319">rest</TOKEN>
<TOKEN id="token-85-25" pos="word" morph="none" start_char="7321" end_char="7323">for</TOKEN>
<TOKEN id="token-85-26" pos="word" morph="none" start_char="7325" end_char="7329">weeks</TOKEN>
<TOKEN id="token-85-27" pos="word" morph="none" start_char="7331" end_char="7332">on</TOKEN>
<TOKEN id="token-85-28" pos="word" morph="none" start_char="7334" end_char="7336">end</TOKEN>
<TOKEN id="token-85-29" pos="punct" morph="none" start_char="7337" end_char="7337">.</TOKEN>
</SEG>
<SEG id="segment-86" start_char="7340" end_char="7434">
<ORIGINAL_TEXT>In a socialist/communist country the resource drain from the elderly is reaching crises levels.</ORIGINAL_TEXT>
<TOKEN id="token-86-0" pos="word" morph="none" start_char="7340" end_char="7341">In</TOKEN>
<TOKEN id="token-86-1" pos="word" morph="none" start_char="7343" end_char="7343">a</TOKEN>
<TOKEN id="token-86-2" pos="unknown" morph="none" start_char="7345" end_char="7363">socialist/communist</TOKEN>
<TOKEN id="token-86-3" pos="word" morph="none" start_char="7365" end_char="7371">country</TOKEN>
<TOKEN id="token-86-4" pos="word" morph="none" start_char="7373" end_char="7375">the</TOKEN>
<TOKEN id="token-86-5" pos="word" morph="none" start_char="7377" end_char="7384">resource</TOKEN>
<TOKEN id="token-86-6" pos="word" morph="none" start_char="7386" end_char="7390">drain</TOKEN>
<TOKEN id="token-86-7" pos="word" morph="none" start_char="7392" end_char="7395">from</TOKEN>
<TOKEN id="token-86-8" pos="word" morph="none" start_char="7397" end_char="7399">the</TOKEN>
<TOKEN id="token-86-9" pos="word" morph="none" start_char="7401" end_char="7407">elderly</TOKEN>
<TOKEN id="token-86-10" pos="word" morph="none" start_char="7409" end_char="7410">is</TOKEN>
<TOKEN id="token-86-11" pos="word" morph="none" start_char="7412" end_char="7419">reaching</TOKEN>
<TOKEN id="token-86-12" pos="word" morph="none" start_char="7421" end_char="7426">crises</TOKEN>
<TOKEN id="token-86-13" pos="word" morph="none" start_char="7428" end_char="7433">levels</TOKEN>
<TOKEN id="token-86-14" pos="punct" morph="none" start_char="7434" end_char="7434">.</TOKEN>
</SEG>
<SEG id="segment-87" start_char="7436" end_char="7509">
<ORIGINAL_TEXT>Aside from China, China may see itself as doing good for the entire world.</ORIGINAL_TEXT>
<TOKEN id="token-87-0" pos="word" morph="none" start_char="7436" end_char="7440">Aside</TOKEN>
<TOKEN id="token-87-1" pos="word" morph="none" start_char="7442" end_char="7445">from</TOKEN>
<TOKEN id="token-87-2" pos="word" morph="none" start_char="7447" end_char="7451">China</TOKEN>
<TOKEN id="token-87-3" pos="punct" morph="none" start_char="7452" end_char="7452">,</TOKEN>
<TOKEN id="token-87-4" pos="word" morph="none" start_char="7454" end_char="7458">China</TOKEN>
<TOKEN id="token-87-5" pos="word" morph="none" start_char="7460" end_char="7462">may</TOKEN>
<TOKEN id="token-87-6" pos="word" morph="none" start_char="7464" end_char="7466">see</TOKEN>
<TOKEN id="token-87-7" pos="word" morph="none" start_char="7468" end_char="7473">itself</TOKEN>
<TOKEN id="token-87-8" pos="word" morph="none" start_char="7475" end_char="7476">as</TOKEN>
<TOKEN id="token-87-9" pos="word" morph="none" start_char="7478" end_char="7482">doing</TOKEN>
<TOKEN id="token-87-10" pos="word" morph="none" start_char="7484" end_char="7487">good</TOKEN>
<TOKEN id="token-87-11" pos="word" morph="none" start_char="7489" end_char="7491">for</TOKEN>
<TOKEN id="token-87-12" pos="word" morph="none" start_char="7493" end_char="7495">the</TOKEN>
<TOKEN id="token-87-13" pos="word" morph="none" start_char="7497" end_char="7502">entire</TOKEN>
<TOKEN id="token-87-14" pos="word" morph="none" start_char="7504" end_char="7508">world</TOKEN>
<TOKEN id="token-87-15" pos="punct" morph="none" start_char="7509" end_char="7509">.</TOKEN>
</SEG>
<SEG id="segment-88" start_char="7511" end_char="7581">
<ORIGINAL_TEXT>There are an excess of elderly in every developed country in the world.</ORIGINAL_TEXT>
<TOKEN id="token-88-0" pos="word" morph="none" start_char="7511" end_char="7515">There</TOKEN>
<TOKEN id="token-88-1" pos="word" morph="none" start_char="7517" end_char="7519">are</TOKEN>
<TOKEN id="token-88-2" pos="word" morph="none" start_char="7521" end_char="7522">an</TOKEN>
<TOKEN id="token-88-3" pos="word" morph="none" start_char="7524" end_char="7529">excess</TOKEN>
<TOKEN id="token-88-4" pos="word" morph="none" start_char="7531" end_char="7532">of</TOKEN>
<TOKEN id="token-88-5" pos="word" morph="none" start_char="7534" end_char="7540">elderly</TOKEN>
<TOKEN id="token-88-6" pos="word" morph="none" start_char="7542" end_char="7543">in</TOKEN>
<TOKEN id="token-88-7" pos="word" morph="none" start_char="7545" end_char="7549">every</TOKEN>
<TOKEN id="token-88-8" pos="word" morph="none" start_char="7551" end_char="7559">developed</TOKEN>
<TOKEN id="token-88-9" pos="word" morph="none" start_char="7561" end_char="7567">country</TOKEN>
<TOKEN id="token-88-10" pos="word" morph="none" start_char="7569" end_char="7570">in</TOKEN>
<TOKEN id="token-88-11" pos="word" morph="none" start_char="7572" end_char="7574">the</TOKEN>
<TOKEN id="token-88-12" pos="word" morph="none" start_char="7576" end_char="7580">world</TOKEN>
<TOKEN id="token-88-13" pos="punct" morph="none" start_char="7581" end_char="7581">.</TOKEN>
</SEG>
<SEG id="segment-89" start_char="7584" end_char="7705">
<ORIGINAL_TEXT>To deny or dismiss it being a designer virus to kill the excess elderly population is like sticking your head in the sand.</ORIGINAL_TEXT>
<TOKEN id="token-89-0" pos="word" morph="none" start_char="7584" end_char="7585">To</TOKEN>
<TOKEN id="token-89-1" pos="word" morph="none" start_char="7587" end_char="7590">deny</TOKEN>
<TOKEN id="token-89-2" pos="word" morph="none" start_char="7592" end_char="7593">or</TOKEN>
<TOKEN id="token-89-3" pos="word" morph="none" start_char="7595" end_char="7601">dismiss</TOKEN>
<TOKEN id="token-89-4" pos="word" morph="none" start_char="7603" end_char="7604">it</TOKEN>
<TOKEN id="token-89-5" pos="word" morph="none" start_char="7606" end_char="7610">being</TOKEN>
<TOKEN id="token-89-6" pos="word" morph="none" start_char="7612" end_char="7612">a</TOKEN>
<TOKEN id="token-89-7" pos="word" morph="none" start_char="7614" end_char="7621">designer</TOKEN>
<TOKEN id="token-89-8" pos="word" morph="none" start_char="7623" end_char="7627">virus</TOKEN>
<TOKEN id="token-89-9" pos="word" morph="none" start_char="7629" end_char="7630">to</TOKEN>
<TOKEN id="token-89-10" pos="word" morph="none" start_char="7632" end_char="7635">kill</TOKEN>
<TOKEN id="token-89-11" pos="word" morph="none" start_char="7637" end_char="7639">the</TOKEN>
<TOKEN id="token-89-12" pos="word" morph="none" start_char="7641" end_char="7646">excess</TOKEN>
<TOKEN id="token-89-13" pos="word" morph="none" start_char="7648" end_char="7654">elderly</TOKEN>
<TOKEN id="token-89-14" pos="word" morph="none" start_char="7656" end_char="7665">population</TOKEN>
<TOKEN id="token-89-15" pos="word" morph="none" start_char="7667" end_char="7668">is</TOKEN>
<TOKEN id="token-89-16" pos="word" morph="none" start_char="7670" end_char="7673">like</TOKEN>
<TOKEN id="token-89-17" pos="word" morph="none" start_char="7675" end_char="7682">sticking</TOKEN>
<TOKEN id="token-89-18" pos="word" morph="none" start_char="7684" end_char="7687">your</TOKEN>
<TOKEN id="token-89-19" pos="word" morph="none" start_char="7689" end_char="7692">head</TOKEN>
<TOKEN id="token-89-20" pos="word" morph="none" start_char="7694" end_char="7695">in</TOKEN>
<TOKEN id="token-89-21" pos="word" morph="none" start_char="7697" end_char="7699">the</TOKEN>
<TOKEN id="token-89-22" pos="word" morph="none" start_char="7701" end_char="7704">sand</TOKEN>
<TOKEN id="token-89-23" pos="punct" morph="none" start_char="7705" end_char="7705">.</TOKEN>
</SEG>
<SEG id="segment-90" start_char="7708" end_char="7893">
<ORIGINAL_TEXT>I have seen several people doing that and wonder if they are Chinese paid operatives who are doing their best to make this highly logical conclusion sound like a weird conspiracy theory.</ORIGINAL_TEXT>
<TOKEN id="token-90-0" pos="word" morph="none" start_char="7708" end_char="7708">I</TOKEN>
<TOKEN id="token-90-1" pos="word" morph="none" start_char="7710" end_char="7713">have</TOKEN>
<TOKEN id="token-90-2" pos="word" morph="none" start_char="7715" end_char="7718">seen</TOKEN>
<TOKEN id="token-90-3" pos="word" morph="none" start_char="7720" end_char="7726">several</TOKEN>
<TOKEN id="token-90-4" pos="word" morph="none" start_char="7728" end_char="7733">people</TOKEN>
<TOKEN id="token-90-5" pos="word" morph="none" start_char="7735" end_char="7739">doing</TOKEN>
<TOKEN id="token-90-6" pos="word" morph="none" start_char="7741" end_char="7744">that</TOKEN>
<TOKEN id="token-90-7" pos="word" morph="none" start_char="7746" end_char="7748">and</TOKEN>
<TOKEN id="token-90-8" pos="word" morph="none" start_char="7750" end_char="7755">wonder</TOKEN>
<TOKEN id="token-90-9" pos="word" morph="none" start_char="7757" end_char="7758">if</TOKEN>
<TOKEN id="token-90-10" pos="word" morph="none" start_char="7760" end_char="7763">they</TOKEN>
<TOKEN id="token-90-11" pos="word" morph="none" start_char="7765" end_char="7767">are</TOKEN>
<TOKEN id="token-90-12" pos="word" morph="none" start_char="7769" end_char="7775">Chinese</TOKEN>
<TOKEN id="token-90-13" pos="word" morph="none" start_char="7777" end_char="7780">paid</TOKEN>
<TOKEN id="token-90-14" pos="word" morph="none" start_char="7782" end_char="7791">operatives</TOKEN>
<TOKEN id="token-90-15" pos="word" morph="none" start_char="7793" end_char="7795">who</TOKEN>
<TOKEN id="token-90-16" pos="word" morph="none" start_char="7797" end_char="7799">are</TOKEN>
<TOKEN id="token-90-17" pos="word" morph="none" start_char="7801" end_char="7805">doing</TOKEN>
<TOKEN id="token-90-18" pos="word" morph="none" start_char="7807" end_char="7811">their</TOKEN>
<TOKEN id="token-90-19" pos="word" morph="none" start_char="7813" end_char="7816">best</TOKEN>
<TOKEN id="token-90-20" pos="word" morph="none" start_char="7818" end_char="7819">to</TOKEN>
<TOKEN id="token-90-21" pos="word" morph="none" start_char="7821" end_char="7824">make</TOKEN>
<TOKEN id="token-90-22" pos="word" morph="none" start_char="7826" end_char="7829">this</TOKEN>
<TOKEN id="token-90-23" pos="word" morph="none" start_char="7831" end_char="7836">highly</TOKEN>
<TOKEN id="token-90-24" pos="word" morph="none" start_char="7838" end_char="7844">logical</TOKEN>
<TOKEN id="token-90-25" pos="word" morph="none" start_char="7846" end_char="7855">conclusion</TOKEN>
<TOKEN id="token-90-26" pos="word" morph="none" start_char="7857" end_char="7861">sound</TOKEN>
<TOKEN id="token-90-27" pos="word" morph="none" start_char="7863" end_char="7866">like</TOKEN>
<TOKEN id="token-90-28" pos="word" morph="none" start_char="7868" end_char="7868">a</TOKEN>
<TOKEN id="token-90-29" pos="word" morph="none" start_char="7870" end_char="7874">weird</TOKEN>
<TOKEN id="token-90-30" pos="word" morph="none" start_char="7876" end_char="7885">conspiracy</TOKEN>
<TOKEN id="token-90-31" pos="word" morph="none" start_char="7887" end_char="7892">theory</TOKEN>
<TOKEN id="token-90-32" pos="punct" morph="none" start_char="7893" end_char="7893">.</TOKEN>
</SEG>
<SEG id="segment-91" start_char="7896" end_char="8051">
<ORIGINAL_TEXT>Someone with 2 masters degrees, and a very steady person asked me the other day if I thought the Chinese designed this and it got loose from their facility.</ORIGINAL_TEXT>
<TOKEN id="token-91-0" pos="word" morph="none" start_char="7896" end_char="7902">Someone</TOKEN>
<TOKEN id="token-91-1" pos="word" morph="none" start_char="7904" end_char="7907">with</TOKEN>
<TOKEN id="token-91-2" pos="word" morph="none" start_char="7909" end_char="7909">2</TOKEN>
<TOKEN id="token-91-3" pos="word" morph="none" start_char="7911" end_char="7917">masters</TOKEN>
<TOKEN id="token-91-4" pos="word" morph="none" start_char="7919" end_char="7925">degrees</TOKEN>
<TOKEN id="token-91-5" pos="punct" morph="none" start_char="7926" end_char="7926">,</TOKEN>
<TOKEN id="token-91-6" pos="word" morph="none" start_char="7928" end_char="7930">and</TOKEN>
<TOKEN id="token-91-7" pos="word" morph="none" start_char="7932" end_char="7932">a</TOKEN>
<TOKEN id="token-91-8" pos="word" morph="none" start_char="7934" end_char="7937">very</TOKEN>
<TOKEN id="token-91-9" pos="word" morph="none" start_char="7939" end_char="7944">steady</TOKEN>
<TOKEN id="token-91-10" pos="word" morph="none" start_char="7946" end_char="7951">person</TOKEN>
<TOKEN id="token-91-11" pos="word" morph="none" start_char="7953" end_char="7957">asked</TOKEN>
<TOKEN id="token-91-12" pos="word" morph="none" start_char="7959" end_char="7960">me</TOKEN>
<TOKEN id="token-91-13" pos="word" morph="none" start_char="7962" end_char="7964">the</TOKEN>
<TOKEN id="token-91-14" pos="word" morph="none" start_char="7966" end_char="7970">other</TOKEN>
<TOKEN id="token-91-15" pos="word" morph="none" start_char="7972" end_char="7974">day</TOKEN>
<TOKEN id="token-91-16" pos="word" morph="none" start_char="7976" end_char="7977">if</TOKEN>
<TOKEN id="token-91-17" pos="word" morph="none" start_char="7979" end_char="7979">I</TOKEN>
<TOKEN id="token-91-18" pos="word" morph="none" start_char="7981" end_char="7987">thought</TOKEN>
<TOKEN id="token-91-19" pos="word" morph="none" start_char="7989" end_char="7991">the</TOKEN>
<TOKEN id="token-91-20" pos="word" morph="none" start_char="7993" end_char="7999">Chinese</TOKEN>
<TOKEN id="token-91-21" pos="word" morph="none" start_char="8001" end_char="8008">designed</TOKEN>
<TOKEN id="token-91-22" pos="word" morph="none" start_char="8010" end_char="8013">this</TOKEN>
<TOKEN id="token-91-23" pos="word" morph="none" start_char="8015" end_char="8017">and</TOKEN>
<TOKEN id="token-91-24" pos="word" morph="none" start_char="8019" end_char="8020">it</TOKEN>
<TOKEN id="token-91-25" pos="word" morph="none" start_char="8022" end_char="8024">got</TOKEN>
<TOKEN id="token-91-26" pos="word" morph="none" start_char="8026" end_char="8030">loose</TOKEN>
<TOKEN id="token-91-27" pos="word" morph="none" start_char="8032" end_char="8035">from</TOKEN>
<TOKEN id="token-91-28" pos="word" morph="none" start_char="8037" end_char="8041">their</TOKEN>
<TOKEN id="token-91-29" pos="word" morph="none" start_char="8043" end_char="8050">facility</TOKEN>
<TOKEN id="token-91-30" pos="punct" morph="none" start_char="8051" end_char="8051">.</TOKEN>
</SEG>
<SEG id="segment-92" start_char="8053" end_char="8105">
<ORIGINAL_TEXT>I said a cautious yes, and the person said, I do too.</ORIGINAL_TEXT>
<TOKEN id="token-92-0" pos="word" morph="none" start_char="8053" end_char="8053">I</TOKEN>
<TOKEN id="token-92-1" pos="word" morph="none" start_char="8055" end_char="8058">said</TOKEN>
<TOKEN id="token-92-2" pos="word" morph="none" start_char="8060" end_char="8060">a</TOKEN>
<TOKEN id="token-92-3" pos="word" morph="none" start_char="8062" end_char="8069">cautious</TOKEN>
<TOKEN id="token-92-4" pos="word" morph="none" start_char="8071" end_char="8073">yes</TOKEN>
<TOKEN id="token-92-5" pos="punct" morph="none" start_char="8074" end_char="8074">,</TOKEN>
<TOKEN id="token-92-6" pos="word" morph="none" start_char="8076" end_char="8078">and</TOKEN>
<TOKEN id="token-92-7" pos="word" morph="none" start_char="8080" end_char="8082">the</TOKEN>
<TOKEN id="token-92-8" pos="word" morph="none" start_char="8084" end_char="8089">person</TOKEN>
<TOKEN id="token-92-9" pos="word" morph="none" start_char="8091" end_char="8094">said</TOKEN>
<TOKEN id="token-92-10" pos="punct" morph="none" start_char="8095" end_char="8095">,</TOKEN>
<TOKEN id="token-92-11" pos="word" morph="none" start_char="8097" end_char="8097">I</TOKEN>
<TOKEN id="token-92-12" pos="word" morph="none" start_char="8099" end_char="8100">do</TOKEN>
<TOKEN id="token-92-13" pos="word" morph="none" start_char="8102" end_char="8104">too</TOKEN>
<TOKEN id="token-92-14" pos="punct" morph="none" start_char="8105" end_char="8105">.</TOKEN>
</SEG>
<SEG id="segment-93" start_char="8107" end_char="8211">
<ORIGINAL_TEXT>This shows that even people who aren't into "the new" the way ATS people are have seen the obvious truth.</ORIGINAL_TEXT>
<TOKEN id="token-93-0" pos="word" morph="none" start_char="8107" end_char="8110">This</TOKEN>
<TOKEN id="token-93-1" pos="word" morph="none" start_char="8112" end_char="8116">shows</TOKEN>
<TOKEN id="token-93-2" pos="word" morph="none" start_char="8118" end_char="8121">that</TOKEN>
<TOKEN id="token-93-3" pos="word" morph="none" start_char="8123" end_char="8126">even</TOKEN>
<TOKEN id="token-93-4" pos="word" morph="none" start_char="8128" end_char="8133">people</TOKEN>
<TOKEN id="token-93-5" pos="word" morph="none" start_char="8135" end_char="8137">who</TOKEN>
<TOKEN id="token-93-6" pos="word" morph="none" start_char="8139" end_char="8144">aren't</TOKEN>
<TOKEN id="token-93-7" pos="word" morph="none" start_char="8146" end_char="8149">into</TOKEN>
<TOKEN id="token-93-8" pos="punct" morph="none" start_char="8151" end_char="8151">"</TOKEN>
<TOKEN id="token-93-9" pos="word" morph="none" start_char="8152" end_char="8154">the</TOKEN>
<TOKEN id="token-93-10" pos="word" morph="none" start_char="8156" end_char="8158">new</TOKEN>
<TOKEN id="token-93-11" pos="punct" morph="none" start_char="8159" end_char="8159">"</TOKEN>
<TOKEN id="token-93-12" pos="word" morph="none" start_char="8161" end_char="8163">the</TOKEN>
<TOKEN id="token-93-13" pos="word" morph="none" start_char="8165" end_char="8167">way</TOKEN>
<TOKEN id="token-93-14" pos="word" morph="none" start_char="8169" end_char="8171">ATS</TOKEN>
<TOKEN id="token-93-15" pos="word" morph="none" start_char="8173" end_char="8178">people</TOKEN>
<TOKEN id="token-93-16" pos="word" morph="none" start_char="8180" end_char="8182">are</TOKEN>
<TOKEN id="token-93-17" pos="word" morph="none" start_char="8184" end_char="8187">have</TOKEN>
<TOKEN id="token-93-18" pos="word" morph="none" start_char="8189" end_char="8192">seen</TOKEN>
<TOKEN id="token-93-19" pos="word" morph="none" start_char="8194" end_char="8196">the</TOKEN>
<TOKEN id="token-93-20" pos="word" morph="none" start_char="8198" end_char="8204">obvious</TOKEN>
<TOKEN id="token-93-21" pos="word" morph="none" start_char="8206" end_char="8210">truth</TOKEN>
<TOKEN id="token-93-22" pos="punct" morph="none" start_char="8211" end_char="8211">.</TOKEN>
</SEG>
<SEG id="segment-94" start_char="8214" end_char="8259">
<ORIGINAL_TEXT>edit on 3/13/20 by The2Billies because: format</ORIGINAL_TEXT>
<TOKEN id="token-94-0" pos="word" morph="none" start_char="8214" end_char="8217">edit</TOKEN>
<TOKEN id="token-94-1" pos="word" morph="none" start_char="8219" end_char="8220">on</TOKEN>
<TOKEN id="token-94-2" pos="unknown" morph="none" start_char="8222" end_char="8228">3/13/20</TOKEN>
<TOKEN id="token-94-3" pos="word" morph="none" start_char="8230" end_char="8231">by</TOKEN>
<TOKEN id="token-94-4" pos="word" morph="none" start_char="8233" end_char="8243">The2Billies</TOKEN>
<TOKEN id="token-94-5" pos="word" morph="none" start_char="8245" end_char="8251">because</TOKEN>
<TOKEN id="token-94-6" pos="punct" morph="none" start_char="8252" end_char="8252">:</TOKEN>
<TOKEN id="token-94-7" pos="word" morph="none" start_char="8254" end_char="8259">format</TOKEN>
</SEG>
<SEG id="segment-95" start_char="8263" end_char="8282">
<ORIGINAL_TEXT>"What Are The Odds?"</ORIGINAL_TEXT>
<TOKEN id="token-95-0" pos="punct" morph="none" start_char="8263" end_char="8263">"</TOKEN>
<TOKEN id="token-95-1" pos="word" morph="none" start_char="8264" end_char="8267">What</TOKEN>
<TOKEN id="token-95-2" pos="word" morph="none" start_char="8269" end_char="8271">Are</TOKEN>
<TOKEN id="token-95-3" pos="word" morph="none" start_char="8273" end_char="8275">The</TOKEN>
<TOKEN id="token-95-4" pos="word" morph="none" start_char="8277" end_char="8280">Odds</TOKEN>
<TOKEN id="token-95-5" pos="punct" morph="none" start_char="8281" end_char="8282">?"</TOKEN>
</SEG>
<SEG id="segment-96" start_char="8284" end_char="8371">
<ORIGINAL_TEXT>- A Timeline Of Facts Linking Covid-19, HIV, Wuhan's Secret Bio-Lab www.zerohedge.com...</ORIGINAL_TEXT>
<TOKEN id="token-96-0" pos="punct" morph="none" start_char="8284" end_char="8284">-</TOKEN>
<TOKEN id="token-96-1" pos="word" morph="none" start_char="8286" end_char="8286">A</TOKEN>
<TOKEN id="token-96-2" pos="word" morph="none" start_char="8288" end_char="8295">Timeline</TOKEN>
<TOKEN id="token-96-3" pos="word" morph="none" start_char="8297" end_char="8298">Of</TOKEN>
<TOKEN id="token-96-4" pos="word" morph="none" start_char="8300" end_char="8304">Facts</TOKEN>
<TOKEN id="token-96-5" pos="word" morph="none" start_char="8306" end_char="8312">Linking</TOKEN>
<TOKEN id="token-96-6" pos="unknown" morph="none" start_char="8314" end_char="8321">Covid-19</TOKEN>
<TOKEN id="token-96-7" pos="punct" morph="none" start_char="8322" end_char="8322">,</TOKEN>
<TOKEN id="token-96-8" pos="word" morph="none" start_char="8324" end_char="8326">HIV</TOKEN>
<TOKEN id="token-96-9" pos="punct" morph="none" start_char="8327" end_char="8327">,</TOKEN>
<TOKEN id="token-96-10" pos="word" morph="none" start_char="8329" end_char="8335">Wuhan's</TOKEN>
<TOKEN id="token-96-11" pos="word" morph="none" start_char="8337" end_char="8342">Secret</TOKEN>
<TOKEN id="token-96-12" pos="unknown" morph="none" start_char="8344" end_char="8350">Bio-Lab</TOKEN>
<TOKEN id="token-96-13" pos="url" morph="none" start_char="8352" end_char="8371">www.zerohedge.com...</TOKEN>
</SEG>
<SEG id="segment-97" start_char="8374" end_char="8430">
<ORIGINAL_TEXT>So theres original SARS, which is a type of coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-97-0" pos="word" morph="none" start_char="8374" end_char="8375">So</TOKEN>
<TOKEN id="token-97-1" pos="word" morph="none" start_char="8377" end_char="8383">theres</TOKEN>
<TOKEN id="token-97-2" pos="word" morph="none" start_char="8385" end_char="8392">original</TOKEN>
<TOKEN id="token-97-3" pos="word" morph="none" start_char="8394" end_char="8397">SARS</TOKEN>
<TOKEN id="token-97-4" pos="punct" morph="none" start_char="8398" end_char="8398">,</TOKEN>
<TOKEN id="token-97-5" pos="word" morph="none" start_char="8400" end_char="8404">which</TOKEN>
<TOKEN id="token-97-6" pos="word" morph="none" start_char="8406" end_char="8407">is</TOKEN>
<TOKEN id="token-97-7" pos="word" morph="none" start_char="8409" end_char="8409">a</TOKEN>
<TOKEN id="token-97-8" pos="word" morph="none" start_char="8411" end_char="8414">type</TOKEN>
<TOKEN id="token-97-9" pos="word" morph="none" start_char="8416" end_char="8417">of</TOKEN>
<TOKEN id="token-97-10" pos="word" morph="none" start_char="8419" end_char="8429">coronavirus</TOKEN>
<TOKEN id="token-97-11" pos="punct" morph="none" start_char="8430" end_char="8430">.</TOKEN>
</SEG>
<SEG id="segment-98" start_char="8432" end_char="8485">
<ORIGINAL_TEXT>SARS infects cells through the ACE2 receptor in hosts.</ORIGINAL_TEXT>
<TOKEN id="token-98-0" pos="word" morph="none" start_char="8432" end_char="8435">SARS</TOKEN>
<TOKEN id="token-98-1" pos="word" morph="none" start_char="8437" end_char="8443">infects</TOKEN>
<TOKEN id="token-98-2" pos="word" morph="none" start_char="8445" end_char="8449">cells</TOKEN>
<TOKEN id="token-98-3" pos="word" morph="none" start_char="8451" end_char="8457">through</TOKEN>
<TOKEN id="token-98-4" pos="word" morph="none" start_char="8459" end_char="8461">the</TOKEN>
<TOKEN id="token-98-5" pos="word" morph="none" start_char="8463" end_char="8466">ACE2</TOKEN>
<TOKEN id="token-98-6" pos="word" morph="none" start_char="8468" end_char="8475">receptor</TOKEN>
<TOKEN id="token-98-7" pos="word" morph="none" start_char="8477" end_char="8478">in</TOKEN>
<TOKEN id="token-98-8" pos="word" morph="none" start_char="8480" end_char="8484">hosts</TOKEN>
<TOKEN id="token-98-9" pos="punct" morph="none" start_char="8485" end_char="8485">.</TOKEN>
</SEG>
<SEG id="segment-99" start_char="8487" end_char="8554">
<ORIGINAL_TEXT>The S spike protein plays a key role in how the virus infects cells.</ORIGINAL_TEXT>
<TOKEN id="token-99-0" pos="word" morph="none" start_char="8487" end_char="8489">The</TOKEN>
<TOKEN id="token-99-1" pos="word" morph="none" start_char="8491" end_char="8491">S</TOKEN>
<TOKEN id="token-99-2" pos="word" morph="none" start_char="8493" end_char="8497">spike</TOKEN>
<TOKEN id="token-99-3" pos="word" morph="none" start_char="8499" end_char="8505">protein</TOKEN>
<TOKEN id="token-99-4" pos="word" morph="none" start_char="8507" end_char="8511">plays</TOKEN>
<TOKEN id="token-99-5" pos="word" morph="none" start_char="8513" end_char="8513">a</TOKEN>
<TOKEN id="token-99-6" pos="word" morph="none" start_char="8515" end_char="8517">key</TOKEN>
<TOKEN id="token-99-7" pos="word" morph="none" start_char="8519" end_char="8522">role</TOKEN>
<TOKEN id="token-99-8" pos="word" morph="none" start_char="8524" end_char="8525">in</TOKEN>
<TOKEN id="token-99-9" pos="word" morph="none" start_char="8527" end_char="8529">how</TOKEN>
<TOKEN id="token-99-10" pos="word" morph="none" start_char="8531" end_char="8533">the</TOKEN>
<TOKEN id="token-99-11" pos="word" morph="none" start_char="8535" end_char="8539">virus</TOKEN>
<TOKEN id="token-99-12" pos="word" morph="none" start_char="8541" end_char="8547">infects</TOKEN>
<TOKEN id="token-99-13" pos="word" morph="none" start_char="8549" end_char="8553">cells</TOKEN>
<TOKEN id="token-99-14" pos="punct" morph="none" start_char="8554" end_char="8554">.</TOKEN>
</SEG>
<SEG id="segment-100" start_char="8556" end_char="8645">
<ORIGINAL_TEXT>Each of the little spikes that surround the coronavirus is a spike protein (or S protein).</ORIGINAL_TEXT>
<TOKEN id="token-100-0" pos="word" morph="none" start_char="8556" end_char="8559">Each</TOKEN>
<TOKEN id="token-100-1" pos="word" morph="none" start_char="8561" end_char="8562">of</TOKEN>
<TOKEN id="token-100-2" pos="word" morph="none" start_char="8564" end_char="8566">the</TOKEN>
<TOKEN id="token-100-3" pos="word" morph="none" start_char="8568" end_char="8573">little</TOKEN>
<TOKEN id="token-100-4" pos="word" morph="none" start_char="8575" end_char="8580">spikes</TOKEN>
<TOKEN id="token-100-5" pos="word" morph="none" start_char="8582" end_char="8585">that</TOKEN>
<TOKEN id="token-100-6" pos="word" morph="none" start_char="8587" end_char="8594">surround</TOKEN>
<TOKEN id="token-100-7" pos="word" morph="none" start_char="8596" end_char="8598">the</TOKEN>
<TOKEN id="token-100-8" pos="word" morph="none" start_char="8600" end_char="8610">coronavirus</TOKEN>
<TOKEN id="token-100-9" pos="word" morph="none" start_char="8612" end_char="8613">is</TOKEN>
<TOKEN id="token-100-10" pos="word" morph="none" start_char="8615" end_char="8615">a</TOKEN>
<TOKEN id="token-100-11" pos="word" morph="none" start_char="8617" end_char="8621">spike</TOKEN>
<TOKEN id="token-100-12" pos="word" morph="none" start_char="8623" end_char="8629">protein</TOKEN>
<TOKEN id="token-100-13" pos="punct" morph="none" start_char="8631" end_char="8631">(</TOKEN>
<TOKEN id="token-100-14" pos="word" morph="none" start_char="8632" end_char="8633">or</TOKEN>
<TOKEN id="token-100-15" pos="word" morph="none" start_char="8635" end_char="8635">S</TOKEN>
<TOKEN id="token-100-16" pos="word" morph="none" start_char="8637" end_char="8643">protein</TOKEN>
<TOKEN id="token-100-17" pos="punct" morph="none" start_char="8644" end_char="8645">).</TOKEN>
</SEG>
<SEG id="segment-101" start_char="8647" end_char="8721">
<ORIGINAL_TEXT>Thats what gives the coronavirus its name - its "crown" of these spikes.</ORIGINAL_TEXT>
<TOKEN id="token-101-0" pos="word" morph="none" start_char="8647" end_char="8652">Thats</TOKEN>
<TOKEN id="token-101-1" pos="word" morph="none" start_char="8654" end_char="8657">what</TOKEN>
<TOKEN id="token-101-2" pos="word" morph="none" start_char="8659" end_char="8663">gives</TOKEN>
<TOKEN id="token-101-3" pos="word" morph="none" start_char="8665" end_char="8667">the</TOKEN>
<TOKEN id="token-101-4" pos="word" morph="none" start_char="8669" end_char="8679">coronavirus</TOKEN>
<TOKEN id="token-101-5" pos="word" morph="none" start_char="8681" end_char="8684">its</TOKEN>
<TOKEN id="token-101-6" pos="word" morph="none" start_char="8686" end_char="8689">name</TOKEN>
<TOKEN id="token-101-7" pos="punct" morph="none" start_char="8691" end_char="8691">-</TOKEN>
<TOKEN id="token-101-8" pos="word" morph="none" start_char="8693" end_char="8696">its</TOKEN>
<TOKEN id="token-101-9" pos="punct" morph="none" start_char="8698" end_char="8698">"</TOKEN>
<TOKEN id="token-101-10" pos="word" morph="none" start_char="8699" end_char="8703">crown</TOKEN>
<TOKEN id="token-101-11" pos="punct" morph="none" start_char="8704" end_char="8704">"</TOKEN>
<TOKEN id="token-101-12" pos="word" morph="none" start_char="8706" end_char="8707">of</TOKEN>
<TOKEN id="token-101-13" pos="word" morph="none" start_char="8709" end_char="8713">these</TOKEN>
<TOKEN id="token-101-14" pos="word" morph="none" start_char="8715" end_char="8720">spikes</TOKEN>
<TOKEN id="token-101-15" pos="punct" morph="none" start_char="8721" end_char="8721">.</TOKEN>
</SEG>
<SEG id="segment-102" start_char="8724" end_char="8806">
<ORIGINAL_TEXT>After the first SARS outbreak, there was a "land rush" to find other coronaviruses.</ORIGINAL_TEXT>
<TOKEN id="token-102-0" pos="word" morph="none" start_char="8724" end_char="8728">After</TOKEN>
<TOKEN id="token-102-1" pos="word" morph="none" start_char="8730" end_char="8732">the</TOKEN>
<TOKEN id="token-102-2" pos="word" morph="none" start_char="8734" end_char="8738">first</TOKEN>
<TOKEN id="token-102-3" pos="word" morph="none" start_char="8740" end_char="8743">SARS</TOKEN>
<TOKEN id="token-102-4" pos="word" morph="none" start_char="8745" end_char="8752">outbreak</TOKEN>
<TOKEN id="token-102-5" pos="punct" morph="none" start_char="8753" end_char="8753">,</TOKEN>
<TOKEN id="token-102-6" pos="word" morph="none" start_char="8755" end_char="8759">there</TOKEN>
<TOKEN id="token-102-7" pos="word" morph="none" start_char="8761" end_char="8763">was</TOKEN>
<TOKEN id="token-102-8" pos="word" morph="none" start_char="8765" end_char="8765">a</TOKEN>
<TOKEN id="token-102-9" pos="punct" morph="none" start_char="8767" end_char="8767">"</TOKEN>
<TOKEN id="token-102-10" pos="word" morph="none" start_char="8768" end_char="8771">land</TOKEN>
<TOKEN id="token-102-11" pos="word" morph="none" start_char="8773" end_char="8776">rush</TOKEN>
<TOKEN id="token-102-12" pos="punct" morph="none" start_char="8777" end_char="8777">"</TOKEN>
<TOKEN id="token-102-13" pos="word" morph="none" start_char="8779" end_char="8780">to</TOKEN>
<TOKEN id="token-102-14" pos="word" morph="none" start_char="8782" end_char="8785">find</TOKEN>
<TOKEN id="token-102-15" pos="word" morph="none" start_char="8787" end_char="8791">other</TOKEN>
<TOKEN id="token-102-16" pos="word" morph="none" start_char="8793" end_char="8805">coronaviruses</TOKEN>
<TOKEN id="token-102-17" pos="punct" morph="none" start_char="8806" end_char="8806">.</TOKEN>
</SEG>
<SEG id="segment-103" start_char="8808" end_char="8948">
<ORIGINAL_TEXT>A collection of SARS-*like* coronaviruses was isolated in several horseshoe bat species over 10 years ago, called SARS-like CoVs, or SL-CoVs.</ORIGINAL_TEXT>
<TOKEN id="token-103-0" pos="word" morph="none" start_char="8808" end_char="8808">A</TOKEN>
<TOKEN id="token-103-1" pos="word" morph="none" start_char="8810" end_char="8819">collection</TOKEN>
<TOKEN id="token-103-2" pos="word" morph="none" start_char="8821" end_char="8822">of</TOKEN>
<TOKEN id="token-103-3" pos="unknown" morph="none" start_char="8824" end_char="8833">SARS-*like</TOKEN>
<TOKEN id="token-103-4" pos="punct" morph="none" start_char="8834" end_char="8834">*</TOKEN>
<TOKEN id="token-103-5" pos="word" morph="none" start_char="8836" end_char="8848">coronaviruses</TOKEN>
<TOKEN id="token-103-6" pos="word" morph="none" start_char="8850" end_char="8852">was</TOKEN>
<TOKEN id="token-103-7" pos="word" morph="none" start_char="8854" end_char="8861">isolated</TOKEN>
<TOKEN id="token-103-8" pos="word" morph="none" start_char="8863" end_char="8864">in</TOKEN>
<TOKEN id="token-103-9" pos="word" morph="none" start_char="8866" end_char="8872">several</TOKEN>
<TOKEN id="token-103-10" pos="word" morph="none" start_char="8874" end_char="8882">horseshoe</TOKEN>
<TOKEN id="token-103-11" pos="word" morph="none" start_char="8884" end_char="8886">bat</TOKEN>
<TOKEN id="token-103-12" pos="word" morph="none" start_char="8888" end_char="8894">species</TOKEN>
<TOKEN id="token-103-13" pos="word" morph="none" start_char="8896" end_char="8899">over</TOKEN>
<TOKEN id="token-103-14" pos="word" morph="none" start_char="8901" end_char="8902">10</TOKEN>
<TOKEN id="token-103-15" pos="word" morph="none" start_char="8904" end_char="8908">years</TOKEN>
<TOKEN id="token-103-16" pos="word" morph="none" start_char="8910" end_char="8912">ago</TOKEN>
<TOKEN id="token-103-17" pos="punct" morph="none" start_char="8913" end_char="8913">,</TOKEN>
<TOKEN id="token-103-18" pos="word" morph="none" start_char="8915" end_char="8920">called</TOKEN>
<TOKEN id="token-103-19" pos="unknown" morph="none" start_char="8922" end_char="8930">SARS-like</TOKEN>
<TOKEN id="token-103-20" pos="word" morph="none" start_char="8932" end_char="8935">CoVs</TOKEN>
<TOKEN id="token-103-21" pos="punct" morph="none" start_char="8936" end_char="8936">,</TOKEN>
<TOKEN id="token-103-22" pos="word" morph="none" start_char="8938" end_char="8939">or</TOKEN>
<TOKEN id="token-103-23" pos="unknown" morph="none" start_char="8941" end_char="8947">SL-CoVs</TOKEN>
<TOKEN id="token-103-24" pos="punct" morph="none" start_char="8948" end_char="8948">.</TOKEN>
</SEG>
<SEG id="segment-104" start_char="8950" end_char="9001">
<ORIGINAL_TEXT>Not SARS exactly, but coronaviruses similar to SARS.</ORIGINAL_TEXT>
<TOKEN id="token-104-0" pos="word" morph="none" start_char="8950" end_char="8952">Not</TOKEN>
<TOKEN id="token-104-1" pos="word" morph="none" start_char="8954" end_char="8957">SARS</TOKEN>
<TOKEN id="token-104-2" pos="word" morph="none" start_char="8959" end_char="8965">exactly</TOKEN>
<TOKEN id="token-104-3" pos="punct" morph="none" start_char="8966" end_char="8966">,</TOKEN>
<TOKEN id="token-104-4" pos="word" morph="none" start_char="8968" end_char="8970">but</TOKEN>
<TOKEN id="token-104-5" pos="word" morph="none" start_char="8972" end_char="8984">coronaviruses</TOKEN>
<TOKEN id="token-104-6" pos="word" morph="none" start_char="8986" end_char="8992">similar</TOKEN>
<TOKEN id="token-104-7" pos="word" morph="none" start_char="8994" end_char="8995">to</TOKEN>
<TOKEN id="token-104-8" pos="word" morph="none" start_char="8997" end_char="9000">SARS</TOKEN>
<TOKEN id="token-104-9" pos="punct" morph="none" start_char="9001" end_char="9001">.</TOKEN>
</SEG>
<SEG id="segment-105" start_char="9003" end_char="9159">
<ORIGINAL_TEXT>In 2007, a team of researchers based in Wuhan, in conjunction with an Australian laboratory, conducted a study with SARS, a SARS-like coronavirus, and HIV-1.</ORIGINAL_TEXT>
<TOKEN id="token-105-0" pos="word" morph="none" start_char="9003" end_char="9004">In</TOKEN>
<TOKEN id="token-105-1" pos="word" morph="none" start_char="9006" end_char="9009">2007</TOKEN>
<TOKEN id="token-105-2" pos="punct" morph="none" start_char="9010" end_char="9010">,</TOKEN>
<TOKEN id="token-105-3" pos="word" morph="none" start_char="9012" end_char="9012">a</TOKEN>
<TOKEN id="token-105-4" pos="word" morph="none" start_char="9014" end_char="9017">team</TOKEN>
<TOKEN id="token-105-5" pos="word" morph="none" start_char="9019" end_char="9020">of</TOKEN>
<TOKEN id="token-105-6" pos="word" morph="none" start_char="9022" end_char="9032">researchers</TOKEN>
<TOKEN id="token-105-7" pos="word" morph="none" start_char="9034" end_char="9038">based</TOKEN>
<TOKEN id="token-105-8" pos="word" morph="none" start_char="9040" end_char="9041">in</TOKEN>
<TOKEN id="token-105-9" pos="word" morph="none" start_char="9043" end_char="9047">Wuhan</TOKEN>
<TOKEN id="token-105-10" pos="punct" morph="none" start_char="9048" end_char="9048">,</TOKEN>
<TOKEN id="token-105-11" pos="word" morph="none" start_char="9050" end_char="9051">in</TOKEN>
<TOKEN id="token-105-12" pos="word" morph="none" start_char="9053" end_char="9063">conjunction</TOKEN>
<TOKEN id="token-105-13" pos="word" morph="none" start_char="9065" end_char="9068">with</TOKEN>
<TOKEN id="token-105-14" pos="word" morph="none" start_char="9070" end_char="9071">an</TOKEN>
<TOKEN id="token-105-15" pos="word" morph="none" start_char="9073" end_char="9082">Australian</TOKEN>
<TOKEN id="token-105-16" pos="word" morph="none" start_char="9084" end_char="9093">laboratory</TOKEN>
<TOKEN id="token-105-17" pos="punct" morph="none" start_char="9094" end_char="9094">,</TOKEN>
<TOKEN id="token-105-18" pos="word" morph="none" start_char="9096" end_char="9104">conducted</TOKEN>
<TOKEN id="token-105-19" pos="word" morph="none" start_char="9106" end_char="9106">a</TOKEN>
<TOKEN id="token-105-20" pos="word" morph="none" start_char="9108" end_char="9112">study</TOKEN>
<TOKEN id="token-105-21" pos="word" morph="none" start_char="9114" end_char="9117">with</TOKEN>
<TOKEN id="token-105-22" pos="word" morph="none" start_char="9119" end_char="9122">SARS</TOKEN>
<TOKEN id="token-105-23" pos="punct" morph="none" start_char="9123" end_char="9123">,</TOKEN>
<TOKEN id="token-105-24" pos="word" morph="none" start_char="9125" end_char="9125">a</TOKEN>
<TOKEN id="token-105-25" pos="unknown" morph="none" start_char="9127" end_char="9135">SARS-like</TOKEN>
<TOKEN id="token-105-26" pos="word" morph="none" start_char="9137" end_char="9147">coronavirus</TOKEN>
<TOKEN id="token-105-27" pos="punct" morph="none" start_char="9148" end_char="9148">,</TOKEN>
<TOKEN id="token-105-28" pos="word" morph="none" start_char="9150" end_char="9152">and</TOKEN>
<TOKEN id="token-105-29" pos="unknown" morph="none" start_char="9154" end_char="9158">HIV-1</TOKEN>
<TOKEN id="token-105-30" pos="punct" morph="none" start_char="9159" end_char="9159">.</TOKEN>
</SEG>
<SEG id="segment-106" start_char="9162" end_char="9302">
<ORIGINAL_TEXT>They also predicted based on the S-ACE2 binding structure, that SARS-like CoVs were not able to use this same attack method (ACE2 mediation).</ORIGINAL_TEXT>
<TOKEN id="token-106-0" pos="word" morph="none" start_char="9162" end_char="9165">They</TOKEN>
<TOKEN id="token-106-1" pos="word" morph="none" start_char="9167" end_char="9170">also</TOKEN>
<TOKEN id="token-106-2" pos="word" morph="none" start_char="9172" end_char="9180">predicted</TOKEN>
<TOKEN id="token-106-3" pos="word" morph="none" start_char="9182" end_char="9186">based</TOKEN>
<TOKEN id="token-106-4" pos="word" morph="none" start_char="9188" end_char="9189">on</TOKEN>
<TOKEN id="token-106-5" pos="word" morph="none" start_char="9191" end_char="9193">the</TOKEN>
<TOKEN id="token-106-6" pos="unknown" morph="none" start_char="9195" end_char="9200">S-ACE2</TOKEN>
<TOKEN id="token-106-7" pos="word" morph="none" start_char="9202" end_char="9208">binding</TOKEN>
<TOKEN id="token-106-8" pos="word" morph="none" start_char="9210" end_char="9218">structure</TOKEN>
<TOKEN id="token-106-9" pos="punct" morph="none" start_char="9219" end_char="9219">,</TOKEN>
<TOKEN id="token-106-10" pos="word" morph="none" start_char="9221" end_char="9224">that</TOKEN>
<TOKEN id="token-106-11" pos="unknown" morph="none" start_char="9226" end_char="9234">SARS-like</TOKEN>
<TOKEN id="token-106-12" pos="word" morph="none" start_char="9236" end_char="9239">CoVs</TOKEN>
<TOKEN id="token-106-13" pos="word" morph="none" start_char="9241" end_char="9244">were</TOKEN>
<TOKEN id="token-106-14" pos="word" morph="none" start_char="9246" end_char="9248">not</TOKEN>
<TOKEN id="token-106-15" pos="word" morph="none" start_char="9250" end_char="9253">able</TOKEN>
<TOKEN id="token-106-16" pos="word" morph="none" start_char="9255" end_char="9256">to</TOKEN>
<TOKEN id="token-106-17" pos="word" morph="none" start_char="9258" end_char="9260">use</TOKEN>
<TOKEN id="token-106-18" pos="word" morph="none" start_char="9262" end_char="9265">this</TOKEN>
<TOKEN id="token-106-19" pos="word" morph="none" start_char="9267" end_char="9270">same</TOKEN>
<TOKEN id="token-106-20" pos="word" morph="none" start_char="9272" end_char="9277">attack</TOKEN>
<TOKEN id="token-106-21" pos="word" morph="none" start_char="9279" end_char="9284">method</TOKEN>
<TOKEN id="token-106-22" pos="punct" morph="none" start_char="9286" end_char="9286">(</TOKEN>
<TOKEN id="token-106-23" pos="word" morph="none" start_char="9287" end_char="9290">ACE2</TOKEN>
<TOKEN id="token-106-24" pos="word" morph="none" start_char="9292" end_char="9300">mediation</TOKEN>
<TOKEN id="token-106-25" pos="punct" morph="none" start_char="9301" end_char="9302">).</TOKEN>
</SEG>
<SEG id="segment-107" start_char="9304" end_char="9401">
<ORIGINAL_TEXT>They decided to create a pseudovirus where they essentially put a SARS-like CoV in a HIV envelope.</ORIGINAL_TEXT>
<TOKEN id="token-107-0" pos="word" morph="none" start_char="9304" end_char="9307">They</TOKEN>
<TOKEN id="token-107-1" pos="word" morph="none" start_char="9309" end_char="9315">decided</TOKEN>
<TOKEN id="token-107-2" pos="word" morph="none" start_char="9317" end_char="9318">to</TOKEN>
<TOKEN id="token-107-3" pos="word" morph="none" start_char="9320" end_char="9325">create</TOKEN>
<TOKEN id="token-107-4" pos="word" morph="none" start_char="9327" end_char="9327">a</TOKEN>
<TOKEN id="token-107-5" pos="word" morph="none" start_char="9329" end_char="9339">pseudovirus</TOKEN>
<TOKEN id="token-107-6" pos="word" morph="none" start_char="9341" end_char="9345">where</TOKEN>
<TOKEN id="token-107-7" pos="word" morph="none" start_char="9347" end_char="9350">they</TOKEN>
<TOKEN id="token-107-8" pos="word" morph="none" start_char="9352" end_char="9362">essentially</TOKEN>
<TOKEN id="token-107-9" pos="word" morph="none" start_char="9364" end_char="9366">put</TOKEN>
<TOKEN id="token-107-10" pos="word" morph="none" start_char="9368" end_char="9368">a</TOKEN>
<TOKEN id="token-107-11" pos="unknown" morph="none" start_char="9370" end_char="9378">SARS-like</TOKEN>
<TOKEN id="token-107-12" pos="word" morph="none" start_char="9380" end_char="9382">CoV</TOKEN>
<TOKEN id="token-107-13" pos="word" morph="none" start_char="9384" end_char="9385">in</TOKEN>
<TOKEN id="token-107-14" pos="word" morph="none" start_char="9387" end_char="9387">a</TOKEN>
<TOKEN id="token-107-15" pos="word" morph="none" start_char="9389" end_char="9391">HIV</TOKEN>
<TOKEN id="token-107-16" pos="word" morph="none" start_char="9393" end_char="9400">envelope</TOKEN>
<TOKEN id="token-107-17" pos="punct" morph="none" start_char="9401" end_char="9401">.</TOKEN>
</SEG>
<SEG id="segment-108" start_char="9403" end_char="9412">
<ORIGINAL_TEXT>It worked.</ORIGINAL_TEXT>
<TOKEN id="token-108-0" pos="word" morph="none" start_char="9403" end_char="9404">It</TOKEN>
<TOKEN id="token-108-1" pos="word" morph="none" start_char="9406" end_char="9411">worked</TOKEN>
<TOKEN id="token-108-2" pos="punct" morph="none" start_char="9412" end_char="9412">.</TOKEN>
</SEG>
<SEG id="segment-109" start_char="9414" end_char="9580">
<ORIGINAL_TEXT>Using an HIV envelope, they replaced the RBD (receptor binding domain) of SL-CoV with that of SARS-CoV, and used it to successfully infect bats through ACE2 mediation.</ORIGINAL_TEXT>
<TOKEN id="token-109-0" pos="word" morph="none" start_char="9414" end_char="9418">Using</TOKEN>
<TOKEN id="token-109-1" pos="word" morph="none" start_char="9420" end_char="9421">an</TOKEN>
<TOKEN id="token-109-2" pos="word" morph="none" start_char="9423" end_char="9425">HIV</TOKEN>
<TOKEN id="token-109-3" pos="word" morph="none" start_char="9427" end_char="9434">envelope</TOKEN>
<TOKEN id="token-109-4" pos="punct" morph="none" start_char="9435" end_char="9435">,</TOKEN>
<TOKEN id="token-109-5" pos="word" morph="none" start_char="9437" end_char="9440">they</TOKEN>
<TOKEN id="token-109-6" pos="word" morph="none" start_char="9442" end_char="9449">replaced</TOKEN>
<TOKEN id="token-109-7" pos="word" morph="none" start_char="9451" end_char="9453">the</TOKEN>
<TOKEN id="token-109-8" pos="word" morph="none" start_char="9455" end_char="9457">RBD</TOKEN>
<TOKEN id="token-109-9" pos="punct" morph="none" start_char="9459" end_char="9459">(</TOKEN>
<TOKEN id="token-109-10" pos="word" morph="none" start_char="9460" end_char="9467">receptor</TOKEN>
<TOKEN id="token-109-11" pos="word" morph="none" start_char="9469" end_char="9475">binding</TOKEN>
<TOKEN id="token-109-12" pos="word" morph="none" start_char="9477" end_char="9482">domain</TOKEN>
<TOKEN id="token-109-13" pos="punct" morph="none" start_char="9483" end_char="9483">)</TOKEN>
<TOKEN id="token-109-14" pos="word" morph="none" start_char="9485" end_char="9486">of</TOKEN>
<TOKEN id="token-109-15" pos="unknown" morph="none" start_char="9488" end_char="9493">SL-CoV</TOKEN>
<TOKEN id="token-109-16" pos="word" morph="none" start_char="9495" end_char="9498">with</TOKEN>
<TOKEN id="token-109-17" pos="word" morph="none" start_char="9500" end_char="9503">that</TOKEN>
<TOKEN id="token-109-18" pos="word" morph="none" start_char="9505" end_char="9506">of</TOKEN>
<TOKEN id="token-109-19" pos="unknown" morph="none" start_char="9508" end_char="9515">SARS-CoV</TOKEN>
<TOKEN id="token-109-20" pos="punct" morph="none" start_char="9516" end_char="9516">,</TOKEN>
<TOKEN id="token-109-21" pos="word" morph="none" start_char="9518" end_char="9520">and</TOKEN>
<TOKEN id="token-109-22" pos="word" morph="none" start_char="9522" end_char="9525">used</TOKEN>
<TOKEN id="token-109-23" pos="word" morph="none" start_char="9527" end_char="9528">it</TOKEN>
<TOKEN id="token-109-24" pos="word" morph="none" start_char="9530" end_char="9531">to</TOKEN>
<TOKEN id="token-109-25" pos="word" morph="none" start_char="9533" end_char="9544">successfully</TOKEN>
<TOKEN id="token-109-26" pos="word" morph="none" start_char="9546" end_char="9551">infect</TOKEN>
<TOKEN id="token-109-27" pos="word" morph="none" start_char="9553" end_char="9556">bats</TOKEN>
<TOKEN id="token-109-28" pos="word" morph="none" start_char="9558" end_char="9564">through</TOKEN>
<TOKEN id="token-109-29" pos="word" morph="none" start_char="9566" end_char="9569">ACE2</TOKEN>
<TOKEN id="token-109-30" pos="word" morph="none" start_char="9571" end_char="9579">mediation</TOKEN>
<TOKEN id="token-109-31" pos="punct" morph="none" start_char="9580" end_char="9580">.</TOKEN>
</SEG>
<SEG id="segment-110" start_char="9583" end_char="9639">
<ORIGINAL_TEXT>The Indian scientific paper that Chinese got angry about.</ORIGINAL_TEXT>
<TOKEN id="token-110-0" pos="word" morph="none" start_char="9583" end_char="9585">The</TOKEN>
<TOKEN id="token-110-1" pos="word" morph="none" start_char="9587" end_char="9592">Indian</TOKEN>
<TOKEN id="token-110-2" pos="word" morph="none" start_char="9594" end_char="9603">scientific</TOKEN>
<TOKEN id="token-110-3" pos="word" morph="none" start_char="9605" end_char="9609">paper</TOKEN>
<TOKEN id="token-110-4" pos="word" morph="none" start_char="9611" end_char="9614">that</TOKEN>
<TOKEN id="token-110-5" pos="word" morph="none" start_char="9616" end_char="9622">Chinese</TOKEN>
<TOKEN id="token-110-6" pos="word" morph="none" start_char="9624" end_char="9626">got</TOKEN>
<TOKEN id="token-110-7" pos="word" morph="none" start_char="9628" end_char="9632">angry</TOKEN>
<TOKEN id="token-110-8" pos="word" morph="none" start_char="9634" end_char="9638">about</TOKEN>
<TOKEN id="token-110-9" pos="punct" morph="none" start_char="9639" end_char="9639">.</TOKEN>
</SEG>
<SEG id="segment-111" start_char="9642" end_char="9731">
<ORIGINAL_TEXT>Uncanny similarity of unique inserts in the 2019-nCoV spike protein to HIV-1 gp120 and Gag</ORIGINAL_TEXT>
<TOKEN id="token-111-0" pos="word" morph="none" start_char="9642" end_char="9648">Uncanny</TOKEN>
<TOKEN id="token-111-1" pos="word" morph="none" start_char="9650" end_char="9659">similarity</TOKEN>
<TOKEN id="token-111-2" pos="word" morph="none" start_char="9661" end_char="9662">of</TOKEN>
<TOKEN id="token-111-3" pos="word" morph="none" start_char="9664" end_char="9669">unique</TOKEN>
<TOKEN id="token-111-4" pos="word" morph="none" start_char="9671" end_char="9677">inserts</TOKEN>
<TOKEN id="token-111-5" pos="word" morph="none" start_char="9679" end_char="9680">in</TOKEN>
<TOKEN id="token-111-6" pos="word" morph="none" start_char="9682" end_char="9684">the</TOKEN>
<TOKEN id="token-111-7" pos="unknown" morph="none" start_char="9686" end_char="9694">2019-nCoV</TOKEN>
<TOKEN id="token-111-8" pos="word" morph="none" start_char="9696" end_char="9700">spike</TOKEN>
<TOKEN id="token-111-9" pos="word" morph="none" start_char="9702" end_char="9708">protein</TOKEN>
<TOKEN id="token-111-10" pos="word" morph="none" start_char="9710" end_char="9711">to</TOKEN>
<TOKEN id="token-111-11" pos="unknown" morph="none" start_char="9713" end_char="9717">HIV-1</TOKEN>
<TOKEN id="token-111-12" pos="word" morph="none" start_char="9719" end_char="9723">gp120</TOKEN>
<TOKEN id="token-111-13" pos="word" morph="none" start_char="9725" end_char="9727">and</TOKEN>
<TOKEN id="token-111-14" pos="word" morph="none" start_char="9729" end_char="9731">Gag</TOKEN>
</SEG>
<SEG id="segment-112" start_char="9734" end_char="9849">
<ORIGINAL_TEXT>And then we have the articles on people working at the lab selling animals at food market instead of cremating them.</ORIGINAL_TEXT>
<TOKEN id="token-112-0" pos="word" morph="none" start_char="9734" end_char="9736">And</TOKEN>
<TOKEN id="token-112-1" pos="word" morph="none" start_char="9738" end_char="9741">then</TOKEN>
<TOKEN id="token-112-2" pos="word" morph="none" start_char="9743" end_char="9744">we</TOKEN>
<TOKEN id="token-112-3" pos="word" morph="none" start_char="9746" end_char="9749">have</TOKEN>
<TOKEN id="token-112-4" pos="word" morph="none" start_char="9751" end_char="9753">the</TOKEN>
<TOKEN id="token-112-5" pos="word" morph="none" start_char="9755" end_char="9762">articles</TOKEN>
<TOKEN id="token-112-6" pos="word" morph="none" start_char="9764" end_char="9765">on</TOKEN>
<TOKEN id="token-112-7" pos="word" morph="none" start_char="9767" end_char="9772">people</TOKEN>
<TOKEN id="token-112-8" pos="word" morph="none" start_char="9774" end_char="9780">working</TOKEN>
<TOKEN id="token-112-9" pos="word" morph="none" start_char="9782" end_char="9783">at</TOKEN>
<TOKEN id="token-112-10" pos="word" morph="none" start_char="9785" end_char="9787">the</TOKEN>
<TOKEN id="token-112-11" pos="word" morph="none" start_char="9789" end_char="9791">lab</TOKEN>
<TOKEN id="token-112-12" pos="word" morph="none" start_char="9793" end_char="9799">selling</TOKEN>
<TOKEN id="token-112-13" pos="word" morph="none" start_char="9801" end_char="9807">animals</TOKEN>
<TOKEN id="token-112-14" pos="word" morph="none" start_char="9809" end_char="9810">at</TOKEN>
<TOKEN id="token-112-15" pos="word" morph="none" start_char="9812" end_char="9815">food</TOKEN>
<TOKEN id="token-112-16" pos="word" morph="none" start_char="9817" end_char="9822">market</TOKEN>
<TOKEN id="token-112-17" pos="word" morph="none" start_char="9824" end_char="9830">instead</TOKEN>
<TOKEN id="token-112-18" pos="word" morph="none" start_char="9832" end_char="9833">of</TOKEN>
<TOKEN id="token-112-19" pos="word" morph="none" start_char="9835" end_char="9843">cremating</TOKEN>
<TOKEN id="token-112-20" pos="word" morph="none" start_char="9845" end_char="9848">them</TOKEN>
<TOKEN id="token-112-21" pos="punct" morph="none" start_char="9849" end_char="9849">.</TOKEN>
</SEG>
<SEG id="segment-113" start_char="9851" end_char="9870">
<ORIGINAL_TEXT>www.breitbart.com...</ORIGINAL_TEXT>
<TOKEN id="token-113-0" pos="url" morph="none" start_char="9851" end_char="9870">www.breitbart.com...</TOKEN>
</SEG>
<SEG id="segment-114" start_char="9875" end_char="9944">
<ORIGINAL_TEXT>originally posted by: hounddoghowlie please, a super market tabloid???</ORIGINAL_TEXT>
<TOKEN id="token-114-0" pos="word" morph="none" start_char="9875" end_char="9884">originally</TOKEN>
<TOKEN id="token-114-1" pos="word" morph="none" start_char="9886" end_char="9891">posted</TOKEN>
<TOKEN id="token-114-2" pos="word" morph="none" start_char="9893" end_char="9894">by</TOKEN>
<TOKEN id="token-114-3" pos="punct" morph="none" start_char="9895" end_char="9895">:</TOKEN>
<TOKEN id="token-114-4" pos="word" morph="none" start_char="9897" end_char="9910">hounddoghowlie</TOKEN>
<TOKEN id="token-114-5" pos="word" morph="none" start_char="9912" end_char="9917">please</TOKEN>
<TOKEN id="token-114-6" pos="punct" morph="none" start_char="9918" end_char="9918">,</TOKEN>
<TOKEN id="token-114-7" pos="word" morph="none" start_char="9920" end_char="9920">a</TOKEN>
<TOKEN id="token-114-8" pos="word" morph="none" start_char="9922" end_char="9926">super</TOKEN>
<TOKEN id="token-114-9" pos="word" morph="none" start_char="9928" end_char="9933">market</TOKEN>
<TOKEN id="token-114-10" pos="word" morph="none" start_char="9935" end_char="9941">tabloid</TOKEN>
<TOKEN id="token-114-11" pos="punct" morph="none" start_char="9942" end_char="9944">???</TOKEN>
</SEG>
<SEG id="segment-115" start_char="9947" end_char="10174">
<ORIGINAL_TEXT>To me it seems ironic how certain people seem to espouse the CCP propaganda about this story not being real when the article mentions the names of the Chinese scientists whom wrote this report, and a story the CCP tried to bury.</ORIGINAL_TEXT>
<TOKEN id="token-115-0" pos="word" morph="none" start_char="9947" end_char="9948">To</TOKEN>
<TOKEN id="token-115-1" pos="word" morph="none" start_char="9950" end_char="9951">me</TOKEN>
<TOKEN id="token-115-2" pos="word" morph="none" start_char="9953" end_char="9954">it</TOKEN>
<TOKEN id="token-115-3" pos="word" morph="none" start_char="9956" end_char="9960">seems</TOKEN>
<TOKEN id="token-115-4" pos="word" morph="none" start_char="9962" end_char="9967">ironic</TOKEN>
<TOKEN id="token-115-5" pos="word" morph="none" start_char="9969" end_char="9971">how</TOKEN>
<TOKEN id="token-115-6" pos="word" morph="none" start_char="9973" end_char="9979">certain</TOKEN>
<TOKEN id="token-115-7" pos="word" morph="none" start_char="9981" end_char="9986">people</TOKEN>
<TOKEN id="token-115-8" pos="word" morph="none" start_char="9988" end_char="9991">seem</TOKEN>
<TOKEN id="token-115-9" pos="word" morph="none" start_char="9993" end_char="9994">to</TOKEN>
<TOKEN id="token-115-10" pos="word" morph="none" start_char="9996" end_char="10002">espouse</TOKEN>
<TOKEN id="token-115-11" pos="word" morph="none" start_char="10004" end_char="10006">the</TOKEN>
<TOKEN id="token-115-12" pos="word" morph="none" start_char="10008" end_char="10010">CCP</TOKEN>
<TOKEN id="token-115-13" pos="word" morph="none" start_char="10012" end_char="10021">propaganda</TOKEN>
<TOKEN id="token-115-14" pos="word" morph="none" start_char="10023" end_char="10027">about</TOKEN>
<TOKEN id="token-115-15" pos="word" morph="none" start_char="10029" end_char="10032">this</TOKEN>
<TOKEN id="token-115-16" pos="word" morph="none" start_char="10034" end_char="10038">story</TOKEN>
<TOKEN id="token-115-17" pos="word" morph="none" start_char="10040" end_char="10042">not</TOKEN>
<TOKEN id="token-115-18" pos="word" morph="none" start_char="10044" end_char="10048">being</TOKEN>
<TOKEN id="token-115-19" pos="word" morph="none" start_char="10050" end_char="10053">real</TOKEN>
<TOKEN id="token-115-20" pos="word" morph="none" start_char="10055" end_char="10058">when</TOKEN>
<TOKEN id="token-115-21" pos="word" morph="none" start_char="10060" end_char="10062">the</TOKEN>
<TOKEN id="token-115-22" pos="word" morph="none" start_char="10064" end_char="10070">article</TOKEN>
<TOKEN id="token-115-23" pos="word" morph="none" start_char="10072" end_char="10079">mentions</TOKEN>
<TOKEN id="token-115-24" pos="word" morph="none" start_char="10081" end_char="10083">the</TOKEN>
<TOKEN id="token-115-25" pos="word" morph="none" start_char="10085" end_char="10089">names</TOKEN>
<TOKEN id="token-115-26" pos="word" morph="none" start_char="10091" end_char="10092">of</TOKEN>
<TOKEN id="token-115-27" pos="word" morph="none" start_char="10094" end_char="10096">the</TOKEN>
<TOKEN id="token-115-28" pos="word" morph="none" start_char="10098" end_char="10104">Chinese</TOKEN>
<TOKEN id="token-115-29" pos="word" morph="none" start_char="10106" end_char="10115">scientists</TOKEN>
<TOKEN id="token-115-30" pos="word" morph="none" start_char="10117" end_char="10120">whom</TOKEN>
<TOKEN id="token-115-31" pos="word" morph="none" start_char="10122" end_char="10126">wrote</TOKEN>
<TOKEN id="token-115-32" pos="word" morph="none" start_char="10128" end_char="10131">this</TOKEN>
<TOKEN id="token-115-33" pos="word" morph="none" start_char="10133" end_char="10138">report</TOKEN>
<TOKEN id="token-115-34" pos="punct" morph="none" start_char="10139" end_char="10139">,</TOKEN>
<TOKEN id="token-115-35" pos="word" morph="none" start_char="10141" end_char="10143">and</TOKEN>
<TOKEN id="token-115-36" pos="word" morph="none" start_char="10145" end_char="10145">a</TOKEN>
<TOKEN id="token-115-37" pos="word" morph="none" start_char="10147" end_char="10151">story</TOKEN>
<TOKEN id="token-115-38" pos="word" morph="none" start_char="10153" end_char="10155">the</TOKEN>
<TOKEN id="token-115-39" pos="word" morph="none" start_char="10157" end_char="10159">CCP</TOKEN>
<TOKEN id="token-115-40" pos="word" morph="none" start_char="10161" end_char="10165">tried</TOKEN>
<TOKEN id="token-115-41" pos="word" morph="none" start_char="10167" end_char="10168">to</TOKEN>
<TOKEN id="token-115-42" pos="word" morph="none" start_char="10170" end_char="10173">bury</TOKEN>
<TOKEN id="token-115-43" pos="punct" morph="none" start_char="10174" end_char="10174">.</TOKEN>
</SEG>
<SEG id="segment-116" start_char="10177" end_char="10328">
<ORIGINAL_TEXT>But anyways, here is an excerpt and link to the paper, which took me a while to find and wasn't possible for me to post last night for personal reasons.</ORIGINAL_TEXT>
<TOKEN id="token-116-0" pos="word" morph="none" start_char="10177" end_char="10179">But</TOKEN>
<TOKEN id="token-116-1" pos="word" morph="none" start_char="10181" end_char="10187">anyways</TOKEN>
<TOKEN id="token-116-2" pos="punct" morph="none" start_char="10188" end_char="10188">,</TOKEN>
<TOKEN id="token-116-3" pos="word" morph="none" start_char="10190" end_char="10193">here</TOKEN>
<TOKEN id="token-116-4" pos="word" morph="none" start_char="10195" end_char="10196">is</TOKEN>
<TOKEN id="token-116-5" pos="word" morph="none" start_char="10198" end_char="10199">an</TOKEN>
<TOKEN id="token-116-6" pos="word" morph="none" start_char="10201" end_char="10207">excerpt</TOKEN>
<TOKEN id="token-116-7" pos="word" morph="none" start_char="10209" end_char="10211">and</TOKEN>
<TOKEN id="token-116-8" pos="word" morph="none" start_char="10213" end_char="10216">link</TOKEN>
<TOKEN id="token-116-9" pos="word" morph="none" start_char="10218" end_char="10219">to</TOKEN>
<TOKEN id="token-116-10" pos="word" morph="none" start_char="10221" end_char="10223">the</TOKEN>
<TOKEN id="token-116-11" pos="word" morph="none" start_char="10225" end_char="10229">paper</TOKEN>
<TOKEN id="token-116-12" pos="punct" morph="none" start_char="10230" end_char="10230">,</TOKEN>
<TOKEN id="token-116-13" pos="word" morph="none" start_char="10232" end_char="10236">which</TOKEN>
<TOKEN id="token-116-14" pos="word" morph="none" start_char="10238" end_char="10241">took</TOKEN>
<TOKEN id="token-116-15" pos="word" morph="none" start_char="10243" end_char="10244">me</TOKEN>
<TOKEN id="token-116-16" pos="word" morph="none" start_char="10246" end_char="10246">a</TOKEN>
<TOKEN id="token-116-17" pos="word" morph="none" start_char="10248" end_char="10252">while</TOKEN>
<TOKEN id="token-116-18" pos="word" morph="none" start_char="10254" end_char="10255">to</TOKEN>
<TOKEN id="token-116-19" pos="word" morph="none" start_char="10257" end_char="10260">find</TOKEN>
<TOKEN id="token-116-20" pos="word" morph="none" start_char="10262" end_char="10264">and</TOKEN>
<TOKEN id="token-116-21" pos="word" morph="none" start_char="10266" end_char="10271">wasn't</TOKEN>
<TOKEN id="token-116-22" pos="word" morph="none" start_char="10273" end_char="10280">possible</TOKEN>
<TOKEN id="token-116-23" pos="word" morph="none" start_char="10282" end_char="10284">for</TOKEN>
<TOKEN id="token-116-24" pos="word" morph="none" start_char="10286" end_char="10287">me</TOKEN>
<TOKEN id="token-116-25" pos="word" morph="none" start_char="10289" end_char="10290">to</TOKEN>
<TOKEN id="token-116-26" pos="word" morph="none" start_char="10292" end_char="10295">post</TOKEN>
<TOKEN id="token-116-27" pos="word" morph="none" start_char="10297" end_char="10300">last</TOKEN>
<TOKEN id="token-116-28" pos="word" morph="none" start_char="10302" end_char="10306">night</TOKEN>
<TOKEN id="token-116-29" pos="word" morph="none" start_char="10308" end_char="10310">for</TOKEN>
<TOKEN id="token-116-30" pos="word" morph="none" start_char="10312" end_char="10319">personal</TOKEN>
<TOKEN id="token-116-31" pos="word" morph="none" start_char="10321" end_char="10327">reasons</TOKEN>
<TOKEN id="token-116-32" pos="punct" morph="none" start_char="10328" end_char="10328">.</TOKEN>
</SEG>
<SEG id="segment-117" start_char="10331" end_char="10585">
<ORIGINAL_TEXT>The article even states that the CCP buried this story when it came out, but thankfully we have archives that shine the truth about stories, and the attempts of dictatorships like China, in doing everything they can to stop the truth from ever coming out.</ORIGINAL_TEXT>
<TOKEN id="token-117-0" pos="word" morph="none" start_char="10331" end_char="10333">The</TOKEN>
<TOKEN id="token-117-1" pos="word" morph="none" start_char="10335" end_char="10341">article</TOKEN>
<TOKEN id="token-117-2" pos="word" morph="none" start_char="10343" end_char="10346">even</TOKEN>
<TOKEN id="token-117-3" pos="word" morph="none" start_char="10348" end_char="10353">states</TOKEN>
<TOKEN id="token-117-4" pos="word" morph="none" start_char="10355" end_char="10358">that</TOKEN>
<TOKEN id="token-117-5" pos="word" morph="none" start_char="10360" end_char="10362">the</TOKEN>
<TOKEN id="token-117-6" pos="word" morph="none" start_char="10364" end_char="10366">CCP</TOKEN>
<TOKEN id="token-117-7" pos="word" morph="none" start_char="10368" end_char="10373">buried</TOKEN>
<TOKEN id="token-117-8" pos="word" morph="none" start_char="10375" end_char="10378">this</TOKEN>
<TOKEN id="token-117-9" pos="word" morph="none" start_char="10380" end_char="10384">story</TOKEN>
<TOKEN id="token-117-10" pos="word" morph="none" start_char="10386" end_char="10389">when</TOKEN>
<TOKEN id="token-117-11" pos="word" morph="none" start_char="10391" end_char="10392">it</TOKEN>
<TOKEN id="token-117-12" pos="word" morph="none" start_char="10394" end_char="10397">came</TOKEN>
<TOKEN id="token-117-13" pos="word" morph="none" start_char="10399" end_char="10401">out</TOKEN>
<TOKEN id="token-117-14" pos="punct" morph="none" start_char="10402" end_char="10402">,</TOKEN>
<TOKEN id="token-117-15" pos="word" morph="none" start_char="10404" end_char="10406">but</TOKEN>
<TOKEN id="token-117-16" pos="word" morph="none" start_char="10408" end_char="10417">thankfully</TOKEN>
<TOKEN id="token-117-17" pos="word" morph="none" start_char="10419" end_char="10420">we</TOKEN>
<TOKEN id="token-117-18" pos="word" morph="none" start_char="10422" end_char="10425">have</TOKEN>
<TOKEN id="token-117-19" pos="word" morph="none" start_char="10427" end_char="10434">archives</TOKEN>
<TOKEN id="token-117-20" pos="word" morph="none" start_char="10436" end_char="10439">that</TOKEN>
<TOKEN id="token-117-21" pos="word" morph="none" start_char="10441" end_char="10445">shine</TOKEN>
<TOKEN id="token-117-22" pos="word" morph="none" start_char="10447" end_char="10449">the</TOKEN>
<TOKEN id="token-117-23" pos="word" morph="none" start_char="10451" end_char="10455">truth</TOKEN>
<TOKEN id="token-117-24" pos="word" morph="none" start_char="10457" end_char="10461">about</TOKEN>
<TOKEN id="token-117-25" pos="word" morph="none" start_char="10463" end_char="10469">stories</TOKEN>
<TOKEN id="token-117-26" pos="punct" morph="none" start_char="10470" end_char="10470">,</TOKEN>
<TOKEN id="token-117-27" pos="word" morph="none" start_char="10472" end_char="10474">and</TOKEN>
<TOKEN id="token-117-28" pos="word" morph="none" start_char="10476" end_char="10478">the</TOKEN>
<TOKEN id="token-117-29" pos="word" morph="none" start_char="10480" end_char="10487">attempts</TOKEN>
<TOKEN id="token-117-30" pos="word" morph="none" start_char="10489" end_char="10490">of</TOKEN>
<TOKEN id="token-117-31" pos="word" morph="none" start_char="10492" end_char="10504">dictatorships</TOKEN>
<TOKEN id="token-117-32" pos="word" morph="none" start_char="10506" end_char="10509">like</TOKEN>
<TOKEN id="token-117-33" pos="word" morph="none" start_char="10511" end_char="10515">China</TOKEN>
<TOKEN id="token-117-34" pos="punct" morph="none" start_char="10516" end_char="10516">,</TOKEN>
<TOKEN id="token-117-35" pos="word" morph="none" start_char="10518" end_char="10519">in</TOKEN>
<TOKEN id="token-117-36" pos="word" morph="none" start_char="10521" end_char="10525">doing</TOKEN>
<TOKEN id="token-117-37" pos="word" morph="none" start_char="10527" end_char="10536">everything</TOKEN>
<TOKEN id="token-117-38" pos="word" morph="none" start_char="10538" end_char="10541">they</TOKEN>
<TOKEN id="token-117-39" pos="word" morph="none" start_char="10543" end_char="10545">can</TOKEN>
<TOKEN id="token-117-40" pos="word" morph="none" start_char="10547" end_char="10548">to</TOKEN>
<TOKEN id="token-117-41" pos="word" morph="none" start_char="10550" end_char="10553">stop</TOKEN>
<TOKEN id="token-117-42" pos="word" morph="none" start_char="10555" end_char="10557">the</TOKEN>
<TOKEN id="token-117-43" pos="word" morph="none" start_char="10559" end_char="10563">truth</TOKEN>
<TOKEN id="token-117-44" pos="word" morph="none" start_char="10565" end_char="10568">from</TOKEN>
<TOKEN id="token-117-45" pos="word" morph="none" start_char="10570" end_char="10573">ever</TOKEN>
<TOKEN id="token-117-46" pos="word" morph="none" start_char="10575" end_char="10580">coming</TOKEN>
<TOKEN id="token-117-47" pos="word" morph="none" start_char="10582" end_char="10584">out</TOKEN>
<TOKEN id="token-117-48" pos="punct" morph="none" start_char="10585" end_char="10585">.</TOKEN>
</SEG>
<SEG id="segment-118" start_char="10588" end_char="10882">
<ORIGINAL_TEXT>The possible origins of 2019-nCoV coronavirus Preprint (PDF Available)  February 2020 with 547 Reads DOI: 10.13140/RG.2.2.21799.29601 Cite this publication The 2019-nCoV has caused an epidemic of 28,060 laboratory-confirmed infections in human including 564 deaths in China by February 6, 2020.</ORIGINAL_TEXT>
<TOKEN id="token-118-0" pos="word" morph="none" start_char="10588" end_char="10590">The</TOKEN>
<TOKEN id="token-118-1" pos="word" morph="none" start_char="10592" end_char="10599">possible</TOKEN>
<TOKEN id="token-118-2" pos="word" morph="none" start_char="10601" end_char="10607">origins</TOKEN>
<TOKEN id="token-118-3" pos="word" morph="none" start_char="10609" end_char="10610">of</TOKEN>
<TOKEN id="token-118-4" pos="unknown" morph="none" start_char="10612" end_char="10620">2019-nCoV</TOKEN>
<TOKEN id="token-118-5" pos="word" morph="none" start_char="10622" end_char="10632">coronavirus</TOKEN>
<TOKEN id="token-118-6" pos="word" morph="none" start_char="10634" end_char="10641">Preprint</TOKEN>
<TOKEN id="token-118-7" pos="punct" morph="none" start_char="10643" end_char="10643">(</TOKEN>
<TOKEN id="token-118-8" pos="word" morph="none" start_char="10644" end_char="10646">PDF</TOKEN>
<TOKEN id="token-118-9" pos="word" morph="none" start_char="10648" end_char="10656">Available</TOKEN>
<TOKEN id="token-118-10" pos="punct" morph="none" start_char="10657" end_char="10657">)</TOKEN>
<TOKEN id="token-118-11" pos="punct" morph="none" start_char="10659" end_char="10659"></TOKEN>
<TOKEN id="token-118-12" pos="word" morph="none" start_char="10661" end_char="10668">February</TOKEN>
<TOKEN id="token-118-13" pos="word" morph="none" start_char="10670" end_char="10673">2020</TOKEN>
<TOKEN id="token-118-14" pos="word" morph="none" start_char="10675" end_char="10678">with</TOKEN>
<TOKEN id="token-118-15" pos="word" morph="none" start_char="10680" end_char="10682">547</TOKEN>
<TOKEN id="token-118-16" pos="word" morph="none" start_char="10684" end_char="10688">Reads</TOKEN>
<TOKEN id="token-118-17" pos="word" morph="none" start_char="10690" end_char="10692">DOI</TOKEN>
<TOKEN id="token-118-18" pos="punct" morph="none" start_char="10693" end_char="10693">:</TOKEN>
<TOKEN id="token-118-19" pos="unknown" morph="none" start_char="10695" end_char="10721">10.13140/RG.2.2.21799.29601</TOKEN>
<TOKEN id="token-118-20" pos="word" morph="none" start_char="10723" end_char="10726">Cite</TOKEN>
<TOKEN id="token-118-21" pos="word" morph="none" start_char="10728" end_char="10731">this</TOKEN>
<TOKEN id="token-118-22" pos="word" morph="none" start_char="10733" end_char="10743">publication</TOKEN>
<TOKEN id="token-118-23" pos="word" morph="none" start_char="10745" end_char="10747">The</TOKEN>
<TOKEN id="token-118-24" pos="unknown" morph="none" start_char="10749" end_char="10757">2019-nCoV</TOKEN>
<TOKEN id="token-118-25" pos="word" morph="none" start_char="10759" end_char="10761">has</TOKEN>
<TOKEN id="token-118-26" pos="word" morph="none" start_char="10763" end_char="10768">caused</TOKEN>
<TOKEN id="token-118-27" pos="word" morph="none" start_char="10770" end_char="10771">an</TOKEN>
<TOKEN id="token-118-28" pos="word" morph="none" start_char="10773" end_char="10780">epidemic</TOKEN>
<TOKEN id="token-118-29" pos="word" morph="none" start_char="10782" end_char="10783">of</TOKEN>
<TOKEN id="token-118-30" pos="unknown" morph="none" start_char="10785" end_char="10790">28,060</TOKEN>
<TOKEN id="token-118-31" pos="unknown" morph="none" start_char="10792" end_char="10811">laboratory-confirmed</TOKEN>
<TOKEN id="token-118-32" pos="word" morph="none" start_char="10813" end_char="10822">infections</TOKEN>
<TOKEN id="token-118-33" pos="word" morph="none" start_char="10824" end_char="10825">in</TOKEN>
<TOKEN id="token-118-34" pos="word" morph="none" start_char="10827" end_char="10831">human</TOKEN>
<TOKEN id="token-118-35" pos="word" morph="none" start_char="10833" end_char="10841">including</TOKEN>
<TOKEN id="token-118-36" pos="word" morph="none" start_char="10843" end_char="10845">564</TOKEN>
<TOKEN id="token-118-37" pos="word" morph="none" start_char="10847" end_char="10852">deaths</TOKEN>
<TOKEN id="token-118-38" pos="word" morph="none" start_char="10854" end_char="10855">in</TOKEN>
<TOKEN id="token-118-39" pos="word" morph="none" start_char="10857" end_char="10861">China</TOKEN>
<TOKEN id="token-118-40" pos="word" morph="none" start_char="10863" end_char="10864">by</TOKEN>
<TOKEN id="token-118-41" pos="word" morph="none" start_char="10866" end_char="10873">February</TOKEN>
<TOKEN id="token-118-42" pos="word" morph="none" start_char="10875" end_char="10875">6</TOKEN>
<TOKEN id="token-118-43" pos="punct" morph="none" start_char="10876" end_char="10876">,</TOKEN>
<TOKEN id="token-118-44" pos="word" morph="none" start_char="10878" end_char="10881">2020</TOKEN>
<TOKEN id="token-118-45" pos="punct" morph="none" start_char="10882" end_char="10882">.</TOKEN>
</SEG>
<SEG id="segment-119" start_char="10884" end_char="11047">
<ORIGINAL_TEXT>Two descriptions of the virus published on Nature this week indicated that the genome sequences from patients were almost identical to the Bat CoV ZC45 coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-119-0" pos="word" morph="none" start_char="10884" end_char="10886">Two</TOKEN>
<TOKEN id="token-119-1" pos="word" morph="none" start_char="10888" end_char="10899">descriptions</TOKEN>
<TOKEN id="token-119-2" pos="word" morph="none" start_char="10901" end_char="10902">of</TOKEN>
<TOKEN id="token-119-3" pos="word" morph="none" start_char="10904" end_char="10906">the</TOKEN>
<TOKEN id="token-119-4" pos="word" morph="none" start_char="10908" end_char="10912">virus</TOKEN>
<TOKEN id="token-119-5" pos="word" morph="none" start_char="10914" end_char="10922">published</TOKEN>
<TOKEN id="token-119-6" pos="word" morph="none" start_char="10924" end_char="10925">on</TOKEN>
<TOKEN id="token-119-7" pos="word" morph="none" start_char="10927" end_char="10932">Nature</TOKEN>
<TOKEN id="token-119-8" pos="word" morph="none" start_char="10934" end_char="10937">this</TOKEN>
<TOKEN id="token-119-9" pos="word" morph="none" start_char="10939" end_char="10942">week</TOKEN>
<TOKEN id="token-119-10" pos="word" morph="none" start_char="10944" end_char="10952">indicated</TOKEN>
<TOKEN id="token-119-11" pos="word" morph="none" start_char="10954" end_char="10957">that</TOKEN>
<TOKEN id="token-119-12" pos="word" morph="none" start_char="10959" end_char="10961">the</TOKEN>
<TOKEN id="token-119-13" pos="word" morph="none" start_char="10963" end_char="10968">genome</TOKEN>
<TOKEN id="token-119-14" pos="word" morph="none" start_char="10970" end_char="10978">sequences</TOKEN>
<TOKEN id="token-119-15" pos="word" morph="none" start_char="10980" end_char="10983">from</TOKEN>
<TOKEN id="token-119-16" pos="word" morph="none" start_char="10985" end_char="10992">patients</TOKEN>
<TOKEN id="token-119-17" pos="word" morph="none" start_char="10994" end_char="10997">were</TOKEN>
<TOKEN id="token-119-18" pos="word" morph="none" start_char="10999" end_char="11004">almost</TOKEN>
<TOKEN id="token-119-19" pos="word" morph="none" start_char="11006" end_char="11014">identical</TOKEN>
<TOKEN id="token-119-20" pos="word" morph="none" start_char="11016" end_char="11017">to</TOKEN>
<TOKEN id="token-119-21" pos="word" morph="none" start_char="11019" end_char="11021">the</TOKEN>
<TOKEN id="token-119-22" pos="word" morph="none" start_char="11023" end_char="11025">Bat</TOKEN>
<TOKEN id="token-119-23" pos="word" morph="none" start_char="11027" end_char="11029">CoV</TOKEN>
<TOKEN id="token-119-24" pos="word" morph="none" start_char="11031" end_char="11034">ZC45</TOKEN>
<TOKEN id="token-119-25" pos="word" morph="none" start_char="11036" end_char="11046">coronavirus</TOKEN>
<TOKEN id="token-119-26" pos="punct" morph="none" start_char="11047" end_char="11047">.</TOKEN>
</SEG>
<SEG id="segment-120" start_char="11049" end_char="11131">
<ORIGINAL_TEXT>It was critical to study where the pathogen came from and how it passed onto human.</ORIGINAL_TEXT>
<TOKEN id="token-120-0" pos="word" morph="none" start_char="11049" end_char="11050">It</TOKEN>
<TOKEN id="token-120-1" pos="word" morph="none" start_char="11052" end_char="11054">was</TOKEN>
<TOKEN id="token-120-2" pos="word" morph="none" start_char="11056" end_char="11063">critical</TOKEN>
<TOKEN id="token-120-3" pos="word" morph="none" start_char="11065" end_char="11066">to</TOKEN>
<TOKEN id="token-120-4" pos="word" morph="none" start_char="11068" end_char="11072">study</TOKEN>
<TOKEN id="token-120-5" pos="word" morph="none" start_char="11074" end_char="11078">where</TOKEN>
<TOKEN id="token-120-6" pos="word" morph="none" start_char="11080" end_char="11082">the</TOKEN>
<TOKEN id="token-120-7" pos="word" morph="none" start_char="11084" end_char="11091">pathogen</TOKEN>
<TOKEN id="token-120-8" pos="word" morph="none" start_char="11093" end_char="11096">came</TOKEN>
<TOKEN id="token-120-9" pos="word" morph="none" start_char="11098" end_char="11101">from</TOKEN>
<TOKEN id="token-120-10" pos="word" morph="none" start_char="11103" end_char="11105">and</TOKEN>
<TOKEN id="token-120-11" pos="word" morph="none" start_char="11107" end_char="11109">how</TOKEN>
<TOKEN id="token-120-12" pos="word" morph="none" start_char="11111" end_char="11112">it</TOKEN>
<TOKEN id="token-120-13" pos="word" morph="none" start_char="11114" end_char="11119">passed</TOKEN>
<TOKEN id="token-120-14" pos="word" morph="none" start_char="11121" end_char="11124">onto</TOKEN>
<TOKEN id="token-120-15" pos="word" morph="none" start_char="11126" end_char="11130">human</TOKEN>
<TOKEN id="token-120-16" pos="punct" morph="none" start_char="11131" end_char="11131">.</TOKEN>
</SEG>
<SEG id="segment-121" start_char="11133" end_char="11275">
<ORIGINAL_TEXT>An article published on The Lancet reported that 27 of 41 infected patients were found to have contact with the Huanan Seafood Market in Wuhan.</ORIGINAL_TEXT>
<TOKEN id="token-121-0" pos="word" morph="none" start_char="11133" end_char="11134">An</TOKEN>
<TOKEN id="token-121-1" pos="word" morph="none" start_char="11136" end_char="11142">article</TOKEN>
<TOKEN id="token-121-2" pos="word" morph="none" start_char="11144" end_char="11152">published</TOKEN>
<TOKEN id="token-121-3" pos="word" morph="none" start_char="11154" end_char="11155">on</TOKEN>
<TOKEN id="token-121-4" pos="word" morph="none" start_char="11157" end_char="11159">The</TOKEN>
<TOKEN id="token-121-5" pos="word" morph="none" start_char="11161" end_char="11166">Lancet</TOKEN>
<TOKEN id="token-121-6" pos="word" morph="none" start_char="11168" end_char="11175">reported</TOKEN>
<TOKEN id="token-121-7" pos="word" morph="none" start_char="11177" end_char="11180">that</TOKEN>
<TOKEN id="token-121-8" pos="word" morph="none" start_char="11182" end_char="11183">27</TOKEN>
<TOKEN id="token-121-9" pos="word" morph="none" start_char="11185" end_char="11186">of</TOKEN>
<TOKEN id="token-121-10" pos="word" morph="none" start_char="11188" end_char="11189">41</TOKEN>
<TOKEN id="token-121-11" pos="word" morph="none" start_char="11191" end_char="11198">infected</TOKEN>
<TOKEN id="token-121-12" pos="word" morph="none" start_char="11200" end_char="11207">patients</TOKEN>
<TOKEN id="token-121-13" pos="word" morph="none" start_char="11209" end_char="11212">were</TOKEN>
<TOKEN id="token-121-14" pos="word" morph="none" start_char="11214" end_char="11218">found</TOKEN>
<TOKEN id="token-121-15" pos="word" morph="none" start_char="11220" end_char="11221">to</TOKEN>
<TOKEN id="token-121-16" pos="word" morph="none" start_char="11223" end_char="11226">have</TOKEN>
<TOKEN id="token-121-17" pos="word" morph="none" start_char="11228" end_char="11234">contact</TOKEN>
<TOKEN id="token-121-18" pos="word" morph="none" start_char="11236" end_char="11239">with</TOKEN>
<TOKEN id="token-121-19" pos="word" morph="none" start_char="11241" end_char="11243">the</TOKEN>
<TOKEN id="token-121-20" pos="word" morph="none" start_char="11245" end_char="11250">Huanan</TOKEN>
<TOKEN id="token-121-21" pos="word" morph="none" start_char="11252" end_char="11258">Seafood</TOKEN>
<TOKEN id="token-121-22" pos="word" morph="none" start_char="11260" end_char="11265">Market</TOKEN>
<TOKEN id="token-121-23" pos="word" morph="none" start_char="11267" end_char="11268">in</TOKEN>
<TOKEN id="token-121-24" pos="word" morph="none" start_char="11270" end_char="11274">Wuhan</TOKEN>
<TOKEN id="token-121-25" pos="punct" morph="none" start_char="11275" end_char="11275">.</TOKEN>
</SEG>
<SEG id="segment-122" start_char="11277" end_char="11408">
<ORIGINAL_TEXT>We noted two laboratories conducting research on bat coronavirus in Wuhan, one of which was only 280 meters from the seafood market.</ORIGINAL_TEXT>
<TOKEN id="token-122-0" pos="word" morph="none" start_char="11277" end_char="11278">We</TOKEN>
<TOKEN id="token-122-1" pos="word" morph="none" start_char="11280" end_char="11284">noted</TOKEN>
<TOKEN id="token-122-2" pos="word" morph="none" start_char="11286" end_char="11288">two</TOKEN>
<TOKEN id="token-122-3" pos="word" morph="none" start_char="11290" end_char="11301">laboratories</TOKEN>
<TOKEN id="token-122-4" pos="word" morph="none" start_char="11303" end_char="11312">conducting</TOKEN>
<TOKEN id="token-122-5" pos="word" morph="none" start_char="11314" end_char="11321">research</TOKEN>
<TOKEN id="token-122-6" pos="word" morph="none" start_char="11323" end_char="11324">on</TOKEN>
<TOKEN id="token-122-7" pos="word" morph="none" start_char="11326" end_char="11328">bat</TOKEN>
<TOKEN id="token-122-8" pos="word" morph="none" start_char="11330" end_char="11340">coronavirus</TOKEN>
<TOKEN id="token-122-9" pos="word" morph="none" start_char="11342" end_char="11343">in</TOKEN>
<TOKEN id="token-122-10" pos="word" morph="none" start_char="11345" end_char="11349">Wuhan</TOKEN>
<TOKEN id="token-122-11" pos="punct" morph="none" start_char="11350" end_char="11350">,</TOKEN>
<TOKEN id="token-122-12" pos="word" morph="none" start_char="11352" end_char="11354">one</TOKEN>
<TOKEN id="token-122-13" pos="word" morph="none" start_char="11356" end_char="11357">of</TOKEN>
<TOKEN id="token-122-14" pos="word" morph="none" start_char="11359" end_char="11363">which</TOKEN>
<TOKEN id="token-122-15" pos="word" morph="none" start_char="11365" end_char="11367">was</TOKEN>
<TOKEN id="token-122-16" pos="word" morph="none" start_char="11369" end_char="11372">only</TOKEN>
<TOKEN id="token-122-17" pos="word" morph="none" start_char="11374" end_char="11376">280</TOKEN>
<TOKEN id="token-122-18" pos="word" morph="none" start_char="11378" end_char="11383">meters</TOKEN>
<TOKEN id="token-122-19" pos="word" morph="none" start_char="11385" end_char="11388">from</TOKEN>
<TOKEN id="token-122-20" pos="word" morph="none" start_char="11390" end_char="11392">the</TOKEN>
<TOKEN id="token-122-21" pos="word" morph="none" start_char="11394" end_char="11400">seafood</TOKEN>
<TOKEN id="token-122-22" pos="word" morph="none" start_char="11402" end_char="11407">market</TOKEN>
<TOKEN id="token-122-23" pos="punct" morph="none" start_char="11408" end_char="11408">.</TOKEN>
</SEG>
<SEG id="segment-123" start_char="11410" end_char="11535">
<ORIGINAL_TEXT>We briefly examined the histories of the laboratories and proposed that the coronavirus probably originated from a laboratory.</ORIGINAL_TEXT>
<TOKEN id="token-123-0" pos="word" morph="none" start_char="11410" end_char="11411">We</TOKEN>
<TOKEN id="token-123-1" pos="word" morph="none" start_char="11413" end_char="11419">briefly</TOKEN>
<TOKEN id="token-123-2" pos="word" morph="none" start_char="11421" end_char="11428">examined</TOKEN>
<TOKEN id="token-123-3" pos="word" morph="none" start_char="11430" end_char="11432">the</TOKEN>
<TOKEN id="token-123-4" pos="word" morph="none" start_char="11434" end_char="11442">histories</TOKEN>
<TOKEN id="token-123-5" pos="word" morph="none" start_char="11444" end_char="11445">of</TOKEN>
<TOKEN id="token-123-6" pos="word" morph="none" start_char="11447" end_char="11449">the</TOKEN>
<TOKEN id="token-123-7" pos="word" morph="none" start_char="11451" end_char="11462">laboratories</TOKEN>
<TOKEN id="token-123-8" pos="word" morph="none" start_char="11464" end_char="11466">and</TOKEN>
<TOKEN id="token-123-9" pos="word" morph="none" start_char="11468" end_char="11475">proposed</TOKEN>
<TOKEN id="token-123-10" pos="word" morph="none" start_char="11477" end_char="11480">that</TOKEN>
<TOKEN id="token-123-11" pos="word" morph="none" start_char="11482" end_char="11484">the</TOKEN>
<TOKEN id="token-123-12" pos="word" morph="none" start_char="11486" end_char="11496">coronavirus</TOKEN>
<TOKEN id="token-123-13" pos="word" morph="none" start_char="11498" end_char="11505">probably</TOKEN>
<TOKEN id="token-123-14" pos="word" morph="none" start_char="11507" end_char="11516">originated</TOKEN>
<TOKEN id="token-123-15" pos="word" morph="none" start_char="11518" end_char="11521">from</TOKEN>
<TOKEN id="token-123-16" pos="word" morph="none" start_char="11523" end_char="11523">a</TOKEN>
<TOKEN id="token-123-17" pos="word" morph="none" start_char="11525" end_char="11534">laboratory</TOKEN>
<TOKEN id="token-123-18" pos="punct" morph="none" start_char="11535" end_char="11535">.</TOKEN>
</SEG>
<SEG id="segment-124" start_char="11537" end_char="11658">
<ORIGINAL_TEXT>Our proposal provided an alternative origin of the coronavirus in addition to natural recombination and intermediate host.</ORIGINAL_TEXT>
<TOKEN id="token-124-0" pos="word" morph="none" start_char="11537" end_char="11539">Our</TOKEN>
<TOKEN id="token-124-1" pos="word" morph="none" start_char="11541" end_char="11548">proposal</TOKEN>
<TOKEN id="token-124-2" pos="word" morph="none" start_char="11550" end_char="11557">provided</TOKEN>
<TOKEN id="token-124-3" pos="word" morph="none" start_char="11559" end_char="11560">an</TOKEN>
<TOKEN id="token-124-4" pos="word" morph="none" start_char="11562" end_char="11572">alternative</TOKEN>
<TOKEN id="token-124-5" pos="word" morph="none" start_char="11574" end_char="11579">origin</TOKEN>
<TOKEN id="token-124-6" pos="word" morph="none" start_char="11581" end_char="11582">of</TOKEN>
<TOKEN id="token-124-7" pos="word" morph="none" start_char="11584" end_char="11586">the</TOKEN>
<TOKEN id="token-124-8" pos="word" morph="none" start_char="11588" end_char="11598">coronavirus</TOKEN>
<TOKEN id="token-124-9" pos="word" morph="none" start_char="11600" end_char="11601">in</TOKEN>
<TOKEN id="token-124-10" pos="word" morph="none" start_char="11603" end_char="11610">addition</TOKEN>
<TOKEN id="token-124-11" pos="word" morph="none" start_char="11612" end_char="11613">to</TOKEN>
<TOKEN id="token-124-12" pos="word" morph="none" start_char="11615" end_char="11621">natural</TOKEN>
<TOKEN id="token-124-13" pos="word" morph="none" start_char="11623" end_char="11635">recombination</TOKEN>
<TOKEN id="token-124-14" pos="word" morph="none" start_char="11637" end_char="11639">and</TOKEN>
<TOKEN id="token-124-15" pos="word" morph="none" start_char="11641" end_char="11652">intermediate</TOKEN>
<TOKEN id="token-124-16" pos="word" morph="none" start_char="11654" end_char="11657">host</TOKEN>
<TOKEN id="token-124-17" pos="punct" morph="none" start_char="11658" end_char="11658">.</TOKEN>
</SEG>
<SEG id="segment-125" start_char="11661" end_char="11769">
<ORIGINAL_TEXT>web.archive.org...://www.researchgate.net/publication/339070128_The_possible_origins_of_2019-nCoV_coronavirus</ORIGINAL_TEXT>
<TOKEN id="token-125-0" pos="unknown" morph="none" start_char="11661" end_char="11769">web.archive.org...://www.researchgate.net/publication/339070128_The_possible_origins_of_2019-nCoV_coronavirus</TOKEN>
</SEG>
<SEG id="segment-126" start_char="11772" end_char="11809">
<ORIGINAL_TEXT>(For some reason i can't fix the link.</ORIGINAL_TEXT>
<TOKEN id="token-126-0" pos="punct" morph="none" start_char="11772" end_char="11772">(</TOKEN>
<TOKEN id="token-126-1" pos="word" morph="none" start_char="11773" end_char="11775">For</TOKEN>
<TOKEN id="token-126-2" pos="word" morph="none" start_char="11777" end_char="11780">some</TOKEN>
<TOKEN id="token-126-3" pos="word" morph="none" start_char="11782" end_char="11787">reason</TOKEN>
<TOKEN id="token-126-4" pos="word" morph="none" start_char="11789" end_char="11789">i</TOKEN>
<TOKEN id="token-126-5" pos="word" morph="none" start_char="11791" end_char="11795">can't</TOKEN>
<TOKEN id="token-126-6" pos="word" morph="none" start_char="11797" end_char="11799">fix</TOKEN>
<TOKEN id="token-126-7" pos="word" morph="none" start_char="11801" end_char="11803">the</TOKEN>
<TOKEN id="token-126-8" pos="word" morph="none" start_char="11805" end_char="11808">link</TOKEN>
<TOKEN id="token-126-9" pos="punct" morph="none" start_char="11809" end_char="11809">.</TOKEN>
</SEG>
<SEG id="segment-127" start_char="11811" end_char="11920">
<ORIGINAL_TEXT>To find the link, which has another link to the entire paper, just copy the url and paste it in a new window.)</ORIGINAL_TEXT>
<TOKEN id="token-127-0" pos="word" morph="none" start_char="11811" end_char="11812">To</TOKEN>
<TOKEN id="token-127-1" pos="word" morph="none" start_char="11814" end_char="11817">find</TOKEN>
<TOKEN id="token-127-2" pos="word" morph="none" start_char="11819" end_char="11821">the</TOKEN>
<TOKEN id="token-127-3" pos="word" morph="none" start_char="11823" end_char="11826">link</TOKEN>
<TOKEN id="token-127-4" pos="punct" morph="none" start_char="11827" end_char="11827">,</TOKEN>
<TOKEN id="token-127-5" pos="word" morph="none" start_char="11829" end_char="11833">which</TOKEN>
<TOKEN id="token-127-6" pos="word" morph="none" start_char="11835" end_char="11837">has</TOKEN>
<TOKEN id="token-127-7" pos="word" morph="none" start_char="11839" end_char="11845">another</TOKEN>
<TOKEN id="token-127-8" pos="word" morph="none" start_char="11847" end_char="11850">link</TOKEN>
<TOKEN id="token-127-9" pos="word" morph="none" start_char="11852" end_char="11853">to</TOKEN>
<TOKEN id="token-127-10" pos="word" morph="none" start_char="11855" end_char="11857">the</TOKEN>
<TOKEN id="token-127-11" pos="word" morph="none" start_char="11859" end_char="11864">entire</TOKEN>
<TOKEN id="token-127-12" pos="word" morph="none" start_char="11866" end_char="11870">paper</TOKEN>
<TOKEN id="token-127-13" pos="punct" morph="none" start_char="11871" end_char="11871">,</TOKEN>
<TOKEN id="token-127-14" pos="word" morph="none" start_char="11873" end_char="11876">just</TOKEN>
<TOKEN id="token-127-15" pos="word" morph="none" start_char="11878" end_char="11881">copy</TOKEN>
<TOKEN id="token-127-16" pos="word" morph="none" start_char="11883" end_char="11885">the</TOKEN>
<TOKEN id="token-127-17" pos="word" morph="none" start_char="11887" end_char="11889">url</TOKEN>
<TOKEN id="token-127-18" pos="word" morph="none" start_char="11891" end_char="11893">and</TOKEN>
<TOKEN id="token-127-19" pos="word" morph="none" start_char="11895" end_char="11899">paste</TOKEN>
<TOKEN id="token-127-20" pos="word" morph="none" start_char="11901" end_char="11902">it</TOKEN>
<TOKEN id="token-127-21" pos="word" morph="none" start_char="11904" end_char="11905">in</TOKEN>
<TOKEN id="token-127-22" pos="word" morph="none" start_char="11907" end_char="11907">a</TOKEN>
<TOKEN id="token-127-23" pos="word" morph="none" start_char="11909" end_char="11911">new</TOKEN>
<TOKEN id="token-127-24" pos="word" morph="none" start_char="11913" end_char="11918">window</TOKEN>
<TOKEN id="token-127-25" pos="punct" morph="none" start_char="11919" end_char="11920">.)</TOKEN>
</SEG>
<SEG id="segment-128" start_char="11923" end_char="12048">
<ORIGINAL_TEXT>BTW, the Chinese government attempted to claim that the "U.S. military released this virus in Wuhan," which of course it's BS.</ORIGINAL_TEXT>
<TOKEN id="token-128-0" pos="word" morph="none" start_char="11923" end_char="11925">BTW</TOKEN>
<TOKEN id="token-128-1" pos="punct" morph="none" start_char="11926" end_char="11926">,</TOKEN>
<TOKEN id="token-128-2" pos="word" morph="none" start_char="11928" end_char="11930">the</TOKEN>
<TOKEN id="token-128-3" pos="word" morph="none" start_char="11932" end_char="11938">Chinese</TOKEN>
<TOKEN id="token-128-4" pos="word" morph="none" start_char="11940" end_char="11949">government</TOKEN>
<TOKEN id="token-128-5" pos="word" morph="none" start_char="11951" end_char="11959">attempted</TOKEN>
<TOKEN id="token-128-6" pos="word" morph="none" start_char="11961" end_char="11962">to</TOKEN>
<TOKEN id="token-128-7" pos="word" morph="none" start_char="11964" end_char="11968">claim</TOKEN>
<TOKEN id="token-128-8" pos="word" morph="none" start_char="11970" end_char="11973">that</TOKEN>
<TOKEN id="token-128-9" pos="word" morph="none" start_char="11975" end_char="11977">the</TOKEN>
<TOKEN id="token-128-10" pos="punct" morph="none" start_char="11979" end_char="11979">"</TOKEN>
<TOKEN id="token-128-11" pos="unknown" morph="none" start_char="11980" end_char="11982">U.S</TOKEN>
<TOKEN id="token-128-12" pos="punct" morph="none" start_char="11983" end_char="11983">.</TOKEN>
<TOKEN id="token-128-13" pos="word" morph="none" start_char="11985" end_char="11992">military</TOKEN>
<TOKEN id="token-128-14" pos="word" morph="none" start_char="11994" end_char="12001">released</TOKEN>
<TOKEN id="token-128-15" pos="word" morph="none" start_char="12003" end_char="12006">this</TOKEN>
<TOKEN id="token-128-16" pos="word" morph="none" start_char="12008" end_char="12012">virus</TOKEN>
<TOKEN id="token-128-17" pos="word" morph="none" start_char="12014" end_char="12015">in</TOKEN>
<TOKEN id="token-128-18" pos="word" morph="none" start_char="12017" end_char="12021">Wuhan</TOKEN>
<TOKEN id="token-128-19" pos="punct" morph="none" start_char="12022" end_char="12023">,"</TOKEN>
<TOKEN id="token-128-20" pos="word" morph="none" start_char="12025" end_char="12029">which</TOKEN>
<TOKEN id="token-128-21" pos="word" morph="none" start_char="12031" end_char="12032">of</TOKEN>
<TOKEN id="token-128-22" pos="word" morph="none" start_char="12034" end_char="12039">course</TOKEN>
<TOKEN id="token-128-23" pos="word" morph="none" start_char="12041" end_char="12044">it's</TOKEN>
<TOKEN id="token-128-24" pos="word" morph="none" start_char="12046" end_char="12047">BS</TOKEN>
<TOKEN id="token-128-25" pos="punct" morph="none" start_char="12048" end_char="12048">.</TOKEN>
</SEG>
<SEG id="segment-129" start_char="12051" end_char="12141">
<ORIGINAL_TEXT>edit on 13-3-2020 by ElectricUniverse because: correct comment and attempt to correct link.</ORIGINAL_TEXT>
<TOKEN id="token-129-0" pos="word" morph="none" start_char="12051" end_char="12054">edit</TOKEN>
<TOKEN id="token-129-1" pos="word" morph="none" start_char="12056" end_char="12057">on</TOKEN>
<TOKEN id="token-129-2" pos="unknown" morph="none" start_char="12059" end_char="12067">13-3-2020</TOKEN>
<TOKEN id="token-129-3" pos="word" morph="none" start_char="12069" end_char="12070">by</TOKEN>
<TOKEN id="token-129-4" pos="word" morph="none" start_char="12072" end_char="12087">ElectricUniverse</TOKEN>
<TOKEN id="token-129-5" pos="word" morph="none" start_char="12089" end_char="12095">because</TOKEN>
<TOKEN id="token-129-6" pos="punct" morph="none" start_char="12096" end_char="12096">:</TOKEN>
<TOKEN id="token-129-7" pos="word" morph="none" start_char="12098" end_char="12104">correct</TOKEN>
<TOKEN id="token-129-8" pos="word" morph="none" start_char="12106" end_char="12112">comment</TOKEN>
<TOKEN id="token-129-9" pos="word" morph="none" start_char="12114" end_char="12116">and</TOKEN>
<TOKEN id="token-129-10" pos="word" morph="none" start_char="12118" end_char="12124">attempt</TOKEN>
<TOKEN id="token-129-11" pos="word" morph="none" start_char="12126" end_char="12127">to</TOKEN>
<TOKEN id="token-129-12" pos="word" morph="none" start_char="12129" end_char="12135">correct</TOKEN>
<TOKEN id="token-129-13" pos="word" morph="none" start_char="12137" end_char="12140">link</TOKEN>
<TOKEN id="token-129-14" pos="punct" morph="none" start_char="12141" end_char="12141">.</TOKEN>
</SEG>
<SEG id="segment-130" start_char="12146" end_char="12173">
<ORIGINAL_TEXT>a reply to: ElectricUniverse</ORIGINAL_TEXT>
<TOKEN id="token-130-0" pos="word" morph="none" start_char="12146" end_char="12146">a</TOKEN>
<TOKEN id="token-130-1" pos="word" morph="none" start_char="12148" end_char="12152">reply</TOKEN>
<TOKEN id="token-130-2" pos="word" morph="none" start_char="12154" end_char="12155">to</TOKEN>
<TOKEN id="token-130-3" pos="punct" morph="none" start_char="12156" end_char="12156">:</TOKEN>
<TOKEN id="token-130-4" pos="word" morph="none" start_char="12158" end_char="12173">ElectricUniverse</TOKEN>
</SEG>
<SEG id="segment-131" start_char="12176" end_char="12277">
<ORIGINAL_TEXT>This virus has been sequenced and deconstructed in multiple state and private labs all over the world.</ORIGINAL_TEXT>
<TOKEN id="token-131-0" pos="word" morph="none" start_char="12176" end_char="12179">This</TOKEN>
<TOKEN id="token-131-1" pos="word" morph="none" start_char="12181" end_char="12185">virus</TOKEN>
<TOKEN id="token-131-2" pos="word" morph="none" start_char="12187" end_char="12189">has</TOKEN>
<TOKEN id="token-131-3" pos="word" morph="none" start_char="12191" end_char="12194">been</TOKEN>
<TOKEN id="token-131-4" pos="word" morph="none" start_char="12196" end_char="12204">sequenced</TOKEN>
<TOKEN id="token-131-5" pos="word" morph="none" start_char="12206" end_char="12208">and</TOKEN>
<TOKEN id="token-131-6" pos="word" morph="none" start_char="12210" end_char="12222">deconstructed</TOKEN>
<TOKEN id="token-131-7" pos="word" morph="none" start_char="12224" end_char="12225">in</TOKEN>
<TOKEN id="token-131-8" pos="word" morph="none" start_char="12227" end_char="12234">multiple</TOKEN>
<TOKEN id="token-131-9" pos="word" morph="none" start_char="12236" end_char="12240">state</TOKEN>
<TOKEN id="token-131-10" pos="word" morph="none" start_char="12242" end_char="12244">and</TOKEN>
<TOKEN id="token-131-11" pos="word" morph="none" start_char="12246" end_char="12252">private</TOKEN>
<TOKEN id="token-131-12" pos="word" morph="none" start_char="12254" end_char="12257">labs</TOKEN>
<TOKEN id="token-131-13" pos="word" morph="none" start_char="12259" end_char="12261">all</TOKEN>
<TOKEN id="token-131-14" pos="word" morph="none" start_char="12263" end_char="12266">over</TOKEN>
<TOKEN id="token-131-15" pos="word" morph="none" start_char="12268" end_char="12270">the</TOKEN>
<TOKEN id="token-131-16" pos="word" morph="none" start_char="12272" end_char="12276">world</TOKEN>
<TOKEN id="token-131-17" pos="punct" morph="none" start_char="12277" end_char="12277">.</TOKEN>
</SEG>
<SEG id="segment-132" start_char="12279" end_char="12303">
<ORIGINAL_TEXT>Including many in the US.</ORIGINAL_TEXT>
<TOKEN id="token-132-0" pos="word" morph="none" start_char="12279" end_char="12287">Including</TOKEN>
<TOKEN id="token-132-1" pos="word" morph="none" start_char="12289" end_char="12292">many</TOKEN>
<TOKEN id="token-132-2" pos="word" morph="none" start_char="12294" end_char="12295">in</TOKEN>
<TOKEN id="token-132-3" pos="word" morph="none" start_char="12297" end_char="12299">the</TOKEN>
<TOKEN id="token-132-4" pos="word" morph="none" start_char="12301" end_char="12302">US</TOKEN>
<TOKEN id="token-132-5" pos="punct" morph="none" start_char="12303" end_char="12303">.</TOKEN>
</SEG>
<SEG id="segment-133" start_char="12306" end_char="12415">
<ORIGINAL_TEXT>So far, nobody has found any trace that might indicate that it was genetically engineered, or even hybridised.</ORIGINAL_TEXT>
<TOKEN id="token-133-0" pos="word" morph="none" start_char="12306" end_char="12307">So</TOKEN>
<TOKEN id="token-133-1" pos="word" morph="none" start_char="12309" end_char="12311">far</TOKEN>
<TOKEN id="token-133-2" pos="punct" morph="none" start_char="12312" end_char="12312">,</TOKEN>
<TOKEN id="token-133-3" pos="word" morph="none" start_char="12314" end_char="12319">nobody</TOKEN>
<TOKEN id="token-133-4" pos="word" morph="none" start_char="12321" end_char="12323">has</TOKEN>
<TOKEN id="token-133-5" pos="word" morph="none" start_char="12325" end_char="12329">found</TOKEN>
<TOKEN id="token-133-6" pos="word" morph="none" start_char="12331" end_char="12333">any</TOKEN>
<TOKEN id="token-133-7" pos="word" morph="none" start_char="12335" end_char="12339">trace</TOKEN>
<TOKEN id="token-133-8" pos="word" morph="none" start_char="12341" end_char="12344">that</TOKEN>
<TOKEN id="token-133-9" pos="word" morph="none" start_char="12346" end_char="12350">might</TOKEN>
<TOKEN id="token-133-10" pos="word" morph="none" start_char="12352" end_char="12359">indicate</TOKEN>
<TOKEN id="token-133-11" pos="word" morph="none" start_char="12361" end_char="12364">that</TOKEN>
<TOKEN id="token-133-12" pos="word" morph="none" start_char="12366" end_char="12367">it</TOKEN>
<TOKEN id="token-133-13" pos="word" morph="none" start_char="12369" end_char="12371">was</TOKEN>
<TOKEN id="token-133-14" pos="word" morph="none" start_char="12373" end_char="12383">genetically</TOKEN>
<TOKEN id="token-133-15" pos="word" morph="none" start_char="12385" end_char="12394">engineered</TOKEN>
<TOKEN id="token-133-16" pos="punct" morph="none" start_char="12395" end_char="12395">,</TOKEN>
<TOKEN id="token-133-17" pos="word" morph="none" start_char="12397" end_char="12398">or</TOKEN>
<TOKEN id="token-133-18" pos="word" morph="none" start_char="12400" end_char="12403">even</TOKEN>
<TOKEN id="token-133-19" pos="word" morph="none" start_char="12405" end_char="12414">hybridised</TOKEN>
<TOKEN id="token-133-20" pos="punct" morph="none" start_char="12415" end_char="12415">.</TOKEN>
</SEG>
<SEG id="segment-134" start_char="12418" end_char="12568">
<ORIGINAL_TEXT>The technology for gene editing is well known, and it leaves marks on the subject that would stand out to any expert where parts were added or removed.</ORIGINAL_TEXT>
<TOKEN id="token-134-0" pos="word" morph="none" start_char="12418" end_char="12420">The</TOKEN>
<TOKEN id="token-134-1" pos="word" morph="none" start_char="12422" end_char="12431">technology</TOKEN>
<TOKEN id="token-134-2" pos="word" morph="none" start_char="12433" end_char="12435">for</TOKEN>
<TOKEN id="token-134-3" pos="word" morph="none" start_char="12437" end_char="12440">gene</TOKEN>
<TOKEN id="token-134-4" pos="word" morph="none" start_char="12442" end_char="12448">editing</TOKEN>
<TOKEN id="token-134-5" pos="word" morph="none" start_char="12450" end_char="12451">is</TOKEN>
<TOKEN id="token-134-6" pos="word" morph="none" start_char="12453" end_char="12456">well</TOKEN>
<TOKEN id="token-134-7" pos="word" morph="none" start_char="12458" end_char="12462">known</TOKEN>
<TOKEN id="token-134-8" pos="punct" morph="none" start_char="12463" end_char="12463">,</TOKEN>
<TOKEN id="token-134-9" pos="word" morph="none" start_char="12465" end_char="12467">and</TOKEN>
<TOKEN id="token-134-10" pos="word" morph="none" start_char="12469" end_char="12470">it</TOKEN>
<TOKEN id="token-134-11" pos="word" morph="none" start_char="12472" end_char="12477">leaves</TOKEN>
<TOKEN id="token-134-12" pos="word" morph="none" start_char="12479" end_char="12483">marks</TOKEN>
<TOKEN id="token-134-13" pos="word" morph="none" start_char="12485" end_char="12486">on</TOKEN>
<TOKEN id="token-134-14" pos="word" morph="none" start_char="12488" end_char="12490">the</TOKEN>
<TOKEN id="token-134-15" pos="word" morph="none" start_char="12492" end_char="12498">subject</TOKEN>
<TOKEN id="token-134-16" pos="word" morph="none" start_char="12500" end_char="12503">that</TOKEN>
<TOKEN id="token-134-17" pos="word" morph="none" start_char="12505" end_char="12509">would</TOKEN>
<TOKEN id="token-134-18" pos="word" morph="none" start_char="12511" end_char="12515">stand</TOKEN>
<TOKEN id="token-134-19" pos="word" morph="none" start_char="12517" end_char="12519">out</TOKEN>
<TOKEN id="token-134-20" pos="word" morph="none" start_char="12521" end_char="12522">to</TOKEN>
<TOKEN id="token-134-21" pos="word" morph="none" start_char="12524" end_char="12526">any</TOKEN>
<TOKEN id="token-134-22" pos="word" morph="none" start_char="12528" end_char="12533">expert</TOKEN>
<TOKEN id="token-134-23" pos="word" morph="none" start_char="12535" end_char="12539">where</TOKEN>
<TOKEN id="token-134-24" pos="word" morph="none" start_char="12541" end_char="12545">parts</TOKEN>
<TOKEN id="token-134-25" pos="word" morph="none" start_char="12547" end_char="12550">were</TOKEN>
<TOKEN id="token-134-26" pos="word" morph="none" start_char="12552" end_char="12556">added</TOKEN>
<TOKEN id="token-134-27" pos="word" morph="none" start_char="12558" end_char="12559">or</TOKEN>
<TOKEN id="token-134-28" pos="word" morph="none" start_char="12561" end_char="12567">removed</TOKEN>
<TOKEN id="token-134-29" pos="punct" morph="none" start_char="12568" end_char="12568">.</TOKEN>
</SEG>
<SEG id="segment-135" start_char="12571" end_char="12712">
<ORIGINAL_TEXT>If this virus is man made the it's been made using a technology that is completely unknown to science, and which leaves no recognizable trace.</ORIGINAL_TEXT>
<TOKEN id="token-135-0" pos="word" morph="none" start_char="12571" end_char="12572">If</TOKEN>
<TOKEN id="token-135-1" pos="word" morph="none" start_char="12574" end_char="12577">this</TOKEN>
<TOKEN id="token-135-2" pos="word" morph="none" start_char="12579" end_char="12583">virus</TOKEN>
<TOKEN id="token-135-3" pos="word" morph="none" start_char="12585" end_char="12586">is</TOKEN>
<TOKEN id="token-135-4" pos="word" morph="none" start_char="12588" end_char="12590">man</TOKEN>
<TOKEN id="token-135-5" pos="word" morph="none" start_char="12592" end_char="12595">made</TOKEN>
<TOKEN id="token-135-6" pos="word" morph="none" start_char="12597" end_char="12599">the</TOKEN>
<TOKEN id="token-135-7" pos="word" morph="none" start_char="12601" end_char="12604">it's</TOKEN>
<TOKEN id="token-135-8" pos="word" morph="none" start_char="12606" end_char="12609">been</TOKEN>
<TOKEN id="token-135-9" pos="word" morph="none" start_char="12611" end_char="12614">made</TOKEN>
<TOKEN id="token-135-10" pos="word" morph="none" start_char="12616" end_char="12620">using</TOKEN>
<TOKEN id="token-135-11" pos="word" morph="none" start_char="12622" end_char="12622">a</TOKEN>
<TOKEN id="token-135-12" pos="word" morph="none" start_char="12624" end_char="12633">technology</TOKEN>
<TOKEN id="token-135-13" pos="word" morph="none" start_char="12635" end_char="12638">that</TOKEN>
<TOKEN id="token-135-14" pos="word" morph="none" start_char="12640" end_char="12641">is</TOKEN>
<TOKEN id="token-135-15" pos="word" morph="none" start_char="12643" end_char="12652">completely</TOKEN>
<TOKEN id="token-135-16" pos="word" morph="none" start_char="12654" end_char="12660">unknown</TOKEN>
<TOKEN id="token-135-17" pos="word" morph="none" start_char="12662" end_char="12663">to</TOKEN>
<TOKEN id="token-135-18" pos="word" morph="none" start_char="12665" end_char="12671">science</TOKEN>
<TOKEN id="token-135-19" pos="punct" morph="none" start_char="12672" end_char="12672">,</TOKEN>
<TOKEN id="token-135-20" pos="word" morph="none" start_char="12674" end_char="12676">and</TOKEN>
<TOKEN id="token-135-21" pos="word" morph="none" start_char="12678" end_char="12682">which</TOKEN>
<TOKEN id="token-135-22" pos="word" morph="none" start_char="12684" end_char="12689">leaves</TOKEN>
<TOKEN id="token-135-23" pos="word" morph="none" start_char="12691" end_char="12692">no</TOKEN>
<TOKEN id="token-135-24" pos="word" morph="none" start_char="12694" end_char="12705">recognizable</TOKEN>
<TOKEN id="token-135-25" pos="word" morph="none" start_char="12707" end_char="12711">trace</TOKEN>
<TOKEN id="token-135-26" pos="punct" morph="none" start_char="12712" end_char="12712">.</TOKEN>
</SEG>
<SEG id="segment-136" start_char="12714" end_char="12786">
<ORIGINAL_TEXT>So, I'm going to go for it being a natural organizm and not a bio-weapon.</ORIGINAL_TEXT>
<TOKEN id="token-136-0" pos="word" morph="none" start_char="12714" end_char="12715">So</TOKEN>
<TOKEN id="token-136-1" pos="punct" morph="none" start_char="12716" end_char="12716">,</TOKEN>
<TOKEN id="token-136-2" pos="word" morph="none" start_char="12718" end_char="12720">I'm</TOKEN>
<TOKEN id="token-136-3" pos="word" morph="none" start_char="12722" end_char="12726">going</TOKEN>
<TOKEN id="token-136-4" pos="word" morph="none" start_char="12728" end_char="12729">to</TOKEN>
<TOKEN id="token-136-5" pos="word" morph="none" start_char="12731" end_char="12732">go</TOKEN>
<TOKEN id="token-136-6" pos="word" morph="none" start_char="12734" end_char="12736">for</TOKEN>
<TOKEN id="token-136-7" pos="word" morph="none" start_char="12738" end_char="12739">it</TOKEN>
<TOKEN id="token-136-8" pos="word" morph="none" start_char="12741" end_char="12745">being</TOKEN>
<TOKEN id="token-136-9" pos="word" morph="none" start_char="12747" end_char="12747">a</TOKEN>
<TOKEN id="token-136-10" pos="word" morph="none" start_char="12749" end_char="12755">natural</TOKEN>
<TOKEN id="token-136-11" pos="word" morph="none" start_char="12757" end_char="12764">organizm</TOKEN>
<TOKEN id="token-136-12" pos="word" morph="none" start_char="12766" end_char="12768">and</TOKEN>
<TOKEN id="token-136-13" pos="word" morph="none" start_char="12770" end_char="12772">not</TOKEN>
<TOKEN id="token-136-14" pos="word" morph="none" start_char="12774" end_char="12774">a</TOKEN>
<TOKEN id="token-136-15" pos="unknown" morph="none" start_char="12776" end_char="12785">bio-weapon</TOKEN>
<TOKEN id="token-136-16" pos="punct" morph="none" start_char="12786" end_char="12786">.</TOKEN>
</SEG>
<SEG id="segment-137" start_char="12791" end_char="12870">
<ORIGINAL_TEXT>originally posted by: The2Billies a reply to: ElectricUniverse Of course it did.</ORIGINAL_TEXT>
<TOKEN id="token-137-0" pos="word" morph="none" start_char="12791" end_char="12800">originally</TOKEN>
<TOKEN id="token-137-1" pos="word" morph="none" start_char="12802" end_char="12807">posted</TOKEN>
<TOKEN id="token-137-2" pos="word" morph="none" start_char="12809" end_char="12810">by</TOKEN>
<TOKEN id="token-137-3" pos="punct" morph="none" start_char="12811" end_char="12811">:</TOKEN>
<TOKEN id="token-137-4" pos="word" morph="none" start_char="12813" end_char="12823">The2Billies</TOKEN>
<TOKEN id="token-137-5" pos="word" morph="none" start_char="12825" end_char="12825">a</TOKEN>
<TOKEN id="token-137-6" pos="word" morph="none" start_char="12827" end_char="12831">reply</TOKEN>
<TOKEN id="token-137-7" pos="word" morph="none" start_char="12833" end_char="12834">to</TOKEN>
<TOKEN id="token-137-8" pos="punct" morph="none" start_char="12835" end_char="12835">:</TOKEN>
<TOKEN id="token-137-9" pos="word" morph="none" start_char="12837" end_char="12852">ElectricUniverse</TOKEN>
<TOKEN id="token-137-10" pos="word" morph="none" start_char="12854" end_char="12855">Of</TOKEN>
<TOKEN id="token-137-11" pos="word" morph="none" start_char="12857" end_char="12862">course</TOKEN>
<TOKEN id="token-137-12" pos="word" morph="none" start_char="12864" end_char="12865">it</TOKEN>
<TOKEN id="token-137-13" pos="word" morph="none" start_char="12867" end_char="12869">did</TOKEN>
<TOKEN id="token-137-14" pos="punct" morph="none" start_char="12870" end_char="12870">.</TOKEN>
</SEG>
<SEG id="segment-138" start_char="12872" end_char="12943">
<ORIGINAL_TEXT>It started near a bioweapon facility and several bioresearch facilities.</ORIGINAL_TEXT>
<TOKEN id="token-138-0" pos="word" morph="none" start_char="12872" end_char="12873">It</TOKEN>
<TOKEN id="token-138-1" pos="word" morph="none" start_char="12875" end_char="12881">started</TOKEN>
<TOKEN id="token-138-2" pos="word" morph="none" start_char="12883" end_char="12886">near</TOKEN>
<TOKEN id="token-138-3" pos="word" morph="none" start_char="12888" end_char="12888">a</TOKEN>
<TOKEN id="token-138-4" pos="word" morph="none" start_char="12890" end_char="12898">bioweapon</TOKEN>
<TOKEN id="token-138-5" pos="word" morph="none" start_char="12900" end_char="12907">facility</TOKEN>
<TOKEN id="token-138-6" pos="word" morph="none" start_char="12909" end_char="12911">and</TOKEN>
<TOKEN id="token-138-7" pos="word" morph="none" start_char="12913" end_char="12919">several</TOKEN>
<TOKEN id="token-138-8" pos="word" morph="none" start_char="12921" end_char="12931">bioresearch</TOKEN>
<TOKEN id="token-138-9" pos="word" morph="none" start_char="12933" end_char="12942">facilities</TOKEN>
<TOKEN id="token-138-10" pos="punct" morph="none" start_char="12943" end_char="12943">.</TOKEN>
</SEG>
<SEG id="segment-139" start_char="12945" end_char="12978">
<ORIGINAL_TEXT>Too much a coincidence to dismiss.</ORIGINAL_TEXT>
<TOKEN id="token-139-0" pos="word" morph="none" start_char="12945" end_char="12947">Too</TOKEN>
<TOKEN id="token-139-1" pos="word" morph="none" start_char="12949" end_char="12952">much</TOKEN>
<TOKEN id="token-139-2" pos="word" morph="none" start_char="12954" end_char="12954">a</TOKEN>
<TOKEN id="token-139-3" pos="word" morph="none" start_char="12956" end_char="12966">coincidence</TOKEN>
<TOKEN id="token-139-4" pos="word" morph="none" start_char="12968" end_char="12969">to</TOKEN>
<TOKEN id="token-139-5" pos="word" morph="none" start_char="12971" end_char="12977">dismiss</TOKEN>
<TOKEN id="token-139-6" pos="punct" morph="none" start_char="12978" end_char="12978">.</TOKEN>
</SEG>
<SEG id="segment-140" start_char="12980" end_char="13056">
<ORIGINAL_TEXT>Especially since the virus is truly beneficial to Chinese society as a whole.</ORIGINAL_TEXT>
<TOKEN id="token-140-0" pos="word" morph="none" start_char="12980" end_char="12989">Especially</TOKEN>
<TOKEN id="token-140-1" pos="word" morph="none" start_char="12991" end_char="12995">since</TOKEN>
<TOKEN id="token-140-2" pos="word" morph="none" start_char="12997" end_char="12999">the</TOKEN>
<TOKEN id="token-140-3" pos="word" morph="none" start_char="13001" end_char="13005">virus</TOKEN>
<TOKEN id="token-140-4" pos="word" morph="none" start_char="13007" end_char="13008">is</TOKEN>
<TOKEN id="token-140-5" pos="word" morph="none" start_char="13010" end_char="13014">truly</TOKEN>
<TOKEN id="token-140-6" pos="word" morph="none" start_char="13016" end_char="13025">beneficial</TOKEN>
<TOKEN id="token-140-7" pos="word" morph="none" start_char="13027" end_char="13028">to</TOKEN>
<TOKEN id="token-140-8" pos="word" morph="none" start_char="13030" end_char="13036">Chinese</TOKEN>
<TOKEN id="token-140-9" pos="word" morph="none" start_char="13038" end_char="13044">society</TOKEN>
<TOKEN id="token-140-10" pos="word" morph="none" start_char="13046" end_char="13047">as</TOKEN>
<TOKEN id="token-140-11" pos="word" morph="none" start_char="13049" end_char="13049">a</TOKEN>
<TOKEN id="token-140-12" pos="word" morph="none" start_char="13051" end_char="13055">whole</TOKEN>
<TOKEN id="token-140-13" pos="punct" morph="none" start_char="13056" end_char="13056">.</TOKEN>
</SEG>
<SEG id="segment-141" start_char="13058" end_char="13112">
<ORIGINAL_TEXT>China is a communist country, individuals mean nothing.</ORIGINAL_TEXT>
<TOKEN id="token-141-0" pos="word" morph="none" start_char="13058" end_char="13062">China</TOKEN>
<TOKEN id="token-141-1" pos="word" morph="none" start_char="13064" end_char="13065">is</TOKEN>
<TOKEN id="token-141-2" pos="word" morph="none" start_char="13067" end_char="13067">a</TOKEN>
<TOKEN id="token-141-3" pos="word" morph="none" start_char="13069" end_char="13077">communist</TOKEN>
<TOKEN id="token-141-4" pos="word" morph="none" start_char="13079" end_char="13085">country</TOKEN>
<TOKEN id="token-141-5" pos="punct" morph="none" start_char="13086" end_char="13086">,</TOKEN>
<TOKEN id="token-141-6" pos="word" morph="none" start_char="13088" end_char="13098">individuals</TOKEN>
<TOKEN id="token-141-7" pos="word" morph="none" start_char="13100" end_char="13103">mean</TOKEN>
<TOKEN id="token-141-8" pos="word" morph="none" start_char="13105" end_char="13111">nothing</TOKEN>
<TOKEN id="token-141-9" pos="punct" morph="none" start_char="13112" end_char="13112">.</TOKEN>
</SEG>
<SEG id="segment-142" start_char="13114" end_char="13178">
<ORIGINAL_TEXT>Everything is done for the good of the whole, society as a whole.</ORIGINAL_TEXT>
<TOKEN id="token-142-0" pos="word" morph="none" start_char="13114" end_char="13123">Everything</TOKEN>
<TOKEN id="token-142-1" pos="word" morph="none" start_char="13125" end_char="13126">is</TOKEN>
<TOKEN id="token-142-2" pos="word" morph="none" start_char="13128" end_char="13131">done</TOKEN>
<TOKEN id="token-142-3" pos="word" morph="none" start_char="13133" end_char="13135">for</TOKEN>
<TOKEN id="token-142-4" pos="word" morph="none" start_char="13137" end_char="13139">the</TOKEN>
<TOKEN id="token-142-5" pos="word" morph="none" start_char="13141" end_char="13144">good</TOKEN>
<TOKEN id="token-142-6" pos="word" morph="none" start_char="13146" end_char="13147">of</TOKEN>
<TOKEN id="token-142-7" pos="word" morph="none" start_char="13149" end_char="13151">the</TOKEN>
<TOKEN id="token-142-8" pos="word" morph="none" start_char="13153" end_char="13157">whole</TOKEN>
<TOKEN id="token-142-9" pos="punct" morph="none" start_char="13158" end_char="13158">,</TOKEN>
<TOKEN id="token-142-10" pos="word" morph="none" start_char="13160" end_char="13166">society</TOKEN>
<TOKEN id="token-142-11" pos="word" morph="none" start_char="13168" end_char="13169">as</TOKEN>
<TOKEN id="token-142-12" pos="word" morph="none" start_char="13171" end_char="13171">a</TOKEN>
<TOKEN id="token-142-13" pos="word" morph="none" start_char="13173" end_char="13177">whole</TOKEN>
<TOKEN id="token-142-14" pos="punct" morph="none" start_char="13178" end_char="13178">.</TOKEN>
</SEG>
<SEG id="segment-143" start_char="13180" end_char="13230">
<ORIGINAL_TEXT>They have a enormous problem with too many elderly.</ORIGINAL_TEXT>
<TOKEN id="token-143-0" pos="word" morph="none" start_char="13180" end_char="13183">They</TOKEN>
<TOKEN id="token-143-1" pos="word" morph="none" start_char="13185" end_char="13188">have</TOKEN>
<TOKEN id="token-143-2" pos="word" morph="none" start_char="13190" end_char="13190">a</TOKEN>
<TOKEN id="token-143-3" pos="word" morph="none" start_char="13192" end_char="13199">enormous</TOKEN>
<TOKEN id="token-143-4" pos="word" morph="none" start_char="13201" end_char="13207">problem</TOKEN>
<TOKEN id="token-143-5" pos="word" morph="none" start_char="13209" end_char="13212">with</TOKEN>
<TOKEN id="token-143-6" pos="word" morph="none" start_char="13214" end_char="13216">too</TOKEN>
<TOKEN id="token-143-7" pos="word" morph="none" start_char="13218" end_char="13221">many</TOKEN>
<TOKEN id="token-143-8" pos="word" morph="none" start_char="13223" end_char="13229">elderly</TOKEN>
<TOKEN id="token-143-9" pos="punct" morph="none" start_char="13230" end_char="13230">.</TOKEN>
</SEG>
<SEG id="segment-144" start_char="13232" end_char="13266">
<ORIGINAL_TEXT>This is due their one child policy.</ORIGINAL_TEXT>
<TOKEN id="token-144-0" pos="word" morph="none" start_char="13232" end_char="13235">This</TOKEN>
<TOKEN id="token-144-1" pos="word" morph="none" start_char="13237" end_char="13238">is</TOKEN>
<TOKEN id="token-144-2" pos="word" morph="none" start_char="13240" end_char="13242">due</TOKEN>
<TOKEN id="token-144-3" pos="word" morph="none" start_char="13244" end_char="13248">their</TOKEN>
<TOKEN id="token-144-4" pos="word" morph="none" start_char="13250" end_char="13252">one</TOKEN>
<TOKEN id="token-144-5" pos="word" morph="none" start_char="13254" end_char="13258">child</TOKEN>
<TOKEN id="token-144-6" pos="word" morph="none" start_char="13260" end_char="13265">policy</TOKEN>
<TOKEN id="token-144-7" pos="punct" morph="none" start_char="13266" end_char="13266">.</TOKEN>
</SEG>
<SEG id="segment-145" start_char="13268" end_char="13423">
<ORIGINAL_TEXT>Right now on average a couple is supporting themselves, their child/ren, and FOUR other adults, this is their culture- no to few facilities for the elderly.</ORIGINAL_TEXT>
<TOKEN id="token-145-0" pos="word" morph="none" start_char="13268" end_char="13272">Right</TOKEN>
<TOKEN id="token-145-1" pos="word" morph="none" start_char="13274" end_char="13276">now</TOKEN>
<TOKEN id="token-145-2" pos="word" morph="none" start_char="13278" end_char="13279">on</TOKEN>
<TOKEN id="token-145-3" pos="word" morph="none" start_char="13281" end_char="13287">average</TOKEN>
<TOKEN id="token-145-4" pos="word" morph="none" start_char="13289" end_char="13289">a</TOKEN>
<TOKEN id="token-145-5" pos="word" morph="none" start_char="13291" end_char="13296">couple</TOKEN>
<TOKEN id="token-145-6" pos="word" morph="none" start_char="13298" end_char="13299">is</TOKEN>
<TOKEN id="token-145-7" pos="word" morph="none" start_char="13301" end_char="13310">supporting</TOKEN>
<TOKEN id="token-145-8" pos="word" morph="none" start_char="13312" end_char="13321">themselves</TOKEN>
<TOKEN id="token-145-9" pos="punct" morph="none" start_char="13322" end_char="13322">,</TOKEN>
<TOKEN id="token-145-10" pos="word" morph="none" start_char="13324" end_char="13328">their</TOKEN>
<TOKEN id="token-145-11" pos="unknown" morph="none" start_char="13330" end_char="13338">child/ren</TOKEN>
<TOKEN id="token-145-12" pos="punct" morph="none" start_char="13339" end_char="13339">,</TOKEN>
<TOKEN id="token-145-13" pos="word" morph="none" start_char="13341" end_char="13343">and</TOKEN>
<TOKEN id="token-145-14" pos="word" morph="none" start_char="13345" end_char="13348">FOUR</TOKEN>
<TOKEN id="token-145-15" pos="word" morph="none" start_char="13350" end_char="13354">other</TOKEN>
<TOKEN id="token-145-16" pos="word" morph="none" start_char="13356" end_char="13361">adults</TOKEN>
<TOKEN id="token-145-17" pos="punct" morph="none" start_char="13362" end_char="13362">,</TOKEN>
<TOKEN id="token-145-18" pos="word" morph="none" start_char="13364" end_char="13367">this</TOKEN>
<TOKEN id="token-145-19" pos="word" morph="none" start_char="13369" end_char="13370">is</TOKEN>
<TOKEN id="token-145-20" pos="word" morph="none" start_char="13372" end_char="13376">their</TOKEN>
<TOKEN id="token-145-21" pos="word" morph="none" start_char="13378" end_char="13384">culture</TOKEN>
<TOKEN id="token-145-22" pos="punct" morph="none" start_char="13385" end_char="13385">-</TOKEN>
<TOKEN id="token-145-23" pos="word" morph="none" start_char="13387" end_char="13388">no</TOKEN>
<TOKEN id="token-145-24" pos="word" morph="none" start_char="13390" end_char="13391">to</TOKEN>
<TOKEN id="token-145-25" pos="word" morph="none" start_char="13393" end_char="13395">few</TOKEN>
<TOKEN id="token-145-26" pos="word" morph="none" start_char="13397" end_char="13406">facilities</TOKEN>
<TOKEN id="token-145-27" pos="word" morph="none" start_char="13408" end_char="13410">for</TOKEN>
<TOKEN id="token-145-28" pos="word" morph="none" start_char="13412" end_char="13414">the</TOKEN>
<TOKEN id="token-145-29" pos="word" morph="none" start_char="13416" end_char="13422">elderly</TOKEN>
<TOKEN id="token-145-30" pos="punct" morph="none" start_char="13423" end_char="13423">.</TOKEN>
</SEG>
<SEG id="segment-146" start_char="13425" end_char="13506">
<ORIGINAL_TEXT>This virus is specifically designed to kill the elderly and not harm young people.</ORIGINAL_TEXT>
<TOKEN id="token-146-0" pos="word" morph="none" start_char="13425" end_char="13428">This</TOKEN>
<TOKEN id="token-146-1" pos="word" morph="none" start_char="13430" end_char="13434">virus</TOKEN>
<TOKEN id="token-146-2" pos="word" morph="none" start_char="13436" end_char="13437">is</TOKEN>
<TOKEN id="token-146-3" pos="word" morph="none" start_char="13439" end_char="13450">specifically</TOKEN>
<TOKEN id="token-146-4" pos="word" morph="none" start_char="13452" end_char="13459">designed</TOKEN>
<TOKEN id="token-146-5" pos="word" morph="none" start_char="13461" end_char="13462">to</TOKEN>
<TOKEN id="token-146-6" pos="word" morph="none" start_char="13464" end_char="13467">kill</TOKEN>
<TOKEN id="token-146-7" pos="word" morph="none" start_char="13469" end_char="13471">the</TOKEN>
<TOKEN id="token-146-8" pos="word" morph="none" start_char="13473" end_char="13479">elderly</TOKEN>
<TOKEN id="token-146-9" pos="word" morph="none" start_char="13481" end_char="13483">and</TOKEN>
<TOKEN id="token-146-10" pos="word" morph="none" start_char="13485" end_char="13487">not</TOKEN>
<TOKEN id="token-146-11" pos="word" morph="none" start_char="13489" end_char="13492">harm</TOKEN>
<TOKEN id="token-146-12" pos="word" morph="none" start_char="13494" end_char="13498">young</TOKEN>
<TOKEN id="token-146-13" pos="word" morph="none" start_char="13500" end_char="13505">people</TOKEN>
<TOKEN id="token-146-14" pos="punct" morph="none" start_char="13506" end_char="13506">.</TOKEN>
</SEG>
<SEG id="segment-147" start_char="13508" end_char="13578">
<ORIGINAL_TEXT>An excellent way to genocide the elderly without looking like they did.</ORIGINAL_TEXT>
<TOKEN id="token-147-0" pos="word" morph="none" start_char="13508" end_char="13509">An</TOKEN>
<TOKEN id="token-147-1" pos="word" morph="none" start_char="13511" end_char="13519">excellent</TOKEN>
<TOKEN id="token-147-2" pos="word" morph="none" start_char="13521" end_char="13523">way</TOKEN>
<TOKEN id="token-147-3" pos="word" morph="none" start_char="13525" end_char="13526">to</TOKEN>
<TOKEN id="token-147-4" pos="word" morph="none" start_char="13528" end_char="13535">genocide</TOKEN>
<TOKEN id="token-147-5" pos="word" morph="none" start_char="13537" end_char="13539">the</TOKEN>
<TOKEN id="token-147-6" pos="word" morph="none" start_char="13541" end_char="13547">elderly</TOKEN>
<TOKEN id="token-147-7" pos="word" morph="none" start_char="13549" end_char="13555">without</TOKEN>
<TOKEN id="token-147-8" pos="word" morph="none" start_char="13557" end_char="13563">looking</TOKEN>
<TOKEN id="token-147-9" pos="word" morph="none" start_char="13565" end_char="13568">like</TOKEN>
<TOKEN id="token-147-10" pos="word" morph="none" start_char="13570" end_char="13573">they</TOKEN>
<TOKEN id="token-147-11" pos="word" morph="none" start_char="13575" end_char="13577">did</TOKEN>
<TOKEN id="token-147-12" pos="punct" morph="none" start_char="13578" end_char="13578">.</TOKEN>
</SEG>
<SEG id="segment-148" start_char="13580" end_char="13733">
<ORIGINAL_TEXT>There are always outliers who die from any virus, like health workers forced by the government to work 24/7 without rest or minimal rest for weeks on end.</ORIGINAL_TEXT>
<TOKEN id="token-148-0" pos="word" morph="none" start_char="13580" end_char="13584">There</TOKEN>
<TOKEN id="token-148-1" pos="word" morph="none" start_char="13586" end_char="13588">are</TOKEN>
<TOKEN id="token-148-2" pos="word" morph="none" start_char="13590" end_char="13595">always</TOKEN>
<TOKEN id="token-148-3" pos="word" morph="none" start_char="13597" end_char="13604">outliers</TOKEN>
<TOKEN id="token-148-4" pos="word" morph="none" start_char="13606" end_char="13608">who</TOKEN>
<TOKEN id="token-148-5" pos="word" morph="none" start_char="13610" end_char="13612">die</TOKEN>
<TOKEN id="token-148-6" pos="word" morph="none" start_char="13614" end_char="13617">from</TOKEN>
<TOKEN id="token-148-7" pos="word" morph="none" start_char="13619" end_char="13621">any</TOKEN>
<TOKEN id="token-148-8" pos="word" morph="none" start_char="13623" end_char="13627">virus</TOKEN>
<TOKEN id="token-148-9" pos="punct" morph="none" start_char="13628" end_char="13628">,</TOKEN>
<TOKEN id="token-148-10" pos="word" morph="none" start_char="13630" end_char="13633">like</TOKEN>
<TOKEN id="token-148-11" pos="word" morph="none" start_char="13635" end_char="13640">health</TOKEN>
<TOKEN id="token-148-12" pos="word" morph="none" start_char="13642" end_char="13648">workers</TOKEN>
<TOKEN id="token-148-13" pos="word" morph="none" start_char="13650" end_char="13655">forced</TOKEN>
<TOKEN id="token-148-14" pos="word" morph="none" start_char="13657" end_char="13658">by</TOKEN>
<TOKEN id="token-148-15" pos="word" morph="none" start_char="13660" end_char="13662">the</TOKEN>
<TOKEN id="token-148-16" pos="word" morph="none" start_char="13664" end_char="13673">government</TOKEN>
<TOKEN id="token-148-17" pos="word" morph="none" start_char="13675" end_char="13676">to</TOKEN>
<TOKEN id="token-148-18" pos="word" morph="none" start_char="13678" end_char="13681">work</TOKEN>
<TOKEN id="token-148-19" pos="unknown" morph="none" start_char="13683" end_char="13686">24/7</TOKEN>
<TOKEN id="token-148-20" pos="word" morph="none" start_char="13688" end_char="13694">without</TOKEN>
<TOKEN id="token-148-21" pos="word" morph="none" start_char="13696" end_char="13699">rest</TOKEN>
<TOKEN id="token-148-22" pos="word" morph="none" start_char="13701" end_char="13702">or</TOKEN>
<TOKEN id="token-148-23" pos="word" morph="none" start_char="13704" end_char="13710">minimal</TOKEN>
<TOKEN id="token-148-24" pos="word" morph="none" start_char="13712" end_char="13715">rest</TOKEN>
<TOKEN id="token-148-25" pos="word" morph="none" start_char="13717" end_char="13719">for</TOKEN>
<TOKEN id="token-148-26" pos="word" morph="none" start_char="13721" end_char="13725">weeks</TOKEN>
<TOKEN id="token-148-27" pos="word" morph="none" start_char="13727" end_char="13728">on</TOKEN>
<TOKEN id="token-148-28" pos="word" morph="none" start_char="13730" end_char="13732">end</TOKEN>
<TOKEN id="token-148-29" pos="punct" morph="none" start_char="13733" end_char="13733">.</TOKEN>
</SEG>
<SEG id="segment-149" start_char="13735" end_char="13829">
<ORIGINAL_TEXT>In a socialist/communist country the resource drain from the elderly is reaching crises levels.</ORIGINAL_TEXT>
<TOKEN id="token-149-0" pos="word" morph="none" start_char="13735" end_char="13736">In</TOKEN>
<TOKEN id="token-149-1" pos="word" morph="none" start_char="13738" end_char="13738">a</TOKEN>
<TOKEN id="token-149-2" pos="unknown" morph="none" start_char="13740" end_char="13758">socialist/communist</TOKEN>
<TOKEN id="token-149-3" pos="word" morph="none" start_char="13760" end_char="13766">country</TOKEN>
<TOKEN id="token-149-4" pos="word" morph="none" start_char="13768" end_char="13770">the</TOKEN>
<TOKEN id="token-149-5" pos="word" morph="none" start_char="13772" end_char="13779">resource</TOKEN>
<TOKEN id="token-149-6" pos="word" morph="none" start_char="13781" end_char="13785">drain</TOKEN>
<TOKEN id="token-149-7" pos="word" morph="none" start_char="13787" end_char="13790">from</TOKEN>
<TOKEN id="token-149-8" pos="word" morph="none" start_char="13792" end_char="13794">the</TOKEN>
<TOKEN id="token-149-9" pos="word" morph="none" start_char="13796" end_char="13802">elderly</TOKEN>
<TOKEN id="token-149-10" pos="word" morph="none" start_char="13804" end_char="13805">is</TOKEN>
<TOKEN id="token-149-11" pos="word" morph="none" start_char="13807" end_char="13814">reaching</TOKEN>
<TOKEN id="token-149-12" pos="word" morph="none" start_char="13816" end_char="13821">crises</TOKEN>
<TOKEN id="token-149-13" pos="word" morph="none" start_char="13823" end_char="13828">levels</TOKEN>
<TOKEN id="token-149-14" pos="punct" morph="none" start_char="13829" end_char="13829">.</TOKEN>
</SEG>
<SEG id="segment-150" start_char="13831" end_char="13904">
<ORIGINAL_TEXT>Aside from China, China may see itself as doing good for the entire world.</ORIGINAL_TEXT>
<TOKEN id="token-150-0" pos="word" morph="none" start_char="13831" end_char="13835">Aside</TOKEN>
<TOKEN id="token-150-1" pos="word" morph="none" start_char="13837" end_char="13840">from</TOKEN>
<TOKEN id="token-150-2" pos="word" morph="none" start_char="13842" end_char="13846">China</TOKEN>
<TOKEN id="token-150-3" pos="punct" morph="none" start_char="13847" end_char="13847">,</TOKEN>
<TOKEN id="token-150-4" pos="word" morph="none" start_char="13849" end_char="13853">China</TOKEN>
<TOKEN id="token-150-5" pos="word" morph="none" start_char="13855" end_char="13857">may</TOKEN>
<TOKEN id="token-150-6" pos="word" morph="none" start_char="13859" end_char="13861">see</TOKEN>
<TOKEN id="token-150-7" pos="word" morph="none" start_char="13863" end_char="13868">itself</TOKEN>
<TOKEN id="token-150-8" pos="word" morph="none" start_char="13870" end_char="13871">as</TOKEN>
<TOKEN id="token-150-9" pos="word" morph="none" start_char="13873" end_char="13877">doing</TOKEN>
<TOKEN id="token-150-10" pos="word" morph="none" start_char="13879" end_char="13882">good</TOKEN>
<TOKEN id="token-150-11" pos="word" morph="none" start_char="13884" end_char="13886">for</TOKEN>
<TOKEN id="token-150-12" pos="word" morph="none" start_char="13888" end_char="13890">the</TOKEN>
<TOKEN id="token-150-13" pos="word" morph="none" start_char="13892" end_char="13897">entire</TOKEN>
<TOKEN id="token-150-14" pos="word" morph="none" start_char="13899" end_char="13903">world</TOKEN>
<TOKEN id="token-150-15" pos="punct" morph="none" start_char="13904" end_char="13904">.</TOKEN>
</SEG>
<SEG id="segment-151" start_char="13906" end_char="13976">
<ORIGINAL_TEXT>There are an excess of elderly in every developed country in the world.</ORIGINAL_TEXT>
<TOKEN id="token-151-0" pos="word" morph="none" start_char="13906" end_char="13910">There</TOKEN>
<TOKEN id="token-151-1" pos="word" morph="none" start_char="13912" end_char="13914">are</TOKEN>
<TOKEN id="token-151-2" pos="word" morph="none" start_char="13916" end_char="13917">an</TOKEN>
<TOKEN id="token-151-3" pos="word" morph="none" start_char="13919" end_char="13924">excess</TOKEN>
<TOKEN id="token-151-4" pos="word" morph="none" start_char="13926" end_char="13927">of</TOKEN>
<TOKEN id="token-151-5" pos="word" morph="none" start_char="13929" end_char="13935">elderly</TOKEN>
<TOKEN id="token-151-6" pos="word" morph="none" start_char="13937" end_char="13938">in</TOKEN>
<TOKEN id="token-151-7" pos="word" morph="none" start_char="13940" end_char="13944">every</TOKEN>
<TOKEN id="token-151-8" pos="word" morph="none" start_char="13946" end_char="13954">developed</TOKEN>
<TOKEN id="token-151-9" pos="word" morph="none" start_char="13956" end_char="13962">country</TOKEN>
<TOKEN id="token-151-10" pos="word" morph="none" start_char="13964" end_char="13965">in</TOKEN>
<TOKEN id="token-151-11" pos="word" morph="none" start_char="13967" end_char="13969">the</TOKEN>
<TOKEN id="token-151-12" pos="word" morph="none" start_char="13971" end_char="13975">world</TOKEN>
<TOKEN id="token-151-13" pos="punct" morph="none" start_char="13976" end_char="13976">.</TOKEN>
</SEG>
<SEG id="segment-152" start_char="13978" end_char="14099">
<ORIGINAL_TEXT>To deny or dismiss it being a designer virus to kill the excess elderly population is like sticking your head in the sand.</ORIGINAL_TEXT>
<TOKEN id="token-152-0" pos="word" morph="none" start_char="13978" end_char="13979">To</TOKEN>
<TOKEN id="token-152-1" pos="word" morph="none" start_char="13981" end_char="13984">deny</TOKEN>
<TOKEN id="token-152-2" pos="word" morph="none" start_char="13986" end_char="13987">or</TOKEN>
<TOKEN id="token-152-3" pos="word" morph="none" start_char="13989" end_char="13995">dismiss</TOKEN>
<TOKEN id="token-152-4" pos="word" morph="none" start_char="13997" end_char="13998">it</TOKEN>
<TOKEN id="token-152-5" pos="word" morph="none" start_char="14000" end_char="14004">being</TOKEN>
<TOKEN id="token-152-6" pos="word" morph="none" start_char="14006" end_char="14006">a</TOKEN>
<TOKEN id="token-152-7" pos="word" morph="none" start_char="14008" end_char="14015">designer</TOKEN>
<TOKEN id="token-152-8" pos="word" morph="none" start_char="14017" end_char="14021">virus</TOKEN>
<TOKEN id="token-152-9" pos="word" morph="none" start_char="14023" end_char="14024">to</TOKEN>
<TOKEN id="token-152-10" pos="word" morph="none" start_char="14026" end_char="14029">kill</TOKEN>
<TOKEN id="token-152-11" pos="word" morph="none" start_char="14031" end_char="14033">the</TOKEN>
<TOKEN id="token-152-12" pos="word" morph="none" start_char="14035" end_char="14040">excess</TOKEN>
<TOKEN id="token-152-13" pos="word" morph="none" start_char="14042" end_char="14048">elderly</TOKEN>
<TOKEN id="token-152-14" pos="word" morph="none" start_char="14050" end_char="14059">population</TOKEN>
<TOKEN id="token-152-15" pos="word" morph="none" start_char="14061" end_char="14062">is</TOKEN>
<TOKEN id="token-152-16" pos="word" morph="none" start_char="14064" end_char="14067">like</TOKEN>
<TOKEN id="token-152-17" pos="word" morph="none" start_char="14069" end_char="14076">sticking</TOKEN>
<TOKEN id="token-152-18" pos="word" morph="none" start_char="14078" end_char="14081">your</TOKEN>
<TOKEN id="token-152-19" pos="word" morph="none" start_char="14083" end_char="14086">head</TOKEN>
<TOKEN id="token-152-20" pos="word" morph="none" start_char="14088" end_char="14089">in</TOKEN>
<TOKEN id="token-152-21" pos="word" morph="none" start_char="14091" end_char="14093">the</TOKEN>
<TOKEN id="token-152-22" pos="word" morph="none" start_char="14095" end_char="14098">sand</TOKEN>
<TOKEN id="token-152-23" pos="punct" morph="none" start_char="14099" end_char="14099">.</TOKEN>
</SEG>
<SEG id="segment-153" start_char="14101" end_char="14286">
<ORIGINAL_TEXT>I have seen several people doing that and wonder if they are Chinese paid operatives who are doing their best to make this highly logical conclusion sound like a weird conspiracy theory.</ORIGINAL_TEXT>
<TOKEN id="token-153-0" pos="word" morph="none" start_char="14101" end_char="14101">I</TOKEN>
<TOKEN id="token-153-1" pos="word" morph="none" start_char="14103" end_char="14106">have</TOKEN>
<TOKEN id="token-153-2" pos="word" morph="none" start_char="14108" end_char="14111">seen</TOKEN>
<TOKEN id="token-153-3" pos="word" morph="none" start_char="14113" end_char="14119">several</TOKEN>
<TOKEN id="token-153-4" pos="word" morph="none" start_char="14121" end_char="14126">people</TOKEN>
<TOKEN id="token-153-5" pos="word" morph="none" start_char="14128" end_char="14132">doing</TOKEN>
<TOKEN id="token-153-6" pos="word" morph="none" start_char="14134" end_char="14137">that</TOKEN>
<TOKEN id="token-153-7" pos="word" morph="none" start_char="14139" end_char="14141">and</TOKEN>
<TOKEN id="token-153-8" pos="word" morph="none" start_char="14143" end_char="14148">wonder</TOKEN>
<TOKEN id="token-153-9" pos="word" morph="none" start_char="14150" end_char="14151">if</TOKEN>
<TOKEN id="token-153-10" pos="word" morph="none" start_char="14153" end_char="14156">they</TOKEN>
<TOKEN id="token-153-11" pos="word" morph="none" start_char="14158" end_char="14160">are</TOKEN>
<TOKEN id="token-153-12" pos="word" morph="none" start_char="14162" end_char="14168">Chinese</TOKEN>
<TOKEN id="token-153-13" pos="word" morph="none" start_char="14170" end_char="14173">paid</TOKEN>
<TOKEN id="token-153-14" pos="word" morph="none" start_char="14175" end_char="14184">operatives</TOKEN>
<TOKEN id="token-153-15" pos="word" morph="none" start_char="14186" end_char="14188">who</TOKEN>
<TOKEN id="token-153-16" pos="word" morph="none" start_char="14190" end_char="14192">are</TOKEN>
<TOKEN id="token-153-17" pos="word" morph="none" start_char="14194" end_char="14198">doing</TOKEN>
<TOKEN id="token-153-18" pos="word" morph="none" start_char="14200" end_char="14204">their</TOKEN>
<TOKEN id="token-153-19" pos="word" morph="none" start_char="14206" end_char="14209">best</TOKEN>
<TOKEN id="token-153-20" pos="word" morph="none" start_char="14211" end_char="14212">to</TOKEN>
<TOKEN id="token-153-21" pos="word" morph="none" start_char="14214" end_char="14217">make</TOKEN>
<TOKEN id="token-153-22" pos="word" morph="none" start_char="14219" end_char="14222">this</TOKEN>
<TOKEN id="token-153-23" pos="word" morph="none" start_char="14224" end_char="14229">highly</TOKEN>
<TOKEN id="token-153-24" pos="word" morph="none" start_char="14231" end_char="14237">logical</TOKEN>
<TOKEN id="token-153-25" pos="word" morph="none" start_char="14239" end_char="14248">conclusion</TOKEN>
<TOKEN id="token-153-26" pos="word" morph="none" start_char="14250" end_char="14254">sound</TOKEN>
<TOKEN id="token-153-27" pos="word" morph="none" start_char="14256" end_char="14259">like</TOKEN>
<TOKEN id="token-153-28" pos="word" morph="none" start_char="14261" end_char="14261">a</TOKEN>
<TOKEN id="token-153-29" pos="word" morph="none" start_char="14263" end_char="14267">weird</TOKEN>
<TOKEN id="token-153-30" pos="word" morph="none" start_char="14269" end_char="14278">conspiracy</TOKEN>
<TOKEN id="token-153-31" pos="word" morph="none" start_char="14280" end_char="14285">theory</TOKEN>
<TOKEN id="token-153-32" pos="punct" morph="none" start_char="14286" end_char="14286">.</TOKEN>
</SEG>
<SEG id="segment-154" start_char="14288" end_char="14443">
<ORIGINAL_TEXT>Someone with 2 masters degrees, and a very steady person asked me the other day if I thought the Chinese designed this and it got loose from their facility.</ORIGINAL_TEXT>
<TOKEN id="token-154-0" pos="word" morph="none" start_char="14288" end_char="14294">Someone</TOKEN>
<TOKEN id="token-154-1" pos="word" morph="none" start_char="14296" end_char="14299">with</TOKEN>
<TOKEN id="token-154-2" pos="word" morph="none" start_char="14301" end_char="14301">2</TOKEN>
<TOKEN id="token-154-3" pos="word" morph="none" start_char="14303" end_char="14309">masters</TOKEN>
<TOKEN id="token-154-4" pos="word" morph="none" start_char="14311" end_char="14317">degrees</TOKEN>
<TOKEN id="token-154-5" pos="punct" morph="none" start_char="14318" end_char="14318">,</TOKEN>
<TOKEN id="token-154-6" pos="word" morph="none" start_char="14320" end_char="14322">and</TOKEN>
<TOKEN id="token-154-7" pos="word" morph="none" start_char="14324" end_char="14324">a</TOKEN>
<TOKEN id="token-154-8" pos="word" morph="none" start_char="14326" end_char="14329">very</TOKEN>
<TOKEN id="token-154-9" pos="word" morph="none" start_char="14331" end_char="14336">steady</TOKEN>
<TOKEN id="token-154-10" pos="word" morph="none" start_char="14338" end_char="14343">person</TOKEN>
<TOKEN id="token-154-11" pos="word" morph="none" start_char="14345" end_char="14349">asked</TOKEN>
<TOKEN id="token-154-12" pos="word" morph="none" start_char="14351" end_char="14352">me</TOKEN>
<TOKEN id="token-154-13" pos="word" morph="none" start_char="14354" end_char="14356">the</TOKEN>
<TOKEN id="token-154-14" pos="word" morph="none" start_char="14358" end_char="14362">other</TOKEN>
<TOKEN id="token-154-15" pos="word" morph="none" start_char="14364" end_char="14366">day</TOKEN>
<TOKEN id="token-154-16" pos="word" morph="none" start_char="14368" end_char="14369">if</TOKEN>
<TOKEN id="token-154-17" pos="word" morph="none" start_char="14371" end_char="14371">I</TOKEN>
<TOKEN id="token-154-18" pos="word" morph="none" start_char="14373" end_char="14379">thought</TOKEN>
<TOKEN id="token-154-19" pos="word" morph="none" start_char="14381" end_char="14383">the</TOKEN>
<TOKEN id="token-154-20" pos="word" morph="none" start_char="14385" end_char="14391">Chinese</TOKEN>
<TOKEN id="token-154-21" pos="word" morph="none" start_char="14393" end_char="14400">designed</TOKEN>
<TOKEN id="token-154-22" pos="word" morph="none" start_char="14402" end_char="14405">this</TOKEN>
<TOKEN id="token-154-23" pos="word" morph="none" start_char="14407" end_char="14409">and</TOKEN>
<TOKEN id="token-154-24" pos="word" morph="none" start_char="14411" end_char="14412">it</TOKEN>
<TOKEN id="token-154-25" pos="word" morph="none" start_char="14414" end_char="14416">got</TOKEN>
<TOKEN id="token-154-26" pos="word" morph="none" start_char="14418" end_char="14422">loose</TOKEN>
<TOKEN id="token-154-27" pos="word" morph="none" start_char="14424" end_char="14427">from</TOKEN>
<TOKEN id="token-154-28" pos="word" morph="none" start_char="14429" end_char="14433">their</TOKEN>
<TOKEN id="token-154-29" pos="word" morph="none" start_char="14435" end_char="14442">facility</TOKEN>
<TOKEN id="token-154-30" pos="punct" morph="none" start_char="14443" end_char="14443">.</TOKEN>
</SEG>
<SEG id="segment-155" start_char="14445" end_char="14497">
<ORIGINAL_TEXT>I said a cautious yes, and the person said, I do too.</ORIGINAL_TEXT>
<TOKEN id="token-155-0" pos="word" morph="none" start_char="14445" end_char="14445">I</TOKEN>
<TOKEN id="token-155-1" pos="word" morph="none" start_char="14447" end_char="14450">said</TOKEN>
<TOKEN id="token-155-2" pos="word" morph="none" start_char="14452" end_char="14452">a</TOKEN>
<TOKEN id="token-155-3" pos="word" morph="none" start_char="14454" end_char="14461">cautious</TOKEN>
<TOKEN id="token-155-4" pos="word" morph="none" start_char="14463" end_char="14465">yes</TOKEN>
<TOKEN id="token-155-5" pos="punct" morph="none" start_char="14466" end_char="14466">,</TOKEN>
<TOKEN id="token-155-6" pos="word" morph="none" start_char="14468" end_char="14470">and</TOKEN>
<TOKEN id="token-155-7" pos="word" morph="none" start_char="14472" end_char="14474">the</TOKEN>
<TOKEN id="token-155-8" pos="word" morph="none" start_char="14476" end_char="14481">person</TOKEN>
<TOKEN id="token-155-9" pos="word" morph="none" start_char="14483" end_char="14486">said</TOKEN>
<TOKEN id="token-155-10" pos="punct" morph="none" start_char="14487" end_char="14487">,</TOKEN>
<TOKEN id="token-155-11" pos="word" morph="none" start_char="14489" end_char="14489">I</TOKEN>
<TOKEN id="token-155-12" pos="word" morph="none" start_char="14491" end_char="14492">do</TOKEN>
<TOKEN id="token-155-13" pos="word" morph="none" start_char="14494" end_char="14496">too</TOKEN>
<TOKEN id="token-155-14" pos="punct" morph="none" start_char="14497" end_char="14497">.</TOKEN>
</SEG>
<SEG id="segment-156" start_char="14499" end_char="14603">
<ORIGINAL_TEXT>This shows that even people who aren't into "the new" the way ATS people are have seen the obvious truth.</ORIGINAL_TEXT>
<TOKEN id="token-156-0" pos="word" morph="none" start_char="14499" end_char="14502">This</TOKEN>
<TOKEN id="token-156-1" pos="word" morph="none" start_char="14504" end_char="14508">shows</TOKEN>
<TOKEN id="token-156-2" pos="word" morph="none" start_char="14510" end_char="14513">that</TOKEN>
<TOKEN id="token-156-3" pos="word" morph="none" start_char="14515" end_char="14518">even</TOKEN>
<TOKEN id="token-156-4" pos="word" morph="none" start_char="14520" end_char="14525">people</TOKEN>
<TOKEN id="token-156-5" pos="word" morph="none" start_char="14527" end_char="14529">who</TOKEN>
<TOKEN id="token-156-6" pos="word" morph="none" start_char="14531" end_char="14536">aren't</TOKEN>
<TOKEN id="token-156-7" pos="word" morph="none" start_char="14538" end_char="14541">into</TOKEN>
<TOKEN id="token-156-8" pos="punct" morph="none" start_char="14543" end_char="14543">"</TOKEN>
<TOKEN id="token-156-9" pos="word" morph="none" start_char="14544" end_char="14546">the</TOKEN>
<TOKEN id="token-156-10" pos="word" morph="none" start_char="14548" end_char="14550">new</TOKEN>
<TOKEN id="token-156-11" pos="punct" morph="none" start_char="14551" end_char="14551">"</TOKEN>
<TOKEN id="token-156-12" pos="word" morph="none" start_char="14553" end_char="14555">the</TOKEN>
<TOKEN id="token-156-13" pos="word" morph="none" start_char="14557" end_char="14559">way</TOKEN>
<TOKEN id="token-156-14" pos="word" morph="none" start_char="14561" end_char="14563">ATS</TOKEN>
<TOKEN id="token-156-15" pos="word" morph="none" start_char="14565" end_char="14570">people</TOKEN>
<TOKEN id="token-156-16" pos="word" morph="none" start_char="14572" end_char="14574">are</TOKEN>
<TOKEN id="token-156-17" pos="word" morph="none" start_char="14576" end_char="14579">have</TOKEN>
<TOKEN id="token-156-18" pos="word" morph="none" start_char="14581" end_char="14584">seen</TOKEN>
<TOKEN id="token-156-19" pos="word" morph="none" start_char="14586" end_char="14588">the</TOKEN>
<TOKEN id="token-156-20" pos="word" morph="none" start_char="14590" end_char="14596">obvious</TOKEN>
<TOKEN id="token-156-21" pos="word" morph="none" start_char="14598" end_char="14602">truth</TOKEN>
<TOKEN id="token-156-22" pos="punct" morph="none" start_char="14603" end_char="14603">.</TOKEN>
</SEG>
<SEG id="segment-157" start_char="14606" end_char="14634">
<ORIGINAL_TEXT>You're argument has one flaw.</ORIGINAL_TEXT>
<TOKEN id="token-157-0" pos="word" morph="none" start_char="14606" end_char="14611">You're</TOKEN>
<TOKEN id="token-157-1" pos="word" morph="none" start_char="14613" end_char="14620">argument</TOKEN>
<TOKEN id="token-157-2" pos="word" morph="none" start_char="14622" end_char="14624">has</TOKEN>
<TOKEN id="token-157-3" pos="word" morph="none" start_char="14626" end_char="14628">one</TOKEN>
<TOKEN id="token-157-4" pos="word" morph="none" start_char="14630" end_char="14633">flaw</TOKEN>
<TOKEN id="token-157-5" pos="punct" morph="none" start_char="14634" end_char="14634">.</TOKEN>
</SEG>
<SEG id="segment-158" start_char="14637" end_char="14702">
<ORIGINAL_TEXT>The elderly in China are one of the primary sources of child care.</ORIGINAL_TEXT>
<TOKEN id="token-158-0" pos="word" morph="none" start_char="14637" end_char="14639">The</TOKEN>
<TOKEN id="token-158-1" pos="word" morph="none" start_char="14641" end_char="14647">elderly</TOKEN>
<TOKEN id="token-158-2" pos="word" morph="none" start_char="14649" end_char="14650">in</TOKEN>
<TOKEN id="token-158-3" pos="word" morph="none" start_char="14652" end_char="14656">China</TOKEN>
<TOKEN id="token-158-4" pos="word" morph="none" start_char="14658" end_char="14660">are</TOKEN>
<TOKEN id="token-158-5" pos="word" morph="none" start_char="14662" end_char="14664">one</TOKEN>
<TOKEN id="token-158-6" pos="word" morph="none" start_char="14666" end_char="14667">of</TOKEN>
<TOKEN id="token-158-7" pos="word" morph="none" start_char="14669" end_char="14671">the</TOKEN>
<TOKEN id="token-158-8" pos="word" morph="none" start_char="14673" end_char="14679">primary</TOKEN>
<TOKEN id="token-158-9" pos="word" morph="none" start_char="14681" end_char="14687">sources</TOKEN>
<TOKEN id="token-158-10" pos="word" morph="none" start_char="14689" end_char="14690">of</TOKEN>
<TOKEN id="token-158-11" pos="word" morph="none" start_char="14692" end_char="14696">child</TOKEN>
<TOKEN id="token-158-12" pos="word" morph="none" start_char="14698" end_char="14701">care</TOKEN>
<TOKEN id="token-158-13" pos="punct" morph="none" start_char="14702" end_char="14702">.</TOKEN>
</SEG>
<SEG id="segment-159" start_char="14704" end_char="14933">
<ORIGINAL_TEXT>Particularly with internal migrants (Mostly people who were born in rural areas and moved to urban areas, leaving their children behind as the Chinese system makes it difficult for them to go to school outside of their home area).</ORIGINAL_TEXT>
<TOKEN id="token-159-0" pos="word" morph="none" start_char="14704" end_char="14715">Particularly</TOKEN>
<TOKEN id="token-159-1" pos="word" morph="none" start_char="14717" end_char="14720">with</TOKEN>
<TOKEN id="token-159-2" pos="word" morph="none" start_char="14722" end_char="14729">internal</TOKEN>
<TOKEN id="token-159-3" pos="word" morph="none" start_char="14731" end_char="14738">migrants</TOKEN>
<TOKEN id="token-159-4" pos="punct" morph="none" start_char="14740" end_char="14740">(</TOKEN>
<TOKEN id="token-159-5" pos="word" morph="none" start_char="14741" end_char="14746">Mostly</TOKEN>
<TOKEN id="token-159-6" pos="word" morph="none" start_char="14748" end_char="14753">people</TOKEN>
<TOKEN id="token-159-7" pos="word" morph="none" start_char="14755" end_char="14757">who</TOKEN>
<TOKEN id="token-159-8" pos="word" morph="none" start_char="14759" end_char="14762">were</TOKEN>
<TOKEN id="token-159-9" pos="word" morph="none" start_char="14764" end_char="14767">born</TOKEN>
<TOKEN id="token-159-10" pos="word" morph="none" start_char="14769" end_char="14770">in</TOKEN>
<TOKEN id="token-159-11" pos="word" morph="none" start_char="14772" end_char="14776">rural</TOKEN>
<TOKEN id="token-159-12" pos="word" morph="none" start_char="14778" end_char="14782">areas</TOKEN>
<TOKEN id="token-159-13" pos="word" morph="none" start_char="14784" end_char="14786">and</TOKEN>
<TOKEN id="token-159-14" pos="word" morph="none" start_char="14788" end_char="14792">moved</TOKEN>
<TOKEN id="token-159-15" pos="word" morph="none" start_char="14794" end_char="14795">to</TOKEN>
<TOKEN id="token-159-16" pos="word" morph="none" start_char="14797" end_char="14801">urban</TOKEN>
<TOKEN id="token-159-17" pos="word" morph="none" start_char="14803" end_char="14807">areas</TOKEN>
<TOKEN id="token-159-18" pos="punct" morph="none" start_char="14808" end_char="14808">,</TOKEN>
<TOKEN id="token-159-19" pos="word" morph="none" start_char="14810" end_char="14816">leaving</TOKEN>
<TOKEN id="token-159-20" pos="word" morph="none" start_char="14818" end_char="14822">their</TOKEN>
<TOKEN id="token-159-21" pos="word" morph="none" start_char="14824" end_char="14831">children</TOKEN>
<TOKEN id="token-159-22" pos="word" morph="none" start_char="14833" end_char="14838">behind</TOKEN>
<TOKEN id="token-159-23" pos="word" morph="none" start_char="14840" end_char="14841">as</TOKEN>
<TOKEN id="token-159-24" pos="word" morph="none" start_char="14843" end_char="14845">the</TOKEN>
<TOKEN id="token-159-25" pos="word" morph="none" start_char="14847" end_char="14853">Chinese</TOKEN>
<TOKEN id="token-159-26" pos="word" morph="none" start_char="14855" end_char="14860">system</TOKEN>
<TOKEN id="token-159-27" pos="word" morph="none" start_char="14862" end_char="14866">makes</TOKEN>
<TOKEN id="token-159-28" pos="word" morph="none" start_char="14868" end_char="14869">it</TOKEN>
<TOKEN id="token-159-29" pos="word" morph="none" start_char="14871" end_char="14879">difficult</TOKEN>
<TOKEN id="token-159-30" pos="word" morph="none" start_char="14881" end_char="14883">for</TOKEN>
<TOKEN id="token-159-31" pos="word" morph="none" start_char="14885" end_char="14888">them</TOKEN>
<TOKEN id="token-159-32" pos="word" morph="none" start_char="14890" end_char="14891">to</TOKEN>
<TOKEN id="token-159-33" pos="word" morph="none" start_char="14893" end_char="14894">go</TOKEN>
<TOKEN id="token-159-34" pos="word" morph="none" start_char="14896" end_char="14897">to</TOKEN>
<TOKEN id="token-159-35" pos="word" morph="none" start_char="14899" end_char="14904">school</TOKEN>
<TOKEN id="token-159-36" pos="word" morph="none" start_char="14906" end_char="14912">outside</TOKEN>
<TOKEN id="token-159-37" pos="word" morph="none" start_char="14914" end_char="14915">of</TOKEN>
<TOKEN id="token-159-38" pos="word" morph="none" start_char="14917" end_char="14921">their</TOKEN>
<TOKEN id="token-159-39" pos="word" morph="none" start_char="14923" end_char="14926">home</TOKEN>
<TOKEN id="token-159-40" pos="word" morph="none" start_char="14928" end_char="14931">area</TOKEN>
<TOKEN id="token-159-41" pos="punct" morph="none" start_char="14932" end_char="14933">).</TOKEN>
</SEG>
<SEG id="segment-160" start_char="14936" end_char="14979">
<ORIGINAL_TEXT>Kill the elderly, cause a child care crisis.</ORIGINAL_TEXT>
<TOKEN id="token-160-0" pos="word" morph="none" start_char="14936" end_char="14939">Kill</TOKEN>
<TOKEN id="token-160-1" pos="word" morph="none" start_char="14941" end_char="14943">the</TOKEN>
<TOKEN id="token-160-2" pos="word" morph="none" start_char="14945" end_char="14951">elderly</TOKEN>
<TOKEN id="token-160-3" pos="punct" morph="none" start_char="14952" end_char="14952">,</TOKEN>
<TOKEN id="token-160-4" pos="word" morph="none" start_char="14954" end_char="14958">cause</TOKEN>
<TOKEN id="token-160-5" pos="word" morph="none" start_char="14960" end_char="14960">a</TOKEN>
<TOKEN id="token-160-6" pos="word" morph="none" start_char="14962" end_char="14966">child</TOKEN>
<TOKEN id="token-160-7" pos="word" morph="none" start_char="14968" end_char="14971">care</TOKEN>
<TOKEN id="token-160-8" pos="word" morph="none" start_char="14973" end_char="14978">crisis</TOKEN>
<TOKEN id="token-160-9" pos="punct" morph="none" start_char="14979" end_char="14979">.</TOKEN>
</SEG>
<SEG id="segment-161" start_char="14982" end_char="15117">
<ORIGINAL_TEXT>This virus hits the lungs, and China has a huge amount of middle aged male smokers (And Chinese cigarettes can be NASTY in the extreme).</ORIGINAL_TEXT>
<TOKEN id="token-161-0" pos="word" morph="none" start_char="14982" end_char="14985">This</TOKEN>
<TOKEN id="token-161-1" pos="word" morph="none" start_char="14987" end_char="14991">virus</TOKEN>
<TOKEN id="token-161-2" pos="word" morph="none" start_char="14993" end_char="14996">hits</TOKEN>
<TOKEN id="token-161-3" pos="word" morph="none" start_char="14998" end_char="15000">the</TOKEN>
<TOKEN id="token-161-4" pos="word" morph="none" start_char="15002" end_char="15006">lungs</TOKEN>
<TOKEN id="token-161-5" pos="punct" morph="none" start_char="15007" end_char="15007">,</TOKEN>
<TOKEN id="token-161-6" pos="word" morph="none" start_char="15009" end_char="15011">and</TOKEN>
<TOKEN id="token-161-7" pos="word" morph="none" start_char="15013" end_char="15017">China</TOKEN>
<TOKEN id="token-161-8" pos="word" morph="none" start_char="15019" end_char="15021">has</TOKEN>
<TOKEN id="token-161-9" pos="word" morph="none" start_char="15023" end_char="15023">a</TOKEN>
<TOKEN id="token-161-10" pos="word" morph="none" start_char="15025" end_char="15028">huge</TOKEN>
<TOKEN id="token-161-11" pos="word" morph="none" start_char="15030" end_char="15035">amount</TOKEN>
<TOKEN id="token-161-12" pos="word" morph="none" start_char="15037" end_char="15038">of</TOKEN>
<TOKEN id="token-161-13" pos="word" morph="none" start_char="15040" end_char="15045">middle</TOKEN>
<TOKEN id="token-161-14" pos="word" morph="none" start_char="15047" end_char="15050">aged</TOKEN>
<TOKEN id="token-161-15" pos="word" morph="none" start_char="15052" end_char="15055">male</TOKEN>
<TOKEN id="token-161-16" pos="word" morph="none" start_char="15057" end_char="15063">smokers</TOKEN>
<TOKEN id="token-161-17" pos="punct" morph="none" start_char="15065" end_char="15065">(</TOKEN>
<TOKEN id="token-161-18" pos="word" morph="none" start_char="15066" end_char="15068">And</TOKEN>
<TOKEN id="token-161-19" pos="word" morph="none" start_char="15070" end_char="15076">Chinese</TOKEN>
<TOKEN id="token-161-20" pos="word" morph="none" start_char="15078" end_char="15087">cigarettes</TOKEN>
<TOKEN id="token-161-21" pos="word" morph="none" start_char="15089" end_char="15091">can</TOKEN>
<TOKEN id="token-161-22" pos="word" morph="none" start_char="15093" end_char="15094">be</TOKEN>
<TOKEN id="token-161-23" pos="word" morph="none" start_char="15096" end_char="15100">NASTY</TOKEN>
<TOKEN id="token-161-24" pos="word" morph="none" start_char="15102" end_char="15103">in</TOKEN>
<TOKEN id="token-161-25" pos="word" morph="none" start_char="15105" end_char="15107">the</TOKEN>
<TOKEN id="token-161-26" pos="word" morph="none" start_char="15109" end_char="15115">extreme</TOKEN>
<TOKEN id="token-161-27" pos="punct" morph="none" start_char="15116" end_char="15117">).</TOKEN>
</SEG>
<SEG id="segment-162" start_char="15119" end_char="15191">
<ORIGINAL_TEXT>These people are some of the most economically productive in the country.</ORIGINAL_TEXT>
<TOKEN id="token-162-0" pos="word" morph="none" start_char="15119" end_char="15123">These</TOKEN>
<TOKEN id="token-162-1" pos="word" morph="none" start_char="15125" end_char="15130">people</TOKEN>
<TOKEN id="token-162-2" pos="word" morph="none" start_char="15132" end_char="15134">are</TOKEN>
<TOKEN id="token-162-3" pos="word" morph="none" start_char="15136" end_char="15139">some</TOKEN>
<TOKEN id="token-162-4" pos="word" morph="none" start_char="15141" end_char="15142">of</TOKEN>
<TOKEN id="token-162-5" pos="word" morph="none" start_char="15144" end_char="15146">the</TOKEN>
<TOKEN id="token-162-6" pos="word" morph="none" start_char="15148" end_char="15151">most</TOKEN>
<TOKEN id="token-162-7" pos="word" morph="none" start_char="15153" end_char="15164">economically</TOKEN>
<TOKEN id="token-162-8" pos="word" morph="none" start_char="15166" end_char="15175">productive</TOKEN>
<TOKEN id="token-162-9" pos="word" morph="none" start_char="15177" end_char="15178">in</TOKEN>
<TOKEN id="token-162-10" pos="word" morph="none" start_char="15180" end_char="15182">the</TOKEN>
<TOKEN id="token-162-11" pos="word" morph="none" start_char="15184" end_char="15190">country</TOKEN>
<TOKEN id="token-162-12" pos="punct" morph="none" start_char="15191" end_char="15191">.</TOKEN>
</SEG>
<SEG id="segment-163" start_char="15193" end_char="15296">
<ORIGINAL_TEXT>Creating a virus like this is going to hit a productive sector of the population as well as the elderly.</ORIGINAL_TEXT>
<TOKEN id="token-163-0" pos="word" morph="none" start_char="15193" end_char="15200">Creating</TOKEN>
<TOKEN id="token-163-1" pos="word" morph="none" start_char="15202" end_char="15202">a</TOKEN>
<TOKEN id="token-163-2" pos="word" morph="none" start_char="15204" end_char="15208">virus</TOKEN>
<TOKEN id="token-163-3" pos="word" morph="none" start_char="15210" end_char="15213">like</TOKEN>
<TOKEN id="token-163-4" pos="word" morph="none" start_char="15215" end_char="15218">this</TOKEN>
<TOKEN id="token-163-5" pos="word" morph="none" start_char="15220" end_char="15221">is</TOKEN>
<TOKEN id="token-163-6" pos="word" morph="none" start_char="15223" end_char="15227">going</TOKEN>
<TOKEN id="token-163-7" pos="word" morph="none" start_char="15229" end_char="15230">to</TOKEN>
<TOKEN id="token-163-8" pos="word" morph="none" start_char="15232" end_char="15234">hit</TOKEN>
<TOKEN id="token-163-9" pos="word" morph="none" start_char="15236" end_char="15236">a</TOKEN>
<TOKEN id="token-163-10" pos="word" morph="none" start_char="15238" end_char="15247">productive</TOKEN>
<TOKEN id="token-163-11" pos="word" morph="none" start_char="15249" end_char="15254">sector</TOKEN>
<TOKEN id="token-163-12" pos="word" morph="none" start_char="15256" end_char="15257">of</TOKEN>
<TOKEN id="token-163-13" pos="word" morph="none" start_char="15259" end_char="15261">the</TOKEN>
<TOKEN id="token-163-14" pos="word" morph="none" start_char="15263" end_char="15272">population</TOKEN>
<TOKEN id="token-163-15" pos="word" morph="none" start_char="15274" end_char="15275">as</TOKEN>
<TOKEN id="token-163-16" pos="word" morph="none" start_char="15277" end_char="15280">well</TOKEN>
<TOKEN id="token-163-17" pos="word" morph="none" start_char="15282" end_char="15283">as</TOKEN>
<TOKEN id="token-163-18" pos="word" morph="none" start_char="15285" end_char="15287">the</TOKEN>
<TOKEN id="token-163-19" pos="word" morph="none" start_char="15289" end_char="15295">elderly</TOKEN>
<TOKEN id="token-163-20" pos="punct" morph="none" start_char="15296" end_char="15296">.</TOKEN>
</SEG>
<SEG id="segment-164" start_char="15301" end_char="15328">
<ORIGINAL_TEXT>a reply to: ElectricUniverse</ORIGINAL_TEXT>
<TOKEN id="token-164-0" pos="word" morph="none" start_char="15301" end_char="15301">a</TOKEN>
<TOKEN id="token-164-1" pos="word" morph="none" start_char="15303" end_char="15307">reply</TOKEN>
<TOKEN id="token-164-2" pos="word" morph="none" start_char="15309" end_char="15310">to</TOKEN>
<TOKEN id="token-164-3" pos="punct" morph="none" start_char="15311" end_char="15311">:</TOKEN>
<TOKEN id="token-164-4" pos="word" morph="none" start_char="15313" end_char="15328">ElectricUniverse</TOKEN>
</SEG>
<SEG id="segment-165" start_char="15331" end_char="15441">
<ORIGINAL_TEXT>to me it's laughable how certain people always reach for a far fetched reason to find a conspiracy or cover up.</ORIGINAL_TEXT>
<TOKEN id="token-165-0" pos="word" morph="none" start_char="15331" end_char="15332">to</TOKEN>
<TOKEN id="token-165-1" pos="word" morph="none" start_char="15334" end_char="15335">me</TOKEN>
<TOKEN id="token-165-2" pos="word" morph="none" start_char="15337" end_char="15340">it's</TOKEN>
<TOKEN id="token-165-3" pos="word" morph="none" start_char="15342" end_char="15350">laughable</TOKEN>
<TOKEN id="token-165-4" pos="word" morph="none" start_char="15352" end_char="15354">how</TOKEN>
<TOKEN id="token-165-5" pos="word" morph="none" start_char="15356" end_char="15362">certain</TOKEN>
<TOKEN id="token-165-6" pos="word" morph="none" start_char="15364" end_char="15369">people</TOKEN>
<TOKEN id="token-165-7" pos="word" morph="none" start_char="15371" end_char="15376">always</TOKEN>
<TOKEN id="token-165-8" pos="word" morph="none" start_char="15378" end_char="15382">reach</TOKEN>
<TOKEN id="token-165-9" pos="word" morph="none" start_char="15384" end_char="15386">for</TOKEN>
<TOKEN id="token-165-10" pos="word" morph="none" start_char="15388" end_char="15388">a</TOKEN>
<TOKEN id="token-165-11" pos="word" morph="none" start_char="15390" end_char="15392">far</TOKEN>
<TOKEN id="token-165-12" pos="word" morph="none" start_char="15394" end_char="15400">fetched</TOKEN>
<TOKEN id="token-165-13" pos="word" morph="none" start_char="15402" end_char="15407">reason</TOKEN>
<TOKEN id="token-165-14" pos="word" morph="none" start_char="15409" end_char="15410">to</TOKEN>
<TOKEN id="token-165-15" pos="word" morph="none" start_char="15412" end_char="15415">find</TOKEN>
<TOKEN id="token-165-16" pos="word" morph="none" start_char="15417" end_char="15417">a</TOKEN>
<TOKEN id="token-165-17" pos="word" morph="none" start_char="15419" end_char="15428">conspiracy</TOKEN>
<TOKEN id="token-165-18" pos="word" morph="none" start_char="15430" end_char="15431">or</TOKEN>
<TOKEN id="token-165-19" pos="word" morph="none" start_char="15433" end_char="15437">cover</TOKEN>
<TOKEN id="token-165-20" pos="word" morph="none" start_char="15439" end_char="15440">up</TOKEN>
<TOKEN id="token-165-21" pos="punct" morph="none" start_char="15441" end_char="15441">.</TOKEN>
</SEG>
<SEG id="segment-166" start_char="15444" end_char="15496">
<ORIGINAL_TEXT>you do know what preprint means on a paper don't you?</ORIGINAL_TEXT>
<TOKEN id="token-166-0" pos="word" morph="none" start_char="15444" end_char="15446">you</TOKEN>
<TOKEN id="token-166-1" pos="word" morph="none" start_char="15448" end_char="15449">do</TOKEN>
<TOKEN id="token-166-2" pos="word" morph="none" start_char="15451" end_char="15454">know</TOKEN>
<TOKEN id="token-166-3" pos="word" morph="none" start_char="15456" end_char="15459">what</TOKEN>
<TOKEN id="token-166-4" pos="word" morph="none" start_char="15461" end_char="15468">preprint</TOKEN>
<TOKEN id="token-166-5" pos="word" morph="none" start_char="15470" end_char="15474">means</TOKEN>
<TOKEN id="token-166-6" pos="word" morph="none" start_char="15476" end_char="15477">on</TOKEN>
<TOKEN id="token-166-7" pos="word" morph="none" start_char="15479" end_char="15479">a</TOKEN>
<TOKEN id="token-166-8" pos="word" morph="none" start_char="15481" end_char="15485">paper</TOKEN>
<TOKEN id="token-166-9" pos="word" morph="none" start_char="15487" end_char="15491">don't</TOKEN>
<TOKEN id="token-166-10" pos="word" morph="none" start_char="15493" end_char="15495">you</TOKEN>
<TOKEN id="token-166-11" pos="punct" morph="none" start_char="15496" end_char="15496">?</TOKEN>
</SEG>
<SEG id="segment-167" start_char="15498" end_char="15578">
<ORIGINAL_TEXT>it means that it has not been peer reviewed or published in a scientific journal.</ORIGINAL_TEXT>
<TOKEN id="token-167-0" pos="word" morph="none" start_char="15498" end_char="15499">it</TOKEN>
<TOKEN id="token-167-1" pos="word" morph="none" start_char="15501" end_char="15505">means</TOKEN>
<TOKEN id="token-167-2" pos="word" morph="none" start_char="15507" end_char="15510">that</TOKEN>
<TOKEN id="token-167-3" pos="word" morph="none" start_char="15512" end_char="15513">it</TOKEN>
<TOKEN id="token-167-4" pos="word" morph="none" start_char="15515" end_char="15517">has</TOKEN>
<TOKEN id="token-167-5" pos="word" morph="none" start_char="15519" end_char="15521">not</TOKEN>
<TOKEN id="token-167-6" pos="word" morph="none" start_char="15523" end_char="15526">been</TOKEN>
<TOKEN id="token-167-7" pos="word" morph="none" start_char="15528" end_char="15531">peer</TOKEN>
<TOKEN id="token-167-8" pos="word" morph="none" start_char="15533" end_char="15540">reviewed</TOKEN>
<TOKEN id="token-167-9" pos="word" morph="none" start_char="15542" end_char="15543">or</TOKEN>
<TOKEN id="token-167-10" pos="word" morph="none" start_char="15545" end_char="15553">published</TOKEN>
<TOKEN id="token-167-11" pos="word" morph="none" start_char="15555" end_char="15556">in</TOKEN>
<TOKEN id="token-167-12" pos="word" morph="none" start_char="15558" end_char="15558">a</TOKEN>
<TOKEN id="token-167-13" pos="word" morph="none" start_char="15560" end_char="15569">scientific</TOKEN>
<TOKEN id="token-167-14" pos="word" morph="none" start_char="15571" end_char="15577">journal</TOKEN>
<TOKEN id="token-167-15" pos="punct" morph="none" start_char="15578" end_char="15578">.</TOKEN>
</SEG>
<SEG id="segment-168" start_char="15581" end_char="15651">
<ORIGINAL_TEXT>here i found this while trying to find a good link for your broken one.</ORIGINAL_TEXT>
<TOKEN id="token-168-0" pos="word" morph="none" start_char="15581" end_char="15584">here</TOKEN>
<TOKEN id="token-168-1" pos="word" morph="none" start_char="15586" end_char="15586">i</TOKEN>
<TOKEN id="token-168-2" pos="word" morph="none" start_char="15588" end_char="15592">found</TOKEN>
<TOKEN id="token-168-3" pos="word" morph="none" start_char="15594" end_char="15597">this</TOKEN>
<TOKEN id="token-168-4" pos="word" morph="none" start_char="15599" end_char="15603">while</TOKEN>
<TOKEN id="token-168-5" pos="word" morph="none" start_char="15605" end_char="15610">trying</TOKEN>
<TOKEN id="token-168-6" pos="word" morph="none" start_char="15612" end_char="15613">to</TOKEN>
<TOKEN id="token-168-7" pos="word" morph="none" start_char="15615" end_char="15618">find</TOKEN>
<TOKEN id="token-168-8" pos="word" morph="none" start_char="15620" end_char="15620">a</TOKEN>
<TOKEN id="token-168-9" pos="word" morph="none" start_char="15622" end_char="15625">good</TOKEN>
<TOKEN id="token-168-10" pos="word" morph="none" start_char="15627" end_char="15630">link</TOKEN>
<TOKEN id="token-168-11" pos="word" morph="none" start_char="15632" end_char="15634">for</TOKEN>
<TOKEN id="token-168-12" pos="word" morph="none" start_char="15636" end_char="15639">your</TOKEN>
<TOKEN id="token-168-13" pos="word" morph="none" start_char="15641" end_char="15646">broken</TOKEN>
<TOKEN id="token-168-14" pos="word" morph="none" start_char="15648" end_char="15650">one</TOKEN>
<TOKEN id="token-168-15" pos="punct" morph="none" start_char="15651" end_char="15651">.</TOKEN>
</SEG>
<SEG id="segment-169" start_char="15654" end_char="15810">
<ORIGINAL_TEXT>While the two authors do not provide any evidence that the novel coronavirus (SARS-CoV-2) was created in the lab, they build their case based on assumptions.</ORIGINAL_TEXT>
<TOKEN id="token-169-0" pos="word" morph="none" start_char="15654" end_char="15658">While</TOKEN>
<TOKEN id="token-169-1" pos="word" morph="none" start_char="15660" end_char="15662">the</TOKEN>
<TOKEN id="token-169-2" pos="word" morph="none" start_char="15664" end_char="15666">two</TOKEN>
<TOKEN id="token-169-3" pos="word" morph="none" start_char="15668" end_char="15674">authors</TOKEN>
<TOKEN id="token-169-4" pos="word" morph="none" start_char="15676" end_char="15677">do</TOKEN>
<TOKEN id="token-169-5" pos="word" morph="none" start_char="15679" end_char="15681">not</TOKEN>
<TOKEN id="token-169-6" pos="word" morph="none" start_char="15683" end_char="15689">provide</TOKEN>
<TOKEN id="token-169-7" pos="word" morph="none" start_char="15691" end_char="15693">any</TOKEN>
<TOKEN id="token-169-8" pos="word" morph="none" start_char="15695" end_char="15702">evidence</TOKEN>
<TOKEN id="token-169-9" pos="word" morph="none" start_char="15704" end_char="15707">that</TOKEN>
<TOKEN id="token-169-10" pos="word" morph="none" start_char="15709" end_char="15711">the</TOKEN>
<TOKEN id="token-169-11" pos="word" morph="none" start_char="15713" end_char="15717">novel</TOKEN>
<TOKEN id="token-169-12" pos="word" morph="none" start_char="15719" end_char="15729">coronavirus</TOKEN>
<TOKEN id="token-169-13" pos="punct" morph="none" start_char="15731" end_char="15731">(</TOKEN>
<TOKEN id="token-169-14" pos="unknown" morph="none" start_char="15732" end_char="15741">SARS-CoV-2</TOKEN>
<TOKEN id="token-169-15" pos="punct" morph="none" start_char="15742" end_char="15742">)</TOKEN>
<TOKEN id="token-169-16" pos="word" morph="none" start_char="15744" end_char="15746">was</TOKEN>
<TOKEN id="token-169-17" pos="word" morph="none" start_char="15748" end_char="15754">created</TOKEN>
<TOKEN id="token-169-18" pos="word" morph="none" start_char="15756" end_char="15757">in</TOKEN>
<TOKEN id="token-169-19" pos="word" morph="none" start_char="15759" end_char="15761">the</TOKEN>
<TOKEN id="token-169-20" pos="word" morph="none" start_char="15763" end_char="15765">lab</TOKEN>
<TOKEN id="token-169-21" pos="punct" morph="none" start_char="15766" end_char="15766">,</TOKEN>
<TOKEN id="token-169-22" pos="word" morph="none" start_char="15768" end_char="15771">they</TOKEN>
<TOKEN id="token-169-23" pos="word" morph="none" start_char="15773" end_char="15777">build</TOKEN>
<TOKEN id="token-169-24" pos="word" morph="none" start_char="15779" end_char="15783">their</TOKEN>
<TOKEN id="token-169-25" pos="word" morph="none" start_char="15785" end_char="15788">case</TOKEN>
<TOKEN id="token-169-26" pos="word" morph="none" start_char="15790" end_char="15794">based</TOKEN>
<TOKEN id="token-169-27" pos="word" morph="none" start_char="15796" end_char="15797">on</TOKEN>
<TOKEN id="token-169-28" pos="word" morph="none" start_char="15799" end_char="15809">assumptions</TOKEN>
<TOKEN id="token-169-29" pos="punct" morph="none" start_char="15810" end_char="15810">.</TOKEN>
</SEG>
<SEG id="segment-170" start_char="15812" end_char="16025">
<ORIGINAL_TEXT>They begin by saying that bats carrying the novel coronavirus are originally found in Yunnan or Zhejiang province, which is more than 900 km from the seafood market at the centre of the investigation on the source.</ORIGINAL_TEXT>
<TOKEN id="token-170-0" pos="word" morph="none" start_char="15812" end_char="15815">They</TOKEN>
<TOKEN id="token-170-1" pos="word" morph="none" start_char="15817" end_char="15821">begin</TOKEN>
<TOKEN id="token-170-2" pos="word" morph="none" start_char="15823" end_char="15824">by</TOKEN>
<TOKEN id="token-170-3" pos="word" morph="none" start_char="15826" end_char="15831">saying</TOKEN>
<TOKEN id="token-170-4" pos="word" morph="none" start_char="15833" end_char="15836">that</TOKEN>
<TOKEN id="token-170-5" pos="word" morph="none" start_char="15838" end_char="15841">bats</TOKEN>
<TOKEN id="token-170-6" pos="word" morph="none" start_char="15843" end_char="15850">carrying</TOKEN>
<TOKEN id="token-170-7" pos="word" morph="none" start_char="15852" end_char="15854">the</TOKEN>
<TOKEN id="token-170-8" pos="word" morph="none" start_char="15856" end_char="15860">novel</TOKEN>
<TOKEN id="token-170-9" pos="word" morph="none" start_char="15862" end_char="15872">coronavirus</TOKEN>
<TOKEN id="token-170-10" pos="word" morph="none" start_char="15874" end_char="15876">are</TOKEN>
<TOKEN id="token-170-11" pos="word" morph="none" start_char="15878" end_char="15887">originally</TOKEN>
<TOKEN id="token-170-12" pos="word" morph="none" start_char="15889" end_char="15893">found</TOKEN>
<TOKEN id="token-170-13" pos="word" morph="none" start_char="15895" end_char="15896">in</TOKEN>
<TOKEN id="token-170-14" pos="word" morph="none" start_char="15898" end_char="15903">Yunnan</TOKEN>
<TOKEN id="token-170-15" pos="word" morph="none" start_char="15905" end_char="15906">or</TOKEN>
<TOKEN id="token-170-16" pos="word" morph="none" start_char="15908" end_char="15915">Zhejiang</TOKEN>
<TOKEN id="token-170-17" pos="word" morph="none" start_char="15917" end_char="15924">province</TOKEN>
<TOKEN id="token-170-18" pos="punct" morph="none" start_char="15925" end_char="15925">,</TOKEN>
<TOKEN id="token-170-19" pos="word" morph="none" start_char="15927" end_char="15931">which</TOKEN>
<TOKEN id="token-170-20" pos="word" morph="none" start_char="15933" end_char="15934">is</TOKEN>
<TOKEN id="token-170-21" pos="word" morph="none" start_char="15936" end_char="15939">more</TOKEN>
<TOKEN id="token-170-22" pos="word" morph="none" start_char="15941" end_char="15944">than</TOKEN>
<TOKEN id="token-170-23" pos="word" morph="none" start_char="15946" end_char="15948">900</TOKEN>
<TOKEN id="token-170-24" pos="word" morph="none" start_char="15950" end_char="15951">km</TOKEN>
<TOKEN id="token-170-25" pos="word" morph="none" start_char="15953" end_char="15956">from</TOKEN>
<TOKEN id="token-170-26" pos="word" morph="none" start_char="15958" end_char="15960">the</TOKEN>
<TOKEN id="token-170-27" pos="word" morph="none" start_char="15962" end_char="15968">seafood</TOKEN>
<TOKEN id="token-170-28" pos="word" morph="none" start_char="15970" end_char="15975">market</TOKEN>
<TOKEN id="token-170-29" pos="word" morph="none" start_char="15977" end_char="15978">at</TOKEN>
<TOKEN id="token-170-30" pos="word" morph="none" start_char="15980" end_char="15982">the</TOKEN>
<TOKEN id="token-170-31" pos="word" morph="none" start_char="15984" end_char="15989">centre</TOKEN>
<TOKEN id="token-170-32" pos="word" morph="none" start_char="15991" end_char="15992">of</TOKEN>
<TOKEN id="token-170-33" pos="word" morph="none" start_char="15994" end_char="15996">the</TOKEN>
<TOKEN id="token-170-34" pos="word" morph="none" start_char="15998" end_char="16010">investigation</TOKEN>
<TOKEN id="token-170-35" pos="word" morph="none" start_char="16012" end_char="16013">on</TOKEN>
<TOKEN id="token-170-36" pos="word" morph="none" start_char="16015" end_char="16017">the</TOKEN>
<TOKEN id="token-170-37" pos="word" morph="none" start_char="16019" end_char="16024">source</TOKEN>
<TOKEN id="token-170-38" pos="punct" morph="none" start_char="16025" end_char="16025">.</TOKEN>
</SEG>
<SEG id="segment-171" start_char="16027" end_char="16085">
<ORIGINAL_TEXT>Hence, the chances of bats "flying to the market" are slim.</ORIGINAL_TEXT>
<TOKEN id="token-171-0" pos="word" morph="none" start_char="16027" end_char="16031">Hence</TOKEN>
<TOKEN id="token-171-1" pos="punct" morph="none" start_char="16032" end_char="16032">,</TOKEN>
<TOKEN id="token-171-2" pos="word" morph="none" start_char="16034" end_char="16036">the</TOKEN>
<TOKEN id="token-171-3" pos="word" morph="none" start_char="16038" end_char="16044">chances</TOKEN>
<TOKEN id="token-171-4" pos="word" morph="none" start_char="16046" end_char="16047">of</TOKEN>
<TOKEN id="token-171-5" pos="word" morph="none" start_char="16049" end_char="16052">bats</TOKEN>
<TOKEN id="token-171-6" pos="punct" morph="none" start_char="16054" end_char="16054">"</TOKEN>
<TOKEN id="token-171-7" pos="word" morph="none" start_char="16055" end_char="16060">flying</TOKEN>
<TOKEN id="token-171-8" pos="word" morph="none" start_char="16062" end_char="16063">to</TOKEN>
<TOKEN id="token-171-9" pos="word" morph="none" start_char="16065" end_char="16067">the</TOKEN>
<TOKEN id="token-171-10" pos="word" morph="none" start_char="16069" end_char="16074">market</TOKEN>
<TOKEN id="token-171-11" pos="punct" morph="none" start_char="16075" end_char="16075">"</TOKEN>
<TOKEN id="token-171-12" pos="word" morph="none" start_char="16077" end_char="16079">are</TOKEN>
<TOKEN id="token-171-13" pos="word" morph="none" start_char="16081" end_char="16084">slim</TOKEN>
<TOKEN id="token-171-14" pos="punct" morph="none" start_char="16085" end_char="16085">.</TOKEN>
</SEG>
<SEG id="segment-172" start_char="16087" end_char="16173">
<ORIGINAL_TEXT>Opinion | A preprint provides ammunition to conspiracy theories about SARS-CoV-2 origin</ORIGINAL_TEXT>
<TOKEN id="token-172-0" pos="word" morph="none" start_char="16087" end_char="16093">Opinion</TOKEN>
<TOKEN id="token-172-1" pos="unknown" morph="none" start_char="16095" end_char="16095">|</TOKEN>
<TOKEN id="token-172-2" pos="word" morph="none" start_char="16097" end_char="16097">A</TOKEN>
<TOKEN id="token-172-3" pos="word" morph="none" start_char="16099" end_char="16106">preprint</TOKEN>
<TOKEN id="token-172-4" pos="word" morph="none" start_char="16108" end_char="16115">provides</TOKEN>
<TOKEN id="token-172-5" pos="word" morph="none" start_char="16117" end_char="16126">ammunition</TOKEN>
<TOKEN id="token-172-6" pos="word" morph="none" start_char="16128" end_char="16129">to</TOKEN>
<TOKEN id="token-172-7" pos="word" morph="none" start_char="16131" end_char="16140">conspiracy</TOKEN>
<TOKEN id="token-172-8" pos="word" morph="none" start_char="16142" end_char="16149">theories</TOKEN>
<TOKEN id="token-172-9" pos="word" morph="none" start_char="16151" end_char="16155">about</TOKEN>
<TOKEN id="token-172-10" pos="unknown" morph="none" start_char="16157" end_char="16166">SARS-CoV-2</TOKEN>
<TOKEN id="token-172-11" pos="word" morph="none" start_char="16168" end_char="16173">origin</TOKEN>
</SEG>
<SEG id="segment-173" start_char="16176" end_char="16211">
<ORIGINAL_TEXT>now granted this is a Opinion piece.</ORIGINAL_TEXT>
<TOKEN id="token-173-0" pos="word" morph="none" start_char="16176" end_char="16178">now</TOKEN>
<TOKEN id="token-173-1" pos="word" morph="none" start_char="16180" end_char="16186">granted</TOKEN>
<TOKEN id="token-173-2" pos="word" morph="none" start_char="16188" end_char="16191">this</TOKEN>
<TOKEN id="token-173-3" pos="word" morph="none" start_char="16193" end_char="16194">is</TOKEN>
<TOKEN id="token-173-4" pos="word" morph="none" start_char="16196" end_char="16196">a</TOKEN>
<TOKEN id="token-173-5" pos="word" morph="none" start_char="16198" end_char="16204">Opinion</TOKEN>
<TOKEN id="token-173-6" pos="word" morph="none" start_char="16206" end_char="16210">piece</TOKEN>
<TOKEN id="token-173-7" pos="punct" morph="none" start_char="16211" end_char="16211">.</TOKEN>
</SEG>
<SEG id="segment-174" start_char="16213" end_char="16280">
<ORIGINAL_TEXT>but The Hindu is rated high for factual reporting and their sources.</ORIGINAL_TEXT>
<TOKEN id="token-174-0" pos="word" morph="none" start_char="16213" end_char="16215">but</TOKEN>
<TOKEN id="token-174-1" pos="word" morph="none" start_char="16217" end_char="16219">The</TOKEN>
<TOKEN id="token-174-2" pos="word" morph="none" start_char="16221" end_char="16225">Hindu</TOKEN>
<TOKEN id="token-174-3" pos="word" morph="none" start_char="16227" end_char="16228">is</TOKEN>
<TOKEN id="token-174-4" pos="word" morph="none" start_char="16230" end_char="16234">rated</TOKEN>
<TOKEN id="token-174-5" pos="word" morph="none" start_char="16236" end_char="16239">high</TOKEN>
<TOKEN id="token-174-6" pos="word" morph="none" start_char="16241" end_char="16243">for</TOKEN>
<TOKEN id="token-174-7" pos="word" morph="none" start_char="16245" end_char="16251">factual</TOKEN>
<TOKEN id="token-174-8" pos="word" morph="none" start_char="16253" end_char="16261">reporting</TOKEN>
<TOKEN id="token-174-9" pos="word" morph="none" start_char="16263" end_char="16265">and</TOKEN>
<TOKEN id="token-174-10" pos="word" morph="none" start_char="16267" end_char="16271">their</TOKEN>
<TOKEN id="token-174-11" pos="word" morph="none" start_char="16273" end_char="16279">sources</TOKEN>
<TOKEN id="token-174-12" pos="punct" morph="none" start_char="16280" end_char="16280">.</TOKEN>
</SEG>
<SEG id="segment-175" start_char="16283" end_char="16341">
<ORIGINAL_TEXT>These media sources have a slight to moderate liberal bias.</ORIGINAL_TEXT>
<TOKEN id="token-175-0" pos="word" morph="none" start_char="16283" end_char="16287">These</TOKEN>
<TOKEN id="token-175-1" pos="word" morph="none" start_char="16289" end_char="16293">media</TOKEN>
<TOKEN id="token-175-2" pos="word" morph="none" start_char="16295" end_char="16301">sources</TOKEN>
<TOKEN id="token-175-3" pos="word" morph="none" start_char="16303" end_char="16306">have</TOKEN>
<TOKEN id="token-175-4" pos="word" morph="none" start_char="16308" end_char="16308">a</TOKEN>
<TOKEN id="token-175-5" pos="word" morph="none" start_char="16310" end_char="16315">slight</TOKEN>
<TOKEN id="token-175-6" pos="word" morph="none" start_char="16317" end_char="16318">to</TOKEN>
<TOKEN id="token-175-7" pos="word" morph="none" start_char="16320" end_char="16327">moderate</TOKEN>
<TOKEN id="token-175-8" pos="word" morph="none" start_char="16329" end_char="16335">liberal</TOKEN>
<TOKEN id="token-175-9" pos="word" morph="none" start_char="16337" end_char="16340">bias</TOKEN>
<TOKEN id="token-175-10" pos="punct" morph="none" start_char="16341" end_char="16341">.</TOKEN>
</SEG>
<SEG id="segment-176" start_char="16343" end_char="16523">
<ORIGINAL_TEXT>They often publish factual information that utilizes loaded words (wording that attempts to influence an audience by using appeal to emotion or stereotypes) to favor liberal causes.</ORIGINAL_TEXT>
<TOKEN id="token-176-0" pos="word" morph="none" start_char="16343" end_char="16346">They</TOKEN>
<TOKEN id="token-176-1" pos="word" morph="none" start_char="16348" end_char="16352">often</TOKEN>
<TOKEN id="token-176-2" pos="word" morph="none" start_char="16354" end_char="16360">publish</TOKEN>
<TOKEN id="token-176-3" pos="word" morph="none" start_char="16362" end_char="16368">factual</TOKEN>
<TOKEN id="token-176-4" pos="word" morph="none" start_char="16370" end_char="16380">information</TOKEN>
<TOKEN id="token-176-5" pos="word" morph="none" start_char="16382" end_char="16385">that</TOKEN>
<TOKEN id="token-176-6" pos="word" morph="none" start_char="16387" end_char="16394">utilizes</TOKEN>
<TOKEN id="token-176-7" pos="word" morph="none" start_char="16396" end_char="16401">loaded</TOKEN>
<TOKEN id="token-176-8" pos="word" morph="none" start_char="16403" end_char="16407">words</TOKEN>
<TOKEN id="token-176-9" pos="punct" morph="none" start_char="16409" end_char="16409">(</TOKEN>
<TOKEN id="token-176-10" pos="word" morph="none" start_char="16410" end_char="16416">wording</TOKEN>
<TOKEN id="token-176-11" pos="word" morph="none" start_char="16418" end_char="16421">that</TOKEN>
<TOKEN id="token-176-12" pos="word" morph="none" start_char="16423" end_char="16430">attempts</TOKEN>
<TOKEN id="token-176-13" pos="word" morph="none" start_char="16432" end_char="16433">to</TOKEN>
<TOKEN id="token-176-14" pos="word" morph="none" start_char="16435" end_char="16443">influence</TOKEN>
<TOKEN id="token-176-15" pos="word" morph="none" start_char="16445" end_char="16446">an</TOKEN>
<TOKEN id="token-176-16" pos="word" morph="none" start_char="16448" end_char="16455">audience</TOKEN>
<TOKEN id="token-176-17" pos="word" morph="none" start_char="16457" end_char="16458">by</TOKEN>
<TOKEN id="token-176-18" pos="word" morph="none" start_char="16460" end_char="16464">using</TOKEN>
<TOKEN id="token-176-19" pos="word" morph="none" start_char="16466" end_char="16471">appeal</TOKEN>
<TOKEN id="token-176-20" pos="word" morph="none" start_char="16473" end_char="16474">to</TOKEN>
<TOKEN id="token-176-21" pos="word" morph="none" start_char="16476" end_char="16482">emotion</TOKEN>
<TOKEN id="token-176-22" pos="word" morph="none" start_char="16484" end_char="16485">or</TOKEN>
<TOKEN id="token-176-23" pos="word" morph="none" start_char="16487" end_char="16497">stereotypes</TOKEN>
<TOKEN id="token-176-24" pos="punct" morph="none" start_char="16498" end_char="16498">)</TOKEN>
<TOKEN id="token-176-25" pos="word" morph="none" start_char="16500" end_char="16501">to</TOKEN>
<TOKEN id="token-176-26" pos="word" morph="none" start_char="16503" end_char="16507">favor</TOKEN>
<TOKEN id="token-176-27" pos="word" morph="none" start_char="16509" end_char="16515">liberal</TOKEN>
<TOKEN id="token-176-28" pos="word" morph="none" start_char="16517" end_char="16522">causes</TOKEN>
<TOKEN id="token-176-29" pos="punct" morph="none" start_char="16523" end_char="16523">.</TOKEN>
</SEG>
<SEG id="segment-177" start_char="16525" end_char="16619">
<ORIGINAL_TEXT>These sources are generally trustworthy for information, but may require further investigation.</ORIGINAL_TEXT>
<TOKEN id="token-177-0" pos="word" morph="none" start_char="16525" end_char="16529">These</TOKEN>
<TOKEN id="token-177-1" pos="word" morph="none" start_char="16531" end_char="16537">sources</TOKEN>
<TOKEN id="token-177-2" pos="word" morph="none" start_char="16539" end_char="16541">are</TOKEN>
<TOKEN id="token-177-3" pos="word" morph="none" start_char="16543" end_char="16551">generally</TOKEN>
<TOKEN id="token-177-4" pos="word" morph="none" start_char="16553" end_char="16563">trustworthy</TOKEN>
<TOKEN id="token-177-5" pos="word" morph="none" start_char="16565" end_char="16567">for</TOKEN>
<TOKEN id="token-177-6" pos="word" morph="none" start_char="16569" end_char="16579">information</TOKEN>
<TOKEN id="token-177-7" pos="punct" morph="none" start_char="16580" end_char="16580">,</TOKEN>
<TOKEN id="token-177-8" pos="word" morph="none" start_char="16582" end_char="16584">but</TOKEN>
<TOKEN id="token-177-9" pos="word" morph="none" start_char="16586" end_char="16588">may</TOKEN>
<TOKEN id="token-177-10" pos="word" morph="none" start_char="16590" end_char="16596">require</TOKEN>
<TOKEN id="token-177-11" pos="word" morph="none" start_char="16598" end_char="16604">further</TOKEN>
<TOKEN id="token-177-12" pos="word" morph="none" start_char="16606" end_char="16618">investigation</TOKEN>
<TOKEN id="token-177-13" pos="punct" morph="none" start_char="16619" end_char="16619">.</TOKEN>
</SEG>
<SEG id="segment-178" start_char="16621" end_char="16648">
<ORIGINAL_TEXT>See all Left-Center sources.</ORIGINAL_TEXT>
<TOKEN id="token-178-0" pos="word" morph="none" start_char="16621" end_char="16623">See</TOKEN>
<TOKEN id="token-178-1" pos="word" morph="none" start_char="16625" end_char="16627">all</TOKEN>
<TOKEN id="token-178-2" pos="unknown" morph="none" start_char="16629" end_char="16639">Left-Center</TOKEN>
<TOKEN id="token-178-3" pos="word" morph="none" start_char="16641" end_char="16647">sources</TOKEN>
<TOKEN id="token-178-4" pos="punct" morph="none" start_char="16648" end_char="16648">.</TOKEN>
</SEG>
<SEG id="segment-179" start_char="16650" end_char="16736">
<ORIGINAL_TEXT>Factual Reporting: HIGH Notes: The Hindu is an English-language Indian daily newspaper.</ORIGINAL_TEXT>
<TOKEN id="token-179-0" pos="word" morph="none" start_char="16650" end_char="16656">Factual</TOKEN>
<TOKEN id="token-179-1" pos="word" morph="none" start_char="16658" end_char="16666">Reporting</TOKEN>
<TOKEN id="token-179-2" pos="punct" morph="none" start_char="16667" end_char="16667">:</TOKEN>
<TOKEN id="token-179-3" pos="word" morph="none" start_char="16669" end_char="16672">HIGH</TOKEN>
<TOKEN id="token-179-4" pos="word" morph="none" start_char="16674" end_char="16678">Notes</TOKEN>
<TOKEN id="token-179-5" pos="punct" morph="none" start_char="16679" end_char="16679">:</TOKEN>
<TOKEN id="token-179-6" pos="word" morph="none" start_char="16681" end_char="16683">The</TOKEN>
<TOKEN id="token-179-7" pos="word" morph="none" start_char="16685" end_char="16689">Hindu</TOKEN>
<TOKEN id="token-179-8" pos="word" morph="none" start_char="16691" end_char="16692">is</TOKEN>
<TOKEN id="token-179-9" pos="word" morph="none" start_char="16694" end_char="16695">an</TOKEN>
<TOKEN id="token-179-10" pos="unknown" morph="none" start_char="16697" end_char="16712">English-language</TOKEN>
<TOKEN id="token-179-11" pos="word" morph="none" start_char="16714" end_char="16719">Indian</TOKEN>
<TOKEN id="token-179-12" pos="word" morph="none" start_char="16721" end_char="16725">daily</TOKEN>
<TOKEN id="token-179-13" pos="word" morph="none" start_char="16727" end_char="16735">newspaper</TOKEN>
<TOKEN id="token-179-14" pos="punct" morph="none" start_char="16736" end_char="16736">.</TOKEN>
</SEG>
<SEG id="segment-180" start_char="16738" end_char="16865">
<ORIGINAL_TEXT>The Hindu has been accused of left-wing bias with its articles and editorials, but covers the USA with a more centrist approach.</ORIGINAL_TEXT>
<TOKEN id="token-180-0" pos="word" morph="none" start_char="16738" end_char="16740">The</TOKEN>
<TOKEN id="token-180-1" pos="word" morph="none" start_char="16742" end_char="16746">Hindu</TOKEN>
<TOKEN id="token-180-2" pos="word" morph="none" start_char="16748" end_char="16750">has</TOKEN>
<TOKEN id="token-180-3" pos="word" morph="none" start_char="16752" end_char="16755">been</TOKEN>
<TOKEN id="token-180-4" pos="word" morph="none" start_char="16757" end_char="16763">accused</TOKEN>
<TOKEN id="token-180-5" pos="word" morph="none" start_char="16765" end_char="16766">of</TOKEN>
<TOKEN id="token-180-6" pos="unknown" morph="none" start_char="16768" end_char="16776">left-wing</TOKEN>
<TOKEN id="token-180-7" pos="word" morph="none" start_char="16778" end_char="16781">bias</TOKEN>
<TOKEN id="token-180-8" pos="word" morph="none" start_char="16783" end_char="16786">with</TOKEN>
<TOKEN id="token-180-9" pos="word" morph="none" start_char="16788" end_char="16790">its</TOKEN>
<TOKEN id="token-180-10" pos="word" morph="none" start_char="16792" end_char="16799">articles</TOKEN>
<TOKEN id="token-180-11" pos="word" morph="none" start_char="16801" end_char="16803">and</TOKEN>
<TOKEN id="token-180-12" pos="word" morph="none" start_char="16805" end_char="16814">editorials</TOKEN>
<TOKEN id="token-180-13" pos="punct" morph="none" start_char="16815" end_char="16815">,</TOKEN>
<TOKEN id="token-180-14" pos="word" morph="none" start_char="16817" end_char="16819">but</TOKEN>
<TOKEN id="token-180-15" pos="word" morph="none" start_char="16821" end_char="16826">covers</TOKEN>
<TOKEN id="token-180-16" pos="word" morph="none" start_char="16828" end_char="16830">the</TOKEN>
<TOKEN id="token-180-17" pos="word" morph="none" start_char="16832" end_char="16834">USA</TOKEN>
<TOKEN id="token-180-18" pos="word" morph="none" start_char="16836" end_char="16839">with</TOKEN>
<TOKEN id="token-180-19" pos="word" morph="none" start_char="16841" end_char="16841">a</TOKEN>
<TOKEN id="token-180-20" pos="word" morph="none" start_char="16843" end_char="16846">more</TOKEN>
<TOKEN id="token-180-21" pos="word" morph="none" start_char="16848" end_char="16855">centrist</TOKEN>
<TOKEN id="token-180-22" pos="word" morph="none" start_char="16857" end_char="16864">approach</TOKEN>
<TOKEN id="token-180-23" pos="punct" morph="none" start_char="16865" end_char="16865">.</TOKEN>
</SEG>
<SEG id="segment-181" start_char="16867" end_char="16869">
<ORIGINAL_TEXT>(D.</ORIGINAL_TEXT>
<TOKEN id="token-181-0" pos="punct" morph="none" start_char="16867" end_char="16867">(</TOKEN>
<TOKEN id="token-181-1" pos="word" morph="none" start_char="16868" end_char="16868">D</TOKEN>
<TOKEN id="token-181-2" pos="punct" morph="none" start_char="16869" end_char="16869">.</TOKEN>
</SEG>
<SEG id="segment-182" start_char="16871" end_char="16901">
<ORIGINAL_TEXT>Van Zandt 10/27/2016) The Hindu</ORIGINAL_TEXT>
<TOKEN id="token-182-0" pos="word" morph="none" start_char="16871" end_char="16873">Van</TOKEN>
<TOKEN id="token-182-1" pos="word" morph="none" start_char="16875" end_char="16879">Zandt</TOKEN>
<TOKEN id="token-182-2" pos="unknown" morph="none" start_char="16881" end_char="16890">10/27/2016</TOKEN>
<TOKEN id="token-182-3" pos="punct" morph="none" start_char="16891" end_char="16891">)</TOKEN>
<TOKEN id="token-182-4" pos="word" morph="none" start_char="16893" end_char="16895">The</TOKEN>
<TOKEN id="token-182-5" pos="word" morph="none" start_char="16897" end_char="16901">Hindu</TOKEN>
</SEG>
<SEG id="segment-183" start_char="16904" end_char="17040">
<ORIGINAL_TEXT>so i guess i'm one of those certain people that would take the word of a left leaning, opinion piece over a super market tabloid any day.</ORIGINAL_TEXT>
<TOKEN id="token-183-0" pos="word" morph="none" start_char="16904" end_char="16905">so</TOKEN>
<TOKEN id="token-183-1" pos="word" morph="none" start_char="16907" end_char="16907">i</TOKEN>
<TOKEN id="token-183-2" pos="word" morph="none" start_char="16909" end_char="16913">guess</TOKEN>
<TOKEN id="token-183-3" pos="word" morph="none" start_char="16915" end_char="16917">i'm</TOKEN>
<TOKEN id="token-183-4" pos="word" morph="none" start_char="16919" end_char="16921">one</TOKEN>
<TOKEN id="token-183-5" pos="word" morph="none" start_char="16923" end_char="16924">of</TOKEN>
<TOKEN id="token-183-6" pos="word" morph="none" start_char="16926" end_char="16930">those</TOKEN>
<TOKEN id="token-183-7" pos="word" morph="none" start_char="16932" end_char="16938">certain</TOKEN>
<TOKEN id="token-183-8" pos="word" morph="none" start_char="16940" end_char="16945">people</TOKEN>
<TOKEN id="token-183-9" pos="word" morph="none" start_char="16947" end_char="16950">that</TOKEN>
<TOKEN id="token-183-10" pos="word" morph="none" start_char="16952" end_char="16956">would</TOKEN>
<TOKEN id="token-183-11" pos="word" morph="none" start_char="16958" end_char="16961">take</TOKEN>
<TOKEN id="token-183-12" pos="word" morph="none" start_char="16963" end_char="16965">the</TOKEN>
<TOKEN id="token-183-13" pos="word" morph="none" start_char="16967" end_char="16970">word</TOKEN>
<TOKEN id="token-183-14" pos="word" morph="none" start_char="16972" end_char="16973">of</TOKEN>
<TOKEN id="token-183-15" pos="word" morph="none" start_char="16975" end_char="16975">a</TOKEN>
<TOKEN id="token-183-16" pos="word" morph="none" start_char="16977" end_char="16980">left</TOKEN>
<TOKEN id="token-183-17" pos="word" morph="none" start_char="16982" end_char="16988">leaning</TOKEN>
<TOKEN id="token-183-18" pos="punct" morph="none" start_char="16989" end_char="16989">,</TOKEN>
<TOKEN id="token-183-19" pos="word" morph="none" start_char="16991" end_char="16997">opinion</TOKEN>
<TOKEN id="token-183-20" pos="word" morph="none" start_char="16999" end_char="17003">piece</TOKEN>
<TOKEN id="token-183-21" pos="word" morph="none" start_char="17005" end_char="17008">over</TOKEN>
<TOKEN id="token-183-22" pos="word" morph="none" start_char="17010" end_char="17010">a</TOKEN>
<TOKEN id="token-183-23" pos="word" morph="none" start_char="17012" end_char="17016">super</TOKEN>
<TOKEN id="token-183-24" pos="word" morph="none" start_char="17018" end_char="17023">market</TOKEN>
<TOKEN id="token-183-25" pos="word" morph="none" start_char="17025" end_char="17031">tabloid</TOKEN>
<TOKEN id="token-183-26" pos="word" morph="none" start_char="17033" end_char="17035">any</TOKEN>
<TOKEN id="token-183-27" pos="word" morph="none" start_char="17037" end_char="17039">day</TOKEN>
<TOKEN id="token-183-28" pos="punct" morph="none" start_char="17040" end_char="17040">.</TOKEN>
</SEG>
<SEG id="segment-184" start_char="17042" end_char="17121">
<ORIGINAL_TEXT>plus, did you notice that your external source has the word preprint at the top.</ORIGINAL_TEXT>
<TOKEN id="token-184-0" pos="word" morph="none" start_char="17042" end_char="17045">plus</TOKEN>
<TOKEN id="token-184-1" pos="punct" morph="none" start_char="17046" end_char="17046">,</TOKEN>
<TOKEN id="token-184-2" pos="word" morph="none" start_char="17048" end_char="17050">did</TOKEN>
<TOKEN id="token-184-3" pos="word" morph="none" start_char="17052" end_char="17054">you</TOKEN>
<TOKEN id="token-184-4" pos="word" morph="none" start_char="17056" end_char="17061">notice</TOKEN>
<TOKEN id="token-184-5" pos="word" morph="none" start_char="17063" end_char="17066">that</TOKEN>
<TOKEN id="token-184-6" pos="word" morph="none" start_char="17068" end_char="17071">your</TOKEN>
<TOKEN id="token-184-7" pos="word" morph="none" start_char="17073" end_char="17080">external</TOKEN>
<TOKEN id="token-184-8" pos="word" morph="none" start_char="17082" end_char="17087">source</TOKEN>
<TOKEN id="token-184-9" pos="word" morph="none" start_char="17089" end_char="17091">has</TOKEN>
<TOKEN id="token-184-10" pos="word" morph="none" start_char="17093" end_char="17095">the</TOKEN>
<TOKEN id="token-184-11" pos="word" morph="none" start_char="17097" end_char="17100">word</TOKEN>
<TOKEN id="token-184-12" pos="word" morph="none" start_char="17102" end_char="17109">preprint</TOKEN>
<TOKEN id="token-184-13" pos="word" morph="none" start_char="17111" end_char="17112">at</TOKEN>
<TOKEN id="token-184-14" pos="word" morph="none" start_char="17114" end_char="17116">the</TOKEN>
<TOKEN id="token-184-15" pos="word" morph="none" start_char="17118" end_char="17120">top</TOKEN>
<TOKEN id="token-184-16" pos="punct" morph="none" start_char="17121" end_char="17121">.</TOKEN>
</SEG>
<SEG id="segment-185" start_char="17124" end_char="17229">
<ORIGINAL_TEXT>also do you really believe that the WHO would back China in this so called BIO weapon escape/ or accident.</ORIGINAL_TEXT>
<TOKEN id="token-185-0" pos="word" morph="none" start_char="17124" end_char="17127">also</TOKEN>
<TOKEN id="token-185-1" pos="word" morph="none" start_char="17129" end_char="17130">do</TOKEN>
<TOKEN id="token-185-2" pos="word" morph="none" start_char="17132" end_char="17134">you</TOKEN>
<TOKEN id="token-185-3" pos="word" morph="none" start_char="17136" end_char="17141">really</TOKEN>
<TOKEN id="token-185-4" pos="word" morph="none" start_char="17143" end_char="17149">believe</TOKEN>
<TOKEN id="token-185-5" pos="word" morph="none" start_char="17151" end_char="17154">that</TOKEN>
<TOKEN id="token-185-6" pos="word" morph="none" start_char="17156" end_char="17158">the</TOKEN>
<TOKEN id="token-185-7" pos="word" morph="none" start_char="17160" end_char="17162">WHO</TOKEN>
<TOKEN id="token-185-8" pos="word" morph="none" start_char="17164" end_char="17168">would</TOKEN>
<TOKEN id="token-185-9" pos="word" morph="none" start_char="17170" end_char="17173">back</TOKEN>
<TOKEN id="token-185-10" pos="word" morph="none" start_char="17175" end_char="17179">China</TOKEN>
<TOKEN id="token-185-11" pos="word" morph="none" start_char="17181" end_char="17182">in</TOKEN>
<TOKEN id="token-185-12" pos="word" morph="none" start_char="17184" end_char="17187">this</TOKEN>
<TOKEN id="token-185-13" pos="word" morph="none" start_char="17189" end_char="17190">so</TOKEN>
<TOKEN id="token-185-14" pos="word" morph="none" start_char="17192" end_char="17197">called</TOKEN>
<TOKEN id="token-185-15" pos="word" morph="none" start_char="17199" end_char="17201">BIO</TOKEN>
<TOKEN id="token-185-16" pos="word" morph="none" start_char="17203" end_char="17208">weapon</TOKEN>
<TOKEN id="token-185-17" pos="word" morph="none" start_char="17210" end_char="17215">escape</TOKEN>
<TOKEN id="token-185-18" pos="punct" morph="none" start_char="17216" end_char="17216">/</TOKEN>
<TOKEN id="token-185-19" pos="word" morph="none" start_char="17218" end_char="17219">or</TOKEN>
<TOKEN id="token-185-20" pos="word" morph="none" start_char="17221" end_char="17228">accident</TOKEN>
<TOKEN id="token-185-21" pos="punct" morph="none" start_char="17229" end_char="17229">.</TOKEN>
</SEG>
<SEG id="segment-186" start_char="17231" end_char="17337">
<ORIGINAL_TEXT>to do that and if any evidence came out that it did cover it up their credibility would be shot completely.</ORIGINAL_TEXT>
<TOKEN id="token-186-0" pos="word" morph="none" start_char="17231" end_char="17232">to</TOKEN>
<TOKEN id="token-186-1" pos="word" morph="none" start_char="17234" end_char="17235">do</TOKEN>
<TOKEN id="token-186-2" pos="word" morph="none" start_char="17237" end_char="17240">that</TOKEN>
<TOKEN id="token-186-3" pos="word" morph="none" start_char="17242" end_char="17244">and</TOKEN>
<TOKEN id="token-186-4" pos="word" morph="none" start_char="17246" end_char="17247">if</TOKEN>
<TOKEN id="token-186-5" pos="word" morph="none" start_char="17249" end_char="17251">any</TOKEN>
<TOKEN id="token-186-6" pos="word" morph="none" start_char="17253" end_char="17260">evidence</TOKEN>
<TOKEN id="token-186-7" pos="word" morph="none" start_char="17262" end_char="17265">came</TOKEN>
<TOKEN id="token-186-8" pos="word" morph="none" start_char="17267" end_char="17269">out</TOKEN>
<TOKEN id="token-186-9" pos="word" morph="none" start_char="17271" end_char="17274">that</TOKEN>
<TOKEN id="token-186-10" pos="word" morph="none" start_char="17276" end_char="17277">it</TOKEN>
<TOKEN id="token-186-11" pos="word" morph="none" start_char="17279" end_char="17281">did</TOKEN>
<TOKEN id="token-186-12" pos="word" morph="none" start_char="17283" end_char="17287">cover</TOKEN>
<TOKEN id="token-186-13" pos="word" morph="none" start_char="17289" end_char="17290">it</TOKEN>
<TOKEN id="token-186-14" pos="word" morph="none" start_char="17292" end_char="17293">up</TOKEN>
<TOKEN id="token-186-15" pos="word" morph="none" start_char="17295" end_char="17299">their</TOKEN>
<TOKEN id="token-186-16" pos="word" morph="none" start_char="17301" end_char="17311">credibility</TOKEN>
<TOKEN id="token-186-17" pos="word" morph="none" start_char="17313" end_char="17317">would</TOKEN>
<TOKEN id="token-186-18" pos="word" morph="none" start_char="17319" end_char="17320">be</TOKEN>
<TOKEN id="token-186-19" pos="word" morph="none" start_char="17322" end_char="17325">shot</TOKEN>
<TOKEN id="token-186-20" pos="word" morph="none" start_char="17327" end_char="17336">completely</TOKEN>
<TOKEN id="token-186-21" pos="punct" morph="none" start_char="17337" end_char="17337">.</TOKEN>
</SEG>
<SEG id="segment-187" start_char="17339" end_char="17380">
<ORIGINAL_TEXT>they don't have a high degree of that now.</ORIGINAL_TEXT>
<TOKEN id="token-187-0" pos="word" morph="none" start_char="17339" end_char="17342">they</TOKEN>
<TOKEN id="token-187-1" pos="word" morph="none" start_char="17344" end_char="17348">don't</TOKEN>
<TOKEN id="token-187-2" pos="word" morph="none" start_char="17350" end_char="17353">have</TOKEN>
<TOKEN id="token-187-3" pos="word" morph="none" start_char="17355" end_char="17355">a</TOKEN>
<TOKEN id="token-187-4" pos="word" morph="none" start_char="17357" end_char="17360">high</TOKEN>
<TOKEN id="token-187-5" pos="word" morph="none" start_char="17362" end_char="17367">degree</TOKEN>
<TOKEN id="token-187-6" pos="word" morph="none" start_char="17369" end_char="17370">of</TOKEN>
<TOKEN id="token-187-7" pos="word" morph="none" start_char="17372" end_char="17375">that</TOKEN>
<TOKEN id="token-187-8" pos="word" morph="none" start_char="17377" end_char="17379">now</TOKEN>
<TOKEN id="token-187-9" pos="punct" morph="none" start_char="17380" end_char="17380">.</TOKEN>
</SEG>
<SEG id="segment-188" start_char="17383" end_char="17444">
<ORIGINAL_TEXT>edit on 14-3-2020 by hounddoghowlie because: (no reason given)</ORIGINAL_TEXT>
<TOKEN id="token-188-0" pos="word" morph="none" start_char="17383" end_char="17386">edit</TOKEN>
<TOKEN id="token-188-1" pos="word" morph="none" start_char="17388" end_char="17389">on</TOKEN>
<TOKEN id="token-188-2" pos="unknown" morph="none" start_char="17391" end_char="17399">14-3-2020</TOKEN>
<TOKEN id="token-188-3" pos="word" morph="none" start_char="17401" end_char="17402">by</TOKEN>
<TOKEN id="token-188-4" pos="word" morph="none" start_char="17404" end_char="17417">hounddoghowlie</TOKEN>
<TOKEN id="token-188-5" pos="word" morph="none" start_char="17419" end_char="17425">because</TOKEN>
<TOKEN id="token-188-6" pos="punct" morph="none" start_char="17426" end_char="17426">:</TOKEN>
<TOKEN id="token-188-7" pos="punct" morph="none" start_char="17428" end_char="17428">(</TOKEN>
<TOKEN id="token-188-8" pos="word" morph="none" start_char="17429" end_char="17430">no</TOKEN>
<TOKEN id="token-188-9" pos="word" morph="none" start_char="17432" end_char="17437">reason</TOKEN>
<TOKEN id="token-188-10" pos="word" morph="none" start_char="17439" end_char="17443">given</TOKEN>
<TOKEN id="token-188-11" pos="punct" morph="none" start_char="17444" end_char="17444">)</TOKEN>
</SEG>
<SEG id="segment-189" start_char="17447" end_char="17546">
<ORIGINAL_TEXT>oh and i forgot to mention that there is a link to your so called research paper in The Hindu piece.</ORIGINAL_TEXT>
<TOKEN id="token-189-0" pos="word" morph="none" start_char="17447" end_char="17448">oh</TOKEN>
<TOKEN id="token-189-1" pos="word" morph="none" start_char="17450" end_char="17452">and</TOKEN>
<TOKEN id="token-189-2" pos="word" morph="none" start_char="17454" end_char="17454">i</TOKEN>
<TOKEN id="token-189-3" pos="word" morph="none" start_char="17456" end_char="17461">forgot</TOKEN>
<TOKEN id="token-189-4" pos="word" morph="none" start_char="17463" end_char="17464">to</TOKEN>
<TOKEN id="token-189-5" pos="word" morph="none" start_char="17466" end_char="17472">mention</TOKEN>
<TOKEN id="token-189-6" pos="word" morph="none" start_char="17474" end_char="17477">that</TOKEN>
<TOKEN id="token-189-7" pos="word" morph="none" start_char="17479" end_char="17483">there</TOKEN>
<TOKEN id="token-189-8" pos="word" morph="none" start_char="17485" end_char="17486">is</TOKEN>
<TOKEN id="token-189-9" pos="word" morph="none" start_char="17488" end_char="17488">a</TOKEN>
<TOKEN id="token-189-10" pos="word" morph="none" start_char="17490" end_char="17493">link</TOKEN>
<TOKEN id="token-189-11" pos="word" morph="none" start_char="17495" end_char="17496">to</TOKEN>
<TOKEN id="token-189-12" pos="word" morph="none" start_char="17498" end_char="17501">your</TOKEN>
<TOKEN id="token-189-13" pos="word" morph="none" start_char="17503" end_char="17504">so</TOKEN>
<TOKEN id="token-189-14" pos="word" morph="none" start_char="17506" end_char="17511">called</TOKEN>
<TOKEN id="token-189-15" pos="word" morph="none" start_char="17513" end_char="17520">research</TOKEN>
<TOKEN id="token-189-16" pos="word" morph="none" start_char="17522" end_char="17526">paper</TOKEN>
<TOKEN id="token-189-17" pos="word" morph="none" start_char="17528" end_char="17529">in</TOKEN>
<TOKEN id="token-189-18" pos="word" morph="none" start_char="17531" end_char="17533">The</TOKEN>
<TOKEN id="token-189-19" pos="word" morph="none" start_char="17535" end_char="17539">Hindu</TOKEN>
<TOKEN id="token-189-20" pos="word" morph="none" start_char="17541" end_char="17545">piece</TOKEN>
<TOKEN id="token-189-21" pos="punct" morph="none" start_char="17546" end_char="17546">.</TOKEN>
</SEG>
<SEG id="segment-190" start_char="17548" end_char="17566">
<ORIGINAL_TEXT>it's only one page.</ORIGINAL_TEXT>
<TOKEN id="token-190-0" pos="word" morph="none" start_char="17548" end_char="17551">it's</TOKEN>
<TOKEN id="token-190-1" pos="word" morph="none" start_char="17553" end_char="17556">only</TOKEN>
<TOKEN id="token-190-2" pos="word" morph="none" start_char="17558" end_char="17560">one</TOKEN>
<TOKEN id="token-190-3" pos="word" morph="none" start_char="17562" end_char="17565">page</TOKEN>
<TOKEN id="token-190-4" pos="punct" morph="none" start_char="17566" end_char="17566">.</TOKEN>
</SEG>
<SEG id="segment-191" start_char="17568" end_char="17660">
<ORIGINAL_TEXT>what kind of self respecting researcher is going to write a paper that is only one page long.</ORIGINAL_TEXT>
<TOKEN id="token-191-0" pos="word" morph="none" start_char="17568" end_char="17571">what</TOKEN>
<TOKEN id="token-191-1" pos="word" morph="none" start_char="17573" end_char="17576">kind</TOKEN>
<TOKEN id="token-191-2" pos="word" morph="none" start_char="17578" end_char="17579">of</TOKEN>
<TOKEN id="token-191-3" pos="word" morph="none" start_char="17581" end_char="17584">self</TOKEN>
<TOKEN id="token-191-4" pos="word" morph="none" start_char="17586" end_char="17595">respecting</TOKEN>
<TOKEN id="token-191-5" pos="word" morph="none" start_char="17597" end_char="17606">researcher</TOKEN>
<TOKEN id="token-191-6" pos="word" morph="none" start_char="17608" end_char="17609">is</TOKEN>
<TOKEN id="token-191-7" pos="word" morph="none" start_char="17611" end_char="17615">going</TOKEN>
<TOKEN id="token-191-8" pos="word" morph="none" start_char="17617" end_char="17618">to</TOKEN>
<TOKEN id="token-191-9" pos="word" morph="none" start_char="17620" end_char="17624">write</TOKEN>
<TOKEN id="token-191-10" pos="word" morph="none" start_char="17626" end_char="17626">a</TOKEN>
<TOKEN id="token-191-11" pos="word" morph="none" start_char="17628" end_char="17632">paper</TOKEN>
<TOKEN id="token-191-12" pos="word" morph="none" start_char="17634" end_char="17637">that</TOKEN>
<TOKEN id="token-191-13" pos="word" morph="none" start_char="17639" end_char="17640">is</TOKEN>
<TOKEN id="token-191-14" pos="word" morph="none" start_char="17642" end_char="17645">only</TOKEN>
<TOKEN id="token-191-15" pos="word" morph="none" start_char="17647" end_char="17649">one</TOKEN>
<TOKEN id="token-191-16" pos="word" morph="none" start_char="17651" end_char="17654">page</TOKEN>
<TOKEN id="token-191-17" pos="word" morph="none" start_char="17656" end_char="17659">long</TOKEN>
<TOKEN id="token-191-18" pos="punct" morph="none" start_char="17660" end_char="17660">.</TOKEN>
</SEG>
<SEG id="segment-192" start_char="17662" end_char="17703">
<ORIGINAL_TEXT>plus he also says possible not that it is.</ORIGINAL_TEXT>
<TOKEN id="token-192-0" pos="word" morph="none" start_char="17662" end_char="17665">plus</TOKEN>
<TOKEN id="token-192-1" pos="word" morph="none" start_char="17667" end_char="17668">he</TOKEN>
<TOKEN id="token-192-2" pos="word" morph="none" start_char="17670" end_char="17673">also</TOKEN>
<TOKEN id="token-192-3" pos="word" morph="none" start_char="17675" end_char="17678">says</TOKEN>
<TOKEN id="token-192-4" pos="word" morph="none" start_char="17680" end_char="17687">possible</TOKEN>
<TOKEN id="token-192-5" pos="word" morph="none" start_char="17689" end_char="17691">not</TOKEN>
<TOKEN id="token-192-6" pos="word" morph="none" start_char="17693" end_char="17696">that</TOKEN>
<TOKEN id="token-192-7" pos="word" morph="none" start_char="17698" end_char="17699">it</TOKEN>
<TOKEN id="token-192-8" pos="word" morph="none" start_char="17701" end_char="17702">is</TOKEN>
<TOKEN id="token-192-9" pos="punct" morph="none" start_char="17703" end_char="17703">.</TOKEN>
</SEG>
<SEG id="segment-193" start_char="17705" end_char="17856">
<ORIGINAL_TEXT>it's possible that if a grass hopper could fire a .45 the birds wouldn't blank with him, or if a frog had wings he wouldn't bump his azz when he hopped.</ORIGINAL_TEXT>
<TOKEN id="token-193-0" pos="word" morph="none" start_char="17705" end_char="17708">it's</TOKEN>
<TOKEN id="token-193-1" pos="word" morph="none" start_char="17710" end_char="17717">possible</TOKEN>
<TOKEN id="token-193-2" pos="word" morph="none" start_char="17719" end_char="17722">that</TOKEN>
<TOKEN id="token-193-3" pos="word" morph="none" start_char="17724" end_char="17725">if</TOKEN>
<TOKEN id="token-193-4" pos="word" morph="none" start_char="17727" end_char="17727">a</TOKEN>
<TOKEN id="token-193-5" pos="word" morph="none" start_char="17729" end_char="17733">grass</TOKEN>
<TOKEN id="token-193-6" pos="word" morph="none" start_char="17735" end_char="17740">hopper</TOKEN>
<TOKEN id="token-193-7" pos="word" morph="none" start_char="17742" end_char="17746">could</TOKEN>
<TOKEN id="token-193-8" pos="word" morph="none" start_char="17748" end_char="17751">fire</TOKEN>
<TOKEN id="token-193-9" pos="word" morph="none" start_char="17753" end_char="17753">a</TOKEN>
<TOKEN id="token-193-10" pos="word" morph="none" start_char="17755" end_char="17757">.45</TOKEN>
<TOKEN id="token-193-11" pos="word" morph="none" start_char="17759" end_char="17761">the</TOKEN>
<TOKEN id="token-193-12" pos="word" morph="none" start_char="17763" end_char="17767">birds</TOKEN>
<TOKEN id="token-193-13" pos="word" morph="none" start_char="17769" end_char="17776">wouldn't</TOKEN>
<TOKEN id="token-193-14" pos="word" morph="none" start_char="17778" end_char="17782">blank</TOKEN>
<TOKEN id="token-193-15" pos="word" morph="none" start_char="17784" end_char="17787">with</TOKEN>
<TOKEN id="token-193-16" pos="word" morph="none" start_char="17789" end_char="17791">him</TOKEN>
<TOKEN id="token-193-17" pos="punct" morph="none" start_char="17792" end_char="17792">,</TOKEN>
<TOKEN id="token-193-18" pos="word" morph="none" start_char="17794" end_char="17795">or</TOKEN>
<TOKEN id="token-193-19" pos="word" morph="none" start_char="17797" end_char="17798">if</TOKEN>
<TOKEN id="token-193-20" pos="word" morph="none" start_char="17800" end_char="17800">a</TOKEN>
<TOKEN id="token-193-21" pos="word" morph="none" start_char="17802" end_char="17805">frog</TOKEN>
<TOKEN id="token-193-22" pos="word" morph="none" start_char="17807" end_char="17809">had</TOKEN>
<TOKEN id="token-193-23" pos="word" morph="none" start_char="17811" end_char="17815">wings</TOKEN>
<TOKEN id="token-193-24" pos="word" morph="none" start_char="17817" end_char="17818">he</TOKEN>
<TOKEN id="token-193-25" pos="word" morph="none" start_char="17820" end_char="17827">wouldn't</TOKEN>
<TOKEN id="token-193-26" pos="word" morph="none" start_char="17829" end_char="17832">bump</TOKEN>
<TOKEN id="token-193-27" pos="word" morph="none" start_char="17834" end_char="17836">his</TOKEN>
<TOKEN id="token-193-28" pos="word" morph="none" start_char="17838" end_char="17840">azz</TOKEN>
<TOKEN id="token-193-29" pos="word" morph="none" start_char="17842" end_char="17845">when</TOKEN>
<TOKEN id="token-193-30" pos="word" morph="none" start_char="17847" end_char="17848">he</TOKEN>
<TOKEN id="token-193-31" pos="word" morph="none" start_char="17850" end_char="17855">hopped</TOKEN>
<TOKEN id="token-193-32" pos="punct" morph="none" start_char="17856" end_char="17856">.</TOKEN>
</SEG>
<SEG id="segment-194" start_char="17859" end_char="17919">
<ORIGINAL_TEXT>here the paper, The possible origins of 2019-nCoV coronavirus</ORIGINAL_TEXT>
<TOKEN id="token-194-0" pos="word" morph="none" start_char="17859" end_char="17862">here</TOKEN>
<TOKEN id="token-194-1" pos="word" morph="none" start_char="17864" end_char="17866">the</TOKEN>
<TOKEN id="token-194-2" pos="word" morph="none" start_char="17868" end_char="17872">paper</TOKEN>
<TOKEN id="token-194-3" pos="punct" morph="none" start_char="17873" end_char="17873">,</TOKEN>
<TOKEN id="token-194-4" pos="word" morph="none" start_char="17875" end_char="17877">The</TOKEN>
<TOKEN id="token-194-5" pos="word" morph="none" start_char="17879" end_char="17886">possible</TOKEN>
<TOKEN id="token-194-6" pos="word" morph="none" start_char="17888" end_char="17894">origins</TOKEN>
<TOKEN id="token-194-7" pos="word" morph="none" start_char="17896" end_char="17897">of</TOKEN>
<TOKEN id="token-194-8" pos="unknown" morph="none" start_char="17899" end_char="17907">2019-nCoV</TOKEN>
<TOKEN id="token-194-9" pos="word" morph="none" start_char="17909" end_char="17919">coronavirus</TOKEN>
</SEG>
<SEG id="segment-195" start_char="17922" end_char="17983">
<ORIGINAL_TEXT>edit on 14-3-2020 by hounddoghowlie because: (no reason given)</ORIGINAL_TEXT>
<TOKEN id="token-195-0" pos="word" morph="none" start_char="17922" end_char="17925">edit</TOKEN>
<TOKEN id="token-195-1" pos="word" morph="none" start_char="17927" end_char="17928">on</TOKEN>
<TOKEN id="token-195-2" pos="unknown" morph="none" start_char="17930" end_char="17938">14-3-2020</TOKEN>
<TOKEN id="token-195-3" pos="word" morph="none" start_char="17940" end_char="17941">by</TOKEN>
<TOKEN id="token-195-4" pos="word" morph="none" start_char="17943" end_char="17956">hounddoghowlie</TOKEN>
<TOKEN id="token-195-5" pos="word" morph="none" start_char="17958" end_char="17964">because</TOKEN>
<TOKEN id="token-195-6" pos="punct" morph="none" start_char="17965" end_char="17965">:</TOKEN>
<TOKEN id="token-195-7" pos="punct" morph="none" start_char="17967" end_char="17967">(</TOKEN>
<TOKEN id="token-195-8" pos="word" morph="none" start_char="17968" end_char="17969">no</TOKEN>
<TOKEN id="token-195-9" pos="word" morph="none" start_char="17971" end_char="17976">reason</TOKEN>
<TOKEN id="token-195-10" pos="word" morph="none" start_char="17978" end_char="17982">given</TOKEN>
<TOKEN id="token-195-11" pos="punct" morph="none" start_char="17983" end_char="17983">)</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
