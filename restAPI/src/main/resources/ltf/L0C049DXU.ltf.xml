<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C049DXU" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="4243" raw_text_md5="5f1a31cbbac899b646c391ef0cdf58fd">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="98">
<ORIGINAL_TEXT>No hay evidencia para afirmar que el coronavirus actual fue creado en 2014 por un instituto inglés</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="2">No</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="4" end_char="6">hay</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="8" end_char="16">evidencia</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="18" end_char="21">para</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="23" end_char="29">afirmar</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="31" end_char="33">que</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="35" end_char="36">el</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="38" end_char="48">coronavirus</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="50" end_char="55">actual</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="57" end_char="59">fue</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="61" end_char="66">creado</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="68" end_char="69">en</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="71" end_char="74">2014</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="76" end_char="78">por</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="80" end_char="81">un</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="83" end_char="91">instituto</TOKEN>
<TOKEN id="token-0-16" pos="word" morph="none" start_char="93" end_char="98">inglés</TOKEN>
</SEG>
<SEG id="segment-1" start_char="102" end_char="204">
<ORIGINAL_TEXT>Esta no es la única desinformación ni el único mito que circula en redes sociales sobre el coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="102" end_char="105">Esta</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="107" end_char="108">no</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="110" end_char="111">es</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="113" end_char="114">la</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="116" end_char="120">única</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="122" end_char="135">desinformación</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="137" end_char="138">ni</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="140" end_char="141">el</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="143" end_char="147">único</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="149" end_char="152">mito</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="154" end_char="156">que</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="158" end_char="164">circula</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="166" end_char="167">en</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="169" end_char="173">redes</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="175" end_char="182">sociales</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="184" end_char="188">sobre</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="190" end_char="191">el</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="193" end_char="203">coronavirus</TOKEN>
<TOKEN id="token-1-18" pos="punct" morph="none" start_char="204" end_char="204">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="206" end_char="209">
<ORIGINAL_TEXT>(AP)</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="punct" morph="none" start_char="206" end_char="206">(</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="207" end_char="208">AP</TOKEN>
<TOKEN id="token-2-2" pos="punct" morph="none" start_char="209" end_char="209">)</TOKEN>
</SEG>
<SEG id="segment-3" start_char="213" end_char="354">
<ORIGINAL_TEXT>En la tarde del viernes, el ministro de Salud de la Nación, Ginés González García, se confirmó la segunda muerte en Argentina por coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="213" end_char="214">En</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="216" end_char="217">la</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="219" end_char="223">tarde</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="225" end_char="227">del</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="229" end_char="235">viernes</TOKEN>
<TOKEN id="token-3-5" pos="punct" morph="none" start_char="236" end_char="236">,</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="238" end_char="239">el</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="241" end_char="248">ministro</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="250" end_char="251">de</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="253" end_char="257">Salud</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="259" end_char="260">de</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="262" end_char="263">la</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="265" end_char="270">Nación</TOKEN>
<TOKEN id="token-3-13" pos="punct" morph="none" start_char="271" end_char="271">,</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="273" end_char="277">Ginés</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="279" end_char="286">González</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="288" end_char="293">García</TOKEN>
<TOKEN id="token-3-17" pos="punct" morph="none" start_char="294" end_char="294">,</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="296" end_char="297">se</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="299" end_char="306">confirmó</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="308" end_char="309">la</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="311" end_char="317">segunda</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="319" end_char="324">muerte</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="326" end_char="327">en</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="329" end_char="337">Argentina</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="339" end_char="341">por</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="343" end_char="353">coronavirus</TOKEN>
<TOKEN id="token-3-27" pos="punct" morph="none" start_char="354" end_char="354">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="356" end_char="410">
<ORIGINAL_TEXT>Se trata de un paciente de 61 años que llegó de Europa.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="356" end_char="357">Se</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="359" end_char="363">trata</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="365" end_char="366">de</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="368" end_char="369">un</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="371" end_char="378">paciente</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="380" end_char="381">de</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="383" end_char="384">61</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="386" end_char="389">años</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="391" end_char="393">que</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="395" end_char="399">llegó</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="401" end_char="402">de</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="404" end_char="409">Europa</TOKEN>
<TOKEN id="token-4-12" pos="punct" morph="none" start_char="410" end_char="410">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="413" end_char="614">
<ORIGINAL_TEXT>En medio de la propagación del virus, circula por WhatsApp y Facebook un video que afirma que el coronavirus "fue creado en los laboratorios de bioinformática de la empresa Pirbright Institute en 2014".</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="413" end_char="414">En</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="416" end_char="420">medio</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="422" end_char="423">de</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="425" end_char="426">la</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="428" end_char="438">propagación</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="440" end_char="442">del</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="444" end_char="448">virus</TOKEN>
<TOKEN id="token-5-7" pos="punct" morph="none" start_char="449" end_char="449">,</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="451" end_char="457">circula</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="459" end_char="461">por</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="463" end_char="470">WhatsApp</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="472" end_char="472">y</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="474" end_char="481">Facebook</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="483" end_char="484">un</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="486" end_char="490">video</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="492" end_char="494">que</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="496" end_char="501">afirma</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="503" end_char="505">que</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="507" end_char="508">el</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="510" end_char="520">coronavirus</TOKEN>
<TOKEN id="token-5-20" pos="punct" morph="none" start_char="522" end_char="522">"</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="523" end_char="525">fue</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="527" end_char="532">creado</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="534" end_char="535">en</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="537" end_char="539">los</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="541" end_char="552">laboratorios</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="554" end_char="555">de</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="557" end_char="570">bioinformática</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="572" end_char="573">de</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="575" end_char="576">la</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="578" end_char="584">empresa</TOKEN>
<TOKEN id="token-5-31" pos="word" morph="none" start_char="586" end_char="594">Pirbright</TOKEN>
<TOKEN id="token-5-32" pos="word" morph="none" start_char="596" end_char="604">Institute</TOKEN>
<TOKEN id="token-5-33" pos="word" morph="none" start_char="606" end_char="607">en</TOKEN>
<TOKEN id="token-5-34" pos="word" morph="none" start_char="609" end_char="612">2014</TOKEN>
<TOKEN id="token-5-35" pos="punct" morph="none" start_char="613" end_char="614">".</TOKEN>
</SEG>
<SEG id="segment-6" start_char="616" end_char="712">
<ORIGINAL_TEXT>El video muestra la supuesta patente de este virus, que es el que provoca la enfermedad COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="616" end_char="617">El</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="619" end_char="623">video</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="625" end_char="631">muestra</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="633" end_char="634">la</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="636" end_char="643">supuesta</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="645" end_char="651">patente</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="653" end_char="654">de</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="656" end_char="659">este</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="661" end_char="665">virus</TOKEN>
<TOKEN id="token-6-9" pos="punct" morph="none" start_char="666" end_char="666">,</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="668" end_char="670">que</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="672" end_char="673">es</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="675" end_char="676">el</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="678" end_char="680">que</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="682" end_char="688">provoca</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="690" end_char="691">la</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="693" end_char="702">enfermedad</TOKEN>
<TOKEN id="token-6-17" pos="unknown" morph="none" start_char="704" end_char="711">COVID-19</TOKEN>
<TOKEN id="token-6-18" pos="punct" morph="none" start_char="712" end_char="712">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="714" end_char="839">
<ORIGINAL_TEXT>Sin embargo, todo esto es falso: esta patente no corresponde a la nueva cepa de coronavirus, descubierta en diciembre de 2019.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="714" end_char="716">Sin</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="718" end_char="724">embargo</TOKEN>
<TOKEN id="token-7-2" pos="punct" morph="none" start_char="725" end_char="725">,</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="727" end_char="730">todo</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="732" end_char="735">esto</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="737" end_char="738">es</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="740" end_char="744">falso</TOKEN>
<TOKEN id="token-7-7" pos="punct" morph="none" start_char="745" end_char="745">:</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="747" end_char="750">esta</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="752" end_char="758">patente</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="760" end_char="761">no</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="763" end_char="773">corresponde</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="775" end_char="775">a</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="777" end_char="778">la</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="780" end_char="784">nueva</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="786" end_char="789">cepa</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="791" end_char="792">de</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="794" end_char="804">coronavirus</TOKEN>
<TOKEN id="token-7-18" pos="punct" morph="none" start_char="805" end_char="805">,</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="807" end_char="817">descubierta</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="819" end_char="820">en</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="822" end_char="830">diciembre</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="832" end_char="833">de</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="835" end_char="838">2019</TOKEN>
<TOKEN id="token-7-24" pos="punct" morph="none" start_char="839" end_char="839">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="841" end_char="893">
<ORIGINAL_TEXT>Además, el propio Pirbright Institute desmintió esto.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="841" end_char="846">Además</TOKEN>
<TOKEN id="token-8-1" pos="punct" morph="none" start_char="847" end_char="847">,</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="849" end_char="850">el</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="852" end_char="857">propio</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="859" end_char="867">Pirbright</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="869" end_char="877">Institute</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="879" end_char="887">desmintió</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="889" end_char="892">esto</TOKEN>
<TOKEN id="token-8-8" pos="punct" morph="none" start_char="893" end_char="893">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="896" end_char="1016">
<ORIGINAL_TEXT>La desinformación fue enviada para que sea verificada al menos cinco veces al WhatsApp de Chequeado (+54 9 11 3679-0690).</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="896" end_char="897">La</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="899" end_char="912">desinformación</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="914" end_char="916">fue</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="918" end_char="924">enviada</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="926" end_char="929">para</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="931" end_char="933">que</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="935" end_char="937">sea</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="939" end_char="948">verificada</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="950" end_char="951">al</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="953" end_char="957">menos</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="959" end_char="963">cinco</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="965" end_char="969">veces</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="971" end_char="972">al</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="974" end_char="981">WhatsApp</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="983" end_char="984">de</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="986" end_char="994">Chequeado</TOKEN>
<TOKEN id="token-9-16" pos="unknown" morph="none" start_char="996" end_char="999">(+54</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1001" end_char="1001">9</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1003" end_char="1004">11</TOKEN>
<TOKEN id="token-9-19" pos="unknown" morph="none" start_char="1006" end_char="1014">3679-0690</TOKEN>
<TOKEN id="token-9-20" pos="punct" morph="none" start_char="1015" end_char="1016">).</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1018" end_char="1074">
<ORIGINAL_TEXT>En Facebook, el video fue reproducido más de 6 mil veces.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1018" end_char="1019">En</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1021" end_char="1028">Facebook</TOKEN>
<TOKEN id="token-10-2" pos="punct" morph="none" start_char="1029" end_char="1029">,</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1031" end_char="1032">el</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1034" end_char="1038">video</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1040" end_char="1042">fue</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1044" end_char="1054">reproducido</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1056" end_char="1058">más</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1060" end_char="1061">de</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1063" end_char="1063">6</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1065" end_char="1067">mil</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1069" end_char="1073">veces</TOKEN>
<TOKEN id="token-10-12" pos="punct" morph="none" start_char="1074" end_char="1074">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1077" end_char="1121">
<ORIGINAL_TEXT>Por qué lo que se afirma en el video es falso</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1077" end_char="1079">Por</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1081" end_char="1083">qué</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1085" end_char="1086">lo</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1088" end_char="1090">que</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1092" end_char="1093">se</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1095" end_char="1100">afirma</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1102" end_char="1103">en</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1105" end_char="1106">el</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1108" end_char="1112">video</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1114" end_char="1115">es</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1117" end_char="1121">falso</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1124" end_char="1371">
<ORIGINAL_TEXT>El video se basa en una patente que solicitó en 2014 y publicó en 2018 el Pirbright Institute, un centro británico dedicado a la investigación y vigilancia de enfermedades virales de animales de granja y virus que se propagan de animales a humanos.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1124" end_char="1125">El</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1127" end_char="1131">video</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1133" end_char="1134">se</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1136" end_char="1139">basa</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1141" end_char="1142">en</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1144" end_char="1146">una</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1148" end_char="1154">patente</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1156" end_char="1158">que</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1160" end_char="1167">solicitó</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1169" end_char="1170">en</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1172" end_char="1175">2014</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1177" end_char="1177">y</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1179" end_char="1185">publicó</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1187" end_char="1188">en</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1190" end_char="1193">2018</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1195" end_char="1196">el</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1198" end_char="1206">Pirbright</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1208" end_char="1216">Institute</TOKEN>
<TOKEN id="token-12-18" pos="punct" morph="none" start_char="1217" end_char="1217">,</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1219" end_char="1220">un</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1222" end_char="1227">centro</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1229" end_char="1237">británico</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1239" end_char="1246">dedicado</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="1248" end_char="1248">a</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="1250" end_char="1251">la</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="1253" end_char="1265">investigación</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="1267" end_char="1267">y</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="1269" end_char="1278">vigilancia</TOKEN>
<TOKEN id="token-12-28" pos="word" morph="none" start_char="1280" end_char="1281">de</TOKEN>
<TOKEN id="token-12-29" pos="word" morph="none" start_char="1283" end_char="1294">enfermedades</TOKEN>
<TOKEN id="token-12-30" pos="word" morph="none" start_char="1296" end_char="1302">virales</TOKEN>
<TOKEN id="token-12-31" pos="word" morph="none" start_char="1304" end_char="1305">de</TOKEN>
<TOKEN id="token-12-32" pos="word" morph="none" start_char="1307" end_char="1314">animales</TOKEN>
<TOKEN id="token-12-33" pos="word" morph="none" start_char="1316" end_char="1317">de</TOKEN>
<TOKEN id="token-12-34" pos="word" morph="none" start_char="1319" end_char="1324">granja</TOKEN>
<TOKEN id="token-12-35" pos="word" morph="none" start_char="1326" end_char="1326">y</TOKEN>
<TOKEN id="token-12-36" pos="word" morph="none" start_char="1328" end_char="1332">virus</TOKEN>
<TOKEN id="token-12-37" pos="word" morph="none" start_char="1334" end_char="1336">que</TOKEN>
<TOKEN id="token-12-38" pos="word" morph="none" start_char="1338" end_char="1339">se</TOKEN>
<TOKEN id="token-12-39" pos="word" morph="none" start_char="1341" end_char="1348">propagan</TOKEN>
<TOKEN id="token-12-40" pos="word" morph="none" start_char="1350" end_char="1351">de</TOKEN>
<TOKEN id="token-12-41" pos="word" morph="none" start_char="1353" end_char="1360">animales</TOKEN>
<TOKEN id="token-12-42" pos="word" morph="none" start_char="1362" end_char="1362">a</TOKEN>
<TOKEN id="token-12-43" pos="word" morph="none" start_char="1364" end_char="1370">humanos</TOKEN>
<TOKEN id="token-12-44" pos="punct" morph="none" start_char="1371" end_char="1371">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1374" end_char="1752">
<ORIGINAL_TEXT>Sin embargo, según explicó el propio instituto en un comunicado publicado en su página web, esta patente no corresponde al nuevo coronavirus descubierto en diciembre de 2019, sino que el instituto lleva a cabo investigaciones sobre el virus de la bronquitis infecciosa (IBV), un coronavirus que infecta a las aves de corral y el Deltacoronavirus porcino que infecta a los cerdos.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1374" end_char="1376">Sin</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1378" end_char="1384">embargo</TOKEN>
<TOKEN id="token-13-2" pos="punct" morph="none" start_char="1385" end_char="1385">,</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1387" end_char="1391">según</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1393" end_char="1399">explicó</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1401" end_char="1402">el</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1404" end_char="1409">propio</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1411" end_char="1419">instituto</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1421" end_char="1422">en</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1424" end_char="1425">un</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1427" end_char="1436">comunicado</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1438" end_char="1446">publicado</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1448" end_char="1449">en</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1451" end_char="1452">su</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1454" end_char="1459">página</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1461" end_char="1463">web</TOKEN>
<TOKEN id="token-13-16" pos="punct" morph="none" start_char="1464" end_char="1464">,</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1466" end_char="1469">esta</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1471" end_char="1477">patente</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1479" end_char="1480">no</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1482" end_char="1492">corresponde</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="1494" end_char="1495">al</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="1497" end_char="1501">nuevo</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="1503" end_char="1513">coronavirus</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="1515" end_char="1525">descubierto</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="1527" end_char="1528">en</TOKEN>
<TOKEN id="token-13-26" pos="word" morph="none" start_char="1530" end_char="1538">diciembre</TOKEN>
<TOKEN id="token-13-27" pos="word" morph="none" start_char="1540" end_char="1541">de</TOKEN>
<TOKEN id="token-13-28" pos="word" morph="none" start_char="1543" end_char="1546">2019</TOKEN>
<TOKEN id="token-13-29" pos="punct" morph="none" start_char="1547" end_char="1547">,</TOKEN>
<TOKEN id="token-13-30" pos="word" morph="none" start_char="1549" end_char="1552">sino</TOKEN>
<TOKEN id="token-13-31" pos="word" morph="none" start_char="1554" end_char="1556">que</TOKEN>
<TOKEN id="token-13-32" pos="word" morph="none" start_char="1558" end_char="1559">el</TOKEN>
<TOKEN id="token-13-33" pos="word" morph="none" start_char="1561" end_char="1569">instituto</TOKEN>
<TOKEN id="token-13-34" pos="word" morph="none" start_char="1571" end_char="1575">lleva</TOKEN>
<TOKEN id="token-13-35" pos="word" morph="none" start_char="1577" end_char="1577">a</TOKEN>
<TOKEN id="token-13-36" pos="word" morph="none" start_char="1579" end_char="1582">cabo</TOKEN>
<TOKEN id="token-13-37" pos="word" morph="none" start_char="1584" end_char="1598">investigaciones</TOKEN>
<TOKEN id="token-13-38" pos="word" morph="none" start_char="1600" end_char="1604">sobre</TOKEN>
<TOKEN id="token-13-39" pos="word" morph="none" start_char="1606" end_char="1607">el</TOKEN>
<TOKEN id="token-13-40" pos="word" morph="none" start_char="1609" end_char="1613">virus</TOKEN>
<TOKEN id="token-13-41" pos="word" morph="none" start_char="1615" end_char="1616">de</TOKEN>
<TOKEN id="token-13-42" pos="word" morph="none" start_char="1618" end_char="1619">la</TOKEN>
<TOKEN id="token-13-43" pos="word" morph="none" start_char="1621" end_char="1630">bronquitis</TOKEN>
<TOKEN id="token-13-44" pos="word" morph="none" start_char="1632" end_char="1641">infecciosa</TOKEN>
<TOKEN id="token-13-45" pos="punct" morph="none" start_char="1643" end_char="1643">(</TOKEN>
<TOKEN id="token-13-46" pos="word" morph="none" start_char="1644" end_char="1646">IBV</TOKEN>
<TOKEN id="token-13-47" pos="punct" morph="none" start_char="1647" end_char="1648">),</TOKEN>
<TOKEN id="token-13-48" pos="word" morph="none" start_char="1650" end_char="1651">un</TOKEN>
<TOKEN id="token-13-49" pos="word" morph="none" start_char="1653" end_char="1663">coronavirus</TOKEN>
<TOKEN id="token-13-50" pos="word" morph="none" start_char="1665" end_char="1667">que</TOKEN>
<TOKEN id="token-13-51" pos="word" morph="none" start_char="1669" end_char="1675">infecta</TOKEN>
<TOKEN id="token-13-52" pos="word" morph="none" start_char="1677" end_char="1677">a</TOKEN>
<TOKEN id="token-13-53" pos="word" morph="none" start_char="1679" end_char="1681">las</TOKEN>
<TOKEN id="token-13-54" pos="word" morph="none" start_char="1683" end_char="1686">aves</TOKEN>
<TOKEN id="token-13-55" pos="word" morph="none" start_char="1688" end_char="1689">de</TOKEN>
<TOKEN id="token-13-56" pos="word" morph="none" start_char="1691" end_char="1696">corral</TOKEN>
<TOKEN id="token-13-57" pos="word" morph="none" start_char="1698" end_char="1698">y</TOKEN>
<TOKEN id="token-13-58" pos="word" morph="none" start_char="1700" end_char="1701">el</TOKEN>
<TOKEN id="token-13-59" pos="word" morph="none" start_char="1703" end_char="1718">Deltacoronavirus</TOKEN>
<TOKEN id="token-13-60" pos="word" morph="none" start_char="1720" end_char="1726">porcino</TOKEN>
<TOKEN id="token-13-61" pos="word" morph="none" start_char="1728" end_char="1730">que</TOKEN>
<TOKEN id="token-13-62" pos="word" morph="none" start_char="1732" end_char="1738">infecta</TOKEN>
<TOKEN id="token-13-63" pos="word" morph="none" start_char="1740" end_char="1740">a</TOKEN>
<TOKEN id="token-13-64" pos="word" morph="none" start_char="1742" end_char="1744">los</TOKEN>
<TOKEN id="token-13-65" pos="word" morph="none" start_char="1746" end_char="1751">cerdos</TOKEN>
<TOKEN id="token-13-66" pos="punct" morph="none" start_char="1752" end_char="1752">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1754" end_char="1835">
<ORIGINAL_TEXT>Además, la institución precisó que no trabaja actualmente con coronavirus humanos.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1754" end_char="1759">Además</TOKEN>
<TOKEN id="token-14-1" pos="punct" morph="none" start_char="1760" end_char="1760">,</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1762" end_char="1763">la</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1765" end_char="1775">institución</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1777" end_char="1783">precisó</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1785" end_char="1787">que</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1789" end_char="1790">no</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1792" end_char="1798">trabaja</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1800" end_char="1810">actualmente</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1812" end_char="1814">con</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1816" end_char="1826">coronavirus</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1828" end_char="1834">humanos</TOKEN>
<TOKEN id="token-14-12" pos="punct" morph="none" start_char="1835" end_char="1835">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1838" end_char="1871">
<ORIGINAL_TEXT>"El Instituto posee la Patente no.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="punct" morph="none" start_char="1838" end_char="1838">"</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1839" end_char="1840">El</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1842" end_char="1850">Instituto</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1852" end_char="1856">posee</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1858" end_char="1859">la</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1861" end_char="1867">Patente</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1869" end_char="1870">no</TOKEN>
<TOKEN id="token-15-7" pos="punct" morph="none" start_char="1871" end_char="1871">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1873" end_char="2071">
<ORIGINAL_TEXT>10130701 que cubre el desarrollo de una forma atenuada (debilitada) del coronavirus que podría usarse potencialmente como una vacuna para prevenir enfermedades respiratorias en aves y otros animales.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1873" end_char="1880">10130701</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1882" end_char="1884">que</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1886" end_char="1890">cubre</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1892" end_char="1893">el</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1895" end_char="1904">desarrollo</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1906" end_char="1907">de</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1909" end_char="1911">una</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1913" end_char="1917">forma</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1919" end_char="1926">atenuada</TOKEN>
<TOKEN id="token-16-9" pos="punct" morph="none" start_char="1928" end_char="1928">(</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="1929" end_char="1938">debilitada</TOKEN>
<TOKEN id="token-16-11" pos="punct" morph="none" start_char="1939" end_char="1939">)</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="1941" end_char="1943">del</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="1945" end_char="1955">coronavirus</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="1957" end_char="1959">que</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="1961" end_char="1966">podría</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="1968" end_char="1973">usarse</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="1975" end_char="1988">potencialmente</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="1990" end_char="1993">como</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="1995" end_char="1997">una</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="1999" end_char="2004">vacuna</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="2006" end_char="2009">para</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="2011" end_char="2018">prevenir</TOKEN>
<TOKEN id="token-16-23" pos="word" morph="none" start_char="2020" end_char="2031">enfermedades</TOKEN>
<TOKEN id="token-16-24" pos="word" morph="none" start_char="2033" end_char="2045">respiratorias</TOKEN>
<TOKEN id="token-16-25" pos="word" morph="none" start_char="2047" end_char="2048">en</TOKEN>
<TOKEN id="token-16-26" pos="word" morph="none" start_char="2050" end_char="2053">aves</TOKEN>
<TOKEN id="token-16-27" pos="word" morph="none" start_char="2055" end_char="2055">y</TOKEN>
<TOKEN id="token-16-28" pos="word" morph="none" start_char="2057" end_char="2061">otros</TOKEN>
<TOKEN id="token-16-29" pos="word" morph="none" start_char="2063" end_char="2070">animales</TOKEN>
<TOKEN id="token-16-30" pos="punct" morph="none" start_char="2071" end_char="2071">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2073" end_char="2142">
<ORIGINAL_TEXT>Muchas vacunas se hacen de esta manera, desde la gripe hasta la polio.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2073" end_char="2078">Muchas</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2080" end_char="2086">vacunas</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2088" end_char="2089">se</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2091" end_char="2095">hacen</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2097" end_char="2098">de</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2100" end_char="2103">esta</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2105" end_char="2110">manera</TOKEN>
<TOKEN id="token-17-7" pos="punct" morph="none" start_char="2111" end_char="2111">,</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2113" end_char="2117">desde</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2119" end_char="2120">la</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2122" end_char="2126">gripe</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2128" end_char="2132">hasta</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2134" end_char="2135">la</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2137" end_char="2141">polio</TOKEN>
<TOKEN id="token-17-14" pos="punct" morph="none" start_char="2142" end_char="2142">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2144" end_char="2274">
<ORIGINAL_TEXT>Todavía no hemos desarrollado una vacuna contra el VBI, pero la investigación está en curso", precisa el instituto en lo publicado.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2144" end_char="2150">Todavía</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2152" end_char="2153">no</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2155" end_char="2159">hemos</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2161" end_char="2172">desarrollado</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2174" end_char="2176">una</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2178" end_char="2183">vacuna</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2185" end_char="2190">contra</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2192" end_char="2193">el</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2195" end_char="2197">VBI</TOKEN>
<TOKEN id="token-18-9" pos="punct" morph="none" start_char="2198" end_char="2198">,</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="2200" end_char="2203">pero</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="2205" end_char="2206">la</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2208" end_char="2220">investigación</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="2222" end_char="2225">está</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="2227" end_char="2228">en</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="2230" end_char="2234">curso</TOKEN>
<TOKEN id="token-18-16" pos="punct" morph="none" start_char="2235" end_char="2236">",</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="2238" end_char="2244">precisa</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="2246" end_char="2247">el</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="2249" end_char="2257">instituto</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="2259" end_char="2260">en</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="2262" end_char="2263">lo</TOKEN>
<TOKEN id="token-18-22" pos="word" morph="none" start_char="2265" end_char="2273">publicado</TOKEN>
<TOKEN id="token-18-23" pos="punct" morph="none" start_char="2274" end_char="2274">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2277" end_char="2562">
<ORIGINAL_TEXT>Esto también fue verificado por Maldito Bulo, un sitio de fact-checking español, y Politifact, un sitio de fact-checking estadounidense, quienes concluyeron que se trata de una desinformación, y que la cepa con la que trabaja el Instituto Pirbright no es la misma del nuevo coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2277" end_char="2280">Esto</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2282" end_char="2288">también</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2290" end_char="2292">fue</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2294" end_char="2303">verificado</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2305" end_char="2307">por</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2309" end_char="2315">Maldito</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2317" end_char="2320">Bulo</TOKEN>
<TOKEN id="token-19-7" pos="punct" morph="none" start_char="2321" end_char="2321">,</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2323" end_char="2324">un</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="2326" end_char="2330">sitio</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="2332" end_char="2333">de</TOKEN>
<TOKEN id="token-19-11" pos="unknown" morph="none" start_char="2335" end_char="2347">fact-checking</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="2349" end_char="2355">español</TOKEN>
<TOKEN id="token-19-13" pos="punct" morph="none" start_char="2356" end_char="2356">,</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="2358" end_char="2358">y</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="2360" end_char="2369">Politifact</TOKEN>
<TOKEN id="token-19-16" pos="punct" morph="none" start_char="2370" end_char="2370">,</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="2372" end_char="2373">un</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="2375" end_char="2379">sitio</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="2381" end_char="2382">de</TOKEN>
<TOKEN id="token-19-20" pos="unknown" morph="none" start_char="2384" end_char="2396">fact-checking</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="2398" end_char="2411">estadounidense</TOKEN>
<TOKEN id="token-19-22" pos="punct" morph="none" start_char="2412" end_char="2412">,</TOKEN>
<TOKEN id="token-19-23" pos="word" morph="none" start_char="2414" end_char="2420">quienes</TOKEN>
<TOKEN id="token-19-24" pos="word" morph="none" start_char="2422" end_char="2432">concluyeron</TOKEN>
<TOKEN id="token-19-25" pos="word" morph="none" start_char="2434" end_char="2436">que</TOKEN>
<TOKEN id="token-19-26" pos="word" morph="none" start_char="2438" end_char="2439">se</TOKEN>
<TOKEN id="token-19-27" pos="word" morph="none" start_char="2441" end_char="2445">trata</TOKEN>
<TOKEN id="token-19-28" pos="word" morph="none" start_char="2447" end_char="2448">de</TOKEN>
<TOKEN id="token-19-29" pos="word" morph="none" start_char="2450" end_char="2452">una</TOKEN>
<TOKEN id="token-19-30" pos="word" morph="none" start_char="2454" end_char="2467">desinformación</TOKEN>
<TOKEN id="token-19-31" pos="punct" morph="none" start_char="2468" end_char="2468">,</TOKEN>
<TOKEN id="token-19-32" pos="word" morph="none" start_char="2470" end_char="2470">y</TOKEN>
<TOKEN id="token-19-33" pos="word" morph="none" start_char="2472" end_char="2474">que</TOKEN>
<TOKEN id="token-19-34" pos="word" morph="none" start_char="2476" end_char="2477">la</TOKEN>
<TOKEN id="token-19-35" pos="word" morph="none" start_char="2479" end_char="2482">cepa</TOKEN>
<TOKEN id="token-19-36" pos="word" morph="none" start_char="2484" end_char="2486">con</TOKEN>
<TOKEN id="token-19-37" pos="word" morph="none" start_char="2488" end_char="2489">la</TOKEN>
<TOKEN id="token-19-38" pos="word" morph="none" start_char="2491" end_char="2493">que</TOKEN>
<TOKEN id="token-19-39" pos="word" morph="none" start_char="2495" end_char="2501">trabaja</TOKEN>
<TOKEN id="token-19-40" pos="word" morph="none" start_char="2503" end_char="2504">el</TOKEN>
<TOKEN id="token-19-41" pos="word" morph="none" start_char="2506" end_char="2514">Instituto</TOKEN>
<TOKEN id="token-19-42" pos="word" morph="none" start_char="2516" end_char="2524">Pirbright</TOKEN>
<TOKEN id="token-19-43" pos="word" morph="none" start_char="2526" end_char="2527">no</TOKEN>
<TOKEN id="token-19-44" pos="word" morph="none" start_char="2529" end_char="2530">es</TOKEN>
<TOKEN id="token-19-45" pos="word" morph="none" start_char="2532" end_char="2533">la</TOKEN>
<TOKEN id="token-19-46" pos="word" morph="none" start_char="2535" end_char="2539">misma</TOKEN>
<TOKEN id="token-19-47" pos="word" morph="none" start_char="2541" end_char="2543">del</TOKEN>
<TOKEN id="token-19-48" pos="word" morph="none" start_char="2545" end_char="2549">nuevo</TOKEN>
<TOKEN id="token-19-49" pos="word" morph="none" start_char="2551" end_char="2561">coronavirus</TOKEN>
<TOKEN id="token-19-50" pos="punct" morph="none" start_char="2562" end_char="2562">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2565" end_char="2616">
<ORIGINAL_TEXT>Además, el video habla de algo llamado "Evento 201".</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2565" end_char="2570">Además</TOKEN>
<TOKEN id="token-20-1" pos="punct" morph="none" start_char="2571" end_char="2571">,</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2573" end_char="2574">el</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2576" end_char="2580">video</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2582" end_char="2586">habla</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2588" end_char="2589">de</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2591" end_char="2594">algo</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2596" end_char="2602">llamado</TOKEN>
<TOKEN id="token-20-8" pos="punct" morph="none" start_char="2604" end_char="2604">"</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2605" end_char="2610">Evento</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2612" end_char="2614">201</TOKEN>
<TOKEN id="token-20-11" pos="punct" morph="none" start_char="2615" end_char="2616">".</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2618" end_char="2717">
<ORIGINAL_TEXT>Según el video esto sería "un ejercicio pandémico de alto nivel", pero esto también es una falsedad.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2618" end_char="2622">Según</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2624" end_char="2625">el</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2627" end_char="2631">video</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2633" end_char="2636">esto</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2638" end_char="2642">sería</TOKEN>
<TOKEN id="token-21-5" pos="punct" morph="none" start_char="2644" end_char="2644">"</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2645" end_char="2646">un</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="2648" end_char="2656">ejercicio</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="2658" end_char="2666">pandémico</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="2668" end_char="2669">de</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="2671" end_char="2674">alto</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="2676" end_char="2680">nivel</TOKEN>
<TOKEN id="token-21-12" pos="punct" morph="none" start_char="2681" end_char="2682">",</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="2684" end_char="2687">pero</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="2689" end_char="2692">esto</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="2694" end_char="2700">también</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="2702" end_char="2703">es</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="2705" end_char="2707">una</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="2709" end_char="2716">falsedad</TOKEN>
<TOKEN id="token-21-19" pos="punct" morph="none" start_char="2717" end_char="2717">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2719" end_char="3052">
<ORIGINAL_TEXT>Tal como explicó la Universidad John Hopkins a través de un comunicado, el Evento 201 fue un "ejercicio de simulación de pandemia" realizado en Nueva York el 18 de octubre de 2019 junto con el Foro Económico Mundial y la Fundación Bill y Melinda Gates en el que no se hizo ninguna predicción sobre la situación actual del coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2719" end_char="2721">Tal</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2723" end_char="2726">como</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2728" end_char="2734">explicó</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2736" end_char="2737">la</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2739" end_char="2749">Universidad</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2751" end_char="2754">John</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2756" end_char="2762">Hopkins</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2764" end_char="2764">a</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="2766" end_char="2771">través</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="2773" end_char="2774">de</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="2776" end_char="2777">un</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="2779" end_char="2788">comunicado</TOKEN>
<TOKEN id="token-22-12" pos="punct" morph="none" start_char="2789" end_char="2789">,</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="2791" end_char="2792">el</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="2794" end_char="2799">Evento</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="2801" end_char="2803">201</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="2805" end_char="2807">fue</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="2809" end_char="2810">un</TOKEN>
<TOKEN id="token-22-18" pos="punct" morph="none" start_char="2812" end_char="2812">"</TOKEN>
<TOKEN id="token-22-19" pos="word" morph="none" start_char="2813" end_char="2821">ejercicio</TOKEN>
<TOKEN id="token-22-20" pos="word" morph="none" start_char="2823" end_char="2824">de</TOKEN>
<TOKEN id="token-22-21" pos="word" morph="none" start_char="2826" end_char="2835">simulación</TOKEN>
<TOKEN id="token-22-22" pos="word" morph="none" start_char="2837" end_char="2838">de</TOKEN>
<TOKEN id="token-22-23" pos="word" morph="none" start_char="2840" end_char="2847">pandemia</TOKEN>
<TOKEN id="token-22-24" pos="punct" morph="none" start_char="2848" end_char="2848">"</TOKEN>
<TOKEN id="token-22-25" pos="word" morph="none" start_char="2850" end_char="2858">realizado</TOKEN>
<TOKEN id="token-22-26" pos="word" morph="none" start_char="2860" end_char="2861">en</TOKEN>
<TOKEN id="token-22-27" pos="word" morph="none" start_char="2863" end_char="2867">Nueva</TOKEN>
<TOKEN id="token-22-28" pos="word" morph="none" start_char="2869" end_char="2872">York</TOKEN>
<TOKEN id="token-22-29" pos="word" morph="none" start_char="2874" end_char="2875">el</TOKEN>
<TOKEN id="token-22-30" pos="word" morph="none" start_char="2877" end_char="2878">18</TOKEN>
<TOKEN id="token-22-31" pos="word" morph="none" start_char="2880" end_char="2881">de</TOKEN>
<TOKEN id="token-22-32" pos="word" morph="none" start_char="2883" end_char="2889">octubre</TOKEN>
<TOKEN id="token-22-33" pos="word" morph="none" start_char="2891" end_char="2892">de</TOKEN>
<TOKEN id="token-22-34" pos="word" morph="none" start_char="2894" end_char="2897">2019</TOKEN>
<TOKEN id="token-22-35" pos="word" morph="none" start_char="2899" end_char="2903">junto</TOKEN>
<TOKEN id="token-22-36" pos="word" morph="none" start_char="2905" end_char="2907">con</TOKEN>
<TOKEN id="token-22-37" pos="word" morph="none" start_char="2909" end_char="2910">el</TOKEN>
<TOKEN id="token-22-38" pos="word" morph="none" start_char="2912" end_char="2915">Foro</TOKEN>
<TOKEN id="token-22-39" pos="word" morph="none" start_char="2917" end_char="2925">Económico</TOKEN>
<TOKEN id="token-22-40" pos="word" morph="none" start_char="2927" end_char="2933">Mundial</TOKEN>
<TOKEN id="token-22-41" pos="word" morph="none" start_char="2935" end_char="2935">y</TOKEN>
<TOKEN id="token-22-42" pos="word" morph="none" start_char="2937" end_char="2938">la</TOKEN>
<TOKEN id="token-22-43" pos="word" morph="none" start_char="2940" end_char="2948">Fundación</TOKEN>
<TOKEN id="token-22-44" pos="word" morph="none" start_char="2950" end_char="2953">Bill</TOKEN>
<TOKEN id="token-22-45" pos="word" morph="none" start_char="2955" end_char="2955">y</TOKEN>
<TOKEN id="token-22-46" pos="word" morph="none" start_char="2957" end_char="2963">Melinda</TOKEN>
<TOKEN id="token-22-47" pos="word" morph="none" start_char="2965" end_char="2969">Gates</TOKEN>
<TOKEN id="token-22-48" pos="word" morph="none" start_char="2971" end_char="2972">en</TOKEN>
<TOKEN id="token-22-49" pos="word" morph="none" start_char="2974" end_char="2975">el</TOKEN>
<TOKEN id="token-22-50" pos="word" morph="none" start_char="2977" end_char="2979">que</TOKEN>
<TOKEN id="token-22-51" pos="word" morph="none" start_char="2981" end_char="2982">no</TOKEN>
<TOKEN id="token-22-52" pos="word" morph="none" start_char="2984" end_char="2985">se</TOKEN>
<TOKEN id="token-22-53" pos="word" morph="none" start_char="2987" end_char="2990">hizo</TOKEN>
<TOKEN id="token-22-54" pos="word" morph="none" start_char="2992" end_char="2998">ninguna</TOKEN>
<TOKEN id="token-22-55" pos="word" morph="none" start_char="3000" end_char="3009">predicción</TOKEN>
<TOKEN id="token-22-56" pos="word" morph="none" start_char="3011" end_char="3015">sobre</TOKEN>
<TOKEN id="token-22-57" pos="word" morph="none" start_char="3017" end_char="3018">la</TOKEN>
<TOKEN id="token-22-58" pos="word" morph="none" start_char="3020" end_char="3028">situación</TOKEN>
<TOKEN id="token-22-59" pos="word" morph="none" start_char="3030" end_char="3035">actual</TOKEN>
<TOKEN id="token-22-60" pos="word" morph="none" start_char="3037" end_char="3039">del</TOKEN>
<TOKEN id="token-22-61" pos="word" morph="none" start_char="3041" end_char="3051">coronavirus</TOKEN>
<TOKEN id="token-22-62" pos="punct" morph="none" start_char="3052" end_char="3052">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="3055" end_char="3179">
<ORIGINAL_TEXT>"Para el escenario, modelamos una pandemia de coronavirus ficticia, pero declaramos explícitamente que no era una predicción.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="punct" morph="none" start_char="3055" end_char="3055">"</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="3056" end_char="3059">Para</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="3061" end_char="3062">el</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="3064" end_char="3072">escenario</TOKEN>
<TOKEN id="token-23-4" pos="punct" morph="none" start_char="3073" end_char="3073">,</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="3075" end_char="3083">modelamos</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="3085" end_char="3087">una</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="3089" end_char="3096">pandemia</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="3098" end_char="3099">de</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="3101" end_char="3111">coronavirus</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="3113" end_char="3120">ficticia</TOKEN>
<TOKEN id="token-23-11" pos="punct" morph="none" start_char="3121" end_char="3121">,</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="3123" end_char="3126">pero</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="3128" end_char="3137">declaramos</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="3139" end_char="3152">explícitamente</TOKEN>
<TOKEN id="token-23-15" pos="word" morph="none" start_char="3154" end_char="3156">que</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="3158" end_char="3159">no</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="3161" end_char="3163">era</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="3165" end_char="3167">una</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="3169" end_char="3178">predicción</TOKEN>
<TOKEN id="token-23-20" pos="punct" morph="none" start_char="3179" end_char="3179">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="3181" end_char="3319">
<ORIGINAL_TEXT>En cambio, el ejercicio sirvió para destacar los desafíos de preparación y respuesta que probablemente surgirían en una pandemia muy grave.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="3181" end_char="3182">En</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="3184" end_char="3189">cambio</TOKEN>
<TOKEN id="token-24-2" pos="punct" morph="none" start_char="3190" end_char="3190">,</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="3192" end_char="3193">el</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="3195" end_char="3203">ejercicio</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="3205" end_char="3210">sirvió</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="3212" end_char="3215">para</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="3217" end_char="3224">destacar</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="3226" end_char="3228">los</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="3230" end_char="3237">desafíos</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="3239" end_char="3240">de</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="3242" end_char="3252">preparación</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="3254" end_char="3254">y</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="3256" end_char="3264">respuesta</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="3266" end_char="3268">que</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="3270" end_char="3282">probablemente</TOKEN>
<TOKEN id="token-24-16" pos="word" morph="none" start_char="3284" end_char="3292">surgirían</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="3294" end_char="3295">en</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="3297" end_char="3299">una</TOKEN>
<TOKEN id="token-24-19" pos="word" morph="none" start_char="3301" end_char="3308">pandemia</TOKEN>
<TOKEN id="token-24-20" pos="word" morph="none" start_char="3310" end_char="3312">muy</TOKEN>
<TOKEN id="token-24-21" pos="word" morph="none" start_char="3314" end_char="3318">grave</TOKEN>
<TOKEN id="token-24-22" pos="punct" morph="none" start_char="3319" end_char="3319">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="3321" end_char="3393">
<ORIGINAL_TEXT>No predecimos que el brote de nCoV-2019 matará a 65 millones de personas.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="3321" end_char="3322">No</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="3324" end_char="3333">predecimos</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="3335" end_char="3337">que</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="3339" end_char="3340">el</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="3342" end_char="3346">brote</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="3348" end_char="3349">de</TOKEN>
<TOKEN id="token-25-6" pos="unknown" morph="none" start_char="3351" end_char="3359">nCoV-2019</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="3361" end_char="3366">matará</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="3368" end_char="3368">a</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="3370" end_char="3371">65</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="3373" end_char="3380">millones</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="3382" end_char="3383">de</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="3385" end_char="3392">personas</TOKEN>
<TOKEN id="token-25-13" pos="punct" morph="none" start_char="3393" end_char="3393">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="3395" end_char="3628">
<ORIGINAL_TEXT>Aunque nuestro ejercicio de simulación incluía un falso y novedoso coronavirus, los datos que utilizamos para modelar el posible impacto de ese virus ficticio no son similares a los del nCoV-2019", explica la Universidad John Hopkins.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="3395" end_char="3400">Aunque</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="3402" end_char="3408">nuestro</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="3410" end_char="3418">ejercicio</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="3420" end_char="3421">de</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="3423" end_char="3432">simulación</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="3434" end_char="3440">incluía</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="3442" end_char="3443">un</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="3445" end_char="3449">falso</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="3451" end_char="3451">y</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="3453" end_char="3460">novedoso</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="3462" end_char="3472">coronavirus</TOKEN>
<TOKEN id="token-26-11" pos="punct" morph="none" start_char="3473" end_char="3473">,</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="3475" end_char="3477">los</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="3479" end_char="3483">datos</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="3485" end_char="3487">que</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="3489" end_char="3498">utilizamos</TOKEN>
<TOKEN id="token-26-16" pos="word" morph="none" start_char="3500" end_char="3503">para</TOKEN>
<TOKEN id="token-26-17" pos="word" morph="none" start_char="3505" end_char="3511">modelar</TOKEN>
<TOKEN id="token-26-18" pos="word" morph="none" start_char="3513" end_char="3514">el</TOKEN>
<TOKEN id="token-26-19" pos="word" morph="none" start_char="3516" end_char="3522">posible</TOKEN>
<TOKEN id="token-26-20" pos="word" morph="none" start_char="3524" end_char="3530">impacto</TOKEN>
<TOKEN id="token-26-21" pos="word" morph="none" start_char="3532" end_char="3533">de</TOKEN>
<TOKEN id="token-26-22" pos="word" morph="none" start_char="3535" end_char="3537">ese</TOKEN>
<TOKEN id="token-26-23" pos="word" morph="none" start_char="3539" end_char="3543">virus</TOKEN>
<TOKEN id="token-26-24" pos="word" morph="none" start_char="3545" end_char="3552">ficticio</TOKEN>
<TOKEN id="token-26-25" pos="word" morph="none" start_char="3554" end_char="3555">no</TOKEN>
<TOKEN id="token-26-26" pos="word" morph="none" start_char="3557" end_char="3559">son</TOKEN>
<TOKEN id="token-26-27" pos="word" morph="none" start_char="3561" end_char="3569">similares</TOKEN>
<TOKEN id="token-26-28" pos="word" morph="none" start_char="3571" end_char="3571">a</TOKEN>
<TOKEN id="token-26-29" pos="word" morph="none" start_char="3573" end_char="3575">los</TOKEN>
<TOKEN id="token-26-30" pos="word" morph="none" start_char="3577" end_char="3579">del</TOKEN>
<TOKEN id="token-26-31" pos="unknown" morph="none" start_char="3581" end_char="3589">nCoV-2019</TOKEN>
<TOKEN id="token-26-32" pos="punct" morph="none" start_char="3590" end_char="3591">",</TOKEN>
<TOKEN id="token-26-33" pos="word" morph="none" start_char="3593" end_char="3599">explica</TOKEN>
<TOKEN id="token-26-34" pos="word" morph="none" start_char="3601" end_char="3602">la</TOKEN>
<TOKEN id="token-26-35" pos="word" morph="none" start_char="3604" end_char="3614">Universidad</TOKEN>
<TOKEN id="token-26-36" pos="word" morph="none" start_char="3616" end_char="3619">John</TOKEN>
<TOKEN id="token-26-37" pos="word" morph="none" start_char="3621" end_char="3627">Hopkins</TOKEN>
<TOKEN id="token-26-38" pos="punct" morph="none" start_char="3628" end_char="3628">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="3631" end_char="3733">
<ORIGINAL_TEXT>Esta no es la única desinformación ni el único mito que circula en redes sociales sobre el coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="3631" end_char="3634">Esta</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="3636" end_char="3637">no</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="3639" end_char="3640">es</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="3642" end_char="3643">la</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="3645" end_char="3649">única</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="3651" end_char="3664">desinformación</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="3666" end_char="3667">ni</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="3669" end_char="3670">el</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="3672" end_char="3676">único</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="3678" end_char="3681">mito</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="3683" end_char="3685">que</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="3687" end_char="3693">circula</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="3695" end_char="3696">en</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="3698" end_char="3702">redes</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="3704" end_char="3711">sociales</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="3713" end_char="3717">sobre</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="3719" end_char="3720">el</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="3722" end_char="3732">coronavirus</TOKEN>
<TOKEN id="token-27-18" pos="punct" morph="none" start_char="3733" end_char="3733">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3735" end_char="3902">
<ORIGINAL_TEXT>Chequeado ya desmintió diferentes falsedades y además publicó una serie de certezas, comunicadas por organismos sanitarios nacionales e internacionales, sobre el virus.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="3735" end_char="3743">Chequeado</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="3745" end_char="3746">ya</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="3748" end_char="3756">desmintió</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="3758" end_char="3767">diferentes</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="3769" end_char="3778">falsedades</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="3780" end_char="3780">y</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="3782" end_char="3787">además</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="3789" end_char="3795">publicó</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="3797" end_char="3799">una</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="3801" end_char="3805">serie</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="3807" end_char="3808">de</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="3810" end_char="3817">certezas</TOKEN>
<TOKEN id="token-28-12" pos="punct" morph="none" start_char="3818" end_char="3818">,</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="3820" end_char="3830">comunicadas</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="3832" end_char="3834">por</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="3836" end_char="3845">organismos</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="3847" end_char="3856">sanitarios</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="3858" end_char="3867">nacionales</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="3869" end_char="3869">e</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="3871" end_char="3885">internacionales</TOKEN>
<TOKEN id="token-28-20" pos="punct" morph="none" start_char="3886" end_char="3886">,</TOKEN>
<TOKEN id="token-28-21" pos="word" morph="none" start_char="3888" end_char="3892">sobre</TOKEN>
<TOKEN id="token-28-22" pos="word" morph="none" start_char="3894" end_char="3895">el</TOKEN>
<TOKEN id="token-28-23" pos="word" morph="none" start_char="3897" end_char="3901">virus</TOKEN>
<TOKEN id="token-28-24" pos="punct" morph="none" start_char="3902" end_char="3902">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3904" end_char="3963">
<ORIGINAL_TEXT>Toda la información verificada está disponible en esta nota.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="3904" end_char="3907">Toda</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="3909" end_char="3910">la</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="3912" end_char="3922">información</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="3924" end_char="3933">verificada</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="3935" end_char="3938">está</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="3940" end_char="3949">disponible</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="3951" end_char="3952">en</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="3954" end_char="3957">esta</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="3959" end_char="3962">nota</TOKEN>
<TOKEN id="token-29-9" pos="punct" morph="none" start_char="3963" end_char="3963">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3966" end_char="4057">
<ORIGINAL_TEXT>Este chequeo es parte de la iniciativa Third Party Fact-checker de Facebook en la Argentina.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="3966" end_char="3969">Este</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="3971" end_char="3977">chequeo</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="3979" end_char="3980">es</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="3982" end_char="3986">parte</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="3988" end_char="3989">de</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="3991" end_char="3992">la</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="3994" end_char="4003">iniciativa</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="4005" end_char="4009">Third</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="4011" end_char="4015">Party</TOKEN>
<TOKEN id="token-30-9" pos="unknown" morph="none" start_char="4017" end_char="4028">Fact-checker</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="4030" end_char="4031">de</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="4033" end_char="4040">Facebook</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="4042" end_char="4043">en</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="4045" end_char="4046">la</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="4048" end_char="4056">Argentina</TOKEN>
<TOKEN id="token-30-15" pos="punct" morph="none" start_char="4057" end_char="4057">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="4059" end_char="4239">
<ORIGINAL_TEXT>En los casos de fotos y videos trabajamos con imágenes trucadas o sacadas de contexto y siempre analizamos en conjunto las imágenes junto con el texto con el que fueron presentadas.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="4059" end_char="4060">En</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="4062" end_char="4064">los</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="4066" end_char="4070">casos</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="4072" end_char="4073">de</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="4075" end_char="4079">fotos</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="4081" end_char="4081">y</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="4083" end_char="4088">videos</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="4090" end_char="4099">trabajamos</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="4101" end_char="4103">con</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="4105" end_char="4112">imágenes</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="4114" end_char="4121">trucadas</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="4123" end_char="4123">o</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="4125" end_char="4131">sacadas</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="4133" end_char="4134">de</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="4136" end_char="4143">contexto</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="4145" end_char="4145">y</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="4147" end_char="4153">siempre</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="4155" end_char="4164">analizamos</TOKEN>
<TOKEN id="token-31-18" pos="word" morph="none" start_char="4166" end_char="4167">en</TOKEN>
<TOKEN id="token-31-19" pos="word" morph="none" start_char="4169" end_char="4176">conjunto</TOKEN>
<TOKEN id="token-31-20" pos="word" morph="none" start_char="4178" end_char="4180">las</TOKEN>
<TOKEN id="token-31-21" pos="word" morph="none" start_char="4182" end_char="4189">imágenes</TOKEN>
<TOKEN id="token-31-22" pos="word" morph="none" start_char="4191" end_char="4195">junto</TOKEN>
<TOKEN id="token-31-23" pos="word" morph="none" start_char="4197" end_char="4199">con</TOKEN>
<TOKEN id="token-31-24" pos="word" morph="none" start_char="4201" end_char="4202">el</TOKEN>
<TOKEN id="token-31-25" pos="word" morph="none" start_char="4204" end_char="4208">texto</TOKEN>
<TOKEN id="token-31-26" pos="word" morph="none" start_char="4210" end_char="4212">con</TOKEN>
<TOKEN id="token-31-27" pos="word" morph="none" start_char="4214" end_char="4215">el</TOKEN>
<TOKEN id="token-31-28" pos="word" morph="none" start_char="4217" end_char="4219">que</TOKEN>
<TOKEN id="token-31-29" pos="word" morph="none" start_char="4221" end_char="4226">fueron</TOKEN>
<TOKEN id="token-31-30" pos="word" morph="none" start_char="4228" end_char="4238">presentadas</TOKEN>
<TOKEN id="token-31-31" pos="punct" morph="none" start_char="4239" end_char="4239">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
