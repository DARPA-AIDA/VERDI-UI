<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CAB6" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="2335" raw_text_md5="965d6ae454fcb1fb7e52fcb93ffc42c0">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="85">
<ORIGINAL_TEXT>Новая теория коронавируса – он существовал всегда, но находился в «спящем» состоянии.</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="5">Новая</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="7" end_char="12">теория</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="14" end_char="25">коронавируса</TOKEN>
<TOKEN id="token-0-3" pos="punct" morph="none" start_char="27" end_char="27">–</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="29" end_char="30">он</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="32" end_char="42">существовал</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="44" end_char="49">всегда</TOKEN>
<TOKEN id="token-0-7" pos="punct" morph="none" start_char="50" end_char="50">,</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="52" end_char="53">но</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="55" end_char="63">находился</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="65" end_char="65">в</TOKEN>
<TOKEN id="token-0-11" pos="punct" morph="none" start_char="67" end_char="67">«</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="68" end_char="73">спящем</TOKEN>
<TOKEN id="token-0-13" pos="punct" morph="none" start_char="74" end_char="74">»</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="76" end_char="84">состоянии</TOKEN>
<TOKEN id="token-0-15" pos="punct" morph="none" start_char="85" end_char="85">.</TOKEN>
</SEG>
<SEG id="segment-1" start_char="87" end_char="107">
<ORIGINAL_TEXT>ВОЗ уже это проверяет</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="87" end_char="89">ВОЗ</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="91" end_char="93">уже</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="95" end_char="97">это</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="99" end_char="107">проверяет</TOKEN>
</SEG>
<SEG id="segment-2" start_char="112" end_char="243">
<ORIGINAL_TEXT>Британский ученый ссылается на заявления испанских ученых, которые нашли следы коронавируса в образце сточных вод за март 2019 года.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="112" end_char="121">Британский</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="123" end_char="128">ученый</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="130" end_char="138">ссылается</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="140" end_char="141">на</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="143" end_char="151">заявления</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="153" end_char="161">испанских</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="163" end_char="168">ученых</TOKEN>
<TOKEN id="token-2-7" pos="punct" morph="none" start_char="169" end_char="169">,</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="171" end_char="177">которые</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="179" end_char="183">нашли</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="185" end_char="189">следы</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="191" end_char="202">коронавируса</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="204" end_char="204">в</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="206" end_char="212">образце</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="214" end_char="220">сточных</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="222" end_char="224">вод</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="226" end_char="227">за</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="229" end_char="232">март</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="234" end_char="237">2019</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="239" end_char="242">года</TOKEN>
<TOKEN id="token-2-20" pos="punct" morph="none" start_char="243" end_char="243">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="246" end_char="388">
<ORIGINAL_TEXT>Преобладающая на данный момент версия происхождения коронавируса SARS-Cov-2 – это то, что он пришел из Китая (с рынка или лаборатории в Ухане).</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="246" end_char="258">Преобладающая</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="260" end_char="261">на</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="263" end_char="268">данный</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="270" end_char="275">момент</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="277" end_char="282">версия</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="284" end_char="296">происхождения</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="298" end_char="309">коронавируса</TOKEN>
<TOKEN id="token-3-7" pos="unknown" morph="none" start_char="311" end_char="320">SARS-Cov-2</TOKEN>
<TOKEN id="token-3-8" pos="punct" morph="none" start_char="322" end_char="322">–</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="324" end_char="326">это</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="328" end_char="329">то</TOKEN>
<TOKEN id="token-3-11" pos="punct" morph="none" start_char="330" end_char="330">,</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="332" end_char="334">что</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="336" end_char="337">он</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="339" end_char="344">пришел</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="346" end_char="347">из</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="349" end_char="353">Китая</TOKEN>
<TOKEN id="token-3-17" pos="punct" morph="none" start_char="355" end_char="355">(</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="356" end_char="356">с</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="358" end_char="362">рынка</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="364" end_char="366">или</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="368" end_char="378">лаборатории</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="380" end_char="380">в</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="382" end_char="386">Ухане</TOKEN>
<TOKEN id="token-3-24" pos="punct" morph="none" start_char="387" end_char="388">).</TOKEN>
</SEG>
<SEG id="segment-4" start_char="390" end_char="527">
<ORIGINAL_TEXT>Но это все чаще ставят под сомнение, а теперь появилась новая теория о том, коронавирус не возник внезапно, а существовал уже очень давно.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="390" end_char="391">Но</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="393" end_char="395">это</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="397" end_char="399">все</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="401" end_char="404">чаще</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="406" end_char="411">ставят</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="413" end_char="415">под</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="417" end_char="424">сомнение</TOKEN>
<TOKEN id="token-4-7" pos="punct" morph="none" start_char="425" end_char="425">,</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="427" end_char="427">а</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="429" end_char="434">теперь</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="436" end_char="444">появилась</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="446" end_char="450">новая</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="452" end_char="457">теория</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="459" end_char="459">о</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="461" end_char="463">том</TOKEN>
<TOKEN id="token-4-15" pos="punct" morph="none" start_char="464" end_char="464">,</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="466" end_char="476">коронавирус</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="478" end_char="479">не</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="481" end_char="486">возник</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="488" end_char="495">внезапно</TOKEN>
<TOKEN id="token-4-20" pos="punct" morph="none" start_char="496" end_char="496">,</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="498" end_char="498">а</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="500" end_char="510">существовал</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="512" end_char="514">уже</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="516" end_char="520">очень</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="522" end_char="526">давно</TOKEN>
<TOKEN id="token-4-26" pos="punct" morph="none" start_char="527" end_char="527">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="530" end_char="818">
<ORIGINAL_TEXT>Том Джефферсон из Центра доказательной медицины Оксфордского университета рассказал британской газете «Telegraph» о том, что ученые всерьез рассматривают версию того, что коронавирус уже был в Европе за несколько месяцев до того, как случаи заражения начали массово регистрировать в Китае.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="530" end_char="532">Том</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="534" end_char="543">Джефферсон</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="545" end_char="546">из</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="548" end_char="553">Центра</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="555" end_char="567">доказательной</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="569" end_char="576">медицины</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="578" end_char="589">Оксфордского</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="591" end_char="602">университета</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="604" end_char="612">рассказал</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="614" end_char="623">британской</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="625" end_char="630">газете</TOKEN>
<TOKEN id="token-5-11" pos="punct" morph="none" start_char="632" end_char="632">«</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="633" end_char="641">Telegraph</TOKEN>
<TOKEN id="token-5-13" pos="punct" morph="none" start_char="642" end_char="642">»</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="644" end_char="644">о</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="646" end_char="648">том</TOKEN>
<TOKEN id="token-5-16" pos="punct" morph="none" start_char="649" end_char="649">,</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="651" end_char="653">что</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="655" end_char="660">ученые</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="662" end_char="668">всерьез</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="670" end_char="682">рассматривают</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="684" end_char="689">версию</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="691" end_char="694">того</TOKEN>
<TOKEN id="token-5-23" pos="punct" morph="none" start_char="695" end_char="695">,</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="697" end_char="699">что</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="701" end_char="711">коронавирус</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="713" end_char="715">уже</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="717" end_char="719">был</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="721" end_char="721">в</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="723" end_char="728">Европе</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="730" end_char="731">за</TOKEN>
<TOKEN id="token-5-31" pos="word" morph="none" start_char="733" end_char="741">несколько</TOKEN>
<TOKEN id="token-5-32" pos="word" morph="none" start_char="743" end_char="749">месяцев</TOKEN>
<TOKEN id="token-5-33" pos="word" morph="none" start_char="751" end_char="752">до</TOKEN>
<TOKEN id="token-5-34" pos="word" morph="none" start_char="754" end_char="757">того</TOKEN>
<TOKEN id="token-5-35" pos="punct" morph="none" start_char="758" end_char="758">,</TOKEN>
<TOKEN id="token-5-36" pos="word" morph="none" start_char="760" end_char="762">как</TOKEN>
<TOKEN id="token-5-37" pos="word" morph="none" start_char="764" end_char="769">случаи</TOKEN>
<TOKEN id="token-5-38" pos="word" morph="none" start_char="771" end_char="779">заражения</TOKEN>
<TOKEN id="token-5-39" pos="word" morph="none" start_char="781" end_char="786">начали</TOKEN>
<TOKEN id="token-5-40" pos="word" morph="none" start_char="788" end_char="794">массово</TOKEN>
<TOKEN id="token-5-41" pos="word" morph="none" start_char="796" end_char="809">регистрировать</TOKEN>
<TOKEN id="token-5-42" pos="word" morph="none" start_char="811" end_char="811">в</TOKEN>
<TOKEN id="token-5-43" pos="word" morph="none" start_char="813" end_char="817">Китае</TOKEN>
<TOKEN id="token-5-44" pos="punct" morph="none" start_char="818" end_char="818">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="821" end_char="958">
<ORIGINAL_TEXT>Эта версия предполагает, что SARS-Cov-2 существовал по всему миру в скрытой форме, «дожидаясь» подходящих для его распространения условий.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="821" end_char="823">Эта</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="825" end_char="830">версия</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="832" end_char="843">предполагает</TOKEN>
<TOKEN id="token-6-3" pos="punct" morph="none" start_char="844" end_char="844">,</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="846" end_char="848">что</TOKEN>
<TOKEN id="token-6-5" pos="unknown" morph="none" start_char="850" end_char="859">SARS-Cov-2</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="861" end_char="871">существовал</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="873" end_char="874">по</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="876" end_char="880">всему</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="882" end_char="885">миру</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="887" end_char="887">в</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="889" end_char="895">скрытой</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="897" end_char="901">форме</TOKEN>
<TOKEN id="token-6-13" pos="punct" morph="none" start_char="902" end_char="902">,</TOKEN>
<TOKEN id="token-6-14" pos="punct" morph="none" start_char="904" end_char="904">«</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="905" end_char="913">дожидаясь</TOKEN>
<TOKEN id="token-6-16" pos="punct" morph="none" start_char="914" end_char="914">»</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="916" end_char="925">подходящих</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="927" end_char="929">для</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="931" end_char="933">его</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="935" end_char="949">распространения</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="951" end_char="957">условий</TOKEN>
<TOKEN id="token-6-22" pos="punct" morph="none" start_char="958" end_char="958">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="960" end_char="1057">
<ORIGINAL_TEXT>Джефферсон напоминает, что с каждым днем ученые обнаруживают все больше доказательств этой теории.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="960" end_char="969">Джефферсон</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="971" end_char="980">напоминает</TOKEN>
<TOKEN id="token-7-2" pos="punct" morph="none" start_char="981" end_char="981">,</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="983" end_char="985">что</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="987" end_char="987">с</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="989" end_char="994">каждым</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="996" end_char="999">днем</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="1001" end_char="1006">ученые</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="1008" end_char="1019">обнаруживают</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="1021" end_char="1023">все</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="1025" end_char="1030">больше</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="1032" end_char="1044">доказательств</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="1046" end_char="1049">этой</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="1051" end_char="1056">теории</TOKEN>
<TOKEN id="token-7-14" pos="punct" morph="none" start_char="1057" end_char="1057">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1059" end_char="1258">
<ORIGINAL_TEXT>Например, недавно испанские вирусологи объявили, что нашли следы коронавируса в образце сточных вод, взятом в марте 2019 года – то есть, как минимум за 9 месяцев до того, как вирус обнаружили в Китае.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1059" end_char="1066">Например</TOKEN>
<TOKEN id="token-8-1" pos="punct" morph="none" start_char="1067" end_char="1067">,</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1069" end_char="1075">недавно</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1077" end_char="1085">испанские</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1087" end_char="1096">вирусологи</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1098" end_char="1105">объявили</TOKEN>
<TOKEN id="token-8-6" pos="punct" morph="none" start_char="1106" end_char="1106">,</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1108" end_char="1110">что</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1112" end_char="1116">нашли</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1118" end_char="1122">следы</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1124" end_char="1135">коронавируса</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1137" end_char="1137">в</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1139" end_char="1145">образце</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1147" end_char="1153">сточных</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1155" end_char="1157">вод</TOKEN>
<TOKEN id="token-8-15" pos="punct" morph="none" start_char="1158" end_char="1158">,</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1160" end_char="1165">взятом</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1167" end_char="1167">в</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1169" end_char="1173">марте</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1175" end_char="1178">2019</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="1180" end_char="1183">года</TOKEN>
<TOKEN id="token-8-21" pos="punct" morph="none" start_char="1185" end_char="1185">–</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="1187" end_char="1188">то</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="1190" end_char="1193">есть</TOKEN>
<TOKEN id="token-8-24" pos="punct" morph="none" start_char="1194" end_char="1194">,</TOKEN>
<TOKEN id="token-8-25" pos="word" morph="none" start_char="1196" end_char="1198">как</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="1200" end_char="1206">минимум</TOKEN>
<TOKEN id="token-8-27" pos="word" morph="none" start_char="1208" end_char="1209">за</TOKEN>
<TOKEN id="token-8-28" pos="word" morph="none" start_char="1211" end_char="1211">9</TOKEN>
<TOKEN id="token-8-29" pos="word" morph="none" start_char="1213" end_char="1219">месяцев</TOKEN>
<TOKEN id="token-8-30" pos="word" morph="none" start_char="1221" end_char="1222">до</TOKEN>
<TOKEN id="token-8-31" pos="word" morph="none" start_char="1224" end_char="1227">того</TOKEN>
<TOKEN id="token-8-32" pos="punct" morph="none" start_char="1228" end_char="1228">,</TOKEN>
<TOKEN id="token-8-33" pos="word" morph="none" start_char="1230" end_char="1232">как</TOKEN>
<TOKEN id="token-8-34" pos="word" morph="none" start_char="1234" end_char="1238">вирус</TOKEN>
<TOKEN id="token-8-35" pos="word" morph="none" start_char="1240" end_char="1249">обнаружили</TOKEN>
<TOKEN id="token-8-36" pos="word" morph="none" start_char="1251" end_char="1251">в</TOKEN>
<TOKEN id="token-8-37" pos="word" morph="none" start_char="1253" end_char="1257">Китае</TOKEN>
<TOKEN id="token-8-38" pos="punct" morph="none" start_char="1258" end_char="1258">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1261" end_char="1431">
<ORIGINAL_TEXT>Кроме того, следы коронавируса были обнаружены в Италии и Бразилии в ноябре и декабре прошлого года, а в начале февраля был отмечен первый случай на Фолклендских островах.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1261" end_char="1265">Кроме</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1267" end_char="1270">того</TOKEN>
<TOKEN id="token-9-2" pos="punct" morph="none" start_char="1271" end_char="1271">,</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1273" end_char="1277">следы</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1279" end_char="1290">коронавируса</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1292" end_char="1295">были</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1297" end_char="1306">обнаружены</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1308" end_char="1308">в</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1310" end_char="1315">Италии</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1317" end_char="1317">и</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1319" end_char="1326">Бразилии</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1328" end_char="1328">в</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1330" end_char="1335">ноябре</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1337" end_char="1337">и</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1339" end_char="1345">декабре</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1347" end_char="1354">прошлого</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1356" end_char="1359">года</TOKEN>
<TOKEN id="token-9-17" pos="punct" morph="none" start_char="1360" end_char="1360">,</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1362" end_char="1362">а</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1364" end_char="1364">в</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1366" end_char="1371">начале</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1373" end_char="1379">февраля</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1381" end_char="1383">был</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1385" end_char="1391">отмечен</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1393" end_char="1398">первый</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1400" end_char="1405">случай</TOKEN>
<TOKEN id="token-9-26" pos="word" morph="none" start_char="1407" end_char="1408">на</TOKEN>
<TOKEN id="token-9-27" pos="word" morph="none" start_char="1410" end_char="1421">Фолклендских</TOKEN>
<TOKEN id="token-9-28" pos="word" morph="none" start_char="1423" end_char="1430">островах</TOKEN>
<TOKEN id="token-9-29" pos="punct" morph="none" start_char="1431" end_char="1431">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1434" end_char="1503">
<ORIGINAL_TEXT>Поэтому, считает Джефферсон, вирус уже был везде, но в «спящей» форме.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1434" end_char="1440">Поэтому</TOKEN>
<TOKEN id="token-10-1" pos="punct" morph="none" start_char="1441" end_char="1441">,</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1443" end_char="1449">считает</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1451" end_char="1460">Джефферсон</TOKEN>
<TOKEN id="token-10-4" pos="punct" morph="none" start_char="1461" end_char="1461">,</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1463" end_char="1467">вирус</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1469" end_char="1471">уже</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1473" end_char="1475">был</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1477" end_char="1481">везде</TOKEN>
<TOKEN id="token-10-9" pos="punct" morph="none" start_char="1482" end_char="1482">,</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1484" end_char="1485">но</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1487" end_char="1487">в</TOKEN>
<TOKEN id="token-10-12" pos="punct" morph="none" start_char="1489" end_char="1489">«</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1490" end_char="1495">спящей</TOKEN>
<TOKEN id="token-10-14" pos="punct" morph="none" start_char="1496" end_char="1496">»</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1498" end_char="1502">форме</TOKEN>
<TOKEN id="token-10-16" pos="punct" morph="none" start_char="1503" end_char="1503">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1505" end_char="1596">
<ORIGINAL_TEXT>А когда условия окружающей среды это позволили, он активизировался и начал распространяться.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1505" end_char="1505">А</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1507" end_char="1511">когда</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1513" end_char="1519">условия</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1521" end_char="1530">окружающей</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1532" end_char="1536">среды</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1538" end_char="1540">это</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1542" end_char="1550">позволили</TOKEN>
<TOKEN id="token-11-7" pos="punct" morph="none" start_char="1551" end_char="1551">,</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1553" end_char="1554">он</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1556" end_char="1570">активизировался</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1572" end_char="1572">и</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1574" end_char="1578">начал</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1580" end_char="1595">распространяться</TOKEN>
<TOKEN id="token-11-13" pos="punct" morph="none" start_char="1596" end_char="1596">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1598" end_char="1770">
<ORIGINAL_TEXT>В качестве еще одного примера он напомнил историю времен «испанки» – тогда на Западном Самоа от гриппа умерли 30% населения, но остров не имел никакой связи с внешним миром.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1598" end_char="1598">В</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1600" end_char="1607">качестве</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1609" end_char="1611">еще</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1613" end_char="1618">одного</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1620" end_char="1626">примера</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1628" end_char="1629">он</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1631" end_char="1638">напомнил</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1640" end_char="1646">историю</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1648" end_char="1653">времен</TOKEN>
<TOKEN id="token-12-9" pos="punct" morph="none" start_char="1655" end_char="1655">«</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1656" end_char="1662">испанки</TOKEN>
<TOKEN id="token-12-11" pos="punct" morph="none" start_char="1663" end_char="1663">»</TOKEN>
<TOKEN id="token-12-12" pos="punct" morph="none" start_char="1665" end_char="1665">–</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1667" end_char="1671">тогда</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1673" end_char="1674">на</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1676" end_char="1683">Западном</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1685" end_char="1689">Самоа</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1691" end_char="1692">от</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1694" end_char="1699">гриппа</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1701" end_char="1706">умерли</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1708" end_char="1709">30</TOKEN>
<TOKEN id="token-12-21" pos="punct" morph="none" start_char="1710" end_char="1710">%</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1712" end_char="1720">населения</TOKEN>
<TOKEN id="token-12-23" pos="punct" morph="none" start_char="1721" end_char="1721">,</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="1723" end_char="1724">но</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="1726" end_char="1731">остров</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="1733" end_char="1734">не</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="1736" end_char="1739">имел</TOKEN>
<TOKEN id="token-12-28" pos="word" morph="none" start_char="1741" end_char="1747">никакой</TOKEN>
<TOKEN id="token-12-29" pos="word" morph="none" start_char="1749" end_char="1753">связи</TOKEN>
<TOKEN id="token-12-30" pos="word" morph="none" start_char="1755" end_char="1755">с</TOKEN>
<TOKEN id="token-12-31" pos="word" morph="none" start_char="1757" end_char="1763">внешним</TOKEN>
<TOKEN id="token-12-32" pos="word" morph="none" start_char="1765" end_char="1769">миром</TOKEN>
<TOKEN id="token-12-33" pos="punct" morph="none" start_char="1770" end_char="1770">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1772" end_char="1911">
<ORIGINAL_TEXT>Следовательно, одна из версий происхождения вирусов – они существуют всегда, но «активируются» после определенных изменений внешних условий.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1772" end_char="1784">Следовательно</TOKEN>
<TOKEN id="token-13-1" pos="punct" morph="none" start_char="1785" end_char="1785">,</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1787" end_char="1790">одна</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1792" end_char="1793">из</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1795" end_char="1800">версий</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1802" end_char="1814">происхождения</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1816" end_char="1822">вирусов</TOKEN>
<TOKEN id="token-13-7" pos="punct" morph="none" start_char="1824" end_char="1824">–</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1826" end_char="1828">они</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1830" end_char="1839">существуют</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1841" end_char="1846">всегда</TOKEN>
<TOKEN id="token-13-11" pos="punct" morph="none" start_char="1847" end_char="1847">,</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1849" end_char="1850">но</TOKEN>
<TOKEN id="token-13-13" pos="punct" morph="none" start_char="1852" end_char="1852">«</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1853" end_char="1864">активируются</TOKEN>
<TOKEN id="token-13-15" pos="punct" morph="none" start_char="1865" end_char="1865">»</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1867" end_char="1871">после</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1873" end_char="1884">определенных</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1886" end_char="1894">изменений</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1896" end_char="1902">внешних</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1904" end_char="1910">условий</TOKEN>
<TOKEN id="token-13-21" pos="punct" morph="none" start_char="1911" end_char="1911">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1914" end_char="2024">
<ORIGINAL_TEXT>Во Всемирной организации здравоохранения посчитали, что эта версия заслуживает внимания и тщательного изучения.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1914" end_char="1915">Во</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1917" end_char="1925">Всемирной</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1927" end_char="1937">организации</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1939" end_char="1953">здравоохранения</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1955" end_char="1963">посчитали</TOKEN>
<TOKEN id="token-14-5" pos="punct" morph="none" start_char="1964" end_char="1964">,</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1966" end_char="1968">что</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1970" end_char="1972">эта</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1974" end_char="1979">версия</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1981" end_char="1991">заслуживает</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1993" end_char="2000">внимания</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="2002" end_char="2002">и</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="2004" end_char="2014">тщательного</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="2016" end_char="2023">изучения</TOKEN>
<TOKEN id="token-14-14" pos="punct" morph="none" start_char="2024" end_char="2024">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="2026" end_char="2137">
<ORIGINAL_TEXT>В ВОЗ уже создали большую команду, которая вместе с китайскими учеными будет анализировать происхождение вируса.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="2026" end_char="2026">В</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="2028" end_char="2030">ВОЗ</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="2032" end_char="2034">уже</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="2036" end_char="2042">создали</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="2044" end_char="2050">большую</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="2052" end_char="2058">команду</TOKEN>
<TOKEN id="token-15-6" pos="punct" morph="none" start_char="2059" end_char="2059">,</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="2061" end_char="2067">которая</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="2069" end_char="2074">вместе</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="2076" end_char="2076">с</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="2078" end_char="2087">китайскими</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="2089" end_char="2095">учеными</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="2097" end_char="2101">будет</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="2103" end_char="2115">анализировать</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="2117" end_char="2129">происхождение</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="2131" end_char="2136">вируса</TOKEN>
<TOKEN id="token-15-16" pos="punct" morph="none" start_char="2137" end_char="2137">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="2139" end_char="2210">
<ORIGINAL_TEXT>Продолжается исследование старых образцов, но все это потребует времени.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="2139" end_char="2150">Продолжается</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="2152" end_char="2163">исследование</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="2165" end_char="2170">старых</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="2172" end_char="2179">образцов</TOKEN>
<TOKEN id="token-16-4" pos="punct" morph="none" start_char="2180" end_char="2180">,</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="2182" end_char="2183">но</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="2185" end_char="2187">все</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="2189" end_char="2191">это</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="2193" end_char="2201">потребует</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="2203" end_char="2209">времени</TOKEN>
<TOKEN id="token-16-10" pos="punct" morph="none" start_char="2210" end_char="2210">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2212" end_char="2331">
<ORIGINAL_TEXT>Как только будет какой-то результат, ВОЗ сразу его объявит, заверила представитель организации в России Мелита Вуйнович.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2212" end_char="2214">Как</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2216" end_char="2221">только</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2223" end_char="2227">будет</TOKEN>
<TOKEN id="token-17-3" pos="unknown" morph="none" start_char="2229" end_char="2236">какой-то</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2238" end_char="2246">результат</TOKEN>
<TOKEN id="token-17-5" pos="punct" morph="none" start_char="2247" end_char="2247">,</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2249" end_char="2251">ВОЗ</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2253" end_char="2257">сразу</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2259" end_char="2261">его</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2263" end_char="2269">объявит</TOKEN>
<TOKEN id="token-17-10" pos="punct" morph="none" start_char="2270" end_char="2270">,</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2272" end_char="2279">заверила</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2281" end_char="2293">представитель</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2295" end_char="2305">организации</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2307" end_char="2307">в</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2309" end_char="2314">России</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="2316" end_char="2321">Мелита</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="2323" end_char="2330">Вуйнович</TOKEN>
<TOKEN id="token-17-18" pos="punct" morph="none" start_char="2331" end_char="2331">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
