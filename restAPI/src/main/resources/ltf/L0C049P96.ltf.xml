<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="ukr">
<DOC id="L0C049P96" lang="ukr" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="5372" raw_text_md5="fb1ec5a0d075fb1fb8cc5923415da0f8">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="51">
<ORIGINAL_TEXT>Fact check: US government did not engineer COVID-19</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="4">Fact</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="6" end_char="10">check</TOKEN>
<TOKEN id="token-0-2" pos="punct" morph="none" start_char="11" end_char="11">:</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="13" end_char="14">US</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="16" end_char="25">government</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="27" end_char="29">did</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="31" end_char="33">not</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="35" end_char="42">engineer</TOKEN>
<TOKEN id="token-0-8" pos="unknown" morph="none" start_char="44" end_char="51">COVID-19</TOKEN>
</SEG>
<SEG id="segment-1" start_char="56" end_char="167">
<ORIGINAL_TEXT>The claim: The novel coronavirus was intentionally engineered by the U.S. government in research overseen by Dr.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="56" end_char="58">The</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="60" end_char="64">claim</TOKEN>
<TOKEN id="token-1-2" pos="punct" morph="none" start_char="65" end_char="65">:</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="67" end_char="69">The</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="71" end_char="75">novel</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="77" end_char="87">coronavirus</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="89" end_char="91">was</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="93" end_char="105">intentionally</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="107" end_char="116">engineered</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="118" end_char="119">by</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="121" end_char="123">the</TOKEN>
<TOKEN id="token-1-11" pos="unknown" morph="none" start_char="125" end_char="127">U.S</TOKEN>
<TOKEN id="token-1-12" pos="punct" morph="none" start_char="128" end_char="128">.</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="130" end_char="139">government</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="141" end_char="142">in</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="144" end_char="151">research</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="153" end_char="160">overseen</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="162" end_char="163">by</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="165" end_char="166">Dr</TOKEN>
<TOKEN id="token-1-19" pos="punct" morph="none" start_char="167" end_char="167">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="169" end_char="181">
<ORIGINAL_TEXT>Anthony Fauci</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="169" end_char="175">Anthony</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="177" end_char="181">Fauci</TOKEN>
</SEG>
<SEG id="segment-3" start_char="185" end_char="308">
<ORIGINAL_TEXT>In the newest slew of theories as to the origin of the novel coronavirus, the U.S. government played a role in its creation.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="185" end_char="186">In</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="188" end_char="190">the</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="192" end_char="197">newest</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="199" end_char="202">slew</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="204" end_char="205">of</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="207" end_char="214">theories</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="216" end_char="217">as</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="219" end_char="220">to</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="222" end_char="224">the</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="226" end_char="231">origin</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="233" end_char="234">of</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="236" end_char="238">the</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="240" end_char="244">novel</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="246" end_char="256">coronavirus</TOKEN>
<TOKEN id="token-3-14" pos="punct" morph="none" start_char="257" end_char="257">,</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="259" end_char="261">the</TOKEN>
<TOKEN id="token-3-16" pos="unknown" morph="none" start_char="263" end_char="265">U.S</TOKEN>
<TOKEN id="token-3-17" pos="punct" morph="none" start_char="266" end_char="266">.</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="268" end_char="277">government</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="279" end_char="284">played</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="286" end_char="286">a</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="288" end_char="291">role</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="293" end_char="294">in</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="296" end_char="298">its</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="300" end_char="307">creation</TOKEN>
<TOKEN id="token-3-25" pos="punct" morph="none" start_char="308" end_char="308">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="311" end_char="538">
<ORIGINAL_TEXT>"After the (SARS) outbreak in 2002, the United States government funded a collaboration of Chinese scientists and the US military from a bioweapons lab in (F)ort Detrick," Malcolm Harris alleges in a May 21 article on The Duran.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="punct" morph="none" start_char="311" end_char="311">"</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="312" end_char="316">After</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="318" end_char="320">the</TOKEN>
<TOKEN id="token-4-3" pos="punct" morph="none" start_char="322" end_char="322">(</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="323" end_char="326">SARS</TOKEN>
<TOKEN id="token-4-5" pos="punct" morph="none" start_char="327" end_char="327">)</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="329" end_char="336">outbreak</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="338" end_char="339">in</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="341" end_char="344">2002</TOKEN>
<TOKEN id="token-4-9" pos="punct" morph="none" start_char="345" end_char="345">,</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="347" end_char="349">the</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="351" end_char="356">United</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="358" end_char="363">States</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="365" end_char="374">government</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="376" end_char="381">funded</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="383" end_char="383">a</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="385" end_char="397">collaboration</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="399" end_char="400">of</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="402" end_char="408">Chinese</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="410" end_char="419">scientists</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="421" end_char="423">and</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="425" end_char="427">the</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="429" end_char="430">US</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="432" end_char="439">military</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="441" end_char="444">from</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="446" end_char="446">a</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="448" end_char="457">bioweapons</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="459" end_char="461">lab</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="463" end_char="464">in</TOKEN>
<TOKEN id="token-4-29" pos="punct" morph="none" start_char="466" end_char="466">(</TOKEN>
<TOKEN id="token-4-30" pos="unknown" morph="none" start_char="467" end_char="471">F)ort</TOKEN>
<TOKEN id="token-4-31" pos="word" morph="none" start_char="473" end_char="479">Detrick</TOKEN>
<TOKEN id="token-4-32" pos="punct" morph="none" start_char="480" end_char="481">,"</TOKEN>
<TOKEN id="token-4-33" pos="word" morph="none" start_char="483" end_char="489">Malcolm</TOKEN>
<TOKEN id="token-4-34" pos="word" morph="none" start_char="491" end_char="496">Harris</TOKEN>
<TOKEN id="token-4-35" pos="word" morph="none" start_char="498" end_char="504">alleges</TOKEN>
<TOKEN id="token-4-36" pos="word" morph="none" start_char="506" end_char="507">in</TOKEN>
<TOKEN id="token-4-37" pos="word" morph="none" start_char="509" end_char="509">a</TOKEN>
<TOKEN id="token-4-38" pos="word" morph="none" start_char="511" end_char="513">May</TOKEN>
<TOKEN id="token-4-39" pos="word" morph="none" start_char="515" end_char="516">21</TOKEN>
<TOKEN id="token-4-40" pos="word" morph="none" start_char="518" end_char="524">article</TOKEN>
<TOKEN id="token-4-41" pos="word" morph="none" start_char="526" end_char="527">on</TOKEN>
<TOKEN id="token-4-42" pos="word" morph="none" start_char="529" end_char="531">The</TOKEN>
<TOKEN id="token-4-43" pos="word" morph="none" start_char="533" end_char="537">Duran</TOKEN>
<TOKEN id="token-4-44" pos="punct" morph="none" start_char="538" end_char="538">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="541" end_char="659">
<ORIGINAL_TEXT>It goes on to claim that none other than the director of the National Institute of Allergy and Infectious Diseases, Dr.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="541" end_char="542">It</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="544" end_char="547">goes</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="549" end_char="550">on</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="552" end_char="553">to</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="555" end_char="559">claim</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="561" end_char="564">that</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="566" end_char="569">none</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="571" end_char="575">other</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="577" end_char="580">than</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="582" end_char="584">the</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="586" end_char="593">director</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="595" end_char="596">of</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="598" end_char="600">the</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="602" end_char="609">National</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="611" end_char="619">Institute</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="621" end_char="622">of</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="624" end_char="630">Allergy</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="632" end_char="634">and</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="636" end_char="645">Infectious</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="647" end_char="654">Diseases</TOKEN>
<TOKEN id="token-5-20" pos="punct" morph="none" start_char="655" end_char="655">,</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="657" end_char="658">Dr</TOKEN>
<TOKEN id="token-5-22" pos="punct" morph="none" start_char="659" end_char="659">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="661" end_char="833">
<ORIGINAL_TEXT>Anthony Fauci, oversaw the research initiative that led to the development of "pandemic superbots" and viral strains more lethal than their naturally occurring counterparts.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="661" end_char="667">Anthony</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="669" end_char="673">Fauci</TOKEN>
<TOKEN id="token-6-2" pos="punct" morph="none" start_char="674" end_char="674">,</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="676" end_char="682">oversaw</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="684" end_char="686">the</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="688" end_char="695">research</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="697" end_char="706">initiative</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="708" end_char="711">that</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="713" end_char="715">led</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="717" end_char="718">to</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="720" end_char="722">the</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="724" end_char="734">development</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="736" end_char="737">of</TOKEN>
<TOKEN id="token-6-13" pos="punct" morph="none" start_char="739" end_char="739">"</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="740" end_char="747">pandemic</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="749" end_char="757">superbots</TOKEN>
<TOKEN id="token-6-16" pos="punct" morph="none" start_char="758" end_char="758">"</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="760" end_char="762">and</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="764" end_char="768">viral</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="770" end_char="776">strains</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="778" end_char="781">more</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="783" end_char="788">lethal</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="790" end_char="793">than</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="795" end_char="799">their</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="801" end_char="809">naturally</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="811" end_char="819">occurring</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="821" end_char="832">counterparts</TOKEN>
<TOKEN id="token-6-27" pos="punct" morph="none" start_char="833" end_char="833">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="836" end_char="956">
<ORIGINAL_TEXT>There were concerns raised by an unnamed "Harvard professor" that Fauci's work "was intentionally weaponizing the virus."</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="836" end_char="840">There</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="842" end_char="845">were</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="847" end_char="854">concerns</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="856" end_char="861">raised</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="863" end_char="864">by</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="866" end_char="867">an</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="869" end_char="875">unnamed</TOKEN>
<TOKEN id="token-7-7" pos="punct" morph="none" start_char="877" end_char="877">"</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="878" end_char="884">Harvard</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="886" end_char="894">professor</TOKEN>
<TOKEN id="token-7-10" pos="punct" morph="none" start_char="895" end_char="895">"</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="897" end_char="900">that</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="902" end_char="908">Fauci's</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="910" end_char="913">work</TOKEN>
<TOKEN id="token-7-14" pos="punct" morph="none" start_char="915" end_char="915">"</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="916" end_char="918">was</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="920" end_char="932">intentionally</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="934" end_char="944">weaponizing</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="946" end_char="948">the</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="950" end_char="954">virus</TOKEN>
<TOKEN id="token-7-20" pos="punct" morph="none" start_char="955" end_char="956">."</TOKEN>
</SEG>
<SEG id="segment-8" start_char="958" end_char="1049">
<ORIGINAL_TEXT>However, research continued unfettered and subsidized by the U.S. government, Harris claims.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="958" end_char="964">However</TOKEN>
<TOKEN id="token-8-1" pos="punct" morph="none" start_char="965" end_char="965">,</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="967" end_char="974">research</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="976" end_char="984">continued</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="986" end_char="995">unfettered</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="997" end_char="999">and</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1001" end_char="1010">subsidized</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1012" end_char="1013">by</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1015" end_char="1017">the</TOKEN>
<TOKEN id="token-8-9" pos="unknown" morph="none" start_char="1019" end_char="1021">U.S</TOKEN>
<TOKEN id="token-8-10" pos="punct" morph="none" start_char="1022" end_char="1022">.</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1024" end_char="1033">government</TOKEN>
<TOKEN id="token-8-12" pos="punct" morph="none" start_char="1034" end_char="1034">,</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1036" end_char="1041">Harris</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1043" end_char="1048">claims</TOKEN>
<TOKEN id="token-8-15" pos="punct" morph="none" start_char="1049" end_char="1049">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1052" end_char="1189">
<ORIGINAL_TEXT>Years later, incidents involving the near release of the weaponized virus, on which Harris does not elaborate, put a stop to Fauci's work.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1052" end_char="1056">Years</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1058" end_char="1062">later</TOKEN>
<TOKEN id="token-9-2" pos="punct" morph="none" start_char="1063" end_char="1063">,</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1065" end_char="1073">incidents</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1075" end_char="1083">involving</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1085" end_char="1087">the</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1089" end_char="1092">near</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1094" end_char="1100">release</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1102" end_char="1103">of</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1105" end_char="1107">the</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1109" end_char="1118">weaponized</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1120" end_char="1124">virus</TOKEN>
<TOKEN id="token-9-12" pos="punct" morph="none" start_char="1125" end_char="1125">,</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1127" end_char="1128">on</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1130" end_char="1134">which</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1136" end_char="1141">Harris</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1143" end_char="1146">does</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1148" end_char="1150">not</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1152" end_char="1160">elaborate</TOKEN>
<TOKEN id="token-9-19" pos="punct" morph="none" start_char="1161" end_char="1161">,</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1163" end_char="1165">put</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1167" end_char="1167">a</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1169" end_char="1172">stop</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1174" end_char="1175">to</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1177" end_char="1183">Fauci's</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1185" end_char="1188">work</TOKEN>
<TOKEN id="token-9-26" pos="punct" morph="none" start_char="1189" end_char="1189">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1191" end_char="1269">
<ORIGINAL_TEXT>"In 2014, the US government terminated Fauci’s federal funding," Harris writes.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="punct" morph="none" start_char="1191" end_char="1191">"</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1192" end_char="1193">In</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1195" end_char="1198">2014</TOKEN>
<TOKEN id="token-10-3" pos="punct" morph="none" start_char="1199" end_char="1199">,</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1201" end_char="1203">the</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1205" end_char="1206">US</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1208" end_char="1217">government</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1219" end_char="1228">terminated</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1230" end_char="1236">Fauci’s</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1238" end_char="1244">federal</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1246" end_char="1252">funding</TOKEN>
<TOKEN id="token-10-11" pos="punct" morph="none" start_char="1253" end_char="1254">,"</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1256" end_char="1261">Harris</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1263" end_char="1268">writes</TOKEN>
<TOKEN id="token-10-14" pos="punct" morph="none" start_char="1269" end_char="1269">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1271" end_char="1427">
<ORIGINAL_TEXT>This does not truly stop the experimentation, Harris claims, instead shifting it, along with U.S. funding of $3.7 million, to a military lab in Wuhan, China.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1271" end_char="1274">This</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1276" end_char="1279">does</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1281" end_char="1283">not</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1285" end_char="1289">truly</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1291" end_char="1294">stop</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1296" end_char="1298">the</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1300" end_char="1314">experimentation</TOKEN>
<TOKEN id="token-11-7" pos="punct" morph="none" start_char="1315" end_char="1315">,</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1317" end_char="1322">Harris</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1324" end_char="1329">claims</TOKEN>
<TOKEN id="token-11-10" pos="punct" morph="none" start_char="1330" end_char="1330">,</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1332" end_char="1338">instead</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1340" end_char="1347">shifting</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1349" end_char="1350">it</TOKEN>
<TOKEN id="token-11-14" pos="punct" morph="none" start_char="1351" end_char="1351">,</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1353" end_char="1357">along</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1359" end_char="1362">with</TOKEN>
<TOKEN id="token-11-17" pos="unknown" morph="none" start_char="1364" end_char="1366">U.S</TOKEN>
<TOKEN id="token-11-18" pos="punct" morph="none" start_char="1367" end_char="1367">.</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="1369" end_char="1375">funding</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1377" end_char="1378">of</TOKEN>
<TOKEN id="token-11-21" pos="unknown" morph="none" start_char="1380" end_char="1383">$3.7</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="1385" end_char="1391">million</TOKEN>
<TOKEN id="token-11-23" pos="punct" morph="none" start_char="1392" end_char="1392">,</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="1394" end_char="1395">to</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="1397" end_char="1397">a</TOKEN>
<TOKEN id="token-11-26" pos="word" morph="none" start_char="1399" end_char="1406">military</TOKEN>
<TOKEN id="token-11-27" pos="word" morph="none" start_char="1408" end_char="1410">lab</TOKEN>
<TOKEN id="token-11-28" pos="word" morph="none" start_char="1412" end_char="1413">in</TOKEN>
<TOKEN id="token-11-29" pos="word" morph="none" start_char="1415" end_char="1419">Wuhan</TOKEN>
<TOKEN id="token-11-30" pos="punct" morph="none" start_char="1420" end_char="1420">,</TOKEN>
<TOKEN id="token-11-31" pos="word" morph="none" start_char="1422" end_char="1426">China</TOKEN>
<TOKEN id="token-11-32" pos="punct" morph="none" start_char="1427" end_char="1427">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1430" end_char="1499">
<ORIGINAL_TEXT>Fact check:Obama administration did not send $3.7 million to Wuhan lab</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1430" end_char="1433">Fact</TOKEN>
<TOKEN id="token-12-1" pos="unknown" morph="none" start_char="1435" end_char="1445">check:Obama</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1447" end_char="1460">administration</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1462" end_char="1464">did</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1466" end_char="1468">not</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1470" end_char="1473">send</TOKEN>
<TOKEN id="token-12-6" pos="unknown" morph="none" start_char="1475" end_char="1478">$3.7</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1480" end_char="1486">million</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1488" end_char="1489">to</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1491" end_char="1495">Wuhan</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1497" end_char="1499">lab</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1502" end_char="1726">
<ORIGINAL_TEXT>Harris draws parallels with different instances of unethical human experimentation such as Operation Sea Spray, the Tuskegee study and the CIA's mind-control project MKUltra to claim the coronavirus was intentionally created.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1502" end_char="1507">Harris</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1509" end_char="1513">draws</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1515" end_char="1523">parallels</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1525" end_char="1528">with</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1530" end_char="1538">different</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1540" end_char="1548">instances</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1550" end_char="1551">of</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1553" end_char="1561">unethical</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1563" end_char="1567">human</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1569" end_char="1583">experimentation</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1585" end_char="1588">such</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1590" end_char="1591">as</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1593" end_char="1601">Operation</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1603" end_char="1605">Sea</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1607" end_char="1611">Spray</TOKEN>
<TOKEN id="token-13-15" pos="punct" morph="none" start_char="1612" end_char="1612">,</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1614" end_char="1616">the</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1618" end_char="1625">Tuskegee</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1627" end_char="1631">study</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1633" end_char="1635">and</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1637" end_char="1639">the</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="1641" end_char="1645">CIA's</TOKEN>
<TOKEN id="token-13-22" pos="unknown" morph="none" start_char="1647" end_char="1658">mind-control</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="1660" end_char="1666">project</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="1668" end_char="1674">MKUltra</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="1676" end_char="1677">to</TOKEN>
<TOKEN id="token-13-26" pos="word" morph="none" start_char="1679" end_char="1683">claim</TOKEN>
<TOKEN id="token-13-27" pos="word" morph="none" start_char="1685" end_char="1687">the</TOKEN>
<TOKEN id="token-13-28" pos="word" morph="none" start_char="1689" end_char="1699">coronavirus</TOKEN>
<TOKEN id="token-13-29" pos="word" morph="none" start_char="1701" end_char="1703">was</TOKEN>
<TOKEN id="token-13-30" pos="word" morph="none" start_char="1705" end_char="1717">intentionally</TOKEN>
<TOKEN id="token-13-31" pos="word" morph="none" start_char="1719" end_char="1725">created</TOKEN>
<TOKEN id="token-13-32" pos="punct" morph="none" start_char="1726" end_char="1726">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1729" end_char="1869">
<ORIGINAL_TEXT>The website that published Harris' claim, The Duran, did not respond to a request for Harris's contact information or comment from USA TODAY.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1729" end_char="1731">The</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1733" end_char="1739">website</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1741" end_char="1744">that</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1746" end_char="1754">published</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1756" end_char="1761">Harris</TOKEN>
<TOKEN id="token-14-5" pos="punct" morph="none" start_char="1762" end_char="1762">'</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1764" end_char="1768">claim</TOKEN>
<TOKEN id="token-14-7" pos="punct" morph="none" start_char="1769" end_char="1769">,</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1771" end_char="1773">The</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1775" end_char="1779">Duran</TOKEN>
<TOKEN id="token-14-10" pos="punct" morph="none" start_char="1780" end_char="1780">,</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1782" end_char="1784">did</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1786" end_char="1788">not</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1790" end_char="1796">respond</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="1798" end_char="1799">to</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1801" end_char="1801">a</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1803" end_char="1809">request</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="1811" end_char="1813">for</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="1815" end_char="1822">Harris's</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="1824" end_char="1830">contact</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="1832" end_char="1842">information</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="1844" end_char="1845">or</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="1847" end_char="1853">comment</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="1855" end_char="1858">from</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="1860" end_char="1862">USA</TOKEN>
<TOKEN id="token-14-25" pos="word" morph="none" start_char="1864" end_char="1868">TODAY</TOKEN>
<TOKEN id="token-14-26" pos="punct" morph="none" start_char="1869" end_char="1869">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1871" end_char="1990">
<ORIGINAL_TEXT>On its website, The Duran acknowledges it "does not routinely moderate, screen, or edit content contributed by readers."</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1871" end_char="1872">On</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1874" end_char="1876">its</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1878" end_char="1884">website</TOKEN>
<TOKEN id="token-15-3" pos="punct" morph="none" start_char="1885" end_char="1885">,</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1887" end_char="1889">The</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1891" end_char="1895">Duran</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1897" end_char="1908">acknowledges</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1910" end_char="1911">it</TOKEN>
<TOKEN id="token-15-8" pos="punct" morph="none" start_char="1913" end_char="1913">"</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1914" end_char="1917">does</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1919" end_char="1921">not</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1923" end_char="1931">routinely</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1933" end_char="1940">moderate</TOKEN>
<TOKEN id="token-15-13" pos="punct" morph="none" start_char="1941" end_char="1941">,</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1943" end_char="1948">screen</TOKEN>
<TOKEN id="token-15-15" pos="punct" morph="none" start_char="1949" end_char="1949">,</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="1951" end_char="1952">or</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="1954" end_char="1957">edit</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="1959" end_char="1965">content</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="1967" end_char="1977">contributed</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="1979" end_char="1980">by</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="1982" end_char="1988">readers</TOKEN>
<TOKEN id="token-15-22" pos="punct" morph="none" start_char="1989" end_char="1990">."</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1992" end_char="2061">
<ORIGINAL_TEXT>Some believe the outlet is a possible platform for Russian propaganda.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1992" end_char="1995">Some</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1997" end_char="2003">believe</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="2005" end_char="2007">the</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="2009" end_char="2014">outlet</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="2016" end_char="2017">is</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="2019" end_char="2019">a</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="2021" end_char="2028">possible</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="2030" end_char="2037">platform</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="2039" end_char="2041">for</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="2043" end_char="2049">Russian</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="2051" end_char="2060">propaganda</TOKEN>
<TOKEN id="token-16-11" pos="punct" morph="none" start_char="2061" end_char="2061">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2064" end_char="2208">
<ORIGINAL_TEXT>According to Media Bias Fact Check, The Duran is owned by the Cyprus-based DRN Media PLC, with Russian native Alex Christoforou as its president.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2064" end_char="2072">According</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2074" end_char="2075">to</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2077" end_char="2081">Media</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2083" end_char="2086">Bias</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2088" end_char="2091">Fact</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2093" end_char="2097">Check</TOKEN>
<TOKEN id="token-17-6" pos="punct" morph="none" start_char="2098" end_char="2098">,</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2100" end_char="2102">The</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2104" end_char="2108">Duran</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2110" end_char="2111">is</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2113" end_char="2117">owned</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2119" end_char="2120">by</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2122" end_char="2124">the</TOKEN>
<TOKEN id="token-17-13" pos="unknown" morph="none" start_char="2126" end_char="2137">Cyprus-based</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2139" end_char="2141">DRN</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2143" end_char="2147">Media</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="2149" end_char="2151">PLC</TOKEN>
<TOKEN id="token-17-17" pos="punct" morph="none" start_char="2152" end_char="2152">,</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="2154" end_char="2157">with</TOKEN>
<TOKEN id="token-17-19" pos="word" morph="none" start_char="2159" end_char="2165">Russian</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="2167" end_char="2172">native</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="2174" end_char="2177">Alex</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="2179" end_char="2190">Christoforou</TOKEN>
<TOKEN id="token-17-23" pos="word" morph="none" start_char="2192" end_char="2193">as</TOKEN>
<TOKEN id="token-17-24" pos="word" morph="none" start_char="2195" end_char="2197">its</TOKEN>
<TOKEN id="token-17-25" pos="word" morph="none" start_char="2199" end_char="2207">president</TOKEN>
<TOKEN id="token-17-26" pos="punct" morph="none" start_char="2208" end_char="2208">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2211" end_char="2228">
<ORIGINAL_TEXT>Fauci's background</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2211" end_char="2217">Fauci's</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2219" end_char="2228">background</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2232" end_char="2324">
<ORIGINAL_TEXT>Fauci has been the face of the national coronavirus response since the start of the pandemic.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2232" end_char="2236">Fauci</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2238" end_char="2240">has</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2242" end_char="2245">been</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2247" end_char="2249">the</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2251" end_char="2254">face</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2256" end_char="2257">of</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2259" end_char="2261">the</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2263" end_char="2270">national</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2272" end_char="2282">coronavirus</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="2284" end_char="2291">response</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="2293" end_char="2297">since</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="2299" end_char="2301">the</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="2303" end_char="2307">start</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="2309" end_char="2310">of</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="2312" end_char="2314">the</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="2316" end_char="2323">pandemic</TOKEN>
<TOKEN id="token-19-16" pos="punct" morph="none" start_char="2324" end_char="2324">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2326" end_char="2417">
<ORIGINAL_TEXT>It's a position that has earned him national admiration but also vilification and suspicion.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2326" end_char="2329">It's</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2331" end_char="2331">a</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2333" end_char="2340">position</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2342" end_char="2345">that</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2347" end_char="2349">has</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2351" end_char="2356">earned</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2358" end_char="2360">him</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2362" end_char="2369">national</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="2371" end_char="2380">admiration</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2382" end_char="2384">but</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2386" end_char="2389">also</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="2391" end_char="2402">vilification</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="2404" end_char="2406">and</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="2408" end_char="2416">suspicion</TOKEN>
<TOKEN id="token-20-14" pos="punct" morph="none" start_char="2417" end_char="2417">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2420" end_char="2451">
<ORIGINAL_TEXT>Other Fauci conspiracy theories:</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2420" end_char="2424">Other</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2426" end_char="2430">Fauci</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2432" end_char="2441">conspiracy</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2443" end_char="2450">theories</TOKEN>
<TOKEN id="token-21-4" pos="punct" morph="none" start_char="2451" end_char="2451">:</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2454" end_char="2616">
<ORIGINAL_TEXT>While Fauci has overseen a variety of research – some involving viruses like Ebola and Zika – in his 36-year directorial tenure, his primary focus has been on HIV.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2454" end_char="2458">While</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2460" end_char="2464">Fauci</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2466" end_char="2468">has</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2470" end_char="2477">overseen</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2479" end_char="2479">a</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2481" end_char="2487">variety</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2489" end_char="2490">of</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2492" end_char="2499">research</TOKEN>
<TOKEN id="token-22-8" pos="punct" morph="none" start_char="2501" end_char="2501">–</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="2503" end_char="2506">some</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="2508" end_char="2516">involving</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="2518" end_char="2524">viruses</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="2526" end_char="2529">like</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="2531" end_char="2535">Ebola</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="2537" end_char="2539">and</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="2541" end_char="2544">Zika</TOKEN>
<TOKEN id="token-22-16" pos="punct" morph="none" start_char="2546" end_char="2546">–</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="2548" end_char="2549">in</TOKEN>
<TOKEN id="token-22-18" pos="word" morph="none" start_char="2551" end_char="2553">his</TOKEN>
<TOKEN id="token-22-19" pos="unknown" morph="none" start_char="2555" end_char="2561">36-year</TOKEN>
<TOKEN id="token-22-20" pos="word" morph="none" start_char="2563" end_char="2573">directorial</TOKEN>
<TOKEN id="token-22-21" pos="word" morph="none" start_char="2575" end_char="2580">tenure</TOKEN>
<TOKEN id="token-22-22" pos="punct" morph="none" start_char="2581" end_char="2581">,</TOKEN>
<TOKEN id="token-22-23" pos="word" morph="none" start_char="2583" end_char="2585">his</TOKEN>
<TOKEN id="token-22-24" pos="word" morph="none" start_char="2587" end_char="2593">primary</TOKEN>
<TOKEN id="token-22-25" pos="word" morph="none" start_char="2595" end_char="2599">focus</TOKEN>
<TOKEN id="token-22-26" pos="word" morph="none" start_char="2601" end_char="2603">has</TOKEN>
<TOKEN id="token-22-27" pos="word" morph="none" start_char="2605" end_char="2608">been</TOKEN>
<TOKEN id="token-22-28" pos="word" morph="none" start_char="2610" end_char="2611">on</TOKEN>
<TOKEN id="token-22-29" pos="word" morph="none" start_char="2613" end_char="2615">HIV</TOKEN>
<TOKEN id="token-22-30" pos="punct" morph="none" start_char="2616" end_char="2616">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2618" end_char="2796">
<ORIGINAL_TEXT>In the early years of the HIV epidemic, Fauci investigated how the body's immune defenses were wrecked by the virus, explaining why infected people were getting so sick and dying.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2618" end_char="2619">In</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2621" end_char="2623">the</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2625" end_char="2629">early</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2631" end_char="2635">years</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="2637" end_char="2638">of</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="2640" end_char="2642">the</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="2644" end_char="2646">HIV</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="2648" end_char="2655">epidemic</TOKEN>
<TOKEN id="token-23-8" pos="punct" morph="none" start_char="2656" end_char="2656">,</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="2658" end_char="2662">Fauci</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="2664" end_char="2675">investigated</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="2677" end_char="2679">how</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="2681" end_char="2683">the</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="2685" end_char="2690">body's</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="2692" end_char="2697">immune</TOKEN>
<TOKEN id="token-23-15" pos="word" morph="none" start_char="2699" end_char="2706">defenses</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="2708" end_char="2711">were</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="2713" end_char="2719">wrecked</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="2721" end_char="2722">by</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="2724" end_char="2726">the</TOKEN>
<TOKEN id="token-23-20" pos="word" morph="none" start_char="2728" end_char="2732">virus</TOKEN>
<TOKEN id="token-23-21" pos="punct" morph="none" start_char="2733" end_char="2733">,</TOKEN>
<TOKEN id="token-23-22" pos="word" morph="none" start_char="2735" end_char="2744">explaining</TOKEN>
<TOKEN id="token-23-23" pos="word" morph="none" start_char="2746" end_char="2748">why</TOKEN>
<TOKEN id="token-23-24" pos="word" morph="none" start_char="2750" end_char="2757">infected</TOKEN>
<TOKEN id="token-23-25" pos="word" morph="none" start_char="2759" end_char="2764">people</TOKEN>
<TOKEN id="token-23-26" pos="word" morph="none" start_char="2766" end_char="2769">were</TOKEN>
<TOKEN id="token-23-27" pos="word" morph="none" start_char="2771" end_char="2777">getting</TOKEN>
<TOKEN id="token-23-28" pos="word" morph="none" start_char="2779" end_char="2780">so</TOKEN>
<TOKEN id="token-23-29" pos="word" morph="none" start_char="2782" end_char="2785">sick</TOKEN>
<TOKEN id="token-23-30" pos="word" morph="none" start_char="2787" end_char="2789">and</TOKEN>
<TOKEN id="token-23-31" pos="word" morph="none" start_char="2791" end_char="2795">dying</TOKEN>
<TOKEN id="token-23-32" pos="punct" morph="none" start_char="2796" end_char="2796">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2798" end_char="2965">
<ORIGINAL_TEXT>Later, he was instrumental in working with AIDS activists to loosen clinical drug trial policies, making experimental HIV/AIDS treatments available to patients in need.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="2798" end_char="2802">Later</TOKEN>
<TOKEN id="token-24-1" pos="punct" morph="none" start_char="2803" end_char="2803">,</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="2805" end_char="2806">he</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="2808" end_char="2810">was</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="2812" end_char="2823">instrumental</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="2825" end_char="2826">in</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="2828" end_char="2834">working</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="2836" end_char="2839">with</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="2841" end_char="2844">AIDS</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="2846" end_char="2854">activists</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="2856" end_char="2857">to</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="2859" end_char="2864">loosen</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="2866" end_char="2873">clinical</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="2875" end_char="2878">drug</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="2880" end_char="2884">trial</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="2886" end_char="2893">policies</TOKEN>
<TOKEN id="token-24-16" pos="punct" morph="none" start_char="2894" end_char="2894">,</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="2896" end_char="2901">making</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="2903" end_char="2914">experimental</TOKEN>
<TOKEN id="token-24-19" pos="unknown" morph="none" start_char="2916" end_char="2923">HIV/AIDS</TOKEN>
<TOKEN id="token-24-20" pos="word" morph="none" start_char="2925" end_char="2934">treatments</TOKEN>
<TOKEN id="token-24-21" pos="word" morph="none" start_char="2936" end_char="2944">available</TOKEN>
<TOKEN id="token-24-22" pos="word" morph="none" start_char="2946" end_char="2947">to</TOKEN>
<TOKEN id="token-24-23" pos="word" morph="none" start_char="2949" end_char="2956">patients</TOKEN>
<TOKEN id="token-24-24" pos="word" morph="none" start_char="2958" end_char="2959">in</TOKEN>
<TOKEN id="token-24-25" pos="word" morph="none" start_char="2961" end_char="2964">need</TOKEN>
<TOKEN id="token-24-26" pos="punct" morph="none" start_char="2965" end_char="2965">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2968" end_char="3141">
<ORIGINAL_TEXT>Since then, the 79-year-old immunologist has continued to advance the study of HIV and has served as a health adviser to six presidents, most recently President Donald Trump.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="2968" end_char="2972">Since</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="2974" end_char="2977">then</TOKEN>
<TOKEN id="token-25-2" pos="punct" morph="none" start_char="2978" end_char="2978">,</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="2980" end_char="2982">the</TOKEN>
<TOKEN id="token-25-4" pos="unknown" morph="none" start_char="2984" end_char="2994">79-year-old</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="2996" end_char="3007">immunologist</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="3009" end_char="3011">has</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="3013" end_char="3021">continued</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="3023" end_char="3024">to</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="3026" end_char="3032">advance</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="3034" end_char="3036">the</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="3038" end_char="3042">study</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="3044" end_char="3045">of</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="3047" end_char="3049">HIV</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="3051" end_char="3053">and</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="3055" end_char="3057">has</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="3059" end_char="3064">served</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="3066" end_char="3067">as</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="3069" end_char="3069">a</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="3071" end_char="3076">health</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="3078" end_char="3084">adviser</TOKEN>
<TOKEN id="token-25-21" pos="word" morph="none" start_char="3086" end_char="3087">to</TOKEN>
<TOKEN id="token-25-22" pos="word" morph="none" start_char="3089" end_char="3091">six</TOKEN>
<TOKEN id="token-25-23" pos="word" morph="none" start_char="3093" end_char="3102">presidents</TOKEN>
<TOKEN id="token-25-24" pos="punct" morph="none" start_char="3103" end_char="3103">,</TOKEN>
<TOKEN id="token-25-25" pos="word" morph="none" start_char="3105" end_char="3108">most</TOKEN>
<TOKEN id="token-25-26" pos="word" morph="none" start_char="3110" end_char="3117">recently</TOKEN>
<TOKEN id="token-25-27" pos="word" morph="none" start_char="3119" end_char="3127">President</TOKEN>
<TOKEN id="token-25-28" pos="word" morph="none" start_char="3129" end_char="3134">Donald</TOKEN>
<TOKEN id="token-25-29" pos="word" morph="none" start_char="3136" end_char="3140">Trump</TOKEN>
<TOKEN id="token-25-30" pos="punct" morph="none" start_char="3141" end_char="3141">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="3143" end_char="3234">
<ORIGINAL_TEXT>There is no evidence to suggest Fauci himself was directly involved in coronavirus research.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="3143" end_char="3147">There</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="3149" end_char="3150">is</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="3152" end_char="3153">no</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="3155" end_char="3162">evidence</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="3164" end_char="3165">to</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="3167" end_char="3173">suggest</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="3175" end_char="3179">Fauci</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="3181" end_char="3187">himself</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="3189" end_char="3191">was</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="3193" end_char="3200">directly</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="3202" end_char="3209">involved</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="3211" end_char="3212">in</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="3214" end_char="3224">coronavirus</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="3226" end_char="3233">research</TOKEN>
<TOKEN id="token-26-14" pos="punct" morph="none" start_char="3234" end_char="3234">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="3237" end_char="3260">
<ORIGINAL_TEXT>Coronavirus not man-made</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="3237" end_char="3247">Coronavirus</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="3249" end_char="3251">not</TOKEN>
<TOKEN id="token-27-2" pos="unknown" morph="none" start_char="3253" end_char="3260">man-made</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3264" end_char="3615">
<ORIGINAL_TEXT>While there's no question the U.S has been involved in human medical experimentation in the past – Senate hearings during the early 1950s revealed testing of biological agents on the public, and the CIA's mind-control program MKUltra was confirmed in the 1975 Church Committee – evidence does not point to the coronavirus being purposefully engineered.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="3264" end_char="3268">While</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="3270" end_char="3276">there's</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="3278" end_char="3279">no</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="3281" end_char="3288">question</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="3290" end_char="3292">the</TOKEN>
<TOKEN id="token-28-5" pos="unknown" morph="none" start_char="3294" end_char="3296">U.S</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="3298" end_char="3300">has</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="3302" end_char="3305">been</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="3307" end_char="3314">involved</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="3316" end_char="3317">in</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="3319" end_char="3323">human</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="3325" end_char="3331">medical</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="3333" end_char="3347">experimentation</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="3349" end_char="3350">in</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="3352" end_char="3354">the</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="3356" end_char="3359">past</TOKEN>
<TOKEN id="token-28-16" pos="punct" morph="none" start_char="3361" end_char="3361">–</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="3363" end_char="3368">Senate</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="3370" end_char="3377">hearings</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="3379" end_char="3384">during</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="3386" end_char="3388">the</TOKEN>
<TOKEN id="token-28-21" pos="word" morph="none" start_char="3390" end_char="3394">early</TOKEN>
<TOKEN id="token-28-22" pos="word" morph="none" start_char="3396" end_char="3400">1950s</TOKEN>
<TOKEN id="token-28-23" pos="word" morph="none" start_char="3402" end_char="3409">revealed</TOKEN>
<TOKEN id="token-28-24" pos="word" morph="none" start_char="3411" end_char="3417">testing</TOKEN>
<TOKEN id="token-28-25" pos="word" morph="none" start_char="3419" end_char="3420">of</TOKEN>
<TOKEN id="token-28-26" pos="word" morph="none" start_char="3422" end_char="3431">biological</TOKEN>
<TOKEN id="token-28-27" pos="word" morph="none" start_char="3433" end_char="3438">agents</TOKEN>
<TOKEN id="token-28-28" pos="word" morph="none" start_char="3440" end_char="3441">on</TOKEN>
<TOKEN id="token-28-29" pos="word" morph="none" start_char="3443" end_char="3445">the</TOKEN>
<TOKEN id="token-28-30" pos="word" morph="none" start_char="3447" end_char="3452">public</TOKEN>
<TOKEN id="token-28-31" pos="punct" morph="none" start_char="3453" end_char="3453">,</TOKEN>
<TOKEN id="token-28-32" pos="word" morph="none" start_char="3455" end_char="3457">and</TOKEN>
<TOKEN id="token-28-33" pos="word" morph="none" start_char="3459" end_char="3461">the</TOKEN>
<TOKEN id="token-28-34" pos="word" morph="none" start_char="3463" end_char="3467">CIA's</TOKEN>
<TOKEN id="token-28-35" pos="unknown" morph="none" start_char="3469" end_char="3480">mind-control</TOKEN>
<TOKEN id="token-28-36" pos="word" morph="none" start_char="3482" end_char="3488">program</TOKEN>
<TOKEN id="token-28-37" pos="word" morph="none" start_char="3490" end_char="3496">MKUltra</TOKEN>
<TOKEN id="token-28-38" pos="word" morph="none" start_char="3498" end_char="3500">was</TOKEN>
<TOKEN id="token-28-39" pos="word" morph="none" start_char="3502" end_char="3510">confirmed</TOKEN>
<TOKEN id="token-28-40" pos="word" morph="none" start_char="3512" end_char="3513">in</TOKEN>
<TOKEN id="token-28-41" pos="word" morph="none" start_char="3515" end_char="3517">the</TOKEN>
<TOKEN id="token-28-42" pos="word" morph="none" start_char="3519" end_char="3522">1975</TOKEN>
<TOKEN id="token-28-43" pos="word" morph="none" start_char="3524" end_char="3529">Church</TOKEN>
<TOKEN id="token-28-44" pos="word" morph="none" start_char="3531" end_char="3539">Committee</TOKEN>
<TOKEN id="token-28-45" pos="punct" morph="none" start_char="3541" end_char="3541">–</TOKEN>
<TOKEN id="token-28-46" pos="word" morph="none" start_char="3543" end_char="3550">evidence</TOKEN>
<TOKEN id="token-28-47" pos="word" morph="none" start_char="3552" end_char="3555">does</TOKEN>
<TOKEN id="token-28-48" pos="word" morph="none" start_char="3557" end_char="3559">not</TOKEN>
<TOKEN id="token-28-49" pos="word" morph="none" start_char="3561" end_char="3565">point</TOKEN>
<TOKEN id="token-28-50" pos="word" morph="none" start_char="3567" end_char="3568">to</TOKEN>
<TOKEN id="token-28-51" pos="word" morph="none" start_char="3570" end_char="3572">the</TOKEN>
<TOKEN id="token-28-52" pos="word" morph="none" start_char="3574" end_char="3584">coronavirus</TOKEN>
<TOKEN id="token-28-53" pos="word" morph="none" start_char="3586" end_char="3590">being</TOKEN>
<TOKEN id="token-28-54" pos="word" morph="none" start_char="3592" end_char="3603">purposefully</TOKEN>
<TOKEN id="token-28-55" pos="word" morph="none" start_char="3605" end_char="3614">engineered</TOKEN>
<TOKEN id="token-28-56" pos="punct" morph="none" start_char="3615" end_char="3615">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3618" end_char="3801">
<ORIGINAL_TEXT>"It's extremely unlikely that there was any intentional development or any intentional action in a laboratory, whether in China or the United States, to develop (the coronavirus)," Dr.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="punct" morph="none" start_char="3618" end_char="3618">"</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="3619" end_char="3622">It's</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="3624" end_char="3632">extremely</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="3634" end_char="3641">unlikely</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="3643" end_char="3646">that</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="3648" end_char="3652">there</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="3654" end_char="3656">was</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="3658" end_char="3660">any</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="3662" end_char="3672">intentional</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="3674" end_char="3684">development</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="3686" end_char="3687">or</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="3689" end_char="3691">any</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="3693" end_char="3703">intentional</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="3705" end_char="3710">action</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="3712" end_char="3713">in</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="3715" end_char="3715">a</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="3717" end_char="3726">laboratory</TOKEN>
<TOKEN id="token-29-17" pos="punct" morph="none" start_char="3727" end_char="3727">,</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="3729" end_char="3735">whether</TOKEN>
<TOKEN id="token-29-19" pos="word" morph="none" start_char="3737" end_char="3738">in</TOKEN>
<TOKEN id="token-29-20" pos="word" morph="none" start_char="3740" end_char="3744">China</TOKEN>
<TOKEN id="token-29-21" pos="word" morph="none" start_char="3746" end_char="3747">or</TOKEN>
<TOKEN id="token-29-22" pos="word" morph="none" start_char="3749" end_char="3751">the</TOKEN>
<TOKEN id="token-29-23" pos="word" morph="none" start_char="3753" end_char="3758">United</TOKEN>
<TOKEN id="token-29-24" pos="word" morph="none" start_char="3760" end_char="3765">States</TOKEN>
<TOKEN id="token-29-25" pos="punct" morph="none" start_char="3766" end_char="3766">,</TOKEN>
<TOKEN id="token-29-26" pos="word" morph="none" start_char="3768" end_char="3769">to</TOKEN>
<TOKEN id="token-29-27" pos="word" morph="none" start_char="3771" end_char="3777">develop</TOKEN>
<TOKEN id="token-29-28" pos="punct" morph="none" start_char="3779" end_char="3779">(</TOKEN>
<TOKEN id="token-29-29" pos="word" morph="none" start_char="3780" end_char="3782">the</TOKEN>
<TOKEN id="token-29-30" pos="word" morph="none" start_char="3784" end_char="3794">coronavirus</TOKEN>
<TOKEN id="token-29-31" pos="punct" morph="none" start_char="3795" end_char="3797">),"</TOKEN>
<TOKEN id="token-29-32" pos="word" morph="none" start_char="3799" end_char="3800">Dr</TOKEN>
<TOKEN id="token-29-33" pos="punct" morph="none" start_char="3801" end_char="3801">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3803" end_char="3930">
<ORIGINAL_TEXT>Leonard Cole, director of the Terror Medicine and Security at Rutgers New Jersey Medical School, told USA TODAY in an interview.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="3803" end_char="3809">Leonard</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="3811" end_char="3814">Cole</TOKEN>
<TOKEN id="token-30-2" pos="punct" morph="none" start_char="3815" end_char="3815">,</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="3817" end_char="3824">director</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="3826" end_char="3827">of</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="3829" end_char="3831">the</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="3833" end_char="3838">Terror</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="3840" end_char="3847">Medicine</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="3849" end_char="3851">and</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="3853" end_char="3860">Security</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="3862" end_char="3863">at</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="3865" end_char="3871">Rutgers</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="3873" end_char="3875">New</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="3877" end_char="3882">Jersey</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="3884" end_char="3890">Medical</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="3892" end_char="3897">School</TOKEN>
<TOKEN id="token-30-16" pos="punct" morph="none" start_char="3898" end_char="3898">,</TOKEN>
<TOKEN id="token-30-17" pos="word" morph="none" start_char="3900" end_char="3903">told</TOKEN>
<TOKEN id="token-30-18" pos="word" morph="none" start_char="3905" end_char="3907">USA</TOKEN>
<TOKEN id="token-30-19" pos="word" morph="none" start_char="3909" end_char="3913">TODAY</TOKEN>
<TOKEN id="token-30-20" pos="word" morph="none" start_char="3915" end_char="3916">in</TOKEN>
<TOKEN id="token-30-21" pos="word" morph="none" start_char="3918" end_char="3919">an</TOKEN>
<TOKEN id="token-30-22" pos="word" morph="none" start_char="3921" end_char="3929">interview</TOKEN>
<TOKEN id="token-30-23" pos="punct" morph="none" start_char="3930" end_char="3930">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="3932" end_char="4074">
<ORIGINAL_TEXT>Cole has written several books on the topic of bioterrorism, including "Clouds of Secrecy: The Army's Germ Warfare Tests Over Populated Areas."</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="3932" end_char="3935">Cole</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="3937" end_char="3939">has</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="3941" end_char="3947">written</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="3949" end_char="3955">several</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="3957" end_char="3961">books</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="3963" end_char="3964">on</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="3966" end_char="3968">the</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="3970" end_char="3974">topic</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="3976" end_char="3977">of</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="3979" end_char="3990">bioterrorism</TOKEN>
<TOKEN id="token-31-10" pos="punct" morph="none" start_char="3991" end_char="3991">,</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="3993" end_char="4001">including</TOKEN>
<TOKEN id="token-31-12" pos="punct" morph="none" start_char="4003" end_char="4003">"</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="4004" end_char="4009">Clouds</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="4011" end_char="4012">of</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="4014" end_char="4020">Secrecy</TOKEN>
<TOKEN id="token-31-16" pos="punct" morph="none" start_char="4021" end_char="4021">:</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="4023" end_char="4025">The</TOKEN>
<TOKEN id="token-31-18" pos="word" morph="none" start_char="4027" end_char="4032">Army's</TOKEN>
<TOKEN id="token-31-19" pos="word" morph="none" start_char="4034" end_char="4037">Germ</TOKEN>
<TOKEN id="token-31-20" pos="word" morph="none" start_char="4039" end_char="4045">Warfare</TOKEN>
<TOKEN id="token-31-21" pos="word" morph="none" start_char="4047" end_char="4051">Tests</TOKEN>
<TOKEN id="token-31-22" pos="word" morph="none" start_char="4053" end_char="4056">Over</TOKEN>
<TOKEN id="token-31-23" pos="word" morph="none" start_char="4058" end_char="4066">Populated</TOKEN>
<TOKEN id="token-31-24" pos="word" morph="none" start_char="4068" end_char="4072">Areas</TOKEN>
<TOKEN id="token-31-25" pos="punct" morph="none" start_char="4073" end_char="4074">."</TOKEN>
</SEG>
<SEG id="segment-32" start_char="4077" end_char="4186">
<ORIGINAL_TEXT>Several scientific analyses have also rejected the notion that the novel coronavirus was purposefully created.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="4077" end_char="4083">Several</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="4085" end_char="4094">scientific</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="4096" end_char="4103">analyses</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="4105" end_char="4108">have</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="4110" end_char="4113">also</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="4115" end_char="4122">rejected</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="4124" end_char="4126">the</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="4128" end_char="4133">notion</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="4135" end_char="4138">that</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="4140" end_char="4142">the</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="4144" end_char="4148">novel</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="4150" end_char="4160">coronavirus</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="4162" end_char="4164">was</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="4166" end_char="4177">purposefully</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="4179" end_char="4185">created</TOKEN>
<TOKEN id="token-32-15" pos="punct" morph="none" start_char="4186" end_char="4186">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="4189" end_char="4269">
<ORIGINAL_TEXT>Fact check: Coronavirus not man-made or engineered but its origin remains unclear</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="4189" end_char="4192">Fact</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="4194" end_char="4198">check</TOKEN>
<TOKEN id="token-33-2" pos="punct" morph="none" start_char="4199" end_char="4199">:</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="4201" end_char="4211">Coronavirus</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="4213" end_char="4215">not</TOKEN>
<TOKEN id="token-33-5" pos="unknown" morph="none" start_char="4217" end_char="4224">man-made</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="4226" end_char="4227">or</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="4229" end_char="4238">engineered</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="4240" end_char="4242">but</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="4244" end_char="4246">its</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="4248" end_char="4253">origin</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="4255" end_char="4261">remains</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="4263" end_char="4269">unclear</TOKEN>
</SEG>
<SEG id="segment-34" start_char="4272" end_char="4598">
<ORIGINAL_TEXT>"By comparing the available genome sequence data for known coronavirus strains, we can firmly determine that (the novel coronavirus) originated through natural processes," Dr. Kristian Andersen, PhD, an associate professor of immunology and microbiology at Scripps Research, said in a March statement released by the institute.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="punct" morph="none" start_char="4272" end_char="4272">"</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="4273" end_char="4274">By</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="4276" end_char="4284">comparing</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="4286" end_char="4288">the</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="4290" end_char="4298">available</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="4300" end_char="4305">genome</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="4307" end_char="4314">sequence</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="4316" end_char="4319">data</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="4321" end_char="4323">for</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="4325" end_char="4329">known</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="4331" end_char="4341">coronavirus</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="4343" end_char="4349">strains</TOKEN>
<TOKEN id="token-34-12" pos="punct" morph="none" start_char="4350" end_char="4350">,</TOKEN>
<TOKEN id="token-34-13" pos="word" morph="none" start_char="4352" end_char="4353">we</TOKEN>
<TOKEN id="token-34-14" pos="word" morph="none" start_char="4355" end_char="4357">can</TOKEN>
<TOKEN id="token-34-15" pos="word" morph="none" start_char="4359" end_char="4364">firmly</TOKEN>
<TOKEN id="token-34-16" pos="word" morph="none" start_char="4366" end_char="4374">determine</TOKEN>
<TOKEN id="token-34-17" pos="word" morph="none" start_char="4376" end_char="4379">that</TOKEN>
<TOKEN id="token-34-18" pos="punct" morph="none" start_char="4381" end_char="4381">(</TOKEN>
<TOKEN id="token-34-19" pos="word" morph="none" start_char="4382" end_char="4384">the</TOKEN>
<TOKEN id="token-34-20" pos="word" morph="none" start_char="4386" end_char="4390">novel</TOKEN>
<TOKEN id="token-34-21" pos="word" morph="none" start_char="4392" end_char="4402">coronavirus</TOKEN>
<TOKEN id="token-34-22" pos="punct" morph="none" start_char="4403" end_char="4403">)</TOKEN>
<TOKEN id="token-34-23" pos="word" morph="none" start_char="4405" end_char="4414">originated</TOKEN>
<TOKEN id="token-34-24" pos="word" morph="none" start_char="4416" end_char="4422">through</TOKEN>
<TOKEN id="token-34-25" pos="word" morph="none" start_char="4424" end_char="4430">natural</TOKEN>
<TOKEN id="token-34-26" pos="word" morph="none" start_char="4432" end_char="4440">processes</TOKEN>
<TOKEN id="token-34-27" pos="punct" morph="none" start_char="4441" end_char="4442">,"</TOKEN>
<TOKEN id="token-34-28" pos="word" morph="none" start_char="4444" end_char="4445">Dr</TOKEN>
<TOKEN id="token-34-29" pos="punct" morph="none" start_char="4446" end_char="4446">.</TOKEN>
<TOKEN id="token-34-30" pos="word" morph="none" start_char="4448" end_char="4455">Kristian</TOKEN>
<TOKEN id="token-34-31" pos="word" morph="none" start_char="4457" end_char="4464">Andersen</TOKEN>
<TOKEN id="token-34-32" pos="punct" morph="none" start_char="4465" end_char="4465">,</TOKEN>
<TOKEN id="token-34-33" pos="word" morph="none" start_char="4467" end_char="4469">PhD</TOKEN>
<TOKEN id="token-34-34" pos="punct" morph="none" start_char="4470" end_char="4470">,</TOKEN>
<TOKEN id="token-34-35" pos="word" morph="none" start_char="4472" end_char="4473">an</TOKEN>
<TOKEN id="token-34-36" pos="word" morph="none" start_char="4475" end_char="4483">associate</TOKEN>
<TOKEN id="token-34-37" pos="word" morph="none" start_char="4485" end_char="4493">professor</TOKEN>
<TOKEN id="token-34-38" pos="word" morph="none" start_char="4495" end_char="4496">of</TOKEN>
<TOKEN id="token-34-39" pos="word" morph="none" start_char="4498" end_char="4507">immunology</TOKEN>
<TOKEN id="token-34-40" pos="word" morph="none" start_char="4509" end_char="4511">and</TOKEN>
<TOKEN id="token-34-41" pos="word" morph="none" start_char="4513" end_char="4524">microbiology</TOKEN>
<TOKEN id="token-34-42" pos="word" morph="none" start_char="4526" end_char="4527">at</TOKEN>
<TOKEN id="token-34-43" pos="word" morph="none" start_char="4529" end_char="4535">Scripps</TOKEN>
<TOKEN id="token-34-44" pos="word" morph="none" start_char="4537" end_char="4544">Research</TOKEN>
<TOKEN id="token-34-45" pos="punct" morph="none" start_char="4545" end_char="4545">,</TOKEN>
<TOKEN id="token-34-46" pos="word" morph="none" start_char="4547" end_char="4550">said</TOKEN>
<TOKEN id="token-34-47" pos="word" morph="none" start_char="4552" end_char="4553">in</TOKEN>
<TOKEN id="token-34-48" pos="word" morph="none" start_char="4555" end_char="4555">a</TOKEN>
<TOKEN id="token-34-49" pos="word" morph="none" start_char="4557" end_char="4561">March</TOKEN>
<TOKEN id="token-34-50" pos="word" morph="none" start_char="4563" end_char="4571">statement</TOKEN>
<TOKEN id="token-34-51" pos="word" morph="none" start_char="4573" end_char="4580">released</TOKEN>
<TOKEN id="token-34-52" pos="word" morph="none" start_char="4582" end_char="4583">by</TOKEN>
<TOKEN id="token-34-53" pos="word" morph="none" start_char="4585" end_char="4587">the</TOKEN>
<TOKEN id="token-34-54" pos="word" morph="none" start_char="4589" end_char="4597">institute</TOKEN>
<TOKEN id="token-34-55" pos="punct" morph="none" start_char="4598" end_char="4598">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="4601" end_char="4775">
<ORIGINAL_TEXT>"If someone were seeking to engineer a new coronavirus as a pathogen, they would have constructed it from the backbone of a virus known to cause illness," Andersen also added.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="punct" morph="none" start_char="4601" end_char="4601">"</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="4602" end_char="4603">If</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="4605" end_char="4611">someone</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="4613" end_char="4616">were</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="4618" end_char="4624">seeking</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="4626" end_char="4627">to</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="4629" end_char="4636">engineer</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="4638" end_char="4638">a</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="4640" end_char="4642">new</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="4644" end_char="4654">coronavirus</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="4656" end_char="4657">as</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="4659" end_char="4659">a</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="4661" end_char="4668">pathogen</TOKEN>
<TOKEN id="token-35-13" pos="punct" morph="none" start_char="4669" end_char="4669">,</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="4671" end_char="4674">they</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="4676" end_char="4680">would</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="4682" end_char="4685">have</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="4687" end_char="4697">constructed</TOKEN>
<TOKEN id="token-35-18" pos="word" morph="none" start_char="4699" end_char="4700">it</TOKEN>
<TOKEN id="token-35-19" pos="word" morph="none" start_char="4702" end_char="4705">from</TOKEN>
<TOKEN id="token-35-20" pos="word" morph="none" start_char="4707" end_char="4709">the</TOKEN>
<TOKEN id="token-35-21" pos="word" morph="none" start_char="4711" end_char="4718">backbone</TOKEN>
<TOKEN id="token-35-22" pos="word" morph="none" start_char="4720" end_char="4721">of</TOKEN>
<TOKEN id="token-35-23" pos="word" morph="none" start_char="4723" end_char="4723">a</TOKEN>
<TOKEN id="token-35-24" pos="word" morph="none" start_char="4725" end_char="4729">virus</TOKEN>
<TOKEN id="token-35-25" pos="word" morph="none" start_char="4731" end_char="4735">known</TOKEN>
<TOKEN id="token-35-26" pos="word" morph="none" start_char="4737" end_char="4738">to</TOKEN>
<TOKEN id="token-35-27" pos="word" morph="none" start_char="4740" end_char="4744">cause</TOKEN>
<TOKEN id="token-35-28" pos="word" morph="none" start_char="4746" end_char="4752">illness</TOKEN>
<TOKEN id="token-35-29" pos="punct" morph="none" start_char="4753" end_char="4754">,"</TOKEN>
<TOKEN id="token-35-30" pos="word" morph="none" start_char="4756" end_char="4763">Andersen</TOKEN>
<TOKEN id="token-35-31" pos="word" morph="none" start_char="4765" end_char="4768">also</TOKEN>
<TOKEN id="token-35-32" pos="word" morph="none" start_char="4770" end_char="4774">added</TOKEN>
<TOKEN id="token-35-33" pos="punct" morph="none" start_char="4775" end_char="4775">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="4778" end_char="4794">
<ORIGINAL_TEXT>Our ruling: False</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="4778" end_char="4780">Our</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="4782" end_char="4787">ruling</TOKEN>
<TOKEN id="token-36-2" pos="punct" morph="none" start_char="4788" end_char="4788">:</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="4790" end_char="4794">False</TOKEN>
</SEG>
<SEG id="segment-37" start_char="4798" end_char="4976">
<ORIGINAL_TEXT>We rate the claim that the U.S. government purposefully created the novel coronavirus, through research efforts led by Fauci, as FALSE because it is not supported by our research.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="4798" end_char="4799">We</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="4801" end_char="4804">rate</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="4806" end_char="4808">the</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="4810" end_char="4814">claim</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="4816" end_char="4819">that</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="4821" end_char="4823">the</TOKEN>
<TOKEN id="token-37-6" pos="unknown" morph="none" start_char="4825" end_char="4827">U.S</TOKEN>
<TOKEN id="token-37-7" pos="punct" morph="none" start_char="4828" end_char="4828">.</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="4830" end_char="4839">government</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="4841" end_char="4852">purposefully</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="4854" end_char="4860">created</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="4862" end_char="4864">the</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="4866" end_char="4870">novel</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="4872" end_char="4882">coronavirus</TOKEN>
<TOKEN id="token-37-14" pos="punct" morph="none" start_char="4883" end_char="4883">,</TOKEN>
<TOKEN id="token-37-15" pos="word" morph="none" start_char="4885" end_char="4891">through</TOKEN>
<TOKEN id="token-37-16" pos="word" morph="none" start_char="4893" end_char="4900">research</TOKEN>
<TOKEN id="token-37-17" pos="word" morph="none" start_char="4902" end_char="4908">efforts</TOKEN>
<TOKEN id="token-37-18" pos="word" morph="none" start_char="4910" end_char="4912">led</TOKEN>
<TOKEN id="token-37-19" pos="word" morph="none" start_char="4914" end_char="4915">by</TOKEN>
<TOKEN id="token-37-20" pos="word" morph="none" start_char="4917" end_char="4921">Fauci</TOKEN>
<TOKEN id="token-37-21" pos="punct" morph="none" start_char="4922" end_char="4922">,</TOKEN>
<TOKEN id="token-37-22" pos="word" morph="none" start_char="4924" end_char="4925">as</TOKEN>
<TOKEN id="token-37-23" pos="word" morph="none" start_char="4927" end_char="4931">FALSE</TOKEN>
<TOKEN id="token-37-24" pos="word" morph="none" start_char="4933" end_char="4939">because</TOKEN>
<TOKEN id="token-37-25" pos="word" morph="none" start_char="4941" end_char="4942">it</TOKEN>
<TOKEN id="token-37-26" pos="word" morph="none" start_char="4944" end_char="4945">is</TOKEN>
<TOKEN id="token-37-27" pos="word" morph="none" start_char="4947" end_char="4949">not</TOKEN>
<TOKEN id="token-37-28" pos="word" morph="none" start_char="4951" end_char="4959">supported</TOKEN>
<TOKEN id="token-37-29" pos="word" morph="none" start_char="4961" end_char="4962">by</TOKEN>
<TOKEN id="token-37-30" pos="word" morph="none" start_char="4964" end_char="4966">our</TOKEN>
<TOKEN id="token-37-31" pos="word" morph="none" start_char="4968" end_char="4975">research</TOKEN>
<TOKEN id="token-37-32" pos="punct" morph="none" start_char="4976" end_char="4976">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="4978" end_char="5106">
<ORIGINAL_TEXT>Scientific evidence has found no support for the claim that the coronavirus was intentionally engineered in a laboratory setting.</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="4978" end_char="4987">Scientific</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="4989" end_char="4996">evidence</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="4998" end_char="5000">has</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="5002" end_char="5006">found</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="5008" end_char="5009">no</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="5011" end_char="5017">support</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="5019" end_char="5021">for</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="5023" end_char="5025">the</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="5027" end_char="5031">claim</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="5033" end_char="5036">that</TOKEN>
<TOKEN id="token-38-10" pos="word" morph="none" start_char="5038" end_char="5040">the</TOKEN>
<TOKEN id="token-38-11" pos="word" morph="none" start_char="5042" end_char="5052">coronavirus</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="5054" end_char="5056">was</TOKEN>
<TOKEN id="token-38-13" pos="word" morph="none" start_char="5058" end_char="5070">intentionally</TOKEN>
<TOKEN id="token-38-14" pos="word" morph="none" start_char="5072" end_char="5081">engineered</TOKEN>
<TOKEN id="token-38-15" pos="word" morph="none" start_char="5083" end_char="5084">in</TOKEN>
<TOKEN id="token-38-16" pos="word" morph="none" start_char="5086" end_char="5086">a</TOKEN>
<TOKEN id="token-38-17" pos="word" morph="none" start_char="5088" end_char="5097">laboratory</TOKEN>
<TOKEN id="token-38-18" pos="word" morph="none" start_char="5099" end_char="5105">setting</TOKEN>
<TOKEN id="token-38-19" pos="punct" morph="none" start_char="5106" end_char="5106">.</TOKEN>
</SEG>
<SEG id="segment-39" start_char="5109" end_char="5131">
<ORIGINAL_TEXT>Our fact-check sources:</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="5109" end_char="5111">Our</TOKEN>
<TOKEN id="token-39-1" pos="unknown" morph="none" start_char="5113" end_char="5122">fact-check</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="5124" end_char="5130">sources</TOKEN>
<TOKEN id="token-39-3" pos="punct" morph="none" start_char="5131" end_char="5131">:</TOKEN>
</SEG>
<SEG id="segment-40" start_char="5135" end_char="5168">
<ORIGINAL_TEXT>Media Bias/Fact Check, "The Duran"</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="5135" end_char="5139">Media</TOKEN>
<TOKEN id="token-40-1" pos="unknown" morph="none" start_char="5141" end_char="5149">Bias/Fact</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="5151" end_char="5155">Check</TOKEN>
<TOKEN id="token-40-3" pos="punct" morph="none" start_char="5156" end_char="5156">,</TOKEN>
<TOKEN id="token-40-4" pos="punct" morph="none" start_char="5158" end_char="5158">"</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="5159" end_char="5161">The</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="5163" end_char="5167">Duran</TOKEN>
<TOKEN id="token-40-7" pos="punct" morph="none" start_char="5168" end_char="5168">"</TOKEN>
</SEG>
<SEG id="segment-41" start_char="5171" end_char="5210">
<ORIGINAL_TEXT>Thank you for supporting our journalism.</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="5171" end_char="5175">Thank</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="5177" end_char="5179">you</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="5181" end_char="5183">for</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="5185" end_char="5194">supporting</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="5196" end_char="5198">our</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="5200" end_char="5209">journalism</TOKEN>
<TOKEN id="token-41-6" pos="punct" morph="none" start_char="5210" end_char="5210">.</TOKEN>
</SEG>
<SEG id="segment-42" start_char="5212" end_char="5300">
<ORIGINAL_TEXT>You can subscribe to our print edition, ad-free app or electronic newspaper replica here.</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="5212" end_char="5214">You</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="5216" end_char="5218">can</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="5220" end_char="5228">subscribe</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="5230" end_char="5231">to</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="5233" end_char="5235">our</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="5237" end_char="5241">print</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="5243" end_char="5249">edition</TOKEN>
<TOKEN id="token-42-7" pos="punct" morph="none" start_char="5250" end_char="5250">,</TOKEN>
<TOKEN id="token-42-8" pos="unknown" morph="none" start_char="5252" end_char="5258">ad-free</TOKEN>
<TOKEN id="token-42-9" pos="word" morph="none" start_char="5260" end_char="5262">app</TOKEN>
<TOKEN id="token-42-10" pos="word" morph="none" start_char="5264" end_char="5265">or</TOKEN>
<TOKEN id="token-42-11" pos="word" morph="none" start_char="5267" end_char="5276">electronic</TOKEN>
<TOKEN id="token-42-12" pos="word" morph="none" start_char="5278" end_char="5286">newspaper</TOKEN>
<TOKEN id="token-42-13" pos="word" morph="none" start_char="5288" end_char="5294">replica</TOKEN>
<TOKEN id="token-42-14" pos="word" morph="none" start_char="5296" end_char="5299">here</TOKEN>
<TOKEN id="token-42-15" pos="punct" morph="none" start_char="5300" end_char="5300">.</TOKEN>
</SEG>
<SEG id="segment-43" start_char="5303" end_char="5368">
<ORIGINAL_TEXT>Our fact check work is supported in part by a grant from Facebook.</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="5303" end_char="5305">Our</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="5307" end_char="5310">fact</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="5312" end_char="5316">check</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="5318" end_char="5321">work</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="5323" end_char="5324">is</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="5326" end_char="5334">supported</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="5336" end_char="5337">in</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="5339" end_char="5342">part</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="5344" end_char="5345">by</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="5347" end_char="5347">a</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="5349" end_char="5353">grant</TOKEN>
<TOKEN id="token-43-11" pos="word" morph="none" start_char="5355" end_char="5358">from</TOKEN>
<TOKEN id="token-43-12" pos="word" morph="none" start_char="5360" end_char="5367">Facebook</TOKEN>
<TOKEN id="token-43-13" pos="punct" morph="none" start_char="5368" end_char="5368">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
