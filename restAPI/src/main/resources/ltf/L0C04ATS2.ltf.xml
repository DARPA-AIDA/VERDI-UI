<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATS2" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="5186" raw_text_md5="f75bcf2e760c9360327e79bd2e14393c">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="127">
<ORIGINAL_TEXT>El vídeo de la RAI en 2015 y la nula evidencia científica de que el coronavirus fuese creado en un laboratorio de China en 2015</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="2">El</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="4" end_char="8">vídeo</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="10" end_char="11">de</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="13" end_char="14">la</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="16" end_char="18">RAI</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="20" end_char="21">en</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="23" end_char="26">2015</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="28" end_char="28">y</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="30" end_char="31">la</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="33" end_char="36">nula</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="38" end_char="46">evidencia</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="48" end_char="57">científica</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="59" end_char="60">de</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="62" end_char="64">que</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="66" end_char="67">el</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="69" end_char="79">coronavirus</TOKEN>
<TOKEN id="token-0-16" pos="word" morph="none" start_char="81" end_char="85">fuese</TOKEN>
<TOKEN id="token-0-17" pos="word" morph="none" start_char="87" end_char="92">creado</TOKEN>
<TOKEN id="token-0-18" pos="word" morph="none" start_char="94" end_char="95">en</TOKEN>
<TOKEN id="token-0-19" pos="word" morph="none" start_char="97" end_char="98">un</TOKEN>
<TOKEN id="token-0-20" pos="word" morph="none" start_char="100" end_char="110">laboratorio</TOKEN>
<TOKEN id="token-0-21" pos="word" morph="none" start_char="112" end_char="113">de</TOKEN>
<TOKEN id="token-0-22" pos="word" morph="none" start_char="115" end_char="119">China</TOKEN>
<TOKEN id="token-0-23" pos="word" morph="none" start_char="121" end_char="122">en</TOKEN>
<TOKEN id="token-0-24" pos="word" morph="none" start_char="124" end_char="127">2015</TOKEN>
</SEG>
<SEG id="segment-1" start_char="132" end_char="195">
<ORIGINAL_TEXT>Se ha viralizado en las redes sociales un fragmento del programa</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="132" end_char="133">Se</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="135" end_char="136">ha</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="138" end_char="147">viralizado</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="149" end_char="150">en</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="152" end_char="154">las</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="156" end_char="160">redes</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="162" end_char="169">sociales</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="171" end_char="172">un</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="174" end_char="182">fragmento</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="184" end_char="186">del</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="188" end_char="195">programa</TOKEN>
</SEG>
<SEG id="segment-2" start_char="198" end_char="209">
<ORIGINAL_TEXT>TGR Leonardo</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="198" end_char="200">TGR</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="202" end_char="209">Leonardo</TOKEN>
</SEG>
<SEG id="segment-3" start_char="212" end_char="436">
<ORIGINAL_TEXT>emitido en el canal de la televisión italiana RAI en noviembre de 2015 en el que el presentador habla de un coronavirus creado en un laboratorio de China a partir de murciélagos y ratones y que podría afectar a seres humanos.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="212" end_char="218">emitido</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="220" end_char="221">en</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="223" end_char="224">el</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="226" end_char="230">canal</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="232" end_char="233">de</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="235" end_char="236">la</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="238" end_char="247">televisión</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="249" end_char="256">italiana</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="258" end_char="260">RAI</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="262" end_char="263">en</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="265" end_char="273">noviembre</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="275" end_char="276">de</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="278" end_char="281">2015</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="283" end_char="284">en</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="286" end_char="287">el</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="289" end_char="291">que</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="293" end_char="294">el</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="296" end_char="306">presentador</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="308" end_char="312">habla</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="314" end_char="315">de</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="317" end_char="318">un</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="320" end_char="330">coronavirus</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="332" end_char="337">creado</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="339" end_char="340">en</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="342" end_char="343">un</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="345" end_char="355">laboratorio</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="357" end_char="358">de</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="360" end_char="364">China</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="366" end_char="366">a</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="368" end_char="373">partir</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="375" end_char="376">de</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="378" end_char="388">murciélagos</TOKEN>
<TOKEN id="token-3-32" pos="word" morph="none" start_char="390" end_char="390">y</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="392" end_char="398">ratones</TOKEN>
<TOKEN id="token-3-34" pos="word" morph="none" start_char="400" end_char="400">y</TOKEN>
<TOKEN id="token-3-35" pos="word" morph="none" start_char="402" end_char="404">que</TOKEN>
<TOKEN id="token-3-36" pos="word" morph="none" start_char="406" end_char="411">podría</TOKEN>
<TOKEN id="token-3-37" pos="word" morph="none" start_char="413" end_char="419">afectar</TOKEN>
<TOKEN id="token-3-38" pos="word" morph="none" start_char="421" end_char="421">a</TOKEN>
<TOKEN id="token-3-39" pos="word" morph="none" start_char="423" end_char="427">seres</TOKEN>
<TOKEN id="token-3-40" pos="word" morph="none" start_char="429" end_char="435">humanos</TOKEN>
<TOKEN id="token-3-41" pos="punct" morph="none" start_char="436" end_char="436">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="438" end_char="500">
<ORIGINAL_TEXT>Este experimento se publicó días antes en la revista científica</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="438" end_char="441">Este</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="443" end_char="453">experimento</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="455" end_char="456">se</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="458" end_char="464">publicó</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="466" end_char="469">días</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="471" end_char="475">antes</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="477" end_char="478">en</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="480" end_char="481">la</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="483" end_char="489">revista</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="491" end_char="500">científica</TOKEN>
</SEG>
<SEG id="segment-5" start_char="503" end_char="508">
<ORIGINAL_TEXT>Nature</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="503" end_char="508">Nature</TOKEN>
</SEG>
<SEG id="segment-6" start_char="511" end_char="511">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="punct" morph="none" start_char="511" end_char="511">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="514" end_char="529">
<ORIGINAL_TEXT>Además, el medio</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="514" end_char="519">Además</TOKEN>
<TOKEN id="token-7-1" pos="punct" morph="none" start_char="520" end_char="520">,</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="522" end_char="523">el</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="525" end_char="529">medio</TOKEN>
</SEG>
<SEG id="segment-8" start_char="532" end_char="538">
<ORIGINAL_TEXT>Toro Tv</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="532" end_char="535">Toro</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="537" end_char="538">Tv</TOKEN>
</SEG>
<SEG id="segment-9" start_char="541" end_char="548">
<ORIGINAL_TEXT>(antigua</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="punct" morph="none" start_char="541" end_char="541">(</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="542" end_char="548">antigua</TOKEN>
</SEG>
<SEG id="segment-10" start_char="551" end_char="564">
<ORIGINAL_TEXT>Intereconomía)</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="551" end_char="563">Intereconomía</TOKEN>
<TOKEN id="token-10-1" pos="punct" morph="none" start_char="564" end_char="564">)</TOKEN>
</SEG>
<SEG id="segment-11" start_char="567" end_char="631">
<ORIGINAL_TEXT>publicó el 29 de marzo este fragmento del programa italiano [min.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="567" end_char="573">publicó</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="575" end_char="576">el</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="578" end_char="579">29</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="581" end_char="582">de</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="584" end_char="588">marzo</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="590" end_char="593">este</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="595" end_char="603">fragmento</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="605" end_char="607">del</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="609" end_char="616">programa</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="618" end_char="625">italiano</TOKEN>
<TOKEN id="token-11-10" pos="punct" morph="none" start_char="627" end_char="627">[</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="628" end_char="630">min</TOKEN>
<TOKEN id="token-11-12" pos="punct" morph="none" start_char="631" end_char="631">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="633" end_char="766">
<ORIGINAL_TEXT>54:35] y uno de los colaboradores señaló que "hay unos tipos en el mundo que están jugando con la vida y la salud del universo entero.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="unknown" morph="none" start_char="633" end_char="637">54:35</TOKEN>
<TOKEN id="token-12-1" pos="punct" morph="none" start_char="638" end_char="638">]</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="640" end_char="640">y</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="642" end_char="644">uno</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="646" end_char="647">de</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="649" end_char="651">los</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="653" end_char="665">colaboradores</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="667" end_char="672">señaló</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="674" end_char="676">que</TOKEN>
<TOKEN id="token-12-9" pos="punct" morph="none" start_char="678" end_char="678">"</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="679" end_char="681">hay</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="683" end_char="686">unos</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="688" end_char="692">tipos</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="694" end_char="695">en</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="697" end_char="698">el</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="700" end_char="704">mundo</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="706" end_char="708">que</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="710" end_char="714">están</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="716" end_char="722">jugando</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="724" end_char="726">con</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="728" end_char="729">la</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="731" end_char="734">vida</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="736" end_char="736">y</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="738" end_char="739">la</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="741" end_char="745">salud</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="747" end_char="749">del</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="751" end_char="758">universo</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="760" end_char="765">entero</TOKEN>
<TOKEN id="token-12-28" pos="punct" morph="none" start_char="766" end_char="766">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="768" end_char="802">
<ORIGINAL_TEXT>Mira lo que estamos viviendo" [min.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="768" end_char="771">Mira</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="773" end_char="774">lo</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="776" end_char="778">que</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="780" end_char="786">estamos</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="788" end_char="795">viviendo</TOKEN>
<TOKEN id="token-13-5" pos="punct" morph="none" start_char="796" end_char="796">"</TOKEN>
<TOKEN id="token-13-6" pos="punct" morph="none" start_char="798" end_char="798">[</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="799" end_char="801">min</TOKEN>
<TOKEN id="token-13-8" pos="punct" morph="none" start_char="802" end_char="802">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="804" end_char="811">
<ORIGINAL_TEXT>59:52]*.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="unknown" morph="none" start_char="804" end_char="808">59:52</TOKEN>
<TOKEN id="token-14-1" pos="punct" morph="none" start_char="809" end_char="811">]*.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="813" end_char="967">
<ORIGINAL_TEXT>No hay ninguna evidencia científica de que el coronavirus haya sido obra del hombre: la comunidad científica afirma que el SARS-CoV-2 tiene origen natural.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="813" end_char="814">No</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="816" end_char="818">hay</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="820" end_char="826">ninguna</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="828" end_char="836">evidencia</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="838" end_char="847">científica</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="849" end_char="850">de</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="852" end_char="854">que</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="856" end_char="857">el</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="859" end_char="869">coronavirus</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="871" end_char="874">haya</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="876" end_char="879">sido</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="881" end_char="884">obra</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="886" end_char="888">del</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="890" end_char="895">hombre</TOKEN>
<TOKEN id="token-15-14" pos="punct" morph="none" start_char="896" end_char="896">:</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="898" end_char="899">la</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="901" end_char="909">comunidad</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="911" end_char="920">científica</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="922" end_char="927">afirma</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="929" end_char="931">que</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="933" end_char="934">el</TOKEN>
<TOKEN id="token-15-21" pos="unknown" morph="none" start_char="936" end_char="945">SARS-CoV-2</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="947" end_char="951">tiene</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="953" end_char="958">origen</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="960" end_char="966">natural</TOKEN>
<TOKEN id="token-15-25" pos="punct" morph="none" start_char="967" end_char="967">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="970" end_char="1018">
<ORIGINAL_TEXT>El 12 de noviembre de 2015, la revista científica</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="970" end_char="971">El</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="973" end_char="974">12</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="976" end_char="977">de</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="979" end_char="987">noviembre</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="989" end_char="990">de</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="992" end_char="995">2015</TOKEN>
<TOKEN id="token-16-6" pos="punct" morph="none" start_char="996" end_char="996">,</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="998" end_char="999">la</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1001" end_char="1007">revista</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="1009" end_char="1018">científica</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1021" end_char="1026">
<ORIGINAL_TEXT>Nature</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1021" end_char="1026">Nature</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1029" end_char="1247">
<ORIGINAL_TEXT>publicó los hallazgos de un grupo de investigación que había sido capaz de "infectar con coronavirus de murciélago directamente a los humanos (en lugar de necesitar evolucionar primero en un huésped animal intermedio)".</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="1029" end_char="1035">publicó</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="1037" end_char="1039">los</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="1041" end_char="1049">hallazgos</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="1051" end_char="1052">de</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="1054" end_char="1055">un</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="1057" end_char="1061">grupo</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="1063" end_char="1064">de</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="1066" end_char="1078">investigación</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="1080" end_char="1082">que</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="1084" end_char="1088">había</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="1090" end_char="1093">sido</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="1095" end_char="1099">capaz</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="1101" end_char="1102">de</TOKEN>
<TOKEN id="token-18-13" pos="punct" morph="none" start_char="1104" end_char="1104">"</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="1105" end_char="1112">infectar</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="1114" end_char="1116">con</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="1118" end_char="1128">coronavirus</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="1130" end_char="1131">de</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="1133" end_char="1142">murciélago</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="1144" end_char="1155">directamente</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="1157" end_char="1157">a</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="1159" end_char="1161">los</TOKEN>
<TOKEN id="token-18-22" pos="word" morph="none" start_char="1163" end_char="1169">humanos</TOKEN>
<TOKEN id="token-18-23" pos="punct" morph="none" start_char="1171" end_char="1171">(</TOKEN>
<TOKEN id="token-18-24" pos="word" morph="none" start_char="1172" end_char="1173">en</TOKEN>
<TOKEN id="token-18-25" pos="word" morph="none" start_char="1175" end_char="1179">lugar</TOKEN>
<TOKEN id="token-18-26" pos="word" morph="none" start_char="1181" end_char="1182">de</TOKEN>
<TOKEN id="token-18-27" pos="word" morph="none" start_char="1184" end_char="1192">necesitar</TOKEN>
<TOKEN id="token-18-28" pos="word" morph="none" start_char="1194" end_char="1204">evolucionar</TOKEN>
<TOKEN id="token-18-29" pos="word" morph="none" start_char="1206" end_char="1212">primero</TOKEN>
<TOKEN id="token-18-30" pos="word" morph="none" start_char="1214" end_char="1215">en</TOKEN>
<TOKEN id="token-18-31" pos="word" morph="none" start_char="1217" end_char="1218">un</TOKEN>
<TOKEN id="token-18-32" pos="word" morph="none" start_char="1220" end_char="1226">huésped</TOKEN>
<TOKEN id="token-18-33" pos="word" morph="none" start_char="1228" end_char="1233">animal</TOKEN>
<TOKEN id="token-18-34" pos="word" morph="none" start_char="1235" end_char="1244">intermedio</TOKEN>
<TOKEN id="token-18-35" pos="punct" morph="none" start_char="1245" end_char="1247">)".</TOKEN>
</SEG>
<SEG id="segment-19" start_char="1250" end_char="1355">
<ORIGINAL_TEXT>Cuatro días más tarde, el 16 de noviembre de 2015, la televisión pública italiana, RAI, emitió el programa</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="1250" end_char="1255">Cuatro</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="1257" end_char="1260">días</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="1262" end_char="1264">más</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="1266" end_char="1270">tarde</TOKEN>
<TOKEN id="token-19-4" pos="punct" morph="none" start_char="1271" end_char="1271">,</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="1273" end_char="1274">el</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="1276" end_char="1277">16</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="1279" end_char="1280">de</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="1282" end_char="1290">noviembre</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="1292" end_char="1293">de</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="1295" end_char="1298">2015</TOKEN>
<TOKEN id="token-19-11" pos="punct" morph="none" start_char="1299" end_char="1299">,</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="1301" end_char="1302">la</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="1304" end_char="1313">televisión</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="1315" end_char="1321">pública</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="1323" end_char="1330">italiana</TOKEN>
<TOKEN id="token-19-16" pos="punct" morph="none" start_char="1331" end_char="1331">,</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="1333" end_char="1335">RAI</TOKEN>
<TOKEN id="token-19-18" pos="punct" morph="none" start_char="1336" end_char="1336">,</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="1338" end_char="1343">emitió</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="1345" end_char="1346">el</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="1348" end_char="1355">programa</TOKEN>
</SEG>
<SEG id="segment-20" start_char="1358" end_char="1369">
<ORIGINAL_TEXT>TGR Leonardo</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="1358" end_char="1360">TGR</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="1362" end_char="1369">Leonardo</TOKEN>
</SEG>
<SEG id="segment-21" start_char="1372" end_char="1662">
<ORIGINAL_TEXT>, especializado en información científica, y habló de los resultados de "un grupo de investigadores chinos que injertó una proteína de superficie tomada de murciélagos en un virus que causa SARS derivado de ratones", creando "un supervirus que podría afectar a los humanos" [a partir de min.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="punct" morph="none" start_char="1372" end_char="1372">,</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="1374" end_char="1386">especializado</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="1388" end_char="1389">en</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="1391" end_char="1401">información</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="1403" end_char="1412">científica</TOKEN>
<TOKEN id="token-21-5" pos="punct" morph="none" start_char="1413" end_char="1413">,</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="1415" end_char="1415">y</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="1417" end_char="1421">habló</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="1423" end_char="1424">de</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="1426" end_char="1428">los</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="1430" end_char="1439">resultados</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="1441" end_char="1442">de</TOKEN>
<TOKEN id="token-21-12" pos="punct" morph="none" start_char="1444" end_char="1444">"</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="1445" end_char="1446">un</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="1448" end_char="1452">grupo</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="1454" end_char="1455">de</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="1457" end_char="1470">investigadores</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="1472" end_char="1477">chinos</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="1479" end_char="1481">que</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="1483" end_char="1489">injertó</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="1491" end_char="1493">una</TOKEN>
<TOKEN id="token-21-21" pos="word" morph="none" start_char="1495" end_char="1502">proteína</TOKEN>
<TOKEN id="token-21-22" pos="word" morph="none" start_char="1504" end_char="1505">de</TOKEN>
<TOKEN id="token-21-23" pos="word" morph="none" start_char="1507" end_char="1516">superficie</TOKEN>
<TOKEN id="token-21-24" pos="word" morph="none" start_char="1518" end_char="1523">tomada</TOKEN>
<TOKEN id="token-21-25" pos="word" morph="none" start_char="1525" end_char="1526">de</TOKEN>
<TOKEN id="token-21-26" pos="word" morph="none" start_char="1528" end_char="1538">murciélagos</TOKEN>
<TOKEN id="token-21-27" pos="word" morph="none" start_char="1540" end_char="1541">en</TOKEN>
<TOKEN id="token-21-28" pos="word" morph="none" start_char="1543" end_char="1544">un</TOKEN>
<TOKEN id="token-21-29" pos="word" morph="none" start_char="1546" end_char="1550">virus</TOKEN>
<TOKEN id="token-21-30" pos="word" morph="none" start_char="1552" end_char="1554">que</TOKEN>
<TOKEN id="token-21-31" pos="word" morph="none" start_char="1556" end_char="1560">causa</TOKEN>
<TOKEN id="token-21-32" pos="word" morph="none" start_char="1562" end_char="1565">SARS</TOKEN>
<TOKEN id="token-21-33" pos="word" morph="none" start_char="1567" end_char="1574">derivado</TOKEN>
<TOKEN id="token-21-34" pos="word" morph="none" start_char="1576" end_char="1577">de</TOKEN>
<TOKEN id="token-21-35" pos="word" morph="none" start_char="1579" end_char="1585">ratones</TOKEN>
<TOKEN id="token-21-36" pos="punct" morph="none" start_char="1586" end_char="1587">",</TOKEN>
<TOKEN id="token-21-37" pos="word" morph="none" start_char="1589" end_char="1595">creando</TOKEN>
<TOKEN id="token-21-38" pos="punct" morph="none" start_char="1597" end_char="1597">"</TOKEN>
<TOKEN id="token-21-39" pos="word" morph="none" start_char="1598" end_char="1599">un</TOKEN>
<TOKEN id="token-21-40" pos="word" morph="none" start_char="1601" end_char="1610">supervirus</TOKEN>
<TOKEN id="token-21-41" pos="word" morph="none" start_char="1612" end_char="1614">que</TOKEN>
<TOKEN id="token-21-42" pos="word" morph="none" start_char="1616" end_char="1621">podría</TOKEN>
<TOKEN id="token-21-43" pos="word" morph="none" start_char="1623" end_char="1629">afectar</TOKEN>
<TOKEN id="token-21-44" pos="word" morph="none" start_char="1631" end_char="1631">a</TOKEN>
<TOKEN id="token-21-45" pos="word" morph="none" start_char="1633" end_char="1635">los</TOKEN>
<TOKEN id="token-21-46" pos="word" morph="none" start_char="1637" end_char="1643">humanos</TOKEN>
<TOKEN id="token-21-47" pos="punct" morph="none" start_char="1644" end_char="1644">"</TOKEN>
<TOKEN id="token-21-48" pos="punct" morph="none" start_char="1646" end_char="1646">[</TOKEN>
<TOKEN id="token-21-49" pos="word" morph="none" start_char="1647" end_char="1647">a</TOKEN>
<TOKEN id="token-21-50" pos="word" morph="none" start_char="1649" end_char="1654">partir</TOKEN>
<TOKEN id="token-21-51" pos="word" morph="none" start_char="1656" end_char="1657">de</TOKEN>
<TOKEN id="token-21-52" pos="word" morph="none" start_char="1659" end_char="1661">min</TOKEN>
<TOKEN id="token-21-53" pos="punct" morph="none" start_char="1662" end_char="1662">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="1664" end_char="1669">
<ORIGINAL_TEXT>4:55].</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="unknown" morph="none" start_char="1664" end_char="1667">4:55</TOKEN>
<TOKEN id="token-22-1" pos="punct" morph="none" start_char="1668" end_char="1669">].</TOKEN>
</SEG>
<SEG id="segment-23" start_char="1672" end_char="1677">
<ORIGINAL_TEXT>Nature</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="1672" end_char="1677">Nature</TOKEN>
</SEG>
<SEG id="segment-24" start_char="1680" end_char="1799">
<ORIGINAL_TEXT>ha explicado que el coronavirus del que hablan en el artículo no tiene nada que ver con el que está causando el COVID-19</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="1680" end_char="1681">ha</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="1683" end_char="1691">explicado</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="1693" end_char="1695">que</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="1697" end_char="1698">el</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="1700" end_char="1710">coronavirus</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="1712" end_char="1714">del</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="1716" end_char="1718">que</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="1720" end_char="1725">hablan</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="1727" end_char="1728">en</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="1730" end_char="1731">el</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="1733" end_char="1740">artículo</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="1742" end_char="1743">no</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="1745" end_char="1749">tiene</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="1751" end_char="1754">nada</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="1756" end_char="1758">que</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="1760" end_char="1762">ver</TOKEN>
<TOKEN id="token-24-16" pos="word" morph="none" start_char="1764" end_char="1766">con</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="1768" end_char="1769">el</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="1771" end_char="1773">que</TOKEN>
<TOKEN id="token-24-19" pos="word" morph="none" start_char="1775" end_char="1778">está</TOKEN>
<TOKEN id="token-24-20" pos="word" morph="none" start_char="1780" end_char="1787">causando</TOKEN>
<TOKEN id="token-24-21" pos="word" morph="none" start_char="1789" end_char="1790">el</TOKEN>
<TOKEN id="token-24-22" pos="unknown" morph="none" start_char="1792" end_char="1799">COVID-19</TOKEN>
</SEG>
<SEG id="segment-25" start_char="1803" end_char="1829">
<ORIGINAL_TEXT>Sin embargo, recientemente,</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="1803" end_char="1805">Sin</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="1807" end_char="1813">embargo</TOKEN>
<TOKEN id="token-25-2" pos="punct" morph="none" start_char="1814" end_char="1814">,</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="1816" end_char="1828">recientemente</TOKEN>
<TOKEN id="token-25-4" pos="punct" morph="none" start_char="1829" end_char="1829">,</TOKEN>
</SEG>
<SEG id="segment-26" start_char="1832" end_char="1837">
<ORIGINAL_TEXT>Nature</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="1832" end_char="1837">Nature</TOKEN>
</SEG>
<SEG id="segment-27" start_char="1840" end_char="2164">
<ORIGINAL_TEXT>ha añadido una nota para aclarar que el coronavirus del que hablan en el artículo no tiene nada que ver con el que está causando el COVID-19: "Somos conscientes de que este experimento se está utilizando como base para las teorías no verificadas de que el nuevo coronavirus que causa COVID-19 fue diseñado en un laboratorio".</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="1840" end_char="1841">ha</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="1843" end_char="1849">añadido</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="1851" end_char="1853">una</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="1855" end_char="1858">nota</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="1860" end_char="1863">para</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="1865" end_char="1871">aclarar</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="1873" end_char="1875">que</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="1877" end_char="1878">el</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="1880" end_char="1890">coronavirus</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="1892" end_char="1894">del</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="1896" end_char="1898">que</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="1900" end_char="1905">hablan</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="1907" end_char="1908">en</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="1910" end_char="1911">el</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="1913" end_char="1920">artículo</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="1922" end_char="1923">no</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="1925" end_char="1929">tiene</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="1931" end_char="1934">nada</TOKEN>
<TOKEN id="token-27-18" pos="word" morph="none" start_char="1936" end_char="1938">que</TOKEN>
<TOKEN id="token-27-19" pos="word" morph="none" start_char="1940" end_char="1942">ver</TOKEN>
<TOKEN id="token-27-20" pos="word" morph="none" start_char="1944" end_char="1946">con</TOKEN>
<TOKEN id="token-27-21" pos="word" morph="none" start_char="1948" end_char="1949">el</TOKEN>
<TOKEN id="token-27-22" pos="word" morph="none" start_char="1951" end_char="1953">que</TOKEN>
<TOKEN id="token-27-23" pos="word" morph="none" start_char="1955" end_char="1958">está</TOKEN>
<TOKEN id="token-27-24" pos="word" morph="none" start_char="1960" end_char="1967">causando</TOKEN>
<TOKEN id="token-27-25" pos="word" morph="none" start_char="1969" end_char="1970">el</TOKEN>
<TOKEN id="token-27-26" pos="unknown" morph="none" start_char="1972" end_char="1979">COVID-19</TOKEN>
<TOKEN id="token-27-27" pos="punct" morph="none" start_char="1980" end_char="1980">:</TOKEN>
<TOKEN id="token-27-28" pos="punct" morph="none" start_char="1982" end_char="1982">"</TOKEN>
<TOKEN id="token-27-29" pos="word" morph="none" start_char="1983" end_char="1987">Somos</TOKEN>
<TOKEN id="token-27-30" pos="word" morph="none" start_char="1989" end_char="1999">conscientes</TOKEN>
<TOKEN id="token-27-31" pos="word" morph="none" start_char="2001" end_char="2002">de</TOKEN>
<TOKEN id="token-27-32" pos="word" morph="none" start_char="2004" end_char="2006">que</TOKEN>
<TOKEN id="token-27-33" pos="word" morph="none" start_char="2008" end_char="2011">este</TOKEN>
<TOKEN id="token-27-34" pos="word" morph="none" start_char="2013" end_char="2023">experimento</TOKEN>
<TOKEN id="token-27-35" pos="word" morph="none" start_char="2025" end_char="2026">se</TOKEN>
<TOKEN id="token-27-36" pos="word" morph="none" start_char="2028" end_char="2031">está</TOKEN>
<TOKEN id="token-27-37" pos="word" morph="none" start_char="2033" end_char="2042">utilizando</TOKEN>
<TOKEN id="token-27-38" pos="word" morph="none" start_char="2044" end_char="2047">como</TOKEN>
<TOKEN id="token-27-39" pos="word" morph="none" start_char="2049" end_char="2052">base</TOKEN>
<TOKEN id="token-27-40" pos="word" morph="none" start_char="2054" end_char="2057">para</TOKEN>
<TOKEN id="token-27-41" pos="word" morph="none" start_char="2059" end_char="2061">las</TOKEN>
<TOKEN id="token-27-42" pos="word" morph="none" start_char="2063" end_char="2069">teorías</TOKEN>
<TOKEN id="token-27-43" pos="word" morph="none" start_char="2071" end_char="2072">no</TOKEN>
<TOKEN id="token-27-44" pos="word" morph="none" start_char="2074" end_char="2084">verificadas</TOKEN>
<TOKEN id="token-27-45" pos="word" morph="none" start_char="2086" end_char="2087">de</TOKEN>
<TOKEN id="token-27-46" pos="word" morph="none" start_char="2089" end_char="2091">que</TOKEN>
<TOKEN id="token-27-47" pos="word" morph="none" start_char="2093" end_char="2094">el</TOKEN>
<TOKEN id="token-27-48" pos="word" morph="none" start_char="2096" end_char="2100">nuevo</TOKEN>
<TOKEN id="token-27-49" pos="word" morph="none" start_char="2102" end_char="2112">coronavirus</TOKEN>
<TOKEN id="token-27-50" pos="word" morph="none" start_char="2114" end_char="2116">que</TOKEN>
<TOKEN id="token-27-51" pos="word" morph="none" start_char="2118" end_char="2122">causa</TOKEN>
<TOKEN id="token-27-52" pos="unknown" morph="none" start_char="2124" end_char="2131">COVID-19</TOKEN>
<TOKEN id="token-27-53" pos="word" morph="none" start_char="2133" end_char="2135">fue</TOKEN>
<TOKEN id="token-27-54" pos="word" morph="none" start_char="2137" end_char="2144">diseñado</TOKEN>
<TOKEN id="token-27-55" pos="word" morph="none" start_char="2146" end_char="2147">en</TOKEN>
<TOKEN id="token-27-56" pos="word" morph="none" start_char="2149" end_char="2150">un</TOKEN>
<TOKEN id="token-27-57" pos="word" morph="none" start_char="2152" end_char="2162">laboratorio</TOKEN>
<TOKEN id="token-27-58" pos="punct" morph="none" start_char="2163" end_char="2164">".</TOKEN>
</SEG>
<SEG id="segment-28" start_char="2166" end_char="2224">
<ORIGINAL_TEXT>Y añade: "no hay ninguna evidencia de que esto sea cierto".</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="2166" end_char="2166">Y</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="2168" end_char="2172">añade</TOKEN>
<TOKEN id="token-28-2" pos="punct" morph="none" start_char="2173" end_char="2173">:</TOKEN>
<TOKEN id="token-28-3" pos="punct" morph="none" start_char="2175" end_char="2175">"</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="2176" end_char="2177">no</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="2179" end_char="2181">hay</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="2183" end_char="2189">ninguna</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="2191" end_char="2199">evidencia</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="2201" end_char="2202">de</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="2204" end_char="2206">que</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="2208" end_char="2211">esto</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="2213" end_char="2215">sea</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="2217" end_char="2222">cierto</TOKEN>
<TOKEN id="token-28-13" pos="punct" morph="none" start_char="2223" end_char="2224">".</TOKEN>
</SEG>
<SEG id="segment-29" start_char="2227" end_char="2308">
<ORIGINAL_TEXT>Nota del editor del artículo de Nature publicado el pasado 12 de noviembre de 2015</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="2227" end_char="2230">Nota</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="2232" end_char="2234">del</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="2236" end_char="2241">editor</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="2243" end_char="2245">del</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="2247" end_char="2254">artículo</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="2256" end_char="2257">de</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="2259" end_char="2264">Nature</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="2266" end_char="2274">publicado</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="2276" end_char="2277">el</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="2279" end_char="2284">pasado</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="2286" end_char="2287">12</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="2289" end_char="2290">de</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="2292" end_char="2300">noviembre</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="2302" end_char="2303">de</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="2305" end_char="2308">2015</TOKEN>
</SEG>
<SEG id="segment-30" start_char="2312" end_char="2348">
<ORIGINAL_TEXT>En ese sentido, el periódico italiano</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="2312" end_char="2313">En</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="2315" end_char="2317">ese</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="2319" end_char="2325">sentido</TOKEN>
<TOKEN id="token-30-3" pos="punct" morph="none" start_char="2326" end_char="2326">,</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="2328" end_char="2329">el</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="2331" end_char="2339">periódico</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="2341" end_char="2348">italiano</TOKEN>
</SEG>
<SEG id="segment-31" start_char="2351" end_char="2369">
<ORIGINAL_TEXT>Corriere Della Sera</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="2351" end_char="2358">Corriere</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="2360" end_char="2364">Della</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="2366" end_char="2369">Sera</TOKEN>
</SEG>
<SEG id="segment-32" start_char="2372" end_char="2469">
<ORIGINAL_TEXT>ha publicado que "el mismo director del canal Rai, Alessandro Casarin", ha explicado cómo programa</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="2372" end_char="2373">ha</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="2375" end_char="2383">publicado</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="2385" end_char="2387">que</TOKEN>
<TOKEN id="token-32-3" pos="punct" morph="none" start_char="2389" end_char="2389">"</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="2390" end_char="2391">el</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="2393" end_char="2397">mismo</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="2399" end_char="2406">director</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="2408" end_char="2410">del</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="2412" end_char="2416">canal</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="2418" end_char="2420">Rai</TOKEN>
<TOKEN id="token-32-10" pos="punct" morph="none" start_char="2421" end_char="2421">,</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="2423" end_char="2432">Alessandro</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="2434" end_char="2440">Casarin</TOKEN>
<TOKEN id="token-32-13" pos="punct" morph="none" start_char="2441" end_char="2442">",</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="2444" end_char="2445">ha</TOKEN>
<TOKEN id="token-32-15" pos="word" morph="none" start_char="2447" end_char="2455">explicado</TOKEN>
<TOKEN id="token-32-16" pos="word" morph="none" start_char="2457" end_char="2460">cómo</TOKEN>
<TOKEN id="token-32-17" pos="word" morph="none" start_char="2462" end_char="2469">programa</TOKEN>
</SEG>
<SEG id="segment-33" start_char="2472" end_char="2483">
<ORIGINAL_TEXT>TGR Leonardo</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="2472" end_char="2474">TGR</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="2476" end_char="2483">Leonardo</TOKEN>
</SEG>
<SEG id="segment-34" start_char="2486" end_char="2525">
<ORIGINAL_TEXT>se basó en una publicación de la revista</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="2486" end_char="2487">se</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="2489" end_char="2492">basó</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="2494" end_char="2495">en</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="2497" end_char="2499">una</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="2501" end_char="2511">publicación</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="2513" end_char="2514">de</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="2516" end_char="2517">la</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="2519" end_char="2525">revista</TOKEN>
</SEG>
<SEG id="segment-35" start_char="2528" end_char="2533">
<ORIGINAL_TEXT>Nature</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="2528" end_char="2533">Nature</TOKEN>
</SEG>
<SEG id="segment-36" start_char="2536" end_char="2699">
<ORIGINAL_TEXT>pero que la misma revista ha aclarado que "el virus mencionado en el programa, creado en el laboratorio, no tiene relación con el virus actual que causa Covid-19 ".</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="2536" end_char="2539">pero</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="2541" end_char="2543">que</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="2545" end_char="2546">la</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="2548" end_char="2552">misma</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="2554" end_char="2560">revista</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="2562" end_char="2563">ha</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="2565" end_char="2572">aclarado</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="2574" end_char="2576">que</TOKEN>
<TOKEN id="token-36-8" pos="punct" morph="none" start_char="2578" end_char="2578">"</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="2579" end_char="2580">el</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="2582" end_char="2586">virus</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="2588" end_char="2597">mencionado</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="2599" end_char="2600">en</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="2602" end_char="2603">el</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="2605" end_char="2612">programa</TOKEN>
<TOKEN id="token-36-15" pos="punct" morph="none" start_char="2613" end_char="2613">,</TOKEN>
<TOKEN id="token-36-16" pos="word" morph="none" start_char="2615" end_char="2620">creado</TOKEN>
<TOKEN id="token-36-17" pos="word" morph="none" start_char="2622" end_char="2623">en</TOKEN>
<TOKEN id="token-36-18" pos="word" morph="none" start_char="2625" end_char="2626">el</TOKEN>
<TOKEN id="token-36-19" pos="word" morph="none" start_char="2628" end_char="2638">laboratorio</TOKEN>
<TOKEN id="token-36-20" pos="punct" morph="none" start_char="2639" end_char="2639">,</TOKEN>
<TOKEN id="token-36-21" pos="word" morph="none" start_char="2641" end_char="2642">no</TOKEN>
<TOKEN id="token-36-22" pos="word" morph="none" start_char="2644" end_char="2648">tiene</TOKEN>
<TOKEN id="token-36-23" pos="word" morph="none" start_char="2650" end_char="2657">relación</TOKEN>
<TOKEN id="token-36-24" pos="word" morph="none" start_char="2659" end_char="2661">con</TOKEN>
<TOKEN id="token-36-25" pos="word" morph="none" start_char="2663" end_char="2664">el</TOKEN>
<TOKEN id="token-36-26" pos="word" morph="none" start_char="2666" end_char="2670">virus</TOKEN>
<TOKEN id="token-36-27" pos="word" morph="none" start_char="2672" end_char="2677">actual</TOKEN>
<TOKEN id="token-36-28" pos="word" morph="none" start_char="2679" end_char="2681">que</TOKEN>
<TOKEN id="token-36-29" pos="word" morph="none" start_char="2683" end_char="2687">causa</TOKEN>
<TOKEN id="token-36-30" pos="unknown" morph="none" start_char="2689" end_char="2696">Covid-19</TOKEN>
<TOKEN id="token-36-31" pos="punct" morph="none" start_char="2698" end_char="2699">".</TOKEN>
</SEG>
<SEG id="segment-37" start_char="2702" end_char="2786">
<ORIGINAL_TEXT>Científicos publican un comunicado contra los rumores sobre el origen del coronavirus</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="2702" end_char="2712">Científicos</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="2714" end_char="2721">publican</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="2723" end_char="2724">un</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="2726" end_char="2735">comunicado</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="2737" end_char="2742">contra</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="2744" end_char="2746">los</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="2748" end_char="2754">rumores</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="2756" end_char="2760">sobre</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="2762" end_char="2763">el</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="2765" end_char="2770">origen</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="2772" end_char="2774">del</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="2776" end_char="2786">coronavirus</TOKEN>
</SEG>
<SEG id="segment-38" start_char="2790" end_char="2791">
<ORIGINAL_TEXT>En</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="2790" end_char="2791">En</TOKEN>
</SEG>
<SEG id="segment-39" start_char="2794" end_char="2803">
<ORIGINAL_TEXT>Maldita.es</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="unknown" morph="none" start_char="2794" end_char="2803">Maldita.es</TOKEN>
</SEG>
<SEG id="segment-40" start_char="2806" end_char="3077">
<ORIGINAL_TEXT>ya os hemos explicado que para desmentir estos rumores y teorías de conspiración sobre el origen del nuevo coronavirus, científicos especializados en salud pública que han seguido de cerca la crisis sanitaria del nuevo coronavirus han publicado un comunicado en la revista</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="2806" end_char="2807">ya</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="2809" end_char="2810">os</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="2812" end_char="2816">hemos</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="2818" end_char="2826">explicado</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="2828" end_char="2830">que</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="2832" end_char="2835">para</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="2837" end_char="2845">desmentir</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="2847" end_char="2851">estos</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="2853" end_char="2859">rumores</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="2861" end_char="2861">y</TOKEN>
<TOKEN id="token-40-10" pos="word" morph="none" start_char="2863" end_char="2869">teorías</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="2871" end_char="2872">de</TOKEN>
<TOKEN id="token-40-12" pos="word" morph="none" start_char="2874" end_char="2885">conspiración</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="2887" end_char="2891">sobre</TOKEN>
<TOKEN id="token-40-14" pos="word" morph="none" start_char="2893" end_char="2894">el</TOKEN>
<TOKEN id="token-40-15" pos="word" morph="none" start_char="2896" end_char="2901">origen</TOKEN>
<TOKEN id="token-40-16" pos="word" morph="none" start_char="2903" end_char="2905">del</TOKEN>
<TOKEN id="token-40-17" pos="word" morph="none" start_char="2907" end_char="2911">nuevo</TOKEN>
<TOKEN id="token-40-18" pos="word" morph="none" start_char="2913" end_char="2923">coronavirus</TOKEN>
<TOKEN id="token-40-19" pos="punct" morph="none" start_char="2924" end_char="2924">,</TOKEN>
<TOKEN id="token-40-20" pos="word" morph="none" start_char="2926" end_char="2936">científicos</TOKEN>
<TOKEN id="token-40-21" pos="word" morph="none" start_char="2938" end_char="2951">especializados</TOKEN>
<TOKEN id="token-40-22" pos="word" morph="none" start_char="2953" end_char="2954">en</TOKEN>
<TOKEN id="token-40-23" pos="word" morph="none" start_char="2956" end_char="2960">salud</TOKEN>
<TOKEN id="token-40-24" pos="word" morph="none" start_char="2962" end_char="2968">pública</TOKEN>
<TOKEN id="token-40-25" pos="word" morph="none" start_char="2970" end_char="2972">que</TOKEN>
<TOKEN id="token-40-26" pos="word" morph="none" start_char="2974" end_char="2976">han</TOKEN>
<TOKEN id="token-40-27" pos="word" morph="none" start_char="2978" end_char="2984">seguido</TOKEN>
<TOKEN id="token-40-28" pos="word" morph="none" start_char="2986" end_char="2987">de</TOKEN>
<TOKEN id="token-40-29" pos="word" morph="none" start_char="2989" end_char="2993">cerca</TOKEN>
<TOKEN id="token-40-30" pos="word" morph="none" start_char="2995" end_char="2996">la</TOKEN>
<TOKEN id="token-40-31" pos="word" morph="none" start_char="2998" end_char="3003">crisis</TOKEN>
<TOKEN id="token-40-32" pos="word" morph="none" start_char="3005" end_char="3013">sanitaria</TOKEN>
<TOKEN id="token-40-33" pos="word" morph="none" start_char="3015" end_char="3017">del</TOKEN>
<TOKEN id="token-40-34" pos="word" morph="none" start_char="3019" end_char="3023">nuevo</TOKEN>
<TOKEN id="token-40-35" pos="word" morph="none" start_char="3025" end_char="3035">coronavirus</TOKEN>
<TOKEN id="token-40-36" pos="word" morph="none" start_char="3037" end_char="3039">han</TOKEN>
<TOKEN id="token-40-37" pos="word" morph="none" start_char="3041" end_char="3049">publicado</TOKEN>
<TOKEN id="token-40-38" pos="word" morph="none" start_char="3051" end_char="3052">un</TOKEN>
<TOKEN id="token-40-39" pos="word" morph="none" start_char="3054" end_char="3063">comunicado</TOKEN>
<TOKEN id="token-40-40" pos="word" morph="none" start_char="3065" end_char="3066">en</TOKEN>
<TOKEN id="token-40-41" pos="word" morph="none" start_char="3068" end_char="3069">la</TOKEN>
<TOKEN id="token-40-42" pos="word" morph="none" start_char="3071" end_char="3077">revista</TOKEN>
</SEG>
<SEG id="segment-41" start_char="3080" end_char="3089">
<ORIGINAL_TEXT>The Lancet</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="3080" end_char="3082">The</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="3084" end_char="3089">Lancet</TOKEN>
</SEG>
<SEG id="segment-42" start_char="3092" end_char="3224">
<ORIGINAL_TEXT>en el que señalan que "científicos de múltiples países concluyen abrumadoramente que este coronavirus se originó en la vida salvaje".</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="3092" end_char="3093">en</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="3095" end_char="3096">el</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="3098" end_char="3100">que</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="3102" end_char="3108">señalan</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="3110" end_char="3112">que</TOKEN>
<TOKEN id="token-42-5" pos="punct" morph="none" start_char="3114" end_char="3114">"</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="3115" end_char="3125">científicos</TOKEN>
<TOKEN id="token-42-7" pos="word" morph="none" start_char="3127" end_char="3128">de</TOKEN>
<TOKEN id="token-42-8" pos="word" morph="none" start_char="3130" end_char="3138">múltiples</TOKEN>
<TOKEN id="token-42-9" pos="word" morph="none" start_char="3140" end_char="3145">países</TOKEN>
<TOKEN id="token-42-10" pos="word" morph="none" start_char="3147" end_char="3155">concluyen</TOKEN>
<TOKEN id="token-42-11" pos="word" morph="none" start_char="3157" end_char="3171">abrumadoramente</TOKEN>
<TOKEN id="token-42-12" pos="word" morph="none" start_char="3173" end_char="3175">que</TOKEN>
<TOKEN id="token-42-13" pos="word" morph="none" start_char="3177" end_char="3180">este</TOKEN>
<TOKEN id="token-42-14" pos="word" morph="none" start_char="3182" end_char="3192">coronavirus</TOKEN>
<TOKEN id="token-42-15" pos="word" morph="none" start_char="3194" end_char="3195">se</TOKEN>
<TOKEN id="token-42-16" pos="word" morph="none" start_char="3197" end_char="3203">originó</TOKEN>
<TOKEN id="token-42-17" pos="word" morph="none" start_char="3205" end_char="3206">en</TOKEN>
<TOKEN id="token-42-18" pos="word" morph="none" start_char="3208" end_char="3209">la</TOKEN>
<TOKEN id="token-42-19" pos="word" morph="none" start_char="3211" end_char="3214">vida</TOKEN>
<TOKEN id="token-42-20" pos="word" morph="none" start_char="3216" end_char="3222">salvaje</TOKEN>
<TOKEN id="token-42-21" pos="punct" morph="none" start_char="3223" end_char="3224">".</TOKEN>
</SEG>
<SEG id="segment-43" start_char="3227" end_char="3503">
<ORIGINAL_TEXT>El objetivo principal del texto es condenar y desmentir los rumores que mantienen que el origen de la epidemia no fue natural, sino una creación humana como herramienta para lograr fines de todo tipo (reducir la población envejecida, igualar el número de hombres y mujeres...).</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="3227" end_char="3228">El</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="3230" end_char="3237">objetivo</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="3239" end_char="3247">principal</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="3249" end_char="3251">del</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="3253" end_char="3257">texto</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="3259" end_char="3260">es</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="3262" end_char="3269">condenar</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="3271" end_char="3271">y</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="3273" end_char="3281">desmentir</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="3283" end_char="3285">los</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="3287" end_char="3293">rumores</TOKEN>
<TOKEN id="token-43-11" pos="word" morph="none" start_char="3295" end_char="3297">que</TOKEN>
<TOKEN id="token-43-12" pos="word" morph="none" start_char="3299" end_char="3307">mantienen</TOKEN>
<TOKEN id="token-43-13" pos="word" morph="none" start_char="3309" end_char="3311">que</TOKEN>
<TOKEN id="token-43-14" pos="word" morph="none" start_char="3313" end_char="3314">el</TOKEN>
<TOKEN id="token-43-15" pos="word" morph="none" start_char="3316" end_char="3321">origen</TOKEN>
<TOKEN id="token-43-16" pos="word" morph="none" start_char="3323" end_char="3324">de</TOKEN>
<TOKEN id="token-43-17" pos="word" morph="none" start_char="3326" end_char="3327">la</TOKEN>
<TOKEN id="token-43-18" pos="word" morph="none" start_char="3329" end_char="3336">epidemia</TOKEN>
<TOKEN id="token-43-19" pos="word" morph="none" start_char="3338" end_char="3339">no</TOKEN>
<TOKEN id="token-43-20" pos="word" morph="none" start_char="3341" end_char="3343">fue</TOKEN>
<TOKEN id="token-43-21" pos="word" morph="none" start_char="3345" end_char="3351">natural</TOKEN>
<TOKEN id="token-43-22" pos="punct" morph="none" start_char="3352" end_char="3352">,</TOKEN>
<TOKEN id="token-43-23" pos="word" morph="none" start_char="3354" end_char="3357">sino</TOKEN>
<TOKEN id="token-43-24" pos="word" morph="none" start_char="3359" end_char="3361">una</TOKEN>
<TOKEN id="token-43-25" pos="word" morph="none" start_char="3363" end_char="3370">creación</TOKEN>
<TOKEN id="token-43-26" pos="word" morph="none" start_char="3372" end_char="3377">humana</TOKEN>
<TOKEN id="token-43-27" pos="word" morph="none" start_char="3379" end_char="3382">como</TOKEN>
<TOKEN id="token-43-28" pos="word" morph="none" start_char="3384" end_char="3394">herramienta</TOKEN>
<TOKEN id="token-43-29" pos="word" morph="none" start_char="3396" end_char="3399">para</TOKEN>
<TOKEN id="token-43-30" pos="word" morph="none" start_char="3401" end_char="3406">lograr</TOKEN>
<TOKEN id="token-43-31" pos="word" morph="none" start_char="3408" end_char="3412">fines</TOKEN>
<TOKEN id="token-43-32" pos="word" morph="none" start_char="3414" end_char="3415">de</TOKEN>
<TOKEN id="token-43-33" pos="word" morph="none" start_char="3417" end_char="3420">todo</TOKEN>
<TOKEN id="token-43-34" pos="word" morph="none" start_char="3422" end_char="3425">tipo</TOKEN>
<TOKEN id="token-43-35" pos="punct" morph="none" start_char="3427" end_char="3427">(</TOKEN>
<TOKEN id="token-43-36" pos="word" morph="none" start_char="3428" end_char="3434">reducir</TOKEN>
<TOKEN id="token-43-37" pos="word" morph="none" start_char="3436" end_char="3437">la</TOKEN>
<TOKEN id="token-43-38" pos="word" morph="none" start_char="3439" end_char="3447">población</TOKEN>
<TOKEN id="token-43-39" pos="word" morph="none" start_char="3449" end_char="3458">envejecida</TOKEN>
<TOKEN id="token-43-40" pos="punct" morph="none" start_char="3459" end_char="3459">,</TOKEN>
<TOKEN id="token-43-41" pos="word" morph="none" start_char="3461" end_char="3467">igualar</TOKEN>
<TOKEN id="token-43-42" pos="word" morph="none" start_char="3469" end_char="3470">el</TOKEN>
<TOKEN id="token-43-43" pos="word" morph="none" start_char="3472" end_char="3477">número</TOKEN>
<TOKEN id="token-43-44" pos="word" morph="none" start_char="3479" end_char="3480">de</TOKEN>
<TOKEN id="token-43-45" pos="word" morph="none" start_char="3482" end_char="3488">hombres</TOKEN>
<TOKEN id="token-43-46" pos="word" morph="none" start_char="3490" end_char="3490">y</TOKEN>
<TOKEN id="token-43-47" pos="word" morph="none" start_char="3492" end_char="3498">mujeres</TOKEN>
<TOKEN id="token-43-48" pos="punct" morph="none" start_char="3499" end_char="3503">...).</TOKEN>
</SEG>
<SEG id="segment-44" start_char="3506" end_char="3566">
<ORIGINAL_TEXT>Los autores de este artículo, publicado en el foro científico</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="3506" end_char="3508">Los</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="3510" end_char="3516">autores</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="3518" end_char="3519">de</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="3521" end_char="3524">este</TOKEN>
<TOKEN id="token-44-4" pos="word" morph="none" start_char="3526" end_char="3533">artículo</TOKEN>
<TOKEN id="token-44-5" pos="punct" morph="none" start_char="3534" end_char="3534">,</TOKEN>
<TOKEN id="token-44-6" pos="word" morph="none" start_char="3536" end_char="3544">publicado</TOKEN>
<TOKEN id="token-44-7" pos="word" morph="none" start_char="3546" end_char="3547">en</TOKEN>
<TOKEN id="token-44-8" pos="word" morph="none" start_char="3549" end_char="3550">el</TOKEN>
<TOKEN id="token-44-9" pos="word" morph="none" start_char="3552" end_char="3555">foro</TOKEN>
<TOKEN id="token-44-10" pos="word" morph="none" start_char="3557" end_char="3566">científico</TOKEN>
</SEG>
<SEG id="segment-45" start_char="3569" end_char="3577">
<ORIGINAL_TEXT>Virologic</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="3569" end_char="3577">Virologic</TOKEN>
</SEG>
<SEG id="segment-46" start_char="3580" end_char="3704">
<ORIGINAL_TEXT>, indican que "la evidencia genómica no apoya la posibilidad de que el nuevo coronavirus haya sido creado en un laboratorio".</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="punct" morph="none" start_char="3580" end_char="3580">,</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="3582" end_char="3588">indican</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="3590" end_char="3592">que</TOKEN>
<TOKEN id="token-46-3" pos="punct" morph="none" start_char="3594" end_char="3594">"</TOKEN>
<TOKEN id="token-46-4" pos="word" morph="none" start_char="3595" end_char="3596">la</TOKEN>
<TOKEN id="token-46-5" pos="word" morph="none" start_char="3598" end_char="3606">evidencia</TOKEN>
<TOKEN id="token-46-6" pos="word" morph="none" start_char="3608" end_char="3615">genómica</TOKEN>
<TOKEN id="token-46-7" pos="word" morph="none" start_char="3617" end_char="3618">no</TOKEN>
<TOKEN id="token-46-8" pos="word" morph="none" start_char="3620" end_char="3624">apoya</TOKEN>
<TOKEN id="token-46-9" pos="word" morph="none" start_char="3626" end_char="3627">la</TOKEN>
<TOKEN id="token-46-10" pos="word" morph="none" start_char="3629" end_char="3639">posibilidad</TOKEN>
<TOKEN id="token-46-11" pos="word" morph="none" start_char="3641" end_char="3642">de</TOKEN>
<TOKEN id="token-46-12" pos="word" morph="none" start_char="3644" end_char="3646">que</TOKEN>
<TOKEN id="token-46-13" pos="word" morph="none" start_char="3648" end_char="3649">el</TOKEN>
<TOKEN id="token-46-14" pos="word" morph="none" start_char="3651" end_char="3655">nuevo</TOKEN>
<TOKEN id="token-46-15" pos="word" morph="none" start_char="3657" end_char="3667">coronavirus</TOKEN>
<TOKEN id="token-46-16" pos="word" morph="none" start_char="3669" end_char="3672">haya</TOKEN>
<TOKEN id="token-46-17" pos="word" morph="none" start_char="3674" end_char="3677">sido</TOKEN>
<TOKEN id="token-46-18" pos="word" morph="none" start_char="3679" end_char="3684">creado</TOKEN>
<TOKEN id="token-46-19" pos="word" morph="none" start_char="3686" end_char="3687">en</TOKEN>
<TOKEN id="token-46-20" pos="word" morph="none" start_char="3689" end_char="3690">un</TOKEN>
<TOKEN id="token-46-21" pos="word" morph="none" start_char="3692" end_char="3702">laboratorio</TOKEN>
<TOKEN id="token-46-22" pos="punct" morph="none" start_char="3703" end_char="3704">".</TOKEN>
</SEG>
<SEG id="segment-47" start_char="3706" end_char="3893">
<ORIGINAL_TEXT>Este otro estudio indica que el origen del SARS-CoV-2 fueron mutaciones y selección natural, además de recombinación del SARS-CoV, el virus capaz de infectar a animales como el murciélago.</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="3706" end_char="3709">Este</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="3711" end_char="3714">otro</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="3716" end_char="3722">estudio</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="3724" end_char="3729">indica</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="3731" end_char="3733">que</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="3735" end_char="3736">el</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="3738" end_char="3743">origen</TOKEN>
<TOKEN id="token-47-7" pos="word" morph="none" start_char="3745" end_char="3747">del</TOKEN>
<TOKEN id="token-47-8" pos="unknown" morph="none" start_char="3749" end_char="3758">SARS-CoV-2</TOKEN>
<TOKEN id="token-47-9" pos="word" morph="none" start_char="3760" end_char="3765">fueron</TOKEN>
<TOKEN id="token-47-10" pos="word" morph="none" start_char="3767" end_char="3776">mutaciones</TOKEN>
<TOKEN id="token-47-11" pos="word" morph="none" start_char="3778" end_char="3778">y</TOKEN>
<TOKEN id="token-47-12" pos="word" morph="none" start_char="3780" end_char="3788">selección</TOKEN>
<TOKEN id="token-47-13" pos="word" morph="none" start_char="3790" end_char="3796">natural</TOKEN>
<TOKEN id="token-47-14" pos="punct" morph="none" start_char="3797" end_char="3797">,</TOKEN>
<TOKEN id="token-47-15" pos="word" morph="none" start_char="3799" end_char="3804">además</TOKEN>
<TOKEN id="token-47-16" pos="word" morph="none" start_char="3806" end_char="3807">de</TOKEN>
<TOKEN id="token-47-17" pos="word" morph="none" start_char="3809" end_char="3821">recombinación</TOKEN>
<TOKEN id="token-47-18" pos="word" morph="none" start_char="3823" end_char="3825">del</TOKEN>
<TOKEN id="token-47-19" pos="unknown" morph="none" start_char="3827" end_char="3834">SARS-CoV</TOKEN>
<TOKEN id="token-47-20" pos="punct" morph="none" start_char="3835" end_char="3835">,</TOKEN>
<TOKEN id="token-47-21" pos="word" morph="none" start_char="3837" end_char="3838">el</TOKEN>
<TOKEN id="token-47-22" pos="word" morph="none" start_char="3840" end_char="3844">virus</TOKEN>
<TOKEN id="token-47-23" pos="word" morph="none" start_char="3846" end_char="3850">capaz</TOKEN>
<TOKEN id="token-47-24" pos="word" morph="none" start_char="3852" end_char="3853">de</TOKEN>
<TOKEN id="token-47-25" pos="word" morph="none" start_char="3855" end_char="3862">infectar</TOKEN>
<TOKEN id="token-47-26" pos="word" morph="none" start_char="3864" end_char="3864">a</TOKEN>
<TOKEN id="token-47-27" pos="word" morph="none" start_char="3866" end_char="3873">animales</TOKEN>
<TOKEN id="token-47-28" pos="word" morph="none" start_char="3875" end_char="3878">como</TOKEN>
<TOKEN id="token-47-29" pos="word" morph="none" start_char="3880" end_char="3881">el</TOKEN>
<TOKEN id="token-47-30" pos="word" morph="none" start_char="3883" end_char="3892">murciélago</TOKEN>
<TOKEN id="token-47-31" pos="punct" morph="none" start_char="3893" end_char="3893">.</TOKEN>
</SEG>
<SEG id="segment-48" start_char="3896" end_char="3955">
<ORIGINAL_TEXT>Además, esta investigación publicada en la revista ientífica</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="3896" end_char="3901">Además</TOKEN>
<TOKEN id="token-48-1" pos="punct" morph="none" start_char="3902" end_char="3902">,</TOKEN>
<TOKEN id="token-48-2" pos="word" morph="none" start_char="3904" end_char="3907">esta</TOKEN>
<TOKEN id="token-48-3" pos="word" morph="none" start_char="3909" end_char="3921">investigación</TOKEN>
<TOKEN id="token-48-4" pos="word" morph="none" start_char="3923" end_char="3931">publicada</TOKEN>
<TOKEN id="token-48-5" pos="word" morph="none" start_char="3933" end_char="3934">en</TOKEN>
<TOKEN id="token-48-6" pos="word" morph="none" start_char="3936" end_char="3937">la</TOKEN>
<TOKEN id="token-48-7" pos="word" morph="none" start_char="3939" end_char="3945">revista</TOKEN>
<TOKEN id="token-48-8" pos="word" morph="none" start_char="3947" end_char="3955">ientífica</TOKEN>
</SEG>
<SEG id="segment-49" start_char="3958" end_char="3963">
<ORIGINAL_TEXT>Nature</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="3958" end_char="3963">Nature</TOKEN>
</SEG>
<SEG id="segment-50" start_char="3966" end_char="4084">
<ORIGINAL_TEXT>concluye que el genoma del nuevo coronavirus es un 96% idéntico al del coronavirus capaz de infectar a los murciélagos.</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="3966" end_char="3973">concluye</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="3975" end_char="3977">que</TOKEN>
<TOKEN id="token-50-2" pos="word" morph="none" start_char="3979" end_char="3980">el</TOKEN>
<TOKEN id="token-50-3" pos="word" morph="none" start_char="3982" end_char="3987">genoma</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="3989" end_char="3991">del</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="3993" end_char="3997">nuevo</TOKEN>
<TOKEN id="token-50-6" pos="word" morph="none" start_char="3999" end_char="4009">coronavirus</TOKEN>
<TOKEN id="token-50-7" pos="word" morph="none" start_char="4011" end_char="4012">es</TOKEN>
<TOKEN id="token-50-8" pos="word" morph="none" start_char="4014" end_char="4015">un</TOKEN>
<TOKEN id="token-50-9" pos="word" morph="none" start_char="4017" end_char="4018">96</TOKEN>
<TOKEN id="token-50-10" pos="punct" morph="none" start_char="4019" end_char="4019">%</TOKEN>
<TOKEN id="token-50-11" pos="word" morph="none" start_char="4021" end_char="4028">idéntico</TOKEN>
<TOKEN id="token-50-12" pos="word" morph="none" start_char="4030" end_char="4031">al</TOKEN>
<TOKEN id="token-50-13" pos="word" morph="none" start_char="4033" end_char="4035">del</TOKEN>
<TOKEN id="token-50-14" pos="word" morph="none" start_char="4037" end_char="4047">coronavirus</TOKEN>
<TOKEN id="token-50-15" pos="word" morph="none" start_char="4049" end_char="4053">capaz</TOKEN>
<TOKEN id="token-50-16" pos="word" morph="none" start_char="4055" end_char="4056">de</TOKEN>
<TOKEN id="token-50-17" pos="word" morph="none" start_char="4058" end_char="4065">infectar</TOKEN>
<TOKEN id="token-50-18" pos="word" morph="none" start_char="4067" end_char="4067">a</TOKEN>
<TOKEN id="token-50-19" pos="word" morph="none" start_char="4069" end_char="4071">los</TOKEN>
<TOKEN id="token-50-20" pos="word" morph="none" start_char="4073" end_char="4083">murciélagos</TOKEN>
<TOKEN id="token-50-21" pos="punct" morph="none" start_char="4084" end_char="4084">.</TOKEN>
</SEG>
<SEG id="segment-51" start_char="4087" end_char="4129">
<ORIGINAL_TEXT>En la misma línea, un artículo publicado en</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="word" morph="none" start_char="4087" end_char="4088">En</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="4090" end_char="4091">la</TOKEN>
<TOKEN id="token-51-2" pos="word" morph="none" start_char="4093" end_char="4097">misma</TOKEN>
<TOKEN id="token-51-3" pos="word" morph="none" start_char="4099" end_char="4103">línea</TOKEN>
<TOKEN id="token-51-4" pos="punct" morph="none" start_char="4104" end_char="4104">,</TOKEN>
<TOKEN id="token-51-5" pos="word" morph="none" start_char="4106" end_char="4107">un</TOKEN>
<TOKEN id="token-51-6" pos="word" morph="none" start_char="4109" end_char="4116">artículo</TOKEN>
<TOKEN id="token-51-7" pos="word" morph="none" start_char="4118" end_char="4126">publicado</TOKEN>
<TOKEN id="token-51-8" pos="word" morph="none" start_char="4128" end_char="4129">en</TOKEN>
</SEG>
<SEG id="segment-52" start_char="4132" end_char="4146">
<ORIGINAL_TEXT>Nature Medicine</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="4132" end_char="4137">Nature</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="4139" end_char="4146">Medicine</TOKEN>
</SEG>
<SEG id="segment-53" start_char="4149" end_char="4249">
<ORIGINAL_TEXT>concluía que el SARS-CoV-2 "no es una construcción de laboratorio o un virus manipulado a propósito".</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="word" morph="none" start_char="4149" end_char="4156">concluía</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="4158" end_char="4160">que</TOKEN>
<TOKEN id="token-53-2" pos="word" morph="none" start_char="4162" end_char="4163">el</TOKEN>
<TOKEN id="token-53-3" pos="unknown" morph="none" start_char="4165" end_char="4174">SARS-CoV-2</TOKEN>
<TOKEN id="token-53-4" pos="punct" morph="none" start_char="4176" end_char="4176">"</TOKEN>
<TOKEN id="token-53-5" pos="word" morph="none" start_char="4177" end_char="4178">no</TOKEN>
<TOKEN id="token-53-6" pos="word" morph="none" start_char="4180" end_char="4181">es</TOKEN>
<TOKEN id="token-53-7" pos="word" morph="none" start_char="4183" end_char="4185">una</TOKEN>
<TOKEN id="token-53-8" pos="word" morph="none" start_char="4187" end_char="4198">construcción</TOKEN>
<TOKEN id="token-53-9" pos="word" morph="none" start_char="4200" end_char="4201">de</TOKEN>
<TOKEN id="token-53-10" pos="word" morph="none" start_char="4203" end_char="4213">laboratorio</TOKEN>
<TOKEN id="token-53-11" pos="word" morph="none" start_char="4215" end_char="4215">o</TOKEN>
<TOKEN id="token-53-12" pos="word" morph="none" start_char="4217" end_char="4218">un</TOKEN>
<TOKEN id="token-53-13" pos="word" morph="none" start_char="4220" end_char="4224">virus</TOKEN>
<TOKEN id="token-53-14" pos="word" morph="none" start_char="4226" end_char="4235">manipulado</TOKEN>
<TOKEN id="token-53-15" pos="word" morph="none" start_char="4237" end_char="4237">a</TOKEN>
<TOKEN id="token-53-16" pos="word" morph="none" start_char="4239" end_char="4247">propósito</TOKEN>
<TOKEN id="token-53-17" pos="punct" morph="none" start_char="4248" end_char="4249">".</TOKEN>
</SEG>
<SEG id="segment-54" start_char="4251" end_char="4251">
<ORIGINAL_TEXT>*</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="punct" morph="none" start_char="4251" end_char="4251">*</TOKEN>
</SEG>
<SEG id="segment-55" start_char="4254" end_char="4644">
<ORIGINAL_TEXT>"Hemos visto cómo profesionales de salud pública y médicos, en China, en particular, han trabajado diligentemente y de forma eficiente para identificar rápidamente el patógeno detrás de este brote, poner en marcha medidas significativas para reducir su impacto, y compartir sus resultados con la comunidad sanitaria a nivel mundial", afirman los autores al inicio del comunicado publicado en</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="punct" morph="none" start_char="4254" end_char="4254">"</TOKEN>
<TOKEN id="token-55-1" pos="word" morph="none" start_char="4255" end_char="4259">Hemos</TOKEN>
<TOKEN id="token-55-2" pos="word" morph="none" start_char="4261" end_char="4265">visto</TOKEN>
<TOKEN id="token-55-3" pos="word" morph="none" start_char="4267" end_char="4270">cómo</TOKEN>
<TOKEN id="token-55-4" pos="word" morph="none" start_char="4272" end_char="4284">profesionales</TOKEN>
<TOKEN id="token-55-5" pos="word" morph="none" start_char="4286" end_char="4287">de</TOKEN>
<TOKEN id="token-55-6" pos="word" morph="none" start_char="4289" end_char="4293">salud</TOKEN>
<TOKEN id="token-55-7" pos="word" morph="none" start_char="4295" end_char="4301">pública</TOKEN>
<TOKEN id="token-55-8" pos="word" morph="none" start_char="4303" end_char="4303">y</TOKEN>
<TOKEN id="token-55-9" pos="word" morph="none" start_char="4305" end_char="4311">médicos</TOKEN>
<TOKEN id="token-55-10" pos="punct" morph="none" start_char="4312" end_char="4312">,</TOKEN>
<TOKEN id="token-55-11" pos="word" morph="none" start_char="4314" end_char="4315">en</TOKEN>
<TOKEN id="token-55-12" pos="word" morph="none" start_char="4317" end_char="4321">China</TOKEN>
<TOKEN id="token-55-13" pos="punct" morph="none" start_char="4322" end_char="4322">,</TOKEN>
<TOKEN id="token-55-14" pos="word" morph="none" start_char="4324" end_char="4325">en</TOKEN>
<TOKEN id="token-55-15" pos="word" morph="none" start_char="4327" end_char="4336">particular</TOKEN>
<TOKEN id="token-55-16" pos="punct" morph="none" start_char="4337" end_char="4337">,</TOKEN>
<TOKEN id="token-55-17" pos="word" morph="none" start_char="4339" end_char="4341">han</TOKEN>
<TOKEN id="token-55-18" pos="word" morph="none" start_char="4343" end_char="4351">trabajado</TOKEN>
<TOKEN id="token-55-19" pos="word" morph="none" start_char="4353" end_char="4366">diligentemente</TOKEN>
<TOKEN id="token-55-20" pos="word" morph="none" start_char="4368" end_char="4368">y</TOKEN>
<TOKEN id="token-55-21" pos="word" morph="none" start_char="4370" end_char="4371">de</TOKEN>
<TOKEN id="token-55-22" pos="word" morph="none" start_char="4373" end_char="4377">forma</TOKEN>
<TOKEN id="token-55-23" pos="word" morph="none" start_char="4379" end_char="4387">eficiente</TOKEN>
<TOKEN id="token-55-24" pos="word" morph="none" start_char="4389" end_char="4392">para</TOKEN>
<TOKEN id="token-55-25" pos="word" morph="none" start_char="4394" end_char="4404">identificar</TOKEN>
<TOKEN id="token-55-26" pos="word" morph="none" start_char="4406" end_char="4416">rápidamente</TOKEN>
<TOKEN id="token-55-27" pos="word" morph="none" start_char="4418" end_char="4419">el</TOKEN>
<TOKEN id="token-55-28" pos="word" morph="none" start_char="4421" end_char="4428">patógeno</TOKEN>
<TOKEN id="token-55-29" pos="word" morph="none" start_char="4430" end_char="4435">detrás</TOKEN>
<TOKEN id="token-55-30" pos="word" morph="none" start_char="4437" end_char="4438">de</TOKEN>
<TOKEN id="token-55-31" pos="word" morph="none" start_char="4440" end_char="4443">este</TOKEN>
<TOKEN id="token-55-32" pos="word" morph="none" start_char="4445" end_char="4449">brote</TOKEN>
<TOKEN id="token-55-33" pos="punct" morph="none" start_char="4450" end_char="4450">,</TOKEN>
<TOKEN id="token-55-34" pos="word" morph="none" start_char="4452" end_char="4456">poner</TOKEN>
<TOKEN id="token-55-35" pos="word" morph="none" start_char="4458" end_char="4459">en</TOKEN>
<TOKEN id="token-55-36" pos="word" morph="none" start_char="4461" end_char="4466">marcha</TOKEN>
<TOKEN id="token-55-37" pos="word" morph="none" start_char="4468" end_char="4474">medidas</TOKEN>
<TOKEN id="token-55-38" pos="word" morph="none" start_char="4476" end_char="4489">significativas</TOKEN>
<TOKEN id="token-55-39" pos="word" morph="none" start_char="4491" end_char="4494">para</TOKEN>
<TOKEN id="token-55-40" pos="word" morph="none" start_char="4496" end_char="4502">reducir</TOKEN>
<TOKEN id="token-55-41" pos="word" morph="none" start_char="4504" end_char="4505">su</TOKEN>
<TOKEN id="token-55-42" pos="word" morph="none" start_char="4507" end_char="4513">impacto</TOKEN>
<TOKEN id="token-55-43" pos="punct" morph="none" start_char="4514" end_char="4514">,</TOKEN>
<TOKEN id="token-55-44" pos="word" morph="none" start_char="4516" end_char="4516">y</TOKEN>
<TOKEN id="token-55-45" pos="word" morph="none" start_char="4518" end_char="4526">compartir</TOKEN>
<TOKEN id="token-55-46" pos="word" morph="none" start_char="4528" end_char="4530">sus</TOKEN>
<TOKEN id="token-55-47" pos="word" morph="none" start_char="4532" end_char="4541">resultados</TOKEN>
<TOKEN id="token-55-48" pos="word" morph="none" start_char="4543" end_char="4545">con</TOKEN>
<TOKEN id="token-55-49" pos="word" morph="none" start_char="4547" end_char="4548">la</TOKEN>
<TOKEN id="token-55-50" pos="word" morph="none" start_char="4550" end_char="4558">comunidad</TOKEN>
<TOKEN id="token-55-51" pos="word" morph="none" start_char="4560" end_char="4568">sanitaria</TOKEN>
<TOKEN id="token-55-52" pos="word" morph="none" start_char="4570" end_char="4570">a</TOKEN>
<TOKEN id="token-55-53" pos="word" morph="none" start_char="4572" end_char="4576">nivel</TOKEN>
<TOKEN id="token-55-54" pos="word" morph="none" start_char="4578" end_char="4584">mundial</TOKEN>
<TOKEN id="token-55-55" pos="punct" morph="none" start_char="4585" end_char="4586">",</TOKEN>
<TOKEN id="token-55-56" pos="word" morph="none" start_char="4588" end_char="4594">afirman</TOKEN>
<TOKEN id="token-55-57" pos="word" morph="none" start_char="4596" end_char="4598">los</TOKEN>
<TOKEN id="token-55-58" pos="word" morph="none" start_char="4600" end_char="4606">autores</TOKEN>
<TOKEN id="token-55-59" pos="word" morph="none" start_char="4608" end_char="4609">al</TOKEN>
<TOKEN id="token-55-60" pos="word" morph="none" start_char="4611" end_char="4616">inicio</TOKEN>
<TOKEN id="token-55-61" pos="word" morph="none" start_char="4618" end_char="4620">del</TOKEN>
<TOKEN id="token-55-62" pos="word" morph="none" start_char="4622" end_char="4631">comunicado</TOKEN>
<TOKEN id="token-55-63" pos="word" morph="none" start_char="4633" end_char="4641">publicado</TOKEN>
<TOKEN id="token-55-64" pos="word" morph="none" start_char="4643" end_char="4644">en</TOKEN>
</SEG>
<SEG id="segment-56" start_char="4647" end_char="4656">
<ORIGINAL_TEXT>The Lancet</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="4647" end_char="4649">The</TOKEN>
<TOKEN id="token-56-1" pos="word" morph="none" start_char="4651" end_char="4656">Lancet</TOKEN>
</SEG>
<SEG id="segment-57" start_char="4659" end_char="4659">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN id="token-57-0" pos="punct" morph="none" start_char="4659" end_char="4659">.</TOKEN>
</SEG>
<SEG id="segment-58" start_char="4662" end_char="4953">
<ORIGINAL_TEXT>Por lo tanto, no es cierto que el coronavirus haya sido creado en un laboratorio de China a partir de murciélagos y ratones y que podría afectar a seres humanos ya que no hay ninguna evidencia científica y la comunidad científica afirma que el origen del SARS-CoV-2 está "en la vida salvaje".</ORIGINAL_TEXT>
<TOKEN id="token-58-0" pos="word" morph="none" start_char="4662" end_char="4664">Por</TOKEN>
<TOKEN id="token-58-1" pos="word" morph="none" start_char="4666" end_char="4667">lo</TOKEN>
<TOKEN id="token-58-2" pos="word" morph="none" start_char="4669" end_char="4673">tanto</TOKEN>
<TOKEN id="token-58-3" pos="punct" morph="none" start_char="4674" end_char="4674">,</TOKEN>
<TOKEN id="token-58-4" pos="word" morph="none" start_char="4676" end_char="4677">no</TOKEN>
<TOKEN id="token-58-5" pos="word" morph="none" start_char="4679" end_char="4680">es</TOKEN>
<TOKEN id="token-58-6" pos="word" morph="none" start_char="4682" end_char="4687">cierto</TOKEN>
<TOKEN id="token-58-7" pos="word" morph="none" start_char="4689" end_char="4691">que</TOKEN>
<TOKEN id="token-58-8" pos="word" morph="none" start_char="4693" end_char="4694">el</TOKEN>
<TOKEN id="token-58-9" pos="word" morph="none" start_char="4696" end_char="4706">coronavirus</TOKEN>
<TOKEN id="token-58-10" pos="word" morph="none" start_char="4708" end_char="4711">haya</TOKEN>
<TOKEN id="token-58-11" pos="word" morph="none" start_char="4713" end_char="4716">sido</TOKEN>
<TOKEN id="token-58-12" pos="word" morph="none" start_char="4718" end_char="4723">creado</TOKEN>
<TOKEN id="token-58-13" pos="word" morph="none" start_char="4725" end_char="4726">en</TOKEN>
<TOKEN id="token-58-14" pos="word" morph="none" start_char="4728" end_char="4729">un</TOKEN>
<TOKEN id="token-58-15" pos="word" morph="none" start_char="4731" end_char="4741">laboratorio</TOKEN>
<TOKEN id="token-58-16" pos="word" morph="none" start_char="4743" end_char="4744">de</TOKEN>
<TOKEN id="token-58-17" pos="word" morph="none" start_char="4746" end_char="4750">China</TOKEN>
<TOKEN id="token-58-18" pos="word" morph="none" start_char="4752" end_char="4752">a</TOKEN>
<TOKEN id="token-58-19" pos="word" morph="none" start_char="4754" end_char="4759">partir</TOKEN>
<TOKEN id="token-58-20" pos="word" morph="none" start_char="4761" end_char="4762">de</TOKEN>
<TOKEN id="token-58-21" pos="word" morph="none" start_char="4764" end_char="4774">murciélagos</TOKEN>
<TOKEN id="token-58-22" pos="word" morph="none" start_char="4776" end_char="4776">y</TOKEN>
<TOKEN id="token-58-23" pos="word" morph="none" start_char="4778" end_char="4784">ratones</TOKEN>
<TOKEN id="token-58-24" pos="word" morph="none" start_char="4786" end_char="4786">y</TOKEN>
<TOKEN id="token-58-25" pos="word" morph="none" start_char="4788" end_char="4790">que</TOKEN>
<TOKEN id="token-58-26" pos="word" morph="none" start_char="4792" end_char="4797">podría</TOKEN>
<TOKEN id="token-58-27" pos="word" morph="none" start_char="4799" end_char="4805">afectar</TOKEN>
<TOKEN id="token-58-28" pos="word" morph="none" start_char="4807" end_char="4807">a</TOKEN>
<TOKEN id="token-58-29" pos="word" morph="none" start_char="4809" end_char="4813">seres</TOKEN>
<TOKEN id="token-58-30" pos="word" morph="none" start_char="4815" end_char="4821">humanos</TOKEN>
<TOKEN id="token-58-31" pos="word" morph="none" start_char="4823" end_char="4824">ya</TOKEN>
<TOKEN id="token-58-32" pos="word" morph="none" start_char="4826" end_char="4828">que</TOKEN>
<TOKEN id="token-58-33" pos="word" morph="none" start_char="4830" end_char="4831">no</TOKEN>
<TOKEN id="token-58-34" pos="word" morph="none" start_char="4833" end_char="4835">hay</TOKEN>
<TOKEN id="token-58-35" pos="word" morph="none" start_char="4837" end_char="4843">ninguna</TOKEN>
<TOKEN id="token-58-36" pos="word" morph="none" start_char="4845" end_char="4853">evidencia</TOKEN>
<TOKEN id="token-58-37" pos="word" morph="none" start_char="4855" end_char="4864">científica</TOKEN>
<TOKEN id="token-58-38" pos="word" morph="none" start_char="4866" end_char="4866">y</TOKEN>
<TOKEN id="token-58-39" pos="word" morph="none" start_char="4868" end_char="4869">la</TOKEN>
<TOKEN id="token-58-40" pos="word" morph="none" start_char="4871" end_char="4879">comunidad</TOKEN>
<TOKEN id="token-58-41" pos="word" morph="none" start_char="4881" end_char="4890">científica</TOKEN>
<TOKEN id="token-58-42" pos="word" morph="none" start_char="4892" end_char="4897">afirma</TOKEN>
<TOKEN id="token-58-43" pos="word" morph="none" start_char="4899" end_char="4901">que</TOKEN>
<TOKEN id="token-58-44" pos="word" morph="none" start_char="4903" end_char="4904">el</TOKEN>
<TOKEN id="token-58-45" pos="word" morph="none" start_char="4906" end_char="4911">origen</TOKEN>
<TOKEN id="token-58-46" pos="word" morph="none" start_char="4913" end_char="4915">del</TOKEN>
<TOKEN id="token-58-47" pos="unknown" morph="none" start_char="4917" end_char="4926">SARS-CoV-2</TOKEN>
<TOKEN id="token-58-48" pos="word" morph="none" start_char="4928" end_char="4931">está</TOKEN>
<TOKEN id="token-58-49" pos="punct" morph="none" start_char="4933" end_char="4933">"</TOKEN>
<TOKEN id="token-58-50" pos="word" morph="none" start_char="4934" end_char="4935">en</TOKEN>
<TOKEN id="token-58-51" pos="word" morph="none" start_char="4937" end_char="4938">la</TOKEN>
<TOKEN id="token-58-52" pos="word" morph="none" start_char="4940" end_char="4943">vida</TOKEN>
<TOKEN id="token-58-53" pos="word" morph="none" start_char="4945" end_char="4951">salvaje</TOKEN>
<TOKEN id="token-58-54" pos="punct" morph="none" start_char="4952" end_char="4953">".</TOKEN>
</SEG>
<SEG id="segment-59" start_char="4956" end_char="5059">
<ORIGINAL_TEXT>(*) Esta pieza se ha actualizado el 2/04/2020 para añadir que este mismo vídeo circula con la captura de</ORIGINAL_TEXT>
<TOKEN id="token-59-0" pos="punct" morph="none" start_char="4956" end_char="4958">(*)</TOKEN>
<TOKEN id="token-59-1" pos="word" morph="none" start_char="4960" end_char="4963">Esta</TOKEN>
<TOKEN id="token-59-2" pos="word" morph="none" start_char="4965" end_char="4969">pieza</TOKEN>
<TOKEN id="token-59-3" pos="word" morph="none" start_char="4971" end_char="4972">se</TOKEN>
<TOKEN id="token-59-4" pos="word" morph="none" start_char="4974" end_char="4975">ha</TOKEN>
<TOKEN id="token-59-5" pos="word" morph="none" start_char="4977" end_char="4987">actualizado</TOKEN>
<TOKEN id="token-59-6" pos="word" morph="none" start_char="4989" end_char="4990">el</TOKEN>
<TOKEN id="token-59-7" pos="unknown" morph="none" start_char="4992" end_char="5000">2/04/2020</TOKEN>
<TOKEN id="token-59-8" pos="word" morph="none" start_char="5002" end_char="5005">para</TOKEN>
<TOKEN id="token-59-9" pos="word" morph="none" start_char="5007" end_char="5012">añadir</TOKEN>
<TOKEN id="token-59-10" pos="word" morph="none" start_char="5014" end_char="5016">que</TOKEN>
<TOKEN id="token-59-11" pos="word" morph="none" start_char="5018" end_char="5021">este</TOKEN>
<TOKEN id="token-59-12" pos="word" morph="none" start_char="5023" end_char="5027">mismo</TOKEN>
<TOKEN id="token-59-13" pos="word" morph="none" start_char="5029" end_char="5033">vídeo</TOKEN>
<TOKEN id="token-59-14" pos="word" morph="none" start_char="5035" end_char="5041">circula</TOKEN>
<TOKEN id="token-59-15" pos="word" morph="none" start_char="5043" end_char="5045">con</TOKEN>
<TOKEN id="token-59-16" pos="word" morph="none" start_char="5047" end_char="5048">la</TOKEN>
<TOKEN id="token-59-17" pos="word" morph="none" start_char="5050" end_char="5056">captura</TOKEN>
<TOKEN id="token-59-18" pos="word" morph="none" start_char="5058" end_char="5059">de</TOKEN>
</SEG>
<SEG id="segment-60" start_char="5062" end_char="5068">
<ORIGINAL_TEXT>Toro Tv</ORIGINAL_TEXT>
<TOKEN id="token-60-0" pos="word" morph="none" start_char="5062" end_char="5065">Toro</TOKEN>
<TOKEN id="token-60-1" pos="word" morph="none" start_char="5067" end_char="5068">Tv</TOKEN>
</SEG>
<SEG id="segment-61" start_char="5071" end_char="5182">
<ORIGINAL_TEXT>porque el pasado día 29/03/2020 se publicó el fragmento de la cadena de televisión italiana durante el programa.</ORIGINAL_TEXT>
<TOKEN id="token-61-0" pos="word" morph="none" start_char="5071" end_char="5076">porque</TOKEN>
<TOKEN id="token-61-1" pos="word" morph="none" start_char="5078" end_char="5079">el</TOKEN>
<TOKEN id="token-61-2" pos="word" morph="none" start_char="5081" end_char="5086">pasado</TOKEN>
<TOKEN id="token-61-3" pos="word" morph="none" start_char="5088" end_char="5090">día</TOKEN>
<TOKEN id="token-61-4" pos="unknown" morph="none" start_char="5092" end_char="5101">29/03/2020</TOKEN>
<TOKEN id="token-61-5" pos="word" morph="none" start_char="5103" end_char="5104">se</TOKEN>
<TOKEN id="token-61-6" pos="word" morph="none" start_char="5106" end_char="5112">publicó</TOKEN>
<TOKEN id="token-61-7" pos="word" morph="none" start_char="5114" end_char="5115">el</TOKEN>
<TOKEN id="token-61-8" pos="word" morph="none" start_char="5117" end_char="5125">fragmento</TOKEN>
<TOKEN id="token-61-9" pos="word" morph="none" start_char="5127" end_char="5128">de</TOKEN>
<TOKEN id="token-61-10" pos="word" morph="none" start_char="5130" end_char="5131">la</TOKEN>
<TOKEN id="token-61-11" pos="word" morph="none" start_char="5133" end_char="5138">cadena</TOKEN>
<TOKEN id="token-61-12" pos="word" morph="none" start_char="5140" end_char="5141">de</TOKEN>
<TOKEN id="token-61-13" pos="word" morph="none" start_char="5143" end_char="5152">televisión</TOKEN>
<TOKEN id="token-61-14" pos="word" morph="none" start_char="5154" end_char="5161">italiana</TOKEN>
<TOKEN id="token-61-15" pos="word" morph="none" start_char="5163" end_char="5169">durante</TOKEN>
<TOKEN id="token-61-16" pos="word" morph="none" start_char="5171" end_char="5172">el</TOKEN>
<TOKEN id="token-61-17" pos="word" morph="none" start_char="5174" end_char="5181">programa</TOKEN>
<TOKEN id="token-61-18" pos="punct" morph="none" start_char="5182" end_char="5182">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
