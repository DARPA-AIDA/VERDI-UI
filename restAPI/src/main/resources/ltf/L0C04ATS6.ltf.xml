<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATS6" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="6080" raw_text_md5="7536641ac9cfc62c5a80901cd1311b9b">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="41">
<ORIGINAL_TEXT>El origen del CORONAVIRUS (Vídeo de 2015)</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="2">El</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="4" end_char="9">origen</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="11" end_char="13">del</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="15" end_char="25">CORONAVIRUS</TOKEN>
<TOKEN id="token-0-4" pos="punct" morph="none" start_char="27" end_char="27">(</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="28" end_char="32">Vídeo</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="34" end_char="35">de</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="37" end_char="40">2015</TOKEN>
<TOKEN id="token-0-8" pos="punct" morph="none" start_char="41" end_char="41">)</TOKEN>
</SEG>
<SEG id="segment-1" start_char="50" end_char="97">
<ORIGINAL_TEXT>Me lo han mandado por WhatsApp hoy y he flipado.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="50" end_char="51">Me</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="53" end_char="54">lo</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="56" end_char="58">han</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="60" end_char="66">mandado</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="68" end_char="70">por</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="72" end_char="79">WhatsApp</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="81" end_char="83">hoy</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="85" end_char="85">y</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="87" end_char="88">he</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="90" end_char="96">flipado</TOKEN>
<TOKEN id="token-1-10" pos="punct" morph="none" start_char="97" end_char="97">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="99" end_char="163">
<ORIGINAL_TEXT>Cuanto más sabes sobre el virus menos entiendes qué está pasando.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="99" end_char="104">Cuanto</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="106" end_char="108">más</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="110" end_char="114">sabes</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="116" end_char="120">sobre</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="122" end_char="123">el</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="125" end_char="129">virus</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="131" end_char="135">menos</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="137" end_char="145">entiendes</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="147" end_char="149">qué</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="151" end_char="154">está</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="156" end_char="162">pasando</TOKEN>
<TOKEN id="token-2-11" pos="punct" morph="none" start_char="163" end_char="163">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="165" end_char="239">
<ORIGINAL_TEXT>Lo que sí está claro es que esto no es casual y huele muy pero que muy mal.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="165" end_char="166">Lo</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="168" end_char="170">que</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="172" end_char="173">sí</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="175" end_char="178">está</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="180" end_char="184">claro</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="186" end_char="187">es</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="189" end_char="191">que</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="193" end_char="196">esto</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="198" end_char="199">no</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="201" end_char="202">es</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="204" end_char="209">casual</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="211" end_char="211">y</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="213" end_char="217">huele</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="219" end_char="221">muy</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="223" end_char="226">pero</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="228" end_char="230">que</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="232" end_char="234">muy</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="236" end_char="238">mal</TOKEN>
<TOKEN id="token-3-18" pos="punct" morph="none" start_char="239" end_char="239">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="241" end_char="348">
<ORIGINAL_TEXT>Los movimientos de piezas que se están dando a nivel geopolítico ahora mismo no nos los podemos ni imaginar.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="241" end_char="243">Los</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="245" end_char="255">movimientos</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="257" end_char="258">de</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="260" end_char="265">piezas</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="267" end_char="269">que</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="271" end_char="272">se</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="274" end_char="278">están</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="280" end_char="284">dando</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="286" end_char="286">a</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="288" end_char="292">nivel</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="294" end_char="304">geopolítico</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="306" end_char="310">ahora</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="312" end_char="316">mismo</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="318" end_char="319">no</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="321" end_char="323">nos</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="325" end_char="327">los</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="329" end_char="335">podemos</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="337" end_char="338">ni</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="340" end_char="347">imaginar</TOKEN>
<TOKEN id="token-4-19" pos="punct" morph="none" start_char="348" end_char="348">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="352" end_char="501">
<ORIGINAL_TEXT>Hay un monton de patentes relacionados con coronavirus que causan SARS alterados, en principio, para poder hacer vacunas y tratamientos para curarlos.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="352" end_char="354">Hay</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="356" end_char="357">un</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="359" end_char="364">monton</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="366" end_char="367">de</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="369" end_char="376">patentes</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="378" end_char="389">relacionados</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="391" end_char="393">con</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="395" end_char="405">coronavirus</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="407" end_char="409">que</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="411" end_char="416">causan</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="418" end_char="421">SARS</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="423" end_char="431">alterados</TOKEN>
<TOKEN id="token-5-12" pos="punct" morph="none" start_char="432" end_char="432">,</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="434" end_char="435">en</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="437" end_char="445">principio</TOKEN>
<TOKEN id="token-5-15" pos="punct" morph="none" start_char="446" end_char="446">,</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="448" end_char="451">para</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="453" end_char="457">poder</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="459" end_char="463">hacer</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="465" end_char="471">vacunas</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="473" end_char="473">y</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="475" end_char="486">tratamientos</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="488" end_char="491">para</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="493" end_char="500">curarlos</TOKEN>
<TOKEN id="token-5-24" pos="punct" morph="none" start_char="501" end_char="501">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="503" end_char="555">
<ORIGINAL_TEXT>Los mas recientes hechos por chinos en mayo del 2019.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="503" end_char="505">Los</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="507" end_char="509">mas</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="511" end_char="519">recientes</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="521" end_char="526">hechos</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="528" end_char="530">por</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="532" end_char="537">chinos</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="539" end_char="540">en</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="542" end_char="545">mayo</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="547" end_char="549">del</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="551" end_char="554">2019</TOKEN>
<TOKEN id="token-6-10" pos="punct" morph="none" start_char="555" end_char="555">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="557" end_char="765">
<ORIGINAL_TEXT>Este experimento, que comenta la creaciacion de un coronavirus alterado capaz de transmitirse de humano a humano, por los chinos, seria ya sin excusa, el reconocimiento de que ha sido creado en el laboratorio.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="557" end_char="560">Este</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="562" end_char="572">experimento</TOKEN>
<TOKEN id="token-7-2" pos="punct" morph="none" start_char="573" end_char="573">,</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="575" end_char="577">que</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="579" end_char="585">comenta</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="587" end_char="588">la</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="590" end_char="600">creaciacion</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="602" end_char="603">de</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="605" end_char="606">un</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="608" end_char="618">coronavirus</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="620" end_char="627">alterado</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="629" end_char="633">capaz</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="635" end_char="636">de</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="638" end_char="649">transmitirse</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="651" end_char="652">de</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="654" end_char="659">humano</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="661" end_char="661">a</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="663" end_char="668">humano</TOKEN>
<TOKEN id="token-7-18" pos="punct" morph="none" start_char="669" end_char="669">,</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="671" end_char="673">por</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="675" end_char="677">los</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="679" end_char="684">chinos</TOKEN>
<TOKEN id="token-7-22" pos="punct" morph="none" start_char="685" end_char="685">,</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="687" end_char="691">seria</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="693" end_char="694">ya</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="696" end_char="698">sin</TOKEN>
<TOKEN id="token-7-26" pos="word" morph="none" start_char="700" end_char="705">excusa</TOKEN>
<TOKEN id="token-7-27" pos="punct" morph="none" start_char="706" end_char="706">,</TOKEN>
<TOKEN id="token-7-28" pos="word" morph="none" start_char="708" end_char="709">el</TOKEN>
<TOKEN id="token-7-29" pos="word" morph="none" start_char="711" end_char="724">reconocimiento</TOKEN>
<TOKEN id="token-7-30" pos="word" morph="none" start_char="726" end_char="727">de</TOKEN>
<TOKEN id="token-7-31" pos="word" morph="none" start_char="729" end_char="731">que</TOKEN>
<TOKEN id="token-7-32" pos="word" morph="none" start_char="733" end_char="734">ha</TOKEN>
<TOKEN id="token-7-33" pos="word" morph="none" start_char="736" end_char="739">sido</TOKEN>
<TOKEN id="token-7-34" pos="word" morph="none" start_char="741" end_char="746">creado</TOKEN>
<TOKEN id="token-7-35" pos="word" morph="none" start_char="748" end_char="749">en</TOKEN>
<TOKEN id="token-7-36" pos="word" morph="none" start_char="751" end_char="752">el</TOKEN>
<TOKEN id="token-7-37" pos="word" morph="none" start_char="754" end_char="764">laboratorio</TOKEN>
<TOKEN id="token-7-38" pos="punct" morph="none" start_char="765" end_char="765">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="767" end_char="858">
<ORIGINAL_TEXT>USA y Canada, como minimo tambien lo tenian o, al menos, tambien trabajaban con coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="767" end_char="769">USA</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="771" end_char="771">y</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="773" end_char="778">Canada</TOKEN>
<TOKEN id="token-8-3" pos="punct" morph="none" start_char="779" end_char="779">,</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="781" end_char="784">como</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="786" end_char="791">minimo</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="793" end_char="799">tambien</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="801" end_char="802">lo</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="804" end_char="809">tenian</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="811" end_char="811">o</TOKEN>
<TOKEN id="token-8-10" pos="punct" morph="none" start_char="812" end_char="812">,</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="814" end_char="815">al</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="817" end_char="821">menos</TOKEN>
<TOKEN id="token-8-13" pos="punct" morph="none" start_char="822" end_char="822">,</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="824" end_char="830">tambien</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="832" end_char="841">trabajaban</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="843" end_char="845">con</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="847" end_char="857">coronavirus</TOKEN>
<TOKEN id="token-8-18" pos="punct" morph="none" start_char="858" end_char="858">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="860" end_char="1128">
<ORIGINAL_TEXT>Incluso el CNI español, ha reconocido que teniendo la secuencia genetica completa son capaces de sintetizarlo (crearlo por medios artificiales, ya que son capaces de quitar secuencias geneticas a un organismo e insertarselas a otro) para su investigacion en una vacuna.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="860" end_char="866">Incluso</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="868" end_char="869">el</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="871" end_char="873">CNI</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="875" end_char="881">español</TOKEN>
<TOKEN id="token-9-4" pos="punct" morph="none" start_char="882" end_char="882">,</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="884" end_char="885">ha</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="887" end_char="896">reconocido</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="898" end_char="900">que</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="902" end_char="909">teniendo</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="911" end_char="912">la</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="914" end_char="922">secuencia</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="924" end_char="931">genetica</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="933" end_char="940">completa</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="942" end_char="944">son</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="946" end_char="952">capaces</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="954" end_char="955">de</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="957" end_char="968">sintetizarlo</TOKEN>
<TOKEN id="token-9-17" pos="punct" morph="none" start_char="970" end_char="970">(</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="971" end_char="977">crearlo</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="979" end_char="981">por</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="983" end_char="988">medios</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="990" end_char="1001">artificiales</TOKEN>
<TOKEN id="token-9-22" pos="punct" morph="none" start_char="1002" end_char="1002">,</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1004" end_char="1005">ya</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1007" end_char="1009">que</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1011" end_char="1013">son</TOKEN>
<TOKEN id="token-9-26" pos="word" morph="none" start_char="1015" end_char="1021">capaces</TOKEN>
<TOKEN id="token-9-27" pos="word" morph="none" start_char="1023" end_char="1024">de</TOKEN>
<TOKEN id="token-9-28" pos="word" morph="none" start_char="1026" end_char="1031">quitar</TOKEN>
<TOKEN id="token-9-29" pos="word" morph="none" start_char="1033" end_char="1042">secuencias</TOKEN>
<TOKEN id="token-9-30" pos="word" morph="none" start_char="1044" end_char="1052">geneticas</TOKEN>
<TOKEN id="token-9-31" pos="word" morph="none" start_char="1054" end_char="1054">a</TOKEN>
<TOKEN id="token-9-32" pos="word" morph="none" start_char="1056" end_char="1057">un</TOKEN>
<TOKEN id="token-9-33" pos="word" morph="none" start_char="1059" end_char="1067">organismo</TOKEN>
<TOKEN id="token-9-34" pos="word" morph="none" start_char="1069" end_char="1069">e</TOKEN>
<TOKEN id="token-9-35" pos="word" morph="none" start_char="1071" end_char="1083">insertarselas</TOKEN>
<TOKEN id="token-9-36" pos="word" morph="none" start_char="1085" end_char="1085">a</TOKEN>
<TOKEN id="token-9-37" pos="word" morph="none" start_char="1087" end_char="1090">otro</TOKEN>
<TOKEN id="token-9-38" pos="punct" morph="none" start_char="1091" end_char="1091">)</TOKEN>
<TOKEN id="token-9-39" pos="word" morph="none" start_char="1093" end_char="1096">para</TOKEN>
<TOKEN id="token-9-40" pos="word" morph="none" start_char="1098" end_char="1099">su</TOKEN>
<TOKEN id="token-9-41" pos="word" morph="none" start_char="1101" end_char="1113">investigacion</TOKEN>
<TOKEN id="token-9-42" pos="word" morph="none" start_char="1115" end_char="1116">en</TOKEN>
<TOKEN id="token-9-43" pos="word" morph="none" start_char="1118" end_char="1120">una</TOKEN>
<TOKEN id="token-9-44" pos="word" morph="none" start_char="1122" end_char="1127">vacuna</TOKEN>
<TOKEN id="token-9-45" pos="punct" morph="none" start_char="1128" end_char="1128">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1131" end_char="1226">
<ORIGINAL_TEXT>Es totalmente falso, lo que han dicho varios medios, de que no se puede crear en un laboratorio.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1131" end_char="1132">Es</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1134" end_char="1143">totalmente</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1145" end_char="1149">falso</TOKEN>
<TOKEN id="token-10-3" pos="punct" morph="none" start_char="1150" end_char="1150">,</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1152" end_char="1153">lo</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1155" end_char="1157">que</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1159" end_char="1161">han</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1163" end_char="1167">dicho</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1169" end_char="1174">varios</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1176" end_char="1181">medios</TOKEN>
<TOKEN id="token-10-10" pos="punct" morph="none" start_char="1182" end_char="1182">,</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1184" end_char="1185">de</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1187" end_char="1189">que</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1191" end_char="1192">no</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1194" end_char="1195">se</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1197" end_char="1201">puede</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1203" end_char="1207">crear</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1209" end_char="1210">en</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1212" end_char="1213">un</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1215" end_char="1225">laboratorio</TOKEN>
<TOKEN id="token-10-20" pos="punct" morph="none" start_char="1226" end_char="1226">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1228" end_char="1287">
<ORIGINAL_TEXT>Se puede, se ha hecho y cada vez lo podran hacer mas paises.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1228" end_char="1229">Se</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1231" end_char="1235">puede</TOKEN>
<TOKEN id="token-11-2" pos="punct" morph="none" start_char="1236" end_char="1236">,</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1238" end_char="1239">se</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1241" end_char="1242">ha</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1244" end_char="1248">hecho</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1250" end_char="1250">y</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1252" end_char="1255">cada</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1257" end_char="1259">vez</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1261" end_char="1262">lo</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1264" end_char="1269">podran</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1271" end_char="1275">hacer</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1277" end_char="1279">mas</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1281" end_char="1286">paises</TOKEN>
<TOKEN id="token-11-14" pos="punct" morph="none" start_char="1287" end_char="1287">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1290" end_char="1424">
<ORIGINAL_TEXT>A mi me parece una guerra, como si uno hubiera tirado una bomba nuclear, pero recibe como respuesta otra, y terminan los dos perdiendo.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1290" end_char="1290">A</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1292" end_char="1293">mi</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1295" end_char="1296">me</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1298" end_char="1303">parece</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1305" end_char="1307">una</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1309" end_char="1314">guerra</TOKEN>
<TOKEN id="token-12-6" pos="punct" morph="none" start_char="1315" end_char="1315">,</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1317" end_char="1320">como</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1322" end_char="1323">si</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1325" end_char="1327">uno</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1329" end_char="1335">hubiera</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1337" end_char="1342">tirado</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1344" end_char="1346">una</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1348" end_char="1352">bomba</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1354" end_char="1360">nuclear</TOKEN>
<TOKEN id="token-12-15" pos="punct" morph="none" start_char="1361" end_char="1361">,</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1363" end_char="1366">pero</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1368" end_char="1373">recibe</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1375" end_char="1378">como</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1380" end_char="1388">respuesta</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1390" end_char="1393">otra</TOKEN>
<TOKEN id="token-12-21" pos="punct" morph="none" start_char="1394" end_char="1394">,</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1396" end_char="1396">y</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="1398" end_char="1405">terminan</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="1407" end_char="1409">los</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="1411" end_char="1413">dos</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="1415" end_char="1423">perdiendo</TOKEN>
<TOKEN id="token-12-27" pos="punct" morph="none" start_char="1424" end_char="1424">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1427" end_char="1541">
<ORIGINAL_TEXT>Lo ultimo que he leido, es que un japones en USA, ha creado una cepa de gripe A resistente al sistema inmunologico.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1427" end_char="1428">Lo</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1430" end_char="1435">ultimo</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1437" end_char="1439">que</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1441" end_char="1442">he</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1444" end_char="1448">leido</TOKEN>
<TOKEN id="token-13-5" pos="punct" morph="none" start_char="1449" end_char="1449">,</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1451" end_char="1452">es</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1454" end_char="1456">que</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1458" end_char="1459">un</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1461" end_char="1467">japones</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1469" end_char="1470">en</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1472" end_char="1474">USA</TOKEN>
<TOKEN id="token-13-12" pos="punct" morph="none" start_char="1475" end_char="1475">,</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1477" end_char="1478">ha</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1480" end_char="1485">creado</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1487" end_char="1489">una</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1491" end_char="1494">cepa</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1496" end_char="1497">de</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1499" end_char="1503">gripe</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1505" end_char="1505">A</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1507" end_char="1516">resistente</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="1518" end_char="1519">al</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="1521" end_char="1527">sistema</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="1529" end_char="1540">inmunologico</TOKEN>
<TOKEN id="token-13-24" pos="punct" morph="none" start_char="1541" end_char="1541">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1543" end_char="1634">
<ORIGINAL_TEXT>En este caso, por seleccion de las cepas mas dañinas en diferentes generaciones, segun dice.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1543" end_char="1544">En</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1546" end_char="1549">este</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1551" end_char="1554">caso</TOKEN>
<TOKEN id="token-14-3" pos="punct" morph="none" start_char="1555" end_char="1555">,</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1557" end_char="1559">por</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1561" end_char="1569">seleccion</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1571" end_char="1572">de</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1574" end_char="1576">las</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1578" end_char="1582">cepas</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1584" end_char="1586">mas</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1588" end_char="1594">dañinas</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1596" end_char="1597">en</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1599" end_char="1608">diferentes</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1610" end_char="1621">generaciones</TOKEN>
<TOKEN id="token-14-14" pos="punct" morph="none" start_char="1622" end_char="1622">,</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1624" end_char="1628">segun</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1630" end_char="1633">dice</TOKEN>
<TOKEN id="token-14-17" pos="punct" morph="none" start_char="1634" end_char="1634">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1638" end_char="1722">
<ORIGINAL_TEXT>(Vídeo revelador) ¿Es el Covid-19 un virus creado por los chinos de forma deliberada?</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="punct" morph="none" start_char="1638" end_char="1638">(</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1639" end_char="1643">Vídeo</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1645" end_char="1653">revelador</TOKEN>
<TOKEN id="token-15-3" pos="punct" morph="none" start_char="1654" end_char="1654">)</TOKEN>
<TOKEN id="token-15-4" pos="punct" morph="none" start_char="1656" end_char="1656">¿</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1657" end_char="1658">Es</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1660" end_char="1661">el</TOKEN>
<TOKEN id="token-15-7" pos="unknown" morph="none" start_char="1663" end_char="1670">Covid-19</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1672" end_char="1673">un</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1675" end_char="1679">virus</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1681" end_char="1686">creado</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1688" end_char="1690">por</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1692" end_char="1694">los</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1696" end_char="1701">chinos</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1703" end_char="1704">de</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="1706" end_char="1710">forma</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="1712" end_char="1721">deliberada</TOKEN>
<TOKEN id="token-15-17" pos="punct" morph="none" start_char="1722" end_char="1722">?</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1724" end_char="2030">
<ORIGINAL_TEXT>Los medios ocultan la información y tenemos las pruebas COMPARTIR TAGS ChinoCovid 19DisenadoInformacionOcultanPropositoPruebasVirus Carlota Sales Llop.- Los grandes medios informativos parecen estar mudos, ciegos y sordos ante un vídeo que está circulando por los canales alternativos y ocultos de Internet.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1724" end_char="1726">Los</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1728" end_char="1733">medios</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1735" end_char="1741">ocultan</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1743" end_char="1744">la</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1746" end_char="1756">información</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1758" end_char="1758">y</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1760" end_char="1766">tenemos</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1768" end_char="1770">las</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1772" end_char="1778">pruebas</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="1780" end_char="1788">COMPARTIR</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="1790" end_char="1793">TAGS</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="1795" end_char="1804">ChinoCovid</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="1806" end_char="1854">19DisenadoInformacionOcultanPropositoPruebasVirus</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="1856" end_char="1862">Carlota</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="1864" end_char="1868">Sales</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="1870" end_char="1873">Llop</TOKEN>
<TOKEN id="token-16-16" pos="punct" morph="none" start_char="1874" end_char="1875">.-</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="1877" end_char="1879">Los</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="1881" end_char="1887">grandes</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="1889" end_char="1894">medios</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="1896" end_char="1907">informativos</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="1909" end_char="1915">parecen</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="1917" end_char="1921">estar</TOKEN>
<TOKEN id="token-16-23" pos="word" morph="none" start_char="1923" end_char="1927">mudos</TOKEN>
<TOKEN id="token-16-24" pos="punct" morph="none" start_char="1928" end_char="1928">,</TOKEN>
<TOKEN id="token-16-25" pos="word" morph="none" start_char="1930" end_char="1935">ciegos</TOKEN>
<TOKEN id="token-16-26" pos="word" morph="none" start_char="1937" end_char="1937">y</TOKEN>
<TOKEN id="token-16-27" pos="word" morph="none" start_char="1939" end_char="1944">sordos</TOKEN>
<TOKEN id="token-16-28" pos="word" morph="none" start_char="1946" end_char="1949">ante</TOKEN>
<TOKEN id="token-16-29" pos="word" morph="none" start_char="1951" end_char="1952">un</TOKEN>
<TOKEN id="token-16-30" pos="word" morph="none" start_char="1954" end_char="1958">vídeo</TOKEN>
<TOKEN id="token-16-31" pos="word" morph="none" start_char="1960" end_char="1962">que</TOKEN>
<TOKEN id="token-16-32" pos="word" morph="none" start_char="1964" end_char="1967">está</TOKEN>
<TOKEN id="token-16-33" pos="word" morph="none" start_char="1969" end_char="1978">circulando</TOKEN>
<TOKEN id="token-16-34" pos="word" morph="none" start_char="1980" end_char="1982">por</TOKEN>
<TOKEN id="token-16-35" pos="word" morph="none" start_char="1984" end_char="1986">los</TOKEN>
<TOKEN id="token-16-36" pos="word" morph="none" start_char="1988" end_char="1994">canales</TOKEN>
<TOKEN id="token-16-37" pos="word" morph="none" start_char="1996" end_char="2007">alternativos</TOKEN>
<TOKEN id="token-16-38" pos="word" morph="none" start_char="2009" end_char="2009">y</TOKEN>
<TOKEN id="token-16-39" pos="word" morph="none" start_char="2011" end_char="2017">ocultos</TOKEN>
<TOKEN id="token-16-40" pos="word" morph="none" start_char="2019" end_char="2020">de</TOKEN>
<TOKEN id="token-16-41" pos="word" morph="none" start_char="2022" end_char="2029">Internet</TOKEN>
<TOKEN id="token-16-42" pos="punct" morph="none" start_char="2030" end_char="2030">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2032" end_char="2160">
<ORIGINAL_TEXT>Sin embargo, este vídeo no es la producción de un desconocido youtuber, o las elucubraciones de algún teórico de la conspiración.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2032" end_char="2034">Sin</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2036" end_char="2042">embargo</TOKEN>
<TOKEN id="token-17-2" pos="punct" morph="none" start_char="2043" end_char="2043">,</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2045" end_char="2048">este</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2050" end_char="2054">vídeo</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2056" end_char="2057">no</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2059" end_char="2060">es</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2062" end_char="2063">la</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2065" end_char="2074">producción</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2076" end_char="2077">de</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2079" end_char="2080">un</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2082" end_char="2092">desconocido</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2094" end_char="2101">youtuber</TOKEN>
<TOKEN id="token-17-13" pos="punct" morph="none" start_char="2102" end_char="2102">,</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2104" end_char="2104">o</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2106" end_char="2108">las</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="2110" end_char="2123">elucubraciones</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="2125" end_char="2126">de</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="2128" end_char="2132">algún</TOKEN>
<TOKEN id="token-17-19" pos="word" morph="none" start_char="2134" end_char="2140">teórico</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="2142" end_char="2143">de</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="2145" end_char="2146">la</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="2148" end_char="2159">conspiración</TOKEN>
<TOKEN id="token-17-23" pos="punct" morph="none" start_char="2160" end_char="2160">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2162" end_char="2419">
<ORIGINAL_TEXT>De ninguna manera: Es un vídeo emitido por la RAI en 2015, y presentado por el prestigiosísimo programa de ciencia "LEONARDO", de la misma cadena estatal, que realizó un reportaje basado en informaciones de la aún más prestigiosa revista científica ‘Nature’.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2162" end_char="2163">De</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2165" end_char="2171">ninguna</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2173" end_char="2178">manera</TOKEN>
<TOKEN id="token-18-3" pos="punct" morph="none" start_char="2179" end_char="2179">:</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2181" end_char="2182">Es</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2184" end_char="2185">un</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2187" end_char="2191">vídeo</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2193" end_char="2199">emitido</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2201" end_char="2203">por</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="2205" end_char="2206">la</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="2208" end_char="2210">RAI</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="2212" end_char="2213">en</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2215" end_char="2218">2015</TOKEN>
<TOKEN id="token-18-13" pos="punct" morph="none" start_char="2219" end_char="2219">,</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="2221" end_char="2221">y</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="2223" end_char="2232">presentado</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="2234" end_char="2236">por</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="2238" end_char="2239">el</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="2241" end_char="2255">prestigiosísimo</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="2257" end_char="2264">programa</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="2266" end_char="2267">de</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="2269" end_char="2275">ciencia</TOKEN>
<TOKEN id="token-18-22" pos="punct" morph="none" start_char="2277" end_char="2277">"</TOKEN>
<TOKEN id="token-18-23" pos="word" morph="none" start_char="2278" end_char="2285">LEONARDO</TOKEN>
<TOKEN id="token-18-24" pos="punct" morph="none" start_char="2286" end_char="2287">",</TOKEN>
<TOKEN id="token-18-25" pos="word" morph="none" start_char="2289" end_char="2290">de</TOKEN>
<TOKEN id="token-18-26" pos="word" morph="none" start_char="2292" end_char="2293">la</TOKEN>
<TOKEN id="token-18-27" pos="word" morph="none" start_char="2295" end_char="2299">misma</TOKEN>
<TOKEN id="token-18-28" pos="word" morph="none" start_char="2301" end_char="2306">cadena</TOKEN>
<TOKEN id="token-18-29" pos="word" morph="none" start_char="2308" end_char="2314">estatal</TOKEN>
<TOKEN id="token-18-30" pos="punct" morph="none" start_char="2315" end_char="2315">,</TOKEN>
<TOKEN id="token-18-31" pos="word" morph="none" start_char="2317" end_char="2319">que</TOKEN>
<TOKEN id="token-18-32" pos="word" morph="none" start_char="2321" end_char="2327">realizó</TOKEN>
<TOKEN id="token-18-33" pos="word" morph="none" start_char="2329" end_char="2330">un</TOKEN>
<TOKEN id="token-18-34" pos="word" morph="none" start_char="2332" end_char="2340">reportaje</TOKEN>
<TOKEN id="token-18-35" pos="word" morph="none" start_char="2342" end_char="2347">basado</TOKEN>
<TOKEN id="token-18-36" pos="word" morph="none" start_char="2349" end_char="2350">en</TOKEN>
<TOKEN id="token-18-37" pos="word" morph="none" start_char="2352" end_char="2364">informaciones</TOKEN>
<TOKEN id="token-18-38" pos="word" morph="none" start_char="2366" end_char="2367">de</TOKEN>
<TOKEN id="token-18-39" pos="word" morph="none" start_char="2369" end_char="2370">la</TOKEN>
<TOKEN id="token-18-40" pos="word" morph="none" start_char="2372" end_char="2374">aún</TOKEN>
<TOKEN id="token-18-41" pos="word" morph="none" start_char="2376" end_char="2378">más</TOKEN>
<TOKEN id="token-18-42" pos="word" morph="none" start_char="2380" end_char="2390">prestigiosa</TOKEN>
<TOKEN id="token-18-43" pos="word" morph="none" start_char="2392" end_char="2398">revista</TOKEN>
<TOKEN id="token-18-44" pos="word" morph="none" start_char="2400" end_char="2409">científica</TOKEN>
<TOKEN id="token-18-45" pos="punct" morph="none" start_char="2411" end_char="2411">‘</TOKEN>
<TOKEN id="token-18-46" pos="word" morph="none" start_char="2412" end_char="2417">Nature</TOKEN>
<TOKEN id="token-18-47" pos="punct" morph="none" start_char="2418" end_char="2419">’.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2421" end_char="2530">
<ORIGINAL_TEXT>Al poco de su emisión, este vídeo fue "misteriosamente" borrado de Youtube y totalmente censurado en Internet.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2421" end_char="2422">Al</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2424" end_char="2427">poco</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2429" end_char="2430">de</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2432" end_char="2433">su</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2435" end_char="2441">emisión</TOKEN>
<TOKEN id="token-19-5" pos="punct" morph="none" start_char="2442" end_char="2442">,</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2444" end_char="2447">este</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2449" end_char="2453">vídeo</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2455" end_char="2457">fue</TOKEN>
<TOKEN id="token-19-9" pos="punct" morph="none" start_char="2459" end_char="2459">"</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="2460" end_char="2474">misteriosamente</TOKEN>
<TOKEN id="token-19-11" pos="punct" morph="none" start_char="2475" end_char="2475">"</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="2477" end_char="2483">borrado</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="2485" end_char="2486">de</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="2488" end_char="2494">Youtube</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="2496" end_char="2496">y</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="2498" end_char="2507">totalmente</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="2509" end_char="2517">censurado</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="2519" end_char="2520">en</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="2522" end_char="2529">Internet</TOKEN>
<TOKEN id="token-19-20" pos="punct" morph="none" start_char="2530" end_char="2530">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2532" end_char="2761">
<ORIGINAL_TEXT>Sin embargo, algún anónimo creyente en la libertad de la información nos lo ha hecho llegar y con subtítulos en castellano, para que sea entendido -y por ello, para que aterrorice, espante y apabulle- a todos aquellos que lo vean.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2532" end_char="2534">Sin</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2536" end_char="2542">embargo</TOKEN>
<TOKEN id="token-20-2" pos="punct" morph="none" start_char="2543" end_char="2543">,</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2545" end_char="2549">algún</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2551" end_char="2557">anónimo</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2559" end_char="2566">creyente</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2568" end_char="2569">en</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2571" end_char="2572">la</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="2574" end_char="2581">libertad</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2583" end_char="2584">de</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2586" end_char="2587">la</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="2589" end_char="2599">información</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="2601" end_char="2603">nos</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="2605" end_char="2606">lo</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="2608" end_char="2609">ha</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="2611" end_char="2615">hecho</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="2617" end_char="2622">llegar</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="2624" end_char="2624">y</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="2626" end_char="2628">con</TOKEN>
<TOKEN id="token-20-19" pos="word" morph="none" start_char="2630" end_char="2639">subtítulos</TOKEN>
<TOKEN id="token-20-20" pos="word" morph="none" start_char="2641" end_char="2642">en</TOKEN>
<TOKEN id="token-20-21" pos="word" morph="none" start_char="2644" end_char="2653">castellano</TOKEN>
<TOKEN id="token-20-22" pos="punct" morph="none" start_char="2654" end_char="2654">,</TOKEN>
<TOKEN id="token-20-23" pos="word" morph="none" start_char="2656" end_char="2659">para</TOKEN>
<TOKEN id="token-20-24" pos="word" morph="none" start_char="2661" end_char="2663">que</TOKEN>
<TOKEN id="token-20-25" pos="word" morph="none" start_char="2665" end_char="2667">sea</TOKEN>
<TOKEN id="token-20-26" pos="word" morph="none" start_char="2669" end_char="2677">entendido</TOKEN>
<TOKEN id="token-20-27" pos="punct" morph="none" start_char="2679" end_char="2679">-</TOKEN>
<TOKEN id="token-20-28" pos="word" morph="none" start_char="2680" end_char="2680">y</TOKEN>
<TOKEN id="token-20-29" pos="word" morph="none" start_char="2682" end_char="2684">por</TOKEN>
<TOKEN id="token-20-30" pos="word" morph="none" start_char="2686" end_char="2689">ello</TOKEN>
<TOKEN id="token-20-31" pos="punct" morph="none" start_char="2690" end_char="2690">,</TOKEN>
<TOKEN id="token-20-32" pos="word" morph="none" start_char="2692" end_char="2695">para</TOKEN>
<TOKEN id="token-20-33" pos="word" morph="none" start_char="2697" end_char="2699">que</TOKEN>
<TOKEN id="token-20-34" pos="word" morph="none" start_char="2701" end_char="2710">aterrorice</TOKEN>
<TOKEN id="token-20-35" pos="punct" morph="none" start_char="2711" end_char="2711">,</TOKEN>
<TOKEN id="token-20-36" pos="word" morph="none" start_char="2713" end_char="2719">espante</TOKEN>
<TOKEN id="token-20-37" pos="word" morph="none" start_char="2721" end_char="2721">y</TOKEN>
<TOKEN id="token-20-38" pos="word" morph="none" start_char="2723" end_char="2730">apabulle</TOKEN>
<TOKEN id="token-20-39" pos="punct" morph="none" start_char="2731" end_char="2731">-</TOKEN>
<TOKEN id="token-20-40" pos="word" morph="none" start_char="2733" end_char="2733">a</TOKEN>
<TOKEN id="token-20-41" pos="word" morph="none" start_char="2735" end_char="2739">todos</TOKEN>
<TOKEN id="token-20-42" pos="word" morph="none" start_char="2741" end_char="2748">aquellos</TOKEN>
<TOKEN id="token-20-43" pos="word" morph="none" start_char="2750" end_char="2752">que</TOKEN>
<TOKEN id="token-20-44" pos="word" morph="none" start_char="2754" end_char="2755">lo</TOKEN>
<TOKEN id="token-20-45" pos="word" morph="none" start_char="2757" end_char="2760">vean</TOKEN>
<TOKEN id="token-20-46" pos="punct" morph="none" start_char="2761" end_char="2761">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2763" end_char="3058">
<ORIGINAL_TEXT>La historia es sencilla: en 2015, China incorporó una proteína al virus SARS -ese que dicen tan similar al Covid-19- que hacía que el virus que se localizaba en murciélagos -¿Les suena?- infectara a los seres humanos produciendo una pulmonía muy aguda aunque -según los investigadores- no mortal.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2763" end_char="2764">La</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2766" end_char="2773">historia</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2775" end_char="2776">es</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2778" end_char="2785">sencilla</TOKEN>
<TOKEN id="token-21-4" pos="punct" morph="none" start_char="2786" end_char="2786">:</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="2788" end_char="2789">en</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2791" end_char="2794">2015</TOKEN>
<TOKEN id="token-21-7" pos="punct" morph="none" start_char="2795" end_char="2795">,</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="2797" end_char="2801">China</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="2803" end_char="2811">incorporó</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="2813" end_char="2815">una</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="2817" end_char="2824">proteína</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="2826" end_char="2827">al</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="2829" end_char="2833">virus</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="2835" end_char="2838">SARS</TOKEN>
<TOKEN id="token-21-15" pos="punct" morph="none" start_char="2840" end_char="2840">-</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="2841" end_char="2843">ese</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="2845" end_char="2847">que</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="2849" end_char="2853">dicen</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="2855" end_char="2857">tan</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="2859" end_char="2865">similar</TOKEN>
<TOKEN id="token-21-21" pos="word" morph="none" start_char="2867" end_char="2868">al</TOKEN>
<TOKEN id="token-21-22" pos="unknown" morph="none" start_char="2870" end_char="2877">Covid-19</TOKEN>
<TOKEN id="token-21-23" pos="punct" morph="none" start_char="2878" end_char="2878">-</TOKEN>
<TOKEN id="token-21-24" pos="word" morph="none" start_char="2880" end_char="2882">que</TOKEN>
<TOKEN id="token-21-25" pos="word" morph="none" start_char="2884" end_char="2888">hacía</TOKEN>
<TOKEN id="token-21-26" pos="word" morph="none" start_char="2890" end_char="2892">que</TOKEN>
<TOKEN id="token-21-27" pos="word" morph="none" start_char="2894" end_char="2895">el</TOKEN>
<TOKEN id="token-21-28" pos="word" morph="none" start_char="2897" end_char="2901">virus</TOKEN>
<TOKEN id="token-21-29" pos="word" morph="none" start_char="2903" end_char="2905">que</TOKEN>
<TOKEN id="token-21-30" pos="word" morph="none" start_char="2907" end_char="2908">se</TOKEN>
<TOKEN id="token-21-31" pos="word" morph="none" start_char="2910" end_char="2919">localizaba</TOKEN>
<TOKEN id="token-21-32" pos="word" morph="none" start_char="2921" end_char="2922">en</TOKEN>
<TOKEN id="token-21-33" pos="word" morph="none" start_char="2924" end_char="2934">murciélagos</TOKEN>
<TOKEN id="token-21-34" pos="punct" morph="none" start_char="2936" end_char="2937">-¿</TOKEN>
<TOKEN id="token-21-35" pos="word" morph="none" start_char="2938" end_char="2940">Les</TOKEN>
<TOKEN id="token-21-36" pos="word" morph="none" start_char="2942" end_char="2946">suena</TOKEN>
<TOKEN id="token-21-37" pos="punct" morph="none" start_char="2947" end_char="2948">?-</TOKEN>
<TOKEN id="token-21-38" pos="word" morph="none" start_char="2950" end_char="2958">infectara</TOKEN>
<TOKEN id="token-21-39" pos="word" morph="none" start_char="2960" end_char="2960">a</TOKEN>
<TOKEN id="token-21-40" pos="word" morph="none" start_char="2962" end_char="2964">los</TOKEN>
<TOKEN id="token-21-41" pos="word" morph="none" start_char="2966" end_char="2970">seres</TOKEN>
<TOKEN id="token-21-42" pos="word" morph="none" start_char="2972" end_char="2978">humanos</TOKEN>
<TOKEN id="token-21-43" pos="word" morph="none" start_char="2980" end_char="2990">produciendo</TOKEN>
<TOKEN id="token-21-44" pos="word" morph="none" start_char="2992" end_char="2994">una</TOKEN>
<TOKEN id="token-21-45" pos="word" morph="none" start_char="2996" end_char="3003">pulmonía</TOKEN>
<TOKEN id="token-21-46" pos="word" morph="none" start_char="3005" end_char="3007">muy</TOKEN>
<TOKEN id="token-21-47" pos="word" morph="none" start_char="3009" end_char="3013">aguda</TOKEN>
<TOKEN id="token-21-48" pos="word" morph="none" start_char="3015" end_char="3020">aunque</TOKEN>
<TOKEN id="token-21-49" pos="punct" morph="none" start_char="3022" end_char="3022">-</TOKEN>
<TOKEN id="token-21-50" pos="word" morph="none" start_char="3023" end_char="3027">según</TOKEN>
<TOKEN id="token-21-51" pos="word" morph="none" start_char="3029" end_char="3031">los</TOKEN>
<TOKEN id="token-21-52" pos="word" morph="none" start_char="3033" end_char="3046">investigadores</TOKEN>
<TOKEN id="token-21-53" pos="punct" morph="none" start_char="3047" end_char="3047">-</TOKEN>
<TOKEN id="token-21-54" pos="word" morph="none" start_char="3049" end_char="3050">no</TOKEN>
<TOKEN id="token-21-55" pos="word" morph="none" start_char="3052" end_char="3057">mortal</TOKEN>
<TOKEN id="token-21-56" pos="punct" morph="none" start_char="3058" end_char="3058">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="3060" end_char="3078">
<ORIGINAL_TEXT>¿Les suena de algo?</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="punct" morph="none" start_char="3060" end_char="3060">¿</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="3061" end_char="3063">Les</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="3065" end_char="3069">suena</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="3071" end_char="3072">de</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="3074" end_char="3077">algo</TOKEN>
<TOKEN id="token-22-5" pos="punct" morph="none" start_char="3078" end_char="3078">?</TOKEN>
</SEG>
<SEG id="segment-23" start_char="3080" end_char="3363">
<ORIGINAL_TEXT>Lo más sospechoso de todo es que a algunos medios, que sabemos que existen de forma artificial para respaldar al Gobierno, han calificado de "bulo" la noticia, pese a reconocer que el vídeo, la información y todo lo narrado es totalmente cierto, pero que "no corresponde al Covid-19".</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="3080" end_char="3081">Lo</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="3083" end_char="3085">más</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="3087" end_char="3096">sospechoso</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="3098" end_char="3099">de</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="3101" end_char="3104">todo</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="3106" end_char="3107">es</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="3109" end_char="3111">que</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="3113" end_char="3113">a</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="3115" end_char="3121">algunos</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="3123" end_char="3128">medios</TOKEN>
<TOKEN id="token-23-10" pos="punct" morph="none" start_char="3129" end_char="3129">,</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="3131" end_char="3133">que</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="3135" end_char="3141">sabemos</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="3143" end_char="3145">que</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="3147" end_char="3153">existen</TOKEN>
<TOKEN id="token-23-15" pos="word" morph="none" start_char="3155" end_char="3156">de</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="3158" end_char="3162">forma</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="3164" end_char="3173">artificial</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="3175" end_char="3178">para</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="3180" end_char="3188">respaldar</TOKEN>
<TOKEN id="token-23-20" pos="word" morph="none" start_char="3190" end_char="3191">al</TOKEN>
<TOKEN id="token-23-21" pos="word" morph="none" start_char="3193" end_char="3200">Gobierno</TOKEN>
<TOKEN id="token-23-22" pos="punct" morph="none" start_char="3201" end_char="3201">,</TOKEN>
<TOKEN id="token-23-23" pos="word" morph="none" start_char="3203" end_char="3205">han</TOKEN>
<TOKEN id="token-23-24" pos="word" morph="none" start_char="3207" end_char="3216">calificado</TOKEN>
<TOKEN id="token-23-25" pos="word" morph="none" start_char="3218" end_char="3219">de</TOKEN>
<TOKEN id="token-23-26" pos="punct" morph="none" start_char="3221" end_char="3221">"</TOKEN>
<TOKEN id="token-23-27" pos="word" morph="none" start_char="3222" end_char="3225">bulo</TOKEN>
<TOKEN id="token-23-28" pos="punct" morph="none" start_char="3226" end_char="3226">"</TOKEN>
<TOKEN id="token-23-29" pos="word" morph="none" start_char="3228" end_char="3229">la</TOKEN>
<TOKEN id="token-23-30" pos="word" morph="none" start_char="3231" end_char="3237">noticia</TOKEN>
<TOKEN id="token-23-31" pos="punct" morph="none" start_char="3238" end_char="3238">,</TOKEN>
<TOKEN id="token-23-32" pos="word" morph="none" start_char="3240" end_char="3243">pese</TOKEN>
<TOKEN id="token-23-33" pos="word" morph="none" start_char="3245" end_char="3245">a</TOKEN>
<TOKEN id="token-23-34" pos="word" morph="none" start_char="3247" end_char="3255">reconocer</TOKEN>
<TOKEN id="token-23-35" pos="word" morph="none" start_char="3257" end_char="3259">que</TOKEN>
<TOKEN id="token-23-36" pos="word" morph="none" start_char="3261" end_char="3262">el</TOKEN>
<TOKEN id="token-23-37" pos="word" morph="none" start_char="3264" end_char="3268">vídeo</TOKEN>
<TOKEN id="token-23-38" pos="punct" morph="none" start_char="3269" end_char="3269">,</TOKEN>
<TOKEN id="token-23-39" pos="word" morph="none" start_char="3271" end_char="3272">la</TOKEN>
<TOKEN id="token-23-40" pos="word" morph="none" start_char="3274" end_char="3284">información</TOKEN>
<TOKEN id="token-23-41" pos="word" morph="none" start_char="3286" end_char="3286">y</TOKEN>
<TOKEN id="token-23-42" pos="word" morph="none" start_char="3288" end_char="3291">todo</TOKEN>
<TOKEN id="token-23-43" pos="word" morph="none" start_char="3293" end_char="3294">lo</TOKEN>
<TOKEN id="token-23-44" pos="word" morph="none" start_char="3296" end_char="3302">narrado</TOKEN>
<TOKEN id="token-23-45" pos="word" morph="none" start_char="3304" end_char="3305">es</TOKEN>
<TOKEN id="token-23-46" pos="word" morph="none" start_char="3307" end_char="3316">totalmente</TOKEN>
<TOKEN id="token-23-47" pos="word" morph="none" start_char="3318" end_char="3323">cierto</TOKEN>
<TOKEN id="token-23-48" pos="punct" morph="none" start_char="3324" end_char="3324">,</TOKEN>
<TOKEN id="token-23-49" pos="word" morph="none" start_char="3326" end_char="3329">pero</TOKEN>
<TOKEN id="token-23-50" pos="word" morph="none" start_char="3331" end_char="3333">que</TOKEN>
<TOKEN id="token-23-51" pos="punct" morph="none" start_char="3335" end_char="3335">"</TOKEN>
<TOKEN id="token-23-52" pos="word" morph="none" start_char="3336" end_char="3337">no</TOKEN>
<TOKEN id="token-23-53" pos="word" morph="none" start_char="3339" end_char="3349">corresponde</TOKEN>
<TOKEN id="token-23-54" pos="word" morph="none" start_char="3351" end_char="3352">al</TOKEN>
<TOKEN id="token-23-55" pos="unknown" morph="none" start_char="3354" end_char="3361">Covid-19</TOKEN>
<TOKEN id="token-23-56" pos="punct" morph="none" start_char="3362" end_char="3363">".</TOKEN>
</SEG>
<SEG id="segment-24" start_char="3365" end_char="3554">
<ORIGINAL_TEXT>Es decir, que aceptan que es líquido, que es blanco, que sabe a leche, que huele a leche, que sirve para hacer queso, que procede de la vaca, pero que quien diga que es leche de vaca miente.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="3365" end_char="3366">Es</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="3368" end_char="3372">decir</TOKEN>
<TOKEN id="token-24-2" pos="punct" morph="none" start_char="3373" end_char="3373">,</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="3375" end_char="3377">que</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="3379" end_char="3385">aceptan</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="3387" end_char="3389">que</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="3391" end_char="3392">es</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="3394" end_char="3400">líquido</TOKEN>
<TOKEN id="token-24-8" pos="punct" morph="none" start_char="3401" end_char="3401">,</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="3403" end_char="3405">que</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="3407" end_char="3408">es</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="3410" end_char="3415">blanco</TOKEN>
<TOKEN id="token-24-12" pos="punct" morph="none" start_char="3416" end_char="3416">,</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="3418" end_char="3420">que</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="3422" end_char="3425">sabe</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="3427" end_char="3427">a</TOKEN>
<TOKEN id="token-24-16" pos="word" morph="none" start_char="3429" end_char="3433">leche</TOKEN>
<TOKEN id="token-24-17" pos="punct" morph="none" start_char="3434" end_char="3434">,</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="3436" end_char="3438">que</TOKEN>
<TOKEN id="token-24-19" pos="word" morph="none" start_char="3440" end_char="3444">huele</TOKEN>
<TOKEN id="token-24-20" pos="word" morph="none" start_char="3446" end_char="3446">a</TOKEN>
<TOKEN id="token-24-21" pos="word" morph="none" start_char="3448" end_char="3452">leche</TOKEN>
<TOKEN id="token-24-22" pos="punct" morph="none" start_char="3453" end_char="3453">,</TOKEN>
<TOKEN id="token-24-23" pos="word" morph="none" start_char="3455" end_char="3457">que</TOKEN>
<TOKEN id="token-24-24" pos="word" morph="none" start_char="3459" end_char="3463">sirve</TOKEN>
<TOKEN id="token-24-25" pos="word" morph="none" start_char="3465" end_char="3468">para</TOKEN>
<TOKEN id="token-24-26" pos="word" morph="none" start_char="3470" end_char="3474">hacer</TOKEN>
<TOKEN id="token-24-27" pos="word" morph="none" start_char="3476" end_char="3480">queso</TOKEN>
<TOKEN id="token-24-28" pos="punct" morph="none" start_char="3481" end_char="3481">,</TOKEN>
<TOKEN id="token-24-29" pos="word" morph="none" start_char="3483" end_char="3485">que</TOKEN>
<TOKEN id="token-24-30" pos="word" morph="none" start_char="3487" end_char="3493">procede</TOKEN>
<TOKEN id="token-24-31" pos="word" morph="none" start_char="3495" end_char="3496">de</TOKEN>
<TOKEN id="token-24-32" pos="word" morph="none" start_char="3498" end_char="3499">la</TOKEN>
<TOKEN id="token-24-33" pos="word" morph="none" start_char="3501" end_char="3504">vaca</TOKEN>
<TOKEN id="token-24-34" pos="punct" morph="none" start_char="3505" end_char="3505">,</TOKEN>
<TOKEN id="token-24-35" pos="word" morph="none" start_char="3507" end_char="3510">pero</TOKEN>
<TOKEN id="token-24-36" pos="word" morph="none" start_char="3512" end_char="3514">que</TOKEN>
<TOKEN id="token-24-37" pos="word" morph="none" start_char="3516" end_char="3520">quien</TOKEN>
<TOKEN id="token-24-38" pos="word" morph="none" start_char="3522" end_char="3525">diga</TOKEN>
<TOKEN id="token-24-39" pos="word" morph="none" start_char="3527" end_char="3529">que</TOKEN>
<TOKEN id="token-24-40" pos="word" morph="none" start_char="3531" end_char="3532">es</TOKEN>
<TOKEN id="token-24-41" pos="word" morph="none" start_char="3534" end_char="3538">leche</TOKEN>
<TOKEN id="token-24-42" pos="word" morph="none" start_char="3540" end_char="3541">de</TOKEN>
<TOKEN id="token-24-43" pos="word" morph="none" start_char="3543" end_char="3546">vaca</TOKEN>
<TOKEN id="token-24-44" pos="word" morph="none" start_char="3548" end_char="3553">miente</TOKEN>
<TOKEN id="token-24-45" pos="punct" morph="none" start_char="3554" end_char="3554">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="3556" end_char="3564">
<ORIGINAL_TEXT>Tal cual.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="3556" end_char="3558">Tal</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="3560" end_char="3563">cual</TOKEN>
<TOKEN id="token-25-2" pos="punct" morph="none" start_char="3564" end_char="3564">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="3566" end_char="3628">
<ORIGINAL_TEXT>Eso es lo que proponen esas censuras progresistas de pacotilla.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="3566" end_char="3568">Eso</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="3570" end_char="3571">es</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="3573" end_char="3574">lo</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="3576" end_char="3578">que</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="3580" end_char="3587">proponen</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="3589" end_char="3592">esas</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="3594" end_char="3601">censuras</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="3603" end_char="3614">progresistas</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="3616" end_char="3617">de</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="3619" end_char="3627">pacotilla</TOKEN>
<TOKEN id="token-26-10" pos="punct" morph="none" start_char="3628" end_char="3628">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="3630" end_char="3667">
<ORIGINAL_TEXT>Allá cada quien las entienda y acepte.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="3630" end_char="3633">Allá</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="3635" end_char="3638">cada</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="3640" end_char="3644">quien</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="3646" end_char="3648">las</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="3650" end_char="3657">entienda</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="3659" end_char="3659">y</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="3661" end_char="3666">acepte</TOKEN>
<TOKEN id="token-27-7" pos="punct" morph="none" start_char="3667" end_char="3667">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3669" end_char="3691">
<ORIGINAL_TEXT>Nosotros no lo hacemos.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="3669" end_char="3676">Nosotros</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="3678" end_char="3679">no</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="3681" end_char="3682">lo</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="3684" end_char="3690">hacemos</TOKEN>
<TOKEN id="token-28-4" pos="punct" morph="none" start_char="3691" end_char="3691">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3693" end_char="3819">
<ORIGINAL_TEXT>Por si les queda alguna duda, les ofrecemos el vídeo del, repetimos, extraordinariamente prestigioso programa oficial italiano.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="3693" end_char="3695">Por</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="3697" end_char="3698">si</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="3700" end_char="3702">les</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="3704" end_char="3708">queda</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="3710" end_char="3715">alguna</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="3717" end_char="3720">duda</TOKEN>
<TOKEN id="token-29-6" pos="punct" morph="none" start_char="3721" end_char="3721">,</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="3723" end_char="3725">les</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="3727" end_char="3735">ofrecemos</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="3737" end_char="3738">el</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="3740" end_char="3744">vídeo</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="3746" end_char="3748">del</TOKEN>
<TOKEN id="token-29-12" pos="punct" morph="none" start_char="3749" end_char="3749">,</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="3751" end_char="3759">repetimos</TOKEN>
<TOKEN id="token-29-14" pos="punct" morph="none" start_char="3760" end_char="3760">,</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="3762" end_char="3780">extraordinariamente</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="3782" end_char="3792">prestigioso</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="3794" end_char="3801">programa</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="3803" end_char="3809">oficial</TOKEN>
<TOKEN id="token-29-19" pos="word" morph="none" start_char="3811" end_char="3818">italiano</TOKEN>
<TOKEN id="token-29-20" pos="punct" morph="none" start_char="3819" end_char="3819">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3821" end_char="3943">
<ORIGINAL_TEXT>Si llegan a la misma conclusión que nosotros, y se sienten víctimas de un ataque con armamento biológico, no nos extrañará.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="3821" end_char="3822">Si</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="3824" end_char="3829">llegan</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="3831" end_char="3831">a</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="3833" end_char="3834">la</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="3836" end_char="3840">misma</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="3842" end_char="3851">conclusión</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="3853" end_char="3855">que</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="3857" end_char="3864">nosotros</TOKEN>
<TOKEN id="token-30-8" pos="punct" morph="none" start_char="3865" end_char="3865">,</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="3867" end_char="3867">y</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="3869" end_char="3870">se</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="3872" end_char="3878">sienten</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="3880" end_char="3887">víctimas</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="3889" end_char="3890">de</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="3892" end_char="3893">un</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="3895" end_char="3900">ataque</TOKEN>
<TOKEN id="token-30-16" pos="word" morph="none" start_char="3902" end_char="3904">con</TOKEN>
<TOKEN id="token-30-17" pos="word" morph="none" start_char="3906" end_char="3914">armamento</TOKEN>
<TOKEN id="token-30-18" pos="word" morph="none" start_char="3916" end_char="3924">biológico</TOKEN>
<TOKEN id="token-30-19" pos="punct" morph="none" start_char="3925" end_char="3925">,</TOKEN>
<TOKEN id="token-30-20" pos="word" morph="none" start_char="3927" end_char="3928">no</TOKEN>
<TOKEN id="token-30-21" pos="word" morph="none" start_char="3930" end_char="3932">nos</TOKEN>
<TOKEN id="token-30-22" pos="word" morph="none" start_char="3934" end_char="3942">extrañará</TOKEN>
<TOKEN id="token-30-23" pos="punct" morph="none" start_char="3943" end_char="3943">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="3945" end_char="4027">
<ORIGINAL_TEXT>LO QUE VAN A VER Y ESCUCHAR ES UN PROGRAMA DE TELEVISIÓN DE LA RAI EMITIDO EN 2015:</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="3945" end_char="3946">LO</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="3948" end_char="3950">QUE</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="3952" end_char="3954">VAN</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="3956" end_char="3956">A</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="3958" end_char="3960">VER</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="3962" end_char="3962">Y</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="3964" end_char="3971">ESCUCHAR</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="3973" end_char="3974">ES</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="3976" end_char="3977">UN</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="3979" end_char="3986">PROGRAMA</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="3988" end_char="3989">DE</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="3991" end_char="4000">TELEVISIÓN</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="4002" end_char="4003">DE</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="4005" end_char="4006">LA</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="4008" end_char="4010">RAI</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="4012" end_char="4018">EMITIDO</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="4020" end_char="4021">EN</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="4023" end_char="4026">2015</TOKEN>
<TOKEN id="token-31-18" pos="punct" morph="none" start_char="4027" end_char="4027">:</TOKEN>
</SEG>
<SEG id="segment-32" start_char="4031" end_char="4048">
<ORIGINAL_TEXT>Que hijos de puta.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="4031" end_char="4033">Que</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="4035" end_char="4039">hijos</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="4041" end_char="4042">de</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="4044" end_char="4047">puta</TOKEN>
<TOKEN id="token-32-4" pos="punct" morph="none" start_char="4048" end_char="4048">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="4050" end_char="4100">
<ORIGINAL_TEXT>Lo ha traducido " el disidente"_"quién está detrás"</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="4050" end_char="4051">Lo</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="4053" end_char="4054">ha</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="4056" end_char="4064">traducido</TOKEN>
<TOKEN id="token-33-3" pos="punct" morph="none" start_char="4066" end_char="4066">"</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="4068" end_char="4069">el</TOKEN>
<TOKEN id="token-33-5" pos="unknown" morph="none" start_char="4071" end_char="4087">disidente"_"quién</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="4089" end_char="4092">está</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="4094" end_char="4099">detrás</TOKEN>
<TOKEN id="token-33-8" pos="punct" morph="none" start_char="4100" end_char="4100">"</TOKEN>
</SEG>
<SEG id="segment-34" start_char="4103" end_char="4129">
<ORIGINAL_TEXT>YA NO PONDREMOS MÁS FUENTES</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="4103" end_char="4104">YA</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="4106" end_char="4107">NO</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="4109" end_char="4117">PONDREMOS</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="4119" end_char="4121">MÁS</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="4123" end_char="4129">FUENTES</TOKEN>
</SEG>
<SEG id="segment-35" start_char="4133" end_char="4163">
<ORIGINAL_TEXT>Si es que sois tontos del culo.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="4133" end_char="4134">Si</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="4136" end_char="4137">es</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="4139" end_char="4141">que</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="4143" end_char="4146">sois</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="4148" end_char="4153">tontos</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="4155" end_char="4157">del</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="4159" end_char="4162">culo</TOKEN>
<TOKEN id="token-35-7" pos="punct" morph="none" start_char="4163" end_char="4163">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="4165" end_char="4196">
<ORIGINAL_TEXT>El único que se salva es samael.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="4165" end_char="4166">El</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="4168" end_char="4172">único</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="4174" end_char="4176">que</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="4178" end_char="4179">se</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="4181" end_char="4185">salva</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="4187" end_char="4188">es</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="4190" end_char="4195">samael</TOKEN>
<TOKEN id="token-36-7" pos="punct" morph="none" start_char="4196" end_char="4196">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="4198" end_char="4228">
<ORIGINAL_TEXT>No existe la disidencia ni Dios</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="4198" end_char="4199">No</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="4201" end_char="4206">existe</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="4208" end_char="4209">la</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="4211" end_char="4220">disidencia</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="4222" end_char="4223">ni</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="4225" end_char="4228">Dios</TOKEN>
</SEG>
<SEG id="segment-38" start_char="4233" end_char="4262">
<ORIGINAL_TEXT>El Disidente 5310 suscriptores</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="4233" end_char="4234">El</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="4236" end_char="4244">Disidente</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="4246" end_char="4249">5310</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="4251" end_char="4262">suscriptores</TOKEN>
</SEG>
<SEG id="segment-39" start_char="4265" end_char="4272">
<ORIGINAL_TEXT>SUSCRITO</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="4265" end_char="4272">SUSCRITO</TOKEN>
</SEG>
<SEG id="segment-40" start_char="4275" end_char="4563">
<ORIGINAL_TEXT>Un programa de la televisión pública italiana RAI 3 especializado en información científica contó en el año 2015 el "logro" de unos científicos chinos que habían conseguido modificar el virus del SARS para que pudiera transmitirse de murciélagos a humanos y afectar sus vías respiratorias.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="4275" end_char="4276">Un</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="4278" end_char="4285">programa</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="4287" end_char="4288">de</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="4290" end_char="4291">la</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="4293" end_char="4302">televisión</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="4304" end_char="4310">pública</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="4312" end_char="4319">italiana</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="4321" end_char="4323">RAI</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="4325" end_char="4325">3</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="4327" end_char="4339">especializado</TOKEN>
<TOKEN id="token-40-10" pos="word" morph="none" start_char="4341" end_char="4342">en</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="4344" end_char="4354">información</TOKEN>
<TOKEN id="token-40-12" pos="word" morph="none" start_char="4356" end_char="4365">científica</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="4367" end_char="4371">contó</TOKEN>
<TOKEN id="token-40-14" pos="word" morph="none" start_char="4373" end_char="4374">en</TOKEN>
<TOKEN id="token-40-15" pos="word" morph="none" start_char="4376" end_char="4377">el</TOKEN>
<TOKEN id="token-40-16" pos="word" morph="none" start_char="4379" end_char="4381">año</TOKEN>
<TOKEN id="token-40-17" pos="word" morph="none" start_char="4383" end_char="4386">2015</TOKEN>
<TOKEN id="token-40-18" pos="word" morph="none" start_char="4388" end_char="4389">el</TOKEN>
<TOKEN id="token-40-19" pos="punct" morph="none" start_char="4391" end_char="4391">"</TOKEN>
<TOKEN id="token-40-20" pos="word" morph="none" start_char="4392" end_char="4396">logro</TOKEN>
<TOKEN id="token-40-21" pos="punct" morph="none" start_char="4397" end_char="4397">"</TOKEN>
<TOKEN id="token-40-22" pos="word" morph="none" start_char="4399" end_char="4400">de</TOKEN>
<TOKEN id="token-40-23" pos="word" morph="none" start_char="4402" end_char="4405">unos</TOKEN>
<TOKEN id="token-40-24" pos="word" morph="none" start_char="4407" end_char="4417">científicos</TOKEN>
<TOKEN id="token-40-25" pos="word" morph="none" start_char="4419" end_char="4424">chinos</TOKEN>
<TOKEN id="token-40-26" pos="word" morph="none" start_char="4426" end_char="4428">que</TOKEN>
<TOKEN id="token-40-27" pos="word" morph="none" start_char="4430" end_char="4435">habían</TOKEN>
<TOKEN id="token-40-28" pos="word" morph="none" start_char="4437" end_char="4446">conseguido</TOKEN>
<TOKEN id="token-40-29" pos="word" morph="none" start_char="4448" end_char="4456">modificar</TOKEN>
<TOKEN id="token-40-30" pos="word" morph="none" start_char="4458" end_char="4459">el</TOKEN>
<TOKEN id="token-40-31" pos="word" morph="none" start_char="4461" end_char="4465">virus</TOKEN>
<TOKEN id="token-40-32" pos="word" morph="none" start_char="4467" end_char="4469">del</TOKEN>
<TOKEN id="token-40-33" pos="word" morph="none" start_char="4471" end_char="4474">SARS</TOKEN>
<TOKEN id="token-40-34" pos="word" morph="none" start_char="4476" end_char="4479">para</TOKEN>
<TOKEN id="token-40-35" pos="word" morph="none" start_char="4481" end_char="4483">que</TOKEN>
<TOKEN id="token-40-36" pos="word" morph="none" start_char="4485" end_char="4491">pudiera</TOKEN>
<TOKEN id="token-40-37" pos="word" morph="none" start_char="4493" end_char="4504">transmitirse</TOKEN>
<TOKEN id="token-40-38" pos="word" morph="none" start_char="4506" end_char="4507">de</TOKEN>
<TOKEN id="token-40-39" pos="word" morph="none" start_char="4509" end_char="4519">murciélagos</TOKEN>
<TOKEN id="token-40-40" pos="word" morph="none" start_char="4521" end_char="4521">a</TOKEN>
<TOKEN id="token-40-41" pos="word" morph="none" start_char="4523" end_char="4529">humanos</TOKEN>
<TOKEN id="token-40-42" pos="word" morph="none" start_char="4531" end_char="4531">y</TOKEN>
<TOKEN id="token-40-43" pos="word" morph="none" start_char="4533" end_char="4539">afectar</TOKEN>
<TOKEN id="token-40-44" pos="word" morph="none" start_char="4541" end_char="4543">sus</TOKEN>
<TOKEN id="token-40-45" pos="word" morph="none" start_char="4545" end_char="4548">vías</TOKEN>
<TOKEN id="token-40-46" pos="word" morph="none" start_char="4550" end_char="4562">respiratorias</TOKEN>
<TOKEN id="token-40-47" pos="punct" morph="none" start_char="4563" end_char="4563">.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="4565" end_char="4582">
<ORIGINAL_TEXT>¿Te suena de algo?</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="punct" morph="none" start_char="4565" end_char="4565">¿</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="4566" end_char="4567">Te</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="4569" end_char="4573">suena</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="4575" end_char="4576">de</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="4578" end_char="4581">algo</TOKEN>
<TOKEN id="token-41-5" pos="punct" morph="none" start_char="4582" end_char="4582">?</TOKEN>
</SEG>
<SEG id="segment-42" start_char="4584" end_char="4652">
<ORIGINAL_TEXT>Traducido al castellano por un servidor y subtitulado por Jedimálaga.</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="4584" end_char="4592">Traducido</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="4594" end_char="4595">al</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="4597" end_char="4606">castellano</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="4608" end_char="4610">por</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="4612" end_char="4613">un</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="4615" end_char="4622">servidor</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="4624" end_char="4624">y</TOKEN>
<TOKEN id="token-42-7" pos="word" morph="none" start_char="4626" end_char="4636">subtitulado</TOKEN>
<TOKEN id="token-42-8" pos="word" morph="none" start_char="4638" end_char="4640">por</TOKEN>
<TOKEN id="token-42-9" pos="word" morph="none" start_char="4642" end_char="4651">Jedimálaga</TOKEN>
<TOKEN id="token-42-10" pos="punct" morph="none" start_char="4652" end_char="4652">.</TOKEN>
</SEG>
<SEG id="segment-43" start_char="4656" end_char="4776">
<ORIGINAL_TEXT>Ahí dice que ese video es de 2005, pero bien podría ser un FAKE creado ahora, pues ese video lo suberon a youtube ayer, y</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="4656" end_char="4658">Ahí</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="4660" end_char="4663">dice</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="4665" end_char="4667">que</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="4669" end_char="4671">ese</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="4673" end_char="4677">video</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="4679" end_char="4680">es</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="4682" end_char="4683">de</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="4685" end_char="4688">2005</TOKEN>
<TOKEN id="token-43-8" pos="punct" morph="none" start_char="4689" end_char="4689">,</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="4691" end_char="4694">pero</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="4696" end_char="4699">bien</TOKEN>
<TOKEN id="token-43-11" pos="word" morph="none" start_char="4701" end_char="4706">podría</TOKEN>
<TOKEN id="token-43-12" pos="word" morph="none" start_char="4708" end_char="4710">ser</TOKEN>
<TOKEN id="token-43-13" pos="word" morph="none" start_char="4712" end_char="4713">un</TOKEN>
<TOKEN id="token-43-14" pos="word" morph="none" start_char="4715" end_char="4718">FAKE</TOKEN>
<TOKEN id="token-43-15" pos="word" morph="none" start_char="4720" end_char="4725">creado</TOKEN>
<TOKEN id="token-43-16" pos="word" morph="none" start_char="4727" end_char="4731">ahora</TOKEN>
<TOKEN id="token-43-17" pos="punct" morph="none" start_char="4732" end_char="4732">,</TOKEN>
<TOKEN id="token-43-18" pos="word" morph="none" start_char="4734" end_char="4737">pues</TOKEN>
<TOKEN id="token-43-19" pos="word" morph="none" start_char="4739" end_char="4741">ese</TOKEN>
<TOKEN id="token-43-20" pos="word" morph="none" start_char="4743" end_char="4747">video</TOKEN>
<TOKEN id="token-43-21" pos="word" morph="none" start_char="4749" end_char="4750">lo</TOKEN>
<TOKEN id="token-43-22" pos="word" morph="none" start_char="4752" end_char="4758">suberon</TOKEN>
<TOKEN id="token-43-23" pos="word" morph="none" start_char="4760" end_char="4760">a</TOKEN>
<TOKEN id="token-43-24" pos="word" morph="none" start_char="4762" end_char="4768">youtube</TOKEN>
<TOKEN id="token-43-25" pos="word" morph="none" start_char="4770" end_char="4773">ayer</TOKEN>
<TOKEN id="token-43-26" pos="punct" morph="none" start_char="4774" end_char="4774">,</TOKEN>
<TOKEN id="token-43-27" pos="word" morph="none" start_char="4776" end_char="4776">y</TOKEN>
</SEG>
<SEG id="segment-44" start_char="4779" end_char="4816">
<ORIGINAL_TEXT>No digo que lo sea, pero podría serlo.</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="4779" end_char="4780">No</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="4782" end_char="4785">digo</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="4787" end_char="4789">que</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="4791" end_char="4792">lo</TOKEN>
<TOKEN id="token-44-4" pos="word" morph="none" start_char="4794" end_char="4796">sea</TOKEN>
<TOKEN id="token-44-5" pos="punct" morph="none" start_char="4797" end_char="4797">,</TOKEN>
<TOKEN id="token-44-6" pos="word" morph="none" start_char="4799" end_char="4802">pero</TOKEN>
<TOKEN id="token-44-7" pos="word" morph="none" start_char="4804" end_char="4809">podría</TOKEN>
<TOKEN id="token-44-8" pos="word" morph="none" start_char="4811" end_char="4815">serlo</TOKEN>
<TOKEN id="token-44-9" pos="punct" morph="none" start_char="4816" end_char="4816">.</TOKEN>
</SEG>
<SEG id="segment-45" start_char="4821" end_char="4936">
<ORIGINAL_TEXT>ikergutierrez dijo: Es totalmente falso, lo que han dicho varios medios, de que no se puede crear en un laboratorio.</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="4821" end_char="4833">ikergutierrez</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="4835" end_char="4838">dijo</TOKEN>
<TOKEN id="token-45-2" pos="punct" morph="none" start_char="4839" end_char="4839">:</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="4841" end_char="4842">Es</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="4844" end_char="4853">totalmente</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="4855" end_char="4859">falso</TOKEN>
<TOKEN id="token-45-6" pos="punct" morph="none" start_char="4860" end_char="4860">,</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="4862" end_char="4863">lo</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="4865" end_char="4867">que</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="4869" end_char="4871">han</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="4873" end_char="4877">dicho</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="4879" end_char="4884">varios</TOKEN>
<TOKEN id="token-45-12" pos="word" morph="none" start_char="4886" end_char="4891">medios</TOKEN>
<TOKEN id="token-45-13" pos="punct" morph="none" start_char="4892" end_char="4892">,</TOKEN>
<TOKEN id="token-45-14" pos="word" morph="none" start_char="4894" end_char="4895">de</TOKEN>
<TOKEN id="token-45-15" pos="word" morph="none" start_char="4897" end_char="4899">que</TOKEN>
<TOKEN id="token-45-16" pos="word" morph="none" start_char="4901" end_char="4902">no</TOKEN>
<TOKEN id="token-45-17" pos="word" morph="none" start_char="4904" end_char="4905">se</TOKEN>
<TOKEN id="token-45-18" pos="word" morph="none" start_char="4907" end_char="4911">puede</TOKEN>
<TOKEN id="token-45-19" pos="word" morph="none" start_char="4913" end_char="4917">crear</TOKEN>
<TOKEN id="token-45-20" pos="word" morph="none" start_char="4919" end_char="4920">en</TOKEN>
<TOKEN id="token-45-21" pos="word" morph="none" start_char="4922" end_char="4923">un</TOKEN>
<TOKEN id="token-45-22" pos="word" morph="none" start_char="4925" end_char="4935">laboratorio</TOKEN>
<TOKEN id="token-45-23" pos="punct" morph="none" start_char="4936" end_char="4936">.</TOKEN>
</SEG>
<SEG id="segment-46" start_char="4938" end_char="4997">
<ORIGINAL_TEXT>Se puede, se ha hecho y cada vez lo podran hacer mas paises.</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="4938" end_char="4939">Se</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="4941" end_char="4945">puede</TOKEN>
<TOKEN id="token-46-2" pos="punct" morph="none" start_char="4946" end_char="4946">,</TOKEN>
<TOKEN id="token-46-3" pos="word" morph="none" start_char="4948" end_char="4949">se</TOKEN>
<TOKEN id="token-46-4" pos="word" morph="none" start_char="4951" end_char="4952">ha</TOKEN>
<TOKEN id="token-46-5" pos="word" morph="none" start_char="4954" end_char="4958">hecho</TOKEN>
<TOKEN id="token-46-6" pos="word" morph="none" start_char="4960" end_char="4960">y</TOKEN>
<TOKEN id="token-46-7" pos="word" morph="none" start_char="4962" end_char="4965">cada</TOKEN>
<TOKEN id="token-46-8" pos="word" morph="none" start_char="4967" end_char="4969">vez</TOKEN>
<TOKEN id="token-46-9" pos="word" morph="none" start_char="4971" end_char="4972">lo</TOKEN>
<TOKEN id="token-46-10" pos="word" morph="none" start_char="4974" end_char="4979">podran</TOKEN>
<TOKEN id="token-46-11" pos="word" morph="none" start_char="4981" end_char="4985">hacer</TOKEN>
<TOKEN id="token-46-12" pos="word" morph="none" start_char="4987" end_char="4989">mas</TOKEN>
<TOKEN id="token-46-13" pos="word" morph="none" start_char="4991" end_char="4996">paises</TOKEN>
<TOKEN id="token-46-14" pos="punct" morph="none" start_char="4997" end_char="4997">.</TOKEN>
</SEG>
<SEG id="segment-47" start_char="5000" end_char="5222">
<ORIGINAL_TEXT>El youtuber de date un vloj puso un vídeo de un experto y decía que para manipular el virus y no dejar huella de la manipulación, tendrían que inventar otro sistema matemático para que los científicos no puedan descubrirlo.</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="5000" end_char="5001">El</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="5003" end_char="5010">youtuber</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="5012" end_char="5013">de</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="5015" end_char="5018">date</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="5020" end_char="5021">un</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="5023" end_char="5026">vloj</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="5028" end_char="5031">puso</TOKEN>
<TOKEN id="token-47-7" pos="word" morph="none" start_char="5033" end_char="5034">un</TOKEN>
<TOKEN id="token-47-8" pos="word" morph="none" start_char="5036" end_char="5040">vídeo</TOKEN>
<TOKEN id="token-47-9" pos="word" morph="none" start_char="5042" end_char="5043">de</TOKEN>
<TOKEN id="token-47-10" pos="word" morph="none" start_char="5045" end_char="5046">un</TOKEN>
<TOKEN id="token-47-11" pos="word" morph="none" start_char="5048" end_char="5054">experto</TOKEN>
<TOKEN id="token-47-12" pos="word" morph="none" start_char="5056" end_char="5056">y</TOKEN>
<TOKEN id="token-47-13" pos="word" morph="none" start_char="5058" end_char="5062">decía</TOKEN>
<TOKEN id="token-47-14" pos="word" morph="none" start_char="5064" end_char="5066">que</TOKEN>
<TOKEN id="token-47-15" pos="word" morph="none" start_char="5068" end_char="5071">para</TOKEN>
<TOKEN id="token-47-16" pos="word" morph="none" start_char="5073" end_char="5081">manipular</TOKEN>
<TOKEN id="token-47-17" pos="word" morph="none" start_char="5083" end_char="5084">el</TOKEN>
<TOKEN id="token-47-18" pos="word" morph="none" start_char="5086" end_char="5090">virus</TOKEN>
<TOKEN id="token-47-19" pos="word" morph="none" start_char="5092" end_char="5092">y</TOKEN>
<TOKEN id="token-47-20" pos="word" morph="none" start_char="5094" end_char="5095">no</TOKEN>
<TOKEN id="token-47-21" pos="word" morph="none" start_char="5097" end_char="5101">dejar</TOKEN>
<TOKEN id="token-47-22" pos="word" morph="none" start_char="5103" end_char="5108">huella</TOKEN>
<TOKEN id="token-47-23" pos="word" morph="none" start_char="5110" end_char="5111">de</TOKEN>
<TOKEN id="token-47-24" pos="word" morph="none" start_char="5113" end_char="5114">la</TOKEN>
<TOKEN id="token-47-25" pos="word" morph="none" start_char="5116" end_char="5127">manipulación</TOKEN>
<TOKEN id="token-47-26" pos="punct" morph="none" start_char="5128" end_char="5128">,</TOKEN>
<TOKEN id="token-47-27" pos="word" morph="none" start_char="5130" end_char="5137">tendrían</TOKEN>
<TOKEN id="token-47-28" pos="word" morph="none" start_char="5139" end_char="5141">que</TOKEN>
<TOKEN id="token-47-29" pos="word" morph="none" start_char="5143" end_char="5150">inventar</TOKEN>
<TOKEN id="token-47-30" pos="word" morph="none" start_char="5152" end_char="5155">otro</TOKEN>
<TOKEN id="token-47-31" pos="word" morph="none" start_char="5157" end_char="5163">sistema</TOKEN>
<TOKEN id="token-47-32" pos="word" morph="none" start_char="5165" end_char="5174">matemático</TOKEN>
<TOKEN id="token-47-33" pos="word" morph="none" start_char="5176" end_char="5179">para</TOKEN>
<TOKEN id="token-47-34" pos="word" morph="none" start_char="5181" end_char="5183">que</TOKEN>
<TOKEN id="token-47-35" pos="word" morph="none" start_char="5185" end_char="5187">los</TOKEN>
<TOKEN id="token-47-36" pos="word" morph="none" start_char="5189" end_char="5199">científicos</TOKEN>
<TOKEN id="token-47-37" pos="word" morph="none" start_char="5201" end_char="5202">no</TOKEN>
<TOKEN id="token-47-38" pos="word" morph="none" start_char="5204" end_char="5209">puedan</TOKEN>
<TOKEN id="token-47-39" pos="word" morph="none" start_char="5211" end_char="5221">descubrirlo</TOKEN>
<TOKEN id="token-47-40" pos="punct" morph="none" start_char="5222" end_char="5222">.</TOKEN>
</SEG>
<SEG id="segment-48" start_char="5224" end_char="5252">
<ORIGINAL_TEXT>Éste no está manipulado dijo.</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="5224" end_char="5227">Éste</TOKEN>
<TOKEN id="token-48-1" pos="word" morph="none" start_char="5229" end_char="5230">no</TOKEN>
<TOKEN id="token-48-2" pos="word" morph="none" start_char="5232" end_char="5235">está</TOKEN>
<TOKEN id="token-48-3" pos="word" morph="none" start_char="5237" end_char="5246">manipulado</TOKEN>
<TOKEN id="token-48-4" pos="word" morph="none" start_char="5248" end_char="5251">dijo</TOKEN>
<TOKEN id="token-48-5" pos="punct" morph="none" start_char="5252" end_char="5252">.</TOKEN>
</SEG>
<SEG id="segment-49" start_char="5254" end_char="5276">
<ORIGINAL_TEXT>Lamento joderos el hilo</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="5254" end_char="5260">Lamento</TOKEN>
<TOKEN id="token-49-1" pos="word" morph="none" start_char="5262" end_char="5268">joderos</TOKEN>
<TOKEN id="token-49-2" pos="word" morph="none" start_char="5270" end_char="5271">el</TOKEN>
<TOKEN id="token-49-3" pos="word" morph="none" start_char="5273" end_char="5276">hilo</TOKEN>
</SEG>
<SEG id="segment-50" start_char="5282" end_char="5522">
<ORIGINAL_TEXT>sabia bruta dijo: El youtuber de date un vloj puso un vídeo de un experto y decía que para manipular el virus y no dejar huella de la manipulación, tendrían que inventar otro sistema matemático para que los científicos no puedan descubrirlo.</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="5282" end_char="5286">sabia</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="5288" end_char="5292">bruta</TOKEN>
<TOKEN id="token-50-2" pos="word" morph="none" start_char="5294" end_char="5297">dijo</TOKEN>
<TOKEN id="token-50-3" pos="punct" morph="none" start_char="5298" end_char="5298">:</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="5300" end_char="5301">El</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="5303" end_char="5310">youtuber</TOKEN>
<TOKEN id="token-50-6" pos="word" morph="none" start_char="5312" end_char="5313">de</TOKEN>
<TOKEN id="token-50-7" pos="word" morph="none" start_char="5315" end_char="5318">date</TOKEN>
<TOKEN id="token-50-8" pos="word" morph="none" start_char="5320" end_char="5321">un</TOKEN>
<TOKEN id="token-50-9" pos="word" morph="none" start_char="5323" end_char="5326">vloj</TOKEN>
<TOKEN id="token-50-10" pos="word" morph="none" start_char="5328" end_char="5331">puso</TOKEN>
<TOKEN id="token-50-11" pos="word" morph="none" start_char="5333" end_char="5334">un</TOKEN>
<TOKEN id="token-50-12" pos="word" morph="none" start_char="5336" end_char="5340">vídeo</TOKEN>
<TOKEN id="token-50-13" pos="word" morph="none" start_char="5342" end_char="5343">de</TOKEN>
<TOKEN id="token-50-14" pos="word" morph="none" start_char="5345" end_char="5346">un</TOKEN>
<TOKEN id="token-50-15" pos="word" morph="none" start_char="5348" end_char="5354">experto</TOKEN>
<TOKEN id="token-50-16" pos="word" morph="none" start_char="5356" end_char="5356">y</TOKEN>
<TOKEN id="token-50-17" pos="word" morph="none" start_char="5358" end_char="5362">decía</TOKEN>
<TOKEN id="token-50-18" pos="word" morph="none" start_char="5364" end_char="5366">que</TOKEN>
<TOKEN id="token-50-19" pos="word" morph="none" start_char="5368" end_char="5371">para</TOKEN>
<TOKEN id="token-50-20" pos="word" morph="none" start_char="5373" end_char="5381">manipular</TOKEN>
<TOKEN id="token-50-21" pos="word" morph="none" start_char="5383" end_char="5384">el</TOKEN>
<TOKEN id="token-50-22" pos="word" morph="none" start_char="5386" end_char="5390">virus</TOKEN>
<TOKEN id="token-50-23" pos="word" morph="none" start_char="5392" end_char="5392">y</TOKEN>
<TOKEN id="token-50-24" pos="word" morph="none" start_char="5394" end_char="5395">no</TOKEN>
<TOKEN id="token-50-25" pos="word" morph="none" start_char="5397" end_char="5401">dejar</TOKEN>
<TOKEN id="token-50-26" pos="word" morph="none" start_char="5403" end_char="5408">huella</TOKEN>
<TOKEN id="token-50-27" pos="word" morph="none" start_char="5410" end_char="5411">de</TOKEN>
<TOKEN id="token-50-28" pos="word" morph="none" start_char="5413" end_char="5414">la</TOKEN>
<TOKEN id="token-50-29" pos="word" morph="none" start_char="5416" end_char="5427">manipulación</TOKEN>
<TOKEN id="token-50-30" pos="punct" morph="none" start_char="5428" end_char="5428">,</TOKEN>
<TOKEN id="token-50-31" pos="word" morph="none" start_char="5430" end_char="5437">tendrían</TOKEN>
<TOKEN id="token-50-32" pos="word" morph="none" start_char="5439" end_char="5441">que</TOKEN>
<TOKEN id="token-50-33" pos="word" morph="none" start_char="5443" end_char="5450">inventar</TOKEN>
<TOKEN id="token-50-34" pos="word" morph="none" start_char="5452" end_char="5455">otro</TOKEN>
<TOKEN id="token-50-35" pos="word" morph="none" start_char="5457" end_char="5463">sistema</TOKEN>
<TOKEN id="token-50-36" pos="word" morph="none" start_char="5465" end_char="5474">matemático</TOKEN>
<TOKEN id="token-50-37" pos="word" morph="none" start_char="5476" end_char="5479">para</TOKEN>
<TOKEN id="token-50-38" pos="word" morph="none" start_char="5481" end_char="5483">que</TOKEN>
<TOKEN id="token-50-39" pos="word" morph="none" start_char="5485" end_char="5487">los</TOKEN>
<TOKEN id="token-50-40" pos="word" morph="none" start_char="5489" end_char="5499">científicos</TOKEN>
<TOKEN id="token-50-41" pos="word" morph="none" start_char="5501" end_char="5502">no</TOKEN>
<TOKEN id="token-50-42" pos="word" morph="none" start_char="5504" end_char="5509">puedan</TOKEN>
<TOKEN id="token-50-43" pos="word" morph="none" start_char="5511" end_char="5521">descubrirlo</TOKEN>
<TOKEN id="token-50-44" pos="punct" morph="none" start_char="5522" end_char="5522">.</TOKEN>
</SEG>
<SEG id="segment-51" start_char="5524" end_char="5552">
<ORIGINAL_TEXT>Éste no está manipulado dijo.</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="word" morph="none" start_char="5524" end_char="5527">Éste</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="5529" end_char="5530">no</TOKEN>
<TOKEN id="token-51-2" pos="word" morph="none" start_char="5532" end_char="5535">está</TOKEN>
<TOKEN id="token-51-3" pos="word" morph="none" start_char="5537" end_char="5546">manipulado</TOKEN>
<TOKEN id="token-51-4" pos="word" morph="none" start_char="5548" end_char="5551">dijo</TOKEN>
<TOKEN id="token-51-5" pos="punct" morph="none" start_char="5552" end_char="5552">.</TOKEN>
</SEG>
<SEG id="segment-52" start_char="5554" end_char="5576">
<ORIGINAL_TEXT>Lamento joderos el hilo</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="5554" end_char="5560">Lamento</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="5562" end_char="5568">joderos</TOKEN>
<TOKEN id="token-52-2" pos="word" morph="none" start_char="5570" end_char="5571">el</TOKEN>
<TOKEN id="token-52-3" pos="word" morph="none" start_char="5573" end_char="5576">hilo</TOKEN>
</SEG>
<SEG id="segment-53" start_char="5579" end_char="5631">
<ORIGINAL_TEXT>Con todos mis respetos, eso me parece una gilipollez.</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="word" morph="none" start_char="5579" end_char="5581">Con</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="5583" end_char="5587">todos</TOKEN>
<TOKEN id="token-53-2" pos="word" morph="none" start_char="5589" end_char="5591">mis</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="5593" end_char="5600">respetos</TOKEN>
<TOKEN id="token-53-4" pos="punct" morph="none" start_char="5601" end_char="5601">,</TOKEN>
<TOKEN id="token-53-5" pos="word" morph="none" start_char="5603" end_char="5605">eso</TOKEN>
<TOKEN id="token-53-6" pos="word" morph="none" start_char="5607" end_char="5608">me</TOKEN>
<TOKEN id="token-53-7" pos="word" morph="none" start_char="5610" end_char="5615">parece</TOKEN>
<TOKEN id="token-53-8" pos="word" morph="none" start_char="5617" end_char="5619">una</TOKEN>
<TOKEN id="token-53-9" pos="word" morph="none" start_char="5621" end_char="5630">gilipollez</TOKEN>
<TOKEN id="token-53-10" pos="punct" morph="none" start_char="5631" end_char="5631">.</TOKEN>
</SEG>
<SEG id="segment-54" start_char="5633" end_char="5679">
<ORIGINAL_TEXT>Hoy en día hay tecnología hast para hacer esto:</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="word" morph="none" start_char="5633" end_char="5635">Hoy</TOKEN>
<TOKEN id="token-54-1" pos="word" morph="none" start_char="5637" end_char="5638">en</TOKEN>
<TOKEN id="token-54-2" pos="word" morph="none" start_char="5640" end_char="5642">día</TOKEN>
<TOKEN id="token-54-3" pos="word" morph="none" start_char="5644" end_char="5646">hay</TOKEN>
<TOKEN id="token-54-4" pos="word" morph="none" start_char="5648" end_char="5657">tecnología</TOKEN>
<TOKEN id="token-54-5" pos="word" morph="none" start_char="5659" end_char="5662">hast</TOKEN>
<TOKEN id="token-54-6" pos="word" morph="none" start_char="5664" end_char="5667">para</TOKEN>
<TOKEN id="token-54-7" pos="word" morph="none" start_char="5669" end_char="5673">hacer</TOKEN>
<TOKEN id="token-54-8" pos="word" morph="none" start_char="5675" end_char="5678">esto</TOKEN>
<TOKEN id="token-54-9" pos="punct" morph="none" start_char="5679" end_char="5679">:</TOKEN>
</SEG>
<SEG id="segment-55" start_char="5683" end_char="5803">
<ORIGINAL_TEXT>Eso que ves es una animación stop/motion realizada por IBM, hecha movieondo ÁTOMOS uno a uno entre fotograma y fotograma.</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="word" morph="none" start_char="5683" end_char="5685">Eso</TOKEN>
<TOKEN id="token-55-1" pos="word" morph="none" start_char="5687" end_char="5689">que</TOKEN>
<TOKEN id="token-55-2" pos="word" morph="none" start_char="5691" end_char="5693">ves</TOKEN>
<TOKEN id="token-55-3" pos="word" morph="none" start_char="5695" end_char="5696">es</TOKEN>
<TOKEN id="token-55-4" pos="word" morph="none" start_char="5698" end_char="5700">una</TOKEN>
<TOKEN id="token-55-5" pos="word" morph="none" start_char="5702" end_char="5710">animación</TOKEN>
<TOKEN id="token-55-6" pos="unknown" morph="none" start_char="5712" end_char="5722">stop/motion</TOKEN>
<TOKEN id="token-55-7" pos="word" morph="none" start_char="5724" end_char="5732">realizada</TOKEN>
<TOKEN id="token-55-8" pos="word" morph="none" start_char="5734" end_char="5736">por</TOKEN>
<TOKEN id="token-55-9" pos="word" morph="none" start_char="5738" end_char="5740">IBM</TOKEN>
<TOKEN id="token-55-10" pos="punct" morph="none" start_char="5741" end_char="5741">,</TOKEN>
<TOKEN id="token-55-11" pos="word" morph="none" start_char="5743" end_char="5747">hecha</TOKEN>
<TOKEN id="token-55-12" pos="word" morph="none" start_char="5749" end_char="5757">movieondo</TOKEN>
<TOKEN id="token-55-13" pos="word" morph="none" start_char="5759" end_char="5764">ÁTOMOS</TOKEN>
<TOKEN id="token-55-14" pos="word" morph="none" start_char="5766" end_char="5768">uno</TOKEN>
<TOKEN id="token-55-15" pos="word" morph="none" start_char="5770" end_char="5770">a</TOKEN>
<TOKEN id="token-55-16" pos="word" morph="none" start_char="5772" end_char="5774">uno</TOKEN>
<TOKEN id="token-55-17" pos="word" morph="none" start_char="5776" end_char="5780">entre</TOKEN>
<TOKEN id="token-55-18" pos="word" morph="none" start_char="5782" end_char="5790">fotograma</TOKEN>
<TOKEN id="token-55-19" pos="word" morph="none" start_char="5792" end_char="5792">y</TOKEN>
<TOKEN id="token-55-20" pos="word" morph="none" start_char="5794" end_char="5802">fotograma</TOKEN>
<TOKEN id="token-55-21" pos="punct" morph="none" start_char="5803" end_char="5803">.</TOKEN>
</SEG>
<SEG id="segment-56" start_char="5808" end_char="5827">
<ORIGINAL_TEXT>Eso dijo el experto.</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="5808" end_char="5810">Eso</TOKEN>
<TOKEN id="token-56-1" pos="word" morph="none" start_char="5812" end_char="5815">dijo</TOKEN>
<TOKEN id="token-56-2" pos="word" morph="none" start_char="5817" end_char="5818">el</TOKEN>
<TOKEN id="token-56-3" pos="word" morph="none" start_char="5820" end_char="5826">experto</TOKEN>
<TOKEN id="token-56-4" pos="punct" morph="none" start_char="5827" end_char="5827">.</TOKEN>
</SEG>
<SEG id="segment-57" start_char="5829" end_char="5858">
<ORIGINAL_TEXT>Voy a buscarlo a ver si lo veo</ORIGINAL_TEXT>
<TOKEN id="token-57-0" pos="word" morph="none" start_char="5829" end_char="5831">Voy</TOKEN>
<TOKEN id="token-57-1" pos="word" morph="none" start_char="5833" end_char="5833">a</TOKEN>
<TOKEN id="token-57-2" pos="word" morph="none" start_char="5835" end_char="5842">buscarlo</TOKEN>
<TOKEN id="token-57-3" pos="word" morph="none" start_char="5844" end_char="5844">a</TOKEN>
<TOKEN id="token-57-4" pos="word" morph="none" start_char="5846" end_char="5848">ver</TOKEN>
<TOKEN id="token-57-5" pos="word" morph="none" start_char="5850" end_char="5851">si</TOKEN>
<TOKEN id="token-57-6" pos="word" morph="none" start_char="5853" end_char="5854">lo</TOKEN>
<TOKEN id="token-57-7" pos="word" morph="none" start_char="5856" end_char="5858">veo</TOKEN>
</SEG>
<SEG id="segment-58" start_char="5867" end_char="5892">
<ORIGINAL_TEXT>Todavía lo estará buscando</ORIGINAL_TEXT>
<TOKEN id="token-58-0" pos="word" morph="none" start_char="5867" end_char="5873">Todavía</TOKEN>
<TOKEN id="token-58-1" pos="word" morph="none" start_char="5875" end_char="5876">lo</TOKEN>
<TOKEN id="token-58-2" pos="word" morph="none" start_char="5878" end_char="5883">estará</TOKEN>
<TOKEN id="token-58-3" pos="word" morph="none" start_char="5885" end_char="5892">buscando</TOKEN>
</SEG>
<SEG id="segment-59" start_char="5896" end_char="5916">
<ORIGINAL_TEXT>Ramón confianza dijo:</ORIGINAL_TEXT>
<TOKEN id="token-59-0" pos="word" morph="none" start_char="5896" end_char="5900">Ramón</TOKEN>
<TOKEN id="token-59-1" pos="word" morph="none" start_char="5902" end_char="5910">confianza</TOKEN>
<TOKEN id="token-59-2" pos="word" morph="none" start_char="5912" end_char="5915">dijo</TOKEN>
<TOKEN id="token-59-3" pos="punct" morph="none" start_char="5916" end_char="5916">:</TOKEN>
</SEG>
<SEG id="segment-60" start_char="5919" end_char="5945">
<ORIGINAL_TEXT>Hacer clic para expandir...</ORIGINAL_TEXT>
<TOKEN id="token-60-0" pos="word" morph="none" start_char="5919" end_char="5923">Hacer</TOKEN>
<TOKEN id="token-60-1" pos="word" morph="none" start_char="5925" end_char="5928">clic</TOKEN>
<TOKEN id="token-60-2" pos="word" morph="none" start_char="5930" end_char="5933">para</TOKEN>
<TOKEN id="token-60-3" pos="word" morph="none" start_char="5935" end_char="5942">expandir</TOKEN>
<TOKEN id="token-60-4" pos="punct" morph="none" start_char="5943" end_char="5945">...</TOKEN>
</SEG>
<SEG id="segment-61" start_char="5949" end_char="5973">
<ORIGINAL_TEXT>Tu fuente es un youtuber?</ORIGINAL_TEXT>
<TOKEN id="token-61-0" pos="word" morph="none" start_char="5949" end_char="5950">Tu</TOKEN>
<TOKEN id="token-61-1" pos="word" morph="none" start_char="5952" end_char="5957">fuente</TOKEN>
<TOKEN id="token-61-2" pos="word" morph="none" start_char="5959" end_char="5960">es</TOKEN>
<TOKEN id="token-61-3" pos="word" morph="none" start_char="5962" end_char="5963">un</TOKEN>
<TOKEN id="token-61-4" pos="word" morph="none" start_char="5965" end_char="5972">youtuber</TOKEN>
<TOKEN id="token-61-5" pos="punct" morph="none" start_char="5973" end_char="5973">?</TOKEN>
</SEG>
<SEG id="segment-62" start_char="5975" end_char="5981">
<ORIGINAL_TEXT>Vale...</ORIGINAL_TEXT>
<TOKEN id="token-62-0" pos="word" morph="none" start_char="5975" end_char="5978">Vale</TOKEN>
<TOKEN id="token-62-1" pos="punct" morph="none" start_char="5979" end_char="5981">...</TOKEN>
</SEG>
<SEG id="segment-63" start_char="5985" end_char="6027">
<ORIGINAL_TEXT>aldebariano dijo: Tu fuente es un youtuber?</ORIGINAL_TEXT>
<TOKEN id="token-63-0" pos="word" morph="none" start_char="5985" end_char="5995">aldebariano</TOKEN>
<TOKEN id="token-63-1" pos="word" morph="none" start_char="5997" end_char="6000">dijo</TOKEN>
<TOKEN id="token-63-2" pos="punct" morph="none" start_char="6001" end_char="6001">:</TOKEN>
<TOKEN id="token-63-3" pos="word" morph="none" start_char="6003" end_char="6004">Tu</TOKEN>
<TOKEN id="token-63-4" pos="word" morph="none" start_char="6006" end_char="6011">fuente</TOKEN>
<TOKEN id="token-63-5" pos="word" morph="none" start_char="6013" end_char="6014">es</TOKEN>
<TOKEN id="token-63-6" pos="word" morph="none" start_char="6016" end_char="6017">un</TOKEN>
<TOKEN id="token-63-7" pos="word" morph="none" start_char="6019" end_char="6026">youtuber</TOKEN>
<TOKEN id="token-63-8" pos="punct" morph="none" start_char="6027" end_char="6027">?</TOKEN>
</SEG>
<SEG id="segment-64" start_char="6029" end_char="6035">
<ORIGINAL_TEXT>Vale...</ORIGINAL_TEXT>
<TOKEN id="token-64-0" pos="word" morph="none" start_char="6029" end_char="6032">Vale</TOKEN>
<TOKEN id="token-64-1" pos="punct" morph="none" start_char="6033" end_char="6035">...</TOKEN>
</SEG>
<SEG id="segment-65" start_char="6039" end_char="6076">
<ORIGINAL_TEXT>Entre otras cosas, y humorista como tù</ORIGINAL_TEXT>
<TOKEN id="token-65-0" pos="word" morph="none" start_char="6039" end_char="6043">Entre</TOKEN>
<TOKEN id="token-65-1" pos="word" morph="none" start_char="6045" end_char="6049">otras</TOKEN>
<TOKEN id="token-65-2" pos="word" morph="none" start_char="6051" end_char="6055">cosas</TOKEN>
<TOKEN id="token-65-3" pos="punct" morph="none" start_char="6056" end_char="6056">,</TOKEN>
<TOKEN id="token-65-4" pos="word" morph="none" start_char="6058" end_char="6058">y</TOKEN>
<TOKEN id="token-65-5" pos="word" morph="none" start_char="6060" end_char="6068">humorista</TOKEN>
<TOKEN id="token-65-6" pos="word" morph="none" start_char="6070" end_char="6073">como</TOKEN>
<TOKEN id="token-65-7" pos="word" morph="none" start_char="6075" end_char="6076">tù</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
