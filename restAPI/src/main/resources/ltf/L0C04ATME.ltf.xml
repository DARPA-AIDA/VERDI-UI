<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATME" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="3642" raw_text_md5="fcb2ca74b678a4683dcdf4b28ff53f5b">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="108">
<ORIGINAL_TEXT>CDC: Some Americans are misusing cleaning products — including drinking them — in effort to kill coronavirus</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="3">CDC</TOKEN>
<TOKEN id="token-0-1" pos="punct" morph="none" start_char="4" end_char="4">:</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="6" end_char="9">Some</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="11" end_char="19">Americans</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="21" end_char="23">are</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="25" end_char="32">misusing</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="34" end_char="41">cleaning</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="43" end_char="50">products</TOKEN>
<TOKEN id="token-0-8" pos="punct" morph="none" start_char="52" end_char="52">—</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="54" end_char="62">including</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="64" end_char="71">drinking</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="73" end_char="76">them</TOKEN>
<TOKEN id="token-0-12" pos="punct" morph="none" start_char="78" end_char="78">—</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="80" end_char="81">in</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="83" end_char="88">effort</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="90" end_char="91">to</TOKEN>
<TOKEN id="token-0-16" pos="word" morph="none" start_char="93" end_char="96">kill</TOKEN>
<TOKEN id="token-0-17" pos="word" morph="none" start_char="98" end_char="108">coronavirus</TOKEN>
</SEG>
<SEG id="segment-1" start_char="112" end_char="131">
<ORIGINAL_TEXT>Who is more idiotic?</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="112" end_char="114">Who</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="116" end_char="117">is</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="119" end_char="122">more</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="124" end_char="130">idiotic</TOKEN>
<TOKEN id="token-1-4" pos="punct" morph="none" start_char="131" end_char="131">?</TOKEN>
</SEG>
<SEG id="segment-2" start_char="133" end_char="342">
<ORIGINAL_TEXT>The people presenting this "scientific" report knowing it’s not done the proper scientific way or an unbelievable 20% people who cannot even read a product label little less to use what’s called a common sense.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="133" end_char="135">The</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="137" end_char="142">people</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="144" end_char="153">presenting</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="155" end_char="158">this</TOKEN>
<TOKEN id="token-2-4" pos="punct" morph="none" start_char="160" end_char="160">"</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="161" end_char="170">scientific</TOKEN>
<TOKEN id="token-2-6" pos="punct" morph="none" start_char="171" end_char="171">"</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="173" end_char="178">report</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="180" end_char="186">knowing</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="188" end_char="191">it’s</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="193" end_char="195">not</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="197" end_char="200">done</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="202" end_char="204">the</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="206" end_char="211">proper</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="213" end_char="222">scientific</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="224" end_char="226">way</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="228" end_char="229">or</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="231" end_char="232">an</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="234" end_char="245">unbelievable</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="247" end_char="248">20</TOKEN>
<TOKEN id="token-2-20" pos="punct" morph="none" start_char="249" end_char="249">%</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="251" end_char="256">people</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="258" end_char="260">who</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="262" end_char="267">cannot</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="269" end_char="272">even</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="274" end_char="277">read</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="279" end_char="279">a</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="281" end_char="287">product</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="289" end_char="293">label</TOKEN>
<TOKEN id="token-2-29" pos="word" morph="none" start_char="295" end_char="300">little</TOKEN>
<TOKEN id="token-2-30" pos="word" morph="none" start_char="302" end_char="305">less</TOKEN>
<TOKEN id="token-2-31" pos="word" morph="none" start_char="307" end_char="308">to</TOKEN>
<TOKEN id="token-2-32" pos="word" morph="none" start_char="310" end_char="312">use</TOKEN>
<TOKEN id="token-2-33" pos="word" morph="none" start_char="314" end_char="319">what’s</TOKEN>
<TOKEN id="token-2-34" pos="word" morph="none" start_char="321" end_char="326">called</TOKEN>
<TOKEN id="token-2-35" pos="word" morph="none" start_char="328" end_char="328">a</TOKEN>
<TOKEN id="token-2-36" pos="word" morph="none" start_char="330" end_char="335">common</TOKEN>
<TOKEN id="token-2-37" pos="word" morph="none" start_char="337" end_char="341">sense</TOKEN>
<TOKEN id="token-2-38" pos="punct" morph="none" start_char="342" end_char="342">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="344" end_char="385">
<ORIGINAL_TEXT>In any case it’s a tragedy upon a tragedy.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="344" end_char="345">In</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="347" end_char="349">any</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="351" end_char="354">case</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="356" end_char="359">it’s</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="361" end_char="361">a</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="363" end_char="369">tragedy</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="371" end_char="374">upon</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="376" end_char="376">a</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="378" end_char="384">tragedy</TOKEN>
<TOKEN id="token-3-9" pos="punct" morph="none" start_char="385" end_char="385">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="389" end_char="437">
<ORIGINAL_TEXT>Given the politics over Trump’s bleach statement?</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="389" end_char="393">Given</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="395" end_char="397">the</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="399" end_char="406">politics</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="408" end_char="411">over</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="413" end_char="419">Trump’s</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="421" end_char="426">bleach</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="428" end_char="436">statement</TOKEN>
<TOKEN id="token-4-7" pos="punct" morph="none" start_char="437" end_char="437">?</TOKEN>
</SEG>
<SEG id="segment-5" start_char="440" end_char="554">
<ORIGINAL_TEXT>That 1 in 5 actually put bleach on food or that a bunch of people trolled this totally unscientific, opt-in survey?</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="440" end_char="443">That</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="445" end_char="445">1</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="447" end_char="448">in</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="450" end_char="450">5</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="452" end_char="459">actually</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="461" end_char="463">put</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="465" end_char="470">bleach</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="472" end_char="473">on</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="475" end_char="478">food</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="480" end_char="481">or</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="483" end_char="486">that</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="488" end_char="488">a</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="490" end_char="494">bunch</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="496" end_char="497">of</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="499" end_char="504">people</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="506" end_char="512">trolled</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="514" end_char="517">this</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="519" end_char="525">totally</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="527" end_char="538">unscientific</TOKEN>
<TOKEN id="token-5-19" pos="punct" morph="none" start_char="539" end_char="539">,</TOKEN>
<TOKEN id="token-5-20" pos="unknown" morph="none" start_char="541" end_char="546">opt-in</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="548" end_char="553">survey</TOKEN>
<TOKEN id="token-5-22" pos="punct" morph="none" start_char="554" end_char="554">?</TOKEN>
</SEG>
<SEG id="segment-6" start_char="557" end_char="638">
<ORIGINAL_TEXT>I love StatNews, but this survey is probably as reliable and the Surgispehre data.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="557" end_char="557">I</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="559" end_char="562">love</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="564" end_char="571">StatNews</TOKEN>
<TOKEN id="token-6-3" pos="punct" morph="none" start_char="572" end_char="572">,</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="574" end_char="576">but</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="578" end_char="581">this</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="583" end_char="588">survey</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="590" end_char="591">is</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="593" end_char="600">probably</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="602" end_char="603">as</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="605" end_char="612">reliable</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="614" end_char="616">and</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="618" end_char="620">the</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="622" end_char="632">Surgispehre</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="634" end_char="637">data</TOKEN>
<TOKEN id="token-6-15" pos="punct" morph="none" start_char="638" end_char="638">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="642" end_char="681">
<ORIGINAL_TEXT>Another anti-Trump rubbish by "experts".</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="642" end_char="648">Another</TOKEN>
<TOKEN id="token-7-1" pos="unknown" morph="none" start_char="650" end_char="659">anti-Trump</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="661" end_char="667">rubbish</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="669" end_char="670">by</TOKEN>
<TOKEN id="token-7-4" pos="punct" morph="none" start_char="672" end_char="672">"</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="673" end_char="679">experts</TOKEN>
<TOKEN id="token-7-6" pos="punct" morph="none" start_char="680" end_char="681">".</TOKEN>
</SEG>
<SEG id="segment-8" start_char="683" end_char="788">
<ORIGINAL_TEXT>Trump should tell people PhDs prevent COVID-19 and then we see if more people will enroll for PhD courses.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="683" end_char="687">Trump</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="689" end_char="694">should</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="696" end_char="699">tell</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="701" end_char="706">people</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="708" end_char="711">PhDs</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="713" end_char="719">prevent</TOKEN>
<TOKEN id="token-8-6" pos="unknown" morph="none" start_char="721" end_char="728">COVID-19</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="730" end_char="732">and</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="734" end_char="737">then</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="739" end_char="740">we</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="742" end_char="744">see</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="746" end_char="747">if</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="749" end_char="752">more</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="754" end_char="759">people</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="761" end_char="764">will</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="766" end_char="771">enroll</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="773" end_char="775">for</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="777" end_char="779">PhD</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="781" end_char="787">courses</TOKEN>
<TOKEN id="token-8-19" pos="punct" morph="none" start_char="788" end_char="788">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="791" end_char="851">
<ORIGINAL_TEXT>The "experts" and the media take millions of people as fools.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="791" end_char="793">The</TOKEN>
<TOKEN id="token-9-1" pos="punct" morph="none" start_char="795" end_char="795">"</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="796" end_char="802">experts</TOKEN>
<TOKEN id="token-9-3" pos="punct" morph="none" start_char="803" end_char="803">"</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="805" end_char="807">and</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="809" end_char="811">the</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="813" end_char="817">media</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="819" end_char="822">take</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="824" end_char="831">millions</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="833" end_char="834">of</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="836" end_char="841">people</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="843" end_char="844">as</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="846" end_char="850">fools</TOKEN>
<TOKEN id="token-9-13" pos="punct" morph="none" start_char="851" end_char="851">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="855" end_char="916">
<ORIGINAL_TEXT>That means still there are many who listen to their president!</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="855" end_char="858">That</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="860" end_char="864">means</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="866" end_char="870">still</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="872" end_char="876">there</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="878" end_char="880">are</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="882" end_char="885">many</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="887" end_char="889">who</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="891" end_char="896">listen</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="898" end_char="899">to</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="901" end_char="905">their</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="907" end_char="915">president</TOKEN>
<TOKEN id="token-10-11" pos="punct" morph="none" start_char="916" end_char="916">!</TOKEN>
</SEG>
<SEG id="segment-11" start_char="920" end_char="926">
<ORIGINAL_TEXT>Shhhhh.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="920" end_char="925">Shhhhh</TOKEN>
<TOKEN id="token-11-1" pos="punct" morph="none" start_char="926" end_char="926">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="928" end_char="942">
<ORIGINAL_TEXT>Darwin at work!</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="928" end_char="933">Darwin</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="935" end_char="936">at</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="938" end_char="941">work</TOKEN>
<TOKEN id="token-12-3" pos="punct" morph="none" start_char="942" end_char="942">!</TOKEN>
</SEG>
<SEG id="segment-13" start_char="946" end_char="1061">
<ORIGINAL_TEXT>"Thirty-nine percent had misused the cleaning products" – so about the same percentage that voted for Trump in 2016.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="punct" morph="none" start_char="946" end_char="946">"</TOKEN>
<TOKEN id="token-13-1" pos="unknown" morph="none" start_char="947" end_char="957">Thirty-nine</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="959" end_char="965">percent</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="967" end_char="969">had</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="971" end_char="977">misused</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="979" end_char="981">the</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="983" end_char="990">cleaning</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="992" end_char="999">products</TOKEN>
<TOKEN id="token-13-8" pos="punct" morph="none" start_char="1000" end_char="1000">"</TOKEN>
<TOKEN id="token-13-9" pos="punct" morph="none" start_char="1002" end_char="1002">–</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1004" end_char="1005">so</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1007" end_char="1011">about</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1013" end_char="1015">the</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1017" end_char="1020">same</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1022" end_char="1031">percentage</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1033" end_char="1036">that</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1038" end_char="1042">voted</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1044" end_char="1046">for</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1048" end_char="1052">Trump</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1054" end_char="1055">in</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1057" end_char="1060">2016</TOKEN>
<TOKEN id="token-13-21" pos="punct" morph="none" start_char="1061" end_char="1061">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1063" end_char="1303">
<ORIGINAL_TEXT>Basically the most uneducated inbred Americans ever, that blame immigrants/liberals/global trade/opiates/China/gun control/Obama Care for their lot in life, rather than taking ownership for educating themselves and improving their situation.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1063" end_char="1071">Basically</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1073" end_char="1075">the</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1077" end_char="1080">most</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1082" end_char="1091">uneducated</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1093" end_char="1098">inbred</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1100" end_char="1108">Americans</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1110" end_char="1113">ever</TOKEN>
<TOKEN id="token-14-7" pos="punct" morph="none" start_char="1114" end_char="1114">,</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1116" end_char="1119">that</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1121" end_char="1125">blame</TOKEN>
<TOKEN id="token-14-10" pos="unknown" morph="none" start_char="1127" end_char="1152">immigrants/liberals/global</TOKEN>
<TOKEN id="token-14-11" pos="unknown" morph="none" start_char="1154" end_char="1176">trade/opiates/China/gun</TOKEN>
<TOKEN id="token-14-12" pos="unknown" morph="none" start_char="1178" end_char="1190">control/Obama</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1192" end_char="1195">Care</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="1197" end_char="1199">for</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1201" end_char="1205">their</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1207" end_char="1209">lot</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="1211" end_char="1212">in</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="1214" end_char="1217">life</TOKEN>
<TOKEN id="token-14-19" pos="punct" morph="none" start_char="1218" end_char="1218">,</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="1220" end_char="1225">rather</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="1227" end_char="1230">than</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="1232" end_char="1237">taking</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="1239" end_char="1247">ownership</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="1249" end_char="1251">for</TOKEN>
<TOKEN id="token-14-25" pos="word" morph="none" start_char="1253" end_char="1261">educating</TOKEN>
<TOKEN id="token-14-26" pos="word" morph="none" start_char="1263" end_char="1272">themselves</TOKEN>
<TOKEN id="token-14-27" pos="word" morph="none" start_char="1274" end_char="1276">and</TOKEN>
<TOKEN id="token-14-28" pos="word" morph="none" start_char="1278" end_char="1286">improving</TOKEN>
<TOKEN id="token-14-29" pos="word" morph="none" start_char="1288" end_char="1292">their</TOKEN>
<TOKEN id="token-14-30" pos="word" morph="none" start_char="1294" end_char="1302">situation</TOKEN>
<TOKEN id="token-14-31" pos="punct" morph="none" start_char="1303" end_char="1303">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1307" end_char="1380">
<ORIGINAL_TEXT>But I thought it was rich people and the one percent that voted for Trump?</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1307" end_char="1309">But</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1311" end_char="1311">I</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1313" end_char="1319">thought</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1321" end_char="1322">it</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1324" end_char="1326">was</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1328" end_char="1331">rich</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1333" end_char="1338">people</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1340" end_char="1342">and</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1344" end_char="1346">the</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1348" end_char="1350">one</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1352" end_char="1358">percent</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1360" end_char="1363">that</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1365" end_char="1369">voted</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1371" end_char="1373">for</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1375" end_char="1379">Trump</TOKEN>
<TOKEN id="token-15-15" pos="punct" morph="none" start_char="1380" end_char="1380">?</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1382" end_char="1442">
<ORIGINAL_TEXT>That is a narrative often heard–that Trump is "for the rich."</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1382" end_char="1385">That</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1387" end_char="1388">is</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1390" end_char="1390">a</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1392" end_char="1400">narrative</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1402" end_char="1406">often</TOKEN>
<TOKEN id="token-16-5" pos="unknown" morph="none" start_char="1408" end_char="1417">heard–that</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1419" end_char="1423">Trump</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1425" end_char="1426">is</TOKEN>
<TOKEN id="token-16-8" pos="punct" morph="none" start_char="1428" end_char="1428">"</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="1429" end_char="1431">for</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="1433" end_char="1435">the</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="1437" end_char="1440">rich</TOKEN>
<TOKEN id="token-16-12" pos="punct" morph="none" start_char="1441" end_char="1442">."</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1444" end_char="1558">
<ORIGINAL_TEXT>This would conflict with your characterization of the entire percentage you state being a bunch of mouth breathers.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1444" end_char="1447">This</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1449" end_char="1453">would</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="1455" end_char="1462">conflict</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="1464" end_char="1467">with</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="1469" end_char="1472">your</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="1474" end_char="1489">characterization</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="1491" end_char="1492">of</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="1494" end_char="1496">the</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="1498" end_char="1503">entire</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="1505" end_char="1514">percentage</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="1516" end_char="1518">you</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="1520" end_char="1524">state</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="1526" end_char="1530">being</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="1532" end_char="1532">a</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="1534" end_char="1538">bunch</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="1540" end_char="1541">of</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="1543" end_char="1547">mouth</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="1549" end_char="1557">breathers</TOKEN>
<TOKEN id="token-17-18" pos="punct" morph="none" start_char="1558" end_char="1558">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1562" end_char="1699">
<ORIGINAL_TEXT>This bit of "throw away " information was gleaned from an online survey of 502 people, compiled, analyzed and written by 11, yes 11 PhD’s.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="1562" end_char="1565">This</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="1567" end_char="1569">bit</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="1571" end_char="1572">of</TOKEN>
<TOKEN id="token-18-3" pos="punct" morph="none" start_char="1574" end_char="1574">"</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="1575" end_char="1579">throw</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="1581" end_char="1584">away</TOKEN>
<TOKEN id="token-18-6" pos="punct" morph="none" start_char="1586" end_char="1586">"</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="1588" end_char="1598">information</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="1600" end_char="1602">was</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="1604" end_char="1610">gleaned</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="1612" end_char="1615">from</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="1617" end_char="1618">an</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="1620" end_char="1625">online</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="1627" end_char="1632">survey</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="1634" end_char="1635">of</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="1637" end_char="1639">502</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="1641" end_char="1646">people</TOKEN>
<TOKEN id="token-18-17" pos="punct" morph="none" start_char="1647" end_char="1647">,</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="1649" end_char="1656">compiled</TOKEN>
<TOKEN id="token-18-19" pos="punct" morph="none" start_char="1657" end_char="1657">,</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="1659" end_char="1666">analyzed</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="1668" end_char="1670">and</TOKEN>
<TOKEN id="token-18-22" pos="word" morph="none" start_char="1672" end_char="1678">written</TOKEN>
<TOKEN id="token-18-23" pos="word" morph="none" start_char="1680" end_char="1681">by</TOKEN>
<TOKEN id="token-18-24" pos="word" morph="none" start_char="1683" end_char="1684">11</TOKEN>
<TOKEN id="token-18-25" pos="punct" morph="none" start_char="1685" end_char="1685">,</TOKEN>
<TOKEN id="token-18-26" pos="word" morph="none" start_char="1687" end_char="1689">yes</TOKEN>
<TOKEN id="token-18-27" pos="word" morph="none" start_char="1691" end_char="1692">11</TOKEN>
<TOKEN id="token-18-28" pos="word" morph="none" start_char="1694" end_char="1698">PhD’s</TOKEN>
<TOKEN id="token-18-29" pos="punct" morph="none" start_char="1699" end_char="1699">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="1701" end_char="1935">
<ORIGINAL_TEXT>We learned that a small, non-representative group of people using smartphones or computers are dumb enough to poison themselves because they have been scared out of their gourds by misrepresentations by "experts" and the slavish media.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="1701" end_char="1702">We</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="1704" end_char="1710">learned</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="1712" end_char="1715">that</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="1717" end_char="1717">a</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="1719" end_char="1723">small</TOKEN>
<TOKEN id="token-19-5" pos="punct" morph="none" start_char="1724" end_char="1724">,</TOKEN>
<TOKEN id="token-19-6" pos="unknown" morph="none" start_char="1726" end_char="1743">non-representative</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="1745" end_char="1749">group</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="1751" end_char="1752">of</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="1754" end_char="1759">people</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="1761" end_char="1765">using</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="1767" end_char="1777">smartphones</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="1779" end_char="1780">or</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="1782" end_char="1790">computers</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="1792" end_char="1794">are</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="1796" end_char="1799">dumb</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="1801" end_char="1806">enough</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="1808" end_char="1809">to</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="1811" end_char="1816">poison</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="1818" end_char="1827">themselves</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="1829" end_char="1835">because</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="1837" end_char="1840">they</TOKEN>
<TOKEN id="token-19-22" pos="word" morph="none" start_char="1842" end_char="1845">have</TOKEN>
<TOKEN id="token-19-23" pos="word" morph="none" start_char="1847" end_char="1850">been</TOKEN>
<TOKEN id="token-19-24" pos="word" morph="none" start_char="1852" end_char="1857">scared</TOKEN>
<TOKEN id="token-19-25" pos="word" morph="none" start_char="1859" end_char="1861">out</TOKEN>
<TOKEN id="token-19-26" pos="word" morph="none" start_char="1863" end_char="1864">of</TOKEN>
<TOKEN id="token-19-27" pos="word" morph="none" start_char="1866" end_char="1870">their</TOKEN>
<TOKEN id="token-19-28" pos="word" morph="none" start_char="1872" end_char="1877">gourds</TOKEN>
<TOKEN id="token-19-29" pos="word" morph="none" start_char="1879" end_char="1880">by</TOKEN>
<TOKEN id="token-19-30" pos="word" morph="none" start_char="1882" end_char="1899">misrepresentations</TOKEN>
<TOKEN id="token-19-31" pos="word" morph="none" start_char="1901" end_char="1902">by</TOKEN>
<TOKEN id="token-19-32" pos="punct" morph="none" start_char="1904" end_char="1904">"</TOKEN>
<TOKEN id="token-19-33" pos="word" morph="none" start_char="1905" end_char="1911">experts</TOKEN>
<TOKEN id="token-19-34" pos="punct" morph="none" start_char="1912" end_char="1912">"</TOKEN>
<TOKEN id="token-19-35" pos="word" morph="none" start_char="1914" end_char="1916">and</TOKEN>
<TOKEN id="token-19-36" pos="word" morph="none" start_char="1918" end_char="1920">the</TOKEN>
<TOKEN id="token-19-37" pos="word" morph="none" start_char="1922" end_char="1928">slavish</TOKEN>
<TOKEN id="token-19-38" pos="word" morph="none" start_char="1930" end_char="1934">media</TOKEN>
<TOKEN id="token-19-39" pos="punct" morph="none" start_char="1935" end_char="1935">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="1937" end_char="1989">
<ORIGINAL_TEXT>The only scientific principles proved here is that 1.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="1937" end_char="1939">The</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="1941" end_char="1944">only</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="1946" end_char="1955">scientific</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="1957" end_char="1966">principles</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="1968" end_char="1973">proved</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="1975" end_char="1978">here</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="1980" end_char="1981">is</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="1983" end_char="1986">that</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="1988" end_char="1988">1</TOKEN>
<TOKEN id="token-20-9" pos="punct" morph="none" start_char="1989" end_char="1989">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="1991" end_char="2007">
<ORIGINAL_TEXT>Agitprop works 2.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="1991" end_char="1998">Agitprop</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2000" end_char="2004">works</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2006" end_char="2006">2</TOKEN>
<TOKEN id="token-21-3" pos="punct" morph="none" start_char="2007" end_char="2007">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2009" end_char="2024">
<ORIGINAL_TEXT>Darwin is right.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2009" end_char="2014">Darwin</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2016" end_char="2017">is</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2019" end_char="2023">right</TOKEN>
<TOKEN id="token-22-3" pos="punct" morph="none" start_char="2024" end_char="2024">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2026" end_char="2071">
<ORIGINAL_TEXT>Oh, and one other thing the Orange Guy is bad!</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2026" end_char="2027">Oh</TOKEN>
<TOKEN id="token-23-1" pos="punct" morph="none" start_char="2028" end_char="2028">,</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2030" end_char="2032">and</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2034" end_char="2036">one</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="2038" end_char="2042">other</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="2044" end_char="2048">thing</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="2050" end_char="2052">the</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="2054" end_char="2059">Orange</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="2061" end_char="2063">Guy</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="2065" end_char="2066">is</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="2068" end_char="2070">bad</TOKEN>
<TOKEN id="token-23-11" pos="punct" morph="none" start_char="2071" end_char="2071">!</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2075" end_char="2184">
<ORIGINAL_TEXT>Everyone is to blame: The media, the idiots, the experts…even the researchers leading this "throw away" study.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="2075" end_char="2082">Everyone</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="2084" end_char="2085">is</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="2087" end_char="2088">to</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="2090" end_char="2094">blame</TOKEN>
<TOKEN id="token-24-4" pos="punct" morph="none" start_char="2095" end_char="2095">:</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="2097" end_char="2099">The</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="2101" end_char="2105">media</TOKEN>
<TOKEN id="token-24-7" pos="punct" morph="none" start_char="2106" end_char="2106">,</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="2108" end_char="2110">the</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="2112" end_char="2117">idiots</TOKEN>
<TOKEN id="token-24-10" pos="punct" morph="none" start_char="2118" end_char="2118">,</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="2120" end_char="2122">the</TOKEN>
<TOKEN id="token-24-12" pos="unknown" morph="none" start_char="2124" end_char="2135">experts…even</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="2137" end_char="2139">the</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="2141" end_char="2151">researchers</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="2153" end_char="2159">leading</TOKEN>
<TOKEN id="token-24-16" pos="word" morph="none" start_char="2161" end_char="2164">this</TOKEN>
<TOKEN id="token-24-17" pos="punct" morph="none" start_char="2166" end_char="2166">"</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="2167" end_char="2171">throw</TOKEN>
<TOKEN id="token-24-19" pos="word" morph="none" start_char="2173" end_char="2176">away</TOKEN>
<TOKEN id="token-24-20" pos="punct" morph="none" start_char="2177" end_char="2177">"</TOKEN>
<TOKEN id="token-24-21" pos="word" morph="none" start_char="2179" end_char="2183">study</TOKEN>
<TOKEN id="token-24-22" pos="punct" morph="none" start_char="2184" end_char="2184">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2186" end_char="2211">
<ORIGINAL_TEXT>Yes, everyone is to blame.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="2186" end_char="2188">Yes</TOKEN>
<TOKEN id="token-25-1" pos="punct" morph="none" start_char="2189" end_char="2189">,</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="2191" end_char="2198">everyone</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="2200" end_char="2201">is</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="2203" end_char="2204">to</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="2206" end_char="2210">blame</TOKEN>
<TOKEN id="token-25-6" pos="punct" morph="none" start_char="2211" end_char="2211">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="2213" end_char="2252">
<ORIGINAL_TEXT>Everyone, that is, except the President.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="2213" end_char="2220">Everyone</TOKEN>
<TOKEN id="token-26-1" pos="punct" morph="none" start_char="2221" end_char="2221">,</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="2223" end_char="2226">that</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="2228" end_char="2229">is</TOKEN>
<TOKEN id="token-26-4" pos="punct" morph="none" start_char="2230" end_char="2230">,</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="2232" end_char="2237">except</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="2239" end_char="2241">the</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="2243" end_char="2251">President</TOKEN>
<TOKEN id="token-26-8" pos="punct" morph="none" start_char="2252" end_char="2252">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="2254" end_char="2296">
<ORIGINAL_TEXT>That bastion of truth and tremendous ideas.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="2254" end_char="2257">That</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="2259" end_char="2265">bastion</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="2267" end_char="2268">of</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="2270" end_char="2274">truth</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="2276" end_char="2278">and</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="2280" end_char="2289">tremendous</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="2291" end_char="2295">ideas</TOKEN>
<TOKEN id="token-27-7" pos="punct" morph="none" start_char="2296" end_char="2296">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="2298" end_char="2357">
<ORIGINAL_TEXT>That paragon of dignity, knowledge, and measured leadership.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="2298" end_char="2301">That</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="2303" end_char="2309">paragon</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="2311" end_char="2312">of</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="2314" end_char="2320">dignity</TOKEN>
<TOKEN id="token-28-4" pos="punct" morph="none" start_char="2321" end_char="2321">,</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="2323" end_char="2331">knowledge</TOKEN>
<TOKEN id="token-28-6" pos="punct" morph="none" start_char="2332" end_char="2332">,</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="2334" end_char="2336">and</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="2338" end_char="2345">measured</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="2347" end_char="2356">leadership</TOKEN>
<TOKEN id="token-28-10" pos="punct" morph="none" start_char="2357" end_char="2357">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="2359" end_char="2389">
<ORIGINAL_TEXT>Thank you for opening our eyes.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="2359" end_char="2363">Thank</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="2365" end_char="2367">you</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="2369" end_char="2371">for</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="2373" end_char="2379">opening</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="2381" end_char="2383">our</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="2385" end_char="2388">eyes</TOKEN>
<TOKEN id="token-29-6" pos="punct" morph="none" start_char="2389" end_char="2389">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="2391" end_char="2420">
<ORIGINAL_TEXT>You are a tremendous American.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="2391" end_char="2393">You</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="2395" end_char="2397">are</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="2399" end_char="2399">a</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="2401" end_char="2410">tremendous</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="2412" end_char="2419">American</TOKEN>
<TOKEN id="token-30-5" pos="punct" morph="none" start_char="2420" end_char="2420">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="2424" end_char="2457">
<ORIGINAL_TEXT>It’s everyone else’s fault, right?</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="2424" end_char="2427">It’s</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="2429" end_char="2436">everyone</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="2438" end_char="2443">else’s</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="2445" end_char="2449">fault</TOKEN>
<TOKEN id="token-31-4" pos="punct" morph="none" start_char="2450" end_char="2450">,</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="2452" end_char="2456">right</TOKEN>
<TOKEN id="token-31-6" pos="punct" morph="none" start_char="2457" end_char="2457">?</TOKEN>
</SEG>
<SEG id="segment-32" start_char="2459" end_char="2501">
<ORIGINAL_TEXT>Please, pretty please, take some ownership.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="2459" end_char="2464">Please</TOKEN>
<TOKEN id="token-32-1" pos="punct" morph="none" start_char="2465" end_char="2465">,</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="2467" end_char="2472">pretty</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="2474" end_char="2479">please</TOKEN>
<TOKEN id="token-32-4" pos="punct" morph="none" start_char="2480" end_char="2480">,</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="2482" end_char="2485">take</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="2487" end_char="2490">some</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="2492" end_char="2500">ownership</TOKEN>
<TOKEN id="token-32-8" pos="punct" morph="none" start_char="2501" end_char="2501">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="2503" end_char="2642">
<ORIGINAL_TEXT>There is no perfect administration, no one can get everything right all of the time, so it’s ok to be objective and call things as they are.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="2503" end_char="2507">There</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="2509" end_char="2510">is</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="2512" end_char="2513">no</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="2515" end_char="2521">perfect</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="2523" end_char="2536">administration</TOKEN>
<TOKEN id="token-33-5" pos="punct" morph="none" start_char="2537" end_char="2537">,</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="2539" end_char="2540">no</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="2542" end_char="2544">one</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="2546" end_char="2548">can</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="2550" end_char="2552">get</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="2554" end_char="2563">everything</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="2565" end_char="2569">right</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="2571" end_char="2573">all</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="2575" end_char="2576">of</TOKEN>
<TOKEN id="token-33-14" pos="word" morph="none" start_char="2578" end_char="2580">the</TOKEN>
<TOKEN id="token-33-15" pos="word" morph="none" start_char="2582" end_char="2585">time</TOKEN>
<TOKEN id="token-33-16" pos="punct" morph="none" start_char="2586" end_char="2586">,</TOKEN>
<TOKEN id="token-33-17" pos="word" morph="none" start_char="2588" end_char="2589">so</TOKEN>
<TOKEN id="token-33-18" pos="word" morph="none" start_char="2591" end_char="2594">it’s</TOKEN>
<TOKEN id="token-33-19" pos="word" morph="none" start_char="2596" end_char="2597">ok</TOKEN>
<TOKEN id="token-33-20" pos="word" morph="none" start_char="2599" end_char="2600">to</TOKEN>
<TOKEN id="token-33-21" pos="word" morph="none" start_char="2602" end_char="2603">be</TOKEN>
<TOKEN id="token-33-22" pos="word" morph="none" start_char="2605" end_char="2613">objective</TOKEN>
<TOKEN id="token-33-23" pos="word" morph="none" start_char="2615" end_char="2617">and</TOKEN>
<TOKEN id="token-33-24" pos="word" morph="none" start_char="2619" end_char="2622">call</TOKEN>
<TOKEN id="token-33-25" pos="word" morph="none" start_char="2624" end_char="2629">things</TOKEN>
<TOKEN id="token-33-26" pos="word" morph="none" start_char="2631" end_char="2632">as</TOKEN>
<TOKEN id="token-33-27" pos="word" morph="none" start_char="2634" end_char="2637">they</TOKEN>
<TOKEN id="token-33-28" pos="word" morph="none" start_char="2639" end_char="2641">are</TOKEN>
<TOKEN id="token-33-29" pos="punct" morph="none" start_char="2642" end_char="2642">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="2644" end_char="2702">
<ORIGINAL_TEXT>This administration has made many errors, many were costly.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="2644" end_char="2647">This</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="2649" end_char="2662">administration</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="2664" end_char="2666">has</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="2668" end_char="2671">made</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="2673" end_char="2676">many</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="2678" end_char="2683">errors</TOKEN>
<TOKEN id="token-34-6" pos="punct" morph="none" start_char="2684" end_char="2684">,</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="2686" end_char="2689">many</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="2691" end_char="2694">were</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="2696" end_char="2701">costly</TOKEN>
<TOKEN id="token-34-10" pos="punct" morph="none" start_char="2702" end_char="2702">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="2704" end_char="2739">
<ORIGINAL_TEXT>I am not sure how one can deny that.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="2704" end_char="2704">I</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="2706" end_char="2707">am</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="2709" end_char="2711">not</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="2713" end_char="2716">sure</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="2718" end_char="2720">how</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="2722" end_char="2724">one</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="2726" end_char="2728">can</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="2730" end_char="2733">deny</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="2735" end_char="2738">that</TOKEN>
<TOKEN id="token-35-9" pos="punct" morph="none" start_char="2739" end_char="2739">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="2743" end_char="2783">
<ORIGINAL_TEXT>Bleach on the skin is not very dangerous.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="2743" end_char="2748">Bleach</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="2750" end_char="2751">on</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="2753" end_char="2755">the</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="2757" end_char="2760">skin</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="2762" end_char="2763">is</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="2765" end_char="2767">not</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="2769" end_char="2772">very</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="2774" end_char="2782">dangerous</TOKEN>
<TOKEN id="token-36-8" pos="punct" morph="none" start_char="2783" end_char="2783">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="2785" end_char="2872">
<ORIGINAL_TEXT>I have soaked my feet in bleach and water plenty of times to remove bacteria and fungus.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="2785" end_char="2785">I</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="2787" end_char="2790">have</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="2792" end_char="2797">soaked</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="2799" end_char="2800">my</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="2802" end_char="2805">feet</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="2807" end_char="2808">in</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="2810" end_char="2815">bleach</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="2817" end_char="2819">and</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="2821" end_char="2825">water</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="2827" end_char="2832">plenty</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="2834" end_char="2835">of</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="2837" end_char="2841">times</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="2843" end_char="2844">to</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="2846" end_char="2851">remove</TOKEN>
<TOKEN id="token-37-14" pos="word" morph="none" start_char="2853" end_char="2860">bacteria</TOKEN>
<TOKEN id="token-37-15" pos="word" morph="none" start_char="2862" end_char="2864">and</TOKEN>
<TOKEN id="token-37-16" pos="word" morph="none" start_char="2866" end_char="2871">fungus</TOKEN>
<TOKEN id="token-37-17" pos="punct" morph="none" start_char="2872" end_char="2872">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="2874" end_char="2895">
<ORIGINAL_TEXT>There are no problems.</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="2874" end_char="2878">There</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="2880" end_char="2882">are</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="2884" end_char="2885">no</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="2887" end_char="2894">problems</TOKEN>
<TOKEN id="token-38-4" pos="punct" morph="none" start_char="2895" end_char="2895">.</TOKEN>
</SEG>
<SEG id="segment-39" start_char="2897" end_char="3053">
<ORIGINAL_TEXT>I even use a mixture of bleach and 91% isopropyl alcohol as a sanitizer because using public transportation and washing one’s hands frequently is not viable.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="2897" end_char="2897">I</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="2899" end_char="2902">even</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="2904" end_char="2906">use</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="2908" end_char="2908">a</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="2910" end_char="2916">mixture</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="2918" end_char="2919">of</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="2921" end_char="2926">bleach</TOKEN>
<TOKEN id="token-39-7" pos="word" morph="none" start_char="2928" end_char="2930">and</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="2932" end_char="2933">91</TOKEN>
<TOKEN id="token-39-9" pos="punct" morph="none" start_char="2934" end_char="2934">%</TOKEN>
<TOKEN id="token-39-10" pos="word" morph="none" start_char="2936" end_char="2944">isopropyl</TOKEN>
<TOKEN id="token-39-11" pos="word" morph="none" start_char="2946" end_char="2952">alcohol</TOKEN>
<TOKEN id="token-39-12" pos="word" morph="none" start_char="2954" end_char="2955">as</TOKEN>
<TOKEN id="token-39-13" pos="word" morph="none" start_char="2957" end_char="2957">a</TOKEN>
<TOKEN id="token-39-14" pos="word" morph="none" start_char="2959" end_char="2967">sanitizer</TOKEN>
<TOKEN id="token-39-15" pos="word" morph="none" start_char="2969" end_char="2975">because</TOKEN>
<TOKEN id="token-39-16" pos="word" morph="none" start_char="2977" end_char="2981">using</TOKEN>
<TOKEN id="token-39-17" pos="word" morph="none" start_char="2983" end_char="2988">public</TOKEN>
<TOKEN id="token-39-18" pos="word" morph="none" start_char="2990" end_char="3003">transportation</TOKEN>
<TOKEN id="token-39-19" pos="word" morph="none" start_char="3005" end_char="3007">and</TOKEN>
<TOKEN id="token-39-20" pos="word" morph="none" start_char="3009" end_char="3015">washing</TOKEN>
<TOKEN id="token-39-21" pos="word" morph="none" start_char="3017" end_char="3021">one’s</TOKEN>
<TOKEN id="token-39-22" pos="word" morph="none" start_char="3023" end_char="3027">hands</TOKEN>
<TOKEN id="token-39-23" pos="word" morph="none" start_char="3029" end_char="3038">frequently</TOKEN>
<TOKEN id="token-39-24" pos="word" morph="none" start_char="3040" end_char="3041">is</TOKEN>
<TOKEN id="token-39-25" pos="word" morph="none" start_char="3043" end_char="3045">not</TOKEN>
<TOKEN id="token-39-26" pos="word" morph="none" start_char="3047" end_char="3052">viable</TOKEN>
<TOKEN id="token-39-27" pos="punct" morph="none" start_char="3053" end_char="3053">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="3055" end_char="3161">
<ORIGINAL_TEXT>I would not put bleach on open wounds and sores but for infrequent or occassional use I would recommend it.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="3055" end_char="3055">I</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="3057" end_char="3061">would</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="3063" end_char="3065">not</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="3067" end_char="3069">put</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="3071" end_char="3076">bleach</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="3078" end_char="3079">on</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="3081" end_char="3084">open</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="3086" end_char="3091">wounds</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="3093" end_char="3095">and</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="3097" end_char="3101">sores</TOKEN>
<TOKEN id="token-40-10" pos="word" morph="none" start_char="3103" end_char="3105">but</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="3107" end_char="3109">for</TOKEN>
<TOKEN id="token-40-12" pos="word" morph="none" start_char="3111" end_char="3120">infrequent</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="3122" end_char="3123">or</TOKEN>
<TOKEN id="token-40-14" pos="word" morph="none" start_char="3125" end_char="3135">occassional</TOKEN>
<TOKEN id="token-40-15" pos="word" morph="none" start_char="3137" end_char="3139">use</TOKEN>
<TOKEN id="token-40-16" pos="word" morph="none" start_char="3141" end_char="3141">I</TOKEN>
<TOKEN id="token-40-17" pos="word" morph="none" start_char="3143" end_char="3147">would</TOKEN>
<TOKEN id="token-40-18" pos="word" morph="none" start_char="3149" end_char="3157">recommend</TOKEN>
<TOKEN id="token-40-19" pos="word" morph="none" start_char="3159" end_char="3160">it</TOKEN>
<TOKEN id="token-40-20" pos="punct" morph="none" start_char="3161" end_char="3161">.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="3163" end_char="3182">
<ORIGINAL_TEXT>No, do not drink it.</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="3163" end_char="3164">No</TOKEN>
<TOKEN id="token-41-1" pos="punct" morph="none" start_char="3165" end_char="3165">,</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="3167" end_char="3168">do</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="3170" end_char="3172">not</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="3174" end_char="3178">drink</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="3180" end_char="3181">it</TOKEN>
<TOKEN id="token-41-6" pos="punct" morph="none" start_char="3182" end_char="3182">.</TOKEN>
</SEG>
<SEG id="segment-42" start_char="3184" end_char="3207">
<ORIGINAL_TEXT>That will kill a person.</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="3184" end_char="3187">That</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="3189" end_char="3192">will</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="3194" end_char="3197">kill</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="3199" end_char="3199">a</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="3201" end_char="3206">person</TOKEN>
<TOKEN id="token-42-5" pos="punct" morph="none" start_char="3207" end_char="3207">.</TOKEN>
</SEG>
<SEG id="segment-43" start_char="3211" end_char="3337">
<ORIGINAL_TEXT>I would not do what you are doing with bleach–but clearly you are getting by with it and presumably still well enough to write.</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="3211" end_char="3211">I</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="3213" end_char="3217">would</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="3219" end_char="3221">not</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="3223" end_char="3224">do</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="3226" end_char="3229">what</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="3231" end_char="3233">you</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="3235" end_char="3237">are</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="3239" end_char="3243">doing</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="3245" end_char="3248">with</TOKEN>
<TOKEN id="token-43-9" pos="unknown" morph="none" start_char="3250" end_char="3259">bleach–but</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="3261" end_char="3267">clearly</TOKEN>
<TOKEN id="token-43-11" pos="word" morph="none" start_char="3269" end_char="3271">you</TOKEN>
<TOKEN id="token-43-12" pos="word" morph="none" start_char="3273" end_char="3275">are</TOKEN>
<TOKEN id="token-43-13" pos="word" morph="none" start_char="3277" end_char="3283">getting</TOKEN>
<TOKEN id="token-43-14" pos="word" morph="none" start_char="3285" end_char="3286">by</TOKEN>
<TOKEN id="token-43-15" pos="word" morph="none" start_char="3288" end_char="3291">with</TOKEN>
<TOKEN id="token-43-16" pos="word" morph="none" start_char="3293" end_char="3294">it</TOKEN>
<TOKEN id="token-43-17" pos="word" morph="none" start_char="3296" end_char="3298">and</TOKEN>
<TOKEN id="token-43-18" pos="word" morph="none" start_char="3300" end_char="3309">presumably</TOKEN>
<TOKEN id="token-43-19" pos="word" morph="none" start_char="3311" end_char="3315">still</TOKEN>
<TOKEN id="token-43-20" pos="word" morph="none" start_char="3317" end_char="3320">well</TOKEN>
<TOKEN id="token-43-21" pos="word" morph="none" start_char="3322" end_char="3327">enough</TOKEN>
<TOKEN id="token-43-22" pos="word" morph="none" start_char="3329" end_char="3330">to</TOKEN>
<TOKEN id="token-43-23" pos="word" morph="none" start_char="3332" end_char="3336">write</TOKEN>
<TOKEN id="token-43-24" pos="punct" morph="none" start_char="3337" end_char="3337">.</TOKEN>
</SEG>
<SEG id="segment-44" start_char="3339" end_char="3392">
<ORIGINAL_TEXT>My dentist says to rinse my mouth with diluted bleach.</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="3339" end_char="3340">My</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="3342" end_char="3348">dentist</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="3350" end_char="3353">says</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="3355" end_char="3356">to</TOKEN>
<TOKEN id="token-44-4" pos="word" morph="none" start_char="3358" end_char="3362">rinse</TOKEN>
<TOKEN id="token-44-5" pos="word" morph="none" start_char="3364" end_char="3365">my</TOKEN>
<TOKEN id="token-44-6" pos="word" morph="none" start_char="3367" end_char="3371">mouth</TOKEN>
<TOKEN id="token-44-7" pos="word" morph="none" start_char="3373" end_char="3376">with</TOKEN>
<TOKEN id="token-44-8" pos="word" morph="none" start_char="3378" end_char="3384">diluted</TOKEN>
<TOKEN id="token-44-9" pos="word" morph="none" start_char="3386" end_char="3391">bleach</TOKEN>
<TOKEN id="token-44-10" pos="punct" morph="none" start_char="3392" end_char="3392">.</TOKEN>
</SEG>
<SEG id="segment-45" start_char="3394" end_char="3477">
<ORIGINAL_TEXT>In fact that has been in vogue among west coast dentists for about the last 8 years.</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="3394" end_char="3395">In</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="3397" end_char="3400">fact</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="3402" end_char="3405">that</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="3407" end_char="3409">has</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="3411" end_char="3414">been</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="3416" end_char="3417">in</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="3419" end_char="3423">vogue</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="3425" end_char="3429">among</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="3431" end_char="3434">west</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="3436" end_char="3440">coast</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="3442" end_char="3449">dentists</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="3451" end_char="3453">for</TOKEN>
<TOKEN id="token-45-12" pos="word" morph="none" start_char="3455" end_char="3459">about</TOKEN>
<TOKEN id="token-45-13" pos="word" morph="none" start_char="3461" end_char="3463">the</TOKEN>
<TOKEN id="token-45-14" pos="word" morph="none" start_char="3465" end_char="3468">last</TOKEN>
<TOKEN id="token-45-15" pos="word" morph="none" start_char="3470" end_char="3470">8</TOKEN>
<TOKEN id="token-45-16" pos="word" morph="none" start_char="3472" end_char="3476">years</TOKEN>
<TOKEN id="token-45-17" pos="punct" morph="none" start_char="3477" end_char="3477">.</TOKEN>
</SEG>
<SEG id="segment-46" start_char="3479" end_char="3555">
<ORIGINAL_TEXT>I refused to do it, but many are and doing great keeping the cavities at bay.</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="3479" end_char="3479">I</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="3481" end_char="3487">refused</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="3489" end_char="3490">to</TOKEN>
<TOKEN id="token-46-3" pos="word" morph="none" start_char="3492" end_char="3493">do</TOKEN>
<TOKEN id="token-46-4" pos="word" morph="none" start_char="3495" end_char="3496">it</TOKEN>
<TOKEN id="token-46-5" pos="punct" morph="none" start_char="3497" end_char="3497">,</TOKEN>
<TOKEN id="token-46-6" pos="word" morph="none" start_char="3499" end_char="3501">but</TOKEN>
<TOKEN id="token-46-7" pos="word" morph="none" start_char="3503" end_char="3506">many</TOKEN>
<TOKEN id="token-46-8" pos="word" morph="none" start_char="3508" end_char="3510">are</TOKEN>
<TOKEN id="token-46-9" pos="word" morph="none" start_char="3512" end_char="3514">and</TOKEN>
<TOKEN id="token-46-10" pos="word" morph="none" start_char="3516" end_char="3520">doing</TOKEN>
<TOKEN id="token-46-11" pos="word" morph="none" start_char="3522" end_char="3526">great</TOKEN>
<TOKEN id="token-46-12" pos="word" morph="none" start_char="3528" end_char="3534">keeping</TOKEN>
<TOKEN id="token-46-13" pos="word" morph="none" start_char="3536" end_char="3538">the</TOKEN>
<TOKEN id="token-46-14" pos="word" morph="none" start_char="3540" end_char="3547">cavities</TOKEN>
<TOKEN id="token-46-15" pos="word" morph="none" start_char="3549" end_char="3550">at</TOKEN>
<TOKEN id="token-46-16" pos="word" morph="none" start_char="3552" end_char="3554">bay</TOKEN>
<TOKEN id="token-46-17" pos="punct" morph="none" start_char="3555" end_char="3555">.</TOKEN>
</SEG>
<SEG id="segment-47" start_char="3557" end_char="3638">
<ORIGINAL_TEXT>So you may be right that some dilute usage is not as dangerous as one would think.</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="3557" end_char="3558">So</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="3560" end_char="3562">you</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="3564" end_char="3566">may</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="3568" end_char="3569">be</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="3571" end_char="3575">right</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="3577" end_char="3580">that</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="3582" end_char="3585">some</TOKEN>
<TOKEN id="token-47-7" pos="word" morph="none" start_char="3587" end_char="3592">dilute</TOKEN>
<TOKEN id="token-47-8" pos="word" morph="none" start_char="3594" end_char="3598">usage</TOKEN>
<TOKEN id="token-47-9" pos="word" morph="none" start_char="3600" end_char="3601">is</TOKEN>
<TOKEN id="token-47-10" pos="word" morph="none" start_char="3603" end_char="3605">not</TOKEN>
<TOKEN id="token-47-11" pos="word" morph="none" start_char="3607" end_char="3608">as</TOKEN>
<TOKEN id="token-47-12" pos="word" morph="none" start_char="3610" end_char="3618">dangerous</TOKEN>
<TOKEN id="token-47-13" pos="word" morph="none" start_char="3620" end_char="3621">as</TOKEN>
<TOKEN id="token-47-14" pos="word" morph="none" start_char="3623" end_char="3625">one</TOKEN>
<TOKEN id="token-47-15" pos="word" morph="none" start_char="3627" end_char="3631">would</TOKEN>
<TOKEN id="token-47-16" pos="word" morph="none" start_char="3633" end_char="3637">think</TOKEN>
<TOKEN id="token-47-17" pos="punct" morph="none" start_char="3638" end_char="3638">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
