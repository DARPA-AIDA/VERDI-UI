<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATCA" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="910" raw_text_md5="5adf44aa8088c49042aba8a73a33061e">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="87">
<ORIGINAL_TEXT>Un experto alemán cree que fue el perro mapache el animal que transmitió el coronavirus</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="2">Un</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="4" end_char="10">experto</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="12" end_char="17">alemán</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="19" end_char="22">cree</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="24" end_char="26">que</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="28" end_char="30">fue</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="32" end_char="33">el</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="35" end_char="39">perro</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="41" end_char="47">mapache</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="49" end_char="50">el</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="52" end_char="57">animal</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="59" end_char="61">que</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="63" end_char="72">transmitió</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="74" end_char="75">el</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="77" end_char="87">coronavirus</TOKEN>
</SEG>
<SEG id="segment-1" start_char="91" end_char="328">
<ORIGINAL_TEXT>El director del instituto de Virología del Hospital Charité de Berlí, Christian Drosten, que fue uno de los investigadores del SARS de 2003, ha señalado en una entrevista que cree que el posible origen del coronavirus es el perro mapache.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="91" end_char="92">El</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="94" end_char="101">director</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="103" end_char="105">del</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="107" end_char="115">instituto</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="117" end_char="118">de</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="120" end_char="128">Virología</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="130" end_char="132">del</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="134" end_char="141">Hospital</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="143" end_char="149">Charité</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="151" end_char="152">de</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="154" end_char="158">Berlí</TOKEN>
<TOKEN id="token-1-11" pos="punct" morph="none" start_char="159" end_char="159">,</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="161" end_char="169">Christian</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="171" end_char="177">Drosten</TOKEN>
<TOKEN id="token-1-14" pos="punct" morph="none" start_char="178" end_char="178">,</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="180" end_char="182">que</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="184" end_char="186">fue</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="188" end_char="190">uno</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="192" end_char="193">de</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="195" end_char="197">los</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="199" end_char="212">investigadores</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="214" end_char="216">del</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="218" end_char="221">SARS</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="223" end_char="224">de</TOKEN>
<TOKEN id="token-1-24" pos="word" morph="none" start_char="226" end_char="229">2003</TOKEN>
<TOKEN id="token-1-25" pos="punct" morph="none" start_char="230" end_char="230">,</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="232" end_char="233">ha</TOKEN>
<TOKEN id="token-1-27" pos="word" morph="none" start_char="235" end_char="242">señalado</TOKEN>
<TOKEN id="token-1-28" pos="word" morph="none" start_char="244" end_char="245">en</TOKEN>
<TOKEN id="token-1-29" pos="word" morph="none" start_char="247" end_char="249">una</TOKEN>
<TOKEN id="token-1-30" pos="word" morph="none" start_char="251" end_char="260">entrevista</TOKEN>
<TOKEN id="token-1-31" pos="word" morph="none" start_char="262" end_char="264">que</TOKEN>
<TOKEN id="token-1-32" pos="word" morph="none" start_char="266" end_char="269">cree</TOKEN>
<TOKEN id="token-1-33" pos="word" morph="none" start_char="271" end_char="273">que</TOKEN>
<TOKEN id="token-1-34" pos="word" morph="none" start_char="275" end_char="276">el</TOKEN>
<TOKEN id="token-1-35" pos="word" morph="none" start_char="278" end_char="284">posible</TOKEN>
<TOKEN id="token-1-36" pos="word" morph="none" start_char="286" end_char="291">origen</TOKEN>
<TOKEN id="token-1-37" pos="word" morph="none" start_char="293" end_char="295">del</TOKEN>
<TOKEN id="token-1-38" pos="word" morph="none" start_char="297" end_char="307">coronavirus</TOKEN>
<TOKEN id="token-1-39" pos="word" morph="none" start_char="309" end_char="310">es</TOKEN>
<TOKEN id="token-1-40" pos="word" morph="none" start_char="312" end_char="313">el</TOKEN>
<TOKEN id="token-1-41" pos="word" morph="none" start_char="315" end_char="319">perro</TOKEN>
<TOKEN id="token-1-42" pos="word" morph="none" start_char="321" end_char="327">mapache</TOKEN>
<TOKEN id="token-1-43" pos="punct" morph="none" start_char="328" end_char="328">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="331" end_char="497">
<ORIGINAL_TEXT>En una entrevista concedida a The Guardian diciendo que no ve ninguna evidencia de que el virus pasara por los pangolines a los humanos, como algunos estudios afirman.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="331" end_char="332">En</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="334" end_char="336">una</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="338" end_char="347">entrevista</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="349" end_char="357">concedida</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="359" end_char="359">a</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="361" end_char="363">The</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="365" end_char="372">Guardian</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="374" end_char="381">diciendo</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="383" end_char="385">que</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="387" end_char="388">no</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="390" end_char="391">ve</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="393" end_char="399">ninguna</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="401" end_char="409">evidencia</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="411" end_char="412">de</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="414" end_char="416">que</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="418" end_char="419">el</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="421" end_char="425">virus</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="427" end_char="432">pasara</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="434" end_char="436">por</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="438" end_char="440">los</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="442" end_char="451">pangolines</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="453" end_char="453">a</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="455" end_char="457">los</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="459" end_char="465">humanos</TOKEN>
<TOKEN id="token-2-24" pos="punct" morph="none" start_char="466" end_char="466">,</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="468" end_char="471">como</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="473" end_char="479">algunos</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="481" end_char="488">estudios</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="490" end_char="496">afirman</TOKEN>
<TOKEN id="token-2-29" pos="punct" morph="none" start_char="497" end_char="497">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="499" end_char="567">
<ORIGINAL_TEXT>Por lo que explicó que "hay una pieza interesante en el antiguo Sars.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="499" end_char="501">Por</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="503" end_char="504">lo</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="506" end_char="508">que</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="510" end_char="516">explicó</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="518" end_char="520">que</TOKEN>
<TOKEN id="token-3-5" pos="punct" morph="none" start_char="522" end_char="522">"</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="523" end_char="525">hay</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="527" end_char="529">una</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="531" end_char="535">pieza</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="537" end_char="547">interesante</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="549" end_char="550">en</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="552" end_char="553">el</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="555" end_char="561">antiguo</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="563" end_char="566">Sars</TOKEN>
<TOKEN id="token-3-14" pos="punct" morph="none" start_char="567" end_char="567">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="569" end_char="645">
<ORIGINAL_TEXT>Ese virus se encontró en perros mapache, algo que todos han pasado por alto".</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="569" end_char="571">Ese</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="573" end_char="577">virus</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="579" end_char="580">se</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="582" end_char="589">encontró</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="591" end_char="592">en</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="594" end_char="599">perros</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="601" end_char="607">mapache</TOKEN>
<TOKEN id="token-4-7" pos="punct" morph="none" start_char="608" end_char="608">,</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="610" end_char="613">algo</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="615" end_char="617">que</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="619" end_char="623">todos</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="625" end_char="627">han</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="629" end_char="634">pasado</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="636" end_char="638">por</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="640" end_char="643">alto</TOKEN>
<TOKEN id="token-4-15" pos="punct" morph="none" start_char="644" end_char="645">".</TOKEN>
</SEG>
<SEG id="segment-5" start_char="648" end_char="746">
<ORIGINAL_TEXT>Añadiendo que "los perros mapache son una industria masiva en China, donde son criados en granjas".</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="648" end_char="656">Añadiendo</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="658" end_char="660">que</TOKEN>
<TOKEN id="token-5-2" pos="punct" morph="none" start_char="662" end_char="662">"</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="663" end_char="665">los</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="667" end_char="672">perros</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="674" end_char="680">mapache</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="682" end_char="684">son</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="686" end_char="688">una</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="690" end_char="698">industria</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="700" end_char="705">masiva</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="707" end_char="708">en</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="710" end_char="714">China</TOKEN>
<TOKEN id="token-5-12" pos="punct" morph="none" start_char="715" end_char="715">,</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="717" end_char="721">donde</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="723" end_char="725">son</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="727" end_char="733">criados</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="735" end_char="736">en</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="738" end_char="744">granjas</TOKEN>
<TOKEN id="token-5-18" pos="punct" morph="none" start_char="745" end_char="746">".</TOKEN>
</SEG>
<SEG id="segment-6" start_char="748" end_char="906">
<ORIGINAL_TEXT>Por lo que fue contundente en decir que si pudiera ir a China a investigar sobre el origen del coronavirus buscaría "lugares donde se crían perros de mapache".</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="748" end_char="750">Por</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="752" end_char="753">lo</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="755" end_char="757">que</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="759" end_char="761">fue</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="763" end_char="773">contundente</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="775" end_char="776">en</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="778" end_char="782">decir</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="784" end_char="786">que</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="788" end_char="789">si</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="791" end_char="797">pudiera</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="799" end_char="800">ir</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="802" end_char="802">a</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="804" end_char="808">China</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="810" end_char="810">a</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="812" end_char="821">investigar</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="823" end_char="827">sobre</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="829" end_char="830">el</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="832" end_char="837">origen</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="839" end_char="841">del</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="843" end_char="853">coronavirus</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="855" end_char="862">buscaría</TOKEN>
<TOKEN id="token-6-21" pos="punct" morph="none" start_char="864" end_char="864">"</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="865" end_char="871">lugares</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="873" end_char="877">donde</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="879" end_char="880">se</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="882" end_char="886">crían</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="888" end_char="893">perros</TOKEN>
<TOKEN id="token-6-27" pos="word" morph="none" start_char="895" end_char="896">de</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="898" end_char="904">mapache</TOKEN>
<TOKEN id="token-6-29" pos="punct" morph="none" start_char="905" end_char="906">".</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
