<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C049DT5" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="1052" raw_text_md5="cdee93e8bf241ba038f1d5bf7da7ea13">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="71">
<ORIGINAL_TEXT>Multa a cantante por propagar el bulo de que la marihuana cura la COVID</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="5">Multa</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="7" end_char="7">a</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="9" end_char="16">cantante</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="18" end_char="20">por</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="22" end_char="29">propagar</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="31" end_char="32">el</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="34" end_char="37">bulo</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="39" end_char="40">de</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="42" end_char="44">que</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="46" end_char="47">la</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="49" end_char="57">marihuana</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="59" end_char="62">cura</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="64" end_char="65">la</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="67" end_char="71">COVID</TOKEN>
</SEG>
<SEG id="segment-1" start_char="77" end_char="241">
<ORIGINAL_TEXT>A Hsieh Ho-hsien, cantante taiwanés, le ha caído una multa de unos 1800 euros por compartir una imagen en Instagram en la que se podía leer "La yerba mata al Covid".</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="77" end_char="77">A</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="79" end_char="83">Hsieh</TOKEN>
<TOKEN id="token-1-2" pos="unknown" morph="none" start_char="85" end_char="92">Ho-hsien</TOKEN>
<TOKEN id="token-1-3" pos="punct" morph="none" start_char="93" end_char="93">,</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="95" end_char="102">cantante</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="104" end_char="111">taiwanés</TOKEN>
<TOKEN id="token-1-6" pos="punct" morph="none" start_char="112" end_char="112">,</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="114" end_char="115">le</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="117" end_char="118">ha</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="120" end_char="124">caído</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="126" end_char="128">una</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="130" end_char="134">multa</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="136" end_char="137">de</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="139" end_char="142">unos</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="144" end_char="147">1800</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="149" end_char="153">euros</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="155" end_char="157">por</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="159" end_char="167">compartir</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="169" end_char="171">una</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="173" end_char="178">imagen</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="180" end_char="181">en</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="183" end_char="191">Instagram</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="193" end_char="194">en</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="196" end_char="197">la</TOKEN>
<TOKEN id="token-1-24" pos="word" morph="none" start_char="199" end_char="201">que</TOKEN>
<TOKEN id="token-1-25" pos="word" morph="none" start_char="203" end_char="204">se</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="206" end_char="210">podía</TOKEN>
<TOKEN id="token-1-27" pos="word" morph="none" start_char="212" end_char="215">leer</TOKEN>
<TOKEN id="token-1-28" pos="punct" morph="none" start_char="217" end_char="217">"</TOKEN>
<TOKEN id="token-1-29" pos="word" morph="none" start_char="218" end_char="219">La</TOKEN>
<TOKEN id="token-1-30" pos="word" morph="none" start_char="221" end_char="225">yerba</TOKEN>
<TOKEN id="token-1-31" pos="word" morph="none" start_char="227" end_char="230">mata</TOKEN>
<TOKEN id="token-1-32" pos="word" morph="none" start_char="232" end_char="233">al</TOKEN>
<TOKEN id="token-1-33" pos="word" morph="none" start_char="235" end_char="239">Covid</TOKEN>
<TOKEN id="token-1-34" pos="punct" morph="none" start_char="240" end_char="241">".</TOKEN>
</SEG>
<SEG id="segment-2" start_char="243" end_char="331">
<ORIGINAL_TEXT>El mensaje fue enviado en febrero, cuando la pandemia estaba en su peor momento en China.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="243" end_char="244">El</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="246" end_char="252">mensaje</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="254" end_char="256">fue</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="258" end_char="264">enviado</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="266" end_char="267">en</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="269" end_char="275">febrero</TOKEN>
<TOKEN id="token-2-6" pos="punct" morph="none" start_char="276" end_char="276">,</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="278" end_char="283">cuando</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="285" end_char="286">la</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="288" end_char="295">pandemia</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="297" end_char="302">estaba</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="304" end_char="305">en</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="307" end_char="308">su</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="310" end_char="313">peor</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="315" end_char="321">momento</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="323" end_char="324">en</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="326" end_char="330">China</TOKEN>
<TOKEN id="token-2-17" pos="punct" morph="none" start_char="331" end_char="331">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="334" end_char="527">
<ORIGINAL_TEXT>Según Hsieh, él se hizo eco de otro mensaje que recibió de un amigo europeo que le mandó a principios de febrero de este 2020 en el que le decía que el cannabis era capaz de matar al Sars-Cov-2.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="334" end_char="338">Según</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="340" end_char="344">Hsieh</TOKEN>
<TOKEN id="token-3-2" pos="punct" morph="none" start_char="345" end_char="345">,</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="347" end_char="348">él</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="350" end_char="351">se</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="353" end_char="356">hizo</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="358" end_char="360">eco</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="362" end_char="363">de</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="365" end_char="368">otro</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="370" end_char="376">mensaje</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="378" end_char="380">que</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="382" end_char="388">recibió</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="390" end_char="391">de</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="393" end_char="394">un</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="396" end_char="400">amigo</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="402" end_char="408">europeo</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="410" end_char="412">que</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="414" end_char="415">le</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="417" end_char="421">mandó</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="423" end_char="423">a</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="425" end_char="434">principios</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="436" end_char="437">de</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="439" end_char="445">febrero</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="447" end_char="448">de</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="450" end_char="453">este</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="455" end_char="458">2020</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="460" end_char="461">en</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="463" end_char="464">el</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="466" end_char="468">que</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="470" end_char="471">le</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="473" end_char="477">decía</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="479" end_char="481">que</TOKEN>
<TOKEN id="token-3-32" pos="word" morph="none" start_char="483" end_char="484">el</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="486" end_char="493">cannabis</TOKEN>
<TOKEN id="token-3-34" pos="word" morph="none" start_char="495" end_char="497">era</TOKEN>
<TOKEN id="token-3-35" pos="word" morph="none" start_char="499" end_char="503">capaz</TOKEN>
<TOKEN id="token-3-36" pos="word" morph="none" start_char="505" end_char="506">de</TOKEN>
<TOKEN id="token-3-37" pos="word" morph="none" start_char="508" end_char="512">matar</TOKEN>
<TOKEN id="token-3-38" pos="word" morph="none" start_char="514" end_char="515">al</TOKEN>
<TOKEN id="token-3-39" pos="unknown" morph="none" start_char="517" end_char="526">Sars-Cov-2</TOKEN>
<TOKEN id="token-3-40" pos="punct" morph="none" start_char="527" end_char="527">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="529" end_char="616">
<ORIGINAL_TEXT>La fiscalía le acusaba de haber compartido de nuevo este mensaje sin haberlo verificado.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="529" end_char="530">La</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="532" end_char="539">fiscalía</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="541" end_char="542">le</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="544" end_char="550">acusaba</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="552" end_char="553">de</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="555" end_char="559">haber</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="561" end_char="570">compartido</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="572" end_char="573">de</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="575" end_char="579">nuevo</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="581" end_char="584">este</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="586" end_char="592">mensaje</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="594" end_char="596">sin</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="598" end_char="604">haberlo</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="606" end_char="615">verificado</TOKEN>
<TOKEN id="token-4-14" pos="punct" morph="none" start_char="616" end_char="616">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="619" end_char="795">
<ORIGINAL_TEXT>La acusación formal, como se puede esperar, se resume en que Hsieh compartió información falsa de manera arbitraria causando pánico en un momento en el que existía una pandemia.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="619" end_char="620">La</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="622" end_char="630">acusación</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="632" end_char="637">formal</TOKEN>
<TOKEN id="token-5-3" pos="punct" morph="none" start_char="638" end_char="638">,</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="640" end_char="643">como</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="645" end_char="646">se</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="648" end_char="652">puede</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="654" end_char="660">esperar</TOKEN>
<TOKEN id="token-5-8" pos="punct" morph="none" start_char="661" end_char="661">,</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="663" end_char="664">se</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="666" end_char="671">resume</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="673" end_char="674">en</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="676" end_char="678">que</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="680" end_char="684">Hsieh</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="686" end_char="694">compartió</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="696" end_char="706">información</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="708" end_char="712">falsa</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="714" end_char="715">de</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="717" end_char="722">manera</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="724" end_char="733">arbitraria</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="735" end_char="742">causando</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="744" end_char="749">pánico</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="751" end_char="752">en</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="754" end_char="755">un</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="757" end_char="763">momento</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="765" end_char="766">en</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="768" end_char="769">el</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="771" end_char="773">que</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="775" end_char="781">existía</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="783" end_char="785">una</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="787" end_char="794">pandemia</TOKEN>
<TOKEN id="token-5-31" pos="punct" morph="none" start_char="795" end_char="795">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="798" end_char="850">
<ORIGINAL_TEXT>La resolución es inapelable y Hsieh tendrá que pagar.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="798" end_char="799">La</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="801" end_char="810">resolución</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="812" end_char="813">es</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="815" end_char="824">inapelable</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="826" end_char="826">y</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="828" end_char="832">Hsieh</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="834" end_char="839">tendrá</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="841" end_char="843">que</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="845" end_char="849">pagar</TOKEN>
<TOKEN id="token-6-9" pos="punct" morph="none" start_char="850" end_char="850">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="852" end_char="879">
<ORIGINAL_TEXT>No es mucho, todo sea dicho.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="852" end_char="853">No</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="855" end_char="856">es</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="858" end_char="862">mucho</TOKEN>
<TOKEN id="token-7-3" pos="punct" morph="none" start_char="863" end_char="863">,</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="865" end_char="868">todo</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="870" end_char="872">sea</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="874" end_char="878">dicho</TOKEN>
<TOKEN id="token-7-7" pos="punct" morph="none" start_char="879" end_char="879">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="881" end_char="941">
<ORIGINAL_TEXT>Hsieh ya fue detenido en diciembre 2019 por llevar marihuana.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="881" end_char="885">Hsieh</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="887" end_char="888">ya</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="890" end_char="892">fue</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="894" end_char="901">detenido</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="903" end_char="904">en</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="906" end_char="914">diciembre</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="916" end_char="919">2019</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="921" end_char="923">por</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="925" end_char="930">llevar</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="932" end_char="940">marihuana</TOKEN>
<TOKEN id="token-8-10" pos="punct" morph="none" start_char="941" end_char="941">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="943" end_char="1021">
<ORIGINAL_TEXT>Su mujer le acusó a la policía de llevar mandanga encima y por eso le pillaron.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="943" end_char="944">Su</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="946" end_char="950">mujer</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="952" end_char="953">le</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="955" end_char="959">acusó</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="961" end_char="961">a</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="963" end_char="964">la</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="966" end_char="972">policía</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="974" end_char="975">de</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="977" end_char="982">llevar</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="984" end_char="991">mandanga</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="993" end_char="998">encima</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1000" end_char="1000">y</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1002" end_char="1004">por</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1006" end_char="1008">eso</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1010" end_char="1011">le</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1013" end_char="1020">pillaron</TOKEN>
<TOKEN id="token-9-16" pos="punct" morph="none" start_char="1021" end_char="1021">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1023" end_char="1048">
<ORIGINAL_TEXT>Pero esa es otra historia.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1023" end_char="1026">Pero</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1028" end_char="1030">esa</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1032" end_char="1033">es</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1035" end_char="1038">otra</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1040" end_char="1047">historia</TOKEN>
<TOKEN id="token-10-5" pos="punct" morph="none" start_char="1048" end_char="1048">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
