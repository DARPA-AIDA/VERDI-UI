<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATQL" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="6821" raw_text_md5="702ac907199d0b31525d4a36b504c728">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="91">
<ORIGINAL_TEXT>Coronavirus: el estudio estadounidense que aumenta las dudas sobre el inicio de la pandemia</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="11">Coronavirus</TOKEN>
<TOKEN id="token-0-1" pos="punct" morph="none" start_char="12" end_char="12">:</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="14" end_char="15">el</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="17" end_char="23">estudio</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="25" end_char="38">estadounidense</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="40" end_char="42">que</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="44" end_char="50">aumenta</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="52" end_char="54">las</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="56" end_char="60">dudas</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="62" end_char="66">sobre</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="68" end_char="69">el</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="71" end_char="76">inicio</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="78" end_char="79">de</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="81" end_char="82">la</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="84" end_char="91">pandemia</TOKEN>
</SEG>
<SEG id="segment-1" start_char="95" end_char="171">
<ORIGINAL_TEXT>Estados Unidos es el país del mundo con mayor número de casos de coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="95" end_char="101">Estados</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="103" end_char="108">Unidos</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="110" end_char="111">es</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="113" end_char="114">el</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="116" end_char="119">país</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="121" end_char="123">del</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="125" end_char="129">mundo</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="131" end_char="133">con</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="135" end_char="139">mayor</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="141" end_char="146">número</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="148" end_char="149">de</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="151" end_char="155">casos</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="157" end_char="158">de</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="160" end_char="170">coronavirus</TOKEN>
<TOKEN id="token-1-14" pos="punct" morph="none" start_char="171" end_char="171">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="175" end_char="388">
<ORIGINAL_TEXT>Casi un año después de que se encendieran las primeras alarmas por el surgimiento del nuevo coronavirus Sars-CoV-2, la comunidad científica sigue haciendo descubrimientos intrigantes sobre el origen de la pandemia.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="175" end_char="178">Casi</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="180" end_char="181">un</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="183" end_char="185">año</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="187" end_char="193">después</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="195" end_char="196">de</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="198" end_char="200">que</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="202" end_char="203">se</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="205" end_char="215">encendieran</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="217" end_char="219">las</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="221" end_char="228">primeras</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="230" end_char="236">alarmas</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="238" end_char="240">por</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="242" end_char="243">el</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="245" end_char="255">surgimiento</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="257" end_char="259">del</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="261" end_char="265">nuevo</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="267" end_char="277">coronavirus</TOKEN>
<TOKEN id="token-2-17" pos="unknown" morph="none" start_char="279" end_char="288">Sars-CoV-2</TOKEN>
<TOKEN id="token-2-18" pos="punct" morph="none" start_char="289" end_char="289">,</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="291" end_char="292">la</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="294" end_char="302">comunidad</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="304" end_char="313">científica</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="315" end_char="319">sigue</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="321" end_char="328">haciendo</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="330" end_char="344">descubrimientos</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="346" end_char="356">intrigantes</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="358" end_char="362">sobre</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="364" end_char="365">el</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="367" end_char="372">origen</TOKEN>
<TOKEN id="token-2-29" pos="word" morph="none" start_char="374" end_char="375">de</TOKEN>
<TOKEN id="token-2-30" pos="word" morph="none" start_char="377" end_char="378">la</TOKEN>
<TOKEN id="token-2-31" pos="word" morph="none" start_char="380" end_char="387">pandemia</TOKEN>
<TOKEN id="token-2-32" pos="punct" morph="none" start_char="388" end_char="388">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="391" end_char="445">
<ORIGINAL_TEXT>Un estudio publicado este 30 de noviembre en la revista</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="391" end_char="392">Un</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="394" end_char="400">estudio</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="402" end_char="410">publicado</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="412" end_char="415">este</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="417" end_char="418">30</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="420" end_char="421">de</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="423" end_char="431">noviembre</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="433" end_char="434">en</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="436" end_char="437">la</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="439" end_char="445">revista</TOKEN>
</SEG>
<SEG id="segment-4" start_char="448" end_char="475">
<ORIGINAL_TEXT>Clinical Infectious Diseases</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="448" end_char="455">Clinical</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="457" end_char="466">Infectious</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="468" end_char="475">Diseases</TOKEN>
</SEG>
<SEG id="segment-5" start_char="478" end_char="682">
<ORIGINAL_TEXT>elaborado por expertos de los Centros para el Control y la Prevención de Enfermedades (CDC, por sus siglas en inglés) de Estados Unidos agregó nuevas dudas sobre el inicio real de la pandemia del covid-19.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="478" end_char="486">elaborado</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="488" end_char="490">por</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="492" end_char="499">expertos</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="501" end_char="502">de</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="504" end_char="506">los</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="508" end_char="514">Centros</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="516" end_char="519">para</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="521" end_char="522">el</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="524" end_char="530">Control</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="532" end_char="532">y</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="534" end_char="535">la</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="537" end_char="546">Prevención</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="548" end_char="549">de</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="551" end_char="562">Enfermedades</TOKEN>
<TOKEN id="token-5-14" pos="punct" morph="none" start_char="564" end_char="564">(</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="565" end_char="567">CDC</TOKEN>
<TOKEN id="token-5-16" pos="punct" morph="none" start_char="568" end_char="568">,</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="570" end_char="572">por</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="574" end_char="576">sus</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="578" end_char="583">siglas</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="585" end_char="586">en</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="588" end_char="593">inglés</TOKEN>
<TOKEN id="token-5-22" pos="punct" morph="none" start_char="594" end_char="594">)</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="596" end_char="597">de</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="599" end_char="605">Estados</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="607" end_char="612">Unidos</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="614" end_char="619">agregó</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="621" end_char="626">nuevas</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="628" end_char="632">dudas</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="634" end_char="638">sobre</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="640" end_char="641">el</TOKEN>
<TOKEN id="token-5-31" pos="word" morph="none" start_char="643" end_char="648">inicio</TOKEN>
<TOKEN id="token-5-32" pos="word" morph="none" start_char="650" end_char="653">real</TOKEN>
<TOKEN id="token-5-33" pos="word" morph="none" start_char="655" end_char="656">de</TOKEN>
<TOKEN id="token-5-34" pos="word" morph="none" start_char="658" end_char="659">la</TOKEN>
<TOKEN id="token-5-35" pos="word" morph="none" start_char="661" end_char="668">pandemia</TOKEN>
<TOKEN id="token-5-36" pos="word" morph="none" start_char="670" end_char="672">del</TOKEN>
<TOKEN id="token-5-37" pos="unknown" morph="none" start_char="674" end_char="681">covid-19</TOKEN>
<TOKEN id="token-5-38" pos="punct" morph="none" start_char="682" end_char="682">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="685" end_char="909">
<ORIGINAL_TEXT>La cronología oficial señala como fecha de partida el 31 de diciembre de 2019, cuando la autoridad sanitaria de la ciudad china de Wuhan emitió una alerta sobre una serie de casos asociados a un misterioso virus respiratorio.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="685" end_char="686">La</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="688" end_char="697">cronología</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="699" end_char="705">oficial</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="707" end_char="712">señala</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="714" end_char="717">como</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="719" end_char="723">fecha</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="725" end_char="726">de</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="728" end_char="734">partida</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="736" end_char="737">el</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="739" end_char="740">31</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="742" end_char="743">de</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="745" end_char="753">diciembre</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="755" end_char="756">de</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="758" end_char="761">2019</TOKEN>
<TOKEN id="token-6-14" pos="punct" morph="none" start_char="762" end_char="762">,</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="764" end_char="769">cuando</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="771" end_char="772">la</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="774" end_char="782">autoridad</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="784" end_char="792">sanitaria</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="794" end_char="795">de</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="797" end_char="798">la</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="800" end_char="805">ciudad</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="807" end_char="811">china</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="813" end_char="814">de</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="816" end_char="820">Wuhan</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="822" end_char="827">emitió</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="829" end_char="831">una</TOKEN>
<TOKEN id="token-6-27" pos="word" morph="none" start_char="833" end_char="838">alerta</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="840" end_char="844">sobre</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="846" end_char="848">una</TOKEN>
<TOKEN id="token-6-30" pos="word" morph="none" start_char="850" end_char="854">serie</TOKEN>
<TOKEN id="token-6-31" pos="word" morph="none" start_char="856" end_char="857">de</TOKEN>
<TOKEN id="token-6-32" pos="word" morph="none" start_char="859" end_char="863">casos</TOKEN>
<TOKEN id="token-6-33" pos="word" morph="none" start_char="865" end_char="873">asociados</TOKEN>
<TOKEN id="token-6-34" pos="word" morph="none" start_char="875" end_char="875">a</TOKEN>
<TOKEN id="token-6-35" pos="word" morph="none" start_char="877" end_char="878">un</TOKEN>
<TOKEN id="token-6-36" pos="word" morph="none" start_char="880" end_char="889">misterioso</TOKEN>
<TOKEN id="token-6-37" pos="word" morph="none" start_char="891" end_char="895">virus</TOKEN>
<TOKEN id="token-6-38" pos="word" morph="none" start_char="897" end_char="908">respiratorio</TOKEN>
<TOKEN id="token-6-39" pos="punct" morph="none" start_char="909" end_char="909">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="912" end_char="1019">
<ORIGINAL_TEXT>El punto en común entre los pacientes era un mercado municipal que vendía animales salvajes vivos y muertos.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="912" end_char="913">El</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="915" end_char="919">punto</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="921" end_char="922">en</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="924" end_char="928">común</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="930" end_char="934">entre</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="936" end_char="938">los</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="940" end_char="948">pacientes</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="950" end_char="952">era</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="954" end_char="955">un</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="957" end_char="963">mercado</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="965" end_char="973">municipal</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="975" end_char="977">que</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="979" end_char="984">vendía</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="986" end_char="993">animales</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="995" end_char="1002">salvajes</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="1004" end_char="1008">vivos</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="1010" end_char="1010">y</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="1012" end_char="1018">muertos</TOKEN>
<TOKEN id="token-7-18" pos="punct" morph="none" start_char="1019" end_char="1019">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1022" end_char="1290">
<ORIGINAL_TEXT>Ahora, 11 meses más tarde, investigadores vinculados al gobierno estadounidense han identificado retroactivamente que 39 personas de tres estados del país ya habían desarrollado anticuerpos contra el coronavirus dos semanas antes de que se produjera la alerta en China.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1022" end_char="1026">Ahora</TOKEN>
<TOKEN id="token-8-1" pos="punct" morph="none" start_char="1027" end_char="1027">,</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1029" end_char="1030">11</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1032" end_char="1036">meses</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1038" end_char="1040">más</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1042" end_char="1046">tarde</TOKEN>
<TOKEN id="token-8-6" pos="punct" morph="none" start_char="1047" end_char="1047">,</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1049" end_char="1062">investigadores</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1064" end_char="1073">vinculados</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1075" end_char="1076">al</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1078" end_char="1085">gobierno</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1087" end_char="1100">estadounidense</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1102" end_char="1104">han</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1106" end_char="1117">identificado</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1119" end_char="1134">retroactivamente</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1136" end_char="1138">que</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1140" end_char="1141">39</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1143" end_char="1150">personas</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1152" end_char="1153">de</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1155" end_char="1158">tres</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="1160" end_char="1166">estados</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="1168" end_char="1170">del</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="1172" end_char="1175">país</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="1177" end_char="1178">ya</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="1180" end_char="1185">habían</TOKEN>
<TOKEN id="token-8-25" pos="word" morph="none" start_char="1187" end_char="1198">desarrollado</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="1200" end_char="1210">anticuerpos</TOKEN>
<TOKEN id="token-8-27" pos="word" morph="none" start_char="1212" end_char="1217">contra</TOKEN>
<TOKEN id="token-8-28" pos="word" morph="none" start_char="1219" end_char="1220">el</TOKEN>
<TOKEN id="token-8-29" pos="word" morph="none" start_char="1222" end_char="1232">coronavirus</TOKEN>
<TOKEN id="token-8-30" pos="word" morph="none" start_char="1234" end_char="1236">dos</TOKEN>
<TOKEN id="token-8-31" pos="word" morph="none" start_char="1238" end_char="1244">semanas</TOKEN>
<TOKEN id="token-8-32" pos="word" morph="none" start_char="1246" end_char="1250">antes</TOKEN>
<TOKEN id="token-8-33" pos="word" morph="none" start_char="1252" end_char="1253">de</TOKEN>
<TOKEN id="token-8-34" pos="word" morph="none" start_char="1255" end_char="1257">que</TOKEN>
<TOKEN id="token-8-35" pos="word" morph="none" start_char="1259" end_char="1260">se</TOKEN>
<TOKEN id="token-8-36" pos="word" morph="none" start_char="1262" end_char="1270">produjera</TOKEN>
<TOKEN id="token-8-37" pos="word" morph="none" start_char="1272" end_char="1273">la</TOKEN>
<TOKEN id="token-8-38" pos="word" morph="none" start_char="1275" end_char="1280">alerta</TOKEN>
<TOKEN id="token-8-39" pos="word" morph="none" start_char="1282" end_char="1283">en</TOKEN>
<TOKEN id="token-8-40" pos="word" morph="none" start_char="1285" end_char="1289">China</TOKEN>
<TOKEN id="token-8-41" pos="punct" morph="none" start_char="1290" end_char="1290">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1293" end_char="1327">
<ORIGINAL_TEXT>Final de Quizás también te interese</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1293" end_char="1297">Final</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1299" end_char="1300">de</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1302" end_char="1307">Quizás</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1309" end_char="1315">también</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1317" end_char="1318">te</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1320" end_char="1327">interese</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1330" end_char="1426">
<ORIGINAL_TEXT>Estados Unidos no identificó oficialmente el primer caso en el país hasta el 21 de enero de 2020.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1330" end_char="1336">Estados</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1338" end_char="1343">Unidos</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1345" end_char="1346">no</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1348" end_char="1357">identificó</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1359" end_char="1370">oficialmente</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1372" end_char="1373">el</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1375" end_char="1380">primer</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1382" end_char="1385">caso</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1387" end_char="1388">en</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1390" end_char="1391">el</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1393" end_char="1396">país</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1398" end_char="1402">hasta</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1404" end_char="1405">el</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1407" end_char="1408">21</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1410" end_char="1411">de</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1413" end_char="1417">enero</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1419" end_char="1420">de</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1422" end_char="1425">2020</TOKEN>
<TOKEN id="token-10-18" pos="punct" morph="none" start_char="1426" end_char="1426">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1429" end_char="1537">
<ORIGINAL_TEXT>El estudio se basó en el análisis de muestras de sangre procedentes de donaciones recogidas por la Cruz Roja.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1429" end_char="1430">El</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1432" end_char="1438">estudio</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1440" end_char="1441">se</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1443" end_char="1446">basó</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1448" end_char="1449">en</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1451" end_char="1452">el</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1454" end_char="1461">análisis</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1463" end_char="1464">de</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1466" end_char="1473">muestras</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1475" end_char="1476">de</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1478" end_char="1483">sangre</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1485" end_char="1495">procedentes</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1497" end_char="1498">de</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1500" end_char="1509">donaciones</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1511" end_char="1519">recogidas</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1521" end_char="1523">por</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1525" end_char="1526">la</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1528" end_char="1531">Cruz</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1533" end_char="1536">Roja</TOKEN>
<TOKEN id="token-11-19" pos="punct" morph="none" start_char="1537" end_char="1537">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1541" end_char="1664">
<ORIGINAL_TEXT>El estudio se basó en muestras de sangre de donaciones realizadas entre el 13 de diciembre de 2019 y el 17 de enero de 2020.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1541" end_char="1542">El</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1544" end_char="1550">estudio</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1552" end_char="1553">se</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1555" end_char="1558">basó</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1560" end_char="1561">en</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1563" end_char="1570">muestras</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1572" end_char="1573">de</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1575" end_char="1580">sangre</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1582" end_char="1583">de</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1585" end_char="1594">donaciones</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1596" end_char="1605">realizadas</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1607" end_char="1611">entre</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1613" end_char="1614">el</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1616" end_char="1617">13</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1619" end_char="1620">de</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1622" end_char="1630">diciembre</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1632" end_char="1633">de</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1635" end_char="1638">2019</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1640" end_char="1640">y</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1642" end_char="1643">el</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1645" end_char="1646">17</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1648" end_char="1649">de</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1651" end_char="1655">enero</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="1657" end_char="1658">de</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="1660" end_char="1663">2020</TOKEN>
<TOKEN id="token-12-25" pos="punct" morph="none" start_char="1664" end_char="1664">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1666" end_char="1812">
<ORIGINAL_TEXT>Las 7.389 muestras analizadas fueron recolectadas de forma rutinaria de donaciones organizadas por la Cruz Roja en nueve estados de Estados Unidos.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1666" end_char="1668">Las</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1670" end_char="1674">7.389</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1676" end_char="1683">muestras</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1685" end_char="1694">analizadas</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1696" end_char="1701">fueron</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1703" end_char="1714">recolectadas</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1716" end_char="1717">de</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1719" end_char="1723">forma</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1725" end_char="1733">rutinaria</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1735" end_char="1736">de</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1738" end_char="1747">donaciones</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1749" end_char="1759">organizadas</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1761" end_char="1763">por</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1765" end_char="1766">la</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1768" end_char="1771">Cruz</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1773" end_char="1776">Roja</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1778" end_char="1779">en</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1781" end_char="1785">nueve</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1787" end_char="1793">estados</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1795" end_char="1796">de</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1798" end_char="1804">Estados</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="1806" end_char="1811">Unidos</TOKEN>
<TOKEN id="token-13-22" pos="punct" morph="none" start_char="1812" end_char="1812">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1815" end_char="1957">
<ORIGINAL_TEXT>De 1.912 muestras de donaciones realizadas entre el 13 y el 16 de diciembre, 39 dieron positivo (26 en California y 16 en Oregon o Washington).</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1815" end_char="1816">De</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1818" end_char="1822">1.912</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1824" end_char="1831">muestras</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1833" end_char="1834">de</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1836" end_char="1845">donaciones</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1847" end_char="1856">realizadas</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1858" end_char="1862">entre</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1864" end_char="1865">el</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1867" end_char="1868">13</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1870" end_char="1870">y</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1872" end_char="1873">el</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1875" end_char="1876">16</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1878" end_char="1879">de</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1881" end_char="1889">diciembre</TOKEN>
<TOKEN id="token-14-14" pos="punct" morph="none" start_char="1890" end_char="1890">,</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1892" end_char="1893">39</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1895" end_char="1900">dieron</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="1902" end_char="1909">positivo</TOKEN>
<TOKEN id="token-14-18" pos="punct" morph="none" start_char="1911" end_char="1911">(</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="1912" end_char="1913">26</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="1915" end_char="1916">en</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="1918" end_char="1927">California</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="1929" end_char="1929">y</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="1931" end_char="1932">16</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="1934" end_char="1935">en</TOKEN>
<TOKEN id="token-14-25" pos="word" morph="none" start_char="1937" end_char="1942">Oregon</TOKEN>
<TOKEN id="token-14-26" pos="word" morph="none" start_char="1944" end_char="1944">o</TOKEN>
<TOKEN id="token-14-27" pos="word" morph="none" start_char="1946" end_char="1955">Washington</TOKEN>
<TOKEN id="token-14-28" pos="punct" morph="none" start_char="1956" end_char="1957">).</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1960" end_char="2103">
<ORIGINAL_TEXT>Otras 67 muestras que contenían el virus fueron identificadas entre donaciones hechas entre el 30 de diciembre de 2019 y el 17 de enero de 2020.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1960" end_char="1964">Otras</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1966" end_char="1967">67</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1969" end_char="1976">muestras</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1978" end_char="1980">que</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1982" end_char="1990">contenían</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1992" end_char="1993">el</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1995" end_char="1999">virus</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="2001" end_char="2006">fueron</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="2008" end_char="2020">identificadas</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="2022" end_char="2026">entre</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="2028" end_char="2037">donaciones</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="2039" end_char="2044">hechas</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="2046" end_char="2050">entre</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="2052" end_char="2053">el</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="2055" end_char="2056">30</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="2058" end_char="2059">de</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="2061" end_char="2069">diciembre</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="2071" end_char="2072">de</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="2074" end_char="2077">2019</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="2079" end_char="2079">y</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="2081" end_char="2082">el</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="2084" end_char="2085">17</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="2087" end_char="2088">de</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="2090" end_char="2094">enero</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="2096" end_char="2097">de</TOKEN>
<TOKEN id="token-15-25" pos="word" morph="none" start_char="2099" end_char="2102">2020</TOKEN>
<TOKEN id="token-15-26" pos="punct" morph="none" start_char="2103" end_char="2103">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="2105" end_char="2189">
<ORIGINAL_TEXT>La edad promedio de las personas infectadas era de 52 años y la mayoría eran hombres.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="2105" end_char="2106">La</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="2108" end_char="2111">edad</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="2113" end_char="2120">promedio</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="2122" end_char="2123">de</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="2125" end_char="2127">las</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="2129" end_char="2136">personas</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="2138" end_char="2147">infectadas</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="2149" end_char="2151">era</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="2153" end_char="2154">de</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="2156" end_char="2157">52</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="2159" end_char="2162">años</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="2164" end_char="2164">y</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="2166" end_char="2167">la</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="2169" end_char="2175">mayoría</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="2177" end_char="2180">eran</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="2182" end_char="2188">hombres</TOKEN>
<TOKEN id="token-16-16" pos="punct" morph="none" start_char="2189" end_char="2189">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2192" end_char="2499">
<ORIGINAL_TEXT>Para los autores del estudio, parte de estos anticuerpos identificados deben estar vinculados a otros tipos de coronavirus que circulan por el mundo, pero la gran cantidad de personas encontradas con estos anticuerpos en el análisis indica que otra parte era muy probable que tuviera covid-19 en ese momento.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2192" end_char="2195">Para</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2197" end_char="2199">los</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2201" end_char="2207">autores</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2209" end_char="2211">del</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2213" end_char="2219">estudio</TOKEN>
<TOKEN id="token-17-5" pos="punct" morph="none" start_char="2220" end_char="2220">,</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2222" end_char="2226">parte</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2228" end_char="2229">de</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2231" end_char="2235">estos</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2237" end_char="2247">anticuerpos</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2249" end_char="2261">identificados</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2263" end_char="2267">deben</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2269" end_char="2273">estar</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2275" end_char="2284">vinculados</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2286" end_char="2286">a</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2288" end_char="2292">otros</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="2294" end_char="2298">tipos</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="2300" end_char="2301">de</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="2303" end_char="2313">coronavirus</TOKEN>
<TOKEN id="token-17-19" pos="word" morph="none" start_char="2315" end_char="2317">que</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="2319" end_char="2326">circulan</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="2328" end_char="2330">por</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="2332" end_char="2333">el</TOKEN>
<TOKEN id="token-17-23" pos="word" morph="none" start_char="2335" end_char="2339">mundo</TOKEN>
<TOKEN id="token-17-24" pos="punct" morph="none" start_char="2340" end_char="2340">,</TOKEN>
<TOKEN id="token-17-25" pos="word" morph="none" start_char="2342" end_char="2345">pero</TOKEN>
<TOKEN id="token-17-26" pos="word" morph="none" start_char="2347" end_char="2348">la</TOKEN>
<TOKEN id="token-17-27" pos="word" morph="none" start_char="2350" end_char="2353">gran</TOKEN>
<TOKEN id="token-17-28" pos="word" morph="none" start_char="2355" end_char="2362">cantidad</TOKEN>
<TOKEN id="token-17-29" pos="word" morph="none" start_char="2364" end_char="2365">de</TOKEN>
<TOKEN id="token-17-30" pos="word" morph="none" start_char="2367" end_char="2374">personas</TOKEN>
<TOKEN id="token-17-31" pos="word" morph="none" start_char="2376" end_char="2386">encontradas</TOKEN>
<TOKEN id="token-17-32" pos="word" morph="none" start_char="2388" end_char="2390">con</TOKEN>
<TOKEN id="token-17-33" pos="word" morph="none" start_char="2392" end_char="2396">estos</TOKEN>
<TOKEN id="token-17-34" pos="word" morph="none" start_char="2398" end_char="2408">anticuerpos</TOKEN>
<TOKEN id="token-17-35" pos="word" morph="none" start_char="2410" end_char="2411">en</TOKEN>
<TOKEN id="token-17-36" pos="word" morph="none" start_char="2413" end_char="2414">el</TOKEN>
<TOKEN id="token-17-37" pos="word" morph="none" start_char="2416" end_char="2423">análisis</TOKEN>
<TOKEN id="token-17-38" pos="word" morph="none" start_char="2425" end_char="2430">indica</TOKEN>
<TOKEN id="token-17-39" pos="word" morph="none" start_char="2432" end_char="2434">que</TOKEN>
<TOKEN id="token-17-40" pos="word" morph="none" start_char="2436" end_char="2439">otra</TOKEN>
<TOKEN id="token-17-41" pos="word" morph="none" start_char="2441" end_char="2445">parte</TOKEN>
<TOKEN id="token-17-42" pos="word" morph="none" start_char="2447" end_char="2449">era</TOKEN>
<TOKEN id="token-17-43" pos="word" morph="none" start_char="2451" end_char="2453">muy</TOKEN>
<TOKEN id="token-17-44" pos="word" morph="none" start_char="2455" end_char="2462">probable</TOKEN>
<TOKEN id="token-17-45" pos="word" morph="none" start_char="2464" end_char="2466">que</TOKEN>
<TOKEN id="token-17-46" pos="word" morph="none" start_char="2468" end_char="2474">tuviera</TOKEN>
<TOKEN id="token-17-47" pos="unknown" morph="none" start_char="2476" end_char="2483">covid-19</TOKEN>
<TOKEN id="token-17-48" pos="word" morph="none" start_char="2485" end_char="2486">en</TOKEN>
<TOKEN id="token-17-49" pos="word" morph="none" start_char="2488" end_char="2490">ese</TOKEN>
<TOKEN id="token-17-50" pos="word" morph="none" start_char="2492" end_char="2498">momento</TOKEN>
<TOKEN id="token-17-51" pos="punct" morph="none" start_char="2499" end_char="2499">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2502" end_char="2571">
<ORIGINAL_TEXT>Pero, ¿cómo cambia esto lo que sabemos sobre el inicio de la pandemia?</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2502" end_char="2505">Pero</TOKEN>
<TOKEN id="token-18-1" pos="punct" morph="none" start_char="2506" end_char="2506">,</TOKEN>
<TOKEN id="token-18-2" pos="punct" morph="none" start_char="2508" end_char="2508">¿</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2509" end_char="2512">cómo</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2514" end_char="2519">cambia</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2521" end_char="2524">esto</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2526" end_char="2527">lo</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2529" end_char="2531">que</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2533" end_char="2539">sabemos</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="2541" end_char="2545">sobre</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="2547" end_char="2548">el</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="2550" end_char="2555">inicio</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2557" end_char="2558">de</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="2560" end_char="2561">la</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="2563" end_char="2570">pandemia</TOKEN>
<TOKEN id="token-18-15" pos="punct" morph="none" start_char="2571" end_char="2571">?</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2574" end_char="2774">
<ORIGINAL_TEXT>Lo que se sabe hasta ahora es que el primer brote importante surgió en Wuhan en diciembre de 2019, pero varios indicios sugieren que el virus había estado circulando por el mundo semanas o meses antes.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2574" end_char="2575">Lo</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2577" end_char="2579">que</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2581" end_char="2582">se</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2584" end_char="2587">sabe</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2589" end_char="2593">hasta</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2595" end_char="2599">ahora</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2601" end_char="2602">es</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2604" end_char="2606">que</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2608" end_char="2609">el</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="2611" end_char="2616">primer</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="2618" end_char="2622">brote</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="2624" end_char="2633">importante</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="2635" end_char="2640">surgió</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="2642" end_char="2643">en</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="2645" end_char="2649">Wuhan</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="2651" end_char="2652">en</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="2654" end_char="2662">diciembre</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="2664" end_char="2665">de</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="2667" end_char="2670">2019</TOKEN>
<TOKEN id="token-19-19" pos="punct" morph="none" start_char="2671" end_char="2671">,</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="2673" end_char="2676">pero</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="2678" end_char="2683">varios</TOKEN>
<TOKEN id="token-19-22" pos="word" morph="none" start_char="2685" end_char="2692">indicios</TOKEN>
<TOKEN id="token-19-23" pos="word" morph="none" start_char="2694" end_char="2701">sugieren</TOKEN>
<TOKEN id="token-19-24" pos="word" morph="none" start_char="2703" end_char="2705">que</TOKEN>
<TOKEN id="token-19-25" pos="word" morph="none" start_char="2707" end_char="2708">el</TOKEN>
<TOKEN id="token-19-26" pos="word" morph="none" start_char="2710" end_char="2714">virus</TOKEN>
<TOKEN id="token-19-27" pos="word" morph="none" start_char="2716" end_char="2720">había</TOKEN>
<TOKEN id="token-19-28" pos="word" morph="none" start_char="2722" end_char="2727">estado</TOKEN>
<TOKEN id="token-19-29" pos="word" morph="none" start_char="2729" end_char="2738">circulando</TOKEN>
<TOKEN id="token-19-30" pos="word" morph="none" start_char="2740" end_char="2742">por</TOKEN>
<TOKEN id="token-19-31" pos="word" morph="none" start_char="2744" end_char="2745">el</TOKEN>
<TOKEN id="token-19-32" pos="word" morph="none" start_char="2747" end_char="2751">mundo</TOKEN>
<TOKEN id="token-19-33" pos="word" morph="none" start_char="2753" end_char="2759">semanas</TOKEN>
<TOKEN id="token-19-34" pos="word" morph="none" start_char="2761" end_char="2761">o</TOKEN>
<TOKEN id="token-19-35" pos="word" morph="none" start_char="2763" end_char="2767">meses</TOKEN>
<TOKEN id="token-19-36" pos="word" morph="none" start_char="2769" end_char="2773">antes</TOKEN>
<TOKEN id="token-19-37" pos="punct" morph="none" start_char="2774" end_char="2774">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2777" end_char="2901">
<ORIGINAL_TEXT>Se estima que el primer brote del nuevo coronavirus se produjo en un mercado de animales silvestres en la localidad de Wuhan.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2777" end_char="2778">Se</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2780" end_char="2785">estima</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2787" end_char="2789">que</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2791" end_char="2792">el</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2794" end_char="2799">primer</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2801" end_char="2805">brote</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2807" end_char="2809">del</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2811" end_char="2815">nuevo</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="2817" end_char="2827">coronavirus</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2829" end_char="2830">se</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2832" end_char="2838">produjo</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="2840" end_char="2841">en</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="2843" end_char="2844">un</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="2846" end_char="2852">mercado</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="2854" end_char="2855">de</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="2857" end_char="2864">animales</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="2866" end_char="2875">silvestres</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="2877" end_char="2878">en</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="2880" end_char="2881">la</TOKEN>
<TOKEN id="token-20-19" pos="word" morph="none" start_char="2883" end_char="2891">localidad</TOKEN>
<TOKEN id="token-20-20" pos="word" morph="none" start_char="2893" end_char="2894">de</TOKEN>
<TOKEN id="token-20-21" pos="word" morph="none" start_char="2896" end_char="2900">Wuhan</TOKEN>
<TOKEN id="token-20-22" pos="punct" morph="none" start_char="2901" end_char="2901">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2905" end_char="3176">
<ORIGINAL_TEXT>Los autores del estudio que identificó anticuerpos contra el nuevo coronavirus en decenas de personas en Estados Unidos dicen que este descubrimiento tiene algunas limitaciones, incluida la determinación de si las personas se infectaron en su propio país o durante viajes.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2905" end_char="2907">Los</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2909" end_char="2915">autores</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2917" end_char="2919">del</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2921" end_char="2927">estudio</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2929" end_char="2931">que</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="2933" end_char="2942">identificó</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2944" end_char="2954">anticuerpos</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="2956" end_char="2961">contra</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="2963" end_char="2964">el</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="2966" end_char="2970">nuevo</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="2972" end_char="2982">coronavirus</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="2984" end_char="2985">en</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="2987" end_char="2993">decenas</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="2995" end_char="2996">de</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="2998" end_char="3005">personas</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="3007" end_char="3008">en</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="3010" end_char="3016">Estados</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="3018" end_char="3023">Unidos</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="3025" end_char="3029">dicen</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="3031" end_char="3033">que</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="3035" end_char="3038">este</TOKEN>
<TOKEN id="token-21-21" pos="word" morph="none" start_char="3040" end_char="3053">descubrimiento</TOKEN>
<TOKEN id="token-21-22" pos="word" morph="none" start_char="3055" end_char="3059">tiene</TOKEN>
<TOKEN id="token-21-23" pos="word" morph="none" start_char="3061" end_char="3067">algunas</TOKEN>
<TOKEN id="token-21-24" pos="word" morph="none" start_char="3069" end_char="3080">limitaciones</TOKEN>
<TOKEN id="token-21-25" pos="punct" morph="none" start_char="3081" end_char="3081">,</TOKEN>
<TOKEN id="token-21-26" pos="word" morph="none" start_char="3083" end_char="3090">incluida</TOKEN>
<TOKEN id="token-21-27" pos="word" morph="none" start_char="3092" end_char="3093">la</TOKEN>
<TOKEN id="token-21-28" pos="word" morph="none" start_char="3095" end_char="3107">determinación</TOKEN>
<TOKEN id="token-21-29" pos="word" morph="none" start_char="3109" end_char="3110">de</TOKEN>
<TOKEN id="token-21-30" pos="word" morph="none" start_char="3112" end_char="3113">si</TOKEN>
<TOKEN id="token-21-31" pos="word" morph="none" start_char="3115" end_char="3117">las</TOKEN>
<TOKEN id="token-21-32" pos="word" morph="none" start_char="3119" end_char="3126">personas</TOKEN>
<TOKEN id="token-21-33" pos="word" morph="none" start_char="3128" end_char="3129">se</TOKEN>
<TOKEN id="token-21-34" pos="word" morph="none" start_char="3131" end_char="3140">infectaron</TOKEN>
<TOKEN id="token-21-35" pos="word" morph="none" start_char="3142" end_char="3143">en</TOKEN>
<TOKEN id="token-21-36" pos="word" morph="none" start_char="3145" end_char="3146">su</TOKEN>
<TOKEN id="token-21-37" pos="word" morph="none" start_char="3148" end_char="3153">propio</TOKEN>
<TOKEN id="token-21-38" pos="word" morph="none" start_char="3155" end_char="3158">país</TOKEN>
<TOKEN id="token-21-39" pos="word" morph="none" start_char="3160" end_char="3160">o</TOKEN>
<TOKEN id="token-21-40" pos="word" morph="none" start_char="3162" end_char="3168">durante</TOKEN>
<TOKEN id="token-21-41" pos="word" morph="none" start_char="3170" end_char="3175">viajes</TOKEN>
<TOKEN id="token-21-42" pos="punct" morph="none" start_char="3176" end_char="3176">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="3179" end_char="3298">
<ORIGINAL_TEXT>Una encuesta realizada previamente por la propia Cruz Roja para conocer el perfil de sus donantes arroja algunas pistas.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="3179" end_char="3181">Una</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="3183" end_char="3190">encuesta</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="3192" end_char="3200">realizada</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="3202" end_char="3212">previamente</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="3214" end_char="3216">por</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="3218" end_char="3219">la</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="3221" end_char="3226">propia</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="3228" end_char="3231">Cruz</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="3233" end_char="3236">Roja</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="3238" end_char="3241">para</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="3243" end_char="3249">conocer</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="3251" end_char="3252">el</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="3254" end_char="3259">perfil</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="3261" end_char="3262">de</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="3264" end_char="3266">sus</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="3268" end_char="3275">donantes</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="3277" end_char="3282">arroja</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="3284" end_char="3290">algunas</TOKEN>
<TOKEN id="token-22-18" pos="word" morph="none" start_char="3292" end_char="3297">pistas</TOKEN>
<TOKEN id="token-22-19" pos="punct" morph="none" start_char="3298" end_char="3298">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="3300" end_char="3452">
<ORIGINAL_TEXT>Del total, un 3% dijo haber viajado al exterior en el mes anterior a la donación, y sólo un 5% de ese 3% dijo que el destino de ese viaje estaba en Asia.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="3300" end_char="3302">Del</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="3304" end_char="3308">total</TOKEN>
<TOKEN id="token-23-2" pos="punct" morph="none" start_char="3309" end_char="3309">,</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="3311" end_char="3312">un</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="3314" end_char="3314">3</TOKEN>
<TOKEN id="token-23-5" pos="punct" morph="none" start_char="3315" end_char="3315">%</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="3317" end_char="3320">dijo</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="3322" end_char="3326">haber</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="3328" end_char="3334">viajado</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="3336" end_char="3337">al</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="3339" end_char="3346">exterior</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="3348" end_char="3349">en</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="3351" end_char="3352">el</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="3354" end_char="3356">mes</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="3358" end_char="3365">anterior</TOKEN>
<TOKEN id="token-23-15" pos="word" morph="none" start_char="3367" end_char="3367">a</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="3369" end_char="3370">la</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="3372" end_char="3379">donación</TOKEN>
<TOKEN id="token-23-18" pos="punct" morph="none" start_char="3380" end_char="3380">,</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="3382" end_char="3382">y</TOKEN>
<TOKEN id="token-23-20" pos="word" morph="none" start_char="3384" end_char="3387">sólo</TOKEN>
<TOKEN id="token-23-21" pos="word" morph="none" start_char="3389" end_char="3390">un</TOKEN>
<TOKEN id="token-23-22" pos="word" morph="none" start_char="3392" end_char="3392">5</TOKEN>
<TOKEN id="token-23-23" pos="punct" morph="none" start_char="3393" end_char="3393">%</TOKEN>
<TOKEN id="token-23-24" pos="word" morph="none" start_char="3395" end_char="3396">de</TOKEN>
<TOKEN id="token-23-25" pos="word" morph="none" start_char="3398" end_char="3400">ese</TOKEN>
<TOKEN id="token-23-26" pos="word" morph="none" start_char="3402" end_char="3402">3</TOKEN>
<TOKEN id="token-23-27" pos="punct" morph="none" start_char="3403" end_char="3403">%</TOKEN>
<TOKEN id="token-23-28" pos="word" morph="none" start_char="3405" end_char="3408">dijo</TOKEN>
<TOKEN id="token-23-29" pos="word" morph="none" start_char="3410" end_char="3412">que</TOKEN>
<TOKEN id="token-23-30" pos="word" morph="none" start_char="3414" end_char="3415">el</TOKEN>
<TOKEN id="token-23-31" pos="word" morph="none" start_char="3417" end_char="3423">destino</TOKEN>
<TOKEN id="token-23-32" pos="word" morph="none" start_char="3425" end_char="3426">de</TOKEN>
<TOKEN id="token-23-33" pos="word" morph="none" start_char="3428" end_char="3430">ese</TOKEN>
<TOKEN id="token-23-34" pos="word" morph="none" start_char="3432" end_char="3436">viaje</TOKEN>
<TOKEN id="token-23-35" pos="word" morph="none" start_char="3438" end_char="3443">estaba</TOKEN>
<TOKEN id="token-23-36" pos="word" morph="none" start_char="3445" end_char="3446">en</TOKEN>
<TOKEN id="token-23-37" pos="word" morph="none" start_char="3448" end_char="3451">Asia</TOKEN>
<TOKEN id="token-23-38" pos="punct" morph="none" start_char="3452" end_char="3452">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="3455" end_char="3599">
<ORIGINAL_TEXT>Este descubrimiento no es el primero (y probablemente no será el último) que apunta a la presencia del virus antes de la alerta oficial en China.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="3455" end_char="3458">Este</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="3460" end_char="3473">descubrimiento</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="3475" end_char="3476">no</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="3478" end_char="3479">es</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="3481" end_char="3482">el</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="3484" end_char="3490">primero</TOKEN>
<TOKEN id="token-24-6" pos="punct" morph="none" start_char="3492" end_char="3492">(</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="3493" end_char="3493">y</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="3495" end_char="3507">probablemente</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="3509" end_char="3510">no</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="3512" end_char="3515">será</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="3517" end_char="3518">el</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="3520" end_char="3525">último</TOKEN>
<TOKEN id="token-24-13" pos="punct" morph="none" start_char="3526" end_char="3526">)</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="3528" end_char="3530">que</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="3532" end_char="3537">apunta</TOKEN>
<TOKEN id="token-24-16" pos="word" morph="none" start_char="3539" end_char="3539">a</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="3541" end_char="3542">la</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="3544" end_char="3552">presencia</TOKEN>
<TOKEN id="token-24-19" pos="word" morph="none" start_char="3554" end_char="3556">del</TOKEN>
<TOKEN id="token-24-20" pos="word" morph="none" start_char="3558" end_char="3562">virus</TOKEN>
<TOKEN id="token-24-21" pos="word" morph="none" start_char="3564" end_char="3568">antes</TOKEN>
<TOKEN id="token-24-22" pos="word" morph="none" start_char="3570" end_char="3571">de</TOKEN>
<TOKEN id="token-24-23" pos="word" morph="none" start_char="3573" end_char="3574">la</TOKEN>
<TOKEN id="token-24-24" pos="word" morph="none" start_char="3576" end_char="3581">alerta</TOKEN>
<TOKEN id="token-24-25" pos="word" morph="none" start_char="3583" end_char="3589">oficial</TOKEN>
<TOKEN id="token-24-26" pos="word" morph="none" start_char="3591" end_char="3592">en</TOKEN>
<TOKEN id="token-24-27" pos="word" morph="none" start_char="3594" end_char="3598">China</TOKEN>
<TOKEN id="token-24-28" pos="punct" morph="none" start_char="3599" end_char="3599">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="3602" end_char="3806">
<ORIGINAL_TEXT>Investigadores de al menos cuatro países, incluido Brasil, señalaron la presencia del nuevo coronavirus en muestras de aguas residuales recolectadas semanas o meses antes del primer brote oficial en China.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="3602" end_char="3615">Investigadores</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="3617" end_char="3618">de</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="3620" end_char="3621">al</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="3623" end_char="3627">menos</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="3629" end_char="3634">cuatro</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="3636" end_char="3641">países</TOKEN>
<TOKEN id="token-25-6" pos="punct" morph="none" start_char="3642" end_char="3642">,</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="3644" end_char="3651">incluido</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="3653" end_char="3658">Brasil</TOKEN>
<TOKEN id="token-25-9" pos="punct" morph="none" start_char="3659" end_char="3659">,</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="3661" end_char="3669">señalaron</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="3671" end_char="3672">la</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="3674" end_char="3682">presencia</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="3684" end_char="3686">del</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="3688" end_char="3692">nuevo</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="3694" end_char="3704">coronavirus</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="3706" end_char="3707">en</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="3709" end_char="3716">muestras</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="3718" end_char="3719">de</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="3721" end_char="3725">aguas</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="3727" end_char="3736">residuales</TOKEN>
<TOKEN id="token-25-21" pos="word" morph="none" start_char="3738" end_char="3749">recolectadas</TOKEN>
<TOKEN id="token-25-22" pos="word" morph="none" start_char="3751" end_char="3757">semanas</TOKEN>
<TOKEN id="token-25-23" pos="word" morph="none" start_char="3759" end_char="3759">o</TOKEN>
<TOKEN id="token-25-24" pos="word" morph="none" start_char="3761" end_char="3765">meses</TOKEN>
<TOKEN id="token-25-25" pos="word" morph="none" start_char="3767" end_char="3771">antes</TOKEN>
<TOKEN id="token-25-26" pos="word" morph="none" start_char="3773" end_char="3775">del</TOKEN>
<TOKEN id="token-25-27" pos="word" morph="none" start_char="3777" end_char="3782">primer</TOKEN>
<TOKEN id="token-25-28" pos="word" morph="none" start_char="3784" end_char="3788">brote</TOKEN>
<TOKEN id="token-25-29" pos="word" morph="none" start_char="3790" end_char="3796">oficial</TOKEN>
<TOKEN id="token-25-30" pos="word" morph="none" start_char="3798" end_char="3799">en</TOKEN>
<TOKEN id="token-25-31" pos="word" morph="none" start_char="3801" end_char="3805">China</TOKEN>
<TOKEN id="token-25-32" pos="punct" morph="none" start_char="3806" end_char="3806">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="3809" end_char="3908">
<ORIGINAL_TEXT>El estudio que más llamó la atención fue liderado por investigadores de la Universidad de Barcelona.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="3809" end_char="3810">El</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="3812" end_char="3818">estudio</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="3820" end_char="3822">que</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="3824" end_char="3826">más</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="3828" end_char="3832">llamó</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="3834" end_char="3835">la</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="3837" end_char="3844">atención</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="3846" end_char="3848">fue</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="3850" end_char="3857">liderado</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="3859" end_char="3861">por</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="3863" end_char="3876">investigadores</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="3878" end_char="3879">de</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="3881" end_char="3882">la</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="3884" end_char="3894">Universidad</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="3896" end_char="3897">de</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="3899" end_char="3907">Barcelona</TOKEN>
<TOKEN id="token-26-16" pos="punct" morph="none" start_char="3908" end_char="3908">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="3910" end_char="4179">
<ORIGINAL_TEXT>Según ellos, hubo presencia del nuevo coronavirus en muestras congeladas recogidas en España desde el 15 de enero de 2020 (41 días antes de la primera notificación oficial en el país) y desde el 12 de marzo de 2019 (nueve meses antes del primer caso reportado en China).</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="3910" end_char="3914">Según</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="3916" end_char="3920">ellos</TOKEN>
<TOKEN id="token-27-2" pos="punct" morph="none" start_char="3921" end_char="3921">,</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="3923" end_char="3926">hubo</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="3928" end_char="3936">presencia</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="3938" end_char="3940">del</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="3942" end_char="3946">nuevo</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="3948" end_char="3958">coronavirus</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="3960" end_char="3961">en</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="3963" end_char="3970">muestras</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="3972" end_char="3981">congeladas</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="3983" end_char="3991">recogidas</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="3993" end_char="3994">en</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="3996" end_char="4001">España</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="4003" end_char="4007">desde</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="4009" end_char="4010">el</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="4012" end_char="4013">15</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="4015" end_char="4016">de</TOKEN>
<TOKEN id="token-27-18" pos="word" morph="none" start_char="4018" end_char="4022">enero</TOKEN>
<TOKEN id="token-27-19" pos="word" morph="none" start_char="4024" end_char="4025">de</TOKEN>
<TOKEN id="token-27-20" pos="word" morph="none" start_char="4027" end_char="4030">2020</TOKEN>
<TOKEN id="token-27-21" pos="punct" morph="none" start_char="4032" end_char="4032">(</TOKEN>
<TOKEN id="token-27-22" pos="word" morph="none" start_char="4033" end_char="4034">41</TOKEN>
<TOKEN id="token-27-23" pos="word" morph="none" start_char="4036" end_char="4039">días</TOKEN>
<TOKEN id="token-27-24" pos="word" morph="none" start_char="4041" end_char="4045">antes</TOKEN>
<TOKEN id="token-27-25" pos="word" morph="none" start_char="4047" end_char="4048">de</TOKEN>
<TOKEN id="token-27-26" pos="word" morph="none" start_char="4050" end_char="4051">la</TOKEN>
<TOKEN id="token-27-27" pos="word" morph="none" start_char="4053" end_char="4059">primera</TOKEN>
<TOKEN id="token-27-28" pos="word" morph="none" start_char="4061" end_char="4072">notificación</TOKEN>
<TOKEN id="token-27-29" pos="word" morph="none" start_char="4074" end_char="4080">oficial</TOKEN>
<TOKEN id="token-27-30" pos="word" morph="none" start_char="4082" end_char="4083">en</TOKEN>
<TOKEN id="token-27-31" pos="word" morph="none" start_char="4085" end_char="4086">el</TOKEN>
<TOKEN id="token-27-32" pos="word" morph="none" start_char="4088" end_char="4091">país</TOKEN>
<TOKEN id="token-27-33" pos="punct" morph="none" start_char="4092" end_char="4092">)</TOKEN>
<TOKEN id="token-27-34" pos="word" morph="none" start_char="4094" end_char="4094">y</TOKEN>
<TOKEN id="token-27-35" pos="word" morph="none" start_char="4096" end_char="4100">desde</TOKEN>
<TOKEN id="token-27-36" pos="word" morph="none" start_char="4102" end_char="4103">el</TOKEN>
<TOKEN id="token-27-37" pos="word" morph="none" start_char="4105" end_char="4106">12</TOKEN>
<TOKEN id="token-27-38" pos="word" morph="none" start_char="4108" end_char="4109">de</TOKEN>
<TOKEN id="token-27-39" pos="word" morph="none" start_char="4111" end_char="4115">marzo</TOKEN>
<TOKEN id="token-27-40" pos="word" morph="none" start_char="4117" end_char="4118">de</TOKEN>
<TOKEN id="token-27-41" pos="word" morph="none" start_char="4120" end_char="4123">2019</TOKEN>
<TOKEN id="token-27-42" pos="punct" morph="none" start_char="4125" end_char="4125">(</TOKEN>
<TOKEN id="token-27-43" pos="word" morph="none" start_char="4126" end_char="4130">nueve</TOKEN>
<TOKEN id="token-27-44" pos="word" morph="none" start_char="4132" end_char="4136">meses</TOKEN>
<TOKEN id="token-27-45" pos="word" morph="none" start_char="4138" end_char="4142">antes</TOKEN>
<TOKEN id="token-27-46" pos="word" morph="none" start_char="4144" end_char="4146">del</TOKEN>
<TOKEN id="token-27-47" pos="word" morph="none" start_char="4148" end_char="4153">primer</TOKEN>
<TOKEN id="token-27-48" pos="word" morph="none" start_char="4155" end_char="4158">caso</TOKEN>
<TOKEN id="token-27-49" pos="word" morph="none" start_char="4160" end_char="4168">reportado</TOKEN>
<TOKEN id="token-27-50" pos="word" morph="none" start_char="4170" end_char="4171">en</TOKEN>
<TOKEN id="token-27-51" pos="word" morph="none" start_char="4173" end_char="4177">China</TOKEN>
<TOKEN id="token-27-52" pos="punct" morph="none" start_char="4178" end_char="4179">).</TOKEN>
</SEG>
<SEG id="segment-28" start_char="4182" end_char="4289">
<ORIGINAL_TEXT>El análisis de las aguas residuales permite detectar la presencia del covid-19 en una localidad determinada.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="4182" end_char="4183">El</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="4185" end_char="4192">análisis</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="4194" end_char="4195">de</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="4197" end_char="4199">las</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="4201" end_char="4205">aguas</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="4207" end_char="4216">residuales</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="4218" end_char="4224">permite</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="4226" end_char="4233">detectar</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="4235" end_char="4236">la</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="4238" end_char="4246">presencia</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="4248" end_char="4250">del</TOKEN>
<TOKEN id="token-28-11" pos="unknown" morph="none" start_char="4252" end_char="4259">covid-19</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="4261" end_char="4262">en</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="4264" end_char="4266">una</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="4268" end_char="4276">localidad</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="4278" end_char="4288">determinada</TOKEN>
<TOKEN id="token-28-16" pos="punct" morph="none" start_char="4289" end_char="4289">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="4293" end_char="4383">
<ORIGINAL_TEXT>Pero aún no está claro cómo y cuándo el virus Sars-CoV-2 comenzó a infectar a las personas.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="4293" end_char="4296">Pero</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="4298" end_char="4300">aún</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="4302" end_char="4303">no</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="4305" end_char="4308">está</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="4310" end_char="4314">claro</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="4316" end_char="4319">cómo</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="4321" end_char="4321">y</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="4323" end_char="4328">cuándo</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="4330" end_char="4331">el</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="4333" end_char="4337">virus</TOKEN>
<TOKEN id="token-29-10" pos="unknown" morph="none" start_char="4339" end_char="4348">Sars-CoV-2</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="4350" end_char="4356">comenzó</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="4358" end_char="4358">a</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="4360" end_char="4367">infectar</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="4369" end_char="4369">a</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="4371" end_char="4373">las</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="4375" end_char="4382">personas</TOKEN>
<TOKEN id="token-29-17" pos="punct" morph="none" start_char="4383" end_char="4383">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="4385" end_char="4432">
<ORIGINAL_TEXT>Ni de qué animal "saltó" el virus a los humanos.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="4385" end_char="4386">Ni</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="4388" end_char="4389">de</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="4391" end_char="4393">qué</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="4395" end_char="4400">animal</TOKEN>
<TOKEN id="token-30-4" pos="punct" morph="none" start_char="4402" end_char="4402">"</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="4403" end_char="4407">saltó</TOKEN>
<TOKEN id="token-30-6" pos="punct" morph="none" start_char="4408" end_char="4408">"</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="4410" end_char="4411">el</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="4413" end_char="4417">virus</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="4419" end_char="4419">a</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="4421" end_char="4423">los</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="4425" end_char="4431">humanos</TOKEN>
<TOKEN id="token-30-12" pos="punct" morph="none" start_char="4432" end_char="4432">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="4435" end_char="4576">
<ORIGINAL_TEXT>Existe consenso entre los científicos de que el primer brote se produjo en un mercado de Wuhan que vendía animales silvestres vivos y muertos.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="4435" end_char="4440">Existe</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="4442" end_char="4449">consenso</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="4451" end_char="4455">entre</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="4457" end_char="4459">los</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="4461" end_char="4471">científicos</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="4473" end_char="4474">de</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="4476" end_char="4478">que</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="4480" end_char="4481">el</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="4483" end_char="4488">primer</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="4490" end_char="4494">brote</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="4496" end_char="4497">se</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="4499" end_char="4505">produjo</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="4507" end_char="4508">en</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="4510" end_char="4511">un</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="4513" end_char="4519">mercado</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="4521" end_char="4522">de</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="4524" end_char="4528">Wuhan</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="4530" end_char="4532">que</TOKEN>
<TOKEN id="token-31-18" pos="word" morph="none" start_char="4534" end_char="4539">vendía</TOKEN>
<TOKEN id="token-31-19" pos="word" morph="none" start_char="4541" end_char="4548">animales</TOKEN>
<TOKEN id="token-31-20" pos="word" morph="none" start_char="4550" end_char="4559">silvestres</TOKEN>
<TOKEN id="token-31-21" pos="word" morph="none" start_char="4561" end_char="4565">vivos</TOKEN>
<TOKEN id="token-31-22" pos="word" morph="none" start_char="4567" end_char="4567">y</TOKEN>
<TOKEN id="token-31-23" pos="word" morph="none" start_char="4569" end_char="4575">muertos</TOKEN>
<TOKEN id="token-31-24" pos="punct" morph="none" start_char="4576" end_char="4576">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="4578" end_char="4714">
<ORIGINAL_TEXT>Pero los investigadores no saben si el virus apareció allí o "aprovechó" las condiciones del lugar para propagarse de una persona a otra.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="4578" end_char="4581">Pero</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="4583" end_char="4585">los</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="4587" end_char="4600">investigadores</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="4602" end_char="4603">no</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="4605" end_char="4609">saben</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="4611" end_char="4612">si</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="4614" end_char="4615">el</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="4617" end_char="4621">virus</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="4623" end_char="4630">apareció</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="4632" end_char="4635">allí</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="4637" end_char="4637">o</TOKEN>
<TOKEN id="token-32-11" pos="punct" morph="none" start_char="4639" end_char="4639">"</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="4640" end_char="4648">aprovechó</TOKEN>
<TOKEN id="token-32-13" pos="punct" morph="none" start_char="4649" end_char="4649">"</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="4651" end_char="4653">las</TOKEN>
<TOKEN id="token-32-15" pos="word" morph="none" start_char="4655" end_char="4665">condiciones</TOKEN>
<TOKEN id="token-32-16" pos="word" morph="none" start_char="4667" end_char="4669">del</TOKEN>
<TOKEN id="token-32-17" pos="word" morph="none" start_char="4671" end_char="4675">lugar</TOKEN>
<TOKEN id="token-32-18" pos="word" morph="none" start_char="4677" end_char="4680">para</TOKEN>
<TOKEN id="token-32-19" pos="word" morph="none" start_char="4682" end_char="4691">propagarse</TOKEN>
<TOKEN id="token-32-20" pos="word" morph="none" start_char="4693" end_char="4694">de</TOKEN>
<TOKEN id="token-32-21" pos="word" morph="none" start_char="4696" end_char="4698">una</TOKEN>
<TOKEN id="token-32-22" pos="word" morph="none" start_char="4700" end_char="4706">persona</TOKEN>
<TOKEN id="token-32-23" pos="word" morph="none" start_char="4708" end_char="4708">a</TOKEN>
<TOKEN id="token-32-24" pos="word" morph="none" start_char="4710" end_char="4713">otra</TOKEN>
<TOKEN id="token-32-25" pos="punct" morph="none" start_char="4714" end_char="4714">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="4717" end_char="4911">
<ORIGINAL_TEXT>"Si me preguntan cuál es la mayor posibilidad, yo diría que el virus proviene de mercados que venden animales salvajes", dijo a la BBC Yuen Kwok-yung, microbiólogo de la Universidad de Hong Kong.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="punct" morph="none" start_char="4717" end_char="4717">"</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="4718" end_char="4719">Si</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="4721" end_char="4722">me</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="4724" end_char="4732">preguntan</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="4734" end_char="4737">cuál</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="4739" end_char="4740">es</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="4742" end_char="4743">la</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="4745" end_char="4749">mayor</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="4751" end_char="4761">posibilidad</TOKEN>
<TOKEN id="token-33-9" pos="punct" morph="none" start_char="4762" end_char="4762">,</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="4764" end_char="4765">yo</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="4767" end_char="4771">diría</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="4773" end_char="4775">que</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="4777" end_char="4778">el</TOKEN>
<TOKEN id="token-33-14" pos="word" morph="none" start_char="4780" end_char="4784">virus</TOKEN>
<TOKEN id="token-33-15" pos="word" morph="none" start_char="4786" end_char="4793">proviene</TOKEN>
<TOKEN id="token-33-16" pos="word" morph="none" start_char="4795" end_char="4796">de</TOKEN>
<TOKEN id="token-33-17" pos="word" morph="none" start_char="4798" end_char="4805">mercados</TOKEN>
<TOKEN id="token-33-18" pos="word" morph="none" start_char="4807" end_char="4809">que</TOKEN>
<TOKEN id="token-33-19" pos="word" morph="none" start_char="4811" end_char="4816">venden</TOKEN>
<TOKEN id="token-33-20" pos="word" morph="none" start_char="4818" end_char="4825">animales</TOKEN>
<TOKEN id="token-33-21" pos="word" morph="none" start_char="4827" end_char="4834">salvajes</TOKEN>
<TOKEN id="token-33-22" pos="punct" morph="none" start_char="4835" end_char="4836">",</TOKEN>
<TOKEN id="token-33-23" pos="word" morph="none" start_char="4838" end_char="4841">dijo</TOKEN>
<TOKEN id="token-33-24" pos="word" morph="none" start_char="4843" end_char="4843">a</TOKEN>
<TOKEN id="token-33-25" pos="word" morph="none" start_char="4845" end_char="4846">la</TOKEN>
<TOKEN id="token-33-26" pos="word" morph="none" start_char="4848" end_char="4850">BBC</TOKEN>
<TOKEN id="token-33-27" pos="word" morph="none" start_char="4852" end_char="4855">Yuen</TOKEN>
<TOKEN id="token-33-28" pos="unknown" morph="none" start_char="4857" end_char="4865">Kwok-yung</TOKEN>
<TOKEN id="token-33-29" pos="punct" morph="none" start_char="4866" end_char="4866">,</TOKEN>
<TOKEN id="token-33-30" pos="word" morph="none" start_char="4868" end_char="4879">microbiólogo</TOKEN>
<TOKEN id="token-33-31" pos="word" morph="none" start_char="4881" end_char="4882">de</TOKEN>
<TOKEN id="token-33-32" pos="word" morph="none" start_char="4884" end_char="4885">la</TOKEN>
<TOKEN id="token-33-33" pos="word" morph="none" start_char="4887" end_char="4897">Universidad</TOKEN>
<TOKEN id="token-33-34" pos="word" morph="none" start_char="4899" end_char="4900">de</TOKEN>
<TOKEN id="token-33-35" pos="word" morph="none" start_char="4902" end_char="4905">Hong</TOKEN>
<TOKEN id="token-33-36" pos="word" morph="none" start_char="4907" end_char="4910">Kong</TOKEN>
<TOKEN id="token-33-37" pos="punct" morph="none" start_char="4911" end_char="4911">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="4914" end_char="5097">
<ORIGINAL_TEXT>La propia línea de tiempo sobre el virus en China ha retrocedido, algo común cuando se trata del surgimiento de una enfermedad que se propaga rápidamente, como es el caso del covid-19.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="4914" end_char="4915">La</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="4917" end_char="4922">propia</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="4924" end_char="4928">línea</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="4930" end_char="4931">de</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="4933" end_char="4938">tiempo</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="4940" end_char="4944">sobre</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="4946" end_char="4947">el</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="4949" end_char="4953">virus</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="4955" end_char="4956">en</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="4958" end_char="4962">China</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="4964" end_char="4965">ha</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="4967" end_char="4977">retrocedido</TOKEN>
<TOKEN id="token-34-12" pos="punct" morph="none" start_char="4978" end_char="4978">,</TOKEN>
<TOKEN id="token-34-13" pos="word" morph="none" start_char="4980" end_char="4983">algo</TOKEN>
<TOKEN id="token-34-14" pos="word" morph="none" start_char="4985" end_char="4989">común</TOKEN>
<TOKEN id="token-34-15" pos="word" morph="none" start_char="4991" end_char="4996">cuando</TOKEN>
<TOKEN id="token-34-16" pos="word" morph="none" start_char="4998" end_char="4999">se</TOKEN>
<TOKEN id="token-34-17" pos="word" morph="none" start_char="5001" end_char="5005">trata</TOKEN>
<TOKEN id="token-34-18" pos="word" morph="none" start_char="5007" end_char="5009">del</TOKEN>
<TOKEN id="token-34-19" pos="word" morph="none" start_char="5011" end_char="5021">surgimiento</TOKEN>
<TOKEN id="token-34-20" pos="word" morph="none" start_char="5023" end_char="5024">de</TOKEN>
<TOKEN id="token-34-21" pos="word" morph="none" start_char="5026" end_char="5028">una</TOKEN>
<TOKEN id="token-34-22" pos="word" morph="none" start_char="5030" end_char="5039">enfermedad</TOKEN>
<TOKEN id="token-34-23" pos="word" morph="none" start_char="5041" end_char="5043">que</TOKEN>
<TOKEN id="token-34-24" pos="word" morph="none" start_char="5045" end_char="5046">se</TOKEN>
<TOKEN id="token-34-25" pos="word" morph="none" start_char="5048" end_char="5054">propaga</TOKEN>
<TOKEN id="token-34-26" pos="word" morph="none" start_char="5056" end_char="5066">rápidamente</TOKEN>
<TOKEN id="token-34-27" pos="punct" morph="none" start_char="5067" end_char="5067">,</TOKEN>
<TOKEN id="token-34-28" pos="word" morph="none" start_char="5069" end_char="5072">como</TOKEN>
<TOKEN id="token-34-29" pos="word" morph="none" start_char="5074" end_char="5075">es</TOKEN>
<TOKEN id="token-34-30" pos="word" morph="none" start_char="5077" end_char="5078">el</TOKEN>
<TOKEN id="token-34-31" pos="word" morph="none" start_char="5080" end_char="5083">caso</TOKEN>
<TOKEN id="token-34-32" pos="word" morph="none" start_char="5085" end_char="5087">del</TOKEN>
<TOKEN id="token-34-33" pos="unknown" morph="none" start_char="5089" end_char="5096">covid-19</TOKEN>
<TOKEN id="token-34-34" pos="punct" morph="none" start_char="5097" end_char="5097">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="5100" end_char="5182">
<ORIGINAL_TEXT>Un estudio realizado por médicos en Wuhan, publicado en enero por la revista médica</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="5100" end_char="5101">Un</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="5103" end_char="5109">estudio</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="5111" end_char="5119">realizado</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="5121" end_char="5123">por</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="5125" end_char="5131">médicos</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="5133" end_char="5134">en</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="5136" end_char="5140">Wuhan</TOKEN>
<TOKEN id="token-35-7" pos="punct" morph="none" start_char="5141" end_char="5141">,</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="5143" end_char="5151">publicado</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="5153" end_char="5154">en</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="5156" end_char="5160">enero</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="5162" end_char="5164">por</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="5166" end_char="5167">la</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="5169" end_char="5175">revista</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="5177" end_char="5182">médica</TOKEN>
</SEG>
<SEG id="segment-36" start_char="5185" end_char="5194">
<ORIGINAL_TEXT>The Lancet</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="5185" end_char="5187">The</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="5189" end_char="5194">Lancet</TOKEN>
</SEG>
<SEG id="segment-37" start_char="5197" end_char="5361">
<ORIGINAL_TEXT>, encontró que (hasta ahora) el primer caso de covid-19 se detectó el 1 de diciembre de 2019 y no tenía un vínculo aparente con el mercado público de vida silvestre.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="punct" morph="none" start_char="5197" end_char="5197">,</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="5199" end_char="5206">encontró</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="5208" end_char="5210">que</TOKEN>
<TOKEN id="token-37-3" pos="punct" morph="none" start_char="5212" end_char="5212">(</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="5213" end_char="5217">hasta</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="5219" end_char="5223">ahora</TOKEN>
<TOKEN id="token-37-6" pos="punct" morph="none" start_char="5224" end_char="5224">)</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="5226" end_char="5227">el</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="5229" end_char="5234">primer</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="5236" end_char="5239">caso</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="5241" end_char="5242">de</TOKEN>
<TOKEN id="token-37-11" pos="unknown" morph="none" start_char="5244" end_char="5251">covid-19</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="5253" end_char="5254">se</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="5256" end_char="5262">detectó</TOKEN>
<TOKEN id="token-37-14" pos="word" morph="none" start_char="5264" end_char="5265">el</TOKEN>
<TOKEN id="token-37-15" pos="word" morph="none" start_char="5267" end_char="5267">1</TOKEN>
<TOKEN id="token-37-16" pos="word" morph="none" start_char="5269" end_char="5270">de</TOKEN>
<TOKEN id="token-37-17" pos="word" morph="none" start_char="5272" end_char="5280">diciembre</TOKEN>
<TOKEN id="token-37-18" pos="word" morph="none" start_char="5282" end_char="5283">de</TOKEN>
<TOKEN id="token-37-19" pos="word" morph="none" start_char="5285" end_char="5288">2019</TOKEN>
<TOKEN id="token-37-20" pos="word" morph="none" start_char="5290" end_char="5290">y</TOKEN>
<TOKEN id="token-37-21" pos="word" morph="none" start_char="5292" end_char="5293">no</TOKEN>
<TOKEN id="token-37-22" pos="word" morph="none" start_char="5295" end_char="5299">tenía</TOKEN>
<TOKEN id="token-37-23" pos="word" morph="none" start_char="5301" end_char="5302">un</TOKEN>
<TOKEN id="token-37-24" pos="word" morph="none" start_char="5304" end_char="5310">vínculo</TOKEN>
<TOKEN id="token-37-25" pos="word" morph="none" start_char="5312" end_char="5319">aparente</TOKEN>
<TOKEN id="token-37-26" pos="word" morph="none" start_char="5321" end_char="5323">con</TOKEN>
<TOKEN id="token-37-27" pos="word" morph="none" start_char="5325" end_char="5326">el</TOKEN>
<TOKEN id="token-37-28" pos="word" morph="none" start_char="5328" end_char="5334">mercado</TOKEN>
<TOKEN id="token-37-29" pos="word" morph="none" start_char="5336" end_char="5342">público</TOKEN>
<TOKEN id="token-37-30" pos="word" morph="none" start_char="5344" end_char="5345">de</TOKEN>
<TOKEN id="token-37-31" pos="word" morph="none" start_char="5347" end_char="5350">vida</TOKEN>
<TOKEN id="token-37-32" pos="word" morph="none" start_char="5352" end_char="5360">silvestre</TOKEN>
<TOKEN id="token-37-33" pos="punct" morph="none" start_char="5361" end_char="5361">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="5364" end_char="5531">
<ORIGINAL_TEXT>Algunos expertos también dicen que difícilmente un virus con potencial de convertirse en una pandemia podría circular durante meses por todo el mundo sin ser detectado.</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="5364" end_char="5370">Algunos</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="5372" end_char="5379">expertos</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="5381" end_char="5387">también</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="5389" end_char="5393">dicen</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="5395" end_char="5397">que</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="5399" end_char="5410">difícilmente</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="5412" end_char="5413">un</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="5415" end_char="5419">virus</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="5421" end_char="5423">con</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="5425" end_char="5433">potencial</TOKEN>
<TOKEN id="token-38-10" pos="word" morph="none" start_char="5435" end_char="5436">de</TOKEN>
<TOKEN id="token-38-11" pos="word" morph="none" start_char="5438" end_char="5448">convertirse</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="5450" end_char="5451">en</TOKEN>
<TOKEN id="token-38-13" pos="word" morph="none" start_char="5453" end_char="5455">una</TOKEN>
<TOKEN id="token-38-14" pos="word" morph="none" start_char="5457" end_char="5464">pandemia</TOKEN>
<TOKEN id="token-38-15" pos="word" morph="none" start_char="5466" end_char="5471">podría</TOKEN>
<TOKEN id="token-38-16" pos="word" morph="none" start_char="5473" end_char="5480">circular</TOKEN>
<TOKEN id="token-38-17" pos="word" morph="none" start_char="5482" end_char="5488">durante</TOKEN>
<TOKEN id="token-38-18" pos="word" morph="none" start_char="5490" end_char="5494">meses</TOKEN>
<TOKEN id="token-38-19" pos="word" morph="none" start_char="5496" end_char="5498">por</TOKEN>
<TOKEN id="token-38-20" pos="word" morph="none" start_char="5500" end_char="5503">todo</TOKEN>
<TOKEN id="token-38-21" pos="word" morph="none" start_char="5505" end_char="5506">el</TOKEN>
<TOKEN id="token-38-22" pos="word" morph="none" start_char="5508" end_char="5512">mundo</TOKEN>
<TOKEN id="token-38-23" pos="word" morph="none" start_char="5514" end_char="5516">sin</TOKEN>
<TOKEN id="token-38-24" pos="word" morph="none" start_char="5518" end_char="5520">ser</TOKEN>
<TOKEN id="token-38-25" pos="word" morph="none" start_char="5522" end_char="5530">detectado</TOKEN>
<TOKEN id="token-38-26" pos="punct" morph="none" start_char="5531" end_char="5531">.</TOKEN>
</SEG>
<SEG id="segment-39" start_char="5534" end_char="5643">
<ORIGINAL_TEXT>Pero viajar durante semanas podría ser más factible, especialmente durante el invierno en el hemisferio norte.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="5534" end_char="5537">Pero</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="5539" end_char="5544">viajar</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="5546" end_char="5552">durante</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="5554" end_char="5560">semanas</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="5562" end_char="5567">podría</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="5569" end_char="5571">ser</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="5573" end_char="5575">más</TOKEN>
<TOKEN id="token-39-7" pos="word" morph="none" start_char="5577" end_char="5584">factible</TOKEN>
<TOKEN id="token-39-8" pos="punct" morph="none" start_char="5585" end_char="5585">,</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="5587" end_char="5599">especialmente</TOKEN>
<TOKEN id="token-39-10" pos="word" morph="none" start_char="5601" end_char="5607">durante</TOKEN>
<TOKEN id="token-39-11" pos="word" morph="none" start_char="5609" end_char="5610">el</TOKEN>
<TOKEN id="token-39-12" pos="word" morph="none" start_char="5612" end_char="5619">invierno</TOKEN>
<TOKEN id="token-39-13" pos="word" morph="none" start_char="5621" end_char="5622">en</TOKEN>
<TOKEN id="token-39-14" pos="word" morph="none" start_char="5624" end_char="5625">el</TOKEN>
<TOKEN id="token-39-15" pos="word" morph="none" start_char="5627" end_char="5636">hemisferio</TOKEN>
<TOKEN id="token-39-16" pos="word" morph="none" start_char="5638" end_char="5642">norte</TOKEN>
<TOKEN id="token-39-17" pos="punct" morph="none" start_char="5643" end_char="5643">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="5646" end_char="5755">
<ORIGINAL_TEXT>También hay dudas sobre el momento en que el nuevo coronavirus llegó a Brasil y comenzó a circular en el país.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="5646" end_char="5652">También</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="5654" end_char="5656">hay</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="5658" end_char="5662">dudas</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="5664" end_char="5668">sobre</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="5670" end_char="5671">el</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="5673" end_char="5679">momento</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="5681" end_char="5682">en</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="5684" end_char="5686">que</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="5688" end_char="5689">el</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="5691" end_char="5695">nuevo</TOKEN>
<TOKEN id="token-40-10" pos="word" morph="none" start_char="5697" end_char="5707">coronavirus</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="5709" end_char="5713">llegó</TOKEN>
<TOKEN id="token-40-12" pos="word" morph="none" start_char="5715" end_char="5715">a</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="5717" end_char="5722">Brasil</TOKEN>
<TOKEN id="token-40-14" pos="word" morph="none" start_char="5724" end_char="5724">y</TOKEN>
<TOKEN id="token-40-15" pos="word" morph="none" start_char="5726" end_char="5732">comenzó</TOKEN>
<TOKEN id="token-40-16" pos="word" morph="none" start_char="5734" end_char="5734">a</TOKEN>
<TOKEN id="token-40-17" pos="word" morph="none" start_char="5736" end_char="5743">circular</TOKEN>
<TOKEN id="token-40-18" pos="word" morph="none" start_char="5745" end_char="5746">en</TOKEN>
<TOKEN id="token-40-19" pos="word" morph="none" start_char="5748" end_char="5749">el</TOKEN>
<TOKEN id="token-40-20" pos="word" morph="none" start_char="5751" end_char="5754">país</TOKEN>
<TOKEN id="token-40-21" pos="punct" morph="none" start_char="5755" end_char="5755">.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="5758" end_char="5844">
<ORIGINAL_TEXT>El primer diagnóstico oficial en el país sudamericano ocurrió el 26 de febrero de 2020.</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="5758" end_char="5759">El</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="5761" end_char="5766">primer</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="5768" end_char="5778">diagnóstico</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="5780" end_char="5786">oficial</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="5788" end_char="5789">en</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="5791" end_char="5792">el</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="5794" end_char="5797">país</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="5799" end_char="5810">sudamericano</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="5812" end_char="5818">ocurrió</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="5820" end_char="5821">el</TOKEN>
<TOKEN id="token-41-10" pos="word" morph="none" start_char="5823" end_char="5824">26</TOKEN>
<TOKEN id="token-41-11" pos="word" morph="none" start_char="5826" end_char="5827">de</TOKEN>
<TOKEN id="token-41-12" pos="word" morph="none" start_char="5829" end_char="5835">febrero</TOKEN>
<TOKEN id="token-41-13" pos="word" morph="none" start_char="5837" end_char="5838">de</TOKEN>
<TOKEN id="token-41-14" pos="word" morph="none" start_char="5840" end_char="5843">2020</TOKEN>
<TOKEN id="token-41-15" pos="punct" morph="none" start_char="5844" end_char="5844">.</TOKEN>
</SEG>
<SEG id="segment-42" start_char="5846" end_char="5999">
<ORIGINAL_TEXT>Se trataba de un empresario de Sao Paulo de 61 años de edad que regresaba de un viaje a Italia, que para entonces era el segundo epicentro de la pandemia.</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="5846" end_char="5847">Se</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="5849" end_char="5855">trataba</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="5857" end_char="5858">de</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="5860" end_char="5861">un</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="5863" end_char="5872">empresario</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="5874" end_char="5875">de</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="5877" end_char="5879">Sao</TOKEN>
<TOKEN id="token-42-7" pos="word" morph="none" start_char="5881" end_char="5885">Paulo</TOKEN>
<TOKEN id="token-42-8" pos="word" morph="none" start_char="5887" end_char="5888">de</TOKEN>
<TOKEN id="token-42-9" pos="word" morph="none" start_char="5890" end_char="5891">61</TOKEN>
<TOKEN id="token-42-10" pos="word" morph="none" start_char="5893" end_char="5896">años</TOKEN>
<TOKEN id="token-42-11" pos="word" morph="none" start_char="5898" end_char="5899">de</TOKEN>
<TOKEN id="token-42-12" pos="word" morph="none" start_char="5901" end_char="5904">edad</TOKEN>
<TOKEN id="token-42-13" pos="word" morph="none" start_char="5906" end_char="5908">que</TOKEN>
<TOKEN id="token-42-14" pos="word" morph="none" start_char="5910" end_char="5918">regresaba</TOKEN>
<TOKEN id="token-42-15" pos="word" morph="none" start_char="5920" end_char="5921">de</TOKEN>
<TOKEN id="token-42-16" pos="word" morph="none" start_char="5923" end_char="5924">un</TOKEN>
<TOKEN id="token-42-17" pos="word" morph="none" start_char="5926" end_char="5930">viaje</TOKEN>
<TOKEN id="token-42-18" pos="word" morph="none" start_char="5932" end_char="5932">a</TOKEN>
<TOKEN id="token-42-19" pos="word" morph="none" start_char="5934" end_char="5939">Italia</TOKEN>
<TOKEN id="token-42-20" pos="punct" morph="none" start_char="5940" end_char="5940">,</TOKEN>
<TOKEN id="token-42-21" pos="word" morph="none" start_char="5942" end_char="5944">que</TOKEN>
<TOKEN id="token-42-22" pos="word" morph="none" start_char="5946" end_char="5949">para</TOKEN>
<TOKEN id="token-42-23" pos="word" morph="none" start_char="5951" end_char="5958">entonces</TOKEN>
<TOKEN id="token-42-24" pos="word" morph="none" start_char="5960" end_char="5962">era</TOKEN>
<TOKEN id="token-42-25" pos="word" morph="none" start_char="5964" end_char="5965">el</TOKEN>
<TOKEN id="token-42-26" pos="word" morph="none" start_char="5967" end_char="5973">segundo</TOKEN>
<TOKEN id="token-42-27" pos="word" morph="none" start_char="5975" end_char="5983">epicentro</TOKEN>
<TOKEN id="token-42-28" pos="word" morph="none" start_char="5985" end_char="5986">de</TOKEN>
<TOKEN id="token-42-29" pos="word" morph="none" start_char="5988" end_char="5989">la</TOKEN>
<TOKEN id="token-42-30" pos="word" morph="none" start_char="5991" end_char="5998">pandemia</TOKEN>
<TOKEN id="token-42-31" pos="punct" morph="none" start_char="5999" end_char="5999">.</TOKEN>
</SEG>
<SEG id="segment-43" start_char="6002" end_char="6120">
<ORIGINAL_TEXT>Hay evidencias de que el primer contagio en Brasil ocurrió un mes antes de que la enfermedad se detectara oficialmente.</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="6002" end_char="6004">Hay</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="6006" end_char="6015">evidencias</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="6017" end_char="6018">de</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="6020" end_char="6022">que</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="6024" end_char="6025">el</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="6027" end_char="6032">primer</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="6034" end_char="6041">contagio</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="6043" end_char="6044">en</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="6046" end_char="6051">Brasil</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="6053" end_char="6059">ocurrió</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="6061" end_char="6062">un</TOKEN>
<TOKEN id="token-43-11" pos="word" morph="none" start_char="6064" end_char="6066">mes</TOKEN>
<TOKEN id="token-43-12" pos="word" morph="none" start_char="6068" end_char="6072">antes</TOKEN>
<TOKEN id="token-43-13" pos="word" morph="none" start_char="6074" end_char="6075">de</TOKEN>
<TOKEN id="token-43-14" pos="word" morph="none" start_char="6077" end_char="6079">que</TOKEN>
<TOKEN id="token-43-15" pos="word" morph="none" start_char="6081" end_char="6082">la</TOKEN>
<TOKEN id="token-43-16" pos="word" morph="none" start_char="6084" end_char="6093">enfermedad</TOKEN>
<TOKEN id="token-43-17" pos="word" morph="none" start_char="6095" end_char="6096">se</TOKEN>
<TOKEN id="token-43-18" pos="word" morph="none" start_char="6098" end_char="6106">detectara</TOKEN>
<TOKEN id="token-43-19" pos="word" morph="none" start_char="6108" end_char="6119">oficialmente</TOKEN>
<TOKEN id="token-43-20" pos="punct" morph="none" start_char="6120" end_char="6120">.</TOKEN>
</SEG>
<SEG id="segment-44" start_char="6124" end_char="6326">
<ORIGINAL_TEXT>Pero un equipo liderado por investigadores de la Universidad Federal de Santa Catarina (UFSC) identificó la presencia del virus a partir del 27 de noviembre de 2019 en el alcantarillado de Florianópolis.</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="6124" end_char="6127">Pero</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="6129" end_char="6130">un</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="6132" end_char="6137">equipo</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="6139" end_char="6146">liderado</TOKEN>
<TOKEN id="token-44-4" pos="word" morph="none" start_char="6148" end_char="6150">por</TOKEN>
<TOKEN id="token-44-5" pos="word" morph="none" start_char="6152" end_char="6165">investigadores</TOKEN>
<TOKEN id="token-44-6" pos="word" morph="none" start_char="6167" end_char="6168">de</TOKEN>
<TOKEN id="token-44-7" pos="word" morph="none" start_char="6170" end_char="6171">la</TOKEN>
<TOKEN id="token-44-8" pos="word" morph="none" start_char="6173" end_char="6183">Universidad</TOKEN>
<TOKEN id="token-44-9" pos="word" morph="none" start_char="6185" end_char="6191">Federal</TOKEN>
<TOKEN id="token-44-10" pos="word" morph="none" start_char="6193" end_char="6194">de</TOKEN>
<TOKEN id="token-44-11" pos="word" morph="none" start_char="6196" end_char="6200">Santa</TOKEN>
<TOKEN id="token-44-12" pos="word" morph="none" start_char="6202" end_char="6209">Catarina</TOKEN>
<TOKEN id="token-44-13" pos="punct" morph="none" start_char="6211" end_char="6211">(</TOKEN>
<TOKEN id="token-44-14" pos="word" morph="none" start_char="6212" end_char="6215">UFSC</TOKEN>
<TOKEN id="token-44-15" pos="punct" morph="none" start_char="6216" end_char="6216">)</TOKEN>
<TOKEN id="token-44-16" pos="word" morph="none" start_char="6218" end_char="6227">identificó</TOKEN>
<TOKEN id="token-44-17" pos="word" morph="none" start_char="6229" end_char="6230">la</TOKEN>
<TOKEN id="token-44-18" pos="word" morph="none" start_char="6232" end_char="6240">presencia</TOKEN>
<TOKEN id="token-44-19" pos="word" morph="none" start_char="6242" end_char="6244">del</TOKEN>
<TOKEN id="token-44-20" pos="word" morph="none" start_char="6246" end_char="6250">virus</TOKEN>
<TOKEN id="token-44-21" pos="word" morph="none" start_char="6252" end_char="6252">a</TOKEN>
<TOKEN id="token-44-22" pos="word" morph="none" start_char="6254" end_char="6259">partir</TOKEN>
<TOKEN id="token-44-23" pos="word" morph="none" start_char="6261" end_char="6263">del</TOKEN>
<TOKEN id="token-44-24" pos="word" morph="none" start_char="6265" end_char="6266">27</TOKEN>
<TOKEN id="token-44-25" pos="word" morph="none" start_char="6268" end_char="6269">de</TOKEN>
<TOKEN id="token-44-26" pos="word" morph="none" start_char="6271" end_char="6279">noviembre</TOKEN>
<TOKEN id="token-44-27" pos="word" morph="none" start_char="6281" end_char="6282">de</TOKEN>
<TOKEN id="token-44-28" pos="word" morph="none" start_char="6284" end_char="6287">2019</TOKEN>
<TOKEN id="token-44-29" pos="word" morph="none" start_char="6289" end_char="6290">en</TOKEN>
<TOKEN id="token-44-30" pos="word" morph="none" start_char="6292" end_char="6293">el</TOKEN>
<TOKEN id="token-44-31" pos="word" morph="none" start_char="6295" end_char="6308">alcantarillado</TOKEN>
<TOKEN id="token-44-32" pos="word" morph="none" start_char="6310" end_char="6311">de</TOKEN>
<TOKEN id="token-44-33" pos="word" morph="none" start_char="6313" end_char="6325">Florianópolis</TOKEN>
<TOKEN id="token-44-34" pos="punct" morph="none" start_char="6326" end_char="6326">.</TOKEN>
</SEG>
<SEG id="segment-45" start_char="6329" end_char="6542">
<ORIGINAL_TEXT>Además, investigadores de la Fundación Oswaldo Cruz señalaron la existencia de al menos un caso de Sars-Cov-2 en Brasil un mes antes del primer registro oficial, que tuvo lugar entre el 19 y el 25 de enero de 2020.</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="6329" end_char="6334">Además</TOKEN>
<TOKEN id="token-45-1" pos="punct" morph="none" start_char="6335" end_char="6335">,</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="6337" end_char="6350">investigadores</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="6352" end_char="6353">de</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="6355" end_char="6356">la</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="6358" end_char="6366">Fundación</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="6368" end_char="6374">Oswaldo</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="6376" end_char="6379">Cruz</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="6381" end_char="6389">señalaron</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="6391" end_char="6392">la</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="6394" end_char="6403">existencia</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="6405" end_char="6406">de</TOKEN>
<TOKEN id="token-45-12" pos="word" morph="none" start_char="6408" end_char="6409">al</TOKEN>
<TOKEN id="token-45-13" pos="word" morph="none" start_char="6411" end_char="6415">menos</TOKEN>
<TOKEN id="token-45-14" pos="word" morph="none" start_char="6417" end_char="6418">un</TOKEN>
<TOKEN id="token-45-15" pos="word" morph="none" start_char="6420" end_char="6423">caso</TOKEN>
<TOKEN id="token-45-16" pos="word" morph="none" start_char="6425" end_char="6426">de</TOKEN>
<TOKEN id="token-45-17" pos="unknown" morph="none" start_char="6428" end_char="6437">Sars-Cov-2</TOKEN>
<TOKEN id="token-45-18" pos="word" morph="none" start_char="6439" end_char="6440">en</TOKEN>
<TOKEN id="token-45-19" pos="word" morph="none" start_char="6442" end_char="6447">Brasil</TOKEN>
<TOKEN id="token-45-20" pos="word" morph="none" start_char="6449" end_char="6450">un</TOKEN>
<TOKEN id="token-45-21" pos="word" morph="none" start_char="6452" end_char="6454">mes</TOKEN>
<TOKEN id="token-45-22" pos="word" morph="none" start_char="6456" end_char="6460">antes</TOKEN>
<TOKEN id="token-45-23" pos="word" morph="none" start_char="6462" end_char="6464">del</TOKEN>
<TOKEN id="token-45-24" pos="word" morph="none" start_char="6466" end_char="6471">primer</TOKEN>
<TOKEN id="token-45-25" pos="word" morph="none" start_char="6473" end_char="6480">registro</TOKEN>
<TOKEN id="token-45-26" pos="word" morph="none" start_char="6482" end_char="6488">oficial</TOKEN>
<TOKEN id="token-45-27" pos="punct" morph="none" start_char="6489" end_char="6489">,</TOKEN>
<TOKEN id="token-45-28" pos="word" morph="none" start_char="6491" end_char="6493">que</TOKEN>
<TOKEN id="token-45-29" pos="word" morph="none" start_char="6495" end_char="6498">tuvo</TOKEN>
<TOKEN id="token-45-30" pos="word" morph="none" start_char="6500" end_char="6504">lugar</TOKEN>
<TOKEN id="token-45-31" pos="word" morph="none" start_char="6506" end_char="6510">entre</TOKEN>
<TOKEN id="token-45-32" pos="word" morph="none" start_char="6512" end_char="6513">el</TOKEN>
<TOKEN id="token-45-33" pos="word" morph="none" start_char="6515" end_char="6516">19</TOKEN>
<TOKEN id="token-45-34" pos="word" morph="none" start_char="6518" end_char="6518">y</TOKEN>
<TOKEN id="token-45-35" pos="word" morph="none" start_char="6520" end_char="6521">el</TOKEN>
<TOKEN id="token-45-36" pos="word" morph="none" start_char="6523" end_char="6524">25</TOKEN>
<TOKEN id="token-45-37" pos="word" morph="none" start_char="6526" end_char="6527">de</TOKEN>
<TOKEN id="token-45-38" pos="word" morph="none" start_char="6529" end_char="6533">enero</TOKEN>
<TOKEN id="token-45-39" pos="word" morph="none" start_char="6535" end_char="6536">de</TOKEN>
<TOKEN id="token-45-40" pos="word" morph="none" start_char="6538" end_char="6541">2020</TOKEN>
<TOKEN id="token-45-41" pos="punct" morph="none" start_char="6542" end_char="6542">.</TOKEN>
</SEG>
<SEG id="segment-46" start_char="6545" end_char="6686">
<ORIGINAL_TEXT>No se sabe si esa persona se contagió durante un viaje o por transmisión comunitaria (de otros habitantes del lugar donde vive o se traslada).</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="6545" end_char="6546">No</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="6548" end_char="6549">se</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="6551" end_char="6554">sabe</TOKEN>
<TOKEN id="token-46-3" pos="word" morph="none" start_char="6556" end_char="6557">si</TOKEN>
<TOKEN id="token-46-4" pos="word" morph="none" start_char="6559" end_char="6561">esa</TOKEN>
<TOKEN id="token-46-5" pos="word" morph="none" start_char="6563" end_char="6569">persona</TOKEN>
<TOKEN id="token-46-6" pos="word" morph="none" start_char="6571" end_char="6572">se</TOKEN>
<TOKEN id="token-46-7" pos="word" morph="none" start_char="6574" end_char="6581">contagió</TOKEN>
<TOKEN id="token-46-8" pos="word" morph="none" start_char="6583" end_char="6589">durante</TOKEN>
<TOKEN id="token-46-9" pos="word" morph="none" start_char="6591" end_char="6592">un</TOKEN>
<TOKEN id="token-46-10" pos="word" morph="none" start_char="6594" end_char="6598">viaje</TOKEN>
<TOKEN id="token-46-11" pos="word" morph="none" start_char="6600" end_char="6600">o</TOKEN>
<TOKEN id="token-46-12" pos="word" morph="none" start_char="6602" end_char="6604">por</TOKEN>
<TOKEN id="token-46-13" pos="word" morph="none" start_char="6606" end_char="6616">transmisión</TOKEN>
<TOKEN id="token-46-14" pos="word" morph="none" start_char="6618" end_char="6628">comunitaria</TOKEN>
<TOKEN id="token-46-15" pos="punct" morph="none" start_char="6630" end_char="6630">(</TOKEN>
<TOKEN id="token-46-16" pos="word" morph="none" start_char="6631" end_char="6632">de</TOKEN>
<TOKEN id="token-46-17" pos="word" morph="none" start_char="6634" end_char="6638">otros</TOKEN>
<TOKEN id="token-46-18" pos="word" morph="none" start_char="6640" end_char="6649">habitantes</TOKEN>
<TOKEN id="token-46-19" pos="word" morph="none" start_char="6651" end_char="6653">del</TOKEN>
<TOKEN id="token-46-20" pos="word" morph="none" start_char="6655" end_char="6659">lugar</TOKEN>
<TOKEN id="token-46-21" pos="word" morph="none" start_char="6661" end_char="6665">donde</TOKEN>
<TOKEN id="token-46-22" pos="word" morph="none" start_char="6667" end_char="6670">vive</TOKEN>
<TOKEN id="token-46-23" pos="word" morph="none" start_char="6672" end_char="6672">o</TOKEN>
<TOKEN id="token-46-24" pos="word" morph="none" start_char="6674" end_char="6675">se</TOKEN>
<TOKEN id="token-46-25" pos="word" morph="none" start_char="6677" end_char="6684">traslada</TOKEN>
<TOKEN id="token-46-26" pos="punct" morph="none" start_char="6685" end_char="6686">).</TOKEN>
</SEG>
<SEG id="segment-47" start_char="6689" end_char="6742">
<ORIGINAL_TEXT>Ahora puedes recibir notificaciones de BBC News Mundo.</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="6689" end_char="6693">Ahora</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="6695" end_char="6700">puedes</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="6702" end_char="6708">recibir</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="6710" end_char="6723">notificaciones</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="6725" end_char="6726">de</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="6728" end_char="6730">BBC</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="6732" end_char="6735">News</TOKEN>
<TOKEN id="token-47-7" pos="word" morph="none" start_char="6737" end_char="6741">Mundo</TOKEN>
<TOKEN id="token-47-8" pos="punct" morph="none" start_char="6742" end_char="6742">.</TOKEN>
</SEG>
<SEG id="segment-48" start_char="6744" end_char="6817">
<ORIGINAL_TEXT>Descarga nuestra app y actívalas para no perderte nuestro mejor contenido.</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="6744" end_char="6751">Descarga</TOKEN>
<TOKEN id="token-48-1" pos="word" morph="none" start_char="6753" end_char="6759">nuestra</TOKEN>
<TOKEN id="token-48-2" pos="word" morph="none" start_char="6761" end_char="6763">app</TOKEN>
<TOKEN id="token-48-3" pos="word" morph="none" start_char="6765" end_char="6765">y</TOKEN>
<TOKEN id="token-48-4" pos="word" morph="none" start_char="6767" end_char="6775">actívalas</TOKEN>
<TOKEN id="token-48-5" pos="word" morph="none" start_char="6777" end_char="6780">para</TOKEN>
<TOKEN id="token-48-6" pos="word" morph="none" start_char="6782" end_char="6783">no</TOKEN>
<TOKEN id="token-48-7" pos="word" morph="none" start_char="6785" end_char="6792">perderte</TOKEN>
<TOKEN id="token-48-8" pos="word" morph="none" start_char="6794" end_char="6800">nuestro</TOKEN>
<TOKEN id="token-48-9" pos="word" morph="none" start_char="6802" end_char="6806">mejor</TOKEN>
<TOKEN id="token-48-10" pos="word" morph="none" start_char="6808" end_char="6816">contenido</TOKEN>
<TOKEN id="token-48-11" pos="punct" morph="none" start_char="6817" end_char="6817">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
