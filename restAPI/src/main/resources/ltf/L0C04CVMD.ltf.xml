<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CVMD" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="8344" raw_text_md5="b35fdca92e7d2aa3ab66fea0ea75a011">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="65">
<ORIGINAL_TEXT>¿Es fiable el estudio sobre la hidroxicloroquina de «The Lancet»?</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="punct" morph="none" start_char="1" end_char="1">¿</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="2" end_char="3">Es</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="5" end_char="10">fiable</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="12" end_char="13">el</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="15" end_char="21">estudio</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="23" end_char="27">sobre</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="29" end_char="30">la</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="32" end_char="48">hidroxicloroquina</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="50" end_char="51">de</TOKEN>
<TOKEN id="token-0-9" pos="punct" morph="none" start_char="53" end_char="53">«</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="54" end_char="56">The</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="58" end_char="63">Lancet</TOKEN>
<TOKEN id="token-0-12" pos="punct" morph="none" start_char="64" end_char="65">»?</TOKEN>
</SEG>
<SEG id="segment-1" start_char="69" end_char="119">
<ORIGINAL_TEXT>Tamara Montero Santiago / La Voz 29/05/2020 20:14 h</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="69" end_char="74">Tamara</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="76" end_char="82">Montero</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="84" end_char="91">Santiago</TOKEN>
<TOKEN id="token-1-3" pos="punct" morph="none" start_char="93" end_char="93">/</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="95" end_char="96">La</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="98" end_char="100">Voz</TOKEN>
<TOKEN id="token-1-6" pos="unknown" morph="none" start_char="102" end_char="111">29/05/2020</TOKEN>
<TOKEN id="token-1-7" pos="unknown" morph="none" start_char="113" end_char="117">20:14</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="119" end_char="119">h</TOKEN>
</SEG>
<SEG id="segment-2" start_char="122" end_char="229">
<ORIGINAL_TEXT>La noticia golpeaba hace una semana: un estudio observacional publicado en la prestigiosa revista científica</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="122" end_char="123">La</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="125" end_char="131">noticia</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="133" end_char="140">golpeaba</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="142" end_char="145">hace</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="147" end_char="149">una</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="151" end_char="156">semana</TOKEN>
<TOKEN id="token-2-6" pos="punct" morph="none" start_char="157" end_char="157">:</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="159" end_char="160">un</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="162" end_char="168">estudio</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="170" end_char="182">observacional</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="184" end_char="192">publicado</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="194" end_char="195">en</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="197" end_char="198">la</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="200" end_char="210">prestigiosa</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="212" end_char="218">revista</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="220" end_char="229">científica</TOKEN>
</SEG>
<SEG id="segment-3" start_char="232" end_char="241">
<ORIGINAL_TEXT>The Lancet</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="232" end_char="234">The</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="236" end_char="241">Lancet</TOKEN>
</SEG>
<SEG id="segment-4" start_char="244" end_char="383">
<ORIGINAL_TEXT>sugería que la hidroxicloroquina y la cloroquina no solo no beneficiaba a los pacientes de covid-19, sino que incluso tenía efectos dañinos.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="244" end_char="250">sugería</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="252" end_char="254">que</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="256" end_char="257">la</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="259" end_char="275">hidroxicloroquina</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="277" end_char="277">y</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="279" end_char="280">la</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="282" end_char="291">cloroquina</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="293" end_char="294">no</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="296" end_char="299">solo</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="301" end_char="302">no</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="304" end_char="314">beneficiaba</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="316" end_char="316">a</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="318" end_char="320">los</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="322" end_char="330">pacientes</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="332" end_char="333">de</TOKEN>
<TOKEN id="token-4-15" pos="unknown" morph="none" start_char="335" end_char="342">covid-19</TOKEN>
<TOKEN id="token-4-16" pos="punct" morph="none" start_char="343" end_char="343">,</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="345" end_char="348">sino</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="350" end_char="352">que</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="354" end_char="360">incluso</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="362" end_char="366">tenía</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="368" end_char="374">efectos</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="376" end_char="382">dañinos</TOKEN>
<TOKEN id="token-4-23" pos="punct" morph="none" start_char="383" end_char="383">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="385" end_char="556">
<ORIGINAL_TEXT>A raíz de esos resultados, derivados del estudio de más de 96.000 pacientes ingresados en hospitales de todos los continentes, la OMS paralizó los ensayos con este fármaco.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="385" end_char="385">A</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="387" end_char="390">raíz</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="392" end_char="393">de</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="395" end_char="398">esos</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="400" end_char="409">resultados</TOKEN>
<TOKEN id="token-5-5" pos="punct" morph="none" start_char="410" end_char="410">,</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="412" end_char="420">derivados</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="422" end_char="424">del</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="426" end_char="432">estudio</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="434" end_char="435">de</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="437" end_char="439">más</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="441" end_char="442">de</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="444" end_char="449">96.000</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="451" end_char="459">pacientes</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="461" end_char="470">ingresados</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="472" end_char="473">en</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="475" end_char="484">hospitales</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="486" end_char="487">de</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="489" end_char="493">todos</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="495" end_char="497">los</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="499" end_char="509">continentes</TOKEN>
<TOKEN id="token-5-21" pos="punct" morph="none" start_char="510" end_char="510">,</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="512" end_char="513">la</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="515" end_char="517">OMS</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="519" end_char="526">paralizó</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="528" end_char="530">los</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="532" end_char="538">ensayos</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="540" end_char="542">con</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="544" end_char="547">este</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="549" end_char="555">fármaco</TOKEN>
<TOKEN id="token-5-30" pos="punct" morph="none" start_char="556" end_char="556">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="558" end_char="622">
<ORIGINAL_TEXT>Y sin embargo, ahora hay dudas sobre la fiabilidad de esos datos.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="558" end_char="558">Y</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="560" end_char="562">sin</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="564" end_char="570">embargo</TOKEN>
<TOKEN id="token-6-3" pos="punct" morph="none" start_char="571" end_char="571">,</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="573" end_char="577">ahora</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="579" end_char="581">hay</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="583" end_char="587">dudas</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="589" end_char="593">sobre</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="595" end_char="596">la</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="598" end_char="607">fiabilidad</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="609" end_char="610">de</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="612" end_char="615">esos</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="617" end_char="621">datos</TOKEN>
<TOKEN id="token-6-13" pos="punct" morph="none" start_char="622" end_char="622">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="625" end_char="977">
<ORIGINAL_TEXT>Las han puesto por escrito un grupo de más de cien científicos de diversos puntos del mundo, que a través de una carta abierta dirigida a los autores de la investigación y a Richard Horton, el editor jefe de The Lancet, enumeran una serie de problemas en la metodología utilizada en este estudio y piden tener acceso a los datos para poder comprobarlos.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="625" end_char="627">Las</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="629" end_char="631">han</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="633" end_char="638">puesto</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="640" end_char="642">por</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="644" end_char="650">escrito</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="652" end_char="653">un</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="655" end_char="659">grupo</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="661" end_char="662">de</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="664" end_char="666">más</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="668" end_char="669">de</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="671" end_char="674">cien</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="676" end_char="686">científicos</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="688" end_char="689">de</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="691" end_char="698">diversos</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="700" end_char="705">puntos</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="707" end_char="709">del</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="711" end_char="715">mundo</TOKEN>
<TOKEN id="token-7-17" pos="punct" morph="none" start_char="716" end_char="716">,</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="718" end_char="720">que</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="722" end_char="722">a</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="724" end_char="729">través</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="731" end_char="732">de</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="734" end_char="736">una</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="738" end_char="742">carta</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="744" end_char="750">abierta</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="752" end_char="759">dirigida</TOKEN>
<TOKEN id="token-7-26" pos="word" morph="none" start_char="761" end_char="761">a</TOKEN>
<TOKEN id="token-7-27" pos="word" morph="none" start_char="763" end_char="765">los</TOKEN>
<TOKEN id="token-7-28" pos="word" morph="none" start_char="767" end_char="773">autores</TOKEN>
<TOKEN id="token-7-29" pos="word" morph="none" start_char="775" end_char="776">de</TOKEN>
<TOKEN id="token-7-30" pos="word" morph="none" start_char="778" end_char="779">la</TOKEN>
<TOKEN id="token-7-31" pos="word" morph="none" start_char="781" end_char="793">investigación</TOKEN>
<TOKEN id="token-7-32" pos="word" morph="none" start_char="795" end_char="795">y</TOKEN>
<TOKEN id="token-7-33" pos="word" morph="none" start_char="797" end_char="797">a</TOKEN>
<TOKEN id="token-7-34" pos="word" morph="none" start_char="799" end_char="805">Richard</TOKEN>
<TOKEN id="token-7-35" pos="word" morph="none" start_char="807" end_char="812">Horton</TOKEN>
<TOKEN id="token-7-36" pos="punct" morph="none" start_char="813" end_char="813">,</TOKEN>
<TOKEN id="token-7-37" pos="word" morph="none" start_char="815" end_char="816">el</TOKEN>
<TOKEN id="token-7-38" pos="word" morph="none" start_char="818" end_char="823">editor</TOKEN>
<TOKEN id="token-7-39" pos="word" morph="none" start_char="825" end_char="828">jefe</TOKEN>
<TOKEN id="token-7-40" pos="word" morph="none" start_char="830" end_char="831">de</TOKEN>
<TOKEN id="token-7-41" pos="word" morph="none" start_char="833" end_char="835">The</TOKEN>
<TOKEN id="token-7-42" pos="word" morph="none" start_char="837" end_char="842">Lancet</TOKEN>
<TOKEN id="token-7-43" pos="punct" morph="none" start_char="843" end_char="843">,</TOKEN>
<TOKEN id="token-7-44" pos="word" morph="none" start_char="845" end_char="852">enumeran</TOKEN>
<TOKEN id="token-7-45" pos="word" morph="none" start_char="854" end_char="856">una</TOKEN>
<TOKEN id="token-7-46" pos="word" morph="none" start_char="858" end_char="862">serie</TOKEN>
<TOKEN id="token-7-47" pos="word" morph="none" start_char="864" end_char="865">de</TOKEN>
<TOKEN id="token-7-48" pos="word" morph="none" start_char="867" end_char="875">problemas</TOKEN>
<TOKEN id="token-7-49" pos="word" morph="none" start_char="877" end_char="878">en</TOKEN>
<TOKEN id="token-7-50" pos="word" morph="none" start_char="880" end_char="881">la</TOKEN>
<TOKEN id="token-7-51" pos="word" morph="none" start_char="883" end_char="893">metodología</TOKEN>
<TOKEN id="token-7-52" pos="word" morph="none" start_char="895" end_char="903">utilizada</TOKEN>
<TOKEN id="token-7-53" pos="word" morph="none" start_char="905" end_char="906">en</TOKEN>
<TOKEN id="token-7-54" pos="word" morph="none" start_char="908" end_char="911">este</TOKEN>
<TOKEN id="token-7-55" pos="word" morph="none" start_char="913" end_char="919">estudio</TOKEN>
<TOKEN id="token-7-56" pos="word" morph="none" start_char="921" end_char="921">y</TOKEN>
<TOKEN id="token-7-57" pos="word" morph="none" start_char="923" end_char="927">piden</TOKEN>
<TOKEN id="token-7-58" pos="word" morph="none" start_char="929" end_char="933">tener</TOKEN>
<TOKEN id="token-7-59" pos="word" morph="none" start_char="935" end_char="940">acceso</TOKEN>
<TOKEN id="token-7-60" pos="word" morph="none" start_char="942" end_char="942">a</TOKEN>
<TOKEN id="token-7-61" pos="word" morph="none" start_char="944" end_char="946">los</TOKEN>
<TOKEN id="token-7-62" pos="word" morph="none" start_char="948" end_char="952">datos</TOKEN>
<TOKEN id="token-7-63" pos="word" morph="none" start_char="954" end_char="957">para</TOKEN>
<TOKEN id="token-7-64" pos="word" morph="none" start_char="959" end_char="963">poder</TOKEN>
<TOKEN id="token-7-65" pos="word" morph="none" start_char="965" end_char="976">comprobarlos</TOKEN>
<TOKEN id="token-7-66" pos="punct" morph="none" start_char="977" end_char="977">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="980" end_char="1081">
<ORIGINAL_TEXT>«El impacto ha llevado a muchos investigadores en todo el mundo a comprobar en detalle la publicación.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="punct" morph="none" start_char="980" end_char="980">«</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="981" end_char="982">El</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="984" end_char="990">impacto</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="992" end_char="993">ha</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="995" end_char="1001">llevado</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1003" end_char="1003">a</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1005" end_char="1010">muchos</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1012" end_char="1025">investigadores</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1027" end_char="1028">en</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1030" end_char="1033">todo</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1035" end_char="1036">el</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1038" end_char="1042">mundo</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1044" end_char="1044">a</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1046" end_char="1054">comprobar</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1056" end_char="1057">en</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1059" end_char="1065">detalle</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1067" end_char="1068">la</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1070" end_char="1080">publicación</TOKEN>
<TOKEN id="token-8-18" pos="punct" morph="none" start_char="1081" end_char="1081">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1083" end_char="1188">
<ORIGINAL_TEXT>Y esta comprobación ha llevado a dudas tanto sobre la metodología como sobre los datos», afirma la misiva.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1083" end_char="1083">Y</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1085" end_char="1088">esta</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1090" end_char="1101">comprobación</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1103" end_char="1104">ha</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1106" end_char="1112">llevado</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1114" end_char="1114">a</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1116" end_char="1120">dudas</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1122" end_char="1126">tanto</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1128" end_char="1132">sobre</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1134" end_char="1135">la</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1137" end_char="1147">metodología</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1149" end_char="1152">como</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1154" end_char="1158">sobre</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1160" end_char="1162">los</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1164" end_char="1168">datos</TOKEN>
<TOKEN id="token-9-15" pos="punct" morph="none" start_char="1169" end_char="1170">»,</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1172" end_char="1177">afirma</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1179" end_char="1180">la</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1182" end_char="1187">misiva</TOKEN>
<TOKEN id="token-9-19" pos="punct" morph="none" start_char="1188" end_char="1188">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1191" end_char="1522">
<ORIGINAL_TEXT>Entre las grietas que señalan los investigadores está que hay un ajuste inadecuado de factores de confusión que son conocidos, como la severidad de la enfermedad, los efectos temporales o la dosis utilizada (que de hecho son mayores que las que recomenda la FDA, cuando el 66 % de los datos provienen de hospitales norteamericanos).</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1191" end_char="1195">Entre</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1197" end_char="1199">las</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1201" end_char="1207">grietas</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1209" end_char="1211">que</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1213" end_char="1219">señalan</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1221" end_char="1223">los</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1225" end_char="1238">investigadores</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1240" end_char="1243">está</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1245" end_char="1247">que</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1249" end_char="1251">hay</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1253" end_char="1254">un</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1256" end_char="1261">ajuste</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1263" end_char="1272">inadecuado</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1274" end_char="1275">de</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1277" end_char="1284">factores</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1286" end_char="1287">de</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1289" end_char="1297">confusión</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1299" end_char="1301">que</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1303" end_char="1305">son</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1307" end_char="1315">conocidos</TOKEN>
<TOKEN id="token-10-20" pos="punct" morph="none" start_char="1316" end_char="1316">,</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1318" end_char="1321">como</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1323" end_char="1324">la</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1326" end_char="1334">severidad</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1336" end_char="1337">de</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="1339" end_char="1340">la</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="1342" end_char="1351">enfermedad</TOKEN>
<TOKEN id="token-10-27" pos="punct" morph="none" start_char="1352" end_char="1352">,</TOKEN>
<TOKEN id="token-10-28" pos="word" morph="none" start_char="1354" end_char="1356">los</TOKEN>
<TOKEN id="token-10-29" pos="word" morph="none" start_char="1358" end_char="1364">efectos</TOKEN>
<TOKEN id="token-10-30" pos="word" morph="none" start_char="1366" end_char="1375">temporales</TOKEN>
<TOKEN id="token-10-31" pos="word" morph="none" start_char="1377" end_char="1377">o</TOKEN>
<TOKEN id="token-10-32" pos="word" morph="none" start_char="1379" end_char="1380">la</TOKEN>
<TOKEN id="token-10-33" pos="word" morph="none" start_char="1382" end_char="1386">dosis</TOKEN>
<TOKEN id="token-10-34" pos="word" morph="none" start_char="1388" end_char="1396">utilizada</TOKEN>
<TOKEN id="token-10-35" pos="punct" morph="none" start_char="1398" end_char="1398">(</TOKEN>
<TOKEN id="token-10-36" pos="word" morph="none" start_char="1399" end_char="1401">que</TOKEN>
<TOKEN id="token-10-37" pos="word" morph="none" start_char="1403" end_char="1404">de</TOKEN>
<TOKEN id="token-10-38" pos="word" morph="none" start_char="1406" end_char="1410">hecho</TOKEN>
<TOKEN id="token-10-39" pos="word" morph="none" start_char="1412" end_char="1414">son</TOKEN>
<TOKEN id="token-10-40" pos="word" morph="none" start_char="1416" end_char="1422">mayores</TOKEN>
<TOKEN id="token-10-41" pos="word" morph="none" start_char="1424" end_char="1426">que</TOKEN>
<TOKEN id="token-10-42" pos="word" morph="none" start_char="1428" end_char="1430">las</TOKEN>
<TOKEN id="token-10-43" pos="word" morph="none" start_char="1432" end_char="1434">que</TOKEN>
<TOKEN id="token-10-44" pos="word" morph="none" start_char="1436" end_char="1444">recomenda</TOKEN>
<TOKEN id="token-10-45" pos="word" morph="none" start_char="1446" end_char="1447">la</TOKEN>
<TOKEN id="token-10-46" pos="word" morph="none" start_char="1449" end_char="1451">FDA</TOKEN>
<TOKEN id="token-10-47" pos="punct" morph="none" start_char="1452" end_char="1452">,</TOKEN>
<TOKEN id="token-10-48" pos="word" morph="none" start_char="1454" end_char="1459">cuando</TOKEN>
<TOKEN id="token-10-49" pos="word" morph="none" start_char="1461" end_char="1462">el</TOKEN>
<TOKEN id="token-10-50" pos="word" morph="none" start_char="1464" end_char="1465">66</TOKEN>
<TOKEN id="token-10-51" pos="punct" morph="none" start_char="1467" end_char="1467">%</TOKEN>
<TOKEN id="token-10-52" pos="word" morph="none" start_char="1469" end_char="1470">de</TOKEN>
<TOKEN id="token-10-53" pos="word" morph="none" start_char="1472" end_char="1474">los</TOKEN>
<TOKEN id="token-10-54" pos="word" morph="none" start_char="1476" end_char="1480">datos</TOKEN>
<TOKEN id="token-10-55" pos="word" morph="none" start_char="1482" end_char="1490">provienen</TOKEN>
<TOKEN id="token-10-56" pos="word" morph="none" start_char="1492" end_char="1493">de</TOKEN>
<TOKEN id="token-10-57" pos="word" morph="none" start_char="1495" end_char="1504">hospitales</TOKEN>
<TOKEN id="token-10-58" pos="word" morph="none" start_char="1506" end_char="1520">norteamericanos</TOKEN>
<TOKEN id="token-10-59" pos="punct" morph="none" start_char="1521" end_char="1522">).</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1524" end_char="1777">
<ORIGINAL_TEXT>Eso sí, no mencionan los hospitales que han participado en el estudio y su contribución concreta, algunos datos son incompatibles con los que aportan los gobiernos y algo más: hay muy poca variabilidad entre los resultados de cada uno de los continentes.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1524" end_char="1526">Eso</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1528" end_char="1529">sí</TOKEN>
<TOKEN id="token-11-2" pos="punct" morph="none" start_char="1530" end_char="1530">,</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1532" end_char="1533">no</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1535" end_char="1543">mencionan</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1545" end_char="1547">los</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1549" end_char="1558">hospitales</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1560" end_char="1562">que</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1564" end_char="1566">han</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1568" end_char="1578">participado</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1580" end_char="1581">en</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1583" end_char="1584">el</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1586" end_char="1592">estudio</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1594" end_char="1594">y</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1596" end_char="1597">su</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1599" end_char="1610">contribución</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1612" end_char="1619">concreta</TOKEN>
<TOKEN id="token-11-17" pos="punct" morph="none" start_char="1620" end_char="1620">,</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1622" end_char="1628">algunos</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="1630" end_char="1634">datos</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1636" end_char="1638">son</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="1640" end_char="1652">incompatibles</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="1654" end_char="1656">con</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="1658" end_char="1660">los</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="1662" end_char="1664">que</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="1666" end_char="1672">aportan</TOKEN>
<TOKEN id="token-11-26" pos="word" morph="none" start_char="1674" end_char="1676">los</TOKEN>
<TOKEN id="token-11-27" pos="word" morph="none" start_char="1678" end_char="1686">gobiernos</TOKEN>
<TOKEN id="token-11-28" pos="word" morph="none" start_char="1688" end_char="1688">y</TOKEN>
<TOKEN id="token-11-29" pos="word" morph="none" start_char="1690" end_char="1693">algo</TOKEN>
<TOKEN id="token-11-30" pos="word" morph="none" start_char="1695" end_char="1697">más</TOKEN>
<TOKEN id="token-11-31" pos="punct" morph="none" start_char="1698" end_char="1698">:</TOKEN>
<TOKEN id="token-11-32" pos="word" morph="none" start_char="1700" end_char="1702">hay</TOKEN>
<TOKEN id="token-11-33" pos="word" morph="none" start_char="1704" end_char="1706">muy</TOKEN>
<TOKEN id="token-11-34" pos="word" morph="none" start_char="1708" end_char="1711">poca</TOKEN>
<TOKEN id="token-11-35" pos="word" morph="none" start_char="1713" end_char="1724">variabilidad</TOKEN>
<TOKEN id="token-11-36" pos="word" morph="none" start_char="1726" end_char="1730">entre</TOKEN>
<TOKEN id="token-11-37" pos="word" morph="none" start_char="1732" end_char="1734">los</TOKEN>
<TOKEN id="token-11-38" pos="word" morph="none" start_char="1736" end_char="1745">resultados</TOKEN>
<TOKEN id="token-11-39" pos="word" morph="none" start_char="1747" end_char="1748">de</TOKEN>
<TOKEN id="token-11-40" pos="word" morph="none" start_char="1750" end_char="1753">cada</TOKEN>
<TOKEN id="token-11-41" pos="word" morph="none" start_char="1755" end_char="1757">uno</TOKEN>
<TOKEN id="token-11-42" pos="word" morph="none" start_char="1759" end_char="1760">de</TOKEN>
<TOKEN id="token-11-43" pos="word" morph="none" start_char="1762" end_char="1764">los</TOKEN>
<TOKEN id="token-11-44" pos="word" morph="none" start_char="1766" end_char="1776">continentes</TOKEN>
<TOKEN id="token-11-45" pos="punct" morph="none" start_char="1777" end_char="1777">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1780" end_char="1941">
<ORIGINAL_TEXT>También el jefe de Infecciosas del complejo hospitalario compostelano, Antonio Antela (que además ha superado la enfermedad), habla de limitaciones metodológicas.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1780" end_char="1786">También</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1788" end_char="1789">el</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1791" end_char="1794">jefe</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1796" end_char="1797">de</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1799" end_char="1809">Infecciosas</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1811" end_char="1813">del</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1815" end_char="1822">complejo</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1824" end_char="1835">hospitalario</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1837" end_char="1848">compostelano</TOKEN>
<TOKEN id="token-12-9" pos="punct" morph="none" start_char="1849" end_char="1849">,</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1851" end_char="1857">Antonio</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1859" end_char="1864">Antela</TOKEN>
<TOKEN id="token-12-12" pos="punct" morph="none" start_char="1866" end_char="1866">(</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1867" end_char="1869">que</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1871" end_char="1876">además</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1878" end_char="1879">ha</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1881" end_char="1888">superado</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1890" end_char="1891">la</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1893" end_char="1902">enfermedad</TOKEN>
<TOKEN id="token-12-19" pos="punct" morph="none" start_char="1903" end_char="1904">),</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1906" end_char="1910">habla</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1912" end_char="1913">de</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1915" end_char="1926">limitaciones</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="1928" end_char="1940">metodológicas</TOKEN>
<TOKEN id="token-12-24" pos="punct" morph="none" start_char="1941" end_char="1941">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1943" end_char="1989">
<ORIGINAL_TEXT>«La primera es que tiene un sesgo de selección.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="punct" morph="none" start_char="1943" end_char="1943">«</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1944" end_char="1945">La</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1947" end_char="1953">primera</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1955" end_char="1956">es</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1958" end_char="1960">que</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1962" end_char="1966">tiene</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1968" end_char="1969">un</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1971" end_char="1975">sesgo</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1977" end_char="1978">de</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1980" end_char="1988">selección</TOKEN>
<TOKEN id="token-13-10" pos="punct" morph="none" start_char="1989" end_char="1989">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1991" end_char="2268">
<ORIGINAL_TEXT>Se le dio hidroxicloroquina a los pacientes más graves» y en el análisis no se ajustan los datos a la gravedad del paciente, lo cual es un problema metodológico importante, porque son los más graves los que tienen más posibilidades de morir, así que puede haber una correlación.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1991" end_char="1992">Se</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1994" end_char="1995">le</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1997" end_char="1999">dio</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="2001" end_char="2017">hidroxicloroquina</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="2019" end_char="2019">a</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="2021" end_char="2023">los</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="2025" end_char="2033">pacientes</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="2035" end_char="2037">más</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="2039" end_char="2044">graves</TOKEN>
<TOKEN id="token-14-9" pos="punct" morph="none" start_char="2045" end_char="2045">»</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="2047" end_char="2047">y</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="2049" end_char="2050">en</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="2052" end_char="2053">el</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="2055" end_char="2062">análisis</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="2064" end_char="2065">no</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="2067" end_char="2068">se</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="2070" end_char="2076">ajustan</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="2078" end_char="2080">los</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="2082" end_char="2086">datos</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="2088" end_char="2088">a</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="2090" end_char="2091">la</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="2093" end_char="2100">gravedad</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="2102" end_char="2104">del</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="2106" end_char="2113">paciente</TOKEN>
<TOKEN id="token-14-24" pos="punct" morph="none" start_char="2114" end_char="2114">,</TOKEN>
<TOKEN id="token-14-25" pos="word" morph="none" start_char="2116" end_char="2117">lo</TOKEN>
<TOKEN id="token-14-26" pos="word" morph="none" start_char="2119" end_char="2122">cual</TOKEN>
<TOKEN id="token-14-27" pos="word" morph="none" start_char="2124" end_char="2125">es</TOKEN>
<TOKEN id="token-14-28" pos="word" morph="none" start_char="2127" end_char="2128">un</TOKEN>
<TOKEN id="token-14-29" pos="word" morph="none" start_char="2130" end_char="2137">problema</TOKEN>
<TOKEN id="token-14-30" pos="word" morph="none" start_char="2139" end_char="2150">metodológico</TOKEN>
<TOKEN id="token-14-31" pos="word" morph="none" start_char="2152" end_char="2161">importante</TOKEN>
<TOKEN id="token-14-32" pos="punct" morph="none" start_char="2162" end_char="2162">,</TOKEN>
<TOKEN id="token-14-33" pos="word" morph="none" start_char="2164" end_char="2169">porque</TOKEN>
<TOKEN id="token-14-34" pos="word" morph="none" start_char="2171" end_char="2173">son</TOKEN>
<TOKEN id="token-14-35" pos="word" morph="none" start_char="2175" end_char="2177">los</TOKEN>
<TOKEN id="token-14-36" pos="word" morph="none" start_char="2179" end_char="2181">más</TOKEN>
<TOKEN id="token-14-37" pos="word" morph="none" start_char="2183" end_char="2188">graves</TOKEN>
<TOKEN id="token-14-38" pos="word" morph="none" start_char="2190" end_char="2192">los</TOKEN>
<TOKEN id="token-14-39" pos="word" morph="none" start_char="2194" end_char="2196">que</TOKEN>
<TOKEN id="token-14-40" pos="word" morph="none" start_char="2198" end_char="2203">tienen</TOKEN>
<TOKEN id="token-14-41" pos="word" morph="none" start_char="2205" end_char="2207">más</TOKEN>
<TOKEN id="token-14-42" pos="word" morph="none" start_char="2209" end_char="2221">posibilidades</TOKEN>
<TOKEN id="token-14-43" pos="word" morph="none" start_char="2223" end_char="2224">de</TOKEN>
<TOKEN id="token-14-44" pos="word" morph="none" start_char="2226" end_char="2230">morir</TOKEN>
<TOKEN id="token-14-45" pos="punct" morph="none" start_char="2231" end_char="2231">,</TOKEN>
<TOKEN id="token-14-46" pos="word" morph="none" start_char="2233" end_char="2235">así</TOKEN>
<TOKEN id="token-14-47" pos="word" morph="none" start_char="2237" end_char="2239">que</TOKEN>
<TOKEN id="token-14-48" pos="word" morph="none" start_char="2241" end_char="2245">puede</TOKEN>
<TOKEN id="token-14-49" pos="word" morph="none" start_char="2247" end_char="2251">haber</TOKEN>
<TOKEN id="token-14-50" pos="word" morph="none" start_char="2253" end_char="2255">una</TOKEN>
<TOKEN id="token-14-51" pos="word" morph="none" start_char="2257" end_char="2267">correlación</TOKEN>
<TOKEN id="token-14-52" pos="punct" morph="none" start_char="2268" end_char="2268">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="2271" end_char="2420">
<ORIGINAL_TEXT>Ser precisamente un estudio observacional, retrospectivo, es otro de los sesgos metodológicos: «No todo el mundo hizo lo mismo ni siguió un protocolo.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="2271" end_char="2273">Ser</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="2275" end_char="2286">precisamente</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="2288" end_char="2289">un</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="2291" end_char="2297">estudio</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="2299" end_char="2311">observacional</TOKEN>
<TOKEN id="token-15-5" pos="punct" morph="none" start_char="2312" end_char="2312">,</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="2314" end_char="2326">retrospectivo</TOKEN>
<TOKEN id="token-15-7" pos="punct" morph="none" start_char="2327" end_char="2327">,</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="2329" end_char="2330">es</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="2332" end_char="2335">otro</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="2337" end_char="2338">de</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="2340" end_char="2342">los</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="2344" end_char="2349">sesgos</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="2351" end_char="2363">metodológicos</TOKEN>
<TOKEN id="token-15-14" pos="punct" morph="none" start_char="2364" end_char="2364">:</TOKEN>
<TOKEN id="token-15-15" pos="punct" morph="none" start_char="2366" end_char="2366">«</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="2367" end_char="2368">No</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="2370" end_char="2373">todo</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="2375" end_char="2376">el</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="2378" end_char="2382">mundo</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="2384" end_char="2387">hizo</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="2389" end_char="2390">lo</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="2392" end_char="2396">mismo</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="2398" end_char="2399">ni</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="2401" end_char="2406">siguió</TOKEN>
<TOKEN id="token-15-25" pos="word" morph="none" start_char="2408" end_char="2409">un</TOKEN>
<TOKEN id="token-15-26" pos="word" morph="none" start_char="2411" end_char="2419">protocolo</TOKEN>
<TOKEN id="token-15-27" pos="punct" morph="none" start_char="2420" end_char="2420">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="2422" end_char="2513">
<ORIGINAL_TEXT>Así que no hay una uniformidad en el uso del fármaco o de los pacientes que los recibieron».</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="2422" end_char="2424">Así</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="2426" end_char="2428">que</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="2430" end_char="2431">no</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="2433" end_char="2435">hay</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="2437" end_char="2439">una</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="2441" end_char="2451">uniformidad</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="2453" end_char="2454">en</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="2456" end_char="2457">el</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="2459" end_char="2461">uso</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="2463" end_char="2465">del</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="2467" end_char="2473">fármaco</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="2475" end_char="2475">o</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="2477" end_char="2478">de</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="2480" end_char="2482">los</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="2484" end_char="2492">pacientes</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="2494" end_char="2496">que</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="2498" end_char="2500">los</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="2502" end_char="2511">recibieron</TOKEN>
<TOKEN id="token-16-18" pos="punct" morph="none" start_char="2512" end_char="2513">».</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2516" end_char="2651">
<ORIGINAL_TEXT>La investigación tampoco se adecúa a las prácticas estándar de estadísticas y no han hecho público sus datos o su código, a pesar de que</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2516" end_char="2517">La</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2519" end_char="2531">investigación</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2533" end_char="2539">tampoco</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2541" end_char="2542">se</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2544" end_char="2549">adecúa</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2551" end_char="2551">a</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2553" end_char="2555">las</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2557" end_char="2565">prácticas</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2567" end_char="2574">estándar</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2576" end_char="2577">de</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2579" end_char="2590">estadísticas</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2592" end_char="2592">y</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2594" end_char="2595">no</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2597" end_char="2599">han</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2601" end_char="2605">hecho</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2607" end_char="2613">público</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="2615" end_char="2617">sus</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="2619" end_char="2623">datos</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="2625" end_char="2625">o</TOKEN>
<TOKEN id="token-17-19" pos="word" morph="none" start_char="2627" end_char="2628">su</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="2630" end_char="2635">código</TOKEN>
<TOKEN id="token-17-21" pos="punct" morph="none" start_char="2636" end_char="2636">,</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="2638" end_char="2638">a</TOKEN>
<TOKEN id="token-17-23" pos="word" morph="none" start_char="2640" end_char="2644">pesar</TOKEN>
<TOKEN id="token-17-24" pos="word" morph="none" start_char="2646" end_char="2647">de</TOKEN>
<TOKEN id="token-17-25" pos="word" morph="none" start_char="2649" end_char="2651">que</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2654" end_char="2663">
<ORIGINAL_TEXT>The Lancet</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2654" end_char="2656">The</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2658" end_char="2663">Lancet</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2666" end_char="2776">
<ORIGINAL_TEXT>está entre los firmantes de la declaración sobre el intercambio de datos en las investigaciones sobre Covid-19.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2666" end_char="2669">está</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2671" end_char="2675">entre</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2677" end_char="2679">los</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2681" end_char="2689">firmantes</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2691" end_char="2692">de</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2694" end_char="2695">la</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2697" end_char="2707">declaración</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2709" end_char="2713">sobre</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2715" end_char="2716">el</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="2718" end_char="2728">intercambio</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="2730" end_char="2731">de</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="2733" end_char="2737">datos</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="2739" end_char="2740">en</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="2742" end_char="2744">las</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="2746" end_char="2760">investigaciones</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="2762" end_char="2766">sobre</TOKEN>
<TOKEN id="token-19-16" pos="unknown" morph="none" start_char="2768" end_char="2775">Covid-19</TOKEN>
<TOKEN id="token-19-17" pos="punct" morph="none" start_char="2776" end_char="2776">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2779" end_char="2809">
<ORIGINAL_TEXT>El estudio «tiene limitaciones»</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2779" end_char="2780">El</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2782" end_char="2788">estudio</TOKEN>
<TOKEN id="token-20-2" pos="punct" morph="none" start_char="2790" end_char="2790">«</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2791" end_char="2795">tiene</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2797" end_char="2808">limitaciones</TOKEN>
<TOKEN id="token-20-5" pos="punct" morph="none" start_char="2809" end_char="2809">»</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2812" end_char="2962">
<ORIGINAL_TEXT>Los datos de este estudio provienen de Surgisphere, una empresa de análisis de datos médicos cuyo presidente es uno de los autores de la investigación.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2812" end_char="2814">Los</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2816" end_char="2820">datos</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2822" end_char="2823">de</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2825" end_char="2828">este</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2830" end_char="2836">estudio</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="2838" end_char="2846">provienen</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2848" end_char="2849">de</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="2851" end_char="2861">Surgisphere</TOKEN>
<TOKEN id="token-21-8" pos="punct" morph="none" start_char="2862" end_char="2862">,</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="2864" end_char="2866">una</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="2868" end_char="2874">empresa</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="2876" end_char="2877">de</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="2879" end_char="2886">análisis</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="2888" end_char="2889">de</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="2891" end_char="2895">datos</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="2897" end_char="2903">médicos</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="2905" end_char="2908">cuyo</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="2910" end_char="2919">presidente</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="2921" end_char="2922">es</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="2924" end_char="2926">uno</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="2928" end_char="2929">de</TOKEN>
<TOKEN id="token-21-21" pos="word" morph="none" start_char="2931" end_char="2933">los</TOKEN>
<TOKEN id="token-21-22" pos="word" morph="none" start_char="2935" end_char="2941">autores</TOKEN>
<TOKEN id="token-21-23" pos="word" morph="none" start_char="2943" end_char="2944">de</TOKEN>
<TOKEN id="token-21-24" pos="word" morph="none" start_char="2946" end_char="2947">la</TOKEN>
<TOKEN id="token-21-25" pos="word" morph="none" start_char="2949" end_char="2961">investigación</TOKEN>
<TOKEN id="token-21-26" pos="punct" morph="none" start_char="2962" end_char="2962">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2964" end_char="3355">
<ORIGINAL_TEXT>La compañía ya ha emitido un comunicado en el que defienden la veracidad de las fuentes utilizadas y recuerdan que ya habían señalado con anterioridad que el estudio, de carácter observacional «tiene limitaciones» y que en ningún caso deben realizarse interpretaciones para pacientes que no han desarrollado la enfermedad o que no han sido hospitalizados, remarcan en el comunicado del lunes.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2964" end_char="2965">La</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2967" end_char="2974">compañía</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2976" end_char="2977">ya</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2979" end_char="2980">ha</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2982" end_char="2988">emitido</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2990" end_char="2991">un</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2993" end_char="3002">comunicado</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="3004" end_char="3005">en</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="3007" end_char="3008">el</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="3010" end_char="3012">que</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="3014" end_char="3022">defienden</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="3024" end_char="3025">la</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="3027" end_char="3035">veracidad</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="3037" end_char="3038">de</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="3040" end_char="3042">las</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="3044" end_char="3050">fuentes</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="3052" end_char="3061">utilizadas</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="3063" end_char="3063">y</TOKEN>
<TOKEN id="token-22-18" pos="word" morph="none" start_char="3065" end_char="3073">recuerdan</TOKEN>
<TOKEN id="token-22-19" pos="word" morph="none" start_char="3075" end_char="3077">que</TOKEN>
<TOKEN id="token-22-20" pos="word" morph="none" start_char="3079" end_char="3080">ya</TOKEN>
<TOKEN id="token-22-21" pos="word" morph="none" start_char="3082" end_char="3087">habían</TOKEN>
<TOKEN id="token-22-22" pos="word" morph="none" start_char="3089" end_char="3096">señalado</TOKEN>
<TOKEN id="token-22-23" pos="word" morph="none" start_char="3098" end_char="3100">con</TOKEN>
<TOKEN id="token-22-24" pos="word" morph="none" start_char="3102" end_char="3113">anterioridad</TOKEN>
<TOKEN id="token-22-25" pos="word" morph="none" start_char="3115" end_char="3117">que</TOKEN>
<TOKEN id="token-22-26" pos="word" morph="none" start_char="3119" end_char="3120">el</TOKEN>
<TOKEN id="token-22-27" pos="word" morph="none" start_char="3122" end_char="3128">estudio</TOKEN>
<TOKEN id="token-22-28" pos="punct" morph="none" start_char="3129" end_char="3129">,</TOKEN>
<TOKEN id="token-22-29" pos="word" morph="none" start_char="3131" end_char="3132">de</TOKEN>
<TOKEN id="token-22-30" pos="word" morph="none" start_char="3134" end_char="3141">carácter</TOKEN>
<TOKEN id="token-22-31" pos="word" morph="none" start_char="3143" end_char="3155">observacional</TOKEN>
<TOKEN id="token-22-32" pos="punct" morph="none" start_char="3157" end_char="3157">«</TOKEN>
<TOKEN id="token-22-33" pos="word" morph="none" start_char="3158" end_char="3162">tiene</TOKEN>
<TOKEN id="token-22-34" pos="word" morph="none" start_char="3164" end_char="3175">limitaciones</TOKEN>
<TOKEN id="token-22-35" pos="punct" morph="none" start_char="3176" end_char="3176">»</TOKEN>
<TOKEN id="token-22-36" pos="word" morph="none" start_char="3178" end_char="3178">y</TOKEN>
<TOKEN id="token-22-37" pos="word" morph="none" start_char="3180" end_char="3182">que</TOKEN>
<TOKEN id="token-22-38" pos="word" morph="none" start_char="3184" end_char="3185">en</TOKEN>
<TOKEN id="token-22-39" pos="word" morph="none" start_char="3187" end_char="3192">ningún</TOKEN>
<TOKEN id="token-22-40" pos="word" morph="none" start_char="3194" end_char="3197">caso</TOKEN>
<TOKEN id="token-22-41" pos="word" morph="none" start_char="3199" end_char="3203">deben</TOKEN>
<TOKEN id="token-22-42" pos="word" morph="none" start_char="3205" end_char="3214">realizarse</TOKEN>
<TOKEN id="token-22-43" pos="word" morph="none" start_char="3216" end_char="3231">interpretaciones</TOKEN>
<TOKEN id="token-22-44" pos="word" morph="none" start_char="3233" end_char="3236">para</TOKEN>
<TOKEN id="token-22-45" pos="word" morph="none" start_char="3238" end_char="3246">pacientes</TOKEN>
<TOKEN id="token-22-46" pos="word" morph="none" start_char="3248" end_char="3250">que</TOKEN>
<TOKEN id="token-22-47" pos="word" morph="none" start_char="3252" end_char="3253">no</TOKEN>
<TOKEN id="token-22-48" pos="word" morph="none" start_char="3255" end_char="3257">han</TOKEN>
<TOKEN id="token-22-49" pos="word" morph="none" start_char="3259" end_char="3270">desarrollado</TOKEN>
<TOKEN id="token-22-50" pos="word" morph="none" start_char="3272" end_char="3273">la</TOKEN>
<TOKEN id="token-22-51" pos="word" morph="none" start_char="3275" end_char="3284">enfermedad</TOKEN>
<TOKEN id="token-22-52" pos="word" morph="none" start_char="3286" end_char="3286">o</TOKEN>
<TOKEN id="token-22-53" pos="word" morph="none" start_char="3288" end_char="3290">que</TOKEN>
<TOKEN id="token-22-54" pos="word" morph="none" start_char="3292" end_char="3293">no</TOKEN>
<TOKEN id="token-22-55" pos="word" morph="none" start_char="3295" end_char="3297">han</TOKEN>
<TOKEN id="token-22-56" pos="word" morph="none" start_char="3299" end_char="3302">sido</TOKEN>
<TOKEN id="token-22-57" pos="word" morph="none" start_char="3304" end_char="3317">hospitalizados</TOKEN>
<TOKEN id="token-22-58" pos="punct" morph="none" start_char="3318" end_char="3318">,</TOKEN>
<TOKEN id="token-22-59" pos="word" morph="none" start_char="3320" end_char="3327">remarcan</TOKEN>
<TOKEN id="token-22-60" pos="word" morph="none" start_char="3329" end_char="3330">en</TOKEN>
<TOKEN id="token-22-61" pos="word" morph="none" start_char="3332" end_char="3333">el</TOKEN>
<TOKEN id="token-22-62" pos="word" morph="none" start_char="3335" end_char="3344">comunicado</TOKEN>
<TOKEN id="token-22-63" pos="word" morph="none" start_char="3346" end_char="3348">del</TOKEN>
<TOKEN id="token-22-64" pos="word" morph="none" start_char="3350" end_char="3354">lunes</TOKEN>
<TOKEN id="token-22-65" pos="punct" morph="none" start_char="3355" end_char="3355">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="3358" end_char="3676">
<ORIGINAL_TEXT>De hecho, Antonio Antela explica que si se quieren obtener datos relevantes lo que hay que hacer es un ensayo clínico aleatorizado, de doble ciego: a unos pacientes se les da un medicamento, a otros otro o un placebo por azar, y ni el personal médico ni las personas participantes en el estudio saben qué están tomando.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="3358" end_char="3359">De</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="3361" end_char="3365">hecho</TOKEN>
<TOKEN id="token-23-2" pos="punct" morph="none" start_char="3366" end_char="3366">,</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="3368" end_char="3374">Antonio</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="3376" end_char="3381">Antela</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="3383" end_char="3389">explica</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="3391" end_char="3393">que</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="3395" end_char="3396">si</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="3398" end_char="3399">se</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="3401" end_char="3407">quieren</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="3409" end_char="3415">obtener</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="3417" end_char="3421">datos</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="3423" end_char="3432">relevantes</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="3434" end_char="3435">lo</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="3437" end_char="3439">que</TOKEN>
<TOKEN id="token-23-15" pos="word" morph="none" start_char="3441" end_char="3443">hay</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="3445" end_char="3447">que</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="3449" end_char="3453">hacer</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="3455" end_char="3456">es</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="3458" end_char="3459">un</TOKEN>
<TOKEN id="token-23-20" pos="word" morph="none" start_char="3461" end_char="3466">ensayo</TOKEN>
<TOKEN id="token-23-21" pos="word" morph="none" start_char="3468" end_char="3474">clínico</TOKEN>
<TOKEN id="token-23-22" pos="word" morph="none" start_char="3476" end_char="3487">aleatorizado</TOKEN>
<TOKEN id="token-23-23" pos="punct" morph="none" start_char="3488" end_char="3488">,</TOKEN>
<TOKEN id="token-23-24" pos="word" morph="none" start_char="3490" end_char="3491">de</TOKEN>
<TOKEN id="token-23-25" pos="word" morph="none" start_char="3493" end_char="3497">doble</TOKEN>
<TOKEN id="token-23-26" pos="word" morph="none" start_char="3499" end_char="3503">ciego</TOKEN>
<TOKEN id="token-23-27" pos="punct" morph="none" start_char="3504" end_char="3504">:</TOKEN>
<TOKEN id="token-23-28" pos="word" morph="none" start_char="3506" end_char="3506">a</TOKEN>
<TOKEN id="token-23-29" pos="word" morph="none" start_char="3508" end_char="3511">unos</TOKEN>
<TOKEN id="token-23-30" pos="word" morph="none" start_char="3513" end_char="3521">pacientes</TOKEN>
<TOKEN id="token-23-31" pos="word" morph="none" start_char="3523" end_char="3524">se</TOKEN>
<TOKEN id="token-23-32" pos="word" morph="none" start_char="3526" end_char="3528">les</TOKEN>
<TOKEN id="token-23-33" pos="word" morph="none" start_char="3530" end_char="3531">da</TOKEN>
<TOKEN id="token-23-34" pos="word" morph="none" start_char="3533" end_char="3534">un</TOKEN>
<TOKEN id="token-23-35" pos="word" morph="none" start_char="3536" end_char="3546">medicamento</TOKEN>
<TOKEN id="token-23-36" pos="punct" morph="none" start_char="3547" end_char="3547">,</TOKEN>
<TOKEN id="token-23-37" pos="word" morph="none" start_char="3549" end_char="3549">a</TOKEN>
<TOKEN id="token-23-38" pos="word" morph="none" start_char="3551" end_char="3555">otros</TOKEN>
<TOKEN id="token-23-39" pos="word" morph="none" start_char="3557" end_char="3560">otro</TOKEN>
<TOKEN id="token-23-40" pos="word" morph="none" start_char="3562" end_char="3562">o</TOKEN>
<TOKEN id="token-23-41" pos="word" morph="none" start_char="3564" end_char="3565">un</TOKEN>
<TOKEN id="token-23-42" pos="word" morph="none" start_char="3567" end_char="3573">placebo</TOKEN>
<TOKEN id="token-23-43" pos="word" morph="none" start_char="3575" end_char="3577">por</TOKEN>
<TOKEN id="token-23-44" pos="word" morph="none" start_char="3579" end_char="3582">azar</TOKEN>
<TOKEN id="token-23-45" pos="punct" morph="none" start_char="3583" end_char="3583">,</TOKEN>
<TOKEN id="token-23-46" pos="word" morph="none" start_char="3585" end_char="3585">y</TOKEN>
<TOKEN id="token-23-47" pos="word" morph="none" start_char="3587" end_char="3588">ni</TOKEN>
<TOKEN id="token-23-48" pos="word" morph="none" start_char="3590" end_char="3591">el</TOKEN>
<TOKEN id="token-23-49" pos="word" morph="none" start_char="3593" end_char="3600">personal</TOKEN>
<TOKEN id="token-23-50" pos="word" morph="none" start_char="3602" end_char="3607">médico</TOKEN>
<TOKEN id="token-23-51" pos="word" morph="none" start_char="3609" end_char="3610">ni</TOKEN>
<TOKEN id="token-23-52" pos="word" morph="none" start_char="3612" end_char="3614">las</TOKEN>
<TOKEN id="token-23-53" pos="word" morph="none" start_char="3616" end_char="3623">personas</TOKEN>
<TOKEN id="token-23-54" pos="word" morph="none" start_char="3625" end_char="3637">participantes</TOKEN>
<TOKEN id="token-23-55" pos="word" morph="none" start_char="3639" end_char="3640">en</TOKEN>
<TOKEN id="token-23-56" pos="word" morph="none" start_char="3642" end_char="3643">el</TOKEN>
<TOKEN id="token-23-57" pos="word" morph="none" start_char="3645" end_char="3651">estudio</TOKEN>
<TOKEN id="token-23-58" pos="word" morph="none" start_char="3653" end_char="3657">saben</TOKEN>
<TOKEN id="token-23-59" pos="word" morph="none" start_char="3659" end_char="3661">qué</TOKEN>
<TOKEN id="token-23-60" pos="word" morph="none" start_char="3663" end_char="3667">están</TOKEN>
<TOKEN id="token-23-61" pos="word" morph="none" start_char="3669" end_char="3675">tomando</TOKEN>
<TOKEN id="token-23-62" pos="punct" morph="none" start_char="3676" end_char="3676">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="3678" end_char="3732">
<ORIGINAL_TEXT>Y además debe hacerlo todo el mundo de la misma manera.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="3678" end_char="3678">Y</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="3680" end_char="3685">además</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="3687" end_char="3690">debe</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="3692" end_char="3698">hacerlo</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="3700" end_char="3703">todo</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="3705" end_char="3706">el</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="3708" end_char="3712">mundo</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="3714" end_char="3715">de</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="3717" end_char="3718">la</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="3720" end_char="3724">misma</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="3726" end_char="3731">manera</TOKEN>
<TOKEN id="token-24-11" pos="punct" morph="none" start_char="3732" end_char="3732">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="3735" end_char="4190">
<ORIGINAL_TEXT>A esos límites se ha referido también la Agencia Española del Medicamento, que vigila de cerca la evolución del uso del medicamento y recuerda en su página web que «actualmente ningún ensayo clínico controlado y aleatorizado ha demostrado la eficacia de estos medicamentos para el tratamiento de pacientes con covid-19» y que la información disponible por ahora «procede de estudios in vitro y series de pacientes con limitaciones de tamaño y metodología».</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="3735" end_char="3735">A</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="3737" end_char="3740">esos</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="3742" end_char="3748">límites</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="3750" end_char="3751">se</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="3753" end_char="3754">ha</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="3756" end_char="3763">referido</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="3765" end_char="3771">también</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="3773" end_char="3774">la</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="3776" end_char="3782">Agencia</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="3784" end_char="3791">Española</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="3793" end_char="3795">del</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="3797" end_char="3807">Medicamento</TOKEN>
<TOKEN id="token-25-12" pos="punct" morph="none" start_char="3808" end_char="3808">,</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="3810" end_char="3812">que</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="3814" end_char="3819">vigila</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="3821" end_char="3822">de</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="3824" end_char="3828">cerca</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="3830" end_char="3831">la</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="3833" end_char="3841">evolución</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="3843" end_char="3845">del</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="3847" end_char="3849">uso</TOKEN>
<TOKEN id="token-25-21" pos="word" morph="none" start_char="3851" end_char="3853">del</TOKEN>
<TOKEN id="token-25-22" pos="word" morph="none" start_char="3855" end_char="3865">medicamento</TOKEN>
<TOKEN id="token-25-23" pos="word" morph="none" start_char="3867" end_char="3867">y</TOKEN>
<TOKEN id="token-25-24" pos="word" morph="none" start_char="3869" end_char="3876">recuerda</TOKEN>
<TOKEN id="token-25-25" pos="word" morph="none" start_char="3878" end_char="3879">en</TOKEN>
<TOKEN id="token-25-26" pos="word" morph="none" start_char="3881" end_char="3882">su</TOKEN>
<TOKEN id="token-25-27" pos="word" morph="none" start_char="3884" end_char="3889">página</TOKEN>
<TOKEN id="token-25-28" pos="word" morph="none" start_char="3891" end_char="3893">web</TOKEN>
<TOKEN id="token-25-29" pos="word" morph="none" start_char="3895" end_char="3897">que</TOKEN>
<TOKEN id="token-25-30" pos="punct" morph="none" start_char="3899" end_char="3899">«</TOKEN>
<TOKEN id="token-25-31" pos="word" morph="none" start_char="3900" end_char="3910">actualmente</TOKEN>
<TOKEN id="token-25-32" pos="word" morph="none" start_char="3912" end_char="3917">ningún</TOKEN>
<TOKEN id="token-25-33" pos="word" morph="none" start_char="3919" end_char="3924">ensayo</TOKEN>
<TOKEN id="token-25-34" pos="word" morph="none" start_char="3926" end_char="3932">clínico</TOKEN>
<TOKEN id="token-25-35" pos="word" morph="none" start_char="3934" end_char="3943">controlado</TOKEN>
<TOKEN id="token-25-36" pos="word" morph="none" start_char="3945" end_char="3945">y</TOKEN>
<TOKEN id="token-25-37" pos="word" morph="none" start_char="3947" end_char="3958">aleatorizado</TOKEN>
<TOKEN id="token-25-38" pos="word" morph="none" start_char="3960" end_char="3961">ha</TOKEN>
<TOKEN id="token-25-39" pos="word" morph="none" start_char="3963" end_char="3972">demostrado</TOKEN>
<TOKEN id="token-25-40" pos="word" morph="none" start_char="3974" end_char="3975">la</TOKEN>
<TOKEN id="token-25-41" pos="word" morph="none" start_char="3977" end_char="3984">eficacia</TOKEN>
<TOKEN id="token-25-42" pos="word" morph="none" start_char="3986" end_char="3987">de</TOKEN>
<TOKEN id="token-25-43" pos="word" morph="none" start_char="3989" end_char="3993">estos</TOKEN>
<TOKEN id="token-25-44" pos="word" morph="none" start_char="3995" end_char="4006">medicamentos</TOKEN>
<TOKEN id="token-25-45" pos="word" morph="none" start_char="4008" end_char="4011">para</TOKEN>
<TOKEN id="token-25-46" pos="word" morph="none" start_char="4013" end_char="4014">el</TOKEN>
<TOKEN id="token-25-47" pos="word" morph="none" start_char="4016" end_char="4026">tratamiento</TOKEN>
<TOKEN id="token-25-48" pos="word" morph="none" start_char="4028" end_char="4029">de</TOKEN>
<TOKEN id="token-25-49" pos="word" morph="none" start_char="4031" end_char="4039">pacientes</TOKEN>
<TOKEN id="token-25-50" pos="word" morph="none" start_char="4041" end_char="4043">con</TOKEN>
<TOKEN id="token-25-51" pos="unknown" morph="none" start_char="4045" end_char="4052">covid-19</TOKEN>
<TOKEN id="token-25-52" pos="punct" morph="none" start_char="4053" end_char="4053">»</TOKEN>
<TOKEN id="token-25-53" pos="word" morph="none" start_char="4055" end_char="4055">y</TOKEN>
<TOKEN id="token-25-54" pos="word" morph="none" start_char="4057" end_char="4059">que</TOKEN>
<TOKEN id="token-25-55" pos="word" morph="none" start_char="4061" end_char="4062">la</TOKEN>
<TOKEN id="token-25-56" pos="word" morph="none" start_char="4064" end_char="4074">información</TOKEN>
<TOKEN id="token-25-57" pos="word" morph="none" start_char="4076" end_char="4085">disponible</TOKEN>
<TOKEN id="token-25-58" pos="word" morph="none" start_char="4087" end_char="4089">por</TOKEN>
<TOKEN id="token-25-59" pos="word" morph="none" start_char="4091" end_char="4095">ahora</TOKEN>
<TOKEN id="token-25-60" pos="punct" morph="none" start_char="4097" end_char="4097">«</TOKEN>
<TOKEN id="token-25-61" pos="word" morph="none" start_char="4098" end_char="4104">procede</TOKEN>
<TOKEN id="token-25-62" pos="word" morph="none" start_char="4106" end_char="4107">de</TOKEN>
<TOKEN id="token-25-63" pos="word" morph="none" start_char="4109" end_char="4116">estudios</TOKEN>
<TOKEN id="token-25-64" pos="word" morph="none" start_char="4118" end_char="4119">in</TOKEN>
<TOKEN id="token-25-65" pos="word" morph="none" start_char="4121" end_char="4125">vitro</TOKEN>
<TOKEN id="token-25-66" pos="word" morph="none" start_char="4127" end_char="4127">y</TOKEN>
<TOKEN id="token-25-67" pos="word" morph="none" start_char="4129" end_char="4134">series</TOKEN>
<TOKEN id="token-25-68" pos="word" morph="none" start_char="4136" end_char="4137">de</TOKEN>
<TOKEN id="token-25-69" pos="word" morph="none" start_char="4139" end_char="4147">pacientes</TOKEN>
<TOKEN id="token-25-70" pos="word" morph="none" start_char="4149" end_char="4151">con</TOKEN>
<TOKEN id="token-25-71" pos="word" morph="none" start_char="4153" end_char="4164">limitaciones</TOKEN>
<TOKEN id="token-25-72" pos="word" morph="none" start_char="4166" end_char="4167">de</TOKEN>
<TOKEN id="token-25-73" pos="word" morph="none" start_char="4169" end_char="4174">tamaño</TOKEN>
<TOKEN id="token-25-74" pos="word" morph="none" start_char="4176" end_char="4176">y</TOKEN>
<TOKEN id="token-25-75" pos="word" morph="none" start_char="4178" end_char="4188">metodología</TOKEN>
<TOKEN id="token-25-76" pos="punct" morph="none" start_char="4189" end_char="4190">».</TOKEN>
</SEG>
<SEG id="segment-26" start_char="4193" end_char="4292">
<ORIGINAL_TEXT>Entonces, ¿por qué tanto revuelo, hasta el punto de que la OMS ha decidido detener ensayos clínicos?</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="4193" end_char="4200">Entonces</TOKEN>
<TOKEN id="token-26-1" pos="punct" morph="none" start_char="4201" end_char="4201">,</TOKEN>
<TOKEN id="token-26-2" pos="punct" morph="none" start_char="4203" end_char="4203">¿</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="4204" end_char="4206">por</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="4208" end_char="4210">qué</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="4212" end_char="4216">tanto</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="4218" end_char="4224">revuelo</TOKEN>
<TOKEN id="token-26-7" pos="punct" morph="none" start_char="4225" end_char="4225">,</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="4227" end_char="4231">hasta</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="4233" end_char="4234">el</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="4236" end_char="4240">punto</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="4242" end_char="4243">de</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="4245" end_char="4247">que</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="4249" end_char="4250">la</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="4252" end_char="4254">OMS</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="4256" end_char="4257">ha</TOKEN>
<TOKEN id="token-26-16" pos="word" morph="none" start_char="4259" end_char="4266">decidido</TOKEN>
<TOKEN id="token-26-17" pos="word" morph="none" start_char="4268" end_char="4274">detener</TOKEN>
<TOKEN id="token-26-18" pos="word" morph="none" start_char="4276" end_char="4282">ensayos</TOKEN>
<TOKEN id="token-26-19" pos="word" morph="none" start_char="4284" end_char="4291">clínicos</TOKEN>
<TOKEN id="token-26-20" pos="punct" morph="none" start_char="4292" end_char="4292">?</TOKEN>
</SEG>
<SEG id="segment-27" start_char="4294" end_char="4392">
<ORIGINAL_TEXT>«Primero, porque se ha publicado en The Lancet, que es una revista de alto impacto», afirma Antela.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="punct" morph="none" start_char="4294" end_char="4294">«</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="4295" end_char="4301">Primero</TOKEN>
<TOKEN id="token-27-2" pos="punct" morph="none" start_char="4302" end_char="4302">,</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="4304" end_char="4309">porque</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="4311" end_char="4312">se</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="4314" end_char="4315">ha</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="4317" end_char="4325">publicado</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="4327" end_char="4328">en</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="4330" end_char="4332">The</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="4334" end_char="4339">Lancet</TOKEN>
<TOKEN id="token-27-10" pos="punct" morph="none" start_char="4340" end_char="4340">,</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="4342" end_char="4344">que</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="4346" end_char="4347">es</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="4349" end_char="4351">una</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="4353" end_char="4359">revista</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="4361" end_char="4362">de</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="4364" end_char="4367">alto</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="4369" end_char="4375">impacto</TOKEN>
<TOKEN id="token-27-18" pos="punct" morph="none" start_char="4376" end_char="4377">»,</TOKEN>
<TOKEN id="token-27-19" pos="word" morph="none" start_char="4379" end_char="4384">afirma</TOKEN>
<TOKEN id="token-27-20" pos="word" morph="none" start_char="4386" end_char="4391">Antela</TOKEN>
<TOKEN id="token-27-21" pos="punct" morph="none" start_char="4392" end_char="4392">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="4394" end_char="4599">
<ORIGINAL_TEXT>Y también porque la repercusión mediática ha sido considerable y se ha hablado de un estudio muy potente basándose solo en el número de participantes, «sin tener en cuenta otras deficiencias metodológicas».</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="4394" end_char="4394">Y</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="4396" end_char="4402">también</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="4404" end_char="4409">porque</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="4411" end_char="4412">la</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="4414" end_char="4424">repercusión</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="4426" end_char="4434">mediática</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="4436" end_char="4437">ha</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="4439" end_char="4442">sido</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="4444" end_char="4455">considerable</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="4457" end_char="4457">y</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="4459" end_char="4460">se</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="4462" end_char="4463">ha</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="4465" end_char="4471">hablado</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="4473" end_char="4474">de</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="4476" end_char="4477">un</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="4479" end_char="4485">estudio</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="4487" end_char="4489">muy</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="4491" end_char="4497">potente</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="4499" end_char="4507">basándose</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="4509" end_char="4512">solo</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="4514" end_char="4515">en</TOKEN>
<TOKEN id="token-28-21" pos="word" morph="none" start_char="4517" end_char="4518">el</TOKEN>
<TOKEN id="token-28-22" pos="word" morph="none" start_char="4520" end_char="4525">número</TOKEN>
<TOKEN id="token-28-23" pos="word" morph="none" start_char="4527" end_char="4528">de</TOKEN>
<TOKEN id="token-28-24" pos="word" morph="none" start_char="4530" end_char="4542">participantes</TOKEN>
<TOKEN id="token-28-25" pos="punct" morph="none" start_char="4543" end_char="4543">,</TOKEN>
<TOKEN id="token-28-26" pos="punct" morph="none" start_char="4545" end_char="4545">«</TOKEN>
<TOKEN id="token-28-27" pos="word" morph="none" start_char="4546" end_char="4548">sin</TOKEN>
<TOKEN id="token-28-28" pos="word" morph="none" start_char="4550" end_char="4554">tener</TOKEN>
<TOKEN id="token-28-29" pos="word" morph="none" start_char="4556" end_char="4557">en</TOKEN>
<TOKEN id="token-28-30" pos="word" morph="none" start_char="4559" end_char="4564">cuenta</TOKEN>
<TOKEN id="token-28-31" pos="word" morph="none" start_char="4566" end_char="4570">otras</TOKEN>
<TOKEN id="token-28-32" pos="word" morph="none" start_char="4572" end_char="4583">deficiencias</TOKEN>
<TOKEN id="token-28-33" pos="word" morph="none" start_char="4585" end_char="4597">metodológicas</TOKEN>
<TOKEN id="token-28-34" pos="punct" morph="none" start_char="4598" end_char="4599">».</TOKEN>
</SEG>
<SEG id="segment-29" start_char="4601" end_char="4745">
<ORIGINAL_TEXT>A pesar de que el número de pacientes es muy elevado, si no se usan los criterios estadísticos adecuados pueden obtenerse resultados equivocados.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="4601" end_char="4601">A</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="4603" end_char="4607">pesar</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="4609" end_char="4610">de</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="4612" end_char="4614">que</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="4616" end_char="4617">el</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="4619" end_char="4624">número</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="4626" end_char="4627">de</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="4629" end_char="4637">pacientes</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="4639" end_char="4640">es</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="4642" end_char="4644">muy</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="4646" end_char="4652">elevado</TOKEN>
<TOKEN id="token-29-11" pos="punct" morph="none" start_char="4653" end_char="4653">,</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="4655" end_char="4656">si</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="4658" end_char="4659">no</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="4661" end_char="4662">se</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="4664" end_char="4667">usan</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="4669" end_char="4671">los</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="4673" end_char="4681">criterios</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="4683" end_char="4694">estadísticos</TOKEN>
<TOKEN id="token-29-19" pos="word" morph="none" start_char="4696" end_char="4704">adecuados</TOKEN>
<TOKEN id="token-29-20" pos="word" morph="none" start_char="4706" end_char="4711">pueden</TOKEN>
<TOKEN id="token-29-21" pos="word" morph="none" start_char="4713" end_char="4721">obtenerse</TOKEN>
<TOKEN id="token-29-22" pos="word" morph="none" start_char="4723" end_char="4732">resultados</TOKEN>
<TOKEN id="token-29-23" pos="word" morph="none" start_char="4734" end_char="4744">equivocados</TOKEN>
<TOKEN id="token-29-24" pos="punct" morph="none" start_char="4745" end_char="4745">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="4747" end_char="4921">
<ORIGINAL_TEXT>«De hecho hay un mantra que repiten todos los epidemiólogos, que dice que si hay un número suficiente de casos, podemos demostrar lo que queramos», explica el médico del CHUS.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="punct" morph="none" start_char="4747" end_char="4747">«</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="4748" end_char="4749">De</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="4751" end_char="4755">hecho</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="4757" end_char="4759">hay</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="4761" end_char="4762">un</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="4764" end_char="4769">mantra</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="4771" end_char="4773">que</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="4775" end_char="4781">repiten</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="4783" end_char="4787">todos</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="4789" end_char="4791">los</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="4793" end_char="4805">epidemiólogos</TOKEN>
<TOKEN id="token-30-11" pos="punct" morph="none" start_char="4806" end_char="4806">,</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="4808" end_char="4810">que</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="4812" end_char="4815">dice</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="4817" end_char="4819">que</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="4821" end_char="4822">si</TOKEN>
<TOKEN id="token-30-16" pos="word" morph="none" start_char="4824" end_char="4826">hay</TOKEN>
<TOKEN id="token-30-17" pos="word" morph="none" start_char="4828" end_char="4829">un</TOKEN>
<TOKEN id="token-30-18" pos="word" morph="none" start_char="4831" end_char="4836">número</TOKEN>
<TOKEN id="token-30-19" pos="word" morph="none" start_char="4838" end_char="4847">suficiente</TOKEN>
<TOKEN id="token-30-20" pos="word" morph="none" start_char="4849" end_char="4850">de</TOKEN>
<TOKEN id="token-30-21" pos="word" morph="none" start_char="4852" end_char="4856">casos</TOKEN>
<TOKEN id="token-30-22" pos="punct" morph="none" start_char="4857" end_char="4857">,</TOKEN>
<TOKEN id="token-30-23" pos="word" morph="none" start_char="4859" end_char="4865">podemos</TOKEN>
<TOKEN id="token-30-24" pos="word" morph="none" start_char="4867" end_char="4875">demostrar</TOKEN>
<TOKEN id="token-30-25" pos="word" morph="none" start_char="4877" end_char="4878">lo</TOKEN>
<TOKEN id="token-30-26" pos="word" morph="none" start_char="4880" end_char="4882">que</TOKEN>
<TOKEN id="token-30-27" pos="word" morph="none" start_char="4884" end_char="4891">queramos</TOKEN>
<TOKEN id="token-30-28" pos="punct" morph="none" start_char="4892" end_char="4893">»,</TOKEN>
<TOKEN id="token-30-29" pos="word" morph="none" start_char="4895" end_char="4901">explica</TOKEN>
<TOKEN id="token-30-30" pos="word" morph="none" start_char="4903" end_char="4904">el</TOKEN>
<TOKEN id="token-30-31" pos="word" morph="none" start_char="4906" end_char="4911">médico</TOKEN>
<TOKEN id="token-30-32" pos="word" morph="none" start_char="4913" end_char="4915">del</TOKEN>
<TOKEN id="token-30-33" pos="word" morph="none" start_char="4917" end_char="4920">CHUS</TOKEN>
<TOKEN id="token-30-34" pos="punct" morph="none" start_char="4921" end_char="4921">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="4924" end_char="5171">
<ORIGINAL_TEXT>Queda la duda también de si ha podido hacerse un uso hasta cierto punto político de los resultados, ya que la hidroxicloroquina es defendida por personajes controvertidos como Donald Trump o Jair Bolsonaro e incluso el médico francés Didier Raoult.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="4924" end_char="4928">Queda</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="4930" end_char="4931">la</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="4933" end_char="4936">duda</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="4938" end_char="4944">también</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="4946" end_char="4947">de</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="4949" end_char="4950">si</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="4952" end_char="4953">ha</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="4955" end_char="4960">podido</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="4962" end_char="4968">hacerse</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="4970" end_char="4971">un</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="4973" end_char="4975">uso</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="4977" end_char="4981">hasta</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="4983" end_char="4988">cierto</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="4990" end_char="4994">punto</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="4996" end_char="5003">político</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="5005" end_char="5006">de</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="5008" end_char="5010">los</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="5012" end_char="5021">resultados</TOKEN>
<TOKEN id="token-31-18" pos="punct" morph="none" start_char="5022" end_char="5022">,</TOKEN>
<TOKEN id="token-31-19" pos="word" morph="none" start_char="5024" end_char="5025">ya</TOKEN>
<TOKEN id="token-31-20" pos="word" morph="none" start_char="5027" end_char="5029">que</TOKEN>
<TOKEN id="token-31-21" pos="word" morph="none" start_char="5031" end_char="5032">la</TOKEN>
<TOKEN id="token-31-22" pos="word" morph="none" start_char="5034" end_char="5050">hidroxicloroquina</TOKEN>
<TOKEN id="token-31-23" pos="word" morph="none" start_char="5052" end_char="5053">es</TOKEN>
<TOKEN id="token-31-24" pos="word" morph="none" start_char="5055" end_char="5063">defendida</TOKEN>
<TOKEN id="token-31-25" pos="word" morph="none" start_char="5065" end_char="5067">por</TOKEN>
<TOKEN id="token-31-26" pos="word" morph="none" start_char="5069" end_char="5078">personajes</TOKEN>
<TOKEN id="token-31-27" pos="word" morph="none" start_char="5080" end_char="5093">controvertidos</TOKEN>
<TOKEN id="token-31-28" pos="word" morph="none" start_char="5095" end_char="5098">como</TOKEN>
<TOKEN id="token-31-29" pos="word" morph="none" start_char="5100" end_char="5105">Donald</TOKEN>
<TOKEN id="token-31-30" pos="word" morph="none" start_char="5107" end_char="5111">Trump</TOKEN>
<TOKEN id="token-31-31" pos="word" morph="none" start_char="5113" end_char="5113">o</TOKEN>
<TOKEN id="token-31-32" pos="word" morph="none" start_char="5115" end_char="5118">Jair</TOKEN>
<TOKEN id="token-31-33" pos="word" morph="none" start_char="5120" end_char="5128">Bolsonaro</TOKEN>
<TOKEN id="token-31-34" pos="word" morph="none" start_char="5130" end_char="5130">e</TOKEN>
<TOKEN id="token-31-35" pos="word" morph="none" start_char="5132" end_char="5138">incluso</TOKEN>
<TOKEN id="token-31-36" pos="word" morph="none" start_char="5140" end_char="5141">el</TOKEN>
<TOKEN id="token-31-37" pos="word" morph="none" start_char="5143" end_char="5148">médico</TOKEN>
<TOKEN id="token-31-38" pos="word" morph="none" start_char="5150" end_char="5156">francés</TOKEN>
<TOKEN id="token-31-39" pos="word" morph="none" start_char="5158" end_char="5163">Didier</TOKEN>
<TOKEN id="token-31-40" pos="word" morph="none" start_char="5165" end_char="5170">Raoult</TOKEN>
<TOKEN id="token-31-41" pos="punct" morph="none" start_char="5171" end_char="5171">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="5174" end_char="5227">
<ORIGINAL_TEXT>«La recomendación es que si se puede evitar, evitarlo»</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="punct" morph="none" start_char="5174" end_char="5174">«</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="5175" end_char="5176">La</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="5178" end_char="5190">recomendación</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="5192" end_char="5193">es</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="5195" end_char="5197">que</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="5199" end_char="5200">si</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="5202" end_char="5203">se</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="5205" end_char="5209">puede</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="5211" end_char="5216">evitar</TOKEN>
<TOKEN id="token-32-9" pos="punct" morph="none" start_char="5217" end_char="5217">,</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="5219" end_char="5226">evitarlo</TOKEN>
<TOKEN id="token-32-11" pos="punct" morph="none" start_char="5227" end_char="5227">»</TOKEN>
</SEG>
<SEG id="segment-33" start_char="5230" end_char="5332">
<ORIGINAL_TEXT>La consigna en España es hoy que si es posible evitar el uso clínico de la hidroxicloroquina, se evite.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="5230" end_char="5231">La</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="5233" end_char="5240">consigna</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="5242" end_char="5243">en</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="5245" end_char="5250">España</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="5252" end_char="5253">es</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="5255" end_char="5257">hoy</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="5259" end_char="5261">que</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="5263" end_char="5264">si</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="5266" end_char="5267">es</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="5269" end_char="5275">posible</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="5277" end_char="5282">evitar</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="5284" end_char="5285">el</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="5287" end_char="5289">uso</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="5291" end_char="5297">clínico</TOKEN>
<TOKEN id="token-33-14" pos="word" morph="none" start_char="5299" end_char="5300">de</TOKEN>
<TOKEN id="token-33-15" pos="word" morph="none" start_char="5302" end_char="5303">la</TOKEN>
<TOKEN id="token-33-16" pos="word" morph="none" start_char="5305" end_char="5321">hidroxicloroquina</TOKEN>
<TOKEN id="token-33-17" pos="punct" morph="none" start_char="5322" end_char="5322">,</TOKEN>
<TOKEN id="token-33-18" pos="word" morph="none" start_char="5324" end_char="5325">se</TOKEN>
<TOKEN id="token-33-19" pos="word" morph="none" start_char="5327" end_char="5331">evite</TOKEN>
<TOKEN id="token-33-20" pos="punct" morph="none" start_char="5332" end_char="5332">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="5334" end_char="5571">
<ORIGINAL_TEXT>Así lo confirmaba este jueves Fernando Simón a preguntas de los periodistas: «Formaba parte de un ensayo clinico a cuatro brazos», es decir que, se analizaban varios fármacos y se comparaba la efectividad de unos con respecto a los otros.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="5334" end_char="5336">Así</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="5338" end_char="5339">lo</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="5341" end_char="5350">confirmaba</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="5352" end_char="5355">este</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="5357" end_char="5362">jueves</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="5364" end_char="5371">Fernando</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="5373" end_char="5377">Simón</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="5379" end_char="5379">a</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="5381" end_char="5389">preguntas</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="5391" end_char="5392">de</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="5394" end_char="5396">los</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="5398" end_char="5408">periodistas</TOKEN>
<TOKEN id="token-34-12" pos="punct" morph="none" start_char="5409" end_char="5409">:</TOKEN>
<TOKEN id="token-34-13" pos="punct" morph="none" start_char="5411" end_char="5411">«</TOKEN>
<TOKEN id="token-34-14" pos="word" morph="none" start_char="5412" end_char="5418">Formaba</TOKEN>
<TOKEN id="token-34-15" pos="word" morph="none" start_char="5420" end_char="5424">parte</TOKEN>
<TOKEN id="token-34-16" pos="word" morph="none" start_char="5426" end_char="5427">de</TOKEN>
<TOKEN id="token-34-17" pos="word" morph="none" start_char="5429" end_char="5430">un</TOKEN>
<TOKEN id="token-34-18" pos="word" morph="none" start_char="5432" end_char="5437">ensayo</TOKEN>
<TOKEN id="token-34-19" pos="word" morph="none" start_char="5439" end_char="5445">clinico</TOKEN>
<TOKEN id="token-34-20" pos="word" morph="none" start_char="5447" end_char="5447">a</TOKEN>
<TOKEN id="token-34-21" pos="word" morph="none" start_char="5449" end_char="5454">cuatro</TOKEN>
<TOKEN id="token-34-22" pos="word" morph="none" start_char="5456" end_char="5461">brazos</TOKEN>
<TOKEN id="token-34-23" pos="punct" morph="none" start_char="5462" end_char="5463">»,</TOKEN>
<TOKEN id="token-34-24" pos="word" morph="none" start_char="5465" end_char="5466">es</TOKEN>
<TOKEN id="token-34-25" pos="word" morph="none" start_char="5468" end_char="5472">decir</TOKEN>
<TOKEN id="token-34-26" pos="word" morph="none" start_char="5474" end_char="5476">que</TOKEN>
<TOKEN id="token-34-27" pos="punct" morph="none" start_char="5477" end_char="5477">,</TOKEN>
<TOKEN id="token-34-28" pos="word" morph="none" start_char="5479" end_char="5480">se</TOKEN>
<TOKEN id="token-34-29" pos="word" morph="none" start_char="5482" end_char="5491">analizaban</TOKEN>
<TOKEN id="token-34-30" pos="word" morph="none" start_char="5493" end_char="5498">varios</TOKEN>
<TOKEN id="token-34-31" pos="word" morph="none" start_char="5500" end_char="5507">fármacos</TOKEN>
<TOKEN id="token-34-32" pos="word" morph="none" start_char="5509" end_char="5509">y</TOKEN>
<TOKEN id="token-34-33" pos="word" morph="none" start_char="5511" end_char="5512">se</TOKEN>
<TOKEN id="token-34-34" pos="word" morph="none" start_char="5514" end_char="5522">comparaba</TOKEN>
<TOKEN id="token-34-35" pos="word" morph="none" start_char="5524" end_char="5525">la</TOKEN>
<TOKEN id="token-34-36" pos="word" morph="none" start_char="5527" end_char="5537">efectividad</TOKEN>
<TOKEN id="token-34-37" pos="word" morph="none" start_char="5539" end_char="5540">de</TOKEN>
<TOKEN id="token-34-38" pos="word" morph="none" start_char="5542" end_char="5545">unos</TOKEN>
<TOKEN id="token-34-39" pos="word" morph="none" start_char="5547" end_char="5549">con</TOKEN>
<TOKEN id="token-34-40" pos="word" morph="none" start_char="5551" end_char="5558">respecto</TOKEN>
<TOKEN id="token-34-41" pos="word" morph="none" start_char="5560" end_char="5560">a</TOKEN>
<TOKEN id="token-34-42" pos="word" morph="none" start_char="5562" end_char="5564">los</TOKEN>
<TOKEN id="token-34-43" pos="word" morph="none" start_char="5566" end_char="5570">otros</TOKEN>
<TOKEN id="token-34-44" pos="punct" morph="none" start_char="5571" end_char="5571">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="5573" end_char="5644">
<ORIGINAL_TEXT>«La hidroxicloroquina se ha eliminado del ensayo para prevenir riesgos».</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="punct" morph="none" start_char="5573" end_char="5573">«</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="5574" end_char="5575">La</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="5577" end_char="5593">hidroxicloroquina</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="5595" end_char="5596">se</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="5598" end_char="5599">ha</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="5601" end_char="5609">eliminado</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="5611" end_char="5613">del</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="5615" end_char="5620">ensayo</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="5622" end_char="5625">para</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="5627" end_char="5634">prevenir</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="5636" end_char="5642">riesgos</TOKEN>
<TOKEN id="token-35-11" pos="punct" morph="none" start_char="5643" end_char="5644">».</TOKEN>
</SEG>
<SEG id="segment-36" start_char="5647" end_char="5886">
<ORIGINAL_TEXT>«Lo que ha hecho la OMS es correcto, desde el punto de vista de que se suspende ese brazo en el estudio Solidarity y recomienda suspenderlo en otros ensayos hasta aclarar» si lo que dice el estudio de The Lancet es así o no, subraya Antela.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="punct" morph="none" start_char="5647" end_char="5647">«</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="5648" end_char="5649">Lo</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="5651" end_char="5653">que</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="5655" end_char="5656">ha</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="5658" end_char="5662">hecho</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="5664" end_char="5665">la</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="5667" end_char="5669">OMS</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="5671" end_char="5672">es</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="5674" end_char="5681">correcto</TOKEN>
<TOKEN id="token-36-9" pos="punct" morph="none" start_char="5682" end_char="5682">,</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="5684" end_char="5688">desde</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="5690" end_char="5691">el</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="5693" end_char="5697">punto</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="5699" end_char="5700">de</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="5702" end_char="5706">vista</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="5708" end_char="5709">de</TOKEN>
<TOKEN id="token-36-16" pos="word" morph="none" start_char="5711" end_char="5713">que</TOKEN>
<TOKEN id="token-36-17" pos="word" morph="none" start_char="5715" end_char="5716">se</TOKEN>
<TOKEN id="token-36-18" pos="word" morph="none" start_char="5718" end_char="5725">suspende</TOKEN>
<TOKEN id="token-36-19" pos="word" morph="none" start_char="5727" end_char="5729">ese</TOKEN>
<TOKEN id="token-36-20" pos="word" morph="none" start_char="5731" end_char="5735">brazo</TOKEN>
<TOKEN id="token-36-21" pos="word" morph="none" start_char="5737" end_char="5738">en</TOKEN>
<TOKEN id="token-36-22" pos="word" morph="none" start_char="5740" end_char="5741">el</TOKEN>
<TOKEN id="token-36-23" pos="word" morph="none" start_char="5743" end_char="5749">estudio</TOKEN>
<TOKEN id="token-36-24" pos="word" morph="none" start_char="5751" end_char="5760">Solidarity</TOKEN>
<TOKEN id="token-36-25" pos="word" morph="none" start_char="5762" end_char="5762">y</TOKEN>
<TOKEN id="token-36-26" pos="word" morph="none" start_char="5764" end_char="5773">recomienda</TOKEN>
<TOKEN id="token-36-27" pos="word" morph="none" start_char="5775" end_char="5785">suspenderlo</TOKEN>
<TOKEN id="token-36-28" pos="word" morph="none" start_char="5787" end_char="5788">en</TOKEN>
<TOKEN id="token-36-29" pos="word" morph="none" start_char="5790" end_char="5794">otros</TOKEN>
<TOKEN id="token-36-30" pos="word" morph="none" start_char="5796" end_char="5802">ensayos</TOKEN>
<TOKEN id="token-36-31" pos="word" morph="none" start_char="5804" end_char="5808">hasta</TOKEN>
<TOKEN id="token-36-32" pos="word" morph="none" start_char="5810" end_char="5816">aclarar</TOKEN>
<TOKEN id="token-36-33" pos="punct" morph="none" start_char="5817" end_char="5817">»</TOKEN>
<TOKEN id="token-36-34" pos="word" morph="none" start_char="5819" end_char="5820">si</TOKEN>
<TOKEN id="token-36-35" pos="word" morph="none" start_char="5822" end_char="5823">lo</TOKEN>
<TOKEN id="token-36-36" pos="word" morph="none" start_char="5825" end_char="5827">que</TOKEN>
<TOKEN id="token-36-37" pos="word" morph="none" start_char="5829" end_char="5832">dice</TOKEN>
<TOKEN id="token-36-38" pos="word" morph="none" start_char="5834" end_char="5835">el</TOKEN>
<TOKEN id="token-36-39" pos="word" morph="none" start_char="5837" end_char="5843">estudio</TOKEN>
<TOKEN id="token-36-40" pos="word" morph="none" start_char="5845" end_char="5846">de</TOKEN>
<TOKEN id="token-36-41" pos="word" morph="none" start_char="5848" end_char="5850">The</TOKEN>
<TOKEN id="token-36-42" pos="word" morph="none" start_char="5852" end_char="5857">Lancet</TOKEN>
<TOKEN id="token-36-43" pos="word" morph="none" start_char="5859" end_char="5860">es</TOKEN>
<TOKEN id="token-36-44" pos="word" morph="none" start_char="5862" end_char="5864">así</TOKEN>
<TOKEN id="token-36-45" pos="word" morph="none" start_char="5866" end_char="5866">o</TOKEN>
<TOKEN id="token-36-46" pos="word" morph="none" start_char="5868" end_char="5869">no</TOKEN>
<TOKEN id="token-36-47" pos="punct" morph="none" start_char="5870" end_char="5870">,</TOKEN>
<TOKEN id="token-36-48" pos="word" morph="none" start_char="5872" end_char="5878">subraya</TOKEN>
<TOKEN id="token-36-49" pos="word" morph="none" start_char="5880" end_char="5885">Antela</TOKEN>
<TOKEN id="token-36-50" pos="punct" morph="none" start_char="5886" end_char="5886">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="5888" end_char="6184">
<ORIGINAL_TEXT>Pero hay otros estudios, como el Recovery o Discovery, en Reino Unido y Francia, que no han detenido y el estudio y la agencia española, que ha remarcado que los resultados deben ser tenidos en cuenta del uso clínico pero no para excluirlo de ensayos clínicos aleatorizados, que tienen un control.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="5888" end_char="5891">Pero</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="5893" end_char="5895">hay</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="5897" end_char="5901">otros</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="5903" end_char="5910">estudios</TOKEN>
<TOKEN id="token-37-4" pos="punct" morph="none" start_char="5911" end_char="5911">,</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="5913" end_char="5916">como</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="5918" end_char="5919">el</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="5921" end_char="5928">Recovery</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="5930" end_char="5930">o</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="5932" end_char="5940">Discovery</TOKEN>
<TOKEN id="token-37-10" pos="punct" morph="none" start_char="5941" end_char="5941">,</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="5943" end_char="5944">en</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="5946" end_char="5950">Reino</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="5952" end_char="5956">Unido</TOKEN>
<TOKEN id="token-37-14" pos="word" morph="none" start_char="5958" end_char="5958">y</TOKEN>
<TOKEN id="token-37-15" pos="word" morph="none" start_char="5960" end_char="5966">Francia</TOKEN>
<TOKEN id="token-37-16" pos="punct" morph="none" start_char="5967" end_char="5967">,</TOKEN>
<TOKEN id="token-37-17" pos="word" morph="none" start_char="5969" end_char="5971">que</TOKEN>
<TOKEN id="token-37-18" pos="word" morph="none" start_char="5973" end_char="5974">no</TOKEN>
<TOKEN id="token-37-19" pos="word" morph="none" start_char="5976" end_char="5978">han</TOKEN>
<TOKEN id="token-37-20" pos="word" morph="none" start_char="5980" end_char="5987">detenido</TOKEN>
<TOKEN id="token-37-21" pos="word" morph="none" start_char="5989" end_char="5989">y</TOKEN>
<TOKEN id="token-37-22" pos="word" morph="none" start_char="5991" end_char="5992">el</TOKEN>
<TOKEN id="token-37-23" pos="word" morph="none" start_char="5994" end_char="6000">estudio</TOKEN>
<TOKEN id="token-37-24" pos="word" morph="none" start_char="6002" end_char="6002">y</TOKEN>
<TOKEN id="token-37-25" pos="word" morph="none" start_char="6004" end_char="6005">la</TOKEN>
<TOKEN id="token-37-26" pos="word" morph="none" start_char="6007" end_char="6013">agencia</TOKEN>
<TOKEN id="token-37-27" pos="word" morph="none" start_char="6015" end_char="6022">española</TOKEN>
<TOKEN id="token-37-28" pos="punct" morph="none" start_char="6023" end_char="6023">,</TOKEN>
<TOKEN id="token-37-29" pos="word" morph="none" start_char="6025" end_char="6027">que</TOKEN>
<TOKEN id="token-37-30" pos="word" morph="none" start_char="6029" end_char="6030">ha</TOKEN>
<TOKEN id="token-37-31" pos="word" morph="none" start_char="6032" end_char="6040">remarcado</TOKEN>
<TOKEN id="token-37-32" pos="word" morph="none" start_char="6042" end_char="6044">que</TOKEN>
<TOKEN id="token-37-33" pos="word" morph="none" start_char="6046" end_char="6048">los</TOKEN>
<TOKEN id="token-37-34" pos="word" morph="none" start_char="6050" end_char="6059">resultados</TOKEN>
<TOKEN id="token-37-35" pos="word" morph="none" start_char="6061" end_char="6065">deben</TOKEN>
<TOKEN id="token-37-36" pos="word" morph="none" start_char="6067" end_char="6069">ser</TOKEN>
<TOKEN id="token-37-37" pos="word" morph="none" start_char="6071" end_char="6077">tenidos</TOKEN>
<TOKEN id="token-37-38" pos="word" morph="none" start_char="6079" end_char="6080">en</TOKEN>
<TOKEN id="token-37-39" pos="word" morph="none" start_char="6082" end_char="6087">cuenta</TOKEN>
<TOKEN id="token-37-40" pos="word" morph="none" start_char="6089" end_char="6091">del</TOKEN>
<TOKEN id="token-37-41" pos="word" morph="none" start_char="6093" end_char="6095">uso</TOKEN>
<TOKEN id="token-37-42" pos="word" morph="none" start_char="6097" end_char="6103">clínico</TOKEN>
<TOKEN id="token-37-43" pos="word" morph="none" start_char="6105" end_char="6108">pero</TOKEN>
<TOKEN id="token-37-44" pos="word" morph="none" start_char="6110" end_char="6111">no</TOKEN>
<TOKEN id="token-37-45" pos="word" morph="none" start_char="6113" end_char="6116">para</TOKEN>
<TOKEN id="token-37-46" pos="word" morph="none" start_char="6118" end_char="6126">excluirlo</TOKEN>
<TOKEN id="token-37-47" pos="word" morph="none" start_char="6128" end_char="6129">de</TOKEN>
<TOKEN id="token-37-48" pos="word" morph="none" start_char="6131" end_char="6137">ensayos</TOKEN>
<TOKEN id="token-37-49" pos="word" morph="none" start_char="6139" end_char="6146">clínicos</TOKEN>
<TOKEN id="token-37-50" pos="word" morph="none" start_char="6148" end_char="6160">aleatorizados</TOKEN>
<TOKEN id="token-37-51" pos="punct" morph="none" start_char="6161" end_char="6161">,</TOKEN>
<TOKEN id="token-37-52" pos="word" morph="none" start_char="6163" end_char="6165">que</TOKEN>
<TOKEN id="token-37-53" pos="word" morph="none" start_char="6167" end_char="6172">tienen</TOKEN>
<TOKEN id="token-37-54" pos="word" morph="none" start_char="6174" end_char="6175">un</TOKEN>
<TOKEN id="token-37-55" pos="word" morph="none" start_char="6177" end_char="6183">control</TOKEN>
<TOKEN id="token-37-56" pos="punct" morph="none" start_char="6184" end_char="6184">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="6186" end_char="6344">
<ORIGINAL_TEXT>«Si se registra en un brazo un número elevado de eventos adversos el estudio se detiene», matiza el médico del CHUS, y de momento no se ha registrado nada así.</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="punct" morph="none" start_char="6186" end_char="6186">«</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="6187" end_char="6188">Si</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="6190" end_char="6191">se</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="6193" end_char="6200">registra</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="6202" end_char="6203">en</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="6205" end_char="6206">un</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="6208" end_char="6212">brazo</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="6214" end_char="6215">un</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="6217" end_char="6222">número</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="6224" end_char="6230">elevado</TOKEN>
<TOKEN id="token-38-10" pos="word" morph="none" start_char="6232" end_char="6233">de</TOKEN>
<TOKEN id="token-38-11" pos="word" morph="none" start_char="6235" end_char="6241">eventos</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="6243" end_char="6250">adversos</TOKEN>
<TOKEN id="token-38-13" pos="word" morph="none" start_char="6252" end_char="6253">el</TOKEN>
<TOKEN id="token-38-14" pos="word" morph="none" start_char="6255" end_char="6261">estudio</TOKEN>
<TOKEN id="token-38-15" pos="word" morph="none" start_char="6263" end_char="6264">se</TOKEN>
<TOKEN id="token-38-16" pos="word" morph="none" start_char="6266" end_char="6272">detiene</TOKEN>
<TOKEN id="token-38-17" pos="punct" morph="none" start_char="6273" end_char="6274">»,</TOKEN>
<TOKEN id="token-38-18" pos="word" morph="none" start_char="6276" end_char="6281">matiza</TOKEN>
<TOKEN id="token-38-19" pos="word" morph="none" start_char="6283" end_char="6284">el</TOKEN>
<TOKEN id="token-38-20" pos="word" morph="none" start_char="6286" end_char="6291">médico</TOKEN>
<TOKEN id="token-38-21" pos="word" morph="none" start_char="6293" end_char="6295">del</TOKEN>
<TOKEN id="token-38-22" pos="word" morph="none" start_char="6297" end_char="6300">CHUS</TOKEN>
<TOKEN id="token-38-23" pos="punct" morph="none" start_char="6301" end_char="6301">,</TOKEN>
<TOKEN id="token-38-24" pos="word" morph="none" start_char="6303" end_char="6303">y</TOKEN>
<TOKEN id="token-38-25" pos="word" morph="none" start_char="6305" end_char="6306">de</TOKEN>
<TOKEN id="token-38-26" pos="word" morph="none" start_char="6308" end_char="6314">momento</TOKEN>
<TOKEN id="token-38-27" pos="word" morph="none" start_char="6316" end_char="6317">no</TOKEN>
<TOKEN id="token-38-28" pos="word" morph="none" start_char="6319" end_char="6320">se</TOKEN>
<TOKEN id="token-38-29" pos="word" morph="none" start_char="6322" end_char="6323">ha</TOKEN>
<TOKEN id="token-38-30" pos="word" morph="none" start_char="6325" end_char="6334">registrado</TOKEN>
<TOKEN id="token-38-31" pos="word" morph="none" start_char="6336" end_char="6339">nada</TOKEN>
<TOKEN id="token-38-32" pos="word" morph="none" start_char="6341" end_char="6343">así</TOKEN>
<TOKEN id="token-38-33" pos="punct" morph="none" start_char="6344" end_char="6344">.</TOKEN>
</SEG>
<SEG id="segment-39" start_char="6347" end_char="6565">
<ORIGINAL_TEXT>El fármaco «sigue a disposición» de los profesionales sanitarios, «pero evidentemente deben usarlo con mucho más cuidado y ahora la recomendación es que si se puede evitar, evitarlo», remarcó este jueves Fernando Simón.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="6347" end_char="6348">El</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="6350" end_char="6356">fármaco</TOKEN>
<TOKEN id="token-39-2" pos="punct" morph="none" start_char="6358" end_char="6358">«</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="6359" end_char="6363">sigue</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="6365" end_char="6365">a</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="6367" end_char="6377">disposición</TOKEN>
<TOKEN id="token-39-6" pos="punct" morph="none" start_char="6378" end_char="6378">»</TOKEN>
<TOKEN id="token-39-7" pos="word" morph="none" start_char="6380" end_char="6381">de</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="6383" end_char="6385">los</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="6387" end_char="6399">profesionales</TOKEN>
<TOKEN id="token-39-10" pos="word" morph="none" start_char="6401" end_char="6410">sanitarios</TOKEN>
<TOKEN id="token-39-11" pos="punct" morph="none" start_char="6411" end_char="6411">,</TOKEN>
<TOKEN id="token-39-12" pos="punct" morph="none" start_char="6413" end_char="6413">«</TOKEN>
<TOKEN id="token-39-13" pos="word" morph="none" start_char="6414" end_char="6417">pero</TOKEN>
<TOKEN id="token-39-14" pos="word" morph="none" start_char="6419" end_char="6431">evidentemente</TOKEN>
<TOKEN id="token-39-15" pos="word" morph="none" start_char="6433" end_char="6437">deben</TOKEN>
<TOKEN id="token-39-16" pos="word" morph="none" start_char="6439" end_char="6444">usarlo</TOKEN>
<TOKEN id="token-39-17" pos="word" morph="none" start_char="6446" end_char="6448">con</TOKEN>
<TOKEN id="token-39-18" pos="word" morph="none" start_char="6450" end_char="6454">mucho</TOKEN>
<TOKEN id="token-39-19" pos="word" morph="none" start_char="6456" end_char="6458">más</TOKEN>
<TOKEN id="token-39-20" pos="word" morph="none" start_char="6460" end_char="6466">cuidado</TOKEN>
<TOKEN id="token-39-21" pos="word" morph="none" start_char="6468" end_char="6468">y</TOKEN>
<TOKEN id="token-39-22" pos="word" morph="none" start_char="6470" end_char="6474">ahora</TOKEN>
<TOKEN id="token-39-23" pos="word" morph="none" start_char="6476" end_char="6477">la</TOKEN>
<TOKEN id="token-39-24" pos="word" morph="none" start_char="6479" end_char="6491">recomendación</TOKEN>
<TOKEN id="token-39-25" pos="word" morph="none" start_char="6493" end_char="6494">es</TOKEN>
<TOKEN id="token-39-26" pos="word" morph="none" start_char="6496" end_char="6498">que</TOKEN>
<TOKEN id="token-39-27" pos="word" morph="none" start_char="6500" end_char="6501">si</TOKEN>
<TOKEN id="token-39-28" pos="word" morph="none" start_char="6503" end_char="6504">se</TOKEN>
<TOKEN id="token-39-29" pos="word" morph="none" start_char="6506" end_char="6510">puede</TOKEN>
<TOKEN id="token-39-30" pos="word" morph="none" start_char="6512" end_char="6517">evitar</TOKEN>
<TOKEN id="token-39-31" pos="punct" morph="none" start_char="6518" end_char="6518">,</TOKEN>
<TOKEN id="token-39-32" pos="word" morph="none" start_char="6520" end_char="6527">evitarlo</TOKEN>
<TOKEN id="token-39-33" pos="punct" morph="none" start_char="6528" end_char="6529">»,</TOKEN>
<TOKEN id="token-39-34" pos="word" morph="none" start_char="6531" end_char="6537">remarcó</TOKEN>
<TOKEN id="token-39-35" pos="word" morph="none" start_char="6539" end_char="6542">este</TOKEN>
<TOKEN id="token-39-36" pos="word" morph="none" start_char="6544" end_char="6549">jueves</TOKEN>
<TOKEN id="token-39-37" pos="word" morph="none" start_char="6551" end_char="6558">Fernando</TOKEN>
<TOKEN id="token-39-38" pos="word" morph="none" start_char="6560" end_char="6564">Simón</TOKEN>
<TOKEN id="token-39-39" pos="punct" morph="none" start_char="6565" end_char="6565">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="6567" end_char="6724">
<ORIGINAL_TEXT>Y Antonio Antela añade que sobre todo hay que evitar utilizarlo en combinación con medicamentos que puedan agravar el efecto adverso que provoca, la arritmia.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="6567" end_char="6567">Y</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="6569" end_char="6575">Antonio</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="6577" end_char="6582">Antela</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="6584" end_char="6588">añade</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="6590" end_char="6592">que</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="6594" end_char="6598">sobre</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="6600" end_char="6603">todo</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="6605" end_char="6607">hay</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="6609" end_char="6611">que</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="6613" end_char="6618">evitar</TOKEN>
<TOKEN id="token-40-10" pos="word" morph="none" start_char="6620" end_char="6629">utilizarlo</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="6631" end_char="6632">en</TOKEN>
<TOKEN id="token-40-12" pos="word" morph="none" start_char="6634" end_char="6644">combinación</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="6646" end_char="6648">con</TOKEN>
<TOKEN id="token-40-14" pos="word" morph="none" start_char="6650" end_char="6661">medicamentos</TOKEN>
<TOKEN id="token-40-15" pos="word" morph="none" start_char="6663" end_char="6665">que</TOKEN>
<TOKEN id="token-40-16" pos="word" morph="none" start_char="6667" end_char="6672">puedan</TOKEN>
<TOKEN id="token-40-17" pos="word" morph="none" start_char="6674" end_char="6680">agravar</TOKEN>
<TOKEN id="token-40-18" pos="word" morph="none" start_char="6682" end_char="6683">el</TOKEN>
<TOKEN id="token-40-19" pos="word" morph="none" start_char="6685" end_char="6690">efecto</TOKEN>
<TOKEN id="token-40-20" pos="word" morph="none" start_char="6692" end_char="6698">adverso</TOKEN>
<TOKEN id="token-40-21" pos="word" morph="none" start_char="6700" end_char="6702">que</TOKEN>
<TOKEN id="token-40-22" pos="word" morph="none" start_char="6704" end_char="6710">provoca</TOKEN>
<TOKEN id="token-40-23" pos="punct" morph="none" start_char="6711" end_char="6711">,</TOKEN>
<TOKEN id="token-40-24" pos="word" morph="none" start_char="6713" end_char="6714">la</TOKEN>
<TOKEN id="token-40-25" pos="word" morph="none" start_char="6716" end_char="6723">arritmia</TOKEN>
<TOKEN id="token-40-26" pos="punct" morph="none" start_char="6724" end_char="6724">.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="6726" end_char="6912">
<ORIGINAL_TEXT>«Hay que procurar no asociarlo a azitromizina, que es algo que hemos utilizado frecuentemente, ni a kaletra» porque pueden funcionar como catalizadores de ese efecto adverso cardiológico.</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="punct" morph="none" start_char="6726" end_char="6726">«</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="6727" end_char="6729">Hay</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="6731" end_char="6733">que</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="6735" end_char="6742">procurar</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="6744" end_char="6745">no</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="6747" end_char="6755">asociarlo</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="6757" end_char="6757">a</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="6759" end_char="6770">azitromizina</TOKEN>
<TOKEN id="token-41-8" pos="punct" morph="none" start_char="6771" end_char="6771">,</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="6773" end_char="6775">que</TOKEN>
<TOKEN id="token-41-10" pos="word" morph="none" start_char="6777" end_char="6778">es</TOKEN>
<TOKEN id="token-41-11" pos="word" morph="none" start_char="6780" end_char="6783">algo</TOKEN>
<TOKEN id="token-41-12" pos="word" morph="none" start_char="6785" end_char="6787">que</TOKEN>
<TOKEN id="token-41-13" pos="word" morph="none" start_char="6789" end_char="6793">hemos</TOKEN>
<TOKEN id="token-41-14" pos="word" morph="none" start_char="6795" end_char="6803">utilizado</TOKEN>
<TOKEN id="token-41-15" pos="word" morph="none" start_char="6805" end_char="6818">frecuentemente</TOKEN>
<TOKEN id="token-41-16" pos="punct" morph="none" start_char="6819" end_char="6819">,</TOKEN>
<TOKEN id="token-41-17" pos="word" morph="none" start_char="6821" end_char="6822">ni</TOKEN>
<TOKEN id="token-41-18" pos="word" morph="none" start_char="6824" end_char="6824">a</TOKEN>
<TOKEN id="token-41-19" pos="word" morph="none" start_char="6826" end_char="6832">kaletra</TOKEN>
<TOKEN id="token-41-20" pos="punct" morph="none" start_char="6833" end_char="6833">»</TOKEN>
<TOKEN id="token-41-21" pos="word" morph="none" start_char="6835" end_char="6840">porque</TOKEN>
<TOKEN id="token-41-22" pos="word" morph="none" start_char="6842" end_char="6847">pueden</TOKEN>
<TOKEN id="token-41-23" pos="word" morph="none" start_char="6849" end_char="6857">funcionar</TOKEN>
<TOKEN id="token-41-24" pos="word" morph="none" start_char="6859" end_char="6862">como</TOKEN>
<TOKEN id="token-41-25" pos="word" morph="none" start_char="6864" end_char="6876">catalizadores</TOKEN>
<TOKEN id="token-41-26" pos="word" morph="none" start_char="6878" end_char="6879">de</TOKEN>
<TOKEN id="token-41-27" pos="word" morph="none" start_char="6881" end_char="6883">ese</TOKEN>
<TOKEN id="token-41-28" pos="word" morph="none" start_char="6885" end_char="6890">efecto</TOKEN>
<TOKEN id="token-41-29" pos="word" morph="none" start_char="6892" end_char="6898">adverso</TOKEN>
<TOKEN id="token-41-30" pos="word" morph="none" start_char="6900" end_char="6911">cardiológico</TOKEN>
<TOKEN id="token-41-31" pos="punct" morph="none" start_char="6912" end_char="6912">.</TOKEN>
</SEG>
<SEG id="segment-42" start_char="6915" end_char="7173">
<ORIGINAL_TEXT>El médico del CHUS defiende «utilizar hidroxicloroquina en pacientes que están incluidos en ensayos clínicos aleatorizados y sobre todo cuando se usan en fases precoces o incluso en estudios de prevención», como Épicos, que se centra en el personal sanitario.</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="6915" end_char="6916">El</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="6918" end_char="6923">médico</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="6925" end_char="6927">del</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="6929" end_char="6932">CHUS</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="6934" end_char="6941">defiende</TOKEN>
<TOKEN id="token-42-5" pos="punct" morph="none" start_char="6943" end_char="6943">«</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="6944" end_char="6951">utilizar</TOKEN>
<TOKEN id="token-42-7" pos="word" morph="none" start_char="6953" end_char="6969">hidroxicloroquina</TOKEN>
<TOKEN id="token-42-8" pos="word" morph="none" start_char="6971" end_char="6972">en</TOKEN>
<TOKEN id="token-42-9" pos="word" morph="none" start_char="6974" end_char="6982">pacientes</TOKEN>
<TOKEN id="token-42-10" pos="word" morph="none" start_char="6984" end_char="6986">que</TOKEN>
<TOKEN id="token-42-11" pos="word" morph="none" start_char="6988" end_char="6992">están</TOKEN>
<TOKEN id="token-42-12" pos="word" morph="none" start_char="6994" end_char="7002">incluidos</TOKEN>
<TOKEN id="token-42-13" pos="word" morph="none" start_char="7004" end_char="7005">en</TOKEN>
<TOKEN id="token-42-14" pos="word" morph="none" start_char="7007" end_char="7013">ensayos</TOKEN>
<TOKEN id="token-42-15" pos="word" morph="none" start_char="7015" end_char="7022">clínicos</TOKEN>
<TOKEN id="token-42-16" pos="word" morph="none" start_char="7024" end_char="7036">aleatorizados</TOKEN>
<TOKEN id="token-42-17" pos="word" morph="none" start_char="7038" end_char="7038">y</TOKEN>
<TOKEN id="token-42-18" pos="word" morph="none" start_char="7040" end_char="7044">sobre</TOKEN>
<TOKEN id="token-42-19" pos="word" morph="none" start_char="7046" end_char="7049">todo</TOKEN>
<TOKEN id="token-42-20" pos="word" morph="none" start_char="7051" end_char="7056">cuando</TOKEN>
<TOKEN id="token-42-21" pos="word" morph="none" start_char="7058" end_char="7059">se</TOKEN>
<TOKEN id="token-42-22" pos="word" morph="none" start_char="7061" end_char="7064">usan</TOKEN>
<TOKEN id="token-42-23" pos="word" morph="none" start_char="7066" end_char="7067">en</TOKEN>
<TOKEN id="token-42-24" pos="word" morph="none" start_char="7069" end_char="7073">fases</TOKEN>
<TOKEN id="token-42-25" pos="word" morph="none" start_char="7075" end_char="7082">precoces</TOKEN>
<TOKEN id="token-42-26" pos="word" morph="none" start_char="7084" end_char="7084">o</TOKEN>
<TOKEN id="token-42-27" pos="word" morph="none" start_char="7086" end_char="7092">incluso</TOKEN>
<TOKEN id="token-42-28" pos="word" morph="none" start_char="7094" end_char="7095">en</TOKEN>
<TOKEN id="token-42-29" pos="word" morph="none" start_char="7097" end_char="7104">estudios</TOKEN>
<TOKEN id="token-42-30" pos="word" morph="none" start_char="7106" end_char="7107">de</TOKEN>
<TOKEN id="token-42-31" pos="word" morph="none" start_char="7109" end_char="7118">prevención</TOKEN>
<TOKEN id="token-42-32" pos="punct" morph="none" start_char="7119" end_char="7120">»,</TOKEN>
<TOKEN id="token-42-33" pos="word" morph="none" start_char="7122" end_char="7125">como</TOKEN>
<TOKEN id="token-42-34" pos="word" morph="none" start_char="7127" end_char="7132">Épicos</TOKEN>
<TOKEN id="token-42-35" pos="punct" morph="none" start_char="7133" end_char="7133">,</TOKEN>
<TOKEN id="token-42-36" pos="word" morph="none" start_char="7135" end_char="7137">que</TOKEN>
<TOKEN id="token-42-37" pos="word" morph="none" start_char="7139" end_char="7140">se</TOKEN>
<TOKEN id="token-42-38" pos="word" morph="none" start_char="7142" end_char="7147">centra</TOKEN>
<TOKEN id="token-42-39" pos="word" morph="none" start_char="7149" end_char="7150">en</TOKEN>
<TOKEN id="token-42-40" pos="word" morph="none" start_char="7152" end_char="7153">el</TOKEN>
<TOKEN id="token-42-41" pos="word" morph="none" start_char="7155" end_char="7162">personal</TOKEN>
<TOKEN id="token-42-42" pos="word" morph="none" start_char="7164" end_char="7172">sanitario</TOKEN>
<TOKEN id="token-42-43" pos="punct" morph="none" start_char="7173" end_char="7173">.</TOKEN>
</SEG>
<SEG id="segment-43" start_char="7175" end_char="7509">
<ORIGINAL_TEXT>«El consejo de seguridad del estudio ha emitido un comunicado para pacientes y personal médico diciendo que hay que continuar porque no se han producido efectos secundarios» y porque están tratando a un colectivo específico, que lo que quiere es no infectarse, un escenario distinto al de los pacientes que han contraído la enfermedad.</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="punct" morph="none" start_char="7175" end_char="7175">«</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="7176" end_char="7177">El</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="7179" end_char="7185">consejo</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="7187" end_char="7188">de</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="7190" end_char="7198">seguridad</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="7200" end_char="7202">del</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="7204" end_char="7210">estudio</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="7212" end_char="7213">ha</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="7215" end_char="7221">emitido</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="7223" end_char="7224">un</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="7226" end_char="7235">comunicado</TOKEN>
<TOKEN id="token-43-11" pos="word" morph="none" start_char="7237" end_char="7240">para</TOKEN>
<TOKEN id="token-43-12" pos="word" morph="none" start_char="7242" end_char="7250">pacientes</TOKEN>
<TOKEN id="token-43-13" pos="word" morph="none" start_char="7252" end_char="7252">y</TOKEN>
<TOKEN id="token-43-14" pos="word" morph="none" start_char="7254" end_char="7261">personal</TOKEN>
<TOKEN id="token-43-15" pos="word" morph="none" start_char="7263" end_char="7268">médico</TOKEN>
<TOKEN id="token-43-16" pos="word" morph="none" start_char="7270" end_char="7277">diciendo</TOKEN>
<TOKEN id="token-43-17" pos="word" morph="none" start_char="7279" end_char="7281">que</TOKEN>
<TOKEN id="token-43-18" pos="word" morph="none" start_char="7283" end_char="7285">hay</TOKEN>
<TOKEN id="token-43-19" pos="word" morph="none" start_char="7287" end_char="7289">que</TOKEN>
<TOKEN id="token-43-20" pos="word" morph="none" start_char="7291" end_char="7299">continuar</TOKEN>
<TOKEN id="token-43-21" pos="word" morph="none" start_char="7301" end_char="7306">porque</TOKEN>
<TOKEN id="token-43-22" pos="word" morph="none" start_char="7308" end_char="7309">no</TOKEN>
<TOKEN id="token-43-23" pos="word" morph="none" start_char="7311" end_char="7312">se</TOKEN>
<TOKEN id="token-43-24" pos="word" morph="none" start_char="7314" end_char="7316">han</TOKEN>
<TOKEN id="token-43-25" pos="word" morph="none" start_char="7318" end_char="7326">producido</TOKEN>
<TOKEN id="token-43-26" pos="word" morph="none" start_char="7328" end_char="7334">efectos</TOKEN>
<TOKEN id="token-43-27" pos="word" morph="none" start_char="7336" end_char="7346">secundarios</TOKEN>
<TOKEN id="token-43-28" pos="punct" morph="none" start_char="7347" end_char="7347">»</TOKEN>
<TOKEN id="token-43-29" pos="word" morph="none" start_char="7349" end_char="7349">y</TOKEN>
<TOKEN id="token-43-30" pos="word" morph="none" start_char="7351" end_char="7356">porque</TOKEN>
<TOKEN id="token-43-31" pos="word" morph="none" start_char="7358" end_char="7362">están</TOKEN>
<TOKEN id="token-43-32" pos="word" morph="none" start_char="7364" end_char="7371">tratando</TOKEN>
<TOKEN id="token-43-33" pos="word" morph="none" start_char="7373" end_char="7373">a</TOKEN>
<TOKEN id="token-43-34" pos="word" morph="none" start_char="7375" end_char="7376">un</TOKEN>
<TOKEN id="token-43-35" pos="word" morph="none" start_char="7378" end_char="7386">colectivo</TOKEN>
<TOKEN id="token-43-36" pos="word" morph="none" start_char="7388" end_char="7397">específico</TOKEN>
<TOKEN id="token-43-37" pos="punct" morph="none" start_char="7398" end_char="7398">,</TOKEN>
<TOKEN id="token-43-38" pos="word" morph="none" start_char="7400" end_char="7402">que</TOKEN>
<TOKEN id="token-43-39" pos="word" morph="none" start_char="7404" end_char="7405">lo</TOKEN>
<TOKEN id="token-43-40" pos="word" morph="none" start_char="7407" end_char="7409">que</TOKEN>
<TOKEN id="token-43-41" pos="word" morph="none" start_char="7411" end_char="7416">quiere</TOKEN>
<TOKEN id="token-43-42" pos="word" morph="none" start_char="7418" end_char="7419">es</TOKEN>
<TOKEN id="token-43-43" pos="word" morph="none" start_char="7421" end_char="7422">no</TOKEN>
<TOKEN id="token-43-44" pos="word" morph="none" start_char="7424" end_char="7433">infectarse</TOKEN>
<TOKEN id="token-43-45" pos="punct" morph="none" start_char="7434" end_char="7434">,</TOKEN>
<TOKEN id="token-43-46" pos="word" morph="none" start_char="7436" end_char="7437">un</TOKEN>
<TOKEN id="token-43-47" pos="word" morph="none" start_char="7439" end_char="7447">escenario</TOKEN>
<TOKEN id="token-43-48" pos="word" morph="none" start_char="7449" end_char="7456">distinto</TOKEN>
<TOKEN id="token-43-49" pos="word" morph="none" start_char="7458" end_char="7459">al</TOKEN>
<TOKEN id="token-43-50" pos="word" morph="none" start_char="7461" end_char="7462">de</TOKEN>
<TOKEN id="token-43-51" pos="word" morph="none" start_char="7464" end_char="7466">los</TOKEN>
<TOKEN id="token-43-52" pos="word" morph="none" start_char="7468" end_char="7476">pacientes</TOKEN>
<TOKEN id="token-43-53" pos="word" morph="none" start_char="7478" end_char="7480">que</TOKEN>
<TOKEN id="token-43-54" pos="word" morph="none" start_char="7482" end_char="7484">han</TOKEN>
<TOKEN id="token-43-55" pos="word" morph="none" start_char="7486" end_char="7494">contraído</TOKEN>
<TOKEN id="token-43-56" pos="word" morph="none" start_char="7496" end_char="7497">la</TOKEN>
<TOKEN id="token-43-57" pos="word" morph="none" start_char="7499" end_char="7508">enfermedad</TOKEN>
<TOKEN id="token-43-58" pos="punct" morph="none" start_char="7509" end_char="7509">.</TOKEN>
</SEG>
<SEG id="segment-44" start_char="7512" end_char="7782">
<ORIGINAL_TEXT>Antela también manda un mensaje de tranquilidad sobre el uso del fármaco, aunque el protocolo es utilizar otros fármacos siempre que sea posible hasta que no se aclaren exactamente los efectos que tiene, y que en el caso de usarlo no se asocie con azitromicina o kaletra.</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="7512" end_char="7517">Antela</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="7519" end_char="7525">también</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="7527" end_char="7531">manda</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="7533" end_char="7534">un</TOKEN>
<TOKEN id="token-44-4" pos="word" morph="none" start_char="7536" end_char="7542">mensaje</TOKEN>
<TOKEN id="token-44-5" pos="word" morph="none" start_char="7544" end_char="7545">de</TOKEN>
<TOKEN id="token-44-6" pos="word" morph="none" start_char="7547" end_char="7558">tranquilidad</TOKEN>
<TOKEN id="token-44-7" pos="word" morph="none" start_char="7560" end_char="7564">sobre</TOKEN>
<TOKEN id="token-44-8" pos="word" morph="none" start_char="7566" end_char="7567">el</TOKEN>
<TOKEN id="token-44-9" pos="word" morph="none" start_char="7569" end_char="7571">uso</TOKEN>
<TOKEN id="token-44-10" pos="word" morph="none" start_char="7573" end_char="7575">del</TOKEN>
<TOKEN id="token-44-11" pos="word" morph="none" start_char="7577" end_char="7583">fármaco</TOKEN>
<TOKEN id="token-44-12" pos="punct" morph="none" start_char="7584" end_char="7584">,</TOKEN>
<TOKEN id="token-44-13" pos="word" morph="none" start_char="7586" end_char="7591">aunque</TOKEN>
<TOKEN id="token-44-14" pos="word" morph="none" start_char="7593" end_char="7594">el</TOKEN>
<TOKEN id="token-44-15" pos="word" morph="none" start_char="7596" end_char="7604">protocolo</TOKEN>
<TOKEN id="token-44-16" pos="word" morph="none" start_char="7606" end_char="7607">es</TOKEN>
<TOKEN id="token-44-17" pos="word" morph="none" start_char="7609" end_char="7616">utilizar</TOKEN>
<TOKEN id="token-44-18" pos="word" morph="none" start_char="7618" end_char="7622">otros</TOKEN>
<TOKEN id="token-44-19" pos="word" morph="none" start_char="7624" end_char="7631">fármacos</TOKEN>
<TOKEN id="token-44-20" pos="word" morph="none" start_char="7633" end_char="7639">siempre</TOKEN>
<TOKEN id="token-44-21" pos="word" morph="none" start_char="7641" end_char="7643">que</TOKEN>
<TOKEN id="token-44-22" pos="word" morph="none" start_char="7645" end_char="7647">sea</TOKEN>
<TOKEN id="token-44-23" pos="word" morph="none" start_char="7649" end_char="7655">posible</TOKEN>
<TOKEN id="token-44-24" pos="word" morph="none" start_char="7657" end_char="7661">hasta</TOKEN>
<TOKEN id="token-44-25" pos="word" morph="none" start_char="7663" end_char="7665">que</TOKEN>
<TOKEN id="token-44-26" pos="word" morph="none" start_char="7667" end_char="7668">no</TOKEN>
<TOKEN id="token-44-27" pos="word" morph="none" start_char="7670" end_char="7671">se</TOKEN>
<TOKEN id="token-44-28" pos="word" morph="none" start_char="7673" end_char="7679">aclaren</TOKEN>
<TOKEN id="token-44-29" pos="word" morph="none" start_char="7681" end_char="7691">exactamente</TOKEN>
<TOKEN id="token-44-30" pos="word" morph="none" start_char="7693" end_char="7695">los</TOKEN>
<TOKEN id="token-44-31" pos="word" morph="none" start_char="7697" end_char="7703">efectos</TOKEN>
<TOKEN id="token-44-32" pos="word" morph="none" start_char="7705" end_char="7707">que</TOKEN>
<TOKEN id="token-44-33" pos="word" morph="none" start_char="7709" end_char="7713">tiene</TOKEN>
<TOKEN id="token-44-34" pos="punct" morph="none" start_char="7714" end_char="7714">,</TOKEN>
<TOKEN id="token-44-35" pos="word" morph="none" start_char="7716" end_char="7716">y</TOKEN>
<TOKEN id="token-44-36" pos="word" morph="none" start_char="7718" end_char="7720">que</TOKEN>
<TOKEN id="token-44-37" pos="word" morph="none" start_char="7722" end_char="7723">en</TOKEN>
<TOKEN id="token-44-38" pos="word" morph="none" start_char="7725" end_char="7726">el</TOKEN>
<TOKEN id="token-44-39" pos="word" morph="none" start_char="7728" end_char="7731">caso</TOKEN>
<TOKEN id="token-44-40" pos="word" morph="none" start_char="7733" end_char="7734">de</TOKEN>
<TOKEN id="token-44-41" pos="word" morph="none" start_char="7736" end_char="7741">usarlo</TOKEN>
<TOKEN id="token-44-42" pos="word" morph="none" start_char="7743" end_char="7744">no</TOKEN>
<TOKEN id="token-44-43" pos="word" morph="none" start_char="7746" end_char="7747">se</TOKEN>
<TOKEN id="token-44-44" pos="word" morph="none" start_char="7749" end_char="7754">asocie</TOKEN>
<TOKEN id="token-44-45" pos="word" morph="none" start_char="7756" end_char="7758">con</TOKEN>
<TOKEN id="token-44-46" pos="word" morph="none" start_char="7760" end_char="7771">azitromicina</TOKEN>
<TOKEN id="token-44-47" pos="word" morph="none" start_char="7773" end_char="7773">o</TOKEN>
<TOKEN id="token-44-48" pos="word" morph="none" start_char="7775" end_char="7781">kaletra</TOKEN>
<TOKEN id="token-44-49" pos="punct" morph="none" start_char="7782" end_char="7782">.</TOKEN>
</SEG>
<SEG id="segment-45" start_char="7785" end_char="7949">
<ORIGINAL_TEXT>La administración de hidroxicloroquina para el covid-19 también sigue un protocolo, que incluye la realización de electrocardiogramas y un tratamiento de cinco días.</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="7785" end_char="7786">La</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="7788" end_char="7801">administración</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="7803" end_char="7804">de</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="7806" end_char="7822">hidroxicloroquina</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="7824" end_char="7827">para</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="7829" end_char="7830">el</TOKEN>
<TOKEN id="token-45-6" pos="unknown" morph="none" start_char="7832" end_char="7839">covid-19</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="7841" end_char="7847">también</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="7849" end_char="7853">sigue</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="7855" end_char="7856">un</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="7858" end_char="7866">protocolo</TOKEN>
<TOKEN id="token-45-11" pos="punct" morph="none" start_char="7867" end_char="7867">,</TOKEN>
<TOKEN id="token-45-12" pos="word" morph="none" start_char="7869" end_char="7871">que</TOKEN>
<TOKEN id="token-45-13" pos="word" morph="none" start_char="7873" end_char="7879">incluye</TOKEN>
<TOKEN id="token-45-14" pos="word" morph="none" start_char="7881" end_char="7882">la</TOKEN>
<TOKEN id="token-45-15" pos="word" morph="none" start_char="7884" end_char="7894">realización</TOKEN>
<TOKEN id="token-45-16" pos="word" morph="none" start_char="7896" end_char="7897">de</TOKEN>
<TOKEN id="token-45-17" pos="word" morph="none" start_char="7899" end_char="7917">electrocardiogramas</TOKEN>
<TOKEN id="token-45-18" pos="word" morph="none" start_char="7919" end_char="7919">y</TOKEN>
<TOKEN id="token-45-19" pos="word" morph="none" start_char="7921" end_char="7922">un</TOKEN>
<TOKEN id="token-45-20" pos="word" morph="none" start_char="7924" end_char="7934">tratamiento</TOKEN>
<TOKEN id="token-45-21" pos="word" morph="none" start_char="7936" end_char="7937">de</TOKEN>
<TOKEN id="token-45-22" pos="word" morph="none" start_char="7939" end_char="7943">cinco</TOKEN>
<TOKEN id="token-45-23" pos="word" morph="none" start_char="7945" end_char="7948">días</TOKEN>
<TOKEN id="token-45-24" pos="punct" morph="none" start_char="7949" end_char="7949">.</TOKEN>
</SEG>
<SEG id="segment-46" start_char="7951" end_char="8104">
<ORIGINAL_TEXT>El medicamento es utilizado para el lupus y los pacientes lo toman durante décadas y como tratamiento o profilaxis de la malaria se utiliza durante meses.</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="7951" end_char="7952">El</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="7954" end_char="7964">medicamento</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="7966" end_char="7967">es</TOKEN>
<TOKEN id="token-46-3" pos="word" morph="none" start_char="7969" end_char="7977">utilizado</TOKEN>
<TOKEN id="token-46-4" pos="word" morph="none" start_char="7979" end_char="7982">para</TOKEN>
<TOKEN id="token-46-5" pos="word" morph="none" start_char="7984" end_char="7985">el</TOKEN>
<TOKEN id="token-46-6" pos="word" morph="none" start_char="7987" end_char="7991">lupus</TOKEN>
<TOKEN id="token-46-7" pos="word" morph="none" start_char="7993" end_char="7993">y</TOKEN>
<TOKEN id="token-46-8" pos="word" morph="none" start_char="7995" end_char="7997">los</TOKEN>
<TOKEN id="token-46-9" pos="word" morph="none" start_char="7999" end_char="8007">pacientes</TOKEN>
<TOKEN id="token-46-10" pos="word" morph="none" start_char="8009" end_char="8010">lo</TOKEN>
<TOKEN id="token-46-11" pos="word" morph="none" start_char="8012" end_char="8016">toman</TOKEN>
<TOKEN id="token-46-12" pos="word" morph="none" start_char="8018" end_char="8024">durante</TOKEN>
<TOKEN id="token-46-13" pos="word" morph="none" start_char="8026" end_char="8032">décadas</TOKEN>
<TOKEN id="token-46-14" pos="word" morph="none" start_char="8034" end_char="8034">y</TOKEN>
<TOKEN id="token-46-15" pos="word" morph="none" start_char="8036" end_char="8039">como</TOKEN>
<TOKEN id="token-46-16" pos="word" morph="none" start_char="8041" end_char="8051">tratamiento</TOKEN>
<TOKEN id="token-46-17" pos="word" morph="none" start_char="8053" end_char="8053">o</TOKEN>
<TOKEN id="token-46-18" pos="word" morph="none" start_char="8055" end_char="8064">profilaxis</TOKEN>
<TOKEN id="token-46-19" pos="word" morph="none" start_char="8066" end_char="8067">de</TOKEN>
<TOKEN id="token-46-20" pos="word" morph="none" start_char="8069" end_char="8070">la</TOKEN>
<TOKEN id="token-46-21" pos="word" morph="none" start_char="8072" end_char="8078">malaria</TOKEN>
<TOKEN id="token-46-22" pos="word" morph="none" start_char="8080" end_char="8081">se</TOKEN>
<TOKEN id="token-46-23" pos="word" morph="none" start_char="8083" end_char="8089">utiliza</TOKEN>
<TOKEN id="token-46-24" pos="word" morph="none" start_char="8091" end_char="8097">durante</TOKEN>
<TOKEN id="token-46-25" pos="word" morph="none" start_char="8099" end_char="8103">meses</TOKEN>
<TOKEN id="token-46-26" pos="punct" morph="none" start_char="8104" end_char="8104">.</TOKEN>
</SEG>
<SEG id="segment-47" start_char="8106" end_char="8340">
<ORIGINAL_TEXT>«No sabemos hasta qué punto ha contribuido a la mejora de los pacientes», pero los datos retrospectivos no muestran un incremento considerable de los efectos secundarios o problemas en los pacientes que han utilizado hidroxicloroquina.</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="punct" morph="none" start_char="8106" end_char="8106">«</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="8107" end_char="8108">No</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="8110" end_char="8116">sabemos</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="8118" end_char="8122">hasta</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="8124" end_char="8126">qué</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="8128" end_char="8132">punto</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="8134" end_char="8135">ha</TOKEN>
<TOKEN id="token-47-7" pos="word" morph="none" start_char="8137" end_char="8147">contribuido</TOKEN>
<TOKEN id="token-47-8" pos="word" morph="none" start_char="8149" end_char="8149">a</TOKEN>
<TOKEN id="token-47-9" pos="word" morph="none" start_char="8151" end_char="8152">la</TOKEN>
<TOKEN id="token-47-10" pos="word" morph="none" start_char="8154" end_char="8159">mejora</TOKEN>
<TOKEN id="token-47-11" pos="word" morph="none" start_char="8161" end_char="8162">de</TOKEN>
<TOKEN id="token-47-12" pos="word" morph="none" start_char="8164" end_char="8166">los</TOKEN>
<TOKEN id="token-47-13" pos="word" morph="none" start_char="8168" end_char="8176">pacientes</TOKEN>
<TOKEN id="token-47-14" pos="punct" morph="none" start_char="8177" end_char="8178">»,</TOKEN>
<TOKEN id="token-47-15" pos="word" morph="none" start_char="8180" end_char="8183">pero</TOKEN>
<TOKEN id="token-47-16" pos="word" morph="none" start_char="8185" end_char="8187">los</TOKEN>
<TOKEN id="token-47-17" pos="word" morph="none" start_char="8189" end_char="8193">datos</TOKEN>
<TOKEN id="token-47-18" pos="word" morph="none" start_char="8195" end_char="8208">retrospectivos</TOKEN>
<TOKEN id="token-47-19" pos="word" morph="none" start_char="8210" end_char="8211">no</TOKEN>
<TOKEN id="token-47-20" pos="word" morph="none" start_char="8213" end_char="8220">muestran</TOKEN>
<TOKEN id="token-47-21" pos="word" morph="none" start_char="8222" end_char="8223">un</TOKEN>
<TOKEN id="token-47-22" pos="word" morph="none" start_char="8225" end_char="8234">incremento</TOKEN>
<TOKEN id="token-47-23" pos="word" morph="none" start_char="8236" end_char="8247">considerable</TOKEN>
<TOKEN id="token-47-24" pos="word" morph="none" start_char="8249" end_char="8250">de</TOKEN>
<TOKEN id="token-47-25" pos="word" morph="none" start_char="8252" end_char="8254">los</TOKEN>
<TOKEN id="token-47-26" pos="word" morph="none" start_char="8256" end_char="8262">efectos</TOKEN>
<TOKEN id="token-47-27" pos="word" morph="none" start_char="8264" end_char="8274">secundarios</TOKEN>
<TOKEN id="token-47-28" pos="word" morph="none" start_char="8276" end_char="8276">o</TOKEN>
<TOKEN id="token-47-29" pos="word" morph="none" start_char="8278" end_char="8286">problemas</TOKEN>
<TOKEN id="token-47-30" pos="word" morph="none" start_char="8288" end_char="8289">en</TOKEN>
<TOKEN id="token-47-31" pos="word" morph="none" start_char="8291" end_char="8293">los</TOKEN>
<TOKEN id="token-47-32" pos="word" morph="none" start_char="8295" end_char="8303">pacientes</TOKEN>
<TOKEN id="token-47-33" pos="word" morph="none" start_char="8305" end_char="8307">que</TOKEN>
<TOKEN id="token-47-34" pos="word" morph="none" start_char="8309" end_char="8311">han</TOKEN>
<TOKEN id="token-47-35" pos="word" morph="none" start_char="8313" end_char="8321">utilizado</TOKEN>
<TOKEN id="token-47-36" pos="word" morph="none" start_char="8323" end_char="8339">hidroxicloroquina</TOKEN>
<TOKEN id="token-47-37" pos="punct" morph="none" start_char="8340" end_char="8340">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
