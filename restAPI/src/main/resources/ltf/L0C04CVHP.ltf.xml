<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CVHP" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="8773" raw_text_md5="6797d67df322af706949c8029eb6d29d">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="95">
<ORIGINAL_TEXT>As Florida sets records for Covid-19 cases, health authorities often fail to do contact tracing</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="2">As</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="4" end_char="10">Florida</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="12" end_char="15">sets</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="17" end_char="23">records</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="25" end_char="27">for</TOKEN>
<TOKEN id="token-0-5" pos="unknown" morph="none" start_char="29" end_char="36">Covid-19</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="38" end_char="42">cases</TOKEN>
<TOKEN id="token-0-7" pos="punct" morph="none" start_char="43" end_char="43">,</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="45" end_char="50">health</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="52" end_char="62">authorities</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="64" end_char="68">often</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="70" end_char="73">fail</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="75" end_char="76">to</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="78" end_char="79">do</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="81" end_char="87">contact</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="89" end_char="95">tracing</TOKEN>
</SEG>
<SEG id="segment-1" start_char="99" end_char="154">
<ORIGINAL_TEXT>More young people testing positive for coronavirus 02:19</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="99" end_char="102">More</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="104" end_char="108">young</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="110" end_char="115">people</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="117" end_char="123">testing</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="125" end_char="132">positive</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="134" end_char="136">for</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="138" end_char="148">coronavirus</TOKEN>
<TOKEN id="token-1-7" pos="unknown" morph="none" start_char="150" end_char="154">02:19</TOKEN>
</SEG>
<SEG id="segment-2" start_char="158" end_char="425">
<ORIGINAL_TEXT>(CNN)When Shaila Rivera and her new husband returned home from their honeymoon and tested positive for Covid-19, they expected a phone call from their local health authorities in Florida asking for a list of people they'd been near so that contact tracing could begin.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="punct" morph="none" start_char="158" end_char="158">(</TOKEN>
<TOKEN id="token-2-1" pos="unknown" morph="none" start_char="159" end_char="166">CNN)When</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="168" end_char="173">Shaila</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="175" end_char="180">Rivera</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="182" end_char="184">and</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="186" end_char="188">her</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="190" end_char="192">new</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="194" end_char="200">husband</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="202" end_char="209">returned</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="211" end_char="214">home</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="216" end_char="219">from</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="221" end_char="225">their</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="227" end_char="235">honeymoon</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="237" end_char="239">and</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="241" end_char="246">tested</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="248" end_char="255">positive</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="257" end_char="259">for</TOKEN>
<TOKEN id="token-2-17" pos="unknown" morph="none" start_char="261" end_char="268">Covid-19</TOKEN>
<TOKEN id="token-2-18" pos="punct" morph="none" start_char="269" end_char="269">,</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="271" end_char="274">they</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="276" end_char="283">expected</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="285" end_char="285">a</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="287" end_char="291">phone</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="293" end_char="296">call</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="298" end_char="301">from</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="303" end_char="307">their</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="309" end_char="313">local</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="315" end_char="320">health</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="322" end_char="332">authorities</TOKEN>
<TOKEN id="token-2-29" pos="word" morph="none" start_char="334" end_char="335">in</TOKEN>
<TOKEN id="token-2-30" pos="word" morph="none" start_char="337" end_char="343">Florida</TOKEN>
<TOKEN id="token-2-31" pos="word" morph="none" start_char="345" end_char="350">asking</TOKEN>
<TOKEN id="token-2-32" pos="word" morph="none" start_char="352" end_char="354">for</TOKEN>
<TOKEN id="token-2-33" pos="word" morph="none" start_char="356" end_char="356">a</TOKEN>
<TOKEN id="token-2-34" pos="word" morph="none" start_char="358" end_char="361">list</TOKEN>
<TOKEN id="token-2-35" pos="word" morph="none" start_char="363" end_char="364">of</TOKEN>
<TOKEN id="token-2-36" pos="word" morph="none" start_char="366" end_char="371">people</TOKEN>
<TOKEN id="token-2-37" pos="word" morph="none" start_char="373" end_char="378">they'd</TOKEN>
<TOKEN id="token-2-38" pos="word" morph="none" start_char="380" end_char="383">been</TOKEN>
<TOKEN id="token-2-39" pos="word" morph="none" start_char="385" end_char="388">near</TOKEN>
<TOKEN id="token-2-40" pos="word" morph="none" start_char="390" end_char="391">so</TOKEN>
<TOKEN id="token-2-41" pos="word" morph="none" start_char="393" end_char="396">that</TOKEN>
<TOKEN id="token-2-42" pos="word" morph="none" start_char="398" end_char="404">contact</TOKEN>
<TOKEN id="token-2-43" pos="word" morph="none" start_char="406" end_char="412">tracing</TOKEN>
<TOKEN id="token-2-44" pos="word" morph="none" start_char="414" end_char="418">could</TOKEN>
<TOKEN id="token-2-45" pos="word" morph="none" start_char="420" end_char="424">begin</TOKEN>
<TOKEN id="token-2-46" pos="punct" morph="none" start_char="425" end_char="425">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="428" end_char="466">
<ORIGINAL_TEXT>The Riveras waited for that phone call.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="428" end_char="430">The</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="432" end_char="438">Riveras</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="440" end_char="445">waited</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="447" end_char="449">for</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="451" end_char="454">that</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="456" end_char="460">phone</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="462" end_char="465">call</TOKEN>
<TOKEN id="token-3-7" pos="punct" morph="none" start_char="466" end_char="466">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="468" end_char="478">
<ORIGINAL_TEXT>And waited.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="468" end_char="470">And</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="472" end_char="477">waited</TOKEN>
<TOKEN id="token-4-2" pos="punct" morph="none" start_char="478" end_char="478">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="480" end_char="490">
<ORIGINAL_TEXT>And waited.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="480" end_char="482">And</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="484" end_char="489">waited</TOKEN>
<TOKEN id="token-5-2" pos="punct" morph="none" start_char="490" end_char="490">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="492" end_char="515">
<ORIGINAL_TEXT>But the call never came.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="492" end_char="494">But</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="496" end_char="498">the</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="500" end_char="503">call</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="505" end_char="509">never</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="511" end_char="514">came</TOKEN>
<TOKEN id="token-6-5" pos="punct" morph="none" start_char="515" end_char="515">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="518" end_char="608">
<ORIGINAL_TEXT>"I was shocked," said Rivera, a nurse who has since recovered from her bout with the virus.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="punct" morph="none" start_char="518" end_char="518">"</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="519" end_char="519">I</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="521" end_char="523">was</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="525" end_char="531">shocked</TOKEN>
<TOKEN id="token-7-4" pos="punct" morph="none" start_char="532" end_char="533">,"</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="535" end_char="538">said</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="540" end_char="545">Rivera</TOKEN>
<TOKEN id="token-7-7" pos="punct" morph="none" start_char="546" end_char="546">,</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="548" end_char="548">a</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="550" end_char="554">nurse</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="556" end_char="558">who</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="560" end_char="562">has</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="564" end_char="568">since</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="570" end_char="578">recovered</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="580" end_char="583">from</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="585" end_char="587">her</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="589" end_char="592">bout</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="594" end_char="597">with</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="599" end_char="601">the</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="603" end_char="607">virus</TOKEN>
<TOKEN id="token-7-20" pos="punct" morph="none" start_char="608" end_char="608">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="611" end_char="751">
<ORIGINAL_TEXT>Despite claims that Florida traces every case of Covid-19, a CNN investigation found that health authorities in Florida, now the nation's No.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="611" end_char="617">Despite</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="619" end_char="624">claims</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="626" end_char="629">that</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="631" end_char="637">Florida</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="639" end_char="644">traces</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="646" end_char="650">every</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="652" end_char="655">case</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="657" end_char="658">of</TOKEN>
<TOKEN id="token-8-8" pos="unknown" morph="none" start_char="660" end_char="667">Covid-19</TOKEN>
<TOKEN id="token-8-9" pos="punct" morph="none" start_char="668" end_char="668">,</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="670" end_char="670">a</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="672" end_char="674">CNN</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="676" end_char="688">investigation</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="690" end_char="694">found</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="696" end_char="699">that</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="701" end_char="706">health</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="708" end_char="718">authorities</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="720" end_char="721">in</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="723" end_char="729">Florida</TOKEN>
<TOKEN id="token-8-19" pos="punct" morph="none" start_char="730" end_char="730">,</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="732" end_char="734">now</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="736" end_char="738">the</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="740" end_char="747">nation's</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="749" end_char="750">No</TOKEN>
<TOKEN id="token-8-24" pos="punct" morph="none" start_char="751" end_char="751">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="753" end_char="864">
<ORIGINAL_TEXT>1 hotspot for the virus, often fail to do contact tracing, long considered a key tool in containing an outbreak.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="753" end_char="753">1</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="755" end_char="761">hotspot</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="763" end_char="765">for</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="767" end_char="769">the</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="771" end_char="775">virus</TOKEN>
<TOKEN id="token-9-5" pos="punct" morph="none" start_char="776" end_char="776">,</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="778" end_char="782">often</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="784" end_char="787">fail</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="789" end_char="790">to</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="792" end_char="793">do</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="795" end_char="801">contact</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="803" end_char="809">tracing</TOKEN>
<TOKEN id="token-9-12" pos="punct" morph="none" start_char="810" end_char="810">,</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="812" end_char="815">long</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="817" end_char="826">considered</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="828" end_char="828">a</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="830" end_char="832">key</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="834" end_char="837">tool</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="839" end_char="840">in</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="842" end_char="851">containing</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="853" end_char="854">an</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="856" end_char="863">outbreak</TOKEN>
<TOKEN id="token-9-22" pos="punct" morph="none" start_char="864" end_char="864">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="867" end_char="1091">
<ORIGINAL_TEXT>Florida set a record for most coronavirus cases in the US in a single day on Saturday, with a total of 11,458, according to data compiled by Johns Hopkins University, and on Sunday, the state surpassed 200,000 Covid-19 cases.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="867" end_char="873">Florida</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="875" end_char="877">set</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="879" end_char="879">a</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="881" end_char="886">record</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="888" end_char="890">for</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="892" end_char="895">most</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="897" end_char="907">coronavirus</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="909" end_char="913">cases</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="915" end_char="916">in</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="918" end_char="920">the</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="922" end_char="923">US</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="925" end_char="926">in</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="928" end_char="928">a</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="930" end_char="935">single</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="937" end_char="939">day</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="941" end_char="942">on</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="944" end_char="951">Saturday</TOKEN>
<TOKEN id="token-10-17" pos="punct" morph="none" start_char="952" end_char="952">,</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="954" end_char="957">with</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="959" end_char="959">a</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="961" end_char="965">total</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="967" end_char="968">of</TOKEN>
<TOKEN id="token-10-22" pos="unknown" morph="none" start_char="970" end_char="975">11,458</TOKEN>
<TOKEN id="token-10-23" pos="punct" morph="none" start_char="976" end_char="976">,</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="978" end_char="986">according</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="988" end_char="989">to</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="991" end_char="994">data</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="996" end_char="1003">compiled</TOKEN>
<TOKEN id="token-10-28" pos="word" morph="none" start_char="1005" end_char="1006">by</TOKEN>
<TOKEN id="token-10-29" pos="word" morph="none" start_char="1008" end_char="1012">Johns</TOKEN>
<TOKEN id="token-10-30" pos="word" morph="none" start_char="1014" end_char="1020">Hopkins</TOKEN>
<TOKEN id="token-10-31" pos="word" morph="none" start_char="1022" end_char="1031">University</TOKEN>
<TOKEN id="token-10-32" pos="punct" morph="none" start_char="1032" end_char="1032">,</TOKEN>
<TOKEN id="token-10-33" pos="word" morph="none" start_char="1034" end_char="1036">and</TOKEN>
<TOKEN id="token-10-34" pos="word" morph="none" start_char="1038" end_char="1039">on</TOKEN>
<TOKEN id="token-10-35" pos="word" morph="none" start_char="1041" end_char="1046">Sunday</TOKEN>
<TOKEN id="token-10-36" pos="punct" morph="none" start_char="1047" end_char="1047">,</TOKEN>
<TOKEN id="token-10-37" pos="word" morph="none" start_char="1049" end_char="1051">the</TOKEN>
<TOKEN id="token-10-38" pos="word" morph="none" start_char="1053" end_char="1057">state</TOKEN>
<TOKEN id="token-10-39" pos="word" morph="none" start_char="1059" end_char="1067">surpassed</TOKEN>
<TOKEN id="token-10-40" pos="unknown" morph="none" start_char="1069" end_char="1075">200,000</TOKEN>
<TOKEN id="token-10-41" pos="unknown" morph="none" start_char="1077" end_char="1084">Covid-19</TOKEN>
<TOKEN id="token-10-42" pos="word" morph="none" start_char="1086" end_char="1090">cases</TOKEN>
<TOKEN id="token-10-43" pos="punct" morph="none" start_char="1091" end_char="1091">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1094" end_char="1189">
<ORIGINAL_TEXT>New York county issued subpoenas to force party-goers to speak with coronavirus contact tracers.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1094" end_char="1096">New</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1098" end_char="1101">York</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1103" end_char="1108">county</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1110" end_char="1115">issued</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1117" end_char="1125">subpoenas</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1127" end_char="1128">to</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1130" end_char="1134">force</TOKEN>
<TOKEN id="token-11-7" pos="unknown" morph="none" start_char="1136" end_char="1146">party-goers</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1148" end_char="1149">to</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1151" end_char="1155">speak</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1157" end_char="1160">with</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1162" end_char="1172">coronavirus</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1174" end_char="1180">contact</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1182" end_char="1188">tracers</TOKEN>
<TOKEN id="token-11-14" pos="punct" morph="none" start_char="1189" end_char="1189">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1191" end_char="1200">
<ORIGINAL_TEXT>It worked.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1191" end_char="1192">It</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1194" end_char="1199">worked</TOKEN>
<TOKEN id="token-12-2" pos="punct" morph="none" start_char="1200" end_char="1200">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1204" end_char="1393">
<ORIGINAL_TEXT>Florida's contact tracing challenges are indicative of how hard it is for states hard hit by Covid-19 to do proper contact tracing, which is a challenge even under the best of circumstances.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1204" end_char="1212">Florida's</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1214" end_char="1220">contact</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1222" end_char="1228">tracing</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1230" end_char="1239">challenges</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1241" end_char="1243">are</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1245" end_char="1254">indicative</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1256" end_char="1257">of</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1259" end_char="1261">how</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1263" end_char="1266">hard</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1268" end_char="1269">it</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1271" end_char="1272">is</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1274" end_char="1276">for</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1278" end_char="1283">states</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1285" end_char="1288">hard</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1290" end_char="1292">hit</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1294" end_char="1295">by</TOKEN>
<TOKEN id="token-13-16" pos="unknown" morph="none" start_char="1297" end_char="1304">Covid-19</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1306" end_char="1307">to</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1309" end_char="1310">do</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1312" end_char="1317">proper</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1319" end_char="1325">contact</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="1327" end_char="1333">tracing</TOKEN>
<TOKEN id="token-13-22" pos="punct" morph="none" start_char="1334" end_char="1334">,</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="1336" end_char="1340">which</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="1342" end_char="1343">is</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="1345" end_char="1345">a</TOKEN>
<TOKEN id="token-13-26" pos="word" morph="none" start_char="1347" end_char="1355">challenge</TOKEN>
<TOKEN id="token-13-27" pos="word" morph="none" start_char="1357" end_char="1360">even</TOKEN>
<TOKEN id="token-13-28" pos="word" morph="none" start_char="1362" end_char="1366">under</TOKEN>
<TOKEN id="token-13-29" pos="word" morph="none" start_char="1368" end_char="1370">the</TOKEN>
<TOKEN id="token-13-30" pos="word" morph="none" start_char="1372" end_char="1375">best</TOKEN>
<TOKEN id="token-13-31" pos="word" morph="none" start_char="1377" end_char="1378">of</TOKEN>
<TOKEN id="token-13-32" pos="word" morph="none" start_char="1380" end_char="1392">circumstances</TOKEN>
<TOKEN id="token-13-33" pos="punct" morph="none" start_char="1393" end_char="1393">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1395" end_char="1560">
<ORIGINAL_TEXT>The virus is so far along in states like Florida that it's a seemingly Herculean task to track down every infected person and follow up with all their close contacts.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1395" end_char="1397">The</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1399" end_char="1403">virus</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1405" end_char="1406">is</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1408" end_char="1409">so</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1411" end_char="1413">far</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1415" end_char="1419">along</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1421" end_char="1422">in</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1424" end_char="1429">states</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1431" end_char="1434">like</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1436" end_char="1442">Florida</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1444" end_char="1447">that</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1449" end_char="1452">it's</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1454" end_char="1454">a</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1456" end_char="1464">seemingly</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="1466" end_char="1474">Herculean</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1476" end_char="1479">task</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1481" end_char="1482">to</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="1484" end_char="1488">track</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="1490" end_char="1493">down</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="1495" end_char="1499">every</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="1501" end_char="1508">infected</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="1510" end_char="1515">person</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="1517" end_char="1519">and</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="1521" end_char="1526">follow</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="1528" end_char="1529">up</TOKEN>
<TOKEN id="token-14-25" pos="word" morph="none" start_char="1531" end_char="1534">with</TOKEN>
<TOKEN id="token-14-26" pos="word" morph="none" start_char="1536" end_char="1538">all</TOKEN>
<TOKEN id="token-14-27" pos="word" morph="none" start_char="1540" end_char="1544">their</TOKEN>
<TOKEN id="token-14-28" pos="word" morph="none" start_char="1546" end_char="1550">close</TOKEN>
<TOKEN id="token-14-29" pos="word" morph="none" start_char="1552" end_char="1559">contacts</TOKEN>
<TOKEN id="token-14-30" pos="punct" morph="none" start_char="1560" end_char="1560">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1563" end_char="1652">
<ORIGINAL_TEXT>CNN spoke with 27 Floridians, or their family members, who'd tested positive for Covid-19.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1563" end_char="1565">CNN</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1567" end_char="1571">spoke</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1573" end_char="1576">with</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1578" end_char="1579">27</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1581" end_char="1590">Floridians</TOKEN>
<TOKEN id="token-15-5" pos="punct" morph="none" start_char="1591" end_char="1591">,</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1593" end_char="1594">or</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1596" end_char="1600">their</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1602" end_char="1607">family</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1609" end_char="1615">members</TOKEN>
<TOKEN id="token-15-10" pos="punct" morph="none" start_char="1616" end_char="1616">,</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1618" end_char="1622">who'd</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1624" end_char="1629">tested</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1631" end_char="1638">positive</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1640" end_char="1642">for</TOKEN>
<TOKEN id="token-15-15" pos="unknown" morph="none" start_char="1644" end_char="1651">Covid-19</TOKEN>
<TOKEN id="token-15-16" pos="punct" morph="none" start_char="1652" end_char="1652">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1654" end_char="1753">
<ORIGINAL_TEXT>Of those, only five said they had received a call from health authorities asking for their contacts.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1654" end_char="1655">Of</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1657" end_char="1661">those</TOKEN>
<TOKEN id="token-16-2" pos="punct" morph="none" start_char="1662" end_char="1662">,</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1664" end_char="1667">only</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1669" end_char="1672">five</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1674" end_char="1677">said</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1679" end_char="1682">they</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1684" end_char="1686">had</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1688" end_char="1695">received</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="1697" end_char="1697">a</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="1699" end_char="1702">call</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="1704" end_char="1707">from</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="1709" end_char="1714">health</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="1716" end_char="1726">authorities</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="1728" end_char="1733">asking</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="1735" end_char="1737">for</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="1739" end_char="1743">their</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="1745" end_char="1752">contacts</TOKEN>
<TOKEN id="token-16-18" pos="punct" morph="none" start_char="1753" end_char="1753">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1756" end_char="1828">
<ORIGINAL_TEXT>There are concerns about contact tracing nationally, not just in Florida.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1756" end_char="1760">There</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1762" end_char="1764">are</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="1766" end_char="1773">concerns</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="1775" end_char="1779">about</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="1781" end_char="1787">contact</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="1789" end_char="1795">tracing</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="1797" end_char="1806">nationally</TOKEN>
<TOKEN id="token-17-7" pos="punct" morph="none" start_char="1807" end_char="1807">,</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="1809" end_char="1811">not</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="1813" end_char="1816">just</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="1818" end_char="1819">in</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="1821" end_char="1827">Florida</TOKEN>
<TOKEN id="token-17-12" pos="punct" morph="none" start_char="1828" end_char="1828">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1830" end_char="1867">
<ORIGINAL_TEXT>In an interview in June, CNN asked Dr.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="1830" end_char="1831">In</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="1833" end_char="1834">an</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="1836" end_char="1844">interview</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="1846" end_char="1847">in</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="1849" end_char="1852">June</TOKEN>
<TOKEN id="token-18-5" pos="punct" morph="none" start_char="1853" end_char="1853">,</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="1855" end_char="1857">CNN</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="1859" end_char="1863">asked</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="1865" end_char="1866">Dr</TOKEN>
<TOKEN id="token-18-9" pos="punct" morph="none" start_char="1867" end_char="1867">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="1869" end_char="2016">
<ORIGINAL_TEXT>Anthony Fauci, director of the National Institute of Allergy and Infectious Diseases, how he thought contact tracing was going in the United States.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="1869" end_char="1875">Anthony</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="1877" end_char="1881">Fauci</TOKEN>
<TOKEN id="token-19-2" pos="punct" morph="none" start_char="1882" end_char="1882">,</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="1884" end_char="1891">director</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="1893" end_char="1894">of</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="1896" end_char="1898">the</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="1900" end_char="1907">National</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="1909" end_char="1917">Institute</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="1919" end_char="1920">of</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="1922" end_char="1928">Allergy</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="1930" end_char="1932">and</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="1934" end_char="1943">Infectious</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="1945" end_char="1952">Diseases</TOKEN>
<TOKEN id="token-19-13" pos="punct" morph="none" start_char="1953" end_char="1953">,</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="1955" end_char="1957">how</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="1959" end_char="1960">he</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="1962" end_char="1968">thought</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="1970" end_char="1976">contact</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="1978" end_char="1984">tracing</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="1986" end_char="1988">was</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="1990" end_char="1994">going</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="1996" end_char="1997">in</TOKEN>
<TOKEN id="token-19-22" pos="word" morph="none" start_char="1999" end_char="2001">the</TOKEN>
<TOKEN id="token-19-23" pos="word" morph="none" start_char="2003" end_char="2008">United</TOKEN>
<TOKEN id="token-19-24" pos="word" morph="none" start_char="2010" end_char="2015">States</TOKEN>
<TOKEN id="token-19-25" pos="punct" morph="none" start_char="2016" end_char="2016">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2019" end_char="2069">
<ORIGINAL_TEXT>"I don't think we're doing very well," he answered.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="punct" morph="none" start_char="2019" end_char="2019">"</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2020" end_char="2020">I</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2022" end_char="2026">don't</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2028" end_char="2032">think</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2034" end_char="2038">we're</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2040" end_char="2044">doing</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2046" end_char="2049">very</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2051" end_char="2054">well</TOKEN>
<TOKEN id="token-20-8" pos="punct" morph="none" start_char="2055" end_char="2056">,"</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2058" end_char="2059">he</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2061" end_char="2068">answered</TOKEN>
<TOKEN id="token-20-11" pos="punct" morph="none" start_char="2069" end_char="2069">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2072" end_char="2287">
<ORIGINAL_TEXT>Contact tracing is a centuries-old practice, and the basics haven't changed much: Essentially, health care workers ask infected people for a list of everyone they've been in contact with while potentially contagious.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2072" end_char="2078">Contact</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2080" end_char="2086">tracing</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2088" end_char="2089">is</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2091" end_char="2091">a</TOKEN>
<TOKEN id="token-21-4" pos="unknown" morph="none" start_char="2093" end_char="2105">centuries-old</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="2107" end_char="2114">practice</TOKEN>
<TOKEN id="token-21-6" pos="punct" morph="none" start_char="2115" end_char="2115">,</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="2117" end_char="2119">and</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="2121" end_char="2123">the</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="2125" end_char="2130">basics</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="2132" end_char="2138">haven't</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="2140" end_char="2146">changed</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="2148" end_char="2151">much</TOKEN>
<TOKEN id="token-21-13" pos="punct" morph="none" start_char="2152" end_char="2152">:</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="2154" end_char="2164">Essentially</TOKEN>
<TOKEN id="token-21-15" pos="punct" morph="none" start_char="2165" end_char="2165">,</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="2167" end_char="2172">health</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="2174" end_char="2177">care</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="2179" end_char="2185">workers</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="2187" end_char="2189">ask</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="2191" end_char="2198">infected</TOKEN>
<TOKEN id="token-21-21" pos="word" morph="none" start_char="2200" end_char="2205">people</TOKEN>
<TOKEN id="token-21-22" pos="word" morph="none" start_char="2207" end_char="2209">for</TOKEN>
<TOKEN id="token-21-23" pos="word" morph="none" start_char="2211" end_char="2211">a</TOKEN>
<TOKEN id="token-21-24" pos="word" morph="none" start_char="2213" end_char="2216">list</TOKEN>
<TOKEN id="token-21-25" pos="word" morph="none" start_char="2218" end_char="2219">of</TOKEN>
<TOKEN id="token-21-26" pos="word" morph="none" start_char="2221" end_char="2228">everyone</TOKEN>
<TOKEN id="token-21-27" pos="word" morph="none" start_char="2230" end_char="2236">they've</TOKEN>
<TOKEN id="token-21-28" pos="word" morph="none" start_char="2238" end_char="2241">been</TOKEN>
<TOKEN id="token-21-29" pos="word" morph="none" start_char="2243" end_char="2244">in</TOKEN>
<TOKEN id="token-21-30" pos="word" morph="none" start_char="2246" end_char="2252">contact</TOKEN>
<TOKEN id="token-21-31" pos="word" morph="none" start_char="2254" end_char="2257">with</TOKEN>
<TOKEN id="token-21-32" pos="word" morph="none" start_char="2259" end_char="2263">while</TOKEN>
<TOKEN id="token-21-33" pos="word" morph="none" start_char="2265" end_char="2275">potentially</TOKEN>
<TOKEN id="token-21-34" pos="word" morph="none" start_char="2277" end_char="2286">contagious</TOKEN>
<TOKEN id="token-21-35" pos="punct" morph="none" start_char="2287" end_char="2287">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2289" end_char="2373">
<ORIGINAL_TEXT>The worker then tells those contacts to quarantine themselves and watch for symptoms.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2289" end_char="2291">The</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2293" end_char="2298">worker</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2300" end_char="2303">then</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2305" end_char="2309">tells</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2311" end_char="2315">those</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2317" end_char="2324">contacts</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2326" end_char="2327">to</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2329" end_char="2338">quarantine</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="2340" end_char="2349">themselves</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="2351" end_char="2353">and</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="2355" end_char="2359">watch</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="2361" end_char="2363">for</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="2365" end_char="2372">symptoms</TOKEN>
<TOKEN id="token-22-13" pos="punct" morph="none" start_char="2373" end_char="2373">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2377" end_char="2620">
<ORIGINAL_TEXT>The CDC gives detailed contact tracing guidance to state health departments, explaining that "monitoring of these COVID-19 contacts can effectively break the chain of disease transmission and prevent further spread of the virus in a community."</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2377" end_char="2379">The</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2381" end_char="2383">CDC</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2385" end_char="2389">gives</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2391" end_char="2398">detailed</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="2400" end_char="2406">contact</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="2408" end_char="2414">tracing</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="2416" end_char="2423">guidance</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="2425" end_char="2426">to</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="2428" end_char="2432">state</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="2434" end_char="2439">health</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="2441" end_char="2451">departments</TOKEN>
<TOKEN id="token-23-11" pos="punct" morph="none" start_char="2452" end_char="2452">,</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="2454" end_char="2463">explaining</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="2465" end_char="2468">that</TOKEN>
<TOKEN id="token-23-14" pos="punct" morph="none" start_char="2470" end_char="2470">"</TOKEN>
<TOKEN id="token-23-15" pos="word" morph="none" start_char="2471" end_char="2480">monitoring</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="2482" end_char="2483">of</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="2485" end_char="2489">these</TOKEN>
<TOKEN id="token-23-18" pos="unknown" morph="none" start_char="2491" end_char="2498">COVID-19</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="2500" end_char="2507">contacts</TOKEN>
<TOKEN id="token-23-20" pos="word" morph="none" start_char="2509" end_char="2511">can</TOKEN>
<TOKEN id="token-23-21" pos="word" morph="none" start_char="2513" end_char="2523">effectively</TOKEN>
<TOKEN id="token-23-22" pos="word" morph="none" start_char="2525" end_char="2529">break</TOKEN>
<TOKEN id="token-23-23" pos="word" morph="none" start_char="2531" end_char="2533">the</TOKEN>
<TOKEN id="token-23-24" pos="word" morph="none" start_char="2535" end_char="2539">chain</TOKEN>
<TOKEN id="token-23-25" pos="word" morph="none" start_char="2541" end_char="2542">of</TOKEN>
<TOKEN id="token-23-26" pos="word" morph="none" start_char="2544" end_char="2550">disease</TOKEN>
<TOKEN id="token-23-27" pos="word" morph="none" start_char="2552" end_char="2563">transmission</TOKEN>
<TOKEN id="token-23-28" pos="word" morph="none" start_char="2565" end_char="2567">and</TOKEN>
<TOKEN id="token-23-29" pos="word" morph="none" start_char="2569" end_char="2575">prevent</TOKEN>
<TOKEN id="token-23-30" pos="word" morph="none" start_char="2577" end_char="2583">further</TOKEN>
<TOKEN id="token-23-31" pos="word" morph="none" start_char="2585" end_char="2590">spread</TOKEN>
<TOKEN id="token-23-32" pos="word" morph="none" start_char="2592" end_char="2593">of</TOKEN>
<TOKEN id="token-23-33" pos="word" morph="none" start_char="2595" end_char="2597">the</TOKEN>
<TOKEN id="token-23-34" pos="word" morph="none" start_char="2599" end_char="2603">virus</TOKEN>
<TOKEN id="token-23-35" pos="word" morph="none" start_char="2605" end_char="2606">in</TOKEN>
<TOKEN id="token-23-36" pos="word" morph="none" start_char="2608" end_char="2608">a</TOKEN>
<TOKEN id="token-23-37" pos="word" morph="none" start_char="2610" end_char="2618">community</TOKEN>
<TOKEN id="token-23-38" pos="punct" morph="none" start_char="2619" end_char="2620">."</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2623" end_char="2727">
<ORIGINAL_TEXT>White House guidelines describe contact tracing as one of the "core state preparedness responsibilities."</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="2623" end_char="2627">White</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="2629" end_char="2633">House</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="2635" end_char="2644">guidelines</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="2646" end_char="2653">describe</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="2655" end_char="2661">contact</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="2663" end_char="2669">tracing</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="2671" end_char="2672">as</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="2674" end_char="2676">one</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="2678" end_char="2679">of</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="2681" end_char="2683">the</TOKEN>
<TOKEN id="token-24-10" pos="punct" morph="none" start_char="2685" end_char="2685">"</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="2686" end_char="2689">core</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="2691" end_char="2695">state</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="2697" end_char="2708">preparedness</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="2710" end_char="2725">responsibilities</TOKEN>
<TOKEN id="token-24-15" pos="punct" morph="none" start_char="2726" end_char="2727">."</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2730" end_char="3058">
<ORIGINAL_TEXT>An online infographic from the Florida Department of Health describes contact tracing as a "core public health function," and states that a local epidemiologist will ask people with the virus for a list of everyone they've been in contact with for the past two weeks, and the county health department will monitor those contacts.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="2730" end_char="2731">An</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="2733" end_char="2738">online</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="2740" end_char="2750">infographic</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="2752" end_char="2755">from</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="2757" end_char="2759">the</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="2761" end_char="2767">Florida</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="2769" end_char="2778">Department</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="2780" end_char="2781">of</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="2783" end_char="2788">Health</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="2790" end_char="2798">describes</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="2800" end_char="2806">contact</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="2808" end_char="2814">tracing</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="2816" end_char="2817">as</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="2819" end_char="2819">a</TOKEN>
<TOKEN id="token-25-14" pos="punct" morph="none" start_char="2821" end_char="2821">"</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="2822" end_char="2825">core</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="2827" end_char="2832">public</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="2834" end_char="2839">health</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="2841" end_char="2848">function</TOKEN>
<TOKEN id="token-25-19" pos="punct" morph="none" start_char="2849" end_char="2850">,"</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="2852" end_char="2854">and</TOKEN>
<TOKEN id="token-25-21" pos="word" morph="none" start_char="2856" end_char="2861">states</TOKEN>
<TOKEN id="token-25-22" pos="word" morph="none" start_char="2863" end_char="2866">that</TOKEN>
<TOKEN id="token-25-23" pos="word" morph="none" start_char="2868" end_char="2868">a</TOKEN>
<TOKEN id="token-25-24" pos="word" morph="none" start_char="2870" end_char="2874">local</TOKEN>
<TOKEN id="token-25-25" pos="word" morph="none" start_char="2876" end_char="2889">epidemiologist</TOKEN>
<TOKEN id="token-25-26" pos="word" morph="none" start_char="2891" end_char="2894">will</TOKEN>
<TOKEN id="token-25-27" pos="word" morph="none" start_char="2896" end_char="2898">ask</TOKEN>
<TOKEN id="token-25-28" pos="word" morph="none" start_char="2900" end_char="2905">people</TOKEN>
<TOKEN id="token-25-29" pos="word" morph="none" start_char="2907" end_char="2910">with</TOKEN>
<TOKEN id="token-25-30" pos="word" morph="none" start_char="2912" end_char="2914">the</TOKEN>
<TOKEN id="token-25-31" pos="word" morph="none" start_char="2916" end_char="2920">virus</TOKEN>
<TOKEN id="token-25-32" pos="word" morph="none" start_char="2922" end_char="2924">for</TOKEN>
<TOKEN id="token-25-33" pos="word" morph="none" start_char="2926" end_char="2926">a</TOKEN>
<TOKEN id="token-25-34" pos="word" morph="none" start_char="2928" end_char="2931">list</TOKEN>
<TOKEN id="token-25-35" pos="word" morph="none" start_char="2933" end_char="2934">of</TOKEN>
<TOKEN id="token-25-36" pos="word" morph="none" start_char="2936" end_char="2943">everyone</TOKEN>
<TOKEN id="token-25-37" pos="word" morph="none" start_char="2945" end_char="2951">they've</TOKEN>
<TOKEN id="token-25-38" pos="word" morph="none" start_char="2953" end_char="2956">been</TOKEN>
<TOKEN id="token-25-39" pos="word" morph="none" start_char="2958" end_char="2959">in</TOKEN>
<TOKEN id="token-25-40" pos="word" morph="none" start_char="2961" end_char="2967">contact</TOKEN>
<TOKEN id="token-25-41" pos="word" morph="none" start_char="2969" end_char="2972">with</TOKEN>
<TOKEN id="token-25-42" pos="word" morph="none" start_char="2974" end_char="2976">for</TOKEN>
<TOKEN id="token-25-43" pos="word" morph="none" start_char="2978" end_char="2980">the</TOKEN>
<TOKEN id="token-25-44" pos="word" morph="none" start_char="2982" end_char="2985">past</TOKEN>
<TOKEN id="token-25-45" pos="word" morph="none" start_char="2987" end_char="2989">two</TOKEN>
<TOKEN id="token-25-46" pos="word" morph="none" start_char="2991" end_char="2995">weeks</TOKEN>
<TOKEN id="token-25-47" pos="punct" morph="none" start_char="2996" end_char="2996">,</TOKEN>
<TOKEN id="token-25-48" pos="word" morph="none" start_char="2998" end_char="3000">and</TOKEN>
<TOKEN id="token-25-49" pos="word" morph="none" start_char="3002" end_char="3004">the</TOKEN>
<TOKEN id="token-25-50" pos="word" morph="none" start_char="3006" end_char="3011">county</TOKEN>
<TOKEN id="token-25-51" pos="word" morph="none" start_char="3013" end_char="3018">health</TOKEN>
<TOKEN id="token-25-52" pos="word" morph="none" start_char="3020" end_char="3029">department</TOKEN>
<TOKEN id="token-25-53" pos="word" morph="none" start_char="3031" end_char="3034">will</TOKEN>
<TOKEN id="token-25-54" pos="word" morph="none" start_char="3036" end_char="3042">monitor</TOKEN>
<TOKEN id="token-25-55" pos="word" morph="none" start_char="3044" end_char="3048">those</TOKEN>
<TOKEN id="token-25-56" pos="word" morph="none" start_char="3050" end_char="3057">contacts</TOKEN>
<TOKEN id="token-25-57" pos="punct" morph="none" start_char="3058" end_char="3058">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="3062" end_char="3190">
<ORIGINAL_TEXT>A spokesperson for the Florida Department of Health in Miami-Dade County sent CNN a statement about contact tracing in her state.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="3062" end_char="3062">A</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="3064" end_char="3075">spokesperson</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="3077" end_char="3079">for</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="3081" end_char="3083">the</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="3085" end_char="3091">Florida</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="3093" end_char="3102">Department</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="3104" end_char="3105">of</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="3107" end_char="3112">Health</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="3114" end_char="3115">in</TOKEN>
<TOKEN id="token-26-9" pos="unknown" morph="none" start_char="3117" end_char="3126">Miami-Dade</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="3128" end_char="3133">County</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="3135" end_char="3138">sent</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="3140" end_char="3142">CNN</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="3144" end_char="3144">a</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="3146" end_char="3154">statement</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="3156" end_char="3160">about</TOKEN>
<TOKEN id="token-26-16" pos="word" morph="none" start_char="3162" end_char="3168">contact</TOKEN>
<TOKEN id="token-26-17" pos="word" morph="none" start_char="3170" end_char="3176">tracing</TOKEN>
<TOKEN id="token-26-18" pos="word" morph="none" start_char="3178" end_char="3179">in</TOKEN>
<TOKEN id="token-26-19" pos="word" morph="none" start_char="3181" end_char="3183">her</TOKEN>
<TOKEN id="token-26-20" pos="word" morph="none" start_char="3185" end_char="3189">state</TOKEN>
<TOKEN id="token-26-21" pos="punct" morph="none" start_char="3190" end_char="3190">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="3193" end_char="3499">
<ORIGINAL_TEXT>"When the Department of Health receives notification that a person has tested positive for COVID-19, the department conducts an extensive epidemiological investigation in conjunction with the [Centers for Disease Control and Prevention] to identify individuals who may have had close contact with the virus.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="punct" morph="none" start_char="3193" end_char="3193">"</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="3194" end_char="3197">When</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="3199" end_char="3201">the</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="3203" end_char="3212">Department</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="3214" end_char="3215">of</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="3217" end_char="3222">Health</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="3224" end_char="3231">receives</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="3233" end_char="3244">notification</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="3246" end_char="3249">that</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="3251" end_char="3251">a</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="3253" end_char="3258">person</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="3260" end_char="3262">has</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="3264" end_char="3269">tested</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="3271" end_char="3278">positive</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="3280" end_char="3282">for</TOKEN>
<TOKEN id="token-27-15" pos="unknown" morph="none" start_char="3284" end_char="3291">COVID-19</TOKEN>
<TOKEN id="token-27-16" pos="punct" morph="none" start_char="3292" end_char="3292">,</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="3294" end_char="3296">the</TOKEN>
<TOKEN id="token-27-18" pos="word" morph="none" start_char="3298" end_char="3307">department</TOKEN>
<TOKEN id="token-27-19" pos="word" morph="none" start_char="3309" end_char="3316">conducts</TOKEN>
<TOKEN id="token-27-20" pos="word" morph="none" start_char="3318" end_char="3319">an</TOKEN>
<TOKEN id="token-27-21" pos="word" morph="none" start_char="3321" end_char="3329">extensive</TOKEN>
<TOKEN id="token-27-22" pos="word" morph="none" start_char="3331" end_char="3345">epidemiological</TOKEN>
<TOKEN id="token-27-23" pos="word" morph="none" start_char="3347" end_char="3359">investigation</TOKEN>
<TOKEN id="token-27-24" pos="word" morph="none" start_char="3361" end_char="3362">in</TOKEN>
<TOKEN id="token-27-25" pos="word" morph="none" start_char="3364" end_char="3374">conjunction</TOKEN>
<TOKEN id="token-27-26" pos="word" morph="none" start_char="3376" end_char="3379">with</TOKEN>
<TOKEN id="token-27-27" pos="word" morph="none" start_char="3381" end_char="3383">the</TOKEN>
<TOKEN id="token-27-28" pos="punct" morph="none" start_char="3385" end_char="3385">[</TOKEN>
<TOKEN id="token-27-29" pos="word" morph="none" start_char="3386" end_char="3392">Centers</TOKEN>
<TOKEN id="token-27-30" pos="word" morph="none" start_char="3394" end_char="3396">for</TOKEN>
<TOKEN id="token-27-31" pos="word" morph="none" start_char="3398" end_char="3404">Disease</TOKEN>
<TOKEN id="token-27-32" pos="word" morph="none" start_char="3406" end_char="3412">Control</TOKEN>
<TOKEN id="token-27-33" pos="word" morph="none" start_char="3414" end_char="3416">and</TOKEN>
<TOKEN id="token-27-34" pos="word" morph="none" start_char="3418" end_char="3427">Prevention</TOKEN>
<TOKEN id="token-27-35" pos="punct" morph="none" start_char="3428" end_char="3428">]</TOKEN>
<TOKEN id="token-27-36" pos="word" morph="none" start_char="3430" end_char="3431">to</TOKEN>
<TOKEN id="token-27-37" pos="word" morph="none" start_char="3433" end_char="3440">identify</TOKEN>
<TOKEN id="token-27-38" pos="word" morph="none" start_char="3442" end_char="3452">individuals</TOKEN>
<TOKEN id="token-27-39" pos="word" morph="none" start_char="3454" end_char="3456">who</TOKEN>
<TOKEN id="token-27-40" pos="word" morph="none" start_char="3458" end_char="3460">may</TOKEN>
<TOKEN id="token-27-41" pos="word" morph="none" start_char="3462" end_char="3465">have</TOKEN>
<TOKEN id="token-27-42" pos="word" morph="none" start_char="3467" end_char="3469">had</TOKEN>
<TOKEN id="token-27-43" pos="word" morph="none" start_char="3471" end_char="3475">close</TOKEN>
<TOKEN id="token-27-44" pos="word" morph="none" start_char="3477" end_char="3483">contact</TOKEN>
<TOKEN id="token-27-45" pos="word" morph="none" start_char="3485" end_char="3488">with</TOKEN>
<TOKEN id="token-27-46" pos="word" morph="none" start_char="3490" end_char="3492">the</TOKEN>
<TOKEN id="token-27-47" pos="word" morph="none" start_char="3494" end_char="3498">virus</TOKEN>
<TOKEN id="token-27-48" pos="punct" morph="none" start_char="3499" end_char="3499">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3501" end_char="3756">
<ORIGINAL_TEXT>Those individuals are then notified by their county health department and instructed to self-isolate for 14 days after their exposure to the virus, and to contact their county health department and health care provider immediately if they develop symptoms.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="3501" end_char="3505">Those</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="3507" end_char="3517">individuals</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="3519" end_char="3521">are</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="3523" end_char="3526">then</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="3528" end_char="3535">notified</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="3537" end_char="3538">by</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="3540" end_char="3544">their</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="3546" end_char="3551">county</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="3553" end_char="3558">health</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="3560" end_char="3569">department</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="3571" end_char="3573">and</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="3575" end_char="3584">instructed</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="3586" end_char="3587">to</TOKEN>
<TOKEN id="token-28-13" pos="unknown" morph="none" start_char="3589" end_char="3600">self-isolate</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="3602" end_char="3604">for</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="3606" end_char="3607">14</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="3609" end_char="3612">days</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="3614" end_char="3618">after</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="3620" end_char="3624">their</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="3626" end_char="3633">exposure</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="3635" end_char="3636">to</TOKEN>
<TOKEN id="token-28-21" pos="word" morph="none" start_char="3638" end_char="3640">the</TOKEN>
<TOKEN id="token-28-22" pos="word" morph="none" start_char="3642" end_char="3646">virus</TOKEN>
<TOKEN id="token-28-23" pos="punct" morph="none" start_char="3647" end_char="3647">,</TOKEN>
<TOKEN id="token-28-24" pos="word" morph="none" start_char="3649" end_char="3651">and</TOKEN>
<TOKEN id="token-28-25" pos="word" morph="none" start_char="3653" end_char="3654">to</TOKEN>
<TOKEN id="token-28-26" pos="word" morph="none" start_char="3656" end_char="3662">contact</TOKEN>
<TOKEN id="token-28-27" pos="word" morph="none" start_char="3664" end_char="3668">their</TOKEN>
<TOKEN id="token-28-28" pos="word" morph="none" start_char="3670" end_char="3675">county</TOKEN>
<TOKEN id="token-28-29" pos="word" morph="none" start_char="3677" end_char="3682">health</TOKEN>
<TOKEN id="token-28-30" pos="word" morph="none" start_char="3684" end_char="3693">department</TOKEN>
<TOKEN id="token-28-31" pos="word" morph="none" start_char="3695" end_char="3697">and</TOKEN>
<TOKEN id="token-28-32" pos="word" morph="none" start_char="3699" end_char="3704">health</TOKEN>
<TOKEN id="token-28-33" pos="word" morph="none" start_char="3706" end_char="3709">care</TOKEN>
<TOKEN id="token-28-34" pos="word" morph="none" start_char="3711" end_char="3718">provider</TOKEN>
<TOKEN id="token-28-35" pos="word" morph="none" start_char="3720" end_char="3730">immediately</TOKEN>
<TOKEN id="token-28-36" pos="word" morph="none" start_char="3732" end_char="3733">if</TOKEN>
<TOKEN id="token-28-37" pos="word" morph="none" start_char="3735" end_char="3738">they</TOKEN>
<TOKEN id="token-28-38" pos="word" morph="none" start_char="3740" end_char="3746">develop</TOKEN>
<TOKEN id="token-28-39" pos="word" morph="none" start_char="3748" end_char="3755">symptoms</TOKEN>
<TOKEN id="token-28-40" pos="punct" morph="none" start_char="3756" end_char="3756">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3758" end_char="3864">
<ORIGINAL_TEXT>This process is followed for all individuals who test positive in Florida," Olga Connor wrote in the email.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="3758" end_char="3761">This</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="3763" end_char="3769">process</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="3771" end_char="3772">is</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="3774" end_char="3781">followed</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="3783" end_char="3785">for</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="3787" end_char="3789">all</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="3791" end_char="3801">individuals</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="3803" end_char="3805">who</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="3807" end_char="3810">test</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="3812" end_char="3819">positive</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="3821" end_char="3822">in</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="3824" end_char="3830">Florida</TOKEN>
<TOKEN id="token-29-12" pos="punct" morph="none" start_char="3831" end_char="3832">,"</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="3834" end_char="3837">Olga</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="3839" end_char="3844">Connor</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="3846" end_char="3850">wrote</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="3852" end_char="3853">in</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="3855" end_char="3857">the</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="3859" end_char="3863">email</TOKEN>
<TOKEN id="token-29-19" pos="punct" morph="none" start_char="3864" end_char="3864">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3867" end_char="4022">
<ORIGINAL_TEXT>The National Association of County and City Health Officials estimates that during a pandemic, communities need 30 contact tracers for every 100,000 people.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="3867" end_char="3869">The</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="3871" end_char="3878">National</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="3880" end_char="3890">Association</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="3892" end_char="3893">of</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="3895" end_char="3900">County</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="3902" end_char="3904">and</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="3906" end_char="3909">City</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="3911" end_char="3916">Health</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="3918" end_char="3926">Officials</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="3928" end_char="3936">estimates</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="3938" end_char="3941">that</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="3943" end_char="3948">during</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="3950" end_char="3950">a</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="3952" end_char="3959">pandemic</TOKEN>
<TOKEN id="token-30-14" pos="punct" morph="none" start_char="3960" end_char="3960">,</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="3962" end_char="3972">communities</TOKEN>
<TOKEN id="token-30-16" pos="word" morph="none" start_char="3974" end_char="3977">need</TOKEN>
<TOKEN id="token-30-17" pos="word" morph="none" start_char="3979" end_char="3980">30</TOKEN>
<TOKEN id="token-30-18" pos="word" morph="none" start_char="3982" end_char="3988">contact</TOKEN>
<TOKEN id="token-30-19" pos="word" morph="none" start_char="3990" end_char="3996">tracers</TOKEN>
<TOKEN id="token-30-20" pos="word" morph="none" start_char="3998" end_char="4000">for</TOKEN>
<TOKEN id="token-30-21" pos="word" morph="none" start_char="4002" end_char="4006">every</TOKEN>
<TOKEN id="token-30-22" pos="unknown" morph="none" start_char="4008" end_char="4014">100,000</TOKEN>
<TOKEN id="token-30-23" pos="word" morph="none" start_char="4016" end_char="4021">people</TOKEN>
<TOKEN id="token-30-24" pos="punct" morph="none" start_char="4022" end_char="4022">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="4024" end_char="4107">
<ORIGINAL_TEXT>Florida, with a population of 21.5 million people, would need 6,443 contact tracers.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="4024" end_char="4030">Florida</TOKEN>
<TOKEN id="token-31-1" pos="punct" morph="none" start_char="4031" end_char="4031">,</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="4033" end_char="4036">with</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="4038" end_char="4038">a</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="4040" end_char="4049">population</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="4051" end_char="4052">of</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="4054" end_char="4057">21.5</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="4059" end_char="4065">million</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="4067" end_char="4072">people</TOKEN>
<TOKEN id="token-31-9" pos="punct" morph="none" start_char="4073" end_char="4073">,</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="4075" end_char="4079">would</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="4081" end_char="4084">need</TOKEN>
<TOKEN id="token-31-12" pos="unknown" morph="none" start_char="4086" end_char="4090">6,443</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="4092" end_char="4098">contact</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="4100" end_char="4106">tracers</TOKEN>
<TOKEN id="token-31-15" pos="punct" morph="none" start_char="4107" end_char="4107">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="4110" end_char="4169">
<ORIGINAL_TEXT>Florida does not have nearly that many, and it is not alone.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="4110" end_char="4116">Florida</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="4118" end_char="4121">does</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="4123" end_char="4125">not</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="4127" end_char="4130">have</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="4132" end_char="4137">nearly</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="4139" end_char="4142">that</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="4144" end_char="4147">many</TOKEN>
<TOKEN id="token-32-7" pos="punct" morph="none" start_char="4148" end_char="4148">,</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="4150" end_char="4152">and</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="4154" end_char="4155">it</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="4157" end_char="4158">is</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="4160" end_char="4162">not</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="4164" end_char="4168">alone</TOKEN>
<TOKEN id="token-32-13" pos="punct" morph="none" start_char="4169" end_char="4169">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="4171" end_char="4311">
<ORIGINAL_TEXT>According to a July 3 report by Nephron Research, only seven states have a sufficient number of contact tracers to meet the NACCHO standards.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="4171" end_char="4179">According</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="4181" end_char="4182">to</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="4184" end_char="4184">a</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="4186" end_char="4189">July</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="4191" end_char="4191">3</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="4193" end_char="4198">report</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="4200" end_char="4201">by</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="4203" end_char="4209">Nephron</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="4211" end_char="4218">Research</TOKEN>
<TOKEN id="token-33-9" pos="punct" morph="none" start_char="4219" end_char="4219">,</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="4221" end_char="4224">only</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="4226" end_char="4230">seven</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="4232" end_char="4237">states</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="4239" end_char="4242">have</TOKEN>
<TOKEN id="token-33-14" pos="word" morph="none" start_char="4244" end_char="4244">a</TOKEN>
<TOKEN id="token-33-15" pos="word" morph="none" start_char="4246" end_char="4255">sufficient</TOKEN>
<TOKEN id="token-33-16" pos="word" morph="none" start_char="4257" end_char="4262">number</TOKEN>
<TOKEN id="token-33-17" pos="word" morph="none" start_char="4264" end_char="4265">of</TOKEN>
<TOKEN id="token-33-18" pos="word" morph="none" start_char="4267" end_char="4273">contact</TOKEN>
<TOKEN id="token-33-19" pos="word" morph="none" start_char="4275" end_char="4281">tracers</TOKEN>
<TOKEN id="token-33-20" pos="word" morph="none" start_char="4283" end_char="4284">to</TOKEN>
<TOKEN id="token-33-21" pos="word" morph="none" start_char="4286" end_char="4289">meet</TOKEN>
<TOKEN id="token-33-22" pos="word" morph="none" start_char="4291" end_char="4293">the</TOKEN>
<TOKEN id="token-33-23" pos="word" morph="none" start_char="4295" end_char="4300">NACCHO</TOKEN>
<TOKEN id="token-33-24" pos="word" morph="none" start_char="4302" end_char="4310">standards</TOKEN>
<TOKEN id="token-33-25" pos="punct" morph="none" start_char="4311" end_char="4311">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="4314" end_char="4466">
<ORIGINAL_TEXT>It's unclear how many contact tracers are employed by the state of Florida, as spokespersons for the Department of Health gave CNN two different numbers.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="4314" end_char="4317">It's</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="4319" end_char="4325">unclear</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="4327" end_char="4329">how</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="4331" end_char="4334">many</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="4336" end_char="4342">contact</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="4344" end_char="4350">tracers</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="4352" end_char="4354">are</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="4356" end_char="4363">employed</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="4365" end_char="4366">by</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="4368" end_char="4370">the</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="4372" end_char="4376">state</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="4378" end_char="4379">of</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="4381" end_char="4387">Florida</TOKEN>
<TOKEN id="token-34-13" pos="punct" morph="none" start_char="4388" end_char="4388">,</TOKEN>
<TOKEN id="token-34-14" pos="word" morph="none" start_char="4390" end_char="4391">as</TOKEN>
<TOKEN id="token-34-15" pos="word" morph="none" start_char="4393" end_char="4405">spokespersons</TOKEN>
<TOKEN id="token-34-16" pos="word" morph="none" start_char="4407" end_char="4409">for</TOKEN>
<TOKEN id="token-34-17" pos="word" morph="none" start_char="4411" end_char="4413">the</TOKEN>
<TOKEN id="token-34-18" pos="word" morph="none" start_char="4415" end_char="4424">Department</TOKEN>
<TOKEN id="token-34-19" pos="word" morph="none" start_char="4426" end_char="4427">of</TOKEN>
<TOKEN id="token-34-20" pos="word" morph="none" start_char="4429" end_char="4434">Health</TOKEN>
<TOKEN id="token-34-21" pos="word" morph="none" start_char="4436" end_char="4439">gave</TOKEN>
<TOKEN id="token-34-22" pos="word" morph="none" start_char="4441" end_char="4443">CNN</TOKEN>
<TOKEN id="token-34-23" pos="word" morph="none" start_char="4445" end_char="4447">two</TOKEN>
<TOKEN id="token-34-24" pos="word" morph="none" start_char="4449" end_char="4457">different</TOKEN>
<TOKEN id="token-34-25" pos="word" morph="none" start_char="4459" end_char="4465">numbers</TOKEN>
<TOKEN id="token-34-26" pos="punct" morph="none" start_char="4466" end_char="4466">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="4469" end_char="4760">
<ORIGINAL_TEXT>"More than 1,600 individuals, including students, epidemiologists and other staff from across the Department, are currently involved in contact tracing every positive case of COVID-19 in Florida," Candy Sims, a spokesperson for the Florida Department of Health in Broward County wrote to CNN.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="punct" morph="none" start_char="4469" end_char="4469">"</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="4470" end_char="4473">More</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="4475" end_char="4478">than</TOKEN>
<TOKEN id="token-35-3" pos="unknown" morph="none" start_char="4480" end_char="4484">1,600</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="4486" end_char="4496">individuals</TOKEN>
<TOKEN id="token-35-5" pos="punct" morph="none" start_char="4497" end_char="4497">,</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="4499" end_char="4507">including</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="4509" end_char="4516">students</TOKEN>
<TOKEN id="token-35-8" pos="punct" morph="none" start_char="4517" end_char="4517">,</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="4519" end_char="4533">epidemiologists</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="4535" end_char="4537">and</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="4539" end_char="4543">other</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="4545" end_char="4549">staff</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="4551" end_char="4554">from</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="4556" end_char="4561">across</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="4563" end_char="4565">the</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="4567" end_char="4576">Department</TOKEN>
<TOKEN id="token-35-17" pos="punct" morph="none" start_char="4577" end_char="4577">,</TOKEN>
<TOKEN id="token-35-18" pos="word" morph="none" start_char="4579" end_char="4581">are</TOKEN>
<TOKEN id="token-35-19" pos="word" morph="none" start_char="4583" end_char="4591">currently</TOKEN>
<TOKEN id="token-35-20" pos="word" morph="none" start_char="4593" end_char="4600">involved</TOKEN>
<TOKEN id="token-35-21" pos="word" morph="none" start_char="4602" end_char="4603">in</TOKEN>
<TOKEN id="token-35-22" pos="word" morph="none" start_char="4605" end_char="4611">contact</TOKEN>
<TOKEN id="token-35-23" pos="word" morph="none" start_char="4613" end_char="4619">tracing</TOKEN>
<TOKEN id="token-35-24" pos="word" morph="none" start_char="4621" end_char="4625">every</TOKEN>
<TOKEN id="token-35-25" pos="word" morph="none" start_char="4627" end_char="4634">positive</TOKEN>
<TOKEN id="token-35-26" pos="word" morph="none" start_char="4636" end_char="4639">case</TOKEN>
<TOKEN id="token-35-27" pos="word" morph="none" start_char="4641" end_char="4642">of</TOKEN>
<TOKEN id="token-35-28" pos="unknown" morph="none" start_char="4644" end_char="4651">COVID-19</TOKEN>
<TOKEN id="token-35-29" pos="word" morph="none" start_char="4653" end_char="4654">in</TOKEN>
<TOKEN id="token-35-30" pos="word" morph="none" start_char="4656" end_char="4662">Florida</TOKEN>
<TOKEN id="token-35-31" pos="punct" morph="none" start_char="4663" end_char="4664">,"</TOKEN>
<TOKEN id="token-35-32" pos="word" morph="none" start_char="4666" end_char="4670">Candy</TOKEN>
<TOKEN id="token-35-33" pos="word" morph="none" start_char="4672" end_char="4675">Sims</TOKEN>
<TOKEN id="token-35-34" pos="punct" morph="none" start_char="4676" end_char="4676">,</TOKEN>
<TOKEN id="token-35-35" pos="word" morph="none" start_char="4678" end_char="4678">a</TOKEN>
<TOKEN id="token-35-36" pos="word" morph="none" start_char="4680" end_char="4691">spokesperson</TOKEN>
<TOKEN id="token-35-37" pos="word" morph="none" start_char="4693" end_char="4695">for</TOKEN>
<TOKEN id="token-35-38" pos="word" morph="none" start_char="4697" end_char="4699">the</TOKEN>
<TOKEN id="token-35-39" pos="word" morph="none" start_char="4701" end_char="4707">Florida</TOKEN>
<TOKEN id="token-35-40" pos="word" morph="none" start_char="4709" end_char="4718">Department</TOKEN>
<TOKEN id="token-35-41" pos="word" morph="none" start_char="4720" end_char="4721">of</TOKEN>
<TOKEN id="token-35-42" pos="word" morph="none" start_char="4723" end_char="4728">Health</TOKEN>
<TOKEN id="token-35-43" pos="word" morph="none" start_char="4730" end_char="4731">in</TOKEN>
<TOKEN id="token-35-44" pos="word" morph="none" start_char="4733" end_char="4739">Broward</TOKEN>
<TOKEN id="token-35-45" pos="word" morph="none" start_char="4741" end_char="4746">County</TOKEN>
<TOKEN id="token-35-46" pos="word" morph="none" start_char="4748" end_char="4752">wrote</TOKEN>
<TOKEN id="token-35-47" pos="word" morph="none" start_char="4754" end_char="4755">to</TOKEN>
<TOKEN id="token-35-48" pos="word" morph="none" start_char="4757" end_char="4759">CNN</TOKEN>
<TOKEN id="token-35-49" pos="punct" morph="none" start_char="4760" end_char="4760">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="4763" end_char="4840">
<ORIGINAL_TEXT>Florida topped 200,000 coronavirus cases as nation marked a different July 4th</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="4763" end_char="4769">Florida</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="4771" end_char="4776">topped</TOKEN>
<TOKEN id="token-36-2" pos="unknown" morph="none" start_char="4778" end_char="4784">200,000</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="4786" end_char="4796">coronavirus</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="4798" end_char="4802">cases</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="4804" end_char="4805">as</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="4807" end_char="4812">nation</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="4814" end_char="4819">marked</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="4821" end_char="4821">a</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="4823" end_char="4831">different</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="4833" end_char="4836">July</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="4838" end_char="4840">4th</TOKEN>
</SEG>
<SEG id="segment-37" start_char="4844" end_char="5004">
<ORIGINAL_TEXT>But Alberto Moscoso, a department of health spokesperson, cited a larger number, writing to CNN that Florida has 2,300 "individuals involved in contact tracing."</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="4844" end_char="4846">But</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="4848" end_char="4854">Alberto</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="4856" end_char="4862">Moscoso</TOKEN>
<TOKEN id="token-37-3" pos="punct" morph="none" start_char="4863" end_char="4863">,</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="4865" end_char="4865">a</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="4867" end_char="4876">department</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="4878" end_char="4879">of</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="4881" end_char="4886">health</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="4888" end_char="4899">spokesperson</TOKEN>
<TOKEN id="token-37-9" pos="punct" morph="none" start_char="4900" end_char="4900">,</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="4902" end_char="4906">cited</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="4908" end_char="4908">a</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="4910" end_char="4915">larger</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="4917" end_char="4922">number</TOKEN>
<TOKEN id="token-37-14" pos="punct" morph="none" start_char="4923" end_char="4923">,</TOKEN>
<TOKEN id="token-37-15" pos="word" morph="none" start_char="4925" end_char="4931">writing</TOKEN>
<TOKEN id="token-37-16" pos="word" morph="none" start_char="4933" end_char="4934">to</TOKEN>
<TOKEN id="token-37-17" pos="word" morph="none" start_char="4936" end_char="4938">CNN</TOKEN>
<TOKEN id="token-37-18" pos="word" morph="none" start_char="4940" end_char="4943">that</TOKEN>
<TOKEN id="token-37-19" pos="word" morph="none" start_char="4945" end_char="4951">Florida</TOKEN>
<TOKEN id="token-37-20" pos="word" morph="none" start_char="4953" end_char="4955">has</TOKEN>
<TOKEN id="token-37-21" pos="unknown" morph="none" start_char="4957" end_char="4961">2,300</TOKEN>
<TOKEN id="token-37-22" pos="punct" morph="none" start_char="4963" end_char="4963">"</TOKEN>
<TOKEN id="token-37-23" pos="word" morph="none" start_char="4964" end_char="4974">individuals</TOKEN>
<TOKEN id="token-37-24" pos="word" morph="none" start_char="4976" end_char="4983">involved</TOKEN>
<TOKEN id="token-37-25" pos="word" morph="none" start_char="4985" end_char="4986">in</TOKEN>
<TOKEN id="token-37-26" pos="word" morph="none" start_char="4988" end_char="4994">contact</TOKEN>
<TOKEN id="token-37-27" pos="word" morph="none" start_char="4996" end_char="5002">tracing</TOKEN>
<TOKEN id="token-37-28" pos="punct" morph="none" start_char="5003" end_char="5004">."</TOKEN>
</SEG>
<SEG id="segment-38" start_char="5007" end_char="5095">
<ORIGINAL_TEXT>Sims and Moscoso did not respond to CNN inquiries about the differences in their numbers.</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="5007" end_char="5010">Sims</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="5012" end_char="5014">and</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="5016" end_char="5022">Moscoso</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="5024" end_char="5026">did</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="5028" end_char="5030">not</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="5032" end_char="5038">respond</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="5040" end_char="5041">to</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="5043" end_char="5045">CNN</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="5047" end_char="5055">inquiries</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="5057" end_char="5061">about</TOKEN>
<TOKEN id="token-38-10" pos="word" morph="none" start_char="5063" end_char="5065">the</TOKEN>
<TOKEN id="token-38-11" pos="word" morph="none" start_char="5067" end_char="5077">differences</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="5079" end_char="5080">in</TOKEN>
<TOKEN id="token-38-13" pos="word" morph="none" start_char="5082" end_char="5086">their</TOKEN>
<TOKEN id="token-38-14" pos="word" morph="none" start_char="5088" end_char="5094">numbers</TOKEN>
<TOKEN id="token-38-15" pos="punct" morph="none" start_char="5095" end_char="5095">.</TOKEN>
</SEG>
<SEG id="segment-39" start_char="5098" end_char="5213">
<ORIGINAL_TEXT>In an online infographic, the Florida Department of Health asks infected people to call their contacts on their own.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="5098" end_char="5099">In</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="5101" end_char="5102">an</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="5104" end_char="5109">online</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="5111" end_char="5121">infographic</TOKEN>
<TOKEN id="token-39-4" pos="punct" morph="none" start_char="5122" end_char="5122">,</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="5124" end_char="5126">the</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="5128" end_char="5134">Florida</TOKEN>
<TOKEN id="token-39-7" pos="word" morph="none" start_char="5136" end_char="5145">Department</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="5147" end_char="5148">of</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="5150" end_char="5155">Health</TOKEN>
<TOKEN id="token-39-10" pos="word" morph="none" start_char="5157" end_char="5160">asks</TOKEN>
<TOKEN id="token-39-11" pos="word" morph="none" start_char="5162" end_char="5169">infected</TOKEN>
<TOKEN id="token-39-12" pos="word" morph="none" start_char="5171" end_char="5176">people</TOKEN>
<TOKEN id="token-39-13" pos="word" morph="none" start_char="5178" end_char="5179">to</TOKEN>
<TOKEN id="token-39-14" pos="word" morph="none" start_char="5181" end_char="5184">call</TOKEN>
<TOKEN id="token-39-15" pos="word" morph="none" start_char="5186" end_char="5190">their</TOKEN>
<TOKEN id="token-39-16" pos="word" morph="none" start_char="5192" end_char="5199">contacts</TOKEN>
<TOKEN id="token-39-17" pos="word" morph="none" start_char="5201" end_char="5202">on</TOKEN>
<TOKEN id="token-39-18" pos="word" morph="none" start_char="5204" end_char="5208">their</TOKEN>
<TOKEN id="token-39-19" pos="word" morph="none" start_char="5210" end_char="5212">own</TOKEN>
<TOKEN id="token-39-20" pos="punct" morph="none" start_char="5213" end_char="5213">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="5216" end_char="5374">
<ORIGINAL_TEXT>"Immediately notify people you have had close contact with while ill," according to the graphic, noting that those contacts should then quarantine for 14 days.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="punct" morph="none" start_char="5216" end_char="5216">"</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="5217" end_char="5227">Immediately</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="5229" end_char="5234">notify</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="5236" end_char="5241">people</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="5243" end_char="5245">you</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="5247" end_char="5250">have</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="5252" end_char="5254">had</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="5256" end_char="5260">close</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="5262" end_char="5268">contact</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="5270" end_char="5273">with</TOKEN>
<TOKEN id="token-40-10" pos="word" morph="none" start_char="5275" end_char="5279">while</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="5281" end_char="5283">ill</TOKEN>
<TOKEN id="token-40-12" pos="punct" morph="none" start_char="5284" end_char="5285">,"</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="5287" end_char="5295">according</TOKEN>
<TOKEN id="token-40-14" pos="word" morph="none" start_char="5297" end_char="5298">to</TOKEN>
<TOKEN id="token-40-15" pos="word" morph="none" start_char="5300" end_char="5302">the</TOKEN>
<TOKEN id="token-40-16" pos="word" morph="none" start_char="5304" end_char="5310">graphic</TOKEN>
<TOKEN id="token-40-17" pos="punct" morph="none" start_char="5311" end_char="5311">,</TOKEN>
<TOKEN id="token-40-18" pos="word" morph="none" start_char="5313" end_char="5318">noting</TOKEN>
<TOKEN id="token-40-19" pos="word" morph="none" start_char="5320" end_char="5323">that</TOKEN>
<TOKEN id="token-40-20" pos="word" morph="none" start_char="5325" end_char="5329">those</TOKEN>
<TOKEN id="token-40-21" pos="word" morph="none" start_char="5331" end_char="5338">contacts</TOKEN>
<TOKEN id="token-40-22" pos="word" morph="none" start_char="5340" end_char="5345">should</TOKEN>
<TOKEN id="token-40-23" pos="word" morph="none" start_char="5347" end_char="5350">then</TOKEN>
<TOKEN id="token-40-24" pos="word" morph="none" start_char="5352" end_char="5361">quarantine</TOKEN>
<TOKEN id="token-40-25" pos="word" morph="none" start_char="5363" end_char="5365">for</TOKEN>
<TOKEN id="token-40-26" pos="word" morph="none" start_char="5367" end_char="5368">14</TOKEN>
<TOKEN id="token-40-27" pos="word" morph="none" start_char="5370" end_char="5373">days</TOKEN>
<TOKEN id="token-40-28" pos="punct" morph="none" start_char="5374" end_char="5374">.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="5377" end_char="5417">
<ORIGINAL_TEXT>The CDC, however, gives different advice.</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="5377" end_char="5379">The</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="5381" end_char="5383">CDC</TOKEN>
<TOKEN id="token-41-2" pos="punct" morph="none" start_char="5384" end_char="5384">,</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="5386" end_char="5392">however</TOKEN>
<TOKEN id="token-41-4" pos="punct" morph="none" start_char="5393" end_char="5393">,</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="5395" end_char="5399">gives</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="5401" end_char="5409">different</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="5411" end_char="5416">advice</TOKEN>
<TOKEN id="token-41-8" pos="punct" morph="none" start_char="5417" end_char="5417">.</TOKEN>
</SEG>
<SEG id="segment-42" start_char="5419" end_char="5591">
<ORIGINAL_TEXT>The agency recommends that local health departments ask infected people for a list of everyone they've had close contact with starting two days prior to developing symptoms.</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="5419" end_char="5421">The</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="5423" end_char="5428">agency</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="5430" end_char="5439">recommends</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="5441" end_char="5444">that</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="5446" end_char="5450">local</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="5452" end_char="5457">health</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="5459" end_char="5469">departments</TOKEN>
<TOKEN id="token-42-7" pos="word" morph="none" start_char="5471" end_char="5473">ask</TOKEN>
<TOKEN id="token-42-8" pos="word" morph="none" start_char="5475" end_char="5482">infected</TOKEN>
<TOKEN id="token-42-9" pos="word" morph="none" start_char="5484" end_char="5489">people</TOKEN>
<TOKEN id="token-42-10" pos="word" morph="none" start_char="5491" end_char="5493">for</TOKEN>
<TOKEN id="token-42-11" pos="word" morph="none" start_char="5495" end_char="5495">a</TOKEN>
<TOKEN id="token-42-12" pos="word" morph="none" start_char="5497" end_char="5500">list</TOKEN>
<TOKEN id="token-42-13" pos="word" morph="none" start_char="5502" end_char="5503">of</TOKEN>
<TOKEN id="token-42-14" pos="word" morph="none" start_char="5505" end_char="5512">everyone</TOKEN>
<TOKEN id="token-42-15" pos="word" morph="none" start_char="5514" end_char="5520">they've</TOKEN>
<TOKEN id="token-42-16" pos="word" morph="none" start_char="5522" end_char="5524">had</TOKEN>
<TOKEN id="token-42-17" pos="word" morph="none" start_char="5526" end_char="5530">close</TOKEN>
<TOKEN id="token-42-18" pos="word" morph="none" start_char="5532" end_char="5538">contact</TOKEN>
<TOKEN id="token-42-19" pos="word" morph="none" start_char="5540" end_char="5543">with</TOKEN>
<TOKEN id="token-42-20" pos="word" morph="none" start_char="5545" end_char="5552">starting</TOKEN>
<TOKEN id="token-42-21" pos="word" morph="none" start_char="5554" end_char="5556">two</TOKEN>
<TOKEN id="token-42-22" pos="word" morph="none" start_char="5558" end_char="5561">days</TOKEN>
<TOKEN id="token-42-23" pos="word" morph="none" start_char="5563" end_char="5567">prior</TOKEN>
<TOKEN id="token-42-24" pos="word" morph="none" start_char="5569" end_char="5570">to</TOKEN>
<TOKEN id="token-42-25" pos="word" morph="none" start_char="5572" end_char="5581">developing</TOKEN>
<TOKEN id="token-42-26" pos="word" morph="none" start_char="5583" end_char="5590">symptoms</TOKEN>
<TOKEN id="token-42-27" pos="punct" morph="none" start_char="5591" end_char="5591">.</TOKEN>
</SEG>
<SEG id="segment-43" start_char="5594" end_char="5712">
<ORIGINAL_TEXT>The Florida infographic doesn't explain what to do if someone tests positive for Covid-19 but has never shown symptoms.</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="5594" end_char="5596">The</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="5598" end_char="5604">Florida</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="5606" end_char="5616">infographic</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="5618" end_char="5624">doesn't</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="5626" end_char="5632">explain</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="5634" end_char="5637">what</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="5639" end_char="5640">to</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="5642" end_char="5643">do</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="5645" end_char="5646">if</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="5648" end_char="5654">someone</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="5656" end_char="5660">tests</TOKEN>
<TOKEN id="token-43-11" pos="word" morph="none" start_char="5662" end_char="5669">positive</TOKEN>
<TOKEN id="token-43-12" pos="word" morph="none" start_char="5671" end_char="5673">for</TOKEN>
<TOKEN id="token-43-13" pos="unknown" morph="none" start_char="5675" end_char="5682">Covid-19</TOKEN>
<TOKEN id="token-43-14" pos="word" morph="none" start_char="5684" end_char="5686">but</TOKEN>
<TOKEN id="token-43-15" pos="word" morph="none" start_char="5688" end_char="5690">has</TOKEN>
<TOKEN id="token-43-16" pos="word" morph="none" start_char="5692" end_char="5696">never</TOKEN>
<TOKEN id="token-43-17" pos="word" morph="none" start_char="5698" end_char="5702">shown</TOKEN>
<TOKEN id="token-43-18" pos="word" morph="none" start_char="5704" end_char="5711">symptoms</TOKEN>
<TOKEN id="token-43-19" pos="punct" morph="none" start_char="5712" end_char="5712">.</TOKEN>
</SEG>
<SEG id="segment-44" start_char="5714" end_char="5874">
<ORIGINAL_TEXT>According to the CDC, in that case, people should be notified if they had close contact with the infected person two days before that person took the Covid test.</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="5714" end_char="5722">According</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="5724" end_char="5725">to</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="5727" end_char="5729">the</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="5731" end_char="5733">CDC</TOKEN>
<TOKEN id="token-44-4" pos="punct" morph="none" start_char="5734" end_char="5734">,</TOKEN>
<TOKEN id="token-44-5" pos="word" morph="none" start_char="5736" end_char="5737">in</TOKEN>
<TOKEN id="token-44-6" pos="word" morph="none" start_char="5739" end_char="5742">that</TOKEN>
<TOKEN id="token-44-7" pos="word" morph="none" start_char="5744" end_char="5747">case</TOKEN>
<TOKEN id="token-44-8" pos="punct" morph="none" start_char="5748" end_char="5748">,</TOKEN>
<TOKEN id="token-44-9" pos="word" morph="none" start_char="5750" end_char="5755">people</TOKEN>
<TOKEN id="token-44-10" pos="word" morph="none" start_char="5757" end_char="5762">should</TOKEN>
<TOKEN id="token-44-11" pos="word" morph="none" start_char="5764" end_char="5765">be</TOKEN>
<TOKEN id="token-44-12" pos="word" morph="none" start_char="5767" end_char="5774">notified</TOKEN>
<TOKEN id="token-44-13" pos="word" morph="none" start_char="5776" end_char="5777">if</TOKEN>
<TOKEN id="token-44-14" pos="word" morph="none" start_char="5779" end_char="5782">they</TOKEN>
<TOKEN id="token-44-15" pos="word" morph="none" start_char="5784" end_char="5786">had</TOKEN>
<TOKEN id="token-44-16" pos="word" morph="none" start_char="5788" end_char="5792">close</TOKEN>
<TOKEN id="token-44-17" pos="word" morph="none" start_char="5794" end_char="5800">contact</TOKEN>
<TOKEN id="token-44-18" pos="word" morph="none" start_char="5802" end_char="5805">with</TOKEN>
<TOKEN id="token-44-19" pos="word" morph="none" start_char="5807" end_char="5809">the</TOKEN>
<TOKEN id="token-44-20" pos="word" morph="none" start_char="5811" end_char="5818">infected</TOKEN>
<TOKEN id="token-44-21" pos="word" morph="none" start_char="5820" end_char="5825">person</TOKEN>
<TOKEN id="token-44-22" pos="word" morph="none" start_char="5827" end_char="5829">two</TOKEN>
<TOKEN id="token-44-23" pos="word" morph="none" start_char="5831" end_char="5834">days</TOKEN>
<TOKEN id="token-44-24" pos="word" morph="none" start_char="5836" end_char="5841">before</TOKEN>
<TOKEN id="token-44-25" pos="word" morph="none" start_char="5843" end_char="5846">that</TOKEN>
<TOKEN id="token-44-26" pos="word" morph="none" start_char="5848" end_char="5853">person</TOKEN>
<TOKEN id="token-44-27" pos="word" morph="none" start_char="5855" end_char="5858">took</TOKEN>
<TOKEN id="token-44-28" pos="word" morph="none" start_char="5860" end_char="5862">the</TOKEN>
<TOKEN id="token-44-29" pos="word" morph="none" start_char="5864" end_char="5868">Covid</TOKEN>
<TOKEN id="token-44-30" pos="word" morph="none" start_char="5870" end_char="5873">test</TOKEN>
<TOKEN id="token-44-31" pos="punct" morph="none" start_char="5874" end_char="5874">.</TOKEN>
</SEG>
<SEG id="segment-45" start_char="5877" end_char="6022">
<ORIGINAL_TEXT>Of the 27 Floridians who've tested positive for Covid-19, five told CNN they had received a call from a health official asking for their contacts.</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="5877" end_char="5878">Of</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="5880" end_char="5882">the</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="5884" end_char="5885">27</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="5887" end_char="5896">Floridians</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="5898" end_char="5903">who've</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="5905" end_char="5910">tested</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="5912" end_char="5919">positive</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="5921" end_char="5923">for</TOKEN>
<TOKEN id="token-45-8" pos="unknown" morph="none" start_char="5925" end_char="5932">Covid-19</TOKEN>
<TOKEN id="token-45-9" pos="punct" morph="none" start_char="5933" end_char="5933">,</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="5935" end_char="5938">five</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="5940" end_char="5943">told</TOKEN>
<TOKEN id="token-45-12" pos="word" morph="none" start_char="5945" end_char="5947">CNN</TOKEN>
<TOKEN id="token-45-13" pos="word" morph="none" start_char="5949" end_char="5952">they</TOKEN>
<TOKEN id="token-45-14" pos="word" morph="none" start_char="5954" end_char="5956">had</TOKEN>
<TOKEN id="token-45-15" pos="word" morph="none" start_char="5958" end_char="5965">received</TOKEN>
<TOKEN id="token-45-16" pos="word" morph="none" start_char="5967" end_char="5967">a</TOKEN>
<TOKEN id="token-45-17" pos="word" morph="none" start_char="5969" end_char="5972">call</TOKEN>
<TOKEN id="token-45-18" pos="word" morph="none" start_char="5974" end_char="5977">from</TOKEN>
<TOKEN id="token-45-19" pos="word" morph="none" start_char="5979" end_char="5979">a</TOKEN>
<TOKEN id="token-45-20" pos="word" morph="none" start_char="5981" end_char="5986">health</TOKEN>
<TOKEN id="token-45-21" pos="word" morph="none" start_char="5988" end_char="5995">official</TOKEN>
<TOKEN id="token-45-22" pos="word" morph="none" start_char="5997" end_char="6002">asking</TOKEN>
<TOKEN id="token-45-23" pos="word" morph="none" start_char="6004" end_char="6006">for</TOKEN>
<TOKEN id="token-45-24" pos="word" morph="none" start_char="6008" end_char="6012">their</TOKEN>
<TOKEN id="token-45-25" pos="word" morph="none" start_char="6014" end_char="6021">contacts</TOKEN>
<TOKEN id="token-45-26" pos="punct" morph="none" start_char="6022" end_char="6022">.</TOKEN>
</SEG>
<SEG id="segment-46" start_char="6025" end_char="6118">
<ORIGINAL_TEXT>Among the 27 cases, the earliest diagnosis was in February, and the most recent was last week.</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="6025" end_char="6029">Among</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="6031" end_char="6033">the</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="6035" end_char="6036">27</TOKEN>
<TOKEN id="token-46-3" pos="word" morph="none" start_char="6038" end_char="6042">cases</TOKEN>
<TOKEN id="token-46-4" pos="punct" morph="none" start_char="6043" end_char="6043">,</TOKEN>
<TOKEN id="token-46-5" pos="word" morph="none" start_char="6045" end_char="6047">the</TOKEN>
<TOKEN id="token-46-6" pos="word" morph="none" start_char="6049" end_char="6056">earliest</TOKEN>
<TOKEN id="token-46-7" pos="word" morph="none" start_char="6058" end_char="6066">diagnosis</TOKEN>
<TOKEN id="token-46-8" pos="word" morph="none" start_char="6068" end_char="6070">was</TOKEN>
<TOKEN id="token-46-9" pos="word" morph="none" start_char="6072" end_char="6073">in</TOKEN>
<TOKEN id="token-46-10" pos="word" morph="none" start_char="6075" end_char="6082">February</TOKEN>
<TOKEN id="token-46-11" pos="punct" morph="none" start_char="6083" end_char="6083">,</TOKEN>
<TOKEN id="token-46-12" pos="word" morph="none" start_char="6085" end_char="6087">and</TOKEN>
<TOKEN id="token-46-13" pos="word" morph="none" start_char="6089" end_char="6091">the</TOKEN>
<TOKEN id="token-46-14" pos="word" morph="none" start_char="6093" end_char="6096">most</TOKEN>
<TOKEN id="token-46-15" pos="word" morph="none" start_char="6098" end_char="6103">recent</TOKEN>
<TOKEN id="token-46-16" pos="word" morph="none" start_char="6105" end_char="6107">was</TOKEN>
<TOKEN id="token-46-17" pos="word" morph="none" start_char="6109" end_char="6112">last</TOKEN>
<TOKEN id="token-46-18" pos="word" morph="none" start_char="6114" end_char="6117">week</TOKEN>
<TOKEN id="token-46-19" pos="punct" morph="none" start_char="6118" end_char="6118">.</TOKEN>
</SEG>
<SEG id="segment-47" start_char="6121" end_char="6242">
<ORIGINAL_TEXT>The Riveras contracted Covid in early March, when contact tracers were under considerably less pressure than they are now.</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="6121" end_char="6123">The</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="6125" end_char="6131">Riveras</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="6133" end_char="6142">contracted</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="6144" end_char="6148">Covid</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="6150" end_char="6151">in</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="6153" end_char="6157">early</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="6159" end_char="6163">March</TOKEN>
<TOKEN id="token-47-7" pos="punct" morph="none" start_char="6164" end_char="6164">,</TOKEN>
<TOKEN id="token-47-8" pos="word" morph="none" start_char="6166" end_char="6169">when</TOKEN>
<TOKEN id="token-47-9" pos="word" morph="none" start_char="6171" end_char="6177">contact</TOKEN>
<TOKEN id="token-47-10" pos="word" morph="none" start_char="6179" end_char="6185">tracers</TOKEN>
<TOKEN id="token-47-11" pos="word" morph="none" start_char="6187" end_char="6190">were</TOKEN>
<TOKEN id="token-47-12" pos="word" morph="none" start_char="6192" end_char="6196">under</TOKEN>
<TOKEN id="token-47-13" pos="word" morph="none" start_char="6198" end_char="6209">considerably</TOKEN>
<TOKEN id="token-47-14" pos="word" morph="none" start_char="6211" end_char="6214">less</TOKEN>
<TOKEN id="token-47-15" pos="word" morph="none" start_char="6216" end_char="6223">pressure</TOKEN>
<TOKEN id="token-47-16" pos="word" morph="none" start_char="6225" end_char="6228">than</TOKEN>
<TOKEN id="token-47-17" pos="word" morph="none" start_char="6230" end_char="6233">they</TOKEN>
<TOKEN id="token-47-18" pos="word" morph="none" start_char="6235" end_char="6237">are</TOKEN>
<TOKEN id="token-47-19" pos="word" morph="none" start_char="6239" end_char="6241">now</TOKEN>
<TOKEN id="token-47-20" pos="punct" morph="none" start_char="6242" end_char="6242">.</TOKEN>
</SEG>
<SEG id="segment-48" start_char="6244" end_char="6407">
<ORIGINAL_TEXT>Shaila Rivera said an official from the Miami-Dade County Department of Health called and asked questions about their illnesses but didn't ask about their contacts.</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="6244" end_char="6249">Shaila</TOKEN>
<TOKEN id="token-48-1" pos="word" morph="none" start_char="6251" end_char="6256">Rivera</TOKEN>
<TOKEN id="token-48-2" pos="word" morph="none" start_char="6258" end_char="6261">said</TOKEN>
<TOKEN id="token-48-3" pos="word" morph="none" start_char="6263" end_char="6264">an</TOKEN>
<TOKEN id="token-48-4" pos="word" morph="none" start_char="6266" end_char="6273">official</TOKEN>
<TOKEN id="token-48-5" pos="word" morph="none" start_char="6275" end_char="6278">from</TOKEN>
<TOKEN id="token-48-6" pos="word" morph="none" start_char="6280" end_char="6282">the</TOKEN>
<TOKEN id="token-48-7" pos="unknown" morph="none" start_char="6284" end_char="6293">Miami-Dade</TOKEN>
<TOKEN id="token-48-8" pos="word" morph="none" start_char="6295" end_char="6300">County</TOKEN>
<TOKEN id="token-48-9" pos="word" morph="none" start_char="6302" end_char="6311">Department</TOKEN>
<TOKEN id="token-48-10" pos="word" morph="none" start_char="6313" end_char="6314">of</TOKEN>
<TOKEN id="token-48-11" pos="word" morph="none" start_char="6316" end_char="6321">Health</TOKEN>
<TOKEN id="token-48-12" pos="word" morph="none" start_char="6323" end_char="6328">called</TOKEN>
<TOKEN id="token-48-13" pos="word" morph="none" start_char="6330" end_char="6332">and</TOKEN>
<TOKEN id="token-48-14" pos="word" morph="none" start_char="6334" end_char="6338">asked</TOKEN>
<TOKEN id="token-48-15" pos="word" morph="none" start_char="6340" end_char="6348">questions</TOKEN>
<TOKEN id="token-48-16" pos="word" morph="none" start_char="6350" end_char="6354">about</TOKEN>
<TOKEN id="token-48-17" pos="word" morph="none" start_char="6356" end_char="6360">their</TOKEN>
<TOKEN id="token-48-18" pos="word" morph="none" start_char="6362" end_char="6370">illnesses</TOKEN>
<TOKEN id="token-48-19" pos="word" morph="none" start_char="6372" end_char="6374">but</TOKEN>
<TOKEN id="token-48-20" pos="word" morph="none" start_char="6376" end_char="6381">didn't</TOKEN>
<TOKEN id="token-48-21" pos="word" morph="none" start_char="6383" end_char="6385">ask</TOKEN>
<TOKEN id="token-48-22" pos="word" morph="none" start_char="6387" end_char="6391">about</TOKEN>
<TOKEN id="token-48-23" pos="word" morph="none" start_char="6393" end_char="6397">their</TOKEN>
<TOKEN id="token-48-24" pos="word" morph="none" start_char="6399" end_char="6406">contacts</TOKEN>
<TOKEN id="token-48-25" pos="punct" morph="none" start_char="6407" end_char="6407">.</TOKEN>
</SEG>
<SEG id="segment-49" start_char="6410" end_char="6468">
<ORIGINAL_TEXT>Contact tracing could become a regular part of office life.</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="6410" end_char="6416">Contact</TOKEN>
<TOKEN id="token-49-1" pos="word" morph="none" start_char="6418" end_char="6424">tracing</TOKEN>
<TOKEN id="token-49-2" pos="word" morph="none" start_char="6426" end_char="6430">could</TOKEN>
<TOKEN id="token-49-3" pos="word" morph="none" start_char="6432" end_char="6437">become</TOKEN>
<TOKEN id="token-49-4" pos="word" morph="none" start_char="6439" end_char="6439">a</TOKEN>
<TOKEN id="token-49-5" pos="word" morph="none" start_char="6441" end_char="6447">regular</TOKEN>
<TOKEN id="token-49-6" pos="word" morph="none" start_char="6449" end_char="6452">part</TOKEN>
<TOKEN id="token-49-7" pos="word" morph="none" start_char="6454" end_char="6455">of</TOKEN>
<TOKEN id="token-49-8" pos="word" morph="none" start_char="6457" end_char="6462">office</TOKEN>
<TOKEN id="token-49-9" pos="word" morph="none" start_char="6464" end_char="6467">life</TOKEN>
<TOKEN id="token-49-10" pos="punct" morph="none" start_char="6468" end_char="6468">.</TOKEN>
</SEG>
<SEG id="segment-50" start_char="6470" end_char="6492">
<ORIGINAL_TEXT>Here's how it will work</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="6470" end_char="6475">Here's</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="6477" end_char="6479">how</TOKEN>
<TOKEN id="token-50-2" pos="word" morph="none" start_char="6481" end_char="6482">it</TOKEN>
<TOKEN id="token-50-3" pos="word" morph="none" start_char="6484" end_char="6487">will</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="6489" end_char="6492">work</TOKEN>
</SEG>
<SEG id="segment-51" start_char="6496" end_char="6560">
<ORIGINAL_TEXT>"We were surprised," said Rivera, a pediatric nurse practitioner.</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="punct" morph="none" start_char="6496" end_char="6496">"</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="6497" end_char="6498">We</TOKEN>
<TOKEN id="token-51-2" pos="word" morph="none" start_char="6500" end_char="6503">were</TOKEN>
<TOKEN id="token-51-3" pos="word" morph="none" start_char="6505" end_char="6513">surprised</TOKEN>
<TOKEN id="token-51-4" pos="punct" morph="none" start_char="6514" end_char="6515">,"</TOKEN>
<TOKEN id="token-51-5" pos="word" morph="none" start_char="6517" end_char="6520">said</TOKEN>
<TOKEN id="token-51-6" pos="word" morph="none" start_char="6522" end_char="6527">Rivera</TOKEN>
<TOKEN id="token-51-7" pos="punct" morph="none" start_char="6528" end_char="6528">,</TOKEN>
<TOKEN id="token-51-8" pos="word" morph="none" start_char="6530" end_char="6530">a</TOKEN>
<TOKEN id="token-51-9" pos="word" morph="none" start_char="6532" end_char="6540">pediatric</TOKEN>
<TOKEN id="token-51-10" pos="word" morph="none" start_char="6542" end_char="6546">nurse</TOKEN>
<TOKEN id="token-51-11" pos="word" morph="none" start_char="6548" end_char="6559">practitioner</TOKEN>
<TOKEN id="token-51-12" pos="punct" morph="none" start_char="6560" end_char="6560">.</TOKEN>
</SEG>
<SEG id="segment-52" start_char="6562" end_char="6608">
<ORIGINAL_TEXT>"The whole conversation was less than a minute.</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="punct" morph="none" start_char="6562" end_char="6562">"</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="6563" end_char="6565">The</TOKEN>
<TOKEN id="token-52-2" pos="word" morph="none" start_char="6567" end_char="6571">whole</TOKEN>
<TOKEN id="token-52-3" pos="word" morph="none" start_char="6573" end_char="6584">conversation</TOKEN>
<TOKEN id="token-52-4" pos="word" morph="none" start_char="6586" end_char="6588">was</TOKEN>
<TOKEN id="token-52-5" pos="word" morph="none" start_char="6590" end_char="6593">less</TOKEN>
<TOKEN id="token-52-6" pos="word" morph="none" start_char="6595" end_char="6598">than</TOKEN>
<TOKEN id="token-52-7" pos="word" morph="none" start_char="6600" end_char="6600">a</TOKEN>
<TOKEN id="token-52-8" pos="word" morph="none" start_char="6602" end_char="6607">minute</TOKEN>
<TOKEN id="token-52-9" pos="punct" morph="none" start_char="6608" end_char="6608">.</TOKEN>
</SEG>
<SEG id="segment-53" start_char="6610" end_char="6668">
<ORIGINAL_TEXT>There were no questions like who did you have contact with?</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="word" morph="none" start_char="6610" end_char="6614">There</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="6616" end_char="6619">were</TOKEN>
<TOKEN id="token-53-2" pos="word" morph="none" start_char="6621" end_char="6622">no</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="6624" end_char="6632">questions</TOKEN>
<TOKEN id="token-53-4" pos="word" morph="none" start_char="6634" end_char="6637">like</TOKEN>
<TOKEN id="token-53-5" pos="word" morph="none" start_char="6639" end_char="6641">who</TOKEN>
<TOKEN id="token-53-6" pos="word" morph="none" start_char="6643" end_char="6645">did</TOKEN>
<TOKEN id="token-53-7" pos="word" morph="none" start_char="6647" end_char="6649">you</TOKEN>
<TOKEN id="token-53-8" pos="word" morph="none" start_char="6651" end_char="6654">have</TOKEN>
<TOKEN id="token-53-9" pos="word" morph="none" start_char="6656" end_char="6662">contact</TOKEN>
<TOKEN id="token-53-10" pos="word" morph="none" start_char="6664" end_char="6667">with</TOKEN>
<TOKEN id="token-53-11" pos="punct" morph="none" start_char="6668" end_char="6668">?</TOKEN>
</SEG>
<SEG id="segment-54" start_char="6670" end_char="6688">
<ORIGINAL_TEXT>Did you go to work?</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="word" morph="none" start_char="6670" end_char="6672">Did</TOKEN>
<TOKEN id="token-54-1" pos="word" morph="none" start_char="6674" end_char="6676">you</TOKEN>
<TOKEN id="token-54-2" pos="word" morph="none" start_char="6678" end_char="6679">go</TOKEN>
<TOKEN id="token-54-3" pos="word" morph="none" start_char="6681" end_char="6682">to</TOKEN>
<TOKEN id="token-54-4" pos="word" morph="none" start_char="6684" end_char="6687">work</TOKEN>
<TOKEN id="token-54-5" pos="punct" morph="none" start_char="6688" end_char="6688">?</TOKEN>
</SEG>
<SEG id="segment-55" start_char="6690" end_char="6703">
<ORIGINAL_TEXT>None of that."</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="word" morph="none" start_char="6690" end_char="6693">None</TOKEN>
<TOKEN id="token-55-1" pos="word" morph="none" start_char="6695" end_char="6696">of</TOKEN>
<TOKEN id="token-55-2" pos="word" morph="none" start_char="6698" end_char="6701">that</TOKEN>
<TOKEN id="token-55-3" pos="punct" morph="none" start_char="6702" end_char="6703">."</TOKEN>
</SEG>
<SEG id="segment-56" start_char="6706" end_char="6852">
<ORIGINAL_TEXT>Eleven other people out of the 27 said they, like the Riveras, received calls from a Florida health official but were not asked for their contacts.</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="6706" end_char="6711">Eleven</TOKEN>
<TOKEN id="token-56-1" pos="word" morph="none" start_char="6713" end_char="6717">other</TOKEN>
<TOKEN id="token-56-2" pos="word" morph="none" start_char="6719" end_char="6724">people</TOKEN>
<TOKEN id="token-56-3" pos="word" morph="none" start_char="6726" end_char="6728">out</TOKEN>
<TOKEN id="token-56-4" pos="word" morph="none" start_char="6730" end_char="6731">of</TOKEN>
<TOKEN id="token-56-5" pos="word" morph="none" start_char="6733" end_char="6735">the</TOKEN>
<TOKEN id="token-56-6" pos="word" morph="none" start_char="6737" end_char="6738">27</TOKEN>
<TOKEN id="token-56-7" pos="word" morph="none" start_char="6740" end_char="6743">said</TOKEN>
<TOKEN id="token-56-8" pos="word" morph="none" start_char="6745" end_char="6748">they</TOKEN>
<TOKEN id="token-56-9" pos="punct" morph="none" start_char="6749" end_char="6749">,</TOKEN>
<TOKEN id="token-56-10" pos="word" morph="none" start_char="6751" end_char="6754">like</TOKEN>
<TOKEN id="token-56-11" pos="word" morph="none" start_char="6756" end_char="6758">the</TOKEN>
<TOKEN id="token-56-12" pos="word" morph="none" start_char="6760" end_char="6766">Riveras</TOKEN>
<TOKEN id="token-56-13" pos="punct" morph="none" start_char="6767" end_char="6767">,</TOKEN>
<TOKEN id="token-56-14" pos="word" morph="none" start_char="6769" end_char="6776">received</TOKEN>
<TOKEN id="token-56-15" pos="word" morph="none" start_char="6778" end_char="6782">calls</TOKEN>
<TOKEN id="token-56-16" pos="word" morph="none" start_char="6784" end_char="6787">from</TOKEN>
<TOKEN id="token-56-17" pos="word" morph="none" start_char="6789" end_char="6789">a</TOKEN>
<TOKEN id="token-56-18" pos="word" morph="none" start_char="6791" end_char="6797">Florida</TOKEN>
<TOKEN id="token-56-19" pos="word" morph="none" start_char="6799" end_char="6804">health</TOKEN>
<TOKEN id="token-56-20" pos="word" morph="none" start_char="6806" end_char="6813">official</TOKEN>
<TOKEN id="token-56-21" pos="word" morph="none" start_char="6815" end_char="6817">but</TOKEN>
<TOKEN id="token-56-22" pos="word" morph="none" start_char="6819" end_char="6822">were</TOKEN>
<TOKEN id="token-56-23" pos="word" morph="none" start_char="6824" end_char="6826">not</TOKEN>
<TOKEN id="token-56-24" pos="word" morph="none" start_char="6828" end_char="6832">asked</TOKEN>
<TOKEN id="token-56-25" pos="word" morph="none" start_char="6834" end_char="6836">for</TOKEN>
<TOKEN id="token-56-26" pos="word" morph="none" start_char="6838" end_char="6842">their</TOKEN>
<TOKEN id="token-56-27" pos="word" morph="none" start_char="6844" end_char="6851">contacts</TOKEN>
<TOKEN id="token-56-28" pos="punct" morph="none" start_char="6852" end_char="6852">.</TOKEN>
</SEG>
<SEG id="segment-57" start_char="6855" end_char="6920">
<ORIGINAL_TEXT>"I don't know that we can count on the state to do a thorough job.</ORIGINAL_TEXT>
<TOKEN id="token-57-0" pos="punct" morph="none" start_char="6855" end_char="6855">"</TOKEN>
<TOKEN id="token-57-1" pos="word" morph="none" start_char="6856" end_char="6856">I</TOKEN>
<TOKEN id="token-57-2" pos="word" morph="none" start_char="6858" end_char="6862">don't</TOKEN>
<TOKEN id="token-57-3" pos="word" morph="none" start_char="6864" end_char="6867">know</TOKEN>
<TOKEN id="token-57-4" pos="word" morph="none" start_char="6869" end_char="6872">that</TOKEN>
<TOKEN id="token-57-5" pos="word" morph="none" start_char="6874" end_char="6875">we</TOKEN>
<TOKEN id="token-57-6" pos="word" morph="none" start_char="6877" end_char="6879">can</TOKEN>
<TOKEN id="token-57-7" pos="word" morph="none" start_char="6881" end_char="6885">count</TOKEN>
<TOKEN id="token-57-8" pos="word" morph="none" start_char="6887" end_char="6888">on</TOKEN>
<TOKEN id="token-57-9" pos="word" morph="none" start_char="6890" end_char="6892">the</TOKEN>
<TOKEN id="token-57-10" pos="word" morph="none" start_char="6894" end_char="6898">state</TOKEN>
<TOKEN id="token-57-11" pos="word" morph="none" start_char="6900" end_char="6901">to</TOKEN>
<TOKEN id="token-57-12" pos="word" morph="none" start_char="6903" end_char="6904">do</TOKEN>
<TOKEN id="token-57-13" pos="word" morph="none" start_char="6906" end_char="6906">a</TOKEN>
<TOKEN id="token-57-14" pos="word" morph="none" start_char="6908" end_char="6915">thorough</TOKEN>
<TOKEN id="token-57-15" pos="word" morph="none" start_char="6917" end_char="6919">job</TOKEN>
<TOKEN id="token-57-16" pos="punct" morph="none" start_char="6920" end_char="6920">.</TOKEN>
</SEG>
<SEG id="segment-58" start_char="6922" end_char="6979">
<ORIGINAL_TEXT>I think there are obviously flaws in the system," he said.</ORIGINAL_TEXT>
<TOKEN id="token-58-0" pos="word" morph="none" start_char="6922" end_char="6922">I</TOKEN>
<TOKEN id="token-58-1" pos="word" morph="none" start_char="6924" end_char="6928">think</TOKEN>
<TOKEN id="token-58-2" pos="word" morph="none" start_char="6930" end_char="6934">there</TOKEN>
<TOKEN id="token-58-3" pos="word" morph="none" start_char="6936" end_char="6938">are</TOKEN>
<TOKEN id="token-58-4" pos="word" morph="none" start_char="6940" end_char="6948">obviously</TOKEN>
<TOKEN id="token-58-5" pos="word" morph="none" start_char="6950" end_char="6954">flaws</TOKEN>
<TOKEN id="token-58-6" pos="word" morph="none" start_char="6956" end_char="6957">in</TOKEN>
<TOKEN id="token-58-7" pos="word" morph="none" start_char="6959" end_char="6961">the</TOKEN>
<TOKEN id="token-58-8" pos="word" morph="none" start_char="6963" end_char="6968">system</TOKEN>
<TOKEN id="token-58-9" pos="punct" morph="none" start_char="6969" end_char="6970">,"</TOKEN>
<TOKEN id="token-58-10" pos="word" morph="none" start_char="6972" end_char="6973">he</TOKEN>
<TOKEN id="token-58-11" pos="word" morph="none" start_char="6975" end_char="6978">said</TOKEN>
<TOKEN id="token-58-12" pos="punct" morph="none" start_char="6979" end_char="6979">.</TOKEN>
</SEG>
<SEG id="segment-59" start_char="6982" end_char="7027">
<ORIGINAL_TEXT>Doubts about the usefulness of contact tracing</ORIGINAL_TEXT>
<TOKEN id="token-59-0" pos="word" morph="none" start_char="6982" end_char="6987">Doubts</TOKEN>
<TOKEN id="token-59-1" pos="word" morph="none" start_char="6989" end_char="6993">about</TOKEN>
<TOKEN id="token-59-2" pos="word" morph="none" start_char="6995" end_char="6997">the</TOKEN>
<TOKEN id="token-59-3" pos="word" morph="none" start_char="6999" end_char="7008">usefulness</TOKEN>
<TOKEN id="token-59-4" pos="word" morph="none" start_char="7010" end_char="7011">of</TOKEN>
<TOKEN id="token-59-5" pos="word" morph="none" start_char="7013" end_char="7019">contact</TOKEN>
<TOKEN id="token-59-6" pos="word" morph="none" start_char="7021" end_char="7027">tracing</TOKEN>
</SEG>
<SEG id="segment-60" start_char="7031" end_char="7206">
<ORIGINAL_TEXT>Contact tracing has been done since the very first case in the United States more than five months ago, and there are several reasons why it has failed to contain the outbreak.</ORIGINAL_TEXT>
<TOKEN id="token-60-0" pos="word" morph="none" start_char="7031" end_char="7037">Contact</TOKEN>
<TOKEN id="token-60-1" pos="word" morph="none" start_char="7039" end_char="7045">tracing</TOKEN>
<TOKEN id="token-60-2" pos="word" morph="none" start_char="7047" end_char="7049">has</TOKEN>
<TOKEN id="token-60-3" pos="word" morph="none" start_char="7051" end_char="7054">been</TOKEN>
<TOKEN id="token-60-4" pos="word" morph="none" start_char="7056" end_char="7059">done</TOKEN>
<TOKEN id="token-60-5" pos="word" morph="none" start_char="7061" end_char="7065">since</TOKEN>
<TOKEN id="token-60-6" pos="word" morph="none" start_char="7067" end_char="7069">the</TOKEN>
<TOKEN id="token-60-7" pos="word" morph="none" start_char="7071" end_char="7074">very</TOKEN>
<TOKEN id="token-60-8" pos="word" morph="none" start_char="7076" end_char="7080">first</TOKEN>
<TOKEN id="token-60-9" pos="word" morph="none" start_char="7082" end_char="7085">case</TOKEN>
<TOKEN id="token-60-10" pos="word" morph="none" start_char="7087" end_char="7088">in</TOKEN>
<TOKEN id="token-60-11" pos="word" morph="none" start_char="7090" end_char="7092">the</TOKEN>
<TOKEN id="token-60-12" pos="word" morph="none" start_char="7094" end_char="7099">United</TOKEN>
<TOKEN id="token-60-13" pos="word" morph="none" start_char="7101" end_char="7106">States</TOKEN>
<TOKEN id="token-60-14" pos="word" morph="none" start_char="7108" end_char="7111">more</TOKEN>
<TOKEN id="token-60-15" pos="word" morph="none" start_char="7113" end_char="7116">than</TOKEN>
<TOKEN id="token-60-16" pos="word" morph="none" start_char="7118" end_char="7121">five</TOKEN>
<TOKEN id="token-60-17" pos="word" morph="none" start_char="7123" end_char="7128">months</TOKEN>
<TOKEN id="token-60-18" pos="word" morph="none" start_char="7130" end_char="7132">ago</TOKEN>
<TOKEN id="token-60-19" pos="punct" morph="none" start_char="7133" end_char="7133">,</TOKEN>
<TOKEN id="token-60-20" pos="word" morph="none" start_char="7135" end_char="7137">and</TOKEN>
<TOKEN id="token-60-21" pos="word" morph="none" start_char="7139" end_char="7143">there</TOKEN>
<TOKEN id="token-60-22" pos="word" morph="none" start_char="7145" end_char="7147">are</TOKEN>
<TOKEN id="token-60-23" pos="word" morph="none" start_char="7149" end_char="7155">several</TOKEN>
<TOKEN id="token-60-24" pos="word" morph="none" start_char="7157" end_char="7163">reasons</TOKEN>
<TOKEN id="token-60-25" pos="word" morph="none" start_char="7165" end_char="7167">why</TOKEN>
<TOKEN id="token-60-26" pos="word" morph="none" start_char="7169" end_char="7170">it</TOKEN>
<TOKEN id="token-60-27" pos="word" morph="none" start_char="7172" end_char="7174">has</TOKEN>
<TOKEN id="token-60-28" pos="word" morph="none" start_char="7176" end_char="7181">failed</TOKEN>
<TOKEN id="token-60-29" pos="word" morph="none" start_char="7183" end_char="7184">to</TOKEN>
<TOKEN id="token-60-30" pos="word" morph="none" start_char="7186" end_char="7192">contain</TOKEN>
<TOKEN id="token-60-31" pos="word" morph="none" start_char="7194" end_char="7196">the</TOKEN>
<TOKEN id="token-60-32" pos="word" morph="none" start_char="7198" end_char="7205">outbreak</TOKEN>
<TOKEN id="token-60-33" pos="punct" morph="none" start_char="7206" end_char="7206">.</TOKEN>
</SEG>
<SEG id="segment-61" start_char="7209" end_char="7345">
<ORIGINAL_TEXT>First, the CDC estimates that 35% of Covid cases are asymptomatic, and those people are just as contagious as those who do have symptoms.</ORIGINAL_TEXT>
<TOKEN id="token-61-0" pos="word" morph="none" start_char="7209" end_char="7213">First</TOKEN>
<TOKEN id="token-61-1" pos="punct" morph="none" start_char="7214" end_char="7214">,</TOKEN>
<TOKEN id="token-61-2" pos="word" morph="none" start_char="7216" end_char="7218">the</TOKEN>
<TOKEN id="token-61-3" pos="word" morph="none" start_char="7220" end_char="7222">CDC</TOKEN>
<TOKEN id="token-61-4" pos="word" morph="none" start_char="7224" end_char="7232">estimates</TOKEN>
<TOKEN id="token-61-5" pos="word" morph="none" start_char="7234" end_char="7237">that</TOKEN>
<TOKEN id="token-61-6" pos="word" morph="none" start_char="7239" end_char="7240">35</TOKEN>
<TOKEN id="token-61-7" pos="punct" morph="none" start_char="7241" end_char="7241">%</TOKEN>
<TOKEN id="token-61-8" pos="word" morph="none" start_char="7243" end_char="7244">of</TOKEN>
<TOKEN id="token-61-9" pos="word" morph="none" start_char="7246" end_char="7250">Covid</TOKEN>
<TOKEN id="token-61-10" pos="word" morph="none" start_char="7252" end_char="7256">cases</TOKEN>
<TOKEN id="token-61-11" pos="word" morph="none" start_char="7258" end_char="7260">are</TOKEN>
<TOKEN id="token-61-12" pos="word" morph="none" start_char="7262" end_char="7273">asymptomatic</TOKEN>
<TOKEN id="token-61-13" pos="punct" morph="none" start_char="7274" end_char="7274">,</TOKEN>
<TOKEN id="token-61-14" pos="word" morph="none" start_char="7276" end_char="7278">and</TOKEN>
<TOKEN id="token-61-15" pos="word" morph="none" start_char="7280" end_char="7284">those</TOKEN>
<TOKEN id="token-61-16" pos="word" morph="none" start_char="7286" end_char="7291">people</TOKEN>
<TOKEN id="token-61-17" pos="word" morph="none" start_char="7293" end_char="7295">are</TOKEN>
<TOKEN id="token-61-18" pos="word" morph="none" start_char="7297" end_char="7300">just</TOKEN>
<TOKEN id="token-61-19" pos="word" morph="none" start_char="7302" end_char="7303">as</TOKEN>
<TOKEN id="token-61-20" pos="word" morph="none" start_char="7305" end_char="7314">contagious</TOKEN>
<TOKEN id="token-61-21" pos="word" morph="none" start_char="7316" end_char="7317">as</TOKEN>
<TOKEN id="token-61-22" pos="word" morph="none" start_char="7319" end_char="7323">those</TOKEN>
<TOKEN id="token-61-23" pos="word" morph="none" start_char="7325" end_char="7327">who</TOKEN>
<TOKEN id="token-61-24" pos="word" morph="none" start_char="7329" end_char="7330">do</TOKEN>
<TOKEN id="token-61-25" pos="word" morph="none" start_char="7332" end_char="7335">have</TOKEN>
<TOKEN id="token-61-26" pos="word" morph="none" start_char="7337" end_char="7344">symptoms</TOKEN>
<TOKEN id="token-61-27" pos="punct" morph="none" start_char="7345" end_char="7345">.</TOKEN>
</SEG>
<SEG id="segment-62" start_char="7348" end_char="7418">
<ORIGINAL_TEXT>"How do you do contact tracing when someone doesn't have any symptoms?"</ORIGINAL_TEXT>
<TOKEN id="token-62-0" pos="punct" morph="none" start_char="7348" end_char="7348">"</TOKEN>
<TOKEN id="token-62-1" pos="word" morph="none" start_char="7349" end_char="7351">How</TOKEN>
<TOKEN id="token-62-2" pos="word" morph="none" start_char="7353" end_char="7354">do</TOKEN>
<TOKEN id="token-62-3" pos="word" morph="none" start_char="7356" end_char="7358">you</TOKEN>
<TOKEN id="token-62-4" pos="word" morph="none" start_char="7360" end_char="7361">do</TOKEN>
<TOKEN id="token-62-5" pos="word" morph="none" start_char="7363" end_char="7369">contact</TOKEN>
<TOKEN id="token-62-6" pos="word" morph="none" start_char="7371" end_char="7377">tracing</TOKEN>
<TOKEN id="token-62-7" pos="word" morph="none" start_char="7379" end_char="7382">when</TOKEN>
<TOKEN id="token-62-8" pos="word" morph="none" start_char="7384" end_char="7390">someone</TOKEN>
<TOKEN id="token-62-9" pos="word" morph="none" start_char="7392" end_char="7398">doesn't</TOKEN>
<TOKEN id="token-62-10" pos="word" morph="none" start_char="7400" end_char="7403">have</TOKEN>
<TOKEN id="token-62-11" pos="word" morph="none" start_char="7405" end_char="7407">any</TOKEN>
<TOKEN id="token-62-12" pos="word" morph="none" start_char="7409" end_char="7416">symptoms</TOKEN>
<TOKEN id="token-62-13" pos="punct" morph="none" start_char="7417" end_char="7418">?"</TOKEN>
</SEG>
<SEG id="segment-63" start_char="7420" end_char="7456">
<ORIGINAL_TEXT>Fauci said in his interview with CNN.</ORIGINAL_TEXT>
<TOKEN id="token-63-0" pos="word" morph="none" start_char="7420" end_char="7424">Fauci</TOKEN>
<TOKEN id="token-63-1" pos="word" morph="none" start_char="7426" end_char="7429">said</TOKEN>
<TOKEN id="token-63-2" pos="word" morph="none" start_char="7431" end_char="7432">in</TOKEN>
<TOKEN id="token-63-3" pos="word" morph="none" start_char="7434" end_char="7436">his</TOKEN>
<TOKEN id="token-63-4" pos="word" morph="none" start_char="7438" end_char="7446">interview</TOKEN>
<TOKEN id="token-63-5" pos="word" morph="none" start_char="7448" end_char="7451">with</TOKEN>
<TOKEN id="token-63-6" pos="word" morph="none" start_char="7453" end_char="7455">CNN</TOKEN>
<TOKEN id="token-63-7" pos="punct" morph="none" start_char="7456" end_char="7456">.</TOKEN>
</SEG>
<SEG id="segment-64" start_char="7458" end_char="7618">
<ORIGINAL_TEXT>"The standard, classic paradigm of identification, isolation, contact tracing doesn't work no matter how good you are because you don't know who you're tracing."</ORIGINAL_TEXT>
<TOKEN id="token-64-0" pos="punct" morph="none" start_char="7458" end_char="7458">"</TOKEN>
<TOKEN id="token-64-1" pos="word" morph="none" start_char="7459" end_char="7461">The</TOKEN>
<TOKEN id="token-64-2" pos="word" morph="none" start_char="7463" end_char="7470">standard</TOKEN>
<TOKEN id="token-64-3" pos="punct" morph="none" start_char="7471" end_char="7471">,</TOKEN>
<TOKEN id="token-64-4" pos="word" morph="none" start_char="7473" end_char="7479">classic</TOKEN>
<TOKEN id="token-64-5" pos="word" morph="none" start_char="7481" end_char="7488">paradigm</TOKEN>
<TOKEN id="token-64-6" pos="word" morph="none" start_char="7490" end_char="7491">of</TOKEN>
<TOKEN id="token-64-7" pos="word" morph="none" start_char="7493" end_char="7506">identification</TOKEN>
<TOKEN id="token-64-8" pos="punct" morph="none" start_char="7507" end_char="7507">,</TOKEN>
<TOKEN id="token-64-9" pos="word" morph="none" start_char="7509" end_char="7517">isolation</TOKEN>
<TOKEN id="token-64-10" pos="punct" morph="none" start_char="7518" end_char="7518">,</TOKEN>
<TOKEN id="token-64-11" pos="word" morph="none" start_char="7520" end_char="7526">contact</TOKEN>
<TOKEN id="token-64-12" pos="word" morph="none" start_char="7528" end_char="7534">tracing</TOKEN>
<TOKEN id="token-64-13" pos="word" morph="none" start_char="7536" end_char="7542">doesn't</TOKEN>
<TOKEN id="token-64-14" pos="word" morph="none" start_char="7544" end_char="7547">work</TOKEN>
<TOKEN id="token-64-15" pos="word" morph="none" start_char="7549" end_char="7550">no</TOKEN>
<TOKEN id="token-64-16" pos="word" morph="none" start_char="7552" end_char="7557">matter</TOKEN>
<TOKEN id="token-64-17" pos="word" morph="none" start_char="7559" end_char="7561">how</TOKEN>
<TOKEN id="token-64-18" pos="word" morph="none" start_char="7563" end_char="7566">good</TOKEN>
<TOKEN id="token-64-19" pos="word" morph="none" start_char="7568" end_char="7570">you</TOKEN>
<TOKEN id="token-64-20" pos="word" morph="none" start_char="7572" end_char="7574">are</TOKEN>
<TOKEN id="token-64-21" pos="word" morph="none" start_char="7576" end_char="7582">because</TOKEN>
<TOKEN id="token-64-22" pos="word" morph="none" start_char="7584" end_char="7586">you</TOKEN>
<TOKEN id="token-64-23" pos="word" morph="none" start_char="7588" end_char="7592">don't</TOKEN>
<TOKEN id="token-64-24" pos="word" morph="none" start_char="7594" end_char="7597">know</TOKEN>
<TOKEN id="token-64-25" pos="word" morph="none" start_char="7599" end_char="7601">who</TOKEN>
<TOKEN id="token-64-26" pos="word" morph="none" start_char="7603" end_char="7608">you're</TOKEN>
<TOKEN id="token-64-27" pos="word" morph="none" start_char="7610" end_char="7616">tracing</TOKEN>
<TOKEN id="token-64-28" pos="punct" morph="none" start_char="7617" end_char="7618">."</TOKEN>
</SEG>
<SEG id="segment-65" start_char="7621" end_char="7691">
<ORIGINAL_TEXT>Also, he said some people are hesitant to talk to government officials.</ORIGINAL_TEXT>
<TOKEN id="token-65-0" pos="word" morph="none" start_char="7621" end_char="7624">Also</TOKEN>
<TOKEN id="token-65-1" pos="punct" morph="none" start_char="7625" end_char="7625">,</TOKEN>
<TOKEN id="token-65-2" pos="word" morph="none" start_char="7627" end_char="7628">he</TOKEN>
<TOKEN id="token-65-3" pos="word" morph="none" start_char="7630" end_char="7633">said</TOKEN>
<TOKEN id="token-65-4" pos="word" morph="none" start_char="7635" end_char="7638">some</TOKEN>
<TOKEN id="token-65-5" pos="word" morph="none" start_char="7640" end_char="7645">people</TOKEN>
<TOKEN id="token-65-6" pos="word" morph="none" start_char="7647" end_char="7649">are</TOKEN>
<TOKEN id="token-65-7" pos="word" morph="none" start_char="7651" end_char="7658">hesitant</TOKEN>
<TOKEN id="token-65-8" pos="word" morph="none" start_char="7660" end_char="7661">to</TOKEN>
<TOKEN id="token-65-9" pos="word" morph="none" start_char="7663" end_char="7666">talk</TOKEN>
<TOKEN id="token-65-10" pos="word" morph="none" start_char="7668" end_char="7669">to</TOKEN>
<TOKEN id="token-65-11" pos="word" morph="none" start_char="7671" end_char="7680">government</TOKEN>
<TOKEN id="token-65-12" pos="word" morph="none" start_char="7682" end_char="7690">officials</TOKEN>
<TOKEN id="token-65-13" pos="punct" morph="none" start_char="7691" end_char="7691">.</TOKEN>
</SEG>
<SEG id="segment-66" start_char="7694" end_char="7771">
<ORIGINAL_TEXT>"The dots are not connected because a lot of it is done by phone," Fauci said.</ORIGINAL_TEXT>
<TOKEN id="token-66-0" pos="punct" morph="none" start_char="7694" end_char="7694">"</TOKEN>
<TOKEN id="token-66-1" pos="word" morph="none" start_char="7695" end_char="7697">The</TOKEN>
<TOKEN id="token-66-2" pos="word" morph="none" start_char="7699" end_char="7702">dots</TOKEN>
<TOKEN id="token-66-3" pos="word" morph="none" start_char="7704" end_char="7706">are</TOKEN>
<TOKEN id="token-66-4" pos="word" morph="none" start_char="7708" end_char="7710">not</TOKEN>
<TOKEN id="token-66-5" pos="word" morph="none" start_char="7712" end_char="7720">connected</TOKEN>
<TOKEN id="token-66-6" pos="word" morph="none" start_char="7722" end_char="7728">because</TOKEN>
<TOKEN id="token-66-7" pos="word" morph="none" start_char="7730" end_char="7730">a</TOKEN>
<TOKEN id="token-66-8" pos="word" morph="none" start_char="7732" end_char="7734">lot</TOKEN>
<TOKEN id="token-66-9" pos="word" morph="none" start_char="7736" end_char="7737">of</TOKEN>
<TOKEN id="token-66-10" pos="word" morph="none" start_char="7739" end_char="7740">it</TOKEN>
<TOKEN id="token-66-11" pos="word" morph="none" start_char="7742" end_char="7743">is</TOKEN>
<TOKEN id="token-66-12" pos="word" morph="none" start_char="7745" end_char="7748">done</TOKEN>
<TOKEN id="token-66-13" pos="word" morph="none" start_char="7750" end_char="7751">by</TOKEN>
<TOKEN id="token-66-14" pos="word" morph="none" start_char="7753" end_char="7757">phone</TOKEN>
<TOKEN id="token-66-15" pos="punct" morph="none" start_char="7758" end_char="7759">,"</TOKEN>
<TOKEN id="token-66-16" pos="word" morph="none" start_char="7761" end_char="7765">Fauci</TOKEN>
<TOKEN id="token-66-17" pos="word" morph="none" start_char="7767" end_char="7770">said</TOKEN>
<TOKEN id="token-66-18" pos="punct" morph="none" start_char="7771" end_char="7771">.</TOKEN>
</SEG>
<SEG id="segment-67" start_char="7773" end_char="7874">
<ORIGINAL_TEXT>"Fifty percent of the people because you're coming from an authority, don't even want to talk to you."</ORIGINAL_TEXT>
<TOKEN id="token-67-0" pos="punct" morph="none" start_char="7773" end_char="7773">"</TOKEN>
<TOKEN id="token-67-1" pos="word" morph="none" start_char="7774" end_char="7778">Fifty</TOKEN>
<TOKEN id="token-67-2" pos="word" morph="none" start_char="7780" end_char="7786">percent</TOKEN>
<TOKEN id="token-67-3" pos="word" morph="none" start_char="7788" end_char="7789">of</TOKEN>
<TOKEN id="token-67-4" pos="word" morph="none" start_char="7791" end_char="7793">the</TOKEN>
<TOKEN id="token-67-5" pos="word" morph="none" start_char="7795" end_char="7800">people</TOKEN>
<TOKEN id="token-67-6" pos="word" morph="none" start_char="7802" end_char="7808">because</TOKEN>
<TOKEN id="token-67-7" pos="word" morph="none" start_char="7810" end_char="7815">you're</TOKEN>
<TOKEN id="token-67-8" pos="word" morph="none" start_char="7817" end_char="7822">coming</TOKEN>
<TOKEN id="token-67-9" pos="word" morph="none" start_char="7824" end_char="7827">from</TOKEN>
<TOKEN id="token-67-10" pos="word" morph="none" start_char="7829" end_char="7830">an</TOKEN>
<TOKEN id="token-67-11" pos="word" morph="none" start_char="7832" end_char="7840">authority</TOKEN>
<TOKEN id="token-67-12" pos="punct" morph="none" start_char="7841" end_char="7841">,</TOKEN>
<TOKEN id="token-67-13" pos="word" morph="none" start_char="7843" end_char="7847">don't</TOKEN>
<TOKEN id="token-67-14" pos="word" morph="none" start_char="7849" end_char="7852">even</TOKEN>
<TOKEN id="token-67-15" pos="word" morph="none" start_char="7854" end_char="7857">want</TOKEN>
<TOKEN id="token-67-16" pos="word" morph="none" start_char="7859" end_char="7860">to</TOKEN>
<TOKEN id="token-67-17" pos="word" morph="none" start_char="7862" end_char="7865">talk</TOKEN>
<TOKEN id="token-67-18" pos="word" morph="none" start_char="7867" end_char="7868">to</TOKEN>
<TOKEN id="token-67-19" pos="word" morph="none" start_char="7870" end_char="7872">you</TOKEN>
<TOKEN id="token-67-20" pos="punct" morph="none" start_char="7873" end_char="7874">."</TOKEN>
</SEG>
<SEG id="segment-68" start_char="7877" end_char="7998">
<ORIGINAL_TEXT>On top of these problems, some experts doubt the utility of contact tracing in areas like Florida where cases are spiking.</ORIGINAL_TEXT>
<TOKEN id="token-68-0" pos="word" morph="none" start_char="7877" end_char="7878">On</TOKEN>
<TOKEN id="token-68-1" pos="word" morph="none" start_char="7880" end_char="7882">top</TOKEN>
<TOKEN id="token-68-2" pos="word" morph="none" start_char="7884" end_char="7885">of</TOKEN>
<TOKEN id="token-68-3" pos="word" morph="none" start_char="7887" end_char="7891">these</TOKEN>
<TOKEN id="token-68-4" pos="word" morph="none" start_char="7893" end_char="7900">problems</TOKEN>
<TOKEN id="token-68-5" pos="punct" morph="none" start_char="7901" end_char="7901">,</TOKEN>
<TOKEN id="token-68-6" pos="word" morph="none" start_char="7903" end_char="7906">some</TOKEN>
<TOKEN id="token-68-7" pos="word" morph="none" start_char="7908" end_char="7914">experts</TOKEN>
<TOKEN id="token-68-8" pos="word" morph="none" start_char="7916" end_char="7920">doubt</TOKEN>
<TOKEN id="token-68-9" pos="word" morph="none" start_char="7922" end_char="7924">the</TOKEN>
<TOKEN id="token-68-10" pos="word" morph="none" start_char="7926" end_char="7932">utility</TOKEN>
<TOKEN id="token-68-11" pos="word" morph="none" start_char="7934" end_char="7935">of</TOKEN>
<TOKEN id="token-68-12" pos="word" morph="none" start_char="7937" end_char="7943">contact</TOKEN>
<TOKEN id="token-68-13" pos="word" morph="none" start_char="7945" end_char="7951">tracing</TOKEN>
<TOKEN id="token-68-14" pos="word" morph="none" start_char="7953" end_char="7954">in</TOKEN>
<TOKEN id="token-68-15" pos="word" morph="none" start_char="7956" end_char="7960">areas</TOKEN>
<TOKEN id="token-68-16" pos="word" morph="none" start_char="7962" end_char="7965">like</TOKEN>
<TOKEN id="token-68-17" pos="word" morph="none" start_char="7967" end_char="7973">Florida</TOKEN>
<TOKEN id="token-68-18" pos="word" morph="none" start_char="7975" end_char="7979">where</TOKEN>
<TOKEN id="token-68-19" pos="word" morph="none" start_char="7981" end_char="7985">cases</TOKEN>
<TOKEN id="token-68-20" pos="word" morph="none" start_char="7987" end_char="7989">are</TOKEN>
<TOKEN id="token-68-21" pos="word" morph="none" start_char="7991" end_char="7997">spiking</TOKEN>
<TOKEN id="token-68-22" pos="punct" morph="none" start_char="7998" end_char="7998">.</TOKEN>
</SEG>
<SEG id="segment-69" start_char="8001" end_char="8135">
<ORIGINAL_TEXT>Epidemiologist Michael Osterholm urged Florida leaders to focus on other strategies, such as figuring out where the virus is spreading.</ORIGINAL_TEXT>
<TOKEN id="token-69-0" pos="word" morph="none" start_char="8001" end_char="8014">Epidemiologist</TOKEN>
<TOKEN id="token-69-1" pos="word" morph="none" start_char="8016" end_char="8022">Michael</TOKEN>
<TOKEN id="token-69-2" pos="word" morph="none" start_char="8024" end_char="8032">Osterholm</TOKEN>
<TOKEN id="token-69-3" pos="word" morph="none" start_char="8034" end_char="8038">urged</TOKEN>
<TOKEN id="token-69-4" pos="word" morph="none" start_char="8040" end_char="8046">Florida</TOKEN>
<TOKEN id="token-69-5" pos="word" morph="none" start_char="8048" end_char="8054">leaders</TOKEN>
<TOKEN id="token-69-6" pos="word" morph="none" start_char="8056" end_char="8057">to</TOKEN>
<TOKEN id="token-69-7" pos="word" morph="none" start_char="8059" end_char="8063">focus</TOKEN>
<TOKEN id="token-69-8" pos="word" morph="none" start_char="8065" end_char="8066">on</TOKEN>
<TOKEN id="token-69-9" pos="word" morph="none" start_char="8068" end_char="8072">other</TOKEN>
<TOKEN id="token-69-10" pos="word" morph="none" start_char="8074" end_char="8083">strategies</TOKEN>
<TOKEN id="token-69-11" pos="punct" morph="none" start_char="8084" end_char="8084">,</TOKEN>
<TOKEN id="token-69-12" pos="word" morph="none" start_char="8086" end_char="8089">such</TOKEN>
<TOKEN id="token-69-13" pos="word" morph="none" start_char="8091" end_char="8092">as</TOKEN>
<TOKEN id="token-69-14" pos="word" morph="none" start_char="8094" end_char="8101">figuring</TOKEN>
<TOKEN id="token-69-15" pos="word" morph="none" start_char="8103" end_char="8105">out</TOKEN>
<TOKEN id="token-69-16" pos="word" morph="none" start_char="8107" end_char="8111">where</TOKEN>
<TOKEN id="token-69-17" pos="word" morph="none" start_char="8113" end_char="8115">the</TOKEN>
<TOKEN id="token-69-18" pos="word" morph="none" start_char="8117" end_char="8121">virus</TOKEN>
<TOKEN id="token-69-19" pos="word" morph="none" start_char="8123" end_char="8124">is</TOKEN>
<TOKEN id="token-69-20" pos="word" morph="none" start_char="8126" end_char="8134">spreading</TOKEN>
<TOKEN id="token-69-21" pos="punct" morph="none" start_char="8135" end_char="8135">.</TOKEN>
</SEG>
<SEG id="segment-70" start_char="8138" end_char="8393">
<ORIGINAL_TEXT>"For example, if young adults in bars are the issue, you've got to shut those bars down," said Osterholm, director of the Center for Infectious Disease Research and Policy at the University of Minnesota, which recently released a report on contact tracing.</ORIGINAL_TEXT>
<TOKEN id="token-70-0" pos="punct" morph="none" start_char="8138" end_char="8138">"</TOKEN>
<TOKEN id="token-70-1" pos="word" morph="none" start_char="8139" end_char="8141">For</TOKEN>
<TOKEN id="token-70-2" pos="word" morph="none" start_char="8143" end_char="8149">example</TOKEN>
<TOKEN id="token-70-3" pos="punct" morph="none" start_char="8150" end_char="8150">,</TOKEN>
<TOKEN id="token-70-4" pos="word" morph="none" start_char="8152" end_char="8153">if</TOKEN>
<TOKEN id="token-70-5" pos="word" morph="none" start_char="8155" end_char="8159">young</TOKEN>
<TOKEN id="token-70-6" pos="word" morph="none" start_char="8161" end_char="8166">adults</TOKEN>
<TOKEN id="token-70-7" pos="word" morph="none" start_char="8168" end_char="8169">in</TOKEN>
<TOKEN id="token-70-8" pos="word" morph="none" start_char="8171" end_char="8174">bars</TOKEN>
<TOKEN id="token-70-9" pos="word" morph="none" start_char="8176" end_char="8178">are</TOKEN>
<TOKEN id="token-70-10" pos="word" morph="none" start_char="8180" end_char="8182">the</TOKEN>
<TOKEN id="token-70-11" pos="word" morph="none" start_char="8184" end_char="8188">issue</TOKEN>
<TOKEN id="token-70-12" pos="punct" morph="none" start_char="8189" end_char="8189">,</TOKEN>
<TOKEN id="token-70-13" pos="word" morph="none" start_char="8191" end_char="8196">you've</TOKEN>
<TOKEN id="token-70-14" pos="word" morph="none" start_char="8198" end_char="8200">got</TOKEN>
<TOKEN id="token-70-15" pos="word" morph="none" start_char="8202" end_char="8203">to</TOKEN>
<TOKEN id="token-70-16" pos="word" morph="none" start_char="8205" end_char="8208">shut</TOKEN>
<TOKEN id="token-70-17" pos="word" morph="none" start_char="8210" end_char="8214">those</TOKEN>
<TOKEN id="token-70-18" pos="word" morph="none" start_char="8216" end_char="8219">bars</TOKEN>
<TOKEN id="token-70-19" pos="word" morph="none" start_char="8221" end_char="8224">down</TOKEN>
<TOKEN id="token-70-20" pos="punct" morph="none" start_char="8225" end_char="8226">,"</TOKEN>
<TOKEN id="token-70-21" pos="word" morph="none" start_char="8228" end_char="8231">said</TOKEN>
<TOKEN id="token-70-22" pos="word" morph="none" start_char="8233" end_char="8241">Osterholm</TOKEN>
<TOKEN id="token-70-23" pos="punct" morph="none" start_char="8242" end_char="8242">,</TOKEN>
<TOKEN id="token-70-24" pos="word" morph="none" start_char="8244" end_char="8251">director</TOKEN>
<TOKEN id="token-70-25" pos="word" morph="none" start_char="8253" end_char="8254">of</TOKEN>
<TOKEN id="token-70-26" pos="word" morph="none" start_char="8256" end_char="8258">the</TOKEN>
<TOKEN id="token-70-27" pos="word" morph="none" start_char="8260" end_char="8265">Center</TOKEN>
<TOKEN id="token-70-28" pos="word" morph="none" start_char="8267" end_char="8269">for</TOKEN>
<TOKEN id="token-70-29" pos="word" morph="none" start_char="8271" end_char="8280">Infectious</TOKEN>
<TOKEN id="token-70-30" pos="word" morph="none" start_char="8282" end_char="8288">Disease</TOKEN>
<TOKEN id="token-70-31" pos="word" morph="none" start_char="8290" end_char="8297">Research</TOKEN>
<TOKEN id="token-70-32" pos="word" morph="none" start_char="8299" end_char="8301">and</TOKEN>
<TOKEN id="token-70-33" pos="word" morph="none" start_char="8303" end_char="8308">Policy</TOKEN>
<TOKEN id="token-70-34" pos="word" morph="none" start_char="8310" end_char="8311">at</TOKEN>
<TOKEN id="token-70-35" pos="word" morph="none" start_char="8313" end_char="8315">the</TOKEN>
<TOKEN id="token-70-36" pos="word" morph="none" start_char="8317" end_char="8326">University</TOKEN>
<TOKEN id="token-70-37" pos="word" morph="none" start_char="8328" end_char="8329">of</TOKEN>
<TOKEN id="token-70-38" pos="word" morph="none" start_char="8331" end_char="8339">Minnesota</TOKEN>
<TOKEN id="token-70-39" pos="punct" morph="none" start_char="8340" end_char="8340">,</TOKEN>
<TOKEN id="token-70-40" pos="word" morph="none" start_char="8342" end_char="8346">which</TOKEN>
<TOKEN id="token-70-41" pos="word" morph="none" start_char="8348" end_char="8355">recently</TOKEN>
<TOKEN id="token-70-42" pos="word" morph="none" start_char="8357" end_char="8364">released</TOKEN>
<TOKEN id="token-70-43" pos="word" morph="none" start_char="8366" end_char="8366">a</TOKEN>
<TOKEN id="token-70-44" pos="word" morph="none" start_char="8368" end_char="8373">report</TOKEN>
<TOKEN id="token-70-45" pos="word" morph="none" start_char="8375" end_char="8376">on</TOKEN>
<TOKEN id="token-70-46" pos="word" morph="none" start_char="8378" end_char="8384">contact</TOKEN>
<TOKEN id="token-70-47" pos="word" morph="none" start_char="8386" end_char="8392">tracing</TOKEN>
<TOKEN id="token-70-48" pos="punct" morph="none" start_char="8393" end_char="8393">.</TOKEN>
</SEG>
<SEG id="segment-71" start_char="8396" end_char="8509">
<ORIGINAL_TEXT>With thousands of new cases a day in Florida, Osterholm doubted that contact tracing would have much of an effect.</ORIGINAL_TEXT>
<TOKEN id="token-71-0" pos="word" morph="none" start_char="8396" end_char="8399">With</TOKEN>
<TOKEN id="token-71-1" pos="word" morph="none" start_char="8401" end_char="8409">thousands</TOKEN>
<TOKEN id="token-71-2" pos="word" morph="none" start_char="8411" end_char="8412">of</TOKEN>
<TOKEN id="token-71-3" pos="word" morph="none" start_char="8414" end_char="8416">new</TOKEN>
<TOKEN id="token-71-4" pos="word" morph="none" start_char="8418" end_char="8422">cases</TOKEN>
<TOKEN id="token-71-5" pos="word" morph="none" start_char="8424" end_char="8424">a</TOKEN>
<TOKEN id="token-71-6" pos="word" morph="none" start_char="8426" end_char="8428">day</TOKEN>
<TOKEN id="token-71-7" pos="word" morph="none" start_char="8430" end_char="8431">in</TOKEN>
<TOKEN id="token-71-8" pos="word" morph="none" start_char="8433" end_char="8439">Florida</TOKEN>
<TOKEN id="token-71-9" pos="punct" morph="none" start_char="8440" end_char="8440">,</TOKEN>
<TOKEN id="token-71-10" pos="word" morph="none" start_char="8442" end_char="8450">Osterholm</TOKEN>
<TOKEN id="token-71-11" pos="word" morph="none" start_char="8452" end_char="8458">doubted</TOKEN>
<TOKEN id="token-71-12" pos="word" morph="none" start_char="8460" end_char="8463">that</TOKEN>
<TOKEN id="token-71-13" pos="word" morph="none" start_char="8465" end_char="8471">contact</TOKEN>
<TOKEN id="token-71-14" pos="word" morph="none" start_char="8473" end_char="8479">tracing</TOKEN>
<TOKEN id="token-71-15" pos="word" morph="none" start_char="8481" end_char="8485">would</TOKEN>
<TOKEN id="token-71-16" pos="word" morph="none" start_char="8487" end_char="8490">have</TOKEN>
<TOKEN id="token-71-17" pos="word" morph="none" start_char="8492" end_char="8495">much</TOKEN>
<TOKEN id="token-71-18" pos="word" morph="none" start_char="8497" end_char="8498">of</TOKEN>
<TOKEN id="token-71-19" pos="word" morph="none" start_char="8500" end_char="8501">an</TOKEN>
<TOKEN id="token-71-20" pos="word" morph="none" start_char="8503" end_char="8508">effect</TOKEN>
<TOKEN id="token-71-21" pos="punct" morph="none" start_char="8509" end_char="8509">.</TOKEN>
</SEG>
<SEG id="segment-72" start_char="8512" end_char="8600">
<ORIGINAL_TEXT>"If Florida could get back under 50 to 100 cases a day, contact tracing could be helpful.</ORIGINAL_TEXT>
<TOKEN id="token-72-0" pos="punct" morph="none" start_char="8512" end_char="8512">"</TOKEN>
<TOKEN id="token-72-1" pos="word" morph="none" start_char="8513" end_char="8514">If</TOKEN>
<TOKEN id="token-72-2" pos="word" morph="none" start_char="8516" end_char="8522">Florida</TOKEN>
<TOKEN id="token-72-3" pos="word" morph="none" start_char="8524" end_char="8528">could</TOKEN>
<TOKEN id="token-72-4" pos="word" morph="none" start_char="8530" end_char="8532">get</TOKEN>
<TOKEN id="token-72-5" pos="word" morph="none" start_char="8534" end_char="8537">back</TOKEN>
<TOKEN id="token-72-6" pos="word" morph="none" start_char="8539" end_char="8543">under</TOKEN>
<TOKEN id="token-72-7" pos="word" morph="none" start_char="8545" end_char="8546">50</TOKEN>
<TOKEN id="token-72-8" pos="word" morph="none" start_char="8548" end_char="8549">to</TOKEN>
<TOKEN id="token-72-9" pos="word" morph="none" start_char="8551" end_char="8553">100</TOKEN>
<TOKEN id="token-72-10" pos="word" morph="none" start_char="8555" end_char="8559">cases</TOKEN>
<TOKEN id="token-72-11" pos="word" morph="none" start_char="8561" end_char="8561">a</TOKEN>
<TOKEN id="token-72-12" pos="word" morph="none" start_char="8563" end_char="8565">day</TOKEN>
<TOKEN id="token-72-13" pos="punct" morph="none" start_char="8566" end_char="8566">,</TOKEN>
<TOKEN id="token-72-14" pos="word" morph="none" start_char="8568" end_char="8574">contact</TOKEN>
<TOKEN id="token-72-15" pos="word" morph="none" start_char="8576" end_char="8582">tracing</TOKEN>
<TOKEN id="token-72-16" pos="word" morph="none" start_char="8584" end_char="8588">could</TOKEN>
<TOKEN id="token-72-17" pos="word" morph="none" start_char="8590" end_char="8591">be</TOKEN>
<TOKEN id="token-72-18" pos="word" morph="none" start_char="8593" end_char="8599">helpful</TOKEN>
<TOKEN id="token-72-19" pos="punct" morph="none" start_char="8600" end_char="8600">.</TOKEN>
</SEG>
<SEG id="segment-73" start_char="8602" end_char="8672">
<ORIGINAL_TEXT>But right now, it's not likely to have any measurable impact," he said.</ORIGINAL_TEXT>
<TOKEN id="token-73-0" pos="word" morph="none" start_char="8602" end_char="8604">But</TOKEN>
<TOKEN id="token-73-1" pos="word" morph="none" start_char="8606" end_char="8610">right</TOKEN>
<TOKEN id="token-73-2" pos="word" morph="none" start_char="8612" end_char="8614">now</TOKEN>
<TOKEN id="token-73-3" pos="punct" morph="none" start_char="8615" end_char="8615">,</TOKEN>
<TOKEN id="token-73-4" pos="word" morph="none" start_char="8617" end_char="8620">it's</TOKEN>
<TOKEN id="token-73-5" pos="word" morph="none" start_char="8622" end_char="8624">not</TOKEN>
<TOKEN id="token-73-6" pos="word" morph="none" start_char="8626" end_char="8631">likely</TOKEN>
<TOKEN id="token-73-7" pos="word" morph="none" start_char="8633" end_char="8634">to</TOKEN>
<TOKEN id="token-73-8" pos="word" morph="none" start_char="8636" end_char="8639">have</TOKEN>
<TOKEN id="token-73-9" pos="word" morph="none" start_char="8641" end_char="8643">any</TOKEN>
<TOKEN id="token-73-10" pos="word" morph="none" start_char="8645" end_char="8654">measurable</TOKEN>
<TOKEN id="token-73-11" pos="word" morph="none" start_char="8656" end_char="8661">impact</TOKEN>
<TOKEN id="token-73-12" pos="punct" morph="none" start_char="8662" end_char="8663">,"</TOKEN>
<TOKEN id="token-73-13" pos="word" morph="none" start_char="8665" end_char="8666">he</TOKEN>
<TOKEN id="token-73-14" pos="word" morph="none" start_char="8668" end_char="8671">said</TOKEN>
<TOKEN id="token-73-15" pos="punct" morph="none" start_char="8672" end_char="8672">.</TOKEN>
</SEG>
<SEG id="segment-74" start_char="8674" end_char="8741">
<ORIGINAL_TEXT>"It's like trying to put out a forest fire with a single fire truck.</ORIGINAL_TEXT>
<TOKEN id="token-74-0" pos="punct" morph="none" start_char="8674" end_char="8674">"</TOKEN>
<TOKEN id="token-74-1" pos="word" morph="none" start_char="8675" end_char="8678">It's</TOKEN>
<TOKEN id="token-74-2" pos="word" morph="none" start_char="8680" end_char="8683">like</TOKEN>
<TOKEN id="token-74-3" pos="word" morph="none" start_char="8685" end_char="8690">trying</TOKEN>
<TOKEN id="token-74-4" pos="word" morph="none" start_char="8692" end_char="8693">to</TOKEN>
<TOKEN id="token-74-5" pos="word" morph="none" start_char="8695" end_char="8697">put</TOKEN>
<TOKEN id="token-74-6" pos="word" morph="none" start_char="8699" end_char="8701">out</TOKEN>
<TOKEN id="token-74-7" pos="word" morph="none" start_char="8703" end_char="8703">a</TOKEN>
<TOKEN id="token-74-8" pos="word" morph="none" start_char="8705" end_char="8710">forest</TOKEN>
<TOKEN id="token-74-9" pos="word" morph="none" start_char="8712" end_char="8715">fire</TOKEN>
<TOKEN id="token-74-10" pos="word" morph="none" start_char="8717" end_char="8720">with</TOKEN>
<TOKEN id="token-74-11" pos="word" morph="none" start_char="8722" end_char="8722">a</TOKEN>
<TOKEN id="token-74-12" pos="word" morph="none" start_char="8724" end_char="8729">single</TOKEN>
<TOKEN id="token-74-13" pos="word" morph="none" start_char="8731" end_char="8734">fire</TOKEN>
<TOKEN id="token-74-14" pos="word" morph="none" start_char="8736" end_char="8740">truck</TOKEN>
<TOKEN id="token-74-15" pos="punct" morph="none" start_char="8741" end_char="8741">.</TOKEN>
</SEG>
<SEG id="segment-75" start_char="8743" end_char="8769">
<ORIGINAL_TEXT>It just won't make a dent."</ORIGINAL_TEXT>
<TOKEN id="token-75-0" pos="word" morph="none" start_char="8743" end_char="8744">It</TOKEN>
<TOKEN id="token-75-1" pos="word" morph="none" start_char="8746" end_char="8749">just</TOKEN>
<TOKEN id="token-75-2" pos="word" morph="none" start_char="8751" end_char="8755">won't</TOKEN>
<TOKEN id="token-75-3" pos="word" morph="none" start_char="8757" end_char="8760">make</TOKEN>
<TOKEN id="token-75-4" pos="word" morph="none" start_char="8762" end_char="8762">a</TOKEN>
<TOKEN id="token-75-5" pos="word" morph="none" start_char="8764" end_char="8767">dent</TOKEN>
<TOKEN id="token-75-6" pos="punct" morph="none" start_char="8768" end_char="8769">."</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
