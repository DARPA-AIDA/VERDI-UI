<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CVMX" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="10826" raw_text_md5="11d6e81e419cfa6d065592d160a688e7">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="33">
<ORIGINAL_TEXT>Is Favipiravir Good for COVID-19?</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="2">Is</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="4" end_char="14">Favipiravir</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="16" end_char="19">Good</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="21" end_char="23">for</TOKEN>
<TOKEN id="token-0-4" pos="unknown" morph="none" start_char="25" end_char="32">COVID-19</TOKEN>
<TOKEN id="token-0-5" pos="punct" morph="none" start_char="33" end_char="33">?</TOKEN>
</SEG>
<SEG id="segment-1" start_char="35" end_char="80">
<ORIGINAL_TEXT>Clinical Trial Says No, Press Release Says Yes</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="35" end_char="42">Clinical</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="44" end_char="48">Trial</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="50" end_char="53">Says</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="55" end_char="56">No</TOKEN>
<TOKEN id="token-1-4" pos="punct" morph="none" start_char="57" end_char="57">,</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="59" end_char="63">Press</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="65" end_char="71">Release</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="73" end_char="76">Says</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="78" end_char="80">Yes</TOKEN>
</SEG>
<SEG id="segment-2" start_char="84" end_char="143">
<ORIGINAL_TEXT>A representative photo of various drugs littered on a table.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="84" end_char="84">A</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="86" end_char="99">representative</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="101" end_char="105">photo</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="107" end_char="108">of</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="110" end_char="116">various</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="118" end_char="122">drugs</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="124" end_char="131">littered</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="133" end_char="134">on</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="136" end_char="136">a</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="138" end_char="142">table</TOKEN>
<TOKEN id="token-2-10" pos="punct" morph="none" start_char="143" end_char="143">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="145" end_char="170">
<ORIGINAL_TEXT>Photo: Anna Shvets/Pexels.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="145" end_char="149">Photo</TOKEN>
<TOKEN id="token-3-1" pos="punct" morph="none" start_char="150" end_char="150">:</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="152" end_char="155">Anna</TOKEN>
<TOKEN id="token-3-3" pos="unknown" morph="none" start_char="157" end_char="169">Shvets/Pexels</TOKEN>
<TOKEN id="token-3-4" pos="punct" morph="none" start_char="170" end_char="170">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="174" end_char="392">
<ORIGINAL_TEXT>Bengaluru: Medical experts have accused the Mumbai-based Glenmark Pharmaceuticals of cherrypicking the results of its phase 3 clinical trials to claim that its antiviral drug, favipiravir, is effective against COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="174" end_char="182">Bengaluru</TOKEN>
<TOKEN id="token-4-1" pos="punct" morph="none" start_char="183" end_char="183">:</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="185" end_char="191">Medical</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="193" end_char="199">experts</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="201" end_char="204">have</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="206" end_char="212">accused</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="214" end_char="216">the</TOKEN>
<TOKEN id="token-4-7" pos="unknown" morph="none" start_char="218" end_char="229">Mumbai-based</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="231" end_char="238">Glenmark</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="240" end_char="254">Pharmaceuticals</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="256" end_char="257">of</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="259" end_char="271">cherrypicking</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="273" end_char="275">the</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="277" end_char="283">results</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="285" end_char="286">of</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="288" end_char="290">its</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="292" end_char="296">phase</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="298" end_char="298">3</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="300" end_char="307">clinical</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="309" end_char="314">trials</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="316" end_char="317">to</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="319" end_char="323">claim</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="325" end_char="328">that</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="330" end_char="332">its</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="334" end_char="342">antiviral</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="344" end_char="347">drug</TOKEN>
<TOKEN id="token-4-26" pos="punct" morph="none" start_char="348" end_char="348">,</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="350" end_char="360">favipiravir</TOKEN>
<TOKEN id="token-4-28" pos="punct" morph="none" start_char="361" end_char="361">,</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="363" end_char="364">is</TOKEN>
<TOKEN id="token-4-30" pos="word" morph="none" start_char="366" end_char="374">effective</TOKEN>
<TOKEN id="token-4-31" pos="word" morph="none" start_char="376" end_char="382">against</TOKEN>
<TOKEN id="token-4-32" pos="unknown" morph="none" start_char="384" end_char="391">COVID-19</TOKEN>
<TOKEN id="token-4-33" pos="punct" morph="none" start_char="392" end_char="392">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="394" end_char="538">
<ORIGINAL_TEXT>While the Indian drug regulator approved the drug based on the trial in June, the company only published the trial’s full results on November 16.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="394" end_char="398">While</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="400" end_char="402">the</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="404" end_char="409">Indian</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="411" end_char="414">drug</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="416" end_char="424">regulator</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="426" end_char="433">approved</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="435" end_char="437">the</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="439" end_char="442">drug</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="444" end_char="448">based</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="450" end_char="451">on</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="453" end_char="455">the</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="457" end_char="461">trial</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="463" end_char="464">in</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="466" end_char="469">June</TOKEN>
<TOKEN id="token-5-14" pos="punct" morph="none" start_char="470" end_char="470">,</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="472" end_char="474">the</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="476" end_char="482">company</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="484" end_char="487">only</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="489" end_char="497">published</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="499" end_char="501">the</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="503" end_char="509">trial’s</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="511" end_char="514">full</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="516" end_char="522">results</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="524" end_char="525">on</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="527" end_char="534">November</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="536" end_char="537">16</TOKEN>
<TOKEN id="token-5-26" pos="punct" morph="none" start_char="538" end_char="538">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="540" end_char="658">
<ORIGINAL_TEXT>And experts pointed out that the full results don’t bear out the efficacy claims that Glenmark has made about the drug.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="540" end_char="542">And</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="544" end_char="550">experts</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="552" end_char="558">pointed</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="560" end_char="562">out</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="564" end_char="567">that</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="569" end_char="571">the</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="573" end_char="576">full</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="578" end_char="584">results</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="586" end_char="590">don’t</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="592" end_char="595">bear</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="597" end_char="599">out</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="601" end_char="603">the</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="605" end_char="612">efficacy</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="614" end_char="619">claims</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="621" end_char="624">that</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="626" end_char="633">Glenmark</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="635" end_char="637">has</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="639" end_char="642">made</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="644" end_char="648">about</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="650" end_char="652">the</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="654" end_char="657">drug</TOKEN>
<TOKEN id="token-6-21" pos="punct" morph="none" start_char="658" end_char="658">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="661" end_char="941">
<ORIGINAL_TEXT>Since the drug’s approval, the company has headlined two press releases (here and here) about the trial with the claim that favipiravir recipients were cured of COVID-19’s signs faster than those who received standard of care, and that the difference was statistically significant.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="661" end_char="665">Since</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="667" end_char="669">the</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="671" end_char="676">drug’s</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="678" end_char="685">approval</TOKEN>
<TOKEN id="token-7-4" pos="punct" morph="none" start_char="686" end_char="686">,</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="688" end_char="690">the</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="692" end_char="698">company</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="700" end_char="702">has</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="704" end_char="712">headlined</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="714" end_char="716">two</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="718" end_char="722">press</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="724" end_char="731">releases</TOKEN>
<TOKEN id="token-7-12" pos="punct" morph="none" start_char="733" end_char="733">(</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="734" end_char="737">here</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="739" end_char="741">and</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="743" end_char="746">here</TOKEN>
<TOKEN id="token-7-16" pos="punct" morph="none" start_char="747" end_char="747">)</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="749" end_char="753">about</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="755" end_char="757">the</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="759" end_char="763">trial</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="765" end_char="768">with</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="770" end_char="772">the</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="774" end_char="778">claim</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="780" end_char="783">that</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="785" end_char="795">favipiravir</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="797" end_char="806">recipients</TOKEN>
<TOKEN id="token-7-26" pos="word" morph="none" start_char="808" end_char="811">were</TOKEN>
<TOKEN id="token-7-27" pos="word" morph="none" start_char="813" end_char="817">cured</TOKEN>
<TOKEN id="token-7-28" pos="word" morph="none" start_char="819" end_char="820">of</TOKEN>
<TOKEN id="token-7-29" pos="unknown" morph="none" start_char="822" end_char="831">COVID-19’s</TOKEN>
<TOKEN id="token-7-30" pos="word" morph="none" start_char="833" end_char="837">signs</TOKEN>
<TOKEN id="token-7-31" pos="word" morph="none" start_char="839" end_char="844">faster</TOKEN>
<TOKEN id="token-7-32" pos="word" morph="none" start_char="846" end_char="849">than</TOKEN>
<TOKEN id="token-7-33" pos="word" morph="none" start_char="851" end_char="855">those</TOKEN>
<TOKEN id="token-7-34" pos="word" morph="none" start_char="857" end_char="859">who</TOKEN>
<TOKEN id="token-7-35" pos="word" morph="none" start_char="861" end_char="868">received</TOKEN>
<TOKEN id="token-7-36" pos="word" morph="none" start_char="870" end_char="877">standard</TOKEN>
<TOKEN id="token-7-37" pos="word" morph="none" start_char="879" end_char="880">of</TOKEN>
<TOKEN id="token-7-38" pos="word" morph="none" start_char="882" end_char="885">care</TOKEN>
<TOKEN id="token-7-39" pos="punct" morph="none" start_char="886" end_char="886">,</TOKEN>
<TOKEN id="token-7-40" pos="word" morph="none" start_char="888" end_char="890">and</TOKEN>
<TOKEN id="token-7-41" pos="word" morph="none" start_char="892" end_char="895">that</TOKEN>
<TOKEN id="token-7-42" pos="word" morph="none" start_char="897" end_char="899">the</TOKEN>
<TOKEN id="token-7-43" pos="word" morph="none" start_char="901" end_char="910">difference</TOKEN>
<TOKEN id="token-7-44" pos="word" morph="none" start_char="912" end_char="914">was</TOKEN>
<TOKEN id="token-7-45" pos="word" morph="none" start_char="916" end_char="928">statistically</TOKEN>
<TOKEN id="token-7-46" pos="word" morph="none" start_char="930" end_char="940">significant</TOKEN>
<TOKEN id="token-7-47" pos="punct" morph="none" start_char="941" end_char="941">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="943" end_char="1176">
<ORIGINAL_TEXT>These press releases also said patients in the favipiravir arm cleared the virus faster (as measured by how quickly patients turned negative on an RT-PCR test) than controls, although this difference was not statistically significant.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="943" end_char="947">These</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="949" end_char="953">press</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="955" end_char="962">releases</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="964" end_char="967">also</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="969" end_char="972">said</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="974" end_char="981">patients</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="983" end_char="984">in</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="986" end_char="988">the</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="990" end_char="1000">favipiravir</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1002" end_char="1004">arm</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1006" end_char="1012">cleared</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1014" end_char="1016">the</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1018" end_char="1022">virus</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1024" end_char="1029">faster</TOKEN>
<TOKEN id="token-8-14" pos="punct" morph="none" start_char="1031" end_char="1031">(</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1032" end_char="1033">as</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1035" end_char="1042">measured</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1044" end_char="1045">by</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1047" end_char="1049">how</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1051" end_char="1057">quickly</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="1059" end_char="1066">patients</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="1068" end_char="1073">turned</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="1075" end_char="1082">negative</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="1084" end_char="1085">on</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="1087" end_char="1088">an</TOKEN>
<TOKEN id="token-8-25" pos="unknown" morph="none" start_char="1090" end_char="1095">RT-PCR</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="1097" end_char="1100">test</TOKEN>
<TOKEN id="token-8-27" pos="punct" morph="none" start_char="1101" end_char="1101">)</TOKEN>
<TOKEN id="token-8-28" pos="word" morph="none" start_char="1103" end_char="1106">than</TOKEN>
<TOKEN id="token-8-29" pos="word" morph="none" start_char="1108" end_char="1115">controls</TOKEN>
<TOKEN id="token-8-30" pos="punct" morph="none" start_char="1116" end_char="1116">,</TOKEN>
<TOKEN id="token-8-31" pos="word" morph="none" start_char="1118" end_char="1125">although</TOKEN>
<TOKEN id="token-8-32" pos="word" morph="none" start_char="1127" end_char="1130">this</TOKEN>
<TOKEN id="token-8-33" pos="word" morph="none" start_char="1132" end_char="1141">difference</TOKEN>
<TOKEN id="token-8-34" pos="word" morph="none" start_char="1143" end_char="1145">was</TOKEN>
<TOKEN id="token-8-35" pos="word" morph="none" start_char="1147" end_char="1149">not</TOKEN>
<TOKEN id="token-8-36" pos="word" morph="none" start_char="1151" end_char="1163">statistically</TOKEN>
<TOKEN id="token-8-37" pos="word" morph="none" start_char="1165" end_char="1175">significant</TOKEN>
<TOKEN id="token-8-38" pos="punct" morph="none" start_char="1176" end_char="1176">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1179" end_char="1367">
<ORIGINAL_TEXT>According to Glenmark and the trial’s principal investigator, Mumbai based pulmonologist Zarir Udwadia, these findings together showed that favipiravir can treat mild and moderate COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1179" end_char="1187">According</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1189" end_char="1190">to</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1192" end_char="1199">Glenmark</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1201" end_char="1203">and</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1205" end_char="1207">the</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1209" end_char="1215">trial’s</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1217" end_char="1225">principal</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1227" end_char="1238">investigator</TOKEN>
<TOKEN id="token-9-8" pos="punct" morph="none" start_char="1239" end_char="1239">,</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1241" end_char="1246">Mumbai</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1248" end_char="1252">based</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1254" end_char="1266">pulmonologist</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1268" end_char="1272">Zarir</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1274" end_char="1280">Udwadia</TOKEN>
<TOKEN id="token-9-14" pos="punct" morph="none" start_char="1281" end_char="1281">,</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1283" end_char="1287">these</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1289" end_char="1296">findings</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1298" end_char="1305">together</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1307" end_char="1312">showed</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1314" end_char="1317">that</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1319" end_char="1329">favipiravir</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1331" end_char="1333">can</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1335" end_char="1339">treat</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1341" end_char="1344">mild</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1346" end_char="1348">and</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1350" end_char="1357">moderate</TOKEN>
<TOKEN id="token-9-26" pos="unknown" morph="none" start_char="1359" end_char="1366">COVID-19</TOKEN>
<TOKEN id="token-9-27" pos="punct" morph="none" start_char="1367" end_char="1367">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1370" end_char="1569">
<ORIGINAL_TEXT>But critics have countered that the faster viral clearance in the favipiravir arm was not statistically significant, which means, strictly speaking, that the drug failed to show efficacy in the trial.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1370" end_char="1372">But</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1374" end_char="1380">critics</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1382" end_char="1385">have</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1387" end_char="1395">countered</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1397" end_char="1400">that</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1402" end_char="1404">the</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1406" end_char="1411">faster</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1413" end_char="1417">viral</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1419" end_char="1427">clearance</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1429" end_char="1430">in</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1432" end_char="1434">the</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1436" end_char="1446">favipiravir</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1448" end_char="1450">arm</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1452" end_char="1454">was</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1456" end_char="1458">not</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1460" end_char="1472">statistically</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1474" end_char="1484">significant</TOKEN>
<TOKEN id="token-10-17" pos="punct" morph="none" start_char="1485" end_char="1485">,</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1487" end_char="1491">which</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1493" end_char="1497">means</TOKEN>
<TOKEN id="token-10-20" pos="punct" morph="none" start_char="1498" end_char="1498">,</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1500" end_char="1507">strictly</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1509" end_char="1516">speaking</TOKEN>
<TOKEN id="token-10-23" pos="punct" morph="none" start_char="1517" end_char="1517">,</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1519" end_char="1522">that</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="1524" end_char="1526">the</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="1528" end_char="1531">drug</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="1533" end_char="1538">failed</TOKEN>
<TOKEN id="token-10-28" pos="word" morph="none" start_char="1540" end_char="1541">to</TOKEN>
<TOKEN id="token-10-29" pos="word" morph="none" start_char="1543" end_char="1546">show</TOKEN>
<TOKEN id="token-10-30" pos="word" morph="none" start_char="1548" end_char="1555">efficacy</TOKEN>
<TOKEN id="token-10-31" pos="word" morph="none" start_char="1557" end_char="1558">in</TOKEN>
<TOKEN id="token-10-32" pos="word" morph="none" start_char="1560" end_char="1562">the</TOKEN>
<TOKEN id="token-10-33" pos="word" morph="none" start_char="1564" end_char="1568">trial</TOKEN>
<TOKEN id="token-10-34" pos="punct" morph="none" start_char="1569" end_char="1569">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1571" end_char="1691">
<ORIGINAL_TEXT>In other words, favipiravir recipients could have turned RT-PCR negative faster by chance alone, and not due to the drug.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1571" end_char="1572">In</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1574" end_char="1578">other</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1580" end_char="1584">words</TOKEN>
<TOKEN id="token-11-3" pos="punct" morph="none" start_char="1585" end_char="1585">,</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1587" end_char="1597">favipiravir</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1599" end_char="1608">recipients</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1610" end_char="1614">could</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1616" end_char="1619">have</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1621" end_char="1626">turned</TOKEN>
<TOKEN id="token-11-9" pos="unknown" morph="none" start_char="1628" end_char="1633">RT-PCR</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1635" end_char="1642">negative</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1644" end_char="1649">faster</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1651" end_char="1652">by</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1654" end_char="1659">chance</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1661" end_char="1665">alone</TOKEN>
<TOKEN id="token-11-15" pos="punct" morph="none" start_char="1666" end_char="1666">,</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1668" end_char="1670">and</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1672" end_char="1674">not</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1676" end_char="1678">due</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="1680" end_char="1681">to</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1683" end_char="1685">the</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="1687" end_char="1690">drug</TOKEN>
<TOKEN id="token-11-22" pos="punct" morph="none" start_char="1691" end_char="1691">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1693" end_char="1840">
<ORIGINAL_TEXT>Critics also said the lack of statistical significance in viral clearance was the key result of the trial, rather than the difference in cure times.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1693" end_char="1699">Critics</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1701" end_char="1704">also</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1706" end_char="1709">said</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1711" end_char="1713">the</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1715" end_char="1718">lack</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1720" end_char="1721">of</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1723" end_char="1733">statistical</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1735" end_char="1746">significance</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1748" end_char="1749">in</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1751" end_char="1755">viral</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1757" end_char="1765">clearance</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1767" end_char="1769">was</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1771" end_char="1773">the</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1775" end_char="1777">key</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1779" end_char="1784">result</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1786" end_char="1787">of</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1789" end_char="1791">the</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1793" end_char="1797">trial</TOKEN>
<TOKEN id="token-12-18" pos="punct" morph="none" start_char="1798" end_char="1798">,</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1800" end_char="1805">rather</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1807" end_char="1810">than</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1812" end_char="1814">the</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1816" end_char="1825">difference</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="1827" end_char="1828">in</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="1830" end_char="1833">cure</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="1835" end_char="1839">times</TOKEN>
<TOKEN id="token-12-26" pos="punct" morph="none" start_char="1840" end_char="1840">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1842" end_char="1969">
<ORIGINAL_TEXT>This is because viral clearance was the Glenmark trial’s primary endpoint while the cure times difference was the secondary one.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1842" end_char="1845">This</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1847" end_char="1848">is</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1850" end_char="1856">because</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1858" end_char="1862">viral</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1864" end_char="1872">clearance</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1874" end_char="1876">was</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1878" end_char="1880">the</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1882" end_char="1889">Glenmark</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1891" end_char="1897">trial’s</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1899" end_char="1905">primary</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1907" end_char="1914">endpoint</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1916" end_char="1920">while</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1922" end_char="1924">the</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1926" end_char="1929">cure</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1931" end_char="1935">times</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1937" end_char="1946">difference</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1948" end_char="1950">was</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1952" end_char="1954">the</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1956" end_char="1964">secondary</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1966" end_char="1968">one</TOKEN>
<TOKEN id="token-13-20" pos="punct" morph="none" start_char="1969" end_char="1969">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1972" end_char="2097">
<ORIGINAL_TEXT>Drawing conclusions based on secondary endpoints when the trial has failed on the primary is a bad idea because it can lead to</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1972" end_char="1978">Drawing</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1980" end_char="1990">conclusions</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1992" end_char="1996">based</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1998" end_char="1999">on</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="2001" end_char="2009">secondary</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="2011" end_char="2019">endpoints</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="2021" end_char="2024">when</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="2026" end_char="2028">the</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="2030" end_char="2034">trial</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="2036" end_char="2038">has</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="2040" end_char="2045">failed</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="2047" end_char="2048">on</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="2050" end_char="2052">the</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="2054" end_char="2060">primary</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="2062" end_char="2063">is</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="2065" end_char="2065">a</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="2067" end_char="2069">bad</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="2071" end_char="2074">idea</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="2076" end_char="2082">because</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="2084" end_char="2085">it</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="2087" end_char="2089">can</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="2091" end_char="2094">lead</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="2096" end_char="2097">to</TOKEN>
</SEG>
<SEG id="segment-15" start_char="2100" end_char="2114">
<ORIGINAL_TEXT>false positives</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="2100" end_char="2104">false</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="2106" end_char="2114">positives</TOKEN>
</SEG>
<SEG id="segment-16" start_char="2117" end_char="2117">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="punct" morph="none" start_char="2117" end_char="2117">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2120" end_char="2336">
<ORIGINAL_TEXT>The way Glenmark framed its press releases could mislead laypersons into believing that the trial’s results were promising when they are actually not, C.S. Pramesh, the director of Tata Memorial Hospital, Mumbai, told</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2120" end_char="2122">The</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2124" end_char="2126">way</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2128" end_char="2135">Glenmark</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2137" end_char="2142">framed</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2144" end_char="2146">its</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2148" end_char="2152">press</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2154" end_char="2161">releases</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2163" end_char="2167">could</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2169" end_char="2175">mislead</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2177" end_char="2186">laypersons</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2188" end_char="2191">into</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2193" end_char="2201">believing</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2203" end_char="2206">that</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2208" end_char="2210">the</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2212" end_char="2218">trial’s</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2220" end_char="2226">results</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="2228" end_char="2231">were</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="2233" end_char="2241">promising</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="2243" end_char="2246">when</TOKEN>
<TOKEN id="token-17-19" pos="word" morph="none" start_char="2248" end_char="2251">they</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="2253" end_char="2255">are</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="2257" end_char="2264">actually</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="2266" end_char="2268">not</TOKEN>
<TOKEN id="token-17-23" pos="punct" morph="none" start_char="2269" end_char="2269">,</TOKEN>
<TOKEN id="token-17-24" pos="unknown" morph="none" start_char="2271" end_char="2273">C.S</TOKEN>
<TOKEN id="token-17-25" pos="punct" morph="none" start_char="2274" end_char="2274">.</TOKEN>
<TOKEN id="token-17-26" pos="word" morph="none" start_char="2276" end_char="2282">Pramesh</TOKEN>
<TOKEN id="token-17-27" pos="punct" morph="none" start_char="2283" end_char="2283">,</TOKEN>
<TOKEN id="token-17-28" pos="word" morph="none" start_char="2285" end_char="2287">the</TOKEN>
<TOKEN id="token-17-29" pos="word" morph="none" start_char="2289" end_char="2296">director</TOKEN>
<TOKEN id="token-17-30" pos="word" morph="none" start_char="2298" end_char="2299">of</TOKEN>
<TOKEN id="token-17-31" pos="word" morph="none" start_char="2301" end_char="2304">Tata</TOKEN>
<TOKEN id="token-17-32" pos="word" morph="none" start_char="2306" end_char="2313">Memorial</TOKEN>
<TOKEN id="token-17-33" pos="word" morph="none" start_char="2315" end_char="2322">Hospital</TOKEN>
<TOKEN id="token-17-34" pos="punct" morph="none" start_char="2323" end_char="2323">,</TOKEN>
<TOKEN id="token-17-35" pos="word" morph="none" start_char="2325" end_char="2330">Mumbai</TOKEN>
<TOKEN id="token-17-36" pos="punct" morph="none" start_char="2331" end_char="2331">,</TOKEN>
<TOKEN id="token-17-37" pos="word" morph="none" start_char="2333" end_char="2336">told</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2339" end_char="2354">
<ORIGINAL_TEXT>The Wire Science</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2339" end_char="2341">The</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2343" end_char="2346">Wire</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2348" end_char="2354">Science</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2357" end_char="2357">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="punct" morph="none" start_char="2357" end_char="2357">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2360" end_char="2477">
<ORIGINAL_TEXT>Following the press release, at least two newspapers reported that the results were strongly in favour of favipiravir.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2360" end_char="2368">Following</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2370" end_char="2372">the</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2374" end_char="2378">press</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2380" end_char="2386">release</TOKEN>
<TOKEN id="token-20-4" pos="punct" morph="none" start_char="2387" end_char="2387">,</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2389" end_char="2390">at</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2392" end_char="2396">least</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2398" end_char="2400">two</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="2402" end_char="2411">newspapers</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2413" end_char="2420">reported</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2422" end_char="2425">that</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="2427" end_char="2429">the</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="2431" end_char="2437">results</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="2439" end_char="2442">were</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="2444" end_char="2451">strongly</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="2453" end_char="2454">in</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="2456" end_char="2461">favour</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="2463" end_char="2464">of</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="2466" end_char="2476">favipiravir</TOKEN>
<TOKEN id="token-20-19" pos="punct" morph="none" start_char="2477" end_char="2477">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2479" end_char="2622">
<ORIGINAL_TEXT>On November 21, the Mumbai Mirror ran an article with the headline that Udwadia had found "proof that favipiravir works for the moderately ill".</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2479" end_char="2480">On</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2482" end_char="2489">November</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2491" end_char="2492">21</TOKEN>
<TOKEN id="token-21-3" pos="punct" morph="none" start_char="2493" end_char="2493">,</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2495" end_char="2497">the</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="2499" end_char="2504">Mumbai</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2506" end_char="2511">Mirror</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="2513" end_char="2515">ran</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="2517" end_char="2518">an</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="2520" end_char="2526">article</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="2528" end_char="2531">with</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="2533" end_char="2535">the</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="2537" end_char="2544">headline</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="2546" end_char="2549">that</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="2551" end_char="2557">Udwadia</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="2559" end_char="2561">had</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="2563" end_char="2567">found</TOKEN>
<TOKEN id="token-21-17" pos="punct" morph="none" start_char="2569" end_char="2569">"</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="2570" end_char="2574">proof</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="2576" end_char="2579">that</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="2581" end_char="2591">favipiravir</TOKEN>
<TOKEN id="token-21-21" pos="word" morph="none" start_char="2593" end_char="2597">works</TOKEN>
<TOKEN id="token-21-22" pos="word" morph="none" start_char="2599" end_char="2601">for</TOKEN>
<TOKEN id="token-21-23" pos="word" morph="none" start_char="2603" end_char="2605">the</TOKEN>
<TOKEN id="token-21-24" pos="word" morph="none" start_char="2607" end_char="2616">moderately</TOKEN>
<TOKEN id="token-21-25" pos="word" morph="none" start_char="2618" end_char="2620">ill</TOKEN>
<TOKEN id="token-21-26" pos="punct" morph="none" start_char="2621" end_char="2622">".</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2624" end_char="2626">
<ORIGINAL_TEXT>The</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2624" end_char="2626">The</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2629" end_char="2642">
<ORIGINAL_TEXT>Times of India</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2629" end_char="2633">Times</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2635" end_char="2636">of</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2638" end_char="2642">India</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2645" end_char="2706">
<ORIGINAL_TEXT>reported on the same day that favipiravir cuts treatment time.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="2645" end_char="2652">reported</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="2654" end_char="2655">on</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="2657" end_char="2659">the</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="2661" end_char="2664">same</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="2666" end_char="2668">day</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="2670" end_char="2673">that</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="2675" end_char="2685">favipiravir</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="2687" end_char="2690">cuts</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="2692" end_char="2700">treatment</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="2702" end_char="2705">time</TOKEN>
<TOKEN id="token-24-10" pos="punct" morph="none" start_char="2706" end_char="2706">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2709" end_char="2819">
<ORIGINAL_TEXT>Neither newspaper mentioned favipiravir’s failure to make a statistically significant difference on the trial’s</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="2709" end_char="2715">Neither</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="2717" end_char="2725">newspaper</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="2727" end_char="2735">mentioned</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="2737" end_char="2749">favipiravir’s</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="2751" end_char="2757">failure</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="2759" end_char="2760">to</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="2762" end_char="2765">make</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="2767" end_char="2767">a</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="2769" end_char="2781">statistically</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="2783" end_char="2793">significant</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="2795" end_char="2804">difference</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="2806" end_char="2807">on</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="2809" end_char="2811">the</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="2813" end_char="2819">trial’s</TOKEN>
</SEG>
<SEG id="segment-26" start_char="2822" end_char="2828">
<ORIGINAL_TEXT>primary</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="2822" end_char="2828">primary</TOKEN>
</SEG>
<SEG id="segment-27" start_char="2831" end_char="2839">
<ORIGINAL_TEXT>endpoint.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="2831" end_char="2838">endpoint</TOKEN>
<TOKEN id="token-27-1" pos="punct" morph="none" start_char="2839" end_char="2839">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="2842" end_char="3039">
<ORIGINAL_TEXT>Even the claim that favipiravir cures patients faster is questionable, said Sahaj Rathi, a faculty member in the department of medicine at the Mahatma Gandhi Institute of Medical Sciences, Sevagram.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="2842" end_char="2845">Even</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="2847" end_char="2849">the</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="2851" end_char="2855">claim</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="2857" end_char="2860">that</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="2862" end_char="2872">favipiravir</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="2874" end_char="2878">cures</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="2880" end_char="2887">patients</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="2889" end_char="2894">faster</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="2896" end_char="2897">is</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="2899" end_char="2910">questionable</TOKEN>
<TOKEN id="token-28-10" pos="punct" morph="none" start_char="2911" end_char="2911">,</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="2913" end_char="2916">said</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="2918" end_char="2922">Sahaj</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="2924" end_char="2928">Rathi</TOKEN>
<TOKEN id="token-28-14" pos="punct" morph="none" start_char="2929" end_char="2929">,</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="2931" end_char="2931">a</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="2933" end_char="2939">faculty</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="2941" end_char="2946">member</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="2948" end_char="2949">in</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="2951" end_char="2953">the</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="2955" end_char="2964">department</TOKEN>
<TOKEN id="token-28-21" pos="word" morph="none" start_char="2966" end_char="2967">of</TOKEN>
<TOKEN id="token-28-22" pos="word" morph="none" start_char="2969" end_char="2976">medicine</TOKEN>
<TOKEN id="token-28-23" pos="word" morph="none" start_char="2978" end_char="2979">at</TOKEN>
<TOKEN id="token-28-24" pos="word" morph="none" start_char="2981" end_char="2983">the</TOKEN>
<TOKEN id="token-28-25" pos="word" morph="none" start_char="2985" end_char="2991">Mahatma</TOKEN>
<TOKEN id="token-28-26" pos="word" morph="none" start_char="2993" end_char="2998">Gandhi</TOKEN>
<TOKEN id="token-28-27" pos="word" morph="none" start_char="3000" end_char="3008">Institute</TOKEN>
<TOKEN id="token-28-28" pos="word" morph="none" start_char="3010" end_char="3011">of</TOKEN>
<TOKEN id="token-28-29" pos="word" morph="none" start_char="3013" end_char="3019">Medical</TOKEN>
<TOKEN id="token-28-30" pos="word" morph="none" start_char="3021" end_char="3028">Sciences</TOKEN>
<TOKEN id="token-28-31" pos="punct" morph="none" start_char="3029" end_char="3029">,</TOKEN>
<TOKEN id="token-28-32" pos="word" morph="none" start_char="3031" end_char="3038">Sevagram</TOKEN>
<TOKEN id="token-28-33" pos="punct" morph="none" start_char="3039" end_char="3039">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3041" end_char="3145">
<ORIGINAL_TEXT>Rathi pointed out that the trial had an ‘open-label’ design – which means doctors overseeing the patients</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="3041" end_char="3045">Rathi</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="3047" end_char="3053">pointed</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="3055" end_char="3057">out</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="3059" end_char="3062">that</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="3064" end_char="3066">the</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="3068" end_char="3072">trial</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="3074" end_char="3076">had</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="3078" end_char="3079">an</TOKEN>
<TOKEN id="token-29-8" pos="punct" morph="none" start_char="3081" end_char="3081">‘</TOKEN>
<TOKEN id="token-29-9" pos="unknown" morph="none" start_char="3082" end_char="3091">open-label</TOKEN>
<TOKEN id="token-29-10" pos="punct" morph="none" start_char="3092" end_char="3092">’</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="3094" end_char="3099">design</TOKEN>
<TOKEN id="token-29-12" pos="punct" morph="none" start_char="3101" end_char="3101">–</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="3103" end_char="3107">which</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="3109" end_char="3113">means</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="3115" end_char="3121">doctors</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="3123" end_char="3132">overseeing</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="3134" end_char="3136">the</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="3138" end_char="3145">patients</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3148" end_char="3151">
<ORIGINAL_TEXT>knew</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="3148" end_char="3151">knew</TOKEN>
</SEG>
<SEG id="segment-31" start_char="3154" end_char="3193">
<ORIGINAL_TEXT>who received favipiravir and who didn’t.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="3154" end_char="3156">who</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="3158" end_char="3165">received</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="3167" end_char="3177">favipiravir</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="3179" end_char="3181">and</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="3183" end_char="3185">who</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="3187" end_char="3192">didn’t</TOKEN>
<TOKEN id="token-31-6" pos="punct" morph="none" start_char="3193" end_char="3193">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="3195" end_char="3507">
<ORIGINAL_TEXT>And these doctors also took a call on which patient was considered to have been cured by checking whether the patient’s body temperature had dropped below 98.8º F, respiratory rate had fallen to less than 20 times a minute, blood oxygen levels (SPO2) had returned to over 95%, and cough was either mild or absent.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="3195" end_char="3197">And</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="3199" end_char="3203">these</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="3205" end_char="3211">doctors</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="3213" end_char="3216">also</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="3218" end_char="3221">took</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="3223" end_char="3223">a</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="3225" end_char="3228">call</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="3230" end_char="3231">on</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="3233" end_char="3237">which</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="3239" end_char="3245">patient</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="3247" end_char="3249">was</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="3251" end_char="3260">considered</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="3262" end_char="3263">to</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="3265" end_char="3268">have</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="3270" end_char="3273">been</TOKEN>
<TOKEN id="token-32-15" pos="word" morph="none" start_char="3275" end_char="3279">cured</TOKEN>
<TOKEN id="token-32-16" pos="word" morph="none" start_char="3281" end_char="3282">by</TOKEN>
<TOKEN id="token-32-17" pos="word" morph="none" start_char="3284" end_char="3291">checking</TOKEN>
<TOKEN id="token-32-18" pos="word" morph="none" start_char="3293" end_char="3299">whether</TOKEN>
<TOKEN id="token-32-19" pos="word" morph="none" start_char="3301" end_char="3303">the</TOKEN>
<TOKEN id="token-32-20" pos="word" morph="none" start_char="3305" end_char="3313">patient’s</TOKEN>
<TOKEN id="token-32-21" pos="word" morph="none" start_char="3315" end_char="3318">body</TOKEN>
<TOKEN id="token-32-22" pos="word" morph="none" start_char="3320" end_char="3330">temperature</TOKEN>
<TOKEN id="token-32-23" pos="word" morph="none" start_char="3332" end_char="3334">had</TOKEN>
<TOKEN id="token-32-24" pos="word" morph="none" start_char="3336" end_char="3342">dropped</TOKEN>
<TOKEN id="token-32-25" pos="word" morph="none" start_char="3344" end_char="3348">below</TOKEN>
<TOKEN id="token-32-26" pos="unknown" morph="none" start_char="3350" end_char="3354">98.8º</TOKEN>
<TOKEN id="token-32-27" pos="word" morph="none" start_char="3356" end_char="3356">F</TOKEN>
<TOKEN id="token-32-28" pos="punct" morph="none" start_char="3357" end_char="3357">,</TOKEN>
<TOKEN id="token-32-29" pos="word" morph="none" start_char="3359" end_char="3369">respiratory</TOKEN>
<TOKEN id="token-32-30" pos="word" morph="none" start_char="3371" end_char="3374">rate</TOKEN>
<TOKEN id="token-32-31" pos="word" morph="none" start_char="3376" end_char="3378">had</TOKEN>
<TOKEN id="token-32-32" pos="word" morph="none" start_char="3380" end_char="3385">fallen</TOKEN>
<TOKEN id="token-32-33" pos="word" morph="none" start_char="3387" end_char="3388">to</TOKEN>
<TOKEN id="token-32-34" pos="word" morph="none" start_char="3390" end_char="3393">less</TOKEN>
<TOKEN id="token-32-35" pos="word" morph="none" start_char="3395" end_char="3398">than</TOKEN>
<TOKEN id="token-32-36" pos="word" morph="none" start_char="3400" end_char="3401">20</TOKEN>
<TOKEN id="token-32-37" pos="word" morph="none" start_char="3403" end_char="3407">times</TOKEN>
<TOKEN id="token-32-38" pos="word" morph="none" start_char="3409" end_char="3409">a</TOKEN>
<TOKEN id="token-32-39" pos="word" morph="none" start_char="3411" end_char="3416">minute</TOKEN>
<TOKEN id="token-32-40" pos="punct" morph="none" start_char="3417" end_char="3417">,</TOKEN>
<TOKEN id="token-32-41" pos="word" morph="none" start_char="3419" end_char="3423">blood</TOKEN>
<TOKEN id="token-32-42" pos="word" morph="none" start_char="3425" end_char="3430">oxygen</TOKEN>
<TOKEN id="token-32-43" pos="word" morph="none" start_char="3432" end_char="3437">levels</TOKEN>
<TOKEN id="token-32-44" pos="punct" morph="none" start_char="3439" end_char="3439">(</TOKEN>
<TOKEN id="token-32-45" pos="word" morph="none" start_char="3440" end_char="3443">SPO2</TOKEN>
<TOKEN id="token-32-46" pos="punct" morph="none" start_char="3444" end_char="3444">)</TOKEN>
<TOKEN id="token-32-47" pos="word" morph="none" start_char="3446" end_char="3448">had</TOKEN>
<TOKEN id="token-32-48" pos="word" morph="none" start_char="3450" end_char="3457">returned</TOKEN>
<TOKEN id="token-32-49" pos="word" morph="none" start_char="3459" end_char="3460">to</TOKEN>
<TOKEN id="token-32-50" pos="word" morph="none" start_char="3462" end_char="3465">over</TOKEN>
<TOKEN id="token-32-51" pos="word" morph="none" start_char="3467" end_char="3468">95</TOKEN>
<TOKEN id="token-32-52" pos="punct" morph="none" start_char="3469" end_char="3470">%,</TOKEN>
<TOKEN id="token-32-53" pos="word" morph="none" start_char="3472" end_char="3474">and</TOKEN>
<TOKEN id="token-32-54" pos="word" morph="none" start_char="3476" end_char="3480">cough</TOKEN>
<TOKEN id="token-32-55" pos="word" morph="none" start_char="3482" end_char="3484">was</TOKEN>
<TOKEN id="token-32-56" pos="word" morph="none" start_char="3486" end_char="3491">either</TOKEN>
<TOKEN id="token-32-57" pos="word" morph="none" start_char="3493" end_char="3496">mild</TOKEN>
<TOKEN id="token-32-58" pos="word" morph="none" start_char="3498" end_char="3499">or</TOKEN>
<TOKEN id="token-32-59" pos="word" morph="none" start_char="3501" end_char="3506">absent</TOKEN>
<TOKEN id="token-32-60" pos="punct" morph="none" start_char="3507" end_char="3507">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="3510" end_char="3707">
<ORIGINAL_TEXT>But the knowledge of which patients received the drug could easily influence these doctors’ decisions, given that even temperature, respiratory rate and cough severity can be subjective, Rathi said.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="3510" end_char="3512">But</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="3514" end_char="3516">the</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="3518" end_char="3526">knowledge</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="3528" end_char="3529">of</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="3531" end_char="3535">which</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="3537" end_char="3544">patients</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="3546" end_char="3553">received</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="3555" end_char="3557">the</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="3559" end_char="3562">drug</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="3564" end_char="3568">could</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="3570" end_char="3575">easily</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="3577" end_char="3585">influence</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="3587" end_char="3591">these</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="3593" end_char="3599">doctors</TOKEN>
<TOKEN id="token-33-14" pos="punct" morph="none" start_char="3600" end_char="3600">’</TOKEN>
<TOKEN id="token-33-15" pos="word" morph="none" start_char="3602" end_char="3610">decisions</TOKEN>
<TOKEN id="token-33-16" pos="punct" morph="none" start_char="3611" end_char="3611">,</TOKEN>
<TOKEN id="token-33-17" pos="word" morph="none" start_char="3613" end_char="3617">given</TOKEN>
<TOKEN id="token-33-18" pos="word" morph="none" start_char="3619" end_char="3622">that</TOKEN>
<TOKEN id="token-33-19" pos="word" morph="none" start_char="3624" end_char="3627">even</TOKEN>
<TOKEN id="token-33-20" pos="word" morph="none" start_char="3629" end_char="3639">temperature</TOKEN>
<TOKEN id="token-33-21" pos="punct" morph="none" start_char="3640" end_char="3640">,</TOKEN>
<TOKEN id="token-33-22" pos="word" morph="none" start_char="3642" end_char="3652">respiratory</TOKEN>
<TOKEN id="token-33-23" pos="word" morph="none" start_char="3654" end_char="3657">rate</TOKEN>
<TOKEN id="token-33-24" pos="word" morph="none" start_char="3659" end_char="3661">and</TOKEN>
<TOKEN id="token-33-25" pos="word" morph="none" start_char="3663" end_char="3667">cough</TOKEN>
<TOKEN id="token-33-26" pos="word" morph="none" start_char="3669" end_char="3676">severity</TOKEN>
<TOKEN id="token-33-27" pos="word" morph="none" start_char="3678" end_char="3680">can</TOKEN>
<TOKEN id="token-33-28" pos="word" morph="none" start_char="3682" end_char="3683">be</TOKEN>
<TOKEN id="token-33-29" pos="word" morph="none" start_char="3685" end_char="3694">subjective</TOKEN>
<TOKEN id="token-33-30" pos="punct" morph="none" start_char="3695" end_char="3695">,</TOKEN>
<TOKEN id="token-33-31" pos="word" morph="none" start_char="3697" end_char="3701">Rathi</TOKEN>
<TOKEN id="token-33-32" pos="word" morph="none" start_char="3703" end_char="3706">said</TOKEN>
<TOKEN id="token-33-33" pos="punct" morph="none" start_char="3707" end_char="3707">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="3709" end_char="3877">
<ORIGINAL_TEXT>"Open-label trials are heavily prone to biases… body temperature varies with time and use of antipyretics, respiratory rate varies, and mild cough is a very loose term."</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="punct" morph="none" start_char="3709" end_char="3709">"</TOKEN>
<TOKEN id="token-34-1" pos="unknown" morph="none" start_char="3710" end_char="3719">Open-label</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="3721" end_char="3726">trials</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="3728" end_char="3730">are</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="3732" end_char="3738">heavily</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="3740" end_char="3744">prone</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="3746" end_char="3747">to</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="3749" end_char="3754">biases</TOKEN>
<TOKEN id="token-34-8" pos="punct" morph="none" start_char="3755" end_char="3755">…</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="3757" end_char="3760">body</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="3762" end_char="3772">temperature</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="3774" end_char="3779">varies</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="3781" end_char="3784">with</TOKEN>
<TOKEN id="token-34-13" pos="word" morph="none" start_char="3786" end_char="3789">time</TOKEN>
<TOKEN id="token-34-14" pos="word" morph="none" start_char="3791" end_char="3793">and</TOKEN>
<TOKEN id="token-34-15" pos="word" morph="none" start_char="3795" end_char="3797">use</TOKEN>
<TOKEN id="token-34-16" pos="word" morph="none" start_char="3799" end_char="3800">of</TOKEN>
<TOKEN id="token-34-17" pos="word" morph="none" start_char="3802" end_char="3813">antipyretics</TOKEN>
<TOKEN id="token-34-18" pos="punct" morph="none" start_char="3814" end_char="3814">,</TOKEN>
<TOKEN id="token-34-19" pos="word" morph="none" start_char="3816" end_char="3826">respiratory</TOKEN>
<TOKEN id="token-34-20" pos="word" morph="none" start_char="3828" end_char="3831">rate</TOKEN>
<TOKEN id="token-34-21" pos="word" morph="none" start_char="3833" end_char="3838">varies</TOKEN>
<TOKEN id="token-34-22" pos="punct" morph="none" start_char="3839" end_char="3839">,</TOKEN>
<TOKEN id="token-34-23" pos="word" morph="none" start_char="3841" end_char="3843">and</TOKEN>
<TOKEN id="token-34-24" pos="word" morph="none" start_char="3845" end_char="3848">mild</TOKEN>
<TOKEN id="token-34-25" pos="word" morph="none" start_char="3850" end_char="3854">cough</TOKEN>
<TOKEN id="token-34-26" pos="word" morph="none" start_char="3856" end_char="3857">is</TOKEN>
<TOKEN id="token-34-27" pos="word" morph="none" start_char="3859" end_char="3859">a</TOKEN>
<TOKEN id="token-34-28" pos="word" morph="none" start_char="3861" end_char="3864">very</TOKEN>
<TOKEN id="token-34-29" pos="word" morph="none" start_char="3866" end_char="3870">loose</TOKEN>
<TOKEN id="token-34-30" pos="word" morph="none" start_char="3872" end_char="3875">term</TOKEN>
<TOKEN id="token-34-31" pos="punct" morph="none" start_char="3876" end_char="3877">."</TOKEN>
</SEG>
<SEG id="segment-35" start_char="3880" end_char="4003">
<ORIGINAL_TEXT>Put together, Rathi and others have argued, none of the findings support the company’s claims that favipiravir is effective.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="3880" end_char="3882">Put</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="3884" end_char="3891">together</TOKEN>
<TOKEN id="token-35-2" pos="punct" morph="none" start_char="3892" end_char="3892">,</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="3894" end_char="3898">Rathi</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="3900" end_char="3902">and</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="3904" end_char="3909">others</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="3911" end_char="3914">have</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="3916" end_char="3921">argued</TOKEN>
<TOKEN id="token-35-8" pos="punct" morph="none" start_char="3922" end_char="3922">,</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="3924" end_char="3927">none</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="3929" end_char="3930">of</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="3932" end_char="3934">the</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="3936" end_char="3943">findings</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="3945" end_char="3951">support</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="3953" end_char="3955">the</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="3957" end_char="3965">company’s</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="3967" end_char="3972">claims</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="3974" end_char="3977">that</TOKEN>
<TOKEN id="token-35-18" pos="word" morph="none" start_char="3979" end_char="3989">favipiravir</TOKEN>
<TOKEN id="token-35-19" pos="word" morph="none" start_char="3991" end_char="3992">is</TOKEN>
<TOKEN id="token-35-20" pos="word" morph="none" start_char="3994" end_char="4002">effective</TOKEN>
<TOKEN id="token-35-21" pos="punct" morph="none" start_char="4003" end_char="4003">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="4005" end_char="4092">
<ORIGINAL_TEXT>"Faced with a patient with mild or no symptoms – should a doctor recommend favipiravir?"</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="punct" morph="none" start_char="4005" end_char="4005">"</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="4006" end_char="4010">Faced</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="4012" end_char="4015">with</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="4017" end_char="4017">a</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="4019" end_char="4025">patient</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="4027" end_char="4030">with</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="4032" end_char="4035">mild</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="4037" end_char="4038">or</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="4040" end_char="4041">no</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="4043" end_char="4050">symptoms</TOKEN>
<TOKEN id="token-36-10" pos="punct" morph="none" start_char="4052" end_char="4052">–</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="4054" end_char="4059">should</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="4061" end_char="4061">a</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="4063" end_char="4068">doctor</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="4070" end_char="4078">recommend</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="4080" end_char="4090">favipiravir</TOKEN>
<TOKEN id="token-36-16" pos="punct" morph="none" start_char="4091" end_char="4092">?"</TOKEN>
</SEG>
<SEG id="segment-37" start_char="4094" end_char="4147">
<ORIGINAL_TEXT>Jammi Nagaraj Rao, an epidemiologist in the UK, asked.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="4094" end_char="4098">Jammi</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="4100" end_char="4106">Nagaraj</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="4108" end_char="4110">Rao</TOKEN>
<TOKEN id="token-37-3" pos="punct" morph="none" start_char="4111" end_char="4111">,</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="4113" end_char="4114">an</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="4116" end_char="4129">epidemiologist</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="4131" end_char="4132">in</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="4134" end_char="4136">the</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="4138" end_char="4139">UK</TOKEN>
<TOKEN id="token-37-9" pos="punct" morph="none" start_char="4140" end_char="4140">,</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="4142" end_char="4146">asked</TOKEN>
<TOKEN id="token-37-11" pos="punct" morph="none" start_char="4147" end_char="4147">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="4149" end_char="4174">
<ORIGINAL_TEXT>"Based on this study, no."</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="punct" morph="none" start_char="4149" end_char="4149">"</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="4150" end_char="4154">Based</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="4156" end_char="4157">on</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="4159" end_char="4162">this</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="4164" end_char="4168">study</TOKEN>
<TOKEN id="token-38-5" pos="punct" morph="none" start_char="4169" end_char="4169">,</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="4171" end_char="4172">no</TOKEN>
<TOKEN id="token-38-7" pos="punct" morph="none" start_char="4173" end_char="4174">."</TOKEN>
</SEG>
<SEG id="segment-39" start_char="4177" end_char="4241">
<ORIGINAL_TEXT>But the weak results haven’t deterred widespread use of the drug.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="4177" end_char="4179">But</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="4181" end_char="4183">the</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="4185" end_char="4188">weak</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="4190" end_char="4196">results</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="4198" end_char="4204">haven’t</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="4206" end_char="4213">deterred</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="4215" end_char="4224">widespread</TOKEN>
<TOKEN id="token-39-7" pos="word" morph="none" start_char="4226" end_char="4228">use</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="4230" end_char="4231">of</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="4233" end_char="4235">the</TOKEN>
<TOKEN id="token-39-10" pos="word" morph="none" start_char="4237" end_char="4240">drug</TOKEN>
<TOKEN id="token-39-11" pos="punct" morph="none" start_char="4241" end_char="4241">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="4243" end_char="4340">
<ORIGINAL_TEXT>Since June, favipiravir has gained traction among doctors treating COVID-19 patients across India.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="4243" end_char="4247">Since</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="4249" end_char="4252">June</TOKEN>
<TOKEN id="token-40-2" pos="punct" morph="none" start_char="4253" end_char="4253">,</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="4255" end_char="4265">favipiravir</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="4267" end_char="4269">has</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="4271" end_char="4276">gained</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="4278" end_char="4285">traction</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="4287" end_char="4291">among</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="4293" end_char="4299">doctors</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="4301" end_char="4308">treating</TOKEN>
<TOKEN id="token-40-10" pos="unknown" morph="none" start_char="4310" end_char="4317">COVID-19</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="4319" end_char="4326">patients</TOKEN>
<TOKEN id="token-40-12" pos="word" morph="none" start_char="4328" end_char="4333">across</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="4335" end_char="4339">India</TOKEN>
<TOKEN id="token-40-14" pos="punct" morph="none" start_char="4340" end_char="4340">.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="4342" end_char="4379">
<ORIGINAL_TEXT>In a recent editorial published in the</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="4342" end_char="4343">In</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="4345" end_char="4345">a</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="4347" end_char="4352">recent</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="4354" end_char="4362">editorial</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="4364" end_char="4372">published</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="4374" end_char="4375">in</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="4377" end_char="4379">the</TOKEN>
</SEG>
<SEG id="segment-42" start_char="4382" end_char="4413">
<ORIGINAL_TEXT>Indian Journal of Medical Ethics</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="4382" end_char="4387">Indian</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="4389" end_char="4395">Journal</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="4397" end_char="4398">of</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="4400" end_char="4406">Medical</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="4408" end_char="4413">Ethics</TOKEN>
</SEG>
<SEG id="segment-43" start_char="4416" end_char="4504">
<ORIGINAL_TEXT>, Rathi and his coauthor wrote that favipiravir is now in routine use across the country.</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="punct" morph="none" start_char="4416" end_char="4416">,</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="4418" end_char="4422">Rathi</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="4424" end_char="4426">and</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="4428" end_char="4430">his</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="4432" end_char="4439">coauthor</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="4441" end_char="4445">wrote</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="4447" end_char="4450">that</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="4452" end_char="4462">favipiravir</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="4464" end_char="4465">is</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="4467" end_char="4469">now</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="4471" end_char="4472">in</TOKEN>
<TOKEN id="token-43-11" pos="word" morph="none" start_char="4474" end_char="4480">routine</TOKEN>
<TOKEN id="token-43-12" pos="word" morph="none" start_char="4482" end_char="4484">use</TOKEN>
<TOKEN id="token-43-13" pos="word" morph="none" start_char="4486" end_char="4491">across</TOKEN>
<TOKEN id="token-43-14" pos="word" morph="none" start_char="4493" end_char="4495">the</TOKEN>
<TOKEN id="token-43-15" pos="word" morph="none" start_char="4497" end_char="4503">country</TOKEN>
<TOKEN id="token-43-16" pos="punct" morph="none" start_char="4504" end_char="4504">.</TOKEN>
</SEG>
<SEG id="segment-44" start_char="4506" end_char="4638">
<ORIGINAL_TEXT>At least three states – Maharashtra, Kerala and Karnataka – have recommended the drug in their COVID-19 treatment guidelines as well.</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="4506" end_char="4507">At</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="4509" end_char="4513">least</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="4515" end_char="4519">three</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="4521" end_char="4526">states</TOKEN>
<TOKEN id="token-44-4" pos="punct" morph="none" start_char="4528" end_char="4528">–</TOKEN>
<TOKEN id="token-44-5" pos="word" morph="none" start_char="4530" end_char="4540">Maharashtra</TOKEN>
<TOKEN id="token-44-6" pos="punct" morph="none" start_char="4541" end_char="4541">,</TOKEN>
<TOKEN id="token-44-7" pos="word" morph="none" start_char="4543" end_char="4548">Kerala</TOKEN>
<TOKEN id="token-44-8" pos="word" morph="none" start_char="4550" end_char="4552">and</TOKEN>
<TOKEN id="token-44-9" pos="word" morph="none" start_char="4554" end_char="4562">Karnataka</TOKEN>
<TOKEN id="token-44-10" pos="punct" morph="none" start_char="4564" end_char="4564">–</TOKEN>
<TOKEN id="token-44-11" pos="word" morph="none" start_char="4566" end_char="4569">have</TOKEN>
<TOKEN id="token-44-12" pos="word" morph="none" start_char="4571" end_char="4581">recommended</TOKEN>
<TOKEN id="token-44-13" pos="word" morph="none" start_char="4583" end_char="4585">the</TOKEN>
<TOKEN id="token-44-14" pos="word" morph="none" start_char="4587" end_char="4590">drug</TOKEN>
<TOKEN id="token-44-15" pos="word" morph="none" start_char="4592" end_char="4593">in</TOKEN>
<TOKEN id="token-44-16" pos="word" morph="none" start_char="4595" end_char="4599">their</TOKEN>
<TOKEN id="token-44-17" pos="unknown" morph="none" start_char="4601" end_char="4608">COVID-19</TOKEN>
<TOKEN id="token-44-18" pos="word" morph="none" start_char="4610" end_char="4618">treatment</TOKEN>
<TOKEN id="token-44-19" pos="word" morph="none" start_char="4620" end_char="4629">guidelines</TOKEN>
<TOKEN id="token-44-20" pos="word" morph="none" start_char="4631" end_char="4632">as</TOKEN>
<TOKEN id="token-44-21" pos="word" morph="none" start_char="4634" end_char="4637">well</TOKEN>
<TOKEN id="token-44-22" pos="punct" morph="none" start_char="4638" end_char="4638">.</TOKEN>
</SEG>
<SEG id="segment-45" start_char="4641" end_char="4746">
<ORIGINAL_TEXT>While a Glenmark spokesperson said the company didn’t have a number for favipiravir sales since June 2020,</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="4641" end_char="4645">While</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="4647" end_char="4647">a</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="4649" end_char="4656">Glenmark</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="4658" end_char="4669">spokesperson</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="4671" end_char="4674">said</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="4676" end_char="4678">the</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="4680" end_char="4686">company</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="4688" end_char="4693">didn’t</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="4695" end_char="4698">have</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="4700" end_char="4700">a</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="4702" end_char="4707">number</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="4709" end_char="4711">for</TOKEN>
<TOKEN id="token-45-12" pos="word" morph="none" start_char="4713" end_char="4723">favipiravir</TOKEN>
<TOKEN id="token-45-13" pos="word" morph="none" start_char="4725" end_char="4729">sales</TOKEN>
<TOKEN id="token-45-14" pos="word" morph="none" start_char="4731" end_char="4735">since</TOKEN>
<TOKEN id="token-45-15" pos="word" morph="none" start_char="4737" end_char="4740">June</TOKEN>
<TOKEN id="token-45-16" pos="word" morph="none" start_char="4742" end_char="4745">2020</TOKEN>
<TOKEN id="token-45-17" pos="punct" morph="none" start_char="4746" end_char="4746">,</TOKEN>
</SEG>
<SEG id="segment-46" start_char="4749" end_char="4761">
<ORIGINAL_TEXT>Mumbai Mirror</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="4749" end_char="4754">Mumbai</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="4756" end_char="4761">Mirror</TOKEN>
</SEG>
<SEG id="segment-47" start_char="4764" end_char="4872">
<ORIGINAL_TEXT>reported that the Municipal Corporation of Greater Mumbai alone has amassed a stockpile of five lakh tablets.</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="4764" end_char="4771">reported</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="4773" end_char="4776">that</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="4778" end_char="4780">the</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="4782" end_char="4790">Municipal</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="4792" end_char="4802">Corporation</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="4804" end_char="4805">of</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="4807" end_char="4813">Greater</TOKEN>
<TOKEN id="token-47-7" pos="word" morph="none" start_char="4815" end_char="4820">Mumbai</TOKEN>
<TOKEN id="token-47-8" pos="word" morph="none" start_char="4822" end_char="4826">alone</TOKEN>
<TOKEN id="token-47-9" pos="word" morph="none" start_char="4828" end_char="4830">has</TOKEN>
<TOKEN id="token-47-10" pos="word" morph="none" start_char="4832" end_char="4838">amassed</TOKEN>
<TOKEN id="token-47-11" pos="word" morph="none" start_char="4840" end_char="4840">a</TOKEN>
<TOKEN id="token-47-12" pos="word" morph="none" start_char="4842" end_char="4850">stockpile</TOKEN>
<TOKEN id="token-47-13" pos="word" morph="none" start_char="4852" end_char="4853">of</TOKEN>
<TOKEN id="token-47-14" pos="word" morph="none" start_char="4855" end_char="4858">five</TOKEN>
<TOKEN id="token-47-15" pos="word" morph="none" start_char="4860" end_char="4863">lakh</TOKEN>
<TOKEN id="token-47-16" pos="word" morph="none" start_char="4865" end_char="4871">tablets</TOKEN>
<TOKEN id="token-47-17" pos="punct" morph="none" start_char="4872" end_char="4872">.</TOKEN>
</SEG>
<SEG id="segment-48" start_char="4875" end_char="4898">
<ORIGINAL_TEXT>Primary endpoints matter</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="4875" end_char="4881">Primary</TOKEN>
<TOKEN id="token-48-1" pos="word" morph="none" start_char="4883" end_char="4891">endpoints</TOKEN>
<TOKEN id="token-48-2" pos="word" morph="none" start_char="4893" end_char="4898">matter</TOKEN>
</SEG>
<SEG id="segment-49" start_char="4901" end_char="5088">
<ORIGINAL_TEXT>One reason why experts warn against shifting focus to secondary endpoints when a trial has failed on its primary ones is that trials are designed around the primary, and not the secondary.</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="4901" end_char="4903">One</TOKEN>
<TOKEN id="token-49-1" pos="word" morph="none" start_char="4905" end_char="4910">reason</TOKEN>
<TOKEN id="token-49-2" pos="word" morph="none" start_char="4912" end_char="4914">why</TOKEN>
<TOKEN id="token-49-3" pos="word" morph="none" start_char="4916" end_char="4922">experts</TOKEN>
<TOKEN id="token-49-4" pos="word" morph="none" start_char="4924" end_char="4927">warn</TOKEN>
<TOKEN id="token-49-5" pos="word" morph="none" start_char="4929" end_char="4935">against</TOKEN>
<TOKEN id="token-49-6" pos="word" morph="none" start_char="4937" end_char="4944">shifting</TOKEN>
<TOKEN id="token-49-7" pos="word" morph="none" start_char="4946" end_char="4950">focus</TOKEN>
<TOKEN id="token-49-8" pos="word" morph="none" start_char="4952" end_char="4953">to</TOKEN>
<TOKEN id="token-49-9" pos="word" morph="none" start_char="4955" end_char="4963">secondary</TOKEN>
<TOKEN id="token-49-10" pos="word" morph="none" start_char="4965" end_char="4973">endpoints</TOKEN>
<TOKEN id="token-49-11" pos="word" morph="none" start_char="4975" end_char="4978">when</TOKEN>
<TOKEN id="token-49-12" pos="word" morph="none" start_char="4980" end_char="4980">a</TOKEN>
<TOKEN id="token-49-13" pos="word" morph="none" start_char="4982" end_char="4986">trial</TOKEN>
<TOKEN id="token-49-14" pos="word" morph="none" start_char="4988" end_char="4990">has</TOKEN>
<TOKEN id="token-49-15" pos="word" morph="none" start_char="4992" end_char="4997">failed</TOKEN>
<TOKEN id="token-49-16" pos="word" morph="none" start_char="4999" end_char="5000">on</TOKEN>
<TOKEN id="token-49-17" pos="word" morph="none" start_char="5002" end_char="5004">its</TOKEN>
<TOKEN id="token-49-18" pos="word" morph="none" start_char="5006" end_char="5012">primary</TOKEN>
<TOKEN id="token-49-19" pos="word" morph="none" start_char="5014" end_char="5017">ones</TOKEN>
<TOKEN id="token-49-20" pos="word" morph="none" start_char="5019" end_char="5020">is</TOKEN>
<TOKEN id="token-49-21" pos="word" morph="none" start_char="5022" end_char="5025">that</TOKEN>
<TOKEN id="token-49-22" pos="word" morph="none" start_char="5027" end_char="5032">trials</TOKEN>
<TOKEN id="token-49-23" pos="word" morph="none" start_char="5034" end_char="5036">are</TOKEN>
<TOKEN id="token-49-24" pos="word" morph="none" start_char="5038" end_char="5045">designed</TOKEN>
<TOKEN id="token-49-25" pos="word" morph="none" start_char="5047" end_char="5052">around</TOKEN>
<TOKEN id="token-49-26" pos="word" morph="none" start_char="5054" end_char="5056">the</TOKEN>
<TOKEN id="token-49-27" pos="word" morph="none" start_char="5058" end_char="5064">primary</TOKEN>
<TOKEN id="token-49-28" pos="punct" morph="none" start_char="5065" end_char="5065">,</TOKEN>
<TOKEN id="token-49-29" pos="word" morph="none" start_char="5067" end_char="5069">and</TOKEN>
<TOKEN id="token-49-30" pos="word" morph="none" start_char="5071" end_char="5073">not</TOKEN>
<TOKEN id="token-49-31" pos="word" morph="none" start_char="5075" end_char="5077">the</TOKEN>
<TOKEN id="token-49-32" pos="word" morph="none" start_char="5079" end_char="5087">secondary</TOKEN>
<TOKEN id="token-49-33" pos="punct" morph="none" start_char="5088" end_char="5088">.</TOKEN>
</SEG>
<SEG id="segment-50" start_char="5090" end_char="5178">
<ORIGINAL_TEXT>In other words, a trial should be considered a ‘win’ only if the primary endpoint is met.</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="5090" end_char="5091">In</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="5093" end_char="5097">other</TOKEN>
<TOKEN id="token-50-2" pos="word" morph="none" start_char="5099" end_char="5103">words</TOKEN>
<TOKEN id="token-50-3" pos="punct" morph="none" start_char="5104" end_char="5104">,</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="5106" end_char="5106">a</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="5108" end_char="5112">trial</TOKEN>
<TOKEN id="token-50-6" pos="word" morph="none" start_char="5114" end_char="5119">should</TOKEN>
<TOKEN id="token-50-7" pos="word" morph="none" start_char="5121" end_char="5122">be</TOKEN>
<TOKEN id="token-50-8" pos="word" morph="none" start_char="5124" end_char="5133">considered</TOKEN>
<TOKEN id="token-50-9" pos="word" morph="none" start_char="5135" end_char="5135">a</TOKEN>
<TOKEN id="token-50-10" pos="punct" morph="none" start_char="5137" end_char="5137">‘</TOKEN>
<TOKEN id="token-50-11" pos="word" morph="none" start_char="5138" end_char="5140">win</TOKEN>
<TOKEN id="token-50-12" pos="punct" morph="none" start_char="5141" end_char="5141">’</TOKEN>
<TOKEN id="token-50-13" pos="word" morph="none" start_char="5143" end_char="5146">only</TOKEN>
<TOKEN id="token-50-14" pos="word" morph="none" start_char="5148" end_char="5149">if</TOKEN>
<TOKEN id="token-50-15" pos="word" morph="none" start_char="5151" end_char="5153">the</TOKEN>
<TOKEN id="token-50-16" pos="word" morph="none" start_char="5155" end_char="5161">primary</TOKEN>
<TOKEN id="token-50-17" pos="word" morph="none" start_char="5163" end_char="5170">endpoint</TOKEN>
<TOKEN id="token-50-18" pos="word" morph="none" start_char="5172" end_char="5173">is</TOKEN>
<TOKEN id="token-50-19" pos="word" morph="none" start_char="5175" end_char="5177">met</TOKEN>
<TOKEN id="token-50-20" pos="punct" morph="none" start_char="5178" end_char="5178">.</TOKEN>
</SEG>
<SEG id="segment-51" start_char="5180" end_char="5364">
<ORIGINAL_TEXT>Secondary endpoints help gather further ‘good to know’ information on the drug’s efficacy and can help generate hypotheses for future trials – but can’t be the basis of efficacy claims.</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="word" morph="none" start_char="5180" end_char="5188">Secondary</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="5190" end_char="5198">endpoints</TOKEN>
<TOKEN id="token-51-2" pos="word" morph="none" start_char="5200" end_char="5203">help</TOKEN>
<TOKEN id="token-51-3" pos="word" morph="none" start_char="5205" end_char="5210">gather</TOKEN>
<TOKEN id="token-51-4" pos="word" morph="none" start_char="5212" end_char="5218">further</TOKEN>
<TOKEN id="token-51-5" pos="punct" morph="none" start_char="5220" end_char="5220">‘</TOKEN>
<TOKEN id="token-51-6" pos="word" morph="none" start_char="5221" end_char="5224">good</TOKEN>
<TOKEN id="token-51-7" pos="word" morph="none" start_char="5226" end_char="5227">to</TOKEN>
<TOKEN id="token-51-8" pos="word" morph="none" start_char="5229" end_char="5232">know</TOKEN>
<TOKEN id="token-51-9" pos="punct" morph="none" start_char="5233" end_char="5233">’</TOKEN>
<TOKEN id="token-51-10" pos="word" morph="none" start_char="5235" end_char="5245">information</TOKEN>
<TOKEN id="token-51-11" pos="word" morph="none" start_char="5247" end_char="5248">on</TOKEN>
<TOKEN id="token-51-12" pos="word" morph="none" start_char="5250" end_char="5252">the</TOKEN>
<TOKEN id="token-51-13" pos="word" morph="none" start_char="5254" end_char="5259">drug’s</TOKEN>
<TOKEN id="token-51-14" pos="word" morph="none" start_char="5261" end_char="5268">efficacy</TOKEN>
<TOKEN id="token-51-15" pos="word" morph="none" start_char="5270" end_char="5272">and</TOKEN>
<TOKEN id="token-51-16" pos="word" morph="none" start_char="5274" end_char="5276">can</TOKEN>
<TOKEN id="token-51-17" pos="word" morph="none" start_char="5278" end_char="5281">help</TOKEN>
<TOKEN id="token-51-18" pos="word" morph="none" start_char="5283" end_char="5290">generate</TOKEN>
<TOKEN id="token-51-19" pos="word" morph="none" start_char="5292" end_char="5301">hypotheses</TOKEN>
<TOKEN id="token-51-20" pos="word" morph="none" start_char="5303" end_char="5305">for</TOKEN>
<TOKEN id="token-51-21" pos="word" morph="none" start_char="5307" end_char="5312">future</TOKEN>
<TOKEN id="token-51-22" pos="word" morph="none" start_char="5314" end_char="5319">trials</TOKEN>
<TOKEN id="token-51-23" pos="punct" morph="none" start_char="5321" end_char="5321">–</TOKEN>
<TOKEN id="token-51-24" pos="word" morph="none" start_char="5323" end_char="5325">but</TOKEN>
<TOKEN id="token-51-25" pos="word" morph="none" start_char="5327" end_char="5331">can’t</TOKEN>
<TOKEN id="token-51-26" pos="word" morph="none" start_char="5333" end_char="5334">be</TOKEN>
<TOKEN id="token-51-27" pos="word" morph="none" start_char="5336" end_char="5338">the</TOKEN>
<TOKEN id="token-51-28" pos="word" morph="none" start_char="5340" end_char="5344">basis</TOKEN>
<TOKEN id="token-51-29" pos="word" morph="none" start_char="5346" end_char="5347">of</TOKEN>
<TOKEN id="token-51-30" pos="word" morph="none" start_char="5349" end_char="5356">efficacy</TOKEN>
<TOKEN id="token-51-31" pos="word" morph="none" start_char="5358" end_char="5363">claims</TOKEN>
<TOKEN id="token-51-32" pos="punct" morph="none" start_char="5364" end_char="5364">.</TOKEN>
</SEG>
<SEG id="segment-52" start_char="5367" end_char="5532">
<ORIGINAL_TEXT>If trials are designed around primary endpoints, it means their sample sizes are also calculated based on how effective the drug is expected to be on these endpoints.</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="5367" end_char="5368">If</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="5370" end_char="5375">trials</TOKEN>
<TOKEN id="token-52-2" pos="word" morph="none" start_char="5377" end_char="5379">are</TOKEN>
<TOKEN id="token-52-3" pos="word" morph="none" start_char="5381" end_char="5388">designed</TOKEN>
<TOKEN id="token-52-4" pos="word" morph="none" start_char="5390" end_char="5395">around</TOKEN>
<TOKEN id="token-52-5" pos="word" morph="none" start_char="5397" end_char="5403">primary</TOKEN>
<TOKEN id="token-52-6" pos="word" morph="none" start_char="5405" end_char="5413">endpoints</TOKEN>
<TOKEN id="token-52-7" pos="punct" morph="none" start_char="5414" end_char="5414">,</TOKEN>
<TOKEN id="token-52-8" pos="word" morph="none" start_char="5416" end_char="5417">it</TOKEN>
<TOKEN id="token-52-9" pos="word" morph="none" start_char="5419" end_char="5423">means</TOKEN>
<TOKEN id="token-52-10" pos="word" morph="none" start_char="5425" end_char="5429">their</TOKEN>
<TOKEN id="token-52-11" pos="word" morph="none" start_char="5431" end_char="5436">sample</TOKEN>
<TOKEN id="token-52-12" pos="word" morph="none" start_char="5438" end_char="5442">sizes</TOKEN>
<TOKEN id="token-52-13" pos="word" morph="none" start_char="5444" end_char="5446">are</TOKEN>
<TOKEN id="token-52-14" pos="word" morph="none" start_char="5448" end_char="5451">also</TOKEN>
<TOKEN id="token-52-15" pos="word" morph="none" start_char="5453" end_char="5462">calculated</TOKEN>
<TOKEN id="token-52-16" pos="word" morph="none" start_char="5464" end_char="5468">based</TOKEN>
<TOKEN id="token-52-17" pos="word" morph="none" start_char="5470" end_char="5471">on</TOKEN>
<TOKEN id="token-52-18" pos="word" morph="none" start_char="5473" end_char="5475">how</TOKEN>
<TOKEN id="token-52-19" pos="word" morph="none" start_char="5477" end_char="5485">effective</TOKEN>
<TOKEN id="token-52-20" pos="word" morph="none" start_char="5487" end_char="5489">the</TOKEN>
<TOKEN id="token-52-21" pos="word" morph="none" start_char="5491" end_char="5494">drug</TOKEN>
<TOKEN id="token-52-22" pos="word" morph="none" start_char="5496" end_char="5497">is</TOKEN>
<TOKEN id="token-52-23" pos="word" morph="none" start_char="5499" end_char="5506">expected</TOKEN>
<TOKEN id="token-52-24" pos="word" morph="none" start_char="5508" end_char="5509">to</TOKEN>
<TOKEN id="token-52-25" pos="word" morph="none" start_char="5511" end_char="5512">be</TOKEN>
<TOKEN id="token-52-26" pos="word" morph="none" start_char="5514" end_char="5515">on</TOKEN>
<TOKEN id="token-52-27" pos="word" morph="none" start_char="5517" end_char="5521">these</TOKEN>
<TOKEN id="token-52-28" pos="word" morph="none" start_char="5523" end_char="5531">endpoints</TOKEN>
<TOKEN id="token-52-29" pos="punct" morph="none" start_char="5532" end_char="5532">.</TOKEN>
</SEG>
<SEG id="segment-53" start_char="5534" end_char="5694">
<ORIGINAL_TEXT>For example, in Glenmark’s favipiravir trial, investigators calculated that for the primary endpoint of viral clearance, they would need to recruit 150 patients.</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="word" morph="none" start_char="5534" end_char="5536">For</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="5538" end_char="5544">example</TOKEN>
<TOKEN id="token-53-2" pos="punct" morph="none" start_char="5545" end_char="5545">,</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="5547" end_char="5548">in</TOKEN>
<TOKEN id="token-53-4" pos="word" morph="none" start_char="5550" end_char="5559">Glenmark’s</TOKEN>
<TOKEN id="token-53-5" pos="word" morph="none" start_char="5561" end_char="5571">favipiravir</TOKEN>
<TOKEN id="token-53-6" pos="word" morph="none" start_char="5573" end_char="5577">trial</TOKEN>
<TOKEN id="token-53-7" pos="punct" morph="none" start_char="5578" end_char="5578">,</TOKEN>
<TOKEN id="token-53-8" pos="word" morph="none" start_char="5580" end_char="5592">investigators</TOKEN>
<TOKEN id="token-53-9" pos="word" morph="none" start_char="5594" end_char="5603">calculated</TOKEN>
<TOKEN id="token-53-10" pos="word" morph="none" start_char="5605" end_char="5608">that</TOKEN>
<TOKEN id="token-53-11" pos="word" morph="none" start_char="5610" end_char="5612">for</TOKEN>
<TOKEN id="token-53-12" pos="word" morph="none" start_char="5614" end_char="5616">the</TOKEN>
<TOKEN id="token-53-13" pos="word" morph="none" start_char="5618" end_char="5624">primary</TOKEN>
<TOKEN id="token-53-14" pos="word" morph="none" start_char="5626" end_char="5633">endpoint</TOKEN>
<TOKEN id="token-53-15" pos="word" morph="none" start_char="5635" end_char="5636">of</TOKEN>
<TOKEN id="token-53-16" pos="word" morph="none" start_char="5638" end_char="5642">viral</TOKEN>
<TOKEN id="token-53-17" pos="word" morph="none" start_char="5644" end_char="5652">clearance</TOKEN>
<TOKEN id="token-53-18" pos="punct" morph="none" start_char="5653" end_char="5653">,</TOKEN>
<TOKEN id="token-53-19" pos="word" morph="none" start_char="5655" end_char="5658">they</TOKEN>
<TOKEN id="token-53-20" pos="word" morph="none" start_char="5660" end_char="5664">would</TOKEN>
<TOKEN id="token-53-21" pos="word" morph="none" start_char="5666" end_char="5669">need</TOKEN>
<TOKEN id="token-53-22" pos="word" morph="none" start_char="5671" end_char="5672">to</TOKEN>
<TOKEN id="token-53-23" pos="word" morph="none" start_char="5674" end_char="5680">recruit</TOKEN>
<TOKEN id="token-53-24" pos="word" morph="none" start_char="5682" end_char="5684">150</TOKEN>
<TOKEN id="token-53-25" pos="word" morph="none" start_char="5686" end_char="5693">patients</TOKEN>
<TOKEN id="token-53-26" pos="punct" morph="none" start_char="5694" end_char="5694">.</TOKEN>
</SEG>
<SEG id="segment-54" start_char="5697" end_char="5785">
<ORIGINAL_TEXT>But when it came to measuring the secondary endpoints, the sample sizes were far smaller.</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="word" morph="none" start_char="5697" end_char="5699">But</TOKEN>
<TOKEN id="token-54-1" pos="word" morph="none" start_char="5701" end_char="5704">when</TOKEN>
<TOKEN id="token-54-2" pos="word" morph="none" start_char="5706" end_char="5707">it</TOKEN>
<TOKEN id="token-54-3" pos="word" morph="none" start_char="5709" end_char="5712">came</TOKEN>
<TOKEN id="token-54-4" pos="word" morph="none" start_char="5714" end_char="5715">to</TOKEN>
<TOKEN id="token-54-5" pos="word" morph="none" start_char="5717" end_char="5725">measuring</TOKEN>
<TOKEN id="token-54-6" pos="word" morph="none" start_char="5727" end_char="5729">the</TOKEN>
<TOKEN id="token-54-7" pos="word" morph="none" start_char="5731" end_char="5739">secondary</TOKEN>
<TOKEN id="token-54-8" pos="word" morph="none" start_char="5741" end_char="5749">endpoints</TOKEN>
<TOKEN id="token-54-9" pos="punct" morph="none" start_char="5750" end_char="5750">,</TOKEN>
<TOKEN id="token-54-10" pos="word" morph="none" start_char="5752" end_char="5754">the</TOKEN>
<TOKEN id="token-54-11" pos="word" morph="none" start_char="5756" end_char="5761">sample</TOKEN>
<TOKEN id="token-54-12" pos="word" morph="none" start_char="5763" end_char="5767">sizes</TOKEN>
<TOKEN id="token-54-13" pos="word" morph="none" start_char="5769" end_char="5772">were</TOKEN>
<TOKEN id="token-54-14" pos="word" morph="none" start_char="5774" end_char="5776">far</TOKEN>
<TOKEN id="token-54-15" pos="word" morph="none" start_char="5778" end_char="5784">smaller</TOKEN>
<TOKEN id="token-54-16" pos="punct" morph="none" start_char="5785" end_char="5785">.</TOKEN>
</SEG>
<SEG id="segment-55" start_char="5787" end_char="5952">
<ORIGINAL_TEXT>To calculate time to clinical cure, for instance, the investigators analysed only 102 patients because only this subset of patients had symptoms like fever and cough.</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="word" morph="none" start_char="5787" end_char="5788">To</TOKEN>
<TOKEN id="token-55-1" pos="word" morph="none" start_char="5790" end_char="5798">calculate</TOKEN>
<TOKEN id="token-55-2" pos="word" morph="none" start_char="5800" end_char="5803">time</TOKEN>
<TOKEN id="token-55-3" pos="word" morph="none" start_char="5805" end_char="5806">to</TOKEN>
<TOKEN id="token-55-4" pos="word" morph="none" start_char="5808" end_char="5815">clinical</TOKEN>
<TOKEN id="token-55-5" pos="word" morph="none" start_char="5817" end_char="5820">cure</TOKEN>
<TOKEN id="token-55-6" pos="punct" morph="none" start_char="5821" end_char="5821">,</TOKEN>
<TOKEN id="token-55-7" pos="word" morph="none" start_char="5823" end_char="5825">for</TOKEN>
<TOKEN id="token-55-8" pos="word" morph="none" start_char="5827" end_char="5834">instance</TOKEN>
<TOKEN id="token-55-9" pos="punct" morph="none" start_char="5835" end_char="5835">,</TOKEN>
<TOKEN id="token-55-10" pos="word" morph="none" start_char="5837" end_char="5839">the</TOKEN>
<TOKEN id="token-55-11" pos="word" morph="none" start_char="5841" end_char="5853">investigators</TOKEN>
<TOKEN id="token-55-12" pos="word" morph="none" start_char="5855" end_char="5862">analysed</TOKEN>
<TOKEN id="token-55-13" pos="word" morph="none" start_char="5864" end_char="5867">only</TOKEN>
<TOKEN id="token-55-14" pos="word" morph="none" start_char="5869" end_char="5871">102</TOKEN>
<TOKEN id="token-55-15" pos="word" morph="none" start_char="5873" end_char="5880">patients</TOKEN>
<TOKEN id="token-55-16" pos="word" morph="none" start_char="5882" end_char="5888">because</TOKEN>
<TOKEN id="token-55-17" pos="word" morph="none" start_char="5890" end_char="5893">only</TOKEN>
<TOKEN id="token-55-18" pos="word" morph="none" start_char="5895" end_char="5898">this</TOKEN>
<TOKEN id="token-55-19" pos="word" morph="none" start_char="5900" end_char="5905">subset</TOKEN>
<TOKEN id="token-55-20" pos="word" morph="none" start_char="5907" end_char="5908">of</TOKEN>
<TOKEN id="token-55-21" pos="word" morph="none" start_char="5910" end_char="5917">patients</TOKEN>
<TOKEN id="token-55-22" pos="word" morph="none" start_char="5919" end_char="5921">had</TOKEN>
<TOKEN id="token-55-23" pos="word" morph="none" start_char="5923" end_char="5930">symptoms</TOKEN>
<TOKEN id="token-55-24" pos="word" morph="none" start_char="5932" end_char="5935">like</TOKEN>
<TOKEN id="token-55-25" pos="word" morph="none" start_char="5937" end_char="5941">fever</TOKEN>
<TOKEN id="token-55-26" pos="word" morph="none" start_char="5943" end_char="5945">and</TOKEN>
<TOKEN id="token-55-27" pos="word" morph="none" start_char="5947" end_char="5951">cough</TOKEN>
<TOKEN id="token-55-28" pos="punct" morph="none" start_char="5952" end_char="5952">.</TOKEN>
</SEG>
<SEG id="segment-56" start_char="5955" end_char="6173">
<ORIGINAL_TEXT>Yet another secondary endpoint was how long patients took to deteriorate enough to need oxygen, ventilation or extracorporeal membrane oxygenation (ECMO, in which an external machine does the job of the heart and lungs.</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="5955" end_char="5957">Yet</TOKEN>
<TOKEN id="token-56-1" pos="word" morph="none" start_char="5959" end_char="5965">another</TOKEN>
<TOKEN id="token-56-2" pos="word" morph="none" start_char="5967" end_char="5975">secondary</TOKEN>
<TOKEN id="token-56-3" pos="word" morph="none" start_char="5977" end_char="5984">endpoint</TOKEN>
<TOKEN id="token-56-4" pos="word" morph="none" start_char="5986" end_char="5988">was</TOKEN>
<TOKEN id="token-56-5" pos="word" morph="none" start_char="5990" end_char="5992">how</TOKEN>
<TOKEN id="token-56-6" pos="word" morph="none" start_char="5994" end_char="5997">long</TOKEN>
<TOKEN id="token-56-7" pos="word" morph="none" start_char="5999" end_char="6006">patients</TOKEN>
<TOKEN id="token-56-8" pos="word" morph="none" start_char="6008" end_char="6011">took</TOKEN>
<TOKEN id="token-56-9" pos="word" morph="none" start_char="6013" end_char="6014">to</TOKEN>
<TOKEN id="token-56-10" pos="word" morph="none" start_char="6016" end_char="6026">deteriorate</TOKEN>
<TOKEN id="token-56-11" pos="word" morph="none" start_char="6028" end_char="6033">enough</TOKEN>
<TOKEN id="token-56-12" pos="word" morph="none" start_char="6035" end_char="6036">to</TOKEN>
<TOKEN id="token-56-13" pos="word" morph="none" start_char="6038" end_char="6041">need</TOKEN>
<TOKEN id="token-56-14" pos="word" morph="none" start_char="6043" end_char="6048">oxygen</TOKEN>
<TOKEN id="token-56-15" pos="punct" morph="none" start_char="6049" end_char="6049">,</TOKEN>
<TOKEN id="token-56-16" pos="word" morph="none" start_char="6051" end_char="6061">ventilation</TOKEN>
<TOKEN id="token-56-17" pos="word" morph="none" start_char="6063" end_char="6064">or</TOKEN>
<TOKEN id="token-56-18" pos="word" morph="none" start_char="6066" end_char="6079">extracorporeal</TOKEN>
<TOKEN id="token-56-19" pos="word" morph="none" start_char="6081" end_char="6088">membrane</TOKEN>
<TOKEN id="token-56-20" pos="word" morph="none" start_char="6090" end_char="6100">oxygenation</TOKEN>
<TOKEN id="token-56-21" pos="punct" morph="none" start_char="6102" end_char="6102">(</TOKEN>
<TOKEN id="token-56-22" pos="word" morph="none" start_char="6103" end_char="6106">ECMO</TOKEN>
<TOKEN id="token-56-23" pos="punct" morph="none" start_char="6107" end_char="6107">,</TOKEN>
<TOKEN id="token-56-24" pos="word" morph="none" start_char="6109" end_char="6110">in</TOKEN>
<TOKEN id="token-56-25" pos="word" morph="none" start_char="6112" end_char="6116">which</TOKEN>
<TOKEN id="token-56-26" pos="word" morph="none" start_char="6118" end_char="6119">an</TOKEN>
<TOKEN id="token-56-27" pos="word" morph="none" start_char="6121" end_char="6128">external</TOKEN>
<TOKEN id="token-56-28" pos="word" morph="none" start_char="6130" end_char="6136">machine</TOKEN>
<TOKEN id="token-56-29" pos="word" morph="none" start_char="6138" end_char="6141">does</TOKEN>
<TOKEN id="token-56-30" pos="word" morph="none" start_char="6143" end_char="6145">the</TOKEN>
<TOKEN id="token-56-31" pos="word" morph="none" start_char="6147" end_char="6149">job</TOKEN>
<TOKEN id="token-56-32" pos="word" morph="none" start_char="6151" end_char="6152">of</TOKEN>
<TOKEN id="token-56-33" pos="word" morph="none" start_char="6154" end_char="6156">the</TOKEN>
<TOKEN id="token-56-34" pos="word" morph="none" start_char="6158" end_char="6162">heart</TOKEN>
<TOKEN id="token-56-35" pos="word" morph="none" start_char="6164" end_char="6166">and</TOKEN>
<TOKEN id="token-56-36" pos="word" morph="none" start_char="6168" end_char="6172">lungs</TOKEN>
<TOKEN id="token-56-37" pos="punct" morph="none" start_char="6173" end_char="6173">.</TOKEN>
</SEG>
<SEG id="segment-57" start_char="6175" end_char="6246">
<ORIGINAL_TEXT>This machine is only deployed when patients worsen even on ventilation).</ORIGINAL_TEXT>
<TOKEN id="token-57-0" pos="word" morph="none" start_char="6175" end_char="6178">This</TOKEN>
<TOKEN id="token-57-1" pos="word" morph="none" start_char="6180" end_char="6186">machine</TOKEN>
<TOKEN id="token-57-2" pos="word" morph="none" start_char="6188" end_char="6189">is</TOKEN>
<TOKEN id="token-57-3" pos="word" morph="none" start_char="6191" end_char="6194">only</TOKEN>
<TOKEN id="token-57-4" pos="word" morph="none" start_char="6196" end_char="6203">deployed</TOKEN>
<TOKEN id="token-57-5" pos="word" morph="none" start_char="6205" end_char="6208">when</TOKEN>
<TOKEN id="token-57-6" pos="word" morph="none" start_char="6210" end_char="6217">patients</TOKEN>
<TOKEN id="token-57-7" pos="word" morph="none" start_char="6219" end_char="6224">worsen</TOKEN>
<TOKEN id="token-57-8" pos="word" morph="none" start_char="6226" end_char="6229">even</TOKEN>
<TOKEN id="token-57-9" pos="word" morph="none" start_char="6231" end_char="6232">on</TOKEN>
<TOKEN id="token-57-10" pos="word" morph="none" start_char="6234" end_char="6244">ventilation</TOKEN>
<TOKEN id="token-57-11" pos="punct" morph="none" start_char="6245" end_char="6246">).</TOKEN>
</SEG>
<SEG id="segment-58" start_char="6248" end_char="6385">
<ORIGINAL_TEXT>The investigators measured this endpoint on a mere 14 patients – because only these patients ended up needing oxygen, ventilation or ECMO.</ORIGINAL_TEXT>
<TOKEN id="token-58-0" pos="word" morph="none" start_char="6248" end_char="6250">The</TOKEN>
<TOKEN id="token-58-1" pos="word" morph="none" start_char="6252" end_char="6264">investigators</TOKEN>
<TOKEN id="token-58-2" pos="word" morph="none" start_char="6266" end_char="6273">measured</TOKEN>
<TOKEN id="token-58-3" pos="word" morph="none" start_char="6275" end_char="6278">this</TOKEN>
<TOKEN id="token-58-4" pos="word" morph="none" start_char="6280" end_char="6287">endpoint</TOKEN>
<TOKEN id="token-58-5" pos="word" morph="none" start_char="6289" end_char="6290">on</TOKEN>
<TOKEN id="token-58-6" pos="word" morph="none" start_char="6292" end_char="6292">a</TOKEN>
<TOKEN id="token-58-7" pos="word" morph="none" start_char="6294" end_char="6297">mere</TOKEN>
<TOKEN id="token-58-8" pos="word" morph="none" start_char="6299" end_char="6300">14</TOKEN>
<TOKEN id="token-58-9" pos="word" morph="none" start_char="6302" end_char="6309">patients</TOKEN>
<TOKEN id="token-58-10" pos="punct" morph="none" start_char="6311" end_char="6311">–</TOKEN>
<TOKEN id="token-58-11" pos="word" morph="none" start_char="6313" end_char="6319">because</TOKEN>
<TOKEN id="token-58-12" pos="word" morph="none" start_char="6321" end_char="6324">only</TOKEN>
<TOKEN id="token-58-13" pos="word" morph="none" start_char="6326" end_char="6330">these</TOKEN>
<TOKEN id="token-58-14" pos="word" morph="none" start_char="6332" end_char="6339">patients</TOKEN>
<TOKEN id="token-58-15" pos="word" morph="none" start_char="6341" end_char="6345">ended</TOKEN>
<TOKEN id="token-58-16" pos="word" morph="none" start_char="6347" end_char="6348">up</TOKEN>
<TOKEN id="token-58-17" pos="word" morph="none" start_char="6350" end_char="6356">needing</TOKEN>
<TOKEN id="token-58-18" pos="word" morph="none" start_char="6358" end_char="6363">oxygen</TOKEN>
<TOKEN id="token-58-19" pos="punct" morph="none" start_char="6364" end_char="6364">,</TOKEN>
<TOKEN id="token-58-20" pos="word" morph="none" start_char="6366" end_char="6376">ventilation</TOKEN>
<TOKEN id="token-58-21" pos="word" morph="none" start_char="6378" end_char="6379">or</TOKEN>
<TOKEN id="token-58-22" pos="word" morph="none" start_char="6381" end_char="6384">ECMO</TOKEN>
<TOKEN id="token-58-23" pos="punct" morph="none" start_char="6385" end_char="6385">.</TOKEN>
</SEG>
<SEG id="segment-59" start_char="6388" end_char="6501">
<ORIGINAL_TEXT>Yet Glenmark cited its findings among these small groups to bolster its argument that favipiravir helped patients.</ORIGINAL_TEXT>
<TOKEN id="token-59-0" pos="word" morph="none" start_char="6388" end_char="6390">Yet</TOKEN>
<TOKEN id="token-59-1" pos="word" morph="none" start_char="6392" end_char="6399">Glenmark</TOKEN>
<TOKEN id="token-59-2" pos="word" morph="none" start_char="6401" end_char="6405">cited</TOKEN>
<TOKEN id="token-59-3" pos="word" morph="none" start_char="6407" end_char="6409">its</TOKEN>
<TOKEN id="token-59-4" pos="word" morph="none" start_char="6411" end_char="6418">findings</TOKEN>
<TOKEN id="token-59-5" pos="word" morph="none" start_char="6420" end_char="6424">among</TOKEN>
<TOKEN id="token-59-6" pos="word" morph="none" start_char="6426" end_char="6430">these</TOKEN>
<TOKEN id="token-59-7" pos="word" morph="none" start_char="6432" end_char="6436">small</TOKEN>
<TOKEN id="token-59-8" pos="word" morph="none" start_char="6438" end_char="6443">groups</TOKEN>
<TOKEN id="token-59-9" pos="word" morph="none" start_char="6445" end_char="6446">to</TOKEN>
<TOKEN id="token-59-10" pos="word" morph="none" start_char="6448" end_char="6454">bolster</TOKEN>
<TOKEN id="token-59-11" pos="word" morph="none" start_char="6456" end_char="6458">its</TOKEN>
<TOKEN id="token-59-12" pos="word" morph="none" start_char="6460" end_char="6467">argument</TOKEN>
<TOKEN id="token-59-13" pos="word" morph="none" start_char="6469" end_char="6472">that</TOKEN>
<TOKEN id="token-59-14" pos="word" morph="none" start_char="6474" end_char="6484">favipiravir</TOKEN>
<TOKEN id="token-59-15" pos="word" morph="none" start_char="6486" end_char="6491">helped</TOKEN>
<TOKEN id="token-59-16" pos="word" morph="none" start_char="6493" end_char="6500">patients</TOKEN>
<TOKEN id="token-59-17" pos="punct" morph="none" start_char="6501" end_char="6501">.</TOKEN>
</SEG>
<SEG id="segment-60" start_char="6503" end_char="6568">
<ORIGINAL_TEXT>Such tiny sample sizes make such comparisons meaningless, sad Rao.</ORIGINAL_TEXT>
<TOKEN id="token-60-0" pos="word" morph="none" start_char="6503" end_char="6506">Such</TOKEN>
<TOKEN id="token-60-1" pos="word" morph="none" start_char="6508" end_char="6511">tiny</TOKEN>
<TOKEN id="token-60-2" pos="word" morph="none" start_char="6513" end_char="6518">sample</TOKEN>
<TOKEN id="token-60-3" pos="word" morph="none" start_char="6520" end_char="6524">sizes</TOKEN>
<TOKEN id="token-60-4" pos="word" morph="none" start_char="6526" end_char="6529">make</TOKEN>
<TOKEN id="token-60-5" pos="word" morph="none" start_char="6531" end_char="6534">such</TOKEN>
<TOKEN id="token-60-6" pos="word" morph="none" start_char="6536" end_char="6546">comparisons</TOKEN>
<TOKEN id="token-60-7" pos="word" morph="none" start_char="6548" end_char="6558">meaningless</TOKEN>
<TOKEN id="token-60-8" pos="punct" morph="none" start_char="6559" end_char="6559">,</TOKEN>
<TOKEN id="token-60-9" pos="word" morph="none" start_char="6561" end_char="6563">sad</TOKEN>
<TOKEN id="token-60-10" pos="word" morph="none" start_char="6565" end_char="6567">Rao</TOKEN>
<TOKEN id="token-60-11" pos="punct" morph="none" start_char="6568" end_char="6568">.</TOKEN>
</SEG>
<SEG id="segment-61" start_char="6570" end_char="6670">
<ORIGINAL_TEXT>"The time to needing oxygen is based on so few patients that it is best not to draw any conclusions."</ORIGINAL_TEXT>
<TOKEN id="token-61-0" pos="punct" morph="none" start_char="6570" end_char="6570">"</TOKEN>
<TOKEN id="token-61-1" pos="word" morph="none" start_char="6571" end_char="6573">The</TOKEN>
<TOKEN id="token-61-2" pos="word" morph="none" start_char="6575" end_char="6578">time</TOKEN>
<TOKEN id="token-61-3" pos="word" morph="none" start_char="6580" end_char="6581">to</TOKEN>
<TOKEN id="token-61-4" pos="word" morph="none" start_char="6583" end_char="6589">needing</TOKEN>
<TOKEN id="token-61-5" pos="word" morph="none" start_char="6591" end_char="6596">oxygen</TOKEN>
<TOKEN id="token-61-6" pos="word" morph="none" start_char="6598" end_char="6599">is</TOKEN>
<TOKEN id="token-61-7" pos="word" morph="none" start_char="6601" end_char="6605">based</TOKEN>
<TOKEN id="token-61-8" pos="word" morph="none" start_char="6607" end_char="6608">on</TOKEN>
<TOKEN id="token-61-9" pos="word" morph="none" start_char="6610" end_char="6611">so</TOKEN>
<TOKEN id="token-61-10" pos="word" morph="none" start_char="6613" end_char="6615">few</TOKEN>
<TOKEN id="token-61-11" pos="word" morph="none" start_char="6617" end_char="6624">patients</TOKEN>
<TOKEN id="token-61-12" pos="word" morph="none" start_char="6626" end_char="6629">that</TOKEN>
<TOKEN id="token-61-13" pos="word" morph="none" start_char="6631" end_char="6632">it</TOKEN>
<TOKEN id="token-61-14" pos="word" morph="none" start_char="6634" end_char="6635">is</TOKEN>
<TOKEN id="token-61-15" pos="word" morph="none" start_char="6637" end_char="6640">best</TOKEN>
<TOKEN id="token-61-16" pos="word" morph="none" start_char="6642" end_char="6644">not</TOKEN>
<TOKEN id="token-61-17" pos="word" morph="none" start_char="6646" end_char="6647">to</TOKEN>
<TOKEN id="token-61-18" pos="word" morph="none" start_char="6649" end_char="6652">draw</TOKEN>
<TOKEN id="token-61-19" pos="word" morph="none" start_char="6654" end_char="6656">any</TOKEN>
<TOKEN id="token-61-20" pos="word" morph="none" start_char="6658" end_char="6668">conclusions</TOKEN>
<TOKEN id="token-61-21" pos="punct" morph="none" start_char="6669" end_char="6670">."</TOKEN>
</SEG>
<SEG id="segment-62" start_char="6673" end_char="6703">
<ORIGINAL_TEXT>In their replies to emails from</ORIGINAL_TEXT>
<TOKEN id="token-62-0" pos="word" morph="none" start_char="6673" end_char="6674">In</TOKEN>
<TOKEN id="token-62-1" pos="word" morph="none" start_char="6676" end_char="6680">their</TOKEN>
<TOKEN id="token-62-2" pos="word" morph="none" start_char="6682" end_char="6688">replies</TOKEN>
<TOKEN id="token-62-3" pos="word" morph="none" start_char="6690" end_char="6691">to</TOKEN>
<TOKEN id="token-62-4" pos="word" morph="none" start_char="6693" end_char="6698">emails</TOKEN>
<TOKEN id="token-62-5" pos="word" morph="none" start_char="6700" end_char="6703">from</TOKEN>
</SEG>
<SEG id="segment-63" start_char="6706" end_char="6721">
<ORIGINAL_TEXT>The Wire Science</ORIGINAL_TEXT>
<TOKEN id="token-63-0" pos="word" morph="none" start_char="6706" end_char="6708">The</TOKEN>
<TOKEN id="token-63-1" pos="word" morph="none" start_char="6710" end_char="6713">Wire</TOKEN>
<TOKEN id="token-63-2" pos="word" morph="none" start_char="6715" end_char="6721">Science</TOKEN>
</SEG>
<SEG id="segment-64" start_char="6724" end_char="6813">
<ORIGINAL_TEXT>, the trial investigators defended their decision to rely on secondary endpoints, however.</ORIGINAL_TEXT>
<TOKEN id="token-64-0" pos="punct" morph="none" start_char="6724" end_char="6724">,</TOKEN>
<TOKEN id="token-64-1" pos="word" morph="none" start_char="6726" end_char="6728">the</TOKEN>
<TOKEN id="token-64-2" pos="word" morph="none" start_char="6730" end_char="6734">trial</TOKEN>
<TOKEN id="token-64-3" pos="word" morph="none" start_char="6736" end_char="6748">investigators</TOKEN>
<TOKEN id="token-64-4" pos="word" morph="none" start_char="6750" end_char="6757">defended</TOKEN>
<TOKEN id="token-64-5" pos="word" morph="none" start_char="6759" end_char="6763">their</TOKEN>
<TOKEN id="token-64-6" pos="word" morph="none" start_char="6765" end_char="6772">decision</TOKEN>
<TOKEN id="token-64-7" pos="word" morph="none" start_char="6774" end_char="6775">to</TOKEN>
<TOKEN id="token-64-8" pos="word" morph="none" start_char="6777" end_char="6780">rely</TOKEN>
<TOKEN id="token-64-9" pos="word" morph="none" start_char="6782" end_char="6783">on</TOKEN>
<TOKEN id="token-64-10" pos="word" morph="none" start_char="6785" end_char="6793">secondary</TOKEN>
<TOKEN id="token-64-11" pos="word" morph="none" start_char="6795" end_char="6803">endpoints</TOKEN>
<TOKEN id="token-64-12" pos="punct" morph="none" start_char="6804" end_char="6804">,</TOKEN>
<TOKEN id="token-64-13" pos="word" morph="none" start_char="6806" end_char="6812">however</TOKEN>
<TOKEN id="token-64-14" pos="punct" morph="none" start_char="6813" end_char="6813">.</TOKEN>
</SEG>
<SEG id="segment-65" start_char="6815" end_char="7039">
<ORIGINAL_TEXT>Monika Tandon, the head of clinical development at Glenmark and an investigator on the trial, said the scientific understanding of viral clearance, as measured with RT-PCR tests, had evolved during the course of the pandemic.</ORIGINAL_TEXT>
<TOKEN id="token-65-0" pos="word" morph="none" start_char="6815" end_char="6820">Monika</TOKEN>
<TOKEN id="token-65-1" pos="word" morph="none" start_char="6822" end_char="6827">Tandon</TOKEN>
<TOKEN id="token-65-2" pos="punct" morph="none" start_char="6828" end_char="6828">,</TOKEN>
<TOKEN id="token-65-3" pos="word" morph="none" start_char="6830" end_char="6832">the</TOKEN>
<TOKEN id="token-65-4" pos="word" morph="none" start_char="6834" end_char="6837">head</TOKEN>
<TOKEN id="token-65-5" pos="word" morph="none" start_char="6839" end_char="6840">of</TOKEN>
<TOKEN id="token-65-6" pos="word" morph="none" start_char="6842" end_char="6849">clinical</TOKEN>
<TOKEN id="token-65-7" pos="word" morph="none" start_char="6851" end_char="6861">development</TOKEN>
<TOKEN id="token-65-8" pos="word" morph="none" start_char="6863" end_char="6864">at</TOKEN>
<TOKEN id="token-65-9" pos="word" morph="none" start_char="6866" end_char="6873">Glenmark</TOKEN>
<TOKEN id="token-65-10" pos="word" morph="none" start_char="6875" end_char="6877">and</TOKEN>
<TOKEN id="token-65-11" pos="word" morph="none" start_char="6879" end_char="6880">an</TOKEN>
<TOKEN id="token-65-12" pos="word" morph="none" start_char="6882" end_char="6893">investigator</TOKEN>
<TOKEN id="token-65-13" pos="word" morph="none" start_char="6895" end_char="6896">on</TOKEN>
<TOKEN id="token-65-14" pos="word" morph="none" start_char="6898" end_char="6900">the</TOKEN>
<TOKEN id="token-65-15" pos="word" morph="none" start_char="6902" end_char="6906">trial</TOKEN>
<TOKEN id="token-65-16" pos="punct" morph="none" start_char="6907" end_char="6907">,</TOKEN>
<TOKEN id="token-65-17" pos="word" morph="none" start_char="6909" end_char="6912">said</TOKEN>
<TOKEN id="token-65-18" pos="word" morph="none" start_char="6914" end_char="6916">the</TOKEN>
<TOKEN id="token-65-19" pos="word" morph="none" start_char="6918" end_char="6927">scientific</TOKEN>
<TOKEN id="token-65-20" pos="word" morph="none" start_char="6929" end_char="6941">understanding</TOKEN>
<TOKEN id="token-65-21" pos="word" morph="none" start_char="6943" end_char="6944">of</TOKEN>
<TOKEN id="token-65-22" pos="word" morph="none" start_char="6946" end_char="6950">viral</TOKEN>
<TOKEN id="token-65-23" pos="word" morph="none" start_char="6952" end_char="6960">clearance</TOKEN>
<TOKEN id="token-65-24" pos="punct" morph="none" start_char="6961" end_char="6961">,</TOKEN>
<TOKEN id="token-65-25" pos="word" morph="none" start_char="6963" end_char="6964">as</TOKEN>
<TOKEN id="token-65-26" pos="word" morph="none" start_char="6966" end_char="6973">measured</TOKEN>
<TOKEN id="token-65-27" pos="word" morph="none" start_char="6975" end_char="6978">with</TOKEN>
<TOKEN id="token-65-28" pos="unknown" morph="none" start_char="6980" end_char="6985">RT-PCR</TOKEN>
<TOKEN id="token-65-29" pos="word" morph="none" start_char="6987" end_char="6991">tests</TOKEN>
<TOKEN id="token-65-30" pos="punct" morph="none" start_char="6992" end_char="6992">,</TOKEN>
<TOKEN id="token-65-31" pos="word" morph="none" start_char="6994" end_char="6996">had</TOKEN>
<TOKEN id="token-65-32" pos="word" morph="none" start_char="6998" end_char="7004">evolved</TOKEN>
<TOKEN id="token-65-33" pos="word" morph="none" start_char="7006" end_char="7011">during</TOKEN>
<TOKEN id="token-65-34" pos="word" morph="none" start_char="7013" end_char="7015">the</TOKEN>
<TOKEN id="token-65-35" pos="word" morph="none" start_char="7017" end_char="7022">course</TOKEN>
<TOKEN id="token-65-36" pos="word" morph="none" start_char="7024" end_char="7025">of</TOKEN>
<TOKEN id="token-65-37" pos="word" morph="none" start_char="7027" end_char="7029">the</TOKEN>
<TOKEN id="token-65-38" pos="word" morph="none" start_char="7031" end_char="7038">pandemic</TOKEN>
<TOKEN id="token-65-39" pos="punct" morph="none" start_char="7039" end_char="7039">.</TOKEN>
</SEG>
<SEG id="segment-66" start_char="7042" end_char="7189">
<ORIGINAL_TEXT>According to her, when the trial protocol was drafted in March, RT-PCR tests were thought to reflect the duration of COVID-19 infections accurately.</ORIGINAL_TEXT>
<TOKEN id="token-66-0" pos="word" morph="none" start_char="7042" end_char="7050">According</TOKEN>
<TOKEN id="token-66-1" pos="word" morph="none" start_char="7052" end_char="7053">to</TOKEN>
<TOKEN id="token-66-2" pos="word" morph="none" start_char="7055" end_char="7057">her</TOKEN>
<TOKEN id="token-66-3" pos="punct" morph="none" start_char="7058" end_char="7058">,</TOKEN>
<TOKEN id="token-66-4" pos="word" morph="none" start_char="7060" end_char="7063">when</TOKEN>
<TOKEN id="token-66-5" pos="word" morph="none" start_char="7065" end_char="7067">the</TOKEN>
<TOKEN id="token-66-6" pos="word" morph="none" start_char="7069" end_char="7073">trial</TOKEN>
<TOKEN id="token-66-7" pos="word" morph="none" start_char="7075" end_char="7082">protocol</TOKEN>
<TOKEN id="token-66-8" pos="word" morph="none" start_char="7084" end_char="7086">was</TOKEN>
<TOKEN id="token-66-9" pos="word" morph="none" start_char="7088" end_char="7094">drafted</TOKEN>
<TOKEN id="token-66-10" pos="word" morph="none" start_char="7096" end_char="7097">in</TOKEN>
<TOKEN id="token-66-11" pos="word" morph="none" start_char="7099" end_char="7103">March</TOKEN>
<TOKEN id="token-66-12" pos="punct" morph="none" start_char="7104" end_char="7104">,</TOKEN>
<TOKEN id="token-66-13" pos="unknown" morph="none" start_char="7106" end_char="7111">RT-PCR</TOKEN>
<TOKEN id="token-66-14" pos="word" morph="none" start_char="7113" end_char="7117">tests</TOKEN>
<TOKEN id="token-66-15" pos="word" morph="none" start_char="7119" end_char="7122">were</TOKEN>
<TOKEN id="token-66-16" pos="word" morph="none" start_char="7124" end_char="7130">thought</TOKEN>
<TOKEN id="token-66-17" pos="word" morph="none" start_char="7132" end_char="7133">to</TOKEN>
<TOKEN id="token-66-18" pos="word" morph="none" start_char="7135" end_char="7141">reflect</TOKEN>
<TOKEN id="token-66-19" pos="word" morph="none" start_char="7143" end_char="7145">the</TOKEN>
<TOKEN id="token-66-20" pos="word" morph="none" start_char="7147" end_char="7154">duration</TOKEN>
<TOKEN id="token-66-21" pos="word" morph="none" start_char="7156" end_char="7157">of</TOKEN>
<TOKEN id="token-66-22" pos="unknown" morph="none" start_char="7159" end_char="7166">COVID-19</TOKEN>
<TOKEN id="token-66-23" pos="word" morph="none" start_char="7168" end_char="7177">infections</TOKEN>
<TOKEN id="token-66-24" pos="word" morph="none" start_char="7179" end_char="7188">accurately</TOKEN>
<TOKEN id="token-66-25" pos="punct" morph="none" start_char="7189" end_char="7189">.</TOKEN>
</SEG>
<SEG id="segment-67" start_char="7191" end_char="7244">
<ORIGINAL_TEXT>"RT-PCR was the primary endpoint in most trials then."</ORIGINAL_TEXT>
<TOKEN id="token-67-0" pos="punct" morph="none" start_char="7191" end_char="7191">"</TOKEN>
<TOKEN id="token-67-1" pos="unknown" morph="none" start_char="7192" end_char="7197">RT-PCR</TOKEN>
<TOKEN id="token-67-2" pos="word" morph="none" start_char="7199" end_char="7201">was</TOKEN>
<TOKEN id="token-67-3" pos="word" morph="none" start_char="7203" end_char="7205">the</TOKEN>
<TOKEN id="token-67-4" pos="word" morph="none" start_char="7207" end_char="7213">primary</TOKEN>
<TOKEN id="token-67-5" pos="word" morph="none" start_char="7215" end_char="7222">endpoint</TOKEN>
<TOKEN id="token-67-6" pos="word" morph="none" start_char="7224" end_char="7225">in</TOKEN>
<TOKEN id="token-67-7" pos="word" morph="none" start_char="7227" end_char="7230">most</TOKEN>
<TOKEN id="token-67-8" pos="word" morph="none" start_char="7232" end_char="7237">trials</TOKEN>
<TOKEN id="token-67-9" pos="word" morph="none" start_char="7239" end_char="7242">then</TOKEN>
<TOKEN id="token-67-10" pos="punct" morph="none" start_char="7243" end_char="7244">."</TOKEN>
</SEG>
<SEG id="segment-68" start_char="7246" end_char="7355">
<ORIGINAL_TEXT>But later studies showed that patients could remain RT-PCR-positive long after they had been clinically cured.</ORIGINAL_TEXT>
<TOKEN id="token-68-0" pos="word" morph="none" start_char="7246" end_char="7248">But</TOKEN>
<TOKEN id="token-68-1" pos="word" morph="none" start_char="7250" end_char="7254">later</TOKEN>
<TOKEN id="token-68-2" pos="word" morph="none" start_char="7256" end_char="7262">studies</TOKEN>
<TOKEN id="token-68-3" pos="word" morph="none" start_char="7264" end_char="7269">showed</TOKEN>
<TOKEN id="token-68-4" pos="word" morph="none" start_char="7271" end_char="7274">that</TOKEN>
<TOKEN id="token-68-5" pos="word" morph="none" start_char="7276" end_char="7283">patients</TOKEN>
<TOKEN id="token-68-6" pos="word" morph="none" start_char="7285" end_char="7289">could</TOKEN>
<TOKEN id="token-68-7" pos="word" morph="none" start_char="7291" end_char="7296">remain</TOKEN>
<TOKEN id="token-68-8" pos="unknown" morph="none" start_char="7298" end_char="7312">RT-PCR-positive</TOKEN>
<TOKEN id="token-68-9" pos="word" morph="none" start_char="7314" end_char="7317">long</TOKEN>
<TOKEN id="token-68-10" pos="word" morph="none" start_char="7319" end_char="7323">after</TOKEN>
<TOKEN id="token-68-11" pos="word" morph="none" start_char="7325" end_char="7328">they</TOKEN>
<TOKEN id="token-68-12" pos="word" morph="none" start_char="7330" end_char="7332">had</TOKEN>
<TOKEN id="token-68-13" pos="word" morph="none" start_char="7334" end_char="7337">been</TOKEN>
<TOKEN id="token-68-14" pos="word" morph="none" start_char="7339" end_char="7348">clinically</TOKEN>
<TOKEN id="token-68-15" pos="word" morph="none" start_char="7350" end_char="7354">cured</TOKEN>
<TOKEN id="token-68-16" pos="punct" morph="none" start_char="7355" end_char="7355">.</TOKEN>
</SEG>
<SEG id="segment-69" start_char="7357" end_char="7448">
<ORIGINAL_TEXT>This explained why the primary endpoint did not correlate well with clinical cure, she said.</ORIGINAL_TEXT>
<TOKEN id="token-69-0" pos="word" morph="none" start_char="7357" end_char="7360">This</TOKEN>
<TOKEN id="token-69-1" pos="word" morph="none" start_char="7362" end_char="7370">explained</TOKEN>
<TOKEN id="token-69-2" pos="word" morph="none" start_char="7372" end_char="7374">why</TOKEN>
<TOKEN id="token-69-3" pos="word" morph="none" start_char="7376" end_char="7378">the</TOKEN>
<TOKEN id="token-69-4" pos="word" morph="none" start_char="7380" end_char="7386">primary</TOKEN>
<TOKEN id="token-69-5" pos="word" morph="none" start_char="7388" end_char="7395">endpoint</TOKEN>
<TOKEN id="token-69-6" pos="word" morph="none" start_char="7397" end_char="7399">did</TOKEN>
<TOKEN id="token-69-7" pos="word" morph="none" start_char="7401" end_char="7403">not</TOKEN>
<TOKEN id="token-69-8" pos="word" morph="none" start_char="7405" end_char="7413">correlate</TOKEN>
<TOKEN id="token-69-9" pos="word" morph="none" start_char="7415" end_char="7418">well</TOKEN>
<TOKEN id="token-69-10" pos="word" morph="none" start_char="7420" end_char="7423">with</TOKEN>
<TOKEN id="token-69-11" pos="word" morph="none" start_char="7425" end_char="7432">clinical</TOKEN>
<TOKEN id="token-69-12" pos="word" morph="none" start_char="7434" end_char="7437">cure</TOKEN>
<TOKEN id="token-69-13" pos="punct" morph="none" start_char="7438" end_char="7438">,</TOKEN>
<TOKEN id="token-69-14" pos="word" morph="none" start_char="7440" end_char="7442">she</TOKEN>
<TOKEN id="token-69-15" pos="word" morph="none" start_char="7444" end_char="7447">said</TOKEN>
<TOKEN id="token-69-16" pos="punct" morph="none" start_char="7448" end_char="7448">.</TOKEN>
</SEG>
<SEG id="segment-70" start_char="7451" end_char="7520">
<ORIGINAL_TEXT>Udwadia added that analysing secondary endpoints was not that unusual.</ORIGINAL_TEXT>
<TOKEN id="token-70-0" pos="word" morph="none" start_char="7451" end_char="7457">Udwadia</TOKEN>
<TOKEN id="token-70-1" pos="word" morph="none" start_char="7459" end_char="7463">added</TOKEN>
<TOKEN id="token-70-2" pos="word" morph="none" start_char="7465" end_char="7468">that</TOKEN>
<TOKEN id="token-70-3" pos="word" morph="none" start_char="7470" end_char="7478">analysing</TOKEN>
<TOKEN id="token-70-4" pos="word" morph="none" start_char="7480" end_char="7488">secondary</TOKEN>
<TOKEN id="token-70-5" pos="word" morph="none" start_char="7490" end_char="7498">endpoints</TOKEN>
<TOKEN id="token-70-6" pos="word" morph="none" start_char="7500" end_char="7502">was</TOKEN>
<TOKEN id="token-70-7" pos="word" morph="none" start_char="7504" end_char="7506">not</TOKEN>
<TOKEN id="token-70-8" pos="word" morph="none" start_char="7508" end_char="7511">that</TOKEN>
<TOKEN id="token-70-9" pos="word" morph="none" start_char="7513" end_char="7519">unusual</TOKEN>
<TOKEN id="token-70-10" pos="punct" morph="none" start_char="7520" end_char="7520">.</TOKEN>
</SEG>
<SEG id="segment-71" start_char="7522" end_char="7677">
<ORIGINAL_TEXT>"If the primary endpoints were all that were looked at, there would be no successful COVID-19 trial except for dexamethasone in all of COVID-19 literature."</ORIGINAL_TEXT>
<TOKEN id="token-71-0" pos="punct" morph="none" start_char="7522" end_char="7522">"</TOKEN>
<TOKEN id="token-71-1" pos="word" morph="none" start_char="7523" end_char="7524">If</TOKEN>
<TOKEN id="token-71-2" pos="word" morph="none" start_char="7526" end_char="7528">the</TOKEN>
<TOKEN id="token-71-3" pos="word" morph="none" start_char="7530" end_char="7536">primary</TOKEN>
<TOKEN id="token-71-4" pos="word" morph="none" start_char="7538" end_char="7546">endpoints</TOKEN>
<TOKEN id="token-71-5" pos="word" morph="none" start_char="7548" end_char="7551">were</TOKEN>
<TOKEN id="token-71-6" pos="word" morph="none" start_char="7553" end_char="7555">all</TOKEN>
<TOKEN id="token-71-7" pos="word" morph="none" start_char="7557" end_char="7560">that</TOKEN>
<TOKEN id="token-71-8" pos="word" morph="none" start_char="7562" end_char="7565">were</TOKEN>
<TOKEN id="token-71-9" pos="word" morph="none" start_char="7567" end_char="7572">looked</TOKEN>
<TOKEN id="token-71-10" pos="word" morph="none" start_char="7574" end_char="7575">at</TOKEN>
<TOKEN id="token-71-11" pos="punct" morph="none" start_char="7576" end_char="7576">,</TOKEN>
<TOKEN id="token-71-12" pos="word" morph="none" start_char="7578" end_char="7582">there</TOKEN>
<TOKEN id="token-71-13" pos="word" morph="none" start_char="7584" end_char="7588">would</TOKEN>
<TOKEN id="token-71-14" pos="word" morph="none" start_char="7590" end_char="7591">be</TOKEN>
<TOKEN id="token-71-15" pos="word" morph="none" start_char="7593" end_char="7594">no</TOKEN>
<TOKEN id="token-71-16" pos="word" morph="none" start_char="7596" end_char="7605">successful</TOKEN>
<TOKEN id="token-71-17" pos="unknown" morph="none" start_char="7607" end_char="7614">COVID-19</TOKEN>
<TOKEN id="token-71-18" pos="word" morph="none" start_char="7616" end_char="7620">trial</TOKEN>
<TOKEN id="token-71-19" pos="word" morph="none" start_char="7622" end_char="7627">except</TOKEN>
<TOKEN id="token-71-20" pos="word" morph="none" start_char="7629" end_char="7631">for</TOKEN>
<TOKEN id="token-71-21" pos="word" morph="none" start_char="7633" end_char="7645">dexamethasone</TOKEN>
<TOKEN id="token-71-22" pos="word" morph="none" start_char="7647" end_char="7648">in</TOKEN>
<TOKEN id="token-71-23" pos="word" morph="none" start_char="7650" end_char="7652">all</TOKEN>
<TOKEN id="token-71-24" pos="word" morph="none" start_char="7654" end_char="7655">of</TOKEN>
<TOKEN id="token-71-25" pos="unknown" morph="none" start_char="7657" end_char="7664">COVID-19</TOKEN>
<TOKEN id="token-71-26" pos="word" morph="none" start_char="7666" end_char="7675">literature</TOKEN>
<TOKEN id="token-71-27" pos="punct" morph="none" start_char="7676" end_char="7677">."</TOKEN>
</SEG>
<SEG id="segment-72" start_char="7679" end_char="7888">
<ORIGINAL_TEXT>He added that compared to drugs like hydroxychloroquine, ivermectin and tocilizumab, which have been used with little evidence, the small improvements in clinical cure that favipiravir showed were "meaningful".</ORIGINAL_TEXT>
<TOKEN id="token-72-0" pos="word" morph="none" start_char="7679" end_char="7680">He</TOKEN>
<TOKEN id="token-72-1" pos="word" morph="none" start_char="7682" end_char="7686">added</TOKEN>
<TOKEN id="token-72-2" pos="word" morph="none" start_char="7688" end_char="7691">that</TOKEN>
<TOKEN id="token-72-3" pos="word" morph="none" start_char="7693" end_char="7700">compared</TOKEN>
<TOKEN id="token-72-4" pos="word" morph="none" start_char="7702" end_char="7703">to</TOKEN>
<TOKEN id="token-72-5" pos="word" morph="none" start_char="7705" end_char="7709">drugs</TOKEN>
<TOKEN id="token-72-6" pos="word" morph="none" start_char="7711" end_char="7714">like</TOKEN>
<TOKEN id="token-72-7" pos="word" morph="none" start_char="7716" end_char="7733">hydroxychloroquine</TOKEN>
<TOKEN id="token-72-8" pos="punct" morph="none" start_char="7734" end_char="7734">,</TOKEN>
<TOKEN id="token-72-9" pos="word" morph="none" start_char="7736" end_char="7745">ivermectin</TOKEN>
<TOKEN id="token-72-10" pos="word" morph="none" start_char="7747" end_char="7749">and</TOKEN>
<TOKEN id="token-72-11" pos="word" morph="none" start_char="7751" end_char="7761">tocilizumab</TOKEN>
<TOKEN id="token-72-12" pos="punct" morph="none" start_char="7762" end_char="7762">,</TOKEN>
<TOKEN id="token-72-13" pos="word" morph="none" start_char="7764" end_char="7768">which</TOKEN>
<TOKEN id="token-72-14" pos="word" morph="none" start_char="7770" end_char="7773">have</TOKEN>
<TOKEN id="token-72-15" pos="word" morph="none" start_char="7775" end_char="7778">been</TOKEN>
<TOKEN id="token-72-16" pos="word" morph="none" start_char="7780" end_char="7783">used</TOKEN>
<TOKEN id="token-72-17" pos="word" morph="none" start_char="7785" end_char="7788">with</TOKEN>
<TOKEN id="token-72-18" pos="word" morph="none" start_char="7790" end_char="7795">little</TOKEN>
<TOKEN id="token-72-19" pos="word" morph="none" start_char="7797" end_char="7804">evidence</TOKEN>
<TOKEN id="token-72-20" pos="punct" morph="none" start_char="7805" end_char="7805">,</TOKEN>
<TOKEN id="token-72-21" pos="word" morph="none" start_char="7807" end_char="7809">the</TOKEN>
<TOKEN id="token-72-22" pos="word" morph="none" start_char="7811" end_char="7815">small</TOKEN>
<TOKEN id="token-72-23" pos="word" morph="none" start_char="7817" end_char="7828">improvements</TOKEN>
<TOKEN id="token-72-24" pos="word" morph="none" start_char="7830" end_char="7831">in</TOKEN>
<TOKEN id="token-72-25" pos="word" morph="none" start_char="7833" end_char="7840">clinical</TOKEN>
<TOKEN id="token-72-26" pos="word" morph="none" start_char="7842" end_char="7845">cure</TOKEN>
<TOKEN id="token-72-27" pos="word" morph="none" start_char="7847" end_char="7850">that</TOKEN>
<TOKEN id="token-72-28" pos="word" morph="none" start_char="7852" end_char="7862">favipiravir</TOKEN>
<TOKEN id="token-72-29" pos="word" morph="none" start_char="7864" end_char="7869">showed</TOKEN>
<TOKEN id="token-72-30" pos="word" morph="none" start_char="7871" end_char="7874">were</TOKEN>
<TOKEN id="token-72-31" pos="punct" morph="none" start_char="7876" end_char="7876">"</TOKEN>
<TOKEN id="token-72-32" pos="word" morph="none" start_char="7877" end_char="7886">meaningful</TOKEN>
<TOKEN id="token-72-33" pos="punct" morph="none" start_char="7887" end_char="7888">".</TOKEN>
</SEG>
<SEG id="segment-73" start_char="7891" end_char="8073">
<ORIGINAL_TEXT>While it’s true that pharmaceutical companies have been known to cherry-pick from secondary endpoints to make claims about drugs’ efficacies, experts say this practice is a big no-no.</ORIGINAL_TEXT>
<TOKEN id="token-73-0" pos="word" morph="none" start_char="7891" end_char="7895">While</TOKEN>
<TOKEN id="token-73-1" pos="word" morph="none" start_char="7897" end_char="7900">it’s</TOKEN>
<TOKEN id="token-73-2" pos="word" morph="none" start_char="7902" end_char="7905">true</TOKEN>
<TOKEN id="token-73-3" pos="word" morph="none" start_char="7907" end_char="7910">that</TOKEN>
<TOKEN id="token-73-4" pos="word" morph="none" start_char="7912" end_char="7925">pharmaceutical</TOKEN>
<TOKEN id="token-73-5" pos="word" morph="none" start_char="7927" end_char="7935">companies</TOKEN>
<TOKEN id="token-73-6" pos="word" morph="none" start_char="7937" end_char="7940">have</TOKEN>
<TOKEN id="token-73-7" pos="word" morph="none" start_char="7942" end_char="7945">been</TOKEN>
<TOKEN id="token-73-8" pos="word" morph="none" start_char="7947" end_char="7951">known</TOKEN>
<TOKEN id="token-73-9" pos="word" morph="none" start_char="7953" end_char="7954">to</TOKEN>
<TOKEN id="token-73-10" pos="unknown" morph="none" start_char="7956" end_char="7966">cherry-pick</TOKEN>
<TOKEN id="token-73-11" pos="word" morph="none" start_char="7968" end_char="7971">from</TOKEN>
<TOKEN id="token-73-12" pos="word" morph="none" start_char="7973" end_char="7981">secondary</TOKEN>
<TOKEN id="token-73-13" pos="word" morph="none" start_char="7983" end_char="7991">endpoints</TOKEN>
<TOKEN id="token-73-14" pos="word" morph="none" start_char="7993" end_char="7994">to</TOKEN>
<TOKEN id="token-73-15" pos="word" morph="none" start_char="7996" end_char="7999">make</TOKEN>
<TOKEN id="token-73-16" pos="word" morph="none" start_char="8001" end_char="8006">claims</TOKEN>
<TOKEN id="token-73-17" pos="word" morph="none" start_char="8008" end_char="8012">about</TOKEN>
<TOKEN id="token-73-18" pos="word" morph="none" start_char="8014" end_char="8018">drugs</TOKEN>
<TOKEN id="token-73-19" pos="punct" morph="none" start_char="8019" end_char="8019">’</TOKEN>
<TOKEN id="token-73-20" pos="word" morph="none" start_char="8021" end_char="8030">efficacies</TOKEN>
<TOKEN id="token-73-21" pos="punct" morph="none" start_char="8031" end_char="8031">,</TOKEN>
<TOKEN id="token-73-22" pos="word" morph="none" start_char="8033" end_char="8039">experts</TOKEN>
<TOKEN id="token-73-23" pos="word" morph="none" start_char="8041" end_char="8043">say</TOKEN>
<TOKEN id="token-73-24" pos="word" morph="none" start_char="8045" end_char="8048">this</TOKEN>
<TOKEN id="token-73-25" pos="word" morph="none" start_char="8050" end_char="8057">practice</TOKEN>
<TOKEN id="token-73-26" pos="word" morph="none" start_char="8059" end_char="8060">is</TOKEN>
<TOKEN id="token-73-27" pos="word" morph="none" start_char="8062" end_char="8062">a</TOKEN>
<TOKEN id="token-73-28" pos="word" morph="none" start_char="8064" end_char="8066">big</TOKEN>
<TOKEN id="token-73-29" pos="unknown" morph="none" start_char="8068" end_char="8072">no-no</TOKEN>
<TOKEN id="token-73-30" pos="punct" morph="none" start_char="8073" end_char="8073">.</TOKEN>
</SEG>
<SEG id="segment-74" start_char="8076" end_char="8346">
<ORIGINAL_TEXT>A 2017 guidance for the industry from the US Food and Drug Administration reiterates this in the following words: "Positive results on the secondary endpoints can be interpreted only if there is first a demonstration of a treatment effect on the primary endpoint family."</ORIGINAL_TEXT>
<TOKEN id="token-74-0" pos="word" morph="none" start_char="8076" end_char="8076">A</TOKEN>
<TOKEN id="token-74-1" pos="word" morph="none" start_char="8078" end_char="8081">2017</TOKEN>
<TOKEN id="token-74-2" pos="word" morph="none" start_char="8083" end_char="8090">guidance</TOKEN>
<TOKEN id="token-74-3" pos="word" morph="none" start_char="8092" end_char="8094">for</TOKEN>
<TOKEN id="token-74-4" pos="word" morph="none" start_char="8096" end_char="8098">the</TOKEN>
<TOKEN id="token-74-5" pos="word" morph="none" start_char="8100" end_char="8107">industry</TOKEN>
<TOKEN id="token-74-6" pos="word" morph="none" start_char="8109" end_char="8112">from</TOKEN>
<TOKEN id="token-74-7" pos="word" morph="none" start_char="8114" end_char="8116">the</TOKEN>
<TOKEN id="token-74-8" pos="word" morph="none" start_char="8118" end_char="8119">US</TOKEN>
<TOKEN id="token-74-9" pos="word" morph="none" start_char="8121" end_char="8124">Food</TOKEN>
<TOKEN id="token-74-10" pos="word" morph="none" start_char="8126" end_char="8128">and</TOKEN>
<TOKEN id="token-74-11" pos="word" morph="none" start_char="8130" end_char="8133">Drug</TOKEN>
<TOKEN id="token-74-12" pos="word" morph="none" start_char="8135" end_char="8148">Administration</TOKEN>
<TOKEN id="token-74-13" pos="word" morph="none" start_char="8150" end_char="8159">reiterates</TOKEN>
<TOKEN id="token-74-14" pos="word" morph="none" start_char="8161" end_char="8164">this</TOKEN>
<TOKEN id="token-74-15" pos="word" morph="none" start_char="8166" end_char="8167">in</TOKEN>
<TOKEN id="token-74-16" pos="word" morph="none" start_char="8169" end_char="8171">the</TOKEN>
<TOKEN id="token-74-17" pos="word" morph="none" start_char="8173" end_char="8181">following</TOKEN>
<TOKEN id="token-74-18" pos="word" morph="none" start_char="8183" end_char="8187">words</TOKEN>
<TOKEN id="token-74-19" pos="punct" morph="none" start_char="8188" end_char="8188">:</TOKEN>
<TOKEN id="token-74-20" pos="punct" morph="none" start_char="8190" end_char="8190">"</TOKEN>
<TOKEN id="token-74-21" pos="word" morph="none" start_char="8191" end_char="8198">Positive</TOKEN>
<TOKEN id="token-74-22" pos="word" morph="none" start_char="8200" end_char="8206">results</TOKEN>
<TOKEN id="token-74-23" pos="word" morph="none" start_char="8208" end_char="8209">on</TOKEN>
<TOKEN id="token-74-24" pos="word" morph="none" start_char="8211" end_char="8213">the</TOKEN>
<TOKEN id="token-74-25" pos="word" morph="none" start_char="8215" end_char="8223">secondary</TOKEN>
<TOKEN id="token-74-26" pos="word" morph="none" start_char="8225" end_char="8233">endpoints</TOKEN>
<TOKEN id="token-74-27" pos="word" morph="none" start_char="8235" end_char="8237">can</TOKEN>
<TOKEN id="token-74-28" pos="word" morph="none" start_char="8239" end_char="8240">be</TOKEN>
<TOKEN id="token-74-29" pos="word" morph="none" start_char="8242" end_char="8252">interpreted</TOKEN>
<TOKEN id="token-74-30" pos="word" morph="none" start_char="8254" end_char="8257">only</TOKEN>
<TOKEN id="token-74-31" pos="word" morph="none" start_char="8259" end_char="8260">if</TOKEN>
<TOKEN id="token-74-32" pos="word" morph="none" start_char="8262" end_char="8266">there</TOKEN>
<TOKEN id="token-74-33" pos="word" morph="none" start_char="8268" end_char="8269">is</TOKEN>
<TOKEN id="token-74-34" pos="word" morph="none" start_char="8271" end_char="8275">first</TOKEN>
<TOKEN id="token-74-35" pos="word" morph="none" start_char="8277" end_char="8277">a</TOKEN>
<TOKEN id="token-74-36" pos="word" morph="none" start_char="8279" end_char="8291">demonstration</TOKEN>
<TOKEN id="token-74-37" pos="word" morph="none" start_char="8293" end_char="8294">of</TOKEN>
<TOKEN id="token-74-38" pos="word" morph="none" start_char="8296" end_char="8296">a</TOKEN>
<TOKEN id="token-74-39" pos="word" morph="none" start_char="8298" end_char="8306">treatment</TOKEN>
<TOKEN id="token-74-40" pos="word" morph="none" start_char="8308" end_char="8313">effect</TOKEN>
<TOKEN id="token-74-41" pos="word" morph="none" start_char="8315" end_char="8316">on</TOKEN>
<TOKEN id="token-74-42" pos="word" morph="none" start_char="8318" end_char="8320">the</TOKEN>
<TOKEN id="token-74-43" pos="word" morph="none" start_char="8322" end_char="8328">primary</TOKEN>
<TOKEN id="token-74-44" pos="word" morph="none" start_char="8330" end_char="8337">endpoint</TOKEN>
<TOKEN id="token-74-45" pos="word" morph="none" start_char="8339" end_char="8344">family</TOKEN>
<TOKEN id="token-74-46" pos="punct" morph="none" start_char="8345" end_char="8346">."</TOKEN>
</SEG>
<SEG id="segment-75" start_char="8349" end_char="8587">
<ORIGINAL_TEXT>Further, the Indian drug regulator requires all trials to be registered prospectively on the Clinical Trial Registry of India today, making it harder than before for investigators to shift goalposts surreptitiously at the end of the trial.</ORIGINAL_TEXT>
<TOKEN id="token-75-0" pos="word" morph="none" start_char="8349" end_char="8355">Further</TOKEN>
<TOKEN id="token-75-1" pos="punct" morph="none" start_char="8356" end_char="8356">,</TOKEN>
<TOKEN id="token-75-2" pos="word" morph="none" start_char="8358" end_char="8360">the</TOKEN>
<TOKEN id="token-75-3" pos="word" morph="none" start_char="8362" end_char="8367">Indian</TOKEN>
<TOKEN id="token-75-4" pos="word" morph="none" start_char="8369" end_char="8372">drug</TOKEN>
<TOKEN id="token-75-5" pos="word" morph="none" start_char="8374" end_char="8382">regulator</TOKEN>
<TOKEN id="token-75-6" pos="word" morph="none" start_char="8384" end_char="8391">requires</TOKEN>
<TOKEN id="token-75-7" pos="word" morph="none" start_char="8393" end_char="8395">all</TOKEN>
<TOKEN id="token-75-8" pos="word" morph="none" start_char="8397" end_char="8402">trials</TOKEN>
<TOKEN id="token-75-9" pos="word" morph="none" start_char="8404" end_char="8405">to</TOKEN>
<TOKEN id="token-75-10" pos="word" morph="none" start_char="8407" end_char="8408">be</TOKEN>
<TOKEN id="token-75-11" pos="word" morph="none" start_char="8410" end_char="8419">registered</TOKEN>
<TOKEN id="token-75-12" pos="word" morph="none" start_char="8421" end_char="8433">prospectively</TOKEN>
<TOKEN id="token-75-13" pos="word" morph="none" start_char="8435" end_char="8436">on</TOKEN>
<TOKEN id="token-75-14" pos="word" morph="none" start_char="8438" end_char="8440">the</TOKEN>
<TOKEN id="token-75-15" pos="word" morph="none" start_char="8442" end_char="8449">Clinical</TOKEN>
<TOKEN id="token-75-16" pos="word" morph="none" start_char="8451" end_char="8455">Trial</TOKEN>
<TOKEN id="token-75-17" pos="word" morph="none" start_char="8457" end_char="8464">Registry</TOKEN>
<TOKEN id="token-75-18" pos="word" morph="none" start_char="8466" end_char="8467">of</TOKEN>
<TOKEN id="token-75-19" pos="word" morph="none" start_char="8469" end_char="8473">India</TOKEN>
<TOKEN id="token-75-20" pos="word" morph="none" start_char="8475" end_char="8479">today</TOKEN>
<TOKEN id="token-75-21" pos="punct" morph="none" start_char="8480" end_char="8480">,</TOKEN>
<TOKEN id="token-75-22" pos="word" morph="none" start_char="8482" end_char="8487">making</TOKEN>
<TOKEN id="token-75-23" pos="word" morph="none" start_char="8489" end_char="8490">it</TOKEN>
<TOKEN id="token-75-24" pos="word" morph="none" start_char="8492" end_char="8497">harder</TOKEN>
<TOKEN id="token-75-25" pos="word" morph="none" start_char="8499" end_char="8502">than</TOKEN>
<TOKEN id="token-75-26" pos="word" morph="none" start_char="8504" end_char="8509">before</TOKEN>
<TOKEN id="token-75-27" pos="word" morph="none" start_char="8511" end_char="8513">for</TOKEN>
<TOKEN id="token-75-28" pos="word" morph="none" start_char="8515" end_char="8527">investigators</TOKEN>
<TOKEN id="token-75-29" pos="word" morph="none" start_char="8529" end_char="8530">to</TOKEN>
<TOKEN id="token-75-30" pos="word" morph="none" start_char="8532" end_char="8536">shift</TOKEN>
<TOKEN id="token-75-31" pos="word" morph="none" start_char="8538" end_char="8546">goalposts</TOKEN>
<TOKEN id="token-75-32" pos="word" morph="none" start_char="8548" end_char="8562">surreptitiously</TOKEN>
<TOKEN id="token-75-33" pos="word" morph="none" start_char="8564" end_char="8565">at</TOKEN>
<TOKEN id="token-75-34" pos="word" morph="none" start_char="8567" end_char="8569">the</TOKEN>
<TOKEN id="token-75-35" pos="word" morph="none" start_char="8571" end_char="8573">end</TOKEN>
<TOKEN id="token-75-36" pos="word" morph="none" start_char="8575" end_char="8576">of</TOKEN>
<TOKEN id="token-75-37" pos="word" morph="none" start_char="8578" end_char="8580">the</TOKEN>
<TOKEN id="token-75-38" pos="word" morph="none" start_char="8582" end_char="8586">trial</TOKEN>
<TOKEN id="token-75-39" pos="punct" morph="none" start_char="8587" end_char="8587">.</TOKEN>
</SEG>
<SEG id="segment-76" start_char="8590" end_char="8608">
<ORIGINAL_TEXT>Cost of favipiravir</ORIGINAL_TEXT>
<TOKEN id="token-76-0" pos="word" morph="none" start_char="8590" end_char="8593">Cost</TOKEN>
<TOKEN id="token-76-1" pos="word" morph="none" start_char="8595" end_char="8596">of</TOKEN>
<TOKEN id="token-76-2" pos="word" morph="none" start_char="8598" end_char="8608">favipiravir</TOKEN>
</SEG>
<SEG id="segment-77" start_char="8611" end_char="8710">
<ORIGINAL_TEXT>The widespread use of favipiravir would have been of little concern if the drug was completely safe.</ORIGINAL_TEXT>
<TOKEN id="token-77-0" pos="word" morph="none" start_char="8611" end_char="8613">The</TOKEN>
<TOKEN id="token-77-1" pos="word" morph="none" start_char="8615" end_char="8624">widespread</TOKEN>
<TOKEN id="token-77-2" pos="word" morph="none" start_char="8626" end_char="8628">use</TOKEN>
<TOKEN id="token-77-3" pos="word" morph="none" start_char="8630" end_char="8631">of</TOKEN>
<TOKEN id="token-77-4" pos="word" morph="none" start_char="8633" end_char="8643">favipiravir</TOKEN>
<TOKEN id="token-77-5" pos="word" morph="none" start_char="8645" end_char="8649">would</TOKEN>
<TOKEN id="token-77-6" pos="word" morph="none" start_char="8651" end_char="8654">have</TOKEN>
<TOKEN id="token-77-7" pos="word" morph="none" start_char="8656" end_char="8659">been</TOKEN>
<TOKEN id="token-77-8" pos="word" morph="none" start_char="8661" end_char="8662">of</TOKEN>
<TOKEN id="token-77-9" pos="word" morph="none" start_char="8664" end_char="8669">little</TOKEN>
<TOKEN id="token-77-10" pos="word" morph="none" start_char="8671" end_char="8677">concern</TOKEN>
<TOKEN id="token-77-11" pos="word" morph="none" start_char="8679" end_char="8680">if</TOKEN>
<TOKEN id="token-77-12" pos="word" morph="none" start_char="8682" end_char="8684">the</TOKEN>
<TOKEN id="token-77-13" pos="word" morph="none" start_char="8686" end_char="8689">drug</TOKEN>
<TOKEN id="token-77-14" pos="word" morph="none" start_char="8691" end_char="8693">was</TOKEN>
<TOKEN id="token-77-15" pos="word" morph="none" start_char="8695" end_char="8704">completely</TOKEN>
<TOKEN id="token-77-16" pos="word" morph="none" start_char="8706" end_char="8709">safe</TOKEN>
<TOKEN id="token-77-17" pos="punct" morph="none" start_char="8710" end_char="8710">.</TOKEN>
</SEG>
<SEG id="segment-78" start_char="8712" end_char="8917">
<ORIGINAL_TEXT>But in Glenmark’s trial, favipiravir recipients experienced adverse effects like elevated blood uric acid and abnormal liver function tests around 36% of the time, while controls did so only 8% of the time.</ORIGINAL_TEXT>
<TOKEN id="token-78-0" pos="word" morph="none" start_char="8712" end_char="8714">But</TOKEN>
<TOKEN id="token-78-1" pos="word" morph="none" start_char="8716" end_char="8717">in</TOKEN>
<TOKEN id="token-78-2" pos="word" morph="none" start_char="8719" end_char="8728">Glenmark’s</TOKEN>
<TOKEN id="token-78-3" pos="word" morph="none" start_char="8730" end_char="8734">trial</TOKEN>
<TOKEN id="token-78-4" pos="punct" morph="none" start_char="8735" end_char="8735">,</TOKEN>
<TOKEN id="token-78-5" pos="word" morph="none" start_char="8737" end_char="8747">favipiravir</TOKEN>
<TOKEN id="token-78-6" pos="word" morph="none" start_char="8749" end_char="8758">recipients</TOKEN>
<TOKEN id="token-78-7" pos="word" morph="none" start_char="8760" end_char="8770">experienced</TOKEN>
<TOKEN id="token-78-8" pos="word" morph="none" start_char="8772" end_char="8778">adverse</TOKEN>
<TOKEN id="token-78-9" pos="word" morph="none" start_char="8780" end_char="8786">effects</TOKEN>
<TOKEN id="token-78-10" pos="word" morph="none" start_char="8788" end_char="8791">like</TOKEN>
<TOKEN id="token-78-11" pos="word" morph="none" start_char="8793" end_char="8800">elevated</TOKEN>
<TOKEN id="token-78-12" pos="word" morph="none" start_char="8802" end_char="8806">blood</TOKEN>
<TOKEN id="token-78-13" pos="word" morph="none" start_char="8808" end_char="8811">uric</TOKEN>
<TOKEN id="token-78-14" pos="word" morph="none" start_char="8813" end_char="8816">acid</TOKEN>
<TOKEN id="token-78-15" pos="word" morph="none" start_char="8818" end_char="8820">and</TOKEN>
<TOKEN id="token-78-16" pos="word" morph="none" start_char="8822" end_char="8829">abnormal</TOKEN>
<TOKEN id="token-78-17" pos="word" morph="none" start_char="8831" end_char="8835">liver</TOKEN>
<TOKEN id="token-78-18" pos="word" morph="none" start_char="8837" end_char="8844">function</TOKEN>
<TOKEN id="token-78-19" pos="word" morph="none" start_char="8846" end_char="8850">tests</TOKEN>
<TOKEN id="token-78-20" pos="word" morph="none" start_char="8852" end_char="8857">around</TOKEN>
<TOKEN id="token-78-21" pos="word" morph="none" start_char="8859" end_char="8860">36</TOKEN>
<TOKEN id="token-78-22" pos="punct" morph="none" start_char="8861" end_char="8861">%</TOKEN>
<TOKEN id="token-78-23" pos="word" morph="none" start_char="8863" end_char="8864">of</TOKEN>
<TOKEN id="token-78-24" pos="word" morph="none" start_char="8866" end_char="8868">the</TOKEN>
<TOKEN id="token-78-25" pos="word" morph="none" start_char="8870" end_char="8873">time</TOKEN>
<TOKEN id="token-78-26" pos="punct" morph="none" start_char="8874" end_char="8874">,</TOKEN>
<TOKEN id="token-78-27" pos="word" morph="none" start_char="8876" end_char="8880">while</TOKEN>
<TOKEN id="token-78-28" pos="word" morph="none" start_char="8882" end_char="8889">controls</TOKEN>
<TOKEN id="token-78-29" pos="word" morph="none" start_char="8891" end_char="8893">did</TOKEN>
<TOKEN id="token-78-30" pos="word" morph="none" start_char="8895" end_char="8896">so</TOKEN>
<TOKEN id="token-78-31" pos="word" morph="none" start_char="8898" end_char="8901">only</TOKEN>
<TOKEN id="token-78-32" pos="word" morph="none" start_char="8903" end_char="8903">8</TOKEN>
<TOKEN id="token-78-33" pos="punct" morph="none" start_char="8904" end_char="8904">%</TOKEN>
<TOKEN id="token-78-34" pos="word" morph="none" start_char="8906" end_char="8907">of</TOKEN>
<TOKEN id="token-78-35" pos="word" morph="none" start_char="8909" end_char="8911">the</TOKEN>
<TOKEN id="token-78-36" pos="word" morph="none" start_char="8913" end_char="8916">time</TOKEN>
<TOKEN id="token-78-37" pos="punct" morph="none" start_char="8917" end_char="8917">.</TOKEN>
</SEG>
<SEG id="segment-79" start_char="8920" end_char="9058">
<ORIGINAL_TEXT>Tandon and her colleagues have argued that these adverse effects were mild and reversible, and worth the trouble given the drug’s benefits.</ORIGINAL_TEXT>
<TOKEN id="token-79-0" pos="word" morph="none" start_char="8920" end_char="8925">Tandon</TOKEN>
<TOKEN id="token-79-1" pos="word" morph="none" start_char="8927" end_char="8929">and</TOKEN>
<TOKEN id="token-79-2" pos="word" morph="none" start_char="8931" end_char="8933">her</TOKEN>
<TOKEN id="token-79-3" pos="word" morph="none" start_char="8935" end_char="8944">colleagues</TOKEN>
<TOKEN id="token-79-4" pos="word" morph="none" start_char="8946" end_char="8949">have</TOKEN>
<TOKEN id="token-79-5" pos="word" morph="none" start_char="8951" end_char="8956">argued</TOKEN>
<TOKEN id="token-79-6" pos="word" morph="none" start_char="8958" end_char="8961">that</TOKEN>
<TOKEN id="token-79-7" pos="word" morph="none" start_char="8963" end_char="8967">these</TOKEN>
<TOKEN id="token-79-8" pos="word" morph="none" start_char="8969" end_char="8975">adverse</TOKEN>
<TOKEN id="token-79-9" pos="word" morph="none" start_char="8977" end_char="8983">effects</TOKEN>
<TOKEN id="token-79-10" pos="word" morph="none" start_char="8985" end_char="8988">were</TOKEN>
<TOKEN id="token-79-11" pos="word" morph="none" start_char="8990" end_char="8993">mild</TOKEN>
<TOKEN id="token-79-12" pos="word" morph="none" start_char="8995" end_char="8997">and</TOKEN>
<TOKEN id="token-79-13" pos="word" morph="none" start_char="8999" end_char="9008">reversible</TOKEN>
<TOKEN id="token-79-14" pos="punct" morph="none" start_char="9009" end_char="9009">,</TOKEN>
<TOKEN id="token-79-15" pos="word" morph="none" start_char="9011" end_char="9013">and</TOKEN>
<TOKEN id="token-79-16" pos="word" morph="none" start_char="9015" end_char="9019">worth</TOKEN>
<TOKEN id="token-79-17" pos="word" morph="none" start_char="9021" end_char="9023">the</TOKEN>
<TOKEN id="token-79-18" pos="word" morph="none" start_char="9025" end_char="9031">trouble</TOKEN>
<TOKEN id="token-79-19" pos="word" morph="none" start_char="9033" end_char="9037">given</TOKEN>
<TOKEN id="token-79-20" pos="word" morph="none" start_char="9039" end_char="9041">the</TOKEN>
<TOKEN id="token-79-21" pos="word" morph="none" start_char="9043" end_char="9048">drug’s</TOKEN>
<TOKEN id="token-79-22" pos="word" morph="none" start_char="9050" end_char="9057">benefits</TOKEN>
<TOKEN id="token-79-23" pos="punct" morph="none" start_char="9058" end_char="9058">.</TOKEN>
</SEG>
<SEG id="segment-80" start_char="9060" end_char="9086">
<ORIGINAL_TEXT>But this might not be true.</ORIGINAL_TEXT>
<TOKEN id="token-80-0" pos="word" morph="none" start_char="9060" end_char="9062">But</TOKEN>
<TOKEN id="token-80-1" pos="word" morph="none" start_char="9064" end_char="9067">this</TOKEN>
<TOKEN id="token-80-2" pos="word" morph="none" start_char="9069" end_char="9073">might</TOKEN>
<TOKEN id="token-80-3" pos="word" morph="none" start_char="9075" end_char="9077">not</TOKEN>
<TOKEN id="token-80-4" pos="word" morph="none" start_char="9079" end_char="9080">be</TOKEN>
<TOKEN id="token-80-5" pos="word" morph="none" start_char="9082" end_char="9085">true</TOKEN>
<TOKEN id="token-80-6" pos="punct" morph="none" start_char="9086" end_char="9086">.</TOKEN>
</SEG>
<SEG id="segment-81" start_char="9088" end_char="9258">
<ORIGINAL_TEXT>One of the adverse effects experienced by favipiravir recipients more often, for example, was viral pneumonitis – the inflammation of lung tissue, captured on X-ray scans.</ORIGINAL_TEXT>
<TOKEN id="token-81-0" pos="word" morph="none" start_char="9088" end_char="9090">One</TOKEN>
<TOKEN id="token-81-1" pos="word" morph="none" start_char="9092" end_char="9093">of</TOKEN>
<TOKEN id="token-81-2" pos="word" morph="none" start_char="9095" end_char="9097">the</TOKEN>
<TOKEN id="token-81-3" pos="word" morph="none" start_char="9099" end_char="9105">adverse</TOKEN>
<TOKEN id="token-81-4" pos="word" morph="none" start_char="9107" end_char="9113">effects</TOKEN>
<TOKEN id="token-81-5" pos="word" morph="none" start_char="9115" end_char="9125">experienced</TOKEN>
<TOKEN id="token-81-6" pos="word" morph="none" start_char="9127" end_char="9128">by</TOKEN>
<TOKEN id="token-81-7" pos="word" morph="none" start_char="9130" end_char="9140">favipiravir</TOKEN>
<TOKEN id="token-81-8" pos="word" morph="none" start_char="9142" end_char="9151">recipients</TOKEN>
<TOKEN id="token-81-9" pos="word" morph="none" start_char="9153" end_char="9156">more</TOKEN>
<TOKEN id="token-81-10" pos="word" morph="none" start_char="9158" end_char="9162">often</TOKEN>
<TOKEN id="token-81-11" pos="punct" morph="none" start_char="9163" end_char="9163">,</TOKEN>
<TOKEN id="token-81-12" pos="word" morph="none" start_char="9165" end_char="9167">for</TOKEN>
<TOKEN id="token-81-13" pos="word" morph="none" start_char="9169" end_char="9175">example</TOKEN>
<TOKEN id="token-81-14" pos="punct" morph="none" start_char="9176" end_char="9176">,</TOKEN>
<TOKEN id="token-81-15" pos="word" morph="none" start_char="9178" end_char="9180">was</TOKEN>
<TOKEN id="token-81-16" pos="word" morph="none" start_char="9182" end_char="9186">viral</TOKEN>
<TOKEN id="token-81-17" pos="word" morph="none" start_char="9188" end_char="9198">pneumonitis</TOKEN>
<TOKEN id="token-81-18" pos="punct" morph="none" start_char="9200" end_char="9200">–</TOKEN>
<TOKEN id="token-81-19" pos="word" morph="none" start_char="9202" end_char="9204">the</TOKEN>
<TOKEN id="token-81-20" pos="word" morph="none" start_char="9206" end_char="9217">inflammation</TOKEN>
<TOKEN id="token-81-21" pos="word" morph="none" start_char="9219" end_char="9220">of</TOKEN>
<TOKEN id="token-81-22" pos="word" morph="none" start_char="9222" end_char="9225">lung</TOKEN>
<TOKEN id="token-81-23" pos="word" morph="none" start_char="9227" end_char="9232">tissue</TOKEN>
<TOKEN id="token-81-24" pos="punct" morph="none" start_char="9233" end_char="9233">,</TOKEN>
<TOKEN id="token-81-25" pos="word" morph="none" start_char="9235" end_char="9242">captured</TOKEN>
<TOKEN id="token-81-26" pos="word" morph="none" start_char="9244" end_char="9245">on</TOKEN>
<TOKEN id="token-81-27" pos="unknown" morph="none" start_char="9247" end_char="9251">X-ray</TOKEN>
<TOKEN id="token-81-28" pos="word" morph="none" start_char="9253" end_char="9257">scans</TOKEN>
<TOKEN id="token-81-29" pos="punct" morph="none" start_char="9258" end_char="9258">.</TOKEN>
</SEG>
<SEG id="segment-82" start_char="9260" end_char="9388">
<ORIGINAL_TEXT>Pneumonitis can result in future complications, like scarring of the lung tissue, leaving patients incapacitated for a long time.</ORIGINAL_TEXT>
<TOKEN id="token-82-0" pos="word" morph="none" start_char="9260" end_char="9270">Pneumonitis</TOKEN>
<TOKEN id="token-82-1" pos="word" morph="none" start_char="9272" end_char="9274">can</TOKEN>
<TOKEN id="token-82-2" pos="word" morph="none" start_char="9276" end_char="9281">result</TOKEN>
<TOKEN id="token-82-3" pos="word" morph="none" start_char="9283" end_char="9284">in</TOKEN>
<TOKEN id="token-82-4" pos="word" morph="none" start_char="9286" end_char="9291">future</TOKEN>
<TOKEN id="token-82-5" pos="word" morph="none" start_char="9293" end_char="9305">complications</TOKEN>
<TOKEN id="token-82-6" pos="punct" morph="none" start_char="9306" end_char="9306">,</TOKEN>
<TOKEN id="token-82-7" pos="word" morph="none" start_char="9308" end_char="9311">like</TOKEN>
<TOKEN id="token-82-8" pos="word" morph="none" start_char="9313" end_char="9320">scarring</TOKEN>
<TOKEN id="token-82-9" pos="word" morph="none" start_char="9322" end_char="9323">of</TOKEN>
<TOKEN id="token-82-10" pos="word" morph="none" start_char="9325" end_char="9327">the</TOKEN>
<TOKEN id="token-82-11" pos="word" morph="none" start_char="9329" end_char="9332">lung</TOKEN>
<TOKEN id="token-82-12" pos="word" morph="none" start_char="9334" end_char="9339">tissue</TOKEN>
<TOKEN id="token-82-13" pos="punct" morph="none" start_char="9340" end_char="9340">,</TOKEN>
<TOKEN id="token-82-14" pos="word" morph="none" start_char="9342" end_char="9348">leaving</TOKEN>
<TOKEN id="token-82-15" pos="word" morph="none" start_char="9350" end_char="9357">patients</TOKEN>
<TOKEN id="token-82-16" pos="word" morph="none" start_char="9359" end_char="9371">incapacitated</TOKEN>
<TOKEN id="token-82-17" pos="word" morph="none" start_char="9373" end_char="9375">for</TOKEN>
<TOKEN id="token-82-18" pos="word" morph="none" start_char="9377" end_char="9377">a</TOKEN>
<TOKEN id="token-82-19" pos="word" morph="none" start_char="9379" end_char="9382">long</TOKEN>
<TOKEN id="token-82-20" pos="word" morph="none" start_char="9384" end_char="9387">time</TOKEN>
<TOKEN id="token-82-21" pos="punct" morph="none" start_char="9388" end_char="9388">.</TOKEN>
</SEG>
<SEG id="segment-83" start_char="9391" end_char="9434">
<ORIGINAL_TEXT>Then there is the matter of the drug’s cost.</ORIGINAL_TEXT>
<TOKEN id="token-83-0" pos="word" morph="none" start_char="9391" end_char="9394">Then</TOKEN>
<TOKEN id="token-83-1" pos="word" morph="none" start_char="9396" end_char="9400">there</TOKEN>
<TOKEN id="token-83-2" pos="word" morph="none" start_char="9402" end_char="9403">is</TOKEN>
<TOKEN id="token-83-3" pos="word" morph="none" start_char="9405" end_char="9407">the</TOKEN>
<TOKEN id="token-83-4" pos="word" morph="none" start_char="9409" end_char="9414">matter</TOKEN>
<TOKEN id="token-83-5" pos="word" morph="none" start_char="9416" end_char="9417">of</TOKEN>
<TOKEN id="token-83-6" pos="word" morph="none" start_char="9419" end_char="9421">the</TOKEN>
<TOKEN id="token-83-7" pos="word" morph="none" start_char="9423" end_char="9428">drug’s</TOKEN>
<TOKEN id="token-83-8" pos="word" morph="none" start_char="9430" end_char="9433">cost</TOKEN>
<TOKEN id="token-83-9" pos="punct" morph="none" start_char="9434" end_char="9434">.</TOKEN>
</SEG>
<SEG id="segment-84" start_char="9436" end_char="9585">
<ORIGINAL_TEXT>When favipiravir was first launched, Glenmark priced it at Rs 103 per tablet, which means a full course of 122 tablets would have cost over Rs 12,500.</ORIGINAL_TEXT>
<TOKEN id="token-84-0" pos="word" morph="none" start_char="9436" end_char="9439">When</TOKEN>
<TOKEN id="token-84-1" pos="word" morph="none" start_char="9441" end_char="9451">favipiravir</TOKEN>
<TOKEN id="token-84-2" pos="word" morph="none" start_char="9453" end_char="9455">was</TOKEN>
<TOKEN id="token-84-3" pos="word" morph="none" start_char="9457" end_char="9461">first</TOKEN>
<TOKEN id="token-84-4" pos="word" morph="none" start_char="9463" end_char="9470">launched</TOKEN>
<TOKEN id="token-84-5" pos="punct" morph="none" start_char="9471" end_char="9471">,</TOKEN>
<TOKEN id="token-84-6" pos="word" morph="none" start_char="9473" end_char="9480">Glenmark</TOKEN>
<TOKEN id="token-84-7" pos="word" morph="none" start_char="9482" end_char="9487">priced</TOKEN>
<TOKEN id="token-84-8" pos="word" morph="none" start_char="9489" end_char="9490">it</TOKEN>
<TOKEN id="token-84-9" pos="word" morph="none" start_char="9492" end_char="9493">at</TOKEN>
<TOKEN id="token-84-10" pos="word" morph="none" start_char="9495" end_char="9496">Rs</TOKEN>
<TOKEN id="token-84-11" pos="word" morph="none" start_char="9498" end_char="9500">103</TOKEN>
<TOKEN id="token-84-12" pos="word" morph="none" start_char="9502" end_char="9504">per</TOKEN>
<TOKEN id="token-84-13" pos="word" morph="none" start_char="9506" end_char="9511">tablet</TOKEN>
<TOKEN id="token-84-14" pos="punct" morph="none" start_char="9512" end_char="9512">,</TOKEN>
<TOKEN id="token-84-15" pos="word" morph="none" start_char="9514" end_char="9518">which</TOKEN>
<TOKEN id="token-84-16" pos="word" morph="none" start_char="9520" end_char="9524">means</TOKEN>
<TOKEN id="token-84-17" pos="word" morph="none" start_char="9526" end_char="9526">a</TOKEN>
<TOKEN id="token-84-18" pos="word" morph="none" start_char="9528" end_char="9531">full</TOKEN>
<TOKEN id="token-84-19" pos="word" morph="none" start_char="9533" end_char="9538">course</TOKEN>
<TOKEN id="token-84-20" pos="word" morph="none" start_char="9540" end_char="9541">of</TOKEN>
<TOKEN id="token-84-21" pos="word" morph="none" start_char="9543" end_char="9545">122</TOKEN>
<TOKEN id="token-84-22" pos="word" morph="none" start_char="9547" end_char="9553">tablets</TOKEN>
<TOKEN id="token-84-23" pos="word" morph="none" start_char="9555" end_char="9559">would</TOKEN>
<TOKEN id="token-84-24" pos="word" morph="none" start_char="9561" end_char="9564">have</TOKEN>
<TOKEN id="token-84-25" pos="word" morph="none" start_char="9566" end_char="9569">cost</TOKEN>
<TOKEN id="token-84-26" pos="word" morph="none" start_char="9571" end_char="9574">over</TOKEN>
<TOKEN id="token-84-27" pos="word" morph="none" start_char="9576" end_char="9577">Rs</TOKEN>
<TOKEN id="token-84-28" pos="unknown" morph="none" start_char="9579" end_char="9584">12,500</TOKEN>
<TOKEN id="token-84-29" pos="punct" morph="none" start_char="9585" end_char="9585">.</TOKEN>
</SEG>
<SEG id="segment-85" start_char="9587" end_char="9740">
<ORIGINAL_TEXT>Today, with several other manufacturers making the same product, Glenmark’s price has dropped to Rs 37-38 per tablet, according to a company spokesperson.</ORIGINAL_TEXT>
<TOKEN id="token-85-0" pos="word" morph="none" start_char="9587" end_char="9591">Today</TOKEN>
<TOKEN id="token-85-1" pos="punct" morph="none" start_char="9592" end_char="9592">,</TOKEN>
<TOKEN id="token-85-2" pos="word" morph="none" start_char="9594" end_char="9597">with</TOKEN>
<TOKEN id="token-85-3" pos="word" morph="none" start_char="9599" end_char="9605">several</TOKEN>
<TOKEN id="token-85-4" pos="word" morph="none" start_char="9607" end_char="9611">other</TOKEN>
<TOKEN id="token-85-5" pos="word" morph="none" start_char="9613" end_char="9625">manufacturers</TOKEN>
<TOKEN id="token-85-6" pos="word" morph="none" start_char="9627" end_char="9632">making</TOKEN>
<TOKEN id="token-85-7" pos="word" morph="none" start_char="9634" end_char="9636">the</TOKEN>
<TOKEN id="token-85-8" pos="word" morph="none" start_char="9638" end_char="9641">same</TOKEN>
<TOKEN id="token-85-9" pos="word" morph="none" start_char="9643" end_char="9649">product</TOKEN>
<TOKEN id="token-85-10" pos="punct" morph="none" start_char="9650" end_char="9650">,</TOKEN>
<TOKEN id="token-85-11" pos="word" morph="none" start_char="9652" end_char="9661">Glenmark’s</TOKEN>
<TOKEN id="token-85-12" pos="word" morph="none" start_char="9663" end_char="9667">price</TOKEN>
<TOKEN id="token-85-13" pos="word" morph="none" start_char="9669" end_char="9671">has</TOKEN>
<TOKEN id="token-85-14" pos="word" morph="none" start_char="9673" end_char="9679">dropped</TOKEN>
<TOKEN id="token-85-15" pos="word" morph="none" start_char="9681" end_char="9682">to</TOKEN>
<TOKEN id="token-85-16" pos="word" morph="none" start_char="9684" end_char="9685">Rs</TOKEN>
<TOKEN id="token-85-17" pos="unknown" morph="none" start_char="9687" end_char="9691">37-38</TOKEN>
<TOKEN id="token-85-18" pos="word" morph="none" start_char="9693" end_char="9695">per</TOKEN>
<TOKEN id="token-85-19" pos="word" morph="none" start_char="9697" end_char="9702">tablet</TOKEN>
<TOKEN id="token-85-20" pos="punct" morph="none" start_char="9703" end_char="9703">,</TOKEN>
<TOKEN id="token-85-21" pos="word" morph="none" start_char="9705" end_char="9713">according</TOKEN>
<TOKEN id="token-85-22" pos="word" morph="none" start_char="9715" end_char="9716">to</TOKEN>
<TOKEN id="token-85-23" pos="word" morph="none" start_char="9718" end_char="9718">a</TOKEN>
<TOKEN id="token-85-24" pos="word" morph="none" start_char="9720" end_char="9726">company</TOKEN>
<TOKEN id="token-85-25" pos="word" morph="none" start_char="9728" end_char="9739">spokesperson</TOKEN>
<TOKEN id="token-85-26" pos="punct" morph="none" start_char="9740" end_char="9740">.</TOKEN>
</SEG>
<SEG id="segment-86" start_char="9742" end_char="9840">
<ORIGINAL_TEXT>But this, too, adds up to at least Rs 4,514 per full course – not an insignificant amount for many.</ORIGINAL_TEXT>
<TOKEN id="token-86-0" pos="word" morph="none" start_char="9742" end_char="9744">But</TOKEN>
<TOKEN id="token-86-1" pos="word" morph="none" start_char="9746" end_char="9749">this</TOKEN>
<TOKEN id="token-86-2" pos="punct" morph="none" start_char="9750" end_char="9750">,</TOKEN>
<TOKEN id="token-86-3" pos="word" morph="none" start_char="9752" end_char="9754">too</TOKEN>
<TOKEN id="token-86-4" pos="punct" morph="none" start_char="9755" end_char="9755">,</TOKEN>
<TOKEN id="token-86-5" pos="word" morph="none" start_char="9757" end_char="9760">adds</TOKEN>
<TOKEN id="token-86-6" pos="word" morph="none" start_char="9762" end_char="9763">up</TOKEN>
<TOKEN id="token-86-7" pos="word" morph="none" start_char="9765" end_char="9766">to</TOKEN>
<TOKEN id="token-86-8" pos="word" morph="none" start_char="9768" end_char="9769">at</TOKEN>
<TOKEN id="token-86-9" pos="word" morph="none" start_char="9771" end_char="9775">least</TOKEN>
<TOKEN id="token-86-10" pos="word" morph="none" start_char="9777" end_char="9778">Rs</TOKEN>
<TOKEN id="token-86-11" pos="unknown" morph="none" start_char="9780" end_char="9784">4,514</TOKEN>
<TOKEN id="token-86-12" pos="word" morph="none" start_char="9786" end_char="9788">per</TOKEN>
<TOKEN id="token-86-13" pos="word" morph="none" start_char="9790" end_char="9793">full</TOKEN>
<TOKEN id="token-86-14" pos="word" morph="none" start_char="9795" end_char="9800">course</TOKEN>
<TOKEN id="token-86-15" pos="punct" morph="none" start_char="9802" end_char="9802">–</TOKEN>
<TOKEN id="token-86-16" pos="word" morph="none" start_char="9804" end_char="9806">not</TOKEN>
<TOKEN id="token-86-17" pos="word" morph="none" start_char="9808" end_char="9809">an</TOKEN>
<TOKEN id="token-86-18" pos="word" morph="none" start_char="9811" end_char="9823">insignificant</TOKEN>
<TOKEN id="token-86-19" pos="word" morph="none" start_char="9825" end_char="9830">amount</TOKEN>
<TOKEN id="token-86-20" pos="word" morph="none" start_char="9832" end_char="9834">for</TOKEN>
<TOKEN id="token-86-21" pos="word" morph="none" start_char="9836" end_char="9839">many</TOKEN>
<TOKEN id="token-86-22" pos="punct" morph="none" start_char="9840" end_char="9840">.</TOKEN>
</SEG>
<SEG id="segment-87" start_char="9843" end_char="9914">
<ORIGINAL_TEXT>Should a patient then take the drug, given its benefits remain unproven?</ORIGINAL_TEXT>
<TOKEN id="token-87-0" pos="word" morph="none" start_char="9843" end_char="9848">Should</TOKEN>
<TOKEN id="token-87-1" pos="word" morph="none" start_char="9850" end_char="9850">a</TOKEN>
<TOKEN id="token-87-2" pos="word" morph="none" start_char="9852" end_char="9858">patient</TOKEN>
<TOKEN id="token-87-3" pos="word" morph="none" start_char="9860" end_char="9863">then</TOKEN>
<TOKEN id="token-87-4" pos="word" morph="none" start_char="9865" end_char="9868">take</TOKEN>
<TOKEN id="token-87-5" pos="word" morph="none" start_char="9870" end_char="9872">the</TOKEN>
<TOKEN id="token-87-6" pos="word" morph="none" start_char="9874" end_char="9877">drug</TOKEN>
<TOKEN id="token-87-7" pos="punct" morph="none" start_char="9878" end_char="9878">,</TOKEN>
<TOKEN id="token-87-8" pos="word" morph="none" start_char="9880" end_char="9884">given</TOKEN>
<TOKEN id="token-87-9" pos="word" morph="none" start_char="9886" end_char="9888">its</TOKEN>
<TOKEN id="token-87-10" pos="word" morph="none" start_char="9890" end_char="9897">benefits</TOKEN>
<TOKEN id="token-87-11" pos="word" morph="none" start_char="9899" end_char="9904">remain</TOKEN>
<TOKEN id="token-87-12" pos="word" morph="none" start_char="9906" end_char="9913">unproven</TOKEN>
<TOKEN id="token-87-13" pos="punct" morph="none" start_char="9914" end_char="9914">?</TOKEN>
</SEG>
<SEG id="segment-88" start_char="9916" end_char="9999">
<ORIGINAL_TEXT>Critics of the favipiravir approval say there isn’t enough justification to do this.</ORIGINAL_TEXT>
<TOKEN id="token-88-0" pos="word" morph="none" start_char="9916" end_char="9922">Critics</TOKEN>
<TOKEN id="token-88-1" pos="word" morph="none" start_char="9924" end_char="9925">of</TOKEN>
<TOKEN id="token-88-2" pos="word" morph="none" start_char="9927" end_char="9929">the</TOKEN>
<TOKEN id="token-88-3" pos="word" morph="none" start_char="9931" end_char="9941">favipiravir</TOKEN>
<TOKEN id="token-88-4" pos="word" morph="none" start_char="9943" end_char="9950">approval</TOKEN>
<TOKEN id="token-88-5" pos="word" morph="none" start_char="9952" end_char="9954">say</TOKEN>
<TOKEN id="token-88-6" pos="word" morph="none" start_char="9956" end_char="9960">there</TOKEN>
<TOKEN id="token-88-7" pos="word" morph="none" start_char="9962" end_char="9966">isn’t</TOKEN>
<TOKEN id="token-88-8" pos="word" morph="none" start_char="9968" end_char="9973">enough</TOKEN>
<TOKEN id="token-88-9" pos="word" morph="none" start_char="9975" end_char="9987">justification</TOKEN>
<TOKEN id="token-88-10" pos="word" morph="none" start_char="9989" end_char="9990">to</TOKEN>
<TOKEN id="token-88-11" pos="word" morph="none" start_char="9992" end_char="9993">do</TOKEN>
<TOKEN id="token-88-12" pos="word" morph="none" start_char="9995" end_char="9998">this</TOKEN>
<TOKEN id="token-88-13" pos="punct" morph="none" start_char="9999" end_char="9999">.</TOKEN>
</SEG>
<SEG id="segment-89" start_char="10001" end_char="10100">
<ORIGINAL_TEXT>"The best I can say is that this trial improves on existing evidence for favipiravir," Pramesh said.</ORIGINAL_TEXT>
<TOKEN id="token-89-0" pos="punct" morph="none" start_char="10001" end_char="10001">"</TOKEN>
<TOKEN id="token-89-1" pos="word" morph="none" start_char="10002" end_char="10004">The</TOKEN>
<TOKEN id="token-89-2" pos="word" morph="none" start_char="10006" end_char="10009">best</TOKEN>
<TOKEN id="token-89-3" pos="word" morph="none" start_char="10011" end_char="10011">I</TOKEN>
<TOKEN id="token-89-4" pos="word" morph="none" start_char="10013" end_char="10015">can</TOKEN>
<TOKEN id="token-89-5" pos="word" morph="none" start_char="10017" end_char="10019">say</TOKEN>
<TOKEN id="token-89-6" pos="word" morph="none" start_char="10021" end_char="10022">is</TOKEN>
<TOKEN id="token-89-7" pos="word" morph="none" start_char="10024" end_char="10027">that</TOKEN>
<TOKEN id="token-89-8" pos="word" morph="none" start_char="10029" end_char="10032">this</TOKEN>
<TOKEN id="token-89-9" pos="word" morph="none" start_char="10034" end_char="10038">trial</TOKEN>
<TOKEN id="token-89-10" pos="word" morph="none" start_char="10040" end_char="10047">improves</TOKEN>
<TOKEN id="token-89-11" pos="word" morph="none" start_char="10049" end_char="10050">on</TOKEN>
<TOKEN id="token-89-12" pos="word" morph="none" start_char="10052" end_char="10059">existing</TOKEN>
<TOKEN id="token-89-13" pos="word" morph="none" start_char="10061" end_char="10068">evidence</TOKEN>
<TOKEN id="token-89-14" pos="word" morph="none" start_char="10070" end_char="10072">for</TOKEN>
<TOKEN id="token-89-15" pos="word" morph="none" start_char="10074" end_char="10084">favipiravir</TOKEN>
<TOKEN id="token-89-16" pos="punct" morph="none" start_char="10085" end_char="10086">,"</TOKEN>
<TOKEN id="token-89-17" pos="word" morph="none" start_char="10088" end_char="10094">Pramesh</TOKEN>
<TOKEN id="token-89-18" pos="word" morph="none" start_char="10096" end_char="10099">said</TOKEN>
<TOKEN id="token-89-19" pos="punct" morph="none" start_char="10100" end_char="10100">.</TOKEN>
</SEG>
<SEG id="segment-90" start_char="10102" end_char="10175">
<ORIGINAL_TEXT>"But by no means can this trial be considered a definitive phase 3 trial."</ORIGINAL_TEXT>
<TOKEN id="token-90-0" pos="punct" morph="none" start_char="10102" end_char="10102">"</TOKEN>
<TOKEN id="token-90-1" pos="word" morph="none" start_char="10103" end_char="10105">But</TOKEN>
<TOKEN id="token-90-2" pos="word" morph="none" start_char="10107" end_char="10108">by</TOKEN>
<TOKEN id="token-90-3" pos="word" morph="none" start_char="10110" end_char="10111">no</TOKEN>
<TOKEN id="token-90-4" pos="word" morph="none" start_char="10113" end_char="10117">means</TOKEN>
<TOKEN id="token-90-5" pos="word" morph="none" start_char="10119" end_char="10121">can</TOKEN>
<TOKEN id="token-90-6" pos="word" morph="none" start_char="10123" end_char="10126">this</TOKEN>
<TOKEN id="token-90-7" pos="word" morph="none" start_char="10128" end_char="10132">trial</TOKEN>
<TOKEN id="token-90-8" pos="word" morph="none" start_char="10134" end_char="10135">be</TOKEN>
<TOKEN id="token-90-9" pos="word" morph="none" start_char="10137" end_char="10146">considered</TOKEN>
<TOKEN id="token-90-10" pos="word" morph="none" start_char="10148" end_char="10148">a</TOKEN>
<TOKEN id="token-90-11" pos="word" morph="none" start_char="10150" end_char="10159">definitive</TOKEN>
<TOKEN id="token-90-12" pos="word" morph="none" start_char="10161" end_char="10165">phase</TOKEN>
<TOKEN id="token-90-13" pos="word" morph="none" start_char="10167" end_char="10167">3</TOKEN>
<TOKEN id="token-90-14" pos="word" morph="none" start_char="10169" end_char="10173">trial</TOKEN>
<TOKEN id="token-90-15" pos="punct" morph="none" start_char="10174" end_char="10175">."</TOKEN>
</SEG>
<SEG id="segment-91" start_char="10178" end_char="10385">
<ORIGINAL_TEXT>Glenmark officials say the company isn’t planning any larger controlled studies of favipiravir alone, although they pointed out that a few randomised studies are already happening in other parts of the world.</ORIGINAL_TEXT>
<TOKEN id="token-91-0" pos="word" morph="none" start_char="10178" end_char="10185">Glenmark</TOKEN>
<TOKEN id="token-91-1" pos="word" morph="none" start_char="10187" end_char="10195">officials</TOKEN>
<TOKEN id="token-91-2" pos="word" morph="none" start_char="10197" end_char="10199">say</TOKEN>
<TOKEN id="token-91-3" pos="word" morph="none" start_char="10201" end_char="10203">the</TOKEN>
<TOKEN id="token-91-4" pos="word" morph="none" start_char="10205" end_char="10211">company</TOKEN>
<TOKEN id="token-91-5" pos="word" morph="none" start_char="10213" end_char="10217">isn’t</TOKEN>
<TOKEN id="token-91-6" pos="word" morph="none" start_char="10219" end_char="10226">planning</TOKEN>
<TOKEN id="token-91-7" pos="word" morph="none" start_char="10228" end_char="10230">any</TOKEN>
<TOKEN id="token-91-8" pos="word" morph="none" start_char="10232" end_char="10237">larger</TOKEN>
<TOKEN id="token-91-9" pos="word" morph="none" start_char="10239" end_char="10248">controlled</TOKEN>
<TOKEN id="token-91-10" pos="word" morph="none" start_char="10250" end_char="10256">studies</TOKEN>
<TOKEN id="token-91-11" pos="word" morph="none" start_char="10258" end_char="10259">of</TOKEN>
<TOKEN id="token-91-12" pos="word" morph="none" start_char="10261" end_char="10271">favipiravir</TOKEN>
<TOKEN id="token-91-13" pos="word" morph="none" start_char="10273" end_char="10277">alone</TOKEN>
<TOKEN id="token-91-14" pos="punct" morph="none" start_char="10278" end_char="10278">,</TOKEN>
<TOKEN id="token-91-15" pos="word" morph="none" start_char="10280" end_char="10287">although</TOKEN>
<TOKEN id="token-91-16" pos="word" morph="none" start_char="10289" end_char="10292">they</TOKEN>
<TOKEN id="token-91-17" pos="word" morph="none" start_char="10294" end_char="10300">pointed</TOKEN>
<TOKEN id="token-91-18" pos="word" morph="none" start_char="10302" end_char="10304">out</TOKEN>
<TOKEN id="token-91-19" pos="word" morph="none" start_char="10306" end_char="10309">that</TOKEN>
<TOKEN id="token-91-20" pos="word" morph="none" start_char="10311" end_char="10311">a</TOKEN>
<TOKEN id="token-91-21" pos="word" morph="none" start_char="10313" end_char="10315">few</TOKEN>
<TOKEN id="token-91-22" pos="word" morph="none" start_char="10317" end_char="10326">randomised</TOKEN>
<TOKEN id="token-91-23" pos="word" morph="none" start_char="10328" end_char="10334">studies</TOKEN>
<TOKEN id="token-91-24" pos="word" morph="none" start_char="10336" end_char="10338">are</TOKEN>
<TOKEN id="token-91-25" pos="word" morph="none" start_char="10340" end_char="10346">already</TOKEN>
<TOKEN id="token-91-26" pos="word" morph="none" start_char="10348" end_char="10356">happening</TOKEN>
<TOKEN id="token-91-27" pos="word" morph="none" start_char="10358" end_char="10359">in</TOKEN>
<TOKEN id="token-91-28" pos="word" morph="none" start_char="10361" end_char="10365">other</TOKEN>
<TOKEN id="token-91-29" pos="word" morph="none" start_char="10367" end_char="10371">parts</TOKEN>
<TOKEN id="token-91-30" pos="word" morph="none" start_char="10373" end_char="10374">of</TOKEN>
<TOKEN id="token-91-31" pos="word" morph="none" start_char="10376" end_char="10378">the</TOKEN>
<TOKEN id="token-91-32" pos="word" morph="none" start_char="10380" end_char="10384">world</TOKEN>
<TOKEN id="token-91-33" pos="punct" morph="none" start_char="10385" end_char="10385">.</TOKEN>
</SEG>
<SEG id="segment-92" start_char="10387" end_char="10557">
<ORIGINAL_TEXT>Favipiravir may yet turn out to be a drug worth prescribing to COVID-19 patients – but we will have to wait for these ongoing trials to finish to know if this is the case.</ORIGINAL_TEXT>
<TOKEN id="token-92-0" pos="word" morph="none" start_char="10387" end_char="10397">Favipiravir</TOKEN>
<TOKEN id="token-92-1" pos="word" morph="none" start_char="10399" end_char="10401">may</TOKEN>
<TOKEN id="token-92-2" pos="word" morph="none" start_char="10403" end_char="10405">yet</TOKEN>
<TOKEN id="token-92-3" pos="word" morph="none" start_char="10407" end_char="10410">turn</TOKEN>
<TOKEN id="token-92-4" pos="word" morph="none" start_char="10412" end_char="10414">out</TOKEN>
<TOKEN id="token-92-5" pos="word" morph="none" start_char="10416" end_char="10417">to</TOKEN>
<TOKEN id="token-92-6" pos="word" morph="none" start_char="10419" end_char="10420">be</TOKEN>
<TOKEN id="token-92-7" pos="word" morph="none" start_char="10422" end_char="10422">a</TOKEN>
<TOKEN id="token-92-8" pos="word" morph="none" start_char="10424" end_char="10427">drug</TOKEN>
<TOKEN id="token-92-9" pos="word" morph="none" start_char="10429" end_char="10433">worth</TOKEN>
<TOKEN id="token-92-10" pos="word" morph="none" start_char="10435" end_char="10445">prescribing</TOKEN>
<TOKEN id="token-92-11" pos="word" morph="none" start_char="10447" end_char="10448">to</TOKEN>
<TOKEN id="token-92-12" pos="unknown" morph="none" start_char="10450" end_char="10457">COVID-19</TOKEN>
<TOKEN id="token-92-13" pos="word" morph="none" start_char="10459" end_char="10466">patients</TOKEN>
<TOKEN id="token-92-14" pos="punct" morph="none" start_char="10468" end_char="10468">–</TOKEN>
<TOKEN id="token-92-15" pos="word" morph="none" start_char="10470" end_char="10472">but</TOKEN>
<TOKEN id="token-92-16" pos="word" morph="none" start_char="10474" end_char="10475">we</TOKEN>
<TOKEN id="token-92-17" pos="word" morph="none" start_char="10477" end_char="10480">will</TOKEN>
<TOKEN id="token-92-18" pos="word" morph="none" start_char="10482" end_char="10485">have</TOKEN>
<TOKEN id="token-92-19" pos="word" morph="none" start_char="10487" end_char="10488">to</TOKEN>
<TOKEN id="token-92-20" pos="word" morph="none" start_char="10490" end_char="10493">wait</TOKEN>
<TOKEN id="token-92-21" pos="word" morph="none" start_char="10495" end_char="10497">for</TOKEN>
<TOKEN id="token-92-22" pos="word" morph="none" start_char="10499" end_char="10503">these</TOKEN>
<TOKEN id="token-92-23" pos="word" morph="none" start_char="10505" end_char="10511">ongoing</TOKEN>
<TOKEN id="token-92-24" pos="word" morph="none" start_char="10513" end_char="10518">trials</TOKEN>
<TOKEN id="token-92-25" pos="word" morph="none" start_char="10520" end_char="10521">to</TOKEN>
<TOKEN id="token-92-26" pos="word" morph="none" start_char="10523" end_char="10528">finish</TOKEN>
<TOKEN id="token-92-27" pos="word" morph="none" start_char="10530" end_char="10531">to</TOKEN>
<TOKEN id="token-92-28" pos="word" morph="none" start_char="10533" end_char="10536">know</TOKEN>
<TOKEN id="token-92-29" pos="word" morph="none" start_char="10538" end_char="10539">if</TOKEN>
<TOKEN id="token-92-30" pos="word" morph="none" start_char="10541" end_char="10544">this</TOKEN>
<TOKEN id="token-92-31" pos="word" morph="none" start_char="10546" end_char="10547">is</TOKEN>
<TOKEN id="token-92-32" pos="word" morph="none" start_char="10549" end_char="10551">the</TOKEN>
<TOKEN id="token-92-33" pos="word" morph="none" start_char="10553" end_char="10556">case</TOKEN>
<TOKEN id="token-92-34" pos="punct" morph="none" start_char="10557" end_char="10557">.</TOKEN>
</SEG>
<SEG id="segment-93" start_char="10560" end_char="10605">
<ORIGINAL_TEXT>As of now, experts say, it’s best to hold off.</ORIGINAL_TEXT>
<TOKEN id="token-93-0" pos="word" morph="none" start_char="10560" end_char="10561">As</TOKEN>
<TOKEN id="token-93-1" pos="word" morph="none" start_char="10563" end_char="10564">of</TOKEN>
<TOKEN id="token-93-2" pos="word" morph="none" start_char="10566" end_char="10568">now</TOKEN>
<TOKEN id="token-93-3" pos="punct" morph="none" start_char="10569" end_char="10569">,</TOKEN>
<TOKEN id="token-93-4" pos="word" morph="none" start_char="10571" end_char="10577">experts</TOKEN>
<TOKEN id="token-93-5" pos="word" morph="none" start_char="10579" end_char="10581">say</TOKEN>
<TOKEN id="token-93-6" pos="punct" morph="none" start_char="10582" end_char="10582">,</TOKEN>
<TOKEN id="token-93-7" pos="word" morph="none" start_char="10584" end_char="10587">it’s</TOKEN>
<TOKEN id="token-93-8" pos="word" morph="none" start_char="10589" end_char="10592">best</TOKEN>
<TOKEN id="token-93-9" pos="word" morph="none" start_char="10594" end_char="10595">to</TOKEN>
<TOKEN id="token-93-10" pos="word" morph="none" start_char="10597" end_char="10600">hold</TOKEN>
<TOKEN id="token-93-11" pos="word" morph="none" start_char="10602" end_char="10604">off</TOKEN>
<TOKEN id="token-93-12" pos="punct" morph="none" start_char="10605" end_char="10605">.</TOKEN>
</SEG>
<SEG id="segment-94" start_char="10608" end_char="10697">
<ORIGINAL_TEXT>The reporting for this article was supported by a grant from the Thakur Family Foundation.</ORIGINAL_TEXT>
<TOKEN id="token-94-0" pos="word" morph="none" start_char="10608" end_char="10610">The</TOKEN>
<TOKEN id="token-94-1" pos="word" morph="none" start_char="10612" end_char="10620">reporting</TOKEN>
<TOKEN id="token-94-2" pos="word" morph="none" start_char="10622" end_char="10624">for</TOKEN>
<TOKEN id="token-94-3" pos="word" morph="none" start_char="10626" end_char="10629">this</TOKEN>
<TOKEN id="token-94-4" pos="word" morph="none" start_char="10631" end_char="10637">article</TOKEN>
<TOKEN id="token-94-5" pos="word" morph="none" start_char="10639" end_char="10641">was</TOKEN>
<TOKEN id="token-94-6" pos="word" morph="none" start_char="10643" end_char="10651">supported</TOKEN>
<TOKEN id="token-94-7" pos="word" morph="none" start_char="10653" end_char="10654">by</TOKEN>
<TOKEN id="token-94-8" pos="word" morph="none" start_char="10656" end_char="10656">a</TOKEN>
<TOKEN id="token-94-9" pos="word" morph="none" start_char="10658" end_char="10662">grant</TOKEN>
<TOKEN id="token-94-10" pos="word" morph="none" start_char="10664" end_char="10667">from</TOKEN>
<TOKEN id="token-94-11" pos="word" morph="none" start_char="10669" end_char="10671">the</TOKEN>
<TOKEN id="token-94-12" pos="word" morph="none" start_char="10673" end_char="10678">Thakur</TOKEN>
<TOKEN id="token-94-13" pos="word" morph="none" start_char="10680" end_char="10685">Family</TOKEN>
<TOKEN id="token-94-14" pos="word" morph="none" start_char="10687" end_char="10696">Foundation</TOKEN>
<TOKEN id="token-94-15" pos="punct" morph="none" start_char="10697" end_char="10697">.</TOKEN>
</SEG>
<SEG id="segment-95" start_char="10699" end_char="10785">
<ORIGINAL_TEXT>The foundation did not exercise any editorial control over the contents of the article.</ORIGINAL_TEXT>
<TOKEN id="token-95-0" pos="word" morph="none" start_char="10699" end_char="10701">The</TOKEN>
<TOKEN id="token-95-1" pos="word" morph="none" start_char="10703" end_char="10712">foundation</TOKEN>
<TOKEN id="token-95-2" pos="word" morph="none" start_char="10714" end_char="10716">did</TOKEN>
<TOKEN id="token-95-3" pos="word" morph="none" start_char="10718" end_char="10720">not</TOKEN>
<TOKEN id="token-95-4" pos="word" morph="none" start_char="10722" end_char="10729">exercise</TOKEN>
<TOKEN id="token-95-5" pos="word" morph="none" start_char="10731" end_char="10733">any</TOKEN>
<TOKEN id="token-95-6" pos="word" morph="none" start_char="10735" end_char="10743">editorial</TOKEN>
<TOKEN id="token-95-7" pos="word" morph="none" start_char="10745" end_char="10751">control</TOKEN>
<TOKEN id="token-95-8" pos="word" morph="none" start_char="10753" end_char="10756">over</TOKEN>
<TOKEN id="token-95-9" pos="word" morph="none" start_char="10758" end_char="10760">the</TOKEN>
<TOKEN id="token-95-10" pos="word" morph="none" start_char="10762" end_char="10769">contents</TOKEN>
<TOKEN id="token-95-11" pos="word" morph="none" start_char="10771" end_char="10772">of</TOKEN>
<TOKEN id="token-95-12" pos="word" morph="none" start_char="10774" end_char="10776">the</TOKEN>
<TOKEN id="token-95-13" pos="word" morph="none" start_char="10778" end_char="10784">article</TOKEN>
<TOKEN id="token-95-14" pos="punct" morph="none" start_char="10785" end_char="10785">.</TOKEN>
</SEG>
<SEG id="segment-96" start_char="10788" end_char="10822">
<ORIGINAL_TEXT>Priyanka Pulla is a science writer.</ORIGINAL_TEXT>
<TOKEN id="token-96-0" pos="word" morph="none" start_char="10788" end_char="10795">Priyanka</TOKEN>
<TOKEN id="token-96-1" pos="word" morph="none" start_char="10797" end_char="10801">Pulla</TOKEN>
<TOKEN id="token-96-2" pos="word" morph="none" start_char="10803" end_char="10804">is</TOKEN>
<TOKEN id="token-96-3" pos="word" morph="none" start_char="10806" end_char="10806">a</TOKEN>
<TOKEN id="token-96-4" pos="word" morph="none" start_char="10808" end_char="10814">science</TOKEN>
<TOKEN id="token-96-5" pos="word" morph="none" start_char="10816" end_char="10821">writer</TOKEN>
<TOKEN id="token-96-6" pos="punct" morph="none" start_char="10822" end_char="10822">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
