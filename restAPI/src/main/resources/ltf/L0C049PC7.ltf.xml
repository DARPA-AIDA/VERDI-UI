<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="ukr">
<DOC id="L0C049PC7" lang="ukr" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="6802" raw_text_md5="2b356d67c7704ce2368ccea4fb91dc79">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="69">
<ORIGINAL_TEXT>Debunked: This image doesn't show 'extent of corpse burning in Wuhan'</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="8">Debunked</TOKEN>
<TOKEN id="token-0-1" pos="punct" morph="none" start_char="9" end_char="9">:</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="11" end_char="14">This</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="16" end_char="20">image</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="22" end_char="28">doesn't</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="30" end_char="33">show</TOKEN>
<TOKEN id="token-0-6" pos="punct" morph="none" start_char="35" end_char="35">'</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="36" end_char="41">extent</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="43" end_char="44">of</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="46" end_char="51">corpse</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="53" end_char="59">burning</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="61" end_char="62">in</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="64" end_char="68">Wuhan</TOKEN>
<TOKEN id="token-0-13" pos="punct" morph="none" start_char="69" end_char="69">'</TOKEN>
</SEG>
<SEG id="segment-1" start_char="73" end_char="142">
<ORIGINAL_TEXT>Sulphur dioxyde levels forecast for Wuhan and Chongqing on February 12</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="73" end_char="79">Sulphur</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="81" end_char="87">dioxyde</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="89" end_char="94">levels</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="96" end_char="103">forecast</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="105" end_char="107">for</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="109" end_char="113">Wuhan</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="115" end_char="117">and</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="119" end_char="127">Chongqing</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="129" end_char="130">on</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="132" end_char="139">February</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="141" end_char="142">12</TOKEN>
</SEG>
<SEG id="segment-2" start_char="146" end_char="371">
<ORIGINAL_TEXT>In the midst of what the World Health Organisation calls an "infodemic" of fake news around the COVID-19 coronavirus outbreak, British tabloid newspapers published images they suggested was evidence of corpse burning in Wuhan.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="146" end_char="147">In</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="149" end_char="151">the</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="153" end_char="157">midst</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="159" end_char="160">of</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="162" end_char="165">what</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="167" end_char="169">the</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="171" end_char="175">World</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="177" end_char="182">Health</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="184" end_char="195">Organisation</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="197" end_char="201">calls</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="203" end_char="204">an</TOKEN>
<TOKEN id="token-2-11" pos="punct" morph="none" start_char="206" end_char="206">"</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="207" end_char="215">infodemic</TOKEN>
<TOKEN id="token-2-13" pos="punct" morph="none" start_char="216" end_char="216">"</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="218" end_char="219">of</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="221" end_char="224">fake</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="226" end_char="229">news</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="231" end_char="236">around</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="238" end_char="240">the</TOKEN>
<TOKEN id="token-2-19" pos="unknown" morph="none" start_char="242" end_char="249">COVID-19</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="251" end_char="261">coronavirus</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="263" end_char="270">outbreak</TOKEN>
<TOKEN id="token-2-22" pos="punct" morph="none" start_char="271" end_char="271">,</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="273" end_char="279">British</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="281" end_char="287">tabloid</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="289" end_char="298">newspapers</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="300" end_char="308">published</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="310" end_char="315">images</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="317" end_char="320">they</TOKEN>
<TOKEN id="token-2-29" pos="word" morph="none" start_char="322" end_char="330">suggested</TOKEN>
<TOKEN id="token-2-30" pos="word" morph="none" start_char="332" end_char="334">was</TOKEN>
<TOKEN id="token-2-31" pos="word" morph="none" start_char="336" end_char="343">evidence</TOKEN>
<TOKEN id="token-2-32" pos="word" morph="none" start_char="345" end_char="346">of</TOKEN>
<TOKEN id="token-2-33" pos="word" morph="none" start_char="348" end_char="353">corpse</TOKEN>
<TOKEN id="token-2-34" pos="word" morph="none" start_char="355" end_char="361">burning</TOKEN>
<TOKEN id="token-2-35" pos="word" morph="none" start_char="363" end_char="364">in</TOKEN>
<TOKEN id="token-2-36" pos="word" morph="none" start_char="366" end_char="370">Wuhan</TOKEN>
<TOKEN id="token-2-37" pos="punct" morph="none" start_char="371" end_char="371">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="374" end_char="591">
<ORIGINAL_TEXT>Although the conditional tense was used, they inferred "satellite images" from the windy.com showed high levels of sulphur dioxide (SO2) in Wuhan and Chongqing, both cities quarantined at the epicentre of the outbreak.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="374" end_char="381">Although</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="383" end_char="385">the</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="387" end_char="397">conditional</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="399" end_char="403">tense</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="405" end_char="407">was</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="409" end_char="412">used</TOKEN>
<TOKEN id="token-3-6" pos="punct" morph="none" start_char="413" end_char="413">,</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="415" end_char="418">they</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="420" end_char="427">inferred</TOKEN>
<TOKEN id="token-3-9" pos="punct" morph="none" start_char="429" end_char="429">"</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="430" end_char="438">satellite</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="440" end_char="445">images</TOKEN>
<TOKEN id="token-3-12" pos="punct" morph="none" start_char="446" end_char="446">"</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="448" end_char="451">from</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="453" end_char="455">the</TOKEN>
<TOKEN id="token-3-15" pos="unknown" morph="none" start_char="457" end_char="465">windy.com</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="467" end_char="472">showed</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="474" end_char="477">high</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="479" end_char="484">levels</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="486" end_char="487">of</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="489" end_char="495">sulphur</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="497" end_char="503">dioxide</TOKEN>
<TOKEN id="token-3-22" pos="punct" morph="none" start_char="505" end_char="505">(</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="506" end_char="508">SO2</TOKEN>
<TOKEN id="token-3-24" pos="punct" morph="none" start_char="509" end_char="509">)</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="511" end_char="512">in</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="514" end_char="518">Wuhan</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="520" end_char="522">and</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="524" end_char="532">Chongqing</TOKEN>
<TOKEN id="token-3-29" pos="punct" morph="none" start_char="533" end_char="533">,</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="535" end_char="538">both</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="540" end_char="545">cities</TOKEN>
<TOKEN id="token-3-32" pos="word" morph="none" start_char="547" end_char="557">quarantined</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="559" end_char="560">at</TOKEN>
<TOKEN id="token-3-34" pos="word" morph="none" start_char="562" end_char="564">the</TOKEN>
<TOKEN id="token-3-35" pos="word" morph="none" start_char="566" end_char="574">epicentre</TOKEN>
<TOKEN id="token-3-36" pos="word" morph="none" start_char="576" end_char="577">of</TOKEN>
<TOKEN id="token-3-37" pos="word" morph="none" start_char="579" end_char="581">the</TOKEN>
<TOKEN id="token-3-38" pos="word" morph="none" start_char="583" end_char="590">outbreak</TOKEN>
<TOKEN id="token-3-39" pos="punct" morph="none" start_char="591" end_char="591">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="594" end_char="669">
<ORIGINAL_TEXT>The Sun newspaper ran a story suggesting Beijing was "burning the evidence".</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="594" end_char="596">The</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="598" end_char="600">Sun</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="602" end_char="610">newspaper</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="612" end_char="614">ran</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="616" end_char="616">a</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="618" end_char="622">story</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="624" end_char="633">suggesting</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="635" end_char="641">Beijing</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="643" end_char="645">was</TOKEN>
<TOKEN id="token-4-9" pos="punct" morph="none" start_char="647" end_char="647">"</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="648" end_char="654">burning</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="656" end_char="658">the</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="660" end_char="667">evidence</TOKEN>
<TOKEN id="token-4-13" pos="punct" morph="none" start_char="668" end_char="669">".</TOKEN>
</SEG>
<SEG id="segment-5" start_char="671" end_char="806">
<ORIGINAL_TEXT>The headline read: with China accused of major coronavirus cover-up as chilling satellite pics 'show extent of corpse burning in Wuhan’.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="671" end_char="673">The</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="675" end_char="682">headline</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="684" end_char="687">read</TOKEN>
<TOKEN id="token-5-3" pos="punct" morph="none" start_char="688" end_char="688">:</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="690" end_char="693">with</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="695" end_char="699">China</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="701" end_char="707">accused</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="709" end_char="710">of</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="712" end_char="716">major</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="718" end_char="728">coronavirus</TOKEN>
<TOKEN id="token-5-10" pos="unknown" morph="none" start_char="730" end_char="737">cover-up</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="739" end_char="740">as</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="742" end_char="749">chilling</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="751" end_char="759">satellite</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="761" end_char="764">pics</TOKEN>
<TOKEN id="token-5-15" pos="punct" morph="none" start_char="766" end_char="766">'</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="767" end_char="770">show</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="772" end_char="777">extent</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="779" end_char="780">of</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="782" end_char="787">corpse</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="789" end_char="795">burning</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="797" end_char="798">in</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="800" end_char="804">Wuhan</TOKEN>
<TOKEN id="token-5-23" pos="punct" morph="none" start_char="805" end_char="806">’.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="809" end_char="846">
<ORIGINAL_TEXT>The Daily Mirror used a question mark.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="809" end_char="811">The</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="813" end_char="817">Daily</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="819" end_char="824">Mirror</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="826" end_char="829">used</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="831" end_char="831">a</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="833" end_char="840">question</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="842" end_char="845">mark</TOKEN>
<TOKEN id="token-6-7" pos="punct" morph="none" start_char="846" end_char="846">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="849" end_char="965">
<ORIGINAL_TEXT>But both suggested that these high levels of SO2 could have come from an unusual crematorium activity in both cities.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="849" end_char="851">But</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="853" end_char="856">both</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="858" end_char="866">suggested</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="868" end_char="871">that</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="873" end_char="877">these</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="879" end_char="882">high</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="884" end_char="889">levels</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="891" end_char="892">of</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="894" end_char="896">SO2</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="898" end_char="902">could</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="904" end_char="907">have</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="909" end_char="912">come</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="914" end_char="917">from</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="919" end_char="920">an</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="922" end_char="928">unusual</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="930" end_char="940">crematorium</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="942" end_char="949">activity</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="951" end_char="952">in</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="954" end_char="957">both</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="959" end_char="964">cities</TOKEN>
<TOKEN id="token-7-20" pos="punct" morph="none" start_char="965" end_char="965">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="967" end_char="992">
<ORIGINAL_TEXT>Other media followed suit.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="967" end_char="971">Other</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="973" end_char="977">media</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="979" end_char="986">followed</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="988" end_char="991">suit</TOKEN>
<TOKEN id="token-8-4" pos="punct" morph="none" start_char="992" end_char="992">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="995" end_char="1107">
<ORIGINAL_TEXT>The claim pushed China's air quality office to issue a statement via China's Ministry of Ecology and Environment.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="995" end_char="997">The</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="999" end_char="1003">claim</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1005" end_char="1010">pushed</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1012" end_char="1018">China's</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1020" end_char="1022">air</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1024" end_char="1030">quality</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1032" end_char="1037">office</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1039" end_char="1040">to</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1042" end_char="1046">issue</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1048" end_char="1048">a</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1050" end_char="1058">statement</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1060" end_char="1062">via</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1064" end_char="1070">China's</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1072" end_char="1079">Ministry</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1081" end_char="1082">of</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1084" end_char="1090">Ecology</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1092" end_char="1094">and</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1096" end_char="1106">Environment</TOKEN>
<TOKEN id="token-9-18" pos="punct" morph="none" start_char="1107" end_char="1107">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1110" end_char="1265">
<ORIGINAL_TEXT>It said: "After careful confirmation, we found that the SO2 rise published by windy.com was a 'serious distortion' and its statistics could not be trusted."</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1110" end_char="1111">It</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1113" end_char="1116">said</TOKEN>
<TOKEN id="token-10-2" pos="punct" morph="none" start_char="1117" end_char="1117">:</TOKEN>
<TOKEN id="token-10-3" pos="punct" morph="none" start_char="1119" end_char="1119">"</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1120" end_char="1124">After</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1126" end_char="1132">careful</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1134" end_char="1145">confirmation</TOKEN>
<TOKEN id="token-10-7" pos="punct" morph="none" start_char="1146" end_char="1146">,</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1148" end_char="1149">we</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1151" end_char="1155">found</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1157" end_char="1160">that</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1162" end_char="1164">the</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1166" end_char="1168">SO2</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1170" end_char="1173">rise</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1175" end_char="1183">published</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1185" end_char="1186">by</TOKEN>
<TOKEN id="token-10-16" pos="unknown" morph="none" start_char="1188" end_char="1196">windy.com</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1198" end_char="1200">was</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1202" end_char="1202">a</TOKEN>
<TOKEN id="token-10-19" pos="punct" morph="none" start_char="1204" end_char="1204">'</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1205" end_char="1211">serious</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1213" end_char="1222">distortion</TOKEN>
<TOKEN id="token-10-22" pos="punct" morph="none" start_char="1223" end_char="1223">'</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1225" end_char="1227">and</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1229" end_char="1231">its</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="1233" end_char="1242">statistics</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="1244" end_char="1248">could</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="1250" end_char="1252">not</TOKEN>
<TOKEN id="token-10-28" pos="word" morph="none" start_char="1254" end_char="1255">be</TOKEN>
<TOKEN id="token-10-29" pos="word" morph="none" start_char="1257" end_char="1263">trusted</TOKEN>
<TOKEN id="token-10-30" pos="punct" morph="none" start_char="1264" end_char="1265">."</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1268" end_char="1404">
<ORIGINAL_TEXT>According to their data, a concentration of between 4 and 8 μg/m3 was recorded on Sunday and not 1,300 μg/m3 as shown by the application.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1268" end_char="1276">According</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1278" end_char="1279">to</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1281" end_char="1285">their</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1287" end_char="1290">data</TOKEN>
<TOKEN id="token-11-4" pos="punct" morph="none" start_char="1291" end_char="1291">,</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1293" end_char="1293">a</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1295" end_char="1307">concentration</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1309" end_char="1310">of</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1312" end_char="1318">between</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1320" end_char="1320">4</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1322" end_char="1324">and</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1326" end_char="1326">8</TOKEN>
<TOKEN id="token-11-12" pos="unknown" morph="none" start_char="1328" end_char="1332">μg/m3</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1334" end_char="1336">was</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1338" end_char="1345">recorded</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1347" end_char="1348">on</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1350" end_char="1355">Sunday</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1357" end_char="1359">and</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1361" end_char="1363">not</TOKEN>
<TOKEN id="token-11-19" pos="unknown" morph="none" start_char="1365" end_char="1369">1,300</TOKEN>
<TOKEN id="token-11-20" pos="unknown" morph="none" start_char="1371" end_char="1375">μg/m3</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="1377" end_char="1378">as</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="1380" end_char="1384">shown</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="1386" end_char="1387">by</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="1389" end_char="1391">the</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="1393" end_char="1403">application</TOKEN>
<TOKEN id="token-11-26" pos="punct" morph="none" start_char="1404" end_char="1404">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1407" end_char="1452">
<ORIGINAL_TEXT>Where did the sulphur dioxide claim come from?</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1407" end_char="1411">Where</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1413" end_char="1415">did</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1417" end_char="1419">the</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1421" end_char="1427">sulphur</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1429" end_char="1435">dioxide</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1437" end_char="1441">claim</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1443" end_char="1446">come</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1448" end_char="1451">from</TOKEN>
<TOKEN id="token-12-8" pos="punct" morph="none" start_char="1452" end_char="1452">?</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1456" end_char="1608">
<ORIGINAL_TEXT>A tweet from Twitter account @inteldotwav, with just over 16,000 followers, posted a thread including what looked like an impressive image on February 8.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1456" end_char="1456">A</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1458" end_char="1462">tweet</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1464" end_char="1467">from</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1469" end_char="1475">Twitter</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1477" end_char="1483">account</TOKEN>
<TOKEN id="token-13-5" pos="tag" morph="none" start_char="1485" end_char="1497">@inteldotwav,</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1499" end_char="1502">with</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1504" end_char="1507">just</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1509" end_char="1512">over</TOKEN>
<TOKEN id="token-13-9" pos="unknown" morph="none" start_char="1514" end_char="1519">16,000</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1521" end_char="1529">followers</TOKEN>
<TOKEN id="token-13-11" pos="punct" morph="none" start_char="1530" end_char="1530">,</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1532" end_char="1537">posted</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1539" end_char="1539">a</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1541" end_char="1546">thread</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1548" end_char="1556">including</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1558" end_char="1561">what</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1563" end_char="1568">looked</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1570" end_char="1573">like</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1575" end_char="1576">an</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1578" end_char="1587">impressive</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="1589" end_char="1593">image</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="1595" end_char="1596">on</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="1598" end_char="1605">February</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="1607" end_char="1607">8</TOKEN>
<TOKEN id="token-13-25" pos="punct" morph="none" start_char="1608" end_char="1608">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1611" end_char="1685">
<ORIGINAL_TEXT>It claimed to show dangerously high levels of SO2 near Wuhan and Chongqing.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1611" end_char="1612">It</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1614" end_char="1620">claimed</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1622" end_char="1623">to</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1625" end_char="1628">show</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1630" end_char="1640">dangerously</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1642" end_char="1645">high</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1647" end_char="1652">levels</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1654" end_char="1655">of</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1657" end_char="1659">SO2</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1661" end_char="1664">near</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1666" end_char="1670">Wuhan</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1672" end_char="1674">and</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1676" end_char="1684">Chongqing</TOKEN>
<TOKEN id="token-14-13" pos="punct" morph="none" start_char="1685" end_char="1685">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1688" end_char="1791">
<ORIGINAL_TEXT>The person behind the tweet left interpretation of what the high levels of SO2 meant open to the reader,</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1688" end_char="1690">The</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1692" end_char="1697">person</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1699" end_char="1704">behind</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1706" end_char="1708">the</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1710" end_char="1714">tweet</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1716" end_char="1719">left</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1721" end_char="1734">interpretation</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1736" end_char="1737">of</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1739" end_char="1742">what</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1744" end_char="1746">the</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1748" end_char="1751">high</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1753" end_char="1758">levels</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1760" end_char="1761">of</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1763" end_char="1765">SO2</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1767" end_char="1771">meant</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="1773" end_char="1776">open</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="1778" end_char="1779">to</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="1781" end_char="1783">the</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="1785" end_char="1790">reader</TOKEN>
<TOKEN id="token-15-19" pos="punct" morph="none" start_char="1791" end_char="1791">,</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1794" end_char="2101">
<ORIGINAL_TEXT>It was suggested it could be a power plant, burning garbage or animal carcasses, and "the third and most morbid: that bodies are being burned on the outskirts of the city, that the numbers of victims are much higher than what the Chinese Communist Party is reporting, and that things are really, really bad."</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1794" end_char="1795">It</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1797" end_char="1799">was</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1801" end_char="1809">suggested</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1811" end_char="1812">it</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1814" end_char="1818">could</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1820" end_char="1821">be</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1823" end_char="1823">a</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1825" end_char="1829">power</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1831" end_char="1835">plant</TOKEN>
<TOKEN id="token-16-9" pos="punct" morph="none" start_char="1836" end_char="1836">,</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="1838" end_char="1844">burning</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="1846" end_char="1852">garbage</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="1854" end_char="1855">or</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="1857" end_char="1862">animal</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="1864" end_char="1872">carcasses</TOKEN>
<TOKEN id="token-16-15" pos="punct" morph="none" start_char="1873" end_char="1873">,</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="1875" end_char="1877">and</TOKEN>
<TOKEN id="token-16-17" pos="punct" morph="none" start_char="1879" end_char="1879">"</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="1880" end_char="1882">the</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="1884" end_char="1888">third</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="1890" end_char="1892">and</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="1894" end_char="1897">most</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="1899" end_char="1904">morbid</TOKEN>
<TOKEN id="token-16-23" pos="punct" morph="none" start_char="1905" end_char="1905">:</TOKEN>
<TOKEN id="token-16-24" pos="word" morph="none" start_char="1907" end_char="1910">that</TOKEN>
<TOKEN id="token-16-25" pos="word" morph="none" start_char="1912" end_char="1917">bodies</TOKEN>
<TOKEN id="token-16-26" pos="word" morph="none" start_char="1919" end_char="1921">are</TOKEN>
<TOKEN id="token-16-27" pos="word" morph="none" start_char="1923" end_char="1927">being</TOKEN>
<TOKEN id="token-16-28" pos="word" morph="none" start_char="1929" end_char="1934">burned</TOKEN>
<TOKEN id="token-16-29" pos="word" morph="none" start_char="1936" end_char="1937">on</TOKEN>
<TOKEN id="token-16-30" pos="word" morph="none" start_char="1939" end_char="1941">the</TOKEN>
<TOKEN id="token-16-31" pos="word" morph="none" start_char="1943" end_char="1951">outskirts</TOKEN>
<TOKEN id="token-16-32" pos="word" morph="none" start_char="1953" end_char="1954">of</TOKEN>
<TOKEN id="token-16-33" pos="word" morph="none" start_char="1956" end_char="1958">the</TOKEN>
<TOKEN id="token-16-34" pos="word" morph="none" start_char="1960" end_char="1963">city</TOKEN>
<TOKEN id="token-16-35" pos="punct" morph="none" start_char="1964" end_char="1964">,</TOKEN>
<TOKEN id="token-16-36" pos="word" morph="none" start_char="1966" end_char="1969">that</TOKEN>
<TOKEN id="token-16-37" pos="word" morph="none" start_char="1971" end_char="1973">the</TOKEN>
<TOKEN id="token-16-38" pos="word" morph="none" start_char="1975" end_char="1981">numbers</TOKEN>
<TOKEN id="token-16-39" pos="word" morph="none" start_char="1983" end_char="1984">of</TOKEN>
<TOKEN id="token-16-40" pos="word" morph="none" start_char="1986" end_char="1992">victims</TOKEN>
<TOKEN id="token-16-41" pos="word" morph="none" start_char="1994" end_char="1996">are</TOKEN>
<TOKEN id="token-16-42" pos="word" morph="none" start_char="1998" end_char="2001">much</TOKEN>
<TOKEN id="token-16-43" pos="word" morph="none" start_char="2003" end_char="2008">higher</TOKEN>
<TOKEN id="token-16-44" pos="word" morph="none" start_char="2010" end_char="2013">than</TOKEN>
<TOKEN id="token-16-45" pos="word" morph="none" start_char="2015" end_char="2018">what</TOKEN>
<TOKEN id="token-16-46" pos="word" morph="none" start_char="2020" end_char="2022">the</TOKEN>
<TOKEN id="token-16-47" pos="word" morph="none" start_char="2024" end_char="2030">Chinese</TOKEN>
<TOKEN id="token-16-48" pos="word" morph="none" start_char="2032" end_char="2040">Communist</TOKEN>
<TOKEN id="token-16-49" pos="word" morph="none" start_char="2042" end_char="2046">Party</TOKEN>
<TOKEN id="token-16-50" pos="word" morph="none" start_char="2048" end_char="2049">is</TOKEN>
<TOKEN id="token-16-51" pos="word" morph="none" start_char="2051" end_char="2059">reporting</TOKEN>
<TOKEN id="token-16-52" pos="punct" morph="none" start_char="2060" end_char="2060">,</TOKEN>
<TOKEN id="token-16-53" pos="word" morph="none" start_char="2062" end_char="2064">and</TOKEN>
<TOKEN id="token-16-54" pos="word" morph="none" start_char="2066" end_char="2069">that</TOKEN>
<TOKEN id="token-16-55" pos="word" morph="none" start_char="2071" end_char="2076">things</TOKEN>
<TOKEN id="token-16-56" pos="word" morph="none" start_char="2078" end_char="2080">are</TOKEN>
<TOKEN id="token-16-57" pos="word" morph="none" start_char="2082" end_char="2087">really</TOKEN>
<TOKEN id="token-16-58" pos="punct" morph="none" start_char="2088" end_char="2088">,</TOKEN>
<TOKEN id="token-16-59" pos="word" morph="none" start_char="2090" end_char="2095">really</TOKEN>
<TOKEN id="token-16-60" pos="word" morph="none" start_char="2097" end_char="2099">bad</TOKEN>
<TOKEN id="token-16-61" pos="punct" morph="none" start_char="2100" end_char="2101">."</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2104" end_char="2202">
<ORIGINAL_TEXT>The tweeter confirmed he saw the rumours on the internet and decided to do his own "investigation".</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2104" end_char="2106">The</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2108" end_char="2114">tweeter</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2116" end_char="2124">confirmed</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2126" end_char="2127">he</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2129" end_char="2131">saw</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2133" end_char="2135">the</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2137" end_char="2143">rumours</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2145" end_char="2146">on</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2148" end_char="2150">the</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2152" end_char="2159">internet</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2161" end_char="2163">and</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2165" end_char="2171">decided</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2173" end_char="2174">to</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2176" end_char="2177">do</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2179" end_char="2181">his</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2183" end_char="2185">own</TOKEN>
<TOKEN id="token-17-16" pos="punct" morph="none" start_char="2187" end_char="2187">"</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="2188" end_char="2200">investigation</TOKEN>
<TOKEN id="token-17-18" pos="punct" morph="none" start_char="2201" end_char="2202">".</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2204" end_char="2247">
<ORIGINAL_TEXT>However, his method proved to be misleading.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2204" end_char="2210">However</TOKEN>
<TOKEN id="token-18-1" pos="punct" morph="none" start_char="2211" end_char="2211">,</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2213" end_char="2215">his</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2217" end_char="2222">method</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2224" end_char="2229">proved</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2231" end_char="2232">to</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2234" end_char="2235">be</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2237" end_char="2246">misleading</TOKEN>
<TOKEN id="token-18-8" pos="punct" morph="none" start_char="2247" end_char="2247">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2250" end_char="2500">
<ORIGINAL_TEXT>In recent days, some media have reported that Wuhan's crematoria are operating 24/7 based on an interview with an employee, interviewed reportedly obtained by The Epoch Times, a conservative and anti-communist media of the Chinese community in the US.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2250" end_char="2251">In</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2253" end_char="2258">recent</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2260" end_char="2263">days</TOKEN>
<TOKEN id="token-19-3" pos="punct" morph="none" start_char="2264" end_char="2264">,</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2266" end_char="2269">some</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2271" end_char="2275">media</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2277" end_char="2280">have</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2282" end_char="2289">reported</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2291" end_char="2294">that</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="2296" end_char="2302">Wuhan's</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="2304" end_char="2313">crematoria</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="2315" end_char="2317">are</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="2319" end_char="2327">operating</TOKEN>
<TOKEN id="token-19-13" pos="unknown" morph="none" start_char="2329" end_char="2332">24/7</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="2334" end_char="2338">based</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="2340" end_char="2341">on</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="2343" end_char="2344">an</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="2346" end_char="2354">interview</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="2356" end_char="2359">with</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="2361" end_char="2362">an</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="2364" end_char="2371">employee</TOKEN>
<TOKEN id="token-19-21" pos="punct" morph="none" start_char="2372" end_char="2372">,</TOKEN>
<TOKEN id="token-19-22" pos="word" morph="none" start_char="2374" end_char="2384">interviewed</TOKEN>
<TOKEN id="token-19-23" pos="word" morph="none" start_char="2386" end_char="2395">reportedly</TOKEN>
<TOKEN id="token-19-24" pos="word" morph="none" start_char="2397" end_char="2404">obtained</TOKEN>
<TOKEN id="token-19-25" pos="word" morph="none" start_char="2406" end_char="2407">by</TOKEN>
<TOKEN id="token-19-26" pos="word" morph="none" start_char="2409" end_char="2411">The</TOKEN>
<TOKEN id="token-19-27" pos="word" morph="none" start_char="2413" end_char="2417">Epoch</TOKEN>
<TOKEN id="token-19-28" pos="word" morph="none" start_char="2419" end_char="2423">Times</TOKEN>
<TOKEN id="token-19-29" pos="punct" morph="none" start_char="2424" end_char="2424">,</TOKEN>
<TOKEN id="token-19-30" pos="word" morph="none" start_char="2426" end_char="2426">a</TOKEN>
<TOKEN id="token-19-31" pos="word" morph="none" start_char="2428" end_char="2439">conservative</TOKEN>
<TOKEN id="token-19-32" pos="word" morph="none" start_char="2441" end_char="2443">and</TOKEN>
<TOKEN id="token-19-33" pos="unknown" morph="none" start_char="2445" end_char="2458">anti-communist</TOKEN>
<TOKEN id="token-19-34" pos="word" morph="none" start_char="2460" end_char="2464">media</TOKEN>
<TOKEN id="token-19-35" pos="word" morph="none" start_char="2466" end_char="2467">of</TOKEN>
<TOKEN id="token-19-36" pos="word" morph="none" start_char="2469" end_char="2471">the</TOKEN>
<TOKEN id="token-19-37" pos="word" morph="none" start_char="2473" end_char="2479">Chinese</TOKEN>
<TOKEN id="token-19-38" pos="word" morph="none" start_char="2481" end_char="2489">community</TOKEN>
<TOKEN id="token-19-39" pos="word" morph="none" start_char="2491" end_char="2492">in</TOKEN>
<TOKEN id="token-19-40" pos="word" morph="none" start_char="2494" end_char="2496">the</TOKEN>
<TOKEN id="token-19-41" pos="word" morph="none" start_char="2498" end_char="2499">US</TOKEN>
<TOKEN id="token-19-42" pos="punct" morph="none" start_char="2500" end_char="2500">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2502" end_char="2583">
<ORIGINAL_TEXT>Other experts outside China also question the accuracy of the official death toll.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2502" end_char="2506">Other</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2508" end_char="2514">experts</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2516" end_char="2522">outside</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2524" end_char="2528">China</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2530" end_char="2533">also</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2535" end_char="2542">question</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2544" end_char="2546">the</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2548" end_char="2555">accuracy</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="2557" end_char="2558">of</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2560" end_char="2562">the</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2564" end_char="2571">official</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="2573" end_char="2577">death</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="2579" end_char="2582">toll</TOKEN>
<TOKEN id="token-20-13" pos="punct" morph="none" start_char="2583" end_char="2583">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2586" end_char="2605">
<ORIGINAL_TEXT>So what's the truth?</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2586" end_char="2587">So</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2589" end_char="2594">what's</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2596" end_char="2598">the</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2600" end_char="2604">truth</TOKEN>
<TOKEN id="token-21-4" pos="punct" morph="none" start_char="2605" end_char="2605">?</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2609" end_char="2692">
<ORIGINAL_TEXT>It is true that data on windy.com shows extremely high levels of SO2 in both cities.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2609" end_char="2610">It</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2612" end_char="2613">is</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2615" end_char="2618">true</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2620" end_char="2623">that</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2625" end_char="2628">data</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2630" end_char="2631">on</TOKEN>
<TOKEN id="token-22-6" pos="unknown" morph="none" start_char="2633" end_char="2641">windy.com</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2643" end_char="2647">shows</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="2649" end_char="2657">extremely</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="2659" end_char="2662">high</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="2664" end_char="2669">levels</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="2671" end_char="2672">of</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="2674" end_char="2676">SO2</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="2678" end_char="2679">in</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="2681" end_char="2684">both</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="2686" end_char="2691">cities</TOKEN>
<TOKEN id="token-22-16" pos="punct" morph="none" start_char="2692" end_char="2692">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2695" end_char="2815">
<ORIGINAL_TEXT>But little or nothing allows us to establish a relationship with the alleged unbridled activity at the city's crematoria.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2695" end_char="2697">But</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2699" end_char="2704">little</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2706" end_char="2707">or</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2709" end_char="2715">nothing</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="2717" end_char="2722">allows</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="2724" end_char="2725">us</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="2727" end_char="2728">to</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="2730" end_char="2738">establish</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="2740" end_char="2740">a</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="2742" end_char="2753">relationship</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="2755" end_char="2758">with</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="2760" end_char="2762">the</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="2764" end_char="2770">alleged</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="2772" end_char="2780">unbridled</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="2782" end_char="2789">activity</TOKEN>
<TOKEN id="token-23-15" pos="word" morph="none" start_char="2791" end_char="2792">at</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="2794" end_char="2796">the</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="2798" end_char="2803">city's</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="2805" end_char="2814">crematoria</TOKEN>
<TOKEN id="token-23-19" pos="punct" morph="none" start_char="2815" end_char="2815">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2818" end_char="2866">
<ORIGINAL_TEXT>Sulfur dioxide is naturally emitted by volcanoes.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="2818" end_char="2823">Sulfur</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="2825" end_char="2831">dioxide</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="2833" end_char="2834">is</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="2836" end_char="2844">naturally</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="2846" end_char="2852">emitted</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="2854" end_char="2855">by</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="2857" end_char="2865">volcanoes</TOKEN>
<TOKEN id="token-24-7" pos="punct" morph="none" start_char="2866" end_char="2866">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2868" end_char="3117">
<ORIGINAL_TEXT>According to the WHO, the main human source of SO2 emissions is the combustion of sulphur-containing fossils used for domestic heating, electricity generation and motor vehicles as well as the burning of waste and the decomposition of organic matter.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="2868" end_char="2876">According</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="2878" end_char="2879">to</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="2881" end_char="2883">the</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="2885" end_char="2887">WHO</TOKEN>
<TOKEN id="token-25-4" pos="punct" morph="none" start_char="2888" end_char="2888">,</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="2890" end_char="2892">the</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="2894" end_char="2897">main</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="2899" end_char="2903">human</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="2905" end_char="2910">source</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="2912" end_char="2913">of</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="2915" end_char="2917">SO2</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="2919" end_char="2927">emissions</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="2929" end_char="2930">is</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="2932" end_char="2934">the</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="2936" end_char="2945">combustion</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="2947" end_char="2948">of</TOKEN>
<TOKEN id="token-25-16" pos="unknown" morph="none" start_char="2950" end_char="2967">sulphur-containing</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="2969" end_char="2975">fossils</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="2977" end_char="2980">used</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="2982" end_char="2984">for</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="2986" end_char="2993">domestic</TOKEN>
<TOKEN id="token-25-21" pos="word" morph="none" start_char="2995" end_char="3001">heating</TOKEN>
<TOKEN id="token-25-22" pos="punct" morph="none" start_char="3002" end_char="3002">,</TOKEN>
<TOKEN id="token-25-23" pos="word" morph="none" start_char="3004" end_char="3014">electricity</TOKEN>
<TOKEN id="token-25-24" pos="word" morph="none" start_char="3016" end_char="3025">generation</TOKEN>
<TOKEN id="token-25-25" pos="word" morph="none" start_char="3027" end_char="3029">and</TOKEN>
<TOKEN id="token-25-26" pos="word" morph="none" start_char="3031" end_char="3035">motor</TOKEN>
<TOKEN id="token-25-27" pos="word" morph="none" start_char="3037" end_char="3044">vehicles</TOKEN>
<TOKEN id="token-25-28" pos="word" morph="none" start_char="3046" end_char="3047">as</TOKEN>
<TOKEN id="token-25-29" pos="word" morph="none" start_char="3049" end_char="3052">well</TOKEN>
<TOKEN id="token-25-30" pos="word" morph="none" start_char="3054" end_char="3055">as</TOKEN>
<TOKEN id="token-25-31" pos="word" morph="none" start_char="3057" end_char="3059">the</TOKEN>
<TOKEN id="token-25-32" pos="word" morph="none" start_char="3061" end_char="3067">burning</TOKEN>
<TOKEN id="token-25-33" pos="word" morph="none" start_char="3069" end_char="3070">of</TOKEN>
<TOKEN id="token-25-34" pos="word" morph="none" start_char="3072" end_char="3076">waste</TOKEN>
<TOKEN id="token-25-35" pos="word" morph="none" start_char="3078" end_char="3080">and</TOKEN>
<TOKEN id="token-25-36" pos="word" morph="none" start_char="3082" end_char="3084">the</TOKEN>
<TOKEN id="token-25-37" pos="word" morph="none" start_char="3086" end_char="3098">decomposition</TOKEN>
<TOKEN id="token-25-38" pos="word" morph="none" start_char="3100" end_char="3101">of</TOKEN>
<TOKEN id="token-25-39" pos="word" morph="none" start_char="3103" end_char="3109">organic</TOKEN>
<TOKEN id="token-25-40" pos="word" morph="none" start_char="3111" end_char="3116">matter</TOKEN>
<TOKEN id="token-25-41" pos="punct" morph="none" start_char="3117" end_char="3117">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="3120" end_char="3173">
<ORIGINAL_TEXT>Models used for forecasts are not "satellite measures"</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="3120" end_char="3125">Models</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="3127" end_char="3130">used</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="3132" end_char="3134">for</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="3136" end_char="3144">forecasts</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="3146" end_char="3148">are</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="3150" end_char="3152">not</TOKEN>
<TOKEN id="token-26-6" pos="punct" morph="none" start_char="3154" end_char="3154">"</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="3155" end_char="3163">satellite</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="3165" end_char="3172">measures</TOKEN>
<TOKEN id="token-26-9" pos="punct" morph="none" start_char="3173" end_char="3173">"</TOKEN>
</SEG>
<SEG id="segment-27" start_char="3177" end_char="3288">
<ORIGINAL_TEXT>The data on windy.com is not based on satellite images, as claimed by the Sun tabloid newspaper in its headline.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="3177" end_char="3179">The</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="3181" end_char="3184">data</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="3186" end_char="3187">on</TOKEN>
<TOKEN id="token-27-3" pos="unknown" morph="none" start_char="3189" end_char="3197">windy.com</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="3199" end_char="3200">is</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="3202" end_char="3204">not</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="3206" end_char="3210">based</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="3212" end_char="3213">on</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="3215" end_char="3223">satellite</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="3225" end_char="3230">images</TOKEN>
<TOKEN id="token-27-10" pos="punct" morph="none" start_char="3231" end_char="3231">,</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="3233" end_char="3234">as</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="3236" end_char="3242">claimed</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="3244" end_char="3245">by</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="3247" end_char="3249">the</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="3251" end_char="3253">Sun</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="3255" end_char="3261">tabloid</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="3263" end_char="3271">newspaper</TOKEN>
<TOKEN id="token-27-18" pos="word" morph="none" start_char="3273" end_char="3274">in</TOKEN>
<TOKEN id="token-27-19" pos="word" morph="none" start_char="3276" end_char="3278">its</TOKEN>
<TOKEN id="token-27-20" pos="word" morph="none" start_char="3280" end_char="3287">headline</TOKEN>
<TOKEN id="token-27-21" pos="punct" morph="none" start_char="3288" end_char="3288">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3291" end_char="3459">
<ORIGINAL_TEXT>Instead, they are based upon forecasts based on NASA's GEOS-5 model, which, according to the US agency itself, often give significantly higher results than observations.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="3291" end_char="3297">Instead</TOKEN>
<TOKEN id="token-28-1" pos="punct" morph="none" start_char="3298" end_char="3298">,</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="3300" end_char="3303">they</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="3305" end_char="3307">are</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="3309" end_char="3313">based</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="3315" end_char="3318">upon</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="3320" end_char="3328">forecasts</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="3330" end_char="3334">based</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="3336" end_char="3337">on</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="3339" end_char="3344">NASA's</TOKEN>
<TOKEN id="token-28-10" pos="unknown" morph="none" start_char="3346" end_char="3351">GEOS-5</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="3353" end_char="3357">model</TOKEN>
<TOKEN id="token-28-12" pos="punct" morph="none" start_char="3358" end_char="3358">,</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="3360" end_char="3364">which</TOKEN>
<TOKEN id="token-28-14" pos="punct" morph="none" start_char="3365" end_char="3365">,</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="3367" end_char="3375">according</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="3377" end_char="3378">to</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="3380" end_char="3382">the</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="3384" end_char="3385">US</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="3387" end_char="3392">agency</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="3394" end_char="3399">itself</TOKEN>
<TOKEN id="token-28-21" pos="punct" morph="none" start_char="3400" end_char="3400">,</TOKEN>
<TOKEN id="token-28-22" pos="word" morph="none" start_char="3402" end_char="3406">often</TOKEN>
<TOKEN id="token-28-23" pos="word" morph="none" start_char="3408" end_char="3411">give</TOKEN>
<TOKEN id="token-28-24" pos="word" morph="none" start_char="3413" end_char="3425">significantly</TOKEN>
<TOKEN id="token-28-25" pos="word" morph="none" start_char="3427" end_char="3432">higher</TOKEN>
<TOKEN id="token-28-26" pos="word" morph="none" start_char="3434" end_char="3440">results</TOKEN>
<TOKEN id="token-28-27" pos="word" morph="none" start_char="3442" end_char="3445">than</TOKEN>
<TOKEN id="token-28-28" pos="word" morph="none" start_char="3447" end_char="3458">observations</TOKEN>
<TOKEN id="token-28-29" pos="punct" morph="none" start_char="3459" end_char="3459">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3462" end_char="3539">
<ORIGINAL_TEXT>The models are not updated to take into account episodes like the coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="3462" end_char="3464">The</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="3466" end_char="3471">models</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="3473" end_char="3475">are</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="3477" end_char="3479">not</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="3481" end_char="3487">updated</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="3489" end_char="3490">to</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="3492" end_char="3495">take</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="3497" end_char="3500">into</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="3502" end_char="3508">account</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="3510" end_char="3517">episodes</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="3519" end_char="3522">like</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="3524" end_char="3526">the</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="3528" end_char="3538">coronavirus</TOKEN>
<TOKEN id="token-29-13" pos="punct" morph="none" start_char="3539" end_char="3539">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3541" end_char="3667">
<ORIGINAL_TEXT>They're based on "emissions inventories", for example, the probability of pollution levels based on known sources of emissions.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="3541" end_char="3547">They're</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="3549" end_char="3553">based</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="3555" end_char="3556">on</TOKEN>
<TOKEN id="token-30-3" pos="punct" morph="none" start_char="3558" end_char="3558">"</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="3559" end_char="3567">emissions</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="3569" end_char="3579">inventories</TOKEN>
<TOKEN id="token-30-6" pos="punct" morph="none" start_char="3580" end_char="3581">",</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="3583" end_char="3585">for</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="3587" end_char="3593">example</TOKEN>
<TOKEN id="token-30-9" pos="punct" morph="none" start_char="3594" end_char="3594">,</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="3596" end_char="3598">the</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="3600" end_char="3610">probability</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="3612" end_char="3613">of</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="3615" end_char="3623">pollution</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="3625" end_char="3630">levels</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="3632" end_char="3636">based</TOKEN>
<TOKEN id="token-30-16" pos="word" morph="none" start_char="3638" end_char="3639">on</TOKEN>
<TOKEN id="token-30-17" pos="word" morph="none" start_char="3641" end_char="3645">known</TOKEN>
<TOKEN id="token-30-18" pos="word" morph="none" start_char="3647" end_char="3653">sources</TOKEN>
<TOKEN id="token-30-19" pos="word" morph="none" start_char="3655" end_char="3656">of</TOKEN>
<TOKEN id="token-30-20" pos="word" morph="none" start_char="3658" end_char="3666">emissions</TOKEN>
<TOKEN id="token-30-21" pos="punct" morph="none" start_char="3667" end_char="3667">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="3670" end_char="3828">
<ORIGINAL_TEXT>They take into account the usual sources of emissions of an area: factories, power and heating plants, and cross-references them with meteorological variables.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="3670" end_char="3673">They</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="3675" end_char="3678">take</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="3680" end_char="3683">into</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="3685" end_char="3691">account</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="3693" end_char="3695">the</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="3697" end_char="3701">usual</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="3703" end_char="3709">sources</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="3711" end_char="3712">of</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="3714" end_char="3722">emissions</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="3724" end_char="3725">of</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="3727" end_char="3728">an</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="3730" end_char="3733">area</TOKEN>
<TOKEN id="token-31-12" pos="punct" morph="none" start_char="3734" end_char="3734">:</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="3736" end_char="3744">factories</TOKEN>
<TOKEN id="token-31-14" pos="punct" morph="none" start_char="3745" end_char="3745">,</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="3747" end_char="3751">power</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="3753" end_char="3755">and</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="3757" end_char="3763">heating</TOKEN>
<TOKEN id="token-31-18" pos="word" morph="none" start_char="3765" end_char="3770">plants</TOKEN>
<TOKEN id="token-31-19" pos="punct" morph="none" start_char="3771" end_char="3771">,</TOKEN>
<TOKEN id="token-31-20" pos="word" morph="none" start_char="3773" end_char="3775">and</TOKEN>
<TOKEN id="token-31-21" pos="unknown" morph="none" start_char="3777" end_char="3792">cross-references</TOKEN>
<TOKEN id="token-31-22" pos="word" morph="none" start_char="3794" end_char="3797">them</TOKEN>
<TOKEN id="token-31-23" pos="word" morph="none" start_char="3799" end_char="3802">with</TOKEN>
<TOKEN id="token-31-24" pos="word" morph="none" start_char="3804" end_char="3817">meteorological</TOKEN>
<TOKEN id="token-31-25" pos="word" morph="none" start_char="3819" end_char="3827">variables</TOKEN>
<TOKEN id="token-31-26" pos="punct" morph="none" start_char="3828" end_char="3828">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="3830" end_char="3927">
<ORIGINAL_TEXT>In other words, NASA would have had to introduce a "burning human bodies in crematoria" parameter.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="3830" end_char="3831">In</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="3833" end_char="3837">other</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="3839" end_char="3843">words</TOKEN>
<TOKEN id="token-32-3" pos="punct" morph="none" start_char="3844" end_char="3844">,</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="3846" end_char="3849">NASA</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="3851" end_char="3855">would</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="3857" end_char="3860">have</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="3862" end_char="3864">had</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="3866" end_char="3867">to</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="3869" end_char="3877">introduce</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="3879" end_char="3879">a</TOKEN>
<TOKEN id="token-32-11" pos="punct" morph="none" start_char="3881" end_char="3881">"</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="3882" end_char="3888">burning</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="3890" end_char="3894">human</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="3896" end_char="3901">bodies</TOKEN>
<TOKEN id="token-32-15" pos="word" morph="none" start_char="3903" end_char="3904">in</TOKEN>
<TOKEN id="token-32-16" pos="word" morph="none" start_char="3906" end_char="3915">crematoria</TOKEN>
<TOKEN id="token-32-17" pos="punct" morph="none" start_char="3916" end_char="3916">"</TOKEN>
<TOKEN id="token-32-18" pos="word" morph="none" start_char="3918" end_char="3926">parameter</TOKEN>
<TOKEN id="token-32-19" pos="punct" morph="none" start_char="3927" end_char="3927">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="3929" end_char="3950">
<ORIGINAL_TEXT>This is very unlikely.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="3929" end_char="3932">This</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="3934" end_char="3935">is</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="3937" end_char="3940">very</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="3942" end_char="3949">unlikely</TOKEN>
<TOKEN id="token-33-4" pos="punct" morph="none" start_char="3950" end_char="3950">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="3953" end_char="4017">
<ORIGINAL_TEXT>NASA has not responded to Euronews' requests for comment on this.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="3953" end_char="3956">NASA</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="3958" end_char="3960">has</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="3962" end_char="3964">not</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="3966" end_char="3974">responded</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="3976" end_char="3977">to</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="3979" end_char="3986">Euronews</TOKEN>
<TOKEN id="token-34-6" pos="punct" morph="none" start_char="3987" end_char="3987">'</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="3989" end_char="3996">requests</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="3998" end_char="4000">for</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="4002" end_char="4008">comment</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="4010" end_char="4011">on</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="4013" end_char="4016">this</TOKEN>
<TOKEN id="token-34-12" pos="punct" morph="none" start_char="4017" end_char="4017">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="4020" end_char="4178">
<ORIGINAL_TEXT>This type of forecast uses satellite data, but, in general, satellites are not able to detect small sources of sulphur dioxide such as factories or crematoria.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="4020" end_char="4023">This</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="4025" end_char="4028">type</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="4030" end_char="4031">of</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="4033" end_char="4040">forecast</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="4042" end_char="4045">uses</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="4047" end_char="4055">satellite</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="4057" end_char="4060">data</TOKEN>
<TOKEN id="token-35-7" pos="punct" morph="none" start_char="4061" end_char="4061">,</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="4063" end_char="4065">but</TOKEN>
<TOKEN id="token-35-9" pos="punct" morph="none" start_char="4066" end_char="4066">,</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="4068" end_char="4069">in</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="4071" end_char="4077">general</TOKEN>
<TOKEN id="token-35-12" pos="punct" morph="none" start_char="4078" end_char="4078">,</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="4080" end_char="4089">satellites</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="4091" end_char="4093">are</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="4095" end_char="4097">not</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="4099" end_char="4102">able</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="4104" end_char="4105">to</TOKEN>
<TOKEN id="token-35-18" pos="word" morph="none" start_char="4107" end_char="4112">detect</TOKEN>
<TOKEN id="token-35-19" pos="word" morph="none" start_char="4114" end_char="4118">small</TOKEN>
<TOKEN id="token-35-20" pos="word" morph="none" start_char="4120" end_char="4126">sources</TOKEN>
<TOKEN id="token-35-21" pos="word" morph="none" start_char="4128" end_char="4129">of</TOKEN>
<TOKEN id="token-35-22" pos="word" morph="none" start_char="4131" end_char="4137">sulphur</TOKEN>
<TOKEN id="token-35-23" pos="word" morph="none" start_char="4139" end_char="4145">dioxide</TOKEN>
<TOKEN id="token-35-24" pos="word" morph="none" start_char="4147" end_char="4150">such</TOKEN>
<TOKEN id="token-35-25" pos="word" morph="none" start_char="4152" end_char="4153">as</TOKEN>
<TOKEN id="token-35-26" pos="word" morph="none" start_char="4155" end_char="4163">factories</TOKEN>
<TOKEN id="token-35-27" pos="word" morph="none" start_char="4165" end_char="4166">or</TOKEN>
<TOKEN id="token-35-28" pos="word" morph="none" start_char="4168" end_char="4177">crematoria</TOKEN>
<TOKEN id="token-35-29" pos="punct" morph="none" start_char="4178" end_char="4178">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="4180" end_char="4256">
<ORIGINAL_TEXT>They do accurately measure more intense phenomena such as volcanic eruptions.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="4180" end_char="4183">They</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="4185" end_char="4186">do</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="4188" end_char="4197">accurately</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="4199" end_char="4205">measure</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="4207" end_char="4210">more</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="4212" end_char="4218">intense</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="4220" end_char="4228">phenomena</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="4230" end_char="4233">such</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="4235" end_char="4236">as</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="4238" end_char="4245">volcanic</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="4247" end_char="4255">eruptions</TOKEN>
<TOKEN id="token-36-11" pos="punct" morph="none" start_char="4256" end_char="4256">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="4259" end_char="4371">
<ORIGINAL_TEXT>So, if there were an intense, unusual emissions activity due to crematoria, it wouldn't be shown on these models.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="4259" end_char="4260">So</TOKEN>
<TOKEN id="token-37-1" pos="punct" morph="none" start_char="4261" end_char="4261">,</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="4263" end_char="4264">if</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="4266" end_char="4270">there</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="4272" end_char="4275">were</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="4277" end_char="4278">an</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="4280" end_char="4286">intense</TOKEN>
<TOKEN id="token-37-7" pos="punct" morph="none" start_char="4287" end_char="4287">,</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="4289" end_char="4295">unusual</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="4297" end_char="4305">emissions</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="4307" end_char="4314">activity</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="4316" end_char="4318">due</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="4320" end_char="4321">to</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="4323" end_char="4332">crematoria</TOKEN>
<TOKEN id="token-37-14" pos="punct" morph="none" start_char="4333" end_char="4333">,</TOKEN>
<TOKEN id="token-37-15" pos="word" morph="none" start_char="4335" end_char="4336">it</TOKEN>
<TOKEN id="token-37-16" pos="word" morph="none" start_char="4338" end_char="4345">wouldn't</TOKEN>
<TOKEN id="token-37-17" pos="word" morph="none" start_char="4347" end_char="4348">be</TOKEN>
<TOKEN id="token-37-18" pos="word" morph="none" start_char="4350" end_char="4354">shown</TOKEN>
<TOKEN id="token-37-19" pos="word" morph="none" start_char="4356" end_char="4357">on</TOKEN>
<TOKEN id="token-37-20" pos="word" morph="none" start_char="4359" end_char="4363">these</TOKEN>
<TOKEN id="token-37-21" pos="word" morph="none" start_char="4365" end_char="4370">models</TOKEN>
<TOKEN id="token-37-22" pos="punct" morph="none" start_char="4371" end_char="4371">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="4374" end_char="4444">
<ORIGINAL_TEXT>Wuhan and Chongqing always have high levels of SO2 using the NASA model</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="4374" end_char="4378">Wuhan</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="4380" end_char="4382">and</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="4384" end_char="4392">Chongqing</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="4394" end_char="4399">always</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="4401" end_char="4404">have</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="4406" end_char="4409">high</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="4411" end_char="4416">levels</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="4418" end_char="4419">of</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="4421" end_char="4423">SO2</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="4425" end_char="4429">using</TOKEN>
<TOKEN id="token-38-10" pos="word" morph="none" start_char="4431" end_char="4433">the</TOKEN>
<TOKEN id="token-38-11" pos="word" morph="none" start_char="4435" end_char="4438">NASA</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="4440" end_char="4444">model</TOKEN>
</SEG>
<SEG id="segment-39" start_char="4448" end_char="4512">
<ORIGINAL_TEXT>The earth.nullschool application uses the same GEOS-5 NASA model.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="4448" end_char="4450">The</TOKEN>
<TOKEN id="token-39-1" pos="unknown" morph="none" start_char="4452" end_char="4467">earth.nullschool</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="4469" end_char="4479">application</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="4481" end_char="4484">uses</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="4486" end_char="4488">the</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="4490" end_char="4493">same</TOKEN>
<TOKEN id="token-39-6" pos="unknown" morph="none" start_char="4495" end_char="4500">GEOS-5</TOKEN>
<TOKEN id="token-39-7" pos="word" morph="none" start_char="4502" end_char="4505">NASA</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="4507" end_char="4511">model</TOKEN>
<TOKEN id="token-39-9" pos="punct" morph="none" start_char="4512" end_char="4512">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="4514" end_char="4552">
<ORIGINAL_TEXT>But it also has an archive of measures.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="4514" end_char="4516">But</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="4518" end_char="4519">it</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="4521" end_char="4524">also</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="4526" end_char="4528">has</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="4530" end_char="4531">an</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="4533" end_char="4539">archive</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="4541" end_char="4542">of</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="4544" end_char="4551">measures</TOKEN>
<TOKEN id="token-40-8" pos="punct" morph="none" start_char="4552" end_char="4552">.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="4554" end_char="4729">
<ORIGINAL_TEXT>At random, we went to February 14, 2019 - long before the world knew about the existence of a new type of coronavirus - and obtained even more impressive values of 1,583 µg/m3.</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="4554" end_char="4555">At</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="4557" end_char="4562">random</TOKEN>
<TOKEN id="token-41-2" pos="punct" morph="none" start_char="4563" end_char="4563">,</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="4565" end_char="4566">we</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="4568" end_char="4571">went</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="4573" end_char="4574">to</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="4576" end_char="4583">February</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="4585" end_char="4586">14</TOKEN>
<TOKEN id="token-41-8" pos="punct" morph="none" start_char="4587" end_char="4587">,</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="4589" end_char="4592">2019</TOKEN>
<TOKEN id="token-41-10" pos="punct" morph="none" start_char="4594" end_char="4594">-</TOKEN>
<TOKEN id="token-41-11" pos="word" morph="none" start_char="4596" end_char="4599">long</TOKEN>
<TOKEN id="token-41-12" pos="word" morph="none" start_char="4601" end_char="4606">before</TOKEN>
<TOKEN id="token-41-13" pos="word" morph="none" start_char="4608" end_char="4610">the</TOKEN>
<TOKEN id="token-41-14" pos="word" morph="none" start_char="4612" end_char="4616">world</TOKEN>
<TOKEN id="token-41-15" pos="word" morph="none" start_char="4618" end_char="4621">knew</TOKEN>
<TOKEN id="token-41-16" pos="word" morph="none" start_char="4623" end_char="4627">about</TOKEN>
<TOKEN id="token-41-17" pos="word" morph="none" start_char="4629" end_char="4631">the</TOKEN>
<TOKEN id="token-41-18" pos="word" morph="none" start_char="4633" end_char="4641">existence</TOKEN>
<TOKEN id="token-41-19" pos="word" morph="none" start_char="4643" end_char="4644">of</TOKEN>
<TOKEN id="token-41-20" pos="word" morph="none" start_char="4646" end_char="4646">a</TOKEN>
<TOKEN id="token-41-21" pos="word" morph="none" start_char="4648" end_char="4650">new</TOKEN>
<TOKEN id="token-41-22" pos="word" morph="none" start_char="4652" end_char="4655">type</TOKEN>
<TOKEN id="token-41-23" pos="word" morph="none" start_char="4657" end_char="4658">of</TOKEN>
<TOKEN id="token-41-24" pos="word" morph="none" start_char="4660" end_char="4670">coronavirus</TOKEN>
<TOKEN id="token-41-25" pos="punct" morph="none" start_char="4672" end_char="4672">-</TOKEN>
<TOKEN id="token-41-26" pos="word" morph="none" start_char="4674" end_char="4676">and</TOKEN>
<TOKEN id="token-41-27" pos="word" morph="none" start_char="4678" end_char="4685">obtained</TOKEN>
<TOKEN id="token-41-28" pos="word" morph="none" start_char="4687" end_char="4690">even</TOKEN>
<TOKEN id="token-41-29" pos="word" morph="none" start_char="4692" end_char="4695">more</TOKEN>
<TOKEN id="token-41-30" pos="word" morph="none" start_char="4697" end_char="4706">impressive</TOKEN>
<TOKEN id="token-41-31" pos="word" morph="none" start_char="4708" end_char="4713">values</TOKEN>
<TOKEN id="token-41-32" pos="word" morph="none" start_char="4715" end_char="4716">of</TOKEN>
<TOKEN id="token-41-33" pos="unknown" morph="none" start_char="4718" end_char="4722">1,583</TOKEN>
<TOKEN id="token-41-34" pos="unknown" morph="none" start_char="4724" end_char="4728">µg/m3</TOKEN>
<TOKEN id="token-41-35" pos="punct" morph="none" start_char="4729" end_char="4729">.</TOKEN>
</SEG>
<SEG id="segment-42" start_char="4732" end_char="4788">
<ORIGINAL_TEXT>The values change depending on where we place the cursor.</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="4732" end_char="4734">The</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="4736" end_char="4741">values</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="4743" end_char="4748">change</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="4750" end_char="4758">depending</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="4760" end_char="4761">on</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="4763" end_char="4767">where</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="4769" end_char="4770">we</TOKEN>
<TOKEN id="token-42-7" pos="word" morph="none" start_char="4772" end_char="4776">place</TOKEN>
<TOKEN id="token-42-8" pos="word" morph="none" start_char="4778" end_char="4780">the</TOKEN>
<TOKEN id="token-42-9" pos="word" morph="none" start_char="4782" end_char="4787">cursor</TOKEN>
<TOKEN id="token-42-10" pos="punct" morph="none" start_char="4788" end_char="4788">.</TOKEN>
</SEG>
<SEG id="segment-43" start_char="4791" end_char="4877">
<ORIGINAL_TEXT>Screenshot of the SO2 levels for Wuhan for February 14 2019 with levels of 1.583 µg/m3.</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="4791" end_char="4800">Screenshot</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="4802" end_char="4803">of</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="4805" end_char="4807">the</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="4809" end_char="4811">SO2</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="4813" end_char="4818">levels</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="4820" end_char="4822">for</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="4824" end_char="4828">Wuhan</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="4830" end_char="4832">for</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="4834" end_char="4841">February</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="4843" end_char="4844">14</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="4846" end_char="4849">2019</TOKEN>
<TOKEN id="token-43-11" pos="word" morph="none" start_char="4851" end_char="4854">with</TOKEN>
<TOKEN id="token-43-12" pos="word" morph="none" start_char="4856" end_char="4861">levels</TOKEN>
<TOKEN id="token-43-13" pos="word" morph="none" start_char="4863" end_char="4864">of</TOKEN>
<TOKEN id="token-43-14" pos="word" morph="none" start_char="4866" end_char="4870">1.583</TOKEN>
<TOKEN id="token-43-15" pos="unknown" morph="none" start_char="4872" end_char="4876">µg/m3</TOKEN>
<TOKEN id="token-43-16" pos="punct" morph="none" start_char="4877" end_char="4877">.</TOKEN>
</SEG>
<SEG id="segment-44" start_char="4881" end_char="4988">
<ORIGINAL_TEXT>The same goes for Chongqing, where, at random, we get levels of over 1,000 μg/m3 last year, or even in 2018.</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="4881" end_char="4883">The</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="4885" end_char="4888">same</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="4890" end_char="4893">goes</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="4895" end_char="4897">for</TOKEN>
<TOKEN id="token-44-4" pos="word" morph="none" start_char="4899" end_char="4907">Chongqing</TOKEN>
<TOKEN id="token-44-5" pos="punct" morph="none" start_char="4908" end_char="4908">,</TOKEN>
<TOKEN id="token-44-6" pos="word" morph="none" start_char="4910" end_char="4914">where</TOKEN>
<TOKEN id="token-44-7" pos="punct" morph="none" start_char="4915" end_char="4915">,</TOKEN>
<TOKEN id="token-44-8" pos="word" morph="none" start_char="4917" end_char="4918">at</TOKEN>
<TOKEN id="token-44-9" pos="word" morph="none" start_char="4920" end_char="4925">random</TOKEN>
<TOKEN id="token-44-10" pos="punct" morph="none" start_char="4926" end_char="4926">,</TOKEN>
<TOKEN id="token-44-11" pos="word" morph="none" start_char="4928" end_char="4929">we</TOKEN>
<TOKEN id="token-44-12" pos="word" morph="none" start_char="4931" end_char="4933">get</TOKEN>
<TOKEN id="token-44-13" pos="word" morph="none" start_char="4935" end_char="4940">levels</TOKEN>
<TOKEN id="token-44-14" pos="word" morph="none" start_char="4942" end_char="4943">of</TOKEN>
<TOKEN id="token-44-15" pos="word" morph="none" start_char="4945" end_char="4948">over</TOKEN>
<TOKEN id="token-44-16" pos="unknown" morph="none" start_char="4950" end_char="4954">1,000</TOKEN>
<TOKEN id="token-44-17" pos="unknown" morph="none" start_char="4956" end_char="4960">μg/m3</TOKEN>
<TOKEN id="token-44-18" pos="word" morph="none" start_char="4962" end_char="4965">last</TOKEN>
<TOKEN id="token-44-19" pos="word" morph="none" start_char="4967" end_char="4970">year</TOKEN>
<TOKEN id="token-44-20" pos="punct" morph="none" start_char="4971" end_char="4971">,</TOKEN>
<TOKEN id="token-44-21" pos="word" morph="none" start_char="4973" end_char="4974">or</TOKEN>
<TOKEN id="token-44-22" pos="word" morph="none" start_char="4976" end_char="4979">even</TOKEN>
<TOKEN id="token-44-23" pos="word" morph="none" start_char="4981" end_char="4982">in</TOKEN>
<TOKEN id="token-44-24" pos="word" morph="none" start_char="4984" end_char="4987">2018</TOKEN>
<TOKEN id="token-44-25" pos="punct" morph="none" start_char="4988" end_char="4988">.</TOKEN>
</SEG>
<SEG id="segment-45" start_char="4991" end_char="5238">
<ORIGINAL_TEXT>This means the "forecasts" of these platforms are an interesting and useful indicator, and, certainly, Chongqing and Wuhan suffer from poor air quality, but this is approximative data to be taken into perspective, not a scientific measure or proof.</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="4991" end_char="4994">This</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="4996" end_char="5000">means</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="5002" end_char="5004">the</TOKEN>
<TOKEN id="token-45-3" pos="punct" morph="none" start_char="5006" end_char="5006">"</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="5007" end_char="5015">forecasts</TOKEN>
<TOKEN id="token-45-5" pos="punct" morph="none" start_char="5016" end_char="5016">"</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="5018" end_char="5019">of</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="5021" end_char="5025">these</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="5027" end_char="5035">platforms</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="5037" end_char="5039">are</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="5041" end_char="5042">an</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="5044" end_char="5054">interesting</TOKEN>
<TOKEN id="token-45-12" pos="word" morph="none" start_char="5056" end_char="5058">and</TOKEN>
<TOKEN id="token-45-13" pos="word" morph="none" start_char="5060" end_char="5065">useful</TOKEN>
<TOKEN id="token-45-14" pos="word" morph="none" start_char="5067" end_char="5075">indicator</TOKEN>
<TOKEN id="token-45-15" pos="punct" morph="none" start_char="5076" end_char="5076">,</TOKEN>
<TOKEN id="token-45-16" pos="word" morph="none" start_char="5078" end_char="5080">and</TOKEN>
<TOKEN id="token-45-17" pos="punct" morph="none" start_char="5081" end_char="5081">,</TOKEN>
<TOKEN id="token-45-18" pos="word" morph="none" start_char="5083" end_char="5091">certainly</TOKEN>
<TOKEN id="token-45-19" pos="punct" morph="none" start_char="5092" end_char="5092">,</TOKEN>
<TOKEN id="token-45-20" pos="word" morph="none" start_char="5094" end_char="5102">Chongqing</TOKEN>
<TOKEN id="token-45-21" pos="word" morph="none" start_char="5104" end_char="5106">and</TOKEN>
<TOKEN id="token-45-22" pos="word" morph="none" start_char="5108" end_char="5112">Wuhan</TOKEN>
<TOKEN id="token-45-23" pos="word" morph="none" start_char="5114" end_char="5119">suffer</TOKEN>
<TOKEN id="token-45-24" pos="word" morph="none" start_char="5121" end_char="5124">from</TOKEN>
<TOKEN id="token-45-25" pos="word" morph="none" start_char="5126" end_char="5129">poor</TOKEN>
<TOKEN id="token-45-26" pos="word" morph="none" start_char="5131" end_char="5133">air</TOKEN>
<TOKEN id="token-45-27" pos="word" morph="none" start_char="5135" end_char="5141">quality</TOKEN>
<TOKEN id="token-45-28" pos="punct" morph="none" start_char="5142" end_char="5142">,</TOKEN>
<TOKEN id="token-45-29" pos="word" morph="none" start_char="5144" end_char="5146">but</TOKEN>
<TOKEN id="token-45-30" pos="word" morph="none" start_char="5148" end_char="5151">this</TOKEN>
<TOKEN id="token-45-31" pos="word" morph="none" start_char="5153" end_char="5154">is</TOKEN>
<TOKEN id="token-45-32" pos="word" morph="none" start_char="5156" end_char="5168">approximative</TOKEN>
<TOKEN id="token-45-33" pos="word" morph="none" start_char="5170" end_char="5173">data</TOKEN>
<TOKEN id="token-45-34" pos="word" morph="none" start_char="5175" end_char="5176">to</TOKEN>
<TOKEN id="token-45-35" pos="word" morph="none" start_char="5178" end_char="5179">be</TOKEN>
<TOKEN id="token-45-36" pos="word" morph="none" start_char="5181" end_char="5185">taken</TOKEN>
<TOKEN id="token-45-37" pos="word" morph="none" start_char="5187" end_char="5190">into</TOKEN>
<TOKEN id="token-45-38" pos="word" morph="none" start_char="5192" end_char="5202">perspective</TOKEN>
<TOKEN id="token-45-39" pos="punct" morph="none" start_char="5203" end_char="5203">,</TOKEN>
<TOKEN id="token-45-40" pos="word" morph="none" start_char="5205" end_char="5207">not</TOKEN>
<TOKEN id="token-45-41" pos="word" morph="none" start_char="5209" end_char="5209">a</TOKEN>
<TOKEN id="token-45-42" pos="word" morph="none" start_char="5211" end_char="5220">scientific</TOKEN>
<TOKEN id="token-45-43" pos="word" morph="none" start_char="5222" end_char="5228">measure</TOKEN>
<TOKEN id="token-45-44" pos="word" morph="none" start_char="5230" end_char="5231">or</TOKEN>
<TOKEN id="token-45-45" pos="word" morph="none" start_char="5233" end_char="5237">proof</TOKEN>
<TOKEN id="token-45-46" pos="punct" morph="none" start_char="5238" end_char="5238">.</TOKEN>
</SEG>
<SEG id="segment-46" start_char="5241" end_char="5430">
<ORIGINAL_TEXT>An Italian chemistry professor has made a rough calculation for the website open.online, and he estimates that to get to those levels of SO2 Wuhan would have to burn about 30 million bodies.</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="5241" end_char="5242">An</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="5244" end_char="5250">Italian</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="5252" end_char="5260">chemistry</TOKEN>
<TOKEN id="token-46-3" pos="word" morph="none" start_char="5262" end_char="5270">professor</TOKEN>
<TOKEN id="token-46-4" pos="word" morph="none" start_char="5272" end_char="5274">has</TOKEN>
<TOKEN id="token-46-5" pos="word" morph="none" start_char="5276" end_char="5279">made</TOKEN>
<TOKEN id="token-46-6" pos="word" morph="none" start_char="5281" end_char="5281">a</TOKEN>
<TOKEN id="token-46-7" pos="word" morph="none" start_char="5283" end_char="5287">rough</TOKEN>
<TOKEN id="token-46-8" pos="word" morph="none" start_char="5289" end_char="5299">calculation</TOKEN>
<TOKEN id="token-46-9" pos="word" morph="none" start_char="5301" end_char="5303">for</TOKEN>
<TOKEN id="token-46-10" pos="word" morph="none" start_char="5305" end_char="5307">the</TOKEN>
<TOKEN id="token-46-11" pos="word" morph="none" start_char="5309" end_char="5315">website</TOKEN>
<TOKEN id="token-46-12" pos="unknown" morph="none" start_char="5317" end_char="5327">open.online</TOKEN>
<TOKEN id="token-46-13" pos="punct" morph="none" start_char="5328" end_char="5328">,</TOKEN>
<TOKEN id="token-46-14" pos="word" morph="none" start_char="5330" end_char="5332">and</TOKEN>
<TOKEN id="token-46-15" pos="word" morph="none" start_char="5334" end_char="5335">he</TOKEN>
<TOKEN id="token-46-16" pos="word" morph="none" start_char="5337" end_char="5345">estimates</TOKEN>
<TOKEN id="token-46-17" pos="word" morph="none" start_char="5347" end_char="5350">that</TOKEN>
<TOKEN id="token-46-18" pos="word" morph="none" start_char="5352" end_char="5353">to</TOKEN>
<TOKEN id="token-46-19" pos="word" morph="none" start_char="5355" end_char="5357">get</TOKEN>
<TOKEN id="token-46-20" pos="word" morph="none" start_char="5359" end_char="5360">to</TOKEN>
<TOKEN id="token-46-21" pos="word" morph="none" start_char="5362" end_char="5366">those</TOKEN>
<TOKEN id="token-46-22" pos="word" morph="none" start_char="5368" end_char="5373">levels</TOKEN>
<TOKEN id="token-46-23" pos="word" morph="none" start_char="5375" end_char="5376">of</TOKEN>
<TOKEN id="token-46-24" pos="word" morph="none" start_char="5378" end_char="5380">SO2</TOKEN>
<TOKEN id="token-46-25" pos="word" morph="none" start_char="5382" end_char="5386">Wuhan</TOKEN>
<TOKEN id="token-46-26" pos="word" morph="none" start_char="5388" end_char="5392">would</TOKEN>
<TOKEN id="token-46-27" pos="word" morph="none" start_char="5394" end_char="5397">have</TOKEN>
<TOKEN id="token-46-28" pos="word" morph="none" start_char="5399" end_char="5400">to</TOKEN>
<TOKEN id="token-46-29" pos="word" morph="none" start_char="5402" end_char="5405">burn</TOKEN>
<TOKEN id="token-46-30" pos="word" morph="none" start_char="5407" end_char="5411">about</TOKEN>
<TOKEN id="token-46-31" pos="word" morph="none" start_char="5413" end_char="5414">30</TOKEN>
<TOKEN id="token-46-32" pos="word" morph="none" start_char="5416" end_char="5422">million</TOKEN>
<TOKEN id="token-46-33" pos="word" morph="none" start_char="5424" end_char="5429">bodies</TOKEN>
<TOKEN id="token-46-34" pos="punct" morph="none" start_char="5430" end_char="5430">.</TOKEN>
</SEG>
<SEG id="segment-47" start_char="5432" end_char="5465">
<ORIGINAL_TEXT>That's unlikely, to say the least.</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="5432" end_char="5437">That's</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="5439" end_char="5446">unlikely</TOKEN>
<TOKEN id="token-47-2" pos="punct" morph="none" start_char="5447" end_char="5447">,</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="5449" end_char="5450">to</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="5452" end_char="5454">say</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="5456" end_char="5458">the</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="5460" end_char="5464">least</TOKEN>
<TOKEN id="token-47-7" pos="punct" morph="none" start_char="5465" end_char="5465">.</TOKEN>
</SEG>
<SEG id="segment-48" start_char="5468" end_char="5503">
<ORIGINAL_TEXT>Factories and atmospheric conditions</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="5468" end_char="5476">Factories</TOKEN>
<TOKEN id="token-48-1" pos="word" morph="none" start_char="5478" end_char="5480">and</TOKEN>
<TOKEN id="token-48-2" pos="word" morph="none" start_char="5482" end_char="5492">atmospheric</TOKEN>
<TOKEN id="token-48-3" pos="word" morph="none" start_char="5494" end_char="5503">conditions</TOKEN>
</SEG>
<SEG id="segment-49" start_char="5507" end_char="5643">
<ORIGINAL_TEXT>Experts consulted by Euronews believe that the levels observed are not particularly alarming in one of the world's most polluted country.</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="5507" end_char="5513">Experts</TOKEN>
<TOKEN id="token-49-1" pos="word" morph="none" start_char="5515" end_char="5523">consulted</TOKEN>
<TOKEN id="token-49-2" pos="word" morph="none" start_char="5525" end_char="5526">by</TOKEN>
<TOKEN id="token-49-3" pos="word" morph="none" start_char="5528" end_char="5535">Euronews</TOKEN>
<TOKEN id="token-49-4" pos="word" morph="none" start_char="5537" end_char="5543">believe</TOKEN>
<TOKEN id="token-49-5" pos="word" morph="none" start_char="5545" end_char="5548">that</TOKEN>
<TOKEN id="token-49-6" pos="word" morph="none" start_char="5550" end_char="5552">the</TOKEN>
<TOKEN id="token-49-7" pos="word" morph="none" start_char="5554" end_char="5559">levels</TOKEN>
<TOKEN id="token-49-8" pos="word" morph="none" start_char="5561" end_char="5568">observed</TOKEN>
<TOKEN id="token-49-9" pos="word" morph="none" start_char="5570" end_char="5572">are</TOKEN>
<TOKEN id="token-49-10" pos="word" morph="none" start_char="5574" end_char="5576">not</TOKEN>
<TOKEN id="token-49-11" pos="word" morph="none" start_char="5578" end_char="5589">particularly</TOKEN>
<TOKEN id="token-49-12" pos="word" morph="none" start_char="5591" end_char="5598">alarming</TOKEN>
<TOKEN id="token-49-13" pos="word" morph="none" start_char="5600" end_char="5601">in</TOKEN>
<TOKEN id="token-49-14" pos="word" morph="none" start_char="5603" end_char="5605">one</TOKEN>
<TOKEN id="token-49-15" pos="word" morph="none" start_char="5607" end_char="5608">of</TOKEN>
<TOKEN id="token-49-16" pos="word" morph="none" start_char="5610" end_char="5612">the</TOKEN>
<TOKEN id="token-49-17" pos="word" morph="none" start_char="5614" end_char="5620">world's</TOKEN>
<TOKEN id="token-49-18" pos="word" morph="none" start_char="5622" end_char="5625">most</TOKEN>
<TOKEN id="token-49-19" pos="word" morph="none" start_char="5627" end_char="5634">polluted</TOKEN>
<TOKEN id="token-49-20" pos="word" morph="none" start_char="5636" end_char="5642">country</TOKEN>
<TOKEN id="token-49-21" pos="punct" morph="none" start_char="5643" end_char="5643">.</TOKEN>
</SEG>
<SEG id="segment-50" start_char="5646" end_char="5742">
<ORIGINAL_TEXT>They say that high concentrations in a particular place may be related to atmospheric conditions.</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="5646" end_char="5649">They</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="5651" end_char="5653">say</TOKEN>
<TOKEN id="token-50-2" pos="word" morph="none" start_char="5655" end_char="5658">that</TOKEN>
<TOKEN id="token-50-3" pos="word" morph="none" start_char="5660" end_char="5663">high</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="5665" end_char="5678">concentrations</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="5680" end_char="5681">in</TOKEN>
<TOKEN id="token-50-6" pos="word" morph="none" start_char="5683" end_char="5683">a</TOKEN>
<TOKEN id="token-50-7" pos="word" morph="none" start_char="5685" end_char="5694">particular</TOKEN>
<TOKEN id="token-50-8" pos="word" morph="none" start_char="5696" end_char="5700">place</TOKEN>
<TOKEN id="token-50-9" pos="word" morph="none" start_char="5702" end_char="5704">may</TOKEN>
<TOKEN id="token-50-10" pos="word" morph="none" start_char="5706" end_char="5707">be</TOKEN>
<TOKEN id="token-50-11" pos="word" morph="none" start_char="5709" end_char="5715">related</TOKEN>
<TOKEN id="token-50-12" pos="word" morph="none" start_char="5717" end_char="5718">to</TOKEN>
<TOKEN id="token-50-13" pos="word" morph="none" start_char="5720" end_char="5730">atmospheric</TOKEN>
<TOKEN id="token-50-14" pos="word" morph="none" start_char="5732" end_char="5741">conditions</TOKEN>
<TOKEN id="token-50-15" pos="punct" morph="none" start_char="5742" end_char="5742">.</TOKEN>
</SEG>
<SEG id="segment-51" start_char="5744" end_char="5913">
<ORIGINAL_TEXT>Indeed, last weekend in Wuhan it was cold, about 4-5 degrees — increasing the probability of people using heating — and not very windy, which can increase concentrations.</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="word" morph="none" start_char="5744" end_char="5749">Indeed</TOKEN>
<TOKEN id="token-51-1" pos="punct" morph="none" start_char="5750" end_char="5750">,</TOKEN>
<TOKEN id="token-51-2" pos="word" morph="none" start_char="5752" end_char="5755">last</TOKEN>
<TOKEN id="token-51-3" pos="word" morph="none" start_char="5757" end_char="5763">weekend</TOKEN>
<TOKEN id="token-51-4" pos="word" morph="none" start_char="5765" end_char="5766">in</TOKEN>
<TOKEN id="token-51-5" pos="word" morph="none" start_char="5768" end_char="5772">Wuhan</TOKEN>
<TOKEN id="token-51-6" pos="word" morph="none" start_char="5774" end_char="5775">it</TOKEN>
<TOKEN id="token-51-7" pos="word" morph="none" start_char="5777" end_char="5779">was</TOKEN>
<TOKEN id="token-51-8" pos="word" morph="none" start_char="5781" end_char="5784">cold</TOKEN>
<TOKEN id="token-51-9" pos="punct" morph="none" start_char="5785" end_char="5785">,</TOKEN>
<TOKEN id="token-51-10" pos="word" morph="none" start_char="5787" end_char="5791">about</TOKEN>
<TOKEN id="token-51-11" pos="unknown" morph="none" start_char="5793" end_char="5795">4-5</TOKEN>
<TOKEN id="token-51-12" pos="word" morph="none" start_char="5797" end_char="5803">degrees</TOKEN>
<TOKEN id="token-51-13" pos="punct" morph="none" start_char="5805" end_char="5805">—</TOKEN>
<TOKEN id="token-51-14" pos="word" morph="none" start_char="5807" end_char="5816">increasing</TOKEN>
<TOKEN id="token-51-15" pos="word" morph="none" start_char="5818" end_char="5820">the</TOKEN>
<TOKEN id="token-51-16" pos="word" morph="none" start_char="5822" end_char="5832">probability</TOKEN>
<TOKEN id="token-51-17" pos="word" morph="none" start_char="5834" end_char="5835">of</TOKEN>
<TOKEN id="token-51-18" pos="word" morph="none" start_char="5837" end_char="5842">people</TOKEN>
<TOKEN id="token-51-19" pos="word" morph="none" start_char="5844" end_char="5848">using</TOKEN>
<TOKEN id="token-51-20" pos="word" morph="none" start_char="5850" end_char="5856">heating</TOKEN>
<TOKEN id="token-51-21" pos="punct" morph="none" start_char="5858" end_char="5858">—</TOKEN>
<TOKEN id="token-51-22" pos="word" morph="none" start_char="5860" end_char="5862">and</TOKEN>
<TOKEN id="token-51-23" pos="word" morph="none" start_char="5864" end_char="5866">not</TOKEN>
<TOKEN id="token-51-24" pos="word" morph="none" start_char="5868" end_char="5871">very</TOKEN>
<TOKEN id="token-51-25" pos="word" morph="none" start_char="5873" end_char="5877">windy</TOKEN>
<TOKEN id="token-51-26" pos="punct" morph="none" start_char="5878" end_char="5878">,</TOKEN>
<TOKEN id="token-51-27" pos="word" morph="none" start_char="5880" end_char="5884">which</TOKEN>
<TOKEN id="token-51-28" pos="word" morph="none" start_char="5886" end_char="5888">can</TOKEN>
<TOKEN id="token-51-29" pos="word" morph="none" start_char="5890" end_char="5897">increase</TOKEN>
<TOKEN id="token-51-30" pos="word" morph="none" start_char="5899" end_char="5912">concentrations</TOKEN>
<TOKEN id="token-51-31" pos="punct" morph="none" start_char="5913" end_char="5913">.</TOKEN>
</SEG>
<SEG id="segment-52" start_char="5916" end_char="6128">
<ORIGINAL_TEXT>East of Wuhan, where the large cloud of SO2 was shown, there is a large coal-fired power plant that is identified in NASA's catalogue of sources of sulphur dioxide emissions, as researcher Iolanda Ialongo told us.</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="5916" end_char="5919">East</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="5921" end_char="5922">of</TOKEN>
<TOKEN id="token-52-2" pos="word" morph="none" start_char="5924" end_char="5928">Wuhan</TOKEN>
<TOKEN id="token-52-3" pos="punct" morph="none" start_char="5929" end_char="5929">,</TOKEN>
<TOKEN id="token-52-4" pos="word" morph="none" start_char="5931" end_char="5935">where</TOKEN>
<TOKEN id="token-52-5" pos="word" morph="none" start_char="5937" end_char="5939">the</TOKEN>
<TOKEN id="token-52-6" pos="word" morph="none" start_char="5941" end_char="5945">large</TOKEN>
<TOKEN id="token-52-7" pos="word" morph="none" start_char="5947" end_char="5951">cloud</TOKEN>
<TOKEN id="token-52-8" pos="word" morph="none" start_char="5953" end_char="5954">of</TOKEN>
<TOKEN id="token-52-9" pos="word" morph="none" start_char="5956" end_char="5958">SO2</TOKEN>
<TOKEN id="token-52-10" pos="word" morph="none" start_char="5960" end_char="5962">was</TOKEN>
<TOKEN id="token-52-11" pos="word" morph="none" start_char="5964" end_char="5968">shown</TOKEN>
<TOKEN id="token-52-12" pos="punct" morph="none" start_char="5969" end_char="5969">,</TOKEN>
<TOKEN id="token-52-13" pos="word" morph="none" start_char="5971" end_char="5975">there</TOKEN>
<TOKEN id="token-52-14" pos="word" morph="none" start_char="5977" end_char="5978">is</TOKEN>
<TOKEN id="token-52-15" pos="word" morph="none" start_char="5980" end_char="5980">a</TOKEN>
<TOKEN id="token-52-16" pos="word" morph="none" start_char="5982" end_char="5986">large</TOKEN>
<TOKEN id="token-52-17" pos="unknown" morph="none" start_char="5988" end_char="5997">coal-fired</TOKEN>
<TOKEN id="token-52-18" pos="word" morph="none" start_char="5999" end_char="6003">power</TOKEN>
<TOKEN id="token-52-19" pos="word" morph="none" start_char="6005" end_char="6009">plant</TOKEN>
<TOKEN id="token-52-20" pos="word" morph="none" start_char="6011" end_char="6014">that</TOKEN>
<TOKEN id="token-52-21" pos="word" morph="none" start_char="6016" end_char="6017">is</TOKEN>
<TOKEN id="token-52-22" pos="word" morph="none" start_char="6019" end_char="6028">identified</TOKEN>
<TOKEN id="token-52-23" pos="word" morph="none" start_char="6030" end_char="6031">in</TOKEN>
<TOKEN id="token-52-24" pos="word" morph="none" start_char="6033" end_char="6038">NASA's</TOKEN>
<TOKEN id="token-52-25" pos="word" morph="none" start_char="6040" end_char="6048">catalogue</TOKEN>
<TOKEN id="token-52-26" pos="word" morph="none" start_char="6050" end_char="6051">of</TOKEN>
<TOKEN id="token-52-27" pos="word" morph="none" start_char="6053" end_char="6059">sources</TOKEN>
<TOKEN id="token-52-28" pos="word" morph="none" start_char="6061" end_char="6062">of</TOKEN>
<TOKEN id="token-52-29" pos="word" morph="none" start_char="6064" end_char="6070">sulphur</TOKEN>
<TOKEN id="token-52-30" pos="word" morph="none" start_char="6072" end_char="6078">dioxide</TOKEN>
<TOKEN id="token-52-31" pos="word" morph="none" start_char="6080" end_char="6088">emissions</TOKEN>
<TOKEN id="token-52-32" pos="punct" morph="none" start_char="6089" end_char="6089">,</TOKEN>
<TOKEN id="token-52-33" pos="word" morph="none" start_char="6091" end_char="6092">as</TOKEN>
<TOKEN id="token-52-34" pos="word" morph="none" start_char="6094" end_char="6103">researcher</TOKEN>
<TOKEN id="token-52-35" pos="word" morph="none" start_char="6105" end_char="6111">Iolanda</TOKEN>
<TOKEN id="token-52-36" pos="word" morph="none" start_char="6113" end_char="6119">Ialongo</TOKEN>
<TOKEN id="token-52-37" pos="word" morph="none" start_char="6121" end_char="6124">told</TOKEN>
<TOKEN id="token-52-38" pos="word" morph="none" start_char="6126" end_char="6127">us</TOKEN>
<TOKEN id="token-52-39" pos="punct" morph="none" start_char="6128" end_char="6128">.</TOKEN>
</SEG>
<SEG id="segment-53" start_char="6132" end_char="6360">
<ORIGINAL_TEXT>Anu-Maija Sundström, an air quality expert from the Finnish Meteorological Institute, pointed out that at a quick glance, neither the air quality indices nor the SILAM model showed anything exceptional in the SO2 levels of Wuhan.</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="unknown" morph="none" start_char="6132" end_char="6140">Anu-Maija</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="6142" end_char="6150">Sundström</TOKEN>
<TOKEN id="token-53-2" pos="punct" morph="none" start_char="6151" end_char="6151">,</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="6153" end_char="6154">an</TOKEN>
<TOKEN id="token-53-4" pos="word" morph="none" start_char="6156" end_char="6158">air</TOKEN>
<TOKEN id="token-53-5" pos="word" morph="none" start_char="6160" end_char="6166">quality</TOKEN>
<TOKEN id="token-53-6" pos="word" morph="none" start_char="6168" end_char="6173">expert</TOKEN>
<TOKEN id="token-53-7" pos="word" morph="none" start_char="6175" end_char="6178">from</TOKEN>
<TOKEN id="token-53-8" pos="word" morph="none" start_char="6180" end_char="6182">the</TOKEN>
<TOKEN id="token-53-9" pos="word" morph="none" start_char="6184" end_char="6190">Finnish</TOKEN>
<TOKEN id="token-53-10" pos="word" morph="none" start_char="6192" end_char="6205">Meteorological</TOKEN>
<TOKEN id="token-53-11" pos="word" morph="none" start_char="6207" end_char="6215">Institute</TOKEN>
<TOKEN id="token-53-12" pos="punct" morph="none" start_char="6216" end_char="6216">,</TOKEN>
<TOKEN id="token-53-13" pos="word" morph="none" start_char="6218" end_char="6224">pointed</TOKEN>
<TOKEN id="token-53-14" pos="word" morph="none" start_char="6226" end_char="6228">out</TOKEN>
<TOKEN id="token-53-15" pos="word" morph="none" start_char="6230" end_char="6233">that</TOKEN>
<TOKEN id="token-53-16" pos="word" morph="none" start_char="6235" end_char="6236">at</TOKEN>
<TOKEN id="token-53-17" pos="word" morph="none" start_char="6238" end_char="6238">a</TOKEN>
<TOKEN id="token-53-18" pos="word" morph="none" start_char="6240" end_char="6244">quick</TOKEN>
<TOKEN id="token-53-19" pos="word" morph="none" start_char="6246" end_char="6251">glance</TOKEN>
<TOKEN id="token-53-20" pos="punct" morph="none" start_char="6252" end_char="6252">,</TOKEN>
<TOKEN id="token-53-21" pos="word" morph="none" start_char="6254" end_char="6260">neither</TOKEN>
<TOKEN id="token-53-22" pos="word" morph="none" start_char="6262" end_char="6264">the</TOKEN>
<TOKEN id="token-53-23" pos="word" morph="none" start_char="6266" end_char="6268">air</TOKEN>
<TOKEN id="token-53-24" pos="word" morph="none" start_char="6270" end_char="6276">quality</TOKEN>
<TOKEN id="token-53-25" pos="word" morph="none" start_char="6278" end_char="6284">indices</TOKEN>
<TOKEN id="token-53-26" pos="word" morph="none" start_char="6286" end_char="6288">nor</TOKEN>
<TOKEN id="token-53-27" pos="word" morph="none" start_char="6290" end_char="6292">the</TOKEN>
<TOKEN id="token-53-28" pos="word" morph="none" start_char="6294" end_char="6298">SILAM</TOKEN>
<TOKEN id="token-53-29" pos="word" morph="none" start_char="6300" end_char="6304">model</TOKEN>
<TOKEN id="token-53-30" pos="word" morph="none" start_char="6306" end_char="6311">showed</TOKEN>
<TOKEN id="token-53-31" pos="word" morph="none" start_char="6313" end_char="6320">anything</TOKEN>
<TOKEN id="token-53-32" pos="word" morph="none" start_char="6322" end_char="6332">exceptional</TOKEN>
<TOKEN id="token-53-33" pos="word" morph="none" start_char="6334" end_char="6335">in</TOKEN>
<TOKEN id="token-53-34" pos="word" morph="none" start_char="6337" end_char="6339">the</TOKEN>
<TOKEN id="token-53-35" pos="word" morph="none" start_char="6341" end_char="6343">SO2</TOKEN>
<TOKEN id="token-53-36" pos="word" morph="none" start_char="6345" end_char="6350">levels</TOKEN>
<TOKEN id="token-53-37" pos="word" morph="none" start_char="6352" end_char="6353">of</TOKEN>
<TOKEN id="token-53-38" pos="word" morph="none" start_char="6355" end_char="6359">Wuhan</TOKEN>
<TOKEN id="token-53-39" pos="punct" morph="none" start_char="6360" end_char="6360">.</TOKEN>
</SEG>
<SEG id="segment-54" start_char="6363" end_char="6518">
<ORIGINAL_TEXT>In short, this looks like just another more example of the difficulty of separating rumours and misinformation in a subject as sensitive as the coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="word" morph="none" start_char="6363" end_char="6364">In</TOKEN>
<TOKEN id="token-54-1" pos="word" morph="none" start_char="6366" end_char="6370">short</TOKEN>
<TOKEN id="token-54-2" pos="punct" morph="none" start_char="6371" end_char="6371">,</TOKEN>
<TOKEN id="token-54-3" pos="word" morph="none" start_char="6373" end_char="6376">this</TOKEN>
<TOKEN id="token-54-4" pos="word" morph="none" start_char="6378" end_char="6382">looks</TOKEN>
<TOKEN id="token-54-5" pos="word" morph="none" start_char="6384" end_char="6387">like</TOKEN>
<TOKEN id="token-54-6" pos="word" morph="none" start_char="6389" end_char="6392">just</TOKEN>
<TOKEN id="token-54-7" pos="word" morph="none" start_char="6394" end_char="6400">another</TOKEN>
<TOKEN id="token-54-8" pos="word" morph="none" start_char="6402" end_char="6405">more</TOKEN>
<TOKEN id="token-54-9" pos="word" morph="none" start_char="6407" end_char="6413">example</TOKEN>
<TOKEN id="token-54-10" pos="word" morph="none" start_char="6415" end_char="6416">of</TOKEN>
<TOKEN id="token-54-11" pos="word" morph="none" start_char="6418" end_char="6420">the</TOKEN>
<TOKEN id="token-54-12" pos="word" morph="none" start_char="6422" end_char="6431">difficulty</TOKEN>
<TOKEN id="token-54-13" pos="word" morph="none" start_char="6433" end_char="6434">of</TOKEN>
<TOKEN id="token-54-14" pos="word" morph="none" start_char="6436" end_char="6445">separating</TOKEN>
<TOKEN id="token-54-15" pos="word" morph="none" start_char="6447" end_char="6453">rumours</TOKEN>
<TOKEN id="token-54-16" pos="word" morph="none" start_char="6455" end_char="6457">and</TOKEN>
<TOKEN id="token-54-17" pos="word" morph="none" start_char="6459" end_char="6472">misinformation</TOKEN>
<TOKEN id="token-54-18" pos="word" morph="none" start_char="6474" end_char="6475">in</TOKEN>
<TOKEN id="token-54-19" pos="word" morph="none" start_char="6477" end_char="6477">a</TOKEN>
<TOKEN id="token-54-20" pos="word" morph="none" start_char="6479" end_char="6485">subject</TOKEN>
<TOKEN id="token-54-21" pos="word" morph="none" start_char="6487" end_char="6488">as</TOKEN>
<TOKEN id="token-54-22" pos="word" morph="none" start_char="6490" end_char="6498">sensitive</TOKEN>
<TOKEN id="token-54-23" pos="word" morph="none" start_char="6500" end_char="6501">as</TOKEN>
<TOKEN id="token-54-24" pos="word" morph="none" start_char="6503" end_char="6505">the</TOKEN>
<TOKEN id="token-54-25" pos="word" morph="none" start_char="6507" end_char="6517">coronavirus</TOKEN>
<TOKEN id="token-54-26" pos="punct" morph="none" start_char="6518" end_char="6518">.</TOKEN>
</SEG>
<SEG id="segment-55" start_char="6520" end_char="6636">
<ORIGINAL_TEXT>Many take advantage of the traditional opacity of the Chinese authorities to multiply the most gruesome speculations.</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="word" morph="none" start_char="6520" end_char="6523">Many</TOKEN>
<TOKEN id="token-55-1" pos="word" morph="none" start_char="6525" end_char="6528">take</TOKEN>
<TOKEN id="token-55-2" pos="word" morph="none" start_char="6530" end_char="6538">advantage</TOKEN>
<TOKEN id="token-55-3" pos="word" morph="none" start_char="6540" end_char="6541">of</TOKEN>
<TOKEN id="token-55-4" pos="word" morph="none" start_char="6543" end_char="6545">the</TOKEN>
<TOKEN id="token-55-5" pos="word" morph="none" start_char="6547" end_char="6557">traditional</TOKEN>
<TOKEN id="token-55-6" pos="word" morph="none" start_char="6559" end_char="6565">opacity</TOKEN>
<TOKEN id="token-55-7" pos="word" morph="none" start_char="6567" end_char="6568">of</TOKEN>
<TOKEN id="token-55-8" pos="word" morph="none" start_char="6570" end_char="6572">the</TOKEN>
<TOKEN id="token-55-9" pos="word" morph="none" start_char="6574" end_char="6580">Chinese</TOKEN>
<TOKEN id="token-55-10" pos="word" morph="none" start_char="6582" end_char="6592">authorities</TOKEN>
<TOKEN id="token-55-11" pos="word" morph="none" start_char="6594" end_char="6595">to</TOKEN>
<TOKEN id="token-55-12" pos="word" morph="none" start_char="6597" end_char="6604">multiply</TOKEN>
<TOKEN id="token-55-13" pos="word" morph="none" start_char="6606" end_char="6608">the</TOKEN>
<TOKEN id="token-55-14" pos="word" morph="none" start_char="6610" end_char="6613">most</TOKEN>
<TOKEN id="token-55-15" pos="word" morph="none" start_char="6615" end_char="6622">gruesome</TOKEN>
<TOKEN id="token-55-16" pos="word" morph="none" start_char="6624" end_char="6635">speculations</TOKEN>
<TOKEN id="token-55-17" pos="punct" morph="none" start_char="6636" end_char="6636">.</TOKEN>
</SEG>
<SEG id="segment-56" start_char="6639" end_char="6798">
<ORIGINAL_TEXT>The World Health Organization itself or the major social networks and Internet platforms have created special pages to try to stop false rumours about COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="6639" end_char="6641">The</TOKEN>
<TOKEN id="token-56-1" pos="word" morph="none" start_char="6643" end_char="6647">World</TOKEN>
<TOKEN id="token-56-2" pos="word" morph="none" start_char="6649" end_char="6654">Health</TOKEN>
<TOKEN id="token-56-3" pos="word" morph="none" start_char="6656" end_char="6667">Organization</TOKEN>
<TOKEN id="token-56-4" pos="word" morph="none" start_char="6669" end_char="6674">itself</TOKEN>
<TOKEN id="token-56-5" pos="word" morph="none" start_char="6676" end_char="6677">or</TOKEN>
<TOKEN id="token-56-6" pos="word" morph="none" start_char="6679" end_char="6681">the</TOKEN>
<TOKEN id="token-56-7" pos="word" morph="none" start_char="6683" end_char="6687">major</TOKEN>
<TOKEN id="token-56-8" pos="word" morph="none" start_char="6689" end_char="6694">social</TOKEN>
<TOKEN id="token-56-9" pos="word" morph="none" start_char="6696" end_char="6703">networks</TOKEN>
<TOKEN id="token-56-10" pos="word" morph="none" start_char="6705" end_char="6707">and</TOKEN>
<TOKEN id="token-56-11" pos="word" morph="none" start_char="6709" end_char="6716">Internet</TOKEN>
<TOKEN id="token-56-12" pos="word" morph="none" start_char="6718" end_char="6726">platforms</TOKEN>
<TOKEN id="token-56-13" pos="word" morph="none" start_char="6728" end_char="6731">have</TOKEN>
<TOKEN id="token-56-14" pos="word" morph="none" start_char="6733" end_char="6739">created</TOKEN>
<TOKEN id="token-56-15" pos="word" morph="none" start_char="6741" end_char="6747">special</TOKEN>
<TOKEN id="token-56-16" pos="word" morph="none" start_char="6749" end_char="6753">pages</TOKEN>
<TOKEN id="token-56-17" pos="word" morph="none" start_char="6755" end_char="6756">to</TOKEN>
<TOKEN id="token-56-18" pos="word" morph="none" start_char="6758" end_char="6760">try</TOKEN>
<TOKEN id="token-56-19" pos="word" morph="none" start_char="6762" end_char="6763">to</TOKEN>
<TOKEN id="token-56-20" pos="word" morph="none" start_char="6765" end_char="6768">stop</TOKEN>
<TOKEN id="token-56-21" pos="word" morph="none" start_char="6770" end_char="6774">false</TOKEN>
<TOKEN id="token-56-22" pos="word" morph="none" start_char="6776" end_char="6782">rumours</TOKEN>
<TOKEN id="token-56-23" pos="word" morph="none" start_char="6784" end_char="6788">about</TOKEN>
<TOKEN id="token-56-24" pos="unknown" morph="none" start_char="6790" end_char="6797">COVID-19</TOKEN>
<TOKEN id="token-56-25" pos="punct" morph="none" start_char="6798" end_char="6798">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
