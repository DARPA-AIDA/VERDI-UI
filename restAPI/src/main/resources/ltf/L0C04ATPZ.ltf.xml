<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATPZ" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="2225" raw_text_md5="de6cd6277c1554d9e03dcf2b2ca3877a">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="85">
<ORIGINAL_TEXT>Lo que debes que saber del ‘paciente cero’, el primer caso de coronavirus en el mundo</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="2">Lo</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="4" end_char="6">que</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="8" end_char="12">debes</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="14" end_char="16">que</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="18" end_char="22">saber</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="24" end_char="26">del</TOKEN>
<TOKEN id="token-0-6" pos="punct" morph="none" start_char="28" end_char="28">‘</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="29" end_char="36">paciente</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="38" end_char="41">cero</TOKEN>
<TOKEN id="token-0-9" pos="punct" morph="none" start_char="42" end_char="43">’,</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="45" end_char="46">el</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="48" end_char="53">primer</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="55" end_char="58">caso</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="60" end_char="61">de</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="63" end_char="73">coronavirus</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="75" end_char="76">en</TOKEN>
<TOKEN id="token-0-16" pos="word" morph="none" start_char="78" end_char="79">el</TOKEN>
<TOKEN id="token-0-17" pos="word" morph="none" start_char="81" end_char="85">mundo</TOKEN>
</SEG>
<SEG id="segment-1" start_char="90" end_char="756">
<ORIGINAL_TEXT>Hace un año exactamente el primer caso de covid-19 se dio en el mundo, en ese entonces aún se desconocía que se trataba de una enfermedad que podía llegar a ser mortal y que ocasionaría que la vida como la conocíamos terminara, actualmente la población mundial ya está acostumbrada a escuchar cifras que muchas veces son alarmantes sobre el número elevado de casos que hay, pero todo esto inició con una persona a la que se identifica como el ‘paciente cero’, esto quiere decir que fue la primera persona en portar la enfermedad, al menos de la que se tiene registro, ya que muchos estudios han revelado actualmente que el virus pudo estar presente desde mucho antes.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="90" end_char="93">Hace</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="95" end_char="96">un</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="98" end_char="100">año</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="102" end_char="112">exactamente</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="114" end_char="115">el</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="117" end_char="122">primer</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="124" end_char="127">caso</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="129" end_char="130">de</TOKEN>
<TOKEN id="token-1-8" pos="unknown" morph="none" start_char="132" end_char="139">covid-19</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="141" end_char="142">se</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="144" end_char="146">dio</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="148" end_char="149">en</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="151" end_char="152">el</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="154" end_char="158">mundo</TOKEN>
<TOKEN id="token-1-14" pos="punct" morph="none" start_char="159" end_char="159">,</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="161" end_char="162">en</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="164" end_char="166">ese</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="168" end_char="175">entonces</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="177" end_char="179">aún</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="181" end_char="182">se</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="184" end_char="193">desconocía</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="195" end_char="197">que</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="199" end_char="200">se</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="202" end_char="208">trataba</TOKEN>
<TOKEN id="token-1-24" pos="word" morph="none" start_char="210" end_char="211">de</TOKEN>
<TOKEN id="token-1-25" pos="word" morph="none" start_char="213" end_char="215">una</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="217" end_char="226">enfermedad</TOKEN>
<TOKEN id="token-1-27" pos="word" morph="none" start_char="228" end_char="230">que</TOKEN>
<TOKEN id="token-1-28" pos="word" morph="none" start_char="232" end_char="236">podía</TOKEN>
<TOKEN id="token-1-29" pos="word" morph="none" start_char="238" end_char="243">llegar</TOKEN>
<TOKEN id="token-1-30" pos="word" morph="none" start_char="245" end_char="245">a</TOKEN>
<TOKEN id="token-1-31" pos="word" morph="none" start_char="247" end_char="249">ser</TOKEN>
<TOKEN id="token-1-32" pos="word" morph="none" start_char="251" end_char="256">mortal</TOKEN>
<TOKEN id="token-1-33" pos="word" morph="none" start_char="258" end_char="258">y</TOKEN>
<TOKEN id="token-1-34" pos="word" morph="none" start_char="260" end_char="262">que</TOKEN>
<TOKEN id="token-1-35" pos="word" morph="none" start_char="264" end_char="274">ocasionaría</TOKEN>
<TOKEN id="token-1-36" pos="word" morph="none" start_char="276" end_char="278">que</TOKEN>
<TOKEN id="token-1-37" pos="word" morph="none" start_char="280" end_char="281">la</TOKEN>
<TOKEN id="token-1-38" pos="word" morph="none" start_char="283" end_char="286">vida</TOKEN>
<TOKEN id="token-1-39" pos="word" morph="none" start_char="288" end_char="291">como</TOKEN>
<TOKEN id="token-1-40" pos="word" morph="none" start_char="293" end_char="294">la</TOKEN>
<TOKEN id="token-1-41" pos="word" morph="none" start_char="296" end_char="305">conocíamos</TOKEN>
<TOKEN id="token-1-42" pos="word" morph="none" start_char="307" end_char="315">terminara</TOKEN>
<TOKEN id="token-1-43" pos="punct" morph="none" start_char="316" end_char="316">,</TOKEN>
<TOKEN id="token-1-44" pos="word" morph="none" start_char="318" end_char="328">actualmente</TOKEN>
<TOKEN id="token-1-45" pos="word" morph="none" start_char="330" end_char="331">la</TOKEN>
<TOKEN id="token-1-46" pos="word" morph="none" start_char="333" end_char="341">población</TOKEN>
<TOKEN id="token-1-47" pos="word" morph="none" start_char="343" end_char="349">mundial</TOKEN>
<TOKEN id="token-1-48" pos="word" morph="none" start_char="351" end_char="352">ya</TOKEN>
<TOKEN id="token-1-49" pos="word" morph="none" start_char="354" end_char="357">está</TOKEN>
<TOKEN id="token-1-50" pos="word" morph="none" start_char="359" end_char="370">acostumbrada</TOKEN>
<TOKEN id="token-1-51" pos="word" morph="none" start_char="372" end_char="372">a</TOKEN>
<TOKEN id="token-1-52" pos="word" morph="none" start_char="374" end_char="381">escuchar</TOKEN>
<TOKEN id="token-1-53" pos="word" morph="none" start_char="383" end_char="388">cifras</TOKEN>
<TOKEN id="token-1-54" pos="word" morph="none" start_char="390" end_char="392">que</TOKEN>
<TOKEN id="token-1-55" pos="word" morph="none" start_char="394" end_char="399">muchas</TOKEN>
<TOKEN id="token-1-56" pos="word" morph="none" start_char="401" end_char="405">veces</TOKEN>
<TOKEN id="token-1-57" pos="word" morph="none" start_char="407" end_char="409">son</TOKEN>
<TOKEN id="token-1-58" pos="word" morph="none" start_char="411" end_char="420">alarmantes</TOKEN>
<TOKEN id="token-1-59" pos="word" morph="none" start_char="422" end_char="426">sobre</TOKEN>
<TOKEN id="token-1-60" pos="word" morph="none" start_char="428" end_char="429">el</TOKEN>
<TOKEN id="token-1-61" pos="word" morph="none" start_char="431" end_char="436">número</TOKEN>
<TOKEN id="token-1-62" pos="word" morph="none" start_char="438" end_char="444">elevado</TOKEN>
<TOKEN id="token-1-63" pos="word" morph="none" start_char="446" end_char="447">de</TOKEN>
<TOKEN id="token-1-64" pos="word" morph="none" start_char="449" end_char="453">casos</TOKEN>
<TOKEN id="token-1-65" pos="word" morph="none" start_char="455" end_char="457">que</TOKEN>
<TOKEN id="token-1-66" pos="word" morph="none" start_char="459" end_char="461">hay</TOKEN>
<TOKEN id="token-1-67" pos="punct" morph="none" start_char="462" end_char="462">,</TOKEN>
<TOKEN id="token-1-68" pos="word" morph="none" start_char="464" end_char="467">pero</TOKEN>
<TOKEN id="token-1-69" pos="word" morph="none" start_char="469" end_char="472">todo</TOKEN>
<TOKEN id="token-1-70" pos="word" morph="none" start_char="474" end_char="477">esto</TOKEN>
<TOKEN id="token-1-71" pos="word" morph="none" start_char="479" end_char="484">inició</TOKEN>
<TOKEN id="token-1-72" pos="word" morph="none" start_char="486" end_char="488">con</TOKEN>
<TOKEN id="token-1-73" pos="word" morph="none" start_char="490" end_char="492">una</TOKEN>
<TOKEN id="token-1-74" pos="word" morph="none" start_char="494" end_char="500">persona</TOKEN>
<TOKEN id="token-1-75" pos="word" morph="none" start_char="502" end_char="502">a</TOKEN>
<TOKEN id="token-1-76" pos="word" morph="none" start_char="504" end_char="505">la</TOKEN>
<TOKEN id="token-1-77" pos="word" morph="none" start_char="507" end_char="509">que</TOKEN>
<TOKEN id="token-1-78" pos="word" morph="none" start_char="511" end_char="512">se</TOKEN>
<TOKEN id="token-1-79" pos="word" morph="none" start_char="514" end_char="523">identifica</TOKEN>
<TOKEN id="token-1-80" pos="word" morph="none" start_char="525" end_char="528">como</TOKEN>
<TOKEN id="token-1-81" pos="word" morph="none" start_char="530" end_char="531">el</TOKEN>
<TOKEN id="token-1-82" pos="punct" morph="none" start_char="533" end_char="533">‘</TOKEN>
<TOKEN id="token-1-83" pos="word" morph="none" start_char="534" end_char="541">paciente</TOKEN>
<TOKEN id="token-1-84" pos="word" morph="none" start_char="543" end_char="546">cero</TOKEN>
<TOKEN id="token-1-85" pos="punct" morph="none" start_char="547" end_char="548">’,</TOKEN>
<TOKEN id="token-1-86" pos="word" morph="none" start_char="550" end_char="553">esto</TOKEN>
<TOKEN id="token-1-87" pos="word" morph="none" start_char="555" end_char="560">quiere</TOKEN>
<TOKEN id="token-1-88" pos="word" morph="none" start_char="562" end_char="566">decir</TOKEN>
<TOKEN id="token-1-89" pos="word" morph="none" start_char="568" end_char="570">que</TOKEN>
<TOKEN id="token-1-90" pos="word" morph="none" start_char="572" end_char="574">fue</TOKEN>
<TOKEN id="token-1-91" pos="word" morph="none" start_char="576" end_char="577">la</TOKEN>
<TOKEN id="token-1-92" pos="word" morph="none" start_char="579" end_char="585">primera</TOKEN>
<TOKEN id="token-1-93" pos="word" morph="none" start_char="587" end_char="593">persona</TOKEN>
<TOKEN id="token-1-94" pos="word" morph="none" start_char="595" end_char="596">en</TOKEN>
<TOKEN id="token-1-95" pos="word" morph="none" start_char="598" end_char="603">portar</TOKEN>
<TOKEN id="token-1-96" pos="word" morph="none" start_char="605" end_char="606">la</TOKEN>
<TOKEN id="token-1-97" pos="word" morph="none" start_char="608" end_char="617">enfermedad</TOKEN>
<TOKEN id="token-1-98" pos="punct" morph="none" start_char="618" end_char="618">,</TOKEN>
<TOKEN id="token-1-99" pos="word" morph="none" start_char="620" end_char="621">al</TOKEN>
<TOKEN id="token-1-100" pos="word" morph="none" start_char="623" end_char="627">menos</TOKEN>
<TOKEN id="token-1-101" pos="word" morph="none" start_char="629" end_char="630">de</TOKEN>
<TOKEN id="token-1-102" pos="word" morph="none" start_char="632" end_char="633">la</TOKEN>
<TOKEN id="token-1-103" pos="word" morph="none" start_char="635" end_char="637">que</TOKEN>
<TOKEN id="token-1-104" pos="word" morph="none" start_char="639" end_char="640">se</TOKEN>
<TOKEN id="token-1-105" pos="word" morph="none" start_char="642" end_char="646">tiene</TOKEN>
<TOKEN id="token-1-106" pos="word" morph="none" start_char="648" end_char="655">registro</TOKEN>
<TOKEN id="token-1-107" pos="punct" morph="none" start_char="656" end_char="656">,</TOKEN>
<TOKEN id="token-1-108" pos="word" morph="none" start_char="658" end_char="659">ya</TOKEN>
<TOKEN id="token-1-109" pos="word" morph="none" start_char="661" end_char="663">que</TOKEN>
<TOKEN id="token-1-110" pos="word" morph="none" start_char="665" end_char="670">muchos</TOKEN>
<TOKEN id="token-1-111" pos="word" morph="none" start_char="672" end_char="679">estudios</TOKEN>
<TOKEN id="token-1-112" pos="word" morph="none" start_char="681" end_char="683">han</TOKEN>
<TOKEN id="token-1-113" pos="word" morph="none" start_char="685" end_char="692">revelado</TOKEN>
<TOKEN id="token-1-114" pos="word" morph="none" start_char="694" end_char="704">actualmente</TOKEN>
<TOKEN id="token-1-115" pos="word" morph="none" start_char="706" end_char="708">que</TOKEN>
<TOKEN id="token-1-116" pos="word" morph="none" start_char="710" end_char="711">el</TOKEN>
<TOKEN id="token-1-117" pos="word" morph="none" start_char="713" end_char="717">virus</TOKEN>
<TOKEN id="token-1-118" pos="word" morph="none" start_char="719" end_char="722">pudo</TOKEN>
<TOKEN id="token-1-119" pos="word" morph="none" start_char="724" end_char="728">estar</TOKEN>
<TOKEN id="token-1-120" pos="word" morph="none" start_char="730" end_char="737">presente</TOKEN>
<TOKEN id="token-1-121" pos="word" morph="none" start_char="739" end_char="743">desde</TOKEN>
<TOKEN id="token-1-122" pos="word" morph="none" start_char="745" end_char="749">mucho</TOKEN>
<TOKEN id="token-1-123" pos="word" morph="none" start_char="751" end_char="755">antes</TOKEN>
<TOKEN id="token-1-124" pos="punct" morph="none" start_char="756" end_char="756">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="759" end_char="1277">
<ORIGINAL_TEXT>Fue en la provincia de Hubei en China que se dio este primer caso, las autoridades rastrearon la cadena de contagios hasta el primer caso en día 17 de noviembre de 2019, se trató de un hombre de 55 años, no se saben muchos detalles sobre él, pero tenerlo identificado es clave para entender la pandemia actual, identificar este primer brote ayudó al mundo a tomar medidas antes de que se convirtiera en pandemia y aunque muchas cosas han fallado, la situación podría ser aún peor de no conocer a lo que nos enfrentamos.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="759" end_char="761">Fue</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="763" end_char="764">en</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="766" end_char="767">la</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="769" end_char="777">provincia</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="779" end_char="780">de</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="782" end_char="786">Hubei</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="788" end_char="789">en</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="791" end_char="795">China</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="797" end_char="799">que</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="801" end_char="802">se</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="804" end_char="806">dio</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="808" end_char="811">este</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="813" end_char="818">primer</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="820" end_char="823">caso</TOKEN>
<TOKEN id="token-2-14" pos="punct" morph="none" start_char="824" end_char="824">,</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="826" end_char="828">las</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="830" end_char="840">autoridades</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="842" end_char="851">rastrearon</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="853" end_char="854">la</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="856" end_char="861">cadena</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="863" end_char="864">de</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="866" end_char="874">contagios</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="876" end_char="880">hasta</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="882" end_char="883">el</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="885" end_char="890">primer</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="892" end_char="895">caso</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="897" end_char="898">en</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="900" end_char="902">día</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="904" end_char="905">17</TOKEN>
<TOKEN id="token-2-29" pos="word" morph="none" start_char="907" end_char="908">de</TOKEN>
<TOKEN id="token-2-30" pos="word" morph="none" start_char="910" end_char="918">noviembre</TOKEN>
<TOKEN id="token-2-31" pos="word" morph="none" start_char="920" end_char="921">de</TOKEN>
<TOKEN id="token-2-32" pos="word" morph="none" start_char="923" end_char="926">2019</TOKEN>
<TOKEN id="token-2-33" pos="punct" morph="none" start_char="927" end_char="927">,</TOKEN>
<TOKEN id="token-2-34" pos="word" morph="none" start_char="929" end_char="930">se</TOKEN>
<TOKEN id="token-2-35" pos="word" morph="none" start_char="932" end_char="936">trató</TOKEN>
<TOKEN id="token-2-36" pos="word" morph="none" start_char="938" end_char="939">de</TOKEN>
<TOKEN id="token-2-37" pos="word" morph="none" start_char="941" end_char="942">un</TOKEN>
<TOKEN id="token-2-38" pos="word" morph="none" start_char="944" end_char="949">hombre</TOKEN>
<TOKEN id="token-2-39" pos="word" morph="none" start_char="951" end_char="952">de</TOKEN>
<TOKEN id="token-2-40" pos="word" morph="none" start_char="954" end_char="955">55</TOKEN>
<TOKEN id="token-2-41" pos="word" morph="none" start_char="957" end_char="960">años</TOKEN>
<TOKEN id="token-2-42" pos="punct" morph="none" start_char="961" end_char="961">,</TOKEN>
<TOKEN id="token-2-43" pos="word" morph="none" start_char="963" end_char="964">no</TOKEN>
<TOKEN id="token-2-44" pos="word" morph="none" start_char="966" end_char="967">se</TOKEN>
<TOKEN id="token-2-45" pos="word" morph="none" start_char="969" end_char="973">saben</TOKEN>
<TOKEN id="token-2-46" pos="word" morph="none" start_char="975" end_char="980">muchos</TOKEN>
<TOKEN id="token-2-47" pos="word" morph="none" start_char="982" end_char="989">detalles</TOKEN>
<TOKEN id="token-2-48" pos="word" morph="none" start_char="991" end_char="995">sobre</TOKEN>
<TOKEN id="token-2-49" pos="word" morph="none" start_char="997" end_char="998">él</TOKEN>
<TOKEN id="token-2-50" pos="punct" morph="none" start_char="999" end_char="999">,</TOKEN>
<TOKEN id="token-2-51" pos="word" morph="none" start_char="1001" end_char="1004">pero</TOKEN>
<TOKEN id="token-2-52" pos="word" morph="none" start_char="1006" end_char="1012">tenerlo</TOKEN>
<TOKEN id="token-2-53" pos="word" morph="none" start_char="1014" end_char="1025">identificado</TOKEN>
<TOKEN id="token-2-54" pos="word" morph="none" start_char="1027" end_char="1028">es</TOKEN>
<TOKEN id="token-2-55" pos="word" morph="none" start_char="1030" end_char="1034">clave</TOKEN>
<TOKEN id="token-2-56" pos="word" morph="none" start_char="1036" end_char="1039">para</TOKEN>
<TOKEN id="token-2-57" pos="word" morph="none" start_char="1041" end_char="1048">entender</TOKEN>
<TOKEN id="token-2-58" pos="word" morph="none" start_char="1050" end_char="1051">la</TOKEN>
<TOKEN id="token-2-59" pos="word" morph="none" start_char="1053" end_char="1060">pandemia</TOKEN>
<TOKEN id="token-2-60" pos="word" morph="none" start_char="1062" end_char="1067">actual</TOKEN>
<TOKEN id="token-2-61" pos="punct" morph="none" start_char="1068" end_char="1068">,</TOKEN>
<TOKEN id="token-2-62" pos="word" morph="none" start_char="1070" end_char="1080">identificar</TOKEN>
<TOKEN id="token-2-63" pos="word" morph="none" start_char="1082" end_char="1085">este</TOKEN>
<TOKEN id="token-2-64" pos="word" morph="none" start_char="1087" end_char="1092">primer</TOKEN>
<TOKEN id="token-2-65" pos="word" morph="none" start_char="1094" end_char="1098">brote</TOKEN>
<TOKEN id="token-2-66" pos="word" morph="none" start_char="1100" end_char="1104">ayudó</TOKEN>
<TOKEN id="token-2-67" pos="word" morph="none" start_char="1106" end_char="1107">al</TOKEN>
<TOKEN id="token-2-68" pos="word" morph="none" start_char="1109" end_char="1113">mundo</TOKEN>
<TOKEN id="token-2-69" pos="word" morph="none" start_char="1115" end_char="1115">a</TOKEN>
<TOKEN id="token-2-70" pos="word" morph="none" start_char="1117" end_char="1121">tomar</TOKEN>
<TOKEN id="token-2-71" pos="word" morph="none" start_char="1123" end_char="1129">medidas</TOKEN>
<TOKEN id="token-2-72" pos="word" morph="none" start_char="1131" end_char="1135">antes</TOKEN>
<TOKEN id="token-2-73" pos="word" morph="none" start_char="1137" end_char="1138">de</TOKEN>
<TOKEN id="token-2-74" pos="word" morph="none" start_char="1140" end_char="1142">que</TOKEN>
<TOKEN id="token-2-75" pos="word" morph="none" start_char="1144" end_char="1145">se</TOKEN>
<TOKEN id="token-2-76" pos="word" morph="none" start_char="1147" end_char="1157">convirtiera</TOKEN>
<TOKEN id="token-2-77" pos="word" morph="none" start_char="1159" end_char="1160">en</TOKEN>
<TOKEN id="token-2-78" pos="word" morph="none" start_char="1162" end_char="1169">pandemia</TOKEN>
<TOKEN id="token-2-79" pos="word" morph="none" start_char="1171" end_char="1171">y</TOKEN>
<TOKEN id="token-2-80" pos="word" morph="none" start_char="1173" end_char="1178">aunque</TOKEN>
<TOKEN id="token-2-81" pos="word" morph="none" start_char="1180" end_char="1185">muchas</TOKEN>
<TOKEN id="token-2-82" pos="word" morph="none" start_char="1187" end_char="1191">cosas</TOKEN>
<TOKEN id="token-2-83" pos="word" morph="none" start_char="1193" end_char="1195">han</TOKEN>
<TOKEN id="token-2-84" pos="word" morph="none" start_char="1197" end_char="1203">fallado</TOKEN>
<TOKEN id="token-2-85" pos="punct" morph="none" start_char="1204" end_char="1204">,</TOKEN>
<TOKEN id="token-2-86" pos="word" morph="none" start_char="1206" end_char="1207">la</TOKEN>
<TOKEN id="token-2-87" pos="word" morph="none" start_char="1209" end_char="1217">situación</TOKEN>
<TOKEN id="token-2-88" pos="word" morph="none" start_char="1219" end_char="1224">podría</TOKEN>
<TOKEN id="token-2-89" pos="word" morph="none" start_char="1226" end_char="1228">ser</TOKEN>
<TOKEN id="token-2-90" pos="word" morph="none" start_char="1230" end_char="1232">aún</TOKEN>
<TOKEN id="token-2-91" pos="word" morph="none" start_char="1234" end_char="1237">peor</TOKEN>
<TOKEN id="token-2-92" pos="word" morph="none" start_char="1239" end_char="1240">de</TOKEN>
<TOKEN id="token-2-93" pos="word" morph="none" start_char="1242" end_char="1243">no</TOKEN>
<TOKEN id="token-2-94" pos="word" morph="none" start_char="1245" end_char="1251">conocer</TOKEN>
<TOKEN id="token-2-95" pos="word" morph="none" start_char="1253" end_char="1253">a</TOKEN>
<TOKEN id="token-2-96" pos="word" morph="none" start_char="1255" end_char="1256">lo</TOKEN>
<TOKEN id="token-2-97" pos="word" morph="none" start_char="1258" end_char="1260">que</TOKEN>
<TOKEN id="token-2-98" pos="word" morph="none" start_char="1262" end_char="1264">nos</TOKEN>
<TOKEN id="token-2-99" pos="word" morph="none" start_char="1266" end_char="1276">enfrentamos</TOKEN>
<TOKEN id="token-2-100" pos="punct" morph="none" start_char="1277" end_char="1277">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="1280" end_char="1690">
<ORIGINAL_TEXT>Si bien el primer caso se dio en noviembre, no fue hasta el 27 de diciembre que Zhang Jixián, quien fuese un médico en el Hospital Provincial de Medicina Integrada China y Occidental, que reportó la existencia de este nuevo virus, dio a conocer sus efectos en la salud y trató de dar aviso a las autoridades sanitarias de su país, ese día los casos registrados eran 180 y para el inicio del 2020 subieron a 381.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="1280" end_char="1281">Si</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="1283" end_char="1286">bien</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="1288" end_char="1289">el</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="1291" end_char="1296">primer</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="1298" end_char="1301">caso</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="1303" end_char="1304">se</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="1306" end_char="1308">dio</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="1310" end_char="1311">en</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="1313" end_char="1321">noviembre</TOKEN>
<TOKEN id="token-3-9" pos="punct" morph="none" start_char="1322" end_char="1322">,</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="1324" end_char="1325">no</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="1327" end_char="1329">fue</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="1331" end_char="1335">hasta</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="1337" end_char="1338">el</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="1340" end_char="1341">27</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="1343" end_char="1344">de</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="1346" end_char="1354">diciembre</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="1356" end_char="1358">que</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="1360" end_char="1364">Zhang</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="1366" end_char="1371">Jixián</TOKEN>
<TOKEN id="token-3-20" pos="punct" morph="none" start_char="1372" end_char="1372">,</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="1374" end_char="1378">quien</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="1380" end_char="1384">fuese</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="1386" end_char="1387">un</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="1389" end_char="1394">médico</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="1396" end_char="1397">en</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="1399" end_char="1400">el</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="1402" end_char="1409">Hospital</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="1411" end_char="1420">Provincial</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="1422" end_char="1423">de</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="1425" end_char="1432">Medicina</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="1434" end_char="1442">Integrada</TOKEN>
<TOKEN id="token-3-32" pos="word" morph="none" start_char="1444" end_char="1448">China</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="1450" end_char="1450">y</TOKEN>
<TOKEN id="token-3-34" pos="word" morph="none" start_char="1452" end_char="1461">Occidental</TOKEN>
<TOKEN id="token-3-35" pos="punct" morph="none" start_char="1462" end_char="1462">,</TOKEN>
<TOKEN id="token-3-36" pos="word" morph="none" start_char="1464" end_char="1466">que</TOKEN>
<TOKEN id="token-3-37" pos="word" morph="none" start_char="1468" end_char="1474">reportó</TOKEN>
<TOKEN id="token-3-38" pos="word" morph="none" start_char="1476" end_char="1477">la</TOKEN>
<TOKEN id="token-3-39" pos="word" morph="none" start_char="1479" end_char="1488">existencia</TOKEN>
<TOKEN id="token-3-40" pos="word" morph="none" start_char="1490" end_char="1491">de</TOKEN>
<TOKEN id="token-3-41" pos="word" morph="none" start_char="1493" end_char="1496">este</TOKEN>
<TOKEN id="token-3-42" pos="word" morph="none" start_char="1498" end_char="1502">nuevo</TOKEN>
<TOKEN id="token-3-43" pos="word" morph="none" start_char="1504" end_char="1508">virus</TOKEN>
<TOKEN id="token-3-44" pos="punct" morph="none" start_char="1509" end_char="1509">,</TOKEN>
<TOKEN id="token-3-45" pos="word" morph="none" start_char="1511" end_char="1513">dio</TOKEN>
<TOKEN id="token-3-46" pos="word" morph="none" start_char="1515" end_char="1515">a</TOKEN>
<TOKEN id="token-3-47" pos="word" morph="none" start_char="1517" end_char="1523">conocer</TOKEN>
<TOKEN id="token-3-48" pos="word" morph="none" start_char="1525" end_char="1527">sus</TOKEN>
<TOKEN id="token-3-49" pos="word" morph="none" start_char="1529" end_char="1535">efectos</TOKEN>
<TOKEN id="token-3-50" pos="word" morph="none" start_char="1537" end_char="1538">en</TOKEN>
<TOKEN id="token-3-51" pos="word" morph="none" start_char="1540" end_char="1541">la</TOKEN>
<TOKEN id="token-3-52" pos="word" morph="none" start_char="1543" end_char="1547">salud</TOKEN>
<TOKEN id="token-3-53" pos="word" morph="none" start_char="1549" end_char="1549">y</TOKEN>
<TOKEN id="token-3-54" pos="word" morph="none" start_char="1551" end_char="1555">trató</TOKEN>
<TOKEN id="token-3-55" pos="word" morph="none" start_char="1557" end_char="1558">de</TOKEN>
<TOKEN id="token-3-56" pos="word" morph="none" start_char="1560" end_char="1562">dar</TOKEN>
<TOKEN id="token-3-57" pos="word" morph="none" start_char="1564" end_char="1568">aviso</TOKEN>
<TOKEN id="token-3-58" pos="word" morph="none" start_char="1570" end_char="1570">a</TOKEN>
<TOKEN id="token-3-59" pos="word" morph="none" start_char="1572" end_char="1574">las</TOKEN>
<TOKEN id="token-3-60" pos="word" morph="none" start_char="1576" end_char="1586">autoridades</TOKEN>
<TOKEN id="token-3-61" pos="word" morph="none" start_char="1588" end_char="1597">sanitarias</TOKEN>
<TOKEN id="token-3-62" pos="word" morph="none" start_char="1599" end_char="1600">de</TOKEN>
<TOKEN id="token-3-63" pos="word" morph="none" start_char="1602" end_char="1603">su</TOKEN>
<TOKEN id="token-3-64" pos="word" morph="none" start_char="1605" end_char="1608">país</TOKEN>
<TOKEN id="token-3-65" pos="punct" morph="none" start_char="1609" end_char="1609">,</TOKEN>
<TOKEN id="token-3-66" pos="word" morph="none" start_char="1611" end_char="1613">ese</TOKEN>
<TOKEN id="token-3-67" pos="word" morph="none" start_char="1615" end_char="1617">día</TOKEN>
<TOKEN id="token-3-68" pos="word" morph="none" start_char="1619" end_char="1621">los</TOKEN>
<TOKEN id="token-3-69" pos="word" morph="none" start_char="1623" end_char="1627">casos</TOKEN>
<TOKEN id="token-3-70" pos="word" morph="none" start_char="1629" end_char="1639">registrados</TOKEN>
<TOKEN id="token-3-71" pos="word" morph="none" start_char="1641" end_char="1644">eran</TOKEN>
<TOKEN id="token-3-72" pos="word" morph="none" start_char="1646" end_char="1648">180</TOKEN>
<TOKEN id="token-3-73" pos="word" morph="none" start_char="1650" end_char="1650">y</TOKEN>
<TOKEN id="token-3-74" pos="word" morph="none" start_char="1652" end_char="1655">para</TOKEN>
<TOKEN id="token-3-75" pos="word" morph="none" start_char="1657" end_char="1658">el</TOKEN>
<TOKEN id="token-3-76" pos="word" morph="none" start_char="1660" end_char="1665">inicio</TOKEN>
<TOKEN id="token-3-77" pos="word" morph="none" start_char="1667" end_char="1669">del</TOKEN>
<TOKEN id="token-3-78" pos="word" morph="none" start_char="1671" end_char="1674">2020</TOKEN>
<TOKEN id="token-3-79" pos="word" morph="none" start_char="1676" end_char="1683">subieron</TOKEN>
<TOKEN id="token-3-80" pos="word" morph="none" start_char="1685" end_char="1685">a</TOKEN>
<TOKEN id="token-3-81" pos="word" morph="none" start_char="1687" end_char="1689">381</TOKEN>
<TOKEN id="token-3-82" pos="punct" morph="none" start_char="1690" end_char="1690">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="1694" end_char="2212">
<ORIGINAL_TEXT>Gracias a la identificación de este llamado ‘paciente cero’ el origen de la enfermedad fue descubierto, ahora se sabe que pudo haber venido del consumo de un animal salvaje, esta información sin duda ha ayudado en las investigaciones, no solo para saber el origen del virus y su forma de afectar al cuerpo humano, también ha servido para apoyar el desarrollo de vacunas y medicamentos para tratarla, actualmente se dice que estamos cerca de obtener una vacuna que nos permita regresar a la ‘normalidad’ en algunos años.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="1694" end_char="1700">Gracias</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="1702" end_char="1702">a</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="1704" end_char="1705">la</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="1707" end_char="1720">identificación</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="1722" end_char="1723">de</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="1725" end_char="1728">este</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="1730" end_char="1736">llamado</TOKEN>
<TOKEN id="token-4-7" pos="punct" morph="none" start_char="1738" end_char="1738">‘</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="1739" end_char="1746">paciente</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="1748" end_char="1751">cero</TOKEN>
<TOKEN id="token-4-10" pos="punct" morph="none" start_char="1752" end_char="1752">’</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="1754" end_char="1755">el</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="1757" end_char="1762">origen</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="1764" end_char="1765">de</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="1767" end_char="1768">la</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="1770" end_char="1779">enfermedad</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="1781" end_char="1783">fue</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="1785" end_char="1795">descubierto</TOKEN>
<TOKEN id="token-4-18" pos="punct" morph="none" start_char="1796" end_char="1796">,</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="1798" end_char="1802">ahora</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="1804" end_char="1805">se</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="1807" end_char="1810">sabe</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="1812" end_char="1814">que</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="1816" end_char="1819">pudo</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="1821" end_char="1825">haber</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="1827" end_char="1832">venido</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="1834" end_char="1836">del</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="1838" end_char="1844">consumo</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="1846" end_char="1847">de</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="1849" end_char="1850">un</TOKEN>
<TOKEN id="token-4-30" pos="word" morph="none" start_char="1852" end_char="1857">animal</TOKEN>
<TOKEN id="token-4-31" pos="word" morph="none" start_char="1859" end_char="1865">salvaje</TOKEN>
<TOKEN id="token-4-32" pos="punct" morph="none" start_char="1866" end_char="1866">,</TOKEN>
<TOKEN id="token-4-33" pos="word" morph="none" start_char="1868" end_char="1871">esta</TOKEN>
<TOKEN id="token-4-34" pos="word" morph="none" start_char="1873" end_char="1883">información</TOKEN>
<TOKEN id="token-4-35" pos="word" morph="none" start_char="1885" end_char="1887">sin</TOKEN>
<TOKEN id="token-4-36" pos="word" morph="none" start_char="1889" end_char="1892">duda</TOKEN>
<TOKEN id="token-4-37" pos="word" morph="none" start_char="1894" end_char="1895">ha</TOKEN>
<TOKEN id="token-4-38" pos="word" morph="none" start_char="1897" end_char="1903">ayudado</TOKEN>
<TOKEN id="token-4-39" pos="word" morph="none" start_char="1905" end_char="1906">en</TOKEN>
<TOKEN id="token-4-40" pos="word" morph="none" start_char="1908" end_char="1910">las</TOKEN>
<TOKEN id="token-4-41" pos="word" morph="none" start_char="1912" end_char="1926">investigaciones</TOKEN>
<TOKEN id="token-4-42" pos="punct" morph="none" start_char="1927" end_char="1927">,</TOKEN>
<TOKEN id="token-4-43" pos="word" morph="none" start_char="1929" end_char="1930">no</TOKEN>
<TOKEN id="token-4-44" pos="word" morph="none" start_char="1932" end_char="1935">solo</TOKEN>
<TOKEN id="token-4-45" pos="word" morph="none" start_char="1937" end_char="1940">para</TOKEN>
<TOKEN id="token-4-46" pos="word" morph="none" start_char="1942" end_char="1946">saber</TOKEN>
<TOKEN id="token-4-47" pos="word" morph="none" start_char="1948" end_char="1949">el</TOKEN>
<TOKEN id="token-4-48" pos="word" morph="none" start_char="1951" end_char="1956">origen</TOKEN>
<TOKEN id="token-4-49" pos="word" morph="none" start_char="1958" end_char="1960">del</TOKEN>
<TOKEN id="token-4-50" pos="word" morph="none" start_char="1962" end_char="1966">virus</TOKEN>
<TOKEN id="token-4-51" pos="word" morph="none" start_char="1968" end_char="1968">y</TOKEN>
<TOKEN id="token-4-52" pos="word" morph="none" start_char="1970" end_char="1971">su</TOKEN>
<TOKEN id="token-4-53" pos="word" morph="none" start_char="1973" end_char="1977">forma</TOKEN>
<TOKEN id="token-4-54" pos="word" morph="none" start_char="1979" end_char="1980">de</TOKEN>
<TOKEN id="token-4-55" pos="word" morph="none" start_char="1982" end_char="1988">afectar</TOKEN>
<TOKEN id="token-4-56" pos="word" morph="none" start_char="1990" end_char="1991">al</TOKEN>
<TOKEN id="token-4-57" pos="word" morph="none" start_char="1993" end_char="1998">cuerpo</TOKEN>
<TOKEN id="token-4-58" pos="word" morph="none" start_char="2000" end_char="2005">humano</TOKEN>
<TOKEN id="token-4-59" pos="punct" morph="none" start_char="2006" end_char="2006">,</TOKEN>
<TOKEN id="token-4-60" pos="word" morph="none" start_char="2008" end_char="2014">también</TOKEN>
<TOKEN id="token-4-61" pos="word" morph="none" start_char="2016" end_char="2017">ha</TOKEN>
<TOKEN id="token-4-62" pos="word" morph="none" start_char="2019" end_char="2025">servido</TOKEN>
<TOKEN id="token-4-63" pos="word" morph="none" start_char="2027" end_char="2030">para</TOKEN>
<TOKEN id="token-4-64" pos="word" morph="none" start_char="2032" end_char="2037">apoyar</TOKEN>
<TOKEN id="token-4-65" pos="word" morph="none" start_char="2039" end_char="2040">el</TOKEN>
<TOKEN id="token-4-66" pos="word" morph="none" start_char="2042" end_char="2051">desarrollo</TOKEN>
<TOKEN id="token-4-67" pos="word" morph="none" start_char="2053" end_char="2054">de</TOKEN>
<TOKEN id="token-4-68" pos="word" morph="none" start_char="2056" end_char="2062">vacunas</TOKEN>
<TOKEN id="token-4-69" pos="word" morph="none" start_char="2064" end_char="2064">y</TOKEN>
<TOKEN id="token-4-70" pos="word" morph="none" start_char="2066" end_char="2077">medicamentos</TOKEN>
<TOKEN id="token-4-71" pos="word" morph="none" start_char="2079" end_char="2082">para</TOKEN>
<TOKEN id="token-4-72" pos="word" morph="none" start_char="2084" end_char="2091">tratarla</TOKEN>
<TOKEN id="token-4-73" pos="punct" morph="none" start_char="2092" end_char="2092">,</TOKEN>
<TOKEN id="token-4-74" pos="word" morph="none" start_char="2094" end_char="2104">actualmente</TOKEN>
<TOKEN id="token-4-75" pos="word" morph="none" start_char="2106" end_char="2107">se</TOKEN>
<TOKEN id="token-4-76" pos="word" morph="none" start_char="2109" end_char="2112">dice</TOKEN>
<TOKEN id="token-4-77" pos="word" morph="none" start_char="2114" end_char="2116">que</TOKEN>
<TOKEN id="token-4-78" pos="word" morph="none" start_char="2118" end_char="2124">estamos</TOKEN>
<TOKEN id="token-4-79" pos="word" morph="none" start_char="2126" end_char="2130">cerca</TOKEN>
<TOKEN id="token-4-80" pos="word" morph="none" start_char="2132" end_char="2133">de</TOKEN>
<TOKEN id="token-4-81" pos="word" morph="none" start_char="2135" end_char="2141">obtener</TOKEN>
<TOKEN id="token-4-82" pos="word" morph="none" start_char="2143" end_char="2145">una</TOKEN>
<TOKEN id="token-4-83" pos="word" morph="none" start_char="2147" end_char="2152">vacuna</TOKEN>
<TOKEN id="token-4-84" pos="word" morph="none" start_char="2154" end_char="2156">que</TOKEN>
<TOKEN id="token-4-85" pos="word" morph="none" start_char="2158" end_char="2160">nos</TOKEN>
<TOKEN id="token-4-86" pos="word" morph="none" start_char="2162" end_char="2168">permita</TOKEN>
<TOKEN id="token-4-87" pos="word" morph="none" start_char="2170" end_char="2177">regresar</TOKEN>
<TOKEN id="token-4-88" pos="word" morph="none" start_char="2179" end_char="2179">a</TOKEN>
<TOKEN id="token-4-89" pos="word" morph="none" start_char="2181" end_char="2182">la</TOKEN>
<TOKEN id="token-4-90" pos="punct" morph="none" start_char="2184" end_char="2184">‘</TOKEN>
<TOKEN id="token-4-91" pos="word" morph="none" start_char="2185" end_char="2194">normalidad</TOKEN>
<TOKEN id="token-4-92" pos="punct" morph="none" start_char="2195" end_char="2195">’</TOKEN>
<TOKEN id="token-4-93" pos="word" morph="none" start_char="2197" end_char="2198">en</TOKEN>
<TOKEN id="token-4-94" pos="word" morph="none" start_char="2200" end_char="2206">algunos</TOKEN>
<TOKEN id="token-4-95" pos="word" morph="none" start_char="2208" end_char="2211">años</TOKEN>
<TOKEN id="token-4-96" pos="punct" morph="none" start_char="2212" end_char="2212">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="2215" end_char="2215">
<ORIGINAL_TEXT>​</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="unknown" morph="none" start_char="2215" end_char="2215">​</TOKEN>
</SEG>
<SEG id="segment-6" start_char="2218" end_char="2218">
<ORIGINAL_TEXT>​</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="unknown" morph="none" start_char="2218" end_char="2218">​</TOKEN>
</SEG>
<SEG id="segment-7" start_char="2221" end_char="2221">
<ORIGINAL_TEXT>​</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="unknown" morph="none" start_char="2221" end_char="2221">​</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
