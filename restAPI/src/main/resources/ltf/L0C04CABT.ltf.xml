<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CABT" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="5092" raw_text_md5="1cb9bd41f4495c7d30b4cecd3241ea6f">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="110">
<ORIGINAL_TEXT>The first COVID-19 case originated on November 17, according to Chinese officials searching for 'patient zero'</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="3">The</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="5" end_char="9">first</TOKEN>
<TOKEN id="token-0-2" pos="unknown" morph="none" start_char="11" end_char="18">COVID-19</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="20" end_char="23">case</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="25" end_char="34">originated</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="36" end_char="37">on</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="39" end_char="46">November</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="48" end_char="49">17</TOKEN>
<TOKEN id="token-0-8" pos="punct" morph="none" start_char="50" end_char="50">,</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="52" end_char="60">according</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="62" end_char="63">to</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="65" end_char="71">Chinese</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="73" end_char="81">officials</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="83" end_char="91">searching</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="93" end_char="95">for</TOKEN>
<TOKEN id="token-0-15" pos="punct" morph="none" start_char="97" end_char="97">'</TOKEN>
<TOKEN id="token-0-16" pos="word" morph="none" start_char="98" end_char="104">patient</TOKEN>
<TOKEN id="token-0-17" pos="word" morph="none" start_char="106" end_char="109">zero</TOKEN>
<TOKEN id="token-0-18" pos="punct" morph="none" start_char="110" end_char="110">'</TOKEN>
</SEG>
<SEG id="segment-1" start_char="115" end_char="183">
<ORIGINAL_TEXT>The novel coronavirus under colored transmission electron microscopy.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="115" end_char="117">The</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="119" end_char="123">novel</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="125" end_char="135">coronavirus</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="137" end_char="141">under</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="143" end_char="149">colored</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="151" end_char="162">transmission</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="164" end_char="171">electron</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="173" end_char="182">microscopy</TOKEN>
<TOKEN id="token-1-8" pos="punct" morph="none" start_char="183" end_char="183">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="186" end_char="210">
<ORIGINAL_TEXT>BSIP/UIG Via Getty Images</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="unknown" morph="none" start_char="186" end_char="193">BSIP/UIG</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="195" end_char="197">Via</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="199" end_char="203">Getty</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="205" end_char="210">Images</TOKEN>
</SEG>
<SEG id="segment-3" start_char="214" end_char="351">
<ORIGINAL_TEXT>The first case of the novel coronavirus emerged on November 17, according to Chinese government data reviewed by South China Morning Post.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="214" end_char="216">The</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="218" end_char="222">first</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="224" end_char="227">case</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="229" end_char="230">of</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="232" end_char="234">the</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="236" end_char="240">novel</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="242" end_char="252">coronavirus</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="254" end_char="260">emerged</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="262" end_char="263">on</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="265" end_char="272">November</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="274" end_char="275">17</TOKEN>
<TOKEN id="token-3-11" pos="punct" morph="none" start_char="276" end_char="276">,</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="278" end_char="286">according</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="288" end_char="289">to</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="291" end_char="297">Chinese</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="299" end_char="308">government</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="310" end_char="313">data</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="315" end_char="322">reviewed</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="324" end_char="325">by</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="327" end_char="331">South</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="333" end_char="337">China</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="339" end_char="345">Morning</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="347" end_char="350">Post</TOKEN>
<TOKEN id="token-3-23" pos="punct" morph="none" start_char="351" end_char="351">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="354" end_char="478">
<ORIGINAL_TEXT>The identity of the person has not been confirmed, but it appears to be a 55-year-old from the Hubei province, the Post said.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="354" end_char="356">The</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="358" end_char="365">identity</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="367" end_char="368">of</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="370" end_char="372">the</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="374" end_char="379">person</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="381" end_char="383">has</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="385" end_char="387">not</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="389" end_char="392">been</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="394" end_char="402">confirmed</TOKEN>
<TOKEN id="token-4-9" pos="punct" morph="none" start_char="403" end_char="403">,</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="405" end_char="407">but</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="409" end_char="410">it</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="412" end_char="418">appears</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="420" end_char="421">to</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="423" end_char="424">be</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="426" end_char="426">a</TOKEN>
<TOKEN id="token-4-16" pos="unknown" morph="none" start_char="428" end_char="438">55-year-old</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="440" end_char="443">from</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="445" end_char="447">the</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="449" end_char="453">Hubei</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="455" end_char="462">province</TOKEN>
<TOKEN id="token-4-21" pos="punct" morph="none" start_char="463" end_char="463">,</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="465" end_char="467">the</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="469" end_char="472">Post</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="474" end_char="477">said</TOKEN>
<TOKEN id="token-4-25" pos="punct" morph="none" start_char="478" end_char="478">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="481" end_char="583">
<ORIGINAL_TEXT>It wasn't until December that Chinese authorities realized they had a new type of virus on their hands.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="481" end_char="482">It</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="484" end_char="489">wasn't</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="491" end_char="495">until</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="497" end_char="504">December</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="506" end_char="509">that</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="511" end_char="517">Chinese</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="519" end_char="529">authorities</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="531" end_char="538">realized</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="540" end_char="543">they</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="545" end_char="547">had</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="549" end_char="549">a</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="551" end_char="553">new</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="555" end_char="558">type</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="560" end_char="561">of</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="563" end_char="567">virus</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="569" end_char="570">on</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="572" end_char="576">their</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="578" end_char="582">hands</TOKEN>
<TOKEN id="token-5-18" pos="punct" morph="none" start_char="583" end_char="583">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="586" end_char="636">
<ORIGINAL_TEXT>Visit Business Insider's homepage for more stories.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="586" end_char="590">Visit</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="592" end_char="599">Business</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="601" end_char="609">Insider's</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="611" end_char="618">homepage</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="620" end_char="622">for</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="624" end_char="627">more</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="629" end_char="635">stories</TOKEN>
<TOKEN id="token-6-7" pos="punct" morph="none" start_char="636" end_char="636">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="640" end_char="781">
<ORIGINAL_TEXT>The first case of the novel coronavirus emerged on November 17, according to Chinese government data reviewed by the South China Morning Post.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="640" end_char="642">The</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="644" end_char="648">first</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="650" end_char="653">case</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="655" end_char="656">of</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="658" end_char="660">the</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="662" end_char="666">novel</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="668" end_char="678">coronavirus</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="680" end_char="686">emerged</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="688" end_char="689">on</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="691" end_char="698">November</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="700" end_char="701">17</TOKEN>
<TOKEN id="token-7-11" pos="punct" morph="none" start_char="702" end_char="702">,</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="704" end_char="712">according</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="714" end_char="715">to</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="717" end_char="723">Chinese</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="725" end_char="734">government</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="736" end_char="739">data</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="741" end_char="748">reviewed</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="750" end_char="751">by</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="753" end_char="755">the</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="757" end_char="761">South</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="763" end_char="767">China</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="769" end_char="775">Morning</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="777" end_char="780">Post</TOKEN>
<TOKEN id="token-7-24" pos="punct" morph="none" start_char="781" end_char="781">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="784" end_char="881">
<ORIGINAL_TEXT>It wasn't until late December that Chinese officials realized they had a new virus on their hands.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="784" end_char="785">It</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="787" end_char="792">wasn't</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="794" end_char="798">until</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="800" end_char="803">late</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="805" end_char="812">December</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="814" end_char="817">that</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="819" end_char="825">Chinese</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="827" end_char="835">officials</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="837" end_char="844">realized</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="846" end_char="849">they</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="851" end_char="853">had</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="855" end_char="855">a</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="857" end_char="859">new</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="861" end_char="865">virus</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="867" end_char="868">on</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="870" end_char="874">their</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="876" end_char="880">hands</TOKEN>
<TOKEN id="token-8-17" pos="punct" morph="none" start_char="881" end_char="881">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="883" end_char="1015">
<ORIGINAL_TEXT>But even then, China's government clamped down on sharing information about it with the public, according to The Wall Street Journal.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="883" end_char="885">But</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="887" end_char="890">even</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="892" end_char="895">then</TOKEN>
<TOKEN id="token-9-3" pos="punct" morph="none" start_char="896" end_char="896">,</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="898" end_char="904">China's</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="906" end_char="915">government</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="917" end_char="923">clamped</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="925" end_char="928">down</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="930" end_char="931">on</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="933" end_char="939">sharing</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="941" end_char="951">information</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="953" end_char="957">about</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="959" end_char="960">it</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="962" end_char="965">with</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="967" end_char="969">the</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="971" end_char="976">public</TOKEN>
<TOKEN id="token-9-16" pos="punct" morph="none" start_char="977" end_char="977">,</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="979" end_char="987">according</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="989" end_char="990">to</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="992" end_char="994">The</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="996" end_char="999">Wall</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1001" end_char="1006">Street</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1008" end_char="1014">Journal</TOKEN>
<TOKEN id="token-9-23" pos="punct" morph="none" start_char="1015" end_char="1015">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1018" end_char="1180">
<ORIGINAL_TEXT>The Post said the data it reviewed, which has not been made public, suggested that the virus was first contracted by a 55-year-old man from China's Hubei province.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1018" end_char="1020">The</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1022" end_char="1025">Post</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1027" end_char="1030">said</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1032" end_char="1034">the</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1036" end_char="1039">data</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1041" end_char="1042">it</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1044" end_char="1051">reviewed</TOKEN>
<TOKEN id="token-10-7" pos="punct" morph="none" start_char="1052" end_char="1052">,</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1054" end_char="1058">which</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1060" end_char="1062">has</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1064" end_char="1066">not</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1068" end_char="1071">been</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1073" end_char="1076">made</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1078" end_char="1083">public</TOKEN>
<TOKEN id="token-10-14" pos="punct" morph="none" start_char="1084" end_char="1084">,</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1086" end_char="1094">suggested</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1096" end_char="1099">that</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1101" end_char="1103">the</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1105" end_char="1109">virus</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1111" end_char="1113">was</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1115" end_char="1119">first</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1121" end_char="1130">contracted</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1132" end_char="1133">by</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1135" end_char="1135">a</TOKEN>
<TOKEN id="token-10-24" pos="unknown" morph="none" start_char="1137" end_char="1147">55-year-old</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="1149" end_char="1151">man</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="1153" end_char="1156">from</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="1158" end_char="1164">China's</TOKEN>
<TOKEN id="token-10-28" pos="word" morph="none" start_char="1166" end_char="1170">Hubei</TOKEN>
<TOKEN id="token-10-29" pos="word" morph="none" start_char="1172" end_char="1179">province</TOKEN>
<TOKEN id="token-10-30" pos="punct" morph="none" start_char="1180" end_char="1180">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1183" end_char="1241">
<ORIGINAL_TEXT>But as the newspaper noted, the evidence is not conclusive.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1183" end_char="1185">But</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1187" end_char="1188">as</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1190" end_char="1192">the</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1194" end_char="1202">newspaper</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1204" end_char="1208">noted</TOKEN>
<TOKEN id="token-11-5" pos="punct" morph="none" start_char="1209" end_char="1209">,</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1211" end_char="1213">the</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1215" end_char="1222">evidence</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1224" end_char="1225">is</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1227" end_char="1229">not</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1231" end_char="1240">conclusive</TOKEN>
<TOKEN id="token-11-11" pos="punct" morph="none" start_char="1241" end_char="1241">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1243" end_char="1392">
<ORIGINAL_TEXT>The identity of "patient zero" — the first human case of the virus — has still not been confirmed, and it's possible that the data set isn't complete.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1243" end_char="1245">The</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1247" end_char="1254">identity</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1256" end_char="1257">of</TOKEN>
<TOKEN id="token-12-3" pos="punct" morph="none" start_char="1259" end_char="1259">"</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1260" end_char="1266">patient</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1268" end_char="1271">zero</TOKEN>
<TOKEN id="token-12-6" pos="punct" morph="none" start_char="1272" end_char="1272">"</TOKEN>
<TOKEN id="token-12-7" pos="punct" morph="none" start_char="1274" end_char="1274">—</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1276" end_char="1278">the</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1280" end_char="1284">first</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1286" end_char="1290">human</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1292" end_char="1295">case</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1297" end_char="1298">of</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1300" end_char="1302">the</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1304" end_char="1308">virus</TOKEN>
<TOKEN id="token-12-15" pos="punct" morph="none" start_char="1310" end_char="1310">—</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1312" end_char="1314">has</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1316" end_char="1320">still</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1322" end_char="1324">not</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1326" end_char="1329">been</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1331" end_char="1339">confirmed</TOKEN>
<TOKEN id="token-12-21" pos="punct" morph="none" start_char="1340" end_char="1340">,</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1342" end_char="1344">and</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="1346" end_char="1349">it's</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="1351" end_char="1358">possible</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="1360" end_char="1363">that</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="1365" end_char="1367">the</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="1369" end_char="1372">data</TOKEN>
<TOKEN id="token-12-28" pos="word" morph="none" start_char="1374" end_char="1376">set</TOKEN>
<TOKEN id="token-12-29" pos="word" morph="none" start_char="1378" end_char="1382">isn't</TOKEN>
<TOKEN id="token-12-30" pos="word" morph="none" start_char="1384" end_char="1391">complete</TOKEN>
<TOKEN id="token-12-31" pos="punct" morph="none" start_char="1392" end_char="1392">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1395" end_char="1404">
<ORIGINAL_TEXT>Newsletter</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1395" end_char="1404">Newsletter</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1407" end_char="1474">
<ORIGINAL_TEXT>Start your day with the biggest stories in politics and the economy.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1407" end_char="1411">Start</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1413" end_char="1416">your</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1418" end_char="1420">day</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1422" end_char="1425">with</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1427" end_char="1429">the</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1431" end_char="1437">biggest</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1439" end_char="1445">stories</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1447" end_char="1448">in</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1450" end_char="1457">politics</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1459" end_char="1461">and</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1463" end_char="1465">the</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1467" end_char="1473">economy</TOKEN>
<TOKEN id="token-14-12" pos="punct" morph="none" start_char="1474" end_char="1474">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1476" end_char="1509">
<ORIGINAL_TEXT>Sign up for 10 Things in Politics.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1476" end_char="1479">Sign</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1481" end_char="1482">up</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1484" end_char="1486">for</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1488" end_char="1489">10</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1491" end_char="1496">Things</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1498" end_char="1499">in</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1501" end_char="1508">Politics</TOKEN>
<TOKEN id="token-15-7" pos="punct" morph="none" start_char="1509" end_char="1509">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1512" end_char="1532">
<ORIGINAL_TEXT>Something is loading.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1512" end_char="1520">Something</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1522" end_char="1523">is</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1525" end_char="1531">loading</TOKEN>
<TOKEN id="token-16-3" pos="punct" morph="none" start_char="1532" end_char="1532">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1536" end_char="1548">
<ORIGINAL_TEXT>Email address</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1536" end_char="1540">Email</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1542" end_char="1548">address</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1551" end_char="1707">
<ORIGINAL_TEXT>By clicking ‘Sign up’, you agree to receive marketing emails from Insider as well as other partner offers and accept our Terms of Service and Privacy Policy.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="1551" end_char="1552">By</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="1554" end_char="1561">clicking</TOKEN>
<TOKEN id="token-18-2" pos="punct" morph="none" start_char="1563" end_char="1563">‘</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="1564" end_char="1567">Sign</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="1569" end_char="1570">up</TOKEN>
<TOKEN id="token-18-5" pos="punct" morph="none" start_char="1571" end_char="1572">’,</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="1574" end_char="1576">you</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="1578" end_char="1582">agree</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="1584" end_char="1585">to</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="1587" end_char="1593">receive</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="1595" end_char="1603">marketing</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="1605" end_char="1610">emails</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="1612" end_char="1615">from</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="1617" end_char="1623">Insider</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="1625" end_char="1626">as</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="1628" end_char="1631">well</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="1633" end_char="1634">as</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="1636" end_char="1640">other</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="1642" end_char="1648">partner</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="1650" end_char="1655">offers</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="1657" end_char="1659">and</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="1661" end_char="1666">accept</TOKEN>
<TOKEN id="token-18-22" pos="word" morph="none" start_char="1668" end_char="1670">our</TOKEN>
<TOKEN id="token-18-23" pos="word" morph="none" start_char="1672" end_char="1676">Terms</TOKEN>
<TOKEN id="token-18-24" pos="word" morph="none" start_char="1678" end_char="1679">of</TOKEN>
<TOKEN id="token-18-25" pos="word" morph="none" start_char="1681" end_char="1687">Service</TOKEN>
<TOKEN id="token-18-26" pos="word" morph="none" start_char="1689" end_char="1691">and</TOKEN>
<TOKEN id="token-18-27" pos="word" morph="none" start_char="1693" end_char="1699">Privacy</TOKEN>
<TOKEN id="token-18-28" pos="word" morph="none" start_char="1701" end_char="1706">Policy</TOKEN>
<TOKEN id="token-18-29" pos="punct" morph="none" start_char="1707" end_char="1707">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="1710" end_char="1772">
<ORIGINAL_TEXT>New data about 'patient zero' is consistent with other research</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="1710" end_char="1712">New</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="1714" end_char="1717">data</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="1719" end_char="1723">about</TOKEN>
<TOKEN id="token-19-3" pos="punct" morph="none" start_char="1725" end_char="1725">'</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="1726" end_char="1732">patient</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="1734" end_char="1737">zero</TOKEN>
<TOKEN id="token-19-6" pos="punct" morph="none" start_char="1738" end_char="1738">'</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="1740" end_char="1741">is</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="1743" end_char="1752">consistent</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="1754" end_char="1757">with</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="1759" end_char="1763">other</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="1765" end_char="1772">research</TOKEN>
</SEG>
<SEG id="segment-20" start_char="1776" end_char="1926">
<ORIGINAL_TEXT>Chinese health authorities reported the first case of COVID-19, the illness caused by the coronavirus, to the World Health Organization on December 31.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="1776" end_char="1782">Chinese</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="1784" end_char="1789">health</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="1791" end_char="1801">authorities</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="1803" end_char="1810">reported</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="1812" end_char="1814">the</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="1816" end_char="1820">first</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="1822" end_char="1825">case</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="1827" end_char="1828">of</TOKEN>
<TOKEN id="token-20-8" pos="unknown" morph="none" start_char="1830" end_char="1837">COVID-19</TOKEN>
<TOKEN id="token-20-9" pos="punct" morph="none" start_char="1838" end_char="1838">,</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="1840" end_char="1842">the</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="1844" end_char="1850">illness</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="1852" end_char="1857">caused</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="1859" end_char="1860">by</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="1862" end_char="1864">the</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="1866" end_char="1876">coronavirus</TOKEN>
<TOKEN id="token-20-16" pos="punct" morph="none" start_char="1877" end_char="1877">,</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="1879" end_char="1880">to</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="1882" end_char="1884">the</TOKEN>
<TOKEN id="token-20-19" pos="word" morph="none" start_char="1886" end_char="1890">World</TOKEN>
<TOKEN id="token-20-20" pos="word" morph="none" start_char="1892" end_char="1897">Health</TOKEN>
<TOKEN id="token-20-21" pos="word" morph="none" start_char="1899" end_char="1910">Organization</TOKEN>
<TOKEN id="token-20-22" pos="word" morph="none" start_char="1912" end_char="1913">on</TOKEN>
<TOKEN id="token-20-23" pos="word" morph="none" start_char="1915" end_char="1922">December</TOKEN>
<TOKEN id="token-20-24" pos="word" morph="none" start_char="1924" end_char="1925">31</TOKEN>
<TOKEN id="token-20-25" pos="punct" morph="none" start_char="1926" end_char="1926">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="1929" end_char="2087">
<ORIGINAL_TEXT>A team of researchers later published evidence that the first person to test positive was showing symptoms on December 8, the date of the first confirmed case.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="1929" end_char="1929">A</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="1931" end_char="1934">team</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="1936" end_char="1937">of</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="1939" end_char="1949">researchers</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="1951" end_char="1955">later</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="1957" end_char="1965">published</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="1967" end_char="1974">evidence</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="1976" end_char="1979">that</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="1981" end_char="1983">the</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="1985" end_char="1989">first</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="1991" end_char="1996">person</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="1998" end_char="1999">to</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="2001" end_char="2004">test</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="2006" end_char="2013">positive</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="2015" end_char="2017">was</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="2019" end_char="2025">showing</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="2027" end_char="2034">symptoms</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="2036" end_char="2037">on</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="2039" end_char="2046">December</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="2048" end_char="2048">8</TOKEN>
<TOKEN id="token-21-20" pos="punct" morph="none" start_char="2049" end_char="2049">,</TOKEN>
<TOKEN id="token-21-21" pos="word" morph="none" start_char="2051" end_char="2053">the</TOKEN>
<TOKEN id="token-21-22" pos="word" morph="none" start_char="2055" end_char="2058">date</TOKEN>
<TOKEN id="token-21-23" pos="word" morph="none" start_char="2060" end_char="2061">of</TOKEN>
<TOKEN id="token-21-24" pos="word" morph="none" start_char="2063" end_char="2065">the</TOKEN>
<TOKEN id="token-21-25" pos="word" morph="none" start_char="2067" end_char="2071">first</TOKEN>
<TOKEN id="token-21-26" pos="word" morph="none" start_char="2073" end_char="2081">confirmed</TOKEN>
<TOKEN id="token-21-27" pos="word" morph="none" start_char="2083" end_char="2086">case</TOKEN>
<TOKEN id="token-21-28" pos="punct" morph="none" start_char="2087" end_char="2087">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2090" end_char="2223">
<ORIGINAL_TEXT>Other research published in The Lancet in January found that the first person to test positive was exposed to the virus on December 1.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2090" end_char="2094">Other</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2096" end_char="2103">research</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2105" end_char="2113">published</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2115" end_char="2116">in</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2118" end_char="2120">The</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2122" end_char="2127">Lancet</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2129" end_char="2130">in</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2132" end_char="2138">January</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="2140" end_char="2144">found</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="2146" end_char="2149">that</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="2151" end_char="2153">the</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="2155" end_char="2159">first</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="2161" end_char="2166">person</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="2168" end_char="2169">to</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="2171" end_char="2174">test</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="2176" end_char="2183">positive</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="2185" end_char="2187">was</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="2189" end_char="2195">exposed</TOKEN>
<TOKEN id="token-22-18" pos="word" morph="none" start_char="2197" end_char="2198">to</TOKEN>
<TOKEN id="token-22-19" pos="word" morph="none" start_char="2200" end_char="2202">the</TOKEN>
<TOKEN id="token-22-20" pos="word" morph="none" start_char="2204" end_char="2208">virus</TOKEN>
<TOKEN id="token-22-21" pos="word" morph="none" start_char="2210" end_char="2211">on</TOKEN>
<TOKEN id="token-22-22" pos="word" morph="none" start_char="2213" end_char="2220">December</TOKEN>
<TOKEN id="token-22-23" pos="word" morph="none" start_char="2222" end_char="2222">1</TOKEN>
<TOKEN id="token-22-24" pos="punct" morph="none" start_char="2223" end_char="2223">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2226" end_char="2473">
<ORIGINAL_TEXT>The fact that researchers have continually hiked back the likely date of the earliest infection means there still may not be enough evidence to identify "patient zero," but the new Chinese government data reported by the Post sharpens what we know.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2226" end_char="2228">The</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2230" end_char="2233">fact</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2235" end_char="2238">that</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2240" end_char="2250">researchers</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="2252" end_char="2255">have</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="2257" end_char="2267">continually</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="2269" end_char="2273">hiked</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="2275" end_char="2278">back</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="2280" end_char="2282">the</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="2284" end_char="2289">likely</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="2291" end_char="2294">date</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="2296" end_char="2297">of</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="2299" end_char="2301">the</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="2303" end_char="2310">earliest</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="2312" end_char="2320">infection</TOKEN>
<TOKEN id="token-23-15" pos="word" morph="none" start_char="2322" end_char="2326">means</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="2328" end_char="2332">there</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="2334" end_char="2338">still</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="2340" end_char="2342">may</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="2344" end_char="2346">not</TOKEN>
<TOKEN id="token-23-20" pos="word" morph="none" start_char="2348" end_char="2349">be</TOKEN>
<TOKEN id="token-23-21" pos="word" morph="none" start_char="2351" end_char="2356">enough</TOKEN>
<TOKEN id="token-23-22" pos="word" morph="none" start_char="2358" end_char="2365">evidence</TOKEN>
<TOKEN id="token-23-23" pos="word" morph="none" start_char="2367" end_char="2368">to</TOKEN>
<TOKEN id="token-23-24" pos="word" morph="none" start_char="2370" end_char="2377">identify</TOKEN>
<TOKEN id="token-23-25" pos="punct" morph="none" start_char="2379" end_char="2379">"</TOKEN>
<TOKEN id="token-23-26" pos="word" morph="none" start_char="2380" end_char="2386">patient</TOKEN>
<TOKEN id="token-23-27" pos="word" morph="none" start_char="2388" end_char="2391">zero</TOKEN>
<TOKEN id="token-23-28" pos="punct" morph="none" start_char="2392" end_char="2393">,"</TOKEN>
<TOKEN id="token-23-29" pos="word" morph="none" start_char="2395" end_char="2397">but</TOKEN>
<TOKEN id="token-23-30" pos="word" morph="none" start_char="2399" end_char="2401">the</TOKEN>
<TOKEN id="token-23-31" pos="word" morph="none" start_char="2403" end_char="2405">new</TOKEN>
<TOKEN id="token-23-32" pos="word" morph="none" start_char="2407" end_char="2413">Chinese</TOKEN>
<TOKEN id="token-23-33" pos="word" morph="none" start_char="2415" end_char="2424">government</TOKEN>
<TOKEN id="token-23-34" pos="word" morph="none" start_char="2426" end_char="2429">data</TOKEN>
<TOKEN id="token-23-35" pos="word" morph="none" start_char="2431" end_char="2438">reported</TOKEN>
<TOKEN id="token-23-36" pos="word" morph="none" start_char="2440" end_char="2441">by</TOKEN>
<TOKEN id="token-23-37" pos="word" morph="none" start_char="2443" end_char="2445">the</TOKEN>
<TOKEN id="token-23-38" pos="word" morph="none" start_char="2447" end_char="2450">Post</TOKEN>
<TOKEN id="token-23-39" pos="word" morph="none" start_char="2452" end_char="2459">sharpens</TOKEN>
<TOKEN id="token-23-40" pos="word" morph="none" start_char="2461" end_char="2464">what</TOKEN>
<TOKEN id="token-23-41" pos="word" morph="none" start_char="2466" end_char="2467">we</TOKEN>
<TOKEN id="token-23-42" pos="word" morph="none" start_char="2469" end_char="2472">know</TOKEN>
<TOKEN id="token-23-43" pos="punct" morph="none" start_char="2473" end_char="2473">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2477" end_char="2561">
<ORIGINAL_TEXT>A doctor examines a patient with the novel coronavirus at a hospital in Wuhan, China.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="2477" end_char="2477">A</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="2479" end_char="2484">doctor</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="2486" end_char="2493">examines</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="2495" end_char="2495">a</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="2497" end_char="2503">patient</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="2505" end_char="2508">with</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="2510" end_char="2512">the</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="2514" end_char="2518">novel</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="2520" end_char="2530">coronavirus</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="2532" end_char="2533">at</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="2535" end_char="2535">a</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="2537" end_char="2544">hospital</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="2546" end_char="2547">in</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="2549" end_char="2553">Wuhan</TOKEN>
<TOKEN id="token-24-14" pos="punct" morph="none" start_char="2554" end_char="2554">,</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="2556" end_char="2560">China</TOKEN>
<TOKEN id="token-24-16" pos="punct" morph="none" start_char="2561" end_char="2561">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2564" end_char="2587">
<ORIGINAL_TEXT>STR/AFP via Getty Images</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="unknown" morph="none" start_char="2564" end_char="2570">STR/AFP</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="2572" end_char="2574">via</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="2576" end_char="2580">Getty</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="2582" end_char="2587">Images</TOKEN>
</SEG>
<SEG id="segment-26" start_char="2591" end_char="2823">
<ORIGINAL_TEXT>Research published last month by a team of infectious-disease researchers from China found that WeChat users were using terms related to symptoms of the novel coronavirus more than two weeks before officials confirmed the first case.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="2591" end_char="2598">Research</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="2600" end_char="2608">published</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="2610" end_char="2613">last</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="2615" end_char="2619">month</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="2621" end_char="2622">by</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="2624" end_char="2624">a</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="2626" end_char="2629">team</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="2631" end_char="2632">of</TOKEN>
<TOKEN id="token-26-8" pos="unknown" morph="none" start_char="2634" end_char="2651">infectious-disease</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="2653" end_char="2663">researchers</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="2665" end_char="2668">from</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="2670" end_char="2674">China</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="2676" end_char="2680">found</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="2682" end_char="2685">that</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="2687" end_char="2692">WeChat</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="2694" end_char="2698">users</TOKEN>
<TOKEN id="token-26-16" pos="word" morph="none" start_char="2700" end_char="2703">were</TOKEN>
<TOKEN id="token-26-17" pos="word" morph="none" start_char="2705" end_char="2709">using</TOKEN>
<TOKEN id="token-26-18" pos="word" morph="none" start_char="2711" end_char="2715">terms</TOKEN>
<TOKEN id="token-26-19" pos="word" morph="none" start_char="2717" end_char="2723">related</TOKEN>
<TOKEN id="token-26-20" pos="word" morph="none" start_char="2725" end_char="2726">to</TOKEN>
<TOKEN id="token-26-21" pos="word" morph="none" start_char="2728" end_char="2735">symptoms</TOKEN>
<TOKEN id="token-26-22" pos="word" morph="none" start_char="2737" end_char="2738">of</TOKEN>
<TOKEN id="token-26-23" pos="word" morph="none" start_char="2740" end_char="2742">the</TOKEN>
<TOKEN id="token-26-24" pos="word" morph="none" start_char="2744" end_char="2748">novel</TOKEN>
<TOKEN id="token-26-25" pos="word" morph="none" start_char="2750" end_char="2760">coronavirus</TOKEN>
<TOKEN id="token-26-26" pos="word" morph="none" start_char="2762" end_char="2765">more</TOKEN>
<TOKEN id="token-26-27" pos="word" morph="none" start_char="2767" end_char="2770">than</TOKEN>
<TOKEN id="token-26-28" pos="word" morph="none" start_char="2772" end_char="2774">two</TOKEN>
<TOKEN id="token-26-29" pos="word" morph="none" start_char="2776" end_char="2780">weeks</TOKEN>
<TOKEN id="token-26-30" pos="word" morph="none" start_char="2782" end_char="2787">before</TOKEN>
<TOKEN id="token-26-31" pos="word" morph="none" start_char="2789" end_char="2797">officials</TOKEN>
<TOKEN id="token-26-32" pos="word" morph="none" start_char="2799" end_char="2807">confirmed</TOKEN>
<TOKEN id="token-26-33" pos="word" morph="none" start_char="2809" end_char="2811">the</TOKEN>
<TOKEN id="token-26-34" pos="word" morph="none" start_char="2813" end_char="2817">first</TOKEN>
<TOKEN id="token-26-35" pos="word" morph="none" start_char="2819" end_char="2822">case</TOKEN>
<TOKEN id="token-26-36" pos="punct" morph="none" start_char="2823" end_char="2823">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="2826" end_char="3002">
<ORIGINAL_TEXT>"The findings might indicate that the coronavirus started circulating weeks before the first cases were officially diagnosed and reported," Business Insider's Holly Secon wrote.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="punct" morph="none" start_char="2826" end_char="2826">"</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="2827" end_char="2829">The</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="2831" end_char="2838">findings</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="2840" end_char="2844">might</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="2846" end_char="2853">indicate</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="2855" end_char="2858">that</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="2860" end_char="2862">the</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="2864" end_char="2874">coronavirus</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="2876" end_char="2882">started</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="2884" end_char="2894">circulating</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="2896" end_char="2900">weeks</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="2902" end_char="2907">before</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="2909" end_char="2911">the</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="2913" end_char="2917">first</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="2919" end_char="2923">cases</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="2925" end_char="2928">were</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="2930" end_char="2939">officially</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="2941" end_char="2949">diagnosed</TOKEN>
<TOKEN id="token-27-18" pos="word" morph="none" start_char="2951" end_char="2953">and</TOKEN>
<TOKEN id="token-27-19" pos="word" morph="none" start_char="2955" end_char="2962">reported</TOKEN>
<TOKEN id="token-27-20" pos="punct" morph="none" start_char="2963" end_char="2964">,"</TOKEN>
<TOKEN id="token-27-21" pos="word" morph="none" start_char="2966" end_char="2973">Business</TOKEN>
<TOKEN id="token-27-22" pos="word" morph="none" start_char="2975" end_char="2983">Insider's</TOKEN>
<TOKEN id="token-27-23" pos="word" morph="none" start_char="2985" end_char="2989">Holly</TOKEN>
<TOKEN id="token-27-24" pos="word" morph="none" start_char="2991" end_char="2995">Secon</TOKEN>
<TOKEN id="token-27-25" pos="word" morph="none" start_char="2997" end_char="3001">wrote</TOKEN>
<TOKEN id="token-27-26" pos="punct" morph="none" start_char="3002" end_char="3002">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3005" end_char="3139">
<ORIGINAL_TEXT>The research lends further support to the finding that the earliest case of the novel coronavirus did indeed originate in mid-November.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="3005" end_char="3007">The</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="3009" end_char="3016">research</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="3018" end_char="3022">lends</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="3024" end_char="3030">further</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="3032" end_char="3038">support</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="3040" end_char="3041">to</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="3043" end_char="3045">the</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="3047" end_char="3053">finding</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="3055" end_char="3058">that</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="3060" end_char="3062">the</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="3064" end_char="3071">earliest</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="3073" end_char="3076">case</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="3078" end_char="3079">of</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="3081" end_char="3083">the</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="3085" end_char="3089">novel</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="3091" end_char="3101">coronavirus</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="3103" end_char="3105">did</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="3107" end_char="3112">indeed</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="3114" end_char="3122">originate</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="3124" end_char="3125">in</TOKEN>
<TOKEN id="token-28-20" pos="unknown" morph="none" start_char="3127" end_char="3138">mid-November</TOKEN>
<TOKEN id="token-28-21" pos="punct" morph="none" start_char="3139" end_char="3139">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3142" end_char="3203">
<ORIGINAL_TEXT>Identifying patient zero is important for containing the virus</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="3142" end_char="3152">Identifying</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="3154" end_char="3160">patient</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="3162" end_char="3165">zero</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="3167" end_char="3168">is</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="3170" end_char="3178">important</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="3180" end_char="3182">for</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="3184" end_char="3193">containing</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="3195" end_char="3197">the</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="3199" end_char="3203">virus</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3207" end_char="3389">
<ORIGINAL_TEXT>As officials try to identify patient zero, the new government data reported by the Post provides clues about the emergence and spread of a virus that has thrown the world into tumult.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="3207" end_char="3208">As</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="3210" end_char="3218">officials</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="3220" end_char="3222">try</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="3224" end_char="3225">to</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="3227" end_char="3234">identify</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="3236" end_char="3242">patient</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="3244" end_char="3247">zero</TOKEN>
<TOKEN id="token-30-7" pos="punct" morph="none" start_char="3248" end_char="3248">,</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="3250" end_char="3252">the</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="3254" end_char="3256">new</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="3258" end_char="3267">government</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="3269" end_char="3272">data</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="3274" end_char="3281">reported</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="3283" end_char="3284">by</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="3286" end_char="3288">the</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="3290" end_char="3293">Post</TOKEN>
<TOKEN id="token-30-16" pos="word" morph="none" start_char="3295" end_char="3302">provides</TOKEN>
<TOKEN id="token-30-17" pos="word" morph="none" start_char="3304" end_char="3308">clues</TOKEN>
<TOKEN id="token-30-18" pos="word" morph="none" start_char="3310" end_char="3314">about</TOKEN>
<TOKEN id="token-30-19" pos="word" morph="none" start_char="3316" end_char="3318">the</TOKEN>
<TOKEN id="token-30-20" pos="word" morph="none" start_char="3320" end_char="3328">emergence</TOKEN>
<TOKEN id="token-30-21" pos="word" morph="none" start_char="3330" end_char="3332">and</TOKEN>
<TOKEN id="token-30-22" pos="word" morph="none" start_char="3334" end_char="3339">spread</TOKEN>
<TOKEN id="token-30-23" pos="word" morph="none" start_char="3341" end_char="3342">of</TOKEN>
<TOKEN id="token-30-24" pos="word" morph="none" start_char="3344" end_char="3344">a</TOKEN>
<TOKEN id="token-30-25" pos="word" morph="none" start_char="3346" end_char="3350">virus</TOKEN>
<TOKEN id="token-30-26" pos="word" morph="none" start_char="3352" end_char="3355">that</TOKEN>
<TOKEN id="token-30-27" pos="word" morph="none" start_char="3357" end_char="3359">has</TOKEN>
<TOKEN id="token-30-28" pos="word" morph="none" start_char="3361" end_char="3366">thrown</TOKEN>
<TOKEN id="token-30-29" pos="word" morph="none" start_char="3368" end_char="3370">the</TOKEN>
<TOKEN id="token-30-30" pos="word" morph="none" start_char="3372" end_char="3376">world</TOKEN>
<TOKEN id="token-30-31" pos="word" morph="none" start_char="3378" end_char="3381">into</TOKEN>
<TOKEN id="token-30-32" pos="word" morph="none" start_char="3383" end_char="3388">tumult</TOKEN>
<TOKEN id="token-30-33" pos="punct" morph="none" start_char="3389" end_char="3389">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="3392" end_char="3668">
<ORIGINAL_TEXT>"We don't know who the very first patient zero was, presumably in Wuhan, and that leaves a lot of unanswered questions about how the outbreak started and how it initially spread," Sarah Borwein, a doctor at Hong Kong's Central Health Medical Practice, told the Post last month.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="punct" morph="none" start_char="3392" end_char="3392">"</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="3393" end_char="3394">We</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="3396" end_char="3400">don't</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="3402" end_char="3405">know</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="3407" end_char="3409">who</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="3411" end_char="3413">the</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="3415" end_char="3418">very</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="3420" end_char="3424">first</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="3426" end_char="3432">patient</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="3434" end_char="3437">zero</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="3439" end_char="3441">was</TOKEN>
<TOKEN id="token-31-11" pos="punct" morph="none" start_char="3442" end_char="3442">,</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="3444" end_char="3453">presumably</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="3455" end_char="3456">in</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="3458" end_char="3462">Wuhan</TOKEN>
<TOKEN id="token-31-15" pos="punct" morph="none" start_char="3463" end_char="3463">,</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="3465" end_char="3467">and</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="3469" end_char="3472">that</TOKEN>
<TOKEN id="token-31-18" pos="word" morph="none" start_char="3474" end_char="3479">leaves</TOKEN>
<TOKEN id="token-31-19" pos="word" morph="none" start_char="3481" end_char="3481">a</TOKEN>
<TOKEN id="token-31-20" pos="word" morph="none" start_char="3483" end_char="3485">lot</TOKEN>
<TOKEN id="token-31-21" pos="word" morph="none" start_char="3487" end_char="3488">of</TOKEN>
<TOKEN id="token-31-22" pos="word" morph="none" start_char="3490" end_char="3499">unanswered</TOKEN>
<TOKEN id="token-31-23" pos="word" morph="none" start_char="3501" end_char="3509">questions</TOKEN>
<TOKEN id="token-31-24" pos="word" morph="none" start_char="3511" end_char="3515">about</TOKEN>
<TOKEN id="token-31-25" pos="word" morph="none" start_char="3517" end_char="3519">how</TOKEN>
<TOKEN id="token-31-26" pos="word" morph="none" start_char="3521" end_char="3523">the</TOKEN>
<TOKEN id="token-31-27" pos="word" morph="none" start_char="3525" end_char="3532">outbreak</TOKEN>
<TOKEN id="token-31-28" pos="word" morph="none" start_char="3534" end_char="3540">started</TOKEN>
<TOKEN id="token-31-29" pos="word" morph="none" start_char="3542" end_char="3544">and</TOKEN>
<TOKEN id="token-31-30" pos="word" morph="none" start_char="3546" end_char="3548">how</TOKEN>
<TOKEN id="token-31-31" pos="word" morph="none" start_char="3550" end_char="3551">it</TOKEN>
<TOKEN id="token-31-32" pos="word" morph="none" start_char="3553" end_char="3561">initially</TOKEN>
<TOKEN id="token-31-33" pos="word" morph="none" start_char="3563" end_char="3568">spread</TOKEN>
<TOKEN id="token-31-34" pos="punct" morph="none" start_char="3569" end_char="3570">,"</TOKEN>
<TOKEN id="token-31-35" pos="word" morph="none" start_char="3572" end_char="3576">Sarah</TOKEN>
<TOKEN id="token-31-36" pos="word" morph="none" start_char="3578" end_char="3584">Borwein</TOKEN>
<TOKEN id="token-31-37" pos="punct" morph="none" start_char="3585" end_char="3585">,</TOKEN>
<TOKEN id="token-31-38" pos="word" morph="none" start_char="3587" end_char="3587">a</TOKEN>
<TOKEN id="token-31-39" pos="word" morph="none" start_char="3589" end_char="3594">doctor</TOKEN>
<TOKEN id="token-31-40" pos="word" morph="none" start_char="3596" end_char="3597">at</TOKEN>
<TOKEN id="token-31-41" pos="word" morph="none" start_char="3599" end_char="3602">Hong</TOKEN>
<TOKEN id="token-31-42" pos="word" morph="none" start_char="3604" end_char="3609">Kong's</TOKEN>
<TOKEN id="token-31-43" pos="word" morph="none" start_char="3611" end_char="3617">Central</TOKEN>
<TOKEN id="token-31-44" pos="word" morph="none" start_char="3619" end_char="3624">Health</TOKEN>
<TOKEN id="token-31-45" pos="word" morph="none" start_char="3626" end_char="3632">Medical</TOKEN>
<TOKEN id="token-31-46" pos="word" morph="none" start_char="3634" end_char="3641">Practice</TOKEN>
<TOKEN id="token-31-47" pos="punct" morph="none" start_char="3642" end_char="3642">,</TOKEN>
<TOKEN id="token-31-48" pos="word" morph="none" start_char="3644" end_char="3647">told</TOKEN>
<TOKEN id="token-31-49" pos="word" morph="none" start_char="3649" end_char="3651">the</TOKEN>
<TOKEN id="token-31-50" pos="word" morph="none" start_char="3653" end_char="3656">Post</TOKEN>
<TOKEN id="token-31-51" pos="word" morph="none" start_char="3658" end_char="3661">last</TOKEN>
<TOKEN id="token-31-52" pos="word" morph="none" start_char="3663" end_char="3667">month</TOKEN>
<TOKEN id="token-31-53" pos="punct" morph="none" start_char="3668" end_char="3668">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="3672" end_char="3787">
<ORIGINAL_TEXT>Members of a police sanitation team spraying disinfectant to prevent the spread of the coronavirus in Bozhou, China.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="3672" end_char="3678">Members</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="3680" end_char="3681">of</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="3683" end_char="3683">a</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="3685" end_char="3690">police</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="3692" end_char="3701">sanitation</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="3703" end_char="3706">team</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="3708" end_char="3715">spraying</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="3717" end_char="3728">disinfectant</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="3730" end_char="3731">to</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="3733" end_char="3739">prevent</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="3741" end_char="3743">the</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="3745" end_char="3750">spread</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="3752" end_char="3753">of</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="3755" end_char="3757">the</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="3759" end_char="3769">coronavirus</TOKEN>
<TOKEN id="token-32-15" pos="word" morph="none" start_char="3771" end_char="3772">in</TOKEN>
<TOKEN id="token-32-16" pos="word" morph="none" start_char="3774" end_char="3779">Bozhou</TOKEN>
<TOKEN id="token-32-17" pos="punct" morph="none" start_char="3780" end_char="3780">,</TOKEN>
<TOKEN id="token-32-18" pos="word" morph="none" start_char="3782" end_char="3786">China</TOKEN>
<TOKEN id="token-32-19" pos="punct" morph="none" start_char="3787" end_char="3787">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="3790" end_char="3813">
<ORIGINAL_TEXT>STR/AFP via Getty Images</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="unknown" morph="none" start_char="3790" end_char="3796">STR/AFP</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="3798" end_char="3800">via</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="3802" end_char="3806">Getty</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="3808" end_char="3813">Images</TOKEN>
</SEG>
<SEG id="segment-34" start_char="3817" end_char="3953">
<ORIGINAL_TEXT>For experts, finding patient zero is not simply a matter of digging through data and conducting research — it's a race against the clock.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="3817" end_char="3819">For</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="3821" end_char="3827">experts</TOKEN>
<TOKEN id="token-34-2" pos="punct" morph="none" start_char="3828" end_char="3828">,</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="3830" end_char="3836">finding</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="3838" end_char="3844">patient</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="3846" end_char="3849">zero</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="3851" end_char="3852">is</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="3854" end_char="3856">not</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="3858" end_char="3863">simply</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="3865" end_char="3865">a</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="3867" end_char="3872">matter</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="3874" end_char="3875">of</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="3877" end_char="3883">digging</TOKEN>
<TOKEN id="token-34-13" pos="word" morph="none" start_char="3885" end_char="3891">through</TOKEN>
<TOKEN id="token-34-14" pos="word" morph="none" start_char="3893" end_char="3896">data</TOKEN>
<TOKEN id="token-34-15" pos="word" morph="none" start_char="3898" end_char="3900">and</TOKEN>
<TOKEN id="token-34-16" pos="word" morph="none" start_char="3902" end_char="3911">conducting</TOKEN>
<TOKEN id="token-34-17" pos="word" morph="none" start_char="3913" end_char="3920">research</TOKEN>
<TOKEN id="token-34-18" pos="punct" morph="none" start_char="3922" end_char="3922">—</TOKEN>
<TOKEN id="token-34-19" pos="word" morph="none" start_char="3924" end_char="3927">it's</TOKEN>
<TOKEN id="token-34-20" pos="word" morph="none" start_char="3929" end_char="3929">a</TOKEN>
<TOKEN id="token-34-21" pos="word" morph="none" start_char="3931" end_char="3934">race</TOKEN>
<TOKEN id="token-34-22" pos="word" morph="none" start_char="3936" end_char="3942">against</TOKEN>
<TOKEN id="token-34-23" pos="word" morph="none" start_char="3944" end_char="3946">the</TOKEN>
<TOKEN id="token-34-24" pos="word" morph="none" start_char="3948" end_char="3952">clock</TOKEN>
<TOKEN id="token-34-25" pos="punct" morph="none" start_char="3953" end_char="3953">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="3956" end_char="4108">
<ORIGINAL_TEXT>As the number of infections increases, it becomes more difficult to identify that person — and the areas that have been exposed to the virus the longest.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="3956" end_char="3957">As</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="3959" end_char="3961">the</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="3963" end_char="3968">number</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="3970" end_char="3971">of</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="3973" end_char="3982">infections</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="3984" end_char="3992">increases</TOKEN>
<TOKEN id="token-35-6" pos="punct" morph="none" start_char="3993" end_char="3993">,</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="3995" end_char="3996">it</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="3998" end_char="4004">becomes</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="4006" end_char="4009">more</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="4011" end_char="4019">difficult</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="4021" end_char="4022">to</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="4024" end_char="4031">identify</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="4033" end_char="4036">that</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="4038" end_char="4043">person</TOKEN>
<TOKEN id="token-35-15" pos="punct" morph="none" start_char="4045" end_char="4045">—</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="4047" end_char="4049">and</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="4051" end_char="4053">the</TOKEN>
<TOKEN id="token-35-18" pos="word" morph="none" start_char="4055" end_char="4059">areas</TOKEN>
<TOKEN id="token-35-19" pos="word" morph="none" start_char="4061" end_char="4064">that</TOKEN>
<TOKEN id="token-35-20" pos="word" morph="none" start_char="4066" end_char="4069">have</TOKEN>
<TOKEN id="token-35-21" pos="word" morph="none" start_char="4071" end_char="4074">been</TOKEN>
<TOKEN id="token-35-22" pos="word" morph="none" start_char="4076" end_char="4082">exposed</TOKEN>
<TOKEN id="token-35-23" pos="word" morph="none" start_char="4084" end_char="4085">to</TOKEN>
<TOKEN id="token-35-24" pos="word" morph="none" start_char="4087" end_char="4089">the</TOKEN>
<TOKEN id="token-35-25" pos="word" morph="none" start_char="4091" end_char="4095">virus</TOKEN>
<TOKEN id="token-35-26" pos="word" morph="none" start_char="4097" end_char="4099">the</TOKEN>
<TOKEN id="token-35-27" pos="word" morph="none" start_char="4101" end_char="4107">longest</TOKEN>
<TOKEN id="token-35-28" pos="punct" morph="none" start_char="4108" end_char="4108">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="4111" end_char="4398">
<ORIGINAL_TEXT>"We do feel uncomfortable obviously when we diagnose a patient with the illness and we can't work out where it came from," Dale Fisher, the chair of the WHO's Global Outbreak Alert and Response Network, told Reuters last month, adding that "the containment activities are less effective."</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="punct" morph="none" start_char="4111" end_char="4111">"</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="4112" end_char="4113">We</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="4115" end_char="4116">do</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="4118" end_char="4121">feel</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="4123" end_char="4135">uncomfortable</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="4137" end_char="4145">obviously</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="4147" end_char="4150">when</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="4152" end_char="4153">we</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="4155" end_char="4162">diagnose</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="4164" end_char="4164">a</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="4166" end_char="4172">patient</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="4174" end_char="4177">with</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="4179" end_char="4181">the</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="4183" end_char="4189">illness</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="4191" end_char="4193">and</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="4195" end_char="4196">we</TOKEN>
<TOKEN id="token-36-16" pos="word" morph="none" start_char="4198" end_char="4202">can't</TOKEN>
<TOKEN id="token-36-17" pos="word" morph="none" start_char="4204" end_char="4207">work</TOKEN>
<TOKEN id="token-36-18" pos="word" morph="none" start_char="4209" end_char="4211">out</TOKEN>
<TOKEN id="token-36-19" pos="word" morph="none" start_char="4213" end_char="4217">where</TOKEN>
<TOKEN id="token-36-20" pos="word" morph="none" start_char="4219" end_char="4220">it</TOKEN>
<TOKEN id="token-36-21" pos="word" morph="none" start_char="4222" end_char="4225">came</TOKEN>
<TOKEN id="token-36-22" pos="word" morph="none" start_char="4227" end_char="4230">from</TOKEN>
<TOKEN id="token-36-23" pos="punct" morph="none" start_char="4231" end_char="4232">,"</TOKEN>
<TOKEN id="token-36-24" pos="word" morph="none" start_char="4234" end_char="4237">Dale</TOKEN>
<TOKEN id="token-36-25" pos="word" morph="none" start_char="4239" end_char="4244">Fisher</TOKEN>
<TOKEN id="token-36-26" pos="punct" morph="none" start_char="4245" end_char="4245">,</TOKEN>
<TOKEN id="token-36-27" pos="word" morph="none" start_char="4247" end_char="4249">the</TOKEN>
<TOKEN id="token-36-28" pos="word" morph="none" start_char="4251" end_char="4255">chair</TOKEN>
<TOKEN id="token-36-29" pos="word" morph="none" start_char="4257" end_char="4258">of</TOKEN>
<TOKEN id="token-36-30" pos="word" morph="none" start_char="4260" end_char="4262">the</TOKEN>
<TOKEN id="token-36-31" pos="word" morph="none" start_char="4264" end_char="4268">WHO's</TOKEN>
<TOKEN id="token-36-32" pos="word" morph="none" start_char="4270" end_char="4275">Global</TOKEN>
<TOKEN id="token-36-33" pos="word" morph="none" start_char="4277" end_char="4284">Outbreak</TOKEN>
<TOKEN id="token-36-34" pos="word" morph="none" start_char="4286" end_char="4290">Alert</TOKEN>
<TOKEN id="token-36-35" pos="word" morph="none" start_char="4292" end_char="4294">and</TOKEN>
<TOKEN id="token-36-36" pos="word" morph="none" start_char="4296" end_char="4303">Response</TOKEN>
<TOKEN id="token-36-37" pos="word" morph="none" start_char="4305" end_char="4311">Network</TOKEN>
<TOKEN id="token-36-38" pos="punct" morph="none" start_char="4312" end_char="4312">,</TOKEN>
<TOKEN id="token-36-39" pos="word" morph="none" start_char="4314" end_char="4317">told</TOKEN>
<TOKEN id="token-36-40" pos="word" morph="none" start_char="4319" end_char="4325">Reuters</TOKEN>
<TOKEN id="token-36-41" pos="word" morph="none" start_char="4327" end_char="4330">last</TOKEN>
<TOKEN id="token-36-42" pos="word" morph="none" start_char="4332" end_char="4336">month</TOKEN>
<TOKEN id="token-36-43" pos="punct" morph="none" start_char="4337" end_char="4337">,</TOKEN>
<TOKEN id="token-36-44" pos="word" morph="none" start_char="4339" end_char="4344">adding</TOKEN>
<TOKEN id="token-36-45" pos="word" morph="none" start_char="4346" end_char="4349">that</TOKEN>
<TOKEN id="token-36-46" pos="punct" morph="none" start_char="4351" end_char="4351">"</TOKEN>
<TOKEN id="token-36-47" pos="word" morph="none" start_char="4352" end_char="4354">the</TOKEN>
<TOKEN id="token-36-48" pos="word" morph="none" start_char="4356" end_char="4366">containment</TOKEN>
<TOKEN id="token-36-49" pos="word" morph="none" start_char="4368" end_char="4377">activities</TOKEN>
<TOKEN id="token-36-50" pos="word" morph="none" start_char="4379" end_char="4381">are</TOKEN>
<TOKEN id="token-36-51" pos="word" morph="none" start_char="4383" end_char="4386">less</TOKEN>
<TOKEN id="token-36-52" pos="word" morph="none" start_char="4388" end_char="4396">effective</TOKEN>
<TOKEN id="token-36-53" pos="punct" morph="none" start_char="4397" end_char="4398">."</TOKEN>
</SEG>
<SEG id="segment-37" start_char="4401" end_char="4421">
<ORIGINAL_TEXT>Something is loading.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="4401" end_char="4409">Something</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="4411" end_char="4412">is</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="4414" end_char="4420">loading</TOKEN>
<TOKEN id="token-37-3" pos="punct" morph="none" start_char="4421" end_char="4421">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="4424" end_char="4433">
<ORIGINAL_TEXT>Read more:</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="4424" end_char="4427">Read</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="4429" end_char="4432">more</TOKEN>
<TOKEN id="token-38-2" pos="punct" morph="none" start_char="4433" end_char="4433">:</TOKEN>
</SEG>
<SEG id="segment-39" start_char="4436" end_char="4472">
<ORIGINAL_TEXT>Taiwan has only 50 coronavirus cases.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="4436" end_char="4441">Taiwan</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="4443" end_char="4445">has</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="4447" end_char="4450">only</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="4452" end_char="4453">50</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="4455" end_char="4465">coronavirus</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="4467" end_char="4471">cases</TOKEN>
<TOKEN id="token-39-6" pos="punct" morph="none" start_char="4472" end_char="4472">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="4474" end_char="4574">
<ORIGINAL_TEXT>Its response to the crisis shows that swift action and widespread healthcare can prevent an outbreak.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="4474" end_char="4476">Its</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="4478" end_char="4485">response</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="4487" end_char="4488">to</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="4490" end_char="4492">the</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="4494" end_char="4499">crisis</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="4501" end_char="4505">shows</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="4507" end_char="4510">that</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="4512" end_char="4516">swift</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="4518" end_char="4523">action</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="4525" end_char="4527">and</TOKEN>
<TOKEN id="token-40-10" pos="word" morph="none" start_char="4529" end_char="4538">widespread</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="4540" end_char="4549">healthcare</TOKEN>
<TOKEN id="token-40-12" pos="word" morph="none" start_char="4551" end_char="4553">can</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="4555" end_char="4561">prevent</TOKEN>
<TOKEN id="token-40-14" pos="word" morph="none" start_char="4563" end_char="4564">an</TOKEN>
<TOKEN id="token-40-15" pos="word" morph="none" start_char="4566" end_char="4573">outbreak</TOKEN>
<TOKEN id="token-40-16" pos="punct" morph="none" start_char="4574" end_char="4574">.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="4577" end_char="4657">
<ORIGINAL_TEXT>The US is severely under-testing for coronavirus as death toll and new cases rise</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="4577" end_char="4579">The</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="4581" end_char="4582">US</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="4584" end_char="4585">is</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="4587" end_char="4594">severely</TOKEN>
<TOKEN id="token-41-4" pos="unknown" morph="none" start_char="4596" end_char="4608">under-testing</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="4610" end_char="4612">for</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="4614" end_char="4624">coronavirus</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="4626" end_char="4627">as</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="4629" end_char="4633">death</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="4635" end_char="4638">toll</TOKEN>
<TOKEN id="token-41-10" pos="word" morph="none" start_char="4640" end_char="4642">and</TOKEN>
<TOKEN id="token-41-11" pos="word" morph="none" start_char="4644" end_char="4646">new</TOKEN>
<TOKEN id="token-41-12" pos="word" morph="none" start_char="4648" end_char="4652">cases</TOKEN>
<TOKEN id="token-41-13" pos="word" morph="none" start_char="4654" end_char="4657">rise</TOKEN>
</SEG>
<SEG id="segment-42" start_char="4660" end_char="4831">
<ORIGINAL_TEXT>Chinese social-media platform WeChat saw spikes in the terms 'SARS,' 'coronavirus,' and 'shortness of breath,' weeks before the first cases were confirmed, a study suggests</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="4660" end_char="4666">Chinese</TOKEN>
<TOKEN id="token-42-1" pos="unknown" morph="none" start_char="4668" end_char="4679">social-media</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="4681" end_char="4688">platform</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="4690" end_char="4695">WeChat</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="4697" end_char="4699">saw</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="4701" end_char="4706">spikes</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="4708" end_char="4709">in</TOKEN>
<TOKEN id="token-42-7" pos="word" morph="none" start_char="4711" end_char="4713">the</TOKEN>
<TOKEN id="token-42-8" pos="word" morph="none" start_char="4715" end_char="4719">terms</TOKEN>
<TOKEN id="token-42-9" pos="punct" morph="none" start_char="4721" end_char="4721">'</TOKEN>
<TOKEN id="token-42-10" pos="word" morph="none" start_char="4722" end_char="4725">SARS</TOKEN>
<TOKEN id="token-42-11" pos="punct" morph="none" start_char="4726" end_char="4727">,'</TOKEN>
<TOKEN id="token-42-12" pos="punct" morph="none" start_char="4729" end_char="4729">'</TOKEN>
<TOKEN id="token-42-13" pos="word" morph="none" start_char="4730" end_char="4740">coronavirus</TOKEN>
<TOKEN id="token-42-14" pos="punct" morph="none" start_char="4741" end_char="4742">,'</TOKEN>
<TOKEN id="token-42-15" pos="word" morph="none" start_char="4744" end_char="4746">and</TOKEN>
<TOKEN id="token-42-16" pos="punct" morph="none" start_char="4748" end_char="4748">'</TOKEN>
<TOKEN id="token-42-17" pos="word" morph="none" start_char="4749" end_char="4757">shortness</TOKEN>
<TOKEN id="token-42-18" pos="word" morph="none" start_char="4759" end_char="4760">of</TOKEN>
<TOKEN id="token-42-19" pos="word" morph="none" start_char="4762" end_char="4767">breath</TOKEN>
<TOKEN id="token-42-20" pos="punct" morph="none" start_char="4768" end_char="4769">,'</TOKEN>
<TOKEN id="token-42-21" pos="word" morph="none" start_char="4771" end_char="4775">weeks</TOKEN>
<TOKEN id="token-42-22" pos="word" morph="none" start_char="4777" end_char="4782">before</TOKEN>
<TOKEN id="token-42-23" pos="word" morph="none" start_char="4784" end_char="4786">the</TOKEN>
<TOKEN id="token-42-24" pos="word" morph="none" start_char="4788" end_char="4792">first</TOKEN>
<TOKEN id="token-42-25" pos="word" morph="none" start_char="4794" end_char="4798">cases</TOKEN>
<TOKEN id="token-42-26" pos="word" morph="none" start_char="4800" end_char="4803">were</TOKEN>
<TOKEN id="token-42-27" pos="word" morph="none" start_char="4805" end_char="4813">confirmed</TOKEN>
<TOKEN id="token-42-28" pos="punct" morph="none" start_char="4814" end_char="4814">,</TOKEN>
<TOKEN id="token-42-29" pos="word" morph="none" start_char="4816" end_char="4816">a</TOKEN>
<TOKEN id="token-42-30" pos="word" morph="none" start_char="4818" end_char="4822">study</TOKEN>
<TOKEN id="token-42-31" pos="word" morph="none" start_char="4824" end_char="4831">suggests</TOKEN>
</SEG>
<SEG id="segment-43" start_char="4834" end_char="4979">
<ORIGINAL_TEXT>Travel bans in Wuhan only delayed the coronavirus' spread in China by 3 to 5 days, and in the rest of the world by a few weeks, new research shows</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="4834" end_char="4839">Travel</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="4841" end_char="4844">bans</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="4846" end_char="4847">in</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="4849" end_char="4853">Wuhan</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="4855" end_char="4858">only</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="4860" end_char="4866">delayed</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="4868" end_char="4870">the</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="4872" end_char="4882">coronavirus</TOKEN>
<TOKEN id="token-43-8" pos="punct" morph="none" start_char="4883" end_char="4883">'</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="4885" end_char="4890">spread</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="4892" end_char="4893">in</TOKEN>
<TOKEN id="token-43-11" pos="word" morph="none" start_char="4895" end_char="4899">China</TOKEN>
<TOKEN id="token-43-12" pos="word" morph="none" start_char="4901" end_char="4902">by</TOKEN>
<TOKEN id="token-43-13" pos="word" morph="none" start_char="4904" end_char="4904">3</TOKEN>
<TOKEN id="token-43-14" pos="word" morph="none" start_char="4906" end_char="4907">to</TOKEN>
<TOKEN id="token-43-15" pos="word" morph="none" start_char="4909" end_char="4909">5</TOKEN>
<TOKEN id="token-43-16" pos="word" morph="none" start_char="4911" end_char="4914">days</TOKEN>
<TOKEN id="token-43-17" pos="punct" morph="none" start_char="4915" end_char="4915">,</TOKEN>
<TOKEN id="token-43-18" pos="word" morph="none" start_char="4917" end_char="4919">and</TOKEN>
<TOKEN id="token-43-19" pos="word" morph="none" start_char="4921" end_char="4922">in</TOKEN>
<TOKEN id="token-43-20" pos="word" morph="none" start_char="4924" end_char="4926">the</TOKEN>
<TOKEN id="token-43-21" pos="word" morph="none" start_char="4928" end_char="4931">rest</TOKEN>
<TOKEN id="token-43-22" pos="word" morph="none" start_char="4933" end_char="4934">of</TOKEN>
<TOKEN id="token-43-23" pos="word" morph="none" start_char="4936" end_char="4938">the</TOKEN>
<TOKEN id="token-43-24" pos="word" morph="none" start_char="4940" end_char="4944">world</TOKEN>
<TOKEN id="token-43-25" pos="word" morph="none" start_char="4946" end_char="4947">by</TOKEN>
<TOKEN id="token-43-26" pos="word" morph="none" start_char="4949" end_char="4949">a</TOKEN>
<TOKEN id="token-43-27" pos="word" morph="none" start_char="4951" end_char="4953">few</TOKEN>
<TOKEN id="token-43-28" pos="word" morph="none" start_char="4955" end_char="4959">weeks</TOKEN>
<TOKEN id="token-43-29" pos="punct" morph="none" start_char="4960" end_char="4960">,</TOKEN>
<TOKEN id="token-43-30" pos="word" morph="none" start_char="4962" end_char="4964">new</TOKEN>
<TOKEN id="token-43-31" pos="word" morph="none" start_char="4966" end_char="4973">research</TOKEN>
<TOKEN id="token-43-32" pos="word" morph="none" start_char="4975" end_char="4979">shows</TOKEN>
</SEG>
<SEG id="segment-44" start_char="4983" end_char="5017">
<ORIGINAL_TEXT>Two crossed lines that form an 'X'.</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="4983" end_char="4985">Two</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="4987" end_char="4993">crossed</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="4995" end_char="4999">lines</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="5001" end_char="5004">that</TOKEN>
<TOKEN id="token-44-4" pos="word" morph="none" start_char="5006" end_char="5009">form</TOKEN>
<TOKEN id="token-44-5" pos="word" morph="none" start_char="5011" end_char="5012">an</TOKEN>
<TOKEN id="token-44-6" pos="punct" morph="none" start_char="5014" end_char="5014">'</TOKEN>
<TOKEN id="token-44-7" pos="word" morph="none" start_char="5015" end_char="5015">X</TOKEN>
<TOKEN id="token-44-8" pos="punct" morph="none" start_char="5016" end_char="5017">'.</TOKEN>
</SEG>
<SEG id="segment-45" start_char="5019" end_char="5088">
<ORIGINAL_TEXT>It indicates a way to close an interaction, or dismiss a notification.</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="5019" end_char="5020">It</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="5022" end_char="5030">indicates</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="5032" end_char="5032">a</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="5034" end_char="5036">way</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="5038" end_char="5039">to</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="5041" end_char="5045">close</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="5047" end_char="5048">an</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="5050" end_char="5060">interaction</TOKEN>
<TOKEN id="token-45-8" pos="punct" morph="none" start_char="5061" end_char="5061">,</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="5063" end_char="5064">or</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="5066" end_char="5072">dismiss</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="5074" end_char="5074">a</TOKEN>
<TOKEN id="token-45-12" pos="word" morph="none" start_char="5076" end_char="5087">notification</TOKEN>
<TOKEN id="token-45-13" pos="punct" morph="none" start_char="5088" end_char="5088">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
