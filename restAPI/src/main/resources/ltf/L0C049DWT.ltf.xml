<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="eng">
<DOC id="L0C049DWT" lang="eng" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="13744" raw_text_md5="4a805c2c37047c39d178f4b0bc84a9d8">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="37">
<ORIGINAL_TEXT>El covid NO se creo en un laboratorio</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="2">El</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="4" end_char="8">covid</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="10" end_char="11">NO</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="13" end_char="14">se</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="16" end_char="19">creo</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="21" end_char="22">en</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="24" end_char="25">un</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="27" end_char="37">laboratorio</TOKEN>
</SEG>
<SEG id="segment-1" start_char="41" end_char="87">
<ORIGINAL_TEXT>Magufos y biologos del bar Pepe se cae el mito:</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="41" end_char="47">Magufos</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="49" end_char="49">y</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="51" end_char="58">biologos</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="60" end_char="62">del</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="64" end_char="66">bar</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="68" end_char="71">Pepe</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="73" end_char="74">se</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="76" end_char="78">cae</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="80" end_char="81">el</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="83" end_char="86">mito</TOKEN>
<TOKEN id="token-1-10" pos="punct" morph="none" start_char="87" end_char="87">:</TOKEN>
</SEG>
<SEG id="segment-2" start_char="90" end_char="525">
<ORIGINAL_TEXT>"Aunque la evidencia muestra que el SARS-CoV-2 no es un virus manipulado a propósito, actualmente es imposible probar o refutar las otras teorías de su origen descritas aquí. Sin embargo, dado que observamos todas las características notables de SARS-CoV-2, incluida la RBD optimizada y el sitio de escisión polibásica, en coronavirus relacionados en la naturaleza, no creemos que ningún tipo de escenario de laboratorio sea plausible."</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="punct" morph="none" start_char="90" end_char="90">"</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="91" end_char="96">Aunque</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="98" end_char="99">la</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="101" end_char="109">evidencia</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="111" end_char="117">muestra</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="119" end_char="121">que</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="123" end_char="124">el</TOKEN>
<TOKEN id="token-2-7" pos="unknown" morph="none" start_char="126" end_char="135">SARS-CoV-2</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="137" end_char="138">no</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="140" end_char="141">es</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="143" end_char="144">un</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="146" end_char="150">virus</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="152" end_char="161">manipulado</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="163" end_char="163">a</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="165" end_char="173">propósito</TOKEN>
<TOKEN id="token-2-15" pos="punct" morph="none" start_char="174" end_char="174">,</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="176" end_char="186">actualmente</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="188" end_char="189">es</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="191" end_char="199">imposible</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="201" end_char="206">probar</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="208" end_char="208">o</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="210" end_char="216">refutar</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="218" end_char="220">las</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="222" end_char="226">otras</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="228" end_char="234">teorías</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="236" end_char="237">de</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="239" end_char="240">su</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="242" end_char="247">origen</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="249" end_char="257">descritas</TOKEN>
<TOKEN id="token-2-29" pos="word" morph="none" start_char="259" end_char="262">aquí</TOKEN>
<TOKEN id="token-2-30" pos="punct" morph="none" start_char="263" end_char="263">.</TOKEN>
<TOKEN id="token-2-31" pos="word" morph="none" start_char="265" end_char="267">Sin</TOKEN>
<TOKEN id="token-2-32" pos="word" morph="none" start_char="269" end_char="275">embargo</TOKEN>
<TOKEN id="token-2-33" pos="punct" morph="none" start_char="276" end_char="276">,</TOKEN>
<TOKEN id="token-2-34" pos="word" morph="none" start_char="278" end_char="281">dado</TOKEN>
<TOKEN id="token-2-35" pos="word" morph="none" start_char="283" end_char="285">que</TOKEN>
<TOKEN id="token-2-36" pos="word" morph="none" start_char="287" end_char="296">observamos</TOKEN>
<TOKEN id="token-2-37" pos="word" morph="none" start_char="298" end_char="302">todas</TOKEN>
<TOKEN id="token-2-38" pos="word" morph="none" start_char="304" end_char="306">las</TOKEN>
<TOKEN id="token-2-39" pos="word" morph="none" start_char="308" end_char="322">características</TOKEN>
<TOKEN id="token-2-40" pos="word" morph="none" start_char="324" end_char="331">notables</TOKEN>
<TOKEN id="token-2-41" pos="word" morph="none" start_char="333" end_char="334">de</TOKEN>
<TOKEN id="token-2-42" pos="unknown" morph="none" start_char="336" end_char="345">SARS-CoV-2</TOKEN>
<TOKEN id="token-2-43" pos="punct" morph="none" start_char="346" end_char="346">,</TOKEN>
<TOKEN id="token-2-44" pos="word" morph="none" start_char="348" end_char="355">incluida</TOKEN>
<TOKEN id="token-2-45" pos="word" morph="none" start_char="357" end_char="358">la</TOKEN>
<TOKEN id="token-2-46" pos="word" morph="none" start_char="360" end_char="362">RBD</TOKEN>
<TOKEN id="token-2-47" pos="word" morph="none" start_char="364" end_char="373">optimizada</TOKEN>
<TOKEN id="token-2-48" pos="word" morph="none" start_char="375" end_char="375">y</TOKEN>
<TOKEN id="token-2-49" pos="word" morph="none" start_char="377" end_char="378">el</TOKEN>
<TOKEN id="token-2-50" pos="word" morph="none" start_char="380" end_char="384">sitio</TOKEN>
<TOKEN id="token-2-51" pos="word" morph="none" start_char="386" end_char="387">de</TOKEN>
<TOKEN id="token-2-52" pos="word" morph="none" start_char="389" end_char="396">escisión</TOKEN>
<TOKEN id="token-2-53" pos="word" morph="none" start_char="398" end_char="407">polibásica</TOKEN>
<TOKEN id="token-2-54" pos="punct" morph="none" start_char="408" end_char="408">,</TOKEN>
<TOKEN id="token-2-55" pos="word" morph="none" start_char="410" end_char="411">en</TOKEN>
<TOKEN id="token-2-56" pos="word" morph="none" start_char="413" end_char="423">coronavirus</TOKEN>
<TOKEN id="token-2-57" pos="word" morph="none" start_char="425" end_char="436">relacionados</TOKEN>
<TOKEN id="token-2-58" pos="word" morph="none" start_char="438" end_char="439">en</TOKEN>
<TOKEN id="token-2-59" pos="word" morph="none" start_char="441" end_char="442">la</TOKEN>
<TOKEN id="token-2-60" pos="word" morph="none" start_char="444" end_char="453">naturaleza</TOKEN>
<TOKEN id="token-2-61" pos="punct" morph="none" start_char="454" end_char="454">,</TOKEN>
<TOKEN id="token-2-62" pos="word" morph="none" start_char="456" end_char="457">no</TOKEN>
<TOKEN id="token-2-63" pos="word" morph="none" start_char="459" end_char="465">creemos</TOKEN>
<TOKEN id="token-2-64" pos="word" morph="none" start_char="467" end_char="469">que</TOKEN>
<TOKEN id="token-2-65" pos="word" morph="none" start_char="471" end_char="476">ningún</TOKEN>
<TOKEN id="token-2-66" pos="word" morph="none" start_char="478" end_char="481">tipo</TOKEN>
<TOKEN id="token-2-67" pos="word" morph="none" start_char="483" end_char="484">de</TOKEN>
<TOKEN id="token-2-68" pos="word" morph="none" start_char="486" end_char="494">escenario</TOKEN>
<TOKEN id="token-2-69" pos="word" morph="none" start_char="496" end_char="497">de</TOKEN>
<TOKEN id="token-2-70" pos="word" morph="none" start_char="499" end_char="509">laboratorio</TOKEN>
<TOKEN id="token-2-71" pos="word" morph="none" start_char="511" end_char="513">sea</TOKEN>
<TOKEN id="token-2-72" pos="word" morph="none" start_char="515" end_char="523">plausible</TOKEN>
<TOKEN id="token-2-73" pos="punct" morph="none" start_char="524" end_char="525">."</TOKEN>
</SEG>
<SEG id="segment-3" start_char="528" end_char="709">
<ORIGINAL_TEXT>"Although the evidence shows that SARS-CoV-2 is not a purposefully manipulated virus, it is currently impossible to prove or disprove the other theories of its origin described here.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="punct" morph="none" start_char="528" end_char="528">"</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="529" end_char="536">Although</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="538" end_char="540">the</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="542" end_char="549">evidence</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="551" end_char="555">shows</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="557" end_char="560">that</TOKEN>
<TOKEN id="token-3-6" pos="unknown" morph="none" start_char="562" end_char="571">SARS-CoV-2</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="573" end_char="574">is</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="576" end_char="578">not</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="580" end_char="580">a</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="582" end_char="593">purposefully</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="595" end_char="605">manipulated</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="607" end_char="611">virus</TOKEN>
<TOKEN id="token-3-13" pos="punct" morph="none" start_char="612" end_char="612">,</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="614" end_char="615">it</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="617" end_char="618">is</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="620" end_char="628">currently</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="630" end_char="639">impossible</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="641" end_char="642">to</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="644" end_char="648">prove</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="650" end_char="651">or</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="653" end_char="660">disprove</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="662" end_char="664">the</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="666" end_char="670">other</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="672" end_char="679">theories</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="681" end_char="682">of</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="684" end_char="686">its</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="688" end_char="693">origin</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="695" end_char="703">described</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="705" end_char="708">here</TOKEN>
<TOKEN id="token-3-30" pos="punct" morph="none" start_char="709" end_char="709">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="711" end_char="938">
<ORIGINAL_TEXT>However, since we observed all notable SARS-CoV-2 features, including the optimized RBD and polybasic cleavage site, in related coronaviruses in nature, we do not believe that any type of laboratory-based scenario is plausible."</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="711" end_char="717">However</TOKEN>
<TOKEN id="token-4-1" pos="punct" morph="none" start_char="718" end_char="718">,</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="720" end_char="724">since</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="726" end_char="727">we</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="729" end_char="736">observed</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="738" end_char="740">all</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="742" end_char="748">notable</TOKEN>
<TOKEN id="token-4-7" pos="unknown" morph="none" start_char="750" end_char="759">SARS-CoV-2</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="761" end_char="768">features</TOKEN>
<TOKEN id="token-4-9" pos="punct" morph="none" start_char="769" end_char="769">,</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="771" end_char="779">including</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="781" end_char="783">the</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="785" end_char="793">optimized</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="795" end_char="797">RBD</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="799" end_char="801">and</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="803" end_char="811">polybasic</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="813" end_char="820">cleavage</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="822" end_char="825">site</TOKEN>
<TOKEN id="token-4-18" pos="punct" morph="none" start_char="826" end_char="826">,</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="828" end_char="829">in</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="831" end_char="837">related</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="839" end_char="851">coronaviruses</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="853" end_char="854">in</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="856" end_char="861">nature</TOKEN>
<TOKEN id="token-4-24" pos="punct" morph="none" start_char="862" end_char="862">,</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="864" end_char="865">we</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="867" end_char="868">do</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="870" end_char="872">not</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="874" end_char="880">believe</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="882" end_char="885">that</TOKEN>
<TOKEN id="token-4-30" pos="word" morph="none" start_char="887" end_char="889">any</TOKEN>
<TOKEN id="token-4-31" pos="word" morph="none" start_char="891" end_char="894">type</TOKEN>
<TOKEN id="token-4-32" pos="word" morph="none" start_char="896" end_char="897">of</TOKEN>
<TOKEN id="token-4-33" pos="unknown" morph="none" start_char="899" end_char="914">laboratory-based</TOKEN>
<TOKEN id="token-4-34" pos="word" morph="none" start_char="916" end_char="923">scenario</TOKEN>
<TOKEN id="token-4-35" pos="word" morph="none" start_char="925" end_char="926">is</TOKEN>
<TOKEN id="token-4-36" pos="word" morph="none" start_char="928" end_char="936">plausible</TOKEN>
<TOKEN id="token-4-37" pos="punct" morph="none" start_char="937" end_char="938">."</TOKEN>
</SEG>
<SEG id="segment-5" start_char="941" end_char="989">
<ORIGINAL_TEXT>https://www.nature.com/articles/s41591-020-0820-9</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="url" morph="none" start_char="941" end_char="989">https://www.nature.com/articles/s41591-020-0820-9</TOKEN>
</SEG>
<SEG id="segment-6" start_char="992" end_char="1066">
<ORIGINAL_TEXT>Nature es una de las más prestigiosas revistas científicas a nivel mundial.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="992" end_char="997">Nature</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="999" end_char="1000">es</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="1002" end_char="1004">una</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="1006" end_char="1007">de</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="1009" end_char="1011">las</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="1013" end_char="1015">más</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="1017" end_char="1028">prestigiosas</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="1030" end_char="1037">revistas</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="1039" end_char="1049">científicas</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="1051" end_char="1051">a</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="1053" end_char="1057">nivel</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="1059" end_char="1065">mundial</TOKEN>
<TOKEN id="token-6-12" pos="punct" morph="none" start_char="1066" end_char="1066">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="1068" end_char="1155">
<ORIGINAL_TEXT>Para la mayoría de los científicos publicar en Nature constituye una marca de prestigio.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="1068" end_char="1071">Para</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="1073" end_char="1074">la</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="1076" end_char="1082">mayoría</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="1084" end_char="1085">de</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="1087" end_char="1089">los</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="1091" end_char="1101">científicos</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="1103" end_char="1110">publicar</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="1112" end_char="1113">en</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="1115" end_char="1120">Nature</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="1122" end_char="1131">constituye</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="1133" end_char="1135">una</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="1137" end_char="1141">marca</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="1143" end_char="1144">de</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="1146" end_char="1154">prestigio</TOKEN>
<TOKEN id="token-7-14" pos="punct" morph="none" start_char="1155" end_char="1155">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1157" end_char="1255">
<ORIGINAL_TEXT>La revista rechaza en torno al 95% de los artículos que le son enviados para la revisión por pares.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1157" end_char="1158">La</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1160" end_char="1166">revista</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1168" end_char="1174">rechaza</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1176" end_char="1177">en</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1179" end_char="1183">torno</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1185" end_char="1186">al</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1188" end_char="1189">95</TOKEN>
<TOKEN id="token-8-7" pos="punct" morph="none" start_char="1190" end_char="1190">%</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1192" end_char="1193">de</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1195" end_char="1197">los</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1199" end_char="1207">artículos</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1209" end_char="1211">que</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1213" end_char="1214">le</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1216" end_char="1218">son</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1220" end_char="1227">enviados</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1229" end_char="1232">para</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1234" end_char="1235">la</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1237" end_char="1244">revisión</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1246" end_char="1248">por</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1250" end_char="1254">pares</TOKEN>
<TOKEN id="token-8-20" pos="punct" morph="none" start_char="1255" end_char="1255">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1260" end_char="1300">
<ORIGINAL_TEXT>Fue kuando un xino se comió un murciégalo</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1260" end_char="1262">Fue</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1264" end_char="1269">kuando</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1271" end_char="1272">un</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1274" end_char="1277">xino</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1279" end_char="1280">se</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1282" end_char="1286">comió</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1288" end_char="1289">un</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1291" end_char="1300">murciégalo</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1306" end_char="1326">
<ORIGINAL_TEXT>Al rico pangolin oiga</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1306" end_char="1307">Al</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1309" end_char="1312">rico</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1314" end_char="1321">pangolin</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1323" end_char="1326">oiga</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1332" end_char="1350">
<ORIGINAL_TEXT>¿Y qué van a decir?</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="punct" morph="none" start_char="1332" end_char="1332">¿</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1333" end_char="1333">Y</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1335" end_char="1337">qué</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1339" end_char="1341">van</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1343" end_char="1343">a</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1345" end_char="1349">decir</TOKEN>
<TOKEN id="token-11-6" pos="punct" morph="none" start_char="1350" end_char="1350">?</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1356" end_char="1360">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1356" end_char="1359">Cita</TOKEN>
<TOKEN id="token-12-1" pos="punct" morph="none" start_char="1360" end_char="1360">:</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1365" end_char="1417">
<ORIGINAL_TEXT>Originalmente Escrito por Tidus23 ¿Y qué van a decir?</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1365" end_char="1377">Originalmente</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1379" end_char="1385">Escrito</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1387" end_char="1389">por</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1391" end_char="1397">Tidus23</TOKEN>
<TOKEN id="token-13-4" pos="punct" morph="none" start_char="1399" end_char="1399">¿</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1400" end_char="1400">Y</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1402" end_char="1404">qué</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1406" end_char="1408">van</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1410" end_char="1410">a</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1412" end_char="1416">decir</TOKEN>
<TOKEN id="token-13-10" pos="punct" morph="none" start_char="1417" end_char="1417">?</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1422" end_char="1442">
<ORIGINAL_TEXT>Tardo poco el primero</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1422" end_char="1426">Tardo</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1428" end_char="1431">poco</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1433" end_char="1434">el</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1436" end_char="1442">primero</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1448" end_char="1492">
<ORIGINAL_TEXT>¿Sabes la diferencia entre "saber" y "creer"?</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="punct" morph="none" start_char="1448" end_char="1448">¿</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1449" end_char="1453">Sabes</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1455" end_char="1456">la</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1458" end_char="1467">diferencia</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1469" end_char="1473">entre</TOKEN>
<TOKEN id="token-15-5" pos="punct" morph="none" start_char="1475" end_char="1475">"</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1476" end_char="1480">saber</TOKEN>
<TOKEN id="token-15-7" pos="punct" morph="none" start_char="1481" end_char="1481">"</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1483" end_char="1483">y</TOKEN>
<TOKEN id="token-15-9" pos="punct" morph="none" start_char="1485" end_char="1485">"</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1486" end_char="1490">creer</TOKEN>
<TOKEN id="token-15-11" pos="punct" morph="none" start_char="1491" end_char="1492">"?</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1494" end_char="1534">
<ORIGINAL_TEXT>¿Y entre una afirmación y una suposición?</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="punct" morph="none" start_char="1494" end_char="1494">¿</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1495" end_char="1495">Y</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1497" end_char="1501">entre</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1503" end_char="1505">una</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1507" end_char="1516">afirmación</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1518" end_char="1518">y</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1520" end_char="1522">una</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1524" end_char="1533">suposición</TOKEN>
<TOKEN id="token-16-8" pos="punct" morph="none" start_char="1534" end_char="1534">?</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1540" end_char="1599">
<ORIGINAL_TEXT>Si te crees todo lo que dice esta revista es que eres tonto.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1540" end_char="1541">Si</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1543" end_char="1544">te</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="1546" end_char="1550">crees</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="1552" end_char="1555">todo</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="1557" end_char="1558">lo</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="1560" end_char="1562">que</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="1564" end_char="1567">dice</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="1569" end_char="1572">esta</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="1574" end_char="1580">revista</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="1582" end_char="1583">es</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="1585" end_char="1587">que</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="1589" end_char="1592">eres</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="1594" end_char="1598">tonto</TOKEN>
<TOKEN id="token-17-13" pos="punct" morph="none" start_char="1599" end_char="1599">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1605" end_char="1637">
<ORIGINAL_TEXT>Lo hizo madre tierra para limpiar</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="1605" end_char="1606">Lo</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="1608" end_char="1611">hizo</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="1613" end_char="1617">madre</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="1619" end_char="1624">tierra</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="1626" end_char="1629">para</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="1631" end_char="1637">limpiar</TOKEN>
</SEG>
<SEG id="segment-19" start_char="1643" end_char="1742">
<ORIGINAL_TEXT>Está bastante claro que la teoría de que fue creada en un laboratorio es una magufada de campeonato.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="1643" end_char="1646">Está</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="1648" end_char="1655">bastante</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="1657" end_char="1661">claro</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="1663" end_char="1665">que</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="1667" end_char="1668">la</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="1670" end_char="1675">teoría</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="1677" end_char="1678">de</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="1680" end_char="1682">que</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="1684" end_char="1686">fue</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="1688" end_char="1693">creada</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="1695" end_char="1696">en</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="1698" end_char="1699">un</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="1701" end_char="1711">laboratorio</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="1713" end_char="1714">es</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="1716" end_char="1718">una</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="1720" end_char="1727">magufada</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="1729" end_char="1730">de</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="1732" end_char="1741">campeonato</TOKEN>
<TOKEN id="token-19-18" pos="punct" morph="none" start_char="1742" end_char="1742">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="1748" end_char="1752">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="1748" end_char="1751">Cita</TOKEN>
<TOKEN id="token-20-1" pos="punct" morph="none" start_char="1752" end_char="1752">:</TOKEN>
</SEG>
<SEG id="segment-21" start_char="1757" end_char="1839">
<ORIGINAL_TEXT>Originalmente Escrito por -Vicespert- ¿Sabes la diferencia entre "saber" y "creer"?</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="1757" end_char="1769">Originalmente</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="1771" end_char="1777">Escrito</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="1779" end_char="1781">por</TOKEN>
<TOKEN id="token-21-3" pos="punct" morph="none" start_char="1783" end_char="1783">-</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="1784" end_char="1792">Vicespert</TOKEN>
<TOKEN id="token-21-5" pos="punct" morph="none" start_char="1793" end_char="1793">-</TOKEN>
<TOKEN id="token-21-6" pos="punct" morph="none" start_char="1795" end_char="1795">¿</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="1796" end_char="1800">Sabes</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="1802" end_char="1803">la</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="1805" end_char="1814">diferencia</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="1816" end_char="1820">entre</TOKEN>
<TOKEN id="token-21-11" pos="punct" morph="none" start_char="1822" end_char="1822">"</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="1823" end_char="1827">saber</TOKEN>
<TOKEN id="token-21-13" pos="punct" morph="none" start_char="1828" end_char="1828">"</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="1830" end_char="1830">y</TOKEN>
<TOKEN id="token-21-15" pos="punct" morph="none" start_char="1832" end_char="1832">"</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="1833" end_char="1837">creer</TOKEN>
<TOKEN id="token-21-17" pos="punct" morph="none" start_char="1838" end_char="1839">"?</TOKEN>
</SEG>
<SEG id="segment-22" start_char="1841" end_char="1881">
<ORIGINAL_TEXT>¿Y entre una afirmación y una suposición?</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="punct" morph="none" start_char="1841" end_char="1841">¿</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="1842" end_char="1842">Y</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="1844" end_char="1848">entre</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="1850" end_char="1852">una</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="1854" end_char="1863">afirmación</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="1865" end_char="1865">y</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="1867" end_char="1869">una</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="1871" end_char="1880">suposición</TOKEN>
<TOKEN id="token-22-8" pos="punct" morph="none" start_char="1881" end_char="1881">?</TOKEN>
</SEG>
<SEG id="segment-23" start_char="1884" end_char="1954">
<ORIGINAL_TEXT>Se lo explicas a nature y das alguna prueba como hacen los cientificos.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="1884" end_char="1885">Se</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="1887" end_char="1888">lo</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="1890" end_char="1897">explicas</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="1899" end_char="1899">a</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="1901" end_char="1906">nature</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="1908" end_char="1908">y</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="1910" end_char="1912">das</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="1914" end_char="1919">alguna</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="1921" end_char="1926">prueba</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="1928" end_char="1931">como</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="1933" end_char="1937">hacen</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="1939" end_char="1941">los</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="1943" end_char="1953">cientificos</TOKEN>
<TOKEN id="token-23-13" pos="punct" morph="none" start_char="1954" end_char="1954">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="1960" end_char="2018">
<ORIGINAL_TEXT>Es imposible probar o refutar...sabes lo que eso significa?</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="1960" end_char="1961">Es</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="1963" end_char="1971">imposible</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="1973" end_char="1978">probar</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="1980" end_char="1980">o</TOKEN>
<TOKEN id="token-24-4" pos="unknown" morph="none" start_char="1982" end_char="1996">refutar...sabes</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="1998" end_char="1999">lo</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="2001" end_char="2003">que</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="2005" end_char="2007">eso</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="2009" end_char="2017">significa</TOKEN>
<TOKEN id="token-24-9" pos="punct" morph="none" start_char="2018" end_char="2018">?</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2020" end_char="2603">
<ORIGINAL_TEXT>Que te puedes creer que fue porque un chino un día se comió un murciélago o un pangolin o que te puedes creer que fue una cagada del único laboratorio de estudios viricos de nivel 4 de china que está en la misma ciudad donde, casualidades de la vida estaba también el chino que se comió el murciélago o pangolin que originó el virus También puedes fijarte en que china pese a ser el primer país en sufrirlo se tomó muy en serio el virus cerrando la ciudad por completo con apenas 500 infectados, lo que igual nos dice que sabían muy bien a lo que se enfrentaban, ahora dale vueltas...</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="2020" end_char="2022">Que</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="2024" end_char="2025">te</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="2027" end_char="2032">puedes</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="2034" end_char="2038">creer</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="2040" end_char="2042">que</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="2044" end_char="2046">fue</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="2048" end_char="2053">porque</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="2055" end_char="2056">un</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="2058" end_char="2062">chino</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="2064" end_char="2065">un</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="2067" end_char="2069">día</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="2071" end_char="2072">se</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="2074" end_char="2078">comió</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="2080" end_char="2081">un</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="2083" end_char="2092">murciélago</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="2094" end_char="2094">o</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="2096" end_char="2097">un</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="2099" end_char="2106">pangolin</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="2108" end_char="2108">o</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="2110" end_char="2112">que</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="2114" end_char="2115">te</TOKEN>
<TOKEN id="token-25-21" pos="word" morph="none" start_char="2117" end_char="2122">puedes</TOKEN>
<TOKEN id="token-25-22" pos="word" morph="none" start_char="2124" end_char="2128">creer</TOKEN>
<TOKEN id="token-25-23" pos="word" morph="none" start_char="2130" end_char="2132">que</TOKEN>
<TOKEN id="token-25-24" pos="word" morph="none" start_char="2134" end_char="2136">fue</TOKEN>
<TOKEN id="token-25-25" pos="word" morph="none" start_char="2138" end_char="2140">una</TOKEN>
<TOKEN id="token-25-26" pos="word" morph="none" start_char="2142" end_char="2147">cagada</TOKEN>
<TOKEN id="token-25-27" pos="word" morph="none" start_char="2149" end_char="2151">del</TOKEN>
<TOKEN id="token-25-28" pos="word" morph="none" start_char="2153" end_char="2157">único</TOKEN>
<TOKEN id="token-25-29" pos="word" morph="none" start_char="2159" end_char="2169">laboratorio</TOKEN>
<TOKEN id="token-25-30" pos="word" morph="none" start_char="2171" end_char="2172">de</TOKEN>
<TOKEN id="token-25-31" pos="word" morph="none" start_char="2174" end_char="2181">estudios</TOKEN>
<TOKEN id="token-25-32" pos="word" morph="none" start_char="2183" end_char="2189">viricos</TOKEN>
<TOKEN id="token-25-33" pos="word" morph="none" start_char="2191" end_char="2192">de</TOKEN>
<TOKEN id="token-25-34" pos="word" morph="none" start_char="2194" end_char="2198">nivel</TOKEN>
<TOKEN id="token-25-35" pos="word" morph="none" start_char="2200" end_char="2200">4</TOKEN>
<TOKEN id="token-25-36" pos="word" morph="none" start_char="2202" end_char="2203">de</TOKEN>
<TOKEN id="token-25-37" pos="word" morph="none" start_char="2205" end_char="2209">china</TOKEN>
<TOKEN id="token-25-38" pos="word" morph="none" start_char="2211" end_char="2213">que</TOKEN>
<TOKEN id="token-25-39" pos="word" morph="none" start_char="2215" end_char="2218">está</TOKEN>
<TOKEN id="token-25-40" pos="word" morph="none" start_char="2220" end_char="2221">en</TOKEN>
<TOKEN id="token-25-41" pos="word" morph="none" start_char="2223" end_char="2224">la</TOKEN>
<TOKEN id="token-25-42" pos="word" morph="none" start_char="2226" end_char="2230">misma</TOKEN>
<TOKEN id="token-25-43" pos="word" morph="none" start_char="2232" end_char="2237">ciudad</TOKEN>
<TOKEN id="token-25-44" pos="word" morph="none" start_char="2239" end_char="2243">donde</TOKEN>
<TOKEN id="token-25-45" pos="punct" morph="none" start_char="2244" end_char="2244">,</TOKEN>
<TOKEN id="token-25-46" pos="word" morph="none" start_char="2246" end_char="2257">casualidades</TOKEN>
<TOKEN id="token-25-47" pos="word" morph="none" start_char="2259" end_char="2260">de</TOKEN>
<TOKEN id="token-25-48" pos="word" morph="none" start_char="2262" end_char="2263">la</TOKEN>
<TOKEN id="token-25-49" pos="word" morph="none" start_char="2265" end_char="2268">vida</TOKEN>
<TOKEN id="token-25-50" pos="word" morph="none" start_char="2270" end_char="2275">estaba</TOKEN>
<TOKEN id="token-25-51" pos="word" morph="none" start_char="2277" end_char="2283">también</TOKEN>
<TOKEN id="token-25-52" pos="word" morph="none" start_char="2285" end_char="2286">el</TOKEN>
<TOKEN id="token-25-53" pos="word" morph="none" start_char="2288" end_char="2292">chino</TOKEN>
<TOKEN id="token-25-54" pos="word" morph="none" start_char="2294" end_char="2296">que</TOKEN>
<TOKEN id="token-25-55" pos="word" morph="none" start_char="2298" end_char="2299">se</TOKEN>
<TOKEN id="token-25-56" pos="word" morph="none" start_char="2301" end_char="2305">comió</TOKEN>
<TOKEN id="token-25-57" pos="word" morph="none" start_char="2307" end_char="2308">el</TOKEN>
<TOKEN id="token-25-58" pos="word" morph="none" start_char="2310" end_char="2319">murciélago</TOKEN>
<TOKEN id="token-25-59" pos="word" morph="none" start_char="2321" end_char="2321">o</TOKEN>
<TOKEN id="token-25-60" pos="word" morph="none" start_char="2323" end_char="2330">pangolin</TOKEN>
<TOKEN id="token-25-61" pos="word" morph="none" start_char="2332" end_char="2334">que</TOKEN>
<TOKEN id="token-25-62" pos="word" morph="none" start_char="2336" end_char="2342">originó</TOKEN>
<TOKEN id="token-25-63" pos="word" morph="none" start_char="2344" end_char="2345">el</TOKEN>
<TOKEN id="token-25-64" pos="word" morph="none" start_char="2347" end_char="2351">virus</TOKEN>
<TOKEN id="token-25-65" pos="word" morph="none" start_char="2353" end_char="2359">También</TOKEN>
<TOKEN id="token-25-66" pos="word" morph="none" start_char="2361" end_char="2366">puedes</TOKEN>
<TOKEN id="token-25-67" pos="word" morph="none" start_char="2368" end_char="2374">fijarte</TOKEN>
<TOKEN id="token-25-68" pos="word" morph="none" start_char="2376" end_char="2377">en</TOKEN>
<TOKEN id="token-25-69" pos="word" morph="none" start_char="2379" end_char="2381">que</TOKEN>
<TOKEN id="token-25-70" pos="word" morph="none" start_char="2383" end_char="2387">china</TOKEN>
<TOKEN id="token-25-71" pos="word" morph="none" start_char="2389" end_char="2392">pese</TOKEN>
<TOKEN id="token-25-72" pos="word" morph="none" start_char="2394" end_char="2394">a</TOKEN>
<TOKEN id="token-25-73" pos="word" morph="none" start_char="2396" end_char="2398">ser</TOKEN>
<TOKEN id="token-25-74" pos="word" morph="none" start_char="2400" end_char="2401">el</TOKEN>
<TOKEN id="token-25-75" pos="word" morph="none" start_char="2403" end_char="2408">primer</TOKEN>
<TOKEN id="token-25-76" pos="word" morph="none" start_char="2410" end_char="2413">país</TOKEN>
<TOKEN id="token-25-77" pos="word" morph="none" start_char="2415" end_char="2416">en</TOKEN>
<TOKEN id="token-25-78" pos="word" morph="none" start_char="2418" end_char="2425">sufrirlo</TOKEN>
<TOKEN id="token-25-79" pos="word" morph="none" start_char="2427" end_char="2428">se</TOKEN>
<TOKEN id="token-25-80" pos="word" morph="none" start_char="2430" end_char="2433">tomó</TOKEN>
<TOKEN id="token-25-81" pos="word" morph="none" start_char="2435" end_char="2437">muy</TOKEN>
<TOKEN id="token-25-82" pos="word" morph="none" start_char="2439" end_char="2440">en</TOKEN>
<TOKEN id="token-25-83" pos="word" morph="none" start_char="2442" end_char="2446">serio</TOKEN>
<TOKEN id="token-25-84" pos="word" morph="none" start_char="2448" end_char="2449">el</TOKEN>
<TOKEN id="token-25-85" pos="word" morph="none" start_char="2451" end_char="2455">virus</TOKEN>
<TOKEN id="token-25-86" pos="word" morph="none" start_char="2457" end_char="2464">cerrando</TOKEN>
<TOKEN id="token-25-87" pos="word" morph="none" start_char="2466" end_char="2467">la</TOKEN>
<TOKEN id="token-25-88" pos="word" morph="none" start_char="2469" end_char="2474">ciudad</TOKEN>
<TOKEN id="token-25-89" pos="word" morph="none" start_char="2476" end_char="2478">por</TOKEN>
<TOKEN id="token-25-90" pos="word" morph="none" start_char="2480" end_char="2487">completo</TOKEN>
<TOKEN id="token-25-91" pos="word" morph="none" start_char="2489" end_char="2491">con</TOKEN>
<TOKEN id="token-25-92" pos="word" morph="none" start_char="2493" end_char="2498">apenas</TOKEN>
<TOKEN id="token-25-93" pos="word" morph="none" start_char="2500" end_char="2502">500</TOKEN>
<TOKEN id="token-25-94" pos="word" morph="none" start_char="2504" end_char="2513">infectados</TOKEN>
<TOKEN id="token-25-95" pos="punct" morph="none" start_char="2514" end_char="2514">,</TOKEN>
<TOKEN id="token-25-96" pos="word" morph="none" start_char="2516" end_char="2517">lo</TOKEN>
<TOKEN id="token-25-97" pos="word" morph="none" start_char="2519" end_char="2521">que</TOKEN>
<TOKEN id="token-25-98" pos="word" morph="none" start_char="2523" end_char="2527">igual</TOKEN>
<TOKEN id="token-25-99" pos="word" morph="none" start_char="2529" end_char="2531">nos</TOKEN>
<TOKEN id="token-25-100" pos="word" morph="none" start_char="2533" end_char="2536">dice</TOKEN>
<TOKEN id="token-25-101" pos="word" morph="none" start_char="2538" end_char="2540">que</TOKEN>
<TOKEN id="token-25-102" pos="word" morph="none" start_char="2542" end_char="2547">sabían</TOKEN>
<TOKEN id="token-25-103" pos="word" morph="none" start_char="2549" end_char="2551">muy</TOKEN>
<TOKEN id="token-25-104" pos="word" morph="none" start_char="2553" end_char="2556">bien</TOKEN>
<TOKEN id="token-25-105" pos="word" morph="none" start_char="2558" end_char="2558">a</TOKEN>
<TOKEN id="token-25-106" pos="word" morph="none" start_char="2560" end_char="2561">lo</TOKEN>
<TOKEN id="token-25-107" pos="word" morph="none" start_char="2563" end_char="2565">que</TOKEN>
<TOKEN id="token-25-108" pos="word" morph="none" start_char="2567" end_char="2568">se</TOKEN>
<TOKEN id="token-25-109" pos="word" morph="none" start_char="2570" end_char="2580">enfrentaban</TOKEN>
<TOKEN id="token-25-110" pos="punct" morph="none" start_char="2581" end_char="2581">,</TOKEN>
<TOKEN id="token-25-111" pos="word" morph="none" start_char="2583" end_char="2587">ahora</TOKEN>
<TOKEN id="token-25-112" pos="word" morph="none" start_char="2589" end_char="2592">dale</TOKEN>
<TOKEN id="token-25-113" pos="word" morph="none" start_char="2594" end_char="2600">vueltas</TOKEN>
<TOKEN id="token-25-114" pos="punct" morph="none" start_char="2601" end_char="2603">...</TOKEN>
</SEG>
<SEG id="segment-26" start_char="2609" end_char="2613">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="2609" end_char="2612">Cita</TOKEN>
<TOKEN id="token-26-1" pos="punct" morph="none" start_char="2613" end_char="2613">:</TOKEN>
</SEG>
<SEG id="segment-27" start_char="2618" end_char="2670">
<ORIGINAL_TEXT>Originalmente Escrito por Tidus23 ¿Y qué van a decir?</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="2618" end_char="2630">Originalmente</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="2632" end_char="2638">Escrito</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="2640" end_char="2642">por</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="2644" end_char="2650">Tidus23</TOKEN>
<TOKEN id="token-27-4" pos="punct" morph="none" start_char="2652" end_char="2652">¿</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="2653" end_char="2653">Y</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="2655" end_char="2657">qué</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="2659" end_char="2661">van</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="2663" end_char="2663">a</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="2665" end_char="2669">decir</TOKEN>
<TOKEN id="token-27-10" pos="punct" morph="none" start_char="2670" end_char="2670">?</TOKEN>
</SEG>
<SEG id="segment-28" start_char="2675" end_char="2679">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="2675" end_char="2678">Cita</TOKEN>
<TOKEN id="token-28-1" pos="punct" morph="none" start_char="2679" end_char="2679">:</TOKEN>
</SEG>
<SEG id="segment-29" start_char="2684" end_char="2780">
<ORIGINAL_TEXT>Originalmente Escrito por Laverdad30 Si te crees todo lo que dice esta revista es que eres tonto.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="2684" end_char="2696">Originalmente</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="2698" end_char="2704">Escrito</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="2706" end_char="2708">por</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="2710" end_char="2719">Laverdad30</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="2721" end_char="2722">Si</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="2724" end_char="2725">te</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="2727" end_char="2731">crees</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="2733" end_char="2736">todo</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="2738" end_char="2739">lo</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="2741" end_char="2743">que</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="2745" end_char="2748">dice</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="2750" end_char="2753">esta</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="2755" end_char="2761">revista</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="2763" end_char="2764">es</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="2766" end_char="2768">que</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="2770" end_char="2773">eres</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="2775" end_char="2779">tonto</TOKEN>
<TOKEN id="token-29-17" pos="punct" morph="none" start_char="2780" end_char="2780">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="2789" end_char="2793">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="2789" end_char="2792">Cita</TOKEN>
<TOKEN id="token-30-1" pos="punct" morph="none" start_char="2793" end_char="2793">:</TOKEN>
</SEG>
<SEG id="segment-31" start_char="2798" end_char="2853">
<ORIGINAL_TEXT>Originalmente Escrito por RAFisher Tardo poco el primero</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="2798" end_char="2810">Originalmente</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="2812" end_char="2818">Escrito</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="2820" end_char="2822">por</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="2824" end_char="2831">RAFisher</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="2833" end_char="2837">Tardo</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="2839" end_char="2842">poco</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="2844" end_char="2845">el</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="2847" end_char="2853">primero</TOKEN>
</SEG>
<SEG id="segment-32" start_char="2858" end_char="2932">
<ORIGINAL_TEXT>No opino, sólo digo que sea una cosa u otra está claro lo que iban a decir.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="2858" end_char="2859">No</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="2861" end_char="2865">opino</TOKEN>
<TOKEN id="token-32-2" pos="punct" morph="none" start_char="2866" end_char="2866">,</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="2868" end_char="2871">sólo</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="2873" end_char="2876">digo</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="2878" end_char="2880">que</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="2882" end_char="2884">sea</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="2886" end_char="2888">una</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="2890" end_char="2893">cosa</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="2895" end_char="2895">u</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="2897" end_char="2900">otra</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="2902" end_char="2905">está</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="2907" end_char="2911">claro</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="2913" end_char="2914">lo</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="2916" end_char="2918">que</TOKEN>
<TOKEN id="token-32-15" pos="word" morph="none" start_char="2920" end_char="2923">iban</TOKEN>
<TOKEN id="token-32-16" pos="word" morph="none" start_char="2925" end_char="2925">a</TOKEN>
<TOKEN id="token-32-17" pos="word" morph="none" start_char="2927" end_char="2931">decir</TOKEN>
<TOKEN id="token-32-18" pos="punct" morph="none" start_char="2932" end_char="2932">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="2938" end_char="2942">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="2938" end_char="2941">Cita</TOKEN>
<TOKEN id="token-33-1" pos="punct" morph="none" start_char="2942" end_char="2942">:</TOKEN>
</SEG>
<SEG id="segment-34" start_char="2947" end_char="3465">
<ORIGINAL_TEXT>Originalmente Escrito por RAFisher Magufos y biologos del bar Pepe se cae el mito: "Aunque la evidencia muestra que el SARS-CoV-2 no es un virus manipulado a propósito, actualmente es imposible probar o refutar las otras teorías de su origen descritas aquí. Sin embargo, dado que observamos todas las características notables de SARS-CoV-2, incluida la RBD optimizada y el sitio de escisión polibásica, en coronavirus relacionados en la naturaleza, no creemos que ningún tipo de escenario de laboratorio sea plausible."</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="2947" end_char="2959">Originalmente</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="2961" end_char="2967">Escrito</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="2969" end_char="2971">por</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="2973" end_char="2980">RAFisher</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="2982" end_char="2988">Magufos</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="2990" end_char="2990">y</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="2992" end_char="2999">biologos</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="3001" end_char="3003">del</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="3005" end_char="3007">bar</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="3009" end_char="3012">Pepe</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="3014" end_char="3015">se</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="3017" end_char="3019">cae</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="3021" end_char="3022">el</TOKEN>
<TOKEN id="token-34-13" pos="word" morph="none" start_char="3024" end_char="3027">mito</TOKEN>
<TOKEN id="token-34-14" pos="punct" morph="none" start_char="3028" end_char="3028">:</TOKEN>
<TOKEN id="token-34-15" pos="punct" morph="none" start_char="3030" end_char="3030">"</TOKEN>
<TOKEN id="token-34-16" pos="word" morph="none" start_char="3031" end_char="3036">Aunque</TOKEN>
<TOKEN id="token-34-17" pos="word" morph="none" start_char="3038" end_char="3039">la</TOKEN>
<TOKEN id="token-34-18" pos="word" morph="none" start_char="3041" end_char="3049">evidencia</TOKEN>
<TOKEN id="token-34-19" pos="word" morph="none" start_char="3051" end_char="3057">muestra</TOKEN>
<TOKEN id="token-34-20" pos="word" morph="none" start_char="3059" end_char="3061">que</TOKEN>
<TOKEN id="token-34-21" pos="word" morph="none" start_char="3063" end_char="3064">el</TOKEN>
<TOKEN id="token-34-22" pos="unknown" morph="none" start_char="3066" end_char="3075">SARS-CoV-2</TOKEN>
<TOKEN id="token-34-23" pos="word" morph="none" start_char="3077" end_char="3078">no</TOKEN>
<TOKEN id="token-34-24" pos="word" morph="none" start_char="3080" end_char="3081">es</TOKEN>
<TOKEN id="token-34-25" pos="word" morph="none" start_char="3083" end_char="3084">un</TOKEN>
<TOKEN id="token-34-26" pos="word" morph="none" start_char="3086" end_char="3090">virus</TOKEN>
<TOKEN id="token-34-27" pos="word" morph="none" start_char="3092" end_char="3101">manipulado</TOKEN>
<TOKEN id="token-34-28" pos="word" morph="none" start_char="3103" end_char="3103">a</TOKEN>
<TOKEN id="token-34-29" pos="word" morph="none" start_char="3105" end_char="3113">propósito</TOKEN>
<TOKEN id="token-34-30" pos="punct" morph="none" start_char="3114" end_char="3114">,</TOKEN>
<TOKEN id="token-34-31" pos="word" morph="none" start_char="3116" end_char="3126">actualmente</TOKEN>
<TOKEN id="token-34-32" pos="word" morph="none" start_char="3128" end_char="3129">es</TOKEN>
<TOKEN id="token-34-33" pos="word" morph="none" start_char="3131" end_char="3139">imposible</TOKEN>
<TOKEN id="token-34-34" pos="word" morph="none" start_char="3141" end_char="3146">probar</TOKEN>
<TOKEN id="token-34-35" pos="word" morph="none" start_char="3148" end_char="3148">o</TOKEN>
<TOKEN id="token-34-36" pos="word" morph="none" start_char="3150" end_char="3156">refutar</TOKEN>
<TOKEN id="token-34-37" pos="word" morph="none" start_char="3158" end_char="3160">las</TOKEN>
<TOKEN id="token-34-38" pos="word" morph="none" start_char="3162" end_char="3166">otras</TOKEN>
<TOKEN id="token-34-39" pos="word" morph="none" start_char="3168" end_char="3174">teorías</TOKEN>
<TOKEN id="token-34-40" pos="word" morph="none" start_char="3176" end_char="3177">de</TOKEN>
<TOKEN id="token-34-41" pos="word" morph="none" start_char="3179" end_char="3180">su</TOKEN>
<TOKEN id="token-34-42" pos="word" morph="none" start_char="3182" end_char="3187">origen</TOKEN>
<TOKEN id="token-34-43" pos="word" morph="none" start_char="3189" end_char="3197">descritas</TOKEN>
<TOKEN id="token-34-44" pos="word" morph="none" start_char="3199" end_char="3202">aquí</TOKEN>
<TOKEN id="token-34-45" pos="punct" morph="none" start_char="3203" end_char="3203">.</TOKEN>
<TOKEN id="token-34-46" pos="word" morph="none" start_char="3205" end_char="3207">Sin</TOKEN>
<TOKEN id="token-34-47" pos="word" morph="none" start_char="3209" end_char="3215">embargo</TOKEN>
<TOKEN id="token-34-48" pos="punct" morph="none" start_char="3216" end_char="3216">,</TOKEN>
<TOKEN id="token-34-49" pos="word" morph="none" start_char="3218" end_char="3221">dado</TOKEN>
<TOKEN id="token-34-50" pos="word" morph="none" start_char="3223" end_char="3225">que</TOKEN>
<TOKEN id="token-34-51" pos="word" morph="none" start_char="3227" end_char="3236">observamos</TOKEN>
<TOKEN id="token-34-52" pos="word" morph="none" start_char="3238" end_char="3242">todas</TOKEN>
<TOKEN id="token-34-53" pos="word" morph="none" start_char="3244" end_char="3246">las</TOKEN>
<TOKEN id="token-34-54" pos="word" morph="none" start_char="3248" end_char="3262">características</TOKEN>
<TOKEN id="token-34-55" pos="word" morph="none" start_char="3264" end_char="3271">notables</TOKEN>
<TOKEN id="token-34-56" pos="word" morph="none" start_char="3273" end_char="3274">de</TOKEN>
<TOKEN id="token-34-57" pos="unknown" morph="none" start_char="3276" end_char="3285">SARS-CoV-2</TOKEN>
<TOKEN id="token-34-58" pos="punct" morph="none" start_char="3286" end_char="3286">,</TOKEN>
<TOKEN id="token-34-59" pos="word" morph="none" start_char="3288" end_char="3295">incluida</TOKEN>
<TOKEN id="token-34-60" pos="word" morph="none" start_char="3297" end_char="3298">la</TOKEN>
<TOKEN id="token-34-61" pos="word" morph="none" start_char="3300" end_char="3302">RBD</TOKEN>
<TOKEN id="token-34-62" pos="word" morph="none" start_char="3304" end_char="3313">optimizada</TOKEN>
<TOKEN id="token-34-63" pos="word" morph="none" start_char="3315" end_char="3315">y</TOKEN>
<TOKEN id="token-34-64" pos="word" morph="none" start_char="3317" end_char="3318">el</TOKEN>
<TOKEN id="token-34-65" pos="word" morph="none" start_char="3320" end_char="3324">sitio</TOKEN>
<TOKEN id="token-34-66" pos="word" morph="none" start_char="3326" end_char="3327">de</TOKEN>
<TOKEN id="token-34-67" pos="word" morph="none" start_char="3329" end_char="3336">escisión</TOKEN>
<TOKEN id="token-34-68" pos="word" morph="none" start_char="3338" end_char="3347">polibásica</TOKEN>
<TOKEN id="token-34-69" pos="punct" morph="none" start_char="3348" end_char="3348">,</TOKEN>
<TOKEN id="token-34-70" pos="word" morph="none" start_char="3350" end_char="3351">en</TOKEN>
<TOKEN id="token-34-71" pos="word" morph="none" start_char="3353" end_char="3363">coronavirus</TOKEN>
<TOKEN id="token-34-72" pos="word" morph="none" start_char="3365" end_char="3376">relacionados</TOKEN>
<TOKEN id="token-34-73" pos="word" morph="none" start_char="3378" end_char="3379">en</TOKEN>
<TOKEN id="token-34-74" pos="word" morph="none" start_char="3381" end_char="3382">la</TOKEN>
<TOKEN id="token-34-75" pos="word" morph="none" start_char="3384" end_char="3393">naturaleza</TOKEN>
<TOKEN id="token-34-76" pos="punct" morph="none" start_char="3394" end_char="3394">,</TOKEN>
<TOKEN id="token-34-77" pos="word" morph="none" start_char="3396" end_char="3397">no</TOKEN>
<TOKEN id="token-34-78" pos="word" morph="none" start_char="3399" end_char="3405">creemos</TOKEN>
<TOKEN id="token-34-79" pos="word" morph="none" start_char="3407" end_char="3409">que</TOKEN>
<TOKEN id="token-34-80" pos="word" morph="none" start_char="3411" end_char="3416">ningún</TOKEN>
<TOKEN id="token-34-81" pos="word" morph="none" start_char="3418" end_char="3421">tipo</TOKEN>
<TOKEN id="token-34-82" pos="word" morph="none" start_char="3423" end_char="3424">de</TOKEN>
<TOKEN id="token-34-83" pos="word" morph="none" start_char="3426" end_char="3434">escenario</TOKEN>
<TOKEN id="token-34-84" pos="word" morph="none" start_char="3436" end_char="3437">de</TOKEN>
<TOKEN id="token-34-85" pos="word" morph="none" start_char="3439" end_char="3449">laboratorio</TOKEN>
<TOKEN id="token-34-86" pos="word" morph="none" start_char="3451" end_char="3453">sea</TOKEN>
<TOKEN id="token-34-87" pos="word" morph="none" start_char="3455" end_char="3463">plausible</TOKEN>
<TOKEN id="token-34-88" pos="punct" morph="none" start_char="3464" end_char="3465">."</TOKEN>
</SEG>
<SEG id="segment-35" start_char="3467" end_char="3648">
<ORIGINAL_TEXT>"Although the evidence shows that SARS-CoV-2 is not a purposefully manipulated virus, it is currently impossible to prove or disprove the other theories of its origin described here.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="punct" morph="none" start_char="3467" end_char="3467">"</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="3468" end_char="3475">Although</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="3477" end_char="3479">the</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="3481" end_char="3488">evidence</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="3490" end_char="3494">shows</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="3496" end_char="3499">that</TOKEN>
<TOKEN id="token-35-6" pos="unknown" morph="none" start_char="3501" end_char="3510">SARS-CoV-2</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="3512" end_char="3513">is</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="3515" end_char="3517">not</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="3519" end_char="3519">a</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="3521" end_char="3532">purposefully</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="3534" end_char="3544">manipulated</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="3546" end_char="3550">virus</TOKEN>
<TOKEN id="token-35-13" pos="punct" morph="none" start_char="3551" end_char="3551">,</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="3553" end_char="3554">it</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="3556" end_char="3557">is</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="3559" end_char="3567">currently</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="3569" end_char="3578">impossible</TOKEN>
<TOKEN id="token-35-18" pos="word" morph="none" start_char="3580" end_char="3581">to</TOKEN>
<TOKEN id="token-35-19" pos="word" morph="none" start_char="3583" end_char="3587">prove</TOKEN>
<TOKEN id="token-35-20" pos="word" morph="none" start_char="3589" end_char="3590">or</TOKEN>
<TOKEN id="token-35-21" pos="word" morph="none" start_char="3592" end_char="3599">disprove</TOKEN>
<TOKEN id="token-35-22" pos="word" morph="none" start_char="3601" end_char="3603">the</TOKEN>
<TOKEN id="token-35-23" pos="word" morph="none" start_char="3605" end_char="3609">other</TOKEN>
<TOKEN id="token-35-24" pos="word" morph="none" start_char="3611" end_char="3618">theories</TOKEN>
<TOKEN id="token-35-25" pos="word" morph="none" start_char="3620" end_char="3621">of</TOKEN>
<TOKEN id="token-35-26" pos="word" morph="none" start_char="3623" end_char="3625">its</TOKEN>
<TOKEN id="token-35-27" pos="word" morph="none" start_char="3627" end_char="3632">origin</TOKEN>
<TOKEN id="token-35-28" pos="word" morph="none" start_char="3634" end_char="3642">described</TOKEN>
<TOKEN id="token-35-29" pos="word" morph="none" start_char="3644" end_char="3647">here</TOKEN>
<TOKEN id="token-35-30" pos="punct" morph="none" start_char="3648" end_char="3648">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="3650" end_char="3877">
<ORIGINAL_TEXT>However, since we observed all notable SARS-CoV-2 features, including the optimized RBD and polybasic cleavage site, in related coronaviruses in nature, we do not believe that any type of laboratory-based scenario is plausible."</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="3650" end_char="3656">However</TOKEN>
<TOKEN id="token-36-1" pos="punct" morph="none" start_char="3657" end_char="3657">,</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="3659" end_char="3663">since</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="3665" end_char="3666">we</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="3668" end_char="3675">observed</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="3677" end_char="3679">all</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="3681" end_char="3687">notable</TOKEN>
<TOKEN id="token-36-7" pos="unknown" morph="none" start_char="3689" end_char="3698">SARS-CoV-2</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="3700" end_char="3707">features</TOKEN>
<TOKEN id="token-36-9" pos="punct" morph="none" start_char="3708" end_char="3708">,</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="3710" end_char="3718">including</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="3720" end_char="3722">the</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="3724" end_char="3732">optimized</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="3734" end_char="3736">RBD</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="3738" end_char="3740">and</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="3742" end_char="3750">polybasic</TOKEN>
<TOKEN id="token-36-16" pos="word" morph="none" start_char="3752" end_char="3759">cleavage</TOKEN>
<TOKEN id="token-36-17" pos="word" morph="none" start_char="3761" end_char="3764">site</TOKEN>
<TOKEN id="token-36-18" pos="punct" morph="none" start_char="3765" end_char="3765">,</TOKEN>
<TOKEN id="token-36-19" pos="word" morph="none" start_char="3767" end_char="3768">in</TOKEN>
<TOKEN id="token-36-20" pos="word" morph="none" start_char="3770" end_char="3776">related</TOKEN>
<TOKEN id="token-36-21" pos="word" morph="none" start_char="3778" end_char="3790">coronaviruses</TOKEN>
<TOKEN id="token-36-22" pos="word" morph="none" start_char="3792" end_char="3793">in</TOKEN>
<TOKEN id="token-36-23" pos="word" morph="none" start_char="3795" end_char="3800">nature</TOKEN>
<TOKEN id="token-36-24" pos="punct" morph="none" start_char="3801" end_char="3801">,</TOKEN>
<TOKEN id="token-36-25" pos="word" morph="none" start_char="3803" end_char="3804">we</TOKEN>
<TOKEN id="token-36-26" pos="word" morph="none" start_char="3806" end_char="3807">do</TOKEN>
<TOKEN id="token-36-27" pos="word" morph="none" start_char="3809" end_char="3811">not</TOKEN>
<TOKEN id="token-36-28" pos="word" morph="none" start_char="3813" end_char="3819">believe</TOKEN>
<TOKEN id="token-36-29" pos="word" morph="none" start_char="3821" end_char="3824">that</TOKEN>
<TOKEN id="token-36-30" pos="word" morph="none" start_char="3826" end_char="3828">any</TOKEN>
<TOKEN id="token-36-31" pos="word" morph="none" start_char="3830" end_char="3833">type</TOKEN>
<TOKEN id="token-36-32" pos="word" morph="none" start_char="3835" end_char="3836">of</TOKEN>
<TOKEN id="token-36-33" pos="unknown" morph="none" start_char="3838" end_char="3853">laboratory-based</TOKEN>
<TOKEN id="token-36-34" pos="word" morph="none" start_char="3855" end_char="3862">scenario</TOKEN>
<TOKEN id="token-36-35" pos="word" morph="none" start_char="3864" end_char="3865">is</TOKEN>
<TOKEN id="token-36-36" pos="word" morph="none" start_char="3867" end_char="3875">plausible</TOKEN>
<TOKEN id="token-36-37" pos="punct" morph="none" start_char="3876" end_char="3877">."</TOKEN>
</SEG>
<SEG id="segment-37" start_char="3879" end_char="4003">
<ORIGINAL_TEXT>https://www.nature.com/articles/s41591-020-0820-9 Nature es una de las más prestigiosas revistas científicas a nivel mundial.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="url" morph="none" start_char="3879" end_char="3927">https://www.nature.com/articles/s41591-020-0820-9</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="3929" end_char="3934">Nature</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="3936" end_char="3937">es</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="3939" end_char="3941">una</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="3943" end_char="3944">de</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="3946" end_char="3948">las</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="3950" end_char="3952">más</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="3954" end_char="3965">prestigiosas</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="3967" end_char="3974">revistas</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="3976" end_char="3986">científicas</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="3988" end_char="3988">a</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="3990" end_char="3994">nivel</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="3996" end_char="4002">mundial</TOKEN>
<TOKEN id="token-37-13" pos="punct" morph="none" start_char="4003" end_char="4003">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="4005" end_char="4092">
<ORIGINAL_TEXT>Para la mayoría de los científicos publicar en Nature constituye una marca de prestigio.</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="4005" end_char="4008">Para</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="4010" end_char="4011">la</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="4013" end_char="4019">mayoría</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="4021" end_char="4022">de</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="4024" end_char="4026">los</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="4028" end_char="4038">científicos</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="4040" end_char="4047">publicar</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="4049" end_char="4050">en</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="4052" end_char="4057">Nature</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="4059" end_char="4068">constituye</TOKEN>
<TOKEN id="token-38-10" pos="word" morph="none" start_char="4070" end_char="4072">una</TOKEN>
<TOKEN id="token-38-11" pos="word" morph="none" start_char="4074" end_char="4078">marca</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="4080" end_char="4081">de</TOKEN>
<TOKEN id="token-38-13" pos="word" morph="none" start_char="4083" end_char="4091">prestigio</TOKEN>
<TOKEN id="token-38-14" pos="punct" morph="none" start_char="4092" end_char="4092">.</TOKEN>
</SEG>
<SEG id="segment-39" start_char="4094" end_char="4192">
<ORIGINAL_TEXT>La revista rechaza en torno al 95% de los artículos que le son enviados para la revisión por pares.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="4094" end_char="4095">La</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="4097" end_char="4103">revista</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="4105" end_char="4111">rechaza</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="4113" end_char="4114">en</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="4116" end_char="4120">torno</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="4122" end_char="4123">al</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="4125" end_char="4126">95</TOKEN>
<TOKEN id="token-39-7" pos="punct" morph="none" start_char="4127" end_char="4127">%</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="4129" end_char="4130">de</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="4132" end_char="4134">los</TOKEN>
<TOKEN id="token-39-10" pos="word" morph="none" start_char="4136" end_char="4144">artículos</TOKEN>
<TOKEN id="token-39-11" pos="word" morph="none" start_char="4146" end_char="4148">que</TOKEN>
<TOKEN id="token-39-12" pos="word" morph="none" start_char="4150" end_char="4151">le</TOKEN>
<TOKEN id="token-39-13" pos="word" morph="none" start_char="4153" end_char="4155">son</TOKEN>
<TOKEN id="token-39-14" pos="word" morph="none" start_char="4157" end_char="4164">enviados</TOKEN>
<TOKEN id="token-39-15" pos="word" morph="none" start_char="4166" end_char="4169">para</TOKEN>
<TOKEN id="token-39-16" pos="word" morph="none" start_char="4171" end_char="4172">la</TOKEN>
<TOKEN id="token-39-17" pos="word" morph="none" start_char="4174" end_char="4181">revisión</TOKEN>
<TOKEN id="token-39-18" pos="word" morph="none" start_char="4183" end_char="4185">por</TOKEN>
<TOKEN id="token-39-19" pos="word" morph="none" start_char="4187" end_char="4191">pares</TOKEN>
<TOKEN id="token-39-20" pos="punct" morph="none" start_char="4192" end_char="4192">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="4194" end_char="4400">
<ORIGINAL_TEXT>No sé si ha sido creado o no, pero... 1- Se argumenta que '' since we observed all notable SARS-CoV-2 features, including the optimized RBD and polybasic cleavage site, in related coronaviruses in nature ''.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="4194" end_char="4195">No</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="4197" end_char="4198">sé</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="4200" end_char="4201">si</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="4203" end_char="4204">ha</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="4206" end_char="4209">sido</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="4211" end_char="4216">creado</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="4218" end_char="4218">o</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="4220" end_char="4221">no</TOKEN>
<TOKEN id="token-40-8" pos="punct" morph="none" start_char="4222" end_char="4222">,</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="4224" end_char="4227">pero</TOKEN>
<TOKEN id="token-40-10" pos="punct" morph="none" start_char="4228" end_char="4230">...</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="4232" end_char="4232">1</TOKEN>
<TOKEN id="token-40-12" pos="punct" morph="none" start_char="4233" end_char="4233">-</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="4235" end_char="4236">Se</TOKEN>
<TOKEN id="token-40-14" pos="word" morph="none" start_char="4238" end_char="4246">argumenta</TOKEN>
<TOKEN id="token-40-15" pos="word" morph="none" start_char="4248" end_char="4250">que</TOKEN>
<TOKEN id="token-40-16" pos="punct" morph="none" start_char="4252" end_char="4253">''</TOKEN>
<TOKEN id="token-40-17" pos="word" morph="none" start_char="4255" end_char="4259">since</TOKEN>
<TOKEN id="token-40-18" pos="word" morph="none" start_char="4261" end_char="4262">we</TOKEN>
<TOKEN id="token-40-19" pos="word" morph="none" start_char="4264" end_char="4271">observed</TOKEN>
<TOKEN id="token-40-20" pos="word" morph="none" start_char="4273" end_char="4275">all</TOKEN>
<TOKEN id="token-40-21" pos="word" morph="none" start_char="4277" end_char="4283">notable</TOKEN>
<TOKEN id="token-40-22" pos="unknown" morph="none" start_char="4285" end_char="4294">SARS-CoV-2</TOKEN>
<TOKEN id="token-40-23" pos="word" morph="none" start_char="4296" end_char="4303">features</TOKEN>
<TOKEN id="token-40-24" pos="punct" morph="none" start_char="4304" end_char="4304">,</TOKEN>
<TOKEN id="token-40-25" pos="word" morph="none" start_char="4306" end_char="4314">including</TOKEN>
<TOKEN id="token-40-26" pos="word" morph="none" start_char="4316" end_char="4318">the</TOKEN>
<TOKEN id="token-40-27" pos="word" morph="none" start_char="4320" end_char="4328">optimized</TOKEN>
<TOKEN id="token-40-28" pos="word" morph="none" start_char="4330" end_char="4332">RBD</TOKEN>
<TOKEN id="token-40-29" pos="word" morph="none" start_char="4334" end_char="4336">and</TOKEN>
<TOKEN id="token-40-30" pos="word" morph="none" start_char="4338" end_char="4346">polybasic</TOKEN>
<TOKEN id="token-40-31" pos="word" morph="none" start_char="4348" end_char="4355">cleavage</TOKEN>
<TOKEN id="token-40-32" pos="word" morph="none" start_char="4357" end_char="4360">site</TOKEN>
<TOKEN id="token-40-33" pos="punct" morph="none" start_char="4361" end_char="4361">,</TOKEN>
<TOKEN id="token-40-34" pos="word" morph="none" start_char="4363" end_char="4364">in</TOKEN>
<TOKEN id="token-40-35" pos="word" morph="none" start_char="4366" end_char="4372">related</TOKEN>
<TOKEN id="token-40-36" pos="word" morph="none" start_char="4374" end_char="4386">coronaviruses</TOKEN>
<TOKEN id="token-40-37" pos="word" morph="none" start_char="4388" end_char="4389">in</TOKEN>
<TOKEN id="token-40-38" pos="word" morph="none" start_char="4391" end_char="4396">nature</TOKEN>
<TOKEN id="token-40-39" pos="punct" morph="none" start_char="4398" end_char="4400">''.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="4402" end_char="4508">
<ORIGINAL_TEXT>Pero lo que dice (que no tengo ni puta idea) podría haber sido tenido en cuenta por los posibles creadores.</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="4402" end_char="4405">Pero</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="4407" end_char="4408">lo</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="4410" end_char="4412">que</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="4414" end_char="4417">dice</TOKEN>
<TOKEN id="token-41-4" pos="punct" morph="none" start_char="4419" end_char="4419">(</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="4420" end_char="4422">que</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="4424" end_char="4425">no</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="4427" end_char="4431">tengo</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="4433" end_char="4434">ni</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="4436" end_char="4439">puta</TOKEN>
<TOKEN id="token-41-10" pos="word" morph="none" start_char="4441" end_char="4444">idea</TOKEN>
<TOKEN id="token-41-11" pos="punct" morph="none" start_char="4445" end_char="4445">)</TOKEN>
<TOKEN id="token-41-12" pos="word" morph="none" start_char="4447" end_char="4452">podría</TOKEN>
<TOKEN id="token-41-13" pos="word" morph="none" start_char="4454" end_char="4458">haber</TOKEN>
<TOKEN id="token-41-14" pos="word" morph="none" start_char="4460" end_char="4463">sido</TOKEN>
<TOKEN id="token-41-15" pos="word" morph="none" start_char="4465" end_char="4470">tenido</TOKEN>
<TOKEN id="token-41-16" pos="word" morph="none" start_char="4472" end_char="4473">en</TOKEN>
<TOKEN id="token-41-17" pos="word" morph="none" start_char="4475" end_char="4480">cuenta</TOKEN>
<TOKEN id="token-41-18" pos="word" morph="none" start_char="4482" end_char="4484">por</TOKEN>
<TOKEN id="token-41-19" pos="word" morph="none" start_char="4486" end_char="4488">los</TOKEN>
<TOKEN id="token-41-20" pos="word" morph="none" start_char="4490" end_char="4497">posibles</TOKEN>
<TOKEN id="token-41-21" pos="word" morph="none" start_char="4499" end_char="4507">creadores</TOKEN>
<TOKEN id="token-41-22" pos="punct" morph="none" start_char="4508" end_char="4508">.</TOKEN>
</SEG>
<SEG id="segment-42" start_char="4510" end_char="4685">
<ORIGINAL_TEXT>Porque los creadores de virus entenderán de virus, y puestos a crear uno, seguro que si pueden, lo habrían hecho teniendo en cuenta esto para que no se note que ha sido creado.</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="4510" end_char="4515">Porque</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="4517" end_char="4519">los</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="4521" end_char="4529">creadores</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="4531" end_char="4532">de</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="4534" end_char="4538">virus</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="4540" end_char="4549">entenderán</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="4551" end_char="4552">de</TOKEN>
<TOKEN id="token-42-7" pos="word" morph="none" start_char="4554" end_char="4558">virus</TOKEN>
<TOKEN id="token-42-8" pos="punct" morph="none" start_char="4559" end_char="4559">,</TOKEN>
<TOKEN id="token-42-9" pos="word" morph="none" start_char="4561" end_char="4561">y</TOKEN>
<TOKEN id="token-42-10" pos="word" morph="none" start_char="4563" end_char="4569">puestos</TOKEN>
<TOKEN id="token-42-11" pos="word" morph="none" start_char="4571" end_char="4571">a</TOKEN>
<TOKEN id="token-42-12" pos="word" morph="none" start_char="4573" end_char="4577">crear</TOKEN>
<TOKEN id="token-42-13" pos="word" morph="none" start_char="4579" end_char="4581">uno</TOKEN>
<TOKEN id="token-42-14" pos="punct" morph="none" start_char="4582" end_char="4582">,</TOKEN>
<TOKEN id="token-42-15" pos="word" morph="none" start_char="4584" end_char="4589">seguro</TOKEN>
<TOKEN id="token-42-16" pos="word" morph="none" start_char="4591" end_char="4593">que</TOKEN>
<TOKEN id="token-42-17" pos="word" morph="none" start_char="4595" end_char="4596">si</TOKEN>
<TOKEN id="token-42-18" pos="word" morph="none" start_char="4598" end_char="4603">pueden</TOKEN>
<TOKEN id="token-42-19" pos="punct" morph="none" start_char="4604" end_char="4604">,</TOKEN>
<TOKEN id="token-42-20" pos="word" morph="none" start_char="4606" end_char="4607">lo</TOKEN>
<TOKEN id="token-42-21" pos="word" morph="none" start_char="4609" end_char="4615">habrían</TOKEN>
<TOKEN id="token-42-22" pos="word" morph="none" start_char="4617" end_char="4621">hecho</TOKEN>
<TOKEN id="token-42-23" pos="word" morph="none" start_char="4623" end_char="4630">teniendo</TOKEN>
<TOKEN id="token-42-24" pos="word" morph="none" start_char="4632" end_char="4633">en</TOKEN>
<TOKEN id="token-42-25" pos="word" morph="none" start_char="4635" end_char="4640">cuenta</TOKEN>
<TOKEN id="token-42-26" pos="word" morph="none" start_char="4642" end_char="4645">esto</TOKEN>
<TOKEN id="token-42-27" pos="word" morph="none" start_char="4647" end_char="4650">para</TOKEN>
<TOKEN id="token-42-28" pos="word" morph="none" start_char="4652" end_char="4654">que</TOKEN>
<TOKEN id="token-42-29" pos="word" morph="none" start_char="4656" end_char="4657">no</TOKEN>
<TOKEN id="token-42-30" pos="word" morph="none" start_char="4659" end_char="4660">se</TOKEN>
<TOKEN id="token-42-31" pos="word" morph="none" start_char="4662" end_char="4665">note</TOKEN>
<TOKEN id="token-42-32" pos="word" morph="none" start_char="4667" end_char="4669">que</TOKEN>
<TOKEN id="token-42-33" pos="word" morph="none" start_char="4671" end_char="4672">ha</TOKEN>
<TOKEN id="token-42-34" pos="word" morph="none" start_char="4674" end_char="4677">sido</TOKEN>
<TOKEN id="token-42-35" pos="word" morph="none" start_char="4679" end_char="4684">creado</TOKEN>
<TOKEN id="token-42-36" pos="punct" morph="none" start_char="4685" end_char="4685">.</TOKEN>
</SEG>
<SEG id="segment-43" start_char="4687" end_char="4745">
<ORIGINAL_TEXT>2- Las élites influyen mucho en quién obtiene el prestigio.</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="4687" end_char="4687">2</TOKEN>
<TOKEN id="token-43-1" pos="punct" morph="none" start_char="4688" end_char="4688">-</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="4690" end_char="4692">Las</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="4694" end_char="4699">élites</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="4701" end_char="4708">influyen</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="4710" end_char="4714">mucho</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="4716" end_char="4717">en</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="4719" end_char="4723">quién</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="4725" end_char="4731">obtiene</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="4733" end_char="4734">el</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="4736" end_char="4744">prestigio</TOKEN>
<TOKEN id="token-43-11" pos="punct" morph="none" start_char="4745" end_char="4745">.</TOKEN>
</SEG>
<SEG id="segment-44" start_char="4747" end_char="4784">
<ORIGINAL_TEXT>El dinero lo mueve todo en este mundo.</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="4747" end_char="4748">El</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="4750" end_char="4755">dinero</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="4757" end_char="4758">lo</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="4760" end_char="4764">mueve</TOKEN>
<TOKEN id="token-44-4" pos="word" morph="none" start_char="4766" end_char="4769">todo</TOKEN>
<TOKEN id="token-44-5" pos="word" morph="none" start_char="4771" end_char="4772">en</TOKEN>
<TOKEN id="token-44-6" pos="word" morph="none" start_char="4774" end_char="4777">este</TOKEN>
<TOKEN id="token-44-7" pos="word" morph="none" start_char="4779" end_char="4783">mundo</TOKEN>
<TOKEN id="token-44-8" pos="punct" morph="none" start_char="4784" end_char="4784">.</TOKEN>
</SEG>
<SEG id="segment-45" start_char="4786" end_char="4870">
<ORIGINAL_TEXT>Que lo diga una publicación en la revista nature, prestigiosa, tampoco nos dice nada.</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="4786" end_char="4788">Que</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="4790" end_char="4791">lo</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="4793" end_char="4796">diga</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="4798" end_char="4800">una</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="4802" end_char="4812">publicación</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="4814" end_char="4815">en</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="4817" end_char="4818">la</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="4820" end_char="4826">revista</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="4828" end_char="4833">nature</TOKEN>
<TOKEN id="token-45-9" pos="punct" morph="none" start_char="4834" end_char="4834">,</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="4836" end_char="4846">prestigiosa</TOKEN>
<TOKEN id="token-45-11" pos="punct" morph="none" start_char="4847" end_char="4847">,</TOKEN>
<TOKEN id="token-45-12" pos="word" morph="none" start_char="4849" end_char="4855">tampoco</TOKEN>
<TOKEN id="token-45-13" pos="word" morph="none" start_char="4857" end_char="4859">nos</TOKEN>
<TOKEN id="token-45-14" pos="word" morph="none" start_char="4861" end_char="4864">dice</TOKEN>
<TOKEN id="token-45-15" pos="word" morph="none" start_char="4866" end_char="4869">nada</TOKEN>
<TOKEN id="token-45-16" pos="punct" morph="none" start_char="4870" end_char="4870">.</TOKEN>
</SEG>
<SEG id="segment-46" start_char="4872" end_char="5135">
<ORIGINAL_TEXT>y 3- Si las élites hubieran creado el virus, efectivamente lo que harían sería hacer lo que digo en el punto 1, y usarían su poder para publicarlo en la revista, para lograr el efecto de la falacia ad verecundiam que cuela muy bien entre la gente media de la masa.</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="4872" end_char="4872">y</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="4874" end_char="4874">3</TOKEN>
<TOKEN id="token-46-2" pos="punct" morph="none" start_char="4875" end_char="4875">-</TOKEN>
<TOKEN id="token-46-3" pos="word" morph="none" start_char="4877" end_char="4878">Si</TOKEN>
<TOKEN id="token-46-4" pos="word" morph="none" start_char="4880" end_char="4882">las</TOKEN>
<TOKEN id="token-46-5" pos="word" morph="none" start_char="4884" end_char="4889">élites</TOKEN>
<TOKEN id="token-46-6" pos="word" morph="none" start_char="4891" end_char="4898">hubieran</TOKEN>
<TOKEN id="token-46-7" pos="word" morph="none" start_char="4900" end_char="4905">creado</TOKEN>
<TOKEN id="token-46-8" pos="word" morph="none" start_char="4907" end_char="4908">el</TOKEN>
<TOKEN id="token-46-9" pos="word" morph="none" start_char="4910" end_char="4914">virus</TOKEN>
<TOKEN id="token-46-10" pos="punct" morph="none" start_char="4915" end_char="4915">,</TOKEN>
<TOKEN id="token-46-11" pos="word" morph="none" start_char="4917" end_char="4929">efectivamente</TOKEN>
<TOKEN id="token-46-12" pos="word" morph="none" start_char="4931" end_char="4932">lo</TOKEN>
<TOKEN id="token-46-13" pos="word" morph="none" start_char="4934" end_char="4936">que</TOKEN>
<TOKEN id="token-46-14" pos="word" morph="none" start_char="4938" end_char="4943">harían</TOKEN>
<TOKEN id="token-46-15" pos="word" morph="none" start_char="4945" end_char="4949">sería</TOKEN>
<TOKEN id="token-46-16" pos="word" morph="none" start_char="4951" end_char="4955">hacer</TOKEN>
<TOKEN id="token-46-17" pos="word" morph="none" start_char="4957" end_char="4958">lo</TOKEN>
<TOKEN id="token-46-18" pos="word" morph="none" start_char="4960" end_char="4962">que</TOKEN>
<TOKEN id="token-46-19" pos="word" morph="none" start_char="4964" end_char="4967">digo</TOKEN>
<TOKEN id="token-46-20" pos="word" morph="none" start_char="4969" end_char="4970">en</TOKEN>
<TOKEN id="token-46-21" pos="word" morph="none" start_char="4972" end_char="4973">el</TOKEN>
<TOKEN id="token-46-22" pos="word" morph="none" start_char="4975" end_char="4979">punto</TOKEN>
<TOKEN id="token-46-23" pos="word" morph="none" start_char="4981" end_char="4981">1</TOKEN>
<TOKEN id="token-46-24" pos="punct" morph="none" start_char="4982" end_char="4982">,</TOKEN>
<TOKEN id="token-46-25" pos="word" morph="none" start_char="4984" end_char="4984">y</TOKEN>
<TOKEN id="token-46-26" pos="word" morph="none" start_char="4986" end_char="4992">usarían</TOKEN>
<TOKEN id="token-46-27" pos="word" morph="none" start_char="4994" end_char="4995">su</TOKEN>
<TOKEN id="token-46-28" pos="word" morph="none" start_char="4997" end_char="5001">poder</TOKEN>
<TOKEN id="token-46-29" pos="word" morph="none" start_char="5003" end_char="5006">para</TOKEN>
<TOKEN id="token-46-30" pos="word" morph="none" start_char="5008" end_char="5017">publicarlo</TOKEN>
<TOKEN id="token-46-31" pos="word" morph="none" start_char="5019" end_char="5020">en</TOKEN>
<TOKEN id="token-46-32" pos="word" morph="none" start_char="5022" end_char="5023">la</TOKEN>
<TOKEN id="token-46-33" pos="word" morph="none" start_char="5025" end_char="5031">revista</TOKEN>
<TOKEN id="token-46-34" pos="punct" morph="none" start_char="5032" end_char="5032">,</TOKEN>
<TOKEN id="token-46-35" pos="word" morph="none" start_char="5034" end_char="5037">para</TOKEN>
<TOKEN id="token-46-36" pos="word" morph="none" start_char="5039" end_char="5044">lograr</TOKEN>
<TOKEN id="token-46-37" pos="word" morph="none" start_char="5046" end_char="5047">el</TOKEN>
<TOKEN id="token-46-38" pos="word" morph="none" start_char="5049" end_char="5054">efecto</TOKEN>
<TOKEN id="token-46-39" pos="word" morph="none" start_char="5056" end_char="5057">de</TOKEN>
<TOKEN id="token-46-40" pos="word" morph="none" start_char="5059" end_char="5060">la</TOKEN>
<TOKEN id="token-46-41" pos="word" morph="none" start_char="5062" end_char="5068">falacia</TOKEN>
<TOKEN id="token-46-42" pos="word" morph="none" start_char="5070" end_char="5071">ad</TOKEN>
<TOKEN id="token-46-43" pos="word" morph="none" start_char="5073" end_char="5083">verecundiam</TOKEN>
<TOKEN id="token-46-44" pos="word" morph="none" start_char="5085" end_char="5087">que</TOKEN>
<TOKEN id="token-46-45" pos="word" morph="none" start_char="5089" end_char="5093">cuela</TOKEN>
<TOKEN id="token-46-46" pos="word" morph="none" start_char="5095" end_char="5097">muy</TOKEN>
<TOKEN id="token-46-47" pos="word" morph="none" start_char="5099" end_char="5102">bien</TOKEN>
<TOKEN id="token-46-48" pos="word" morph="none" start_char="5104" end_char="5108">entre</TOKEN>
<TOKEN id="token-46-49" pos="word" morph="none" start_char="5110" end_char="5111">la</TOKEN>
<TOKEN id="token-46-50" pos="word" morph="none" start_char="5113" end_char="5117">gente</TOKEN>
<TOKEN id="token-46-51" pos="word" morph="none" start_char="5119" end_char="5123">media</TOKEN>
<TOKEN id="token-46-52" pos="word" morph="none" start_char="5125" end_char="5126">de</TOKEN>
<TOKEN id="token-46-53" pos="word" morph="none" start_char="5128" end_char="5129">la</TOKEN>
<TOKEN id="token-46-54" pos="word" morph="none" start_char="5131" end_char="5134">masa</TOKEN>
<TOKEN id="token-46-55" pos="punct" morph="none" start_char="5135" end_char="5135">.</TOKEN>
</SEG>
<SEG id="segment-47" start_char="5141" end_char="5239">
<ORIGINAL_TEXT>A estas alturas el que no crea que es un virus sintetizado en un laboratorio, es bastante inocente.</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="5141" end_char="5141">A</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="5143" end_char="5147">estas</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="5149" end_char="5155">alturas</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="5157" end_char="5158">el</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="5160" end_char="5162">que</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="5164" end_char="5165">no</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="5167" end_char="5170">crea</TOKEN>
<TOKEN id="token-47-7" pos="word" morph="none" start_char="5172" end_char="5174">que</TOKEN>
<TOKEN id="token-47-8" pos="word" morph="none" start_char="5176" end_char="5177">es</TOKEN>
<TOKEN id="token-47-9" pos="word" morph="none" start_char="5179" end_char="5180">un</TOKEN>
<TOKEN id="token-47-10" pos="word" morph="none" start_char="5182" end_char="5186">virus</TOKEN>
<TOKEN id="token-47-11" pos="word" morph="none" start_char="5188" end_char="5198">sintetizado</TOKEN>
<TOKEN id="token-47-12" pos="word" morph="none" start_char="5200" end_char="5201">en</TOKEN>
<TOKEN id="token-47-13" pos="word" morph="none" start_char="5203" end_char="5204">un</TOKEN>
<TOKEN id="token-47-14" pos="word" morph="none" start_char="5206" end_char="5216">laboratorio</TOKEN>
<TOKEN id="token-47-15" pos="punct" morph="none" start_char="5217" end_char="5217">,</TOKEN>
<TOKEN id="token-47-16" pos="word" morph="none" start_char="5219" end_char="5220">es</TOKEN>
<TOKEN id="token-47-17" pos="word" morph="none" start_char="5222" end_char="5229">bastante</TOKEN>
<TOKEN id="token-47-18" pos="word" morph="none" start_char="5231" end_char="5238">inocente</TOKEN>
<TOKEN id="token-47-19" pos="punct" morph="none" start_char="5239" end_char="5239">.</TOKEN>
</SEG>
<SEG id="segment-48" start_char="5245" end_char="5249">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="5245" end_char="5248">Cita</TOKEN>
<TOKEN id="token-48-1" pos="punct" morph="none" start_char="5249" end_char="5249">:</TOKEN>
</SEG>
<SEG id="segment-49" start_char="5254" end_char="5291">
<ORIGINAL_TEXT>Originalmente Escrito por Voltiamperio</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="5254" end_char="5266">Originalmente</TOKEN>
<TOKEN id="token-49-1" pos="word" morph="none" start_char="5268" end_char="5274">Escrito</TOKEN>
<TOKEN id="token-49-2" pos="word" morph="none" start_char="5276" end_char="5278">por</TOKEN>
<TOKEN id="token-49-3" pos="word" morph="none" start_char="5280" end_char="5291">Voltiamperio</TOKEN>
</SEG>
<SEG id="segment-50" start_char="5296" end_char="5405">
<ORIGINAL_TEXT>Tú debes ser de los que se creen a pie juntillas a los medios de comunicación y a Fernando Simón, por ejemplo.</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="5296" end_char="5297">Tú</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="5299" end_char="5303">debes</TOKEN>
<TOKEN id="token-50-2" pos="word" morph="none" start_char="5305" end_char="5307">ser</TOKEN>
<TOKEN id="token-50-3" pos="word" morph="none" start_char="5309" end_char="5310">de</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="5312" end_char="5314">los</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="5316" end_char="5318">que</TOKEN>
<TOKEN id="token-50-6" pos="word" morph="none" start_char="5320" end_char="5321">se</TOKEN>
<TOKEN id="token-50-7" pos="word" morph="none" start_char="5323" end_char="5327">creen</TOKEN>
<TOKEN id="token-50-8" pos="word" morph="none" start_char="5329" end_char="5329">a</TOKEN>
<TOKEN id="token-50-9" pos="word" morph="none" start_char="5331" end_char="5333">pie</TOKEN>
<TOKEN id="token-50-10" pos="word" morph="none" start_char="5335" end_char="5343">juntillas</TOKEN>
<TOKEN id="token-50-11" pos="word" morph="none" start_char="5345" end_char="5345">a</TOKEN>
<TOKEN id="token-50-12" pos="word" morph="none" start_char="5347" end_char="5349">los</TOKEN>
<TOKEN id="token-50-13" pos="word" morph="none" start_char="5351" end_char="5356">medios</TOKEN>
<TOKEN id="token-50-14" pos="word" morph="none" start_char="5358" end_char="5359">de</TOKEN>
<TOKEN id="token-50-15" pos="word" morph="none" start_char="5361" end_char="5372">comunicación</TOKEN>
<TOKEN id="token-50-16" pos="word" morph="none" start_char="5374" end_char="5374">y</TOKEN>
<TOKEN id="token-50-17" pos="word" morph="none" start_char="5376" end_char="5376">a</TOKEN>
<TOKEN id="token-50-18" pos="word" morph="none" start_char="5378" end_char="5385">Fernando</TOKEN>
<TOKEN id="token-50-19" pos="word" morph="none" start_char="5387" end_char="5391">Simón</TOKEN>
<TOKEN id="token-50-20" pos="punct" morph="none" start_char="5392" end_char="5392">,</TOKEN>
<TOKEN id="token-50-21" pos="word" morph="none" start_char="5394" end_char="5396">por</TOKEN>
<TOKEN id="token-50-22" pos="word" morph="none" start_char="5398" end_char="5404">ejemplo</TOKEN>
<TOKEN id="token-50-23" pos="punct" morph="none" start_char="5405" end_char="5405">.</TOKEN>
</SEG>
<SEG id="segment-51" start_char="5411" end_char="5415">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="word" morph="none" start_char="5411" end_char="5414">Cita</TOKEN>
<TOKEN id="token-51-1" pos="punct" morph="none" start_char="5415" end_char="5415">:</TOKEN>
</SEG>
<SEG id="segment-52" start_char="5420" end_char="5661">
<ORIGINAL_TEXT>Originalmente Escrito por Doctor 7 No sé si ha sido creado o no, pero... 1- Se argumenta que '' since we observed all notable SARS-CoV-2 features, including the optimized RBD and polybasic cleavage site, in related coronaviruses in nature ''.</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="5420" end_char="5432">Originalmente</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="5434" end_char="5440">Escrito</TOKEN>
<TOKEN id="token-52-2" pos="word" morph="none" start_char="5442" end_char="5444">por</TOKEN>
<TOKEN id="token-52-3" pos="word" morph="none" start_char="5446" end_char="5451">Doctor</TOKEN>
<TOKEN id="token-52-4" pos="word" morph="none" start_char="5453" end_char="5453">7</TOKEN>
<TOKEN id="token-52-5" pos="word" morph="none" start_char="5455" end_char="5456">No</TOKEN>
<TOKEN id="token-52-6" pos="word" morph="none" start_char="5458" end_char="5459">sé</TOKEN>
<TOKEN id="token-52-7" pos="word" morph="none" start_char="5461" end_char="5462">si</TOKEN>
<TOKEN id="token-52-8" pos="word" morph="none" start_char="5464" end_char="5465">ha</TOKEN>
<TOKEN id="token-52-9" pos="word" morph="none" start_char="5467" end_char="5470">sido</TOKEN>
<TOKEN id="token-52-10" pos="word" morph="none" start_char="5472" end_char="5477">creado</TOKEN>
<TOKEN id="token-52-11" pos="word" morph="none" start_char="5479" end_char="5479">o</TOKEN>
<TOKEN id="token-52-12" pos="word" morph="none" start_char="5481" end_char="5482">no</TOKEN>
<TOKEN id="token-52-13" pos="punct" morph="none" start_char="5483" end_char="5483">,</TOKEN>
<TOKEN id="token-52-14" pos="word" morph="none" start_char="5485" end_char="5488">pero</TOKEN>
<TOKEN id="token-52-15" pos="punct" morph="none" start_char="5489" end_char="5491">...</TOKEN>
<TOKEN id="token-52-16" pos="word" morph="none" start_char="5493" end_char="5493">1</TOKEN>
<TOKEN id="token-52-17" pos="punct" morph="none" start_char="5494" end_char="5494">-</TOKEN>
<TOKEN id="token-52-18" pos="word" morph="none" start_char="5496" end_char="5497">Se</TOKEN>
<TOKEN id="token-52-19" pos="word" morph="none" start_char="5499" end_char="5507">argumenta</TOKEN>
<TOKEN id="token-52-20" pos="word" morph="none" start_char="5509" end_char="5511">que</TOKEN>
<TOKEN id="token-52-21" pos="punct" morph="none" start_char="5513" end_char="5514">''</TOKEN>
<TOKEN id="token-52-22" pos="word" morph="none" start_char="5516" end_char="5520">since</TOKEN>
<TOKEN id="token-52-23" pos="word" morph="none" start_char="5522" end_char="5523">we</TOKEN>
<TOKEN id="token-52-24" pos="word" morph="none" start_char="5525" end_char="5532">observed</TOKEN>
<TOKEN id="token-52-25" pos="word" morph="none" start_char="5534" end_char="5536">all</TOKEN>
<TOKEN id="token-52-26" pos="word" morph="none" start_char="5538" end_char="5544">notable</TOKEN>
<TOKEN id="token-52-27" pos="unknown" morph="none" start_char="5546" end_char="5555">SARS-CoV-2</TOKEN>
<TOKEN id="token-52-28" pos="word" morph="none" start_char="5557" end_char="5564">features</TOKEN>
<TOKEN id="token-52-29" pos="punct" morph="none" start_char="5565" end_char="5565">,</TOKEN>
<TOKEN id="token-52-30" pos="word" morph="none" start_char="5567" end_char="5575">including</TOKEN>
<TOKEN id="token-52-31" pos="word" morph="none" start_char="5577" end_char="5579">the</TOKEN>
<TOKEN id="token-52-32" pos="word" morph="none" start_char="5581" end_char="5589">optimized</TOKEN>
<TOKEN id="token-52-33" pos="word" morph="none" start_char="5591" end_char="5593">RBD</TOKEN>
<TOKEN id="token-52-34" pos="word" morph="none" start_char="5595" end_char="5597">and</TOKEN>
<TOKEN id="token-52-35" pos="word" morph="none" start_char="5599" end_char="5607">polybasic</TOKEN>
<TOKEN id="token-52-36" pos="word" morph="none" start_char="5609" end_char="5616">cleavage</TOKEN>
<TOKEN id="token-52-37" pos="word" morph="none" start_char="5618" end_char="5621">site</TOKEN>
<TOKEN id="token-52-38" pos="punct" morph="none" start_char="5622" end_char="5622">,</TOKEN>
<TOKEN id="token-52-39" pos="word" morph="none" start_char="5624" end_char="5625">in</TOKEN>
<TOKEN id="token-52-40" pos="word" morph="none" start_char="5627" end_char="5633">related</TOKEN>
<TOKEN id="token-52-41" pos="word" morph="none" start_char="5635" end_char="5647">coronaviruses</TOKEN>
<TOKEN id="token-52-42" pos="word" morph="none" start_char="5649" end_char="5650">in</TOKEN>
<TOKEN id="token-52-43" pos="word" morph="none" start_char="5652" end_char="5657">nature</TOKEN>
<TOKEN id="token-52-44" pos="punct" morph="none" start_char="5659" end_char="5661">''.</TOKEN>
</SEG>
<SEG id="segment-53" start_char="5663" end_char="5769">
<ORIGINAL_TEXT>Pero lo que dice (que no tengo ni puta idea) podría haber sido tenido en cuenta por los posibles creadores.</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="word" morph="none" start_char="5663" end_char="5666">Pero</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="5668" end_char="5669">lo</TOKEN>
<TOKEN id="token-53-2" pos="word" morph="none" start_char="5671" end_char="5673">que</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="5675" end_char="5678">dice</TOKEN>
<TOKEN id="token-53-4" pos="punct" morph="none" start_char="5680" end_char="5680">(</TOKEN>
<TOKEN id="token-53-5" pos="word" morph="none" start_char="5681" end_char="5683">que</TOKEN>
<TOKEN id="token-53-6" pos="word" morph="none" start_char="5685" end_char="5686">no</TOKEN>
<TOKEN id="token-53-7" pos="word" morph="none" start_char="5688" end_char="5692">tengo</TOKEN>
<TOKEN id="token-53-8" pos="word" morph="none" start_char="5694" end_char="5695">ni</TOKEN>
<TOKEN id="token-53-9" pos="word" morph="none" start_char="5697" end_char="5700">puta</TOKEN>
<TOKEN id="token-53-10" pos="word" morph="none" start_char="5702" end_char="5705">idea</TOKEN>
<TOKEN id="token-53-11" pos="punct" morph="none" start_char="5706" end_char="5706">)</TOKEN>
<TOKEN id="token-53-12" pos="word" morph="none" start_char="5708" end_char="5713">podría</TOKEN>
<TOKEN id="token-53-13" pos="word" morph="none" start_char="5715" end_char="5719">haber</TOKEN>
<TOKEN id="token-53-14" pos="word" morph="none" start_char="5721" end_char="5724">sido</TOKEN>
<TOKEN id="token-53-15" pos="word" morph="none" start_char="5726" end_char="5731">tenido</TOKEN>
<TOKEN id="token-53-16" pos="word" morph="none" start_char="5733" end_char="5734">en</TOKEN>
<TOKEN id="token-53-17" pos="word" morph="none" start_char="5736" end_char="5741">cuenta</TOKEN>
<TOKEN id="token-53-18" pos="word" morph="none" start_char="5743" end_char="5745">por</TOKEN>
<TOKEN id="token-53-19" pos="word" morph="none" start_char="5747" end_char="5749">los</TOKEN>
<TOKEN id="token-53-20" pos="word" morph="none" start_char="5751" end_char="5758">posibles</TOKEN>
<TOKEN id="token-53-21" pos="word" morph="none" start_char="5760" end_char="5768">creadores</TOKEN>
<TOKEN id="token-53-22" pos="punct" morph="none" start_char="5769" end_char="5769">.</TOKEN>
</SEG>
<SEG id="segment-54" start_char="5771" end_char="5946">
<ORIGINAL_TEXT>Porque los creadores de virus entenderán de virus, y puestos a crear uno, seguro que si pueden, lo habrían hecho teniendo en cuenta esto para que no se note que ha sido creado.</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="word" morph="none" start_char="5771" end_char="5776">Porque</TOKEN>
<TOKEN id="token-54-1" pos="word" morph="none" start_char="5778" end_char="5780">los</TOKEN>
<TOKEN id="token-54-2" pos="word" morph="none" start_char="5782" end_char="5790">creadores</TOKEN>
<TOKEN id="token-54-3" pos="word" morph="none" start_char="5792" end_char="5793">de</TOKEN>
<TOKEN id="token-54-4" pos="word" morph="none" start_char="5795" end_char="5799">virus</TOKEN>
<TOKEN id="token-54-5" pos="word" morph="none" start_char="5801" end_char="5810">entenderán</TOKEN>
<TOKEN id="token-54-6" pos="word" morph="none" start_char="5812" end_char="5813">de</TOKEN>
<TOKEN id="token-54-7" pos="word" morph="none" start_char="5815" end_char="5819">virus</TOKEN>
<TOKEN id="token-54-8" pos="punct" morph="none" start_char="5820" end_char="5820">,</TOKEN>
<TOKEN id="token-54-9" pos="word" morph="none" start_char="5822" end_char="5822">y</TOKEN>
<TOKEN id="token-54-10" pos="word" morph="none" start_char="5824" end_char="5830">puestos</TOKEN>
<TOKEN id="token-54-11" pos="word" morph="none" start_char="5832" end_char="5832">a</TOKEN>
<TOKEN id="token-54-12" pos="word" morph="none" start_char="5834" end_char="5838">crear</TOKEN>
<TOKEN id="token-54-13" pos="word" morph="none" start_char="5840" end_char="5842">uno</TOKEN>
<TOKEN id="token-54-14" pos="punct" morph="none" start_char="5843" end_char="5843">,</TOKEN>
<TOKEN id="token-54-15" pos="word" morph="none" start_char="5845" end_char="5850">seguro</TOKEN>
<TOKEN id="token-54-16" pos="word" morph="none" start_char="5852" end_char="5854">que</TOKEN>
<TOKEN id="token-54-17" pos="word" morph="none" start_char="5856" end_char="5857">si</TOKEN>
<TOKEN id="token-54-18" pos="word" morph="none" start_char="5859" end_char="5864">pueden</TOKEN>
<TOKEN id="token-54-19" pos="punct" morph="none" start_char="5865" end_char="5865">,</TOKEN>
<TOKEN id="token-54-20" pos="word" morph="none" start_char="5867" end_char="5868">lo</TOKEN>
<TOKEN id="token-54-21" pos="word" morph="none" start_char="5870" end_char="5876">habrían</TOKEN>
<TOKEN id="token-54-22" pos="word" morph="none" start_char="5878" end_char="5882">hecho</TOKEN>
<TOKEN id="token-54-23" pos="word" morph="none" start_char="5884" end_char="5891">teniendo</TOKEN>
<TOKEN id="token-54-24" pos="word" morph="none" start_char="5893" end_char="5894">en</TOKEN>
<TOKEN id="token-54-25" pos="word" morph="none" start_char="5896" end_char="5901">cuenta</TOKEN>
<TOKEN id="token-54-26" pos="word" morph="none" start_char="5903" end_char="5906">esto</TOKEN>
<TOKEN id="token-54-27" pos="word" morph="none" start_char="5908" end_char="5911">para</TOKEN>
<TOKEN id="token-54-28" pos="word" morph="none" start_char="5913" end_char="5915">que</TOKEN>
<TOKEN id="token-54-29" pos="word" morph="none" start_char="5917" end_char="5918">no</TOKEN>
<TOKEN id="token-54-30" pos="word" morph="none" start_char="5920" end_char="5921">se</TOKEN>
<TOKEN id="token-54-31" pos="word" morph="none" start_char="5923" end_char="5926">note</TOKEN>
<TOKEN id="token-54-32" pos="word" morph="none" start_char="5928" end_char="5930">que</TOKEN>
<TOKEN id="token-54-33" pos="word" morph="none" start_char="5932" end_char="5933">ha</TOKEN>
<TOKEN id="token-54-34" pos="word" morph="none" start_char="5935" end_char="5938">sido</TOKEN>
<TOKEN id="token-54-35" pos="word" morph="none" start_char="5940" end_char="5945">creado</TOKEN>
<TOKEN id="token-54-36" pos="punct" morph="none" start_char="5946" end_char="5946">.</TOKEN>
</SEG>
<SEG id="segment-55" start_char="5948" end_char="6006">
<ORIGINAL_TEXT>2- Las élites influyen mucho en quién obtiene el prestigio.</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="word" morph="none" start_char="5948" end_char="5948">2</TOKEN>
<TOKEN id="token-55-1" pos="punct" morph="none" start_char="5949" end_char="5949">-</TOKEN>
<TOKEN id="token-55-2" pos="word" morph="none" start_char="5951" end_char="5953">Las</TOKEN>
<TOKEN id="token-55-3" pos="word" morph="none" start_char="5955" end_char="5960">élites</TOKEN>
<TOKEN id="token-55-4" pos="word" morph="none" start_char="5962" end_char="5969">influyen</TOKEN>
<TOKEN id="token-55-5" pos="word" morph="none" start_char="5971" end_char="5975">mucho</TOKEN>
<TOKEN id="token-55-6" pos="word" morph="none" start_char="5977" end_char="5978">en</TOKEN>
<TOKEN id="token-55-7" pos="word" morph="none" start_char="5980" end_char="5984">quién</TOKEN>
<TOKEN id="token-55-8" pos="word" morph="none" start_char="5986" end_char="5992">obtiene</TOKEN>
<TOKEN id="token-55-9" pos="word" morph="none" start_char="5994" end_char="5995">el</TOKEN>
<TOKEN id="token-55-10" pos="word" morph="none" start_char="5997" end_char="6005">prestigio</TOKEN>
<TOKEN id="token-55-11" pos="punct" morph="none" start_char="6006" end_char="6006">.</TOKEN>
</SEG>
<SEG id="segment-56" start_char="6008" end_char="6045">
<ORIGINAL_TEXT>El dinero lo mueve todo en este mundo.</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="6008" end_char="6009">El</TOKEN>
<TOKEN id="token-56-1" pos="word" morph="none" start_char="6011" end_char="6016">dinero</TOKEN>
<TOKEN id="token-56-2" pos="word" morph="none" start_char="6018" end_char="6019">lo</TOKEN>
<TOKEN id="token-56-3" pos="word" morph="none" start_char="6021" end_char="6025">mueve</TOKEN>
<TOKEN id="token-56-4" pos="word" morph="none" start_char="6027" end_char="6030">todo</TOKEN>
<TOKEN id="token-56-5" pos="word" morph="none" start_char="6032" end_char="6033">en</TOKEN>
<TOKEN id="token-56-6" pos="word" morph="none" start_char="6035" end_char="6038">este</TOKEN>
<TOKEN id="token-56-7" pos="word" morph="none" start_char="6040" end_char="6044">mundo</TOKEN>
<TOKEN id="token-56-8" pos="punct" morph="none" start_char="6045" end_char="6045">.</TOKEN>
</SEG>
<SEG id="segment-57" start_char="6047" end_char="6131">
<ORIGINAL_TEXT>Que lo diga una publicación en la revista nature, prestigiosa, tampoco nos dice nada.</ORIGINAL_TEXT>
<TOKEN id="token-57-0" pos="word" morph="none" start_char="6047" end_char="6049">Que</TOKEN>
<TOKEN id="token-57-1" pos="word" morph="none" start_char="6051" end_char="6052">lo</TOKEN>
<TOKEN id="token-57-2" pos="word" morph="none" start_char="6054" end_char="6057">diga</TOKEN>
<TOKEN id="token-57-3" pos="word" morph="none" start_char="6059" end_char="6061">una</TOKEN>
<TOKEN id="token-57-4" pos="word" morph="none" start_char="6063" end_char="6073">publicación</TOKEN>
<TOKEN id="token-57-5" pos="word" morph="none" start_char="6075" end_char="6076">en</TOKEN>
<TOKEN id="token-57-6" pos="word" morph="none" start_char="6078" end_char="6079">la</TOKEN>
<TOKEN id="token-57-7" pos="word" morph="none" start_char="6081" end_char="6087">revista</TOKEN>
<TOKEN id="token-57-8" pos="word" morph="none" start_char="6089" end_char="6094">nature</TOKEN>
<TOKEN id="token-57-9" pos="punct" morph="none" start_char="6095" end_char="6095">,</TOKEN>
<TOKEN id="token-57-10" pos="word" morph="none" start_char="6097" end_char="6107">prestigiosa</TOKEN>
<TOKEN id="token-57-11" pos="punct" morph="none" start_char="6108" end_char="6108">,</TOKEN>
<TOKEN id="token-57-12" pos="word" morph="none" start_char="6110" end_char="6116">tampoco</TOKEN>
<TOKEN id="token-57-13" pos="word" morph="none" start_char="6118" end_char="6120">nos</TOKEN>
<TOKEN id="token-57-14" pos="word" morph="none" start_char="6122" end_char="6125">dice</TOKEN>
<TOKEN id="token-57-15" pos="word" morph="none" start_char="6127" end_char="6130">nada</TOKEN>
<TOKEN id="token-57-16" pos="punct" morph="none" start_char="6131" end_char="6131">.</TOKEN>
</SEG>
<SEG id="segment-58" start_char="6133" end_char="6396">
<ORIGINAL_TEXT>y 3- Si las élites hubieran creado el virus, efectivamente lo que harían sería hacer lo que digo en el punto 1, y usarían su poder para publicarlo en la revista, para lograr el efecto de la falacia ad verecundiam que cuela muy bien entre la gente media de la masa.</ORIGINAL_TEXT>
<TOKEN id="token-58-0" pos="word" morph="none" start_char="6133" end_char="6133">y</TOKEN>
<TOKEN id="token-58-1" pos="word" morph="none" start_char="6135" end_char="6135">3</TOKEN>
<TOKEN id="token-58-2" pos="punct" morph="none" start_char="6136" end_char="6136">-</TOKEN>
<TOKEN id="token-58-3" pos="word" morph="none" start_char="6138" end_char="6139">Si</TOKEN>
<TOKEN id="token-58-4" pos="word" morph="none" start_char="6141" end_char="6143">las</TOKEN>
<TOKEN id="token-58-5" pos="word" morph="none" start_char="6145" end_char="6150">élites</TOKEN>
<TOKEN id="token-58-6" pos="word" morph="none" start_char="6152" end_char="6159">hubieran</TOKEN>
<TOKEN id="token-58-7" pos="word" morph="none" start_char="6161" end_char="6166">creado</TOKEN>
<TOKEN id="token-58-8" pos="word" morph="none" start_char="6168" end_char="6169">el</TOKEN>
<TOKEN id="token-58-9" pos="word" morph="none" start_char="6171" end_char="6175">virus</TOKEN>
<TOKEN id="token-58-10" pos="punct" morph="none" start_char="6176" end_char="6176">,</TOKEN>
<TOKEN id="token-58-11" pos="word" morph="none" start_char="6178" end_char="6190">efectivamente</TOKEN>
<TOKEN id="token-58-12" pos="word" morph="none" start_char="6192" end_char="6193">lo</TOKEN>
<TOKEN id="token-58-13" pos="word" morph="none" start_char="6195" end_char="6197">que</TOKEN>
<TOKEN id="token-58-14" pos="word" morph="none" start_char="6199" end_char="6204">harían</TOKEN>
<TOKEN id="token-58-15" pos="word" morph="none" start_char="6206" end_char="6210">sería</TOKEN>
<TOKEN id="token-58-16" pos="word" morph="none" start_char="6212" end_char="6216">hacer</TOKEN>
<TOKEN id="token-58-17" pos="word" morph="none" start_char="6218" end_char="6219">lo</TOKEN>
<TOKEN id="token-58-18" pos="word" morph="none" start_char="6221" end_char="6223">que</TOKEN>
<TOKEN id="token-58-19" pos="word" morph="none" start_char="6225" end_char="6228">digo</TOKEN>
<TOKEN id="token-58-20" pos="word" morph="none" start_char="6230" end_char="6231">en</TOKEN>
<TOKEN id="token-58-21" pos="word" morph="none" start_char="6233" end_char="6234">el</TOKEN>
<TOKEN id="token-58-22" pos="word" morph="none" start_char="6236" end_char="6240">punto</TOKEN>
<TOKEN id="token-58-23" pos="word" morph="none" start_char="6242" end_char="6242">1</TOKEN>
<TOKEN id="token-58-24" pos="punct" morph="none" start_char="6243" end_char="6243">,</TOKEN>
<TOKEN id="token-58-25" pos="word" morph="none" start_char="6245" end_char="6245">y</TOKEN>
<TOKEN id="token-58-26" pos="word" morph="none" start_char="6247" end_char="6253">usarían</TOKEN>
<TOKEN id="token-58-27" pos="word" morph="none" start_char="6255" end_char="6256">su</TOKEN>
<TOKEN id="token-58-28" pos="word" morph="none" start_char="6258" end_char="6262">poder</TOKEN>
<TOKEN id="token-58-29" pos="word" morph="none" start_char="6264" end_char="6267">para</TOKEN>
<TOKEN id="token-58-30" pos="word" morph="none" start_char="6269" end_char="6278">publicarlo</TOKEN>
<TOKEN id="token-58-31" pos="word" morph="none" start_char="6280" end_char="6281">en</TOKEN>
<TOKEN id="token-58-32" pos="word" morph="none" start_char="6283" end_char="6284">la</TOKEN>
<TOKEN id="token-58-33" pos="word" morph="none" start_char="6286" end_char="6292">revista</TOKEN>
<TOKEN id="token-58-34" pos="punct" morph="none" start_char="6293" end_char="6293">,</TOKEN>
<TOKEN id="token-58-35" pos="word" morph="none" start_char="6295" end_char="6298">para</TOKEN>
<TOKEN id="token-58-36" pos="word" morph="none" start_char="6300" end_char="6305">lograr</TOKEN>
<TOKEN id="token-58-37" pos="word" morph="none" start_char="6307" end_char="6308">el</TOKEN>
<TOKEN id="token-58-38" pos="word" morph="none" start_char="6310" end_char="6315">efecto</TOKEN>
<TOKEN id="token-58-39" pos="word" morph="none" start_char="6317" end_char="6318">de</TOKEN>
<TOKEN id="token-58-40" pos="word" morph="none" start_char="6320" end_char="6321">la</TOKEN>
<TOKEN id="token-58-41" pos="word" morph="none" start_char="6323" end_char="6329">falacia</TOKEN>
<TOKEN id="token-58-42" pos="word" morph="none" start_char="6331" end_char="6332">ad</TOKEN>
<TOKEN id="token-58-43" pos="word" morph="none" start_char="6334" end_char="6344">verecundiam</TOKEN>
<TOKEN id="token-58-44" pos="word" morph="none" start_char="6346" end_char="6348">que</TOKEN>
<TOKEN id="token-58-45" pos="word" morph="none" start_char="6350" end_char="6354">cuela</TOKEN>
<TOKEN id="token-58-46" pos="word" morph="none" start_char="6356" end_char="6358">muy</TOKEN>
<TOKEN id="token-58-47" pos="word" morph="none" start_char="6360" end_char="6363">bien</TOKEN>
<TOKEN id="token-58-48" pos="word" morph="none" start_char="6365" end_char="6369">entre</TOKEN>
<TOKEN id="token-58-49" pos="word" morph="none" start_char="6371" end_char="6372">la</TOKEN>
<TOKEN id="token-58-50" pos="word" morph="none" start_char="6374" end_char="6378">gente</TOKEN>
<TOKEN id="token-58-51" pos="word" morph="none" start_char="6380" end_char="6384">media</TOKEN>
<TOKEN id="token-58-52" pos="word" morph="none" start_char="6386" end_char="6387">de</TOKEN>
<TOKEN id="token-58-53" pos="word" morph="none" start_char="6389" end_char="6390">la</TOKEN>
<TOKEN id="token-58-54" pos="word" morph="none" start_char="6392" end_char="6395">masa</TOKEN>
<TOKEN id="token-58-55" pos="punct" morph="none" start_char="6396" end_char="6396">.</TOKEN>
</SEG>
<SEG id="segment-59" start_char="6398" end_char="6497">
<ORIGINAL_TEXT>Tal cual Esto no han escuchado nunca lo de Information for the classes VS Information for the masses</ORIGINAL_TEXT>
<TOKEN id="token-59-0" pos="word" morph="none" start_char="6398" end_char="6400">Tal</TOKEN>
<TOKEN id="token-59-1" pos="word" morph="none" start_char="6402" end_char="6405">cual</TOKEN>
<TOKEN id="token-59-2" pos="word" morph="none" start_char="6407" end_char="6410">Esto</TOKEN>
<TOKEN id="token-59-3" pos="word" morph="none" start_char="6412" end_char="6413">no</TOKEN>
<TOKEN id="token-59-4" pos="word" morph="none" start_char="6415" end_char="6417">han</TOKEN>
<TOKEN id="token-59-5" pos="word" morph="none" start_char="6419" end_char="6427">escuchado</TOKEN>
<TOKEN id="token-59-6" pos="word" morph="none" start_char="6429" end_char="6433">nunca</TOKEN>
<TOKEN id="token-59-7" pos="word" morph="none" start_char="6435" end_char="6436">lo</TOKEN>
<TOKEN id="token-59-8" pos="word" morph="none" start_char="6438" end_char="6439">de</TOKEN>
<TOKEN id="token-59-9" pos="word" morph="none" start_char="6441" end_char="6451">Information</TOKEN>
<TOKEN id="token-59-10" pos="word" morph="none" start_char="6453" end_char="6455">for</TOKEN>
<TOKEN id="token-59-11" pos="word" morph="none" start_char="6457" end_char="6459">the</TOKEN>
<TOKEN id="token-59-12" pos="word" morph="none" start_char="6461" end_char="6467">classes</TOKEN>
<TOKEN id="token-59-13" pos="word" morph="none" start_char="6469" end_char="6470">VS</TOKEN>
<TOKEN id="token-59-14" pos="word" morph="none" start_char="6472" end_char="6482">Information</TOKEN>
<TOKEN id="token-59-15" pos="word" morph="none" start_char="6484" end_char="6486">for</TOKEN>
<TOKEN id="token-59-16" pos="word" morph="none" start_char="6488" end_char="6490">the</TOKEN>
<TOKEN id="token-59-17" pos="word" morph="none" start_char="6492" end_char="6497">masses</TOKEN>
</SEG>
<SEG id="segment-60" start_char="6503" end_char="6507">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN id="token-60-0" pos="word" morph="none" start_char="6503" end_char="6506">Cita</TOKEN>
<TOKEN id="token-60-1" pos="punct" morph="none" start_char="6507" end_char="6507">:</TOKEN>
</SEG>
<SEG id="segment-61" start_char="6512" end_char="6605">
<ORIGINAL_TEXT>Originalmente Escrito por Pablix82 Es imposible probar o refutar...sabes lo que eso significa?</ORIGINAL_TEXT>
<TOKEN id="token-61-0" pos="word" morph="none" start_char="6512" end_char="6524">Originalmente</TOKEN>
<TOKEN id="token-61-1" pos="word" morph="none" start_char="6526" end_char="6532">Escrito</TOKEN>
<TOKEN id="token-61-2" pos="word" morph="none" start_char="6534" end_char="6536">por</TOKEN>
<TOKEN id="token-61-3" pos="word" morph="none" start_char="6538" end_char="6545">Pablix82</TOKEN>
<TOKEN id="token-61-4" pos="word" morph="none" start_char="6547" end_char="6548">Es</TOKEN>
<TOKEN id="token-61-5" pos="word" morph="none" start_char="6550" end_char="6558">imposible</TOKEN>
<TOKEN id="token-61-6" pos="word" morph="none" start_char="6560" end_char="6565">probar</TOKEN>
<TOKEN id="token-61-7" pos="word" morph="none" start_char="6567" end_char="6567">o</TOKEN>
<TOKEN id="token-61-8" pos="unknown" morph="none" start_char="6569" end_char="6583">refutar...sabes</TOKEN>
<TOKEN id="token-61-9" pos="word" morph="none" start_char="6585" end_char="6586">lo</TOKEN>
<TOKEN id="token-61-10" pos="word" morph="none" start_char="6588" end_char="6590">que</TOKEN>
<TOKEN id="token-61-11" pos="word" morph="none" start_char="6592" end_char="6594">eso</TOKEN>
<TOKEN id="token-61-12" pos="word" morph="none" start_char="6596" end_char="6604">significa</TOKEN>
<TOKEN id="token-61-13" pos="punct" morph="none" start_char="6605" end_char="6605">?</TOKEN>
</SEG>
<SEG id="segment-62" start_char="6607" end_char="7190">
<ORIGINAL_TEXT>Que te puedes creer que fue porque un chino un día se comió un murciélago o un pangolin o que te puedes creer que fue una cagada del único laboratorio de estudios viricos de nivel 4 de china que está en la misma ciudad donde, casualidades de la vida estaba también el chino que se comió el murciélago o pangolin que originó el virus También puedes fijarte en que china pese a ser el primer país en sufrirlo se tomó muy en serio el virus cerrando la ciudad por completo con apenas 500 infectados, lo que igual nos dice que sabían muy bien a lo que se enfrentaban, ahora dale vueltas...</ORIGINAL_TEXT>
<TOKEN id="token-62-0" pos="word" morph="none" start_char="6607" end_char="6609">Que</TOKEN>
<TOKEN id="token-62-1" pos="word" morph="none" start_char="6611" end_char="6612">te</TOKEN>
<TOKEN id="token-62-2" pos="word" morph="none" start_char="6614" end_char="6619">puedes</TOKEN>
<TOKEN id="token-62-3" pos="word" morph="none" start_char="6621" end_char="6625">creer</TOKEN>
<TOKEN id="token-62-4" pos="word" morph="none" start_char="6627" end_char="6629">que</TOKEN>
<TOKEN id="token-62-5" pos="word" morph="none" start_char="6631" end_char="6633">fue</TOKEN>
<TOKEN id="token-62-6" pos="word" morph="none" start_char="6635" end_char="6640">porque</TOKEN>
<TOKEN id="token-62-7" pos="word" morph="none" start_char="6642" end_char="6643">un</TOKEN>
<TOKEN id="token-62-8" pos="word" morph="none" start_char="6645" end_char="6649">chino</TOKEN>
<TOKEN id="token-62-9" pos="word" morph="none" start_char="6651" end_char="6652">un</TOKEN>
<TOKEN id="token-62-10" pos="word" morph="none" start_char="6654" end_char="6656">día</TOKEN>
<TOKEN id="token-62-11" pos="word" morph="none" start_char="6658" end_char="6659">se</TOKEN>
<TOKEN id="token-62-12" pos="word" morph="none" start_char="6661" end_char="6665">comió</TOKEN>
<TOKEN id="token-62-13" pos="word" morph="none" start_char="6667" end_char="6668">un</TOKEN>
<TOKEN id="token-62-14" pos="word" morph="none" start_char="6670" end_char="6679">murciélago</TOKEN>
<TOKEN id="token-62-15" pos="word" morph="none" start_char="6681" end_char="6681">o</TOKEN>
<TOKEN id="token-62-16" pos="word" morph="none" start_char="6683" end_char="6684">un</TOKEN>
<TOKEN id="token-62-17" pos="word" morph="none" start_char="6686" end_char="6693">pangolin</TOKEN>
<TOKEN id="token-62-18" pos="word" morph="none" start_char="6695" end_char="6695">o</TOKEN>
<TOKEN id="token-62-19" pos="word" morph="none" start_char="6697" end_char="6699">que</TOKEN>
<TOKEN id="token-62-20" pos="word" morph="none" start_char="6701" end_char="6702">te</TOKEN>
<TOKEN id="token-62-21" pos="word" morph="none" start_char="6704" end_char="6709">puedes</TOKEN>
<TOKEN id="token-62-22" pos="word" morph="none" start_char="6711" end_char="6715">creer</TOKEN>
<TOKEN id="token-62-23" pos="word" morph="none" start_char="6717" end_char="6719">que</TOKEN>
<TOKEN id="token-62-24" pos="word" morph="none" start_char="6721" end_char="6723">fue</TOKEN>
<TOKEN id="token-62-25" pos="word" morph="none" start_char="6725" end_char="6727">una</TOKEN>
<TOKEN id="token-62-26" pos="word" morph="none" start_char="6729" end_char="6734">cagada</TOKEN>
<TOKEN id="token-62-27" pos="word" morph="none" start_char="6736" end_char="6738">del</TOKEN>
<TOKEN id="token-62-28" pos="word" morph="none" start_char="6740" end_char="6744">único</TOKEN>
<TOKEN id="token-62-29" pos="word" morph="none" start_char="6746" end_char="6756">laboratorio</TOKEN>
<TOKEN id="token-62-30" pos="word" morph="none" start_char="6758" end_char="6759">de</TOKEN>
<TOKEN id="token-62-31" pos="word" morph="none" start_char="6761" end_char="6768">estudios</TOKEN>
<TOKEN id="token-62-32" pos="word" morph="none" start_char="6770" end_char="6776">viricos</TOKEN>
<TOKEN id="token-62-33" pos="word" morph="none" start_char="6778" end_char="6779">de</TOKEN>
<TOKEN id="token-62-34" pos="word" morph="none" start_char="6781" end_char="6785">nivel</TOKEN>
<TOKEN id="token-62-35" pos="word" morph="none" start_char="6787" end_char="6787">4</TOKEN>
<TOKEN id="token-62-36" pos="word" morph="none" start_char="6789" end_char="6790">de</TOKEN>
<TOKEN id="token-62-37" pos="word" morph="none" start_char="6792" end_char="6796">china</TOKEN>
<TOKEN id="token-62-38" pos="word" morph="none" start_char="6798" end_char="6800">que</TOKEN>
<TOKEN id="token-62-39" pos="word" morph="none" start_char="6802" end_char="6805">está</TOKEN>
<TOKEN id="token-62-40" pos="word" morph="none" start_char="6807" end_char="6808">en</TOKEN>
<TOKEN id="token-62-41" pos="word" morph="none" start_char="6810" end_char="6811">la</TOKEN>
<TOKEN id="token-62-42" pos="word" morph="none" start_char="6813" end_char="6817">misma</TOKEN>
<TOKEN id="token-62-43" pos="word" morph="none" start_char="6819" end_char="6824">ciudad</TOKEN>
<TOKEN id="token-62-44" pos="word" morph="none" start_char="6826" end_char="6830">donde</TOKEN>
<TOKEN id="token-62-45" pos="punct" morph="none" start_char="6831" end_char="6831">,</TOKEN>
<TOKEN id="token-62-46" pos="word" morph="none" start_char="6833" end_char="6844">casualidades</TOKEN>
<TOKEN id="token-62-47" pos="word" morph="none" start_char="6846" end_char="6847">de</TOKEN>
<TOKEN id="token-62-48" pos="word" morph="none" start_char="6849" end_char="6850">la</TOKEN>
<TOKEN id="token-62-49" pos="word" morph="none" start_char="6852" end_char="6855">vida</TOKEN>
<TOKEN id="token-62-50" pos="word" morph="none" start_char="6857" end_char="6862">estaba</TOKEN>
<TOKEN id="token-62-51" pos="word" morph="none" start_char="6864" end_char="6870">también</TOKEN>
<TOKEN id="token-62-52" pos="word" morph="none" start_char="6872" end_char="6873">el</TOKEN>
<TOKEN id="token-62-53" pos="word" morph="none" start_char="6875" end_char="6879">chino</TOKEN>
<TOKEN id="token-62-54" pos="word" morph="none" start_char="6881" end_char="6883">que</TOKEN>
<TOKEN id="token-62-55" pos="word" morph="none" start_char="6885" end_char="6886">se</TOKEN>
<TOKEN id="token-62-56" pos="word" morph="none" start_char="6888" end_char="6892">comió</TOKEN>
<TOKEN id="token-62-57" pos="word" morph="none" start_char="6894" end_char="6895">el</TOKEN>
<TOKEN id="token-62-58" pos="word" morph="none" start_char="6897" end_char="6906">murciélago</TOKEN>
<TOKEN id="token-62-59" pos="word" morph="none" start_char="6908" end_char="6908">o</TOKEN>
<TOKEN id="token-62-60" pos="word" morph="none" start_char="6910" end_char="6917">pangolin</TOKEN>
<TOKEN id="token-62-61" pos="word" morph="none" start_char="6919" end_char="6921">que</TOKEN>
<TOKEN id="token-62-62" pos="word" morph="none" start_char="6923" end_char="6929">originó</TOKEN>
<TOKEN id="token-62-63" pos="word" morph="none" start_char="6931" end_char="6932">el</TOKEN>
<TOKEN id="token-62-64" pos="word" morph="none" start_char="6934" end_char="6938">virus</TOKEN>
<TOKEN id="token-62-65" pos="word" morph="none" start_char="6940" end_char="6946">También</TOKEN>
<TOKEN id="token-62-66" pos="word" morph="none" start_char="6948" end_char="6953">puedes</TOKEN>
<TOKEN id="token-62-67" pos="word" morph="none" start_char="6955" end_char="6961">fijarte</TOKEN>
<TOKEN id="token-62-68" pos="word" morph="none" start_char="6963" end_char="6964">en</TOKEN>
<TOKEN id="token-62-69" pos="word" morph="none" start_char="6966" end_char="6968">que</TOKEN>
<TOKEN id="token-62-70" pos="word" morph="none" start_char="6970" end_char="6974">china</TOKEN>
<TOKEN id="token-62-71" pos="word" morph="none" start_char="6976" end_char="6979">pese</TOKEN>
<TOKEN id="token-62-72" pos="word" morph="none" start_char="6981" end_char="6981">a</TOKEN>
<TOKEN id="token-62-73" pos="word" morph="none" start_char="6983" end_char="6985">ser</TOKEN>
<TOKEN id="token-62-74" pos="word" morph="none" start_char="6987" end_char="6988">el</TOKEN>
<TOKEN id="token-62-75" pos="word" morph="none" start_char="6990" end_char="6995">primer</TOKEN>
<TOKEN id="token-62-76" pos="word" morph="none" start_char="6997" end_char="7000">país</TOKEN>
<TOKEN id="token-62-77" pos="word" morph="none" start_char="7002" end_char="7003">en</TOKEN>
<TOKEN id="token-62-78" pos="word" morph="none" start_char="7005" end_char="7012">sufrirlo</TOKEN>
<TOKEN id="token-62-79" pos="word" morph="none" start_char="7014" end_char="7015">se</TOKEN>
<TOKEN id="token-62-80" pos="word" morph="none" start_char="7017" end_char="7020">tomó</TOKEN>
<TOKEN id="token-62-81" pos="word" morph="none" start_char="7022" end_char="7024">muy</TOKEN>
<TOKEN id="token-62-82" pos="word" morph="none" start_char="7026" end_char="7027">en</TOKEN>
<TOKEN id="token-62-83" pos="word" morph="none" start_char="7029" end_char="7033">serio</TOKEN>
<TOKEN id="token-62-84" pos="word" morph="none" start_char="7035" end_char="7036">el</TOKEN>
<TOKEN id="token-62-85" pos="word" morph="none" start_char="7038" end_char="7042">virus</TOKEN>
<TOKEN id="token-62-86" pos="word" morph="none" start_char="7044" end_char="7051">cerrando</TOKEN>
<TOKEN id="token-62-87" pos="word" morph="none" start_char="7053" end_char="7054">la</TOKEN>
<TOKEN id="token-62-88" pos="word" morph="none" start_char="7056" end_char="7061">ciudad</TOKEN>
<TOKEN id="token-62-89" pos="word" morph="none" start_char="7063" end_char="7065">por</TOKEN>
<TOKEN id="token-62-90" pos="word" morph="none" start_char="7067" end_char="7074">completo</TOKEN>
<TOKEN id="token-62-91" pos="word" morph="none" start_char="7076" end_char="7078">con</TOKEN>
<TOKEN id="token-62-92" pos="word" morph="none" start_char="7080" end_char="7085">apenas</TOKEN>
<TOKEN id="token-62-93" pos="word" morph="none" start_char="7087" end_char="7089">500</TOKEN>
<TOKEN id="token-62-94" pos="word" morph="none" start_char="7091" end_char="7100">infectados</TOKEN>
<TOKEN id="token-62-95" pos="punct" morph="none" start_char="7101" end_char="7101">,</TOKEN>
<TOKEN id="token-62-96" pos="word" morph="none" start_char="7103" end_char="7104">lo</TOKEN>
<TOKEN id="token-62-97" pos="word" morph="none" start_char="7106" end_char="7108">que</TOKEN>
<TOKEN id="token-62-98" pos="word" morph="none" start_char="7110" end_char="7114">igual</TOKEN>
<TOKEN id="token-62-99" pos="word" morph="none" start_char="7116" end_char="7118">nos</TOKEN>
<TOKEN id="token-62-100" pos="word" morph="none" start_char="7120" end_char="7123">dice</TOKEN>
<TOKEN id="token-62-101" pos="word" morph="none" start_char="7125" end_char="7127">que</TOKEN>
<TOKEN id="token-62-102" pos="word" morph="none" start_char="7129" end_char="7134">sabían</TOKEN>
<TOKEN id="token-62-103" pos="word" morph="none" start_char="7136" end_char="7138">muy</TOKEN>
<TOKEN id="token-62-104" pos="word" morph="none" start_char="7140" end_char="7143">bien</TOKEN>
<TOKEN id="token-62-105" pos="word" morph="none" start_char="7145" end_char="7145">a</TOKEN>
<TOKEN id="token-62-106" pos="word" morph="none" start_char="7147" end_char="7148">lo</TOKEN>
<TOKEN id="token-62-107" pos="word" morph="none" start_char="7150" end_char="7152">que</TOKEN>
<TOKEN id="token-62-108" pos="word" morph="none" start_char="7154" end_char="7155">se</TOKEN>
<TOKEN id="token-62-109" pos="word" morph="none" start_char="7157" end_char="7167">enfrentaban</TOKEN>
<TOKEN id="token-62-110" pos="punct" morph="none" start_char="7168" end_char="7168">,</TOKEN>
<TOKEN id="token-62-111" pos="word" morph="none" start_char="7170" end_char="7174">ahora</TOKEN>
<TOKEN id="token-62-112" pos="word" morph="none" start_char="7176" end_char="7179">dale</TOKEN>
<TOKEN id="token-62-113" pos="word" morph="none" start_char="7181" end_char="7187">vueltas</TOKEN>
<TOKEN id="token-62-114" pos="punct" morph="none" start_char="7188" end_char="7190">...</TOKEN>
</SEG>
<SEG id="segment-63" start_char="7193" end_char="7317">
<ORIGINAL_TEXT>Simplemente no han encontrado ninguna evidencia de manipulacion artificial siendo la hipotesis natural totalmente compatible.</ORIGINAL_TEXT>
<TOKEN id="token-63-0" pos="word" morph="none" start_char="7193" end_char="7203">Simplemente</TOKEN>
<TOKEN id="token-63-1" pos="word" morph="none" start_char="7205" end_char="7206">no</TOKEN>
<TOKEN id="token-63-2" pos="word" morph="none" start_char="7208" end_char="7210">han</TOKEN>
<TOKEN id="token-63-3" pos="word" morph="none" start_char="7212" end_char="7221">encontrado</TOKEN>
<TOKEN id="token-63-4" pos="word" morph="none" start_char="7223" end_char="7229">ninguna</TOKEN>
<TOKEN id="token-63-5" pos="word" morph="none" start_char="7231" end_char="7239">evidencia</TOKEN>
<TOKEN id="token-63-6" pos="word" morph="none" start_char="7241" end_char="7242">de</TOKEN>
<TOKEN id="token-63-7" pos="word" morph="none" start_char="7244" end_char="7255">manipulacion</TOKEN>
<TOKEN id="token-63-8" pos="word" morph="none" start_char="7257" end_char="7266">artificial</TOKEN>
<TOKEN id="token-63-9" pos="word" morph="none" start_char="7268" end_char="7273">siendo</TOKEN>
<TOKEN id="token-63-10" pos="word" morph="none" start_char="7275" end_char="7276">la</TOKEN>
<TOKEN id="token-63-11" pos="word" morph="none" start_char="7278" end_char="7286">hipotesis</TOKEN>
<TOKEN id="token-63-12" pos="word" morph="none" start_char="7288" end_char="7294">natural</TOKEN>
<TOKEN id="token-63-13" pos="word" morph="none" start_char="7296" end_char="7305">totalmente</TOKEN>
<TOKEN id="token-63-14" pos="word" morph="none" start_char="7307" end_char="7316">compatible</TOKEN>
<TOKEN id="token-63-15" pos="punct" morph="none" start_char="7317" end_char="7317">.</TOKEN>
</SEG>
<SEG id="segment-64" start_char="7319" end_char="7437">
<ORIGINAL_TEXT>Siendo los investigadores del articulo de USA y UK no te parece que les encantaria destapar que el virus es artificial?</ORIGINAL_TEXT>
<TOKEN id="token-64-0" pos="word" morph="none" start_char="7319" end_char="7324">Siendo</TOKEN>
<TOKEN id="token-64-1" pos="word" morph="none" start_char="7326" end_char="7328">los</TOKEN>
<TOKEN id="token-64-2" pos="word" morph="none" start_char="7330" end_char="7343">investigadores</TOKEN>
<TOKEN id="token-64-3" pos="word" morph="none" start_char="7345" end_char="7347">del</TOKEN>
<TOKEN id="token-64-4" pos="word" morph="none" start_char="7349" end_char="7356">articulo</TOKEN>
<TOKEN id="token-64-5" pos="word" morph="none" start_char="7358" end_char="7359">de</TOKEN>
<TOKEN id="token-64-6" pos="word" morph="none" start_char="7361" end_char="7363">USA</TOKEN>
<TOKEN id="token-64-7" pos="word" morph="none" start_char="7365" end_char="7365">y</TOKEN>
<TOKEN id="token-64-8" pos="word" morph="none" start_char="7367" end_char="7368">UK</TOKEN>
<TOKEN id="token-64-9" pos="word" morph="none" start_char="7370" end_char="7371">no</TOKEN>
<TOKEN id="token-64-10" pos="word" morph="none" start_char="7373" end_char="7374">te</TOKEN>
<TOKEN id="token-64-11" pos="word" morph="none" start_char="7376" end_char="7381">parece</TOKEN>
<TOKEN id="token-64-12" pos="word" morph="none" start_char="7383" end_char="7385">que</TOKEN>
<TOKEN id="token-64-13" pos="word" morph="none" start_char="7387" end_char="7389">les</TOKEN>
<TOKEN id="token-64-14" pos="word" morph="none" start_char="7391" end_char="7400">encantaria</TOKEN>
<TOKEN id="token-64-15" pos="word" morph="none" start_char="7402" end_char="7409">destapar</TOKEN>
<TOKEN id="token-64-16" pos="word" morph="none" start_char="7411" end_char="7413">que</TOKEN>
<TOKEN id="token-64-17" pos="word" morph="none" start_char="7415" end_char="7416">el</TOKEN>
<TOKEN id="token-64-18" pos="word" morph="none" start_char="7418" end_char="7422">virus</TOKEN>
<TOKEN id="token-64-19" pos="word" morph="none" start_char="7424" end_char="7425">es</TOKEN>
<TOKEN id="token-64-20" pos="word" morph="none" start_char="7427" end_char="7436">artificial</TOKEN>
<TOKEN id="token-64-21" pos="punct" morph="none" start_char="7437" end_char="7437">?</TOKEN>
</SEG>
<SEG id="segment-65" start_char="7439" end_char="7471">
<ORIGINAL_TEXT>Sabes el prestigio que les daria?</ORIGINAL_TEXT>
<TOKEN id="token-65-0" pos="word" morph="none" start_char="7439" end_char="7443">Sabes</TOKEN>
<TOKEN id="token-65-1" pos="word" morph="none" start_char="7445" end_char="7446">el</TOKEN>
<TOKEN id="token-65-2" pos="word" morph="none" start_char="7448" end_char="7456">prestigio</TOKEN>
<TOKEN id="token-65-3" pos="word" morph="none" start_char="7458" end_char="7460">que</TOKEN>
<TOKEN id="token-65-4" pos="word" morph="none" start_char="7462" end_char="7464">les</TOKEN>
<TOKEN id="token-65-5" pos="word" morph="none" start_char="7466" end_char="7470">daria</TOKEN>
<TOKEN id="token-65-6" pos="punct" morph="none" start_char="7471" end_char="7471">?</TOKEN>
</SEG>
<SEG id="segment-66" start_char="7477" end_char="7481">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN id="token-66-0" pos="word" morph="none" start_char="7477" end_char="7480">Cita</TOKEN>
<TOKEN id="token-66-1" pos="punct" morph="none" start_char="7481" end_char="7481">:</TOKEN>
</SEG>
<SEG id="segment-67" start_char="7486" end_char="7629">
<ORIGINAL_TEXT>Originalmente Escrito por Tidus23 Tú debes ser de los que se creen a pie juntillas a los medios de comunicación y a Fernando Simón, por ejemplo.</ORIGINAL_TEXT>
<TOKEN id="token-67-0" pos="word" morph="none" start_char="7486" end_char="7498">Originalmente</TOKEN>
<TOKEN id="token-67-1" pos="word" morph="none" start_char="7500" end_char="7506">Escrito</TOKEN>
<TOKEN id="token-67-2" pos="word" morph="none" start_char="7508" end_char="7510">por</TOKEN>
<TOKEN id="token-67-3" pos="word" morph="none" start_char="7512" end_char="7518">Tidus23</TOKEN>
<TOKEN id="token-67-4" pos="word" morph="none" start_char="7520" end_char="7521">Tú</TOKEN>
<TOKEN id="token-67-5" pos="word" morph="none" start_char="7523" end_char="7527">debes</TOKEN>
<TOKEN id="token-67-6" pos="word" morph="none" start_char="7529" end_char="7531">ser</TOKEN>
<TOKEN id="token-67-7" pos="word" morph="none" start_char="7533" end_char="7534">de</TOKEN>
<TOKEN id="token-67-8" pos="word" morph="none" start_char="7536" end_char="7538">los</TOKEN>
<TOKEN id="token-67-9" pos="word" morph="none" start_char="7540" end_char="7542">que</TOKEN>
<TOKEN id="token-67-10" pos="word" morph="none" start_char="7544" end_char="7545">se</TOKEN>
<TOKEN id="token-67-11" pos="word" morph="none" start_char="7547" end_char="7551">creen</TOKEN>
<TOKEN id="token-67-12" pos="word" morph="none" start_char="7553" end_char="7553">a</TOKEN>
<TOKEN id="token-67-13" pos="word" morph="none" start_char="7555" end_char="7557">pie</TOKEN>
<TOKEN id="token-67-14" pos="word" morph="none" start_char="7559" end_char="7567">juntillas</TOKEN>
<TOKEN id="token-67-15" pos="word" morph="none" start_char="7569" end_char="7569">a</TOKEN>
<TOKEN id="token-67-16" pos="word" morph="none" start_char="7571" end_char="7573">los</TOKEN>
<TOKEN id="token-67-17" pos="word" morph="none" start_char="7575" end_char="7580">medios</TOKEN>
<TOKEN id="token-67-18" pos="word" morph="none" start_char="7582" end_char="7583">de</TOKEN>
<TOKEN id="token-67-19" pos="word" morph="none" start_char="7585" end_char="7596">comunicación</TOKEN>
<TOKEN id="token-67-20" pos="word" morph="none" start_char="7598" end_char="7598">y</TOKEN>
<TOKEN id="token-67-21" pos="word" morph="none" start_char="7600" end_char="7600">a</TOKEN>
<TOKEN id="token-67-22" pos="word" morph="none" start_char="7602" end_char="7609">Fernando</TOKEN>
<TOKEN id="token-67-23" pos="word" morph="none" start_char="7611" end_char="7615">Simón</TOKEN>
<TOKEN id="token-67-24" pos="punct" morph="none" start_char="7616" end_char="7616">,</TOKEN>
<TOKEN id="token-67-25" pos="word" morph="none" start_char="7618" end_char="7620">por</TOKEN>
<TOKEN id="token-67-26" pos="word" morph="none" start_char="7622" end_char="7628">ejemplo</TOKEN>
<TOKEN id="token-67-27" pos="punct" morph="none" start_char="7629" end_char="7629">.</TOKEN>
</SEG>
<SEG id="segment-68" start_char="7634" end_char="7700">
<ORIGINAL_TEXT>O que lo de Chernobil era solo un incendio en la planta, nada serio</ORIGINAL_TEXT>
<TOKEN id="token-68-0" pos="word" morph="none" start_char="7634" end_char="7634">O</TOKEN>
<TOKEN id="token-68-1" pos="word" morph="none" start_char="7636" end_char="7638">que</TOKEN>
<TOKEN id="token-68-2" pos="word" morph="none" start_char="7640" end_char="7641">lo</TOKEN>
<TOKEN id="token-68-3" pos="word" morph="none" start_char="7643" end_char="7644">de</TOKEN>
<TOKEN id="token-68-4" pos="word" morph="none" start_char="7646" end_char="7654">Chernobil</TOKEN>
<TOKEN id="token-68-5" pos="word" morph="none" start_char="7656" end_char="7658">era</TOKEN>
<TOKEN id="token-68-6" pos="word" morph="none" start_char="7660" end_char="7663">solo</TOKEN>
<TOKEN id="token-68-7" pos="word" morph="none" start_char="7665" end_char="7666">un</TOKEN>
<TOKEN id="token-68-8" pos="word" morph="none" start_char="7668" end_char="7675">incendio</TOKEN>
<TOKEN id="token-68-9" pos="word" morph="none" start_char="7677" end_char="7678">en</TOKEN>
<TOKEN id="token-68-10" pos="word" morph="none" start_char="7680" end_char="7681">la</TOKEN>
<TOKEN id="token-68-11" pos="word" morph="none" start_char="7683" end_char="7688">planta</TOKEN>
<TOKEN id="token-68-12" pos="punct" morph="none" start_char="7689" end_char="7689">,</TOKEN>
<TOKEN id="token-68-13" pos="word" morph="none" start_char="7691" end_char="7694">nada</TOKEN>
<TOKEN id="token-68-14" pos="word" morph="none" start_char="7696" end_char="7700">serio</TOKEN>
</SEG>
<SEG id="segment-69" start_char="7706" end_char="7710">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN id="token-69-0" pos="word" morph="none" start_char="7706" end_char="7709">Cita</TOKEN>
<TOKEN id="token-69-1" pos="punct" morph="none" start_char="7710" end_char="7710">:</TOKEN>
</SEG>
<SEG id="segment-70" start_char="7715" end_char="8233">
<ORIGINAL_TEXT>Originalmente Escrito por RAFisher Magufos y biologos del bar Pepe se cae el mito: "Aunque la evidencia muestra que el SARS-CoV-2 no es un virus manipulado a propósito, actualmente es imposible probar o refutar las otras teorías de su origen descritas aquí. Sin embargo, dado que observamos todas las características notables de SARS-CoV-2, incluida la RBD optimizada y el sitio de escisión polibásica, en coronavirus relacionados en la naturaleza, no creemos que ningún tipo de escenario de laboratorio sea plausible."</ORIGINAL_TEXT>
<TOKEN id="token-70-0" pos="word" morph="none" start_char="7715" end_char="7727">Originalmente</TOKEN>
<TOKEN id="token-70-1" pos="word" morph="none" start_char="7729" end_char="7735">Escrito</TOKEN>
<TOKEN id="token-70-2" pos="word" morph="none" start_char="7737" end_char="7739">por</TOKEN>
<TOKEN id="token-70-3" pos="word" morph="none" start_char="7741" end_char="7748">RAFisher</TOKEN>
<TOKEN id="token-70-4" pos="word" morph="none" start_char="7750" end_char="7756">Magufos</TOKEN>
<TOKEN id="token-70-5" pos="word" morph="none" start_char="7758" end_char="7758">y</TOKEN>
<TOKEN id="token-70-6" pos="word" morph="none" start_char="7760" end_char="7767">biologos</TOKEN>
<TOKEN id="token-70-7" pos="word" morph="none" start_char="7769" end_char="7771">del</TOKEN>
<TOKEN id="token-70-8" pos="word" morph="none" start_char="7773" end_char="7775">bar</TOKEN>
<TOKEN id="token-70-9" pos="word" morph="none" start_char="7777" end_char="7780">Pepe</TOKEN>
<TOKEN id="token-70-10" pos="word" morph="none" start_char="7782" end_char="7783">se</TOKEN>
<TOKEN id="token-70-11" pos="word" morph="none" start_char="7785" end_char="7787">cae</TOKEN>
<TOKEN id="token-70-12" pos="word" morph="none" start_char="7789" end_char="7790">el</TOKEN>
<TOKEN id="token-70-13" pos="word" morph="none" start_char="7792" end_char="7795">mito</TOKEN>
<TOKEN id="token-70-14" pos="punct" morph="none" start_char="7796" end_char="7796">:</TOKEN>
<TOKEN id="token-70-15" pos="punct" morph="none" start_char="7798" end_char="7798">"</TOKEN>
<TOKEN id="token-70-16" pos="word" morph="none" start_char="7799" end_char="7804">Aunque</TOKEN>
<TOKEN id="token-70-17" pos="word" morph="none" start_char="7806" end_char="7807">la</TOKEN>
<TOKEN id="token-70-18" pos="word" morph="none" start_char="7809" end_char="7817">evidencia</TOKEN>
<TOKEN id="token-70-19" pos="word" morph="none" start_char="7819" end_char="7825">muestra</TOKEN>
<TOKEN id="token-70-20" pos="word" morph="none" start_char="7827" end_char="7829">que</TOKEN>
<TOKEN id="token-70-21" pos="word" morph="none" start_char="7831" end_char="7832">el</TOKEN>
<TOKEN id="token-70-22" pos="unknown" morph="none" start_char="7834" end_char="7843">SARS-CoV-2</TOKEN>
<TOKEN id="token-70-23" pos="word" morph="none" start_char="7845" end_char="7846">no</TOKEN>
<TOKEN id="token-70-24" pos="word" morph="none" start_char="7848" end_char="7849">es</TOKEN>
<TOKEN id="token-70-25" pos="word" morph="none" start_char="7851" end_char="7852">un</TOKEN>
<TOKEN id="token-70-26" pos="word" morph="none" start_char="7854" end_char="7858">virus</TOKEN>
<TOKEN id="token-70-27" pos="word" morph="none" start_char="7860" end_char="7869">manipulado</TOKEN>
<TOKEN id="token-70-28" pos="word" morph="none" start_char="7871" end_char="7871">a</TOKEN>
<TOKEN id="token-70-29" pos="word" morph="none" start_char="7873" end_char="7881">propósito</TOKEN>
<TOKEN id="token-70-30" pos="punct" morph="none" start_char="7882" end_char="7882">,</TOKEN>
<TOKEN id="token-70-31" pos="word" morph="none" start_char="7884" end_char="7894">actualmente</TOKEN>
<TOKEN id="token-70-32" pos="word" morph="none" start_char="7896" end_char="7897">es</TOKEN>
<TOKEN id="token-70-33" pos="word" morph="none" start_char="7899" end_char="7907">imposible</TOKEN>
<TOKEN id="token-70-34" pos="word" morph="none" start_char="7909" end_char="7914">probar</TOKEN>
<TOKEN id="token-70-35" pos="word" morph="none" start_char="7916" end_char="7916">o</TOKEN>
<TOKEN id="token-70-36" pos="word" morph="none" start_char="7918" end_char="7924">refutar</TOKEN>
<TOKEN id="token-70-37" pos="word" morph="none" start_char="7926" end_char="7928">las</TOKEN>
<TOKEN id="token-70-38" pos="word" morph="none" start_char="7930" end_char="7934">otras</TOKEN>
<TOKEN id="token-70-39" pos="word" morph="none" start_char="7936" end_char="7942">teorías</TOKEN>
<TOKEN id="token-70-40" pos="word" morph="none" start_char="7944" end_char="7945">de</TOKEN>
<TOKEN id="token-70-41" pos="word" morph="none" start_char="7947" end_char="7948">su</TOKEN>
<TOKEN id="token-70-42" pos="word" morph="none" start_char="7950" end_char="7955">origen</TOKEN>
<TOKEN id="token-70-43" pos="word" morph="none" start_char="7957" end_char="7965">descritas</TOKEN>
<TOKEN id="token-70-44" pos="word" morph="none" start_char="7967" end_char="7970">aquí</TOKEN>
<TOKEN id="token-70-45" pos="punct" morph="none" start_char="7971" end_char="7971">.</TOKEN>
<TOKEN id="token-70-46" pos="word" morph="none" start_char="7973" end_char="7975">Sin</TOKEN>
<TOKEN id="token-70-47" pos="word" morph="none" start_char="7977" end_char="7983">embargo</TOKEN>
<TOKEN id="token-70-48" pos="punct" morph="none" start_char="7984" end_char="7984">,</TOKEN>
<TOKEN id="token-70-49" pos="word" morph="none" start_char="7986" end_char="7989">dado</TOKEN>
<TOKEN id="token-70-50" pos="word" morph="none" start_char="7991" end_char="7993">que</TOKEN>
<TOKEN id="token-70-51" pos="word" morph="none" start_char="7995" end_char="8004">observamos</TOKEN>
<TOKEN id="token-70-52" pos="word" morph="none" start_char="8006" end_char="8010">todas</TOKEN>
<TOKEN id="token-70-53" pos="word" morph="none" start_char="8012" end_char="8014">las</TOKEN>
<TOKEN id="token-70-54" pos="word" morph="none" start_char="8016" end_char="8030">características</TOKEN>
<TOKEN id="token-70-55" pos="word" morph="none" start_char="8032" end_char="8039">notables</TOKEN>
<TOKEN id="token-70-56" pos="word" morph="none" start_char="8041" end_char="8042">de</TOKEN>
<TOKEN id="token-70-57" pos="unknown" morph="none" start_char="8044" end_char="8053">SARS-CoV-2</TOKEN>
<TOKEN id="token-70-58" pos="punct" morph="none" start_char="8054" end_char="8054">,</TOKEN>
<TOKEN id="token-70-59" pos="word" morph="none" start_char="8056" end_char="8063">incluida</TOKEN>
<TOKEN id="token-70-60" pos="word" morph="none" start_char="8065" end_char="8066">la</TOKEN>
<TOKEN id="token-70-61" pos="word" morph="none" start_char="8068" end_char="8070">RBD</TOKEN>
<TOKEN id="token-70-62" pos="word" morph="none" start_char="8072" end_char="8081">optimizada</TOKEN>
<TOKEN id="token-70-63" pos="word" morph="none" start_char="8083" end_char="8083">y</TOKEN>
<TOKEN id="token-70-64" pos="word" morph="none" start_char="8085" end_char="8086">el</TOKEN>
<TOKEN id="token-70-65" pos="word" morph="none" start_char="8088" end_char="8092">sitio</TOKEN>
<TOKEN id="token-70-66" pos="word" morph="none" start_char="8094" end_char="8095">de</TOKEN>
<TOKEN id="token-70-67" pos="word" morph="none" start_char="8097" end_char="8104">escisión</TOKEN>
<TOKEN id="token-70-68" pos="word" morph="none" start_char="8106" end_char="8115">polibásica</TOKEN>
<TOKEN id="token-70-69" pos="punct" morph="none" start_char="8116" end_char="8116">,</TOKEN>
<TOKEN id="token-70-70" pos="word" morph="none" start_char="8118" end_char="8119">en</TOKEN>
<TOKEN id="token-70-71" pos="word" morph="none" start_char="8121" end_char="8131">coronavirus</TOKEN>
<TOKEN id="token-70-72" pos="word" morph="none" start_char="8133" end_char="8144">relacionados</TOKEN>
<TOKEN id="token-70-73" pos="word" morph="none" start_char="8146" end_char="8147">en</TOKEN>
<TOKEN id="token-70-74" pos="word" morph="none" start_char="8149" end_char="8150">la</TOKEN>
<TOKEN id="token-70-75" pos="word" morph="none" start_char="8152" end_char="8161">naturaleza</TOKEN>
<TOKEN id="token-70-76" pos="punct" morph="none" start_char="8162" end_char="8162">,</TOKEN>
<TOKEN id="token-70-77" pos="word" morph="none" start_char="8164" end_char="8165">no</TOKEN>
<TOKEN id="token-70-78" pos="word" morph="none" start_char="8167" end_char="8173">creemos</TOKEN>
<TOKEN id="token-70-79" pos="word" morph="none" start_char="8175" end_char="8177">que</TOKEN>
<TOKEN id="token-70-80" pos="word" morph="none" start_char="8179" end_char="8184">ningún</TOKEN>
<TOKEN id="token-70-81" pos="word" morph="none" start_char="8186" end_char="8189">tipo</TOKEN>
<TOKEN id="token-70-82" pos="word" morph="none" start_char="8191" end_char="8192">de</TOKEN>
<TOKEN id="token-70-83" pos="word" morph="none" start_char="8194" end_char="8202">escenario</TOKEN>
<TOKEN id="token-70-84" pos="word" morph="none" start_char="8204" end_char="8205">de</TOKEN>
<TOKEN id="token-70-85" pos="word" morph="none" start_char="8207" end_char="8217">laboratorio</TOKEN>
<TOKEN id="token-70-86" pos="word" morph="none" start_char="8219" end_char="8221">sea</TOKEN>
<TOKEN id="token-70-87" pos="word" morph="none" start_char="8223" end_char="8231">plausible</TOKEN>
<TOKEN id="token-70-88" pos="punct" morph="none" start_char="8232" end_char="8233">."</TOKEN>
</SEG>
<SEG id="segment-71" start_char="8235" end_char="8416">
<ORIGINAL_TEXT>"Although the evidence shows that SARS-CoV-2 is not a purposefully manipulated virus, it is currently impossible to prove or disprove the other theories of its origin described here.</ORIGINAL_TEXT>
<TOKEN id="token-71-0" pos="punct" morph="none" start_char="8235" end_char="8235">"</TOKEN>
<TOKEN id="token-71-1" pos="word" morph="none" start_char="8236" end_char="8243">Although</TOKEN>
<TOKEN id="token-71-2" pos="word" morph="none" start_char="8245" end_char="8247">the</TOKEN>
<TOKEN id="token-71-3" pos="word" morph="none" start_char="8249" end_char="8256">evidence</TOKEN>
<TOKEN id="token-71-4" pos="word" morph="none" start_char="8258" end_char="8262">shows</TOKEN>
<TOKEN id="token-71-5" pos="word" morph="none" start_char="8264" end_char="8267">that</TOKEN>
<TOKEN id="token-71-6" pos="unknown" morph="none" start_char="8269" end_char="8278">SARS-CoV-2</TOKEN>
<TOKEN id="token-71-7" pos="word" morph="none" start_char="8280" end_char="8281">is</TOKEN>
<TOKEN id="token-71-8" pos="word" morph="none" start_char="8283" end_char="8285">not</TOKEN>
<TOKEN id="token-71-9" pos="word" morph="none" start_char="8287" end_char="8287">a</TOKEN>
<TOKEN id="token-71-10" pos="word" morph="none" start_char="8289" end_char="8300">purposefully</TOKEN>
<TOKEN id="token-71-11" pos="word" morph="none" start_char="8302" end_char="8312">manipulated</TOKEN>
<TOKEN id="token-71-12" pos="word" morph="none" start_char="8314" end_char="8318">virus</TOKEN>
<TOKEN id="token-71-13" pos="punct" morph="none" start_char="8319" end_char="8319">,</TOKEN>
<TOKEN id="token-71-14" pos="word" morph="none" start_char="8321" end_char="8322">it</TOKEN>
<TOKEN id="token-71-15" pos="word" morph="none" start_char="8324" end_char="8325">is</TOKEN>
<TOKEN id="token-71-16" pos="word" morph="none" start_char="8327" end_char="8335">currently</TOKEN>
<TOKEN id="token-71-17" pos="word" morph="none" start_char="8337" end_char="8346">impossible</TOKEN>
<TOKEN id="token-71-18" pos="word" morph="none" start_char="8348" end_char="8349">to</TOKEN>
<TOKEN id="token-71-19" pos="word" morph="none" start_char="8351" end_char="8355">prove</TOKEN>
<TOKEN id="token-71-20" pos="word" morph="none" start_char="8357" end_char="8358">or</TOKEN>
<TOKEN id="token-71-21" pos="word" morph="none" start_char="8360" end_char="8367">disprove</TOKEN>
<TOKEN id="token-71-22" pos="word" morph="none" start_char="8369" end_char="8371">the</TOKEN>
<TOKEN id="token-71-23" pos="word" morph="none" start_char="8373" end_char="8377">other</TOKEN>
<TOKEN id="token-71-24" pos="word" morph="none" start_char="8379" end_char="8386">theories</TOKEN>
<TOKEN id="token-71-25" pos="word" morph="none" start_char="8388" end_char="8389">of</TOKEN>
<TOKEN id="token-71-26" pos="word" morph="none" start_char="8391" end_char="8393">its</TOKEN>
<TOKEN id="token-71-27" pos="word" morph="none" start_char="8395" end_char="8400">origin</TOKEN>
<TOKEN id="token-71-28" pos="word" morph="none" start_char="8402" end_char="8410">described</TOKEN>
<TOKEN id="token-71-29" pos="word" morph="none" start_char="8412" end_char="8415">here</TOKEN>
<TOKEN id="token-71-30" pos="punct" morph="none" start_char="8416" end_char="8416">.</TOKEN>
</SEG>
<SEG id="segment-72" start_char="8418" end_char="8645">
<ORIGINAL_TEXT>However, since we observed all notable SARS-CoV-2 features, including the optimized RBD and polybasic cleavage site, in related coronaviruses in nature, we do not believe that any type of laboratory-based scenario is plausible."</ORIGINAL_TEXT>
<TOKEN id="token-72-0" pos="word" morph="none" start_char="8418" end_char="8424">However</TOKEN>
<TOKEN id="token-72-1" pos="punct" morph="none" start_char="8425" end_char="8425">,</TOKEN>
<TOKEN id="token-72-2" pos="word" morph="none" start_char="8427" end_char="8431">since</TOKEN>
<TOKEN id="token-72-3" pos="word" morph="none" start_char="8433" end_char="8434">we</TOKEN>
<TOKEN id="token-72-4" pos="word" morph="none" start_char="8436" end_char="8443">observed</TOKEN>
<TOKEN id="token-72-5" pos="word" morph="none" start_char="8445" end_char="8447">all</TOKEN>
<TOKEN id="token-72-6" pos="word" morph="none" start_char="8449" end_char="8455">notable</TOKEN>
<TOKEN id="token-72-7" pos="unknown" morph="none" start_char="8457" end_char="8466">SARS-CoV-2</TOKEN>
<TOKEN id="token-72-8" pos="word" morph="none" start_char="8468" end_char="8475">features</TOKEN>
<TOKEN id="token-72-9" pos="punct" morph="none" start_char="8476" end_char="8476">,</TOKEN>
<TOKEN id="token-72-10" pos="word" morph="none" start_char="8478" end_char="8486">including</TOKEN>
<TOKEN id="token-72-11" pos="word" morph="none" start_char="8488" end_char="8490">the</TOKEN>
<TOKEN id="token-72-12" pos="word" morph="none" start_char="8492" end_char="8500">optimized</TOKEN>
<TOKEN id="token-72-13" pos="word" morph="none" start_char="8502" end_char="8504">RBD</TOKEN>
<TOKEN id="token-72-14" pos="word" morph="none" start_char="8506" end_char="8508">and</TOKEN>
<TOKEN id="token-72-15" pos="word" morph="none" start_char="8510" end_char="8518">polybasic</TOKEN>
<TOKEN id="token-72-16" pos="word" morph="none" start_char="8520" end_char="8527">cleavage</TOKEN>
<TOKEN id="token-72-17" pos="word" morph="none" start_char="8529" end_char="8532">site</TOKEN>
<TOKEN id="token-72-18" pos="punct" morph="none" start_char="8533" end_char="8533">,</TOKEN>
<TOKEN id="token-72-19" pos="word" morph="none" start_char="8535" end_char="8536">in</TOKEN>
<TOKEN id="token-72-20" pos="word" morph="none" start_char="8538" end_char="8544">related</TOKEN>
<TOKEN id="token-72-21" pos="word" morph="none" start_char="8546" end_char="8558">coronaviruses</TOKEN>
<TOKEN id="token-72-22" pos="word" morph="none" start_char="8560" end_char="8561">in</TOKEN>
<TOKEN id="token-72-23" pos="word" morph="none" start_char="8563" end_char="8568">nature</TOKEN>
<TOKEN id="token-72-24" pos="punct" morph="none" start_char="8569" end_char="8569">,</TOKEN>
<TOKEN id="token-72-25" pos="word" morph="none" start_char="8571" end_char="8572">we</TOKEN>
<TOKEN id="token-72-26" pos="word" morph="none" start_char="8574" end_char="8575">do</TOKEN>
<TOKEN id="token-72-27" pos="word" morph="none" start_char="8577" end_char="8579">not</TOKEN>
<TOKEN id="token-72-28" pos="word" morph="none" start_char="8581" end_char="8587">believe</TOKEN>
<TOKEN id="token-72-29" pos="word" morph="none" start_char="8589" end_char="8592">that</TOKEN>
<TOKEN id="token-72-30" pos="word" morph="none" start_char="8594" end_char="8596">any</TOKEN>
<TOKEN id="token-72-31" pos="word" morph="none" start_char="8598" end_char="8601">type</TOKEN>
<TOKEN id="token-72-32" pos="word" morph="none" start_char="8603" end_char="8604">of</TOKEN>
<TOKEN id="token-72-33" pos="unknown" morph="none" start_char="8606" end_char="8621">laboratory-based</TOKEN>
<TOKEN id="token-72-34" pos="word" morph="none" start_char="8623" end_char="8630">scenario</TOKEN>
<TOKEN id="token-72-35" pos="word" morph="none" start_char="8632" end_char="8633">is</TOKEN>
<TOKEN id="token-72-36" pos="word" morph="none" start_char="8635" end_char="8643">plausible</TOKEN>
<TOKEN id="token-72-37" pos="punct" morph="none" start_char="8644" end_char="8645">."</TOKEN>
</SEG>
<SEG id="segment-73" start_char="8647" end_char="8771">
<ORIGINAL_TEXT>https://www.nature.com/articles/s41591-020-0820-9 Nature es una de las más prestigiosas revistas científicas a nivel mundial.</ORIGINAL_TEXT>
<TOKEN id="token-73-0" pos="url" morph="none" start_char="8647" end_char="8695">https://www.nature.com/articles/s41591-020-0820-9</TOKEN>
<TOKEN id="token-73-1" pos="word" morph="none" start_char="8697" end_char="8702">Nature</TOKEN>
<TOKEN id="token-73-2" pos="word" morph="none" start_char="8704" end_char="8705">es</TOKEN>
<TOKEN id="token-73-3" pos="word" morph="none" start_char="8707" end_char="8709">una</TOKEN>
<TOKEN id="token-73-4" pos="word" morph="none" start_char="8711" end_char="8712">de</TOKEN>
<TOKEN id="token-73-5" pos="word" morph="none" start_char="8714" end_char="8716">las</TOKEN>
<TOKEN id="token-73-6" pos="word" morph="none" start_char="8718" end_char="8720">más</TOKEN>
<TOKEN id="token-73-7" pos="word" morph="none" start_char="8722" end_char="8733">prestigiosas</TOKEN>
<TOKEN id="token-73-8" pos="word" morph="none" start_char="8735" end_char="8742">revistas</TOKEN>
<TOKEN id="token-73-9" pos="word" morph="none" start_char="8744" end_char="8754">científicas</TOKEN>
<TOKEN id="token-73-10" pos="word" morph="none" start_char="8756" end_char="8756">a</TOKEN>
<TOKEN id="token-73-11" pos="word" morph="none" start_char="8758" end_char="8762">nivel</TOKEN>
<TOKEN id="token-73-12" pos="word" morph="none" start_char="8764" end_char="8770">mundial</TOKEN>
<TOKEN id="token-73-13" pos="punct" morph="none" start_char="8771" end_char="8771">.</TOKEN>
</SEG>
<SEG id="segment-74" start_char="8773" end_char="8860">
<ORIGINAL_TEXT>Para la mayoría de los científicos publicar en Nature constituye una marca de prestigio.</ORIGINAL_TEXT>
<TOKEN id="token-74-0" pos="word" morph="none" start_char="8773" end_char="8776">Para</TOKEN>
<TOKEN id="token-74-1" pos="word" morph="none" start_char="8778" end_char="8779">la</TOKEN>
<TOKEN id="token-74-2" pos="word" morph="none" start_char="8781" end_char="8787">mayoría</TOKEN>
<TOKEN id="token-74-3" pos="word" morph="none" start_char="8789" end_char="8790">de</TOKEN>
<TOKEN id="token-74-4" pos="word" morph="none" start_char="8792" end_char="8794">los</TOKEN>
<TOKEN id="token-74-5" pos="word" morph="none" start_char="8796" end_char="8806">científicos</TOKEN>
<TOKEN id="token-74-6" pos="word" morph="none" start_char="8808" end_char="8815">publicar</TOKEN>
<TOKEN id="token-74-7" pos="word" morph="none" start_char="8817" end_char="8818">en</TOKEN>
<TOKEN id="token-74-8" pos="word" morph="none" start_char="8820" end_char="8825">Nature</TOKEN>
<TOKEN id="token-74-9" pos="word" morph="none" start_char="8827" end_char="8836">constituye</TOKEN>
<TOKEN id="token-74-10" pos="word" morph="none" start_char="8838" end_char="8840">una</TOKEN>
<TOKEN id="token-74-11" pos="word" morph="none" start_char="8842" end_char="8846">marca</TOKEN>
<TOKEN id="token-74-12" pos="word" morph="none" start_char="8848" end_char="8849">de</TOKEN>
<TOKEN id="token-74-13" pos="word" morph="none" start_char="8851" end_char="8859">prestigio</TOKEN>
<TOKEN id="token-74-14" pos="punct" morph="none" start_char="8860" end_char="8860">.</TOKEN>
</SEG>
<SEG id="segment-75" start_char="8862" end_char="8960">
<ORIGINAL_TEXT>La revista rechaza en torno al 95% de los artículos que le son enviados para la revisión por pares.</ORIGINAL_TEXT>
<TOKEN id="token-75-0" pos="word" morph="none" start_char="8862" end_char="8863">La</TOKEN>
<TOKEN id="token-75-1" pos="word" morph="none" start_char="8865" end_char="8871">revista</TOKEN>
<TOKEN id="token-75-2" pos="word" morph="none" start_char="8873" end_char="8879">rechaza</TOKEN>
<TOKEN id="token-75-3" pos="word" morph="none" start_char="8881" end_char="8882">en</TOKEN>
<TOKEN id="token-75-4" pos="word" morph="none" start_char="8884" end_char="8888">torno</TOKEN>
<TOKEN id="token-75-5" pos="word" morph="none" start_char="8890" end_char="8891">al</TOKEN>
<TOKEN id="token-75-6" pos="word" morph="none" start_char="8893" end_char="8894">95</TOKEN>
<TOKEN id="token-75-7" pos="punct" morph="none" start_char="8895" end_char="8895">%</TOKEN>
<TOKEN id="token-75-8" pos="word" morph="none" start_char="8897" end_char="8898">de</TOKEN>
<TOKEN id="token-75-9" pos="word" morph="none" start_char="8900" end_char="8902">los</TOKEN>
<TOKEN id="token-75-10" pos="word" morph="none" start_char="8904" end_char="8912">artículos</TOKEN>
<TOKEN id="token-75-11" pos="word" morph="none" start_char="8914" end_char="8916">que</TOKEN>
<TOKEN id="token-75-12" pos="word" morph="none" start_char="8918" end_char="8919">le</TOKEN>
<TOKEN id="token-75-13" pos="word" morph="none" start_char="8921" end_char="8923">son</TOKEN>
<TOKEN id="token-75-14" pos="word" morph="none" start_char="8925" end_char="8932">enviados</TOKEN>
<TOKEN id="token-75-15" pos="word" morph="none" start_char="8934" end_char="8937">para</TOKEN>
<TOKEN id="token-75-16" pos="word" morph="none" start_char="8939" end_char="8940">la</TOKEN>
<TOKEN id="token-75-17" pos="word" morph="none" start_char="8942" end_char="8949">revisión</TOKEN>
<TOKEN id="token-75-18" pos="word" morph="none" start_char="8951" end_char="8953">por</TOKEN>
<TOKEN id="token-75-19" pos="word" morph="none" start_char="8955" end_char="8959">pares</TOKEN>
<TOKEN id="token-75-20" pos="punct" morph="none" start_char="8960" end_char="8960">.</TOKEN>
</SEG>
<SEG id="segment-76" start_char="8962" end_char="9131">
<ORIGINAL_TEXT>Ahí lo que dice es que no tienen ni idea de cómo ha aparecido y que basándose en su similitud con otros coronavirus, suponen que cómo esos, es natural y no de laboratorio</ORIGINAL_TEXT>
<TOKEN id="token-76-0" pos="word" morph="none" start_char="8962" end_char="8964">Ahí</TOKEN>
<TOKEN id="token-76-1" pos="word" morph="none" start_char="8966" end_char="8967">lo</TOKEN>
<TOKEN id="token-76-2" pos="word" morph="none" start_char="8969" end_char="8971">que</TOKEN>
<TOKEN id="token-76-3" pos="word" morph="none" start_char="8973" end_char="8976">dice</TOKEN>
<TOKEN id="token-76-4" pos="word" morph="none" start_char="8978" end_char="8979">es</TOKEN>
<TOKEN id="token-76-5" pos="word" morph="none" start_char="8981" end_char="8983">que</TOKEN>
<TOKEN id="token-76-6" pos="word" morph="none" start_char="8985" end_char="8986">no</TOKEN>
<TOKEN id="token-76-7" pos="word" morph="none" start_char="8988" end_char="8993">tienen</TOKEN>
<TOKEN id="token-76-8" pos="word" morph="none" start_char="8995" end_char="8996">ni</TOKEN>
<TOKEN id="token-76-9" pos="word" morph="none" start_char="8998" end_char="9001">idea</TOKEN>
<TOKEN id="token-76-10" pos="word" morph="none" start_char="9003" end_char="9004">de</TOKEN>
<TOKEN id="token-76-11" pos="word" morph="none" start_char="9006" end_char="9009">cómo</TOKEN>
<TOKEN id="token-76-12" pos="word" morph="none" start_char="9011" end_char="9012">ha</TOKEN>
<TOKEN id="token-76-13" pos="word" morph="none" start_char="9014" end_char="9022">aparecido</TOKEN>
<TOKEN id="token-76-14" pos="word" morph="none" start_char="9024" end_char="9024">y</TOKEN>
<TOKEN id="token-76-15" pos="word" morph="none" start_char="9026" end_char="9028">que</TOKEN>
<TOKEN id="token-76-16" pos="word" morph="none" start_char="9030" end_char="9038">basándose</TOKEN>
<TOKEN id="token-76-17" pos="word" morph="none" start_char="9040" end_char="9041">en</TOKEN>
<TOKEN id="token-76-18" pos="word" morph="none" start_char="9043" end_char="9044">su</TOKEN>
<TOKEN id="token-76-19" pos="word" morph="none" start_char="9046" end_char="9054">similitud</TOKEN>
<TOKEN id="token-76-20" pos="word" morph="none" start_char="9056" end_char="9058">con</TOKEN>
<TOKEN id="token-76-21" pos="word" morph="none" start_char="9060" end_char="9064">otros</TOKEN>
<TOKEN id="token-76-22" pos="word" morph="none" start_char="9066" end_char="9076">coronavirus</TOKEN>
<TOKEN id="token-76-23" pos="punct" morph="none" start_char="9077" end_char="9077">,</TOKEN>
<TOKEN id="token-76-24" pos="word" morph="none" start_char="9079" end_char="9085">suponen</TOKEN>
<TOKEN id="token-76-25" pos="word" morph="none" start_char="9087" end_char="9089">que</TOKEN>
<TOKEN id="token-76-26" pos="word" morph="none" start_char="9091" end_char="9094">cómo</TOKEN>
<TOKEN id="token-76-27" pos="word" morph="none" start_char="9096" end_char="9099">esos</TOKEN>
<TOKEN id="token-76-28" pos="punct" morph="none" start_char="9100" end_char="9100">,</TOKEN>
<TOKEN id="token-76-29" pos="word" morph="none" start_char="9102" end_char="9103">es</TOKEN>
<TOKEN id="token-76-30" pos="word" morph="none" start_char="9105" end_char="9111">natural</TOKEN>
<TOKEN id="token-76-31" pos="word" morph="none" start_char="9113" end_char="9113">y</TOKEN>
<TOKEN id="token-76-32" pos="word" morph="none" start_char="9115" end_char="9116">no</TOKEN>
<TOKEN id="token-76-33" pos="word" morph="none" start_char="9118" end_char="9119">de</TOKEN>
<TOKEN id="token-76-34" pos="word" morph="none" start_char="9121" end_char="9131">laboratorio</TOKEN>
</SEG>
<SEG id="segment-77" start_char="9137" end_char="9141">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN id="token-77-0" pos="word" morph="none" start_char="9137" end_char="9140">Cita</TOKEN>
<TOKEN id="token-77-1" pos="punct" morph="none" start_char="9141" end_char="9141">:</TOKEN>
</SEG>
<SEG id="segment-78" start_char="9146" end_char="9289">
<ORIGINAL_TEXT>Originalmente Escrito por Tidus23 Tú debes ser de los que se creen a pie juntillas a los medios de comunicación y a Fernando Simón, por ejemplo.</ORIGINAL_TEXT>
<TOKEN id="token-78-0" pos="word" morph="none" start_char="9146" end_char="9158">Originalmente</TOKEN>
<TOKEN id="token-78-1" pos="word" morph="none" start_char="9160" end_char="9166">Escrito</TOKEN>
<TOKEN id="token-78-2" pos="word" morph="none" start_char="9168" end_char="9170">por</TOKEN>
<TOKEN id="token-78-3" pos="word" morph="none" start_char="9172" end_char="9178">Tidus23</TOKEN>
<TOKEN id="token-78-4" pos="word" morph="none" start_char="9180" end_char="9181">Tú</TOKEN>
<TOKEN id="token-78-5" pos="word" morph="none" start_char="9183" end_char="9187">debes</TOKEN>
<TOKEN id="token-78-6" pos="word" morph="none" start_char="9189" end_char="9191">ser</TOKEN>
<TOKEN id="token-78-7" pos="word" morph="none" start_char="9193" end_char="9194">de</TOKEN>
<TOKEN id="token-78-8" pos="word" morph="none" start_char="9196" end_char="9198">los</TOKEN>
<TOKEN id="token-78-9" pos="word" morph="none" start_char="9200" end_char="9202">que</TOKEN>
<TOKEN id="token-78-10" pos="word" morph="none" start_char="9204" end_char="9205">se</TOKEN>
<TOKEN id="token-78-11" pos="word" morph="none" start_char="9207" end_char="9211">creen</TOKEN>
<TOKEN id="token-78-12" pos="word" morph="none" start_char="9213" end_char="9213">a</TOKEN>
<TOKEN id="token-78-13" pos="word" morph="none" start_char="9215" end_char="9217">pie</TOKEN>
<TOKEN id="token-78-14" pos="word" morph="none" start_char="9219" end_char="9227">juntillas</TOKEN>
<TOKEN id="token-78-15" pos="word" morph="none" start_char="9229" end_char="9229">a</TOKEN>
<TOKEN id="token-78-16" pos="word" morph="none" start_char="9231" end_char="9233">los</TOKEN>
<TOKEN id="token-78-17" pos="word" morph="none" start_char="9235" end_char="9240">medios</TOKEN>
<TOKEN id="token-78-18" pos="word" morph="none" start_char="9242" end_char="9243">de</TOKEN>
<TOKEN id="token-78-19" pos="word" morph="none" start_char="9245" end_char="9256">comunicación</TOKEN>
<TOKEN id="token-78-20" pos="word" morph="none" start_char="9258" end_char="9258">y</TOKEN>
<TOKEN id="token-78-21" pos="word" morph="none" start_char="9260" end_char="9260">a</TOKEN>
<TOKEN id="token-78-22" pos="word" morph="none" start_char="9262" end_char="9269">Fernando</TOKEN>
<TOKEN id="token-78-23" pos="word" morph="none" start_char="9271" end_char="9275">Simón</TOKEN>
<TOKEN id="token-78-24" pos="punct" morph="none" start_char="9276" end_char="9276">,</TOKEN>
<TOKEN id="token-78-25" pos="word" morph="none" start_char="9278" end_char="9280">por</TOKEN>
<TOKEN id="token-78-26" pos="word" morph="none" start_char="9282" end_char="9288">ejemplo</TOKEN>
<TOKEN id="token-78-27" pos="punct" morph="none" start_char="9289" end_char="9289">.</TOKEN>
</SEG>
<SEG id="segment-79" start_char="9294" end_char="9461">
<ORIGINAL_TEXT>Yo creo en el razonamiento objetivo y en la navaja de Occam, no en pajas mentales que argumentan escenarios rebuscados pasandose por el forro las cuestiones mas obvias.</ORIGINAL_TEXT>
<TOKEN id="token-79-0" pos="word" morph="none" start_char="9294" end_char="9295">Yo</TOKEN>
<TOKEN id="token-79-1" pos="word" morph="none" start_char="9297" end_char="9300">creo</TOKEN>
<TOKEN id="token-79-2" pos="word" morph="none" start_char="9302" end_char="9303">en</TOKEN>
<TOKEN id="token-79-3" pos="word" morph="none" start_char="9305" end_char="9306">el</TOKEN>
<TOKEN id="token-79-4" pos="word" morph="none" start_char="9308" end_char="9319">razonamiento</TOKEN>
<TOKEN id="token-79-5" pos="word" morph="none" start_char="9321" end_char="9328">objetivo</TOKEN>
<TOKEN id="token-79-6" pos="word" morph="none" start_char="9330" end_char="9330">y</TOKEN>
<TOKEN id="token-79-7" pos="word" morph="none" start_char="9332" end_char="9333">en</TOKEN>
<TOKEN id="token-79-8" pos="word" morph="none" start_char="9335" end_char="9336">la</TOKEN>
<TOKEN id="token-79-9" pos="word" morph="none" start_char="9338" end_char="9343">navaja</TOKEN>
<TOKEN id="token-79-10" pos="word" morph="none" start_char="9345" end_char="9346">de</TOKEN>
<TOKEN id="token-79-11" pos="word" morph="none" start_char="9348" end_char="9352">Occam</TOKEN>
<TOKEN id="token-79-12" pos="punct" morph="none" start_char="9353" end_char="9353">,</TOKEN>
<TOKEN id="token-79-13" pos="word" morph="none" start_char="9355" end_char="9356">no</TOKEN>
<TOKEN id="token-79-14" pos="word" morph="none" start_char="9358" end_char="9359">en</TOKEN>
<TOKEN id="token-79-15" pos="word" morph="none" start_char="9361" end_char="9365">pajas</TOKEN>
<TOKEN id="token-79-16" pos="word" morph="none" start_char="9367" end_char="9374">mentales</TOKEN>
<TOKEN id="token-79-17" pos="word" morph="none" start_char="9376" end_char="9378">que</TOKEN>
<TOKEN id="token-79-18" pos="word" morph="none" start_char="9380" end_char="9389">argumentan</TOKEN>
<TOKEN id="token-79-19" pos="word" morph="none" start_char="9391" end_char="9400">escenarios</TOKEN>
<TOKEN id="token-79-20" pos="word" morph="none" start_char="9402" end_char="9411">rebuscados</TOKEN>
<TOKEN id="token-79-21" pos="word" morph="none" start_char="9413" end_char="9421">pasandose</TOKEN>
<TOKEN id="token-79-22" pos="word" morph="none" start_char="9423" end_char="9425">por</TOKEN>
<TOKEN id="token-79-23" pos="word" morph="none" start_char="9427" end_char="9428">el</TOKEN>
<TOKEN id="token-79-24" pos="word" morph="none" start_char="9430" end_char="9434">forro</TOKEN>
<TOKEN id="token-79-25" pos="word" morph="none" start_char="9436" end_char="9438">las</TOKEN>
<TOKEN id="token-79-26" pos="word" morph="none" start_char="9440" end_char="9449">cuestiones</TOKEN>
<TOKEN id="token-79-27" pos="word" morph="none" start_char="9451" end_char="9453">mas</TOKEN>
<TOKEN id="token-79-28" pos="word" morph="none" start_char="9455" end_char="9460">obvias</TOKEN>
<TOKEN id="token-79-29" pos="punct" morph="none" start_char="9461" end_char="9461">.</TOKEN>
</SEG>
<SEG id="segment-80" start_char="9467" end_char="9471">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN id="token-80-0" pos="word" morph="none" start_char="9467" end_char="9470">Cita</TOKEN>
<TOKEN id="token-80-1" pos="punct" morph="none" start_char="9471" end_char="9471">:</TOKEN>
</SEG>
<SEG id="segment-81" start_char="9476" end_char="9550">
<ORIGINAL_TEXT>Originalmente Escrito por SixxA.M Fue kuando un xino se comió un murciégalo</ORIGINAL_TEXT>
<TOKEN id="token-81-0" pos="word" morph="none" start_char="9476" end_char="9488">Originalmente</TOKEN>
<TOKEN id="token-81-1" pos="word" morph="none" start_char="9490" end_char="9496">Escrito</TOKEN>
<TOKEN id="token-81-2" pos="word" morph="none" start_char="9498" end_char="9500">por</TOKEN>
<TOKEN id="token-81-3" pos="unknown" morph="none" start_char="9502" end_char="9508">SixxA.M</TOKEN>
<TOKEN id="token-81-4" pos="word" morph="none" start_char="9510" end_char="9512">Fue</TOKEN>
<TOKEN id="token-81-5" pos="word" morph="none" start_char="9514" end_char="9519">kuando</TOKEN>
<TOKEN id="token-81-6" pos="word" morph="none" start_char="9521" end_char="9522">un</TOKEN>
<TOKEN id="token-81-7" pos="word" morph="none" start_char="9524" end_char="9527">xino</TOKEN>
<TOKEN id="token-81-8" pos="word" morph="none" start_char="9529" end_char="9530">se</TOKEN>
<TOKEN id="token-81-9" pos="word" morph="none" start_char="9532" end_char="9536">comió</TOKEN>
<TOKEN id="token-81-10" pos="word" morph="none" start_char="9538" end_char="9539">un</TOKEN>
<TOKEN id="token-81-11" pos="word" morph="none" start_char="9541" end_char="9550">murciégalo</TOKEN>
</SEG>
<SEG id="segment-82" start_char="9555" end_char="9606">
<ORIGINAL_TEXT>que dices, fue que un chino se folló a un murciegalo</ORIGINAL_TEXT>
<TOKEN id="token-82-0" pos="word" morph="none" start_char="9555" end_char="9557">que</TOKEN>
<TOKEN id="token-82-1" pos="word" morph="none" start_char="9559" end_char="9563">dices</TOKEN>
<TOKEN id="token-82-2" pos="punct" morph="none" start_char="9564" end_char="9564">,</TOKEN>
<TOKEN id="token-82-3" pos="word" morph="none" start_char="9566" end_char="9568">fue</TOKEN>
<TOKEN id="token-82-4" pos="word" morph="none" start_char="9570" end_char="9572">que</TOKEN>
<TOKEN id="token-82-5" pos="word" morph="none" start_char="9574" end_char="9575">un</TOKEN>
<TOKEN id="token-82-6" pos="word" morph="none" start_char="9577" end_char="9581">chino</TOKEN>
<TOKEN id="token-82-7" pos="word" morph="none" start_char="9583" end_char="9584">se</TOKEN>
<TOKEN id="token-82-8" pos="word" morph="none" start_char="9586" end_char="9590">folló</TOKEN>
<TOKEN id="token-82-9" pos="word" morph="none" start_char="9592" end_char="9592">a</TOKEN>
<TOKEN id="token-82-10" pos="word" morph="none" start_char="9594" end_char="9595">un</TOKEN>
<TOKEN id="token-82-11" pos="word" morph="none" start_char="9597" end_char="9606">murciegalo</TOKEN>
</SEG>
<SEG id="segment-83" start_char="9612" end_char="9616">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN id="token-83-0" pos="word" morph="none" start_char="9612" end_char="9615">Cita</TOKEN>
<TOKEN id="token-83-1" pos="punct" morph="none" start_char="9616" end_char="9616">:</TOKEN>
</SEG>
<SEG id="segment-84" start_char="9621" end_char="9780">
<ORIGINAL_TEXT>Originalmente Escrito por RAFisher Simplemente no han encontrado ninguna evidencia de manipulacion artificial siendo la hipotesis natural totalmente compatible.</ORIGINAL_TEXT>
<TOKEN id="token-84-0" pos="word" morph="none" start_char="9621" end_char="9633">Originalmente</TOKEN>
<TOKEN id="token-84-1" pos="word" morph="none" start_char="9635" end_char="9641">Escrito</TOKEN>
<TOKEN id="token-84-2" pos="word" morph="none" start_char="9643" end_char="9645">por</TOKEN>
<TOKEN id="token-84-3" pos="word" morph="none" start_char="9647" end_char="9654">RAFisher</TOKEN>
<TOKEN id="token-84-4" pos="word" morph="none" start_char="9656" end_char="9666">Simplemente</TOKEN>
<TOKEN id="token-84-5" pos="word" morph="none" start_char="9668" end_char="9669">no</TOKEN>
<TOKEN id="token-84-6" pos="word" morph="none" start_char="9671" end_char="9673">han</TOKEN>
<TOKEN id="token-84-7" pos="word" morph="none" start_char="9675" end_char="9684">encontrado</TOKEN>
<TOKEN id="token-84-8" pos="word" morph="none" start_char="9686" end_char="9692">ninguna</TOKEN>
<TOKEN id="token-84-9" pos="word" morph="none" start_char="9694" end_char="9702">evidencia</TOKEN>
<TOKEN id="token-84-10" pos="word" morph="none" start_char="9704" end_char="9705">de</TOKEN>
<TOKEN id="token-84-11" pos="word" morph="none" start_char="9707" end_char="9718">manipulacion</TOKEN>
<TOKEN id="token-84-12" pos="word" morph="none" start_char="9720" end_char="9729">artificial</TOKEN>
<TOKEN id="token-84-13" pos="word" morph="none" start_char="9731" end_char="9736">siendo</TOKEN>
<TOKEN id="token-84-14" pos="word" morph="none" start_char="9738" end_char="9739">la</TOKEN>
<TOKEN id="token-84-15" pos="word" morph="none" start_char="9741" end_char="9749">hipotesis</TOKEN>
<TOKEN id="token-84-16" pos="word" morph="none" start_char="9751" end_char="9757">natural</TOKEN>
<TOKEN id="token-84-17" pos="word" morph="none" start_char="9759" end_char="9768">totalmente</TOKEN>
<TOKEN id="token-84-18" pos="word" morph="none" start_char="9770" end_char="9779">compatible</TOKEN>
<TOKEN id="token-84-19" pos="punct" morph="none" start_char="9780" end_char="9780">.</TOKEN>
</SEG>
<SEG id="segment-85" start_char="9782" end_char="9900">
<ORIGINAL_TEXT>Siendo los investigadores del articulo de USA y UK no te parece que les encantaria destapar que el virus es artificial?</ORIGINAL_TEXT>
<TOKEN id="token-85-0" pos="word" morph="none" start_char="9782" end_char="9787">Siendo</TOKEN>
<TOKEN id="token-85-1" pos="word" morph="none" start_char="9789" end_char="9791">los</TOKEN>
<TOKEN id="token-85-2" pos="word" morph="none" start_char="9793" end_char="9806">investigadores</TOKEN>
<TOKEN id="token-85-3" pos="word" morph="none" start_char="9808" end_char="9810">del</TOKEN>
<TOKEN id="token-85-4" pos="word" morph="none" start_char="9812" end_char="9819">articulo</TOKEN>
<TOKEN id="token-85-5" pos="word" morph="none" start_char="9821" end_char="9822">de</TOKEN>
<TOKEN id="token-85-6" pos="word" morph="none" start_char="9824" end_char="9826">USA</TOKEN>
<TOKEN id="token-85-7" pos="word" morph="none" start_char="9828" end_char="9828">y</TOKEN>
<TOKEN id="token-85-8" pos="word" morph="none" start_char="9830" end_char="9831">UK</TOKEN>
<TOKEN id="token-85-9" pos="word" morph="none" start_char="9833" end_char="9834">no</TOKEN>
<TOKEN id="token-85-10" pos="word" morph="none" start_char="9836" end_char="9837">te</TOKEN>
<TOKEN id="token-85-11" pos="word" morph="none" start_char="9839" end_char="9844">parece</TOKEN>
<TOKEN id="token-85-12" pos="word" morph="none" start_char="9846" end_char="9848">que</TOKEN>
<TOKEN id="token-85-13" pos="word" morph="none" start_char="9850" end_char="9852">les</TOKEN>
<TOKEN id="token-85-14" pos="word" morph="none" start_char="9854" end_char="9863">encantaria</TOKEN>
<TOKEN id="token-85-15" pos="word" morph="none" start_char="9865" end_char="9872">destapar</TOKEN>
<TOKEN id="token-85-16" pos="word" morph="none" start_char="9874" end_char="9876">que</TOKEN>
<TOKEN id="token-85-17" pos="word" morph="none" start_char="9878" end_char="9879">el</TOKEN>
<TOKEN id="token-85-18" pos="word" morph="none" start_char="9881" end_char="9885">virus</TOKEN>
<TOKEN id="token-85-19" pos="word" morph="none" start_char="9887" end_char="9888">es</TOKEN>
<TOKEN id="token-85-20" pos="word" morph="none" start_char="9890" end_char="9899">artificial</TOKEN>
<TOKEN id="token-85-21" pos="punct" morph="none" start_char="9900" end_char="9900">?</TOKEN>
</SEG>
<SEG id="segment-86" start_char="9902" end_char="9934">
<ORIGINAL_TEXT>Sabes el prestigio que les daria?</ORIGINAL_TEXT>
<TOKEN id="token-86-0" pos="word" morph="none" start_char="9902" end_char="9906">Sabes</TOKEN>
<TOKEN id="token-86-1" pos="word" morph="none" start_char="9908" end_char="9909">el</TOKEN>
<TOKEN id="token-86-2" pos="word" morph="none" start_char="9911" end_char="9919">prestigio</TOKEN>
<TOKEN id="token-86-3" pos="word" morph="none" start_char="9921" end_char="9923">que</TOKEN>
<TOKEN id="token-86-4" pos="word" morph="none" start_char="9925" end_char="9927">les</TOKEN>
<TOKEN id="token-86-5" pos="word" morph="none" start_char="9929" end_char="9933">daria</TOKEN>
<TOKEN id="token-86-6" pos="punct" morph="none" start_char="9934" end_char="9934">?</TOKEN>
</SEG>
<SEG id="segment-87" start_char="9937" end_char="10163">
<ORIGINAL_TEXT>Sabes que eso podria provocar una guerra, aparte de que como dicen no se puede demostrar... Pero vamos que justo se haya originado el brote en el laboratorio más importante de china respecto a virus pues hombre da que pensar...</ORIGINAL_TEXT>
<TOKEN id="token-87-0" pos="word" morph="none" start_char="9937" end_char="9941">Sabes</TOKEN>
<TOKEN id="token-87-1" pos="word" morph="none" start_char="9943" end_char="9945">que</TOKEN>
<TOKEN id="token-87-2" pos="word" morph="none" start_char="9947" end_char="9949">eso</TOKEN>
<TOKEN id="token-87-3" pos="word" morph="none" start_char="9951" end_char="9956">podria</TOKEN>
<TOKEN id="token-87-4" pos="word" morph="none" start_char="9958" end_char="9965">provocar</TOKEN>
<TOKEN id="token-87-5" pos="word" morph="none" start_char="9967" end_char="9969">una</TOKEN>
<TOKEN id="token-87-6" pos="word" morph="none" start_char="9971" end_char="9976">guerra</TOKEN>
<TOKEN id="token-87-7" pos="punct" morph="none" start_char="9977" end_char="9977">,</TOKEN>
<TOKEN id="token-87-8" pos="word" morph="none" start_char="9979" end_char="9984">aparte</TOKEN>
<TOKEN id="token-87-9" pos="word" morph="none" start_char="9986" end_char="9987">de</TOKEN>
<TOKEN id="token-87-10" pos="word" morph="none" start_char="9989" end_char="9991">que</TOKEN>
<TOKEN id="token-87-11" pos="word" morph="none" start_char="9993" end_char="9996">como</TOKEN>
<TOKEN id="token-87-12" pos="word" morph="none" start_char="9998" end_char="10002">dicen</TOKEN>
<TOKEN id="token-87-13" pos="word" morph="none" start_char="10004" end_char="10005">no</TOKEN>
<TOKEN id="token-87-14" pos="word" morph="none" start_char="10007" end_char="10008">se</TOKEN>
<TOKEN id="token-87-15" pos="word" morph="none" start_char="10010" end_char="10014">puede</TOKEN>
<TOKEN id="token-87-16" pos="word" morph="none" start_char="10016" end_char="10024">demostrar</TOKEN>
<TOKEN id="token-87-17" pos="punct" morph="none" start_char="10025" end_char="10027">...</TOKEN>
<TOKEN id="token-87-18" pos="word" morph="none" start_char="10029" end_char="10032">Pero</TOKEN>
<TOKEN id="token-87-19" pos="word" morph="none" start_char="10034" end_char="10038">vamos</TOKEN>
<TOKEN id="token-87-20" pos="word" morph="none" start_char="10040" end_char="10042">que</TOKEN>
<TOKEN id="token-87-21" pos="word" morph="none" start_char="10044" end_char="10048">justo</TOKEN>
<TOKEN id="token-87-22" pos="word" morph="none" start_char="10050" end_char="10051">se</TOKEN>
<TOKEN id="token-87-23" pos="word" morph="none" start_char="10053" end_char="10056">haya</TOKEN>
<TOKEN id="token-87-24" pos="word" morph="none" start_char="10058" end_char="10066">originado</TOKEN>
<TOKEN id="token-87-25" pos="word" morph="none" start_char="10068" end_char="10069">el</TOKEN>
<TOKEN id="token-87-26" pos="word" morph="none" start_char="10071" end_char="10075">brote</TOKEN>
<TOKEN id="token-87-27" pos="word" morph="none" start_char="10077" end_char="10078">en</TOKEN>
<TOKEN id="token-87-28" pos="word" morph="none" start_char="10080" end_char="10081">el</TOKEN>
<TOKEN id="token-87-29" pos="word" morph="none" start_char="10083" end_char="10093">laboratorio</TOKEN>
<TOKEN id="token-87-30" pos="word" morph="none" start_char="10095" end_char="10097">más</TOKEN>
<TOKEN id="token-87-31" pos="word" morph="none" start_char="10099" end_char="10108">importante</TOKEN>
<TOKEN id="token-87-32" pos="word" morph="none" start_char="10110" end_char="10111">de</TOKEN>
<TOKEN id="token-87-33" pos="word" morph="none" start_char="10113" end_char="10117">china</TOKEN>
<TOKEN id="token-87-34" pos="word" morph="none" start_char="10119" end_char="10126">respecto</TOKEN>
<TOKEN id="token-87-35" pos="word" morph="none" start_char="10128" end_char="10128">a</TOKEN>
<TOKEN id="token-87-36" pos="word" morph="none" start_char="10130" end_char="10134">virus</TOKEN>
<TOKEN id="token-87-37" pos="word" morph="none" start_char="10136" end_char="10139">pues</TOKEN>
<TOKEN id="token-87-38" pos="word" morph="none" start_char="10141" end_char="10146">hombre</TOKEN>
<TOKEN id="token-87-39" pos="word" morph="none" start_char="10148" end_char="10149">da</TOKEN>
<TOKEN id="token-87-40" pos="word" morph="none" start_char="10151" end_char="10153">que</TOKEN>
<TOKEN id="token-87-41" pos="word" morph="none" start_char="10155" end_char="10160">pensar</TOKEN>
<TOKEN id="token-87-42" pos="punct" morph="none" start_char="10161" end_char="10163">...</TOKEN>
</SEG>
<SEG id="segment-88" start_char="10165" end_char="10438">
<ORIGINAL_TEXT>Y no estoy diciendo que los chinos lo soltaran aposta, pero que ha ocurrido un fallo de seguridad en ese laboratorio pues es muy posible, era un laboratorio de nivel 4, lo que significa que trabajan con virus muy peligrosos y que un fallo de seguridad puede ser catastrófico</ORIGINAL_TEXT>
<TOKEN id="token-88-0" pos="word" morph="none" start_char="10165" end_char="10165">Y</TOKEN>
<TOKEN id="token-88-1" pos="word" morph="none" start_char="10167" end_char="10168">no</TOKEN>
<TOKEN id="token-88-2" pos="word" morph="none" start_char="10170" end_char="10174">estoy</TOKEN>
<TOKEN id="token-88-3" pos="word" morph="none" start_char="10176" end_char="10183">diciendo</TOKEN>
<TOKEN id="token-88-4" pos="word" morph="none" start_char="10185" end_char="10187">que</TOKEN>
<TOKEN id="token-88-5" pos="word" morph="none" start_char="10189" end_char="10191">los</TOKEN>
<TOKEN id="token-88-6" pos="word" morph="none" start_char="10193" end_char="10198">chinos</TOKEN>
<TOKEN id="token-88-7" pos="word" morph="none" start_char="10200" end_char="10201">lo</TOKEN>
<TOKEN id="token-88-8" pos="word" morph="none" start_char="10203" end_char="10210">soltaran</TOKEN>
<TOKEN id="token-88-9" pos="word" morph="none" start_char="10212" end_char="10217">aposta</TOKEN>
<TOKEN id="token-88-10" pos="punct" morph="none" start_char="10218" end_char="10218">,</TOKEN>
<TOKEN id="token-88-11" pos="word" morph="none" start_char="10220" end_char="10223">pero</TOKEN>
<TOKEN id="token-88-12" pos="word" morph="none" start_char="10225" end_char="10227">que</TOKEN>
<TOKEN id="token-88-13" pos="word" morph="none" start_char="10229" end_char="10230">ha</TOKEN>
<TOKEN id="token-88-14" pos="word" morph="none" start_char="10232" end_char="10239">ocurrido</TOKEN>
<TOKEN id="token-88-15" pos="word" morph="none" start_char="10241" end_char="10242">un</TOKEN>
<TOKEN id="token-88-16" pos="word" morph="none" start_char="10244" end_char="10248">fallo</TOKEN>
<TOKEN id="token-88-17" pos="word" morph="none" start_char="10250" end_char="10251">de</TOKEN>
<TOKEN id="token-88-18" pos="word" morph="none" start_char="10253" end_char="10261">seguridad</TOKEN>
<TOKEN id="token-88-19" pos="word" morph="none" start_char="10263" end_char="10264">en</TOKEN>
<TOKEN id="token-88-20" pos="word" morph="none" start_char="10266" end_char="10268">ese</TOKEN>
<TOKEN id="token-88-21" pos="word" morph="none" start_char="10270" end_char="10280">laboratorio</TOKEN>
<TOKEN id="token-88-22" pos="word" morph="none" start_char="10282" end_char="10285">pues</TOKEN>
<TOKEN id="token-88-23" pos="word" morph="none" start_char="10287" end_char="10288">es</TOKEN>
<TOKEN id="token-88-24" pos="word" morph="none" start_char="10290" end_char="10292">muy</TOKEN>
<TOKEN id="token-88-25" pos="word" morph="none" start_char="10294" end_char="10300">posible</TOKEN>
<TOKEN id="token-88-26" pos="punct" morph="none" start_char="10301" end_char="10301">,</TOKEN>
<TOKEN id="token-88-27" pos="word" morph="none" start_char="10303" end_char="10305">era</TOKEN>
<TOKEN id="token-88-28" pos="word" morph="none" start_char="10307" end_char="10308">un</TOKEN>
<TOKEN id="token-88-29" pos="word" morph="none" start_char="10310" end_char="10320">laboratorio</TOKEN>
<TOKEN id="token-88-30" pos="word" morph="none" start_char="10322" end_char="10323">de</TOKEN>
<TOKEN id="token-88-31" pos="word" morph="none" start_char="10325" end_char="10329">nivel</TOKEN>
<TOKEN id="token-88-32" pos="word" morph="none" start_char="10331" end_char="10331">4</TOKEN>
<TOKEN id="token-88-33" pos="punct" morph="none" start_char="10332" end_char="10332">,</TOKEN>
<TOKEN id="token-88-34" pos="word" morph="none" start_char="10334" end_char="10335">lo</TOKEN>
<TOKEN id="token-88-35" pos="word" morph="none" start_char="10337" end_char="10339">que</TOKEN>
<TOKEN id="token-88-36" pos="word" morph="none" start_char="10341" end_char="10349">significa</TOKEN>
<TOKEN id="token-88-37" pos="word" morph="none" start_char="10351" end_char="10353">que</TOKEN>
<TOKEN id="token-88-38" pos="word" morph="none" start_char="10355" end_char="10362">trabajan</TOKEN>
<TOKEN id="token-88-39" pos="word" morph="none" start_char="10364" end_char="10366">con</TOKEN>
<TOKEN id="token-88-40" pos="word" morph="none" start_char="10368" end_char="10372">virus</TOKEN>
<TOKEN id="token-88-41" pos="word" morph="none" start_char="10374" end_char="10376">muy</TOKEN>
<TOKEN id="token-88-42" pos="word" morph="none" start_char="10378" end_char="10387">peligrosos</TOKEN>
<TOKEN id="token-88-43" pos="word" morph="none" start_char="10389" end_char="10389">y</TOKEN>
<TOKEN id="token-88-44" pos="word" morph="none" start_char="10391" end_char="10393">que</TOKEN>
<TOKEN id="token-88-45" pos="word" morph="none" start_char="10395" end_char="10396">un</TOKEN>
<TOKEN id="token-88-46" pos="word" morph="none" start_char="10398" end_char="10402">fallo</TOKEN>
<TOKEN id="token-88-47" pos="word" morph="none" start_char="10404" end_char="10405">de</TOKEN>
<TOKEN id="token-88-48" pos="word" morph="none" start_char="10407" end_char="10415">seguridad</TOKEN>
<TOKEN id="token-88-49" pos="word" morph="none" start_char="10417" end_char="10421">puede</TOKEN>
<TOKEN id="token-88-50" pos="word" morph="none" start_char="10423" end_char="10425">ser</TOKEN>
<TOKEN id="token-88-51" pos="word" morph="none" start_char="10427" end_char="10438">catastrófico</TOKEN>
</SEG>
<SEG id="segment-89" start_char="10444" end_char="10474">
<ORIGINAL_TEXT>No CREEMOS que... Venga, adios.</ORIGINAL_TEXT>
<TOKEN id="token-89-0" pos="word" morph="none" start_char="10444" end_char="10445">No</TOKEN>
<TOKEN id="token-89-1" pos="word" morph="none" start_char="10447" end_char="10453">CREEMOS</TOKEN>
<TOKEN id="token-89-2" pos="word" morph="none" start_char="10455" end_char="10457">que</TOKEN>
<TOKEN id="token-89-3" pos="punct" morph="none" start_char="10458" end_char="10460">...</TOKEN>
<TOKEN id="token-89-4" pos="word" morph="none" start_char="10462" end_char="10466">Venga</TOKEN>
<TOKEN id="token-89-5" pos="punct" morph="none" start_char="10467" end_char="10467">,</TOKEN>
<TOKEN id="token-89-6" pos="word" morph="none" start_char="10469" end_char="10473">adios</TOKEN>
<TOKEN id="token-89-7" pos="punct" morph="none" start_char="10474" end_char="10474">.</TOKEN>
</SEG>
<SEG id="segment-90" start_char="10480" end_char="10542">
<ORIGINAL_TEXT>Si lo dice "Nature" entonces he de ir pensando en lo contrario.</ORIGINAL_TEXT>
<TOKEN id="token-90-0" pos="word" morph="none" start_char="10480" end_char="10481">Si</TOKEN>
<TOKEN id="token-90-1" pos="word" morph="none" start_char="10483" end_char="10484">lo</TOKEN>
<TOKEN id="token-90-2" pos="word" morph="none" start_char="10486" end_char="10489">dice</TOKEN>
<TOKEN id="token-90-3" pos="punct" morph="none" start_char="10491" end_char="10491">"</TOKEN>
<TOKEN id="token-90-4" pos="word" morph="none" start_char="10492" end_char="10497">Nature</TOKEN>
<TOKEN id="token-90-5" pos="punct" morph="none" start_char="10498" end_char="10498">"</TOKEN>
<TOKEN id="token-90-6" pos="word" morph="none" start_char="10500" end_char="10507">entonces</TOKEN>
<TOKEN id="token-90-7" pos="word" morph="none" start_char="10509" end_char="10510">he</TOKEN>
<TOKEN id="token-90-8" pos="word" morph="none" start_char="10512" end_char="10513">de</TOKEN>
<TOKEN id="token-90-9" pos="word" morph="none" start_char="10515" end_char="10516">ir</TOKEN>
<TOKEN id="token-90-10" pos="word" morph="none" start_char="10518" end_char="10525">pensando</TOKEN>
<TOKEN id="token-90-11" pos="word" morph="none" start_char="10527" end_char="10528">en</TOKEN>
<TOKEN id="token-90-12" pos="word" morph="none" start_char="10530" end_char="10531">lo</TOKEN>
<TOKEN id="token-90-13" pos="word" morph="none" start_char="10533" end_char="10541">contrario</TOKEN>
<TOKEN id="token-90-14" pos="punct" morph="none" start_char="10542" end_char="10542">.</TOKEN>
</SEG>
<SEG id="segment-91" start_char="10544" end_char="10654">
<ORIGINAL_TEXT>Las revistas científicas son muy científicas hasta que los poderes deciden qué ciencia es buena y cuál es mala:</ORIGINAL_TEXT>
<TOKEN id="token-91-0" pos="word" morph="none" start_char="10544" end_char="10546">Las</TOKEN>
<TOKEN id="token-91-1" pos="word" morph="none" start_char="10548" end_char="10555">revistas</TOKEN>
<TOKEN id="token-91-2" pos="word" morph="none" start_char="10557" end_char="10567">científicas</TOKEN>
<TOKEN id="token-91-3" pos="word" morph="none" start_char="10569" end_char="10571">son</TOKEN>
<TOKEN id="token-91-4" pos="word" morph="none" start_char="10573" end_char="10575">muy</TOKEN>
<TOKEN id="token-91-5" pos="word" morph="none" start_char="10577" end_char="10587">científicas</TOKEN>
<TOKEN id="token-91-6" pos="word" morph="none" start_char="10589" end_char="10593">hasta</TOKEN>
<TOKEN id="token-91-7" pos="word" morph="none" start_char="10595" end_char="10597">que</TOKEN>
<TOKEN id="token-91-8" pos="word" morph="none" start_char="10599" end_char="10601">los</TOKEN>
<TOKEN id="token-91-9" pos="word" morph="none" start_char="10603" end_char="10609">poderes</TOKEN>
<TOKEN id="token-91-10" pos="word" morph="none" start_char="10611" end_char="10617">deciden</TOKEN>
<TOKEN id="token-91-11" pos="word" morph="none" start_char="10619" end_char="10621">qué</TOKEN>
<TOKEN id="token-91-12" pos="word" morph="none" start_char="10623" end_char="10629">ciencia</TOKEN>
<TOKEN id="token-91-13" pos="word" morph="none" start_char="10631" end_char="10632">es</TOKEN>
<TOKEN id="token-91-14" pos="word" morph="none" start_char="10634" end_char="10638">buena</TOKEN>
<TOKEN id="token-91-15" pos="word" morph="none" start_char="10640" end_char="10640">y</TOKEN>
<TOKEN id="token-91-16" pos="word" morph="none" start_char="10642" end_char="10645">cuál</TOKEN>
<TOKEN id="token-91-17" pos="word" morph="none" start_char="10647" end_char="10648">es</TOKEN>
<TOKEN id="token-91-18" pos="word" morph="none" start_char="10650" end_char="10653">mala</TOKEN>
<TOKEN id="token-91-19" pos="punct" morph="none" start_char="10654" end_char="10654">:</TOKEN>
</SEG>
<SEG id="segment-92" start_char="10660" end_char="10690">
<ORIGINAL_TEXT>Muy buena informacion, gracias.</ORIGINAL_TEXT>
<TOKEN id="token-92-0" pos="word" morph="none" start_char="10660" end_char="10662">Muy</TOKEN>
<TOKEN id="token-92-1" pos="word" morph="none" start_char="10664" end_char="10668">buena</TOKEN>
<TOKEN id="token-92-2" pos="word" morph="none" start_char="10670" end_char="10680">informacion</TOKEN>
<TOKEN id="token-92-3" pos="punct" morph="none" start_char="10681" end_char="10681">,</TOKEN>
<TOKEN id="token-92-4" pos="word" morph="none" start_char="10683" end_char="10689">gracias</TOKEN>
<TOKEN id="token-92-5" pos="punct" morph="none" start_char="10690" end_char="10690">.</TOKEN>
</SEG>
<SEG id="segment-93" start_char="10692" end_char="10779">
<ORIGINAL_TEXT>A mi lo del murcielago me recuerda a la otra pantochada de los monos del sida en africa.</ORIGINAL_TEXT>
<TOKEN id="token-93-0" pos="word" morph="none" start_char="10692" end_char="10692">A</TOKEN>
<TOKEN id="token-93-1" pos="word" morph="none" start_char="10694" end_char="10695">mi</TOKEN>
<TOKEN id="token-93-2" pos="word" morph="none" start_char="10697" end_char="10698">lo</TOKEN>
<TOKEN id="token-93-3" pos="word" morph="none" start_char="10700" end_char="10702">del</TOKEN>
<TOKEN id="token-93-4" pos="word" morph="none" start_char="10704" end_char="10713">murcielago</TOKEN>
<TOKEN id="token-93-5" pos="word" morph="none" start_char="10715" end_char="10716">me</TOKEN>
<TOKEN id="token-93-6" pos="word" morph="none" start_char="10718" end_char="10725">recuerda</TOKEN>
<TOKEN id="token-93-7" pos="word" morph="none" start_char="10727" end_char="10727">a</TOKEN>
<TOKEN id="token-93-8" pos="word" morph="none" start_char="10729" end_char="10730">la</TOKEN>
<TOKEN id="token-93-9" pos="word" morph="none" start_char="10732" end_char="10735">otra</TOKEN>
<TOKEN id="token-93-10" pos="word" morph="none" start_char="10737" end_char="10746">pantochada</TOKEN>
<TOKEN id="token-93-11" pos="word" morph="none" start_char="10748" end_char="10749">de</TOKEN>
<TOKEN id="token-93-12" pos="word" morph="none" start_char="10751" end_char="10753">los</TOKEN>
<TOKEN id="token-93-13" pos="word" morph="none" start_char="10755" end_char="10759">monos</TOKEN>
<TOKEN id="token-93-14" pos="word" morph="none" start_char="10761" end_char="10763">del</TOKEN>
<TOKEN id="token-93-15" pos="word" morph="none" start_char="10765" end_char="10768">sida</TOKEN>
<TOKEN id="token-93-16" pos="word" morph="none" start_char="10770" end_char="10771">en</TOKEN>
<TOKEN id="token-93-17" pos="word" morph="none" start_char="10773" end_char="10778">africa</TOKEN>
<TOKEN id="token-93-18" pos="punct" morph="none" start_char="10779" end_char="10779">.</TOKEN>
</SEG>
<SEG id="segment-94" start_char="10785" end_char="10789">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN id="token-94-0" pos="word" morph="none" start_char="10785" end_char="10788">Cita</TOKEN>
<TOKEN id="token-94-1" pos="punct" morph="none" start_char="10789" end_char="10789">:</TOKEN>
</SEG>
<SEG id="segment-95" start_char="10794" end_char="10846">
<ORIGINAL_TEXT>Originalmente Escrito por Tidus23 ¿Y qué van a decir?</ORIGINAL_TEXT>
<TOKEN id="token-95-0" pos="word" morph="none" start_char="10794" end_char="10806">Originalmente</TOKEN>
<TOKEN id="token-95-1" pos="word" morph="none" start_char="10808" end_char="10814">Escrito</TOKEN>
<TOKEN id="token-95-2" pos="word" morph="none" start_char="10816" end_char="10818">por</TOKEN>
<TOKEN id="token-95-3" pos="word" morph="none" start_char="10820" end_char="10826">Tidus23</TOKEN>
<TOKEN id="token-95-4" pos="punct" morph="none" start_char="10828" end_char="10828">¿</TOKEN>
<TOKEN id="token-95-5" pos="word" morph="none" start_char="10829" end_char="10829">Y</TOKEN>
<TOKEN id="token-95-6" pos="word" morph="none" start_char="10831" end_char="10833">qué</TOKEN>
<TOKEN id="token-95-7" pos="word" morph="none" start_char="10835" end_char="10837">van</TOKEN>
<TOKEN id="token-95-8" pos="word" morph="none" start_char="10839" end_char="10839">a</TOKEN>
<TOKEN id="token-95-9" pos="word" morph="none" start_char="10841" end_char="10845">decir</TOKEN>
<TOKEN id="token-95-10" pos="punct" morph="none" start_char="10846" end_char="10846">?</TOKEN>
</SEG>
<SEG id="segment-96" start_char="10851" end_char="10863">
<ORIGINAL_TEXT>Din del hilo.</ORIGINAL_TEXT>
<TOKEN id="token-96-0" pos="word" morph="none" start_char="10851" end_char="10853">Din</TOKEN>
<TOKEN id="token-96-1" pos="word" morph="none" start_char="10855" end_char="10857">del</TOKEN>
<TOKEN id="token-96-2" pos="word" morph="none" start_char="10859" end_char="10862">hilo</TOKEN>
<TOKEN id="token-96-3" pos="punct" morph="none" start_char="10863" end_char="10863">.</TOKEN>
</SEG>
<SEG id="segment-97" start_char="10865" end_char="10920">
<ORIGINAL_TEXT>Como cuando el Simón decía que aquí no iba a pasar nada.</ORIGINAL_TEXT>
<TOKEN id="token-97-0" pos="word" morph="none" start_char="10865" end_char="10868">Como</TOKEN>
<TOKEN id="token-97-1" pos="word" morph="none" start_char="10870" end_char="10875">cuando</TOKEN>
<TOKEN id="token-97-2" pos="word" morph="none" start_char="10877" end_char="10878">el</TOKEN>
<TOKEN id="token-97-3" pos="word" morph="none" start_char="10880" end_char="10884">Simón</TOKEN>
<TOKEN id="token-97-4" pos="word" morph="none" start_char="10886" end_char="10890">decía</TOKEN>
<TOKEN id="token-97-5" pos="word" morph="none" start_char="10892" end_char="10894">que</TOKEN>
<TOKEN id="token-97-6" pos="word" morph="none" start_char="10896" end_char="10899">aquí</TOKEN>
<TOKEN id="token-97-7" pos="word" morph="none" start_char="10901" end_char="10902">no</TOKEN>
<TOKEN id="token-97-8" pos="word" morph="none" start_char="10904" end_char="10906">iba</TOKEN>
<TOKEN id="token-97-9" pos="word" morph="none" start_char="10908" end_char="10908">a</TOKEN>
<TOKEN id="token-97-10" pos="word" morph="none" start_char="10910" end_char="10914">pasar</TOKEN>
<TOKEN id="token-97-11" pos="word" morph="none" start_char="10916" end_char="10919">nada</TOKEN>
<TOKEN id="token-97-12" pos="punct" morph="none" start_char="10920" end_char="10920">.</TOKEN>
</SEG>
<SEG id="segment-98" start_char="10922" end_char="11194">
<ORIGINAL_TEXT>Os imaginais declaraciones del tipo: - Va a haber miles de muertos y cientos de miles de infectados - El virus no tiene origen natural, ha sido manipulado - La economía retrocederá al menos 10 años y el paro subirá 5 puntos - Por ahora no tenemos forma de evitar contagios.</ORIGINAL_TEXT>
<TOKEN id="token-98-0" pos="word" morph="none" start_char="10922" end_char="10923">Os</TOKEN>
<TOKEN id="token-98-1" pos="word" morph="none" start_char="10925" end_char="10933">imaginais</TOKEN>
<TOKEN id="token-98-2" pos="word" morph="none" start_char="10935" end_char="10947">declaraciones</TOKEN>
<TOKEN id="token-98-3" pos="word" morph="none" start_char="10949" end_char="10951">del</TOKEN>
<TOKEN id="token-98-4" pos="word" morph="none" start_char="10953" end_char="10956">tipo</TOKEN>
<TOKEN id="token-98-5" pos="punct" morph="none" start_char="10957" end_char="10957">:</TOKEN>
<TOKEN id="token-98-6" pos="punct" morph="none" start_char="10959" end_char="10959">-</TOKEN>
<TOKEN id="token-98-7" pos="word" morph="none" start_char="10961" end_char="10962">Va</TOKEN>
<TOKEN id="token-98-8" pos="word" morph="none" start_char="10964" end_char="10964">a</TOKEN>
<TOKEN id="token-98-9" pos="word" morph="none" start_char="10966" end_char="10970">haber</TOKEN>
<TOKEN id="token-98-10" pos="word" morph="none" start_char="10972" end_char="10976">miles</TOKEN>
<TOKEN id="token-98-11" pos="word" morph="none" start_char="10978" end_char="10979">de</TOKEN>
<TOKEN id="token-98-12" pos="word" morph="none" start_char="10981" end_char="10987">muertos</TOKEN>
<TOKEN id="token-98-13" pos="word" morph="none" start_char="10989" end_char="10989">y</TOKEN>
<TOKEN id="token-98-14" pos="word" morph="none" start_char="10991" end_char="10997">cientos</TOKEN>
<TOKEN id="token-98-15" pos="word" morph="none" start_char="10999" end_char="11000">de</TOKEN>
<TOKEN id="token-98-16" pos="word" morph="none" start_char="11002" end_char="11006">miles</TOKEN>
<TOKEN id="token-98-17" pos="word" morph="none" start_char="11008" end_char="11009">de</TOKEN>
<TOKEN id="token-98-18" pos="word" morph="none" start_char="11011" end_char="11020">infectados</TOKEN>
<TOKEN id="token-98-19" pos="punct" morph="none" start_char="11022" end_char="11022">-</TOKEN>
<TOKEN id="token-98-20" pos="word" morph="none" start_char="11024" end_char="11025">El</TOKEN>
<TOKEN id="token-98-21" pos="word" morph="none" start_char="11027" end_char="11031">virus</TOKEN>
<TOKEN id="token-98-22" pos="word" morph="none" start_char="11033" end_char="11034">no</TOKEN>
<TOKEN id="token-98-23" pos="word" morph="none" start_char="11036" end_char="11040">tiene</TOKEN>
<TOKEN id="token-98-24" pos="word" morph="none" start_char="11042" end_char="11047">origen</TOKEN>
<TOKEN id="token-98-25" pos="word" morph="none" start_char="11049" end_char="11055">natural</TOKEN>
<TOKEN id="token-98-26" pos="punct" morph="none" start_char="11056" end_char="11056">,</TOKEN>
<TOKEN id="token-98-27" pos="word" morph="none" start_char="11058" end_char="11059">ha</TOKEN>
<TOKEN id="token-98-28" pos="word" morph="none" start_char="11061" end_char="11064">sido</TOKEN>
<TOKEN id="token-98-29" pos="word" morph="none" start_char="11066" end_char="11075">manipulado</TOKEN>
<TOKEN id="token-98-30" pos="punct" morph="none" start_char="11077" end_char="11077">-</TOKEN>
<TOKEN id="token-98-31" pos="word" morph="none" start_char="11079" end_char="11080">La</TOKEN>
<TOKEN id="token-98-32" pos="word" morph="none" start_char="11082" end_char="11089">economía</TOKEN>
<TOKEN id="token-98-33" pos="word" morph="none" start_char="11091" end_char="11101">retrocederá</TOKEN>
<TOKEN id="token-98-34" pos="word" morph="none" start_char="11103" end_char="11104">al</TOKEN>
<TOKEN id="token-98-35" pos="word" morph="none" start_char="11106" end_char="11110">menos</TOKEN>
<TOKEN id="token-98-36" pos="word" morph="none" start_char="11112" end_char="11113">10</TOKEN>
<TOKEN id="token-98-37" pos="word" morph="none" start_char="11115" end_char="11118">años</TOKEN>
<TOKEN id="token-98-38" pos="word" morph="none" start_char="11120" end_char="11120">y</TOKEN>
<TOKEN id="token-98-39" pos="word" morph="none" start_char="11122" end_char="11123">el</TOKEN>
<TOKEN id="token-98-40" pos="word" morph="none" start_char="11125" end_char="11128">paro</TOKEN>
<TOKEN id="token-98-41" pos="word" morph="none" start_char="11130" end_char="11135">subirá</TOKEN>
<TOKEN id="token-98-42" pos="word" morph="none" start_char="11137" end_char="11137">5</TOKEN>
<TOKEN id="token-98-43" pos="word" morph="none" start_char="11139" end_char="11144">puntos</TOKEN>
<TOKEN id="token-98-44" pos="punct" morph="none" start_char="11146" end_char="11146">-</TOKEN>
<TOKEN id="token-98-45" pos="word" morph="none" start_char="11148" end_char="11150">Por</TOKEN>
<TOKEN id="token-98-46" pos="word" morph="none" start_char="11152" end_char="11156">ahora</TOKEN>
<TOKEN id="token-98-47" pos="word" morph="none" start_char="11158" end_char="11159">no</TOKEN>
<TOKEN id="token-98-48" pos="word" morph="none" start_char="11161" end_char="11167">tenemos</TOKEN>
<TOKEN id="token-98-49" pos="word" morph="none" start_char="11169" end_char="11173">forma</TOKEN>
<TOKEN id="token-98-50" pos="word" morph="none" start_char="11175" end_char="11176">de</TOKEN>
<TOKEN id="token-98-51" pos="word" morph="none" start_char="11178" end_char="11183">evitar</TOKEN>
<TOKEN id="token-98-52" pos="word" morph="none" start_char="11185" end_char="11193">contagios</TOKEN>
<TOKEN id="token-98-53" pos="punct" morph="none" start_char="11194" end_char="11194">.</TOKEN>
</SEG>
<SEG id="segment-99" start_char="11196" end_char="11304">
<ORIGINAL_TEXT>Estar en casa encerrados mitigará su ritmo para evitar que la gente muera sin atención médica en el hospital.</ORIGINAL_TEXT>
<TOKEN id="token-99-0" pos="word" morph="none" start_char="11196" end_char="11200">Estar</TOKEN>
<TOKEN id="token-99-1" pos="word" morph="none" start_char="11202" end_char="11203">en</TOKEN>
<TOKEN id="token-99-2" pos="word" morph="none" start_char="11205" end_char="11208">casa</TOKEN>
<TOKEN id="token-99-3" pos="word" morph="none" start_char="11210" end_char="11219">encerrados</TOKEN>
<TOKEN id="token-99-4" pos="word" morph="none" start_char="11221" end_char="11228">mitigará</TOKEN>
<TOKEN id="token-99-5" pos="word" morph="none" start_char="11230" end_char="11231">su</TOKEN>
<TOKEN id="token-99-6" pos="word" morph="none" start_char="11233" end_char="11237">ritmo</TOKEN>
<TOKEN id="token-99-7" pos="word" morph="none" start_char="11239" end_char="11242">para</TOKEN>
<TOKEN id="token-99-8" pos="word" morph="none" start_char="11244" end_char="11249">evitar</TOKEN>
<TOKEN id="token-99-9" pos="word" morph="none" start_char="11251" end_char="11253">que</TOKEN>
<TOKEN id="token-99-10" pos="word" morph="none" start_char="11255" end_char="11256">la</TOKEN>
<TOKEN id="token-99-11" pos="word" morph="none" start_char="11258" end_char="11262">gente</TOKEN>
<TOKEN id="token-99-12" pos="word" morph="none" start_char="11264" end_char="11268">muera</TOKEN>
<TOKEN id="token-99-13" pos="word" morph="none" start_char="11270" end_char="11272">sin</TOKEN>
<TOKEN id="token-99-14" pos="word" morph="none" start_char="11274" end_char="11281">atención</TOKEN>
<TOKEN id="token-99-15" pos="word" morph="none" start_char="11283" end_char="11288">médica</TOKEN>
<TOKEN id="token-99-16" pos="word" morph="none" start_char="11290" end_char="11291">en</TOKEN>
<TOKEN id="token-99-17" pos="word" morph="none" start_char="11293" end_char="11294">el</TOKEN>
<TOKEN id="token-99-18" pos="word" morph="none" start_char="11296" end_char="11303">hospital</TOKEN>
<TOKEN id="token-99-19" pos="punct" morph="none" start_char="11304" end_char="11304">.</TOKEN>
</SEG>
<SEG id="segment-100" start_char="11306" end_char="11528">
<ORIGINAL_TEXT>- La vacuna tardará al menos un año, por lo que esta situación se mantedrá así durante un largo tiempo - Si el virus muta, vuelta a empezar Na, es mucho mejor decir que no pasa nada, y mientras ir a las manifas con guantes.</ORIGINAL_TEXT>
<TOKEN id="token-100-0" pos="punct" morph="none" start_char="11306" end_char="11306">-</TOKEN>
<TOKEN id="token-100-1" pos="word" morph="none" start_char="11308" end_char="11309">La</TOKEN>
<TOKEN id="token-100-2" pos="word" morph="none" start_char="11311" end_char="11316">vacuna</TOKEN>
<TOKEN id="token-100-3" pos="word" morph="none" start_char="11318" end_char="11324">tardará</TOKEN>
<TOKEN id="token-100-4" pos="word" morph="none" start_char="11326" end_char="11327">al</TOKEN>
<TOKEN id="token-100-5" pos="word" morph="none" start_char="11329" end_char="11333">menos</TOKEN>
<TOKEN id="token-100-6" pos="word" morph="none" start_char="11335" end_char="11336">un</TOKEN>
<TOKEN id="token-100-7" pos="word" morph="none" start_char="11338" end_char="11340">año</TOKEN>
<TOKEN id="token-100-8" pos="punct" morph="none" start_char="11341" end_char="11341">,</TOKEN>
<TOKEN id="token-100-9" pos="word" morph="none" start_char="11343" end_char="11345">por</TOKEN>
<TOKEN id="token-100-10" pos="word" morph="none" start_char="11347" end_char="11348">lo</TOKEN>
<TOKEN id="token-100-11" pos="word" morph="none" start_char="11350" end_char="11352">que</TOKEN>
<TOKEN id="token-100-12" pos="word" morph="none" start_char="11354" end_char="11357">esta</TOKEN>
<TOKEN id="token-100-13" pos="word" morph="none" start_char="11359" end_char="11367">situación</TOKEN>
<TOKEN id="token-100-14" pos="word" morph="none" start_char="11369" end_char="11370">se</TOKEN>
<TOKEN id="token-100-15" pos="word" morph="none" start_char="11372" end_char="11379">mantedrá</TOKEN>
<TOKEN id="token-100-16" pos="word" morph="none" start_char="11381" end_char="11383">así</TOKEN>
<TOKEN id="token-100-17" pos="word" morph="none" start_char="11385" end_char="11391">durante</TOKEN>
<TOKEN id="token-100-18" pos="word" morph="none" start_char="11393" end_char="11394">un</TOKEN>
<TOKEN id="token-100-19" pos="word" morph="none" start_char="11396" end_char="11400">largo</TOKEN>
<TOKEN id="token-100-20" pos="word" morph="none" start_char="11402" end_char="11407">tiempo</TOKEN>
<TOKEN id="token-100-21" pos="punct" morph="none" start_char="11409" end_char="11409">-</TOKEN>
<TOKEN id="token-100-22" pos="word" morph="none" start_char="11411" end_char="11412">Si</TOKEN>
<TOKEN id="token-100-23" pos="word" morph="none" start_char="11414" end_char="11415">el</TOKEN>
<TOKEN id="token-100-24" pos="word" morph="none" start_char="11417" end_char="11421">virus</TOKEN>
<TOKEN id="token-100-25" pos="word" morph="none" start_char="11423" end_char="11426">muta</TOKEN>
<TOKEN id="token-100-26" pos="punct" morph="none" start_char="11427" end_char="11427">,</TOKEN>
<TOKEN id="token-100-27" pos="word" morph="none" start_char="11429" end_char="11434">vuelta</TOKEN>
<TOKEN id="token-100-28" pos="word" morph="none" start_char="11436" end_char="11436">a</TOKEN>
<TOKEN id="token-100-29" pos="word" morph="none" start_char="11438" end_char="11444">empezar</TOKEN>
<TOKEN id="token-100-30" pos="word" morph="none" start_char="11446" end_char="11447">Na</TOKEN>
<TOKEN id="token-100-31" pos="punct" morph="none" start_char="11448" end_char="11448">,</TOKEN>
<TOKEN id="token-100-32" pos="word" morph="none" start_char="11450" end_char="11451">es</TOKEN>
<TOKEN id="token-100-33" pos="word" morph="none" start_char="11453" end_char="11457">mucho</TOKEN>
<TOKEN id="token-100-34" pos="word" morph="none" start_char="11459" end_char="11463">mejor</TOKEN>
<TOKEN id="token-100-35" pos="word" morph="none" start_char="11465" end_char="11469">decir</TOKEN>
<TOKEN id="token-100-36" pos="word" morph="none" start_char="11471" end_char="11473">que</TOKEN>
<TOKEN id="token-100-37" pos="word" morph="none" start_char="11475" end_char="11476">no</TOKEN>
<TOKEN id="token-100-38" pos="word" morph="none" start_char="11478" end_char="11481">pasa</TOKEN>
<TOKEN id="token-100-39" pos="word" morph="none" start_char="11483" end_char="11486">nada</TOKEN>
<TOKEN id="token-100-40" pos="punct" morph="none" start_char="11487" end_char="11487">,</TOKEN>
<TOKEN id="token-100-41" pos="word" morph="none" start_char="11489" end_char="11489">y</TOKEN>
<TOKEN id="token-100-42" pos="word" morph="none" start_char="11491" end_char="11498">mientras</TOKEN>
<TOKEN id="token-100-43" pos="word" morph="none" start_char="11500" end_char="11501">ir</TOKEN>
<TOKEN id="token-100-44" pos="word" morph="none" start_char="11503" end_char="11503">a</TOKEN>
<TOKEN id="token-100-45" pos="word" morph="none" start_char="11505" end_char="11507">las</TOKEN>
<TOKEN id="token-100-46" pos="word" morph="none" start_char="11509" end_char="11515">manifas</TOKEN>
<TOKEN id="token-100-47" pos="word" morph="none" start_char="11517" end_char="11519">con</TOKEN>
<TOKEN id="token-100-48" pos="word" morph="none" start_char="11521" end_char="11527">guantes</TOKEN>
<TOKEN id="token-100-49" pos="punct" morph="none" start_char="11528" end_char="11528">.</TOKEN>
</SEG>
<SEG id="segment-101" start_char="11534" end_char="11538">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN id="token-101-0" pos="word" morph="none" start_char="11534" end_char="11537">Cita</TOKEN>
<TOKEN id="token-101-1" pos="punct" morph="none" start_char="11538" end_char="11538">:</TOKEN>
</SEG>
<SEG id="segment-102" start_char="11543" end_char="11749">
<ORIGINAL_TEXT>Originalmente Escrito por Voltiamperio Yo creo en el razonamiento objetivo y en la navaja de Occam, no en pajas mentales que argumentan escenarios rebuscados pasandose por el forro las cuestiones mas obvias.</ORIGINAL_TEXT>
<TOKEN id="token-102-0" pos="word" morph="none" start_char="11543" end_char="11555">Originalmente</TOKEN>
<TOKEN id="token-102-1" pos="word" morph="none" start_char="11557" end_char="11563">Escrito</TOKEN>
<TOKEN id="token-102-2" pos="word" morph="none" start_char="11565" end_char="11567">por</TOKEN>
<TOKEN id="token-102-3" pos="word" morph="none" start_char="11569" end_char="11580">Voltiamperio</TOKEN>
<TOKEN id="token-102-4" pos="word" morph="none" start_char="11582" end_char="11583">Yo</TOKEN>
<TOKEN id="token-102-5" pos="word" morph="none" start_char="11585" end_char="11588">creo</TOKEN>
<TOKEN id="token-102-6" pos="word" morph="none" start_char="11590" end_char="11591">en</TOKEN>
<TOKEN id="token-102-7" pos="word" morph="none" start_char="11593" end_char="11594">el</TOKEN>
<TOKEN id="token-102-8" pos="word" morph="none" start_char="11596" end_char="11607">razonamiento</TOKEN>
<TOKEN id="token-102-9" pos="word" morph="none" start_char="11609" end_char="11616">objetivo</TOKEN>
<TOKEN id="token-102-10" pos="word" morph="none" start_char="11618" end_char="11618">y</TOKEN>
<TOKEN id="token-102-11" pos="word" morph="none" start_char="11620" end_char="11621">en</TOKEN>
<TOKEN id="token-102-12" pos="word" morph="none" start_char="11623" end_char="11624">la</TOKEN>
<TOKEN id="token-102-13" pos="word" morph="none" start_char="11626" end_char="11631">navaja</TOKEN>
<TOKEN id="token-102-14" pos="word" morph="none" start_char="11633" end_char="11634">de</TOKEN>
<TOKEN id="token-102-15" pos="word" morph="none" start_char="11636" end_char="11640">Occam</TOKEN>
<TOKEN id="token-102-16" pos="punct" morph="none" start_char="11641" end_char="11641">,</TOKEN>
<TOKEN id="token-102-17" pos="word" morph="none" start_char="11643" end_char="11644">no</TOKEN>
<TOKEN id="token-102-18" pos="word" morph="none" start_char="11646" end_char="11647">en</TOKEN>
<TOKEN id="token-102-19" pos="word" morph="none" start_char="11649" end_char="11653">pajas</TOKEN>
<TOKEN id="token-102-20" pos="word" morph="none" start_char="11655" end_char="11662">mentales</TOKEN>
<TOKEN id="token-102-21" pos="word" morph="none" start_char="11664" end_char="11666">que</TOKEN>
<TOKEN id="token-102-22" pos="word" morph="none" start_char="11668" end_char="11677">argumentan</TOKEN>
<TOKEN id="token-102-23" pos="word" morph="none" start_char="11679" end_char="11688">escenarios</TOKEN>
<TOKEN id="token-102-24" pos="word" morph="none" start_char="11690" end_char="11699">rebuscados</TOKEN>
<TOKEN id="token-102-25" pos="word" morph="none" start_char="11701" end_char="11709">pasandose</TOKEN>
<TOKEN id="token-102-26" pos="word" morph="none" start_char="11711" end_char="11713">por</TOKEN>
<TOKEN id="token-102-27" pos="word" morph="none" start_char="11715" end_char="11716">el</TOKEN>
<TOKEN id="token-102-28" pos="word" morph="none" start_char="11718" end_char="11722">forro</TOKEN>
<TOKEN id="token-102-29" pos="word" morph="none" start_char="11724" end_char="11726">las</TOKEN>
<TOKEN id="token-102-30" pos="word" morph="none" start_char="11728" end_char="11737">cuestiones</TOKEN>
<TOKEN id="token-102-31" pos="word" morph="none" start_char="11739" end_char="11741">mas</TOKEN>
<TOKEN id="token-102-32" pos="word" morph="none" start_char="11743" end_char="11748">obvias</TOKEN>
<TOKEN id="token-102-33" pos="punct" morph="none" start_char="11749" end_char="11749">.</TOKEN>
</SEG>
<SEG id="segment-103" start_char="11754" end_char="11929">
<ORIGINAL_TEXT>Y que surja el brote en la ciudad de china donde esta el laboratorio de estudios viricos que trabaja con los virus más peligrosos de toda china no te parece una cuestión obvia?</ORIGINAL_TEXT>
<TOKEN id="token-103-0" pos="word" morph="none" start_char="11754" end_char="11754">Y</TOKEN>
<TOKEN id="token-103-1" pos="word" morph="none" start_char="11756" end_char="11758">que</TOKEN>
<TOKEN id="token-103-2" pos="word" morph="none" start_char="11760" end_char="11764">surja</TOKEN>
<TOKEN id="token-103-3" pos="word" morph="none" start_char="11766" end_char="11767">el</TOKEN>
<TOKEN id="token-103-4" pos="word" morph="none" start_char="11769" end_char="11773">brote</TOKEN>
<TOKEN id="token-103-5" pos="word" morph="none" start_char="11775" end_char="11776">en</TOKEN>
<TOKEN id="token-103-6" pos="word" morph="none" start_char="11778" end_char="11779">la</TOKEN>
<TOKEN id="token-103-7" pos="word" morph="none" start_char="11781" end_char="11786">ciudad</TOKEN>
<TOKEN id="token-103-8" pos="word" morph="none" start_char="11788" end_char="11789">de</TOKEN>
<TOKEN id="token-103-9" pos="word" morph="none" start_char="11791" end_char="11795">china</TOKEN>
<TOKEN id="token-103-10" pos="word" morph="none" start_char="11797" end_char="11801">donde</TOKEN>
<TOKEN id="token-103-11" pos="word" morph="none" start_char="11803" end_char="11806">esta</TOKEN>
<TOKEN id="token-103-12" pos="word" morph="none" start_char="11808" end_char="11809">el</TOKEN>
<TOKEN id="token-103-13" pos="word" morph="none" start_char="11811" end_char="11821">laboratorio</TOKEN>
<TOKEN id="token-103-14" pos="word" morph="none" start_char="11823" end_char="11824">de</TOKEN>
<TOKEN id="token-103-15" pos="word" morph="none" start_char="11826" end_char="11833">estudios</TOKEN>
<TOKEN id="token-103-16" pos="word" morph="none" start_char="11835" end_char="11841">viricos</TOKEN>
<TOKEN id="token-103-17" pos="word" morph="none" start_char="11843" end_char="11845">que</TOKEN>
<TOKEN id="token-103-18" pos="word" morph="none" start_char="11847" end_char="11853">trabaja</TOKEN>
<TOKEN id="token-103-19" pos="word" morph="none" start_char="11855" end_char="11857">con</TOKEN>
<TOKEN id="token-103-20" pos="word" morph="none" start_char="11859" end_char="11861">los</TOKEN>
<TOKEN id="token-103-21" pos="word" morph="none" start_char="11863" end_char="11867">virus</TOKEN>
<TOKEN id="token-103-22" pos="word" morph="none" start_char="11869" end_char="11871">más</TOKEN>
<TOKEN id="token-103-23" pos="word" morph="none" start_char="11873" end_char="11882">peligrosos</TOKEN>
<TOKEN id="token-103-24" pos="word" morph="none" start_char="11884" end_char="11885">de</TOKEN>
<TOKEN id="token-103-25" pos="word" morph="none" start_char="11887" end_char="11890">toda</TOKEN>
<TOKEN id="token-103-26" pos="word" morph="none" start_char="11892" end_char="11896">china</TOKEN>
<TOKEN id="token-103-27" pos="word" morph="none" start_char="11898" end_char="11899">no</TOKEN>
<TOKEN id="token-103-28" pos="word" morph="none" start_char="11901" end_char="11902">te</TOKEN>
<TOKEN id="token-103-29" pos="word" morph="none" start_char="11904" end_char="11909">parece</TOKEN>
<TOKEN id="token-103-30" pos="word" morph="none" start_char="11911" end_char="11913">una</TOKEN>
<TOKEN id="token-103-31" pos="word" morph="none" start_char="11915" end_char="11922">cuestión</TOKEN>
<TOKEN id="token-103-32" pos="word" morph="none" start_char="11924" end_char="11928">obvia</TOKEN>
<TOKEN id="token-103-33" pos="punct" morph="none" start_char="11929" end_char="11929">?</TOKEN>
</SEG>
<SEG id="segment-104" start_char="11931" end_char="12098">
<ORIGINAL_TEXT>Que con 500 infectados ya cerrarán a cal y canto wuhan y se pusieran a desinfectar las calles no te parece también obvio que sabían ya muy bien a lo que se enfrentaban?</ORIGINAL_TEXT>
<TOKEN id="token-104-0" pos="word" morph="none" start_char="11931" end_char="11933">Que</TOKEN>
<TOKEN id="token-104-1" pos="word" morph="none" start_char="11935" end_char="11937">con</TOKEN>
<TOKEN id="token-104-2" pos="word" morph="none" start_char="11939" end_char="11941">500</TOKEN>
<TOKEN id="token-104-3" pos="word" morph="none" start_char="11943" end_char="11952">infectados</TOKEN>
<TOKEN id="token-104-4" pos="word" morph="none" start_char="11954" end_char="11955">ya</TOKEN>
<TOKEN id="token-104-5" pos="word" morph="none" start_char="11957" end_char="11964">cerrarán</TOKEN>
<TOKEN id="token-104-6" pos="word" morph="none" start_char="11966" end_char="11966">a</TOKEN>
<TOKEN id="token-104-7" pos="word" morph="none" start_char="11968" end_char="11970">cal</TOKEN>
<TOKEN id="token-104-8" pos="word" morph="none" start_char="11972" end_char="11972">y</TOKEN>
<TOKEN id="token-104-9" pos="word" morph="none" start_char="11974" end_char="11978">canto</TOKEN>
<TOKEN id="token-104-10" pos="word" morph="none" start_char="11980" end_char="11984">wuhan</TOKEN>
<TOKEN id="token-104-11" pos="word" morph="none" start_char="11986" end_char="11986">y</TOKEN>
<TOKEN id="token-104-12" pos="word" morph="none" start_char="11988" end_char="11989">se</TOKEN>
<TOKEN id="token-104-13" pos="word" morph="none" start_char="11991" end_char="11998">pusieran</TOKEN>
<TOKEN id="token-104-14" pos="word" morph="none" start_char="12000" end_char="12000">a</TOKEN>
<TOKEN id="token-104-15" pos="word" morph="none" start_char="12002" end_char="12012">desinfectar</TOKEN>
<TOKEN id="token-104-16" pos="word" morph="none" start_char="12014" end_char="12016">las</TOKEN>
<TOKEN id="token-104-17" pos="word" morph="none" start_char="12018" end_char="12023">calles</TOKEN>
<TOKEN id="token-104-18" pos="word" morph="none" start_char="12025" end_char="12026">no</TOKEN>
<TOKEN id="token-104-19" pos="word" morph="none" start_char="12028" end_char="12029">te</TOKEN>
<TOKEN id="token-104-20" pos="word" morph="none" start_char="12031" end_char="12036">parece</TOKEN>
<TOKEN id="token-104-21" pos="word" morph="none" start_char="12038" end_char="12044">también</TOKEN>
<TOKEN id="token-104-22" pos="word" morph="none" start_char="12046" end_char="12050">obvio</TOKEN>
<TOKEN id="token-104-23" pos="word" morph="none" start_char="12052" end_char="12054">que</TOKEN>
<TOKEN id="token-104-24" pos="word" morph="none" start_char="12056" end_char="12061">sabían</TOKEN>
<TOKEN id="token-104-25" pos="word" morph="none" start_char="12063" end_char="12064">ya</TOKEN>
<TOKEN id="token-104-26" pos="word" morph="none" start_char="12066" end_char="12068">muy</TOKEN>
<TOKEN id="token-104-27" pos="word" morph="none" start_char="12070" end_char="12073">bien</TOKEN>
<TOKEN id="token-104-28" pos="word" morph="none" start_char="12075" end_char="12075">a</TOKEN>
<TOKEN id="token-104-29" pos="word" morph="none" start_char="12077" end_char="12078">lo</TOKEN>
<TOKEN id="token-104-30" pos="word" morph="none" start_char="12080" end_char="12082">que</TOKEN>
<TOKEN id="token-104-31" pos="word" morph="none" start_char="12084" end_char="12085">se</TOKEN>
<TOKEN id="token-104-32" pos="word" morph="none" start_char="12087" end_char="12097">enfrentaban</TOKEN>
<TOKEN id="token-104-33" pos="punct" morph="none" start_char="12098" end_char="12098">?</TOKEN>
</SEG>
<SEG id="segment-105" start_char="12104" end_char="12127">
<ORIGINAL_TEXT>Mas @Tonto que un tomate</ORIGINAL_TEXT>
<TOKEN id="token-105-0" pos="word" morph="none" start_char="12104" end_char="12106">Mas</TOKEN>
<TOKEN id="token-105-1" pos="tag" morph="none" start_char="12108" end_char="12113">@Tonto</TOKEN>
<TOKEN id="token-105-2" pos="word" morph="none" start_char="12115" end_char="12117">que</TOKEN>
<TOKEN id="token-105-3" pos="word" morph="none" start_char="12119" end_char="12120">un</TOKEN>
<TOKEN id="token-105-4" pos="word" morph="none" start_char="12122" end_char="12127">tomate</TOKEN>
</SEG>
<SEG id="segment-106" start_char="12133" end_char="12137">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN id="token-106-0" pos="word" morph="none" start_char="12133" end_char="12136">Cita</TOKEN>
<TOKEN id="token-106-1" pos="punct" morph="none" start_char="12137" end_char="12137">:</TOKEN>
</SEG>
<SEG id="segment-107" start_char="12142" end_char="12398">
<ORIGINAL_TEXT>Originalmente Escrito por RAFisher Magufos y biologos del bar Pepe se cae el mito: "Aunque la evidencia muestra que el SARS-CoV-2 no es un virus manipulado a propósito, actualmente es imposible probar o refutar las otras teorías de su origen descritas aquí.</ORIGINAL_TEXT>
<TOKEN id="token-107-0" pos="word" morph="none" start_char="12142" end_char="12154">Originalmente</TOKEN>
<TOKEN id="token-107-1" pos="word" morph="none" start_char="12156" end_char="12162">Escrito</TOKEN>
<TOKEN id="token-107-2" pos="word" morph="none" start_char="12164" end_char="12166">por</TOKEN>
<TOKEN id="token-107-3" pos="word" morph="none" start_char="12168" end_char="12175">RAFisher</TOKEN>
<TOKEN id="token-107-4" pos="word" morph="none" start_char="12177" end_char="12183">Magufos</TOKEN>
<TOKEN id="token-107-5" pos="word" morph="none" start_char="12185" end_char="12185">y</TOKEN>
<TOKEN id="token-107-6" pos="word" morph="none" start_char="12187" end_char="12194">biologos</TOKEN>
<TOKEN id="token-107-7" pos="word" morph="none" start_char="12196" end_char="12198">del</TOKEN>
<TOKEN id="token-107-8" pos="word" morph="none" start_char="12200" end_char="12202">bar</TOKEN>
<TOKEN id="token-107-9" pos="word" morph="none" start_char="12204" end_char="12207">Pepe</TOKEN>
<TOKEN id="token-107-10" pos="word" morph="none" start_char="12209" end_char="12210">se</TOKEN>
<TOKEN id="token-107-11" pos="word" morph="none" start_char="12212" end_char="12214">cae</TOKEN>
<TOKEN id="token-107-12" pos="word" morph="none" start_char="12216" end_char="12217">el</TOKEN>
<TOKEN id="token-107-13" pos="word" morph="none" start_char="12219" end_char="12222">mito</TOKEN>
<TOKEN id="token-107-14" pos="punct" morph="none" start_char="12223" end_char="12223">:</TOKEN>
<TOKEN id="token-107-15" pos="punct" morph="none" start_char="12225" end_char="12225">"</TOKEN>
<TOKEN id="token-107-16" pos="word" morph="none" start_char="12226" end_char="12231">Aunque</TOKEN>
<TOKEN id="token-107-17" pos="word" morph="none" start_char="12233" end_char="12234">la</TOKEN>
<TOKEN id="token-107-18" pos="word" morph="none" start_char="12236" end_char="12244">evidencia</TOKEN>
<TOKEN id="token-107-19" pos="word" morph="none" start_char="12246" end_char="12252">muestra</TOKEN>
<TOKEN id="token-107-20" pos="word" morph="none" start_char="12254" end_char="12256">que</TOKEN>
<TOKEN id="token-107-21" pos="word" morph="none" start_char="12258" end_char="12259">el</TOKEN>
<TOKEN id="token-107-22" pos="unknown" morph="none" start_char="12261" end_char="12270">SARS-CoV-2</TOKEN>
<TOKEN id="token-107-23" pos="word" morph="none" start_char="12272" end_char="12273">no</TOKEN>
<TOKEN id="token-107-24" pos="word" morph="none" start_char="12275" end_char="12276">es</TOKEN>
<TOKEN id="token-107-25" pos="word" morph="none" start_char="12278" end_char="12279">un</TOKEN>
<TOKEN id="token-107-26" pos="word" morph="none" start_char="12281" end_char="12285">virus</TOKEN>
<TOKEN id="token-107-27" pos="word" morph="none" start_char="12287" end_char="12296">manipulado</TOKEN>
<TOKEN id="token-107-28" pos="word" morph="none" start_char="12298" end_char="12298">a</TOKEN>
<TOKEN id="token-107-29" pos="word" morph="none" start_char="12300" end_char="12308">propósito</TOKEN>
<TOKEN id="token-107-30" pos="punct" morph="none" start_char="12309" end_char="12309">,</TOKEN>
<TOKEN id="token-107-31" pos="word" morph="none" start_char="12311" end_char="12321">actualmente</TOKEN>
<TOKEN id="token-107-32" pos="word" morph="none" start_char="12323" end_char="12324">es</TOKEN>
<TOKEN id="token-107-33" pos="word" morph="none" start_char="12326" end_char="12334">imposible</TOKEN>
<TOKEN id="token-107-34" pos="word" morph="none" start_char="12336" end_char="12341">probar</TOKEN>
<TOKEN id="token-107-35" pos="word" morph="none" start_char="12343" end_char="12343">o</TOKEN>
<TOKEN id="token-107-36" pos="word" morph="none" start_char="12345" end_char="12351">refutar</TOKEN>
<TOKEN id="token-107-37" pos="word" morph="none" start_char="12353" end_char="12355">las</TOKEN>
<TOKEN id="token-107-38" pos="word" morph="none" start_char="12357" end_char="12361">otras</TOKEN>
<TOKEN id="token-107-39" pos="word" morph="none" start_char="12363" end_char="12369">teorías</TOKEN>
<TOKEN id="token-107-40" pos="word" morph="none" start_char="12371" end_char="12372">de</TOKEN>
<TOKEN id="token-107-41" pos="word" morph="none" start_char="12374" end_char="12375">su</TOKEN>
<TOKEN id="token-107-42" pos="word" morph="none" start_char="12377" end_char="12382">origen</TOKEN>
<TOKEN id="token-107-43" pos="word" morph="none" start_char="12384" end_char="12392">descritas</TOKEN>
<TOKEN id="token-107-44" pos="word" morph="none" start_char="12394" end_char="12397">aquí</TOKEN>
<TOKEN id="token-107-45" pos="punct" morph="none" start_char="12398" end_char="12398">.</TOKEN>
</SEG>
<SEG id="segment-108" start_char="12400" end_char="12660">
<ORIGINAL_TEXT>Sin embargo, dado que observamos todas las características notables de SARS-CoV-2, incluida la RBD optimizada y el sitio de escisión polibásica, en coronavirus relacionados en la naturaleza, no creemos que ningún tipo de escenario de laboratorio sea plausible."</ORIGINAL_TEXT>
<TOKEN id="token-108-0" pos="word" morph="none" start_char="12400" end_char="12402">Sin</TOKEN>
<TOKEN id="token-108-1" pos="word" morph="none" start_char="12404" end_char="12410">embargo</TOKEN>
<TOKEN id="token-108-2" pos="punct" morph="none" start_char="12411" end_char="12411">,</TOKEN>
<TOKEN id="token-108-3" pos="word" morph="none" start_char="12413" end_char="12416">dado</TOKEN>
<TOKEN id="token-108-4" pos="word" morph="none" start_char="12418" end_char="12420">que</TOKEN>
<TOKEN id="token-108-5" pos="word" morph="none" start_char="12422" end_char="12431">observamos</TOKEN>
<TOKEN id="token-108-6" pos="word" morph="none" start_char="12433" end_char="12437">todas</TOKEN>
<TOKEN id="token-108-7" pos="word" morph="none" start_char="12439" end_char="12441">las</TOKEN>
<TOKEN id="token-108-8" pos="word" morph="none" start_char="12443" end_char="12457">características</TOKEN>
<TOKEN id="token-108-9" pos="word" morph="none" start_char="12459" end_char="12466">notables</TOKEN>
<TOKEN id="token-108-10" pos="word" morph="none" start_char="12468" end_char="12469">de</TOKEN>
<TOKEN id="token-108-11" pos="unknown" morph="none" start_char="12471" end_char="12480">SARS-CoV-2</TOKEN>
<TOKEN id="token-108-12" pos="punct" morph="none" start_char="12481" end_char="12481">,</TOKEN>
<TOKEN id="token-108-13" pos="word" morph="none" start_char="12483" end_char="12490">incluida</TOKEN>
<TOKEN id="token-108-14" pos="word" morph="none" start_char="12492" end_char="12493">la</TOKEN>
<TOKEN id="token-108-15" pos="word" morph="none" start_char="12495" end_char="12497">RBD</TOKEN>
<TOKEN id="token-108-16" pos="word" morph="none" start_char="12499" end_char="12508">optimizada</TOKEN>
<TOKEN id="token-108-17" pos="word" morph="none" start_char="12510" end_char="12510">y</TOKEN>
<TOKEN id="token-108-18" pos="word" morph="none" start_char="12512" end_char="12513">el</TOKEN>
<TOKEN id="token-108-19" pos="word" morph="none" start_char="12515" end_char="12519">sitio</TOKEN>
<TOKEN id="token-108-20" pos="word" morph="none" start_char="12521" end_char="12522">de</TOKEN>
<TOKEN id="token-108-21" pos="word" morph="none" start_char="12524" end_char="12531">escisión</TOKEN>
<TOKEN id="token-108-22" pos="word" morph="none" start_char="12533" end_char="12542">polibásica</TOKEN>
<TOKEN id="token-108-23" pos="punct" morph="none" start_char="12543" end_char="12543">,</TOKEN>
<TOKEN id="token-108-24" pos="word" morph="none" start_char="12545" end_char="12546">en</TOKEN>
<TOKEN id="token-108-25" pos="word" morph="none" start_char="12548" end_char="12558">coronavirus</TOKEN>
<TOKEN id="token-108-26" pos="word" morph="none" start_char="12560" end_char="12571">relacionados</TOKEN>
<TOKEN id="token-108-27" pos="word" morph="none" start_char="12573" end_char="12574">en</TOKEN>
<TOKEN id="token-108-28" pos="word" morph="none" start_char="12576" end_char="12577">la</TOKEN>
<TOKEN id="token-108-29" pos="word" morph="none" start_char="12579" end_char="12588">naturaleza</TOKEN>
<TOKEN id="token-108-30" pos="punct" morph="none" start_char="12589" end_char="12589">,</TOKEN>
<TOKEN id="token-108-31" pos="word" morph="none" start_char="12591" end_char="12592">no</TOKEN>
<TOKEN id="token-108-32" pos="word" morph="none" start_char="12594" end_char="12600">creemos</TOKEN>
<TOKEN id="token-108-33" pos="word" morph="none" start_char="12602" end_char="12604">que</TOKEN>
<TOKEN id="token-108-34" pos="word" morph="none" start_char="12606" end_char="12611">ningún</TOKEN>
<TOKEN id="token-108-35" pos="word" morph="none" start_char="12613" end_char="12616">tipo</TOKEN>
<TOKEN id="token-108-36" pos="word" morph="none" start_char="12618" end_char="12619">de</TOKEN>
<TOKEN id="token-108-37" pos="word" morph="none" start_char="12621" end_char="12629">escenario</TOKEN>
<TOKEN id="token-108-38" pos="word" morph="none" start_char="12631" end_char="12632">de</TOKEN>
<TOKEN id="token-108-39" pos="word" morph="none" start_char="12634" end_char="12644">laboratorio</TOKEN>
<TOKEN id="token-108-40" pos="word" morph="none" start_char="12646" end_char="12648">sea</TOKEN>
<TOKEN id="token-108-41" pos="word" morph="none" start_char="12650" end_char="12658">plausible</TOKEN>
<TOKEN id="token-108-42" pos="punct" morph="none" start_char="12659" end_char="12660">."</TOKEN>
</SEG>
<SEG id="segment-109" start_char="12662" end_char="12843">
<ORIGINAL_TEXT>"Although the evidence shows that SARS-CoV-2 is not a purposefully manipulated virus, it is currently impossible to prove or disprove the other theories of its origin described here.</ORIGINAL_TEXT>
<TOKEN id="token-109-0" pos="punct" morph="none" start_char="12662" end_char="12662">"</TOKEN>
<TOKEN id="token-109-1" pos="word" morph="none" start_char="12663" end_char="12670">Although</TOKEN>
<TOKEN id="token-109-2" pos="word" morph="none" start_char="12672" end_char="12674">the</TOKEN>
<TOKEN id="token-109-3" pos="word" morph="none" start_char="12676" end_char="12683">evidence</TOKEN>
<TOKEN id="token-109-4" pos="word" morph="none" start_char="12685" end_char="12689">shows</TOKEN>
<TOKEN id="token-109-5" pos="word" morph="none" start_char="12691" end_char="12694">that</TOKEN>
<TOKEN id="token-109-6" pos="unknown" morph="none" start_char="12696" end_char="12705">SARS-CoV-2</TOKEN>
<TOKEN id="token-109-7" pos="word" morph="none" start_char="12707" end_char="12708">is</TOKEN>
<TOKEN id="token-109-8" pos="word" morph="none" start_char="12710" end_char="12712">not</TOKEN>
<TOKEN id="token-109-9" pos="word" morph="none" start_char="12714" end_char="12714">a</TOKEN>
<TOKEN id="token-109-10" pos="word" morph="none" start_char="12716" end_char="12727">purposefully</TOKEN>
<TOKEN id="token-109-11" pos="word" morph="none" start_char="12729" end_char="12739">manipulated</TOKEN>
<TOKEN id="token-109-12" pos="word" morph="none" start_char="12741" end_char="12745">virus</TOKEN>
<TOKEN id="token-109-13" pos="punct" morph="none" start_char="12746" end_char="12746">,</TOKEN>
<TOKEN id="token-109-14" pos="word" morph="none" start_char="12748" end_char="12749">it</TOKEN>
<TOKEN id="token-109-15" pos="word" morph="none" start_char="12751" end_char="12752">is</TOKEN>
<TOKEN id="token-109-16" pos="word" morph="none" start_char="12754" end_char="12762">currently</TOKEN>
<TOKEN id="token-109-17" pos="word" morph="none" start_char="12764" end_char="12773">impossible</TOKEN>
<TOKEN id="token-109-18" pos="word" morph="none" start_char="12775" end_char="12776">to</TOKEN>
<TOKEN id="token-109-19" pos="word" morph="none" start_char="12778" end_char="12782">prove</TOKEN>
<TOKEN id="token-109-20" pos="word" morph="none" start_char="12784" end_char="12785">or</TOKEN>
<TOKEN id="token-109-21" pos="word" morph="none" start_char="12787" end_char="12794">disprove</TOKEN>
<TOKEN id="token-109-22" pos="word" morph="none" start_char="12796" end_char="12798">the</TOKEN>
<TOKEN id="token-109-23" pos="word" morph="none" start_char="12800" end_char="12804">other</TOKEN>
<TOKEN id="token-109-24" pos="word" morph="none" start_char="12806" end_char="12813">theories</TOKEN>
<TOKEN id="token-109-25" pos="word" morph="none" start_char="12815" end_char="12816">of</TOKEN>
<TOKEN id="token-109-26" pos="word" morph="none" start_char="12818" end_char="12820">its</TOKEN>
<TOKEN id="token-109-27" pos="word" morph="none" start_char="12822" end_char="12827">origin</TOKEN>
<TOKEN id="token-109-28" pos="word" morph="none" start_char="12829" end_char="12837">described</TOKEN>
<TOKEN id="token-109-29" pos="word" morph="none" start_char="12839" end_char="12842">here</TOKEN>
<TOKEN id="token-109-30" pos="punct" morph="none" start_char="12843" end_char="12843">.</TOKEN>
</SEG>
<SEG id="segment-110" start_char="12845" end_char="13072">
<ORIGINAL_TEXT>However, since we observed all notable SARS-CoV-2 features, including the optimized RBD and polybasic cleavage site, in related coronaviruses in nature, we do not believe that any type of laboratory-based scenario is plausible."</ORIGINAL_TEXT>
<TOKEN id="token-110-0" pos="word" morph="none" start_char="12845" end_char="12851">However</TOKEN>
<TOKEN id="token-110-1" pos="punct" morph="none" start_char="12852" end_char="12852">,</TOKEN>
<TOKEN id="token-110-2" pos="word" morph="none" start_char="12854" end_char="12858">since</TOKEN>
<TOKEN id="token-110-3" pos="word" morph="none" start_char="12860" end_char="12861">we</TOKEN>
<TOKEN id="token-110-4" pos="word" morph="none" start_char="12863" end_char="12870">observed</TOKEN>
<TOKEN id="token-110-5" pos="word" morph="none" start_char="12872" end_char="12874">all</TOKEN>
<TOKEN id="token-110-6" pos="word" morph="none" start_char="12876" end_char="12882">notable</TOKEN>
<TOKEN id="token-110-7" pos="unknown" morph="none" start_char="12884" end_char="12893">SARS-CoV-2</TOKEN>
<TOKEN id="token-110-8" pos="word" morph="none" start_char="12895" end_char="12902">features</TOKEN>
<TOKEN id="token-110-9" pos="punct" morph="none" start_char="12903" end_char="12903">,</TOKEN>
<TOKEN id="token-110-10" pos="word" morph="none" start_char="12905" end_char="12913">including</TOKEN>
<TOKEN id="token-110-11" pos="word" morph="none" start_char="12915" end_char="12917">the</TOKEN>
<TOKEN id="token-110-12" pos="word" morph="none" start_char="12919" end_char="12927">optimized</TOKEN>
<TOKEN id="token-110-13" pos="word" morph="none" start_char="12929" end_char="12931">RBD</TOKEN>
<TOKEN id="token-110-14" pos="word" morph="none" start_char="12933" end_char="12935">and</TOKEN>
<TOKEN id="token-110-15" pos="word" morph="none" start_char="12937" end_char="12945">polybasic</TOKEN>
<TOKEN id="token-110-16" pos="word" morph="none" start_char="12947" end_char="12954">cleavage</TOKEN>
<TOKEN id="token-110-17" pos="word" morph="none" start_char="12956" end_char="12959">site</TOKEN>
<TOKEN id="token-110-18" pos="punct" morph="none" start_char="12960" end_char="12960">,</TOKEN>
<TOKEN id="token-110-19" pos="word" morph="none" start_char="12962" end_char="12963">in</TOKEN>
<TOKEN id="token-110-20" pos="word" morph="none" start_char="12965" end_char="12971">related</TOKEN>
<TOKEN id="token-110-21" pos="word" morph="none" start_char="12973" end_char="12985">coronaviruses</TOKEN>
<TOKEN id="token-110-22" pos="word" morph="none" start_char="12987" end_char="12988">in</TOKEN>
<TOKEN id="token-110-23" pos="word" morph="none" start_char="12990" end_char="12995">nature</TOKEN>
<TOKEN id="token-110-24" pos="punct" morph="none" start_char="12996" end_char="12996">,</TOKEN>
<TOKEN id="token-110-25" pos="word" morph="none" start_char="12998" end_char="12999">we</TOKEN>
<TOKEN id="token-110-26" pos="word" morph="none" start_char="13001" end_char="13002">do</TOKEN>
<TOKEN id="token-110-27" pos="word" morph="none" start_char="13004" end_char="13006">not</TOKEN>
<TOKEN id="token-110-28" pos="word" morph="none" start_char="13008" end_char="13014">believe</TOKEN>
<TOKEN id="token-110-29" pos="word" morph="none" start_char="13016" end_char="13019">that</TOKEN>
<TOKEN id="token-110-30" pos="word" morph="none" start_char="13021" end_char="13023">any</TOKEN>
<TOKEN id="token-110-31" pos="word" morph="none" start_char="13025" end_char="13028">type</TOKEN>
<TOKEN id="token-110-32" pos="word" morph="none" start_char="13030" end_char="13031">of</TOKEN>
<TOKEN id="token-110-33" pos="unknown" morph="none" start_char="13033" end_char="13048">laboratory-based</TOKEN>
<TOKEN id="token-110-34" pos="word" morph="none" start_char="13050" end_char="13057">scenario</TOKEN>
<TOKEN id="token-110-35" pos="word" morph="none" start_char="13059" end_char="13060">is</TOKEN>
<TOKEN id="token-110-36" pos="word" morph="none" start_char="13062" end_char="13070">plausible</TOKEN>
<TOKEN id="token-110-37" pos="punct" morph="none" start_char="13071" end_char="13072">."</TOKEN>
</SEG>
<SEG id="segment-111" start_char="13074" end_char="13198">
<ORIGINAL_TEXT>https://www.nature.com/articles/s41591-020-0820-9 Nature es una de las más prestigiosas revistas científicas a nivel mundial.</ORIGINAL_TEXT>
<TOKEN id="token-111-0" pos="url" morph="none" start_char="13074" end_char="13122">https://www.nature.com/articles/s41591-020-0820-9</TOKEN>
<TOKEN id="token-111-1" pos="word" morph="none" start_char="13124" end_char="13129">Nature</TOKEN>
<TOKEN id="token-111-2" pos="word" morph="none" start_char="13131" end_char="13132">es</TOKEN>
<TOKEN id="token-111-3" pos="word" morph="none" start_char="13134" end_char="13136">una</TOKEN>
<TOKEN id="token-111-4" pos="word" morph="none" start_char="13138" end_char="13139">de</TOKEN>
<TOKEN id="token-111-5" pos="word" morph="none" start_char="13141" end_char="13143">las</TOKEN>
<TOKEN id="token-111-6" pos="word" morph="none" start_char="13145" end_char="13147">más</TOKEN>
<TOKEN id="token-111-7" pos="word" morph="none" start_char="13149" end_char="13160">prestigiosas</TOKEN>
<TOKEN id="token-111-8" pos="word" morph="none" start_char="13162" end_char="13169">revistas</TOKEN>
<TOKEN id="token-111-9" pos="word" morph="none" start_char="13171" end_char="13181">científicas</TOKEN>
<TOKEN id="token-111-10" pos="word" morph="none" start_char="13183" end_char="13183">a</TOKEN>
<TOKEN id="token-111-11" pos="word" morph="none" start_char="13185" end_char="13189">nivel</TOKEN>
<TOKEN id="token-111-12" pos="word" morph="none" start_char="13191" end_char="13197">mundial</TOKEN>
<TOKEN id="token-111-13" pos="punct" morph="none" start_char="13198" end_char="13198">.</TOKEN>
</SEG>
<SEG id="segment-112" start_char="13200" end_char="13287">
<ORIGINAL_TEXT>Para la mayoría de los científicos publicar en Nature constituye una marca de prestigio.</ORIGINAL_TEXT>
<TOKEN id="token-112-0" pos="word" morph="none" start_char="13200" end_char="13203">Para</TOKEN>
<TOKEN id="token-112-1" pos="word" morph="none" start_char="13205" end_char="13206">la</TOKEN>
<TOKEN id="token-112-2" pos="word" morph="none" start_char="13208" end_char="13214">mayoría</TOKEN>
<TOKEN id="token-112-3" pos="word" morph="none" start_char="13216" end_char="13217">de</TOKEN>
<TOKEN id="token-112-4" pos="word" morph="none" start_char="13219" end_char="13221">los</TOKEN>
<TOKEN id="token-112-5" pos="word" morph="none" start_char="13223" end_char="13233">científicos</TOKEN>
<TOKEN id="token-112-6" pos="word" morph="none" start_char="13235" end_char="13242">publicar</TOKEN>
<TOKEN id="token-112-7" pos="word" morph="none" start_char="13244" end_char="13245">en</TOKEN>
<TOKEN id="token-112-8" pos="word" morph="none" start_char="13247" end_char="13252">Nature</TOKEN>
<TOKEN id="token-112-9" pos="word" morph="none" start_char="13254" end_char="13263">constituye</TOKEN>
<TOKEN id="token-112-10" pos="word" morph="none" start_char="13265" end_char="13267">una</TOKEN>
<TOKEN id="token-112-11" pos="word" morph="none" start_char="13269" end_char="13273">marca</TOKEN>
<TOKEN id="token-112-12" pos="word" morph="none" start_char="13275" end_char="13276">de</TOKEN>
<TOKEN id="token-112-13" pos="word" morph="none" start_char="13278" end_char="13286">prestigio</TOKEN>
<TOKEN id="token-112-14" pos="punct" morph="none" start_char="13287" end_char="13287">.</TOKEN>
</SEG>
<SEG id="segment-113" start_char="13289" end_char="13387">
<ORIGINAL_TEXT>La revista rechaza en torno al 95% de los artículos que le son enviados para la revisión por pares.</ORIGINAL_TEXT>
<TOKEN id="token-113-0" pos="word" morph="none" start_char="13289" end_char="13290">La</TOKEN>
<TOKEN id="token-113-1" pos="word" morph="none" start_char="13292" end_char="13298">revista</TOKEN>
<TOKEN id="token-113-2" pos="word" morph="none" start_char="13300" end_char="13306">rechaza</TOKEN>
<TOKEN id="token-113-3" pos="word" morph="none" start_char="13308" end_char="13309">en</TOKEN>
<TOKEN id="token-113-4" pos="word" morph="none" start_char="13311" end_char="13315">torno</TOKEN>
<TOKEN id="token-113-5" pos="word" morph="none" start_char="13317" end_char="13318">al</TOKEN>
<TOKEN id="token-113-6" pos="word" morph="none" start_char="13320" end_char="13321">95</TOKEN>
<TOKEN id="token-113-7" pos="punct" morph="none" start_char="13322" end_char="13322">%</TOKEN>
<TOKEN id="token-113-8" pos="word" morph="none" start_char="13324" end_char="13325">de</TOKEN>
<TOKEN id="token-113-9" pos="word" morph="none" start_char="13327" end_char="13329">los</TOKEN>
<TOKEN id="token-113-10" pos="word" morph="none" start_char="13331" end_char="13339">artículos</TOKEN>
<TOKEN id="token-113-11" pos="word" morph="none" start_char="13341" end_char="13343">que</TOKEN>
<TOKEN id="token-113-12" pos="word" morph="none" start_char="13345" end_char="13346">le</TOKEN>
<TOKEN id="token-113-13" pos="word" morph="none" start_char="13348" end_char="13350">son</TOKEN>
<TOKEN id="token-113-14" pos="word" morph="none" start_char="13352" end_char="13359">enviados</TOKEN>
<TOKEN id="token-113-15" pos="word" morph="none" start_char="13361" end_char="13364">para</TOKEN>
<TOKEN id="token-113-16" pos="word" morph="none" start_char="13366" end_char="13367">la</TOKEN>
<TOKEN id="token-113-17" pos="word" morph="none" start_char="13369" end_char="13376">revisión</TOKEN>
<TOKEN id="token-113-18" pos="word" morph="none" start_char="13378" end_char="13380">por</TOKEN>
<TOKEN id="token-113-19" pos="word" morph="none" start_char="13382" end_char="13386">pares</TOKEN>
<TOKEN id="token-113-20" pos="punct" morph="none" start_char="13387" end_char="13387">.</TOKEN>
</SEG>
<SEG id="segment-114" start_char="13389" end_char="13448">
<ORIGINAL_TEXT>Con todos los respetos, dudo que fuese a decir lo contrario.</ORIGINAL_TEXT>
<TOKEN id="token-114-0" pos="word" morph="none" start_char="13389" end_char="13391">Con</TOKEN>
<TOKEN id="token-114-1" pos="word" morph="none" start_char="13393" end_char="13397">todos</TOKEN>
<TOKEN id="token-114-2" pos="word" morph="none" start_char="13399" end_char="13401">los</TOKEN>
<TOKEN id="token-114-3" pos="word" morph="none" start_char="13403" end_char="13410">respetos</TOKEN>
<TOKEN id="token-114-4" pos="punct" morph="none" start_char="13411" end_char="13411">,</TOKEN>
<TOKEN id="token-114-5" pos="word" morph="none" start_char="13413" end_char="13416">dudo</TOKEN>
<TOKEN id="token-114-6" pos="word" morph="none" start_char="13418" end_char="13420">que</TOKEN>
<TOKEN id="token-114-7" pos="word" morph="none" start_char="13422" end_char="13426">fuese</TOKEN>
<TOKEN id="token-114-8" pos="word" morph="none" start_char="13428" end_char="13428">a</TOKEN>
<TOKEN id="token-114-9" pos="word" morph="none" start_char="13430" end_char="13434">decir</TOKEN>
<TOKEN id="token-114-10" pos="word" morph="none" start_char="13436" end_char="13437">lo</TOKEN>
<TOKEN id="token-114-11" pos="word" morph="none" start_char="13439" end_char="13447">contrario</TOKEN>
<TOKEN id="token-114-12" pos="punct" morph="none" start_char="13448" end_char="13448">.</TOKEN>
</SEG>
<SEG id="segment-115" start_char="13450" end_char="13629">
<ORIGINAL_TEXT>Si dijese que tiene pinta de ser de laboratorio, comenzaría una escalada de acusaciones usa-China donde podría incluso entrar Rusia, y terminar derivando en algo peor que un viras.</ORIGINAL_TEXT>
<TOKEN id="token-115-0" pos="word" morph="none" start_char="13450" end_char="13451">Si</TOKEN>
<TOKEN id="token-115-1" pos="word" morph="none" start_char="13453" end_char="13458">dijese</TOKEN>
<TOKEN id="token-115-2" pos="word" morph="none" start_char="13460" end_char="13462">que</TOKEN>
<TOKEN id="token-115-3" pos="word" morph="none" start_char="13464" end_char="13468">tiene</TOKEN>
<TOKEN id="token-115-4" pos="word" morph="none" start_char="13470" end_char="13474">pinta</TOKEN>
<TOKEN id="token-115-5" pos="word" morph="none" start_char="13476" end_char="13477">de</TOKEN>
<TOKEN id="token-115-6" pos="word" morph="none" start_char="13479" end_char="13481">ser</TOKEN>
<TOKEN id="token-115-7" pos="word" morph="none" start_char="13483" end_char="13484">de</TOKEN>
<TOKEN id="token-115-8" pos="word" morph="none" start_char="13486" end_char="13496">laboratorio</TOKEN>
<TOKEN id="token-115-9" pos="punct" morph="none" start_char="13497" end_char="13497">,</TOKEN>
<TOKEN id="token-115-10" pos="word" morph="none" start_char="13499" end_char="13508">comenzaría</TOKEN>
<TOKEN id="token-115-11" pos="word" morph="none" start_char="13510" end_char="13512">una</TOKEN>
<TOKEN id="token-115-12" pos="word" morph="none" start_char="13514" end_char="13521">escalada</TOKEN>
<TOKEN id="token-115-13" pos="word" morph="none" start_char="13523" end_char="13524">de</TOKEN>
<TOKEN id="token-115-14" pos="word" morph="none" start_char="13526" end_char="13536">acusaciones</TOKEN>
<TOKEN id="token-115-15" pos="unknown" morph="none" start_char="13538" end_char="13546">usa-China</TOKEN>
<TOKEN id="token-115-16" pos="word" morph="none" start_char="13548" end_char="13552">donde</TOKEN>
<TOKEN id="token-115-17" pos="word" morph="none" start_char="13554" end_char="13559">podría</TOKEN>
<TOKEN id="token-115-18" pos="word" morph="none" start_char="13561" end_char="13567">incluso</TOKEN>
<TOKEN id="token-115-19" pos="word" morph="none" start_char="13569" end_char="13574">entrar</TOKEN>
<TOKEN id="token-115-20" pos="word" morph="none" start_char="13576" end_char="13580">Rusia</TOKEN>
<TOKEN id="token-115-21" pos="punct" morph="none" start_char="13581" end_char="13581">,</TOKEN>
<TOKEN id="token-115-22" pos="word" morph="none" start_char="13583" end_char="13583">y</TOKEN>
<TOKEN id="token-115-23" pos="word" morph="none" start_char="13585" end_char="13592">terminar</TOKEN>
<TOKEN id="token-115-24" pos="word" morph="none" start_char="13594" end_char="13602">derivando</TOKEN>
<TOKEN id="token-115-25" pos="word" morph="none" start_char="13604" end_char="13605">en</TOKEN>
<TOKEN id="token-115-26" pos="word" morph="none" start_char="13607" end_char="13610">algo</TOKEN>
<TOKEN id="token-115-27" pos="word" morph="none" start_char="13612" end_char="13615">peor</TOKEN>
<TOKEN id="token-115-28" pos="word" morph="none" start_char="13617" end_char="13619">que</TOKEN>
<TOKEN id="token-115-29" pos="word" morph="none" start_char="13621" end_char="13622">un</TOKEN>
<TOKEN id="token-115-30" pos="word" morph="none" start_char="13624" end_char="13628">viras</TOKEN>
<TOKEN id="token-115-31" pos="punct" morph="none" start_char="13629" end_char="13629">.</TOKEN>
</SEG>
<SEG id="segment-116" start_char="13631" end_char="13739">
<ORIGINAL_TEXT>Es mejor mantener los ánimos tranquilos, a ver si además del viras vamos a empezar a lanzar cohetes nucelares</ORIGINAL_TEXT>
<TOKEN id="token-116-0" pos="word" morph="none" start_char="13631" end_char="13632">Es</TOKEN>
<TOKEN id="token-116-1" pos="word" morph="none" start_char="13634" end_char="13638">mejor</TOKEN>
<TOKEN id="token-116-2" pos="word" morph="none" start_char="13640" end_char="13647">mantener</TOKEN>
<TOKEN id="token-116-3" pos="word" morph="none" start_char="13649" end_char="13651">los</TOKEN>
<TOKEN id="token-116-4" pos="word" morph="none" start_char="13653" end_char="13658">ánimos</TOKEN>
<TOKEN id="token-116-5" pos="word" morph="none" start_char="13660" end_char="13669">tranquilos</TOKEN>
<TOKEN id="token-116-6" pos="punct" morph="none" start_char="13670" end_char="13670">,</TOKEN>
<TOKEN id="token-116-7" pos="word" morph="none" start_char="13672" end_char="13672">a</TOKEN>
<TOKEN id="token-116-8" pos="word" morph="none" start_char="13674" end_char="13676">ver</TOKEN>
<TOKEN id="token-116-9" pos="word" morph="none" start_char="13678" end_char="13679">si</TOKEN>
<TOKEN id="token-116-10" pos="word" morph="none" start_char="13681" end_char="13686">además</TOKEN>
<TOKEN id="token-116-11" pos="word" morph="none" start_char="13688" end_char="13690">del</TOKEN>
<TOKEN id="token-116-12" pos="word" morph="none" start_char="13692" end_char="13696">viras</TOKEN>
<TOKEN id="token-116-13" pos="word" morph="none" start_char="13698" end_char="13702">vamos</TOKEN>
<TOKEN id="token-116-14" pos="word" morph="none" start_char="13704" end_char="13704">a</TOKEN>
<TOKEN id="token-116-15" pos="word" morph="none" start_char="13706" end_char="13712">empezar</TOKEN>
<TOKEN id="token-116-16" pos="word" morph="none" start_char="13714" end_char="13714">a</TOKEN>
<TOKEN id="token-116-17" pos="word" morph="none" start_char="13716" end_char="13721">lanzar</TOKEN>
<TOKEN id="token-116-18" pos="word" morph="none" start_char="13723" end_char="13729">cohetes</TOKEN>
<TOKEN id="token-116-19" pos="word" morph="none" start_char="13731" end_char="13739">nucelares</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
