<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="eng">
<DOC id="L0C049DQV" lang="eng" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="6237" raw_text_md5="40f744733f28ef2cbab8dced34277b09">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="49">
<ORIGINAL_TEXT>COVID- 19 convalescent plasma treatment on hold ?</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="5">COVID</TOKEN>
<TOKEN id="token-0-1" pos="punct" morph="none" start_char="6" end_char="6">-</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="8" end_char="9">19</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="11" end_char="22">convalescent</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="24" end_char="29">plasma</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="31" end_char="39">treatment</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="41" end_char="42">on</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="44" end_char="47">hold</TOKEN>
<TOKEN id="token-0-8" pos="punct" morph="none" start_char="49" end_char="49">?</TOKEN>
</SEG>
<SEG id="segment-1" start_char="53" end_char="238">
<ORIGINAL_TEXT>I am not sure I understand why the FDA and NIAID are deciding its best to apply the breaks in order to study convalescent plasma instead of rolling it out to hospitals across the nation.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="53" end_char="53">I</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="55" end_char="56">am</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="58" end_char="60">not</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="62" end_char="65">sure</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="67" end_char="67">I</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="69" end_char="78">understand</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="80" end_char="82">why</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="84" end_char="86">the</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="88" end_char="90">FDA</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="92" end_char="94">and</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="96" end_char="100">NIAID</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="102" end_char="104">are</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="106" end_char="113">deciding</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="115" end_char="117">its</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="119" end_char="122">best</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="124" end_char="125">to</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="127" end_char="131">apply</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="133" end_char="135">the</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="137" end_char="142">breaks</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="144" end_char="145">in</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="147" end_char="151">order</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="153" end_char="154">to</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="156" end_char="160">study</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="162" end_char="173">convalescent</TOKEN>
<TOKEN id="token-1-24" pos="word" morph="none" start_char="175" end_char="180">plasma</TOKEN>
<TOKEN id="token-1-25" pos="word" morph="none" start_char="182" end_char="188">instead</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="190" end_char="191">of</TOKEN>
<TOKEN id="token-1-27" pos="word" morph="none" start_char="193" end_char="199">rolling</TOKEN>
<TOKEN id="token-1-28" pos="word" morph="none" start_char="201" end_char="202">it</TOKEN>
<TOKEN id="token-1-29" pos="word" morph="none" start_char="204" end_char="206">out</TOKEN>
<TOKEN id="token-1-30" pos="word" morph="none" start_char="208" end_char="209">to</TOKEN>
<TOKEN id="token-1-31" pos="word" morph="none" start_char="211" end_char="219">hospitals</TOKEN>
<TOKEN id="token-1-32" pos="word" morph="none" start_char="221" end_char="226">across</TOKEN>
<TOKEN id="token-1-33" pos="word" morph="none" start_char="228" end_char="230">the</TOKEN>
<TOKEN id="token-1-34" pos="word" morph="none" start_char="232" end_char="237">nation</TOKEN>
<TOKEN id="token-1-35" pos="punct" morph="none" start_char="238" end_char="238">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="240" end_char="318">
<ORIGINAL_TEXT>It's been used for over a century and doctors and patients seem to swear by it.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="240" end_char="243">It's</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="245" end_char="248">been</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="250" end_char="253">used</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="255" end_char="257">for</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="259" end_char="262">over</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="264" end_char="264">a</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="266" end_char="272">century</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="274" end_char="276">and</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="278" end_char="284">doctors</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="286" end_char="288">and</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="290" end_char="297">patients</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="299" end_char="302">seem</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="304" end_char="305">to</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="307" end_char="311">swear</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="313" end_char="314">by</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="316" end_char="317">it</TOKEN>
<TOKEN id="token-2-16" pos="punct" morph="none" start_char="318" end_char="318">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="320" end_char="449">
<ORIGINAL_TEXT>At worst it seems like it would do no-harm so why deny likely beneficial treatment so all the experts can study just to make sure.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="320" end_char="321">At</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="323" end_char="327">worst</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="329" end_char="330">it</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="332" end_char="336">seems</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="338" end_char="341">like</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="343" end_char="344">it</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="346" end_char="350">would</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="352" end_char="353">do</TOKEN>
<TOKEN id="token-3-8" pos="unknown" morph="none" start_char="355" end_char="361">no-harm</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="363" end_char="364">so</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="366" end_char="368">why</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="370" end_char="373">deny</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="375" end_char="380">likely</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="382" end_char="391">beneficial</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="393" end_char="401">treatment</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="403" end_char="404">so</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="406" end_char="408">all</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="410" end_char="412">the</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="414" end_char="420">experts</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="422" end_char="424">can</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="426" end_char="430">study</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="432" end_char="435">just</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="437" end_char="438">to</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="440" end_char="443">make</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="445" end_char="448">sure</TOKEN>
<TOKEN id="token-3-25" pos="punct" morph="none" start_char="449" end_char="449">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="451" end_char="543">
<ORIGINAL_TEXT>The way this is being handled lends credence to HCQ being torpedoed due to political reasons.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="451" end_char="453">The</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="455" end_char="457">way</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="459" end_char="462">this</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="464" end_char="465">is</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="467" end_char="471">being</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="473" end_char="479">handled</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="481" end_char="485">lends</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="487" end_char="494">credence</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="496" end_char="497">to</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="499" end_char="501">HCQ</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="503" end_char="507">being</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="509" end_char="517">torpedoed</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="519" end_char="521">due</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="523" end_char="524">to</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="526" end_char="534">political</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="536" end_char="542">reasons</TOKEN>
<TOKEN id="token-4-16" pos="punct" morph="none" start_char="543" end_char="543">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="546" end_char="651">
<ORIGINAL_TEXT>https://www.whio.com/news/trending/fda-puts-covid-19-blood-plasma-therapy-hold/A5YW6GGBZ5EDNDAMPY27YRQKNQ/</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="url" morph="none" start_char="546" end_char="651">https://www.whio.com/news/trending/fda-puts-covid-19-blood-plasma-therapy-hold/A5YW6GGBZ5EDNDAMPY27YRQKNQ/</TOKEN>
</SEG>
<SEG id="segment-6" start_char="655" end_char="868">
<ORIGINAL_TEXT>Fauci won't be sold on convalescent plasma based on what he feels are weak indications, but he was all about remdesivir based on a study where the endpoint was changed mid-study to produce a faint positive result?!</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="655" end_char="659">Fauci</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="661" end_char="665">won't</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="667" end_char="668">be</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="670" end_char="673">sold</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="675" end_char="676">on</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="678" end_char="689">convalescent</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="691" end_char="696">plasma</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="698" end_char="702">based</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="704" end_char="705">on</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="707" end_char="710">what</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="712" end_char="713">he</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="715" end_char="719">feels</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="721" end_char="723">are</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="725" end_char="728">weak</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="730" end_char="740">indications</TOKEN>
<TOKEN id="token-6-15" pos="punct" morph="none" start_char="741" end_char="741">,</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="743" end_char="745">but</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="747" end_char="748">he</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="750" end_char="752">was</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="754" end_char="756">all</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="758" end_char="762">about</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="764" end_char="773">remdesivir</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="775" end_char="779">based</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="781" end_char="782">on</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="784" end_char="784">a</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="786" end_char="790">study</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="792" end_char="796">where</TOKEN>
<TOKEN id="token-6-27" pos="word" morph="none" start_char="798" end_char="800">the</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="802" end_char="809">endpoint</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="811" end_char="813">was</TOKEN>
<TOKEN id="token-6-30" pos="word" morph="none" start_char="815" end_char="821">changed</TOKEN>
<TOKEN id="token-6-31" pos="unknown" morph="none" start_char="823" end_char="831">mid-study</TOKEN>
<TOKEN id="token-6-32" pos="word" morph="none" start_char="833" end_char="834">to</TOKEN>
<TOKEN id="token-6-33" pos="word" morph="none" start_char="836" end_char="842">produce</TOKEN>
<TOKEN id="token-6-34" pos="word" morph="none" start_char="844" end_char="844">a</TOKEN>
<TOKEN id="token-6-35" pos="word" morph="none" start_char="846" end_char="850">faint</TOKEN>
<TOKEN id="token-6-36" pos="word" morph="none" start_char="852" end_char="859">positive</TOKEN>
<TOKEN id="token-6-37" pos="word" morph="none" start_char="861" end_char="866">result</TOKEN>
<TOKEN id="token-6-38" pos="punct" morph="none" start_char="867" end_char="868">?!</TOKEN>
</SEG>
<SEG id="segment-7" start_char="872" end_char="1041">
<ORIGINAL_TEXT>Per the Houston Chronicle, the doctors at Houston Methodist aren't happy because they have had success using the plasma to treat patients at it's Medical Center location.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="872" end_char="874">Per</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="876" end_char="878">the</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="880" end_char="886">Houston</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="888" end_char="896">Chronicle</TOKEN>
<TOKEN id="token-7-4" pos="punct" morph="none" start_char="897" end_char="897">,</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="899" end_char="901">the</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="903" end_char="909">doctors</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="911" end_char="912">at</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="914" end_char="920">Houston</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="922" end_char="930">Methodist</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="932" end_char="937">aren't</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="939" end_char="943">happy</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="945" end_char="951">because</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="953" end_char="956">they</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="958" end_char="961">have</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="963" end_char="965">had</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="967" end_char="973">success</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="975" end_char="979">using</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="981" end_char="983">the</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="985" end_char="990">plasma</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="992" end_char="993">to</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="995" end_char="999">treat</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="1001" end_char="1008">patients</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="1010" end_char="1011">at</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="1013" end_char="1016">it's</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="1018" end_char="1024">Medical</TOKEN>
<TOKEN id="token-7-26" pos="word" morph="none" start_char="1026" end_char="1031">Center</TOKEN>
<TOKEN id="token-7-27" pos="word" morph="none" start_char="1033" end_char="1040">location</TOKEN>
<TOKEN id="token-7-28" pos="punct" morph="none" start_char="1041" end_char="1041">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1043" end_char="1250">
<ORIGINAL_TEXT>Apparently the experimental use was only allowed at teaching hospitals and Houston Methodist was having success and wanted to see it rolled out to the suburban locations outside of the Medical Center as well.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1043" end_char="1052">Apparently</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1054" end_char="1056">the</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1058" end_char="1069">experimental</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1071" end_char="1073">use</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1075" end_char="1077">was</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1079" end_char="1082">only</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1084" end_char="1090">allowed</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1092" end_char="1093">at</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1095" end_char="1102">teaching</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1104" end_char="1112">hospitals</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1114" end_char="1116">and</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1118" end_char="1124">Houston</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1126" end_char="1134">Methodist</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1136" end_char="1138">was</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1140" end_char="1145">having</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1147" end_char="1153">success</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1155" end_char="1157">and</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1159" end_char="1164">wanted</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1166" end_char="1167">to</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1169" end_char="1171">see</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="1173" end_char="1174">it</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="1176" end_char="1181">rolled</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="1183" end_char="1185">out</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="1187" end_char="1188">to</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="1190" end_char="1192">the</TOKEN>
<TOKEN id="token-8-25" pos="word" morph="none" start_char="1194" end_char="1201">suburban</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="1203" end_char="1211">locations</TOKEN>
<TOKEN id="token-8-27" pos="word" morph="none" start_char="1213" end_char="1219">outside</TOKEN>
<TOKEN id="token-8-28" pos="word" morph="none" start_char="1221" end_char="1222">of</TOKEN>
<TOKEN id="token-8-29" pos="word" morph="none" start_char="1224" end_char="1226">the</TOKEN>
<TOKEN id="token-8-30" pos="word" morph="none" start_char="1228" end_char="1234">Medical</TOKEN>
<TOKEN id="token-8-31" pos="word" morph="none" start_char="1236" end_char="1241">Center</TOKEN>
<TOKEN id="token-8-32" pos="word" morph="none" start_char="1243" end_char="1244">as</TOKEN>
<TOKEN id="token-8-33" pos="word" morph="none" start_char="1246" end_char="1249">well</TOKEN>
<TOKEN id="token-8-34" pos="punct" morph="none" start_char="1250" end_char="1250">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1253" end_char="1409">
<ORIGINAL_TEXT>Makes me wonder if "other" hospitals were perhaps giving this plasma to patients who were too far along in this disease and had too many other complications.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1253" end_char="1257">Makes</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1259" end_char="1260">me</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1262" end_char="1267">wonder</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1269" end_char="1270">if</TOKEN>
<TOKEN id="token-9-4" pos="punct" morph="none" start_char="1272" end_char="1272">"</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1273" end_char="1277">other</TOKEN>
<TOKEN id="token-9-6" pos="punct" morph="none" start_char="1278" end_char="1278">"</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1280" end_char="1288">hospitals</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1290" end_char="1293">were</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1295" end_char="1301">perhaps</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1303" end_char="1308">giving</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1310" end_char="1313">this</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1315" end_char="1320">plasma</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1322" end_char="1323">to</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1325" end_char="1332">patients</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1334" end_char="1336">who</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1338" end_char="1341">were</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1343" end_char="1345">too</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1347" end_char="1349">far</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1351" end_char="1355">along</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1357" end_char="1358">in</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1360" end_char="1363">this</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1365" end_char="1371">disease</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1373" end_char="1375">and</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1377" end_char="1379">had</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1381" end_char="1383">too</TOKEN>
<TOKEN id="token-9-26" pos="word" morph="none" start_char="1385" end_char="1388">many</TOKEN>
<TOKEN id="token-9-27" pos="word" morph="none" start_char="1390" end_char="1394">other</TOKEN>
<TOKEN id="token-9-28" pos="word" morph="none" start_char="1396" end_char="1408">complications</TOKEN>
<TOKEN id="token-9-29" pos="punct" morph="none" start_char="1409" end_char="1409">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1411" end_char="1547">
<ORIGINAL_TEXT>It seems obvious that plasma would most benefit patients early in the course of COVID who didn't have multiple significant complications.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1411" end_char="1412">It</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1414" end_char="1418">seems</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1420" end_char="1426">obvious</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1428" end_char="1431">that</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1433" end_char="1438">plasma</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1440" end_char="1444">would</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1446" end_char="1449">most</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1451" end_char="1457">benefit</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1459" end_char="1466">patients</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1468" end_char="1472">early</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1474" end_char="1475">in</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1477" end_char="1479">the</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1481" end_char="1486">course</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1488" end_char="1489">of</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1491" end_char="1495">COVID</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1497" end_char="1499">who</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1501" end_char="1506">didn't</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1508" end_char="1511">have</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1513" end_char="1520">multiple</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1522" end_char="1532">significant</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1534" end_char="1546">complications</TOKEN>
<TOKEN id="token-10-21" pos="punct" morph="none" start_char="1547" end_char="1547">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1550" end_char="1665">
<ORIGINAL_TEXT>https://www.houstonchronicle.com/news/health/article/uthealth-baylor-college-houston-covid-plasma-texas-15496877.php</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="url" morph="none" start_char="1550" end_char="1665">https://www.houstonchronicle.com/news/health/article/uthealth-baylor-college-houston-covid-plasma-texas-15496877.php</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1669" end_char="1715">
<ORIGINAL_TEXT>Where is the data showing this treatment works?</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1669" end_char="1673">Where</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1675" end_char="1676">is</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1678" end_char="1680">the</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1682" end_char="1685">data</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1687" end_char="1693">showing</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1695" end_char="1698">this</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1700" end_char="1708">treatment</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1710" end_char="1714">works</TOKEN>
<TOKEN id="token-12-8" pos="punct" morph="none" start_char="1715" end_char="1715">?</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1718" end_char="1859">
<ORIGINAL_TEXT>I kind of assumed it would, but with what we know now about the weak B cell response in many patients I'm not so sure how helpful it would be.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1718" end_char="1718">I</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1720" end_char="1723">kind</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1725" end_char="1726">of</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1728" end_char="1734">assumed</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1736" end_char="1737">it</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1739" end_char="1743">would</TOKEN>
<TOKEN id="token-13-6" pos="punct" morph="none" start_char="1744" end_char="1744">,</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1746" end_char="1748">but</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1750" end_char="1753">with</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1755" end_char="1758">what</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1760" end_char="1761">we</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1763" end_char="1766">know</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1768" end_char="1770">now</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1772" end_char="1776">about</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1778" end_char="1780">the</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1782" end_char="1785">weak</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1787" end_char="1787">B</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1789" end_char="1792">cell</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1794" end_char="1801">response</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1803" end_char="1804">in</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1806" end_char="1809">many</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="1811" end_char="1818">patients</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="1820" end_char="1822">I'm</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="1824" end_char="1826">not</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="1828" end_char="1829">so</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="1831" end_char="1834">sure</TOKEN>
<TOKEN id="token-13-26" pos="word" morph="none" start_char="1836" end_char="1838">how</TOKEN>
<TOKEN id="token-13-27" pos="word" morph="none" start_char="1840" end_char="1846">helpful</TOKEN>
<TOKEN id="token-13-28" pos="word" morph="none" start_char="1848" end_char="1849">it</TOKEN>
<TOKEN id="token-13-29" pos="word" morph="none" start_char="1851" end_char="1855">would</TOKEN>
<TOKEN id="token-13-30" pos="word" morph="none" start_char="1857" end_char="1858">be</TOKEN>
<TOKEN id="token-13-31" pos="punct" morph="none" start_char="1859" end_char="1859">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1862" end_char="1903">
<ORIGINAL_TEXT>Also, it's not a scalable solution anyway.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1862" end_char="1865">Also</TOKEN>
<TOKEN id="token-14-1" pos="punct" morph="none" start_char="1866" end_char="1866">,</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1868" end_char="1871">it's</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1873" end_char="1875">not</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1877" end_char="1877">a</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1879" end_char="1886">scalable</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1888" end_char="1895">solution</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1897" end_char="1902">anyway</TOKEN>
<TOKEN id="token-14-8" pos="punct" morph="none" start_char="1903" end_char="1903">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1905" end_char="1995">
<ORIGINAL_TEXT>IF passive immunity is the answer, then one of the antibodies cocktails will have to do it.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1905" end_char="1906">IF</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1908" end_char="1914">passive</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1916" end_char="1923">immunity</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1925" end_char="1926">is</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1928" end_char="1930">the</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1932" end_char="1937">answer</TOKEN>
<TOKEN id="token-15-6" pos="punct" morph="none" start_char="1938" end_char="1938">,</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1940" end_char="1943">then</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1945" end_char="1947">one</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1949" end_char="1950">of</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1952" end_char="1954">the</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1956" end_char="1965">antibodies</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1967" end_char="1975">cocktails</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1977" end_char="1980">will</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1982" end_char="1985">have</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="1987" end_char="1988">to</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="1990" end_char="1991">do</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="1993" end_char="1994">it</TOKEN>
<TOKEN id="token-15-18" pos="punct" morph="none" start_char="1995" end_char="1995">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1999" end_char="2051">
<ORIGINAL_TEXT>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7362821/</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="url" morph="none" start_char="1999" end_char="2051">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7362821/</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2054" end_char="2077">
<ORIGINAL_TEXT>best study I could find.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2054" end_char="2057">best</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2059" end_char="2063">study</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2065" end_char="2065">I</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2067" end_char="2071">could</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2073" end_char="2076">find</TOKEN>
<TOKEN id="token-17-5" pos="punct" morph="none" start_char="2077" end_char="2077">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2079" end_char="2178">
<ORIGINAL_TEXT>They acknowledge that the control group wasn't as sick, so that may be a point in the study's favor.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2079" end_char="2082">They</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2084" end_char="2094">acknowledge</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2096" end_char="2099">that</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2101" end_char="2103">the</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2105" end_char="2111">control</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2113" end_char="2117">group</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2119" end_char="2124">wasn't</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2126" end_char="2127">as</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2129" end_char="2132">sick</TOKEN>
<TOKEN id="token-18-9" pos="punct" morph="none" start_char="2133" end_char="2133">,</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="2135" end_char="2136">so</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="2138" end_char="2141">that</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2143" end_char="2145">may</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="2147" end_char="2148">be</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="2150" end_char="2150">a</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="2152" end_char="2156">point</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="2158" end_char="2159">in</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="2161" end_char="2163">the</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="2165" end_char="2171">study's</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="2173" end_char="2177">favor</TOKEN>
<TOKEN id="token-18-20" pos="punct" morph="none" start_char="2178" end_char="2178">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2180" end_char="2321">
<ORIGINAL_TEXT>Apparently another European study was stopped because all their admitted COVID patients already had high antibody titers at time of admission.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2180" end_char="2189">Apparently</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2191" end_char="2197">another</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2199" end_char="2206">European</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2208" end_char="2212">study</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2214" end_char="2216">was</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2218" end_char="2224">stopped</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2226" end_char="2232">because</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2234" end_char="2236">all</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2238" end_char="2242">their</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="2244" end_char="2251">admitted</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="2253" end_char="2257">COVID</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="2259" end_char="2266">patients</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="2268" end_char="2274">already</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="2276" end_char="2278">had</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="2280" end_char="2283">high</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="2285" end_char="2292">antibody</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="2294" end_char="2299">titers</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="2301" end_char="2302">at</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="2304" end_char="2307">time</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="2309" end_char="2310">of</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="2312" end_char="2320">admission</TOKEN>
<TOKEN id="token-19-21" pos="punct" morph="none" start_char="2321" end_char="2321">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2323" end_char="2363">
<ORIGINAL_TEXT>So there wasn't any point in giving more.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2323" end_char="2324">So</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2326" end_char="2330">there</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2332" end_char="2337">wasn't</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2339" end_char="2341">any</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2343" end_char="2347">point</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2349" end_char="2350">in</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2352" end_char="2357">giving</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2359" end_char="2362">more</TOKEN>
<TOKEN id="token-20-8" pos="punct" morph="none" start_char="2363" end_char="2363">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2366" end_char="2427">
<ORIGINAL_TEXT>I was a bit shocked that the FDA came down so hard on its use.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2366" end_char="2366">I</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2368" end_char="2370">was</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2372" end_char="2372">a</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2374" end_char="2376">bit</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2378" end_char="2384">shocked</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="2386" end_char="2389">that</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2391" end_char="2393">the</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="2395" end_char="2397">FDA</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="2399" end_char="2402">came</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="2404" end_char="2407">down</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="2409" end_char="2410">so</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="2412" end_char="2415">hard</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="2417" end_char="2418">on</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="2420" end_char="2422">its</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="2424" end_char="2426">use</TOKEN>
<TOKEN id="token-21-15" pos="punct" morph="none" start_char="2427" end_char="2427">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2430" end_char="2541">
<ORIGINAL_TEXT>No material on this site is intended to be a substitute for professional medical advice, diagnosis or treatment.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2430" end_char="2431">No</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2433" end_char="2440">material</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2442" end_char="2443">on</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2445" end_char="2448">this</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2450" end_char="2453">site</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2455" end_char="2456">is</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2458" end_char="2465">intended</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2467" end_char="2468">to</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="2470" end_char="2471">be</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="2473" end_char="2473">a</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="2475" end_char="2484">substitute</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="2486" end_char="2488">for</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="2490" end_char="2501">professional</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="2503" end_char="2509">medical</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="2511" end_char="2516">advice</TOKEN>
<TOKEN id="token-22-15" pos="punct" morph="none" start_char="2517" end_char="2517">,</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="2519" end_char="2527">diagnosis</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="2529" end_char="2530">or</TOKEN>
<TOKEN id="token-22-18" pos="word" morph="none" start_char="2532" end_char="2540">treatment</TOKEN>
<TOKEN id="token-22-19" pos="punct" morph="none" start_char="2541" end_char="2541">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2543" end_char="2570">
<ORIGINAL_TEXT>See full Medical Disclaimer.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2543" end_char="2545">See</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2547" end_char="2550">full</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2552" end_char="2558">Medical</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2560" end_char="2569">Disclaimer</TOKEN>
<TOKEN id="token-23-4" pos="punct" morph="none" start_char="2570" end_char="2570">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2574" end_char="2635">
<ORIGINAL_TEXT>The FDA is in a tough spot since this has become so political.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="2574" end_char="2576">The</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="2578" end_char="2580">FDA</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="2582" end_char="2583">is</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="2585" end_char="2586">in</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="2588" end_char="2588">a</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="2590" end_char="2594">tough</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="2596" end_char="2599">spot</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="2601" end_char="2605">since</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="2607" end_char="2610">this</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="2612" end_char="2614">has</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="2616" end_char="2621">become</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="2623" end_char="2624">so</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="2626" end_char="2634">political</TOKEN>
<TOKEN id="token-24-13" pos="punct" morph="none" start_char="2635" end_char="2635">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2637" end_char="2782">
<ORIGINAL_TEXT>They rushed a lot of temporary approvals out in the spring and it really bit them in the ass with tests that were crap and drugs that didn't work.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="2637" end_char="2640">They</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="2642" end_char="2647">rushed</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="2649" end_char="2649">a</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="2651" end_char="2653">lot</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="2655" end_char="2656">of</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="2658" end_char="2666">temporary</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="2668" end_char="2676">approvals</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="2678" end_char="2680">out</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="2682" end_char="2683">in</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="2685" end_char="2687">the</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="2689" end_char="2694">spring</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="2696" end_char="2698">and</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="2700" end_char="2701">it</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="2703" end_char="2708">really</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="2710" end_char="2712">bit</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="2714" end_char="2717">them</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="2719" end_char="2720">in</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="2722" end_char="2724">the</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="2726" end_char="2728">ass</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="2730" end_char="2733">with</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="2735" end_char="2739">tests</TOKEN>
<TOKEN id="token-25-21" pos="word" morph="none" start_char="2741" end_char="2744">that</TOKEN>
<TOKEN id="token-25-22" pos="word" morph="none" start_char="2746" end_char="2749">were</TOKEN>
<TOKEN id="token-25-23" pos="word" morph="none" start_char="2751" end_char="2754">crap</TOKEN>
<TOKEN id="token-25-24" pos="word" morph="none" start_char="2756" end_char="2758">and</TOKEN>
<TOKEN id="token-25-25" pos="word" morph="none" start_char="2760" end_char="2764">drugs</TOKEN>
<TOKEN id="token-25-26" pos="word" morph="none" start_char="2766" end_char="2769">that</TOKEN>
<TOKEN id="token-25-27" pos="word" morph="none" start_char="2771" end_char="2776">didn't</TOKEN>
<TOKEN id="token-25-28" pos="word" morph="none" start_char="2778" end_char="2781">work</TOKEN>
<TOKEN id="token-25-29" pos="punct" morph="none" start_char="2782" end_char="2782">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="2785" end_char="2881">
<ORIGINAL_TEXT>So the easy option now is to go back to the high bar they had for approval in non pandemic times.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="2785" end_char="2786">So</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="2788" end_char="2790">the</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="2792" end_char="2795">easy</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="2797" end_char="2802">option</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="2804" end_char="2806">now</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="2808" end_char="2809">is</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="2811" end_char="2812">to</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="2814" end_char="2815">go</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="2817" end_char="2820">back</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="2822" end_char="2823">to</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="2825" end_char="2827">the</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="2829" end_char="2832">high</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="2834" end_char="2836">bar</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="2838" end_char="2841">they</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="2843" end_char="2845">had</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="2847" end_char="2849">for</TOKEN>
<TOKEN id="token-26-16" pos="word" morph="none" start_char="2851" end_char="2858">approval</TOKEN>
<TOKEN id="token-26-17" pos="word" morph="none" start_char="2860" end_char="2861">in</TOKEN>
<TOKEN id="token-26-18" pos="word" morph="none" start_char="2863" end_char="2865">non</TOKEN>
<TOKEN id="token-26-19" pos="word" morph="none" start_char="2867" end_char="2874">pandemic</TOKEN>
<TOKEN id="token-26-20" pos="word" morph="none" start_char="2876" end_char="2880">times</TOKEN>
<TOKEN id="token-26-21" pos="punct" morph="none" start_char="2881" end_char="2881">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="2883" end_char="3019">
<ORIGINAL_TEXT>They've actually dropped the hammer unexpectedly on a gene therapy for hemophilia and a potential arthritis blockbuster in the last week.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="2883" end_char="2889">They've</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="2891" end_char="2898">actually</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="2900" end_char="2906">dropped</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="2908" end_char="2910">the</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="2912" end_char="2917">hammer</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="2919" end_char="2930">unexpectedly</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="2932" end_char="2933">on</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="2935" end_char="2935">a</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="2937" end_char="2940">gene</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="2942" end_char="2948">therapy</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="2950" end_char="2952">for</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="2954" end_char="2963">hemophilia</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="2965" end_char="2967">and</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="2969" end_char="2969">a</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="2971" end_char="2979">potential</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="2981" end_char="2989">arthritis</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="2991" end_char="3001">blockbuster</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="3003" end_char="3004">in</TOKEN>
<TOKEN id="token-27-18" pos="word" morph="none" start_char="3006" end_char="3008">the</TOKEN>
<TOKEN id="token-27-19" pos="word" morph="none" start_char="3010" end_char="3013">last</TOKEN>
<TOKEN id="token-27-20" pos="word" morph="none" start_char="3015" end_char="3018">week</TOKEN>
<TOKEN id="token-27-21" pos="punct" morph="none" start_char="3019" end_char="3019">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3021" end_char="3081">
<ORIGINAL_TEXT>So it's not just COVID-19 drugs having a hard time right now.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="3021" end_char="3022">So</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="3024" end_char="3027">it's</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="3029" end_char="3031">not</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="3033" end_char="3036">just</TOKEN>
<TOKEN id="token-28-4" pos="unknown" morph="none" start_char="3038" end_char="3045">COVID-19</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="3047" end_char="3051">drugs</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="3053" end_char="3058">having</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="3060" end_char="3060">a</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="3062" end_char="3065">hard</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="3067" end_char="3070">time</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="3072" end_char="3076">right</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="3078" end_char="3080">now</TOKEN>
<TOKEN id="token-28-12" pos="punct" morph="none" start_char="3081" end_char="3081">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3086" end_char="3180">
<ORIGINAL_TEXT>ramblin_ag02 said:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7362821/best study I could find.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="3086" end_char="3097">ramblin_ag02</TOKEN>
<TOKEN id="token-29-1" pos="unknown" morph="none" start_char="3099" end_char="3160">said:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7362821/best</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="3162" end_char="3166">study</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="3168" end_char="3168">I</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="3170" end_char="3174">could</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="3176" end_char="3179">find</TOKEN>
<TOKEN id="token-29-6" pos="punct" morph="none" start_char="3180" end_char="3180">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3182" end_char="3281">
<ORIGINAL_TEXT>They acknowledge that the control group wasn't as sick, so that may be a point in the study's favor.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="3182" end_char="3185">They</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="3187" end_char="3197">acknowledge</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="3199" end_char="3202">that</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="3204" end_char="3206">the</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="3208" end_char="3214">control</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="3216" end_char="3220">group</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="3222" end_char="3227">wasn't</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="3229" end_char="3230">as</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="3232" end_char="3235">sick</TOKEN>
<TOKEN id="token-30-9" pos="punct" morph="none" start_char="3236" end_char="3236">,</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="3238" end_char="3239">so</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="3241" end_char="3244">that</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="3246" end_char="3248">may</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="3250" end_char="3251">be</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="3253" end_char="3253">a</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="3255" end_char="3259">point</TOKEN>
<TOKEN id="token-30-16" pos="word" morph="none" start_char="3261" end_char="3262">in</TOKEN>
<TOKEN id="token-30-17" pos="word" morph="none" start_char="3264" end_char="3266">the</TOKEN>
<TOKEN id="token-30-18" pos="word" morph="none" start_char="3268" end_char="3274">study's</TOKEN>
<TOKEN id="token-30-19" pos="word" morph="none" start_char="3276" end_char="3280">favor</TOKEN>
<TOKEN id="token-30-20" pos="punct" morph="none" start_char="3281" end_char="3281">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="3283" end_char="3424">
<ORIGINAL_TEXT>Apparently another European study was stopped because all their admitted COVID patients already had high antibody titers at time of admission.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="3283" end_char="3292">Apparently</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="3294" end_char="3300">another</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="3302" end_char="3309">European</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="3311" end_char="3315">study</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="3317" end_char="3319">was</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="3321" end_char="3327">stopped</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="3329" end_char="3335">because</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="3337" end_char="3339">all</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="3341" end_char="3345">their</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="3347" end_char="3354">admitted</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="3356" end_char="3360">COVID</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="3362" end_char="3369">patients</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="3371" end_char="3377">already</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="3379" end_char="3381">had</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="3383" end_char="3386">high</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="3388" end_char="3395">antibody</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="3397" end_char="3402">titers</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="3404" end_char="3405">at</TOKEN>
<TOKEN id="token-31-18" pos="word" morph="none" start_char="3407" end_char="3410">time</TOKEN>
<TOKEN id="token-31-19" pos="word" morph="none" start_char="3412" end_char="3413">of</TOKEN>
<TOKEN id="token-31-20" pos="word" morph="none" start_char="3415" end_char="3423">admission</TOKEN>
<TOKEN id="token-31-21" pos="punct" morph="none" start_char="3424" end_char="3424">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="3426" end_char="3528">
<ORIGINAL_TEXT>So there wasn't any point in giving more.I was a bit shocked that the FDA came down so hard on its use.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="3426" end_char="3427">So</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="3429" end_char="3433">there</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="3435" end_char="3440">wasn't</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="3442" end_char="3444">any</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="3446" end_char="3450">point</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="3452" end_char="3453">in</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="3455" end_char="3460">giving</TOKEN>
<TOKEN id="token-32-7" pos="unknown" morph="none" start_char="3462" end_char="3467">more.I</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="3469" end_char="3471">was</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="3473" end_char="3473">a</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="3475" end_char="3477">bit</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="3479" end_char="3485">shocked</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="3487" end_char="3490">that</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="3492" end_char="3494">the</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="3496" end_char="3498">FDA</TOKEN>
<TOKEN id="token-32-15" pos="word" morph="none" start_char="3500" end_char="3503">came</TOKEN>
<TOKEN id="token-32-16" pos="word" morph="none" start_char="3505" end_char="3508">down</TOKEN>
<TOKEN id="token-32-17" pos="word" morph="none" start_char="3510" end_char="3511">so</TOKEN>
<TOKEN id="token-32-18" pos="word" morph="none" start_char="3513" end_char="3516">hard</TOKEN>
<TOKEN id="token-32-19" pos="word" morph="none" start_char="3518" end_char="3519">on</TOKEN>
<TOKEN id="token-32-20" pos="word" morph="none" start_char="3521" end_char="3523">its</TOKEN>
<TOKEN id="token-32-21" pos="word" morph="none" start_char="3525" end_char="3527">use</TOKEN>
<TOKEN id="token-32-22" pos="punct" morph="none" start_char="3528" end_char="3528">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="3531" end_char="3696">
<ORIGINAL_TEXT>Thanks for posting that link ramblin ag02. Based on those findings I don't know what Dr. Fauci is looking at because it seems apparent that convalescent plasma helps.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="3531" end_char="3536">Thanks</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="3538" end_char="3540">for</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="3542" end_char="3548">posting</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="3550" end_char="3553">that</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="3555" end_char="3558">link</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="3560" end_char="3566">ramblin</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="3568" end_char="3571">ag02</TOKEN>
<TOKEN id="token-33-7" pos="punct" morph="none" start_char="3572" end_char="3572">.</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="3574" end_char="3578">Based</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="3580" end_char="3581">on</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="3583" end_char="3587">those</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="3589" end_char="3596">findings</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="3598" end_char="3598">I</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="3600" end_char="3604">don't</TOKEN>
<TOKEN id="token-33-14" pos="word" morph="none" start_char="3606" end_char="3609">know</TOKEN>
<TOKEN id="token-33-15" pos="word" morph="none" start_char="3611" end_char="3614">what</TOKEN>
<TOKEN id="token-33-16" pos="word" morph="none" start_char="3616" end_char="3617">Dr</TOKEN>
<TOKEN id="token-33-17" pos="punct" morph="none" start_char="3618" end_char="3618">.</TOKEN>
<TOKEN id="token-33-18" pos="word" morph="none" start_char="3620" end_char="3624">Fauci</TOKEN>
<TOKEN id="token-33-19" pos="word" morph="none" start_char="3626" end_char="3627">is</TOKEN>
<TOKEN id="token-33-20" pos="word" morph="none" start_char="3629" end_char="3635">looking</TOKEN>
<TOKEN id="token-33-21" pos="word" morph="none" start_char="3637" end_char="3638">at</TOKEN>
<TOKEN id="token-33-22" pos="word" morph="none" start_char="3640" end_char="3646">because</TOKEN>
<TOKEN id="token-33-23" pos="word" morph="none" start_char="3648" end_char="3649">it</TOKEN>
<TOKEN id="token-33-24" pos="word" morph="none" start_char="3651" end_char="3655">seems</TOKEN>
<TOKEN id="token-33-25" pos="word" morph="none" start_char="3657" end_char="3664">apparent</TOKEN>
<TOKEN id="token-33-26" pos="word" morph="none" start_char="3666" end_char="3669">that</TOKEN>
<TOKEN id="token-33-27" pos="word" morph="none" start_char="3671" end_char="3682">convalescent</TOKEN>
<TOKEN id="token-33-28" pos="word" morph="none" start_char="3684" end_char="3689">plasma</TOKEN>
<TOKEN id="token-33-29" pos="word" morph="none" start_char="3691" end_char="3695">helps</TOKEN>
<TOKEN id="token-33-30" pos="punct" morph="none" start_char="3696" end_char="3696">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="3698" end_char="3778">
<ORIGINAL_TEXT>I wish everyone could remove all of the politics and simply utilize common sense.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="3698" end_char="3698">I</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="3700" end_char="3703">wish</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="3705" end_char="3712">everyone</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="3714" end_char="3718">could</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="3720" end_char="3725">remove</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="3727" end_char="3729">all</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="3731" end_char="3732">of</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="3734" end_char="3736">the</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="3738" end_char="3745">politics</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="3747" end_char="3749">and</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="3751" end_char="3756">simply</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="3758" end_char="3764">utilize</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="3766" end_char="3771">common</TOKEN>
<TOKEN id="token-34-13" pos="word" morph="none" start_char="3773" end_char="3777">sense</TOKEN>
<TOKEN id="token-34-14" pos="punct" morph="none" start_char="3778" end_char="3778">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="3783" end_char="3934">
<ORIGINAL_TEXT>I think we're still in the equipoise phase where we really don't know if it helps or not, but it's not like we have a ton of other fantastic treatments.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="3783" end_char="3783">I</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="3785" end_char="3789">think</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="3791" end_char="3795">we're</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="3797" end_char="3801">still</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="3803" end_char="3804">in</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="3806" end_char="3808">the</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="3810" end_char="3818">equipoise</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="3820" end_char="3824">phase</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="3826" end_char="3830">where</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="3832" end_char="3833">we</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="3835" end_char="3840">really</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="3842" end_char="3846">don't</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="3848" end_char="3851">know</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="3853" end_char="3854">if</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="3856" end_char="3857">it</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="3859" end_char="3863">helps</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="3865" end_char="3866">or</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="3868" end_char="3870">not</TOKEN>
<TOKEN id="token-35-18" pos="punct" morph="none" start_char="3871" end_char="3871">,</TOKEN>
<TOKEN id="token-35-19" pos="word" morph="none" start_char="3873" end_char="3875">but</TOKEN>
<TOKEN id="token-35-20" pos="word" morph="none" start_char="3877" end_char="3880">it's</TOKEN>
<TOKEN id="token-35-21" pos="word" morph="none" start_char="3882" end_char="3884">not</TOKEN>
<TOKEN id="token-35-22" pos="word" morph="none" start_char="3886" end_char="3889">like</TOKEN>
<TOKEN id="token-35-23" pos="word" morph="none" start_char="3891" end_char="3892">we</TOKEN>
<TOKEN id="token-35-24" pos="word" morph="none" start_char="3894" end_char="3897">have</TOKEN>
<TOKEN id="token-35-25" pos="word" morph="none" start_char="3899" end_char="3899">a</TOKEN>
<TOKEN id="token-35-26" pos="word" morph="none" start_char="3901" end_char="3903">ton</TOKEN>
<TOKEN id="token-35-27" pos="word" morph="none" start_char="3905" end_char="3906">of</TOKEN>
<TOKEN id="token-35-28" pos="word" morph="none" start_char="3908" end_char="3912">other</TOKEN>
<TOKEN id="token-35-29" pos="word" morph="none" start_char="3914" end_char="3922">fantastic</TOKEN>
<TOKEN id="token-35-30" pos="word" morph="none" start_char="3924" end_char="3933">treatments</TOKEN>
<TOKEN id="token-35-31" pos="punct" morph="none" start_char="3934" end_char="3934">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="3936" end_char="4042">
<ORIGINAL_TEXT>Also agree with the point above that lots of things like remdesivir are getting approval despite weak data.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="3936" end_char="3939">Also</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="3941" end_char="3945">agree</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="3947" end_char="3950">with</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="3952" end_char="3954">the</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="3956" end_char="3960">point</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="3962" end_char="3966">above</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="3968" end_char="3971">that</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="3973" end_char="3976">lots</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="3978" end_char="3979">of</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="3981" end_char="3986">things</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="3988" end_char="3991">like</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="3993" end_char="4002">remdesivir</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="4004" end_char="4006">are</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="4008" end_char="4014">getting</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="4016" end_char="4023">approval</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="4025" end_char="4031">despite</TOKEN>
<TOKEN id="token-36-16" pos="word" morph="none" start_char="4033" end_char="4036">weak</TOKEN>
<TOKEN id="token-36-17" pos="word" morph="none" start_char="4038" end_char="4041">data</TOKEN>
<TOKEN id="token-36-18" pos="punct" morph="none" start_char="4042" end_char="4042">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="4044" end_char="4153">
<ORIGINAL_TEXT>Seems like a weird choice to shut down first since supply will limit use anyway and it's pretty well tolerated</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="4044" end_char="4048">Seems</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="4050" end_char="4053">like</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="4055" end_char="4055">a</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="4057" end_char="4061">weird</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="4063" end_char="4068">choice</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="4070" end_char="4071">to</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="4073" end_char="4076">shut</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="4078" end_char="4081">down</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="4083" end_char="4087">first</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="4089" end_char="4093">since</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="4095" end_char="4100">supply</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="4102" end_char="4105">will</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="4107" end_char="4111">limit</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="4113" end_char="4115">use</TOKEN>
<TOKEN id="token-37-14" pos="word" morph="none" start_char="4117" end_char="4122">anyway</TOKEN>
<TOKEN id="token-37-15" pos="word" morph="none" start_char="4124" end_char="4126">and</TOKEN>
<TOKEN id="token-37-16" pos="word" morph="none" start_char="4128" end_char="4131">it's</TOKEN>
<TOKEN id="token-37-17" pos="word" morph="none" start_char="4133" end_char="4138">pretty</TOKEN>
<TOKEN id="token-37-18" pos="word" morph="none" start_char="4140" end_char="4143">well</TOKEN>
<TOKEN id="token-37-19" pos="word" morph="none" start_char="4145" end_char="4153">tolerated</TOKEN>
</SEG>
<SEG id="segment-38" start_char="4156" end_char="4267">
<ORIGINAL_TEXT>No material on this site is intended to be a substitute for professional medical advice, diagnosis or treatment.</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="4156" end_char="4157">No</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="4159" end_char="4166">material</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="4168" end_char="4169">on</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="4171" end_char="4174">this</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="4176" end_char="4179">site</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="4181" end_char="4182">is</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="4184" end_char="4191">intended</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="4193" end_char="4194">to</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="4196" end_char="4197">be</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="4199" end_char="4199">a</TOKEN>
<TOKEN id="token-38-10" pos="word" morph="none" start_char="4201" end_char="4210">substitute</TOKEN>
<TOKEN id="token-38-11" pos="word" morph="none" start_char="4212" end_char="4214">for</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="4216" end_char="4227">professional</TOKEN>
<TOKEN id="token-38-13" pos="word" morph="none" start_char="4229" end_char="4235">medical</TOKEN>
<TOKEN id="token-38-14" pos="word" morph="none" start_char="4237" end_char="4242">advice</TOKEN>
<TOKEN id="token-38-15" pos="punct" morph="none" start_char="4243" end_char="4243">,</TOKEN>
<TOKEN id="token-38-16" pos="word" morph="none" start_char="4245" end_char="4253">diagnosis</TOKEN>
<TOKEN id="token-38-17" pos="word" morph="none" start_char="4255" end_char="4256">or</TOKEN>
<TOKEN id="token-38-18" pos="word" morph="none" start_char="4258" end_char="4266">treatment</TOKEN>
<TOKEN id="token-38-19" pos="punct" morph="none" start_char="4267" end_char="4267">.</TOKEN>
</SEG>
<SEG id="segment-39" start_char="4269" end_char="4296">
<ORIGINAL_TEXT>See full Medical Disclaimer.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="4269" end_char="4271">See</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="4273" end_char="4276">full</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="4278" end_char="4284">Medical</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="4286" end_char="4295">Disclaimer</TOKEN>
<TOKEN id="token-39-4" pos="punct" morph="none" start_char="4296" end_char="4296">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="4300" end_char="4345">
<ORIGINAL_TEXT>I think the news articles are a bit confusing.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="4300" end_char="4300">I</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="4302" end_char="4306">think</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="4308" end_char="4310">the</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="4312" end_char="4315">news</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="4317" end_char="4324">articles</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="4326" end_char="4328">are</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="4330" end_char="4330">a</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="4332" end_char="4334">bit</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="4336" end_char="4344">confusing</TOKEN>
<TOKEN id="token-40-9" pos="punct" morph="none" start_char="4345" end_char="4345">.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="4348" end_char="4490">
<ORIGINAL_TEXT>Hospitals are ordering as much as ever, and we are actively working to build a national stockpile of the product once we have local demand met.</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="4348" end_char="4356">Hospitals</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="4358" end_char="4360">are</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="4362" end_char="4369">ordering</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="4371" end_char="4372">as</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="4374" end_char="4377">much</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="4379" end_char="4380">as</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="4382" end_char="4385">ever</TOKEN>
<TOKEN id="token-41-7" pos="punct" morph="none" start_char="4386" end_char="4386">,</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="4388" end_char="4390">and</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="4392" end_char="4393">we</TOKEN>
<TOKEN id="token-41-10" pos="word" morph="none" start_char="4395" end_char="4397">are</TOKEN>
<TOKEN id="token-41-11" pos="word" morph="none" start_char="4399" end_char="4406">actively</TOKEN>
<TOKEN id="token-41-12" pos="word" morph="none" start_char="4408" end_char="4414">working</TOKEN>
<TOKEN id="token-41-13" pos="word" morph="none" start_char="4416" end_char="4417">to</TOKEN>
<TOKEN id="token-41-14" pos="word" morph="none" start_char="4419" end_char="4423">build</TOKEN>
<TOKEN id="token-41-15" pos="word" morph="none" start_char="4425" end_char="4425">a</TOKEN>
<TOKEN id="token-41-16" pos="word" morph="none" start_char="4427" end_char="4434">national</TOKEN>
<TOKEN id="token-41-17" pos="word" morph="none" start_char="4436" end_char="4444">stockpile</TOKEN>
<TOKEN id="token-41-18" pos="word" morph="none" start_char="4446" end_char="4447">of</TOKEN>
<TOKEN id="token-41-19" pos="word" morph="none" start_char="4449" end_char="4451">the</TOKEN>
<TOKEN id="token-41-20" pos="word" morph="none" start_char="4453" end_char="4459">product</TOKEN>
<TOKEN id="token-41-21" pos="word" morph="none" start_char="4461" end_char="4464">once</TOKEN>
<TOKEN id="token-41-22" pos="word" morph="none" start_char="4466" end_char="4467">we</TOKEN>
<TOKEN id="token-41-23" pos="word" morph="none" start_char="4469" end_char="4472">have</TOKEN>
<TOKEN id="token-41-24" pos="word" morph="none" start_char="4474" end_char="4478">local</TOKEN>
<TOKEN id="token-41-25" pos="word" morph="none" start_char="4480" end_char="4485">demand</TOKEN>
<TOKEN id="token-41-26" pos="word" morph="none" start_char="4487" end_char="4489">met</TOKEN>
<TOKEN id="token-41-27" pos="punct" morph="none" start_char="4490" end_char="4490">.</TOKEN>
</SEG>
<SEG id="segment-42" start_char="4493" end_char="4628">
<ORIGINAL_TEXT>The fda really didn't change much in the current guidance, they just decided to not expand its usage at this time beyond current access.</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="4493" end_char="4495">The</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="4497" end_char="4499">fda</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="4501" end_char="4506">really</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="4508" end_char="4513">didn't</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="4515" end_char="4520">change</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="4522" end_char="4525">much</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="4527" end_char="4528">in</TOKEN>
<TOKEN id="token-42-7" pos="word" morph="none" start_char="4530" end_char="4532">the</TOKEN>
<TOKEN id="token-42-8" pos="word" morph="none" start_char="4534" end_char="4540">current</TOKEN>
<TOKEN id="token-42-9" pos="word" morph="none" start_char="4542" end_char="4549">guidance</TOKEN>
<TOKEN id="token-42-10" pos="punct" morph="none" start_char="4550" end_char="4550">,</TOKEN>
<TOKEN id="token-42-11" pos="word" morph="none" start_char="4552" end_char="4555">they</TOKEN>
<TOKEN id="token-42-12" pos="word" morph="none" start_char="4557" end_char="4560">just</TOKEN>
<TOKEN id="token-42-13" pos="word" morph="none" start_char="4562" end_char="4568">decided</TOKEN>
<TOKEN id="token-42-14" pos="word" morph="none" start_char="4570" end_char="4571">to</TOKEN>
<TOKEN id="token-42-15" pos="word" morph="none" start_char="4573" end_char="4575">not</TOKEN>
<TOKEN id="token-42-16" pos="word" morph="none" start_char="4577" end_char="4582">expand</TOKEN>
<TOKEN id="token-42-17" pos="word" morph="none" start_char="4584" end_char="4586">its</TOKEN>
<TOKEN id="token-42-18" pos="word" morph="none" start_char="4588" end_char="4592">usage</TOKEN>
<TOKEN id="token-42-19" pos="word" morph="none" start_char="4594" end_char="4595">at</TOKEN>
<TOKEN id="token-42-20" pos="word" morph="none" start_char="4597" end_char="4600">this</TOKEN>
<TOKEN id="token-42-21" pos="word" morph="none" start_char="4602" end_char="4605">time</TOKEN>
<TOKEN id="token-42-22" pos="word" morph="none" start_char="4607" end_char="4612">beyond</TOKEN>
<TOKEN id="token-42-23" pos="word" morph="none" start_char="4614" end_char="4620">current</TOKEN>
<TOKEN id="token-42-24" pos="word" morph="none" start_char="4622" end_char="4627">access</TOKEN>
<TOKEN id="token-42-25" pos="punct" morph="none" start_char="4628" end_char="4628">.</TOKEN>
</SEG>
<SEG id="segment-43" start_char="4631" end_char="4770">
<ORIGINAL_TEXT>But any hospital willing to work through the investigational access can enroll (through the Mayo program) and be eligible to receive plasma.</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="4631" end_char="4633">But</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="4635" end_char="4637">any</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="4639" end_char="4646">hospital</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="4648" end_char="4654">willing</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="4656" end_char="4657">to</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="4659" end_char="4662">work</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="4664" end_char="4670">through</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="4672" end_char="4674">the</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="4676" end_char="4690">investigational</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="4692" end_char="4697">access</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="4699" end_char="4701">can</TOKEN>
<TOKEN id="token-43-11" pos="word" morph="none" start_char="4703" end_char="4708">enroll</TOKEN>
<TOKEN id="token-43-12" pos="punct" morph="none" start_char="4710" end_char="4710">(</TOKEN>
<TOKEN id="token-43-13" pos="word" morph="none" start_char="4711" end_char="4717">through</TOKEN>
<TOKEN id="token-43-14" pos="word" morph="none" start_char="4719" end_char="4721">the</TOKEN>
<TOKEN id="token-43-15" pos="word" morph="none" start_char="4723" end_char="4726">Mayo</TOKEN>
<TOKEN id="token-43-16" pos="word" morph="none" start_char="4728" end_char="4734">program</TOKEN>
<TOKEN id="token-43-17" pos="punct" morph="none" start_char="4735" end_char="4735">)</TOKEN>
<TOKEN id="token-43-18" pos="word" morph="none" start_char="4737" end_char="4739">and</TOKEN>
<TOKEN id="token-43-19" pos="word" morph="none" start_char="4741" end_char="4742">be</TOKEN>
<TOKEN id="token-43-20" pos="word" morph="none" start_char="4744" end_char="4751">eligible</TOKEN>
<TOKEN id="token-43-21" pos="word" morph="none" start_char="4753" end_char="4754">to</TOKEN>
<TOKEN id="token-43-22" pos="word" morph="none" start_char="4756" end_char="4762">receive</TOKEN>
<TOKEN id="token-43-23" pos="word" morph="none" start_char="4764" end_char="4769">plasma</TOKEN>
<TOKEN id="token-43-24" pos="punct" morph="none" start_char="4770" end_char="4770">.</TOKEN>
</SEG>
<SEG id="segment-44" start_char="4773" end_char="4924">
<ORIGINAL_TEXT>There are also multiple studies on going, one in my backyard that is working to determine efficacy and the best protocol for transfusion as a treatment.</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="4773" end_char="4777">There</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="4779" end_char="4781">are</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="4783" end_char="4786">also</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="4788" end_char="4795">multiple</TOKEN>
<TOKEN id="token-44-4" pos="word" morph="none" start_char="4797" end_char="4803">studies</TOKEN>
<TOKEN id="token-44-5" pos="word" morph="none" start_char="4805" end_char="4806">on</TOKEN>
<TOKEN id="token-44-6" pos="word" morph="none" start_char="4808" end_char="4812">going</TOKEN>
<TOKEN id="token-44-7" pos="punct" morph="none" start_char="4813" end_char="4813">,</TOKEN>
<TOKEN id="token-44-8" pos="word" morph="none" start_char="4815" end_char="4817">one</TOKEN>
<TOKEN id="token-44-9" pos="word" morph="none" start_char="4819" end_char="4820">in</TOKEN>
<TOKEN id="token-44-10" pos="word" morph="none" start_char="4822" end_char="4823">my</TOKEN>
<TOKEN id="token-44-11" pos="word" morph="none" start_char="4825" end_char="4832">backyard</TOKEN>
<TOKEN id="token-44-12" pos="word" morph="none" start_char="4834" end_char="4837">that</TOKEN>
<TOKEN id="token-44-13" pos="word" morph="none" start_char="4839" end_char="4840">is</TOKEN>
<TOKEN id="token-44-14" pos="word" morph="none" start_char="4842" end_char="4848">working</TOKEN>
<TOKEN id="token-44-15" pos="word" morph="none" start_char="4850" end_char="4851">to</TOKEN>
<TOKEN id="token-44-16" pos="word" morph="none" start_char="4853" end_char="4861">determine</TOKEN>
<TOKEN id="token-44-17" pos="word" morph="none" start_char="4863" end_char="4870">efficacy</TOKEN>
<TOKEN id="token-44-18" pos="word" morph="none" start_char="4872" end_char="4874">and</TOKEN>
<TOKEN id="token-44-19" pos="word" morph="none" start_char="4876" end_char="4878">the</TOKEN>
<TOKEN id="token-44-20" pos="word" morph="none" start_char="4880" end_char="4883">best</TOKEN>
<TOKEN id="token-44-21" pos="word" morph="none" start_char="4885" end_char="4892">protocol</TOKEN>
<TOKEN id="token-44-22" pos="word" morph="none" start_char="4894" end_char="4896">for</TOKEN>
<TOKEN id="token-44-23" pos="word" morph="none" start_char="4898" end_char="4908">transfusion</TOKEN>
<TOKEN id="token-44-24" pos="word" morph="none" start_char="4910" end_char="4911">as</TOKEN>
<TOKEN id="token-44-25" pos="word" morph="none" start_char="4913" end_char="4913">a</TOKEN>
<TOKEN id="token-44-26" pos="word" morph="none" start_char="4915" end_char="4923">treatment</TOKEN>
<TOKEN id="token-44-27" pos="punct" morph="none" start_char="4924" end_char="4924">.</TOKEN>
</SEG>
<SEG id="segment-45" start_char="4927" end_char="4971">
<ORIGINAL_TEXT>Eta: link to fda protocol released yesterday.</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="4927" end_char="4929">Eta</TOKEN>
<TOKEN id="token-45-1" pos="punct" morph="none" start_char="4930" end_char="4930">:</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="4932" end_char="4935">link</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="4937" end_char="4938">to</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="4940" end_char="4942">fda</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="4944" end_char="4951">protocol</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="4953" end_char="4960">released</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="4962" end_char="4970">yesterday</TOKEN>
<TOKEN id="token-45-8" pos="punct" morph="none" start_char="4971" end_char="4971">.</TOKEN>
</SEG>
<SEG id="segment-46" start_char="4974" end_char="5144">
<ORIGINAL_TEXT>https://www.fda.gov/vaccines-blood-biologics/investigational-new-drug-ind-or-device-exemption-ide-process-cber/recommendations-investigational-covid-19-convalescent-plasma</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="url" morph="none" start_char="4974" end_char="5144">https://www.fda.gov/vaccines-blood-biologics/investigational-new-drug-ind-or-device-exemption-ide-process-cber/recommendations-investigational-covid-19-convalescent-plasma</TOKEN>
</SEG>
<SEG id="segment-47" start_char="5147" end_char="5263">
<ORIGINAL_TEXT>It doesn't change any of the current usage treatment, simply not opening up usage to uncontrolled or non studied use.</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="5147" end_char="5148">It</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="5150" end_char="5156">doesn't</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="5158" end_char="5163">change</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="5165" end_char="5167">any</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="5169" end_char="5170">of</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="5172" end_char="5174">the</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="5176" end_char="5182">current</TOKEN>
<TOKEN id="token-47-7" pos="word" morph="none" start_char="5184" end_char="5188">usage</TOKEN>
<TOKEN id="token-47-8" pos="word" morph="none" start_char="5190" end_char="5198">treatment</TOKEN>
<TOKEN id="token-47-9" pos="punct" morph="none" start_char="5199" end_char="5199">,</TOKEN>
<TOKEN id="token-47-10" pos="word" morph="none" start_char="5201" end_char="5206">simply</TOKEN>
<TOKEN id="token-47-11" pos="word" morph="none" start_char="5208" end_char="5210">not</TOKEN>
<TOKEN id="token-47-12" pos="word" morph="none" start_char="5212" end_char="5218">opening</TOKEN>
<TOKEN id="token-47-13" pos="word" morph="none" start_char="5220" end_char="5221">up</TOKEN>
<TOKEN id="token-47-14" pos="word" morph="none" start_char="5223" end_char="5227">usage</TOKEN>
<TOKEN id="token-47-15" pos="word" morph="none" start_char="5229" end_char="5230">to</TOKEN>
<TOKEN id="token-47-16" pos="word" morph="none" start_char="5232" end_char="5243">uncontrolled</TOKEN>
<TOKEN id="token-47-17" pos="word" morph="none" start_char="5245" end_char="5246">or</TOKEN>
<TOKEN id="token-47-18" pos="word" morph="none" start_char="5248" end_char="5250">non</TOKEN>
<TOKEN id="token-47-19" pos="word" morph="none" start_char="5252" end_char="5258">studied</TOKEN>
<TOKEN id="token-47-20" pos="word" morph="none" start_char="5260" end_char="5262">use</TOKEN>
<TOKEN id="token-47-21" pos="punct" morph="none" start_char="5263" end_char="5263">.</TOKEN>
</SEG>
<SEG id="segment-48" start_char="5267" end_char="5339">
<ORIGINAL_TEXT>The Medcram Update #103 was released today and discusses this very topic.</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="5267" end_char="5269">The</TOKEN>
<TOKEN id="token-48-1" pos="word" morph="none" start_char="5271" end_char="5277">Medcram</TOKEN>
<TOKEN id="token-48-2" pos="word" morph="none" start_char="5279" end_char="5284">Update</TOKEN>
<TOKEN id="token-48-3" pos="tag" morph="none" start_char="5286" end_char="5289">#103</TOKEN>
<TOKEN id="token-48-4" pos="word" morph="none" start_char="5291" end_char="5293">was</TOKEN>
<TOKEN id="token-48-5" pos="word" morph="none" start_char="5295" end_char="5302">released</TOKEN>
<TOKEN id="token-48-6" pos="word" morph="none" start_char="5304" end_char="5308">today</TOKEN>
<TOKEN id="token-48-7" pos="word" morph="none" start_char="5310" end_char="5312">and</TOKEN>
<TOKEN id="token-48-8" pos="word" morph="none" start_char="5314" end_char="5322">discusses</TOKEN>
<TOKEN id="token-48-9" pos="word" morph="none" start_char="5324" end_char="5327">this</TOKEN>
<TOKEN id="token-48-10" pos="word" morph="none" start_char="5329" end_char="5332">very</TOKEN>
<TOKEN id="token-48-11" pos="word" morph="none" start_char="5334" end_char="5338">topic</TOKEN>
<TOKEN id="token-48-12" pos="punct" morph="none" start_char="5339" end_char="5339">.</TOKEN>
</SEG>
<SEG id="segment-49" start_char="5343" end_char="5550">
<ORIGINAL_TEXT>As I suspected it looks like hospitals have been giving it to patients who are too far along (&gt; 4 days from onset of symptoms) and then noting that its not helping a large enough percentage of these patients.</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="5343" end_char="5344">As</TOKEN>
<TOKEN id="token-49-1" pos="word" morph="none" start_char="5346" end_char="5346">I</TOKEN>
<TOKEN id="token-49-2" pos="word" morph="none" start_char="5348" end_char="5356">suspected</TOKEN>
<TOKEN id="token-49-3" pos="word" morph="none" start_char="5358" end_char="5359">it</TOKEN>
<TOKEN id="token-49-4" pos="word" morph="none" start_char="5361" end_char="5365">looks</TOKEN>
<TOKEN id="token-49-5" pos="word" morph="none" start_char="5367" end_char="5370">like</TOKEN>
<TOKEN id="token-49-6" pos="word" morph="none" start_char="5372" end_char="5380">hospitals</TOKEN>
<TOKEN id="token-49-7" pos="word" morph="none" start_char="5382" end_char="5385">have</TOKEN>
<TOKEN id="token-49-8" pos="word" morph="none" start_char="5387" end_char="5390">been</TOKEN>
<TOKEN id="token-49-9" pos="word" morph="none" start_char="5392" end_char="5397">giving</TOKEN>
<TOKEN id="token-49-10" pos="word" morph="none" start_char="5399" end_char="5400">it</TOKEN>
<TOKEN id="token-49-11" pos="word" morph="none" start_char="5402" end_char="5403">to</TOKEN>
<TOKEN id="token-49-12" pos="word" morph="none" start_char="5405" end_char="5412">patients</TOKEN>
<TOKEN id="token-49-13" pos="word" morph="none" start_char="5414" end_char="5416">who</TOKEN>
<TOKEN id="token-49-14" pos="word" morph="none" start_char="5418" end_char="5420">are</TOKEN>
<TOKEN id="token-49-15" pos="word" morph="none" start_char="5422" end_char="5424">too</TOKEN>
<TOKEN id="token-49-16" pos="word" morph="none" start_char="5426" end_char="5428">far</TOKEN>
<TOKEN id="token-49-17" pos="word" morph="none" start_char="5430" end_char="5434">along</TOKEN>
<TOKEN id="token-49-18" pos="unknown" morph="none" start_char="5436" end_char="5437">(&gt;</TOKEN>
<TOKEN id="token-49-19" pos="word" morph="none" start_char="5439" end_char="5439">4</TOKEN>
<TOKEN id="token-49-20" pos="word" morph="none" start_char="5441" end_char="5444">days</TOKEN>
<TOKEN id="token-49-21" pos="word" morph="none" start_char="5446" end_char="5449">from</TOKEN>
<TOKEN id="token-49-22" pos="word" morph="none" start_char="5451" end_char="5455">onset</TOKEN>
<TOKEN id="token-49-23" pos="word" morph="none" start_char="5457" end_char="5458">of</TOKEN>
<TOKEN id="token-49-24" pos="word" morph="none" start_char="5460" end_char="5467">symptoms</TOKEN>
<TOKEN id="token-49-25" pos="punct" morph="none" start_char="5468" end_char="5468">)</TOKEN>
<TOKEN id="token-49-26" pos="word" morph="none" start_char="5470" end_char="5472">and</TOKEN>
<TOKEN id="token-49-27" pos="word" morph="none" start_char="5474" end_char="5477">then</TOKEN>
<TOKEN id="token-49-28" pos="word" morph="none" start_char="5479" end_char="5484">noting</TOKEN>
<TOKEN id="token-49-29" pos="word" morph="none" start_char="5486" end_char="5489">that</TOKEN>
<TOKEN id="token-49-30" pos="word" morph="none" start_char="5491" end_char="5493">its</TOKEN>
<TOKEN id="token-49-31" pos="word" morph="none" start_char="5495" end_char="5497">not</TOKEN>
<TOKEN id="token-49-32" pos="word" morph="none" start_char="5499" end_char="5505">helping</TOKEN>
<TOKEN id="token-49-33" pos="word" morph="none" start_char="5507" end_char="5507">a</TOKEN>
<TOKEN id="token-49-34" pos="word" morph="none" start_char="5509" end_char="5513">large</TOKEN>
<TOKEN id="token-49-35" pos="word" morph="none" start_char="5515" end_char="5520">enough</TOKEN>
<TOKEN id="token-49-36" pos="word" morph="none" start_char="5522" end_char="5531">percentage</TOKEN>
<TOKEN id="token-49-37" pos="word" morph="none" start_char="5533" end_char="5534">of</TOKEN>
<TOKEN id="token-49-38" pos="word" morph="none" start_char="5536" end_char="5540">these</TOKEN>
<TOKEN id="token-49-39" pos="word" morph="none" start_char="5542" end_char="5549">patients</TOKEN>
<TOKEN id="token-49-40" pos="punct" morph="none" start_char="5550" end_char="5550">.</TOKEN>
</SEG>
<SEG id="segment-50" start_char="5552" end_char="5715">
<ORIGINAL_TEXT>However as expected, the patients who received the plasma in 3 or less days showed statistically significant improvement, thus meaning its validated for this group.</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="5552" end_char="5558">However</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="5560" end_char="5561">as</TOKEN>
<TOKEN id="token-50-2" pos="word" morph="none" start_char="5563" end_char="5570">expected</TOKEN>
<TOKEN id="token-50-3" pos="punct" morph="none" start_char="5571" end_char="5571">,</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="5573" end_char="5575">the</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="5577" end_char="5584">patients</TOKEN>
<TOKEN id="token-50-6" pos="word" morph="none" start_char="5586" end_char="5588">who</TOKEN>
<TOKEN id="token-50-7" pos="word" morph="none" start_char="5590" end_char="5597">received</TOKEN>
<TOKEN id="token-50-8" pos="word" morph="none" start_char="5599" end_char="5601">the</TOKEN>
<TOKEN id="token-50-9" pos="word" morph="none" start_char="5603" end_char="5608">plasma</TOKEN>
<TOKEN id="token-50-10" pos="word" morph="none" start_char="5610" end_char="5611">in</TOKEN>
<TOKEN id="token-50-11" pos="word" morph="none" start_char="5613" end_char="5613">3</TOKEN>
<TOKEN id="token-50-12" pos="word" morph="none" start_char="5615" end_char="5616">or</TOKEN>
<TOKEN id="token-50-13" pos="word" morph="none" start_char="5618" end_char="5621">less</TOKEN>
<TOKEN id="token-50-14" pos="word" morph="none" start_char="5623" end_char="5626">days</TOKEN>
<TOKEN id="token-50-15" pos="word" morph="none" start_char="5628" end_char="5633">showed</TOKEN>
<TOKEN id="token-50-16" pos="word" morph="none" start_char="5635" end_char="5647">statistically</TOKEN>
<TOKEN id="token-50-17" pos="word" morph="none" start_char="5649" end_char="5659">significant</TOKEN>
<TOKEN id="token-50-18" pos="word" morph="none" start_char="5661" end_char="5671">improvement</TOKEN>
<TOKEN id="token-50-19" pos="punct" morph="none" start_char="5672" end_char="5672">,</TOKEN>
<TOKEN id="token-50-20" pos="word" morph="none" start_char="5674" end_char="5677">thus</TOKEN>
<TOKEN id="token-50-21" pos="word" morph="none" start_char="5679" end_char="5685">meaning</TOKEN>
<TOKEN id="token-50-22" pos="word" morph="none" start_char="5687" end_char="5689">its</TOKEN>
<TOKEN id="token-50-23" pos="word" morph="none" start_char="5691" end_char="5699">validated</TOKEN>
<TOKEN id="token-50-24" pos="word" morph="none" start_char="5701" end_char="5703">for</TOKEN>
<TOKEN id="token-50-25" pos="word" morph="none" start_char="5705" end_char="5708">this</TOKEN>
<TOKEN id="token-50-26" pos="word" morph="none" start_char="5710" end_char="5714">group</TOKEN>
<TOKEN id="token-50-27" pos="punct" morph="none" start_char="5715" end_char="5715">.</TOKEN>
</SEG>
<SEG id="segment-51" start_char="5717" end_char="5874">
<ORIGINAL_TEXT>Unfortunately when these 2 populations are combined, the results of the 3 day patients are watered down and the data no longer shows statistical significance.</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="word" morph="none" start_char="5717" end_char="5729">Unfortunately</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="5731" end_char="5734">when</TOKEN>
<TOKEN id="token-51-2" pos="word" morph="none" start_char="5736" end_char="5740">these</TOKEN>
<TOKEN id="token-51-3" pos="word" morph="none" start_char="5742" end_char="5742">2</TOKEN>
<TOKEN id="token-51-4" pos="word" morph="none" start_char="5744" end_char="5754">populations</TOKEN>
<TOKEN id="token-51-5" pos="word" morph="none" start_char="5756" end_char="5758">are</TOKEN>
<TOKEN id="token-51-6" pos="word" morph="none" start_char="5760" end_char="5767">combined</TOKEN>
<TOKEN id="token-51-7" pos="punct" morph="none" start_char="5768" end_char="5768">,</TOKEN>
<TOKEN id="token-51-8" pos="word" morph="none" start_char="5770" end_char="5772">the</TOKEN>
<TOKEN id="token-51-9" pos="word" morph="none" start_char="5774" end_char="5780">results</TOKEN>
<TOKEN id="token-51-10" pos="word" morph="none" start_char="5782" end_char="5783">of</TOKEN>
<TOKEN id="token-51-11" pos="word" morph="none" start_char="5785" end_char="5787">the</TOKEN>
<TOKEN id="token-51-12" pos="word" morph="none" start_char="5789" end_char="5789">3</TOKEN>
<TOKEN id="token-51-13" pos="word" morph="none" start_char="5791" end_char="5793">day</TOKEN>
<TOKEN id="token-51-14" pos="word" morph="none" start_char="5795" end_char="5802">patients</TOKEN>
<TOKEN id="token-51-15" pos="word" morph="none" start_char="5804" end_char="5806">are</TOKEN>
<TOKEN id="token-51-16" pos="word" morph="none" start_char="5808" end_char="5814">watered</TOKEN>
<TOKEN id="token-51-17" pos="word" morph="none" start_char="5816" end_char="5819">down</TOKEN>
<TOKEN id="token-51-18" pos="word" morph="none" start_char="5821" end_char="5823">and</TOKEN>
<TOKEN id="token-51-19" pos="word" morph="none" start_char="5825" end_char="5827">the</TOKEN>
<TOKEN id="token-51-20" pos="word" morph="none" start_char="5829" end_char="5832">data</TOKEN>
<TOKEN id="token-51-21" pos="word" morph="none" start_char="5834" end_char="5835">no</TOKEN>
<TOKEN id="token-51-22" pos="word" morph="none" start_char="5837" end_char="5842">longer</TOKEN>
<TOKEN id="token-51-23" pos="word" morph="none" start_char="5844" end_char="5848">shows</TOKEN>
<TOKEN id="token-51-24" pos="word" morph="none" start_char="5850" end_char="5860">statistical</TOKEN>
<TOKEN id="token-51-25" pos="word" morph="none" start_char="5862" end_char="5873">significance</TOKEN>
<TOKEN id="token-51-26" pos="punct" morph="none" start_char="5874" end_char="5874">.</TOKEN>
</SEG>
<SEG id="segment-52" start_char="5876" end_char="6023">
<ORIGINAL_TEXT>As a result the FDA raises red flags and informs the medical community to tap the breaks and is now requesting a another study with a control group.</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="5876" end_char="5877">As</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="5879" end_char="5879">a</TOKEN>
<TOKEN id="token-52-2" pos="word" morph="none" start_char="5881" end_char="5886">result</TOKEN>
<TOKEN id="token-52-3" pos="word" morph="none" start_char="5888" end_char="5890">the</TOKEN>
<TOKEN id="token-52-4" pos="word" morph="none" start_char="5892" end_char="5894">FDA</TOKEN>
<TOKEN id="token-52-5" pos="word" morph="none" start_char="5896" end_char="5901">raises</TOKEN>
<TOKEN id="token-52-6" pos="word" morph="none" start_char="5903" end_char="5905">red</TOKEN>
<TOKEN id="token-52-7" pos="word" morph="none" start_char="5907" end_char="5911">flags</TOKEN>
<TOKEN id="token-52-8" pos="word" morph="none" start_char="5913" end_char="5915">and</TOKEN>
<TOKEN id="token-52-9" pos="word" morph="none" start_char="5917" end_char="5923">informs</TOKEN>
<TOKEN id="token-52-10" pos="word" morph="none" start_char="5925" end_char="5927">the</TOKEN>
<TOKEN id="token-52-11" pos="word" morph="none" start_char="5929" end_char="5935">medical</TOKEN>
<TOKEN id="token-52-12" pos="word" morph="none" start_char="5937" end_char="5945">community</TOKEN>
<TOKEN id="token-52-13" pos="word" morph="none" start_char="5947" end_char="5948">to</TOKEN>
<TOKEN id="token-52-14" pos="word" morph="none" start_char="5950" end_char="5952">tap</TOKEN>
<TOKEN id="token-52-15" pos="word" morph="none" start_char="5954" end_char="5956">the</TOKEN>
<TOKEN id="token-52-16" pos="word" morph="none" start_char="5958" end_char="5963">breaks</TOKEN>
<TOKEN id="token-52-17" pos="word" morph="none" start_char="5965" end_char="5967">and</TOKEN>
<TOKEN id="token-52-18" pos="word" morph="none" start_char="5969" end_char="5970">is</TOKEN>
<TOKEN id="token-52-19" pos="word" morph="none" start_char="5972" end_char="5974">now</TOKEN>
<TOKEN id="token-52-20" pos="word" morph="none" start_char="5976" end_char="5985">requesting</TOKEN>
<TOKEN id="token-52-21" pos="word" morph="none" start_char="5987" end_char="5987">a</TOKEN>
<TOKEN id="token-52-22" pos="word" morph="none" start_char="5989" end_char="5995">another</TOKEN>
<TOKEN id="token-52-23" pos="word" morph="none" start_char="5997" end_char="6001">study</TOKEN>
<TOKEN id="token-52-24" pos="word" morph="none" start_char="6003" end_char="6006">with</TOKEN>
<TOKEN id="token-52-25" pos="word" morph="none" start_char="6008" end_char="6008">a</TOKEN>
<TOKEN id="token-52-26" pos="word" morph="none" start_char="6010" end_char="6016">control</TOKEN>
<TOKEN id="token-52-27" pos="word" morph="none" start_char="6018" end_char="6022">group</TOKEN>
<TOKEN id="token-52-28" pos="punct" morph="none" start_char="6023" end_char="6023">.</TOKEN>
</SEG>
<SEG id="segment-53" start_char="6026" end_char="6090">
<ORIGINAL_TEXT>Wow, I don't see how all of this isn't obvious to these eggheads!</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="word" morph="none" start_char="6026" end_char="6028">Wow</TOKEN>
<TOKEN id="token-53-1" pos="punct" morph="none" start_char="6029" end_char="6029">,</TOKEN>
<TOKEN id="token-53-2" pos="word" morph="none" start_char="6031" end_char="6031">I</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="6033" end_char="6037">don't</TOKEN>
<TOKEN id="token-53-4" pos="word" morph="none" start_char="6039" end_char="6041">see</TOKEN>
<TOKEN id="token-53-5" pos="word" morph="none" start_char="6043" end_char="6045">how</TOKEN>
<TOKEN id="token-53-6" pos="word" morph="none" start_char="6047" end_char="6049">all</TOKEN>
<TOKEN id="token-53-7" pos="word" morph="none" start_char="6051" end_char="6052">of</TOKEN>
<TOKEN id="token-53-8" pos="word" morph="none" start_char="6054" end_char="6057">this</TOKEN>
<TOKEN id="token-53-9" pos="word" morph="none" start_char="6059" end_char="6063">isn't</TOKEN>
<TOKEN id="token-53-10" pos="word" morph="none" start_char="6065" end_char="6071">obvious</TOKEN>
<TOKEN id="token-53-11" pos="word" morph="none" start_char="6073" end_char="6074">to</TOKEN>
<TOKEN id="token-53-12" pos="word" morph="none" start_char="6076" end_char="6080">these</TOKEN>
<TOKEN id="token-53-13" pos="word" morph="none" start_char="6082" end_char="6089">eggheads</TOKEN>
<TOKEN id="token-53-14" pos="punct" morph="none" start_char="6090" end_char="6090">!</TOKEN>
</SEG>
<SEG id="segment-54" start_char="6092" end_char="6193">
<ORIGINAL_TEXT>At worst convalescent plasma does no harm and has been shown to be beneficial when administered early.</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="word" morph="none" start_char="6092" end_char="6093">At</TOKEN>
<TOKEN id="token-54-1" pos="word" morph="none" start_char="6095" end_char="6099">worst</TOKEN>
<TOKEN id="token-54-2" pos="word" morph="none" start_char="6101" end_char="6112">convalescent</TOKEN>
<TOKEN id="token-54-3" pos="word" morph="none" start_char="6114" end_char="6119">plasma</TOKEN>
<TOKEN id="token-54-4" pos="word" morph="none" start_char="6121" end_char="6124">does</TOKEN>
<TOKEN id="token-54-5" pos="word" morph="none" start_char="6126" end_char="6127">no</TOKEN>
<TOKEN id="token-54-6" pos="word" morph="none" start_char="6129" end_char="6132">harm</TOKEN>
<TOKEN id="token-54-7" pos="word" morph="none" start_char="6134" end_char="6136">and</TOKEN>
<TOKEN id="token-54-8" pos="word" morph="none" start_char="6138" end_char="6140">has</TOKEN>
<TOKEN id="token-54-9" pos="word" morph="none" start_char="6142" end_char="6145">been</TOKEN>
<TOKEN id="token-54-10" pos="word" morph="none" start_char="6147" end_char="6151">shown</TOKEN>
<TOKEN id="token-54-11" pos="word" morph="none" start_char="6153" end_char="6154">to</TOKEN>
<TOKEN id="token-54-12" pos="word" morph="none" start_char="6156" end_char="6157">be</TOKEN>
<TOKEN id="token-54-13" pos="word" morph="none" start_char="6159" end_char="6168">beneficial</TOKEN>
<TOKEN id="token-54-14" pos="word" morph="none" start_char="6170" end_char="6173">when</TOKEN>
<TOKEN id="token-54-15" pos="word" morph="none" start_char="6175" end_char="6186">administered</TOKEN>
<TOKEN id="token-54-16" pos="word" morph="none" start_char="6188" end_char="6192">early</TOKEN>
<TOKEN id="token-54-17" pos="punct" morph="none" start_char="6193" end_char="6193">.</TOKEN>
</SEG>
<SEG id="segment-55" start_char="6195" end_char="6233">
<ORIGINAL_TEXT>Do these guys chew on lead paint chips?</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="word" morph="none" start_char="6195" end_char="6196">Do</TOKEN>
<TOKEN id="token-55-1" pos="word" morph="none" start_char="6198" end_char="6202">these</TOKEN>
<TOKEN id="token-55-2" pos="word" morph="none" start_char="6204" end_char="6207">guys</TOKEN>
<TOKEN id="token-55-3" pos="word" morph="none" start_char="6209" end_char="6212">chew</TOKEN>
<TOKEN id="token-55-4" pos="word" morph="none" start_char="6214" end_char="6215">on</TOKEN>
<TOKEN id="token-55-5" pos="word" morph="none" start_char="6217" end_char="6220">lead</TOKEN>
<TOKEN id="token-55-6" pos="word" morph="none" start_char="6222" end_char="6226">paint</TOKEN>
<TOKEN id="token-55-7" pos="word" morph="none" start_char="6228" end_char="6232">chips</TOKEN>
<TOKEN id="token-55-8" pos="punct" morph="none" start_char="6233" end_char="6233">?</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
