<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C049DY5" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="2592" raw_text_md5="04a790fa18efab79f404bf0b0d833e70">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="42">
<ORIGINAL_TEXT>insertar en un coronavirus genes del VIH-1</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="8">insertar</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="10" end_char="11">en</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="13" end_char="14">un</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="16" end_char="26">coronavirus</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="28" end_char="32">genes</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="34" end_char="36">del</TOKEN>
<TOKEN id="token-0-6" pos="unknown" morph="none" start_char="38" end_char="42">VIH-1</TOKEN>
</SEG>
<SEG id="segment-1" start_char="46" end_char="176">
<ORIGINAL_TEXT>La interrogante sobre el origen del coronavirus que desató una nueva pandemia mantiene en alerta a la comunidad científica mundial.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="46" end_char="47">La</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="49" end_char="60">interrogante</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="62" end_char="66">sobre</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="68" end_char="69">el</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="71" end_char="76">origen</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="78" end_char="80">del</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="82" end_char="92">coronavirus</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="94" end_char="96">que</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="98" end_char="103">desató</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="105" end_char="107">una</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="109" end_char="113">nueva</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="115" end_char="122">pandemia</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="124" end_char="131">mantiene</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="133" end_char="134">en</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="136" end_char="141">alerta</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="143" end_char="143">a</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="145" end_char="146">la</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="148" end_char="156">comunidad</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="158" end_char="167">científica</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="169" end_char="175">mundial</TOKEN>
<TOKEN id="token-1-20" pos="punct" morph="none" start_char="176" end_char="176">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="179" end_char="380">
<ORIGINAL_TEXT>El científico francés Luc Montagnier -quien se alzó en el 2008 con un Premio Nobel de Medicina por descubrir el VIH- planteó la polémica hipótesis de que el virus habría sido 'creado en un laboratorio'.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="179" end_char="180">El</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="182" end_char="191">científico</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="193" end_char="199">francés</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="201" end_char="203">Luc</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="205" end_char="214">Montagnier</TOKEN>
<TOKEN id="token-2-5" pos="punct" morph="none" start_char="216" end_char="216">-</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="217" end_char="221">quien</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="223" end_char="224">se</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="226" end_char="229">alzó</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="231" end_char="232">en</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="234" end_char="235">el</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="237" end_char="240">2008</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="242" end_char="244">con</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="246" end_char="247">un</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="249" end_char="254">Premio</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="256" end_char="260">Nobel</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="262" end_char="263">de</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="265" end_char="272">Medicina</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="274" end_char="276">por</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="278" end_char="286">descubrir</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="288" end_char="289">el</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="291" end_char="293">VIH</TOKEN>
<TOKEN id="token-2-22" pos="punct" morph="none" start_char="294" end_char="294">-</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="296" end_char="302">planteó</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="304" end_char="305">la</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="307" end_char="314">polémica</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="316" end_char="324">hipótesis</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="326" end_char="327">de</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="329" end_char="331">que</TOKEN>
<TOKEN id="token-2-29" pos="word" morph="none" start_char="333" end_char="334">el</TOKEN>
<TOKEN id="token-2-30" pos="word" morph="none" start_char="336" end_char="340">virus</TOKEN>
<TOKEN id="token-2-31" pos="word" morph="none" start_char="342" end_char="347">habría</TOKEN>
<TOKEN id="token-2-32" pos="word" morph="none" start_char="349" end_char="352">sido</TOKEN>
<TOKEN id="token-2-33" pos="punct" morph="none" start_char="354" end_char="354">'</TOKEN>
<TOKEN id="token-2-34" pos="word" morph="none" start_char="355" end_char="360">creado</TOKEN>
<TOKEN id="token-2-35" pos="word" morph="none" start_char="362" end_char="363">en</TOKEN>
<TOKEN id="token-2-36" pos="word" morph="none" start_char="365" end_char="366">un</TOKEN>
<TOKEN id="token-2-37" pos="word" morph="none" start_char="368" end_char="378">laboratorio</TOKEN>
<TOKEN id="token-2-38" pos="punct" morph="none" start_char="379" end_char="380">'.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="383" end_char="645">
<ORIGINAL_TEXT>Durante un diálogo con el medio de comunicación francés CNews, que data del 17 de abril, Montagnier señaló que no cree que el covid-19 se haya originado en el mercado de Wuhan, en China: "El virus está saliendo accidentalmente de un laboratorio de Wuhan", afirmó.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="383" end_char="389">Durante</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="391" end_char="392">un</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="394" end_char="400">diálogo</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="402" end_char="404">con</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="406" end_char="407">el</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="409" end_char="413">medio</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="415" end_char="416">de</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="418" end_char="429">comunicación</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="431" end_char="437">francés</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="439" end_char="443">CNews</TOKEN>
<TOKEN id="token-3-10" pos="punct" morph="none" start_char="444" end_char="444">,</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="446" end_char="448">que</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="450" end_char="453">data</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="455" end_char="457">del</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="459" end_char="460">17</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="462" end_char="463">de</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="465" end_char="469">abril</TOKEN>
<TOKEN id="token-3-17" pos="punct" morph="none" start_char="470" end_char="470">,</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="472" end_char="481">Montagnier</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="483" end_char="488">señaló</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="490" end_char="492">que</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="494" end_char="495">no</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="497" end_char="500">cree</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="502" end_char="504">que</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="506" end_char="507">el</TOKEN>
<TOKEN id="token-3-25" pos="unknown" morph="none" start_char="509" end_char="516">covid-19</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="518" end_char="519">se</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="521" end_char="524">haya</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="526" end_char="534">originado</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="536" end_char="537">en</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="539" end_char="540">el</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="542" end_char="548">mercado</TOKEN>
<TOKEN id="token-3-32" pos="word" morph="none" start_char="550" end_char="551">de</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="553" end_char="557">Wuhan</TOKEN>
<TOKEN id="token-3-34" pos="punct" morph="none" start_char="558" end_char="558">,</TOKEN>
<TOKEN id="token-3-35" pos="word" morph="none" start_char="560" end_char="561">en</TOKEN>
<TOKEN id="token-3-36" pos="word" morph="none" start_char="563" end_char="567">China</TOKEN>
<TOKEN id="token-3-37" pos="punct" morph="none" start_char="568" end_char="568">:</TOKEN>
<TOKEN id="token-3-38" pos="punct" morph="none" start_char="570" end_char="570">"</TOKEN>
<TOKEN id="token-3-39" pos="word" morph="none" start_char="571" end_char="572">El</TOKEN>
<TOKEN id="token-3-40" pos="word" morph="none" start_char="574" end_char="578">virus</TOKEN>
<TOKEN id="token-3-41" pos="word" morph="none" start_char="580" end_char="583">está</TOKEN>
<TOKEN id="token-3-42" pos="word" morph="none" start_char="585" end_char="592">saliendo</TOKEN>
<TOKEN id="token-3-43" pos="word" morph="none" start_char="594" end_char="608">accidentalmente</TOKEN>
<TOKEN id="token-3-44" pos="word" morph="none" start_char="610" end_char="611">de</TOKEN>
<TOKEN id="token-3-45" pos="word" morph="none" start_char="613" end_char="614">un</TOKEN>
<TOKEN id="token-3-46" pos="word" morph="none" start_char="616" end_char="626">laboratorio</TOKEN>
<TOKEN id="token-3-47" pos="word" morph="none" start_char="628" end_char="629">de</TOKEN>
<TOKEN id="token-3-48" pos="word" morph="none" start_char="631" end_char="635">Wuhan</TOKEN>
<TOKEN id="token-3-49" pos="punct" morph="none" start_char="636" end_char="637">",</TOKEN>
<TOKEN id="token-3-50" pos="word" morph="none" start_char="639" end_char="644">afirmó</TOKEN>
<TOKEN id="token-3-51" pos="punct" morph="none" start_char="645" end_char="645">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="648" end_char="794">
<ORIGINAL_TEXT>De acuerdo con el científico, "el laboratorio de la ciudad de Wuhan se ha especializado en estos coronavirus desde principios de la década de 2000.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="648" end_char="649">De</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="651" end_char="657">acuerdo</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="659" end_char="661">con</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="663" end_char="664">el</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="666" end_char="675">científico</TOKEN>
<TOKEN id="token-4-5" pos="punct" morph="none" start_char="676" end_char="676">,</TOKEN>
<TOKEN id="token-4-6" pos="punct" morph="none" start_char="678" end_char="678">"</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="679" end_char="680">el</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="682" end_char="692">laboratorio</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="694" end_char="695">de</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="697" end_char="698">la</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="700" end_char="705">ciudad</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="707" end_char="708">de</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="710" end_char="714">Wuhan</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="716" end_char="717">se</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="719" end_char="720">ha</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="722" end_char="734">especializado</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="736" end_char="737">en</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="739" end_char="743">estos</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="745" end_char="755">coronavirus</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="757" end_char="761">desde</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="763" end_char="772">principios</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="774" end_char="775">de</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="777" end_char="778">la</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="780" end_char="785">década</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="787" end_char="788">de</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="790" end_char="793">2000</TOKEN>
<TOKEN id="token-4-27" pos="punct" morph="none" start_char="794" end_char="794">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="796" end_char="821">
<ORIGINAL_TEXT>Tienen experiencia", dijo.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="796" end_char="801">Tienen</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="803" end_char="813">experiencia</TOKEN>
<TOKEN id="token-5-2" pos="punct" morph="none" start_char="814" end_char="815">",</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="817" end_char="820">dijo</TOKEN>
<TOKEN id="token-5-4" pos="punct" morph="none" start_char="821" end_char="821">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="824" end_char="878">
<ORIGINAL_TEXT>El premio Nobel asegura que el virus tiene genes de VIH</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="824" end_char="825">El</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="827" end_char="832">premio</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="834" end_char="838">Nobel</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="840" end_char="846">asegura</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="848" end_char="850">que</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="852" end_char="853">el</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="855" end_char="859">virus</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="861" end_char="865">tiene</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="867" end_char="871">genes</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="873" end_char="874">de</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="876" end_char="878">VIH</TOKEN>
</SEG>
<SEG id="segment-7" start_char="882" end_char="1127">
<ORIGINAL_TEXT>Tras un análisis realizado en colaboración con el académico matemático Jean-Claude Perrez, Montaigner planteó que el virus SARS-CoV-2, que causa la enfermedad covid-19, fue diseñada en un laboratorio al insertar en un coronavirus genes del VIH-1.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="882" end_char="885">Tras</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="887" end_char="888">un</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="890" end_char="897">análisis</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="899" end_char="907">realizado</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="909" end_char="910">en</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="912" end_char="923">colaboración</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="925" end_char="927">con</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="929" end_char="930">el</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="932" end_char="940">académico</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="942" end_char="951">matemático</TOKEN>
<TOKEN id="token-7-10" pos="unknown" morph="none" start_char="953" end_char="963">Jean-Claude</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="965" end_char="970">Perrez</TOKEN>
<TOKEN id="token-7-12" pos="punct" morph="none" start_char="971" end_char="971">,</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="973" end_char="982">Montaigner</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="984" end_char="990">planteó</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="992" end_char="994">que</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="996" end_char="997">el</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="999" end_char="1003">virus</TOKEN>
<TOKEN id="token-7-18" pos="unknown" morph="none" start_char="1005" end_char="1014">SARS-CoV-2</TOKEN>
<TOKEN id="token-7-19" pos="punct" morph="none" start_char="1015" end_char="1015">,</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="1017" end_char="1019">que</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="1021" end_char="1025">causa</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="1027" end_char="1028">la</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="1030" end_char="1039">enfermedad</TOKEN>
<TOKEN id="token-7-24" pos="unknown" morph="none" start_char="1041" end_char="1048">covid-19</TOKEN>
<TOKEN id="token-7-25" pos="punct" morph="none" start_char="1049" end_char="1049">,</TOKEN>
<TOKEN id="token-7-26" pos="word" morph="none" start_char="1051" end_char="1053">fue</TOKEN>
<TOKEN id="token-7-27" pos="word" morph="none" start_char="1055" end_char="1062">diseñada</TOKEN>
<TOKEN id="token-7-28" pos="word" morph="none" start_char="1064" end_char="1065">en</TOKEN>
<TOKEN id="token-7-29" pos="word" morph="none" start_char="1067" end_char="1068">un</TOKEN>
<TOKEN id="token-7-30" pos="word" morph="none" start_char="1070" end_char="1080">laboratorio</TOKEN>
<TOKEN id="token-7-31" pos="word" morph="none" start_char="1082" end_char="1083">al</TOKEN>
<TOKEN id="token-7-32" pos="word" morph="none" start_char="1085" end_char="1092">insertar</TOKEN>
<TOKEN id="token-7-33" pos="word" morph="none" start_char="1094" end_char="1095">en</TOKEN>
<TOKEN id="token-7-34" pos="word" morph="none" start_char="1097" end_char="1098">un</TOKEN>
<TOKEN id="token-7-35" pos="word" morph="none" start_char="1100" end_char="1110">coronavirus</TOKEN>
<TOKEN id="token-7-36" pos="word" morph="none" start_char="1112" end_char="1116">genes</TOKEN>
<TOKEN id="token-7-37" pos="word" morph="none" start_char="1118" end_char="1120">del</TOKEN>
<TOKEN id="token-7-38" pos="unknown" morph="none" start_char="1122" end_char="1126">VIH-1</TOKEN>
<TOKEN id="token-7-39" pos="punct" morph="none" start_char="1127" end_char="1127">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1129" end_char="1156">
<ORIGINAL_TEXT>Es decir, el virus del SIDA.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1129" end_char="1130">Es</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1132" end_char="1136">decir</TOKEN>
<TOKEN id="token-8-2" pos="punct" morph="none" start_char="1137" end_char="1137">,</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1139" end_char="1140">el</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1142" end_char="1146">virus</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1148" end_char="1150">del</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1152" end_char="1155">SIDA</TOKEN>
<TOKEN id="token-8-7" pos="punct" morph="none" start_char="1156" end_char="1156">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1159" end_char="1260">
<ORIGINAL_TEXT>Según el polémico especialista, "hubo una manipulación del virus: al menos una parte, no la totalidad.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1159" end_char="1163">Según</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1165" end_char="1166">el</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1168" end_char="1175">polémico</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1177" end_char="1188">especialista</TOKEN>
<TOKEN id="token-9-4" pos="punct" morph="none" start_char="1189" end_char="1189">,</TOKEN>
<TOKEN id="token-9-5" pos="punct" morph="none" start_char="1191" end_char="1191">"</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1192" end_char="1195">hubo</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1197" end_char="1199">una</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1201" end_char="1212">manipulación</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1214" end_char="1216">del</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1218" end_char="1222">virus</TOKEN>
<TOKEN id="token-9-11" pos="punct" morph="none" start_char="1223" end_char="1223">:</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1225" end_char="1226">al</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1228" end_char="1232">menos</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1234" end_char="1236">una</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1238" end_char="1242">parte</TOKEN>
<TOKEN id="token-9-16" pos="punct" morph="none" start_char="1243" end_char="1243">,</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1245" end_char="1246">no</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1248" end_char="1249">la</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1251" end_char="1259">totalidad</TOKEN>
<TOKEN id="token-9-20" pos="punct" morph="none" start_char="1260" end_char="1260">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1262" end_char="1409">
<ORIGINAL_TEXT>Existió un modelo, que es el virus clásico, que proviene principalmente de los murciélagos, pero al que se han agregado secuencias de VIH", aseguró.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1262" end_char="1268">Existió</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1270" end_char="1271">un</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1273" end_char="1278">modelo</TOKEN>
<TOKEN id="token-10-3" pos="punct" morph="none" start_char="1279" end_char="1279">,</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1281" end_char="1283">que</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1285" end_char="1286">es</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1288" end_char="1289">el</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1291" end_char="1295">virus</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1297" end_char="1303">clásico</TOKEN>
<TOKEN id="token-10-9" pos="punct" morph="none" start_char="1304" end_char="1304">,</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1306" end_char="1308">que</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1310" end_char="1317">proviene</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1319" end_char="1332">principalmente</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1334" end_char="1335">de</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1337" end_char="1339">los</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1341" end_char="1351">murciélagos</TOKEN>
<TOKEN id="token-10-16" pos="punct" morph="none" start_char="1352" end_char="1352">,</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1354" end_char="1357">pero</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1359" end_char="1360">al</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1362" end_char="1364">que</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1366" end_char="1367">se</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1369" end_char="1371">han</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1373" end_char="1380">agregado</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1382" end_char="1391">secuencias</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1393" end_char="1394">de</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="1396" end_char="1398">VIH</TOKEN>
<TOKEN id="token-10-26" pos="punct" morph="none" start_char="1399" end_char="1400">",</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="1402" end_char="1408">aseguró</TOKEN>
<TOKEN id="token-10-28" pos="punct" morph="none" start_char="1409" end_char="1409">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1412" end_char="1568">
<ORIGINAL_TEXT>Después de lanzar su hipótesis, el ganador del Premio Nobel añadió que la supuesta creación del virus "es la labor de profesionales, de biólogos moleculares.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1412" end_char="1418">Después</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1420" end_char="1421">de</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1423" end_char="1428">lanzar</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1430" end_char="1431">su</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1433" end_char="1441">hipótesis</TOKEN>
<TOKEN id="token-11-5" pos="punct" morph="none" start_char="1442" end_char="1442">,</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1444" end_char="1445">el</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1447" end_char="1453">ganador</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1455" end_char="1457">del</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1459" end_char="1464">Premio</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1466" end_char="1470">Nobel</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1472" end_char="1477">añadió</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1479" end_char="1481">que</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1483" end_char="1484">la</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1486" end_char="1493">supuesta</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1495" end_char="1502">creación</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1504" end_char="1506">del</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1508" end_char="1512">virus</TOKEN>
<TOKEN id="token-11-18" pos="punct" morph="none" start_char="1514" end_char="1514">"</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="1515" end_char="1516">es</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1518" end_char="1519">la</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="1521" end_char="1525">labor</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="1527" end_char="1528">de</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="1530" end_char="1542">profesionales</TOKEN>
<TOKEN id="token-11-24" pos="punct" morph="none" start_char="1543" end_char="1543">,</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="1545" end_char="1546">de</TOKEN>
<TOKEN id="token-11-26" pos="word" morph="none" start_char="1548" end_char="1555">biólogos</TOKEN>
<TOKEN id="token-11-27" pos="word" morph="none" start_char="1557" end_char="1567">moleculares</TOKEN>
<TOKEN id="token-11-28" pos="punct" morph="none" start_char="1568" end_char="1568">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1570" end_char="1612">
<ORIGINAL_TEXT>Un trabajo muy laborioso ¿Con qué objetivo?</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1570" end_char="1571">Un</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1573" end_char="1579">trabajo</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1581" end_char="1583">muy</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1585" end_char="1593">laborioso</TOKEN>
<TOKEN id="token-12-4" pos="punct" morph="none" start_char="1595" end_char="1595">¿</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1596" end_char="1598">Con</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1600" end_char="1602">qué</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1604" end_char="1611">objetivo</TOKEN>
<TOKEN id="token-12-8" pos="punct" morph="none" start_char="1612" end_char="1612">?</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1614" end_char="1622">
<ORIGINAL_TEXT>No lo sé.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1614" end_char="1615">No</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1617" end_char="1618">lo</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1620" end_char="1621">sé</TOKEN>
<TOKEN id="token-13-3" pos="punct" morph="none" start_char="1622" end_char="1622">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1624" end_char="1726">
<ORIGINAL_TEXT>Una hipótesis es que querían crear una vacuna contra el Síndrome de Inmunodeficiencia Adquirida", dijo.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1624" end_char="1626">Una</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1628" end_char="1636">hipótesis</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1638" end_char="1639">es</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1641" end_char="1643">que</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1645" end_char="1651">querían</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1653" end_char="1657">crear</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1659" end_char="1661">una</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1663" end_char="1668">vacuna</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1670" end_char="1675">contra</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1677" end_char="1678">el</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1680" end_char="1687">Síndrome</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1689" end_char="1690">de</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1692" end_char="1708">Inmunodeficiencia</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1710" end_char="1718">Adquirida</TOKEN>
<TOKEN id="token-14-14" pos="punct" morph="none" start_char="1719" end_char="1720">",</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1722" end_char="1725">dijo</TOKEN>
<TOKEN id="token-14-16" pos="punct" morph="none" start_char="1726" end_char="1726">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1729" end_char="1783">
<ORIGINAL_TEXT>Montagnier "descubrió el VIH y recibió el Nobel en 2008</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1729" end_char="1738">Montagnier</TOKEN>
<TOKEN id="token-15-1" pos="punct" morph="none" start_char="1740" end_char="1740">"</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1741" end_char="1749">descubrió</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1751" end_char="1752">el</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1754" end_char="1756">VIH</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1758" end_char="1758">y</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1760" end_char="1766">recibió</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1768" end_char="1769">el</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1771" end_char="1775">Nobel</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1777" end_char="1778">en</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1780" end_char="1783">2008</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1787" end_char="1941">
<ORIGINAL_TEXT>La teoría de Montagnier -según su testimonio- partió de un estudio académico desarrollado por científicos del Instituto Indio de Tecnología de Nueva Delhi.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1787" end_char="1788">La</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1790" end_char="1795">teoría</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1797" end_char="1798">de</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1800" end_char="1809">Montagnier</TOKEN>
<TOKEN id="token-16-4" pos="punct" morph="none" start_char="1811" end_char="1811">-</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1812" end_char="1816">según</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1818" end_char="1819">su</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1821" end_char="1830">testimonio</TOKEN>
<TOKEN id="token-16-8" pos="punct" morph="none" start_char="1831" end_char="1831">-</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="1833" end_char="1838">partió</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="1840" end_char="1841">de</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="1843" end_char="1844">un</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="1846" end_char="1852">estudio</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="1854" end_char="1862">académico</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="1864" end_char="1875">desarrollado</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="1877" end_char="1879">por</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="1881" end_char="1891">científicos</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="1893" end_char="1895">del</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="1897" end_char="1905">Instituto</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="1907" end_char="1911">Indio</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="1913" end_char="1914">de</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="1916" end_char="1925">Tecnología</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="1927" end_char="1928">de</TOKEN>
<TOKEN id="token-16-23" pos="word" morph="none" start_char="1930" end_char="1934">Nueva</TOKEN>
<TOKEN id="token-16-24" pos="word" morph="none" start_char="1936" end_char="1940">Delhi</TOKEN>
<TOKEN id="token-16-25" pos="punct" morph="none" start_char="1941" end_char="1941">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1943" end_char="2110">
<ORIGINAL_TEXT>Los especialistas encontraron un inusual parecido en las "secuencias de aminoácidos de una proteína de SARS-CoV-2 y el de VIH-1", según detallaban en su plataforma web.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1943" end_char="1945">Los</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1947" end_char="1959">especialistas</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="1961" end_char="1971">encontraron</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="1973" end_char="1974">un</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="1976" end_char="1982">inusual</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="1984" end_char="1991">parecido</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="1993" end_char="1994">en</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="1996" end_char="1998">las</TOKEN>
<TOKEN id="token-17-8" pos="punct" morph="none" start_char="2000" end_char="2000">"</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2001" end_char="2010">secuencias</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2012" end_char="2013">de</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2015" end_char="2025">aminoácidos</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2027" end_char="2028">de</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2030" end_char="2032">una</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2034" end_char="2041">proteína</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2043" end_char="2044">de</TOKEN>
<TOKEN id="token-17-16" pos="unknown" morph="none" start_char="2046" end_char="2055">SARS-CoV-2</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="2057" end_char="2057">y</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="2059" end_char="2060">el</TOKEN>
<TOKEN id="token-17-19" pos="word" morph="none" start_char="2062" end_char="2063">de</TOKEN>
<TOKEN id="token-17-20" pos="unknown" morph="none" start_char="2065" end_char="2069">VIH-1</TOKEN>
<TOKEN id="token-17-21" pos="punct" morph="none" start_char="2070" end_char="2071">",</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="2073" end_char="2077">según</TOKEN>
<TOKEN id="token-17-23" pos="word" morph="none" start_char="2079" end_char="2088">detallaban</TOKEN>
<TOKEN id="token-17-24" pos="word" morph="none" start_char="2090" end_char="2091">en</TOKEN>
<TOKEN id="token-17-25" pos="word" morph="none" start_char="2093" end_char="2094">su</TOKEN>
<TOKEN id="token-17-26" pos="word" morph="none" start_char="2096" end_char="2105">plataforma</TOKEN>
<TOKEN id="token-17-27" pos="word" morph="none" start_char="2107" end_char="2109">web</TOKEN>
<TOKEN id="token-17-28" pos="punct" morph="none" start_char="2110" end_char="2110">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2113" end_char="2234">
<ORIGINAL_TEXT>Sin embargo, no fue avalado o verificado por expertos internacionales, por lo que el estudio fue retirado por sus autores.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2113" end_char="2115">Sin</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2117" end_char="2123">embargo</TOKEN>
<TOKEN id="token-18-2" pos="punct" morph="none" start_char="2124" end_char="2124">,</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2126" end_char="2127">no</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2129" end_char="2131">fue</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2133" end_char="2139">avalado</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2141" end_char="2141">o</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2143" end_char="2152">verificado</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2154" end_char="2156">por</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="2158" end_char="2165">expertos</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="2167" end_char="2181">internacionales</TOKEN>
<TOKEN id="token-18-11" pos="punct" morph="none" start_char="2182" end_char="2182">,</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2184" end_char="2186">por</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="2188" end_char="2189">lo</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="2191" end_char="2193">que</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="2195" end_char="2196">el</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="2198" end_char="2204">estudio</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="2206" end_char="2208">fue</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="2210" end_char="2217">retirado</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="2219" end_char="2221">por</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="2223" end_char="2225">sus</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="2227" end_char="2233">autores</TOKEN>
<TOKEN id="token-18-22" pos="punct" morph="none" start_char="2234" end_char="2234">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2237" end_char="2428">
<ORIGINAL_TEXT>Sin embargo, Montagnier pronosticó la desaparición del virus: "Uno puede hacer cualquier cosa con la naturaleza, pero si usted hace una construcción artificial, es poco probable que sobreviva.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2237" end_char="2239">Sin</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2241" end_char="2247">embargo</TOKEN>
<TOKEN id="token-19-2" pos="punct" morph="none" start_char="2248" end_char="2248">,</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2250" end_char="2259">Montagnier</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2261" end_char="2270">pronosticó</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2272" end_char="2273">la</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2275" end_char="2286">desaparición</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2288" end_char="2290">del</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2292" end_char="2296">virus</TOKEN>
<TOKEN id="token-19-9" pos="punct" morph="none" start_char="2297" end_char="2297">:</TOKEN>
<TOKEN id="token-19-10" pos="punct" morph="none" start_char="2299" end_char="2299">"</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="2300" end_char="2302">Uno</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="2304" end_char="2308">puede</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="2310" end_char="2314">hacer</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="2316" end_char="2324">cualquier</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="2326" end_char="2329">cosa</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="2331" end_char="2333">con</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="2335" end_char="2336">la</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="2338" end_char="2347">naturaleza</TOKEN>
<TOKEN id="token-19-19" pos="punct" morph="none" start_char="2348" end_char="2348">,</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="2350" end_char="2353">pero</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="2355" end_char="2356">si</TOKEN>
<TOKEN id="token-19-22" pos="word" morph="none" start_char="2358" end_char="2362">usted</TOKEN>
<TOKEN id="token-19-23" pos="word" morph="none" start_char="2364" end_char="2367">hace</TOKEN>
<TOKEN id="token-19-24" pos="word" morph="none" start_char="2369" end_char="2371">una</TOKEN>
<TOKEN id="token-19-25" pos="word" morph="none" start_char="2373" end_char="2384">construcción</TOKEN>
<TOKEN id="token-19-26" pos="word" morph="none" start_char="2386" end_char="2395">artificial</TOKEN>
<TOKEN id="token-19-27" pos="punct" morph="none" start_char="2396" end_char="2396">,</TOKEN>
<TOKEN id="token-19-28" pos="word" morph="none" start_char="2398" end_char="2399">es</TOKEN>
<TOKEN id="token-19-29" pos="word" morph="none" start_char="2401" end_char="2404">poco</TOKEN>
<TOKEN id="token-19-30" pos="word" morph="none" start_char="2406" end_char="2413">probable</TOKEN>
<TOKEN id="token-19-31" pos="word" morph="none" start_char="2415" end_char="2417">que</TOKEN>
<TOKEN id="token-19-32" pos="word" morph="none" start_char="2419" end_char="2427">sobreviva</TOKEN>
<TOKEN id="token-19-33" pos="punct" morph="none" start_char="2428" end_char="2428">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2430" end_char="2568">
<ORIGINAL_TEXT>La naturaleza ama las cosas armoniosas; lo que es ajeno, como un virus que llega de otro virus, por ejemplo, no es bien tolerado", sostuvo.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2430" end_char="2431">La</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2433" end_char="2442">naturaleza</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2444" end_char="2446">ama</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2448" end_char="2450">las</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2452" end_char="2456">cosas</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2458" end_char="2467">armoniosas</TOKEN>
<TOKEN id="token-20-6" pos="punct" morph="none" start_char="2468" end_char="2468">;</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2470" end_char="2471">lo</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="2473" end_char="2475">que</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2477" end_char="2478">es</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2480" end_char="2484">ajeno</TOKEN>
<TOKEN id="token-20-11" pos="punct" morph="none" start_char="2485" end_char="2485">,</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="2487" end_char="2490">como</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="2492" end_char="2493">un</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="2495" end_char="2499">virus</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="2501" end_char="2503">que</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="2505" end_char="2509">llega</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="2511" end_char="2512">de</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="2514" end_char="2517">otro</TOKEN>
<TOKEN id="token-20-19" pos="word" morph="none" start_char="2519" end_char="2523">virus</TOKEN>
<TOKEN id="token-20-20" pos="punct" morph="none" start_char="2524" end_char="2524">,</TOKEN>
<TOKEN id="token-20-21" pos="word" morph="none" start_char="2526" end_char="2528">por</TOKEN>
<TOKEN id="token-20-22" pos="word" morph="none" start_char="2530" end_char="2536">ejemplo</TOKEN>
<TOKEN id="token-20-23" pos="punct" morph="none" start_char="2537" end_char="2537">,</TOKEN>
<TOKEN id="token-20-24" pos="word" morph="none" start_char="2539" end_char="2540">no</TOKEN>
<TOKEN id="token-20-25" pos="word" morph="none" start_char="2542" end_char="2543">es</TOKEN>
<TOKEN id="token-20-26" pos="word" morph="none" start_char="2545" end_char="2548">bien</TOKEN>
<TOKEN id="token-20-27" pos="word" morph="none" start_char="2550" end_char="2557">tolerado</TOKEN>
<TOKEN id="token-20-28" pos="punct" morph="none" start_char="2558" end_char="2559">",</TOKEN>
<TOKEN id="token-20-29" pos="word" morph="none" start_char="2561" end_char="2567">sostuvo</TOKEN>
<TOKEN id="token-20-30" pos="punct" morph="none" start_char="2568" end_char="2568">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2571" end_char="2588">
<ORIGINAL_TEXT>Mirá la entrevista</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2571" end_char="2574">Mirá</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2576" end_char="2577">la</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2579" end_char="2588">entrevista</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
