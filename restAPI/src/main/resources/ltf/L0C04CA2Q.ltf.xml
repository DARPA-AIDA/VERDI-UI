<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CA2Q" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="3059" raw_text_md5="533d738973da7f34a58004a2fabf0d6f">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="82">
<ORIGINAL_TEXT>La RAI reveló en 2015 que científicos chinos crearon un coronavirus en murciélagos</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="2">La</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="4" end_char="6">RAI</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="8" end_char="13">reveló</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="15" end_char="16">en</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="18" end_char="21">2015</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="23" end_char="25">que</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="27" end_char="37">científicos</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="39" end_char="44">chinos</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="46" end_char="52">crearon</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="54" end_char="55">un</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="57" end_char="67">coronavirus</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="69" end_char="70">en</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="72" end_char="82">murciélagos</TOKEN>
</SEG>
<SEG id="segment-1" start_char="86" end_char="98">
<ORIGINAL_TEXT>Roma, Italia.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="86" end_char="89">Roma</TOKEN>
<TOKEN id="token-1-1" pos="punct" morph="none" start_char="90" end_char="90">,</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="92" end_char="97">Italia</TOKEN>
<TOKEN id="token-1-3" pos="punct" morph="none" start_char="98" end_char="98">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="101" end_char="400">
<ORIGINAL_TEXT>Un video de un programa científico de televisión italiano que avisaba en 2015 de que China estaba fabricando un Coronavirus utilizando murciélagos se ha viralizado en redes sociales en los últimos días apuntando a que el Covid 19, que ha dejado más de 48,000 muertos en el mundo es un arma biológica.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="101" end_char="102">Un</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="104" end_char="108">video</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="110" end_char="111">de</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="113" end_char="114">un</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="116" end_char="123">programa</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="125" end_char="134">científico</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="136" end_char="137">de</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="139" end_char="148">televisión</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="150" end_char="157">italiano</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="159" end_char="161">que</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="163" end_char="169">avisaba</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="171" end_char="172">en</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="174" end_char="177">2015</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="179" end_char="180">de</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="182" end_char="184">que</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="186" end_char="190">China</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="192" end_char="197">estaba</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="199" end_char="208">fabricando</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="210" end_char="211">un</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="213" end_char="223">Coronavirus</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="225" end_char="234">utilizando</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="236" end_char="246">murciélagos</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="248" end_char="249">se</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="251" end_char="252">ha</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="254" end_char="263">viralizado</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="265" end_char="266">en</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="268" end_char="272">redes</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="274" end_char="281">sociales</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="283" end_char="284">en</TOKEN>
<TOKEN id="token-2-29" pos="word" morph="none" start_char="286" end_char="288">los</TOKEN>
<TOKEN id="token-2-30" pos="word" morph="none" start_char="290" end_char="296">últimos</TOKEN>
<TOKEN id="token-2-31" pos="word" morph="none" start_char="298" end_char="301">días</TOKEN>
<TOKEN id="token-2-32" pos="word" morph="none" start_char="303" end_char="311">apuntando</TOKEN>
<TOKEN id="token-2-33" pos="word" morph="none" start_char="313" end_char="313">a</TOKEN>
<TOKEN id="token-2-34" pos="word" morph="none" start_char="315" end_char="317">que</TOKEN>
<TOKEN id="token-2-35" pos="word" morph="none" start_char="319" end_char="320">el</TOKEN>
<TOKEN id="token-2-36" pos="word" morph="none" start_char="322" end_char="326">Covid</TOKEN>
<TOKEN id="token-2-37" pos="word" morph="none" start_char="328" end_char="329">19</TOKEN>
<TOKEN id="token-2-38" pos="punct" morph="none" start_char="330" end_char="330">,</TOKEN>
<TOKEN id="token-2-39" pos="word" morph="none" start_char="332" end_char="334">que</TOKEN>
<TOKEN id="token-2-40" pos="word" morph="none" start_char="336" end_char="337">ha</TOKEN>
<TOKEN id="token-2-41" pos="word" morph="none" start_char="339" end_char="344">dejado</TOKEN>
<TOKEN id="token-2-42" pos="word" morph="none" start_char="346" end_char="348">más</TOKEN>
<TOKEN id="token-2-43" pos="word" morph="none" start_char="350" end_char="351">de</TOKEN>
<TOKEN id="token-2-44" pos="unknown" morph="none" start_char="353" end_char="358">48,000</TOKEN>
<TOKEN id="token-2-45" pos="word" morph="none" start_char="360" end_char="366">muertos</TOKEN>
<TOKEN id="token-2-46" pos="word" morph="none" start_char="368" end_char="369">en</TOKEN>
<TOKEN id="token-2-47" pos="word" morph="none" start_char="371" end_char="372">el</TOKEN>
<TOKEN id="token-2-48" pos="word" morph="none" start_char="374" end_char="378">mundo</TOKEN>
<TOKEN id="token-2-49" pos="word" morph="none" start_char="380" end_char="381">es</TOKEN>
<TOKEN id="token-2-50" pos="word" morph="none" start_char="383" end_char="384">un</TOKEN>
<TOKEN id="token-2-51" pos="word" morph="none" start_char="386" end_char="389">arma</TOKEN>
<TOKEN id="token-2-52" pos="word" morph="none" start_char="391" end_char="399">biológica</TOKEN>
<TOKEN id="token-2-53" pos="punct" morph="none" start_char="400" end_char="400">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="403" end_char="751">
<ORIGINAL_TEXT>Sin embargo, expertos italianos y de la cadena de televisión RAI, salieron a desmentir la información asegurando, que en efecto, un artículo de 2015 publicado por la revista científica Nature Medicine y retomado por la RAI revelaba que China creó un coronavirus a partir de murciélagos para investigar el efecto de este tipo de virus en los humanos.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="403" end_char="405">Sin</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="407" end_char="413">embargo</TOKEN>
<TOKEN id="token-3-2" pos="punct" morph="none" start_char="414" end_char="414">,</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="416" end_char="423">expertos</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="425" end_char="433">italianos</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="435" end_char="435">y</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="437" end_char="438">de</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="440" end_char="441">la</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="443" end_char="448">cadena</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="450" end_char="451">de</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="453" end_char="462">televisión</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="464" end_char="466">RAI</TOKEN>
<TOKEN id="token-3-12" pos="punct" morph="none" start_char="467" end_char="467">,</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="469" end_char="476">salieron</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="478" end_char="478">a</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="480" end_char="488">desmentir</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="490" end_char="491">la</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="493" end_char="503">información</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="505" end_char="514">asegurando</TOKEN>
<TOKEN id="token-3-19" pos="punct" morph="none" start_char="515" end_char="515">,</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="517" end_char="519">que</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="521" end_char="522">en</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="524" end_char="529">efecto</TOKEN>
<TOKEN id="token-3-23" pos="punct" morph="none" start_char="530" end_char="530">,</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="532" end_char="533">un</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="535" end_char="542">artículo</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="544" end_char="545">de</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="547" end_char="550">2015</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="552" end_char="560">publicado</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="562" end_char="564">por</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="566" end_char="567">la</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="569" end_char="575">revista</TOKEN>
<TOKEN id="token-3-32" pos="word" morph="none" start_char="577" end_char="586">científica</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="588" end_char="593">Nature</TOKEN>
<TOKEN id="token-3-34" pos="word" morph="none" start_char="595" end_char="602">Medicine</TOKEN>
<TOKEN id="token-3-35" pos="word" morph="none" start_char="604" end_char="604">y</TOKEN>
<TOKEN id="token-3-36" pos="word" morph="none" start_char="606" end_char="613">retomado</TOKEN>
<TOKEN id="token-3-37" pos="word" morph="none" start_char="615" end_char="617">por</TOKEN>
<TOKEN id="token-3-38" pos="word" morph="none" start_char="619" end_char="620">la</TOKEN>
<TOKEN id="token-3-39" pos="word" morph="none" start_char="622" end_char="624">RAI</TOKEN>
<TOKEN id="token-3-40" pos="word" morph="none" start_char="626" end_char="633">revelaba</TOKEN>
<TOKEN id="token-3-41" pos="word" morph="none" start_char="635" end_char="637">que</TOKEN>
<TOKEN id="token-3-42" pos="word" morph="none" start_char="639" end_char="643">China</TOKEN>
<TOKEN id="token-3-43" pos="word" morph="none" start_char="645" end_char="648">creó</TOKEN>
<TOKEN id="token-3-44" pos="word" morph="none" start_char="650" end_char="651">un</TOKEN>
<TOKEN id="token-3-45" pos="word" morph="none" start_char="653" end_char="663">coronavirus</TOKEN>
<TOKEN id="token-3-46" pos="word" morph="none" start_char="665" end_char="665">a</TOKEN>
<TOKEN id="token-3-47" pos="word" morph="none" start_char="667" end_char="672">partir</TOKEN>
<TOKEN id="token-3-48" pos="word" morph="none" start_char="674" end_char="675">de</TOKEN>
<TOKEN id="token-3-49" pos="word" morph="none" start_char="677" end_char="687">murciélagos</TOKEN>
<TOKEN id="token-3-50" pos="word" morph="none" start_char="689" end_char="692">para</TOKEN>
<TOKEN id="token-3-51" pos="word" morph="none" start_char="694" end_char="703">investigar</TOKEN>
<TOKEN id="token-3-52" pos="word" morph="none" start_char="705" end_char="706">el</TOKEN>
<TOKEN id="token-3-53" pos="word" morph="none" start_char="708" end_char="713">efecto</TOKEN>
<TOKEN id="token-3-54" pos="word" morph="none" start_char="715" end_char="716">de</TOKEN>
<TOKEN id="token-3-55" pos="word" morph="none" start_char="718" end_char="721">este</TOKEN>
<TOKEN id="token-3-56" pos="word" morph="none" start_char="723" end_char="726">tipo</TOKEN>
<TOKEN id="token-3-57" pos="word" morph="none" start_char="728" end_char="729">de</TOKEN>
<TOKEN id="token-3-58" pos="word" morph="none" start_char="731" end_char="735">virus</TOKEN>
<TOKEN id="token-3-59" pos="word" morph="none" start_char="737" end_char="738">en</TOKEN>
<TOKEN id="token-3-60" pos="word" morph="none" start_char="740" end_char="742">los</TOKEN>
<TOKEN id="token-3-61" pos="word" morph="none" start_char="744" end_char="750">humanos</TOKEN>
<TOKEN id="token-3-62" pos="punct" morph="none" start_char="751" end_char="751">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="755" end_char="938">
<ORIGINAL_TEXT>"Un grupo de investigadores chinos insertaron una proteína procedente de murciélagos al virus del SARS provocando una pulmonía aguda en ratones, que podría afectar a los seres humanos.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="punct" morph="none" start_char="755" end_char="755">"</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="756" end_char="757">Un</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="759" end_char="763">grupo</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="765" end_char="766">de</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="768" end_char="781">investigadores</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="783" end_char="788">chinos</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="790" end_char="799">insertaron</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="801" end_char="803">una</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="805" end_char="812">proteína</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="814" end_char="823">procedente</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="825" end_char="826">de</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="828" end_char="838">murciélagos</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="840" end_char="841">al</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="843" end_char="847">virus</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="849" end_char="851">del</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="853" end_char="856">SARS</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="858" end_char="867">provocando</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="869" end_char="871">una</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="873" end_char="880">pulmonía</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="882" end_char="886">aguda</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="888" end_char="889">en</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="891" end_char="897">ratones</TOKEN>
<TOKEN id="token-4-22" pos="punct" morph="none" start_char="898" end_char="898">,</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="900" end_char="902">que</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="904" end_char="909">podría</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="911" end_char="917">afectar</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="919" end_char="919">a</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="921" end_char="923">los</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="925" end_char="929">seres</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="931" end_char="937">humanos</TOKEN>
<TOKEN id="token-4-30" pos="punct" morph="none" start_char="938" end_char="938">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="940" end_char="1089">
<ORIGINAL_TEXT>Está confinado en un laboratorio y sirve solo de estudio, pero ¿vale la pena correr el riesgo que supone crear una amenaza solo para poderla examinar?</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="940" end_char="943">Está</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="945" end_char="953">confinado</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="955" end_char="956">en</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="958" end_char="959">un</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="961" end_char="971">laboratorio</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="973" end_char="973">y</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="975" end_char="979">sirve</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="981" end_char="984">solo</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="986" end_char="987">de</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="989" end_char="995">estudio</TOKEN>
<TOKEN id="token-5-10" pos="punct" morph="none" start_char="996" end_char="996">,</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="998" end_char="1001">pero</TOKEN>
<TOKEN id="token-5-12" pos="punct" morph="none" start_char="1003" end_char="1003">¿</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="1004" end_char="1007">vale</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="1009" end_char="1010">la</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="1012" end_char="1015">pena</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="1017" end_char="1022">correr</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="1024" end_char="1025">el</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="1027" end_char="1032">riesgo</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="1034" end_char="1036">que</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="1038" end_char="1043">supone</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="1045" end_char="1049">crear</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="1051" end_char="1053">una</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="1055" end_char="1061">amenaza</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="1063" end_char="1066">solo</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="1068" end_char="1071">para</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="1073" end_char="1079">poderla</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="1081" end_char="1088">examinar</TOKEN>
<TOKEN id="token-5-28" pos="punct" morph="none" start_char="1089" end_char="1089">?</TOKEN>
</SEG>
<SEG id="segment-6" start_char="1091" end_char="1185">
<ORIGINAL_TEXT>", indicó el periodista de un noticiero que retomó el video que más tarde se viralizó en redes.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="punct" morph="none" start_char="1091" end_char="1092">",</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="1094" end_char="1099">indicó</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="1101" end_char="1102">el</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="1104" end_char="1113">periodista</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="1115" end_char="1116">de</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="1118" end_char="1119">un</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="1121" end_char="1129">noticiero</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="1131" end_char="1133">que</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="1135" end_char="1140">retomó</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="1142" end_char="1143">el</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="1145" end_char="1149">video</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="1151" end_char="1153">que</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="1155" end_char="1157">más</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="1159" end_char="1163">tarde</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="1165" end_char="1166">se</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="1168" end_char="1175">viralizó</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="1177" end_char="1178">en</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="1180" end_char="1184">redes</TOKEN>
<TOKEN id="token-6-18" pos="punct" morph="none" start_char="1185" end_char="1185">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="1188" end_char="1218">
<ORIGINAL_TEXT>El Covid 19 es de origen animal</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="1188" end_char="1189">El</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="1191" end_char="1195">Covid</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="1197" end_char="1198">19</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="1200" end_char="1201">es</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="1203" end_char="1204">de</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="1206" end_char="1211">origen</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="1213" end_char="1218">animal</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1222" end_char="1501">
<ORIGINAL_TEXT>Para desmentir la información, la RAI entrevistó a Antonio Lanzavecchia, director del Instituto Bellinzona y uno de los investigadores que participó en el experimento del 2015, quien confirmó que el Covid-19 es un virus totalmente distinto al que se creó hace cinco años en China.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1222" end_char="1225">Para</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1227" end_char="1235">desmentir</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1237" end_char="1238">la</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1240" end_char="1250">información</TOKEN>
<TOKEN id="token-8-4" pos="punct" morph="none" start_char="1251" end_char="1251">,</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1253" end_char="1254">la</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1256" end_char="1258">RAI</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1260" end_char="1269">entrevistó</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1271" end_char="1271">a</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1273" end_char="1279">Antonio</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1281" end_char="1292">Lanzavecchia</TOKEN>
<TOKEN id="token-8-11" pos="punct" morph="none" start_char="1293" end_char="1293">,</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1295" end_char="1302">director</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1304" end_char="1306">del</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1308" end_char="1316">Instituto</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1318" end_char="1327">Bellinzona</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1329" end_char="1329">y</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1331" end_char="1333">uno</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1335" end_char="1336">de</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1338" end_char="1340">los</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="1342" end_char="1355">investigadores</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="1357" end_char="1359">que</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="1361" end_char="1369">participó</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="1371" end_char="1372">en</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="1374" end_char="1375">el</TOKEN>
<TOKEN id="token-8-25" pos="word" morph="none" start_char="1377" end_char="1387">experimento</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="1389" end_char="1391">del</TOKEN>
<TOKEN id="token-8-27" pos="word" morph="none" start_char="1393" end_char="1396">2015</TOKEN>
<TOKEN id="token-8-28" pos="punct" morph="none" start_char="1397" end_char="1397">,</TOKEN>
<TOKEN id="token-8-29" pos="word" morph="none" start_char="1399" end_char="1403">quien</TOKEN>
<TOKEN id="token-8-30" pos="word" morph="none" start_char="1405" end_char="1412">confirmó</TOKEN>
<TOKEN id="token-8-31" pos="word" morph="none" start_char="1414" end_char="1416">que</TOKEN>
<TOKEN id="token-8-32" pos="word" morph="none" start_char="1418" end_char="1419">el</TOKEN>
<TOKEN id="token-8-33" pos="unknown" morph="none" start_char="1421" end_char="1428">Covid-19</TOKEN>
<TOKEN id="token-8-34" pos="word" morph="none" start_char="1430" end_char="1431">es</TOKEN>
<TOKEN id="token-8-35" pos="word" morph="none" start_char="1433" end_char="1434">un</TOKEN>
<TOKEN id="token-8-36" pos="word" morph="none" start_char="1436" end_char="1440">virus</TOKEN>
<TOKEN id="token-8-37" pos="word" morph="none" start_char="1442" end_char="1451">totalmente</TOKEN>
<TOKEN id="token-8-38" pos="word" morph="none" start_char="1453" end_char="1460">distinto</TOKEN>
<TOKEN id="token-8-39" pos="word" morph="none" start_char="1462" end_char="1463">al</TOKEN>
<TOKEN id="token-8-40" pos="word" morph="none" start_char="1465" end_char="1467">que</TOKEN>
<TOKEN id="token-8-41" pos="word" morph="none" start_char="1469" end_char="1470">se</TOKEN>
<TOKEN id="token-8-42" pos="word" morph="none" start_char="1472" end_char="1475">creó</TOKEN>
<TOKEN id="token-8-43" pos="word" morph="none" start_char="1477" end_char="1480">hace</TOKEN>
<TOKEN id="token-8-44" pos="word" morph="none" start_char="1482" end_char="1486">cinco</TOKEN>
<TOKEN id="token-8-45" pos="word" morph="none" start_char="1488" end_char="1491">años</TOKEN>
<TOKEN id="token-8-46" pos="word" morph="none" start_char="1493" end_char="1494">en</TOKEN>
<TOKEN id="token-8-47" pos="word" morph="none" start_char="1496" end_char="1500">China</TOKEN>
<TOKEN id="token-8-48" pos="punct" morph="none" start_char="1501" end_char="1501">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1504" end_char="1799">
<ORIGINAL_TEXT>La revista Nature también salió al paso de la información al publicar un nuevo artículo titulado "El origen aproximado del SARS-CoV-2", en el que concluye que el virus de la actual pandemia "no es una construcción de laboratorio o un virus manipulado a propósito, sino un virus de origen animal".</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1504" end_char="1505">La</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1507" end_char="1513">revista</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1515" end_char="1520">Nature</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1522" end_char="1528">también</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1530" end_char="1534">salió</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1536" end_char="1537">al</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1539" end_char="1542">paso</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1544" end_char="1545">de</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1547" end_char="1548">la</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1550" end_char="1560">información</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1562" end_char="1563">al</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1565" end_char="1572">publicar</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1574" end_char="1575">un</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1577" end_char="1581">nuevo</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1583" end_char="1590">artículo</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1592" end_char="1599">titulado</TOKEN>
<TOKEN id="token-9-16" pos="punct" morph="none" start_char="1601" end_char="1601">"</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1602" end_char="1603">El</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1605" end_char="1610">origen</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1612" end_char="1621">aproximado</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1623" end_char="1625">del</TOKEN>
<TOKEN id="token-9-21" pos="unknown" morph="none" start_char="1627" end_char="1636">SARS-CoV-2</TOKEN>
<TOKEN id="token-9-22" pos="punct" morph="none" start_char="1637" end_char="1638">",</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1640" end_char="1641">en</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1643" end_char="1644">el</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1646" end_char="1648">que</TOKEN>
<TOKEN id="token-9-26" pos="word" morph="none" start_char="1650" end_char="1657">concluye</TOKEN>
<TOKEN id="token-9-27" pos="word" morph="none" start_char="1659" end_char="1661">que</TOKEN>
<TOKEN id="token-9-28" pos="word" morph="none" start_char="1663" end_char="1664">el</TOKEN>
<TOKEN id="token-9-29" pos="word" morph="none" start_char="1666" end_char="1670">virus</TOKEN>
<TOKEN id="token-9-30" pos="word" morph="none" start_char="1672" end_char="1673">de</TOKEN>
<TOKEN id="token-9-31" pos="word" morph="none" start_char="1675" end_char="1676">la</TOKEN>
<TOKEN id="token-9-32" pos="word" morph="none" start_char="1678" end_char="1683">actual</TOKEN>
<TOKEN id="token-9-33" pos="word" morph="none" start_char="1685" end_char="1692">pandemia</TOKEN>
<TOKEN id="token-9-34" pos="punct" morph="none" start_char="1694" end_char="1694">"</TOKEN>
<TOKEN id="token-9-35" pos="word" morph="none" start_char="1695" end_char="1696">no</TOKEN>
<TOKEN id="token-9-36" pos="word" morph="none" start_char="1698" end_char="1699">es</TOKEN>
<TOKEN id="token-9-37" pos="word" morph="none" start_char="1701" end_char="1703">una</TOKEN>
<TOKEN id="token-9-38" pos="word" morph="none" start_char="1705" end_char="1716">construcción</TOKEN>
<TOKEN id="token-9-39" pos="word" morph="none" start_char="1718" end_char="1719">de</TOKEN>
<TOKEN id="token-9-40" pos="word" morph="none" start_char="1721" end_char="1731">laboratorio</TOKEN>
<TOKEN id="token-9-41" pos="word" morph="none" start_char="1733" end_char="1733">o</TOKEN>
<TOKEN id="token-9-42" pos="word" morph="none" start_char="1735" end_char="1736">un</TOKEN>
<TOKEN id="token-9-43" pos="word" morph="none" start_char="1738" end_char="1742">virus</TOKEN>
<TOKEN id="token-9-44" pos="word" morph="none" start_char="1744" end_char="1753">manipulado</TOKEN>
<TOKEN id="token-9-45" pos="word" morph="none" start_char="1755" end_char="1755">a</TOKEN>
<TOKEN id="token-9-46" pos="word" morph="none" start_char="1757" end_char="1765">propósito</TOKEN>
<TOKEN id="token-9-47" pos="punct" morph="none" start_char="1766" end_char="1766">,</TOKEN>
<TOKEN id="token-9-48" pos="word" morph="none" start_char="1768" end_char="1771">sino</TOKEN>
<TOKEN id="token-9-49" pos="word" morph="none" start_char="1773" end_char="1774">un</TOKEN>
<TOKEN id="token-9-50" pos="word" morph="none" start_char="1776" end_char="1780">virus</TOKEN>
<TOKEN id="token-9-51" pos="word" morph="none" start_char="1782" end_char="1783">de</TOKEN>
<TOKEN id="token-9-52" pos="word" morph="none" start_char="1785" end_char="1790">origen</TOKEN>
<TOKEN id="token-9-53" pos="word" morph="none" start_char="1792" end_char="1797">animal</TOKEN>
<TOKEN id="token-9-54" pos="punct" morph="none" start_char="1798" end_char="1799">".</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1802" end_char="2055">
<ORIGINAL_TEXT>En la misma línea, Franco Locatelli , presidente del Consejo Superior de Salud y miembro del comité científico que apoya al Gobierno en la lucha contra el COVID-19, dijo que "no hay evidencia de que este fue el mecanismo por el cual se generó SARS-CoV-2.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1802" end_char="1803">En</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1805" end_char="1806">la</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1808" end_char="1812">misma</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1814" end_char="1818">línea</TOKEN>
<TOKEN id="token-10-4" pos="punct" morph="none" start_char="1819" end_char="1819">,</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1821" end_char="1826">Franco</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1828" end_char="1836">Locatelli</TOKEN>
<TOKEN id="token-10-7" pos="punct" morph="none" start_char="1838" end_char="1838">,</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1840" end_char="1849">presidente</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1851" end_char="1853">del</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1855" end_char="1861">Consejo</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1863" end_char="1870">Superior</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1872" end_char="1873">de</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1875" end_char="1879">Salud</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1881" end_char="1881">y</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1883" end_char="1889">miembro</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1891" end_char="1893">del</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1895" end_char="1900">comité</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1902" end_char="1911">científico</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1913" end_char="1915">que</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1917" end_char="1921">apoya</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1923" end_char="1924">al</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1926" end_char="1933">Gobierno</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1935" end_char="1936">en</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1938" end_char="1939">la</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="1941" end_char="1945">lucha</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="1947" end_char="1952">contra</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="1954" end_char="1955">el</TOKEN>
<TOKEN id="token-10-28" pos="unknown" morph="none" start_char="1957" end_char="1964">COVID-19</TOKEN>
<TOKEN id="token-10-29" pos="punct" morph="none" start_char="1965" end_char="1965">,</TOKEN>
<TOKEN id="token-10-30" pos="word" morph="none" start_char="1967" end_char="1970">dijo</TOKEN>
<TOKEN id="token-10-31" pos="word" morph="none" start_char="1972" end_char="1974">que</TOKEN>
<TOKEN id="token-10-32" pos="punct" morph="none" start_char="1976" end_char="1976">"</TOKEN>
<TOKEN id="token-10-33" pos="word" morph="none" start_char="1977" end_char="1978">no</TOKEN>
<TOKEN id="token-10-34" pos="word" morph="none" start_char="1980" end_char="1982">hay</TOKEN>
<TOKEN id="token-10-35" pos="word" morph="none" start_char="1984" end_char="1992">evidencia</TOKEN>
<TOKEN id="token-10-36" pos="word" morph="none" start_char="1994" end_char="1995">de</TOKEN>
<TOKEN id="token-10-37" pos="word" morph="none" start_char="1997" end_char="1999">que</TOKEN>
<TOKEN id="token-10-38" pos="word" morph="none" start_char="2001" end_char="2004">este</TOKEN>
<TOKEN id="token-10-39" pos="word" morph="none" start_char="2006" end_char="2008">fue</TOKEN>
<TOKEN id="token-10-40" pos="word" morph="none" start_char="2010" end_char="2011">el</TOKEN>
<TOKEN id="token-10-41" pos="word" morph="none" start_char="2013" end_char="2021">mecanismo</TOKEN>
<TOKEN id="token-10-42" pos="word" morph="none" start_char="2023" end_char="2025">por</TOKEN>
<TOKEN id="token-10-43" pos="word" morph="none" start_char="2027" end_char="2028">el</TOKEN>
<TOKEN id="token-10-44" pos="word" morph="none" start_char="2030" end_char="2033">cual</TOKEN>
<TOKEN id="token-10-45" pos="word" morph="none" start_char="2035" end_char="2036">se</TOKEN>
<TOKEN id="token-10-46" pos="word" morph="none" start_char="2038" end_char="2043">generó</TOKEN>
<TOKEN id="token-10-47" pos="unknown" morph="none" start_char="2045" end_char="2054">SARS-CoV-2</TOKEN>
<TOKEN id="token-10-48" pos="punct" morph="none" start_char="2055" end_char="2055">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="2057" end_char="2085">
<ORIGINAL_TEXT>Es bioterrorismo de fantasía.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="2057" end_char="2058">Es</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="2060" end_char="2072">bioterrorismo</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="2074" end_char="2075">de</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="2077" end_char="2084">fantasía</TOKEN>
<TOKEN id="token-11-4" pos="punct" morph="none" start_char="2085" end_char="2085">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="2087" end_char="2226">
<ORIGINAL_TEXT>Todos los grupos internacionales comparten la secuencia de cepas aisladas del nuevo coronavirus y ese escenario nunca ha sido hipotetizado".</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="2087" end_char="2091">Todos</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="2093" end_char="2095">los</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="2097" end_char="2102">grupos</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="2104" end_char="2118">internacionales</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="2120" end_char="2128">comparten</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="2130" end_char="2131">la</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="2133" end_char="2141">secuencia</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="2143" end_char="2144">de</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="2146" end_char="2150">cepas</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="2152" end_char="2159">aisladas</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="2161" end_char="2163">del</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="2165" end_char="2169">nuevo</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="2171" end_char="2181">coronavirus</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="2183" end_char="2183">y</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="2185" end_char="2187">ese</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="2189" end_char="2197">escenario</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="2199" end_char="2203">nunca</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="2205" end_char="2206">ha</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="2208" end_char="2211">sido</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="2213" end_char="2224">hipotetizado</TOKEN>
<TOKEN id="token-12-20" pos="punct" morph="none" start_char="2225" end_char="2226">".</TOKEN>
</SEG>
<SEG id="segment-13" start_char="2229" end_char="2290">
<ORIGINAL_TEXT>Vea: El hantavirus no es una nueva epidemia que viene de China</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="2229" end_char="2231">Vea</TOKEN>
<TOKEN id="token-13-1" pos="punct" morph="none" start_char="2232" end_char="2232">:</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="2234" end_char="2235">El</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="2237" end_char="2246">hantavirus</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="2248" end_char="2249">no</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="2251" end_char="2252">es</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="2254" end_char="2256">una</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="2258" end_char="2262">nueva</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="2264" end_char="2271">epidemia</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="2273" end_char="2275">que</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="2277" end_char="2281">viene</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="2283" end_char="2284">de</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="2286" end_char="2290">China</TOKEN>
</SEG>
<SEG id="segment-14" start_char="2293" end_char="2442">
<ORIGINAL_TEXT>Varios laboratorios de microbiología o biotecnología suelen modificar y manipular algunos virus para observar su comportamiento y desarrollar vacunas.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="2293" end_char="2298">Varios</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="2300" end_char="2311">laboratorios</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="2313" end_char="2314">de</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="2316" end_char="2328">microbiología</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="2330" end_char="2330">o</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="2332" end_char="2344">biotecnología</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="2346" end_char="2351">suelen</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="2353" end_char="2361">modificar</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="2363" end_char="2363">y</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="2365" end_char="2373">manipular</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="2375" end_char="2381">algunos</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="2383" end_char="2387">virus</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="2389" end_char="2392">para</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="2394" end_char="2401">observar</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="2403" end_char="2404">su</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="2406" end_char="2419">comportamiento</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="2421" end_char="2421">y</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="2423" end_char="2433">desarrollar</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="2435" end_char="2441">vacunas</TOKEN>
<TOKEN id="token-14-19" pos="punct" morph="none" start_char="2442" end_char="2442">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="2445" end_char="2622">
<ORIGINAL_TEXT>Un estudio, publicado en la revista Science China Life Sciences, patrocinado por la Academia China de Ciencias de Pekín, analizó las relaciones entre la nueva cepa y otros virus.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="2445" end_char="2446">Un</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="2448" end_char="2454">estudio</TOKEN>
<TOKEN id="token-15-2" pos="punct" morph="none" start_char="2455" end_char="2455">,</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="2457" end_char="2465">publicado</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="2467" end_char="2468">en</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="2470" end_char="2471">la</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="2473" end_char="2479">revista</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="2481" end_char="2487">Science</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="2489" end_char="2493">China</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="2495" end_char="2498">Life</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="2500" end_char="2507">Sciences</TOKEN>
<TOKEN id="token-15-11" pos="punct" morph="none" start_char="2508" end_char="2508">,</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="2510" end_char="2520">patrocinado</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="2522" end_char="2524">por</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="2526" end_char="2527">la</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="2529" end_char="2536">Academia</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="2538" end_char="2542">China</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="2544" end_char="2545">de</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="2547" end_char="2554">Ciencias</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="2556" end_char="2557">de</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="2559" end_char="2563">Pekín</TOKEN>
<TOKEN id="token-15-21" pos="punct" morph="none" start_char="2564" end_char="2564">,</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="2566" end_char="2572">analizó</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="2574" end_char="2576">las</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="2578" end_char="2587">relaciones</TOKEN>
<TOKEN id="token-15-25" pos="word" morph="none" start_char="2589" end_char="2593">entre</TOKEN>
<TOKEN id="token-15-26" pos="word" morph="none" start_char="2595" end_char="2596">la</TOKEN>
<TOKEN id="token-15-27" pos="word" morph="none" start_char="2598" end_char="2602">nueva</TOKEN>
<TOKEN id="token-15-28" pos="word" morph="none" start_char="2604" end_char="2607">cepa</TOKEN>
<TOKEN id="token-15-29" pos="word" morph="none" start_char="2609" end_char="2609">y</TOKEN>
<TOKEN id="token-15-30" pos="word" morph="none" start_char="2611" end_char="2615">otros</TOKEN>
<TOKEN id="token-15-31" pos="word" morph="none" start_char="2617" end_char="2621">virus</TOKEN>
<TOKEN id="token-15-32" pos="punct" morph="none" start_char="2622" end_char="2622">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="2625" end_char="2762">
<ORIGINAL_TEXT>Descubrió que el coronavirus que surgió en la ciudad de Wuhan estaba estrechamente relacionado con una cepa que existe en los murciélagos.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="2625" end_char="2633">Descubrió</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="2635" end_char="2637">que</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="2639" end_char="2640">el</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="2642" end_char="2652">coronavirus</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="2654" end_char="2656">que</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="2658" end_char="2663">surgió</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="2665" end_char="2666">en</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="2668" end_char="2669">la</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="2671" end_char="2676">ciudad</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="2678" end_char="2679">de</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="2681" end_char="2685">Wuhan</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="2687" end_char="2692">estaba</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="2694" end_char="2706">estrechamente</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="2708" end_char="2718">relacionado</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="2720" end_char="2722">con</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="2724" end_char="2726">una</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="2728" end_char="2731">cepa</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="2733" end_char="2735">que</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="2737" end_char="2742">existe</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="2744" end_char="2745">en</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="2747" end_char="2749">los</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="2751" end_char="2761">murciélagos</TOKEN>
<TOKEN id="token-16-22" pos="punct" morph="none" start_char="2762" end_char="2762">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2765" end_char="3055">
<ORIGINAL_TEXT>"El hecho de que los murciélagos sean los huéspedes nativos del Wuhan CoV (coronavirus) sería el razonamiento lógico y conveniente, aunque sigue siendo probable que haya huéspedes intermedios en la cascada de transmisión de murciélagos a humanos", señalaron los investigadores en el reporte.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="punct" morph="none" start_char="2765" end_char="2765">"</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2766" end_char="2767">El</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2769" end_char="2773">hecho</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2775" end_char="2776">de</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2778" end_char="2780">que</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2782" end_char="2784">los</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2786" end_char="2796">murciélagos</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2798" end_char="2801">sean</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2803" end_char="2805">los</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2807" end_char="2815">huéspedes</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2817" end_char="2823">nativos</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2825" end_char="2827">del</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2829" end_char="2833">Wuhan</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2835" end_char="2837">CoV</TOKEN>
<TOKEN id="token-17-14" pos="punct" morph="none" start_char="2839" end_char="2839">(</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2840" end_char="2850">coronavirus</TOKEN>
<TOKEN id="token-17-16" pos="punct" morph="none" start_char="2851" end_char="2851">)</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="2853" end_char="2857">sería</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="2859" end_char="2860">el</TOKEN>
<TOKEN id="token-17-19" pos="word" morph="none" start_char="2862" end_char="2873">razonamiento</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="2875" end_char="2880">lógico</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="2882" end_char="2882">y</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="2884" end_char="2894">conveniente</TOKEN>
<TOKEN id="token-17-23" pos="punct" morph="none" start_char="2895" end_char="2895">,</TOKEN>
<TOKEN id="token-17-24" pos="word" morph="none" start_char="2897" end_char="2902">aunque</TOKEN>
<TOKEN id="token-17-25" pos="word" morph="none" start_char="2904" end_char="2908">sigue</TOKEN>
<TOKEN id="token-17-26" pos="word" morph="none" start_char="2910" end_char="2915">siendo</TOKEN>
<TOKEN id="token-17-27" pos="word" morph="none" start_char="2917" end_char="2924">probable</TOKEN>
<TOKEN id="token-17-28" pos="word" morph="none" start_char="2926" end_char="2928">que</TOKEN>
<TOKEN id="token-17-29" pos="word" morph="none" start_char="2930" end_char="2933">haya</TOKEN>
<TOKEN id="token-17-30" pos="word" morph="none" start_char="2935" end_char="2943">huéspedes</TOKEN>
<TOKEN id="token-17-31" pos="word" morph="none" start_char="2945" end_char="2955">intermedios</TOKEN>
<TOKEN id="token-17-32" pos="word" morph="none" start_char="2957" end_char="2958">en</TOKEN>
<TOKEN id="token-17-33" pos="word" morph="none" start_char="2960" end_char="2961">la</TOKEN>
<TOKEN id="token-17-34" pos="word" morph="none" start_char="2963" end_char="2969">cascada</TOKEN>
<TOKEN id="token-17-35" pos="word" morph="none" start_char="2971" end_char="2972">de</TOKEN>
<TOKEN id="token-17-36" pos="word" morph="none" start_char="2974" end_char="2984">transmisión</TOKEN>
<TOKEN id="token-17-37" pos="word" morph="none" start_char="2986" end_char="2987">de</TOKEN>
<TOKEN id="token-17-38" pos="word" morph="none" start_char="2989" end_char="2999">murciélagos</TOKEN>
<TOKEN id="token-17-39" pos="word" morph="none" start_char="3001" end_char="3001">a</TOKEN>
<TOKEN id="token-17-40" pos="word" morph="none" start_char="3003" end_char="3009">humanos</TOKEN>
<TOKEN id="token-17-41" pos="punct" morph="none" start_char="3010" end_char="3011">",</TOKEN>
<TOKEN id="token-17-42" pos="word" morph="none" start_char="3013" end_char="3021">señalaron</TOKEN>
<TOKEN id="token-17-43" pos="word" morph="none" start_char="3023" end_char="3025">los</TOKEN>
<TOKEN id="token-17-44" pos="word" morph="none" start_char="3027" end_char="3040">investigadores</TOKEN>
<TOKEN id="token-17-45" pos="word" morph="none" start_char="3042" end_char="3043">en</TOKEN>
<TOKEN id="token-17-46" pos="word" morph="none" start_char="3045" end_char="3046">el</TOKEN>
<TOKEN id="token-17-47" pos="word" morph="none" start_char="3048" end_char="3054">reporte</TOKEN>
<TOKEN id="token-17-48" pos="punct" morph="none" start_char="3055" end_char="3055">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
