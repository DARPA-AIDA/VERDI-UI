<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C049DRG" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="3121" raw_text_md5="0f15622635da9e2481609421fb8d8fba">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="122">
<ORIGINAL_TEXT>Las "pruebas" de la viróloga china que asegura que la Covid-19 fue creada en un laboratorio no tienen evidencia científica</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="3">Las</TOKEN>
<TOKEN id="token-0-1" pos="punct" morph="none" start_char="5" end_char="5">"</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="6" end_char="12">pruebas</TOKEN>
<TOKEN id="token-0-3" pos="punct" morph="none" start_char="13" end_char="13">"</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="15" end_char="16">de</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="18" end_char="19">la</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="21" end_char="28">viróloga</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="30" end_char="34">china</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="36" end_char="38">que</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="40" end_char="46">asegura</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="48" end_char="50">que</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="52" end_char="53">la</TOKEN>
<TOKEN id="token-0-12" pos="unknown" morph="none" start_char="55" end_char="62">Covid-19</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="64" end_char="66">fue</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="68" end_char="73">creada</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="75" end_char="76">en</TOKEN>
<TOKEN id="token-0-16" pos="word" morph="none" start_char="78" end_char="79">un</TOKEN>
<TOKEN id="token-0-17" pos="word" morph="none" start_char="81" end_char="91">laboratorio</TOKEN>
<TOKEN id="token-0-18" pos="word" morph="none" start_char="93" end_char="94">no</TOKEN>
<TOKEN id="token-0-19" pos="word" morph="none" start_char="96" end_char="101">tienen</TOKEN>
<TOKEN id="token-0-20" pos="word" morph="none" start_char="103" end_char="111">evidencia</TOKEN>
<TOKEN id="token-0-21" pos="word" morph="none" start_char="113" end_char="122">científica</TOKEN>
</SEG>
<SEG id="segment-1" start_char="129" end_char="138">
<ORIGINAL_TEXT>Volume 90%</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="129" end_char="134">Volume</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="136" end_char="137">90</TOKEN>
<TOKEN id="token-1-2" pos="punct" morph="none" start_char="138" end_char="138">%</TOKEN>
</SEG>
<SEG id="segment-2" start_char="141" end_char="204">
<ORIGINAL_TEXT>Press shift question mark to access a list of keyboard shortcuts</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="141" end_char="145">Press</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="147" end_char="151">shift</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="153" end_char="160">question</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="162" end_char="165">mark</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="167" end_char="168">to</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="170" end_char="175">access</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="177" end_char="177">a</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="179" end_char="182">list</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="184" end_char="185">of</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="187" end_char="194">keyboard</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="196" end_char="204">shortcuts</TOKEN>
</SEG>
<SEG id="segment-3" start_char="207" end_char="238">
<ORIGINAL_TEXT>Atajos de TecladoEnabledDisabled</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="207" end_char="212">Atajos</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="214" end_char="215">de</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="217" end_char="238">TecladoEnabledDisabled</TOKEN>
</SEG>
<SEG id="segment-4" start_char="241" end_char="267">
<ORIGINAL_TEXT>Reproducir/PausaEspaciadora</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="unknown" morph="none" start_char="241" end_char="267">Reproducir/PausaEspaciadora</TOKEN>
</SEG>
<SEG id="segment-5" start_char="270" end_char="286">
<ORIGINAL_TEXT>Subir el Volumen↑</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="270" end_char="274">Subir</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="276" end_char="277">el</TOKEN>
<TOKEN id="token-5-2" pos="unknown" morph="none" start_char="279" end_char="286">Volumen↑</TOKEN>
</SEG>
<SEG id="segment-6" start_char="289" end_char="305">
<ORIGINAL_TEXT>Bajar el Volumen↓</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="289" end_char="293">Bajar</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="295" end_char="296">el</TOKEN>
<TOKEN id="token-6-2" pos="unknown" morph="none" start_char="298" end_char="305">Volumen↓</TOKEN>
</SEG>
<SEG id="segment-7" start_char="308" end_char="317">
<ORIGINAL_TEXT>Adelantar→</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="unknown" morph="none" start_char="308" end_char="317">Adelantar→</TOKEN>
</SEG>
<SEG id="segment-8" start_char="320" end_char="330">
<ORIGINAL_TEXT>Retroceder←</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="unknown" morph="none" start_char="320" end_char="330">Retroceder←</TOKEN>
</SEG>
<SEG id="segment-9" start_char="333" end_char="359">
<ORIGINAL_TEXT>Activar/Ocultar Subtítulosc</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="unknown" morph="none" start_char="333" end_char="347">Activar/Ocultar</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="349" end_char="359">Subtítulosc</TOKEN>
</SEG>
<SEG id="segment-10" start_char="362" end_char="409">
<ORIGINAL_TEXT>Pantalla Completa/Salir de la Pantalla Completaf</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="362" end_char="369">Pantalla</TOKEN>
<TOKEN id="token-10-1" pos="unknown" morph="none" start_char="371" end_char="384">Completa/Salir</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="386" end_char="387">de</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="389" end_char="390">la</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="392" end_char="399">Pantalla</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="401" end_char="409">Completaf</TOKEN>
</SEG>
<SEG id="segment-11" start_char="412" end_char="436">
<ORIGINAL_TEXT>Silenciar/Activar Sonidom</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="unknown" morph="none" start_char="412" end_char="428">Silenciar/Activar</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="430" end_char="436">Sonidom</TOKEN>
</SEG>
<SEG id="segment-12" start_char="439" end_char="452">
<ORIGINAL_TEXT>Adelantar %0-9</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="439" end_char="447">Adelantar</TOKEN>
<TOKEN id="token-12-1" pos="punct" morph="none" start_char="449" end_char="449">%</TOKEN>
<TOKEN id="token-12-2" pos="unknown" morph="none" start_char="450" end_char="452">0-9</TOKEN>
</SEG>
<SEG id="segment-13" start_char="455" end_char="469">
<ORIGINAL_TEXT>Siguiente vídeo</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="455" end_char="463">Siguiente</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="465" end_char="469">vídeo</TOKEN>
</SEG>
<SEG id="segment-14" start_char="472" end_char="547">
<ORIGINAL_TEXT>La emoción de Bryan Gil al conocer su convocatoria con la Selección Española</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="472" end_char="473">La</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="475" end_char="481">emoción</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="483" end_char="484">de</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="486" end_char="490">Bryan</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="492" end_char="494">Gil</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="496" end_char="497">al</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="499" end_char="505">conocer</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="507" end_char="508">su</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="510" end_char="521">convocatoria</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="523" end_char="525">con</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="527" end_char="528">la</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="530" end_char="538">Selección</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="540" end_char="547">Española</TOKEN>
</SEG>
<SEG id="segment-15" start_char="550" end_char="556">
<ORIGINAL_TEXT>En Vivo</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="550" end_char="551">En</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="553" end_char="556">Vivo</TOKEN>
</SEG>
<SEG id="segment-16" start_char="559" end_char="563">
<ORIGINAL_TEXT>00:00</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="unknown" morph="none" start_char="559" end_char="563">00:00</TOKEN>
</SEG>
<SEG id="segment-17" start_char="566" end_char="570">
<ORIGINAL_TEXT>00:00</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="unknown" morph="none" start_char="566" end_char="570">00:00</TOKEN>
</SEG>
<SEG id="segment-18" start_char="573" end_char="577">
<ORIGINAL_TEXT>00:00</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="unknown" morph="none" start_char="573" end_char="577">00:00</TOKEN>
</SEG>
<SEG id="segment-19" start_char="580" end_char="589">
<ORIGINAL_TEXT>Más Videos</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="580" end_char="582">Más</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="584" end_char="589">Videos</TOKEN>
</SEG>
<SEG id="segment-20" start_char="592" end_char="667">
<ORIGINAL_TEXT>La emoción de Bryan Gil al conocer su convocatoria con la Selección Española</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="592" end_char="593">La</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="595" end_char="601">emoción</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="603" end_char="604">de</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="606" end_char="610">Bryan</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="612" end_char="614">Gil</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="616" end_char="617">al</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="619" end_char="625">conocer</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="627" end_char="628">su</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="630" end_char="641">convocatoria</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="643" end_char="645">con</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="647" end_char="648">la</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="650" end_char="658">Selección</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="660" end_char="667">Española</TOKEN>
</SEG>
<SEG id="segment-21" start_char="670" end_char="767">
<ORIGINAL_TEXT>Un accidente entre dos camiones provoca enormes retenciones en la AP-7 en Santa Perpètua de Mogoda</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="670" end_char="671">Un</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="673" end_char="681">accidente</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="683" end_char="687">entre</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="689" end_char="691">dos</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="693" end_char="700">camiones</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="702" end_char="708">provoca</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="710" end_char="716">enormes</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="718" end_char="728">retenciones</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="730" end_char="731">en</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="733" end_char="734">la</TOKEN>
<TOKEN id="token-21-10" pos="unknown" morph="none" start_char="736" end_char="739">AP-7</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="741" end_char="742">en</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="744" end_char="748">Santa</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="750" end_char="757">Perpètua</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="759" end_char="760">de</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="762" end_char="767">Mogoda</TOKEN>
</SEG>
<SEG id="segment-22" start_char="770" end_char="842">
<ORIGINAL_TEXT>La Policía localiza un bebé de cinco meses en una fiesta ilegal en Madrid</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="770" end_char="771">La</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="773" end_char="779">Policía</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="781" end_char="788">localiza</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="790" end_char="791">un</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="793" end_char="796">bebé</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="798" end_char="799">de</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="801" end_char="805">cinco</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="807" end_char="811">meses</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="813" end_char="814">en</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="816" end_char="818">una</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="820" end_char="825">fiesta</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="827" end_char="832">ilegal</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="834" end_char="835">en</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="837" end_char="842">Madrid</TOKEN>
</SEG>
<SEG id="segment-23" start_char="845" end_char="926">
<ORIGINAL_TEXT>Ayuso dice que España 'le debe una': "Hemos sacado a Pablo Iglesias de la Moncloa"</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="845" end_char="849">Ayuso</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="851" end_char="854">dice</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="856" end_char="858">que</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="860" end_char="865">España</TOKEN>
<TOKEN id="token-23-4" pos="punct" morph="none" start_char="867" end_char="867">'</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="868" end_char="869">le</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="871" end_char="874">debe</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="876" end_char="878">una</TOKEN>
<TOKEN id="token-23-8" pos="punct" morph="none" start_char="879" end_char="880">':</TOKEN>
<TOKEN id="token-23-9" pos="punct" morph="none" start_char="882" end_char="882">"</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="883" end_char="887">Hemos</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="889" end_char="894">sacado</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="896" end_char="896">a</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="898" end_char="902">Pablo</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="904" end_char="911">Iglesias</TOKEN>
<TOKEN id="token-23-15" pos="word" morph="none" start_char="913" end_char="914">de</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="916" end_char="917">la</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="919" end_char="925">Moncloa</TOKEN>
<TOKEN id="token-23-18" pos="punct" morph="none" start_char="926" end_char="926">"</TOKEN>
</SEG>
<SEG id="segment-24" start_char="929" end_char="1002">
<ORIGINAL_TEXT>España mantiene por ahora la vacuna de AstraZeneca solo para menores de 55</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="929" end_char="934">España</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="936" end_char="943">mantiene</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="945" end_char="947">por</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="949" end_char="953">ahora</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="955" end_char="956">la</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="958" end_char="963">vacuna</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="965" end_char="966">de</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="968" end_char="978">AstraZeneca</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="980" end_char="983">solo</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="985" end_char="988">para</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="990" end_char="996">menores</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="998" end_char="999">de</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="1001" end_char="1002">55</TOKEN>
</SEG>
<SEG id="segment-25" start_char="1005" end_char="1076">
<ORIGINAL_TEXT>Sara Carbonero e Iker Casillas, ¿se confirma la separación de la pareja?</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="1005" end_char="1008">Sara</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="1010" end_char="1018">Carbonero</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="1020" end_char="1020">e</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="1022" end_char="1025">Iker</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="1027" end_char="1034">Casillas</TOKEN>
<TOKEN id="token-25-5" pos="punct" morph="none" start_char="1035" end_char="1035">,</TOKEN>
<TOKEN id="token-25-6" pos="punct" morph="none" start_char="1037" end_char="1037">¿</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="1038" end_char="1039">se</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="1041" end_char="1048">confirma</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="1050" end_char="1051">la</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="1053" end_char="1062">separación</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="1064" end_char="1065">de</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="1067" end_char="1068">la</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="1070" end_char="1075">pareja</TOKEN>
<TOKEN id="token-25-14" pos="punct" morph="none" start_char="1076" end_char="1076">?</TOKEN>
</SEG>
<SEG id="segment-26" start_char="1079" end_char="1155">
<ORIGINAL_TEXT>Megan Fox nos descubre a las poderosas guerras vikingas en 'Leyendas ocultas'</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="1079" end_char="1083">Megan</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="1085" end_char="1087">Fox</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="1089" end_char="1091">nos</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="1093" end_char="1100">descubre</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="1102" end_char="1102">a</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="1104" end_char="1106">las</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="1108" end_char="1116">poderosas</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="1118" end_char="1124">guerras</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="1126" end_char="1133">vikingas</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="1135" end_char="1136">en</TOKEN>
<TOKEN id="token-26-10" pos="punct" morph="none" start_char="1138" end_char="1138">'</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="1139" end_char="1146">Leyendas</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="1148" end_char="1154">ocultas</TOKEN>
<TOKEN id="token-26-13" pos="punct" morph="none" start_char="1155" end_char="1155">'</TOKEN>
</SEG>
<SEG id="segment-27" start_char="1158" end_char="1210">
<ORIGINAL_TEXT>Casi se inmola tras un fallido lanzamiento de granada</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="1158" end_char="1161">Casi</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="1163" end_char="1164">se</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="1166" end_char="1171">inmola</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="1173" end_char="1176">tras</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="1178" end_char="1179">un</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="1181" end_char="1187">fallido</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="1189" end_char="1199">lanzamiento</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="1201" end_char="1202">de</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="1204" end_char="1210">granada</TOKEN>
</SEG>
<SEG id="segment-28" start_char="1213" end_char="1218">
<ORIGINAL_TEXT>Cerrar</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="1213" end_char="1218">Cerrar</TOKEN>
</SEG>
<SEG id="segment-29" start_char="1221" end_char="1431">
<ORIGINAL_TEXT>La viróloga china que aseguró que tenía pruebas que demostraban que la Covid-19 fue fabricada en un laboratorio en su país subió esta semana a internet un documento de 26 páginas para demostrar sus afirmaciones.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="1221" end_char="1222">La</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="1224" end_char="1231">viróloga</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="1233" end_char="1237">china</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="1239" end_char="1241">que</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="1243" end_char="1249">aseguró</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="1251" end_char="1253">que</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="1255" end_char="1259">tenía</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="1261" end_char="1267">pruebas</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="1269" end_char="1271">que</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="1273" end_char="1283">demostraban</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="1285" end_char="1287">que</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="1289" end_char="1290">la</TOKEN>
<TOKEN id="token-29-12" pos="unknown" morph="none" start_char="1292" end_char="1299">Covid-19</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="1301" end_char="1303">fue</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="1305" end_char="1313">fabricada</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="1315" end_char="1316">en</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="1318" end_char="1319">un</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="1321" end_char="1331">laboratorio</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="1333" end_char="1334">en</TOKEN>
<TOKEN id="token-29-19" pos="word" morph="none" start_char="1336" end_char="1337">su</TOKEN>
<TOKEN id="token-29-20" pos="word" morph="none" start_char="1339" end_char="1342">país</TOKEN>
<TOKEN id="token-29-21" pos="word" morph="none" start_char="1344" end_char="1348">subió</TOKEN>
<TOKEN id="token-29-22" pos="word" morph="none" start_char="1350" end_char="1353">esta</TOKEN>
<TOKEN id="token-29-23" pos="word" morph="none" start_char="1355" end_char="1360">semana</TOKEN>
<TOKEN id="token-29-24" pos="word" morph="none" start_char="1362" end_char="1362">a</TOKEN>
<TOKEN id="token-29-25" pos="word" morph="none" start_char="1364" end_char="1371">internet</TOKEN>
<TOKEN id="token-29-26" pos="word" morph="none" start_char="1373" end_char="1374">un</TOKEN>
<TOKEN id="token-29-27" pos="word" morph="none" start_char="1376" end_char="1384">documento</TOKEN>
<TOKEN id="token-29-28" pos="word" morph="none" start_char="1386" end_char="1387">de</TOKEN>
<TOKEN id="token-29-29" pos="word" morph="none" start_char="1389" end_char="1390">26</TOKEN>
<TOKEN id="token-29-30" pos="word" morph="none" start_char="1392" end_char="1398">páginas</TOKEN>
<TOKEN id="token-29-31" pos="word" morph="none" start_char="1400" end_char="1403">para</TOKEN>
<TOKEN id="token-29-32" pos="word" morph="none" start_char="1405" end_char="1413">demostrar</TOKEN>
<TOKEN id="token-29-33" pos="word" morph="none" start_char="1415" end_char="1417">sus</TOKEN>
<TOKEN id="token-29-34" pos="word" morph="none" start_char="1419" end_char="1430">afirmaciones</TOKEN>
<TOKEN id="token-29-35" pos="punct" morph="none" start_char="1431" end_char="1431">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="1434" end_char="1572">
<ORIGINAL_TEXT>El informe de Li-Meng Yan ha sido analizado por investigadores de todo el mundo que han concluido que no tiene evidencia científica alguna.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="1434" end_char="1435">El</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="1437" end_char="1443">informe</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="1445" end_char="1446">de</TOKEN>
<TOKEN id="token-30-3" pos="unknown" morph="none" start_char="1448" end_char="1454">Li-Meng</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="1456" end_char="1458">Yan</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="1460" end_char="1461">ha</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="1463" end_char="1466">sido</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="1468" end_char="1476">analizado</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="1478" end_char="1480">por</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="1482" end_char="1495">investigadores</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="1497" end_char="1498">de</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="1500" end_char="1503">todo</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="1505" end_char="1506">el</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="1508" end_char="1512">mundo</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="1514" end_char="1516">que</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="1518" end_char="1520">han</TOKEN>
<TOKEN id="token-30-16" pos="word" morph="none" start_char="1522" end_char="1530">concluido</TOKEN>
<TOKEN id="token-30-17" pos="word" morph="none" start_char="1532" end_char="1534">que</TOKEN>
<TOKEN id="token-30-18" pos="word" morph="none" start_char="1536" end_char="1537">no</TOKEN>
<TOKEN id="token-30-19" pos="word" morph="none" start_char="1539" end_char="1543">tiene</TOKEN>
<TOKEN id="token-30-20" pos="word" morph="none" start_char="1545" end_char="1553">evidencia</TOKEN>
<TOKEN id="token-30-21" pos="word" morph="none" start_char="1555" end_char="1564">científica</TOKEN>
<TOKEN id="token-30-22" pos="word" morph="none" start_char="1566" end_char="1571">alguna</TOKEN>
<TOKEN id="token-30-23" pos="punct" morph="none" start_char="1572" end_char="1572">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="1574" end_char="1775">
<ORIGINAL_TEXT>Los expertos aseguran que la viróloga ha mezclado en su documento investigaciones reales con datos sesgados, llegando incluso a citar estudios españoles del CSIC que desmienten sus propias afirmaciones.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="1574" end_char="1576">Los</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="1578" end_char="1585">expertos</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="1587" end_char="1594">aseguran</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="1596" end_char="1598">que</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="1600" end_char="1601">la</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="1603" end_char="1610">viróloga</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="1612" end_char="1613">ha</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="1615" end_char="1622">mezclado</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="1624" end_char="1625">en</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="1627" end_char="1628">su</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="1630" end_char="1638">documento</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="1640" end_char="1654">investigaciones</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="1656" end_char="1661">reales</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="1663" end_char="1665">con</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="1667" end_char="1671">datos</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="1673" end_char="1680">sesgados</TOKEN>
<TOKEN id="token-31-16" pos="punct" morph="none" start_char="1681" end_char="1681">,</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="1683" end_char="1690">llegando</TOKEN>
<TOKEN id="token-31-18" pos="word" morph="none" start_char="1692" end_char="1698">incluso</TOKEN>
<TOKEN id="token-31-19" pos="word" morph="none" start_char="1700" end_char="1700">a</TOKEN>
<TOKEN id="token-31-20" pos="word" morph="none" start_char="1702" end_char="1706">citar</TOKEN>
<TOKEN id="token-31-21" pos="word" morph="none" start_char="1708" end_char="1715">estudios</TOKEN>
<TOKEN id="token-31-22" pos="word" morph="none" start_char="1717" end_char="1725">españoles</TOKEN>
<TOKEN id="token-31-23" pos="word" morph="none" start_char="1727" end_char="1729">del</TOKEN>
<TOKEN id="token-31-24" pos="word" morph="none" start_char="1731" end_char="1734">CSIC</TOKEN>
<TOKEN id="token-31-25" pos="word" morph="none" start_char="1736" end_char="1738">que</TOKEN>
<TOKEN id="token-31-26" pos="word" morph="none" start_char="1740" end_char="1749">desmienten</TOKEN>
<TOKEN id="token-31-27" pos="word" morph="none" start_char="1751" end_char="1753">sus</TOKEN>
<TOKEN id="token-31-28" pos="word" morph="none" start_char="1755" end_char="1761">propias</TOKEN>
<TOKEN id="token-31-29" pos="word" morph="none" start_char="1763" end_char="1774">afirmaciones</TOKEN>
<TOKEN id="token-31-30" pos="punct" morph="none" start_char="1775" end_char="1775">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="1778" end_char="1898">
<ORIGINAL_TEXT>Las conclusiones de Li-Meng Yang han sido financiadas por Steve Bannon, el ideólogo detrás de la campaña de Donald Trump.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="1778" end_char="1780">Las</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="1782" end_char="1793">conclusiones</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="1795" end_char="1796">de</TOKEN>
<TOKEN id="token-32-3" pos="unknown" morph="none" start_char="1798" end_char="1804">Li-Meng</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="1806" end_char="1809">Yang</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="1811" end_char="1813">han</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="1815" end_char="1818">sido</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="1820" end_char="1830">financiadas</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="1832" end_char="1834">por</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="1836" end_char="1840">Steve</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="1842" end_char="1847">Bannon</TOKEN>
<TOKEN id="token-32-11" pos="punct" morph="none" start_char="1848" end_char="1848">,</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="1850" end_char="1851">el</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="1853" end_char="1860">ideólogo</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="1862" end_char="1867">detrás</TOKEN>
<TOKEN id="token-32-15" pos="word" morph="none" start_char="1869" end_char="1870">de</TOKEN>
<TOKEN id="token-32-16" pos="word" morph="none" start_char="1872" end_char="1873">la</TOKEN>
<TOKEN id="token-32-17" pos="word" morph="none" start_char="1875" end_char="1881">campaña</TOKEN>
<TOKEN id="token-32-18" pos="word" morph="none" start_char="1883" end_char="1884">de</TOKEN>
<TOKEN id="token-32-19" pos="word" morph="none" start_char="1886" end_char="1891">Donald</TOKEN>
<TOKEN id="token-32-20" pos="word" morph="none" start_char="1893" end_char="1897">Trump</TOKEN>
<TOKEN id="token-32-21" pos="punct" morph="none" start_char="1898" end_char="1898">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="1900" end_char="2085">
<ORIGINAL_TEXT>Este informe daría alas a las cuatro demandas que existen en Estados Unidos contra China, además de exonerar de responsabilidad al presidente norteamericano de la gestión de la pandemia.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="1900" end_char="1903">Este</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="1905" end_char="1911">informe</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="1913" end_char="1917">daría</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="1919" end_char="1922">alas</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="1924" end_char="1924">a</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="1926" end_char="1928">las</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="1930" end_char="1935">cuatro</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="1937" end_char="1944">demandas</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="1946" end_char="1948">que</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="1950" end_char="1956">existen</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="1958" end_char="1959">en</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="1961" end_char="1967">Estados</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="1969" end_char="1974">Unidos</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="1976" end_char="1981">contra</TOKEN>
<TOKEN id="token-33-14" pos="word" morph="none" start_char="1983" end_char="1987">China</TOKEN>
<TOKEN id="token-33-15" pos="punct" morph="none" start_char="1988" end_char="1988">,</TOKEN>
<TOKEN id="token-33-16" pos="word" morph="none" start_char="1990" end_char="1995">además</TOKEN>
<TOKEN id="token-33-17" pos="word" morph="none" start_char="1997" end_char="1998">de</TOKEN>
<TOKEN id="token-33-18" pos="word" morph="none" start_char="2000" end_char="2007">exonerar</TOKEN>
<TOKEN id="token-33-19" pos="word" morph="none" start_char="2009" end_char="2010">de</TOKEN>
<TOKEN id="token-33-20" pos="word" morph="none" start_char="2012" end_char="2026">responsabilidad</TOKEN>
<TOKEN id="token-33-21" pos="word" morph="none" start_char="2028" end_char="2029">al</TOKEN>
<TOKEN id="token-33-22" pos="word" morph="none" start_char="2031" end_char="2040">presidente</TOKEN>
<TOKEN id="token-33-23" pos="word" morph="none" start_char="2042" end_char="2055">norteamericano</TOKEN>
<TOKEN id="token-33-24" pos="word" morph="none" start_char="2057" end_char="2058">de</TOKEN>
<TOKEN id="token-33-25" pos="word" morph="none" start_char="2060" end_char="2061">la</TOKEN>
<TOKEN id="token-33-26" pos="word" morph="none" start_char="2063" end_char="2069">gestión</TOKEN>
<TOKEN id="token-33-27" pos="word" morph="none" start_char="2071" end_char="2072">de</TOKEN>
<TOKEN id="token-33-28" pos="word" morph="none" start_char="2074" end_char="2075">la</TOKEN>
<TOKEN id="token-33-29" pos="word" morph="none" start_char="2077" end_char="2084">pandemia</TOKEN>
<TOKEN id="token-33-30" pos="punct" morph="none" start_char="2085" end_char="2085">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="2087" end_char="2203">
<ORIGINAL_TEXT>Esta tesis también es un soplo de aliento para los negacionistas de la pandemia que han proliferado en todo el mundo.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="2087" end_char="2090">Esta</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="2092" end_char="2096">tesis</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="2098" end_char="2104">también</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="2106" end_char="2107">es</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="2109" end_char="2110">un</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="2112" end_char="2116">soplo</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="2118" end_char="2119">de</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="2121" end_char="2127">aliento</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="2129" end_char="2132">para</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="2134" end_char="2136">los</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="2138" end_char="2150">negacionistas</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="2152" end_char="2153">de</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="2155" end_char="2156">la</TOKEN>
<TOKEN id="token-34-13" pos="word" morph="none" start_char="2158" end_char="2165">pandemia</TOKEN>
<TOKEN id="token-34-14" pos="word" morph="none" start_char="2167" end_char="2169">que</TOKEN>
<TOKEN id="token-34-15" pos="word" morph="none" start_char="2171" end_char="2173">han</TOKEN>
<TOKEN id="token-34-16" pos="word" morph="none" start_char="2175" end_char="2185">proliferado</TOKEN>
<TOKEN id="token-34-17" pos="word" morph="none" start_char="2187" end_char="2188">en</TOKEN>
<TOKEN id="token-34-18" pos="word" morph="none" start_char="2190" end_char="2193">todo</TOKEN>
<TOKEN id="token-34-19" pos="word" morph="none" start_char="2195" end_char="2196">el</TOKEN>
<TOKEN id="token-34-20" pos="word" morph="none" start_char="2198" end_char="2202">mundo</TOKEN>
<TOKEN id="token-34-21" pos="punct" morph="none" start_char="2203" end_char="2203">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="2206" end_char="2280">
<ORIGINAL_TEXT>Hace semanas que Li-Meng Yang huyó de China y se refugió en Estados Unidos.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="2206" end_char="2209">Hace</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="2211" end_char="2217">semanas</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="2219" end_char="2221">que</TOKEN>
<TOKEN id="token-35-3" pos="unknown" morph="none" start_char="2223" end_char="2229">Li-Meng</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="2231" end_char="2234">Yang</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="2236" end_char="2239">huyó</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="2241" end_char="2242">de</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="2244" end_char="2248">China</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="2250" end_char="2250">y</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="2252" end_char="2253">se</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="2255" end_char="2261">refugió</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="2263" end_char="2264">en</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="2266" end_char="2272">Estados</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="2274" end_char="2279">Unidos</TOKEN>
<TOKEN id="token-35-14" pos="punct" morph="none" start_char="2280" end_char="2280">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="2282" end_char="2476">
<ORIGINAL_TEXT>Según ha mantenido en repetidas ocasiones, el motivo de su huida no fue otro que escapar de las presiones del Gobierno chino por haber hablado sin tapujos sobre el posible origen del coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="2282" end_char="2286">Según</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="2288" end_char="2289">ha</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="2291" end_char="2299">mantenido</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="2301" end_char="2302">en</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="2304" end_char="2312">repetidas</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="2314" end_char="2322">ocasiones</TOKEN>
<TOKEN id="token-36-6" pos="punct" morph="none" start_char="2323" end_char="2323">,</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="2325" end_char="2326">el</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="2328" end_char="2333">motivo</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="2335" end_char="2336">de</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="2338" end_char="2339">su</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="2341" end_char="2345">huida</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="2347" end_char="2348">no</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="2350" end_char="2352">fue</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="2354" end_char="2357">otro</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="2359" end_char="2361">que</TOKEN>
<TOKEN id="token-36-16" pos="word" morph="none" start_char="2363" end_char="2369">escapar</TOKEN>
<TOKEN id="token-36-17" pos="word" morph="none" start_char="2371" end_char="2372">de</TOKEN>
<TOKEN id="token-36-18" pos="word" morph="none" start_char="2374" end_char="2376">las</TOKEN>
<TOKEN id="token-36-19" pos="word" morph="none" start_char="2378" end_char="2386">presiones</TOKEN>
<TOKEN id="token-36-20" pos="word" morph="none" start_char="2388" end_char="2390">del</TOKEN>
<TOKEN id="token-36-21" pos="word" morph="none" start_char="2392" end_char="2399">Gobierno</TOKEN>
<TOKEN id="token-36-22" pos="word" morph="none" start_char="2401" end_char="2405">chino</TOKEN>
<TOKEN id="token-36-23" pos="word" morph="none" start_char="2407" end_char="2409">por</TOKEN>
<TOKEN id="token-36-24" pos="word" morph="none" start_char="2411" end_char="2415">haber</TOKEN>
<TOKEN id="token-36-25" pos="word" morph="none" start_char="2417" end_char="2423">hablado</TOKEN>
<TOKEN id="token-36-26" pos="word" morph="none" start_char="2425" end_char="2427">sin</TOKEN>
<TOKEN id="token-36-27" pos="word" morph="none" start_char="2429" end_char="2435">tapujos</TOKEN>
<TOKEN id="token-36-28" pos="word" morph="none" start_char="2437" end_char="2441">sobre</TOKEN>
<TOKEN id="token-36-29" pos="word" morph="none" start_char="2443" end_char="2444">el</TOKEN>
<TOKEN id="token-36-30" pos="word" morph="none" start_char="2446" end_char="2452">posible</TOKEN>
<TOKEN id="token-36-31" pos="word" morph="none" start_char="2454" end_char="2459">origen</TOKEN>
<TOKEN id="token-36-32" pos="word" morph="none" start_char="2461" end_char="2463">del</TOKEN>
<TOKEN id="token-36-33" pos="word" morph="none" start_char="2465" end_char="2475">coronavirus</TOKEN>
<TOKEN id="token-36-34" pos="punct" morph="none" start_char="2476" end_char="2476">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="2479" end_char="2647">
<ORIGINAL_TEXT>El director general de la Organización Mundial de la Salud (OMS), Tedros Adhanom Ghebreyesus, volvió a incidir este sábado en que el coronavirus tiene un origen natural.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="2479" end_char="2480">El</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="2482" end_char="2489">director</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="2491" end_char="2497">general</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="2499" end_char="2500">de</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="2502" end_char="2503">la</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="2505" end_char="2516">Organización</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="2518" end_char="2524">Mundial</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="2526" end_char="2527">de</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="2529" end_char="2530">la</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="2532" end_char="2536">Salud</TOKEN>
<TOKEN id="token-37-10" pos="punct" morph="none" start_char="2538" end_char="2538">(</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="2539" end_char="2541">OMS</TOKEN>
<TOKEN id="token-37-12" pos="punct" morph="none" start_char="2542" end_char="2543">),</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="2545" end_char="2550">Tedros</TOKEN>
<TOKEN id="token-37-14" pos="word" morph="none" start_char="2552" end_char="2558">Adhanom</TOKEN>
<TOKEN id="token-37-15" pos="word" morph="none" start_char="2560" end_char="2570">Ghebreyesus</TOKEN>
<TOKEN id="token-37-16" pos="punct" morph="none" start_char="2571" end_char="2571">,</TOKEN>
<TOKEN id="token-37-17" pos="word" morph="none" start_char="2573" end_char="2578">volvió</TOKEN>
<TOKEN id="token-37-18" pos="word" morph="none" start_char="2580" end_char="2580">a</TOKEN>
<TOKEN id="token-37-19" pos="word" morph="none" start_char="2582" end_char="2588">incidir</TOKEN>
<TOKEN id="token-37-20" pos="word" morph="none" start_char="2590" end_char="2593">este</TOKEN>
<TOKEN id="token-37-21" pos="word" morph="none" start_char="2595" end_char="2600">sábado</TOKEN>
<TOKEN id="token-37-22" pos="word" morph="none" start_char="2602" end_char="2603">en</TOKEN>
<TOKEN id="token-37-23" pos="word" morph="none" start_char="2605" end_char="2607">que</TOKEN>
<TOKEN id="token-37-24" pos="word" morph="none" start_char="2609" end_char="2610">el</TOKEN>
<TOKEN id="token-37-25" pos="word" morph="none" start_char="2612" end_char="2622">coronavirus</TOKEN>
<TOKEN id="token-37-26" pos="word" morph="none" start_char="2624" end_char="2628">tiene</TOKEN>
<TOKEN id="token-37-27" pos="word" morph="none" start_char="2630" end_char="2631">un</TOKEN>
<TOKEN id="token-37-28" pos="word" morph="none" start_char="2633" end_char="2638">origen</TOKEN>
<TOKEN id="token-37-29" pos="word" morph="none" start_char="2640" end_char="2646">natural</TOKEN>
<TOKEN id="token-37-30" pos="punct" morph="none" start_char="2647" end_char="2647">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="2649" end_char="2888">
<ORIGINAL_TEXT>Preguntado acerca de una entrevista en la que alguien afirmaba que el virus provenía de un laboratorio, es decir, que fue creado artificialmente, Ghebreyesus ratificó que el coronavirus que causa la Covid-19 "ha ocurrido de manera natural".</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="2649" end_char="2658">Preguntado</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="2660" end_char="2665">acerca</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="2667" end_char="2668">de</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="2670" end_char="2672">una</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="2674" end_char="2683">entrevista</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="2685" end_char="2686">en</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="2688" end_char="2689">la</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="2691" end_char="2693">que</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="2695" end_char="2701">alguien</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="2703" end_char="2710">afirmaba</TOKEN>
<TOKEN id="token-38-10" pos="word" morph="none" start_char="2712" end_char="2714">que</TOKEN>
<TOKEN id="token-38-11" pos="word" morph="none" start_char="2716" end_char="2717">el</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="2719" end_char="2723">virus</TOKEN>
<TOKEN id="token-38-13" pos="word" morph="none" start_char="2725" end_char="2732">provenía</TOKEN>
<TOKEN id="token-38-14" pos="word" morph="none" start_char="2734" end_char="2735">de</TOKEN>
<TOKEN id="token-38-15" pos="word" morph="none" start_char="2737" end_char="2738">un</TOKEN>
<TOKEN id="token-38-16" pos="word" morph="none" start_char="2740" end_char="2750">laboratorio</TOKEN>
<TOKEN id="token-38-17" pos="punct" morph="none" start_char="2751" end_char="2751">,</TOKEN>
<TOKEN id="token-38-18" pos="word" morph="none" start_char="2753" end_char="2754">es</TOKEN>
<TOKEN id="token-38-19" pos="word" morph="none" start_char="2756" end_char="2760">decir</TOKEN>
<TOKEN id="token-38-20" pos="punct" morph="none" start_char="2761" end_char="2761">,</TOKEN>
<TOKEN id="token-38-21" pos="word" morph="none" start_char="2763" end_char="2765">que</TOKEN>
<TOKEN id="token-38-22" pos="word" morph="none" start_char="2767" end_char="2769">fue</TOKEN>
<TOKEN id="token-38-23" pos="word" morph="none" start_char="2771" end_char="2776">creado</TOKEN>
<TOKEN id="token-38-24" pos="word" morph="none" start_char="2778" end_char="2792">artificialmente</TOKEN>
<TOKEN id="token-38-25" pos="punct" morph="none" start_char="2793" end_char="2793">,</TOKEN>
<TOKEN id="token-38-26" pos="word" morph="none" start_char="2795" end_char="2805">Ghebreyesus</TOKEN>
<TOKEN id="token-38-27" pos="word" morph="none" start_char="2807" end_char="2814">ratificó</TOKEN>
<TOKEN id="token-38-28" pos="word" morph="none" start_char="2816" end_char="2818">que</TOKEN>
<TOKEN id="token-38-29" pos="word" morph="none" start_char="2820" end_char="2821">el</TOKEN>
<TOKEN id="token-38-30" pos="word" morph="none" start_char="2823" end_char="2833">coronavirus</TOKEN>
<TOKEN id="token-38-31" pos="word" morph="none" start_char="2835" end_char="2837">que</TOKEN>
<TOKEN id="token-38-32" pos="word" morph="none" start_char="2839" end_char="2843">causa</TOKEN>
<TOKEN id="token-38-33" pos="word" morph="none" start_char="2845" end_char="2846">la</TOKEN>
<TOKEN id="token-38-34" pos="unknown" morph="none" start_char="2848" end_char="2855">Covid-19</TOKEN>
<TOKEN id="token-38-35" pos="punct" morph="none" start_char="2857" end_char="2857">"</TOKEN>
<TOKEN id="token-38-36" pos="word" morph="none" start_char="2858" end_char="2859">ha</TOKEN>
<TOKEN id="token-38-37" pos="word" morph="none" start_char="2861" end_char="2868">ocurrido</TOKEN>
<TOKEN id="token-38-38" pos="word" morph="none" start_char="2870" end_char="2871">de</TOKEN>
<TOKEN id="token-38-39" pos="word" morph="none" start_char="2873" end_char="2878">manera</TOKEN>
<TOKEN id="token-38-40" pos="word" morph="none" start_char="2880" end_char="2886">natural</TOKEN>
<TOKEN id="token-38-41" pos="punct" morph="none" start_char="2887" end_char="2888">".</TOKEN>
</SEG>
<SEG id="segment-39" start_char="2891" end_char="3117">
<ORIGINAL_TEXT>"Todas las publicaciones que hemos visto apuntan a que es algo que se ha generado de manera natural", aseguró el médico, de alguna forma tirando también por tierra los postulados que mantiene la viróloga china huida de su país.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="punct" morph="none" start_char="2891" end_char="2891">"</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="2892" end_char="2896">Todas</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="2898" end_char="2900">las</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="2902" end_char="2914">publicaciones</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="2916" end_char="2918">que</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="2920" end_char="2924">hemos</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="2926" end_char="2930">visto</TOKEN>
<TOKEN id="token-39-7" pos="word" morph="none" start_char="2932" end_char="2938">apuntan</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="2940" end_char="2940">a</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="2942" end_char="2944">que</TOKEN>
<TOKEN id="token-39-10" pos="word" morph="none" start_char="2946" end_char="2947">es</TOKEN>
<TOKEN id="token-39-11" pos="word" morph="none" start_char="2949" end_char="2952">algo</TOKEN>
<TOKEN id="token-39-12" pos="word" morph="none" start_char="2954" end_char="2956">que</TOKEN>
<TOKEN id="token-39-13" pos="word" morph="none" start_char="2958" end_char="2959">se</TOKEN>
<TOKEN id="token-39-14" pos="word" morph="none" start_char="2961" end_char="2962">ha</TOKEN>
<TOKEN id="token-39-15" pos="word" morph="none" start_char="2964" end_char="2971">generado</TOKEN>
<TOKEN id="token-39-16" pos="word" morph="none" start_char="2973" end_char="2974">de</TOKEN>
<TOKEN id="token-39-17" pos="word" morph="none" start_char="2976" end_char="2981">manera</TOKEN>
<TOKEN id="token-39-18" pos="word" morph="none" start_char="2983" end_char="2989">natural</TOKEN>
<TOKEN id="token-39-19" pos="punct" morph="none" start_char="2990" end_char="2991">",</TOKEN>
<TOKEN id="token-39-20" pos="word" morph="none" start_char="2993" end_char="2999">aseguró</TOKEN>
<TOKEN id="token-39-21" pos="word" morph="none" start_char="3001" end_char="3002">el</TOKEN>
<TOKEN id="token-39-22" pos="word" morph="none" start_char="3004" end_char="3009">médico</TOKEN>
<TOKEN id="token-39-23" pos="punct" morph="none" start_char="3010" end_char="3010">,</TOKEN>
<TOKEN id="token-39-24" pos="word" morph="none" start_char="3012" end_char="3013">de</TOKEN>
<TOKEN id="token-39-25" pos="word" morph="none" start_char="3015" end_char="3020">alguna</TOKEN>
<TOKEN id="token-39-26" pos="word" morph="none" start_char="3022" end_char="3026">forma</TOKEN>
<TOKEN id="token-39-27" pos="word" morph="none" start_char="3028" end_char="3034">tirando</TOKEN>
<TOKEN id="token-39-28" pos="word" morph="none" start_char="3036" end_char="3042">también</TOKEN>
<TOKEN id="token-39-29" pos="word" morph="none" start_char="3044" end_char="3046">por</TOKEN>
<TOKEN id="token-39-30" pos="word" morph="none" start_char="3048" end_char="3053">tierra</TOKEN>
<TOKEN id="token-39-31" pos="word" morph="none" start_char="3055" end_char="3057">los</TOKEN>
<TOKEN id="token-39-32" pos="word" morph="none" start_char="3059" end_char="3068">postulados</TOKEN>
<TOKEN id="token-39-33" pos="word" morph="none" start_char="3070" end_char="3072">que</TOKEN>
<TOKEN id="token-39-34" pos="word" morph="none" start_char="3074" end_char="3081">mantiene</TOKEN>
<TOKEN id="token-39-35" pos="word" morph="none" start_char="3083" end_char="3084">la</TOKEN>
<TOKEN id="token-39-36" pos="word" morph="none" start_char="3086" end_char="3093">viróloga</TOKEN>
<TOKEN id="token-39-37" pos="word" morph="none" start_char="3095" end_char="3099">china</TOKEN>
<TOKEN id="token-39-38" pos="word" morph="none" start_char="3101" end_char="3105">huida</TOKEN>
<TOKEN id="token-39-39" pos="word" morph="none" start_char="3107" end_char="3108">de</TOKEN>
<TOKEN id="token-39-40" pos="word" morph="none" start_char="3110" end_char="3111">su</TOKEN>
<TOKEN id="token-39-41" pos="word" morph="none" start_char="3113" end_char="3116">país</TOKEN>
<TOKEN id="token-39-42" pos="punct" morph="none" start_char="3117" end_char="3117">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
