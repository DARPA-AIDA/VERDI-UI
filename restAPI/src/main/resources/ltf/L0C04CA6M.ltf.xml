<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CA6M" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="5307" raw_text_md5="96e7dfb8cde68728ab52128ee6a3a62d">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="86">
<ORIGINAL_TEXT>In search for origin, no sample of COVID-19 was kept at Wuhan lab, WHO researchers say</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="2">In</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="4" end_char="9">search</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="11" end_char="13">for</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="15" end_char="20">origin</TOKEN>
<TOKEN id="token-0-4" pos="punct" morph="none" start_char="21" end_char="21">,</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="23" end_char="24">no</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="26" end_char="31">sample</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="33" end_char="34">of</TOKEN>
<TOKEN id="token-0-8" pos="unknown" morph="none" start_char="36" end_char="43">COVID-19</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="45" end_char="47">was</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="49" end_char="52">kept</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="54" end_char="55">at</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="57" end_char="61">Wuhan</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="63" end_char="65">lab</TOKEN>
<TOKEN id="token-0-14" pos="punct" morph="none" start_char="66" end_char="66">,</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="68" end_char="70">WHO</TOKEN>
<TOKEN id="token-0-16" pos="word" morph="none" start_char="72" end_char="82">researchers</TOKEN>
<TOKEN id="token-0-17" pos="word" morph="none" start_char="84" end_char="86">say</TOKEN>
</SEG>
<SEG id="segment-1" start_char="90" end_char="370">
<ORIGINAL_TEXT>WUHAN, China (AP) — The coronavirus most likely first appeared in humans after jumping from an animal, a team of international and Chinese scientists looking for the origins of COVID-19 said Tuesday, saying an alternate theory that the virus leaked from a Chinese lab was unlikely.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="90" end_char="94">WUHAN</TOKEN>
<TOKEN id="token-1-1" pos="punct" morph="none" start_char="95" end_char="95">,</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="97" end_char="101">China</TOKEN>
<TOKEN id="token-1-3" pos="punct" morph="none" start_char="103" end_char="103">(</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="104" end_char="105">AP</TOKEN>
<TOKEN id="token-1-5" pos="punct" morph="none" start_char="106" end_char="106">)</TOKEN>
<TOKEN id="token-1-6" pos="punct" morph="none" start_char="108" end_char="108">—</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="110" end_char="112">The</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="114" end_char="124">coronavirus</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="126" end_char="129">most</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="131" end_char="136">likely</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="138" end_char="142">first</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="144" end_char="151">appeared</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="153" end_char="154">in</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="156" end_char="161">humans</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="163" end_char="167">after</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="169" end_char="175">jumping</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="177" end_char="180">from</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="182" end_char="183">an</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="185" end_char="190">animal</TOKEN>
<TOKEN id="token-1-20" pos="punct" morph="none" start_char="191" end_char="191">,</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="193" end_char="193">a</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="195" end_char="198">team</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="200" end_char="201">of</TOKEN>
<TOKEN id="token-1-24" pos="word" morph="none" start_char="203" end_char="215">international</TOKEN>
<TOKEN id="token-1-25" pos="word" morph="none" start_char="217" end_char="219">and</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="221" end_char="227">Chinese</TOKEN>
<TOKEN id="token-1-27" pos="word" morph="none" start_char="229" end_char="238">scientists</TOKEN>
<TOKEN id="token-1-28" pos="word" morph="none" start_char="240" end_char="246">looking</TOKEN>
<TOKEN id="token-1-29" pos="word" morph="none" start_char="248" end_char="250">for</TOKEN>
<TOKEN id="token-1-30" pos="word" morph="none" start_char="252" end_char="254">the</TOKEN>
<TOKEN id="token-1-31" pos="word" morph="none" start_char="256" end_char="262">origins</TOKEN>
<TOKEN id="token-1-32" pos="word" morph="none" start_char="264" end_char="265">of</TOKEN>
<TOKEN id="token-1-33" pos="unknown" morph="none" start_char="267" end_char="274">COVID-19</TOKEN>
<TOKEN id="token-1-34" pos="word" morph="none" start_char="276" end_char="279">said</TOKEN>
<TOKEN id="token-1-35" pos="word" morph="none" start_char="281" end_char="287">Tuesday</TOKEN>
<TOKEN id="token-1-36" pos="punct" morph="none" start_char="288" end_char="288">,</TOKEN>
<TOKEN id="token-1-37" pos="word" morph="none" start_char="290" end_char="295">saying</TOKEN>
<TOKEN id="token-1-38" pos="word" morph="none" start_char="297" end_char="298">an</TOKEN>
<TOKEN id="token-1-39" pos="word" morph="none" start_char="300" end_char="308">alternate</TOKEN>
<TOKEN id="token-1-40" pos="word" morph="none" start_char="310" end_char="315">theory</TOKEN>
<TOKEN id="token-1-41" pos="word" morph="none" start_char="317" end_char="320">that</TOKEN>
<TOKEN id="token-1-42" pos="word" morph="none" start_char="322" end_char="324">the</TOKEN>
<TOKEN id="token-1-43" pos="word" morph="none" start_char="326" end_char="330">virus</TOKEN>
<TOKEN id="token-1-44" pos="word" morph="none" start_char="332" end_char="337">leaked</TOKEN>
<TOKEN id="token-1-45" pos="word" morph="none" start_char="339" end_char="342">from</TOKEN>
<TOKEN id="token-1-46" pos="word" morph="none" start_char="344" end_char="344">a</TOKEN>
<TOKEN id="token-1-47" pos="word" morph="none" start_char="346" end_char="352">Chinese</TOKEN>
<TOKEN id="token-1-48" pos="word" morph="none" start_char="354" end_char="356">lab</TOKEN>
<TOKEN id="token-1-49" pos="word" morph="none" start_char="358" end_char="360">was</TOKEN>
<TOKEN id="token-1-50" pos="word" morph="none" start_char="362" end_char="369">unlikely</TOKEN>
<TOKEN id="token-1-51" pos="punct" morph="none" start_char="370" end_char="370">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="373" end_char="656">
<ORIGINAL_TEXT>A closely watched visit by World Health Organization experts to Wuhan — the Chinese city where the first coronavirus cases were discovered — did not dramatically change the current understanding of the early days of the pandemic, said Peter Ben Embarek, the leader of the WHO mission.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="373" end_char="373">A</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="375" end_char="381">closely</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="383" end_char="389">watched</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="391" end_char="395">visit</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="397" end_char="398">by</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="400" end_char="404">World</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="406" end_char="411">Health</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="413" end_char="424">Organization</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="426" end_char="432">experts</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="434" end_char="435">to</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="437" end_char="441">Wuhan</TOKEN>
<TOKEN id="token-2-11" pos="punct" morph="none" start_char="443" end_char="443">—</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="445" end_char="447">the</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="449" end_char="455">Chinese</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="457" end_char="460">city</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="462" end_char="466">where</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="468" end_char="470">the</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="472" end_char="476">first</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="478" end_char="488">coronavirus</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="490" end_char="494">cases</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="496" end_char="499">were</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="501" end_char="510">discovered</TOKEN>
<TOKEN id="token-2-22" pos="punct" morph="none" start_char="512" end_char="512">—</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="514" end_char="516">did</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="518" end_char="520">not</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="522" end_char="533">dramatically</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="535" end_char="540">change</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="542" end_char="544">the</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="546" end_char="552">current</TOKEN>
<TOKEN id="token-2-29" pos="word" morph="none" start_char="554" end_char="566">understanding</TOKEN>
<TOKEN id="token-2-30" pos="word" morph="none" start_char="568" end_char="569">of</TOKEN>
<TOKEN id="token-2-31" pos="word" morph="none" start_char="571" end_char="573">the</TOKEN>
<TOKEN id="token-2-32" pos="word" morph="none" start_char="575" end_char="579">early</TOKEN>
<TOKEN id="token-2-33" pos="word" morph="none" start_char="581" end_char="584">days</TOKEN>
<TOKEN id="token-2-34" pos="word" morph="none" start_char="586" end_char="587">of</TOKEN>
<TOKEN id="token-2-35" pos="word" morph="none" start_char="589" end_char="591">the</TOKEN>
<TOKEN id="token-2-36" pos="word" morph="none" start_char="593" end_char="600">pandemic</TOKEN>
<TOKEN id="token-2-37" pos="punct" morph="none" start_char="601" end_char="601">,</TOKEN>
<TOKEN id="token-2-38" pos="word" morph="none" start_char="603" end_char="606">said</TOKEN>
<TOKEN id="token-2-39" pos="word" morph="none" start_char="608" end_char="612">Peter</TOKEN>
<TOKEN id="token-2-40" pos="word" morph="none" start_char="614" end_char="616">Ben</TOKEN>
<TOKEN id="token-2-41" pos="word" morph="none" start_char="618" end_char="624">Embarek</TOKEN>
<TOKEN id="token-2-42" pos="punct" morph="none" start_char="625" end_char="625">,</TOKEN>
<TOKEN id="token-2-43" pos="word" morph="none" start_char="627" end_char="629">the</TOKEN>
<TOKEN id="token-2-44" pos="word" morph="none" start_char="631" end_char="636">leader</TOKEN>
<TOKEN id="token-2-45" pos="word" morph="none" start_char="638" end_char="639">of</TOKEN>
<TOKEN id="token-2-46" pos="word" morph="none" start_char="641" end_char="643">the</TOKEN>
<TOKEN id="token-2-47" pos="word" morph="none" start_char="645" end_char="647">WHO</TOKEN>
<TOKEN id="token-2-48" pos="word" morph="none" start_char="649" end_char="655">mission</TOKEN>
<TOKEN id="token-2-49" pos="punct" morph="none" start_char="656" end_char="656">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="659" end_char="781">
<ORIGINAL_TEXT>But it did "add details to that story," he said at a news conference as the group wrapped up a four-week visit to the city.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="659" end_char="661">But</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="663" end_char="664">it</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="666" end_char="668">did</TOKEN>
<TOKEN id="token-3-3" pos="punct" morph="none" start_char="670" end_char="670">"</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="671" end_char="673">add</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="675" end_char="681">details</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="683" end_char="684">to</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="686" end_char="689">that</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="691" end_char="695">story</TOKEN>
<TOKEN id="token-3-9" pos="punct" morph="none" start_char="696" end_char="697">,"</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="699" end_char="700">he</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="702" end_char="705">said</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="707" end_char="708">at</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="710" end_char="710">a</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="712" end_char="715">news</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="717" end_char="726">conference</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="728" end_char="729">as</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="731" end_char="733">the</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="735" end_char="739">group</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="741" end_char="747">wrapped</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="749" end_char="750">up</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="752" end_char="752">a</TOKEN>
<TOKEN id="token-3-22" pos="unknown" morph="none" start_char="754" end_char="762">four-week</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="764" end_char="768">visit</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="770" end_char="771">to</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="773" end_char="775">the</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="777" end_char="780">city</TOKEN>
<TOKEN id="token-3-27" pos="punct" morph="none" start_char="781" end_char="781">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="784" end_char="1007">
<ORIGINAL_TEXT>And it allowed the joint Chinese-WHO team to further explore the lab leak theory — which former U.S. President Donald Trump and officials from his administration had put forward without evidence — and decide it was unlikely.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="784" end_char="786">And</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="788" end_char="789">it</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="791" end_char="797">allowed</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="799" end_char="801">the</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="803" end_char="807">joint</TOKEN>
<TOKEN id="token-4-5" pos="unknown" morph="none" start_char="809" end_char="819">Chinese-WHO</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="821" end_char="824">team</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="826" end_char="827">to</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="829" end_char="835">further</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="837" end_char="843">explore</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="845" end_char="847">the</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="849" end_char="851">lab</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="853" end_char="856">leak</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="858" end_char="863">theory</TOKEN>
<TOKEN id="token-4-14" pos="punct" morph="none" start_char="865" end_char="865">—</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="867" end_char="871">which</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="873" end_char="878">former</TOKEN>
<TOKEN id="token-4-17" pos="unknown" morph="none" start_char="880" end_char="882">U.S</TOKEN>
<TOKEN id="token-4-18" pos="punct" morph="none" start_char="883" end_char="883">.</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="885" end_char="893">President</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="895" end_char="900">Donald</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="902" end_char="906">Trump</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="908" end_char="910">and</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="912" end_char="920">officials</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="922" end_char="925">from</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="927" end_char="929">his</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="931" end_char="944">administration</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="946" end_char="948">had</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="950" end_char="952">put</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="954" end_char="960">forward</TOKEN>
<TOKEN id="token-4-30" pos="word" morph="none" start_char="962" end_char="968">without</TOKEN>
<TOKEN id="token-4-31" pos="word" morph="none" start_char="970" end_char="977">evidence</TOKEN>
<TOKEN id="token-4-32" pos="punct" morph="none" start_char="979" end_char="979">—</TOKEN>
<TOKEN id="token-4-33" pos="word" morph="none" start_char="981" end_char="983">and</TOKEN>
<TOKEN id="token-4-34" pos="word" morph="none" start_char="985" end_char="990">decide</TOKEN>
<TOKEN id="token-4-35" pos="word" morph="none" start_char="992" end_char="993">it</TOKEN>
<TOKEN id="token-4-36" pos="word" morph="none" start_char="995" end_char="997">was</TOKEN>
<TOKEN id="token-4-37" pos="word" morph="none" start_char="999" end_char="1006">unlikely</TOKEN>
<TOKEN id="token-4-38" pos="punct" morph="none" start_char="1007" end_char="1007">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="1009" end_char="1198">
<ORIGINAL_TEXT>The Wuhan Institute of Virology is home to many different virus samples, leading to allegations that it may have been the source of the original outbreak, whether on purpose or accidentally.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="1009" end_char="1011">The</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="1013" end_char="1017">Wuhan</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="1019" end_char="1027">Institute</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="1029" end_char="1030">of</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="1032" end_char="1039">Virology</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="1041" end_char="1042">is</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="1044" end_char="1047">home</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="1049" end_char="1050">to</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="1052" end_char="1055">many</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="1057" end_char="1065">different</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="1067" end_char="1071">virus</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="1073" end_char="1079">samples</TOKEN>
<TOKEN id="token-5-12" pos="punct" morph="none" start_char="1080" end_char="1080">,</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="1082" end_char="1088">leading</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="1090" end_char="1091">to</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="1093" end_char="1103">allegations</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="1105" end_char="1108">that</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="1110" end_char="1111">it</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="1113" end_char="1115">may</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="1117" end_char="1120">have</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="1122" end_char="1125">been</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="1127" end_char="1129">the</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="1131" end_char="1136">source</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="1138" end_char="1139">of</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="1141" end_char="1143">the</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="1145" end_char="1152">original</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="1154" end_char="1161">outbreak</TOKEN>
<TOKEN id="token-5-27" pos="punct" morph="none" start_char="1162" end_char="1162">,</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="1164" end_char="1170">whether</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="1172" end_char="1173">on</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="1175" end_char="1181">purpose</TOKEN>
<TOKEN id="token-5-31" pos="word" morph="none" start_char="1183" end_char="1184">or</TOKEN>
<TOKEN id="token-5-32" pos="word" morph="none" start_char="1186" end_char="1197">accidentally</TOKEN>
<TOKEN id="token-5-33" pos="punct" morph="none" start_char="1198" end_char="1198">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="1201" end_char="1384">
<ORIGINAL_TEXT>Embarek, a WHO food safety and animal disease expert, said experts now consider the possibility of such a leak so improbable that it will not be suggested as an avenue of future study.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="1201" end_char="1207">Embarek</TOKEN>
<TOKEN id="token-6-1" pos="punct" morph="none" start_char="1208" end_char="1208">,</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="1210" end_char="1210">a</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="1212" end_char="1214">WHO</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="1216" end_char="1219">food</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="1221" end_char="1226">safety</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="1228" end_char="1230">and</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="1232" end_char="1237">animal</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="1239" end_char="1245">disease</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="1247" end_char="1252">expert</TOKEN>
<TOKEN id="token-6-10" pos="punct" morph="none" start_char="1253" end_char="1253">,</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="1255" end_char="1258">said</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="1260" end_char="1266">experts</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="1268" end_char="1270">now</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="1272" end_char="1279">consider</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="1281" end_char="1283">the</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="1285" end_char="1295">possibility</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="1297" end_char="1298">of</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="1300" end_char="1303">such</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="1305" end_char="1305">a</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="1307" end_char="1310">leak</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="1312" end_char="1313">so</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="1315" end_char="1324">improbable</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="1326" end_char="1329">that</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="1331" end_char="1332">it</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="1334" end_char="1337">will</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="1339" end_char="1341">not</TOKEN>
<TOKEN id="token-6-27" pos="word" morph="none" start_char="1343" end_char="1344">be</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="1346" end_char="1354">suggested</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="1356" end_char="1357">as</TOKEN>
<TOKEN id="token-6-30" pos="word" morph="none" start_char="1359" end_char="1360">an</TOKEN>
<TOKEN id="token-6-31" pos="word" morph="none" start_char="1362" end_char="1367">avenue</TOKEN>
<TOKEN id="token-6-32" pos="word" morph="none" start_char="1369" end_char="1370">of</TOKEN>
<TOKEN id="token-6-33" pos="word" morph="none" start_char="1372" end_char="1377">future</TOKEN>
<TOKEN id="token-6-34" pos="word" morph="none" start_char="1379" end_char="1383">study</TOKEN>
<TOKEN id="token-6-35" pos="punct" morph="none" start_char="1384" end_char="1384">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="1386" end_char="1556">
<ORIGINAL_TEXT>But another team member, Danish scientist Thea Koelsen Fischer, told reporters that team members could not rule out the possibility of further investigation and new leads.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="1386" end_char="1388">But</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="1390" end_char="1396">another</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="1398" end_char="1401">team</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="1403" end_char="1408">member</TOKEN>
<TOKEN id="token-7-4" pos="punct" morph="none" start_char="1409" end_char="1409">,</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="1411" end_char="1416">Danish</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="1418" end_char="1426">scientist</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="1428" end_char="1431">Thea</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="1433" end_char="1439">Koelsen</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="1441" end_char="1447">Fischer</TOKEN>
<TOKEN id="token-7-10" pos="punct" morph="none" start_char="1448" end_char="1448">,</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="1450" end_char="1453">told</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="1455" end_char="1463">reporters</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="1465" end_char="1468">that</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="1470" end_char="1473">team</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="1475" end_char="1481">members</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="1483" end_char="1487">could</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="1489" end_char="1491">not</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="1493" end_char="1496">rule</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="1498" end_char="1500">out</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="1502" end_char="1504">the</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="1506" end_char="1516">possibility</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="1518" end_char="1519">of</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="1521" end_char="1527">further</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="1529" end_char="1541">investigation</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="1543" end_char="1545">and</TOKEN>
<TOKEN id="token-7-26" pos="word" morph="none" start_char="1547" end_char="1549">new</TOKEN>
<TOKEN id="token-7-27" pos="word" morph="none" start_char="1551" end_char="1555">leads</TOKEN>
<TOKEN id="token-7-28" pos="punct" morph="none" start_char="1556" end_char="1556">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1559" end_char="1652">
<ORIGINAL_TEXT>China had already strongly rejected the possibility of a leak and has promoted other theories.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1559" end_char="1563">China</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1565" end_char="1567">had</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1569" end_char="1575">already</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1577" end_char="1584">strongly</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1586" end_char="1593">rejected</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1595" end_char="1597">the</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1599" end_char="1609">possibility</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1611" end_char="1612">of</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1614" end_char="1614">a</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1616" end_char="1619">leak</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1621" end_char="1623">and</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1625" end_char="1627">has</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1629" end_char="1636">promoted</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1638" end_char="1642">other</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1644" end_char="1651">theories</TOKEN>
<TOKEN id="token-8-15" pos="punct" morph="none" start_char="1652" end_char="1652">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1654" end_char="1837">
<ORIGINAL_TEXT>The Chinese and foreign experts considered several ideas for how the disease first ended up in humans, leading to a pandemic that has now killed more than 2.3 million people worldwide.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1654" end_char="1656">The</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1658" end_char="1664">Chinese</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1666" end_char="1668">and</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1670" end_char="1676">foreign</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1678" end_char="1684">experts</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1686" end_char="1695">considered</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1697" end_char="1703">several</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1705" end_char="1709">ideas</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1711" end_char="1713">for</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1715" end_char="1717">how</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1719" end_char="1721">the</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1723" end_char="1729">disease</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1731" end_char="1735">first</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1737" end_char="1741">ended</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1743" end_char="1744">up</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1746" end_char="1747">in</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1749" end_char="1754">humans</TOKEN>
<TOKEN id="token-9-17" pos="punct" morph="none" start_char="1755" end_char="1755">,</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1757" end_char="1763">leading</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1765" end_char="1766">to</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1768" end_char="1768">a</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1770" end_char="1777">pandemic</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1779" end_char="1782">that</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1784" end_char="1786">has</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1788" end_char="1790">now</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1792" end_char="1797">killed</TOKEN>
<TOKEN id="token-9-26" pos="word" morph="none" start_char="1799" end_char="1802">more</TOKEN>
<TOKEN id="token-9-27" pos="word" morph="none" start_char="1804" end_char="1807">than</TOKEN>
<TOKEN id="token-9-28" pos="word" morph="none" start_char="1809" end_char="1811">2.3</TOKEN>
<TOKEN id="token-9-29" pos="word" morph="none" start_char="1813" end_char="1819">million</TOKEN>
<TOKEN id="token-9-30" pos="word" morph="none" start_char="1821" end_char="1826">people</TOKEN>
<TOKEN id="token-9-31" pos="word" morph="none" start_char="1828" end_char="1836">worldwide</TOKEN>
<TOKEN id="token-9-32" pos="punct" morph="none" start_char="1837" end_char="1837">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1840" end_char="2020">
<ORIGINAL_TEXT>Embarek said the initial findings suggest the most likely pathway the virus followed was from a bat to another animal and then to humans, adding that would require further research.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1840" end_char="1846">Embarek</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1848" end_char="1851">said</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1853" end_char="1855">the</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1857" end_char="1863">initial</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1865" end_char="1872">findings</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1874" end_char="1880">suggest</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1882" end_char="1884">the</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1886" end_char="1889">most</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1891" end_char="1896">likely</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1898" end_char="1904">pathway</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1906" end_char="1908">the</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1910" end_char="1914">virus</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1916" end_char="1923">followed</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1925" end_char="1927">was</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1929" end_char="1932">from</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1934" end_char="1934">a</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1936" end_char="1938">bat</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1940" end_char="1941">to</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1943" end_char="1949">another</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1951" end_char="1956">animal</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1958" end_char="1960">and</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1962" end_char="1965">then</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1967" end_char="1968">to</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1970" end_char="1975">humans</TOKEN>
<TOKEN id="token-10-24" pos="punct" morph="none" start_char="1976" end_char="1976">,</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="1978" end_char="1983">adding</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="1985" end_char="1988">that</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="1990" end_char="1994">would</TOKEN>
<TOKEN id="token-10-28" pos="word" morph="none" start_char="1996" end_char="2002">require</TOKEN>
<TOKEN id="token-10-29" pos="word" morph="none" start_char="2004" end_char="2010">further</TOKEN>
<TOKEN id="token-10-30" pos="word" morph="none" start_char="2012" end_char="2019">research</TOKEN>
<TOKEN id="token-10-31" pos="punct" morph="none" start_char="2020" end_char="2020">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="2023" end_char="2182">
<ORIGINAL_TEXT>"The findings suggest that the laboratory incidents hypothesis is extremely unlikely to explain the introduction of the virus to the human population," he said.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="punct" morph="none" start_char="2023" end_char="2023">"</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="2024" end_char="2026">The</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="2028" end_char="2035">findings</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="2037" end_char="2043">suggest</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="2045" end_char="2048">that</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="2050" end_char="2052">the</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="2054" end_char="2063">laboratory</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="2065" end_char="2073">incidents</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="2075" end_char="2084">hypothesis</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="2086" end_char="2087">is</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="2089" end_char="2097">extremely</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="2099" end_char="2106">unlikely</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="2108" end_char="2109">to</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="2111" end_char="2117">explain</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="2119" end_char="2121">the</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="2123" end_char="2134">introduction</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="2136" end_char="2137">of</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="2139" end_char="2141">the</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="2143" end_char="2147">virus</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="2149" end_char="2150">to</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="2152" end_char="2154">the</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="2156" end_char="2160">human</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="2162" end_char="2171">population</TOKEN>
<TOKEN id="token-11-23" pos="punct" morph="none" start_char="2172" end_char="2173">,"</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="2175" end_char="2176">he</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="2178" end_char="2181">said</TOKEN>
<TOKEN id="token-11-26" pos="punct" morph="none" start_char="2182" end_char="2182">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="2185" end_char="2372">
<ORIGINAL_TEXT>Asked why, Embarek said accidental releases are extremely rare and that the team’s review of the Wuhan institute’s lab operations indicated it would be hard for anything to escape from it.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="2185" end_char="2189">Asked</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="2191" end_char="2193">why</TOKEN>
<TOKEN id="token-12-2" pos="punct" morph="none" start_char="2194" end_char="2194">,</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="2196" end_char="2202">Embarek</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="2204" end_char="2207">said</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="2209" end_char="2218">accidental</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="2220" end_char="2227">releases</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="2229" end_char="2231">are</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="2233" end_char="2241">extremely</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="2243" end_char="2246">rare</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="2248" end_char="2250">and</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="2252" end_char="2255">that</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="2257" end_char="2259">the</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="2261" end_char="2266">team’s</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="2268" end_char="2273">review</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="2275" end_char="2276">of</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="2278" end_char="2280">the</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="2282" end_char="2286">Wuhan</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="2288" end_char="2298">institute’s</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="2300" end_char="2302">lab</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="2304" end_char="2313">operations</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="2315" end_char="2323">indicated</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="2325" end_char="2326">it</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="2328" end_char="2332">would</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="2334" end_char="2335">be</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="2337" end_char="2340">hard</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="2342" end_char="2344">for</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="2346" end_char="2353">anything</TOKEN>
<TOKEN id="token-12-28" pos="word" morph="none" start_char="2355" end_char="2356">to</TOKEN>
<TOKEN id="token-12-29" pos="word" morph="none" start_char="2358" end_char="2363">escape</TOKEN>
<TOKEN id="token-12-30" pos="word" morph="none" start_char="2365" end_char="2368">from</TOKEN>
<TOKEN id="token-12-31" pos="word" morph="none" start_char="2370" end_char="2371">it</TOKEN>
<TOKEN id="token-12-32" pos="punct" morph="none" start_char="2372" end_char="2372">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="2375" end_char="2469">
<ORIGINAL_TEXT>He also noted that there were no reports of this virus in any lab anywhere before the pandemic.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="2375" end_char="2376">He</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="2378" end_char="2381">also</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="2383" end_char="2387">noted</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="2389" end_char="2392">that</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="2394" end_char="2398">there</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="2400" end_char="2403">were</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="2405" end_char="2406">no</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="2408" end_char="2414">reports</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="2416" end_char="2417">of</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="2419" end_char="2422">this</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="2424" end_char="2428">virus</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="2430" end_char="2431">in</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="2433" end_char="2435">any</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="2437" end_char="2439">lab</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="2441" end_char="2448">anywhere</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="2450" end_char="2455">before</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="2457" end_char="2459">the</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="2461" end_char="2468">pandemic</TOKEN>
<TOKEN id="token-13-18" pos="punct" morph="none" start_char="2469" end_char="2469">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="2471" end_char="2593">
<ORIGINAL_TEXT>Liang Wannian, the head of the Chinese side, also emphasized that, saying there was no sample of it in the Wuhan institute.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="2471" end_char="2475">Liang</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="2477" end_char="2483">Wannian</TOKEN>
<TOKEN id="token-14-2" pos="punct" morph="none" start_char="2484" end_char="2484">,</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="2486" end_char="2488">the</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="2490" end_char="2493">head</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="2495" end_char="2496">of</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="2498" end_char="2500">the</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="2502" end_char="2508">Chinese</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="2510" end_char="2513">side</TOKEN>
<TOKEN id="token-14-9" pos="punct" morph="none" start_char="2514" end_char="2514">,</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="2516" end_char="2519">also</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="2521" end_char="2530">emphasized</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="2532" end_char="2535">that</TOKEN>
<TOKEN id="token-14-13" pos="punct" morph="none" start_char="2536" end_char="2536">,</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="2538" end_char="2543">saying</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="2545" end_char="2549">there</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="2551" end_char="2553">was</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="2555" end_char="2556">no</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="2558" end_char="2563">sample</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="2565" end_char="2566">of</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="2568" end_char="2569">it</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="2571" end_char="2572">in</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="2574" end_char="2576">the</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="2578" end_char="2582">Wuhan</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="2584" end_char="2592">institute</TOKEN>
<TOKEN id="token-14-25" pos="punct" morph="none" start_char="2593" end_char="2593">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="2596" end_char="2812">
<ORIGINAL_TEXT>The mission was intended to be an initial step in the process of understanding the origins of the virus, which scientists have posited may have passed to humans through a wild animal, such as a pangolin or bamboo rat.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="2596" end_char="2598">The</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="2600" end_char="2606">mission</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="2608" end_char="2610">was</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="2612" end_char="2619">intended</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="2621" end_char="2622">to</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="2624" end_char="2625">be</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="2627" end_char="2628">an</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="2630" end_char="2636">initial</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="2638" end_char="2641">step</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="2643" end_char="2644">in</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="2646" end_char="2648">the</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="2650" end_char="2656">process</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="2658" end_char="2659">of</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="2661" end_char="2673">understanding</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="2675" end_char="2677">the</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="2679" end_char="2685">origins</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="2687" end_char="2688">of</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="2690" end_char="2692">the</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="2694" end_char="2698">virus</TOKEN>
<TOKEN id="token-15-19" pos="punct" morph="none" start_char="2699" end_char="2699">,</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="2701" end_char="2705">which</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="2707" end_char="2716">scientists</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="2718" end_char="2721">have</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="2723" end_char="2729">posited</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="2731" end_char="2733">may</TOKEN>
<TOKEN id="token-15-25" pos="word" morph="none" start_char="2735" end_char="2738">have</TOKEN>
<TOKEN id="token-15-26" pos="word" morph="none" start_char="2740" end_char="2745">passed</TOKEN>
<TOKEN id="token-15-27" pos="word" morph="none" start_char="2747" end_char="2748">to</TOKEN>
<TOKEN id="token-15-28" pos="word" morph="none" start_char="2750" end_char="2755">humans</TOKEN>
<TOKEN id="token-15-29" pos="word" morph="none" start_char="2757" end_char="2763">through</TOKEN>
<TOKEN id="token-15-30" pos="word" morph="none" start_char="2765" end_char="2765">a</TOKEN>
<TOKEN id="token-15-31" pos="word" morph="none" start_char="2767" end_char="2770">wild</TOKEN>
<TOKEN id="token-15-32" pos="word" morph="none" start_char="2772" end_char="2777">animal</TOKEN>
<TOKEN id="token-15-33" pos="punct" morph="none" start_char="2778" end_char="2778">,</TOKEN>
<TOKEN id="token-15-34" pos="word" morph="none" start_char="2780" end_char="2783">such</TOKEN>
<TOKEN id="token-15-35" pos="word" morph="none" start_char="2785" end_char="2786">as</TOKEN>
<TOKEN id="token-15-36" pos="word" morph="none" start_char="2788" end_char="2788">a</TOKEN>
<TOKEN id="token-15-37" pos="word" morph="none" start_char="2790" end_char="2797">pangolin</TOKEN>
<TOKEN id="token-15-38" pos="word" morph="none" start_char="2799" end_char="2800">or</TOKEN>
<TOKEN id="token-15-39" pos="word" morph="none" start_char="2802" end_char="2807">bamboo</TOKEN>
<TOKEN id="token-15-40" pos="word" morph="none" start_char="2809" end_char="2811">rat</TOKEN>
<TOKEN id="token-15-41" pos="punct" morph="none" start_char="2812" end_char="2812">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="2814" end_char="2937">
<ORIGINAL_TEXT>Transmission directly from bats to humans or through the trade in frozen food products are also possibilities, Embarek said.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="2814" end_char="2825">Transmission</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="2827" end_char="2834">directly</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="2836" end_char="2839">from</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="2841" end_char="2844">bats</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="2846" end_char="2847">to</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="2849" end_char="2854">humans</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="2856" end_char="2857">or</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="2859" end_char="2865">through</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="2867" end_char="2869">the</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="2871" end_char="2875">trade</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="2877" end_char="2878">in</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="2880" end_char="2885">frozen</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="2887" end_char="2890">food</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="2892" end_char="2899">products</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="2901" end_char="2903">are</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="2905" end_char="2908">also</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="2910" end_char="2922">possibilities</TOKEN>
<TOKEN id="token-16-17" pos="punct" morph="none" start_char="2923" end_char="2923">,</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="2925" end_char="2931">Embarek</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="2933" end_char="2936">said</TOKEN>
<TOKEN id="token-16-20" pos="punct" morph="none" start_char="2937" end_char="2937">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2940" end_char="3095">
<ORIGINAL_TEXT>The WHO team’s visit is politically sensitive for Beijing, which is concerned about being blamed for alleged missteps in its early response to the outbreak.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2940" end_char="2942">The</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2944" end_char="2946">WHO</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2948" end_char="2953">team’s</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2955" end_char="2959">visit</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2961" end_char="2962">is</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2964" end_char="2974">politically</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2976" end_char="2984">sensitive</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2986" end_char="2988">for</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2990" end_char="2996">Beijing</TOKEN>
<TOKEN id="token-17-9" pos="punct" morph="none" start_char="2997" end_char="2997">,</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2999" end_char="3003">which</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="3005" end_char="3006">is</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="3008" end_char="3016">concerned</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="3018" end_char="3022">about</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="3024" end_char="3028">being</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="3030" end_char="3035">blamed</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="3037" end_char="3039">for</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="3041" end_char="3047">alleged</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="3049" end_char="3056">missteps</TOKEN>
<TOKEN id="token-17-19" pos="word" morph="none" start_char="3058" end_char="3059">in</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="3061" end_char="3063">its</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="3065" end_char="3069">early</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="3071" end_char="3078">response</TOKEN>
<TOKEN id="token-17-23" pos="word" morph="none" start_char="3080" end_char="3081">to</TOKEN>
<TOKEN id="token-17-24" pos="word" morph="none" start_char="3083" end_char="3085">the</TOKEN>
<TOKEN id="token-17-25" pos="word" morph="none" start_char="3087" end_char="3094">outbreak</TOKEN>
<TOKEN id="token-17-26" pos="punct" morph="none" start_char="3095" end_char="3095">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="3097" end_char="3244">
<ORIGINAL_TEXT>An AP investigation has found that the Chinese government put limits on research into the outbreak and ordered scientists not to speak to reporters.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="3097" end_char="3098">An</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="3100" end_char="3101">AP</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="3103" end_char="3115">investigation</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="3117" end_char="3119">has</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="3121" end_char="3125">found</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="3127" end_char="3130">that</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="3132" end_char="3134">the</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="3136" end_char="3142">Chinese</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="3144" end_char="3153">government</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="3155" end_char="3157">put</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="3159" end_char="3164">limits</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="3166" end_char="3167">on</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="3169" end_char="3176">research</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="3178" end_char="3181">into</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="3183" end_char="3185">the</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="3187" end_char="3194">outbreak</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="3196" end_char="3198">and</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="3200" end_char="3206">ordered</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="3208" end_char="3217">scientists</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="3219" end_char="3221">not</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="3223" end_char="3224">to</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="3226" end_char="3230">speak</TOKEN>
<TOKEN id="token-18-22" pos="word" morph="none" start_char="3232" end_char="3233">to</TOKEN>
<TOKEN id="token-18-23" pos="word" morph="none" start_char="3235" end_char="3243">reporters</TOKEN>
<TOKEN id="token-18-24" pos="punct" morph="none" start_char="3244" end_char="3244">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="3247" end_char="3508">
<ORIGINAL_TEXT>Still, one member of the WHO team, British-born zoologist Peter Daszak, told The Associated Press last week that they enjoyed a greater level of openness than they had anticipated, and that they were granted full access to all sites and personnel they requested.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="3247" end_char="3251">Still</TOKEN>
<TOKEN id="token-19-1" pos="punct" morph="none" start_char="3252" end_char="3252">,</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="3254" end_char="3256">one</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="3258" end_char="3263">member</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="3265" end_char="3266">of</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="3268" end_char="3270">the</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="3272" end_char="3274">WHO</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="3276" end_char="3279">team</TOKEN>
<TOKEN id="token-19-8" pos="punct" morph="none" start_char="3280" end_char="3280">,</TOKEN>
<TOKEN id="token-19-9" pos="unknown" morph="none" start_char="3282" end_char="3293">British-born</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="3295" end_char="3303">zoologist</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="3305" end_char="3309">Peter</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="3311" end_char="3316">Daszak</TOKEN>
<TOKEN id="token-19-13" pos="punct" morph="none" start_char="3317" end_char="3317">,</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="3319" end_char="3322">told</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="3324" end_char="3326">The</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="3328" end_char="3337">Associated</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="3339" end_char="3343">Press</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="3345" end_char="3348">last</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="3350" end_char="3353">week</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="3355" end_char="3358">that</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="3360" end_char="3363">they</TOKEN>
<TOKEN id="token-19-22" pos="word" morph="none" start_char="3365" end_char="3371">enjoyed</TOKEN>
<TOKEN id="token-19-23" pos="word" morph="none" start_char="3373" end_char="3373">a</TOKEN>
<TOKEN id="token-19-24" pos="word" morph="none" start_char="3375" end_char="3381">greater</TOKEN>
<TOKEN id="token-19-25" pos="word" morph="none" start_char="3383" end_char="3387">level</TOKEN>
<TOKEN id="token-19-26" pos="word" morph="none" start_char="3389" end_char="3390">of</TOKEN>
<TOKEN id="token-19-27" pos="word" morph="none" start_char="3392" end_char="3399">openness</TOKEN>
<TOKEN id="token-19-28" pos="word" morph="none" start_char="3401" end_char="3404">than</TOKEN>
<TOKEN id="token-19-29" pos="word" morph="none" start_char="3406" end_char="3409">they</TOKEN>
<TOKEN id="token-19-30" pos="word" morph="none" start_char="3411" end_char="3413">had</TOKEN>
<TOKEN id="token-19-31" pos="word" morph="none" start_char="3415" end_char="3425">anticipated</TOKEN>
<TOKEN id="token-19-32" pos="punct" morph="none" start_char="3426" end_char="3426">,</TOKEN>
<TOKEN id="token-19-33" pos="word" morph="none" start_char="3428" end_char="3430">and</TOKEN>
<TOKEN id="token-19-34" pos="word" morph="none" start_char="3432" end_char="3435">that</TOKEN>
<TOKEN id="token-19-35" pos="word" morph="none" start_char="3437" end_char="3440">they</TOKEN>
<TOKEN id="token-19-36" pos="word" morph="none" start_char="3442" end_char="3445">were</TOKEN>
<TOKEN id="token-19-37" pos="word" morph="none" start_char="3447" end_char="3453">granted</TOKEN>
<TOKEN id="token-19-38" pos="word" morph="none" start_char="3455" end_char="3458">full</TOKEN>
<TOKEN id="token-19-39" pos="word" morph="none" start_char="3460" end_char="3465">access</TOKEN>
<TOKEN id="token-19-40" pos="word" morph="none" start_char="3467" end_char="3468">to</TOKEN>
<TOKEN id="token-19-41" pos="word" morph="none" start_char="3470" end_char="3472">all</TOKEN>
<TOKEN id="token-19-42" pos="word" morph="none" start_char="3474" end_char="3478">sites</TOKEN>
<TOKEN id="token-19-43" pos="word" morph="none" start_char="3480" end_char="3482">and</TOKEN>
<TOKEN id="token-19-44" pos="word" morph="none" start_char="3484" end_char="3492">personnel</TOKEN>
<TOKEN id="token-19-45" pos="word" morph="none" start_char="3494" end_char="3497">they</TOKEN>
<TOKEN id="token-19-46" pos="word" morph="none" start_char="3499" end_char="3507">requested</TOKEN>
<TOKEN id="token-19-47" pos="punct" morph="none" start_char="3508" end_char="3508">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="3511" end_char="3636">
<ORIGINAL_TEXT>Koelsen Fischer said she did not get to see the raw data and had to rely on an analysis of the data that was presented to her.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="3511" end_char="3517">Koelsen</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="3519" end_char="3525">Fischer</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="3527" end_char="3530">said</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="3532" end_char="3534">she</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="3536" end_char="3538">did</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="3540" end_char="3542">not</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="3544" end_char="3546">get</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="3548" end_char="3549">to</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="3551" end_char="3553">see</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="3555" end_char="3557">the</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="3559" end_char="3561">raw</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="3563" end_char="3566">data</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="3568" end_char="3570">and</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="3572" end_char="3574">had</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="3576" end_char="3577">to</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="3579" end_char="3582">rely</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="3584" end_char="3585">on</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="3587" end_char="3588">an</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="3590" end_char="3597">analysis</TOKEN>
<TOKEN id="token-20-19" pos="word" morph="none" start_char="3599" end_char="3600">of</TOKEN>
<TOKEN id="token-20-20" pos="word" morph="none" start_char="3602" end_char="3604">the</TOKEN>
<TOKEN id="token-20-21" pos="word" morph="none" start_char="3606" end_char="3609">data</TOKEN>
<TOKEN id="token-20-22" pos="word" morph="none" start_char="3611" end_char="3614">that</TOKEN>
<TOKEN id="token-20-23" pos="word" morph="none" start_char="3616" end_char="3618">was</TOKEN>
<TOKEN id="token-20-24" pos="word" morph="none" start_char="3620" end_char="3628">presented</TOKEN>
<TOKEN id="token-20-25" pos="word" morph="none" start_char="3630" end_char="3631">to</TOKEN>
<TOKEN id="token-20-26" pos="word" morph="none" start_char="3633" end_char="3635">her</TOKEN>
<TOKEN id="token-20-27" pos="punct" morph="none" start_char="3636" end_char="3636">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="3638" end_char="3687">
<ORIGINAL_TEXT>But she said that would be true in most countries.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="3638" end_char="3640">But</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="3642" end_char="3644">she</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="3646" end_char="3649">said</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="3651" end_char="3654">that</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="3656" end_char="3660">would</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="3662" end_char="3663">be</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="3665" end_char="3668">true</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="3670" end_char="3671">in</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="3673" end_char="3676">most</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="3678" end_char="3686">countries</TOKEN>
<TOKEN id="token-21-10" pos="punct" morph="none" start_char="3687" end_char="3687">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="3690" end_char="3760">
<ORIGINAL_TEXT>The team — which includes experts from 10 countries who arrived on Jan.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="3690" end_char="3692">The</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="3694" end_char="3697">team</TOKEN>
<TOKEN id="token-22-2" pos="punct" morph="none" start_char="3699" end_char="3699">—</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="3701" end_char="3705">which</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="3707" end_char="3714">includes</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="3716" end_char="3722">experts</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="3724" end_char="3727">from</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="3729" end_char="3730">10</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="3732" end_char="3740">countries</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="3742" end_char="3744">who</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="3746" end_char="3752">arrived</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="3754" end_char="3755">on</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="3757" end_char="3759">Jan</TOKEN>
<TOKEN id="token-22-13" pos="punct" morph="none" start_char="3760" end_char="3760">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="3762" end_char="3852">
<ORIGINAL_TEXT>14 — visited the Huanan Seafood Market, the site of an early cluster of cases in late 2019.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="3762" end_char="3763">14</TOKEN>
<TOKEN id="token-23-1" pos="punct" morph="none" start_char="3765" end_char="3765">—</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="3767" end_char="3773">visited</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="3775" end_char="3777">the</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="3779" end_char="3784">Huanan</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="3786" end_char="3792">Seafood</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="3794" end_char="3799">Market</TOKEN>
<TOKEN id="token-23-7" pos="punct" morph="none" start_char="3800" end_char="3800">,</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="3802" end_char="3804">the</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="3806" end_char="3809">site</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="3811" end_char="3812">of</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="3814" end_char="3815">an</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="3817" end_char="3821">early</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="3823" end_char="3829">cluster</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="3831" end_char="3832">of</TOKEN>
<TOKEN id="token-23-15" pos="word" morph="none" start_char="3834" end_char="3838">cases</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="3840" end_char="3841">in</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="3843" end_char="3846">late</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="3848" end_char="3851">2019</TOKEN>
<TOKEN id="token-23-19" pos="punct" morph="none" start_char="3852" end_char="3852">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="3855" end_char="4036">
<ORIGINAL_TEXT>Marion Koopmans, a Dutch virologist on the team, said that some animals at the market were susceptible or suspected to be susceptible to the virus, including rabbits and bamboo rats.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="3855" end_char="3860">Marion</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="3862" end_char="3869">Koopmans</TOKEN>
<TOKEN id="token-24-2" pos="punct" morph="none" start_char="3870" end_char="3870">,</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="3872" end_char="3872">a</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="3874" end_char="3878">Dutch</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="3880" end_char="3889">virologist</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="3891" end_char="3892">on</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="3894" end_char="3896">the</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="3898" end_char="3901">team</TOKEN>
<TOKEN id="token-24-9" pos="punct" morph="none" start_char="3902" end_char="3902">,</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="3904" end_char="3907">said</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="3909" end_char="3912">that</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="3914" end_char="3917">some</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="3919" end_char="3925">animals</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="3927" end_char="3928">at</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="3930" end_char="3932">the</TOKEN>
<TOKEN id="token-24-16" pos="word" morph="none" start_char="3934" end_char="3939">market</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="3941" end_char="3944">were</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="3946" end_char="3956">susceptible</TOKEN>
<TOKEN id="token-24-19" pos="word" morph="none" start_char="3958" end_char="3959">or</TOKEN>
<TOKEN id="token-24-20" pos="word" morph="none" start_char="3961" end_char="3969">suspected</TOKEN>
<TOKEN id="token-24-21" pos="word" morph="none" start_char="3971" end_char="3972">to</TOKEN>
<TOKEN id="token-24-22" pos="word" morph="none" start_char="3974" end_char="3975">be</TOKEN>
<TOKEN id="token-24-23" pos="word" morph="none" start_char="3977" end_char="3987">susceptible</TOKEN>
<TOKEN id="token-24-24" pos="word" morph="none" start_char="3989" end_char="3990">to</TOKEN>
<TOKEN id="token-24-25" pos="word" morph="none" start_char="3992" end_char="3994">the</TOKEN>
<TOKEN id="token-24-26" pos="word" morph="none" start_char="3996" end_char="4000">virus</TOKEN>
<TOKEN id="token-24-27" pos="punct" morph="none" start_char="4001" end_char="4001">,</TOKEN>
<TOKEN id="token-24-28" pos="word" morph="none" start_char="4003" end_char="4011">including</TOKEN>
<TOKEN id="token-24-29" pos="word" morph="none" start_char="4013" end_char="4019">rabbits</TOKEN>
<TOKEN id="token-24-30" pos="word" morph="none" start_char="4021" end_char="4023">and</TOKEN>
<TOKEN id="token-24-31" pos="word" morph="none" start_char="4025" end_char="4030">bamboo</TOKEN>
<TOKEN id="token-24-32" pos="word" morph="none" start_char="4032" end_char="4035">rats</TOKEN>
<TOKEN id="token-24-33" pos="punct" morph="none" start_char="4036" end_char="4036">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="4038" end_char="4188">
<ORIGINAL_TEXT>And some could be traced to farms or traders in regions that are home to the bats that carry the closest related virus to the one that causes COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="4038" end_char="4040">And</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="4042" end_char="4045">some</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="4047" end_char="4051">could</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="4053" end_char="4054">be</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="4056" end_char="4061">traced</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="4063" end_char="4064">to</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="4066" end_char="4070">farms</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="4072" end_char="4073">or</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="4075" end_char="4081">traders</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="4083" end_char="4084">in</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="4086" end_char="4092">regions</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="4094" end_char="4097">that</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="4099" end_char="4101">are</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="4103" end_char="4106">home</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="4108" end_char="4109">to</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="4111" end_char="4113">the</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="4115" end_char="4118">bats</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="4120" end_char="4123">that</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="4125" end_char="4129">carry</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="4131" end_char="4133">the</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="4135" end_char="4141">closest</TOKEN>
<TOKEN id="token-25-21" pos="word" morph="none" start_char="4143" end_char="4149">related</TOKEN>
<TOKEN id="token-25-22" pos="word" morph="none" start_char="4151" end_char="4155">virus</TOKEN>
<TOKEN id="token-25-23" pos="word" morph="none" start_char="4157" end_char="4158">to</TOKEN>
<TOKEN id="token-25-24" pos="word" morph="none" start_char="4160" end_char="4162">the</TOKEN>
<TOKEN id="token-25-25" pos="word" morph="none" start_char="4164" end_char="4166">one</TOKEN>
<TOKEN id="token-25-26" pos="word" morph="none" start_char="4168" end_char="4171">that</TOKEN>
<TOKEN id="token-25-27" pos="word" morph="none" start_char="4173" end_char="4178">causes</TOKEN>
<TOKEN id="token-25-28" pos="unknown" morph="none" start_char="4180" end_char="4187">COVID-19</TOKEN>
<TOKEN id="token-25-29" pos="punct" morph="none" start_char="4188" end_char="4188">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="4191" end_char="4252">
<ORIGINAL_TEXT>She said the next step would be to look more closely at farms.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="4191" end_char="4193">She</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="4195" end_char="4198">said</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="4200" end_char="4202">the</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="4204" end_char="4207">next</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="4209" end_char="4212">step</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="4214" end_char="4218">would</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="4220" end_char="4221">be</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="4223" end_char="4224">to</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="4226" end_char="4229">look</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="4231" end_char="4234">more</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="4236" end_char="4242">closely</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="4244" end_char="4245">at</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="4247" end_char="4251">farms</TOKEN>
<TOKEN id="token-26-13" pos="punct" morph="none" start_char="4252" end_char="4252">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="4255" end_char="4446">
<ORIGINAL_TEXT>Liang, the head of the Chinese team, said the virus also appeared to have been spreading in parts of the city other than the market, so it remains possible that the virus originated elsewhere.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="4255" end_char="4259">Liang</TOKEN>
<TOKEN id="token-27-1" pos="punct" morph="none" start_char="4260" end_char="4260">,</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="4262" end_char="4264">the</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="4266" end_char="4269">head</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="4271" end_char="4272">of</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="4274" end_char="4276">the</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="4278" end_char="4284">Chinese</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="4286" end_char="4289">team</TOKEN>
<TOKEN id="token-27-8" pos="punct" morph="none" start_char="4290" end_char="4290">,</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="4292" end_char="4295">said</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="4297" end_char="4299">the</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="4301" end_char="4305">virus</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="4307" end_char="4310">also</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="4312" end_char="4319">appeared</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="4321" end_char="4322">to</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="4324" end_char="4327">have</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="4329" end_char="4332">been</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="4334" end_char="4342">spreading</TOKEN>
<TOKEN id="token-27-18" pos="word" morph="none" start_char="4344" end_char="4345">in</TOKEN>
<TOKEN id="token-27-19" pos="word" morph="none" start_char="4347" end_char="4351">parts</TOKEN>
<TOKEN id="token-27-20" pos="word" morph="none" start_char="4353" end_char="4354">of</TOKEN>
<TOKEN id="token-27-21" pos="word" morph="none" start_char="4356" end_char="4358">the</TOKEN>
<TOKEN id="token-27-22" pos="word" morph="none" start_char="4360" end_char="4363">city</TOKEN>
<TOKEN id="token-27-23" pos="word" morph="none" start_char="4365" end_char="4369">other</TOKEN>
<TOKEN id="token-27-24" pos="word" morph="none" start_char="4371" end_char="4374">than</TOKEN>
<TOKEN id="token-27-25" pos="word" morph="none" start_char="4376" end_char="4378">the</TOKEN>
<TOKEN id="token-27-26" pos="word" morph="none" start_char="4380" end_char="4385">market</TOKEN>
<TOKEN id="token-27-27" pos="punct" morph="none" start_char="4386" end_char="4386">,</TOKEN>
<TOKEN id="token-27-28" pos="word" morph="none" start_char="4388" end_char="4389">so</TOKEN>
<TOKEN id="token-27-29" pos="word" morph="none" start_char="4391" end_char="4392">it</TOKEN>
<TOKEN id="token-27-30" pos="word" morph="none" start_char="4394" end_char="4400">remains</TOKEN>
<TOKEN id="token-27-31" pos="word" morph="none" start_char="4402" end_char="4409">possible</TOKEN>
<TOKEN id="token-27-32" pos="word" morph="none" start_char="4411" end_char="4414">that</TOKEN>
<TOKEN id="token-27-33" pos="word" morph="none" start_char="4416" end_char="4418">the</TOKEN>
<TOKEN id="token-27-34" pos="word" morph="none" start_char="4420" end_char="4424">virus</TOKEN>
<TOKEN id="token-27-35" pos="word" morph="none" start_char="4426" end_char="4435">originated</TOKEN>
<TOKEN id="token-27-36" pos="word" morph="none" start_char="4437" end_char="4445">elsewhere</TOKEN>
<TOKEN id="token-27-37" pos="punct" morph="none" start_char="4446" end_char="4446">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="4449" end_char="4587">
<ORIGINAL_TEXT>The team found no evidence that the disease was spreading widely any earlier than the initial outbreak in the second half of December 2019.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="4449" end_char="4451">The</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="4453" end_char="4456">team</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="4458" end_char="4462">found</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="4464" end_char="4465">no</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="4467" end_char="4474">evidence</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="4476" end_char="4479">that</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="4481" end_char="4483">the</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="4485" end_char="4491">disease</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="4493" end_char="4495">was</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="4497" end_char="4505">spreading</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="4507" end_char="4512">widely</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="4514" end_char="4516">any</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="4518" end_char="4524">earlier</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="4526" end_char="4529">than</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="4531" end_char="4533">the</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="4535" end_char="4541">initial</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="4543" end_char="4550">outbreak</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="4552" end_char="4553">in</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="4555" end_char="4557">the</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="4559" end_char="4564">second</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="4566" end_char="4569">half</TOKEN>
<TOKEN id="token-28-21" pos="word" morph="none" start_char="4571" end_char="4572">of</TOKEN>
<TOKEN id="token-28-22" pos="word" morph="none" start_char="4574" end_char="4581">December</TOKEN>
<TOKEN id="token-28-23" pos="word" morph="none" start_char="4583" end_char="4586">2019</TOKEN>
<TOKEN id="token-28-24" pos="punct" morph="none" start_char="4587" end_char="4587">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="4590" end_char="4762">
<ORIGINAL_TEXT>"We haven’t been able to fully do the research, but there is no indication there were clusters before what we saw happen in the later part of December in Wuhan," Liang said.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="punct" morph="none" start_char="4590" end_char="4590">"</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="4591" end_char="4592">We</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="4594" end_char="4600">haven’t</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="4602" end_char="4605">been</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="4607" end_char="4610">able</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="4612" end_char="4613">to</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="4615" end_char="4619">fully</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="4621" end_char="4622">do</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="4624" end_char="4626">the</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="4628" end_char="4635">research</TOKEN>
<TOKEN id="token-29-10" pos="punct" morph="none" start_char="4636" end_char="4636">,</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="4638" end_char="4640">but</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="4642" end_char="4646">there</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="4648" end_char="4649">is</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="4651" end_char="4652">no</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="4654" end_char="4663">indication</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="4665" end_char="4669">there</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="4671" end_char="4674">were</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="4676" end_char="4683">clusters</TOKEN>
<TOKEN id="token-29-19" pos="word" morph="none" start_char="4685" end_char="4690">before</TOKEN>
<TOKEN id="token-29-20" pos="word" morph="none" start_char="4692" end_char="4695">what</TOKEN>
<TOKEN id="token-29-21" pos="word" morph="none" start_char="4697" end_char="4698">we</TOKEN>
<TOKEN id="token-29-22" pos="word" morph="none" start_char="4700" end_char="4702">saw</TOKEN>
<TOKEN id="token-29-23" pos="word" morph="none" start_char="4704" end_char="4709">happen</TOKEN>
<TOKEN id="token-29-24" pos="word" morph="none" start_char="4711" end_char="4712">in</TOKEN>
<TOKEN id="token-29-25" pos="word" morph="none" start_char="4714" end_char="4716">the</TOKEN>
<TOKEN id="token-29-26" pos="word" morph="none" start_char="4718" end_char="4722">later</TOKEN>
<TOKEN id="token-29-27" pos="word" morph="none" start_char="4724" end_char="4727">part</TOKEN>
<TOKEN id="token-29-28" pos="word" morph="none" start_char="4729" end_char="4730">of</TOKEN>
<TOKEN id="token-29-29" pos="word" morph="none" start_char="4732" end_char="4739">December</TOKEN>
<TOKEN id="token-29-30" pos="word" morph="none" start_char="4741" end_char="4742">in</TOKEN>
<TOKEN id="token-29-31" pos="word" morph="none" start_char="4744" end_char="4748">Wuhan</TOKEN>
<TOKEN id="token-29-32" pos="punct" morph="none" start_char="4749" end_char="4750">,"</TOKEN>
<TOKEN id="token-29-33" pos="word" morph="none" start_char="4752" end_char="4756">Liang</TOKEN>
<TOKEN id="token-29-34" pos="word" morph="none" start_char="4758" end_char="4761">said</TOKEN>
<TOKEN id="token-29-35" pos="punct" morph="none" start_char="4762" end_char="4762">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="4765" end_char="4815">
<ORIGINAL_TEXT>The visit by the WHO team took months to negotiate.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="4765" end_char="4767">The</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="4769" end_char="4773">visit</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="4775" end_char="4776">by</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="4778" end_char="4780">the</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="4782" end_char="4784">WHO</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="4786" end_char="4789">team</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="4791" end_char="4794">took</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="4796" end_char="4801">months</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="4803" end_char="4804">to</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="4806" end_char="4814">negotiate</TOKEN>
<TOKEN id="token-30-10" pos="punct" morph="none" start_char="4815" end_char="4815">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="4817" end_char="5004">
<ORIGINAL_TEXT>China only agreed to it amid international pressure at the WHO’s World Health Assembly meeting last May, and Beijing has continued to resist calls for a strictly independent investigation.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="4817" end_char="4821">China</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="4823" end_char="4826">only</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="4828" end_char="4833">agreed</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="4835" end_char="4836">to</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="4838" end_char="4839">it</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="4841" end_char="4844">amid</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="4846" end_char="4858">international</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="4860" end_char="4867">pressure</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="4869" end_char="4870">at</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="4872" end_char="4874">the</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="4876" end_char="4880">WHO’s</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="4882" end_char="4886">World</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="4888" end_char="4893">Health</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="4895" end_char="4902">Assembly</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="4904" end_char="4910">meeting</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="4912" end_char="4915">last</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="4917" end_char="4919">May</TOKEN>
<TOKEN id="token-31-17" pos="punct" morph="none" start_char="4920" end_char="4920">,</TOKEN>
<TOKEN id="token-31-18" pos="word" morph="none" start_char="4922" end_char="4924">and</TOKEN>
<TOKEN id="token-31-19" pos="word" morph="none" start_char="4926" end_char="4932">Beijing</TOKEN>
<TOKEN id="token-31-20" pos="word" morph="none" start_char="4934" end_char="4936">has</TOKEN>
<TOKEN id="token-31-21" pos="word" morph="none" start_char="4938" end_char="4946">continued</TOKEN>
<TOKEN id="token-31-22" pos="word" morph="none" start_char="4948" end_char="4949">to</TOKEN>
<TOKEN id="token-31-23" pos="word" morph="none" start_char="4951" end_char="4956">resist</TOKEN>
<TOKEN id="token-31-24" pos="word" morph="none" start_char="4958" end_char="4962">calls</TOKEN>
<TOKEN id="token-31-25" pos="word" morph="none" start_char="4964" end_char="4966">for</TOKEN>
<TOKEN id="token-31-26" pos="word" morph="none" start_char="4968" end_char="4968">a</TOKEN>
<TOKEN id="token-31-27" pos="word" morph="none" start_char="4970" end_char="4977">strictly</TOKEN>
<TOKEN id="token-31-28" pos="word" morph="none" start_char="4979" end_char="4989">independent</TOKEN>
<TOKEN id="token-31-29" pos="word" morph="none" start_char="4991" end_char="5003">investigation</TOKEN>
<TOKEN id="token-31-30" pos="punct" morph="none" start_char="5004" end_char="5004">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="5007" end_char="5176">
<ORIGINAL_TEXT>While China has weathered some localized resurgences of infection since getting the outbreak under control last year, life in Wuhan itself has largely returned to normal.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="5007" end_char="5011">While</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="5013" end_char="5017">China</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="5019" end_char="5021">has</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="5023" end_char="5031">weathered</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="5033" end_char="5036">some</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="5038" end_char="5046">localized</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="5048" end_char="5058">resurgences</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="5060" end_char="5061">of</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="5063" end_char="5071">infection</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="5073" end_char="5077">since</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="5079" end_char="5085">getting</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="5087" end_char="5089">the</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="5091" end_char="5098">outbreak</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="5100" end_char="5104">under</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="5106" end_char="5112">control</TOKEN>
<TOKEN id="token-32-15" pos="word" morph="none" start_char="5114" end_char="5117">last</TOKEN>
<TOKEN id="token-32-16" pos="word" morph="none" start_char="5119" end_char="5122">year</TOKEN>
<TOKEN id="token-32-17" pos="punct" morph="none" start_char="5123" end_char="5123">,</TOKEN>
<TOKEN id="token-32-18" pos="word" morph="none" start_char="5125" end_char="5128">life</TOKEN>
<TOKEN id="token-32-19" pos="word" morph="none" start_char="5130" end_char="5131">in</TOKEN>
<TOKEN id="token-32-20" pos="word" morph="none" start_char="5133" end_char="5137">Wuhan</TOKEN>
<TOKEN id="token-32-21" pos="word" morph="none" start_char="5139" end_char="5144">itself</TOKEN>
<TOKEN id="token-32-22" pos="word" morph="none" start_char="5146" end_char="5148">has</TOKEN>
<TOKEN id="token-32-23" pos="word" morph="none" start_char="5150" end_char="5156">largely</TOKEN>
<TOKEN id="token-32-24" pos="word" morph="none" start_char="5158" end_char="5165">returned</TOKEN>
<TOKEN id="token-32-25" pos="word" morph="none" start_char="5167" end_char="5168">to</TOKEN>
<TOKEN id="token-32-26" pos="word" morph="none" start_char="5170" end_char="5175">normal</TOKEN>
<TOKEN id="token-32-27" pos="punct" morph="none" start_char="5176" end_char="5176">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="5179" end_char="5238">
<ORIGINAL_TEXT>Associated Press writers Ken Moritsugu in Beijing and Jan M.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="5179" end_char="5188">Associated</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="5190" end_char="5194">Press</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="5196" end_char="5202">writers</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="5204" end_char="5206">Ken</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="5208" end_char="5216">Moritsugu</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="5218" end_char="5219">in</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="5221" end_char="5227">Beijing</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="5229" end_char="5231">and</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="5233" end_char="5235">Jan</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="5237" end_char="5237">M</TOKEN>
<TOKEN id="token-33-10" pos="punct" morph="none" start_char="5238" end_char="5238">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="5240" end_char="5296">
<ORIGINAL_TEXT>Olsen in Copenhagen, Denmark, contributed to this report.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="5240" end_char="5244">Olsen</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="5246" end_char="5247">in</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="5249" end_char="5258">Copenhagen</TOKEN>
<TOKEN id="token-34-3" pos="punct" morph="none" start_char="5259" end_char="5259">,</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="5261" end_char="5267">Denmark</TOKEN>
<TOKEN id="token-34-5" pos="punct" morph="none" start_char="5268" end_char="5268">,</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="5270" end_char="5280">contributed</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="5282" end_char="5283">to</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="5285" end_char="5288">this</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="5290" end_char="5295">report</TOKEN>
<TOKEN id="token-34-10" pos="punct" morph="none" start_char="5296" end_char="5296">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="5299" end_char="5303">
<ORIGINAL_TEXT>Video</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="5299" end_char="5303">Video</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
