<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CVMY" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="5541" raw_text_md5="7beb3fc33fd518c7f47010633393e04b">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="103">
<ORIGINAL_TEXT>Is plasma from people who have recovered from COVID-19 an effective treatment for people with COVID-19?</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="2">Is</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="4" end_char="9">plasma</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="11" end_char="14">from</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="16" end_char="21">people</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="23" end_char="25">who</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="27" end_char="30">have</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="32" end_char="40">recovered</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="42" end_char="45">from</TOKEN>
<TOKEN id="token-0-8" pos="unknown" morph="none" start_char="47" end_char="54">COVID-19</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="56" end_char="57">an</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="59" end_char="67">effective</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="69" end_char="77">treatment</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="79" end_char="81">for</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="83" end_char="88">people</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="90" end_char="93">with</TOKEN>
<TOKEN id="token-0-15" pos="unknown" morph="none" start_char="95" end_char="102">COVID-19</TOKEN>
<TOKEN id="token-0-16" pos="punct" morph="none" start_char="103" end_char="103">?</TOKEN>
</SEG>
<SEG id="segment-1" start_char="107" end_char="118">
<ORIGINAL_TEXT>Key messages</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="107" end_char="109">Key</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="111" end_char="118">messages</TOKEN>
</SEG>
<SEG id="segment-2" start_char="121" end_char="246">
<ORIGINAL_TEXT>• We are very confident that convalescent plasma has no benefits for the treatment of people with moderate to severe COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="punct" morph="none" start_char="121" end_char="121">•</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="123" end_char="124">We</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="126" end_char="128">are</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="130" end_char="133">very</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="135" end_char="143">confident</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="145" end_char="148">that</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="150" end_char="161">convalescent</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="163" end_char="168">plasma</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="170" end_char="172">has</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="174" end_char="175">no</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="177" end_char="184">benefits</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="186" end_char="188">for</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="190" end_char="192">the</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="194" end_char="202">treatment</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="204" end_char="205">of</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="207" end_char="212">people</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="214" end_char="217">with</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="219" end_char="226">moderate</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="228" end_char="229">to</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="231" end_char="236">severe</TOKEN>
<TOKEN id="token-2-20" pos="unknown" morph="none" start_char="238" end_char="245">COVID-19</TOKEN>
<TOKEN id="token-2-21" pos="punct" morph="none" start_char="246" end_char="246">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="249" end_char="371">
<ORIGINAL_TEXT>• We are uncertain about the effects of convalescent plasma for treating people with mild COVID-19 or who have no symptoms.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="punct" morph="none" start_char="249" end_char="249">•</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="251" end_char="252">We</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="254" end_char="256">are</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="258" end_char="266">uncertain</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="268" end_char="272">about</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="274" end_char="276">the</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="278" end_char="284">effects</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="286" end_char="287">of</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="289" end_char="300">convalescent</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="302" end_char="307">plasma</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="309" end_char="311">for</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="313" end_char="320">treating</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="322" end_char="327">people</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="329" end_char="332">with</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="334" end_char="337">mild</TOKEN>
<TOKEN id="token-3-15" pos="unknown" morph="none" start_char="339" end_char="346">COVID-19</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="348" end_char="349">or</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="351" end_char="353">who</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="355" end_char="358">have</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="360" end_char="361">no</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="363" end_char="370">symptoms</TOKEN>
<TOKEN id="token-3-21" pos="punct" morph="none" start_char="371" end_char="371">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="374" end_char="446">
<ORIGINAL_TEXT>• We found about 130 ongoing, unpublished and recently published studies.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="punct" morph="none" start_char="374" end_char="374">•</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="376" end_char="377">We</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="379" end_char="383">found</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="385" end_char="389">about</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="391" end_char="393">130</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="395" end_char="401">ongoing</TOKEN>
<TOKEN id="token-4-6" pos="punct" morph="none" start_char="402" end_char="402">,</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="404" end_char="414">unpublished</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="416" end_char="418">and</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="420" end_char="427">recently</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="429" end_char="437">published</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="439" end_char="445">studies</TOKEN>
<TOKEN id="token-4-12" pos="punct" morph="none" start_char="446" end_char="446">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="448" end_char="526">
<ORIGINAL_TEXT>We will update our review with evidence from these studies as soon as possible.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="448" end_char="449">We</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="451" end_char="454">will</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="456" end_char="461">update</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="463" end_char="465">our</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="467" end_char="472">review</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="474" end_char="477">with</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="479" end_char="486">evidence</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="488" end_char="491">from</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="493" end_char="497">these</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="499" end_char="505">studies</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="507" end_char="508">as</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="510" end_char="513">soon</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="515" end_char="516">as</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="518" end_char="525">possible</TOKEN>
<TOKEN id="token-5-14" pos="punct" morph="none" start_char="526" end_char="526">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="528" end_char="575">
<ORIGINAL_TEXT>New evidence may answer our remaining questions.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="528" end_char="530">New</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="532" end_char="539">evidence</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="541" end_char="543">may</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="545" end_char="550">answer</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="552" end_char="554">our</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="556" end_char="564">remaining</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="566" end_char="574">questions</TOKEN>
<TOKEN id="token-6-7" pos="punct" morph="none" start_char="575" end_char="575">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="578" end_char="605">
<ORIGINAL_TEXT>What is convalescent plasma?</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="578" end_char="581">What</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="583" end_char="584">is</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="586" end_char="597">convalescent</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="599" end_char="604">plasma</TOKEN>
<TOKEN id="token-7-4" pos="punct" morph="none" start_char="605" end_char="605">?</TOKEN>
</SEG>
<SEG id="segment-8" start_char="608" end_char="677">
<ORIGINAL_TEXT>The body produces antibodies as one of its defences against infection.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="608" end_char="610">The</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="612" end_char="615">body</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="617" end_char="624">produces</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="626" end_char="635">antibodies</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="637" end_char="638">as</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="640" end_char="642">one</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="644" end_char="645">of</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="647" end_char="649">its</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="651" end_char="658">defences</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="660" end_char="666">against</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="668" end_char="676">infection</TOKEN>
<TOKEN id="token-8-11" pos="punct" morph="none" start_char="677" end_char="677">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="679" end_char="734">
<ORIGINAL_TEXT>Antibodies are found in part of the blood called plasma.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="679" end_char="688">Antibodies</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="690" end_char="692">are</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="694" end_char="698">found</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="700" end_char="701">in</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="703" end_char="706">part</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="708" end_char="709">of</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="711" end_char="713">the</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="715" end_char="719">blood</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="721" end_char="726">called</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="728" end_char="733">plasma</TOKEN>
<TOKEN id="token-9-10" pos="punct" morph="none" start_char="734" end_char="734">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="736" end_char="868">
<ORIGINAL_TEXT>Plasma from people who have recovered from the COVID-19 virus contains COVID-19 antibodies, and can be used to make two preparations.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="736" end_char="741">Plasma</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="743" end_char="746">from</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="748" end_char="753">people</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="755" end_char="757">who</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="759" end_char="762">have</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="764" end_char="772">recovered</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="774" end_char="777">from</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="779" end_char="781">the</TOKEN>
<TOKEN id="token-10-8" pos="unknown" morph="none" start_char="783" end_char="790">COVID-19</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="792" end_char="796">virus</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="798" end_char="805">contains</TOKEN>
<TOKEN id="token-10-11" pos="unknown" morph="none" start_char="807" end_char="814">COVID-19</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="816" end_char="825">antibodies</TOKEN>
<TOKEN id="token-10-13" pos="punct" morph="none" start_char="826" end_char="826">,</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="828" end_char="830">and</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="832" end_char="834">can</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="836" end_char="837">be</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="839" end_char="842">used</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="844" end_char="845">to</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="847" end_char="850">make</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="852" end_char="854">two</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="856" end_char="867">preparations</TOKEN>
<TOKEN id="token-10-22" pos="punct" morph="none" start_char="868" end_char="868">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="870" end_char="969">
<ORIGINAL_TEXT>Firstly, it can be used to make convalescent plasma, which is plasma that contains these antibodies.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="870" end_char="876">Firstly</TOKEN>
<TOKEN id="token-11-1" pos="punct" morph="none" start_char="877" end_char="877">,</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="879" end_char="880">it</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="882" end_char="884">can</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="886" end_char="887">be</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="889" end_char="892">used</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="894" end_char="895">to</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="897" end_char="900">make</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="902" end_char="913">convalescent</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="915" end_char="920">plasma</TOKEN>
<TOKEN id="token-11-10" pos="punct" morph="none" start_char="921" end_char="921">,</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="923" end_char="927">which</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="929" end_char="930">is</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="932" end_char="937">plasma</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="939" end_char="942">that</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="944" end_char="951">contains</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="953" end_char="957">these</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="959" end_char="968">antibodies</TOKEN>
<TOKEN id="token-11-18" pos="punct" morph="none" start_char="969" end_char="969">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="971" end_char="1098">
<ORIGINAL_TEXT>Secondly, it can be used to make hyperimmune immunoglobulin, which is more concentrated, and therefore contains more antibodies.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="971" end_char="978">Secondly</TOKEN>
<TOKEN id="token-12-1" pos="punct" morph="none" start_char="979" end_char="979">,</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="981" end_char="982">it</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="984" end_char="986">can</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="988" end_char="989">be</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="991" end_char="994">used</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="996" end_char="997">to</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="999" end_char="1002">make</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1004" end_char="1014">hyperimmune</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1016" end_char="1029">immunoglobulin</TOKEN>
<TOKEN id="token-12-10" pos="punct" morph="none" start_char="1030" end_char="1030">,</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1032" end_char="1036">which</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1038" end_char="1039">is</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1041" end_char="1044">more</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1046" end_char="1057">concentrated</TOKEN>
<TOKEN id="token-12-15" pos="punct" morph="none" start_char="1058" end_char="1058">,</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1060" end_char="1062">and</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1064" end_char="1072">therefore</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1074" end_char="1081">contains</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1083" end_char="1086">more</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1088" end_char="1097">antibodies</TOKEN>
<TOKEN id="token-12-21" pos="punct" morph="none" start_char="1098" end_char="1098">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1101" end_char="1201">
<ORIGINAL_TEXT>Convalescent plasma and hyperimmune immunoglobulin have been used successfully to treat some viruses.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1101" end_char="1112">Convalescent</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1114" end_char="1119">plasma</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1121" end_char="1123">and</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1125" end_char="1135">hyperimmune</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1137" end_char="1150">immunoglobulin</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1152" end_char="1155">have</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1157" end_char="1160">been</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1162" end_char="1165">used</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1167" end_char="1178">successfully</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1180" end_char="1181">to</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1183" end_char="1187">treat</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1189" end_char="1192">some</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1194" end_char="1200">viruses</TOKEN>
<TOKEN id="token-13-13" pos="punct" morph="none" start_char="1201" end_char="1201">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1203" end_char="1311">
<ORIGINAL_TEXT>These treatments (given by a drip or injection) are generally well-tolerated, but can cause unwanted effects.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1203" end_char="1207">These</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1209" end_char="1218">treatments</TOKEN>
<TOKEN id="token-14-2" pos="punct" morph="none" start_char="1220" end_char="1220">(</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1221" end_char="1225">given</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1227" end_char="1228">by</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1230" end_char="1230">a</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1232" end_char="1235">drip</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1237" end_char="1238">or</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1240" end_char="1248">injection</TOKEN>
<TOKEN id="token-14-9" pos="punct" morph="none" start_char="1249" end_char="1249">)</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1251" end_char="1253">are</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1255" end_char="1263">generally</TOKEN>
<TOKEN id="token-14-12" pos="unknown" morph="none" start_char="1265" end_char="1278">well-tolerated</TOKEN>
<TOKEN id="token-14-13" pos="punct" morph="none" start_char="1279" end_char="1279">,</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="1281" end_char="1283">but</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1285" end_char="1287">can</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1289" end_char="1293">cause</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="1295" end_char="1302">unwanted</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="1304" end_char="1310">effects</TOKEN>
<TOKEN id="token-14-19" pos="punct" morph="none" start_char="1311" end_char="1311">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1314" end_char="1342">
<ORIGINAL_TEXT>What did we want to find out?</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1314" end_char="1317">What</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1319" end_char="1321">did</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1323" end_char="1324">we</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1326" end_char="1329">want</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1331" end_char="1332">to</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1334" end_char="1337">find</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1339" end_char="1341">out</TOKEN>
<TOKEN id="token-15-7" pos="punct" morph="none" start_char="1342" end_char="1342">?</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1345" end_char="1484">
<ORIGINAL_TEXT>We wanted to find out whether convalescent plasma or hyperimmune immunoglobulin are effective treatments for people with confirmed COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1345" end_char="1346">We</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1348" end_char="1353">wanted</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1355" end_char="1356">to</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1358" end_char="1361">find</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1363" end_char="1365">out</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1367" end_char="1373">whether</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1375" end_char="1386">convalescent</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1388" end_char="1393">plasma</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1395" end_char="1396">or</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="1398" end_char="1408">hyperimmune</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="1410" end_char="1423">immunoglobulin</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="1425" end_char="1427">are</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="1429" end_char="1437">effective</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="1439" end_char="1448">treatments</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="1450" end_char="1452">for</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="1454" end_char="1459">people</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="1461" end_char="1464">with</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="1466" end_char="1474">confirmed</TOKEN>
<TOKEN id="token-16-18" pos="unknown" morph="none" start_char="1476" end_char="1483">COVID-19</TOKEN>
<TOKEN id="token-16-19" pos="punct" morph="none" start_char="1484" end_char="1484">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1486" end_char="1498">
<ORIGINAL_TEXT>We looked at:</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1486" end_char="1487">We</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1489" end_char="1494">looked</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="1496" end_char="1497">at</TOKEN>
<TOKEN id="token-17-3" pos="punct" morph="none" start_char="1498" end_char="1498">:</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1501" end_char="1595">
<ORIGINAL_TEXT>• deaths from any cause after treatment with convalescent plasma or hyperimmune immunoglobulin;</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="punct" morph="none" start_char="1501" end_char="1501">•</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="1503" end_char="1508">deaths</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="1510" end_char="1513">from</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="1515" end_char="1517">any</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="1519" end_char="1523">cause</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="1525" end_char="1529">after</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="1531" end_char="1539">treatment</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="1541" end_char="1544">with</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="1546" end_char="1557">convalescent</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="1559" end_char="1564">plasma</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="1566" end_char="1567">or</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="1569" end_char="1579">hyperimmune</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="1581" end_char="1594">immunoglobulin</TOKEN>
<TOKEN id="token-18-13" pos="punct" morph="none" start_char="1595" end_char="1595">;</TOKEN>
</SEG>
<SEG id="segment-19" start_char="1598" end_char="1789">
<ORIGINAL_TEXT>• improvement or worsening of patients’ condition, measured by the number of people who needed help from a ventilator (a machine that helps people breathe if they cannot breathe on their own);</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="punct" morph="none" start_char="1598" end_char="1598">•</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="1600" end_char="1610">improvement</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="1612" end_char="1613">or</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="1615" end_char="1623">worsening</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="1625" end_char="1626">of</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="1628" end_char="1635">patients</TOKEN>
<TOKEN id="token-19-6" pos="punct" morph="none" start_char="1636" end_char="1636">’</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="1638" end_char="1646">condition</TOKEN>
<TOKEN id="token-19-8" pos="punct" morph="none" start_char="1647" end_char="1647">,</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="1649" end_char="1656">measured</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="1658" end_char="1659">by</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="1661" end_char="1663">the</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="1665" end_char="1670">number</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="1672" end_char="1673">of</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="1675" end_char="1680">people</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="1682" end_char="1684">who</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="1686" end_char="1691">needed</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="1693" end_char="1696">help</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="1698" end_char="1701">from</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="1703" end_char="1703">a</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="1705" end_char="1714">ventilator</TOKEN>
<TOKEN id="token-19-21" pos="punct" morph="none" start_char="1716" end_char="1716">(</TOKEN>
<TOKEN id="token-19-22" pos="word" morph="none" start_char="1717" end_char="1717">a</TOKEN>
<TOKEN id="token-19-23" pos="word" morph="none" start_char="1719" end_char="1725">machine</TOKEN>
<TOKEN id="token-19-24" pos="word" morph="none" start_char="1727" end_char="1730">that</TOKEN>
<TOKEN id="token-19-25" pos="word" morph="none" start_char="1732" end_char="1736">helps</TOKEN>
<TOKEN id="token-19-26" pos="word" morph="none" start_char="1738" end_char="1743">people</TOKEN>
<TOKEN id="token-19-27" pos="word" morph="none" start_char="1745" end_char="1751">breathe</TOKEN>
<TOKEN id="token-19-28" pos="word" morph="none" start_char="1753" end_char="1754">if</TOKEN>
<TOKEN id="token-19-29" pos="word" morph="none" start_char="1756" end_char="1759">they</TOKEN>
<TOKEN id="token-19-30" pos="word" morph="none" start_char="1761" end_char="1766">cannot</TOKEN>
<TOKEN id="token-19-31" pos="word" morph="none" start_char="1768" end_char="1774">breathe</TOKEN>
<TOKEN id="token-19-32" pos="word" morph="none" start_char="1776" end_char="1777">on</TOKEN>
<TOKEN id="token-19-33" pos="word" morph="none" start_char="1779" end_char="1783">their</TOKEN>
<TOKEN id="token-19-34" pos="word" morph="none" start_char="1785" end_char="1787">own</TOKEN>
<TOKEN id="token-19-35" pos="punct" morph="none" start_char="1788" end_char="1789">);</TOKEN>
</SEG>
<SEG id="segment-20" start_char="1792" end_char="1813">
<ORIGINAL_TEXT>• quality of life; and</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="punct" morph="none" start_char="1792" end_char="1792">•</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="1794" end_char="1800">quality</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="1802" end_char="1803">of</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="1805" end_char="1808">life</TOKEN>
<TOKEN id="token-20-4" pos="punct" morph="none" start_char="1809" end_char="1809">;</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="1811" end_char="1813">and</TOKEN>
</SEG>
<SEG id="segment-21" start_char="1816" end_char="1834">
<ORIGINAL_TEXT>• unwanted effects.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="punct" morph="none" start_char="1816" end_char="1816">•</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="1818" end_char="1825">unwanted</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="1827" end_char="1833">effects</TOKEN>
<TOKEN id="token-21-3" pos="punct" morph="none" start_char="1834" end_char="1834">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="1837" end_char="1851">
<ORIGINAL_TEXT>What did we do?</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="1837" end_char="1840">What</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="1842" end_char="1844">did</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="1846" end_char="1847">we</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="1849" end_char="1850">do</TOKEN>
<TOKEN id="token-22-4" pos="punct" morph="none" start_char="1851" end_char="1851">?</TOKEN>
</SEG>
<SEG id="segment-23" start_char="1854" end_char="1975">
<ORIGINAL_TEXT>We searched for studies that investigated convalescent plasma or hyperimmune immunoglobulin to treat people with COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="1854" end_char="1855">We</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="1857" end_char="1864">searched</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="1866" end_char="1868">for</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="1870" end_char="1876">studies</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="1878" end_char="1881">that</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="1883" end_char="1894">investigated</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="1896" end_char="1907">convalescent</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="1909" end_char="1914">plasma</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="1916" end_char="1917">or</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="1919" end_char="1929">hyperimmune</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="1931" end_char="1944">immunoglobulin</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="1946" end_char="1947">to</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="1949" end_char="1953">treat</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="1955" end_char="1960">people</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="1962" end_char="1965">with</TOKEN>
<TOKEN id="token-23-15" pos="unknown" morph="none" start_char="1967" end_char="1974">COVID-19</TOKEN>
<TOKEN id="token-23-16" pos="punct" morph="none" start_char="1975" end_char="1975">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="1977" end_char="2120">
<ORIGINAL_TEXT>Studies could take place anywhere in the world and include participants of any age, gender or ethnicity, with mild, moderate or severe COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="1977" end_char="1983">Studies</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="1985" end_char="1989">could</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="1991" end_char="1994">take</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="1996" end_char="2000">place</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="2002" end_char="2009">anywhere</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="2011" end_char="2012">in</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="2014" end_char="2016">the</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="2018" end_char="2022">world</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="2024" end_char="2026">and</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="2028" end_char="2034">include</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="2036" end_char="2047">participants</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="2049" end_char="2050">of</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="2052" end_char="2054">any</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="2056" end_char="2058">age</TOKEN>
<TOKEN id="token-24-14" pos="punct" morph="none" start_char="2059" end_char="2059">,</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="2061" end_char="2066">gender</TOKEN>
<TOKEN id="token-24-16" pos="word" morph="none" start_char="2068" end_char="2069">or</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="2071" end_char="2079">ethnicity</TOKEN>
<TOKEN id="token-24-18" pos="punct" morph="none" start_char="2080" end_char="2080">,</TOKEN>
<TOKEN id="token-24-19" pos="word" morph="none" start_char="2082" end_char="2085">with</TOKEN>
<TOKEN id="token-24-20" pos="word" morph="none" start_char="2087" end_char="2090">mild</TOKEN>
<TOKEN id="token-24-21" pos="punct" morph="none" start_char="2091" end_char="2091">,</TOKEN>
<TOKEN id="token-24-22" pos="word" morph="none" start_char="2093" end_char="2100">moderate</TOKEN>
<TOKEN id="token-24-23" pos="word" morph="none" start_char="2102" end_char="2103">or</TOKEN>
<TOKEN id="token-24-24" pos="word" morph="none" start_char="2105" end_char="2110">severe</TOKEN>
<TOKEN id="token-24-25" pos="unknown" morph="none" start_char="2112" end_char="2119">COVID-19</TOKEN>
<TOKEN id="token-24-26" pos="punct" morph="none" start_char="2120" end_char="2120">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2123" end_char="2184">
<ORIGINAL_TEXT>Where possible we pooled the studies’ results to analyse them.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="2123" end_char="2127">Where</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="2129" end_char="2136">possible</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="2138" end_char="2139">we</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="2141" end_char="2146">pooled</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="2148" end_char="2150">the</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="2152" end_char="2158">studies</TOKEN>
<TOKEN id="token-25-6" pos="punct" morph="none" start_char="2159" end_char="2159">’</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="2161" end_char="2167">results</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="2169" end_char="2170">to</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="2172" end_char="2178">analyse</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="2180" end_char="2183">them</TOKEN>
<TOKEN id="token-25-11" pos="punct" morph="none" start_char="2184" end_char="2184">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="2186" end_char="2275">
<ORIGINAL_TEXT>We rated our confidence in the evidence, based on factors such as study methods and sizes.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="2186" end_char="2187">We</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="2189" end_char="2193">rated</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="2195" end_char="2197">our</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="2199" end_char="2208">confidence</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="2210" end_char="2211">in</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="2213" end_char="2215">the</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="2217" end_char="2224">evidence</TOKEN>
<TOKEN id="token-26-7" pos="punct" morph="none" start_char="2225" end_char="2225">,</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="2227" end_char="2231">based</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="2233" end_char="2234">on</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="2236" end_char="2242">factors</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="2244" end_char="2247">such</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="2249" end_char="2250">as</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="2252" end_char="2256">study</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="2258" end_char="2264">methods</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="2266" end_char="2268">and</TOKEN>
<TOKEN id="token-26-16" pos="word" morph="none" start_char="2270" end_char="2274">sizes</TOKEN>
<TOKEN id="token-26-17" pos="punct" morph="none" start_char="2275" end_char="2275">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="2278" end_char="2294">
<ORIGINAL_TEXT>What did we find?</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="2278" end_char="2281">What</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="2283" end_char="2285">did</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="2287" end_char="2288">we</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="2290" end_char="2293">find</TOKEN>
<TOKEN id="token-27-4" pos="punct" morph="none" start_char="2294" end_char="2294">?</TOKEN>
</SEG>
<SEG id="segment-28" start_char="2297" end_char="2379">
<ORIGINAL_TEXT>We found 13 studies with 48,509 participants that investigated convalescent plasma.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="2297" end_char="2298">We</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="2300" end_char="2304">found</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="2306" end_char="2307">13</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="2309" end_char="2315">studies</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="2317" end_char="2320">with</TOKEN>
<TOKEN id="token-28-5" pos="unknown" morph="none" start_char="2322" end_char="2327">48,509</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="2329" end_char="2340">participants</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="2342" end_char="2345">that</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="2347" end_char="2358">investigated</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="2360" end_char="2371">convalescent</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="2373" end_char="2378">plasma</TOKEN>
<TOKEN id="token-28-11" pos="punct" morph="none" start_char="2379" end_char="2379">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="2381" end_char="2462">
<ORIGINAL_TEXT>All but one of the studies included participants with moderate to severe COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="2381" end_char="2383">All</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="2385" end_char="2387">but</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="2389" end_char="2391">one</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="2393" end_char="2394">of</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="2396" end_char="2398">the</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="2400" end_char="2406">studies</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="2408" end_char="2415">included</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="2417" end_char="2428">participants</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="2430" end_char="2433">with</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="2435" end_char="2442">moderate</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="2444" end_char="2445">to</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="2447" end_char="2452">severe</TOKEN>
<TOKEN id="token-29-12" pos="unknown" morph="none" start_char="2454" end_char="2461">COVID-19</TOKEN>
<TOKEN id="token-29-13" pos="punct" morph="none" start_char="2462" end_char="2462">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="2464" end_char="2536">
<ORIGINAL_TEXT>We did not find any studies that investigated hyperimmune immunoglobulin.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="2464" end_char="2465">We</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="2467" end_char="2469">did</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="2471" end_char="2473">not</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="2475" end_char="2478">find</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="2480" end_char="2482">any</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="2484" end_char="2490">studies</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="2492" end_char="2495">that</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="2497" end_char="2508">investigated</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="2510" end_char="2520">hyperimmune</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="2522" end_char="2535">immunoglobulin</TOKEN>
<TOKEN id="token-30-10" pos="punct" morph="none" start_char="2536" end_char="2536">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="2538" end_char="2609">
<ORIGINAL_TEXT>Studies mainly took place in hospitals, in countries all over the world.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="2538" end_char="2544">Studies</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="2546" end_char="2551">mainly</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="2553" end_char="2556">took</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="2558" end_char="2562">place</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="2564" end_char="2565">in</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="2567" end_char="2575">hospitals</TOKEN>
<TOKEN id="token-31-6" pos="punct" morph="none" start_char="2576" end_char="2576">,</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="2578" end_char="2579">in</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="2581" end_char="2589">countries</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="2591" end_char="2593">all</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="2595" end_char="2598">over</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="2600" end_char="2602">the</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="2604" end_char="2608">world</TOKEN>
<TOKEN id="token-31-13" pos="punct" morph="none" start_char="2609" end_char="2609">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="2612" end_char="2696">
<ORIGINAL_TEXT>Moderate to severe COVID-19 Convalescent plasma compared to placebo or standard care:</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="2612" end_char="2619">Moderate</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="2621" end_char="2622">to</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="2624" end_char="2629">severe</TOKEN>
<TOKEN id="token-32-3" pos="unknown" morph="none" start_char="2631" end_char="2638">COVID-19</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="2640" end_char="2651">Convalescent</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="2653" end_char="2658">plasma</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="2660" end_char="2667">compared</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="2669" end_char="2670">to</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="2672" end_char="2678">placebo</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="2680" end_char="2681">or</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="2683" end_char="2690">standard</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="2692" end_char="2695">care</TOKEN>
<TOKEN id="token-32-12" pos="punct" morph="none" start_char="2696" end_char="2696">:</TOKEN>
</SEG>
<SEG id="segment-33" start_char="2699" end_char="2798">
<ORIGINAL_TEXT>• convalescent plasma makes no difference to deaths from any cause at up to 28 days after treatment.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="punct" morph="none" start_char="2699" end_char="2699">•</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="2701" end_char="2712">convalescent</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="2714" end_char="2719">plasma</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="2721" end_char="2725">makes</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="2727" end_char="2728">no</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="2730" end_char="2739">difference</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="2741" end_char="2742">to</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="2744" end_char="2749">deaths</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="2751" end_char="2754">from</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="2756" end_char="2758">any</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="2760" end_char="2764">cause</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="2766" end_char="2767">at</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="2769" end_char="2770">up</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="2772" end_char="2773">to</TOKEN>
<TOKEN id="token-33-14" pos="word" morph="none" start_char="2775" end_char="2776">28</TOKEN>
<TOKEN id="token-33-15" pos="word" morph="none" start_char="2778" end_char="2781">days</TOKEN>
<TOKEN id="token-33-16" pos="word" morph="none" start_char="2783" end_char="2787">after</TOKEN>
<TOKEN id="token-33-17" pos="word" morph="none" start_char="2789" end_char="2797">treatment</TOKEN>
<TOKEN id="token-33-18" pos="punct" morph="none" start_char="2798" end_char="2798">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="2800" end_char="2958">
<ORIGINAL_TEXT>About 237 in 1000 people given placebo or standard care died, compared to 233 in 1000 people who had been given convalescent plasma (7 studies, 12,646 people);</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="2800" end_char="2804">About</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="2806" end_char="2808">237</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="2810" end_char="2811">in</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="2813" end_char="2816">1000</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="2818" end_char="2823">people</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="2825" end_char="2829">given</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="2831" end_char="2837">placebo</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="2839" end_char="2840">or</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="2842" end_char="2849">standard</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="2851" end_char="2854">care</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="2856" end_char="2859">died</TOKEN>
<TOKEN id="token-34-11" pos="punct" morph="none" start_char="2860" end_char="2860">,</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="2862" end_char="2869">compared</TOKEN>
<TOKEN id="token-34-13" pos="word" morph="none" start_char="2871" end_char="2872">to</TOKEN>
<TOKEN id="token-34-14" pos="word" morph="none" start_char="2874" end_char="2876">233</TOKEN>
<TOKEN id="token-34-15" pos="word" morph="none" start_char="2878" end_char="2879">in</TOKEN>
<TOKEN id="token-34-16" pos="word" morph="none" start_char="2881" end_char="2884">1000</TOKEN>
<TOKEN id="token-34-17" pos="word" morph="none" start_char="2886" end_char="2891">people</TOKEN>
<TOKEN id="token-34-18" pos="word" morph="none" start_char="2893" end_char="2895">who</TOKEN>
<TOKEN id="token-34-19" pos="word" morph="none" start_char="2897" end_char="2899">had</TOKEN>
<TOKEN id="token-34-20" pos="word" morph="none" start_char="2901" end_char="2904">been</TOKEN>
<TOKEN id="token-34-21" pos="word" morph="none" start_char="2906" end_char="2910">given</TOKEN>
<TOKEN id="token-34-22" pos="word" morph="none" start_char="2912" end_char="2923">convalescent</TOKEN>
<TOKEN id="token-34-23" pos="word" morph="none" start_char="2925" end_char="2930">plasma</TOKEN>
<TOKEN id="token-34-24" pos="punct" morph="none" start_char="2932" end_char="2932">(</TOKEN>
<TOKEN id="token-34-25" pos="word" morph="none" start_char="2933" end_char="2933">7</TOKEN>
<TOKEN id="token-34-26" pos="word" morph="none" start_char="2935" end_char="2941">studies</TOKEN>
<TOKEN id="token-34-27" pos="punct" morph="none" start_char="2942" end_char="2942">,</TOKEN>
<TOKEN id="token-34-28" pos="unknown" morph="none" start_char="2944" end_char="2949">12,646</TOKEN>
<TOKEN id="token-34-29" pos="word" morph="none" start_char="2951" end_char="2956">people</TOKEN>
<TOKEN id="token-34-30" pos="punct" morph="none" start_char="2957" end_char="2958">);</TOKEN>
</SEG>
<SEG id="segment-35" start_char="2961" end_char="3315">
<ORIGINAL_TEXT>• convalescent plasma makes little to no difference to the improvement of patients’ condition in terms of needing less breathing support for the overall population needing any breathing support before the start of treatment (8 studies, 12,682 people), and also not for the people that were ventilated at the beginning of the study (2 studies, 630 people);</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="punct" morph="none" start_char="2961" end_char="2961">•</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="2963" end_char="2974">convalescent</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="2976" end_char="2981">plasma</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="2983" end_char="2987">makes</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="2989" end_char="2994">little</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="2996" end_char="2997">to</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="2999" end_char="3000">no</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="3002" end_char="3011">difference</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="3013" end_char="3014">to</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="3016" end_char="3018">the</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="3020" end_char="3030">improvement</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="3032" end_char="3033">of</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="3035" end_char="3042">patients</TOKEN>
<TOKEN id="token-35-13" pos="punct" morph="none" start_char="3043" end_char="3043">’</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="3045" end_char="3053">condition</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="3055" end_char="3056">in</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="3058" end_char="3062">terms</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="3064" end_char="3065">of</TOKEN>
<TOKEN id="token-35-18" pos="word" morph="none" start_char="3067" end_char="3073">needing</TOKEN>
<TOKEN id="token-35-19" pos="word" morph="none" start_char="3075" end_char="3078">less</TOKEN>
<TOKEN id="token-35-20" pos="word" morph="none" start_char="3080" end_char="3088">breathing</TOKEN>
<TOKEN id="token-35-21" pos="word" morph="none" start_char="3090" end_char="3096">support</TOKEN>
<TOKEN id="token-35-22" pos="word" morph="none" start_char="3098" end_char="3100">for</TOKEN>
<TOKEN id="token-35-23" pos="word" morph="none" start_char="3102" end_char="3104">the</TOKEN>
<TOKEN id="token-35-24" pos="word" morph="none" start_char="3106" end_char="3112">overall</TOKEN>
<TOKEN id="token-35-25" pos="word" morph="none" start_char="3114" end_char="3123">population</TOKEN>
<TOKEN id="token-35-26" pos="word" morph="none" start_char="3125" end_char="3131">needing</TOKEN>
<TOKEN id="token-35-27" pos="word" morph="none" start_char="3133" end_char="3135">any</TOKEN>
<TOKEN id="token-35-28" pos="word" morph="none" start_char="3137" end_char="3145">breathing</TOKEN>
<TOKEN id="token-35-29" pos="word" morph="none" start_char="3147" end_char="3153">support</TOKEN>
<TOKEN id="token-35-30" pos="word" morph="none" start_char="3155" end_char="3160">before</TOKEN>
<TOKEN id="token-35-31" pos="word" morph="none" start_char="3162" end_char="3164">the</TOKEN>
<TOKEN id="token-35-32" pos="word" morph="none" start_char="3166" end_char="3170">start</TOKEN>
<TOKEN id="token-35-33" pos="word" morph="none" start_char="3172" end_char="3173">of</TOKEN>
<TOKEN id="token-35-34" pos="word" morph="none" start_char="3175" end_char="3183">treatment</TOKEN>
<TOKEN id="token-35-35" pos="punct" morph="none" start_char="3185" end_char="3185">(</TOKEN>
<TOKEN id="token-35-36" pos="word" morph="none" start_char="3186" end_char="3186">8</TOKEN>
<TOKEN id="token-35-37" pos="word" morph="none" start_char="3188" end_char="3194">studies</TOKEN>
<TOKEN id="token-35-38" pos="punct" morph="none" start_char="3195" end_char="3195">,</TOKEN>
<TOKEN id="token-35-39" pos="unknown" morph="none" start_char="3197" end_char="3202">12,682</TOKEN>
<TOKEN id="token-35-40" pos="word" morph="none" start_char="3204" end_char="3209">people</TOKEN>
<TOKEN id="token-35-41" pos="punct" morph="none" start_char="3210" end_char="3211">),</TOKEN>
<TOKEN id="token-35-42" pos="word" morph="none" start_char="3213" end_char="3215">and</TOKEN>
<TOKEN id="token-35-43" pos="word" morph="none" start_char="3217" end_char="3220">also</TOKEN>
<TOKEN id="token-35-44" pos="word" morph="none" start_char="3222" end_char="3224">not</TOKEN>
<TOKEN id="token-35-45" pos="word" morph="none" start_char="3226" end_char="3228">for</TOKEN>
<TOKEN id="token-35-46" pos="word" morph="none" start_char="3230" end_char="3232">the</TOKEN>
<TOKEN id="token-35-47" pos="word" morph="none" start_char="3234" end_char="3239">people</TOKEN>
<TOKEN id="token-35-48" pos="word" morph="none" start_char="3241" end_char="3244">that</TOKEN>
<TOKEN id="token-35-49" pos="word" morph="none" start_char="3246" end_char="3249">were</TOKEN>
<TOKEN id="token-35-50" pos="word" morph="none" start_char="3251" end_char="3260">ventilated</TOKEN>
<TOKEN id="token-35-51" pos="word" morph="none" start_char="3262" end_char="3263">at</TOKEN>
<TOKEN id="token-35-52" pos="word" morph="none" start_char="3265" end_char="3267">the</TOKEN>
<TOKEN id="token-35-53" pos="word" morph="none" start_char="3269" end_char="3277">beginning</TOKEN>
<TOKEN id="token-35-54" pos="word" morph="none" start_char="3279" end_char="3280">of</TOKEN>
<TOKEN id="token-35-55" pos="word" morph="none" start_char="3282" end_char="3284">the</TOKEN>
<TOKEN id="token-35-56" pos="word" morph="none" start_char="3286" end_char="3290">study</TOKEN>
<TOKEN id="token-35-57" pos="punct" morph="none" start_char="3292" end_char="3292">(</TOKEN>
<TOKEN id="token-35-58" pos="word" morph="none" start_char="3293" end_char="3293">2</TOKEN>
<TOKEN id="token-35-59" pos="word" morph="none" start_char="3295" end_char="3301">studies</TOKEN>
<TOKEN id="token-35-60" pos="punct" morph="none" start_char="3302" end_char="3302">,</TOKEN>
<TOKEN id="token-35-61" pos="word" morph="none" start_char="3304" end_char="3306">630</TOKEN>
<TOKEN id="token-35-62" pos="word" morph="none" start_char="3308" end_char="3313">people</TOKEN>
<TOKEN id="token-35-63" pos="punct" morph="none" start_char="3314" end_char="3315">);</TOKEN>
</SEG>
<SEG id="segment-36" start_char="3318" end_char="3399">
<ORIGINAL_TEXT>• convalescent plasma makes no difference to the worsening of patients’ condition.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="punct" morph="none" start_char="3318" end_char="3318">•</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="3320" end_char="3331">convalescent</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="3333" end_char="3338">plasma</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="3340" end_char="3344">makes</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="3346" end_char="3347">no</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="3349" end_char="3358">difference</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="3360" end_char="3361">to</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="3363" end_char="3365">the</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="3367" end_char="3375">worsening</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="3377" end_char="3378">of</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="3380" end_char="3387">patients</TOKEN>
<TOKEN id="token-36-11" pos="punct" morph="none" start_char="3388" end_char="3388">’</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="3390" end_char="3398">condition</TOKEN>
<TOKEN id="token-36-13" pos="punct" morph="none" start_char="3399" end_char="3399">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="3401" end_char="3593">
<ORIGINAL_TEXT>About 126 in 1000 people given placebo or standard care needed invasive mechanical ventilation, compared to 123 in 1000 people who had been given convalescent plasma (4 studies, 11,765 people);</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="3401" end_char="3405">About</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="3407" end_char="3409">126</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="3411" end_char="3412">in</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="3414" end_char="3417">1000</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="3419" end_char="3424">people</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="3426" end_char="3430">given</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="3432" end_char="3438">placebo</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="3440" end_char="3441">or</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="3443" end_char="3450">standard</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="3452" end_char="3455">care</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="3457" end_char="3462">needed</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="3464" end_char="3471">invasive</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="3473" end_char="3482">mechanical</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="3484" end_char="3494">ventilation</TOKEN>
<TOKEN id="token-37-14" pos="punct" morph="none" start_char="3495" end_char="3495">,</TOKEN>
<TOKEN id="token-37-15" pos="word" morph="none" start_char="3497" end_char="3504">compared</TOKEN>
<TOKEN id="token-37-16" pos="word" morph="none" start_char="3506" end_char="3507">to</TOKEN>
<TOKEN id="token-37-17" pos="word" morph="none" start_char="3509" end_char="3511">123</TOKEN>
<TOKEN id="token-37-18" pos="word" morph="none" start_char="3513" end_char="3514">in</TOKEN>
<TOKEN id="token-37-19" pos="word" morph="none" start_char="3516" end_char="3519">1000</TOKEN>
<TOKEN id="token-37-20" pos="word" morph="none" start_char="3521" end_char="3526">people</TOKEN>
<TOKEN id="token-37-21" pos="word" morph="none" start_char="3528" end_char="3530">who</TOKEN>
<TOKEN id="token-37-22" pos="word" morph="none" start_char="3532" end_char="3534">had</TOKEN>
<TOKEN id="token-37-23" pos="word" morph="none" start_char="3536" end_char="3539">been</TOKEN>
<TOKEN id="token-37-24" pos="word" morph="none" start_char="3541" end_char="3545">given</TOKEN>
<TOKEN id="token-37-25" pos="word" morph="none" start_char="3547" end_char="3558">convalescent</TOKEN>
<TOKEN id="token-37-26" pos="word" morph="none" start_char="3560" end_char="3565">plasma</TOKEN>
<TOKEN id="token-37-27" pos="punct" morph="none" start_char="3567" end_char="3567">(</TOKEN>
<TOKEN id="token-37-28" pos="word" morph="none" start_char="3568" end_char="3568">4</TOKEN>
<TOKEN id="token-37-29" pos="word" morph="none" start_char="3570" end_char="3576">studies</TOKEN>
<TOKEN id="token-37-30" pos="punct" morph="none" start_char="3577" end_char="3577">,</TOKEN>
<TOKEN id="token-37-31" pos="unknown" morph="none" start_char="3579" end_char="3584">11,765</TOKEN>
<TOKEN id="token-37-32" pos="word" morph="none" start_char="3586" end_char="3591">people</TOKEN>
<TOKEN id="token-37-33" pos="punct" morph="none" start_char="3592" end_char="3593">);</TOKEN>
</SEG>
<SEG id="segment-38" start_char="3596" end_char="3660">
<ORIGINAL_TEXT>• convalescent plasma may make no difference to unwanted effects.</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="punct" morph="none" start_char="3596" end_char="3596">•</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="3598" end_char="3609">convalescent</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="3611" end_char="3616">plasma</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="3618" end_char="3620">may</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="3622" end_char="3625">make</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="3627" end_char="3628">no</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="3630" end_char="3639">difference</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="3641" end_char="3642">to</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="3644" end_char="3651">unwanted</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="3653" end_char="3659">effects</TOKEN>
<TOKEN id="token-38-10" pos="punct" morph="none" start_char="3660" end_char="3660">.</TOKEN>
</SEG>
<SEG id="segment-39" start_char="3662" end_char="3801">
<ORIGINAL_TEXT>The 8 studies that reported unwanted effects measured and reported their results very differently, so we are unable to draw any conclusions.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="3662" end_char="3664">The</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="3666" end_char="3666">8</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="3668" end_char="3674">studies</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="3676" end_char="3679">that</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="3681" end_char="3688">reported</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="3690" end_char="3697">unwanted</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="3699" end_char="3705">effects</TOKEN>
<TOKEN id="token-39-7" pos="word" morph="none" start_char="3707" end_char="3714">measured</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="3716" end_char="3718">and</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="3720" end_char="3727">reported</TOKEN>
<TOKEN id="token-39-10" pos="word" morph="none" start_char="3729" end_char="3733">their</TOKEN>
<TOKEN id="token-39-11" pos="word" morph="none" start_char="3735" end_char="3741">results</TOKEN>
<TOKEN id="token-39-12" pos="word" morph="none" start_char="3743" end_char="3746">very</TOKEN>
<TOKEN id="token-39-13" pos="word" morph="none" start_char="3748" end_char="3758">differently</TOKEN>
<TOKEN id="token-39-14" pos="punct" morph="none" start_char="3759" end_char="3759">,</TOKEN>
<TOKEN id="token-39-15" pos="word" morph="none" start_char="3761" end_char="3762">so</TOKEN>
<TOKEN id="token-39-16" pos="word" morph="none" start_char="3764" end_char="3765">we</TOKEN>
<TOKEN id="token-39-17" pos="word" morph="none" start_char="3767" end_char="3769">are</TOKEN>
<TOKEN id="token-39-18" pos="word" morph="none" start_char="3771" end_char="3776">unable</TOKEN>
<TOKEN id="token-39-19" pos="word" morph="none" start_char="3778" end_char="3779">to</TOKEN>
<TOKEN id="token-39-20" pos="word" morph="none" start_char="3781" end_char="3784">draw</TOKEN>
<TOKEN id="token-39-21" pos="word" morph="none" start_char="3786" end_char="3788">any</TOKEN>
<TOKEN id="token-39-22" pos="word" morph="none" start_char="3790" end_char="3800">conclusions</TOKEN>
<TOKEN id="token-39-23" pos="punct" morph="none" start_char="3801" end_char="3801">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="3804" end_char="3848">
<ORIGINAL_TEXT>None of the studies reported quality of life.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="3804" end_char="3807">None</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="3809" end_char="3810">of</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="3812" end_char="3814">the</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="3816" end_char="3822">studies</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="3824" end_char="3831">reported</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="3833" end_char="3839">quality</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="3841" end_char="3842">of</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="3844" end_char="3847">life</TOKEN>
<TOKEN id="token-40-8" pos="punct" morph="none" start_char="3848" end_char="3848">.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="3851" end_char="4064">
<ORIGINAL_TEXT>Mild COVID-19 We do not know if convalescent plasma compared to placebo or standard care makes a difference to number of deaths, improvement or worsening of patients’ condition, quality of life or unwanted effects.</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="3851" end_char="3854">Mild</TOKEN>
<TOKEN id="token-41-1" pos="unknown" morph="none" start_char="3856" end_char="3863">COVID-19</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="3865" end_char="3866">We</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="3868" end_char="3869">do</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="3871" end_char="3873">not</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="3875" end_char="3878">know</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="3880" end_char="3881">if</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="3883" end_char="3894">convalescent</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="3896" end_char="3901">plasma</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="3903" end_char="3910">compared</TOKEN>
<TOKEN id="token-41-10" pos="word" morph="none" start_char="3912" end_char="3913">to</TOKEN>
<TOKEN id="token-41-11" pos="word" morph="none" start_char="3915" end_char="3921">placebo</TOKEN>
<TOKEN id="token-41-12" pos="word" morph="none" start_char="3923" end_char="3924">or</TOKEN>
<TOKEN id="token-41-13" pos="word" morph="none" start_char="3926" end_char="3933">standard</TOKEN>
<TOKEN id="token-41-14" pos="word" morph="none" start_char="3935" end_char="3938">care</TOKEN>
<TOKEN id="token-41-15" pos="word" morph="none" start_char="3940" end_char="3944">makes</TOKEN>
<TOKEN id="token-41-16" pos="word" morph="none" start_char="3946" end_char="3946">a</TOKEN>
<TOKEN id="token-41-17" pos="word" morph="none" start_char="3948" end_char="3957">difference</TOKEN>
<TOKEN id="token-41-18" pos="word" morph="none" start_char="3959" end_char="3960">to</TOKEN>
<TOKEN id="token-41-19" pos="word" morph="none" start_char="3962" end_char="3967">number</TOKEN>
<TOKEN id="token-41-20" pos="word" morph="none" start_char="3969" end_char="3970">of</TOKEN>
<TOKEN id="token-41-21" pos="word" morph="none" start_char="3972" end_char="3977">deaths</TOKEN>
<TOKEN id="token-41-22" pos="punct" morph="none" start_char="3978" end_char="3978">,</TOKEN>
<TOKEN id="token-41-23" pos="word" morph="none" start_char="3980" end_char="3990">improvement</TOKEN>
<TOKEN id="token-41-24" pos="word" morph="none" start_char="3992" end_char="3993">or</TOKEN>
<TOKEN id="token-41-25" pos="word" morph="none" start_char="3995" end_char="4003">worsening</TOKEN>
<TOKEN id="token-41-26" pos="word" morph="none" start_char="4005" end_char="4006">of</TOKEN>
<TOKEN id="token-41-27" pos="word" morph="none" start_char="4008" end_char="4015">patients</TOKEN>
<TOKEN id="token-41-28" pos="punct" morph="none" start_char="4016" end_char="4016">’</TOKEN>
<TOKEN id="token-41-29" pos="word" morph="none" start_char="4018" end_char="4026">condition</TOKEN>
<TOKEN id="token-41-30" pos="punct" morph="none" start_char="4027" end_char="4027">,</TOKEN>
<TOKEN id="token-41-31" pos="word" morph="none" start_char="4029" end_char="4035">quality</TOKEN>
<TOKEN id="token-41-32" pos="word" morph="none" start_char="4037" end_char="4038">of</TOKEN>
<TOKEN id="token-41-33" pos="word" morph="none" start_char="4040" end_char="4043">life</TOKEN>
<TOKEN id="token-41-34" pos="word" morph="none" start_char="4045" end_char="4046">or</TOKEN>
<TOKEN id="token-41-35" pos="word" morph="none" start_char="4048" end_char="4055">unwanted</TOKEN>
<TOKEN id="token-41-36" pos="word" morph="none" start_char="4057" end_char="4063">effects</TOKEN>
<TOKEN id="token-41-37" pos="punct" morph="none" start_char="4064" end_char="4064">.</TOKEN>
</SEG>
<SEG id="segment-42" start_char="4066" end_char="4151">
<ORIGINAL_TEXT>We found only one study with 160 participants that assessed people with mild COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="4066" end_char="4067">We</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="4069" end_char="4073">found</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="4075" end_char="4078">only</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="4080" end_char="4082">one</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="4084" end_char="4088">study</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="4090" end_char="4093">with</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="4095" end_char="4097">160</TOKEN>
<TOKEN id="token-42-7" pos="word" morph="none" start_char="4099" end_char="4110">participants</TOKEN>
<TOKEN id="token-42-8" pos="word" morph="none" start_char="4112" end_char="4115">that</TOKEN>
<TOKEN id="token-42-9" pos="word" morph="none" start_char="4117" end_char="4124">assessed</TOKEN>
<TOKEN id="token-42-10" pos="word" morph="none" start_char="4126" end_char="4131">people</TOKEN>
<TOKEN id="token-42-11" pos="word" morph="none" start_char="4133" end_char="4136">with</TOKEN>
<TOKEN id="token-42-12" pos="word" morph="none" start_char="4138" end_char="4141">mild</TOKEN>
<TOKEN id="token-42-13" pos="unknown" morph="none" start_char="4143" end_char="4150">COVID-19</TOKEN>
<TOKEN id="token-42-14" pos="punct" morph="none" start_char="4151" end_char="4151">.</TOKEN>
</SEG>
<SEG id="segment-43" start_char="4154" end_char="4194">
<ORIGINAL_TEXT>What are the limitations of the evidence?</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="4154" end_char="4157">What</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="4159" end_char="4161">are</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="4163" end_char="4165">the</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="4167" end_char="4177">limitations</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="4179" end_char="4180">of</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="4182" end_char="4184">the</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="4186" end_char="4193">evidence</TOKEN>
<TOKEN id="token-43-7" pos="punct" morph="none" start_char="4194" end_char="4194">?</TOKEN>
</SEG>
<SEG id="segment-44" start_char="4197" end_char="4357">
<ORIGINAL_TEXT>• We are very confident in the evidence for deaths from any cause and improvement or worsening of patients’ condition in people with moderate to severe COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="punct" morph="none" start_char="4197" end_char="4197">•</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="4199" end_char="4200">We</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="4202" end_char="4204">are</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="4206" end_char="4209">very</TOKEN>
<TOKEN id="token-44-4" pos="word" morph="none" start_char="4211" end_char="4219">confident</TOKEN>
<TOKEN id="token-44-5" pos="word" morph="none" start_char="4221" end_char="4222">in</TOKEN>
<TOKEN id="token-44-6" pos="word" morph="none" start_char="4224" end_char="4226">the</TOKEN>
<TOKEN id="token-44-7" pos="word" morph="none" start_char="4228" end_char="4235">evidence</TOKEN>
<TOKEN id="token-44-8" pos="word" morph="none" start_char="4237" end_char="4239">for</TOKEN>
<TOKEN id="token-44-9" pos="word" morph="none" start_char="4241" end_char="4246">deaths</TOKEN>
<TOKEN id="token-44-10" pos="word" morph="none" start_char="4248" end_char="4251">from</TOKEN>
<TOKEN id="token-44-11" pos="word" morph="none" start_char="4253" end_char="4255">any</TOKEN>
<TOKEN id="token-44-12" pos="word" morph="none" start_char="4257" end_char="4261">cause</TOKEN>
<TOKEN id="token-44-13" pos="word" morph="none" start_char="4263" end_char="4265">and</TOKEN>
<TOKEN id="token-44-14" pos="word" morph="none" start_char="4267" end_char="4277">improvement</TOKEN>
<TOKEN id="token-44-15" pos="word" morph="none" start_char="4279" end_char="4280">or</TOKEN>
<TOKEN id="token-44-16" pos="word" morph="none" start_char="4282" end_char="4290">worsening</TOKEN>
<TOKEN id="token-44-17" pos="word" morph="none" start_char="4292" end_char="4293">of</TOKEN>
<TOKEN id="token-44-18" pos="word" morph="none" start_char="4295" end_char="4302">patients</TOKEN>
<TOKEN id="token-44-19" pos="punct" morph="none" start_char="4303" end_char="4303">’</TOKEN>
<TOKEN id="token-44-20" pos="word" morph="none" start_char="4305" end_char="4313">condition</TOKEN>
<TOKEN id="token-44-21" pos="word" morph="none" start_char="4315" end_char="4316">in</TOKEN>
<TOKEN id="token-44-22" pos="word" morph="none" start_char="4318" end_char="4323">people</TOKEN>
<TOKEN id="token-44-23" pos="word" morph="none" start_char="4325" end_char="4328">with</TOKEN>
<TOKEN id="token-44-24" pos="word" morph="none" start_char="4330" end_char="4337">moderate</TOKEN>
<TOKEN id="token-44-25" pos="word" morph="none" start_char="4339" end_char="4340">to</TOKEN>
<TOKEN id="token-44-26" pos="word" morph="none" start_char="4342" end_char="4347">severe</TOKEN>
<TOKEN id="token-44-27" pos="unknown" morph="none" start_char="4349" end_char="4356">COVID-19</TOKEN>
<TOKEN id="token-44-28" pos="punct" morph="none" start_char="4357" end_char="4357">.</TOKEN>
</SEG>
<SEG id="segment-45" start_char="4360" end_char="4579">
<ORIGINAL_TEXT>• Our confidence in the other evidence for people with moderate and severe, and mild COVID-19 is very limited because the studies were very different and did not measure and record their results using consistent methods.</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="punct" morph="none" start_char="4360" end_char="4360">•</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="4362" end_char="4364">Our</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="4366" end_char="4375">confidence</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="4377" end_char="4378">in</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="4380" end_char="4382">the</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="4384" end_char="4388">other</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="4390" end_char="4397">evidence</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="4399" end_char="4401">for</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="4403" end_char="4408">people</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="4410" end_char="4413">with</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="4415" end_char="4422">moderate</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="4424" end_char="4426">and</TOKEN>
<TOKEN id="token-45-12" pos="word" morph="none" start_char="4428" end_char="4433">severe</TOKEN>
<TOKEN id="token-45-13" pos="punct" morph="none" start_char="4434" end_char="4434">,</TOKEN>
<TOKEN id="token-45-14" pos="word" morph="none" start_char="4436" end_char="4438">and</TOKEN>
<TOKEN id="token-45-15" pos="word" morph="none" start_char="4440" end_char="4443">mild</TOKEN>
<TOKEN id="token-45-16" pos="unknown" morph="none" start_char="4445" end_char="4452">COVID-19</TOKEN>
<TOKEN id="token-45-17" pos="word" morph="none" start_char="4454" end_char="4455">is</TOKEN>
<TOKEN id="token-45-18" pos="word" morph="none" start_char="4457" end_char="4460">very</TOKEN>
<TOKEN id="token-45-19" pos="word" morph="none" start_char="4462" end_char="4468">limited</TOKEN>
<TOKEN id="token-45-20" pos="word" morph="none" start_char="4470" end_char="4476">because</TOKEN>
<TOKEN id="token-45-21" pos="word" morph="none" start_char="4478" end_char="4480">the</TOKEN>
<TOKEN id="token-45-22" pos="word" morph="none" start_char="4482" end_char="4488">studies</TOKEN>
<TOKEN id="token-45-23" pos="word" morph="none" start_char="4490" end_char="4493">were</TOKEN>
<TOKEN id="token-45-24" pos="word" morph="none" start_char="4495" end_char="4498">very</TOKEN>
<TOKEN id="token-45-25" pos="word" morph="none" start_char="4500" end_char="4508">different</TOKEN>
<TOKEN id="token-45-26" pos="word" morph="none" start_char="4510" end_char="4512">and</TOKEN>
<TOKEN id="token-45-27" pos="word" morph="none" start_char="4514" end_char="4516">did</TOKEN>
<TOKEN id="token-45-28" pos="word" morph="none" start_char="4518" end_char="4520">not</TOKEN>
<TOKEN id="token-45-29" pos="word" morph="none" start_char="4522" end_char="4528">measure</TOKEN>
<TOKEN id="token-45-30" pos="word" morph="none" start_char="4530" end_char="4532">and</TOKEN>
<TOKEN id="token-45-31" pos="word" morph="none" start_char="4534" end_char="4539">record</TOKEN>
<TOKEN id="token-45-32" pos="word" morph="none" start_char="4541" end_char="4545">their</TOKEN>
<TOKEN id="token-45-33" pos="word" morph="none" start_char="4547" end_char="4553">results</TOKEN>
<TOKEN id="token-45-34" pos="word" morph="none" start_char="4555" end_char="4559">using</TOKEN>
<TOKEN id="token-45-35" pos="word" morph="none" start_char="4561" end_char="4570">consistent</TOKEN>
<TOKEN id="token-45-36" pos="word" morph="none" start_char="4572" end_char="4578">methods</TOKEN>
<TOKEN id="token-45-37" pos="punct" morph="none" start_char="4579" end_char="4579">.</TOKEN>
</SEG>
<SEG id="segment-46" start_char="4582" end_char="4663">
<ORIGINAL_TEXT>• We found little useful evidence on unwanted effects and none on quality of life.</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="punct" morph="none" start_char="4582" end_char="4582">•</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="4584" end_char="4585">We</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="4587" end_char="4591">found</TOKEN>
<TOKEN id="token-46-3" pos="word" morph="none" start_char="4593" end_char="4598">little</TOKEN>
<TOKEN id="token-46-4" pos="word" morph="none" start_char="4600" end_char="4605">useful</TOKEN>
<TOKEN id="token-46-5" pos="word" morph="none" start_char="4607" end_char="4614">evidence</TOKEN>
<TOKEN id="token-46-6" pos="word" morph="none" start_char="4616" end_char="4617">on</TOKEN>
<TOKEN id="token-46-7" pos="word" morph="none" start_char="4619" end_char="4626">unwanted</TOKEN>
<TOKEN id="token-46-8" pos="word" morph="none" start_char="4628" end_char="4634">effects</TOKEN>
<TOKEN id="token-46-9" pos="word" morph="none" start_char="4636" end_char="4638">and</TOKEN>
<TOKEN id="token-46-10" pos="word" morph="none" start_char="4640" end_char="4643">none</TOKEN>
<TOKEN id="token-46-11" pos="word" morph="none" start_char="4645" end_char="4646">on</TOKEN>
<TOKEN id="token-46-12" pos="word" morph="none" start_char="4648" end_char="4654">quality</TOKEN>
<TOKEN id="token-46-13" pos="word" morph="none" start_char="4656" end_char="4657">of</TOKEN>
<TOKEN id="token-46-14" pos="word" morph="none" start_char="4659" end_char="4662">life</TOKEN>
<TOKEN id="token-46-15" pos="punct" morph="none" start_char="4663" end_char="4663">.</TOKEN>
</SEG>
<SEG id="segment-47" start_char="4666" end_char="4697">
<ORIGINAL_TEXT>How up to date is this evidence?</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="4666" end_char="4668">How</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="4670" end_char="4671">up</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="4673" end_char="4674">to</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="4676" end_char="4679">date</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="4681" end_char="4682">is</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="4684" end_char="4687">this</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="4689" end_char="4696">evidence</TOKEN>
<TOKEN id="token-47-7" pos="punct" morph="none" start_char="4697" end_char="4697">?</TOKEN>
</SEG>
<SEG id="segment-48" start_char="4700" end_char="4740">
<ORIGINAL_TEXT>This is the fourth version of our review.</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="4700" end_char="4703">This</TOKEN>
<TOKEN id="token-48-1" pos="word" morph="none" start_char="4705" end_char="4706">is</TOKEN>
<TOKEN id="token-48-2" pos="word" morph="none" start_char="4708" end_char="4710">the</TOKEN>
<TOKEN id="token-48-3" pos="word" morph="none" start_char="4712" end_char="4717">fourth</TOKEN>
<TOKEN id="token-48-4" pos="word" morph="none" start_char="4719" end_char="4725">version</TOKEN>
<TOKEN id="token-48-5" pos="word" morph="none" start_char="4727" end_char="4728">of</TOKEN>
<TOKEN id="token-48-6" pos="word" morph="none" start_char="4730" end_char="4732">our</TOKEN>
<TOKEN id="token-48-7" pos="word" morph="none" start_char="4734" end_char="4739">review</TOKEN>
<TOKEN id="token-48-8" pos="punct" morph="none" start_char="4740" end_char="4740">.</TOKEN>
</SEG>
<SEG id="segment-49" start_char="4742" end_char="4785">
<ORIGINAL_TEXT>The evidence is up to date to 17 March 2021.</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="4742" end_char="4744">The</TOKEN>
<TOKEN id="token-49-1" pos="word" morph="none" start_char="4746" end_char="4753">evidence</TOKEN>
<TOKEN id="token-49-2" pos="word" morph="none" start_char="4755" end_char="4756">is</TOKEN>
<TOKEN id="token-49-3" pos="word" morph="none" start_char="4758" end_char="4759">up</TOKEN>
<TOKEN id="token-49-4" pos="word" morph="none" start_char="4761" end_char="4762">to</TOKEN>
<TOKEN id="token-49-5" pos="word" morph="none" start_char="4764" end_char="4767">date</TOKEN>
<TOKEN id="token-49-6" pos="word" morph="none" start_char="4769" end_char="4770">to</TOKEN>
<TOKEN id="token-49-7" pos="word" morph="none" start_char="4772" end_char="4773">17</TOKEN>
<TOKEN id="token-49-8" pos="word" morph="none" start_char="4775" end_char="4779">March</TOKEN>
<TOKEN id="token-49-9" pos="word" morph="none" start_char="4781" end_char="4784">2021</TOKEN>
<TOKEN id="token-49-10" pos="punct" morph="none" start_char="4785" end_char="4785">.</TOKEN>
</SEG>
<SEG id="segment-50" start_char="4788" end_char="5006">
<ORIGINAL_TEXT>We have high certainty in the evidence that convalescent plasma for the treatment of individuals with moderate to severe disease does not reduce mortality and has little to no impact on measures of clinical improvement.</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="4788" end_char="4789">We</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="4791" end_char="4794">have</TOKEN>
<TOKEN id="token-50-2" pos="word" morph="none" start_char="4796" end_char="4799">high</TOKEN>
<TOKEN id="token-50-3" pos="word" morph="none" start_char="4801" end_char="4809">certainty</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="4811" end_char="4812">in</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="4814" end_char="4816">the</TOKEN>
<TOKEN id="token-50-6" pos="word" morph="none" start_char="4818" end_char="4825">evidence</TOKEN>
<TOKEN id="token-50-7" pos="word" morph="none" start_char="4827" end_char="4830">that</TOKEN>
<TOKEN id="token-50-8" pos="word" morph="none" start_char="4832" end_char="4843">convalescent</TOKEN>
<TOKEN id="token-50-9" pos="word" morph="none" start_char="4845" end_char="4850">plasma</TOKEN>
<TOKEN id="token-50-10" pos="word" morph="none" start_char="4852" end_char="4854">for</TOKEN>
<TOKEN id="token-50-11" pos="word" morph="none" start_char="4856" end_char="4858">the</TOKEN>
<TOKEN id="token-50-12" pos="word" morph="none" start_char="4860" end_char="4868">treatment</TOKEN>
<TOKEN id="token-50-13" pos="word" morph="none" start_char="4870" end_char="4871">of</TOKEN>
<TOKEN id="token-50-14" pos="word" morph="none" start_char="4873" end_char="4883">individuals</TOKEN>
<TOKEN id="token-50-15" pos="word" morph="none" start_char="4885" end_char="4888">with</TOKEN>
<TOKEN id="token-50-16" pos="word" morph="none" start_char="4890" end_char="4897">moderate</TOKEN>
<TOKEN id="token-50-17" pos="word" morph="none" start_char="4899" end_char="4900">to</TOKEN>
<TOKEN id="token-50-18" pos="word" morph="none" start_char="4902" end_char="4907">severe</TOKEN>
<TOKEN id="token-50-19" pos="word" morph="none" start_char="4909" end_char="4915">disease</TOKEN>
<TOKEN id="token-50-20" pos="word" morph="none" start_char="4917" end_char="4920">does</TOKEN>
<TOKEN id="token-50-21" pos="word" morph="none" start_char="4922" end_char="4924">not</TOKEN>
<TOKEN id="token-50-22" pos="word" morph="none" start_char="4926" end_char="4931">reduce</TOKEN>
<TOKEN id="token-50-23" pos="word" morph="none" start_char="4933" end_char="4941">mortality</TOKEN>
<TOKEN id="token-50-24" pos="word" morph="none" start_char="4943" end_char="4945">and</TOKEN>
<TOKEN id="token-50-25" pos="word" morph="none" start_char="4947" end_char="4949">has</TOKEN>
<TOKEN id="token-50-26" pos="word" morph="none" start_char="4951" end_char="4956">little</TOKEN>
<TOKEN id="token-50-27" pos="word" morph="none" start_char="4958" end_char="4959">to</TOKEN>
<TOKEN id="token-50-28" pos="word" morph="none" start_char="4961" end_char="4962">no</TOKEN>
<TOKEN id="token-50-29" pos="word" morph="none" start_char="4964" end_char="4969">impact</TOKEN>
<TOKEN id="token-50-30" pos="word" morph="none" start_char="4971" end_char="4972">on</TOKEN>
<TOKEN id="token-50-31" pos="word" morph="none" start_char="4974" end_char="4981">measures</TOKEN>
<TOKEN id="token-50-32" pos="word" morph="none" start_char="4983" end_char="4984">of</TOKEN>
<TOKEN id="token-50-33" pos="word" morph="none" start_char="4986" end_char="4993">clinical</TOKEN>
<TOKEN id="token-50-34" pos="word" morph="none" start_char="4995" end_char="5005">improvement</TOKEN>
<TOKEN id="token-50-35" pos="punct" morph="none" start_char="5006" end_char="5006">.</TOKEN>
</SEG>
<SEG id="segment-51" start_char="5008" end_char="5073">
<ORIGINAL_TEXT>We are uncertain about the adverse effects of convalescent plasma.</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="word" morph="none" start_char="5008" end_char="5009">We</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="5011" end_char="5013">are</TOKEN>
<TOKEN id="token-51-2" pos="word" morph="none" start_char="5015" end_char="5023">uncertain</TOKEN>
<TOKEN id="token-51-3" pos="word" morph="none" start_char="5025" end_char="5029">about</TOKEN>
<TOKEN id="token-51-4" pos="word" morph="none" start_char="5031" end_char="5033">the</TOKEN>
<TOKEN id="token-51-5" pos="word" morph="none" start_char="5035" end_char="5041">adverse</TOKEN>
<TOKEN id="token-51-6" pos="word" morph="none" start_char="5043" end_char="5049">effects</TOKEN>
<TOKEN id="token-51-7" pos="word" morph="none" start_char="5051" end_char="5052">of</TOKEN>
<TOKEN id="token-51-8" pos="word" morph="none" start_char="5054" end_char="5065">convalescent</TOKEN>
<TOKEN id="token-51-9" pos="word" morph="none" start_char="5067" end_char="5072">plasma</TOKEN>
<TOKEN id="token-51-10" pos="punct" morph="none" start_char="5073" end_char="5073">.</TOKEN>
</SEG>
<SEG id="segment-52" start_char="5075" end_char="5199">
<ORIGINAL_TEXT>While major efforts to conduct research on COVID-19 are being made, heterogeneous reporting of outcomes is still problematic.</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="5075" end_char="5079">While</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="5081" end_char="5085">major</TOKEN>
<TOKEN id="token-52-2" pos="word" morph="none" start_char="5087" end_char="5093">efforts</TOKEN>
<TOKEN id="token-52-3" pos="word" morph="none" start_char="5095" end_char="5096">to</TOKEN>
<TOKEN id="token-52-4" pos="word" morph="none" start_char="5098" end_char="5104">conduct</TOKEN>
<TOKEN id="token-52-5" pos="word" morph="none" start_char="5106" end_char="5113">research</TOKEN>
<TOKEN id="token-52-6" pos="word" morph="none" start_char="5115" end_char="5116">on</TOKEN>
<TOKEN id="token-52-7" pos="unknown" morph="none" start_char="5118" end_char="5125">COVID-19</TOKEN>
<TOKEN id="token-52-8" pos="word" morph="none" start_char="5127" end_char="5129">are</TOKEN>
<TOKEN id="token-52-9" pos="word" morph="none" start_char="5131" end_char="5135">being</TOKEN>
<TOKEN id="token-52-10" pos="word" morph="none" start_char="5137" end_char="5140">made</TOKEN>
<TOKEN id="token-52-11" pos="punct" morph="none" start_char="5141" end_char="5141">,</TOKEN>
<TOKEN id="token-52-12" pos="word" morph="none" start_char="5143" end_char="5155">heterogeneous</TOKEN>
<TOKEN id="token-52-13" pos="word" morph="none" start_char="5157" end_char="5165">reporting</TOKEN>
<TOKEN id="token-52-14" pos="word" morph="none" start_char="5167" end_char="5168">of</TOKEN>
<TOKEN id="token-52-15" pos="word" morph="none" start_char="5170" end_char="5177">outcomes</TOKEN>
<TOKEN id="token-52-16" pos="word" morph="none" start_char="5179" end_char="5180">is</TOKEN>
<TOKEN id="token-52-17" pos="word" morph="none" start_char="5182" end_char="5186">still</TOKEN>
<TOKEN id="token-52-18" pos="word" morph="none" start_char="5188" end_char="5198">problematic</TOKEN>
<TOKEN id="token-52-19" pos="punct" morph="none" start_char="5199" end_char="5199">.</TOKEN>
</SEG>
<SEG id="segment-53" start_char="5201" end_char="5308">
<ORIGINAL_TEXT>There are 100 ongoing studies and 33 studies reporting in a study registry as being completed or terminated.</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="word" morph="none" start_char="5201" end_char="5205">There</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="5207" end_char="5209">are</TOKEN>
<TOKEN id="token-53-2" pos="word" morph="none" start_char="5211" end_char="5213">100</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="5215" end_char="5221">ongoing</TOKEN>
<TOKEN id="token-53-4" pos="word" morph="none" start_char="5223" end_char="5229">studies</TOKEN>
<TOKEN id="token-53-5" pos="word" morph="none" start_char="5231" end_char="5233">and</TOKEN>
<TOKEN id="token-53-6" pos="word" morph="none" start_char="5235" end_char="5236">33</TOKEN>
<TOKEN id="token-53-7" pos="word" morph="none" start_char="5238" end_char="5244">studies</TOKEN>
<TOKEN id="token-53-8" pos="word" morph="none" start_char="5246" end_char="5254">reporting</TOKEN>
<TOKEN id="token-53-9" pos="word" morph="none" start_char="5256" end_char="5257">in</TOKEN>
<TOKEN id="token-53-10" pos="word" morph="none" start_char="5259" end_char="5259">a</TOKEN>
<TOKEN id="token-53-11" pos="word" morph="none" start_char="5261" end_char="5265">study</TOKEN>
<TOKEN id="token-53-12" pos="word" morph="none" start_char="5267" end_char="5274">registry</TOKEN>
<TOKEN id="token-53-13" pos="word" morph="none" start_char="5276" end_char="5277">as</TOKEN>
<TOKEN id="token-53-14" pos="word" morph="none" start_char="5279" end_char="5283">being</TOKEN>
<TOKEN id="token-53-15" pos="word" morph="none" start_char="5285" end_char="5293">completed</TOKEN>
<TOKEN id="token-53-16" pos="word" morph="none" start_char="5295" end_char="5296">or</TOKEN>
<TOKEN id="token-53-17" pos="word" morph="none" start_char="5298" end_char="5307">terminated</TOKEN>
<TOKEN id="token-53-18" pos="punct" morph="none" start_char="5308" end_char="5308">.</TOKEN>
</SEG>
<SEG id="segment-54" start_char="5310" end_char="5537">
<ORIGINAL_TEXT>Publication of ongoing studies might resolve some of the uncertainties around hyperimmune immunoglobulin therapy for people with any disease severity, and convalescent plasma therapy for people with asymptomatic or mild disease.</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="word" morph="none" start_char="5310" end_char="5320">Publication</TOKEN>
<TOKEN id="token-54-1" pos="word" morph="none" start_char="5322" end_char="5323">of</TOKEN>
<TOKEN id="token-54-2" pos="word" morph="none" start_char="5325" end_char="5331">ongoing</TOKEN>
<TOKEN id="token-54-3" pos="word" morph="none" start_char="5333" end_char="5339">studies</TOKEN>
<TOKEN id="token-54-4" pos="word" morph="none" start_char="5341" end_char="5345">might</TOKEN>
<TOKEN id="token-54-5" pos="word" morph="none" start_char="5347" end_char="5353">resolve</TOKEN>
<TOKEN id="token-54-6" pos="word" morph="none" start_char="5355" end_char="5358">some</TOKEN>
<TOKEN id="token-54-7" pos="word" morph="none" start_char="5360" end_char="5361">of</TOKEN>
<TOKEN id="token-54-8" pos="word" morph="none" start_char="5363" end_char="5365">the</TOKEN>
<TOKEN id="token-54-9" pos="word" morph="none" start_char="5367" end_char="5379">uncertainties</TOKEN>
<TOKEN id="token-54-10" pos="word" morph="none" start_char="5381" end_char="5386">around</TOKEN>
<TOKEN id="token-54-11" pos="word" morph="none" start_char="5388" end_char="5398">hyperimmune</TOKEN>
<TOKEN id="token-54-12" pos="word" morph="none" start_char="5400" end_char="5413">immunoglobulin</TOKEN>
<TOKEN id="token-54-13" pos="word" morph="none" start_char="5415" end_char="5421">therapy</TOKEN>
<TOKEN id="token-54-14" pos="word" morph="none" start_char="5423" end_char="5425">for</TOKEN>
<TOKEN id="token-54-15" pos="word" morph="none" start_char="5427" end_char="5432">people</TOKEN>
<TOKEN id="token-54-16" pos="word" morph="none" start_char="5434" end_char="5437">with</TOKEN>
<TOKEN id="token-54-17" pos="word" morph="none" start_char="5439" end_char="5441">any</TOKEN>
<TOKEN id="token-54-18" pos="word" morph="none" start_char="5443" end_char="5449">disease</TOKEN>
<TOKEN id="token-54-19" pos="word" morph="none" start_char="5451" end_char="5458">severity</TOKEN>
<TOKEN id="token-54-20" pos="punct" morph="none" start_char="5459" end_char="5459">,</TOKEN>
<TOKEN id="token-54-21" pos="word" morph="none" start_char="5461" end_char="5463">and</TOKEN>
<TOKEN id="token-54-22" pos="word" morph="none" start_char="5465" end_char="5476">convalescent</TOKEN>
<TOKEN id="token-54-23" pos="word" morph="none" start_char="5478" end_char="5483">plasma</TOKEN>
<TOKEN id="token-54-24" pos="word" morph="none" start_char="5485" end_char="5491">therapy</TOKEN>
<TOKEN id="token-54-25" pos="word" morph="none" start_char="5493" end_char="5495">for</TOKEN>
<TOKEN id="token-54-26" pos="word" morph="none" start_char="5497" end_char="5502">people</TOKEN>
<TOKEN id="token-54-27" pos="word" morph="none" start_char="5504" end_char="5507">with</TOKEN>
<TOKEN id="token-54-28" pos="word" morph="none" start_char="5509" end_char="5520">asymptomatic</TOKEN>
<TOKEN id="token-54-29" pos="word" morph="none" start_char="5522" end_char="5523">or</TOKEN>
<TOKEN id="token-54-30" pos="word" morph="none" start_char="5525" end_char="5528">mild</TOKEN>
<TOKEN id="token-54-31" pos="word" morph="none" start_char="5530" end_char="5536">disease</TOKEN>
<TOKEN id="token-54-32" pos="punct" morph="none" start_char="5537" end_char="5537">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
