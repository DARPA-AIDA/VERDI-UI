<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATF0" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="2547" raw_text_md5="cd7ca88208edecec75aa1bf338d12b48">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="104">
<ORIGINAL_TEXT>Fern Britton questions if Covid is a ‘conspiracy to control population’ as she admits she’s ‘not coping’</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="4">Fern</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="6" end_char="12">Britton</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="14" end_char="22">questions</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="24" end_char="25">if</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="27" end_char="31">Covid</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="33" end_char="34">is</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="36" end_char="36">a</TOKEN>
<TOKEN id="token-0-7" pos="punct" morph="none" start_char="38" end_char="38">‘</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="39" end_char="48">conspiracy</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="50" end_char="51">to</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="53" end_char="59">control</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="61" end_char="70">population</TOKEN>
<TOKEN id="token-0-12" pos="punct" morph="none" start_char="71" end_char="71">’</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="73" end_char="74">as</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="76" end_char="78">she</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="80" end_char="85">admits</TOKEN>
<TOKEN id="token-0-16" pos="word" morph="none" start_char="87" end_char="91">she’s</TOKEN>
<TOKEN id="token-0-17" pos="punct" morph="none" start_char="93" end_char="93">‘</TOKEN>
<TOKEN id="token-0-18" pos="word" morph="none" start_char="94" end_char="96">not</TOKEN>
<TOKEN id="token-0-19" pos="word" morph="none" start_char="98" end_char="103">coping</TOKEN>
<TOKEN id="token-0-20" pos="punct" morph="none" start_char="104" end_char="104">’</TOKEN>
</SEG>
<SEG id="segment-1" start_char="108" end_char="216">
<ORIGINAL_TEXT>FERN Britton questions if Covid is a "conspiracy to control the population" as she admits she’s "not coping".</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="108" end_char="111">FERN</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="113" end_char="119">Britton</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="121" end_char="129">questions</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="131" end_char="132">if</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="134" end_char="138">Covid</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="140" end_char="141">is</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="143" end_char="143">a</TOKEN>
<TOKEN id="token-1-7" pos="punct" morph="none" start_char="145" end_char="145">"</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="146" end_char="155">conspiracy</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="157" end_char="158">to</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="160" end_char="166">control</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="168" end_char="170">the</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="172" end_char="181">population</TOKEN>
<TOKEN id="token-1-13" pos="punct" morph="none" start_char="182" end_char="182">"</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="184" end_char="185">as</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="187" end_char="189">she</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="191" end_char="196">admits</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="198" end_char="202">she’s</TOKEN>
<TOKEN id="token-1-18" pos="punct" morph="none" start_char="204" end_char="204">"</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="205" end_char="207">not</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="209" end_char="214">coping</TOKEN>
<TOKEN id="token-1-21" pos="punct" morph="none" start_char="215" end_char="216">".</TOKEN>
</SEG>
<SEG id="segment-2" start_char="219" end_char="361">
<ORIGINAL_TEXT>The presenter, 64, she believes "Covid is a real and dangerous virus" as she opened up a discussion on conspiracy theories around the pandemic.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="219" end_char="221">The</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="223" end_char="231">presenter</TOKEN>
<TOKEN id="token-2-2" pos="punct" morph="none" start_char="232" end_char="232">,</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="234" end_char="235">64</TOKEN>
<TOKEN id="token-2-4" pos="punct" morph="none" start_char="236" end_char="236">,</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="238" end_char="240">she</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="242" end_char="249">believes</TOKEN>
<TOKEN id="token-2-7" pos="punct" morph="none" start_char="251" end_char="251">"</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="252" end_char="256">Covid</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="258" end_char="259">is</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="261" end_char="261">a</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="263" end_char="266">real</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="268" end_char="270">and</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="272" end_char="280">dangerous</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="282" end_char="286">virus</TOKEN>
<TOKEN id="token-2-15" pos="punct" morph="none" start_char="287" end_char="287">"</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="289" end_char="290">as</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="292" end_char="294">she</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="296" end_char="301">opened</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="303" end_char="304">up</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="306" end_char="306">a</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="308" end_char="317">discussion</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="319" end_char="320">on</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="322" end_char="331">conspiracy</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="333" end_char="340">theories</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="342" end_char="347">around</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="349" end_char="351">the</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="353" end_char="360">pandemic</TOKEN>
<TOKEN id="token-2-28" pos="punct" morph="none" start_char="361" end_char="361">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="364" end_char="364">
<ORIGINAL_TEXT>5</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="364" end_char="364">5</TOKEN>
</SEG>
<SEG id="segment-4" start_char="367" end_char="429">
<ORIGINAL_TEXT>Fern Britton said she’s "not coping" while talking to followers</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="367" end_char="370">Fern</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="372" end_char="378">Britton</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="380" end_char="383">said</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="385" end_char="389">she’s</TOKEN>
<TOKEN id="token-4-4" pos="punct" morph="none" start_char="391" end_char="391">"</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="392" end_char="394">not</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="396" end_char="401">coping</TOKEN>
<TOKEN id="token-4-7" pos="punct" morph="none" start_char="402" end_char="402">"</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="404" end_char="408">while</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="410" end_char="416">talking</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="418" end_char="419">to</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="421" end_char="429">followers</TOKEN>
</SEG>
<SEG id="segment-5" start_char="433" end_char="600">
<ORIGINAL_TEXT>Speaking to her followers on Twitter, Fern said: "I believe Covid is a real and dangerous virus running amok amongst the worlds population and ruining the worlds [sic.]</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="433" end_char="440">Speaking</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="442" end_char="443">to</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="445" end_char="447">her</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="449" end_char="457">followers</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="459" end_char="460">on</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="462" end_char="468">Twitter</TOKEN>
<TOKEN id="token-5-6" pos="punct" morph="none" start_char="469" end_char="469">,</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="471" end_char="474">Fern</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="476" end_char="479">said</TOKEN>
<TOKEN id="token-5-9" pos="punct" morph="none" start_char="480" end_char="480">:</TOKEN>
<TOKEN id="token-5-10" pos="punct" morph="none" start_char="482" end_char="482">"</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="483" end_char="483">I</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="485" end_char="491">believe</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="493" end_char="497">Covid</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="499" end_char="500">is</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="502" end_char="502">a</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="504" end_char="507">real</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="509" end_char="511">and</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="513" end_char="521">dangerous</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="523" end_char="527">virus</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="529" end_char="535">running</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="537" end_char="540">amok</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="542" end_char="548">amongst</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="550" end_char="552">the</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="554" end_char="559">worlds</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="561" end_char="570">population</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="572" end_char="574">and</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="576" end_char="582">ruining</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="584" end_char="586">the</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="588" end_char="593">worlds</TOKEN>
<TOKEN id="token-5-30" pos="punct" morph="none" start_char="595" end_char="595">[</TOKEN>
<TOKEN id="token-5-31" pos="word" morph="none" start_char="596" end_char="598">sic</TOKEN>
<TOKEN id="token-5-32" pos="punct" morph="none" start_char="599" end_char="600">.]</TOKEN>
</SEG>
<SEG id="segment-6" start_char="602" end_char="609">
<ORIGINAL_TEXT>economy.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="602" end_char="608">economy</TOKEN>
<TOKEN id="token-6-1" pos="punct" morph="none" start_char="609" end_char="609">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="612" end_char="678">
<ORIGINAL_TEXT>"However, if this is all a con to control us, what is the end game?</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="punct" morph="none" start_char="612" end_char="612">"</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="613" end_char="619">However</TOKEN>
<TOKEN id="token-7-2" pos="punct" morph="none" start_char="620" end_char="620">,</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="622" end_char="623">if</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="625" end_char="628">this</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="630" end_char="631">is</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="633" end_char="635">all</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="637" end_char="637">a</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="639" end_char="641">con</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="643" end_char="644">to</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="646" end_char="652">control</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="654" end_char="655">us</TOKEN>
<TOKEN id="token-7-12" pos="punct" morph="none" start_char="656" end_char="656">,</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="658" end_char="661">what</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="663" end_char="664">is</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="666" end_char="668">the</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="670" end_char="672">end</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="674" end_char="677">game</TOKEN>
<TOKEN id="token-7-18" pos="punct" morph="none" start_char="678" end_char="678">?</TOKEN>
</SEG>
<SEG id="segment-8" start_char="680" end_char="710">
<ORIGINAL_TEXT>This is an authentic question."</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="680" end_char="683">This</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="685" end_char="686">is</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="688" end_char="689">an</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="691" end_char="699">authentic</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="701" end_char="708">question</TOKEN>
<TOKEN id="token-8-5" pos="punct" morph="none" start_char="709" end_char="710">."</TOKEN>
</SEG>
<SEG id="segment-9" start_char="713" end_char="792">
<ORIGINAL_TEXT>The former This Morning presenters fans mostly agreed there wasn’t a conspiracy.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="713" end_char="715">The</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="717" end_char="722">former</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="724" end_char="727">This</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="729" end_char="735">Morning</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="737" end_char="746">presenters</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="748" end_char="751">fans</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="753" end_char="758">mostly</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="760" end_char="765">agreed</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="767" end_char="771">there</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="773" end_char="778">wasn’t</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="780" end_char="780">a</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="782" end_char="791">conspiracy</TOKEN>
<TOKEN id="token-9-12" pos="punct" morph="none" start_char="792" end_char="792">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="795" end_char="882">
<ORIGINAL_TEXT>One person said: "There isn’t is there, this is a virus Microbe not a global conspiracy.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="795" end_char="797">One</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="799" end_char="804">person</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="806" end_char="809">said</TOKEN>
<TOKEN id="token-10-3" pos="punct" morph="none" start_char="810" end_char="810">:</TOKEN>
<TOKEN id="token-10-4" pos="punct" morph="none" start_char="812" end_char="812">"</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="813" end_char="817">There</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="819" end_char="823">isn’t</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="825" end_char="826">is</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="828" end_char="832">there</TOKEN>
<TOKEN id="token-10-9" pos="punct" morph="none" start_char="833" end_char="833">,</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="835" end_char="838">this</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="840" end_char="841">is</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="843" end_char="843">a</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="845" end_char="849">virus</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="851" end_char="857">Microbe</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="859" end_char="861">not</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="863" end_char="863">a</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="865" end_char="870">global</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="872" end_char="881">conspiracy</TOKEN>
<TOKEN id="token-10-19" pos="punct" morph="none" start_char="882" end_char="882">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="884" end_char="1039">
<ORIGINAL_TEXT>We both know that and as painful as it is we have to keep chasing down anyone says otherwise, your question there is an intelligent way of doing it, thanks!</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="884" end_char="885">We</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="887" end_char="890">both</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="892" end_char="895">know</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="897" end_char="900">that</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="902" end_char="904">and</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="906" end_char="907">as</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="909" end_char="915">painful</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="917" end_char="918">as</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="920" end_char="921">it</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="923" end_char="924">is</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="926" end_char="927">we</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="929" end_char="932">have</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="934" end_char="935">to</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="937" end_char="940">keep</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="942" end_char="948">chasing</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="950" end_char="953">down</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="955" end_char="960">anyone</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="962" end_char="965">says</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="967" end_char="975">otherwise</TOKEN>
<TOKEN id="token-11-19" pos="punct" morph="none" start_char="976" end_char="976">,</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="978" end_char="981">your</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="983" end_char="990">question</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="992" end_char="996">there</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="998" end_char="999">is</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="1001" end_char="1002">an</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="1004" end_char="1014">intelligent</TOKEN>
<TOKEN id="token-11-26" pos="word" morph="none" start_char="1016" end_char="1018">way</TOKEN>
<TOKEN id="token-11-27" pos="word" morph="none" start_char="1020" end_char="1021">of</TOKEN>
<TOKEN id="token-11-28" pos="word" morph="none" start_char="1023" end_char="1027">doing</TOKEN>
<TOKEN id="token-11-29" pos="word" morph="none" start_char="1029" end_char="1030">it</TOKEN>
<TOKEN id="token-11-30" pos="punct" morph="none" start_char="1031" end_char="1031">,</TOKEN>
<TOKEN id="token-11-31" pos="word" morph="none" start_char="1033" end_char="1038">thanks</TOKEN>
<TOKEN id="token-11-32" pos="punct" morph="none" start_char="1039" end_char="1039">!</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1041" end_char="1119">
<ORIGINAL_TEXT>(Shamelessly steals idea Smiling face with open mouth and tightly-closed eyes)"</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="punct" morph="none" start_char="1041" end_char="1041">(</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1042" end_char="1052">Shamelessly</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1054" end_char="1059">steals</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1061" end_char="1064">idea</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1066" end_char="1072">Smiling</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1074" end_char="1077">face</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1079" end_char="1082">with</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1084" end_char="1087">open</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1089" end_char="1093">mouth</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1095" end_char="1097">and</TOKEN>
<TOKEN id="token-12-10" pos="unknown" morph="none" start_char="1099" end_char="1112">tightly-closed</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1114" end_char="1117">eyes</TOKEN>
<TOKEN id="token-12-12" pos="punct" morph="none" start_char="1118" end_char="1119">)"</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1122" end_char="1130">
<ORIGINAL_TEXT>Twitter 5</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1122" end_char="1128">Twitter</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1130" end_char="1130">5</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1133" end_char="1181">
<ORIGINAL_TEXT>The star questioned the Covid conspiracy theories</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1133" end_char="1135">The</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1137" end_char="1140">star</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1142" end_char="1151">questioned</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1153" end_char="1155">the</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1157" end_char="1161">Covid</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1163" end_char="1172">conspiracy</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1174" end_char="1181">theories</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1185" end_char="1185">
<ORIGINAL_TEXT>5</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1185" end_char="1185">5</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1188" end_char="1242">
<ORIGINAL_TEXT>Fern shares the sentiment with Brits across the country</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1188" end_char="1191">Fern</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1193" end_char="1198">shares</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1200" end_char="1202">the</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1204" end_char="1212">sentiment</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1214" end_char="1217">with</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1219" end_char="1223">Brits</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1225" end_char="1230">across</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1232" end_char="1234">the</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1236" end_char="1242">country</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1246" end_char="1296">
<ORIGINAL_TEXT>Another added: "This is exactly what I keep saying!</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1246" end_char="1252">Another</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1254" end_char="1258">added</TOKEN>
<TOKEN id="token-17-2" pos="punct" morph="none" start_char="1259" end_char="1259">:</TOKEN>
<TOKEN id="token-17-3" pos="punct" morph="none" start_char="1261" end_char="1261">"</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="1262" end_char="1265">This</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="1267" end_char="1268">is</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="1270" end_char="1276">exactly</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="1278" end_char="1281">what</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="1283" end_char="1283">I</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="1285" end_char="1288">keep</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="1290" end_char="1295">saying</TOKEN>
<TOKEN id="token-17-11" pos="punct" morph="none" start_char="1296" end_char="1296">!</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1298" end_char="1401">
<ORIGINAL_TEXT>What is the benefit to the whole world pretending there’s a virus, people losing their livelihoods, etc.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="1298" end_char="1301">What</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="1303" end_char="1304">is</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="1306" end_char="1308">the</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="1310" end_char="1316">benefit</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="1318" end_char="1319">to</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="1321" end_char="1323">the</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="1325" end_char="1329">whole</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="1331" end_char="1335">world</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="1337" end_char="1346">pretending</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="1348" end_char="1354">there’s</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="1356" end_char="1356">a</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="1358" end_char="1362">virus</TOKEN>
<TOKEN id="token-18-12" pos="punct" morph="none" start_char="1363" end_char="1363">,</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="1365" end_char="1370">people</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="1372" end_char="1377">losing</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="1379" end_char="1383">their</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="1385" end_char="1395">livelihoods</TOKEN>
<TOKEN id="token-18-17" pos="punct" morph="none" start_char="1396" end_char="1396">,</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="1398" end_char="1400">etc</TOKEN>
<TOKEN id="token-18-19" pos="punct" morph="none" start_char="1401" end_char="1401">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="1403" end_char="1446">
<ORIGINAL_TEXT>Funny they can never answer that when I ask.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="1403" end_char="1407">Funny</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="1409" end_char="1412">they</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="1414" end_char="1416">can</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="1418" end_char="1422">never</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="1424" end_char="1429">answer</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="1431" end_char="1434">that</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="1436" end_char="1439">when</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="1441" end_char="1441">I</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="1443" end_char="1445">ask</TOKEN>
<TOKEN id="token-19-9" pos="punct" morph="none" start_char="1446" end_char="1446">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="1448" end_char="1468">
<ORIGINAL_TEXT>Its totally bonkers!"</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="1448" end_char="1450">Its</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="1452" end_char="1458">totally</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="1460" end_char="1466">bonkers</TOKEN>
<TOKEN id="token-20-3" pos="punct" morph="none" start_char="1467" end_char="1468">!"</TOKEN>
</SEG>
<SEG id="segment-21" start_char="1471" end_char="1519">
<ORIGINAL_TEXT>However, one person said: "Oh god don’t say that.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="1471" end_char="1477">However</TOKEN>
<TOKEN id="token-21-1" pos="punct" morph="none" start_char="1478" end_char="1478">,</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="1480" end_char="1482">one</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="1484" end_char="1489">person</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="1491" end_char="1494">said</TOKEN>
<TOKEN id="token-21-5" pos="punct" morph="none" start_char="1495" end_char="1495">:</TOKEN>
<TOKEN id="token-21-6" pos="punct" morph="none" start_char="1497" end_char="1497">"</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="1498" end_char="1499">Oh</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="1501" end_char="1503">god</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="1505" end_char="1509">don’t</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="1511" end_char="1513">say</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="1515" end_char="1518">that</TOKEN>
<TOKEN id="token-21-12" pos="punct" morph="none" start_char="1519" end_char="1519">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="1521" end_char="1545">
<ORIGINAL_TEXT>I’m not coping as it is."</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="1521" end_char="1523">I’m</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="1525" end_char="1527">not</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="1529" end_char="1534">coping</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="1536" end_char="1537">as</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="1539" end_char="1540">it</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="1542" end_char="1543">is</TOKEN>
<TOKEN id="token-22-6" pos="punct" morph="none" start_char="1544" end_char="1545">."</TOKEN>
</SEG>
<SEG id="segment-23" start_char="1548" end_char="1580">
<ORIGINAL_TEXT>To which Fern replied: "Oh Grant.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="1548" end_char="1549">To</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="1551" end_char="1555">which</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="1557" end_char="1560">Fern</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="1562" end_char="1568">replied</TOKEN>
<TOKEN id="token-23-4" pos="punct" morph="none" start_char="1569" end_char="1569">:</TOKEN>
<TOKEN id="token-23-5" pos="punct" morph="none" start_char="1571" end_char="1571">"</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="1572" end_char="1573">Oh</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="1575" end_char="1579">Grant</TOKEN>
<TOKEN id="token-23-8" pos="punct" morph="none" start_char="1580" end_char="1580">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="1582" end_char="1594">
<ORIGINAL_TEXT>Me neither x"</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="1582" end_char="1583">Me</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="1585" end_char="1591">neither</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="1593" end_char="1593">x</TOKEN>
<TOKEN id="token-24-3" pos="punct" morph="none" start_char="1594" end_char="1594">"</TOKEN>
</SEG>
<SEG id="segment-25" start_char="1597" end_char="1720">
<ORIGINAL_TEXT>The best-selling author has been living in Cornwall since she split with her husband Phil Vickery in January after 20 years.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="1597" end_char="1599">The</TOKEN>
<TOKEN id="token-25-1" pos="unknown" morph="none" start_char="1601" end_char="1612">best-selling</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="1614" end_char="1619">author</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="1621" end_char="1623">has</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="1625" end_char="1628">been</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="1630" end_char="1635">living</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="1637" end_char="1638">in</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="1640" end_char="1647">Cornwall</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="1649" end_char="1653">since</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="1655" end_char="1657">she</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="1659" end_char="1663">split</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="1665" end_char="1668">with</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="1670" end_char="1672">her</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="1674" end_char="1680">husband</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="1682" end_char="1685">Phil</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="1687" end_char="1693">Vickery</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="1695" end_char="1696">in</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="1698" end_char="1704">January</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="1706" end_char="1710">after</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="1712" end_char="1713">20</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="1715" end_char="1719">years</TOKEN>
<TOKEN id="token-25-21" pos="punct" morph="none" start_char="1720" end_char="1720">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="1723" end_char="1723">
<ORIGINAL_TEXT>5</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="1723" end_char="1723">5</TOKEN>
</SEG>
<SEG id="segment-27" start_char="1726" end_char="1763">
<ORIGINAL_TEXT>Fern split with Phil Vickery last year</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="1726" end_char="1729">Fern</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="1731" end_char="1735">split</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="1737" end_char="1740">with</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="1742" end_char="1745">Phil</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="1747" end_char="1753">Vickery</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="1755" end_char="1758">last</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="1760" end_char="1763">year</TOKEN>
</SEG>
<SEG id="segment-28" start_char="1767" end_char="1957">
<ORIGINAL_TEXT>The mum-of-four – who was previously married to TV exec Clive Jones – admitted in November that she misses the company of a man – but has decided she doesn’t want another partner in her life.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="1767" end_char="1769">The</TOKEN>
<TOKEN id="token-28-1" pos="unknown" morph="none" start_char="1771" end_char="1781">mum-of-four</TOKEN>
<TOKEN id="token-28-2" pos="punct" morph="none" start_char="1783" end_char="1783">–</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="1785" end_char="1787">who</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="1789" end_char="1791">was</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="1793" end_char="1802">previously</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="1804" end_char="1810">married</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="1812" end_char="1813">to</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="1815" end_char="1816">TV</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="1818" end_char="1821">exec</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="1823" end_char="1827">Clive</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="1829" end_char="1833">Jones</TOKEN>
<TOKEN id="token-28-12" pos="punct" morph="none" start_char="1835" end_char="1835">–</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="1837" end_char="1844">admitted</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="1846" end_char="1847">in</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="1849" end_char="1856">November</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="1858" end_char="1861">that</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="1863" end_char="1865">she</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="1867" end_char="1872">misses</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="1874" end_char="1876">the</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="1878" end_char="1884">company</TOKEN>
<TOKEN id="token-28-21" pos="word" morph="none" start_char="1886" end_char="1887">of</TOKEN>
<TOKEN id="token-28-22" pos="word" morph="none" start_char="1889" end_char="1889">a</TOKEN>
<TOKEN id="token-28-23" pos="word" morph="none" start_char="1891" end_char="1893">man</TOKEN>
<TOKEN id="token-28-24" pos="punct" morph="none" start_char="1895" end_char="1895">–</TOKEN>
<TOKEN id="token-28-25" pos="word" morph="none" start_char="1897" end_char="1899">but</TOKEN>
<TOKEN id="token-28-26" pos="word" morph="none" start_char="1901" end_char="1903">has</TOKEN>
<TOKEN id="token-28-27" pos="word" morph="none" start_char="1905" end_char="1911">decided</TOKEN>
<TOKEN id="token-28-28" pos="word" morph="none" start_char="1913" end_char="1915">she</TOKEN>
<TOKEN id="token-28-29" pos="word" morph="none" start_char="1917" end_char="1923">doesn’t</TOKEN>
<TOKEN id="token-28-30" pos="word" morph="none" start_char="1925" end_char="1928">want</TOKEN>
<TOKEN id="token-28-31" pos="word" morph="none" start_char="1930" end_char="1936">another</TOKEN>
<TOKEN id="token-28-32" pos="word" morph="none" start_char="1938" end_char="1944">partner</TOKEN>
<TOKEN id="token-28-33" pos="word" morph="none" start_char="1946" end_char="1947">in</TOKEN>
<TOKEN id="token-28-34" pos="word" morph="none" start_char="1949" end_char="1951">her</TOKEN>
<TOKEN id="token-28-35" pos="word" morph="none" start_char="1953" end_char="1956">life</TOKEN>
<TOKEN id="token-28-36" pos="punct" morph="none" start_char="1957" end_char="1957">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="1960" end_char="2205">
<ORIGINAL_TEXT>She told The Mirror: "That’s not to say I don’t miss being married, because I have been married to two incredible husbands for over 30 years, so I have been married for a very long time – two very interesting men who survived being married to me.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="1960" end_char="1962">She</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="1964" end_char="1967">told</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="1969" end_char="1971">The</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="1973" end_char="1978">Mirror</TOKEN>
<TOKEN id="token-29-4" pos="punct" morph="none" start_char="1979" end_char="1979">:</TOKEN>
<TOKEN id="token-29-5" pos="punct" morph="none" start_char="1981" end_char="1981">"</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="1982" end_char="1987">That’s</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="1989" end_char="1991">not</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="1993" end_char="1994">to</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="1996" end_char="1998">say</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="2000" end_char="2000">I</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="2002" end_char="2006">don’t</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="2008" end_char="2011">miss</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="2013" end_char="2017">being</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="2019" end_char="2025">married</TOKEN>
<TOKEN id="token-29-15" pos="punct" morph="none" start_char="2026" end_char="2026">,</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="2028" end_char="2034">because</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="2036" end_char="2036">I</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="2038" end_char="2041">have</TOKEN>
<TOKEN id="token-29-19" pos="word" morph="none" start_char="2043" end_char="2046">been</TOKEN>
<TOKEN id="token-29-20" pos="word" morph="none" start_char="2048" end_char="2054">married</TOKEN>
<TOKEN id="token-29-21" pos="word" morph="none" start_char="2056" end_char="2057">to</TOKEN>
<TOKEN id="token-29-22" pos="word" morph="none" start_char="2059" end_char="2061">two</TOKEN>
<TOKEN id="token-29-23" pos="word" morph="none" start_char="2063" end_char="2072">incredible</TOKEN>
<TOKEN id="token-29-24" pos="word" morph="none" start_char="2074" end_char="2081">husbands</TOKEN>
<TOKEN id="token-29-25" pos="word" morph="none" start_char="2083" end_char="2085">for</TOKEN>
<TOKEN id="token-29-26" pos="word" morph="none" start_char="2087" end_char="2090">over</TOKEN>
<TOKEN id="token-29-27" pos="word" morph="none" start_char="2092" end_char="2093">30</TOKEN>
<TOKEN id="token-29-28" pos="word" morph="none" start_char="2095" end_char="2099">years</TOKEN>
<TOKEN id="token-29-29" pos="punct" morph="none" start_char="2100" end_char="2100">,</TOKEN>
<TOKEN id="token-29-30" pos="word" morph="none" start_char="2102" end_char="2103">so</TOKEN>
<TOKEN id="token-29-31" pos="word" morph="none" start_char="2105" end_char="2105">I</TOKEN>
<TOKEN id="token-29-32" pos="word" morph="none" start_char="2107" end_char="2110">have</TOKEN>
<TOKEN id="token-29-33" pos="word" morph="none" start_char="2112" end_char="2115">been</TOKEN>
<TOKEN id="token-29-34" pos="word" morph="none" start_char="2117" end_char="2123">married</TOKEN>
<TOKEN id="token-29-35" pos="word" morph="none" start_char="2125" end_char="2127">for</TOKEN>
<TOKEN id="token-29-36" pos="word" morph="none" start_char="2129" end_char="2129">a</TOKEN>
<TOKEN id="token-29-37" pos="word" morph="none" start_char="2131" end_char="2134">very</TOKEN>
<TOKEN id="token-29-38" pos="word" morph="none" start_char="2136" end_char="2139">long</TOKEN>
<TOKEN id="token-29-39" pos="word" morph="none" start_char="2141" end_char="2144">time</TOKEN>
<TOKEN id="token-29-40" pos="punct" morph="none" start_char="2146" end_char="2146">–</TOKEN>
<TOKEN id="token-29-41" pos="word" morph="none" start_char="2148" end_char="2150">two</TOKEN>
<TOKEN id="token-29-42" pos="word" morph="none" start_char="2152" end_char="2155">very</TOKEN>
<TOKEN id="token-29-43" pos="word" morph="none" start_char="2157" end_char="2167">interesting</TOKEN>
<TOKEN id="token-29-44" pos="word" morph="none" start_char="2169" end_char="2171">men</TOKEN>
<TOKEN id="token-29-45" pos="word" morph="none" start_char="2173" end_char="2175">who</TOKEN>
<TOKEN id="token-29-46" pos="word" morph="none" start_char="2177" end_char="2184">survived</TOKEN>
<TOKEN id="token-29-47" pos="word" morph="none" start_char="2186" end_char="2190">being</TOKEN>
<TOKEN id="token-29-48" pos="word" morph="none" start_char="2192" end_char="2198">married</TOKEN>
<TOKEN id="token-29-49" pos="word" morph="none" start_char="2200" end_char="2201">to</TOKEN>
<TOKEN id="token-29-50" pos="word" morph="none" start_char="2203" end_char="2204">me</TOKEN>
<TOKEN id="token-29-51" pos="punct" morph="none" start_char="2205" end_char="2205">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="2208" end_char="2303">
<ORIGINAL_TEXT>"It is difficult and it is painful but let’s skip over that… I am not looking for anybody else."</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="punct" morph="none" start_char="2208" end_char="2208">"</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="2209" end_char="2210">It</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="2212" end_char="2213">is</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="2215" end_char="2223">difficult</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="2225" end_char="2227">and</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="2229" end_char="2230">it</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="2232" end_char="2233">is</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="2235" end_char="2241">painful</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="2243" end_char="2245">but</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="2247" end_char="2251">let’s</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="2253" end_char="2256">skip</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="2258" end_char="2261">over</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="2263" end_char="2266">that</TOKEN>
<TOKEN id="token-30-13" pos="punct" morph="none" start_char="2267" end_char="2267">…</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="2269" end_char="2269">I</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="2271" end_char="2272">am</TOKEN>
<TOKEN id="token-30-16" pos="word" morph="none" start_char="2274" end_char="2276">not</TOKEN>
<TOKEN id="token-30-17" pos="word" morph="none" start_char="2278" end_char="2284">looking</TOKEN>
<TOKEN id="token-30-18" pos="word" morph="none" start_char="2286" end_char="2288">for</TOKEN>
<TOKEN id="token-30-19" pos="word" morph="none" start_char="2290" end_char="2296">anybody</TOKEN>
<TOKEN id="token-30-20" pos="word" morph="none" start_char="2298" end_char="2301">else</TOKEN>
<TOKEN id="token-30-21" pos="punct" morph="none" start_char="2302" end_char="2303">."</TOKEN>
</SEG>
<SEG id="segment-31" start_char="2306" end_char="2441">
<ORIGINAL_TEXT>Ferne also admitted she enjoys having "autonomy" over her time and "what I want to do", adding that she plans to travel the world at 70.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="2306" end_char="2310">Ferne</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="2312" end_char="2315">also</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="2317" end_char="2324">admitted</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="2326" end_char="2328">she</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="2330" end_char="2335">enjoys</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="2337" end_char="2342">having</TOKEN>
<TOKEN id="token-31-6" pos="punct" morph="none" start_char="2344" end_char="2344">"</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="2345" end_char="2352">autonomy</TOKEN>
<TOKEN id="token-31-8" pos="punct" morph="none" start_char="2353" end_char="2353">"</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="2355" end_char="2358">over</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="2360" end_char="2362">her</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="2364" end_char="2367">time</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="2369" end_char="2371">and</TOKEN>
<TOKEN id="token-31-13" pos="punct" morph="none" start_char="2373" end_char="2373">"</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="2374" end_char="2377">what</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="2379" end_char="2379">I</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="2381" end_char="2384">want</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="2386" end_char="2387">to</TOKEN>
<TOKEN id="token-31-18" pos="word" morph="none" start_char="2389" end_char="2390">do</TOKEN>
<TOKEN id="token-31-19" pos="punct" morph="none" start_char="2391" end_char="2392">",</TOKEN>
<TOKEN id="token-31-20" pos="word" morph="none" start_char="2394" end_char="2399">adding</TOKEN>
<TOKEN id="token-31-21" pos="word" morph="none" start_char="2401" end_char="2404">that</TOKEN>
<TOKEN id="token-31-22" pos="word" morph="none" start_char="2406" end_char="2408">she</TOKEN>
<TOKEN id="token-31-23" pos="word" morph="none" start_char="2410" end_char="2414">plans</TOKEN>
<TOKEN id="token-31-24" pos="word" morph="none" start_char="2416" end_char="2417">to</TOKEN>
<TOKEN id="token-31-25" pos="word" morph="none" start_char="2419" end_char="2424">travel</TOKEN>
<TOKEN id="token-31-26" pos="word" morph="none" start_char="2426" end_char="2428">the</TOKEN>
<TOKEN id="token-31-27" pos="word" morph="none" start_char="2430" end_char="2434">world</TOKEN>
<TOKEN id="token-31-28" pos="word" morph="none" start_char="2436" end_char="2437">at</TOKEN>
<TOKEN id="token-31-29" pos="word" morph="none" start_char="2439" end_char="2440">70</TOKEN>
<TOKEN id="token-31-30" pos="punct" morph="none" start_char="2441" end_char="2441">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="2444" end_char="2543">
<ORIGINAL_TEXT>Meanwhile, Phil has exchanged a string of messages with Yorkshire Dales sheep farmer Alison O’Neill.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="2444" end_char="2452">Meanwhile</TOKEN>
<TOKEN id="token-32-1" pos="punct" morph="none" start_char="2453" end_char="2453">,</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="2455" end_char="2458">Phil</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="2460" end_char="2462">has</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="2464" end_char="2472">exchanged</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="2474" end_char="2474">a</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="2476" end_char="2481">string</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="2483" end_char="2484">of</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="2486" end_char="2493">messages</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="2495" end_char="2498">with</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="2500" end_char="2508">Yorkshire</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="2510" end_char="2514">Dales</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="2516" end_char="2520">sheep</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="2522" end_char="2527">farmer</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="2529" end_char="2534">Alison</TOKEN>
<TOKEN id="token-32-15" pos="word" morph="none" start_char="2536" end_char="2542">O’Neill</TOKEN>
<TOKEN id="token-32-16" pos="punct" morph="none" start_char="2543" end_char="2543">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
