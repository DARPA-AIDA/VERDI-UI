<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATIK" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="3889" raw_text_md5="b4edb4303aac6792e028f89df6c8334d">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="90">
<ORIGINAL_TEXT>EXCLUSIVA: Un estudio sugiere que el dengue podría dar cierta inmunidad contra la COVID-19</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="9">EXCLUSIVA</TOKEN>
<TOKEN id="token-0-1" pos="punct" morph="none" start_char="10" end_char="10">:</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="12" end_char="13">Un</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="15" end_char="21">estudio</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="23" end_char="29">sugiere</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="31" end_char="33">que</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="35" end_char="36">el</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="38" end_char="43">dengue</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="45" end_char="50">podría</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="52" end_char="54">dar</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="56" end_char="61">cierta</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="63" end_char="71">inmunidad</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="73" end_char="78">contra</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="80" end_char="81">la</TOKEN>
<TOKEN id="token-0-14" pos="unknown" morph="none" start_char="83" end_char="90">COVID-19</TOKEN>
</SEG>
<SEG id="segment-1" start_char="94" end_char="429">
<ORIGINAL_TEXT>RIO DE JANEIRO, 21 sep (Reuters) - Un nuevo estudio que analizó el brote de coronavirus en Brasil ha encontrado un vínculo entre la propagación del virus y los brotes anteriores de dengue, el cual sugiere que la exposición a la enfermedad transmitida por los mosquitos puede proporcionar un cierto nivel de inmunidad contra la COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="94" end_char="96">RIO</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="98" end_char="99">DE</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="101" end_char="107">JANEIRO</TOKEN>
<TOKEN id="token-1-3" pos="punct" morph="none" start_char="108" end_char="108">,</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="110" end_char="111">21</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="113" end_char="115">sep</TOKEN>
<TOKEN id="token-1-6" pos="punct" morph="none" start_char="117" end_char="117">(</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="118" end_char="124">Reuters</TOKEN>
<TOKEN id="token-1-8" pos="punct" morph="none" start_char="125" end_char="125">)</TOKEN>
<TOKEN id="token-1-9" pos="punct" morph="none" start_char="127" end_char="127">-</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="129" end_char="130">Un</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="132" end_char="136">nuevo</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="138" end_char="144">estudio</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="146" end_char="148">que</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="150" end_char="156">analizó</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="158" end_char="159">el</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="161" end_char="165">brote</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="167" end_char="168">de</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="170" end_char="180">coronavirus</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="182" end_char="183">en</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="185" end_char="190">Brasil</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="192" end_char="193">ha</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="195" end_char="204">encontrado</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="206" end_char="207">un</TOKEN>
<TOKEN id="token-1-24" pos="word" morph="none" start_char="209" end_char="215">vínculo</TOKEN>
<TOKEN id="token-1-25" pos="word" morph="none" start_char="217" end_char="221">entre</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="223" end_char="224">la</TOKEN>
<TOKEN id="token-1-27" pos="word" morph="none" start_char="226" end_char="236">propagación</TOKEN>
<TOKEN id="token-1-28" pos="word" morph="none" start_char="238" end_char="240">del</TOKEN>
<TOKEN id="token-1-29" pos="word" morph="none" start_char="242" end_char="246">virus</TOKEN>
<TOKEN id="token-1-30" pos="word" morph="none" start_char="248" end_char="248">y</TOKEN>
<TOKEN id="token-1-31" pos="word" morph="none" start_char="250" end_char="252">los</TOKEN>
<TOKEN id="token-1-32" pos="word" morph="none" start_char="254" end_char="259">brotes</TOKEN>
<TOKEN id="token-1-33" pos="word" morph="none" start_char="261" end_char="270">anteriores</TOKEN>
<TOKEN id="token-1-34" pos="word" morph="none" start_char="272" end_char="273">de</TOKEN>
<TOKEN id="token-1-35" pos="word" morph="none" start_char="275" end_char="280">dengue</TOKEN>
<TOKEN id="token-1-36" pos="punct" morph="none" start_char="281" end_char="281">,</TOKEN>
<TOKEN id="token-1-37" pos="word" morph="none" start_char="283" end_char="284">el</TOKEN>
<TOKEN id="token-1-38" pos="word" morph="none" start_char="286" end_char="289">cual</TOKEN>
<TOKEN id="token-1-39" pos="word" morph="none" start_char="291" end_char="297">sugiere</TOKEN>
<TOKEN id="token-1-40" pos="word" morph="none" start_char="299" end_char="301">que</TOKEN>
<TOKEN id="token-1-41" pos="word" morph="none" start_char="303" end_char="304">la</TOKEN>
<TOKEN id="token-1-42" pos="word" morph="none" start_char="306" end_char="315">exposición</TOKEN>
<TOKEN id="token-1-43" pos="word" morph="none" start_char="317" end_char="317">a</TOKEN>
<TOKEN id="token-1-44" pos="word" morph="none" start_char="319" end_char="320">la</TOKEN>
<TOKEN id="token-1-45" pos="word" morph="none" start_char="322" end_char="331">enfermedad</TOKEN>
<TOKEN id="token-1-46" pos="word" morph="none" start_char="333" end_char="343">transmitida</TOKEN>
<TOKEN id="token-1-47" pos="word" morph="none" start_char="345" end_char="347">por</TOKEN>
<TOKEN id="token-1-48" pos="word" morph="none" start_char="349" end_char="351">los</TOKEN>
<TOKEN id="token-1-49" pos="word" morph="none" start_char="353" end_char="361">mosquitos</TOKEN>
<TOKEN id="token-1-50" pos="word" morph="none" start_char="363" end_char="367">puede</TOKEN>
<TOKEN id="token-1-51" pos="word" morph="none" start_char="369" end_char="380">proporcionar</TOKEN>
<TOKEN id="token-1-52" pos="word" morph="none" start_char="382" end_char="383">un</TOKEN>
<TOKEN id="token-1-53" pos="word" morph="none" start_char="385" end_char="390">cierto</TOKEN>
<TOKEN id="token-1-54" pos="word" morph="none" start_char="392" end_char="396">nivel</TOKEN>
<TOKEN id="token-1-55" pos="word" morph="none" start_char="398" end_char="399">de</TOKEN>
<TOKEN id="token-1-56" pos="word" morph="none" start_char="401" end_char="409">inmunidad</TOKEN>
<TOKEN id="token-1-57" pos="word" morph="none" start_char="411" end_char="416">contra</TOKEN>
<TOKEN id="token-1-58" pos="word" morph="none" start_char="418" end_char="419">la</TOKEN>
<TOKEN id="token-1-59" pos="unknown" morph="none" start_char="421" end_char="428">COVID-19</TOKEN>
<TOKEN id="token-1-60" pos="punct" morph="none" start_char="429" end_char="429">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="432" end_char="567">
<ORIGINAL_TEXT>FOTO DE ARCHIVO: Un hombre con mascarilla camina junto a una ilustración del coronavirus de un centro científico en Oldham, Reino Unido.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="432" end_char="435">FOTO</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="437" end_char="438">DE</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="440" end_char="446">ARCHIVO</TOKEN>
<TOKEN id="token-2-3" pos="punct" morph="none" start_char="447" end_char="447">:</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="449" end_char="450">Un</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="452" end_char="457">hombre</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="459" end_char="461">con</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="463" end_char="472">mascarilla</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="474" end_char="479">camina</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="481" end_char="485">junto</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="487" end_char="487">a</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="489" end_char="491">una</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="493" end_char="503">ilustración</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="505" end_char="507">del</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="509" end_char="519">coronavirus</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="521" end_char="522">de</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="524" end_char="525">un</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="527" end_char="532">centro</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="534" end_char="543">científico</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="545" end_char="546">en</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="548" end_char="553">Oldham</TOKEN>
<TOKEN id="token-2-21" pos="punct" morph="none" start_char="554" end_char="554">,</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="556" end_char="560">Reino</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="562" end_char="566">Unido</TOKEN>
<TOKEN id="token-2-24" pos="punct" morph="none" start_char="567" end_char="567">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="569" end_char="588">
<ORIGINAL_TEXT>3 de agosto de 2020.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="569" end_char="569">3</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="571" end_char="572">de</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="574" end_char="579">agosto</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="581" end_char="582">de</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="584" end_char="587">2020</TOKEN>
<TOKEN id="token-3-5" pos="punct" morph="none" start_char="588" end_char="588">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="590" end_char="607">
<ORIGINAL_TEXT>REUTERS/Phil Noble</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="unknown" morph="none" start_char="590" end_char="601">REUTERS/Phil</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="603" end_char="607">Noble</TOKEN>
</SEG>
<SEG id="segment-5" start_char="611" end_char="885">
<ORIGINAL_TEXT>El estudio dirigido por Miguel Nicolelis, profesor de la Universidad de Duke, que todavía no ha sido publicado y que ha sido compartido exclusivamente con Reuters, comparó la distribución geográfica de los casos de coronavirus con la propagación del dengue entre 2019 y 2020.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="611" end_char="612">El</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="614" end_char="620">estudio</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="622" end_char="629">dirigido</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="631" end_char="633">por</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="635" end_char="640">Miguel</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="642" end_char="650">Nicolelis</TOKEN>
<TOKEN id="token-5-6" pos="punct" morph="none" start_char="651" end_char="651">,</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="653" end_char="660">profesor</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="662" end_char="663">de</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="665" end_char="666">la</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="668" end_char="678">Universidad</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="680" end_char="681">de</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="683" end_char="686">Duke</TOKEN>
<TOKEN id="token-5-13" pos="punct" morph="none" start_char="687" end_char="687">,</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="689" end_char="691">que</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="693" end_char="699">todavía</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="701" end_char="702">no</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="704" end_char="705">ha</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="707" end_char="710">sido</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="712" end_char="720">publicado</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="722" end_char="722">y</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="724" end_char="726">que</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="728" end_char="729">ha</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="731" end_char="734">sido</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="736" end_char="745">compartido</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="747" end_char="760">exclusivamente</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="762" end_char="764">con</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="766" end_char="772">Reuters</TOKEN>
<TOKEN id="token-5-28" pos="punct" morph="none" start_char="773" end_char="773">,</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="775" end_char="781">comparó</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="783" end_char="784">la</TOKEN>
<TOKEN id="token-5-31" pos="word" morph="none" start_char="786" end_char="797">distribución</TOKEN>
<TOKEN id="token-5-32" pos="word" morph="none" start_char="799" end_char="808">geográfica</TOKEN>
<TOKEN id="token-5-33" pos="word" morph="none" start_char="810" end_char="811">de</TOKEN>
<TOKEN id="token-5-34" pos="word" morph="none" start_char="813" end_char="815">los</TOKEN>
<TOKEN id="token-5-35" pos="word" morph="none" start_char="817" end_char="821">casos</TOKEN>
<TOKEN id="token-5-36" pos="word" morph="none" start_char="823" end_char="824">de</TOKEN>
<TOKEN id="token-5-37" pos="word" morph="none" start_char="826" end_char="836">coronavirus</TOKEN>
<TOKEN id="token-5-38" pos="word" morph="none" start_char="838" end_char="840">con</TOKEN>
<TOKEN id="token-5-39" pos="word" morph="none" start_char="842" end_char="843">la</TOKEN>
<TOKEN id="token-5-40" pos="word" morph="none" start_char="845" end_char="855">propagación</TOKEN>
<TOKEN id="token-5-41" pos="word" morph="none" start_char="857" end_char="859">del</TOKEN>
<TOKEN id="token-5-42" pos="word" morph="none" start_char="861" end_char="866">dengue</TOKEN>
<TOKEN id="token-5-43" pos="word" morph="none" start_char="868" end_char="872">entre</TOKEN>
<TOKEN id="token-5-44" pos="word" morph="none" start_char="874" end_char="877">2019</TOKEN>
<TOKEN id="token-5-45" pos="word" morph="none" start_char="879" end_char="879">y</TOKEN>
<TOKEN id="token-5-46" pos="word" morph="none" start_char="881" end_char="884">2020</TOKEN>
<TOKEN id="token-5-47" pos="punct" morph="none" start_char="885" end_char="885">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="888" end_char="1096">
<ORIGINAL_TEXT>Las áreas con menores tasas de infección por coronavirus y con un crecimiento más lento de los casos fueron los lugares que habían sufrido brotes intensos de dengue este año o el anterior, descubrió Nicolelis.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="888" end_char="890">Las</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="892" end_char="896">áreas</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="898" end_char="900">con</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="902" end_char="908">menores</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="910" end_char="914">tasas</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="916" end_char="917">de</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="919" end_char="927">infección</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="929" end_char="931">por</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="933" end_char="943">coronavirus</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="945" end_char="945">y</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="947" end_char="949">con</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="951" end_char="952">un</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="954" end_char="964">crecimiento</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="966" end_char="968">más</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="970" end_char="974">lento</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="976" end_char="977">de</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="979" end_char="981">los</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="983" end_char="987">casos</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="989" end_char="994">fueron</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="996" end_char="998">los</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="1000" end_char="1006">lugares</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="1008" end_char="1010">que</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="1012" end_char="1017">habían</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="1019" end_char="1025">sufrido</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="1027" end_char="1032">brotes</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="1034" end_char="1041">intensos</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="1043" end_char="1044">de</TOKEN>
<TOKEN id="token-6-27" pos="word" morph="none" start_char="1046" end_char="1051">dengue</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="1053" end_char="1056">este</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="1058" end_char="1060">año</TOKEN>
<TOKEN id="token-6-30" pos="word" morph="none" start_char="1062" end_char="1062">o</TOKEN>
<TOKEN id="token-6-31" pos="word" morph="none" start_char="1064" end_char="1065">el</TOKEN>
<TOKEN id="token-6-32" pos="word" morph="none" start_char="1067" end_char="1074">anterior</TOKEN>
<TOKEN id="token-6-33" pos="punct" morph="none" start_char="1075" end_char="1075">,</TOKEN>
<TOKEN id="token-6-34" pos="word" morph="none" start_char="1077" end_char="1085">descubrió</TOKEN>
<TOKEN id="token-6-35" pos="word" morph="none" start_char="1087" end_char="1095">Nicolelis</TOKEN>
<TOKEN id="token-6-36" pos="punct" morph="none" start_char="1096" end_char="1096">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="1099" end_char="1355">
<ORIGINAL_TEXT>"Este sorprendente hallazgo plantea la intrigante posibilidad de una respuesta inmunológica cruzada entre los serotipos Flavivirus del dengue y el SARS-CoV-2", concluyó el estudio, en referencia a los anticuerpos del virus del dengue y al nuevo coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="punct" morph="none" start_char="1099" end_char="1099">"</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="1100" end_char="1103">Este</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="1105" end_char="1116">sorprendente</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="1118" end_char="1125">hallazgo</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="1127" end_char="1133">plantea</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="1135" end_char="1136">la</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="1138" end_char="1147">intrigante</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="1149" end_char="1159">posibilidad</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="1161" end_char="1162">de</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="1164" end_char="1166">una</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="1168" end_char="1176">respuesta</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="1178" end_char="1189">inmunológica</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="1191" end_char="1197">cruzada</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="1199" end_char="1203">entre</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="1205" end_char="1207">los</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="1209" end_char="1217">serotipos</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="1219" end_char="1228">Flavivirus</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="1230" end_char="1232">del</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="1234" end_char="1239">dengue</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="1241" end_char="1241">y</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="1243" end_char="1244">el</TOKEN>
<TOKEN id="token-7-21" pos="unknown" morph="none" start_char="1246" end_char="1255">SARS-CoV-2</TOKEN>
<TOKEN id="token-7-22" pos="punct" morph="none" start_char="1256" end_char="1257">",</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="1259" end_char="1266">concluyó</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="1268" end_char="1269">el</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="1271" end_char="1277">estudio</TOKEN>
<TOKEN id="token-7-26" pos="punct" morph="none" start_char="1278" end_char="1278">,</TOKEN>
<TOKEN id="token-7-27" pos="word" morph="none" start_char="1280" end_char="1281">en</TOKEN>
<TOKEN id="token-7-28" pos="word" morph="none" start_char="1283" end_char="1292">referencia</TOKEN>
<TOKEN id="token-7-29" pos="word" morph="none" start_char="1294" end_char="1294">a</TOKEN>
<TOKEN id="token-7-30" pos="word" morph="none" start_char="1296" end_char="1298">los</TOKEN>
<TOKEN id="token-7-31" pos="word" morph="none" start_char="1300" end_char="1310">anticuerpos</TOKEN>
<TOKEN id="token-7-32" pos="word" morph="none" start_char="1312" end_char="1314">del</TOKEN>
<TOKEN id="token-7-33" pos="word" morph="none" start_char="1316" end_char="1320">virus</TOKEN>
<TOKEN id="token-7-34" pos="word" morph="none" start_char="1322" end_char="1324">del</TOKEN>
<TOKEN id="token-7-35" pos="word" morph="none" start_char="1326" end_char="1331">dengue</TOKEN>
<TOKEN id="token-7-36" pos="word" morph="none" start_char="1333" end_char="1333">y</TOKEN>
<TOKEN id="token-7-37" pos="word" morph="none" start_char="1335" end_char="1336">al</TOKEN>
<TOKEN id="token-7-38" pos="word" morph="none" start_char="1338" end_char="1342">nuevo</TOKEN>
<TOKEN id="token-7-39" pos="word" morph="none" start_char="1344" end_char="1354">coronavirus</TOKEN>
<TOKEN id="token-7-40" pos="punct" morph="none" start_char="1355" end_char="1355">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1358" end_char="1604">
<ORIGINAL_TEXT>"Si se demuestra que es correcta, esta hipótesis podría significar que la infección por dengue o la inmunización con una vacuna eficaz y segura contra el dengue podría producir algún nivel de protección inmunológica" contra el coronavirus, agregó.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="punct" morph="none" start_char="1358" end_char="1358">"</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1359" end_char="1360">Si</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1362" end_char="1363">se</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1365" end_char="1373">demuestra</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1375" end_char="1377">que</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1379" end_char="1380">es</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1382" end_char="1389">correcta</TOKEN>
<TOKEN id="token-8-7" pos="punct" morph="none" start_char="1390" end_char="1390">,</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1392" end_char="1395">esta</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1397" end_char="1405">hipótesis</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1407" end_char="1412">podría</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1414" end_char="1423">significar</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1425" end_char="1427">que</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1429" end_char="1430">la</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1432" end_char="1440">infección</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1442" end_char="1444">por</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1446" end_char="1451">dengue</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1453" end_char="1453">o</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1455" end_char="1456">la</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1458" end_char="1469">inmunización</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="1471" end_char="1473">con</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="1475" end_char="1477">una</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="1479" end_char="1484">vacuna</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="1486" end_char="1491">eficaz</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="1493" end_char="1493">y</TOKEN>
<TOKEN id="token-8-25" pos="word" morph="none" start_char="1495" end_char="1500">segura</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="1502" end_char="1507">contra</TOKEN>
<TOKEN id="token-8-27" pos="word" morph="none" start_char="1509" end_char="1510">el</TOKEN>
<TOKEN id="token-8-28" pos="word" morph="none" start_char="1512" end_char="1517">dengue</TOKEN>
<TOKEN id="token-8-29" pos="word" morph="none" start_char="1519" end_char="1524">podría</TOKEN>
<TOKEN id="token-8-30" pos="word" morph="none" start_char="1526" end_char="1533">producir</TOKEN>
<TOKEN id="token-8-31" pos="word" morph="none" start_char="1535" end_char="1539">algún</TOKEN>
<TOKEN id="token-8-32" pos="word" morph="none" start_char="1541" end_char="1545">nivel</TOKEN>
<TOKEN id="token-8-33" pos="word" morph="none" start_char="1547" end_char="1548">de</TOKEN>
<TOKEN id="token-8-34" pos="word" morph="none" start_char="1550" end_char="1559">protección</TOKEN>
<TOKEN id="token-8-35" pos="word" morph="none" start_char="1561" end_char="1572">inmunológica</TOKEN>
<TOKEN id="token-8-36" pos="punct" morph="none" start_char="1573" end_char="1573">"</TOKEN>
<TOKEN id="token-8-37" pos="word" morph="none" start_char="1575" end_char="1580">contra</TOKEN>
<TOKEN id="token-8-38" pos="word" morph="none" start_char="1582" end_char="1583">el</TOKEN>
<TOKEN id="token-8-39" pos="word" morph="none" start_char="1585" end_char="1595">coronavirus</TOKEN>
<TOKEN id="token-8-40" pos="punct" morph="none" start_char="1596" end_char="1596">,</TOKEN>
<TOKEN id="token-8-41" pos="word" morph="none" start_char="1598" end_char="1603">agregó</TOKEN>
<TOKEN id="token-8-42" pos="punct" morph="none" start_char="1604" end_char="1604">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1607" end_char="1908">
<ORIGINAL_TEXT>Nicolelis dijo a Reuters que los resultados son particularmente interesantes, porque estudios previos han demostrado que las personas con anticuerpos contra el dengue en su sangre pueden dar falsos positivos a los anticuerpos contra la COVID-19, incluso si nunca han sido infectados por el coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1607" end_char="1615">Nicolelis</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1617" end_char="1620">dijo</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1622" end_char="1622">a</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1624" end_char="1630">Reuters</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1632" end_char="1634">que</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1636" end_char="1638">los</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1640" end_char="1649">resultados</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1651" end_char="1653">son</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1655" end_char="1669">particularmente</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1671" end_char="1682">interesantes</TOKEN>
<TOKEN id="token-9-10" pos="punct" morph="none" start_char="1683" end_char="1683">,</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1685" end_char="1690">porque</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1692" end_char="1699">estudios</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1701" end_char="1707">previos</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1709" end_char="1711">han</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1713" end_char="1722">demostrado</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1724" end_char="1726">que</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1728" end_char="1730">las</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1732" end_char="1739">personas</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1741" end_char="1743">con</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1745" end_char="1755">anticuerpos</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1757" end_char="1762">contra</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1764" end_char="1765">el</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1767" end_char="1772">dengue</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1774" end_char="1775">en</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1777" end_char="1778">su</TOKEN>
<TOKEN id="token-9-26" pos="word" morph="none" start_char="1780" end_char="1785">sangre</TOKEN>
<TOKEN id="token-9-27" pos="word" morph="none" start_char="1787" end_char="1792">pueden</TOKEN>
<TOKEN id="token-9-28" pos="word" morph="none" start_char="1794" end_char="1796">dar</TOKEN>
<TOKEN id="token-9-29" pos="word" morph="none" start_char="1798" end_char="1803">falsos</TOKEN>
<TOKEN id="token-9-30" pos="word" morph="none" start_char="1805" end_char="1813">positivos</TOKEN>
<TOKEN id="token-9-31" pos="word" morph="none" start_char="1815" end_char="1815">a</TOKEN>
<TOKEN id="token-9-32" pos="word" morph="none" start_char="1817" end_char="1819">los</TOKEN>
<TOKEN id="token-9-33" pos="word" morph="none" start_char="1821" end_char="1831">anticuerpos</TOKEN>
<TOKEN id="token-9-34" pos="word" morph="none" start_char="1833" end_char="1838">contra</TOKEN>
<TOKEN id="token-9-35" pos="word" morph="none" start_char="1840" end_char="1841">la</TOKEN>
<TOKEN id="token-9-36" pos="unknown" morph="none" start_char="1843" end_char="1850">COVID-19</TOKEN>
<TOKEN id="token-9-37" pos="punct" morph="none" start_char="1851" end_char="1851">,</TOKEN>
<TOKEN id="token-9-38" pos="word" morph="none" start_char="1853" end_char="1859">incluso</TOKEN>
<TOKEN id="token-9-39" pos="word" morph="none" start_char="1861" end_char="1862">si</TOKEN>
<TOKEN id="token-9-40" pos="word" morph="none" start_char="1864" end_char="1868">nunca</TOKEN>
<TOKEN id="token-9-41" pos="word" morph="none" start_char="1870" end_char="1872">han</TOKEN>
<TOKEN id="token-9-42" pos="word" morph="none" start_char="1874" end_char="1877">sido</TOKEN>
<TOKEN id="token-9-43" pos="word" morph="none" start_char="1879" end_char="1888">infectados</TOKEN>
<TOKEN id="token-9-44" pos="word" morph="none" start_char="1890" end_char="1892">por</TOKEN>
<TOKEN id="token-9-45" pos="word" morph="none" start_char="1894" end_char="1895">el</TOKEN>
<TOKEN id="token-9-46" pos="word" morph="none" start_char="1897" end_char="1907">coronavirus</TOKEN>
<TOKEN id="token-9-47" pos="punct" morph="none" start_char="1908" end_char="1908">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1911" end_char="2150">
<ORIGINAL_TEXT>"Esto indica que existe una interacción inmunológica entre dos virus que nadie podría haber esperado, porque los dos son de familias completamente diferentes", dijo Nicolelis, añadiendo que se necesitan más estudios para probar la conexión.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="punct" morph="none" start_char="1911" end_char="1911">"</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1912" end_char="1915">Esto</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1917" end_char="1922">indica</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1924" end_char="1926">que</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1928" end_char="1933">existe</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1935" end_char="1937">una</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1939" end_char="1949">interacción</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1951" end_char="1962">inmunológica</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1964" end_char="1968">entre</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1970" end_char="1972">dos</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1974" end_char="1978">virus</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1980" end_char="1982">que</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1984" end_char="1988">nadie</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1990" end_char="1995">podría</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1997" end_char="2001">haber</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="2003" end_char="2010">esperado</TOKEN>
<TOKEN id="token-10-16" pos="punct" morph="none" start_char="2011" end_char="2011">,</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="2013" end_char="2018">porque</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="2020" end_char="2022">los</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="2024" end_char="2026">dos</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="2028" end_char="2030">son</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="2032" end_char="2033">de</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="2035" end_char="2042">familias</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="2044" end_char="2056">completamente</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="2058" end_char="2067">diferentes</TOKEN>
<TOKEN id="token-10-25" pos="punct" morph="none" start_char="2068" end_char="2069">",</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="2071" end_char="2074">dijo</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="2076" end_char="2084">Nicolelis</TOKEN>
<TOKEN id="token-10-28" pos="punct" morph="none" start_char="2085" end_char="2085">,</TOKEN>
<TOKEN id="token-10-29" pos="word" morph="none" start_char="2087" end_char="2095">añadiendo</TOKEN>
<TOKEN id="token-10-30" pos="word" morph="none" start_char="2097" end_char="2099">que</TOKEN>
<TOKEN id="token-10-31" pos="word" morph="none" start_char="2101" end_char="2102">se</TOKEN>
<TOKEN id="token-10-32" pos="word" morph="none" start_char="2104" end_char="2112">necesitan</TOKEN>
<TOKEN id="token-10-33" pos="word" morph="none" start_char="2114" end_char="2116">más</TOKEN>
<TOKEN id="token-10-34" pos="word" morph="none" start_char="2118" end_char="2125">estudios</TOKEN>
<TOKEN id="token-10-35" pos="word" morph="none" start_char="2127" end_char="2130">para</TOKEN>
<TOKEN id="token-10-36" pos="word" morph="none" start_char="2132" end_char="2137">probar</TOKEN>
<TOKEN id="token-10-37" pos="word" morph="none" start_char="2139" end_char="2140">la</TOKEN>
<TOKEN id="token-10-38" pos="word" morph="none" start_char="2142" end_char="2149">conexión</TOKEN>
<TOKEN id="token-10-39" pos="punct" morph="none" start_char="2150" end_char="2150">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="2153" end_char="2295">
<ORIGINAL_TEXT>El estudio se iba a publicar antes de su revisión por pares en el servidor de preimpresión de MedRxiv y se presentará a una revista científica.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="2153" end_char="2154">El</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="2156" end_char="2162">estudio</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="2164" end_char="2165">se</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="2167" end_char="2169">iba</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="2171" end_char="2171">a</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="2173" end_char="2180">publicar</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="2182" end_char="2186">antes</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="2188" end_char="2189">de</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="2191" end_char="2192">su</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="2194" end_char="2201">revisión</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="2203" end_char="2205">por</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="2207" end_char="2211">pares</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="2213" end_char="2214">en</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="2216" end_char="2217">el</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="2219" end_char="2226">servidor</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="2228" end_char="2229">de</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="2231" end_char="2242">preimpresión</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="2244" end_char="2245">de</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="2247" end_char="2253">MedRxiv</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="2255" end_char="2255">y</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="2257" end_char="2258">se</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="2260" end_char="2269">presentará</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="2271" end_char="2271">a</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="2273" end_char="2275">una</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="2277" end_char="2283">revista</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="2285" end_char="2294">científica</TOKEN>
<TOKEN id="token-11-26" pos="punct" morph="none" start_char="2295" end_char="2295">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="2298" end_char="2500">
<ORIGINAL_TEXT>Destaca una correlación significativa entre la menor incidencia, mortalidad y tasa de crecimiento de la COVID-19 en poblaciones de Brasil donde los niveles de anticuerpos contra el dengue eran más altos.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="2298" end_char="2304">Destaca</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="2306" end_char="2308">una</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="2310" end_char="2320">correlación</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="2322" end_char="2334">significativa</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="2336" end_char="2340">entre</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="2342" end_char="2343">la</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="2345" end_char="2349">menor</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="2351" end_char="2360">incidencia</TOKEN>
<TOKEN id="token-12-8" pos="punct" morph="none" start_char="2361" end_char="2361">,</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="2363" end_char="2372">mortalidad</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="2374" end_char="2374">y</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="2376" end_char="2379">tasa</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="2381" end_char="2382">de</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="2384" end_char="2394">crecimiento</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="2396" end_char="2397">de</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="2399" end_char="2400">la</TOKEN>
<TOKEN id="token-12-16" pos="unknown" morph="none" start_char="2402" end_char="2409">COVID-19</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="2411" end_char="2412">en</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="2414" end_char="2424">poblaciones</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="2426" end_char="2427">de</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="2429" end_char="2434">Brasil</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="2436" end_char="2440">donde</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="2442" end_char="2444">los</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="2446" end_char="2452">niveles</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="2454" end_char="2455">de</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="2457" end_char="2467">anticuerpos</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="2469" end_char="2474">contra</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="2476" end_char="2477">el</TOKEN>
<TOKEN id="token-12-28" pos="word" morph="none" start_char="2479" end_char="2484">dengue</TOKEN>
<TOKEN id="token-12-29" pos="word" morph="none" start_char="2486" end_char="2489">eran</TOKEN>
<TOKEN id="token-12-30" pos="word" morph="none" start_char="2491" end_char="2493">más</TOKEN>
<TOKEN id="token-12-31" pos="word" morph="none" start_char="2495" end_char="2499">altos</TOKEN>
<TOKEN id="token-12-32" pos="punct" morph="none" start_char="2500" end_char="2500">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="2503" end_char="2658">
<ORIGINAL_TEXT>Brasil ocupa el tercer lugar del mundo en cuanto a infecciones por COVID-19, con más de 4,4 millones de casos, sólo por detrás de Estados Unidos y la India.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="2503" end_char="2508">Brasil</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="2510" end_char="2514">ocupa</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="2516" end_char="2517">el</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="2519" end_char="2524">tercer</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="2526" end_char="2530">lugar</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="2532" end_char="2534">del</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="2536" end_char="2540">mundo</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="2542" end_char="2543">en</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="2545" end_char="2550">cuanto</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="2552" end_char="2552">a</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="2554" end_char="2564">infecciones</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="2566" end_char="2568">por</TOKEN>
<TOKEN id="token-13-12" pos="unknown" morph="none" start_char="2570" end_char="2577">COVID-19</TOKEN>
<TOKEN id="token-13-13" pos="punct" morph="none" start_char="2578" end_char="2578">,</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="2580" end_char="2582">con</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="2584" end_char="2586">más</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="2588" end_char="2589">de</TOKEN>
<TOKEN id="token-13-17" pos="unknown" morph="none" start_char="2591" end_char="2593">4,4</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="2595" end_char="2602">millones</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="2604" end_char="2605">de</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="2607" end_char="2611">casos</TOKEN>
<TOKEN id="token-13-21" pos="punct" morph="none" start_char="2612" end_char="2612">,</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="2614" end_char="2617">sólo</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="2619" end_char="2621">por</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="2623" end_char="2628">detrás</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="2630" end_char="2631">de</TOKEN>
<TOKEN id="token-13-26" pos="word" morph="none" start_char="2633" end_char="2639">Estados</TOKEN>
<TOKEN id="token-13-27" pos="word" morph="none" start_char="2641" end_char="2646">Unidos</TOKEN>
<TOKEN id="token-13-28" pos="word" morph="none" start_char="2648" end_char="2648">y</TOKEN>
<TOKEN id="token-13-29" pos="word" morph="none" start_char="2650" end_char="2651">la</TOKEN>
<TOKEN id="token-13-30" pos="word" morph="none" start_char="2653" end_char="2657">India</TOKEN>
<TOKEN id="token-13-31" pos="punct" morph="none" start_char="2658" end_char="2658">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="2661" end_char="3012">
<ORIGINAL_TEXT>En estados como Paraná, Santa Catarina, Rio Grande do Sul, Mato Grosso do Sul y Minas Gerais, con una alta incidencia de dengue el año pasado y a principios de este año, la COVID-19 tardó mucho más tiempo en alcanzar un nivel de alta transmisión en la comunidad en comparación con estados como Amapá, Maranhão y Pará que tuvieron menos casos de dengue.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="2661" end_char="2662">En</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="2664" end_char="2670">estados</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="2672" end_char="2675">como</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="2677" end_char="2682">Paraná</TOKEN>
<TOKEN id="token-14-4" pos="punct" morph="none" start_char="2683" end_char="2683">,</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="2685" end_char="2689">Santa</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="2691" end_char="2698">Catarina</TOKEN>
<TOKEN id="token-14-7" pos="punct" morph="none" start_char="2699" end_char="2699">,</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="2701" end_char="2703">Rio</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="2705" end_char="2710">Grande</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="2712" end_char="2713">do</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="2715" end_char="2717">Sul</TOKEN>
<TOKEN id="token-14-12" pos="punct" morph="none" start_char="2718" end_char="2718">,</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="2720" end_char="2723">Mato</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="2725" end_char="2730">Grosso</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="2732" end_char="2733">do</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="2735" end_char="2737">Sul</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="2739" end_char="2739">y</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="2741" end_char="2745">Minas</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="2747" end_char="2752">Gerais</TOKEN>
<TOKEN id="token-14-20" pos="punct" morph="none" start_char="2753" end_char="2753">,</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="2755" end_char="2757">con</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="2759" end_char="2761">una</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="2763" end_char="2766">alta</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="2768" end_char="2777">incidencia</TOKEN>
<TOKEN id="token-14-25" pos="word" morph="none" start_char="2779" end_char="2780">de</TOKEN>
<TOKEN id="token-14-26" pos="word" morph="none" start_char="2782" end_char="2787">dengue</TOKEN>
<TOKEN id="token-14-27" pos="word" morph="none" start_char="2789" end_char="2790">el</TOKEN>
<TOKEN id="token-14-28" pos="word" morph="none" start_char="2792" end_char="2794">año</TOKEN>
<TOKEN id="token-14-29" pos="word" morph="none" start_char="2796" end_char="2801">pasado</TOKEN>
<TOKEN id="token-14-30" pos="word" morph="none" start_char="2803" end_char="2803">y</TOKEN>
<TOKEN id="token-14-31" pos="word" morph="none" start_char="2805" end_char="2805">a</TOKEN>
<TOKEN id="token-14-32" pos="word" morph="none" start_char="2807" end_char="2816">principios</TOKEN>
<TOKEN id="token-14-33" pos="word" morph="none" start_char="2818" end_char="2819">de</TOKEN>
<TOKEN id="token-14-34" pos="word" morph="none" start_char="2821" end_char="2824">este</TOKEN>
<TOKEN id="token-14-35" pos="word" morph="none" start_char="2826" end_char="2828">año</TOKEN>
<TOKEN id="token-14-36" pos="punct" morph="none" start_char="2829" end_char="2829">,</TOKEN>
<TOKEN id="token-14-37" pos="word" morph="none" start_char="2831" end_char="2832">la</TOKEN>
<TOKEN id="token-14-38" pos="unknown" morph="none" start_char="2834" end_char="2841">COVID-19</TOKEN>
<TOKEN id="token-14-39" pos="word" morph="none" start_char="2843" end_char="2847">tardó</TOKEN>
<TOKEN id="token-14-40" pos="word" morph="none" start_char="2849" end_char="2853">mucho</TOKEN>
<TOKEN id="token-14-41" pos="word" morph="none" start_char="2855" end_char="2857">más</TOKEN>
<TOKEN id="token-14-42" pos="word" morph="none" start_char="2859" end_char="2864">tiempo</TOKEN>
<TOKEN id="token-14-43" pos="word" morph="none" start_char="2866" end_char="2867">en</TOKEN>
<TOKEN id="token-14-44" pos="word" morph="none" start_char="2869" end_char="2876">alcanzar</TOKEN>
<TOKEN id="token-14-45" pos="word" morph="none" start_char="2878" end_char="2879">un</TOKEN>
<TOKEN id="token-14-46" pos="word" morph="none" start_char="2881" end_char="2885">nivel</TOKEN>
<TOKEN id="token-14-47" pos="word" morph="none" start_char="2887" end_char="2888">de</TOKEN>
<TOKEN id="token-14-48" pos="word" morph="none" start_char="2890" end_char="2893">alta</TOKEN>
<TOKEN id="token-14-49" pos="word" morph="none" start_char="2895" end_char="2905">transmisión</TOKEN>
<TOKEN id="token-14-50" pos="word" morph="none" start_char="2907" end_char="2908">en</TOKEN>
<TOKEN id="token-14-51" pos="word" morph="none" start_char="2910" end_char="2911">la</TOKEN>
<TOKEN id="token-14-52" pos="word" morph="none" start_char="2913" end_char="2921">comunidad</TOKEN>
<TOKEN id="token-14-53" pos="word" morph="none" start_char="2923" end_char="2924">en</TOKEN>
<TOKEN id="token-14-54" pos="word" morph="none" start_char="2926" end_char="2936">comparación</TOKEN>
<TOKEN id="token-14-55" pos="word" morph="none" start_char="2938" end_char="2940">con</TOKEN>
<TOKEN id="token-14-56" pos="word" morph="none" start_char="2942" end_char="2948">estados</TOKEN>
<TOKEN id="token-14-57" pos="word" morph="none" start_char="2950" end_char="2953">como</TOKEN>
<TOKEN id="token-14-58" pos="word" morph="none" start_char="2955" end_char="2959">Amapá</TOKEN>
<TOKEN id="token-14-59" pos="punct" morph="none" start_char="2960" end_char="2960">,</TOKEN>
<TOKEN id="token-14-60" pos="word" morph="none" start_char="2962" end_char="2969">Maranhão</TOKEN>
<TOKEN id="token-14-61" pos="word" morph="none" start_char="2971" end_char="2971">y</TOKEN>
<TOKEN id="token-14-62" pos="word" morph="none" start_char="2973" end_char="2976">Pará</TOKEN>
<TOKEN id="token-14-63" pos="word" morph="none" start_char="2978" end_char="2980">que</TOKEN>
<TOKEN id="token-14-64" pos="word" morph="none" start_char="2982" end_char="2989">tuvieron</TOKEN>
<TOKEN id="token-14-65" pos="word" morph="none" start_char="2991" end_char="2995">menos</TOKEN>
<TOKEN id="token-14-66" pos="word" morph="none" start_char="2997" end_char="3001">casos</TOKEN>
<TOKEN id="token-14-67" pos="word" morph="none" start_char="3003" end_char="3004">de</TOKEN>
<TOKEN id="token-14-68" pos="word" morph="none" start_char="3006" end_char="3011">dengue</TOKEN>
<TOKEN id="token-14-69" pos="punct" morph="none" start_char="3012" end_char="3012">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="3015" end_char="3217">
<ORIGINAL_TEXT>El equipo encontró una relación similar entre los brotes de dengue y una propagación más lenta de la COVID-19 en otras partes de América Latina, así como en Asia e islas de los océanos Pacífico e Índico.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="3015" end_char="3016">El</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="3018" end_char="3023">equipo</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="3025" end_char="3032">encontró</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="3034" end_char="3036">una</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="3038" end_char="3045">relación</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="3047" end_char="3053">similar</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="3055" end_char="3059">entre</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="3061" end_char="3063">los</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="3065" end_char="3070">brotes</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="3072" end_char="3073">de</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="3075" end_char="3080">dengue</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="3082" end_char="3082">y</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="3084" end_char="3086">una</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="3088" end_char="3098">propagación</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="3100" end_char="3102">más</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="3104" end_char="3108">lenta</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="3110" end_char="3111">de</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="3113" end_char="3114">la</TOKEN>
<TOKEN id="token-15-18" pos="unknown" morph="none" start_char="3116" end_char="3123">COVID-19</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="3125" end_char="3126">en</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="3128" end_char="3132">otras</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="3134" end_char="3139">partes</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="3141" end_char="3142">de</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="3144" end_char="3150">América</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="3152" end_char="3157">Latina</TOKEN>
<TOKEN id="token-15-25" pos="punct" morph="none" start_char="3158" end_char="3158">,</TOKEN>
<TOKEN id="token-15-26" pos="word" morph="none" start_char="3160" end_char="3162">así</TOKEN>
<TOKEN id="token-15-27" pos="word" morph="none" start_char="3164" end_char="3167">como</TOKEN>
<TOKEN id="token-15-28" pos="word" morph="none" start_char="3169" end_char="3170">en</TOKEN>
<TOKEN id="token-15-29" pos="word" morph="none" start_char="3172" end_char="3175">Asia</TOKEN>
<TOKEN id="token-15-30" pos="word" morph="none" start_char="3177" end_char="3177">e</TOKEN>
<TOKEN id="token-15-31" pos="word" morph="none" start_char="3179" end_char="3183">islas</TOKEN>
<TOKEN id="token-15-32" pos="word" morph="none" start_char="3185" end_char="3186">de</TOKEN>
<TOKEN id="token-15-33" pos="word" morph="none" start_char="3188" end_char="3190">los</TOKEN>
<TOKEN id="token-15-34" pos="word" morph="none" start_char="3192" end_char="3198">océanos</TOKEN>
<TOKEN id="token-15-35" pos="word" morph="none" start_char="3200" end_char="3207">Pacífico</TOKEN>
<TOKEN id="token-15-36" pos="word" morph="none" start_char="3209" end_char="3209">e</TOKEN>
<TOKEN id="token-15-37" pos="word" morph="none" start_char="3211" end_char="3216">Índico</TOKEN>
<TOKEN id="token-15-38" pos="punct" morph="none" start_char="3217" end_char="3217">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="3220" end_char="3505">
<ORIGINAL_TEXT>Nicolelis dijo que su equipo hizo el descubrimiento sobre el dengue por accidente, durante un estudio centrado en cómo se propagó la COVID-19 a través de Brasil, en el que descubrieron que las carreteras desempeñaron un papel importante en la distribución de los casos por todo el país.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="3220" end_char="3228">Nicolelis</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="3230" end_char="3233">dijo</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="3235" end_char="3237">que</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="3239" end_char="3240">su</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="3242" end_char="3247">equipo</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="3249" end_char="3252">hizo</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="3254" end_char="3255">el</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="3257" end_char="3270">descubrimiento</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="3272" end_char="3276">sobre</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="3278" end_char="3279">el</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="3281" end_char="3286">dengue</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="3288" end_char="3290">por</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="3292" end_char="3300">accidente</TOKEN>
<TOKEN id="token-16-13" pos="punct" morph="none" start_char="3301" end_char="3301">,</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="3303" end_char="3309">durante</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="3311" end_char="3312">un</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="3314" end_char="3320">estudio</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="3322" end_char="3329">centrado</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="3331" end_char="3332">en</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="3334" end_char="3337">cómo</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="3339" end_char="3340">se</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="3342" end_char="3348">propagó</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="3350" end_char="3351">la</TOKEN>
<TOKEN id="token-16-23" pos="unknown" morph="none" start_char="3353" end_char="3360">COVID-19</TOKEN>
<TOKEN id="token-16-24" pos="word" morph="none" start_char="3362" end_char="3362">a</TOKEN>
<TOKEN id="token-16-25" pos="word" morph="none" start_char="3364" end_char="3369">través</TOKEN>
<TOKEN id="token-16-26" pos="word" morph="none" start_char="3371" end_char="3372">de</TOKEN>
<TOKEN id="token-16-27" pos="word" morph="none" start_char="3374" end_char="3379">Brasil</TOKEN>
<TOKEN id="token-16-28" pos="punct" morph="none" start_char="3380" end_char="3380">,</TOKEN>
<TOKEN id="token-16-29" pos="word" morph="none" start_char="3382" end_char="3383">en</TOKEN>
<TOKEN id="token-16-30" pos="word" morph="none" start_char="3385" end_char="3386">el</TOKEN>
<TOKEN id="token-16-31" pos="word" morph="none" start_char="3388" end_char="3390">que</TOKEN>
<TOKEN id="token-16-32" pos="word" morph="none" start_char="3392" end_char="3403">descubrieron</TOKEN>
<TOKEN id="token-16-33" pos="word" morph="none" start_char="3405" end_char="3407">que</TOKEN>
<TOKEN id="token-16-34" pos="word" morph="none" start_char="3409" end_char="3411">las</TOKEN>
<TOKEN id="token-16-35" pos="word" morph="none" start_char="3413" end_char="3422">carreteras</TOKEN>
<TOKEN id="token-16-36" pos="word" morph="none" start_char="3424" end_char="3435">desempeñaron</TOKEN>
<TOKEN id="token-16-37" pos="word" morph="none" start_char="3437" end_char="3438">un</TOKEN>
<TOKEN id="token-16-38" pos="word" morph="none" start_char="3440" end_char="3444">papel</TOKEN>
<TOKEN id="token-16-39" pos="word" morph="none" start_char="3446" end_char="3455">importante</TOKEN>
<TOKEN id="token-16-40" pos="word" morph="none" start_char="3457" end_char="3458">en</TOKEN>
<TOKEN id="token-16-41" pos="word" morph="none" start_char="3460" end_char="3461">la</TOKEN>
<TOKEN id="token-16-42" pos="word" morph="none" start_char="3463" end_char="3474">distribución</TOKEN>
<TOKEN id="token-16-43" pos="word" morph="none" start_char="3476" end_char="3477">de</TOKEN>
<TOKEN id="token-16-44" pos="word" morph="none" start_char="3479" end_char="3481">los</TOKEN>
<TOKEN id="token-16-45" pos="word" morph="none" start_char="3483" end_char="3487">casos</TOKEN>
<TOKEN id="token-16-46" pos="word" morph="none" start_char="3489" end_char="3491">por</TOKEN>
<TOKEN id="token-16-47" pos="word" morph="none" start_char="3493" end_char="3496">todo</TOKEN>
<TOKEN id="token-16-48" pos="word" morph="none" start_char="3498" end_char="3499">el</TOKEN>
<TOKEN id="token-16-49" pos="word" morph="none" start_char="3501" end_char="3504">país</TOKEN>
<TOKEN id="token-16-50" pos="punct" morph="none" start_char="3505" end_char="3505">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="3508" end_char="3616">
<ORIGINAL_TEXT>Tras identificar ciertos puntos libres de casos en el mapa, el equipo fue en busca de posibles explicaciones.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="3508" end_char="3511">Tras</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="3513" end_char="3523">identificar</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="3525" end_char="3531">ciertos</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="3533" end_char="3538">puntos</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="3540" end_char="3545">libres</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="3547" end_char="3548">de</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="3550" end_char="3554">casos</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="3556" end_char="3557">en</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="3559" end_char="3560">el</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="3562" end_char="3565">mapa</TOKEN>
<TOKEN id="token-17-10" pos="punct" morph="none" start_char="3566" end_char="3566">,</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="3568" end_char="3569">el</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="3571" end_char="3576">equipo</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="3578" end_char="3580">fue</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="3582" end_char="3583">en</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="3585" end_char="3589">busca</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="3591" end_char="3592">de</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="3594" end_char="3601">posibles</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="3603" end_char="3615">explicaciones</TOKEN>
<TOKEN id="token-17-19" pos="punct" morph="none" start_char="3616" end_char="3616">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="3618" end_char="3715">
<ORIGINAL_TEXT>Un gran avance se logró cuando el equipo comparó la propagación del dengue con la del coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="3618" end_char="3619">Un</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="3621" end_char="3624">gran</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="3626" end_char="3631">avance</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="3633" end_char="3634">se</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="3636" end_char="3640">logró</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="3642" end_char="3647">cuando</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="3649" end_char="3650">el</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="3652" end_char="3657">equipo</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="3659" end_char="3665">comparó</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="3667" end_char="3668">la</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="3670" end_char="3680">propagación</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="3682" end_char="3684">del</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="3686" end_char="3691">dengue</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="3693" end_char="3695">con</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="3697" end_char="3698">la</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="3700" end_char="3702">del</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="3704" end_char="3714">coronavirus</TOKEN>
<TOKEN id="token-18-17" pos="punct" morph="none" start_char="3715" end_char="3715">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="3718" end_char="3731">
<ORIGINAL_TEXT>"Fue un shock.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="punct" morph="none" start_char="3718" end_char="3718">"</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="3719" end_char="3721">Fue</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="3723" end_char="3724">un</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="3726" end_char="3730">shock</TOKEN>
<TOKEN id="token-19-4" pos="punct" morph="none" start_char="3731" end_char="3731">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="3733" end_char="3773">
<ORIGINAL_TEXT>Fue un casualidad total", dijo Nicolelis.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="3733" end_char="3735">Fue</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="3737" end_char="3738">un</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="3740" end_char="3749">casualidad</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="3751" end_char="3755">total</TOKEN>
<TOKEN id="token-20-4" pos="punct" morph="none" start_char="3756" end_char="3757">",</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="3759" end_char="3762">dijo</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="3764" end_char="3772">Nicolelis</TOKEN>
<TOKEN id="token-20-7" pos="punct" morph="none" start_char="3773" end_char="3773">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="3775" end_char="3885">
<ORIGINAL_TEXT>"En la ciencia, eso sucede, le disparas a una cosa y aciertas a un blanco que nunca imaginaste que acertarías".</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="punct" morph="none" start_char="3775" end_char="3775">"</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="3776" end_char="3777">En</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="3779" end_char="3780">la</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="3782" end_char="3788">ciencia</TOKEN>
<TOKEN id="token-21-4" pos="punct" morph="none" start_char="3789" end_char="3789">,</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="3791" end_char="3793">eso</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="3795" end_char="3800">sucede</TOKEN>
<TOKEN id="token-21-7" pos="punct" morph="none" start_char="3801" end_char="3801">,</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="3803" end_char="3804">le</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="3806" end_char="3813">disparas</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="3815" end_char="3815">a</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="3817" end_char="3819">una</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="3821" end_char="3824">cosa</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="3826" end_char="3826">y</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="3828" end_char="3835">aciertas</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="3837" end_char="3837">a</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="3839" end_char="3840">un</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="3842" end_char="3847">blanco</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="3849" end_char="3851">que</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="3853" end_char="3857">nunca</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="3859" end_char="3868">imaginaste</TOKEN>
<TOKEN id="token-21-21" pos="word" morph="none" start_char="3870" end_char="3872">que</TOKEN>
<TOKEN id="token-21-22" pos="word" morph="none" start_char="3874" end_char="3883">acertarías</TOKEN>
<TOKEN id="token-21-23" pos="punct" morph="none" start_char="3884" end_char="3885">".</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
