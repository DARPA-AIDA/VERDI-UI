<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATQI" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="2196" raw_text_md5="7ad8d71c85d2c967a737507d424c2001">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="82">
<ORIGINAL_TEXT>El coronavirus podría haber comenzado a circular por China el pasado mes de agosto</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="2">El</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="4" end_char="14">coronavirus</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="16" end_char="21">podría</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="23" end_char="27">haber</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="29" end_char="37">comenzado</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="39" end_char="39">a</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="41" end_char="48">circular</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="50" end_char="52">por</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="54" end_char="58">China</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="60" end_char="61">el</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="63" end_char="68">pasado</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="70" end_char="72">mes</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="74" end_char="75">de</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="77" end_char="82">agosto</TOKEN>
</SEG>
<SEG id="segment-1" start_char="86" end_char="198">
<ORIGINAL_TEXT>Aunque los resultados no pueden relacionarse de forma directa con el coronavirus, refuerzan otros estudios (Foto.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="86" end_char="91">Aunque</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="93" end_char="95">los</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="97" end_char="106">resultados</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="108" end_char="109">no</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="111" end_char="116">pueden</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="118" end_char="129">relacionarse</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="131" end_char="132">de</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="134" end_char="138">forma</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="140" end_char="146">directa</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="148" end_char="150">con</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="152" end_char="153">el</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="155" end_char="165">coronavirus</TOKEN>
<TOKEN id="token-1-12" pos="punct" morph="none" start_char="166" end_char="166">,</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="168" end_char="176">refuerzan</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="178" end_char="182">otros</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="184" end_char="191">estudios</TOKEN>
<TOKEN id="token-1-16" pos="punct" morph="none" start_char="193" end_char="193">(</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="194" end_char="197">Foto</TOKEN>
<TOKEN id="token-1-18" pos="punct" morph="none" start_char="198" end_char="198">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="200" end_char="207">
<ORIGINAL_TEXT>Freepik)</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="200" end_char="206">Freepik</TOKEN>
<TOKEN id="token-2-1" pos="punct" morph="none" start_char="207" end_char="207">)</TOKEN>
</SEG>
<SEG id="segment-3" start_char="211" end_char="528">
<ORIGINAL_TEXT>Un grupo de investigadores del Harvard Medical School de Boston (Estados Unidos) ha puesto de relieve la posibilidad de que el nuevo coronavirus SARS-CoV-2 que provoca la enfermedad de la Covid-19, podría haber comenzado a circular por la ciudad china de Wuhan, epicentro de la pandemia, desde el pasado mes de agosto.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="211" end_char="212">Un</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="214" end_char="218">grupo</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="220" end_char="221">de</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="223" end_char="236">investigadores</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="238" end_char="240">del</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="242" end_char="248">Harvard</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="250" end_char="256">Medical</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="258" end_char="263">School</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="265" end_char="266">de</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="268" end_char="273">Boston</TOKEN>
<TOKEN id="token-3-10" pos="punct" morph="none" start_char="275" end_char="275">(</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="276" end_char="282">Estados</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="284" end_char="289">Unidos</TOKEN>
<TOKEN id="token-3-13" pos="punct" morph="none" start_char="290" end_char="290">)</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="292" end_char="293">ha</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="295" end_char="300">puesto</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="302" end_char="303">de</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="305" end_char="311">relieve</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="313" end_char="314">la</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="316" end_char="326">posibilidad</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="328" end_char="329">de</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="331" end_char="333">que</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="335" end_char="336">el</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="338" end_char="342">nuevo</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="344" end_char="354">coronavirus</TOKEN>
<TOKEN id="token-3-25" pos="unknown" morph="none" start_char="356" end_char="365">SARS-CoV-2</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="367" end_char="369">que</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="371" end_char="377">provoca</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="379" end_char="380">la</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="382" end_char="391">enfermedad</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="393" end_char="394">de</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="396" end_char="397">la</TOKEN>
<TOKEN id="token-3-32" pos="unknown" morph="none" start_char="399" end_char="406">Covid-19</TOKEN>
<TOKEN id="token-3-33" pos="punct" morph="none" start_char="407" end_char="407">,</TOKEN>
<TOKEN id="token-3-34" pos="word" morph="none" start_char="409" end_char="414">podría</TOKEN>
<TOKEN id="token-3-35" pos="word" morph="none" start_char="416" end_char="420">haber</TOKEN>
<TOKEN id="token-3-36" pos="word" morph="none" start_char="422" end_char="430">comenzado</TOKEN>
<TOKEN id="token-3-37" pos="word" morph="none" start_char="432" end_char="432">a</TOKEN>
<TOKEN id="token-3-38" pos="word" morph="none" start_char="434" end_char="441">circular</TOKEN>
<TOKEN id="token-3-39" pos="word" morph="none" start_char="443" end_char="445">por</TOKEN>
<TOKEN id="token-3-40" pos="word" morph="none" start_char="447" end_char="448">la</TOKEN>
<TOKEN id="token-3-41" pos="word" morph="none" start_char="450" end_char="455">ciudad</TOKEN>
<TOKEN id="token-3-42" pos="word" morph="none" start_char="457" end_char="461">china</TOKEN>
<TOKEN id="token-3-43" pos="word" morph="none" start_char="463" end_char="464">de</TOKEN>
<TOKEN id="token-3-44" pos="word" morph="none" start_char="466" end_char="470">Wuhan</TOKEN>
<TOKEN id="token-3-45" pos="punct" morph="none" start_char="471" end_char="471">,</TOKEN>
<TOKEN id="token-3-46" pos="word" morph="none" start_char="473" end_char="481">epicentro</TOKEN>
<TOKEN id="token-3-47" pos="word" morph="none" start_char="483" end_char="484">de</TOKEN>
<TOKEN id="token-3-48" pos="word" morph="none" start_char="486" end_char="487">la</TOKEN>
<TOKEN id="token-3-49" pos="word" morph="none" start_char="489" end_char="496">pandemia</TOKEN>
<TOKEN id="token-3-50" pos="punct" morph="none" start_char="497" end_char="497">,</TOKEN>
<TOKEN id="token-3-51" pos="word" morph="none" start_char="499" end_char="503">desde</TOKEN>
<TOKEN id="token-3-52" pos="word" morph="none" start_char="505" end_char="506">el</TOKEN>
<TOKEN id="token-3-53" pos="word" morph="none" start_char="508" end_char="513">pasado</TOKEN>
<TOKEN id="token-3-54" pos="word" morph="none" start_char="515" end_char="517">mes</TOKEN>
<TOKEN id="token-3-55" pos="word" morph="none" start_char="519" end_char="520">de</TOKEN>
<TOKEN id="token-3-56" pos="word" morph="none" start_char="522" end_char="527">agosto</TOKEN>
<TOKEN id="token-3-57" pos="punct" morph="none" start_char="528" end_char="528">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="531" end_char="826">
<ORIGINAL_TEXT>Una afirmación que realizan tras el análisis de las imágenes captadas por satélites de los aparcamientos de los principales centros hospitalarios de metrópoli china, además del incremento de búsquedas en internet relacionadas con los síntomas que ahora sabemos que son atribuibles al coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="531" end_char="533">Una</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="535" end_char="544">afirmación</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="546" end_char="548">que</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="550" end_char="557">realizan</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="559" end_char="562">tras</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="564" end_char="565">el</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="567" end_char="574">análisis</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="576" end_char="577">de</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="579" end_char="581">las</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="583" end_char="590">imágenes</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="592" end_char="599">captadas</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="601" end_char="603">por</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="605" end_char="613">satélites</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="615" end_char="616">de</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="618" end_char="620">los</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="622" end_char="634">aparcamientos</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="636" end_char="637">de</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="639" end_char="641">los</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="643" end_char="653">principales</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="655" end_char="661">centros</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="663" end_char="675">hospitalarios</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="677" end_char="678">de</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="680" end_char="688">metrópoli</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="690" end_char="694">china</TOKEN>
<TOKEN id="token-4-24" pos="punct" morph="none" start_char="695" end_char="695">,</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="697" end_char="702">además</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="704" end_char="706">del</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="708" end_char="717">incremento</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="719" end_char="720">de</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="722" end_char="730">búsquedas</TOKEN>
<TOKEN id="token-4-30" pos="word" morph="none" start_char="732" end_char="733">en</TOKEN>
<TOKEN id="token-4-31" pos="word" morph="none" start_char="735" end_char="742">internet</TOKEN>
<TOKEN id="token-4-32" pos="word" morph="none" start_char="744" end_char="755">relacionadas</TOKEN>
<TOKEN id="token-4-33" pos="word" morph="none" start_char="757" end_char="759">con</TOKEN>
<TOKEN id="token-4-34" pos="word" morph="none" start_char="761" end_char="763">los</TOKEN>
<TOKEN id="token-4-35" pos="word" morph="none" start_char="765" end_char="772">síntomas</TOKEN>
<TOKEN id="token-4-36" pos="word" morph="none" start_char="774" end_char="776">que</TOKEN>
<TOKEN id="token-4-37" pos="word" morph="none" start_char="778" end_char="782">ahora</TOKEN>
<TOKEN id="token-4-38" pos="word" morph="none" start_char="784" end_char="790">sabemos</TOKEN>
<TOKEN id="token-4-39" pos="word" morph="none" start_char="792" end_char="794">que</TOKEN>
<TOKEN id="token-4-40" pos="word" morph="none" start_char="796" end_char="798">son</TOKEN>
<TOKEN id="token-4-41" pos="word" morph="none" start_char="800" end_char="810">atribuibles</TOKEN>
<TOKEN id="token-4-42" pos="word" morph="none" start_char="812" end_char="813">al</TOKEN>
<TOKEN id="token-4-43" pos="word" morph="none" start_char="815" end_char="825">coronavirus</TOKEN>
<TOKEN id="token-4-44" pos="punct" morph="none" start_char="826" end_char="826">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="830" end_char="1039">
<ORIGINAL_TEXT>El pasado mes de agosto se produjo un incremento de las visitas a los centros hospitalarios, con una especial concentración entre los meses de septiembre y octubre, culminando con un pico en el mes de diciembre</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="830" end_char="831">El</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="833" end_char="838">pasado</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="840" end_char="842">mes</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="844" end_char="845">de</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="847" end_char="852">agosto</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="854" end_char="855">se</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="857" end_char="863">produjo</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="865" end_char="866">un</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="868" end_char="877">incremento</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="879" end_char="880">de</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="882" end_char="884">las</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="886" end_char="892">visitas</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="894" end_char="894">a</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="896" end_char="898">los</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="900" end_char="906">centros</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="908" end_char="920">hospitalarios</TOKEN>
<TOKEN id="token-5-16" pos="punct" morph="none" start_char="921" end_char="921">,</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="923" end_char="925">con</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="927" end_char="929">una</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="931" end_char="938">especial</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="940" end_char="952">concentración</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="954" end_char="958">entre</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="960" end_char="962">los</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="964" end_char="968">meses</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="970" end_char="971">de</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="973" end_char="982">septiembre</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="984" end_char="984">y</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="986" end_char="992">octubre</TOKEN>
<TOKEN id="token-5-28" pos="punct" morph="none" start_char="993" end_char="993">,</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="995" end_char="1004">culminando</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="1006" end_char="1008">con</TOKEN>
<TOKEN id="token-5-31" pos="word" morph="none" start_char="1010" end_char="1011">un</TOKEN>
<TOKEN id="token-5-32" pos="word" morph="none" start_char="1013" end_char="1016">pico</TOKEN>
<TOKEN id="token-5-33" pos="word" morph="none" start_char="1018" end_char="1019">en</TOKEN>
<TOKEN id="token-5-34" pos="word" morph="none" start_char="1021" end_char="1022">el</TOKEN>
<TOKEN id="token-5-35" pos="word" morph="none" start_char="1024" end_char="1026">mes</TOKEN>
<TOKEN id="token-5-36" pos="word" morph="none" start_char="1028" end_char="1029">de</TOKEN>
<TOKEN id="token-5-37" pos="word" morph="none" start_char="1031" end_char="1039">diciembre</TOKEN>
</SEG>
<SEG id="segment-6" start_char="1044" end_char="1182">
<ORIGINAL_TEXT>En base a estos análisis los investigadores apuntan a que el virus pudo estar circulando meses antes de la aparición de los primeros casos.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="1044" end_char="1045">En</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="1047" end_char="1050">base</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="1052" end_char="1052">a</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="1054" end_char="1058">estos</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="1060" end_char="1067">análisis</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="1069" end_char="1071">los</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="1073" end_char="1086">investigadores</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="1088" end_char="1094">apuntan</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="1096" end_char="1096">a</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="1098" end_char="1100">que</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="1102" end_char="1103">el</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="1105" end_char="1109">virus</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="1111" end_char="1114">pudo</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="1116" end_char="1120">estar</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="1122" end_char="1131">circulando</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="1133" end_char="1137">meses</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="1139" end_char="1143">antes</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="1145" end_char="1146">de</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="1148" end_char="1149">la</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="1151" end_char="1159">aparición</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="1161" end_char="1162">de</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="1164" end_char="1166">los</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="1168" end_char="1175">primeros</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="1177" end_char="1181">casos</TOKEN>
<TOKEN id="token-6-24" pos="punct" morph="none" start_char="1182" end_char="1182">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="1184" end_char="1443">
<ORIGINAL_TEXT>En este sentido indican que, de confirmarse estos hallazgos, el "mercado húmedo" considerado como el origen de la actual pandemia, únicamente habría sido el inicio de un brote puesto que el virus ya se encontraba en movimiento por la ciudad mucho tiempo antes.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="1184" end_char="1185">En</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="1187" end_char="1190">este</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="1192" end_char="1198">sentido</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="1200" end_char="1206">indican</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="1208" end_char="1210">que</TOKEN>
<TOKEN id="token-7-5" pos="punct" morph="none" start_char="1211" end_char="1211">,</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="1213" end_char="1214">de</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="1216" end_char="1226">confirmarse</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="1228" end_char="1232">estos</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="1234" end_char="1242">hallazgos</TOKEN>
<TOKEN id="token-7-10" pos="punct" morph="none" start_char="1243" end_char="1243">,</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="1245" end_char="1246">el</TOKEN>
<TOKEN id="token-7-12" pos="punct" morph="none" start_char="1248" end_char="1248">"</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="1249" end_char="1255">mercado</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="1257" end_char="1262">húmedo</TOKEN>
<TOKEN id="token-7-15" pos="punct" morph="none" start_char="1263" end_char="1263">"</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="1265" end_char="1275">considerado</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="1277" end_char="1280">como</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="1282" end_char="1283">el</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="1285" end_char="1290">origen</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="1292" end_char="1293">de</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="1295" end_char="1296">la</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="1298" end_char="1303">actual</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="1305" end_char="1312">pandemia</TOKEN>
<TOKEN id="token-7-24" pos="punct" morph="none" start_char="1313" end_char="1313">,</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="1315" end_char="1324">únicamente</TOKEN>
<TOKEN id="token-7-26" pos="word" morph="none" start_char="1326" end_char="1331">habría</TOKEN>
<TOKEN id="token-7-27" pos="word" morph="none" start_char="1333" end_char="1336">sido</TOKEN>
<TOKEN id="token-7-28" pos="word" morph="none" start_char="1338" end_char="1339">el</TOKEN>
<TOKEN id="token-7-29" pos="word" morph="none" start_char="1341" end_char="1346">inicio</TOKEN>
<TOKEN id="token-7-30" pos="word" morph="none" start_char="1348" end_char="1349">de</TOKEN>
<TOKEN id="token-7-31" pos="word" morph="none" start_char="1351" end_char="1352">un</TOKEN>
<TOKEN id="token-7-32" pos="word" morph="none" start_char="1354" end_char="1358">brote</TOKEN>
<TOKEN id="token-7-33" pos="word" morph="none" start_char="1360" end_char="1365">puesto</TOKEN>
<TOKEN id="token-7-34" pos="word" morph="none" start_char="1367" end_char="1369">que</TOKEN>
<TOKEN id="token-7-35" pos="word" morph="none" start_char="1371" end_char="1372">el</TOKEN>
<TOKEN id="token-7-36" pos="word" morph="none" start_char="1374" end_char="1378">virus</TOKEN>
<TOKEN id="token-7-37" pos="word" morph="none" start_char="1380" end_char="1381">ya</TOKEN>
<TOKEN id="token-7-38" pos="word" morph="none" start_char="1383" end_char="1384">se</TOKEN>
<TOKEN id="token-7-39" pos="word" morph="none" start_char="1386" end_char="1395">encontraba</TOKEN>
<TOKEN id="token-7-40" pos="word" morph="none" start_char="1397" end_char="1398">en</TOKEN>
<TOKEN id="token-7-41" pos="word" morph="none" start_char="1400" end_char="1409">movimiento</TOKEN>
<TOKEN id="token-7-42" pos="word" morph="none" start_char="1411" end_char="1413">por</TOKEN>
<TOKEN id="token-7-43" pos="word" morph="none" start_char="1415" end_char="1416">la</TOKEN>
<TOKEN id="token-7-44" pos="word" morph="none" start_char="1418" end_char="1423">ciudad</TOKEN>
<TOKEN id="token-7-45" pos="word" morph="none" start_char="1425" end_char="1429">mucho</TOKEN>
<TOKEN id="token-7-46" pos="word" morph="none" start_char="1431" end_char="1436">tiempo</TOKEN>
<TOKEN id="token-7-47" pos="word" morph="none" start_char="1438" end_char="1442">antes</TOKEN>
<TOKEN id="token-7-48" pos="punct" morph="none" start_char="1443" end_char="1443">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1446" end_char="1735">
<ORIGINAL_TEXT>La investigación en base a las imágenes captadas por satélite revela que desde el pasado mes de agosto se produjo un incremento de las visitas a los centros hospitalarios, con una especial concentración entre los meses de septiembre y octubre, culminando con un pico en el mes de diciembre.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1446" end_char="1447">La</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1449" end_char="1461">investigación</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1463" end_char="1464">en</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1466" end_char="1469">base</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1471" end_char="1471">a</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1473" end_char="1475">las</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1477" end_char="1484">imágenes</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1486" end_char="1493">captadas</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1495" end_char="1497">por</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1499" end_char="1506">satélite</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1508" end_char="1513">revela</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1515" end_char="1517">que</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1519" end_char="1523">desde</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1525" end_char="1526">el</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1528" end_char="1533">pasado</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1535" end_char="1537">mes</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1539" end_char="1540">de</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1542" end_char="1547">agosto</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1549" end_char="1550">se</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1552" end_char="1558">produjo</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="1560" end_char="1561">un</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="1563" end_char="1572">incremento</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="1574" end_char="1575">de</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="1577" end_char="1579">las</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="1581" end_char="1587">visitas</TOKEN>
<TOKEN id="token-8-25" pos="word" morph="none" start_char="1589" end_char="1589">a</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="1591" end_char="1593">los</TOKEN>
<TOKEN id="token-8-27" pos="word" morph="none" start_char="1595" end_char="1601">centros</TOKEN>
<TOKEN id="token-8-28" pos="word" morph="none" start_char="1603" end_char="1615">hospitalarios</TOKEN>
<TOKEN id="token-8-29" pos="punct" morph="none" start_char="1616" end_char="1616">,</TOKEN>
<TOKEN id="token-8-30" pos="word" morph="none" start_char="1618" end_char="1620">con</TOKEN>
<TOKEN id="token-8-31" pos="word" morph="none" start_char="1622" end_char="1624">una</TOKEN>
<TOKEN id="token-8-32" pos="word" morph="none" start_char="1626" end_char="1633">especial</TOKEN>
<TOKEN id="token-8-33" pos="word" morph="none" start_char="1635" end_char="1647">concentración</TOKEN>
<TOKEN id="token-8-34" pos="word" morph="none" start_char="1649" end_char="1653">entre</TOKEN>
<TOKEN id="token-8-35" pos="word" morph="none" start_char="1655" end_char="1657">los</TOKEN>
<TOKEN id="token-8-36" pos="word" morph="none" start_char="1659" end_char="1663">meses</TOKEN>
<TOKEN id="token-8-37" pos="word" morph="none" start_char="1665" end_char="1666">de</TOKEN>
<TOKEN id="token-8-38" pos="word" morph="none" start_char="1668" end_char="1677">septiembre</TOKEN>
<TOKEN id="token-8-39" pos="word" morph="none" start_char="1679" end_char="1679">y</TOKEN>
<TOKEN id="token-8-40" pos="word" morph="none" start_char="1681" end_char="1687">octubre</TOKEN>
<TOKEN id="token-8-41" pos="punct" morph="none" start_char="1688" end_char="1688">,</TOKEN>
<TOKEN id="token-8-42" pos="word" morph="none" start_char="1690" end_char="1699">culminando</TOKEN>
<TOKEN id="token-8-43" pos="word" morph="none" start_char="1701" end_char="1703">con</TOKEN>
<TOKEN id="token-8-44" pos="word" morph="none" start_char="1705" end_char="1706">un</TOKEN>
<TOKEN id="token-8-45" pos="word" morph="none" start_char="1708" end_char="1711">pico</TOKEN>
<TOKEN id="token-8-46" pos="word" morph="none" start_char="1713" end_char="1714">en</TOKEN>
<TOKEN id="token-8-47" pos="word" morph="none" start_char="1716" end_char="1717">el</TOKEN>
<TOKEN id="token-8-48" pos="word" morph="none" start_char="1719" end_char="1721">mes</TOKEN>
<TOKEN id="token-8-49" pos="word" morph="none" start_char="1723" end_char="1724">de</TOKEN>
<TOKEN id="token-8-50" pos="word" morph="none" start_char="1726" end_char="1734">diciembre</TOKEN>
<TOKEN id="token-8-51" pos="punct" morph="none" start_char="1735" end_char="1735">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1737" end_char="1879">
<ORIGINAL_TEXT>En este mismo periodo de tiempo se dispararon las búsquedas en la red de redes sobre síntomas asociados a la Covid-19 como la tos y la diarrea.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1737" end_char="1738">En</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1740" end_char="1743">este</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1745" end_char="1749">mismo</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1751" end_char="1757">periodo</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1759" end_char="1760">de</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1762" end_char="1767">tiempo</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1769" end_char="1770">se</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1772" end_char="1781">dispararon</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1783" end_char="1785">las</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1787" end_char="1795">búsquedas</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1797" end_char="1798">en</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1800" end_char="1801">la</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1803" end_char="1805">red</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1807" end_char="1808">de</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1810" end_char="1814">redes</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1816" end_char="1820">sobre</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1822" end_char="1829">síntomas</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1831" end_char="1839">asociados</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1841" end_char="1841">a</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1843" end_char="1844">la</TOKEN>
<TOKEN id="token-9-20" pos="unknown" morph="none" start_char="1846" end_char="1853">Covid-19</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1855" end_char="1858">como</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1860" end_char="1861">la</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1863" end_char="1865">tos</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1867" end_char="1867">y</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1869" end_char="1870">la</TOKEN>
<TOKEN id="token-9-26" pos="word" morph="none" start_char="1872" end_char="1878">diarrea</TOKEN>
<TOKEN id="token-9-27" pos="punct" morph="none" start_char="1879" end_char="1879">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1882" end_char="2145">
<ORIGINAL_TEXT>Los investigadores recalcan que estos hallazgos no pueden relacionarse de forma directa con el coronavirus, pero si ayudan a reforzar otros estudios que intentan demostrar que el coronavirus ya circulaba en Wuhan tiempo antes de la detección de los primeros casos.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1882" end_char="1884">Los</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1886" end_char="1899">investigadores</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1901" end_char="1908">recalcan</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1910" end_char="1912">que</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1914" end_char="1918">estos</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1920" end_char="1928">hallazgos</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1930" end_char="1931">no</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1933" end_char="1938">pueden</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1940" end_char="1951">relacionarse</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1953" end_char="1954">de</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1956" end_char="1960">forma</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1962" end_char="1968">directa</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1970" end_char="1972">con</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1974" end_char="1975">el</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1977" end_char="1987">coronavirus</TOKEN>
<TOKEN id="token-10-15" pos="punct" morph="none" start_char="1988" end_char="1988">,</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1990" end_char="1993">pero</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1995" end_char="1996">si</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1998" end_char="2003">ayudan</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="2005" end_char="2005">a</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="2007" end_char="2014">reforzar</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="2016" end_char="2020">otros</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="2022" end_char="2029">estudios</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="2031" end_char="2033">que</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="2035" end_char="2042">intentan</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="2044" end_char="2052">demostrar</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="2054" end_char="2056">que</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="2058" end_char="2059">el</TOKEN>
<TOKEN id="token-10-28" pos="word" morph="none" start_char="2061" end_char="2071">coronavirus</TOKEN>
<TOKEN id="token-10-29" pos="word" morph="none" start_char="2073" end_char="2074">ya</TOKEN>
<TOKEN id="token-10-30" pos="word" morph="none" start_char="2076" end_char="2084">circulaba</TOKEN>
<TOKEN id="token-10-31" pos="word" morph="none" start_char="2086" end_char="2087">en</TOKEN>
<TOKEN id="token-10-32" pos="word" morph="none" start_char="2089" end_char="2093">Wuhan</TOKEN>
<TOKEN id="token-10-33" pos="word" morph="none" start_char="2095" end_char="2100">tiempo</TOKEN>
<TOKEN id="token-10-34" pos="word" morph="none" start_char="2102" end_char="2106">antes</TOKEN>
<TOKEN id="token-10-35" pos="word" morph="none" start_char="2108" end_char="2109">de</TOKEN>
<TOKEN id="token-10-36" pos="word" morph="none" start_char="2111" end_char="2112">la</TOKEN>
<TOKEN id="token-10-37" pos="word" morph="none" start_char="2114" end_char="2122">detección</TOKEN>
<TOKEN id="token-10-38" pos="word" morph="none" start_char="2124" end_char="2125">de</TOKEN>
<TOKEN id="token-10-39" pos="word" morph="none" start_char="2127" end_char="2129">los</TOKEN>
<TOKEN id="token-10-40" pos="word" morph="none" start_char="2131" end_char="2138">primeros</TOKEN>
<TOKEN id="token-10-41" pos="word" morph="none" start_char="2140" end_char="2144">casos</TOKEN>
<TOKEN id="token-10-42" pos="punct" morph="none" start_char="2145" end_char="2145">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="2148" end_char="2192">
<ORIGINAL_TEXT>Porque salud necesitamos todos... ConSalud.es</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="2148" end_char="2153">Porque</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="2155" end_char="2159">salud</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="2161" end_char="2171">necesitamos</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="2173" end_char="2177">todos</TOKEN>
<TOKEN id="token-11-4" pos="punct" morph="none" start_char="2178" end_char="2180">...</TOKEN>
<TOKEN id="token-11-5" pos="unknown" morph="none" start_char="2182" end_char="2192">ConSalud.es</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
