<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C049DWU" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="7778" raw_text_md5="95d0ec841b4333e2a482645bebc489c7">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="70">
<ORIGINAL_TEXT>Luc Montaigner, Nobel de Medicina, el virus se creo en un laboratorio.</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="3">Luc</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="5" end_char="14">Montaigner</TOKEN>
<TOKEN id="token-0-2" pos="punct" morph="none" start_char="15" end_char="15">,</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="17" end_char="21">Nobel</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="23" end_char="24">de</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="26" end_char="33">Medicina</TOKEN>
<TOKEN id="token-0-6" pos="punct" morph="none" start_char="34" end_char="34">,</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="36" end_char="37">el</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="39" end_char="43">virus</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="45" end_char="46">se</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="48" end_char="51">creo</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="53" end_char="54">en</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="56" end_char="57">un</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="59" end_char="69">laboratorio</TOKEN>
<TOKEN id="token-0-14" pos="punct" morph="none" start_char="70" end_char="70">.</TOKEN>
</SEG>
<SEG id="segment-1" start_char="74" end_char="126">
<ORIGINAL_TEXT>http://spanews24h.com/luc-montagnier...n-adn-del-vih/</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="url" morph="none" start_char="74" end_char="126">http://spanews24h.com/luc-montagnier...n-adn-del-vih/</TOKEN>
</SEG>
<SEG id="segment-2" start_char="129" end_char="456">
<ORIGINAL_TEXT>A medida que el mundo se enfrenta a la pandemia de Covid-19 y los científicos intentan encontrar una vacuna para erradicar el virus, Luc Montagnier, virólogo francés y ganador del Premio Nobel de medicina en 2008 después del descubrimiento del SIDA, acaba de presentar una hipótesis controvertida sobre el origen del SARS-CoV-2.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="129" end_char="129">A</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="131" end_char="136">medida</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="138" end_char="140">que</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="142" end_char="143">el</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="145" end_char="149">mundo</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="151" end_char="152">se</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="154" end_char="161">enfrenta</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="163" end_char="163">a</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="165" end_char="166">la</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="168" end_char="175">pandemia</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="177" end_char="178">de</TOKEN>
<TOKEN id="token-2-11" pos="unknown" morph="none" start_char="180" end_char="187">Covid-19</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="189" end_char="189">y</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="191" end_char="193">los</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="195" end_char="205">científicos</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="207" end_char="214">intentan</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="216" end_char="224">encontrar</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="226" end_char="228">una</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="230" end_char="235">vacuna</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="237" end_char="240">para</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="242" end_char="250">erradicar</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="252" end_char="253">el</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="255" end_char="259">virus</TOKEN>
<TOKEN id="token-2-23" pos="punct" morph="none" start_char="260" end_char="260">,</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="262" end_char="264">Luc</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="266" end_char="275">Montagnier</TOKEN>
<TOKEN id="token-2-26" pos="punct" morph="none" start_char="276" end_char="276">,</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="278" end_char="285">virólogo</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="287" end_char="293">francés</TOKEN>
<TOKEN id="token-2-29" pos="word" morph="none" start_char="295" end_char="295">y</TOKEN>
<TOKEN id="token-2-30" pos="word" morph="none" start_char="297" end_char="303">ganador</TOKEN>
<TOKEN id="token-2-31" pos="word" morph="none" start_char="305" end_char="307">del</TOKEN>
<TOKEN id="token-2-32" pos="word" morph="none" start_char="309" end_char="314">Premio</TOKEN>
<TOKEN id="token-2-33" pos="word" morph="none" start_char="316" end_char="320">Nobel</TOKEN>
<TOKEN id="token-2-34" pos="word" morph="none" start_char="322" end_char="323">de</TOKEN>
<TOKEN id="token-2-35" pos="word" morph="none" start_char="325" end_char="332">medicina</TOKEN>
<TOKEN id="token-2-36" pos="word" morph="none" start_char="334" end_char="335">en</TOKEN>
<TOKEN id="token-2-37" pos="word" morph="none" start_char="337" end_char="340">2008</TOKEN>
<TOKEN id="token-2-38" pos="word" morph="none" start_char="342" end_char="348">después</TOKEN>
<TOKEN id="token-2-39" pos="word" morph="none" start_char="350" end_char="352">del</TOKEN>
<TOKEN id="token-2-40" pos="word" morph="none" start_char="354" end_char="367">descubrimiento</TOKEN>
<TOKEN id="token-2-41" pos="word" morph="none" start_char="369" end_char="371">del</TOKEN>
<TOKEN id="token-2-42" pos="word" morph="none" start_char="373" end_char="376">SIDA</TOKEN>
<TOKEN id="token-2-43" pos="punct" morph="none" start_char="377" end_char="377">,</TOKEN>
<TOKEN id="token-2-44" pos="word" morph="none" start_char="379" end_char="383">acaba</TOKEN>
<TOKEN id="token-2-45" pos="word" morph="none" start_char="385" end_char="386">de</TOKEN>
<TOKEN id="token-2-46" pos="word" morph="none" start_char="388" end_char="396">presentar</TOKEN>
<TOKEN id="token-2-47" pos="word" morph="none" start_char="398" end_char="400">una</TOKEN>
<TOKEN id="token-2-48" pos="word" morph="none" start_char="402" end_char="410">hipótesis</TOKEN>
<TOKEN id="token-2-49" pos="word" morph="none" start_char="412" end_char="424">controvertida</TOKEN>
<TOKEN id="token-2-50" pos="word" morph="none" start_char="426" end_char="430">sobre</TOKEN>
<TOKEN id="token-2-51" pos="word" morph="none" start_char="432" end_char="433">el</TOKEN>
<TOKEN id="token-2-52" pos="word" morph="none" start_char="435" end_char="440">origen</TOKEN>
<TOKEN id="token-2-53" pos="word" morph="none" start_char="442" end_char="444">del</TOKEN>
<TOKEN id="token-2-54" pos="unknown" morph="none" start_char="446" end_char="455">SARS-CoV-2</TOKEN>
<TOKEN id="token-2-55" pos="punct" morph="none" start_char="456" end_char="456">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="459" end_char="484">
<ORIGINAL_TEXT>Entrevistado por el sitio.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="459" end_char="470">Entrevistado</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="472" end_char="474">por</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="476" end_char="477">el</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="479" end_char="483">sitio</TOKEN>
<TOKEN id="token-3-4" pos="punct" morph="none" start_char="484" end_char="484">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="487" end_char="502">
<ORIGINAL_TEXT>¿Por qué doctor?</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="punct" morph="none" start_char="487" end_char="487">¿</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="488" end_char="490">Por</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="492" end_char="494">qué</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="496" end_char="501">doctor</TOKEN>
<TOKEN id="token-4-4" pos="punct" morph="none" start_char="502" end_char="502">?</TOKEN>
</SEG>
<SEG id="segment-5" start_char="505" end_char="596">
<ORIGINAL_TEXT>Este jueves 16 de abril, el profesor francés expresó sus dudas sobre el origen del Covid-19.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="505" end_char="508">Este</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="510" end_char="515">jueves</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="517" end_char="518">16</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="520" end_char="521">de</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="523" end_char="527">abril</TOKEN>
<TOKEN id="token-5-5" pos="punct" morph="none" start_char="528" end_char="528">,</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="530" end_char="531">el</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="533" end_char="540">profesor</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="542" end_char="548">francés</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="550" end_char="556">expresó</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="558" end_char="560">sus</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="562" end_char="566">dudas</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="568" end_char="572">sobre</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="574" end_char="575">el</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="577" end_char="582">origen</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="584" end_char="586">del</TOKEN>
<TOKEN id="token-5-16" pos="unknown" morph="none" start_char="588" end_char="595">Covid-19</TOKEN>
<TOKEN id="token-5-17" pos="punct" morph="none" start_char="596" end_char="596">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="598" end_char="675">
<ORIGINAL_TEXT>Según él, la aparición del virus en un mercado de vida silvestre en Wuhan es "</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="598" end_char="602">Según</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="604" end_char="605">él</TOKEN>
<TOKEN id="token-6-2" pos="punct" morph="none" start_char="606" end_char="606">,</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="608" end_char="609">la</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="611" end_char="619">aparición</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="621" end_char="623">del</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="625" end_char="629">virus</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="631" end_char="632">en</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="634" end_char="635">un</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="637" end_char="643">mercado</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="645" end_char="646">de</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="648" end_char="651">vida</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="653" end_char="661">silvestre</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="663" end_char="664">en</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="666" end_char="670">Wuhan</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="672" end_char="673">es</TOKEN>
<TOKEN id="token-6-16" pos="punct" morph="none" start_char="675" end_char="675">"</TOKEN>
</SEG>
<SEG id="segment-7" start_char="678" end_char="694">
<ORIGINAL_TEXT>una bella leyenda</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="678" end_char="680">una</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="682" end_char="686">bella</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="688" end_char="694">leyenda</TOKEN>
</SEG>
<SEG id="segment-8" start_char="697" end_char="699">
<ORIGINAL_TEXT>"y"</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="punct" morph="none" start_char="697" end_char="697">"</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="698" end_char="698">y</TOKEN>
<TOKEN id="token-8-2" pos="punct" morph="none" start_char="699" end_char="699">"</TOKEN>
</SEG>
<SEG id="segment-9" start_char="702" end_char="714">
<ORIGINAL_TEXT>no es posible</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="702" end_char="703">no</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="705" end_char="706">es</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="708" end_char="714">posible</TOKEN>
</SEG>
<SEG id="segment-10" start_char="717" end_char="718">
<ORIGINAL_TEXT>".</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="punct" morph="none" start_char="717" end_char="718">".</TOKEN>
</SEG>
<SEG id="segment-11" start_char="720" end_char="744">
<ORIGINAL_TEXT>El dice que el Covid-19 "</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="720" end_char="721">El</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="723" end_char="726">dice</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="728" end_char="730">que</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="732" end_char="733">el</TOKEN>
<TOKEN id="token-11-4" pos="unknown" morph="none" start_char="735" end_char="742">Covid-19</TOKEN>
<TOKEN id="token-11-5" pos="punct" morph="none" start_char="744" end_char="744">"</TOKEN>
</SEG>
<SEG id="segment-12" start_char="747" end_char="777">
<ORIGINAL_TEXT>sale de un laboratorio de Wuhan</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="747" end_char="750">sale</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="752" end_char="753">de</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="755" end_char="756">un</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="758" end_char="768">laboratorio</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="770" end_char="771">de</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="773" end_char="777">Wuhan</TOKEN>
</SEG>
<SEG id="segment-13" start_char="780" end_char="781">
<ORIGINAL_TEXT>".</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="punct" morph="none" start_char="780" end_char="781">".</TOKEN>
</SEG>
<SEG id="segment-14" start_char="783" end_char="820">
<ORIGINAL_TEXT>Luc Montagnier continúa diciendo que "</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="783" end_char="785">Luc</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="787" end_char="796">Montagnier</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="798" end_char="805">continúa</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="807" end_char="814">diciendo</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="816" end_char="818">que</TOKEN>
<TOKEN id="token-14-5" pos="punct" morph="none" start_char="820" end_char="820">"</TOKEN>
</SEG>
<SEG id="segment-15" start_char="823" end_char="937">
<ORIGINAL_TEXT>el laboratorio de la ciudad de Wuhan se ha especializado en estos coronavirus desde principios de la década de 2000</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="823" end_char="824">el</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="826" end_char="836">laboratorio</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="838" end_char="839">de</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="841" end_char="842">la</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="844" end_char="849">ciudad</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="851" end_char="852">de</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="854" end_char="858">Wuhan</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="860" end_char="861">se</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="863" end_char="864">ha</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="866" end_char="878">especializado</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="880" end_char="881">en</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="883" end_char="887">estos</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="889" end_char="899">coronavirus</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="901" end_char="905">desde</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="907" end_char="916">principios</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="918" end_char="919">de</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="921" end_char="922">la</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="924" end_char="929">década</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="931" end_char="932">de</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="934" end_char="937">2000</TOKEN>
</SEG>
<SEG id="segment-16" start_char="940" end_char="948">
<ORIGINAL_TEXT>"y posee"</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="punct" morph="none" start_char="940" end_char="940">"</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="941" end_char="941">y</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="943" end_char="947">posee</TOKEN>
<TOKEN id="token-16-3" pos="punct" morph="none" start_char="948" end_char="948">"</TOKEN>
</SEG>
<SEG id="segment-17" start_char="951" end_char="974">
<ORIGINAL_TEXT>experiencia en esta área</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="951" end_char="961">experiencia</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="963" end_char="964">en</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="966" end_char="969">esta</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="971" end_char="974">área</TOKEN>
</SEG>
<SEG id="segment-18" start_char="977" end_char="978">
<ORIGINAL_TEXT>".</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="punct" morph="none" start_char="977" end_char="978">".</TOKEN>
</SEG>
<SEG id="segment-19" start_char="981" end_char="1223">
<ORIGINAL_TEXT>Frente a sus comentarios, su interlocutor le pregunta si los rastros de VIH encontrados en el coronavirus no son simplemente Una mutación natural del virus en el cuerpo de un paciente con SIDA.. Luc Montagnier responde negativamente y explica:</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="981" end_char="986">Frente</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="988" end_char="988">a</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="990" end_char="992">sus</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="994" end_char="1004">comentarios</TOKEN>
<TOKEN id="token-19-4" pos="punct" morph="none" start_char="1005" end_char="1005">,</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="1007" end_char="1008">su</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="1010" end_char="1021">interlocutor</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="1023" end_char="1024">le</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="1026" end_char="1033">pregunta</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="1035" end_char="1036">si</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="1038" end_char="1040">los</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="1042" end_char="1048">rastros</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="1050" end_char="1051">de</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="1053" end_char="1055">VIH</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="1057" end_char="1067">encontrados</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="1069" end_char="1070">en</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="1072" end_char="1073">el</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="1075" end_char="1085">coronavirus</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="1087" end_char="1088">no</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="1090" end_char="1092">son</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="1094" end_char="1104">simplemente</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="1106" end_char="1108">Una</TOKEN>
<TOKEN id="token-19-22" pos="word" morph="none" start_char="1110" end_char="1117">mutación</TOKEN>
<TOKEN id="token-19-23" pos="word" morph="none" start_char="1119" end_char="1125">natural</TOKEN>
<TOKEN id="token-19-24" pos="word" morph="none" start_char="1127" end_char="1129">del</TOKEN>
<TOKEN id="token-19-25" pos="word" morph="none" start_char="1131" end_char="1135">virus</TOKEN>
<TOKEN id="token-19-26" pos="word" morph="none" start_char="1137" end_char="1138">en</TOKEN>
<TOKEN id="token-19-27" pos="word" morph="none" start_char="1140" end_char="1141">el</TOKEN>
<TOKEN id="token-19-28" pos="word" morph="none" start_char="1143" end_char="1148">cuerpo</TOKEN>
<TOKEN id="token-19-29" pos="word" morph="none" start_char="1150" end_char="1151">de</TOKEN>
<TOKEN id="token-19-30" pos="word" morph="none" start_char="1153" end_char="1154">un</TOKEN>
<TOKEN id="token-19-31" pos="word" morph="none" start_char="1156" end_char="1163">paciente</TOKEN>
<TOKEN id="token-19-32" pos="word" morph="none" start_char="1165" end_char="1167">con</TOKEN>
<TOKEN id="token-19-33" pos="word" morph="none" start_char="1169" end_char="1172">SIDA</TOKEN>
<TOKEN id="token-19-34" pos="punct" morph="none" start_char="1173" end_char="1174">..</TOKEN>
<TOKEN id="token-19-35" pos="word" morph="none" start_char="1176" end_char="1178">Luc</TOKEN>
<TOKEN id="token-19-36" pos="word" morph="none" start_char="1180" end_char="1189">Montagnier</TOKEN>
<TOKEN id="token-19-37" pos="word" morph="none" start_char="1191" end_char="1198">responde</TOKEN>
<TOKEN id="token-19-38" pos="word" morph="none" start_char="1200" end_char="1212">negativamente</TOKEN>
<TOKEN id="token-19-39" pos="word" morph="none" start_char="1214" end_char="1214">y</TOKEN>
<TOKEN id="token-19-40" pos="word" morph="none" start_char="1216" end_char="1222">explica</TOKEN>
<TOKEN id="token-19-41" pos="punct" morph="none" start_char="1223" end_char="1223">:</TOKEN>
</SEG>
<SEG id="segment-20" start_char="1226" end_char="1369">
<ORIGINAL_TEXT>Para insertar una secuencia de VIH en el genoma necesita herramientas moleculares, no es el paciente quien lo hará, es el hombre de laboratorio.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="1226" end_char="1229">Para</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="1231" end_char="1238">insertar</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="1240" end_char="1242">una</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="1244" end_char="1252">secuencia</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="1254" end_char="1255">de</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="1257" end_char="1259">VIH</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="1261" end_char="1262">en</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="1264" end_char="1265">el</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="1267" end_char="1272">genoma</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="1274" end_char="1281">necesita</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="1283" end_char="1294">herramientas</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="1296" end_char="1306">moleculares</TOKEN>
<TOKEN id="token-20-12" pos="punct" morph="none" start_char="1307" end_char="1307">,</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="1309" end_char="1310">no</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="1312" end_char="1313">es</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="1315" end_char="1316">el</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="1318" end_char="1325">paciente</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="1327" end_char="1331">quien</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="1333" end_char="1334">lo</TOKEN>
<TOKEN id="token-20-19" pos="word" morph="none" start_char="1336" end_char="1339">hará</TOKEN>
<TOKEN id="token-20-20" pos="punct" morph="none" start_char="1340" end_char="1340">,</TOKEN>
<TOKEN id="token-20-21" pos="word" morph="none" start_char="1342" end_char="1343">es</TOKEN>
<TOKEN id="token-20-22" pos="word" morph="none" start_char="1345" end_char="1346">el</TOKEN>
<TOKEN id="token-20-23" pos="word" morph="none" start_char="1348" end_char="1353">hombre</TOKEN>
<TOKEN id="token-20-24" pos="word" morph="none" start_char="1355" end_char="1356">de</TOKEN>
<TOKEN id="token-20-25" pos="word" morph="none" start_char="1358" end_char="1368">laboratorio</TOKEN>
<TOKEN id="token-20-26" pos="punct" morph="none" start_char="1369" end_char="1369">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="1374" end_char="1456">
<ORIGINAL_TEXT>Unos dicen una cosa y otros otra, al final me creo más JL que a los demás, total...</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="1374" end_char="1377">Unos</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="1379" end_char="1383">dicen</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="1385" end_char="1387">una</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="1389" end_char="1392">cosa</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="1394" end_char="1394">y</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="1396" end_char="1400">otros</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="1402" end_char="1405">otra</TOKEN>
<TOKEN id="token-21-7" pos="punct" morph="none" start_char="1406" end_char="1406">,</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="1408" end_char="1409">al</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="1411" end_char="1415">final</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="1417" end_char="1418">me</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="1420" end_char="1423">creo</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="1425" end_char="1427">más</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="1429" end_char="1430">JL</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="1432" end_char="1434">que</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="1436" end_char="1436">a</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="1438" end_char="1440">los</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="1442" end_char="1446">demás</TOKEN>
<TOKEN id="token-21-18" pos="punct" morph="none" start_char="1447" end_char="1447">,</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="1449" end_char="1453">total</TOKEN>
<TOKEN id="token-21-20" pos="punct" morph="none" start_char="1454" end_char="1456">...</TOKEN>
</SEG>
<SEG id="segment-22" start_char="1462" end_char="1481">
<ORIGINAL_TEXT>Nos comen los chinos</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="1462" end_char="1464">Nos</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="1466" end_char="1470">comen</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="1472" end_char="1474">los</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="1476" end_char="1481">chinos</TOKEN>
</SEG>
<SEG id="segment-23" start_char="1487" end_char="1781">
<ORIGINAL_TEXT>Eso lo sabe todo el mundo, menos los periódicos y las teles que aún no están autorizados a informar al pueblo, como el avión iraní derribado y como cualquier noticia así importante que os dan que la tienes en internet 2 semanas antes, y la gente aún viendo los medios de desinformación oficiales</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="1487" end_char="1489">Eso</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="1491" end_char="1492">lo</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="1494" end_char="1497">sabe</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="1499" end_char="1502">todo</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="1504" end_char="1505">el</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="1507" end_char="1511">mundo</TOKEN>
<TOKEN id="token-23-6" pos="punct" morph="none" start_char="1512" end_char="1512">,</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="1514" end_char="1518">menos</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="1520" end_char="1522">los</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="1524" end_char="1533">periódicos</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="1535" end_char="1535">y</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="1537" end_char="1539">las</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="1541" end_char="1545">teles</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="1547" end_char="1549">que</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="1551" end_char="1553">aún</TOKEN>
<TOKEN id="token-23-15" pos="word" morph="none" start_char="1555" end_char="1556">no</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="1558" end_char="1562">están</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="1564" end_char="1574">autorizados</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="1576" end_char="1576">a</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="1578" end_char="1585">informar</TOKEN>
<TOKEN id="token-23-20" pos="word" morph="none" start_char="1587" end_char="1588">al</TOKEN>
<TOKEN id="token-23-21" pos="word" morph="none" start_char="1590" end_char="1595">pueblo</TOKEN>
<TOKEN id="token-23-22" pos="punct" morph="none" start_char="1596" end_char="1596">,</TOKEN>
<TOKEN id="token-23-23" pos="word" morph="none" start_char="1598" end_char="1601">como</TOKEN>
<TOKEN id="token-23-24" pos="word" morph="none" start_char="1603" end_char="1604">el</TOKEN>
<TOKEN id="token-23-25" pos="word" morph="none" start_char="1606" end_char="1610">avión</TOKEN>
<TOKEN id="token-23-26" pos="word" morph="none" start_char="1612" end_char="1616">iraní</TOKEN>
<TOKEN id="token-23-27" pos="word" morph="none" start_char="1618" end_char="1626">derribado</TOKEN>
<TOKEN id="token-23-28" pos="word" morph="none" start_char="1628" end_char="1628">y</TOKEN>
<TOKEN id="token-23-29" pos="word" morph="none" start_char="1630" end_char="1633">como</TOKEN>
<TOKEN id="token-23-30" pos="word" morph="none" start_char="1635" end_char="1643">cualquier</TOKEN>
<TOKEN id="token-23-31" pos="word" morph="none" start_char="1645" end_char="1651">noticia</TOKEN>
<TOKEN id="token-23-32" pos="word" morph="none" start_char="1653" end_char="1655">así</TOKEN>
<TOKEN id="token-23-33" pos="word" morph="none" start_char="1657" end_char="1666">importante</TOKEN>
<TOKEN id="token-23-34" pos="word" morph="none" start_char="1668" end_char="1670">que</TOKEN>
<TOKEN id="token-23-35" pos="word" morph="none" start_char="1672" end_char="1673">os</TOKEN>
<TOKEN id="token-23-36" pos="word" morph="none" start_char="1675" end_char="1677">dan</TOKEN>
<TOKEN id="token-23-37" pos="word" morph="none" start_char="1679" end_char="1681">que</TOKEN>
<TOKEN id="token-23-38" pos="word" morph="none" start_char="1683" end_char="1684">la</TOKEN>
<TOKEN id="token-23-39" pos="word" morph="none" start_char="1686" end_char="1691">tienes</TOKEN>
<TOKEN id="token-23-40" pos="word" morph="none" start_char="1693" end_char="1694">en</TOKEN>
<TOKEN id="token-23-41" pos="word" morph="none" start_char="1696" end_char="1703">internet</TOKEN>
<TOKEN id="token-23-42" pos="word" morph="none" start_char="1705" end_char="1705">2</TOKEN>
<TOKEN id="token-23-43" pos="word" morph="none" start_char="1707" end_char="1713">semanas</TOKEN>
<TOKEN id="token-23-44" pos="word" morph="none" start_char="1715" end_char="1719">antes</TOKEN>
<TOKEN id="token-23-45" pos="punct" morph="none" start_char="1720" end_char="1720">,</TOKEN>
<TOKEN id="token-23-46" pos="word" morph="none" start_char="1722" end_char="1722">y</TOKEN>
<TOKEN id="token-23-47" pos="word" morph="none" start_char="1724" end_char="1725">la</TOKEN>
<TOKEN id="token-23-48" pos="word" morph="none" start_char="1727" end_char="1731">gente</TOKEN>
<TOKEN id="token-23-49" pos="word" morph="none" start_char="1733" end_char="1735">aún</TOKEN>
<TOKEN id="token-23-50" pos="word" morph="none" start_char="1737" end_char="1742">viendo</TOKEN>
<TOKEN id="token-23-51" pos="word" morph="none" start_char="1744" end_char="1746">los</TOKEN>
<TOKEN id="token-23-52" pos="word" morph="none" start_char="1748" end_char="1753">medios</TOKEN>
<TOKEN id="token-23-53" pos="word" morph="none" start_char="1755" end_char="1756">de</TOKEN>
<TOKEN id="token-23-54" pos="word" morph="none" start_char="1758" end_char="1771">desinformación</TOKEN>
<TOKEN id="token-23-55" pos="word" morph="none" start_char="1773" end_char="1781">oficiales</TOKEN>
</SEG>
<SEG id="segment-24" start_char="1787" end_char="1816">
<ORIGINAL_TEXT>No sé si lo he entendido bien.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="1787" end_char="1788">No</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="1790" end_char="1791">sé</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="1793" end_char="1794">si</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="1796" end_char="1797">lo</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="1799" end_char="1800">he</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="1802" end_char="1810">entendido</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="1812" end_char="1815">bien</TOKEN>
<TOKEN id="token-24-7" pos="punct" morph="none" start_char="1816" end_char="1816">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="1818" end_char="1889">
<ORIGINAL_TEXT>¿Se supone que hay genes del virus del Sida que están en el coronarirus?</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="punct" morph="none" start_char="1818" end_char="1818">¿</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="1819" end_char="1820">Se</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="1822" end_char="1827">supone</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="1829" end_char="1831">que</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="1833" end_char="1835">hay</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="1837" end_char="1841">genes</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="1843" end_char="1845">del</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="1847" end_char="1851">virus</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="1853" end_char="1855">del</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="1857" end_char="1860">Sida</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="1862" end_char="1864">que</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="1866" end_char="1870">están</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="1872" end_char="1873">en</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="1875" end_char="1876">el</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="1878" end_char="1888">coronarirus</TOKEN>
<TOKEN id="token-25-15" pos="punct" morph="none" start_char="1889" end_char="1889">?</TOKEN>
</SEG>
<SEG id="segment-26" start_char="1895" end_char="2047">
<ORIGINAL_TEXT>y el gordo del Ferreras diciendo que trump se había inventado la noticia gogleando...y ahora resulta que lo ha dicho todo un premio nobel...vaia valía...</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="1895" end_char="1895">y</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="1897" end_char="1898">el</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="1900" end_char="1904">gordo</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="1906" end_char="1908">del</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="1910" end_char="1917">Ferreras</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="1919" end_char="1926">diciendo</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="1928" end_char="1930">que</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="1932" end_char="1936">trump</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="1938" end_char="1939">se</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="1941" end_char="1945">había</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="1947" end_char="1955">inventado</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="1957" end_char="1958">la</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="1960" end_char="1966">noticia</TOKEN>
<TOKEN id="token-26-13" pos="unknown" morph="none" start_char="1968" end_char="1980">gogleando...y</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="1982" end_char="1986">ahora</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="1988" end_char="1994">resulta</TOKEN>
<TOKEN id="token-26-16" pos="word" morph="none" start_char="1996" end_char="1998">que</TOKEN>
<TOKEN id="token-26-17" pos="word" morph="none" start_char="2000" end_char="2001">lo</TOKEN>
<TOKEN id="token-26-18" pos="word" morph="none" start_char="2003" end_char="2004">ha</TOKEN>
<TOKEN id="token-26-19" pos="word" morph="none" start_char="2006" end_char="2010">dicho</TOKEN>
<TOKEN id="token-26-20" pos="word" morph="none" start_char="2012" end_char="2015">todo</TOKEN>
<TOKEN id="token-26-21" pos="word" morph="none" start_char="2017" end_char="2018">un</TOKEN>
<TOKEN id="token-26-22" pos="word" morph="none" start_char="2020" end_char="2025">premio</TOKEN>
<TOKEN id="token-26-23" pos="unknown" morph="none" start_char="2027" end_char="2038">nobel...vaia</TOKEN>
<TOKEN id="token-26-24" pos="word" morph="none" start_char="2040" end_char="2044">valía</TOKEN>
<TOKEN id="token-26-25" pos="punct" morph="none" start_char="2045" end_char="2047">...</TOKEN>
</SEG>
<SEG id="segment-27" start_char="2053" end_char="2057">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="2053" end_char="2056">Cita</TOKEN>
<TOKEN id="token-27-1" pos="punct" morph="none" start_char="2057" end_char="2057">:</TOKEN>
</SEG>
<SEG id="segment-28" start_char="2062" end_char="2128">
<ORIGINAL_TEXT>Originalmente Escrito por Pauguiller No sé si lo he entendido bien.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="2062" end_char="2074">Originalmente</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="2076" end_char="2082">Escrito</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="2084" end_char="2086">por</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="2088" end_char="2097">Pauguiller</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="2099" end_char="2100">No</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="2102" end_char="2103">sé</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="2105" end_char="2106">si</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="2108" end_char="2109">lo</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="2111" end_char="2112">he</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="2114" end_char="2122">entendido</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="2124" end_char="2127">bien</TOKEN>
<TOKEN id="token-28-11" pos="punct" morph="none" start_char="2128" end_char="2128">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="2130" end_char="2201">
<ORIGINAL_TEXT>¿Se supone que hay genes del virus del Sida que están en el coronarirus?</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="punct" morph="none" start_char="2130" end_char="2130">¿</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="2131" end_char="2132">Se</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="2134" end_char="2139">supone</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="2141" end_char="2143">que</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="2145" end_char="2147">hay</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="2149" end_char="2153">genes</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="2155" end_char="2157">del</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="2159" end_char="2163">virus</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="2165" end_char="2167">del</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="2169" end_char="2172">Sida</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="2174" end_char="2176">que</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="2178" end_char="2182">están</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="2184" end_char="2185">en</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="2187" end_char="2188">el</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="2190" end_char="2200">coronarirus</TOKEN>
<TOKEN id="token-29-15" pos="punct" morph="none" start_char="2201" end_char="2201">?</TOKEN>
</SEG>
<SEG id="segment-30" start_char="2203" end_char="2272">
<ORIGINAL_TEXT>This, entonces si pillas el coronavirus, coges el vih automáticamente?</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="2203" end_char="2206">This</TOKEN>
<TOKEN id="token-30-1" pos="punct" morph="none" start_char="2207" end_char="2207">,</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="2209" end_char="2216">entonces</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="2218" end_char="2219">si</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="2221" end_char="2226">pillas</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="2228" end_char="2229">el</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="2231" end_char="2241">coronavirus</TOKEN>
<TOKEN id="token-30-7" pos="punct" morph="none" start_char="2242" end_char="2242">,</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="2244" end_char="2248">coges</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="2250" end_char="2251">el</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="2253" end_char="2255">vih</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="2257" end_char="2271">automáticamente</TOKEN>
<TOKEN id="token-30-12" pos="punct" morph="none" start_char="2272" end_char="2272">?</TOKEN>
</SEG>
<SEG id="segment-31" start_char="2274" end_char="2427">
<ORIGINAL_TEXT>Joder a ver si va a ser un invento de un científico de wuhan gafotas granudo virgen que se mata a pajas con el hentai, y quiere putear a todo el que folla</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="2274" end_char="2278">Joder</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="2280" end_char="2280">a</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="2282" end_char="2284">ver</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="2286" end_char="2287">si</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="2289" end_char="2290">va</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="2292" end_char="2292">a</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="2294" end_char="2296">ser</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="2298" end_char="2299">un</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="2301" end_char="2307">invento</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="2309" end_char="2310">de</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="2312" end_char="2313">un</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="2315" end_char="2324">científico</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="2326" end_char="2327">de</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="2329" end_char="2333">wuhan</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="2335" end_char="2341">gafotas</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="2343" end_char="2349">granudo</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="2351" end_char="2356">virgen</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="2358" end_char="2360">que</TOKEN>
<TOKEN id="token-31-18" pos="word" morph="none" start_char="2362" end_char="2363">se</TOKEN>
<TOKEN id="token-31-19" pos="word" morph="none" start_char="2365" end_char="2368">mata</TOKEN>
<TOKEN id="token-31-20" pos="word" morph="none" start_char="2370" end_char="2370">a</TOKEN>
<TOKEN id="token-31-21" pos="word" morph="none" start_char="2372" end_char="2376">pajas</TOKEN>
<TOKEN id="token-31-22" pos="word" morph="none" start_char="2378" end_char="2380">con</TOKEN>
<TOKEN id="token-31-23" pos="word" morph="none" start_char="2382" end_char="2383">el</TOKEN>
<TOKEN id="token-31-24" pos="word" morph="none" start_char="2385" end_char="2390">hentai</TOKEN>
<TOKEN id="token-31-25" pos="punct" morph="none" start_char="2391" end_char="2391">,</TOKEN>
<TOKEN id="token-31-26" pos="word" morph="none" start_char="2393" end_char="2393">y</TOKEN>
<TOKEN id="token-31-27" pos="word" morph="none" start_char="2395" end_char="2400">quiere</TOKEN>
<TOKEN id="token-31-28" pos="word" morph="none" start_char="2402" end_char="2407">putear</TOKEN>
<TOKEN id="token-31-29" pos="word" morph="none" start_char="2409" end_char="2409">a</TOKEN>
<TOKEN id="token-31-30" pos="word" morph="none" start_char="2411" end_char="2414">todo</TOKEN>
<TOKEN id="token-31-31" pos="word" morph="none" start_char="2416" end_char="2417">el</TOKEN>
<TOKEN id="token-31-32" pos="word" morph="none" start_char="2419" end_char="2421">que</TOKEN>
<TOKEN id="token-31-33" pos="word" morph="none" start_char="2423" end_char="2427">folla</TOKEN>
</SEG>
<SEG id="segment-32" start_char="2433" end_char="2475">
<ORIGINAL_TEXT>Lo fácil era cargar la culpa a un pangolin.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="2433" end_char="2434">Lo</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="2436" end_char="2440">fácil</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="2442" end_char="2444">era</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="2446" end_char="2451">cargar</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="2453" end_char="2454">la</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="2456" end_char="2460">culpa</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="2462" end_char="2462">a</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="2464" end_char="2465">un</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="2467" end_char="2474">pangolin</TOKEN>
<TOKEN id="token-32-9" pos="punct" morph="none" start_char="2475" end_char="2475">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="2477" end_char="2488">
<ORIGINAL_TEXT>Pero no coló</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="2477" end_char="2480">Pero</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="2482" end_char="2483">no</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="2485" end_char="2488">coló</TOKEN>
</SEG>
<SEG id="segment-34" start_char="2494" end_char="2698">
<ORIGINAL_TEXT>"Ya ha presentado teorías muy controvertidas sobre el origen y la transmisión del SIDA y, en 2017, 100 académicos le pidieron al Colegio de Médicos que lo sancionara después de sus posiciones antivacunas."</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="punct" morph="none" start_char="2494" end_char="2494">"</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="2495" end_char="2496">Ya</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="2498" end_char="2499">ha</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="2501" end_char="2510">presentado</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="2512" end_char="2518">teorías</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="2520" end_char="2522">muy</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="2524" end_char="2537">controvertidas</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="2539" end_char="2543">sobre</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="2545" end_char="2546">el</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="2548" end_char="2553">origen</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="2555" end_char="2555">y</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="2557" end_char="2558">la</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="2560" end_char="2570">transmisión</TOKEN>
<TOKEN id="token-34-13" pos="word" morph="none" start_char="2572" end_char="2574">del</TOKEN>
<TOKEN id="token-34-14" pos="word" morph="none" start_char="2576" end_char="2579">SIDA</TOKEN>
<TOKEN id="token-34-15" pos="word" morph="none" start_char="2581" end_char="2581">y</TOKEN>
<TOKEN id="token-34-16" pos="punct" morph="none" start_char="2582" end_char="2582">,</TOKEN>
<TOKEN id="token-34-17" pos="word" morph="none" start_char="2584" end_char="2585">en</TOKEN>
<TOKEN id="token-34-18" pos="word" morph="none" start_char="2587" end_char="2590">2017</TOKEN>
<TOKEN id="token-34-19" pos="punct" morph="none" start_char="2591" end_char="2591">,</TOKEN>
<TOKEN id="token-34-20" pos="word" morph="none" start_char="2593" end_char="2595">100</TOKEN>
<TOKEN id="token-34-21" pos="word" morph="none" start_char="2597" end_char="2606">académicos</TOKEN>
<TOKEN id="token-34-22" pos="word" morph="none" start_char="2608" end_char="2609">le</TOKEN>
<TOKEN id="token-34-23" pos="word" morph="none" start_char="2611" end_char="2618">pidieron</TOKEN>
<TOKEN id="token-34-24" pos="word" morph="none" start_char="2620" end_char="2621">al</TOKEN>
<TOKEN id="token-34-25" pos="word" morph="none" start_char="2623" end_char="2629">Colegio</TOKEN>
<TOKEN id="token-34-26" pos="word" morph="none" start_char="2631" end_char="2632">de</TOKEN>
<TOKEN id="token-34-27" pos="word" morph="none" start_char="2634" end_char="2640">Médicos</TOKEN>
<TOKEN id="token-34-28" pos="word" morph="none" start_char="2642" end_char="2644">que</TOKEN>
<TOKEN id="token-34-29" pos="word" morph="none" start_char="2646" end_char="2647">lo</TOKEN>
<TOKEN id="token-34-30" pos="word" morph="none" start_char="2649" end_char="2658">sancionara</TOKEN>
<TOKEN id="token-34-31" pos="word" morph="none" start_char="2660" end_char="2666">después</TOKEN>
<TOKEN id="token-34-32" pos="word" morph="none" start_char="2668" end_char="2669">de</TOKEN>
<TOKEN id="token-34-33" pos="word" morph="none" start_char="2671" end_char="2673">sus</TOKEN>
<TOKEN id="token-34-34" pos="word" morph="none" start_char="2675" end_char="2684">posiciones</TOKEN>
<TOKEN id="token-34-35" pos="word" morph="none" start_char="2686" end_char="2696">antivacunas</TOKEN>
<TOKEN id="token-34-36" pos="punct" morph="none" start_char="2697" end_char="2698">."</TOKEN>
</SEG>
<SEG id="segment-35" start_char="2704" end_char="2815">
<ORIGINAL_TEXT>Todos lo sospechan porque el laboratorio de Wuhan está a 200 metros del mercado donde dicen que se originó todo.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="2704" end_char="2708">Todos</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="2710" end_char="2711">lo</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="2713" end_char="2721">sospechan</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="2723" end_char="2728">porque</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="2730" end_char="2731">el</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="2733" end_char="2743">laboratorio</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="2745" end_char="2746">de</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="2748" end_char="2752">Wuhan</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="2754" end_char="2757">está</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="2759" end_char="2759">a</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="2761" end_char="2763">200</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="2765" end_char="2770">metros</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="2772" end_char="2774">del</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="2776" end_char="2782">mercado</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="2784" end_char="2788">donde</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="2790" end_char="2794">dicen</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="2796" end_char="2798">que</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="2800" end_char="2801">se</TOKEN>
<TOKEN id="token-35-18" pos="word" morph="none" start_char="2803" end_char="2809">originó</TOKEN>
<TOKEN id="token-35-19" pos="word" morph="none" start_char="2811" end_char="2814">todo</TOKEN>
<TOKEN id="token-35-20" pos="punct" morph="none" start_char="2815" end_char="2815">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="2817" end_char="2959">
<ORIGINAL_TEXT>Lo que yo creo es que no fue intencionadamente propagado, si no que un investigador se contagió por error y salió del laboratorio con el bicho.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="2817" end_char="2818">Lo</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="2820" end_char="2822">que</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="2824" end_char="2825">yo</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="2827" end_char="2830">creo</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="2832" end_char="2833">es</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="2835" end_char="2837">que</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="2839" end_char="2840">no</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="2842" end_char="2844">fue</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="2846" end_char="2862">intencionadamente</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="2864" end_char="2872">propagado</TOKEN>
<TOKEN id="token-36-10" pos="punct" morph="none" start_char="2873" end_char="2873">,</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="2875" end_char="2876">si</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="2878" end_char="2879">no</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="2881" end_char="2883">que</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="2885" end_char="2886">un</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="2888" end_char="2899">investigador</TOKEN>
<TOKEN id="token-36-16" pos="word" morph="none" start_char="2901" end_char="2902">se</TOKEN>
<TOKEN id="token-36-17" pos="word" morph="none" start_char="2904" end_char="2911">contagió</TOKEN>
<TOKEN id="token-36-18" pos="word" morph="none" start_char="2913" end_char="2915">por</TOKEN>
<TOKEN id="token-36-19" pos="word" morph="none" start_char="2917" end_char="2921">error</TOKEN>
<TOKEN id="token-36-20" pos="word" morph="none" start_char="2923" end_char="2923">y</TOKEN>
<TOKEN id="token-36-21" pos="word" morph="none" start_char="2925" end_char="2929">salió</TOKEN>
<TOKEN id="token-36-22" pos="word" morph="none" start_char="2931" end_char="2933">del</TOKEN>
<TOKEN id="token-36-23" pos="word" morph="none" start_char="2935" end_char="2945">laboratorio</TOKEN>
<TOKEN id="token-36-24" pos="word" morph="none" start_char="2947" end_char="2949">con</TOKEN>
<TOKEN id="token-36-25" pos="word" morph="none" start_char="2951" end_char="2952">el</TOKEN>
<TOKEN id="token-36-26" pos="word" morph="none" start_char="2954" end_char="2958">bicho</TOKEN>
<TOKEN id="token-36-27" pos="punct" morph="none" start_char="2959" end_char="2959">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="2961" end_char="3046">
<ORIGINAL_TEXT>Incluso puede que fuera a comer o comprar al mercado donde se supone que es la zona 0.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="2961" end_char="2967">Incluso</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="2969" end_char="2973">puede</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="2975" end_char="2977">que</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="2979" end_char="2983">fuera</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="2985" end_char="2985">a</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="2987" end_char="2991">comer</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="2993" end_char="2993">o</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="2995" end_char="3001">comprar</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="3003" end_char="3004">al</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="3006" end_char="3012">mercado</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="3014" end_char="3018">donde</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="3020" end_char="3021">se</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="3023" end_char="3028">supone</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="3030" end_char="3032">que</TOKEN>
<TOKEN id="token-37-14" pos="word" morph="none" start_char="3034" end_char="3035">es</TOKEN>
<TOKEN id="token-37-15" pos="word" morph="none" start_char="3037" end_char="3038">la</TOKEN>
<TOKEN id="token-37-16" pos="word" morph="none" start_char="3040" end_char="3043">zona</TOKEN>
<TOKEN id="token-37-17" pos="word" morph="none" start_char="3045" end_char="3045">0</TOKEN>
<TOKEN id="token-37-18" pos="punct" morph="none" start_char="3046" end_char="3046">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="3048" end_char="3160">
<ORIGINAL_TEXT>Pero supongo que es imposible probar que está hecho por el hombre y que se haya hecho en el laboratorio de Wuhan.</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="3048" end_char="3051">Pero</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="3053" end_char="3059">supongo</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="3061" end_char="3063">que</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="3065" end_char="3066">es</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="3068" end_char="3076">imposible</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="3078" end_char="3083">probar</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="3085" end_char="3087">que</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="3089" end_char="3092">está</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="3094" end_char="3098">hecho</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="3100" end_char="3102">por</TOKEN>
<TOKEN id="token-38-10" pos="word" morph="none" start_char="3104" end_char="3105">el</TOKEN>
<TOKEN id="token-38-11" pos="word" morph="none" start_char="3107" end_char="3112">hombre</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="3114" end_char="3114">y</TOKEN>
<TOKEN id="token-38-13" pos="word" morph="none" start_char="3116" end_char="3118">que</TOKEN>
<TOKEN id="token-38-14" pos="word" morph="none" start_char="3120" end_char="3121">se</TOKEN>
<TOKEN id="token-38-15" pos="word" morph="none" start_char="3123" end_char="3126">haya</TOKEN>
<TOKEN id="token-38-16" pos="word" morph="none" start_char="3128" end_char="3132">hecho</TOKEN>
<TOKEN id="token-38-17" pos="word" morph="none" start_char="3134" end_char="3135">en</TOKEN>
<TOKEN id="token-38-18" pos="word" morph="none" start_char="3137" end_char="3138">el</TOKEN>
<TOKEN id="token-38-19" pos="word" morph="none" start_char="3140" end_char="3150">laboratorio</TOKEN>
<TOKEN id="token-38-20" pos="word" morph="none" start_char="3152" end_char="3153">de</TOKEN>
<TOKEN id="token-38-21" pos="word" morph="none" start_char="3155" end_char="3159">Wuhan</TOKEN>
<TOKEN id="token-38-22" pos="punct" morph="none" start_char="3160" end_char="3160">.</TOKEN>
</SEG>
<SEG id="segment-39" start_char="3166" end_char="3170">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="3166" end_char="3169">Cita</TOKEN>
<TOKEN id="token-39-1" pos="punct" morph="none" start_char="3170" end_char="3170">:</TOKEN>
</SEG>
<SEG id="segment-40" start_char="3175" end_char="3250">
<ORIGINAL_TEXT>Originalmente Escrito por zirick Lo fácil era cargar la culpa a un pangolin.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="3175" end_char="3187">Originalmente</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="3189" end_char="3195">Escrito</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="3197" end_char="3199">por</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="3201" end_char="3206">zirick</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="3208" end_char="3209">Lo</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="3211" end_char="3215">fácil</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="3217" end_char="3219">era</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="3221" end_char="3226">cargar</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="3228" end_char="3229">la</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="3231" end_char="3235">culpa</TOKEN>
<TOKEN id="token-40-10" pos="word" morph="none" start_char="3237" end_char="3237">a</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="3239" end_char="3240">un</TOKEN>
<TOKEN id="token-40-12" pos="word" morph="none" start_char="3242" end_char="3249">pangolin</TOKEN>
<TOKEN id="token-40-13" pos="punct" morph="none" start_char="3250" end_char="3250">.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="3252" end_char="3312">
<ORIGINAL_TEXT>Pero no coló Pero como va a tener virus ese bicho tan majete.</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="3252" end_char="3255">Pero</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="3257" end_char="3258">no</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="3260" end_char="3263">coló</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="3265" end_char="3268">Pero</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="3270" end_char="3273">como</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="3275" end_char="3276">va</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="3278" end_char="3278">a</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="3280" end_char="3284">tener</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="3286" end_char="3290">virus</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="3292" end_char="3294">ese</TOKEN>
<TOKEN id="token-41-10" pos="word" morph="none" start_char="3296" end_char="3300">bicho</TOKEN>
<TOKEN id="token-41-11" pos="word" morph="none" start_char="3302" end_char="3304">tan</TOKEN>
<TOKEN id="token-41-12" pos="word" morph="none" start_char="3306" end_char="3311">majete</TOKEN>
<TOKEN id="token-41-13" pos="punct" morph="none" start_char="3312" end_char="3312">.</TOKEN>
</SEG>
<SEG id="segment-42" start_char="3314" end_char="3323">
<ORIGINAL_TEXT>Yo adoptó.</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="3314" end_char="3315">Yo</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="3317" end_char="3322">adoptó</TOKEN>
<TOKEN id="token-42-2" pos="punct" morph="none" start_char="3323" end_char="3323">.</TOKEN>
</SEG>
<SEG id="segment-43" start_char="3329" end_char="3333">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="3329" end_char="3332">Cita</TOKEN>
<TOKEN id="token-43-1" pos="punct" morph="none" start_char="3333" end_char="3333">:</TOKEN>
</SEG>
<SEG id="segment-44" start_char="3338" end_char="3447">
<ORIGINAL_TEXT>Originalmente Escrito por Magikarp sano This, entonces si pillas el coronavirus, coges el vih automáticamente?</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="3338" end_char="3350">Originalmente</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="3352" end_char="3358">Escrito</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="3360" end_char="3362">por</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="3364" end_char="3371">Magikarp</TOKEN>
<TOKEN id="token-44-4" pos="word" morph="none" start_char="3373" end_char="3376">sano</TOKEN>
<TOKEN id="token-44-5" pos="word" morph="none" start_char="3378" end_char="3381">This</TOKEN>
<TOKEN id="token-44-6" pos="punct" morph="none" start_char="3382" end_char="3382">,</TOKEN>
<TOKEN id="token-44-7" pos="word" morph="none" start_char="3384" end_char="3391">entonces</TOKEN>
<TOKEN id="token-44-8" pos="word" morph="none" start_char="3393" end_char="3394">si</TOKEN>
<TOKEN id="token-44-9" pos="word" morph="none" start_char="3396" end_char="3401">pillas</TOKEN>
<TOKEN id="token-44-10" pos="word" morph="none" start_char="3403" end_char="3404">el</TOKEN>
<TOKEN id="token-44-11" pos="word" morph="none" start_char="3406" end_char="3416">coronavirus</TOKEN>
<TOKEN id="token-44-12" pos="punct" morph="none" start_char="3417" end_char="3417">,</TOKEN>
<TOKEN id="token-44-13" pos="word" morph="none" start_char="3419" end_char="3423">coges</TOKEN>
<TOKEN id="token-44-14" pos="word" morph="none" start_char="3425" end_char="3426">el</TOKEN>
<TOKEN id="token-44-15" pos="word" morph="none" start_char="3428" end_char="3430">vih</TOKEN>
<TOKEN id="token-44-16" pos="word" morph="none" start_char="3432" end_char="3446">automáticamente</TOKEN>
<TOKEN id="token-44-17" pos="punct" morph="none" start_char="3447" end_char="3447">?</TOKEN>
</SEG>
<SEG id="segment-45" start_char="3449" end_char="3602">
<ORIGINAL_TEXT>Joder a ver si va a ser un invento de un científico de wuhan gafotas granudo virgen que se mata a pajas con el hentai, y quiere putear a todo el que folla</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="3449" end_char="3453">Joder</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="3455" end_char="3455">a</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="3457" end_char="3459">ver</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="3461" end_char="3462">si</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="3464" end_char="3465">va</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="3467" end_char="3467">a</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="3469" end_char="3471">ser</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="3473" end_char="3474">un</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="3476" end_char="3482">invento</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="3484" end_char="3485">de</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="3487" end_char="3488">un</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="3490" end_char="3499">científico</TOKEN>
<TOKEN id="token-45-12" pos="word" morph="none" start_char="3501" end_char="3502">de</TOKEN>
<TOKEN id="token-45-13" pos="word" morph="none" start_char="3504" end_char="3508">wuhan</TOKEN>
<TOKEN id="token-45-14" pos="word" morph="none" start_char="3510" end_char="3516">gafotas</TOKEN>
<TOKEN id="token-45-15" pos="word" morph="none" start_char="3518" end_char="3524">granudo</TOKEN>
<TOKEN id="token-45-16" pos="word" morph="none" start_char="3526" end_char="3531">virgen</TOKEN>
<TOKEN id="token-45-17" pos="word" morph="none" start_char="3533" end_char="3535">que</TOKEN>
<TOKEN id="token-45-18" pos="word" morph="none" start_char="3537" end_char="3538">se</TOKEN>
<TOKEN id="token-45-19" pos="word" morph="none" start_char="3540" end_char="3543">mata</TOKEN>
<TOKEN id="token-45-20" pos="word" morph="none" start_char="3545" end_char="3545">a</TOKEN>
<TOKEN id="token-45-21" pos="word" morph="none" start_char="3547" end_char="3551">pajas</TOKEN>
<TOKEN id="token-45-22" pos="word" morph="none" start_char="3553" end_char="3555">con</TOKEN>
<TOKEN id="token-45-23" pos="word" morph="none" start_char="3557" end_char="3558">el</TOKEN>
<TOKEN id="token-45-24" pos="word" morph="none" start_char="3560" end_char="3565">hentai</TOKEN>
<TOKEN id="token-45-25" pos="punct" morph="none" start_char="3566" end_char="3566">,</TOKEN>
<TOKEN id="token-45-26" pos="word" morph="none" start_char="3568" end_char="3568">y</TOKEN>
<TOKEN id="token-45-27" pos="word" morph="none" start_char="3570" end_char="3575">quiere</TOKEN>
<TOKEN id="token-45-28" pos="word" morph="none" start_char="3577" end_char="3582">putear</TOKEN>
<TOKEN id="token-45-29" pos="word" morph="none" start_char="3584" end_char="3584">a</TOKEN>
<TOKEN id="token-45-30" pos="word" morph="none" start_char="3586" end_char="3589">todo</TOKEN>
<TOKEN id="token-45-31" pos="word" morph="none" start_char="3591" end_char="3592">el</TOKEN>
<TOKEN id="token-45-32" pos="word" morph="none" start_char="3594" end_char="3596">que</TOKEN>
<TOKEN id="token-45-33" pos="word" morph="none" start_char="3598" end_char="3602">folla</TOKEN>
</SEG>
<SEG id="segment-46" start_char="3606" end_char="3654">
<ORIGINAL_TEXT>No, sería solo una secuencia, no el virus entero.</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="3606" end_char="3607">No</TOKEN>
<TOKEN id="token-46-1" pos="punct" morph="none" start_char="3608" end_char="3608">,</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="3610" end_char="3614">sería</TOKEN>
<TOKEN id="token-46-3" pos="word" morph="none" start_char="3616" end_char="3619">solo</TOKEN>
<TOKEN id="token-46-4" pos="word" morph="none" start_char="3621" end_char="3623">una</TOKEN>
<TOKEN id="token-46-5" pos="word" morph="none" start_char="3625" end_char="3633">secuencia</TOKEN>
<TOKEN id="token-46-6" pos="punct" morph="none" start_char="3634" end_char="3634">,</TOKEN>
<TOKEN id="token-46-7" pos="word" morph="none" start_char="3636" end_char="3637">no</TOKEN>
<TOKEN id="token-46-8" pos="word" morph="none" start_char="3639" end_char="3640">el</TOKEN>
<TOKEN id="token-46-9" pos="word" morph="none" start_char="3642" end_char="3646">virus</TOKEN>
<TOKEN id="token-46-10" pos="word" morph="none" start_char="3648" end_char="3653">entero</TOKEN>
<TOKEN id="token-46-11" pos="punct" morph="none" start_char="3654" end_char="3654">.</TOKEN>
</SEG>
<SEG id="segment-47" start_char="3656" end_char="3716">
<ORIGINAL_TEXT>Pero ni siquiera eso estoy seguro de si lo he entendido bien.</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="3656" end_char="3659">Pero</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="3661" end_char="3662">ni</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="3664" end_char="3671">siquiera</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="3673" end_char="3675">eso</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="3677" end_char="3681">estoy</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="3683" end_char="3688">seguro</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="3690" end_char="3691">de</TOKEN>
<TOKEN id="token-47-7" pos="word" morph="none" start_char="3693" end_char="3694">si</TOKEN>
<TOKEN id="token-47-8" pos="word" morph="none" start_char="3696" end_char="3697">lo</TOKEN>
<TOKEN id="token-47-9" pos="word" morph="none" start_char="3699" end_char="3700">he</TOKEN>
<TOKEN id="token-47-10" pos="word" morph="none" start_char="3702" end_char="3710">entendido</TOKEN>
<TOKEN id="token-47-11" pos="word" morph="none" start_char="3712" end_char="3715">bien</TOKEN>
<TOKEN id="token-47-12" pos="punct" morph="none" start_char="3716" end_char="3716">.</TOKEN>
</SEG>
<SEG id="segment-48" start_char="3722" end_char="3799">
<ORIGINAL_TEXT>Lo primero..... para descartar que sea un bulo...... a quien vota este hombre?</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="3722" end_char="3723">Lo</TOKEN>
<TOKEN id="token-48-1" pos="word" morph="none" start_char="3725" end_char="3731">primero</TOKEN>
<TOKEN id="token-48-2" pos="punct" morph="none" start_char="3732" end_char="3736">.....</TOKEN>
<TOKEN id="token-48-3" pos="word" morph="none" start_char="3738" end_char="3741">para</TOKEN>
<TOKEN id="token-48-4" pos="word" morph="none" start_char="3743" end_char="3751">descartar</TOKEN>
<TOKEN id="token-48-5" pos="word" morph="none" start_char="3753" end_char="3755">que</TOKEN>
<TOKEN id="token-48-6" pos="word" morph="none" start_char="3757" end_char="3759">sea</TOKEN>
<TOKEN id="token-48-7" pos="word" morph="none" start_char="3761" end_char="3762">un</TOKEN>
<TOKEN id="token-48-8" pos="word" morph="none" start_char="3764" end_char="3767">bulo</TOKEN>
<TOKEN id="token-48-9" pos="punct" morph="none" start_char="3768" end_char="3773">......</TOKEN>
<TOKEN id="token-48-10" pos="word" morph="none" start_char="3775" end_char="3775">a</TOKEN>
<TOKEN id="token-48-11" pos="word" morph="none" start_char="3777" end_char="3781">quien</TOKEN>
<TOKEN id="token-48-12" pos="word" morph="none" start_char="3783" end_char="3786">vota</TOKEN>
<TOKEN id="token-48-13" pos="word" morph="none" start_char="3788" end_char="3791">este</TOKEN>
<TOKEN id="token-48-14" pos="word" morph="none" start_char="3793" end_char="3798">hombre</TOKEN>
<TOKEN id="token-48-15" pos="punct" morph="none" start_char="3799" end_char="3799">?</TOKEN>
</SEG>
<SEG id="segment-49" start_char="3805" end_char="3854">
<ORIGINAL_TEXT>Ese tío es una eminencia en virologia..poco broma.</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="3805" end_char="3807">Ese</TOKEN>
<TOKEN id="token-49-1" pos="word" morph="none" start_char="3809" end_char="3811">tío</TOKEN>
<TOKEN id="token-49-2" pos="word" morph="none" start_char="3813" end_char="3814">es</TOKEN>
<TOKEN id="token-49-3" pos="word" morph="none" start_char="3816" end_char="3818">una</TOKEN>
<TOKEN id="token-49-4" pos="word" morph="none" start_char="3820" end_char="3828">eminencia</TOKEN>
<TOKEN id="token-49-5" pos="word" morph="none" start_char="3830" end_char="3831">en</TOKEN>
<TOKEN id="token-49-6" pos="unknown" morph="none" start_char="3833" end_char="3847">virologia..poco</TOKEN>
<TOKEN id="token-49-7" pos="word" morph="none" start_char="3849" end_char="3853">broma</TOKEN>
<TOKEN id="token-49-8" pos="punct" morph="none" start_char="3854" end_char="3854">.</TOKEN>
</SEG>
<SEG id="segment-50" start_char="3860" end_char="3928">
<ORIGINAL_TEXT>rastros de VIH encontrados en el coronavirus Mira tio , yo ya dimito.</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="3860" end_char="3866">rastros</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="3868" end_char="3869">de</TOKEN>
<TOKEN id="token-50-2" pos="word" morph="none" start_char="3871" end_char="3873">VIH</TOKEN>
<TOKEN id="token-50-3" pos="word" morph="none" start_char="3875" end_char="3885">encontrados</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="3887" end_char="3888">en</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="3890" end_char="3891">el</TOKEN>
<TOKEN id="token-50-6" pos="word" morph="none" start_char="3893" end_char="3903">coronavirus</TOKEN>
<TOKEN id="token-50-7" pos="word" morph="none" start_char="3905" end_char="3908">Mira</TOKEN>
<TOKEN id="token-50-8" pos="word" morph="none" start_char="3910" end_char="3912">tio</TOKEN>
<TOKEN id="token-50-9" pos="punct" morph="none" start_char="3914" end_char="3914">,</TOKEN>
<TOKEN id="token-50-10" pos="word" morph="none" start_char="3916" end_char="3917">yo</TOKEN>
<TOKEN id="token-50-11" pos="word" morph="none" start_char="3919" end_char="3920">ya</TOKEN>
<TOKEN id="token-50-12" pos="word" morph="none" start_char="3922" end_char="3927">dimito</TOKEN>
<TOKEN id="token-50-13" pos="punct" morph="none" start_char="3928" end_char="3928">.</TOKEN>
</SEG>
<SEG id="segment-51" start_char="3930" end_char="3985">
<ORIGINAL_TEXT>Como sea verdad , habra que esconderse debajo del suelo.</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="word" morph="none" start_char="3930" end_char="3933">Como</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="3935" end_char="3937">sea</TOKEN>
<TOKEN id="token-51-2" pos="word" morph="none" start_char="3939" end_char="3944">verdad</TOKEN>
<TOKEN id="token-51-3" pos="punct" morph="none" start_char="3946" end_char="3946">,</TOKEN>
<TOKEN id="token-51-4" pos="word" morph="none" start_char="3948" end_char="3952">habra</TOKEN>
<TOKEN id="token-51-5" pos="word" morph="none" start_char="3954" end_char="3956">que</TOKEN>
<TOKEN id="token-51-6" pos="word" morph="none" start_char="3958" end_char="3967">esconderse</TOKEN>
<TOKEN id="token-51-7" pos="word" morph="none" start_char="3969" end_char="3974">debajo</TOKEN>
<TOKEN id="token-51-8" pos="word" morph="none" start_char="3976" end_char="3978">del</TOKEN>
<TOKEN id="token-51-9" pos="word" morph="none" start_char="3980" end_char="3984">suelo</TOKEN>
<TOKEN id="token-51-10" pos="punct" morph="none" start_char="3985" end_char="3985">.</TOKEN>
</SEG>
<SEG id="segment-52" start_char="3991" end_char="3995">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="3991" end_char="3994">Cita</TOKEN>
<TOKEN id="token-52-1" pos="punct" morph="none" start_char="3995" end_char="3995">:</TOKEN>
</SEG>
<SEG id="segment-53" start_char="4000" end_char="4152">
<ORIGINAL_TEXT>Originalmente Escrito por Mongodemonguer Todos lo sospechan porque el laboratorio de Wuhan está a 200 metros del mercado donde dicen que se originó todo.</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="word" morph="none" start_char="4000" end_char="4012">Originalmente</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="4014" end_char="4020">Escrito</TOKEN>
<TOKEN id="token-53-2" pos="word" morph="none" start_char="4022" end_char="4024">por</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="4026" end_char="4039">Mongodemonguer</TOKEN>
<TOKEN id="token-53-4" pos="word" morph="none" start_char="4041" end_char="4045">Todos</TOKEN>
<TOKEN id="token-53-5" pos="word" morph="none" start_char="4047" end_char="4048">lo</TOKEN>
<TOKEN id="token-53-6" pos="word" morph="none" start_char="4050" end_char="4058">sospechan</TOKEN>
<TOKEN id="token-53-7" pos="word" morph="none" start_char="4060" end_char="4065">porque</TOKEN>
<TOKEN id="token-53-8" pos="word" morph="none" start_char="4067" end_char="4068">el</TOKEN>
<TOKEN id="token-53-9" pos="word" morph="none" start_char="4070" end_char="4080">laboratorio</TOKEN>
<TOKEN id="token-53-10" pos="word" morph="none" start_char="4082" end_char="4083">de</TOKEN>
<TOKEN id="token-53-11" pos="word" morph="none" start_char="4085" end_char="4089">Wuhan</TOKEN>
<TOKEN id="token-53-12" pos="word" morph="none" start_char="4091" end_char="4094">está</TOKEN>
<TOKEN id="token-53-13" pos="word" morph="none" start_char="4096" end_char="4096">a</TOKEN>
<TOKEN id="token-53-14" pos="word" morph="none" start_char="4098" end_char="4100">200</TOKEN>
<TOKEN id="token-53-15" pos="word" morph="none" start_char="4102" end_char="4107">metros</TOKEN>
<TOKEN id="token-53-16" pos="word" morph="none" start_char="4109" end_char="4111">del</TOKEN>
<TOKEN id="token-53-17" pos="word" morph="none" start_char="4113" end_char="4119">mercado</TOKEN>
<TOKEN id="token-53-18" pos="word" morph="none" start_char="4121" end_char="4125">donde</TOKEN>
<TOKEN id="token-53-19" pos="word" morph="none" start_char="4127" end_char="4131">dicen</TOKEN>
<TOKEN id="token-53-20" pos="word" morph="none" start_char="4133" end_char="4135">que</TOKEN>
<TOKEN id="token-53-21" pos="word" morph="none" start_char="4137" end_char="4138">se</TOKEN>
<TOKEN id="token-53-22" pos="word" morph="none" start_char="4140" end_char="4146">originó</TOKEN>
<TOKEN id="token-53-23" pos="word" morph="none" start_char="4148" end_char="4151">todo</TOKEN>
<TOKEN id="token-53-24" pos="punct" morph="none" start_char="4152" end_char="4152">.</TOKEN>
</SEG>
<SEG id="segment-54" start_char="4154" end_char="4296">
<ORIGINAL_TEXT>Lo que yo creo es que no fue intencionadamente propagado, si no que un investigador se contagió por error y salió del laboratorio con el bicho.</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="word" morph="none" start_char="4154" end_char="4155">Lo</TOKEN>
<TOKEN id="token-54-1" pos="word" morph="none" start_char="4157" end_char="4159">que</TOKEN>
<TOKEN id="token-54-2" pos="word" morph="none" start_char="4161" end_char="4162">yo</TOKEN>
<TOKEN id="token-54-3" pos="word" morph="none" start_char="4164" end_char="4167">creo</TOKEN>
<TOKEN id="token-54-4" pos="word" morph="none" start_char="4169" end_char="4170">es</TOKEN>
<TOKEN id="token-54-5" pos="word" morph="none" start_char="4172" end_char="4174">que</TOKEN>
<TOKEN id="token-54-6" pos="word" morph="none" start_char="4176" end_char="4177">no</TOKEN>
<TOKEN id="token-54-7" pos="word" morph="none" start_char="4179" end_char="4181">fue</TOKEN>
<TOKEN id="token-54-8" pos="word" morph="none" start_char="4183" end_char="4199">intencionadamente</TOKEN>
<TOKEN id="token-54-9" pos="word" morph="none" start_char="4201" end_char="4209">propagado</TOKEN>
<TOKEN id="token-54-10" pos="punct" morph="none" start_char="4210" end_char="4210">,</TOKEN>
<TOKEN id="token-54-11" pos="word" morph="none" start_char="4212" end_char="4213">si</TOKEN>
<TOKEN id="token-54-12" pos="word" morph="none" start_char="4215" end_char="4216">no</TOKEN>
<TOKEN id="token-54-13" pos="word" morph="none" start_char="4218" end_char="4220">que</TOKEN>
<TOKEN id="token-54-14" pos="word" morph="none" start_char="4222" end_char="4223">un</TOKEN>
<TOKEN id="token-54-15" pos="word" morph="none" start_char="4225" end_char="4236">investigador</TOKEN>
<TOKEN id="token-54-16" pos="word" morph="none" start_char="4238" end_char="4239">se</TOKEN>
<TOKEN id="token-54-17" pos="word" morph="none" start_char="4241" end_char="4248">contagió</TOKEN>
<TOKEN id="token-54-18" pos="word" morph="none" start_char="4250" end_char="4252">por</TOKEN>
<TOKEN id="token-54-19" pos="word" morph="none" start_char="4254" end_char="4258">error</TOKEN>
<TOKEN id="token-54-20" pos="word" morph="none" start_char="4260" end_char="4260">y</TOKEN>
<TOKEN id="token-54-21" pos="word" morph="none" start_char="4262" end_char="4266">salió</TOKEN>
<TOKEN id="token-54-22" pos="word" morph="none" start_char="4268" end_char="4270">del</TOKEN>
<TOKEN id="token-54-23" pos="word" morph="none" start_char="4272" end_char="4282">laboratorio</TOKEN>
<TOKEN id="token-54-24" pos="word" morph="none" start_char="4284" end_char="4286">con</TOKEN>
<TOKEN id="token-54-25" pos="word" morph="none" start_char="4288" end_char="4289">el</TOKEN>
<TOKEN id="token-54-26" pos="word" morph="none" start_char="4291" end_char="4295">bicho</TOKEN>
<TOKEN id="token-54-27" pos="punct" morph="none" start_char="4296" end_char="4296">.</TOKEN>
</SEG>
<SEG id="segment-55" start_char="4298" end_char="4383">
<ORIGINAL_TEXT>Incluso puede que fuera a comer o comprar al mercado donde se supone que es la zona 0.</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="word" morph="none" start_char="4298" end_char="4304">Incluso</TOKEN>
<TOKEN id="token-55-1" pos="word" morph="none" start_char="4306" end_char="4310">puede</TOKEN>
<TOKEN id="token-55-2" pos="word" morph="none" start_char="4312" end_char="4314">que</TOKEN>
<TOKEN id="token-55-3" pos="word" morph="none" start_char="4316" end_char="4320">fuera</TOKEN>
<TOKEN id="token-55-4" pos="word" morph="none" start_char="4322" end_char="4322">a</TOKEN>
<TOKEN id="token-55-5" pos="word" morph="none" start_char="4324" end_char="4328">comer</TOKEN>
<TOKEN id="token-55-6" pos="word" morph="none" start_char="4330" end_char="4330">o</TOKEN>
<TOKEN id="token-55-7" pos="word" morph="none" start_char="4332" end_char="4338">comprar</TOKEN>
<TOKEN id="token-55-8" pos="word" morph="none" start_char="4340" end_char="4341">al</TOKEN>
<TOKEN id="token-55-9" pos="word" morph="none" start_char="4343" end_char="4349">mercado</TOKEN>
<TOKEN id="token-55-10" pos="word" morph="none" start_char="4351" end_char="4355">donde</TOKEN>
<TOKEN id="token-55-11" pos="word" morph="none" start_char="4357" end_char="4358">se</TOKEN>
<TOKEN id="token-55-12" pos="word" morph="none" start_char="4360" end_char="4365">supone</TOKEN>
<TOKEN id="token-55-13" pos="word" morph="none" start_char="4367" end_char="4369">que</TOKEN>
<TOKEN id="token-55-14" pos="word" morph="none" start_char="4371" end_char="4372">es</TOKEN>
<TOKEN id="token-55-15" pos="word" morph="none" start_char="4374" end_char="4375">la</TOKEN>
<TOKEN id="token-55-16" pos="word" morph="none" start_char="4377" end_char="4380">zona</TOKEN>
<TOKEN id="token-55-17" pos="word" morph="none" start_char="4382" end_char="4382">0</TOKEN>
<TOKEN id="token-55-18" pos="punct" morph="none" start_char="4383" end_char="4383">.</TOKEN>
</SEG>
<SEG id="segment-56" start_char="4386" end_char="4519">
<ORIGINAL_TEXT>Yo también creo en la posibilidad de que los animales de los experimentos en lugar de ser incinerados acabaran vendidos en el mercado.</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="4386" end_char="4387">Yo</TOKEN>
<TOKEN id="token-56-1" pos="word" morph="none" start_char="4389" end_char="4395">también</TOKEN>
<TOKEN id="token-56-2" pos="word" morph="none" start_char="4397" end_char="4400">creo</TOKEN>
<TOKEN id="token-56-3" pos="word" morph="none" start_char="4402" end_char="4403">en</TOKEN>
<TOKEN id="token-56-4" pos="word" morph="none" start_char="4405" end_char="4406">la</TOKEN>
<TOKEN id="token-56-5" pos="word" morph="none" start_char="4408" end_char="4418">posibilidad</TOKEN>
<TOKEN id="token-56-6" pos="word" morph="none" start_char="4420" end_char="4421">de</TOKEN>
<TOKEN id="token-56-7" pos="word" morph="none" start_char="4423" end_char="4425">que</TOKEN>
<TOKEN id="token-56-8" pos="word" morph="none" start_char="4427" end_char="4429">los</TOKEN>
<TOKEN id="token-56-9" pos="word" morph="none" start_char="4431" end_char="4438">animales</TOKEN>
<TOKEN id="token-56-10" pos="word" morph="none" start_char="4440" end_char="4441">de</TOKEN>
<TOKEN id="token-56-11" pos="word" morph="none" start_char="4443" end_char="4445">los</TOKEN>
<TOKEN id="token-56-12" pos="word" morph="none" start_char="4447" end_char="4458">experimentos</TOKEN>
<TOKEN id="token-56-13" pos="word" morph="none" start_char="4460" end_char="4461">en</TOKEN>
<TOKEN id="token-56-14" pos="word" morph="none" start_char="4463" end_char="4467">lugar</TOKEN>
<TOKEN id="token-56-15" pos="word" morph="none" start_char="4469" end_char="4470">de</TOKEN>
<TOKEN id="token-56-16" pos="word" morph="none" start_char="4472" end_char="4474">ser</TOKEN>
<TOKEN id="token-56-17" pos="word" morph="none" start_char="4476" end_char="4486">incinerados</TOKEN>
<TOKEN id="token-56-18" pos="word" morph="none" start_char="4488" end_char="4495">acabaran</TOKEN>
<TOKEN id="token-56-19" pos="word" morph="none" start_char="4497" end_char="4504">vendidos</TOKEN>
<TOKEN id="token-56-20" pos="word" morph="none" start_char="4506" end_char="4507">en</TOKEN>
<TOKEN id="token-56-21" pos="word" morph="none" start_char="4509" end_char="4510">el</TOKEN>
<TOKEN id="token-56-22" pos="word" morph="none" start_char="4512" end_char="4518">mercado</TOKEN>
<TOKEN id="token-56-23" pos="punct" morph="none" start_char="4519" end_char="4519">.</TOKEN>
</SEG>
<SEG id="segment-57" start_char="4521" end_char="4559">
<ORIGINAL_TEXT>Se supone que hay un detenido por ello.</ORIGINAL_TEXT>
<TOKEN id="token-57-0" pos="word" morph="none" start_char="4521" end_char="4522">Se</TOKEN>
<TOKEN id="token-57-1" pos="word" morph="none" start_char="4524" end_char="4529">supone</TOKEN>
<TOKEN id="token-57-2" pos="word" morph="none" start_char="4531" end_char="4533">que</TOKEN>
<TOKEN id="token-57-3" pos="word" morph="none" start_char="4535" end_char="4537">hay</TOKEN>
<TOKEN id="token-57-4" pos="word" morph="none" start_char="4539" end_char="4540">un</TOKEN>
<TOKEN id="token-57-5" pos="word" morph="none" start_char="4542" end_char="4549">detenido</TOKEN>
<TOKEN id="token-57-6" pos="word" morph="none" start_char="4551" end_char="4553">por</TOKEN>
<TOKEN id="token-57-7" pos="word" morph="none" start_char="4555" end_char="4558">ello</TOKEN>
<TOKEN id="token-57-8" pos="punct" morph="none" start_char="4559" end_char="4559">.</TOKEN>
</SEG>
<SEG id="segment-58" start_char="4565" end_char="4606">
<ORIGINAL_TEXT>en esa web no encuentro un ¿quienes Somos?</ORIGINAL_TEXT>
<TOKEN id="token-58-0" pos="word" morph="none" start_char="4565" end_char="4566">en</TOKEN>
<TOKEN id="token-58-1" pos="word" morph="none" start_char="4568" end_char="4570">esa</TOKEN>
<TOKEN id="token-58-2" pos="word" morph="none" start_char="4572" end_char="4574">web</TOKEN>
<TOKEN id="token-58-3" pos="word" morph="none" start_char="4576" end_char="4577">no</TOKEN>
<TOKEN id="token-58-4" pos="word" morph="none" start_char="4579" end_char="4587">encuentro</TOKEN>
<TOKEN id="token-58-5" pos="word" morph="none" start_char="4589" end_char="4590">un</TOKEN>
<TOKEN id="token-58-6" pos="punct" morph="none" start_char="4592" end_char="4592">¿</TOKEN>
<TOKEN id="token-58-7" pos="word" morph="none" start_char="4593" end_char="4599">quienes</TOKEN>
<TOKEN id="token-58-8" pos="word" morph="none" start_char="4601" end_char="4605">Somos</TOKEN>
<TOKEN id="token-58-9" pos="punct" morph="none" start_char="4606" end_char="4606">?</TOKEN>
</SEG>
<SEG id="segment-59" start_char="4608" end_char="4676">
<ORIGINAL_TEXT>o similar, nadie parece dirigir/firmar nada...fiabilidad 0 por tanto.</ORIGINAL_TEXT>
<TOKEN id="token-59-0" pos="word" morph="none" start_char="4608" end_char="4608">o</TOKEN>
<TOKEN id="token-59-1" pos="word" morph="none" start_char="4610" end_char="4616">similar</TOKEN>
<TOKEN id="token-59-2" pos="punct" morph="none" start_char="4617" end_char="4617">,</TOKEN>
<TOKEN id="token-59-3" pos="word" morph="none" start_char="4619" end_char="4623">nadie</TOKEN>
<TOKEN id="token-59-4" pos="word" morph="none" start_char="4625" end_char="4630">parece</TOKEN>
<TOKEN id="token-59-5" pos="unknown" morph="none" start_char="4632" end_char="4645">dirigir/firmar</TOKEN>
<TOKEN id="token-59-6" pos="unknown" morph="none" start_char="4647" end_char="4663">nada...fiabilidad</TOKEN>
<TOKEN id="token-59-7" pos="word" morph="none" start_char="4665" end_char="4665">0</TOKEN>
<TOKEN id="token-59-8" pos="word" morph="none" start_char="4667" end_char="4669">por</TOKEN>
<TOKEN id="token-59-9" pos="word" morph="none" start_char="4671" end_char="4675">tanto</TOKEN>
<TOKEN id="token-59-10" pos="punct" morph="none" start_char="4676" end_char="4676">.</TOKEN>
</SEG>
<SEG id="segment-60" start_char="4682" end_char="4686">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN id="token-60-0" pos="word" morph="none" start_char="4682" end_char="4685">Cita</TOKEN>
<TOKEN id="token-60-1" pos="punct" morph="none" start_char="4686" end_char="4686">:</TOKEN>
</SEG>
<SEG id="segment-61" start_char="4691" end_char="4766">
<ORIGINAL_TEXT>Originalmente Escrito por zirick Lo fácil era cargar la culpa a un pangolin.</ORIGINAL_TEXT>
<TOKEN id="token-61-0" pos="word" morph="none" start_char="4691" end_char="4703">Originalmente</TOKEN>
<TOKEN id="token-61-1" pos="word" morph="none" start_char="4705" end_char="4711">Escrito</TOKEN>
<TOKEN id="token-61-2" pos="word" morph="none" start_char="4713" end_char="4715">por</TOKEN>
<TOKEN id="token-61-3" pos="word" morph="none" start_char="4717" end_char="4722">zirick</TOKEN>
<TOKEN id="token-61-4" pos="word" morph="none" start_char="4724" end_char="4725">Lo</TOKEN>
<TOKEN id="token-61-5" pos="word" morph="none" start_char="4727" end_char="4731">fácil</TOKEN>
<TOKEN id="token-61-6" pos="word" morph="none" start_char="4733" end_char="4735">era</TOKEN>
<TOKEN id="token-61-7" pos="word" morph="none" start_char="4737" end_char="4742">cargar</TOKEN>
<TOKEN id="token-61-8" pos="word" morph="none" start_char="4744" end_char="4745">la</TOKEN>
<TOKEN id="token-61-9" pos="word" morph="none" start_char="4747" end_char="4751">culpa</TOKEN>
<TOKEN id="token-61-10" pos="word" morph="none" start_char="4753" end_char="4753">a</TOKEN>
<TOKEN id="token-61-11" pos="word" morph="none" start_char="4755" end_char="4756">un</TOKEN>
<TOKEN id="token-61-12" pos="word" morph="none" start_char="4758" end_char="4765">pangolin</TOKEN>
<TOKEN id="token-61-13" pos="punct" morph="none" start_char="4766" end_char="4766">.</TOKEN>
</SEG>
<SEG id="segment-62" start_char="4768" end_char="4839">
<ORIGINAL_TEXT>Pero no coló Quién se cree que esta cosa tan bonita puede hacernos daño?</ORIGINAL_TEXT>
<TOKEN id="token-62-0" pos="word" morph="none" start_char="4768" end_char="4771">Pero</TOKEN>
<TOKEN id="token-62-1" pos="word" morph="none" start_char="4773" end_char="4774">no</TOKEN>
<TOKEN id="token-62-2" pos="word" morph="none" start_char="4776" end_char="4779">coló</TOKEN>
<TOKEN id="token-62-3" pos="word" morph="none" start_char="4781" end_char="4785">Quién</TOKEN>
<TOKEN id="token-62-4" pos="word" morph="none" start_char="4787" end_char="4788">se</TOKEN>
<TOKEN id="token-62-5" pos="word" morph="none" start_char="4790" end_char="4793">cree</TOKEN>
<TOKEN id="token-62-6" pos="word" morph="none" start_char="4795" end_char="4797">que</TOKEN>
<TOKEN id="token-62-7" pos="word" morph="none" start_char="4799" end_char="4802">esta</TOKEN>
<TOKEN id="token-62-8" pos="word" morph="none" start_char="4804" end_char="4807">cosa</TOKEN>
<TOKEN id="token-62-9" pos="word" morph="none" start_char="4809" end_char="4811">tan</TOKEN>
<TOKEN id="token-62-10" pos="word" morph="none" start_char="4813" end_char="4818">bonita</TOKEN>
<TOKEN id="token-62-11" pos="word" morph="none" start_char="4820" end_char="4824">puede</TOKEN>
<TOKEN id="token-62-12" pos="word" morph="none" start_char="4826" end_char="4833">hacernos</TOKEN>
<TOKEN id="token-62-13" pos="word" morph="none" start_char="4835" end_char="4838">daño</TOKEN>
<TOKEN id="token-62-14" pos="punct" morph="none" start_char="4839" end_char="4839">?</TOKEN>
</SEG>
<SEG id="segment-63" start_char="4841" end_char="4847">
<ORIGINAL_TEXT>Naaadie</ORIGINAL_TEXT>
<TOKEN id="token-63-0" pos="word" morph="none" start_char="4841" end_char="4847">Naaadie</TOKEN>
</SEG>
<SEG id="segment-64" start_char="4853" end_char="4857">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN id="token-64-0" pos="word" morph="none" start_char="4853" end_char="4856">Cita</TOKEN>
<TOKEN id="token-64-1" pos="punct" morph="none" start_char="4857" end_char="4857">:</TOKEN>
</SEG>
<SEG id="segment-65" start_char="4862" end_char="4948">
<ORIGINAL_TEXT>Originalmente Escrito por Castigator Ese tío es una eminencia en virologia..poco broma.</ORIGINAL_TEXT>
<TOKEN id="token-65-0" pos="word" morph="none" start_char="4862" end_char="4874">Originalmente</TOKEN>
<TOKEN id="token-65-1" pos="word" morph="none" start_char="4876" end_char="4882">Escrito</TOKEN>
<TOKEN id="token-65-2" pos="word" morph="none" start_char="4884" end_char="4886">por</TOKEN>
<TOKEN id="token-65-3" pos="word" morph="none" start_char="4888" end_char="4897">Castigator</TOKEN>
<TOKEN id="token-65-4" pos="word" morph="none" start_char="4899" end_char="4901">Ese</TOKEN>
<TOKEN id="token-65-5" pos="word" morph="none" start_char="4903" end_char="4905">tío</TOKEN>
<TOKEN id="token-65-6" pos="word" morph="none" start_char="4907" end_char="4908">es</TOKEN>
<TOKEN id="token-65-7" pos="word" morph="none" start_char="4910" end_char="4912">una</TOKEN>
<TOKEN id="token-65-8" pos="word" morph="none" start_char="4914" end_char="4922">eminencia</TOKEN>
<TOKEN id="token-65-9" pos="word" morph="none" start_char="4924" end_char="4925">en</TOKEN>
<TOKEN id="token-65-10" pos="unknown" morph="none" start_char="4927" end_char="4941">virologia..poco</TOKEN>
<TOKEN id="token-65-11" pos="word" morph="none" start_char="4943" end_char="4947">broma</TOKEN>
<TOKEN id="token-65-12" pos="punct" morph="none" start_char="4948" end_char="4948">.</TOKEN>
</SEG>
<SEG id="segment-66" start_char="4953" end_char="4968">
<ORIGINAL_TEXT>Es premio Nobel.</ORIGINAL_TEXT>
<TOKEN id="token-66-0" pos="word" morph="none" start_char="4953" end_char="4954">Es</TOKEN>
<TOKEN id="token-66-1" pos="word" morph="none" start_char="4956" end_char="4961">premio</TOKEN>
<TOKEN id="token-66-2" pos="word" morph="none" start_char="4963" end_char="4967">Nobel</TOKEN>
<TOKEN id="token-66-3" pos="punct" morph="none" start_char="4968" end_char="4968">.</TOKEN>
</SEG>
<SEG id="segment-67" start_char="4974" end_char="4996">
<ORIGINAL_TEXT>Falacia Ad Verecundiam.</ORIGINAL_TEXT>
<TOKEN id="token-67-0" pos="word" morph="none" start_char="4974" end_char="4980">Falacia</TOKEN>
<TOKEN id="token-67-1" pos="word" morph="none" start_char="4982" end_char="4983">Ad</TOKEN>
<TOKEN id="token-67-2" pos="word" morph="none" start_char="4985" end_char="4995">Verecundiam</TOKEN>
<TOKEN id="token-67-3" pos="punct" morph="none" start_char="4996" end_char="4996">.</TOKEN>
</SEG>
<SEG id="segment-68" start_char="4998" end_char="5021">
<ORIGINAL_TEXT>De primero de magufería.</ORIGINAL_TEXT>
<TOKEN id="token-68-0" pos="word" morph="none" start_char="4998" end_char="4999">De</TOKEN>
<TOKEN id="token-68-1" pos="word" morph="none" start_char="5001" end_char="5007">primero</TOKEN>
<TOKEN id="token-68-2" pos="word" morph="none" start_char="5009" end_char="5010">de</TOKEN>
<TOKEN id="token-68-3" pos="word" morph="none" start_char="5012" end_char="5020">magufería</TOKEN>
<TOKEN id="token-68-4" pos="punct" morph="none" start_char="5021" end_char="5021">.</TOKEN>
</SEG>
<SEG id="segment-69" start_char="5023" end_char="5053">
<ORIGINAL_TEXT>Os la cuelan como a corderitos.</ORIGINAL_TEXT>
<TOKEN id="token-69-0" pos="word" morph="none" start_char="5023" end_char="5024">Os</TOKEN>
<TOKEN id="token-69-1" pos="word" morph="none" start_char="5026" end_char="5027">la</TOKEN>
<TOKEN id="token-69-2" pos="word" morph="none" start_char="5029" end_char="5034">cuelan</TOKEN>
<TOKEN id="token-69-3" pos="word" morph="none" start_char="5036" end_char="5039">como</TOKEN>
<TOKEN id="token-69-4" pos="word" morph="none" start_char="5041" end_char="5041">a</TOKEN>
<TOKEN id="token-69-5" pos="word" morph="none" start_char="5043" end_char="5052">corderitos</TOKEN>
<TOKEN id="token-69-6" pos="punct" morph="none" start_char="5053" end_char="5053">.</TOKEN>
</SEG>
<SEG id="segment-70" start_char="5055" end_char="5280">
<ORIGINAL_TEXT>¿Qué os da más confianza, un grupo de investigadores que trabajan en un laboratorio día y noche secuenciando el genoma del virus o un Nobel de 87 años que hace 20 años que no pisa un laboratorio y opina desde la barra del bar?</ORIGINAL_TEXT>
<TOKEN id="token-70-0" pos="punct" morph="none" start_char="5055" end_char="5055">¿</TOKEN>
<TOKEN id="token-70-1" pos="word" morph="none" start_char="5056" end_char="5058">Qué</TOKEN>
<TOKEN id="token-70-2" pos="word" morph="none" start_char="5060" end_char="5061">os</TOKEN>
<TOKEN id="token-70-3" pos="word" morph="none" start_char="5063" end_char="5064">da</TOKEN>
<TOKEN id="token-70-4" pos="word" morph="none" start_char="5066" end_char="5068">más</TOKEN>
<TOKEN id="token-70-5" pos="word" morph="none" start_char="5070" end_char="5078">confianza</TOKEN>
<TOKEN id="token-70-6" pos="punct" morph="none" start_char="5079" end_char="5079">,</TOKEN>
<TOKEN id="token-70-7" pos="word" morph="none" start_char="5081" end_char="5082">un</TOKEN>
<TOKEN id="token-70-8" pos="word" morph="none" start_char="5084" end_char="5088">grupo</TOKEN>
<TOKEN id="token-70-9" pos="word" morph="none" start_char="5090" end_char="5091">de</TOKEN>
<TOKEN id="token-70-10" pos="word" morph="none" start_char="5093" end_char="5106">investigadores</TOKEN>
<TOKEN id="token-70-11" pos="word" morph="none" start_char="5108" end_char="5110">que</TOKEN>
<TOKEN id="token-70-12" pos="word" morph="none" start_char="5112" end_char="5119">trabajan</TOKEN>
<TOKEN id="token-70-13" pos="word" morph="none" start_char="5121" end_char="5122">en</TOKEN>
<TOKEN id="token-70-14" pos="word" morph="none" start_char="5124" end_char="5125">un</TOKEN>
<TOKEN id="token-70-15" pos="word" morph="none" start_char="5127" end_char="5137">laboratorio</TOKEN>
<TOKEN id="token-70-16" pos="word" morph="none" start_char="5139" end_char="5141">día</TOKEN>
<TOKEN id="token-70-17" pos="word" morph="none" start_char="5143" end_char="5143">y</TOKEN>
<TOKEN id="token-70-18" pos="word" morph="none" start_char="5145" end_char="5149">noche</TOKEN>
<TOKEN id="token-70-19" pos="word" morph="none" start_char="5151" end_char="5162">secuenciando</TOKEN>
<TOKEN id="token-70-20" pos="word" morph="none" start_char="5164" end_char="5165">el</TOKEN>
<TOKEN id="token-70-21" pos="word" morph="none" start_char="5167" end_char="5172">genoma</TOKEN>
<TOKEN id="token-70-22" pos="word" morph="none" start_char="5174" end_char="5176">del</TOKEN>
<TOKEN id="token-70-23" pos="word" morph="none" start_char="5178" end_char="5182">virus</TOKEN>
<TOKEN id="token-70-24" pos="word" morph="none" start_char="5184" end_char="5184">o</TOKEN>
<TOKEN id="token-70-25" pos="word" morph="none" start_char="5186" end_char="5187">un</TOKEN>
<TOKEN id="token-70-26" pos="word" morph="none" start_char="5189" end_char="5193">Nobel</TOKEN>
<TOKEN id="token-70-27" pos="word" morph="none" start_char="5195" end_char="5196">de</TOKEN>
<TOKEN id="token-70-28" pos="word" morph="none" start_char="5198" end_char="5199">87</TOKEN>
<TOKEN id="token-70-29" pos="word" morph="none" start_char="5201" end_char="5204">años</TOKEN>
<TOKEN id="token-70-30" pos="word" morph="none" start_char="5206" end_char="5208">que</TOKEN>
<TOKEN id="token-70-31" pos="word" morph="none" start_char="5210" end_char="5213">hace</TOKEN>
<TOKEN id="token-70-32" pos="word" morph="none" start_char="5215" end_char="5216">20</TOKEN>
<TOKEN id="token-70-33" pos="word" morph="none" start_char="5218" end_char="5221">años</TOKEN>
<TOKEN id="token-70-34" pos="word" morph="none" start_char="5223" end_char="5225">que</TOKEN>
<TOKEN id="token-70-35" pos="word" morph="none" start_char="5227" end_char="5228">no</TOKEN>
<TOKEN id="token-70-36" pos="word" morph="none" start_char="5230" end_char="5233">pisa</TOKEN>
<TOKEN id="token-70-37" pos="word" morph="none" start_char="5235" end_char="5236">un</TOKEN>
<TOKEN id="token-70-38" pos="word" morph="none" start_char="5238" end_char="5248">laboratorio</TOKEN>
<TOKEN id="token-70-39" pos="word" morph="none" start_char="5250" end_char="5250">y</TOKEN>
<TOKEN id="token-70-40" pos="word" morph="none" start_char="5252" end_char="5256">opina</TOKEN>
<TOKEN id="token-70-41" pos="word" morph="none" start_char="5258" end_char="5262">desde</TOKEN>
<TOKEN id="token-70-42" pos="word" morph="none" start_char="5264" end_char="5265">la</TOKEN>
<TOKEN id="token-70-43" pos="word" morph="none" start_char="5267" end_char="5271">barra</TOKEN>
<TOKEN id="token-70-44" pos="word" morph="none" start_char="5273" end_char="5275">del</TOKEN>
<TOKEN id="token-70-45" pos="word" morph="none" start_char="5277" end_char="5279">bar</TOKEN>
<TOKEN id="token-70-46" pos="punct" morph="none" start_char="5280" end_char="5280">?</TOKEN>
</SEG>
<SEG id="segment-71" start_char="5282" end_char="5293">
<ORIGINAL_TEXT>Vamos joder.</ORIGINAL_TEXT>
<TOKEN id="token-71-0" pos="word" morph="none" start_char="5282" end_char="5286">Vamos</TOKEN>
<TOKEN id="token-71-1" pos="word" morph="none" start_char="5288" end_char="5292">joder</TOKEN>
<TOKEN id="token-71-2" pos="punct" morph="none" start_char="5293" end_char="5293">.</TOKEN>
</SEG>
<SEG id="segment-72" start_char="5299" end_char="5303">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN id="token-72-0" pos="word" morph="none" start_char="5299" end_char="5302">Cita</TOKEN>
<TOKEN id="token-72-1" pos="punct" morph="none" start_char="5303" end_char="5303">:</TOKEN>
</SEG>
<SEG id="segment-73" start_char="5308" end_char="5405">
<ORIGINAL_TEXT>Originalmente Escrito por Nostradonuts Quién se cree que esta cosa tan bonita puede hacernos daño?</ORIGINAL_TEXT>
<TOKEN id="token-73-0" pos="word" morph="none" start_char="5308" end_char="5320">Originalmente</TOKEN>
<TOKEN id="token-73-1" pos="word" morph="none" start_char="5322" end_char="5328">Escrito</TOKEN>
<TOKEN id="token-73-2" pos="word" morph="none" start_char="5330" end_char="5332">por</TOKEN>
<TOKEN id="token-73-3" pos="word" morph="none" start_char="5334" end_char="5345">Nostradonuts</TOKEN>
<TOKEN id="token-73-4" pos="word" morph="none" start_char="5347" end_char="5351">Quién</TOKEN>
<TOKEN id="token-73-5" pos="word" morph="none" start_char="5353" end_char="5354">se</TOKEN>
<TOKEN id="token-73-6" pos="word" morph="none" start_char="5356" end_char="5359">cree</TOKEN>
<TOKEN id="token-73-7" pos="word" morph="none" start_char="5361" end_char="5363">que</TOKEN>
<TOKEN id="token-73-8" pos="word" morph="none" start_char="5365" end_char="5368">esta</TOKEN>
<TOKEN id="token-73-9" pos="word" morph="none" start_char="5370" end_char="5373">cosa</TOKEN>
<TOKEN id="token-73-10" pos="word" morph="none" start_char="5375" end_char="5377">tan</TOKEN>
<TOKEN id="token-73-11" pos="word" morph="none" start_char="5379" end_char="5384">bonita</TOKEN>
<TOKEN id="token-73-12" pos="word" morph="none" start_char="5386" end_char="5390">puede</TOKEN>
<TOKEN id="token-73-13" pos="word" morph="none" start_char="5392" end_char="5399">hacernos</TOKEN>
<TOKEN id="token-73-14" pos="word" morph="none" start_char="5401" end_char="5404">daño</TOKEN>
<TOKEN id="token-73-15" pos="punct" morph="none" start_char="5405" end_char="5405">?</TOKEN>
</SEG>
<SEG id="segment-74" start_char="5407" end_char="5413">
<ORIGINAL_TEXT>Naaadie</ORIGINAL_TEXT>
<TOKEN id="token-74-0" pos="word" morph="none" start_char="5407" end_char="5413">Naaadie</TOKEN>
</SEG>
<SEG id="segment-75" start_char="5418" end_char="5440">
<ORIGINAL_TEXT>Más majete que el copón</ORIGINAL_TEXT>
<TOKEN id="token-75-0" pos="word" morph="none" start_char="5418" end_char="5420">Más</TOKEN>
<TOKEN id="token-75-1" pos="word" morph="none" start_char="5422" end_char="5427">majete</TOKEN>
<TOKEN id="token-75-2" pos="word" morph="none" start_char="5429" end_char="5431">que</TOKEN>
<TOKEN id="token-75-3" pos="word" morph="none" start_char="5433" end_char="5434">el</TOKEN>
<TOKEN id="token-75-4" pos="word" morph="none" start_char="5436" end_char="5440">copón</TOKEN>
</SEG>
<SEG id="segment-76" start_char="5446" end_char="5450">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN id="token-76-0" pos="word" morph="none" start_char="5446" end_char="5449">Cita</TOKEN>
<TOKEN id="token-76-1" pos="punct" morph="none" start_char="5450" end_char="5450">:</TOKEN>
</SEG>
<SEG id="segment-77" start_char="5455" end_char="5572">
<ORIGINAL_TEXT>Originalmente Escrito por sipotons Unos dicen una cosa y otros otra, al final me creo más JL que a los demás, total...</ORIGINAL_TEXT>
<TOKEN id="token-77-0" pos="word" morph="none" start_char="5455" end_char="5467">Originalmente</TOKEN>
<TOKEN id="token-77-1" pos="word" morph="none" start_char="5469" end_char="5475">Escrito</TOKEN>
<TOKEN id="token-77-2" pos="word" morph="none" start_char="5477" end_char="5479">por</TOKEN>
<TOKEN id="token-77-3" pos="word" morph="none" start_char="5481" end_char="5488">sipotons</TOKEN>
<TOKEN id="token-77-4" pos="word" morph="none" start_char="5490" end_char="5493">Unos</TOKEN>
<TOKEN id="token-77-5" pos="word" morph="none" start_char="5495" end_char="5499">dicen</TOKEN>
<TOKEN id="token-77-6" pos="word" morph="none" start_char="5501" end_char="5503">una</TOKEN>
<TOKEN id="token-77-7" pos="word" morph="none" start_char="5505" end_char="5508">cosa</TOKEN>
<TOKEN id="token-77-8" pos="word" morph="none" start_char="5510" end_char="5510">y</TOKEN>
<TOKEN id="token-77-9" pos="word" morph="none" start_char="5512" end_char="5516">otros</TOKEN>
<TOKEN id="token-77-10" pos="word" morph="none" start_char="5518" end_char="5521">otra</TOKEN>
<TOKEN id="token-77-11" pos="punct" morph="none" start_char="5522" end_char="5522">,</TOKEN>
<TOKEN id="token-77-12" pos="word" morph="none" start_char="5524" end_char="5525">al</TOKEN>
<TOKEN id="token-77-13" pos="word" morph="none" start_char="5527" end_char="5531">final</TOKEN>
<TOKEN id="token-77-14" pos="word" morph="none" start_char="5533" end_char="5534">me</TOKEN>
<TOKEN id="token-77-15" pos="word" morph="none" start_char="5536" end_char="5539">creo</TOKEN>
<TOKEN id="token-77-16" pos="word" morph="none" start_char="5541" end_char="5543">más</TOKEN>
<TOKEN id="token-77-17" pos="word" morph="none" start_char="5545" end_char="5546">JL</TOKEN>
<TOKEN id="token-77-18" pos="word" morph="none" start_char="5548" end_char="5550">que</TOKEN>
<TOKEN id="token-77-19" pos="word" morph="none" start_char="5552" end_char="5552">a</TOKEN>
<TOKEN id="token-77-20" pos="word" morph="none" start_char="5554" end_char="5556">los</TOKEN>
<TOKEN id="token-77-21" pos="word" morph="none" start_char="5558" end_char="5562">demás</TOKEN>
<TOKEN id="token-77-22" pos="punct" morph="none" start_char="5563" end_char="5563">,</TOKEN>
<TOKEN id="token-77-23" pos="word" morph="none" start_char="5565" end_char="5569">total</TOKEN>
<TOKEN id="token-77-24" pos="punct" morph="none" start_char="5570" end_char="5572">...</TOKEN>
</SEG>
<SEG id="segment-78" start_char="5577" end_char="5906">
<ORIGINAL_TEXT>En mi opinión, la diferencia está en que al principio nadie sabía nada y se tenía mucho miedo a expresar una opinión mínimamente polémica en parte por corrección política y en parte por posibles represalias (económicas sobre todo) de China, que por cierto lanzó una ofensiva mediática en occidente al grito de "no seáis racistas".</ORIGINAL_TEXT>
<TOKEN id="token-78-0" pos="word" morph="none" start_char="5577" end_char="5578">En</TOKEN>
<TOKEN id="token-78-1" pos="word" morph="none" start_char="5580" end_char="5581">mi</TOKEN>
<TOKEN id="token-78-2" pos="word" morph="none" start_char="5583" end_char="5589">opinión</TOKEN>
<TOKEN id="token-78-3" pos="punct" morph="none" start_char="5590" end_char="5590">,</TOKEN>
<TOKEN id="token-78-4" pos="word" morph="none" start_char="5592" end_char="5593">la</TOKEN>
<TOKEN id="token-78-5" pos="word" morph="none" start_char="5595" end_char="5604">diferencia</TOKEN>
<TOKEN id="token-78-6" pos="word" morph="none" start_char="5606" end_char="5609">está</TOKEN>
<TOKEN id="token-78-7" pos="word" morph="none" start_char="5611" end_char="5612">en</TOKEN>
<TOKEN id="token-78-8" pos="word" morph="none" start_char="5614" end_char="5616">que</TOKEN>
<TOKEN id="token-78-9" pos="word" morph="none" start_char="5618" end_char="5619">al</TOKEN>
<TOKEN id="token-78-10" pos="word" morph="none" start_char="5621" end_char="5629">principio</TOKEN>
<TOKEN id="token-78-11" pos="word" morph="none" start_char="5631" end_char="5635">nadie</TOKEN>
<TOKEN id="token-78-12" pos="word" morph="none" start_char="5637" end_char="5641">sabía</TOKEN>
<TOKEN id="token-78-13" pos="word" morph="none" start_char="5643" end_char="5646">nada</TOKEN>
<TOKEN id="token-78-14" pos="word" morph="none" start_char="5648" end_char="5648">y</TOKEN>
<TOKEN id="token-78-15" pos="word" morph="none" start_char="5650" end_char="5651">se</TOKEN>
<TOKEN id="token-78-16" pos="word" morph="none" start_char="5653" end_char="5657">tenía</TOKEN>
<TOKEN id="token-78-17" pos="word" morph="none" start_char="5659" end_char="5663">mucho</TOKEN>
<TOKEN id="token-78-18" pos="word" morph="none" start_char="5665" end_char="5669">miedo</TOKEN>
<TOKEN id="token-78-19" pos="word" morph="none" start_char="5671" end_char="5671">a</TOKEN>
<TOKEN id="token-78-20" pos="word" morph="none" start_char="5673" end_char="5680">expresar</TOKEN>
<TOKEN id="token-78-21" pos="word" morph="none" start_char="5682" end_char="5684">una</TOKEN>
<TOKEN id="token-78-22" pos="word" morph="none" start_char="5686" end_char="5692">opinión</TOKEN>
<TOKEN id="token-78-23" pos="word" morph="none" start_char="5694" end_char="5704">mínimamente</TOKEN>
<TOKEN id="token-78-24" pos="word" morph="none" start_char="5706" end_char="5713">polémica</TOKEN>
<TOKEN id="token-78-25" pos="word" morph="none" start_char="5715" end_char="5716">en</TOKEN>
<TOKEN id="token-78-26" pos="word" morph="none" start_char="5718" end_char="5722">parte</TOKEN>
<TOKEN id="token-78-27" pos="word" morph="none" start_char="5724" end_char="5726">por</TOKEN>
<TOKEN id="token-78-28" pos="word" morph="none" start_char="5728" end_char="5737">corrección</TOKEN>
<TOKEN id="token-78-29" pos="word" morph="none" start_char="5739" end_char="5746">política</TOKEN>
<TOKEN id="token-78-30" pos="word" morph="none" start_char="5748" end_char="5748">y</TOKEN>
<TOKEN id="token-78-31" pos="word" morph="none" start_char="5750" end_char="5751">en</TOKEN>
<TOKEN id="token-78-32" pos="word" morph="none" start_char="5753" end_char="5757">parte</TOKEN>
<TOKEN id="token-78-33" pos="word" morph="none" start_char="5759" end_char="5761">por</TOKEN>
<TOKEN id="token-78-34" pos="word" morph="none" start_char="5763" end_char="5770">posibles</TOKEN>
<TOKEN id="token-78-35" pos="word" morph="none" start_char="5772" end_char="5782">represalias</TOKEN>
<TOKEN id="token-78-36" pos="punct" morph="none" start_char="5784" end_char="5784">(</TOKEN>
<TOKEN id="token-78-37" pos="word" morph="none" start_char="5785" end_char="5794">económicas</TOKEN>
<TOKEN id="token-78-38" pos="word" morph="none" start_char="5796" end_char="5800">sobre</TOKEN>
<TOKEN id="token-78-39" pos="word" morph="none" start_char="5802" end_char="5805">todo</TOKEN>
<TOKEN id="token-78-40" pos="punct" morph="none" start_char="5806" end_char="5806">)</TOKEN>
<TOKEN id="token-78-41" pos="word" morph="none" start_char="5808" end_char="5809">de</TOKEN>
<TOKEN id="token-78-42" pos="word" morph="none" start_char="5811" end_char="5815">China</TOKEN>
<TOKEN id="token-78-43" pos="punct" morph="none" start_char="5816" end_char="5816">,</TOKEN>
<TOKEN id="token-78-44" pos="word" morph="none" start_char="5818" end_char="5820">que</TOKEN>
<TOKEN id="token-78-45" pos="word" morph="none" start_char="5822" end_char="5824">por</TOKEN>
<TOKEN id="token-78-46" pos="word" morph="none" start_char="5826" end_char="5831">cierto</TOKEN>
<TOKEN id="token-78-47" pos="word" morph="none" start_char="5833" end_char="5837">lanzó</TOKEN>
<TOKEN id="token-78-48" pos="word" morph="none" start_char="5839" end_char="5841">una</TOKEN>
<TOKEN id="token-78-49" pos="word" morph="none" start_char="5843" end_char="5850">ofensiva</TOKEN>
<TOKEN id="token-78-50" pos="word" morph="none" start_char="5852" end_char="5860">mediática</TOKEN>
<TOKEN id="token-78-51" pos="word" morph="none" start_char="5862" end_char="5863">en</TOKEN>
<TOKEN id="token-78-52" pos="word" morph="none" start_char="5865" end_char="5873">occidente</TOKEN>
<TOKEN id="token-78-53" pos="word" morph="none" start_char="5875" end_char="5876">al</TOKEN>
<TOKEN id="token-78-54" pos="word" morph="none" start_char="5878" end_char="5882">grito</TOKEN>
<TOKEN id="token-78-55" pos="word" morph="none" start_char="5884" end_char="5885">de</TOKEN>
<TOKEN id="token-78-56" pos="punct" morph="none" start_char="5887" end_char="5887">"</TOKEN>
<TOKEN id="token-78-57" pos="word" morph="none" start_char="5888" end_char="5889">no</TOKEN>
<TOKEN id="token-78-58" pos="word" morph="none" start_char="5891" end_char="5895">seáis</TOKEN>
<TOKEN id="token-78-59" pos="word" morph="none" start_char="5897" end_char="5904">racistas</TOKEN>
<TOKEN id="token-78-60" pos="punct" morph="none" start_char="5905" end_char="5906">".</TOKEN>
</SEG>
<SEG id="segment-79" start_char="5908" end_char="6136">
<ORIGINAL_TEXT>Ahora ese miedo a la opinión pública se ha perdido porque la gente ha dejado la corrección política a un lado ante la tragedia y la evidente mentira que nos hemos comido como poco en el conteo de muertos y pide respuestas claras.</ORIGINAL_TEXT>
<TOKEN id="token-79-0" pos="word" morph="none" start_char="5908" end_char="5912">Ahora</TOKEN>
<TOKEN id="token-79-1" pos="word" morph="none" start_char="5914" end_char="5916">ese</TOKEN>
<TOKEN id="token-79-2" pos="word" morph="none" start_char="5918" end_char="5922">miedo</TOKEN>
<TOKEN id="token-79-3" pos="word" morph="none" start_char="5924" end_char="5924">a</TOKEN>
<TOKEN id="token-79-4" pos="word" morph="none" start_char="5926" end_char="5927">la</TOKEN>
<TOKEN id="token-79-5" pos="word" morph="none" start_char="5929" end_char="5935">opinión</TOKEN>
<TOKEN id="token-79-6" pos="word" morph="none" start_char="5937" end_char="5943">pública</TOKEN>
<TOKEN id="token-79-7" pos="word" morph="none" start_char="5945" end_char="5946">se</TOKEN>
<TOKEN id="token-79-8" pos="word" morph="none" start_char="5948" end_char="5949">ha</TOKEN>
<TOKEN id="token-79-9" pos="word" morph="none" start_char="5951" end_char="5957">perdido</TOKEN>
<TOKEN id="token-79-10" pos="word" morph="none" start_char="5959" end_char="5964">porque</TOKEN>
<TOKEN id="token-79-11" pos="word" morph="none" start_char="5966" end_char="5967">la</TOKEN>
<TOKEN id="token-79-12" pos="word" morph="none" start_char="5969" end_char="5973">gente</TOKEN>
<TOKEN id="token-79-13" pos="word" morph="none" start_char="5975" end_char="5976">ha</TOKEN>
<TOKEN id="token-79-14" pos="word" morph="none" start_char="5978" end_char="5983">dejado</TOKEN>
<TOKEN id="token-79-15" pos="word" morph="none" start_char="5985" end_char="5986">la</TOKEN>
<TOKEN id="token-79-16" pos="word" morph="none" start_char="5988" end_char="5997">corrección</TOKEN>
<TOKEN id="token-79-17" pos="word" morph="none" start_char="5999" end_char="6006">política</TOKEN>
<TOKEN id="token-79-18" pos="word" morph="none" start_char="6008" end_char="6008">a</TOKEN>
<TOKEN id="token-79-19" pos="word" morph="none" start_char="6010" end_char="6011">un</TOKEN>
<TOKEN id="token-79-20" pos="word" morph="none" start_char="6013" end_char="6016">lado</TOKEN>
<TOKEN id="token-79-21" pos="word" morph="none" start_char="6018" end_char="6021">ante</TOKEN>
<TOKEN id="token-79-22" pos="word" morph="none" start_char="6023" end_char="6024">la</TOKEN>
<TOKEN id="token-79-23" pos="word" morph="none" start_char="6026" end_char="6033">tragedia</TOKEN>
<TOKEN id="token-79-24" pos="word" morph="none" start_char="6035" end_char="6035">y</TOKEN>
<TOKEN id="token-79-25" pos="word" morph="none" start_char="6037" end_char="6038">la</TOKEN>
<TOKEN id="token-79-26" pos="word" morph="none" start_char="6040" end_char="6047">evidente</TOKEN>
<TOKEN id="token-79-27" pos="word" morph="none" start_char="6049" end_char="6055">mentira</TOKEN>
<TOKEN id="token-79-28" pos="word" morph="none" start_char="6057" end_char="6059">que</TOKEN>
<TOKEN id="token-79-29" pos="word" morph="none" start_char="6061" end_char="6063">nos</TOKEN>
<TOKEN id="token-79-30" pos="word" morph="none" start_char="6065" end_char="6069">hemos</TOKEN>
<TOKEN id="token-79-31" pos="word" morph="none" start_char="6071" end_char="6076">comido</TOKEN>
<TOKEN id="token-79-32" pos="word" morph="none" start_char="6078" end_char="6081">como</TOKEN>
<TOKEN id="token-79-33" pos="word" morph="none" start_char="6083" end_char="6086">poco</TOKEN>
<TOKEN id="token-79-34" pos="word" morph="none" start_char="6088" end_char="6089">en</TOKEN>
<TOKEN id="token-79-35" pos="word" morph="none" start_char="6091" end_char="6092">el</TOKEN>
<TOKEN id="token-79-36" pos="word" morph="none" start_char="6094" end_char="6099">conteo</TOKEN>
<TOKEN id="token-79-37" pos="word" morph="none" start_char="6101" end_char="6102">de</TOKEN>
<TOKEN id="token-79-38" pos="word" morph="none" start_char="6104" end_char="6110">muertos</TOKEN>
<TOKEN id="token-79-39" pos="word" morph="none" start_char="6112" end_char="6112">y</TOKEN>
<TOKEN id="token-79-40" pos="word" morph="none" start_char="6114" end_char="6117">pide</TOKEN>
<TOKEN id="token-79-41" pos="word" morph="none" start_char="6119" end_char="6128">respuestas</TOKEN>
<TOKEN id="token-79-42" pos="word" morph="none" start_char="6130" end_char="6135">claras</TOKEN>
<TOKEN id="token-79-43" pos="punct" morph="none" start_char="6136" end_char="6136">.</TOKEN>
</SEG>
<SEG id="segment-80" start_char="6138" end_char="6310">
<ORIGINAL_TEXT>Además, cada vez se sabe un poco más del virus, tanto por el paso del tiempo como porque la información ya no viene sesgada desde su origen y pueden estudiarlo directamente.</ORIGINAL_TEXT>
<TOKEN id="token-80-0" pos="word" morph="none" start_char="6138" end_char="6143">Además</TOKEN>
<TOKEN id="token-80-1" pos="punct" morph="none" start_char="6144" end_char="6144">,</TOKEN>
<TOKEN id="token-80-2" pos="word" morph="none" start_char="6146" end_char="6149">cada</TOKEN>
<TOKEN id="token-80-3" pos="word" morph="none" start_char="6151" end_char="6153">vez</TOKEN>
<TOKEN id="token-80-4" pos="word" morph="none" start_char="6155" end_char="6156">se</TOKEN>
<TOKEN id="token-80-5" pos="word" morph="none" start_char="6158" end_char="6161">sabe</TOKEN>
<TOKEN id="token-80-6" pos="word" morph="none" start_char="6163" end_char="6164">un</TOKEN>
<TOKEN id="token-80-7" pos="word" morph="none" start_char="6166" end_char="6169">poco</TOKEN>
<TOKEN id="token-80-8" pos="word" morph="none" start_char="6171" end_char="6173">más</TOKEN>
<TOKEN id="token-80-9" pos="word" morph="none" start_char="6175" end_char="6177">del</TOKEN>
<TOKEN id="token-80-10" pos="word" morph="none" start_char="6179" end_char="6183">virus</TOKEN>
<TOKEN id="token-80-11" pos="punct" morph="none" start_char="6184" end_char="6184">,</TOKEN>
<TOKEN id="token-80-12" pos="word" morph="none" start_char="6186" end_char="6190">tanto</TOKEN>
<TOKEN id="token-80-13" pos="word" morph="none" start_char="6192" end_char="6194">por</TOKEN>
<TOKEN id="token-80-14" pos="word" morph="none" start_char="6196" end_char="6197">el</TOKEN>
<TOKEN id="token-80-15" pos="word" morph="none" start_char="6199" end_char="6202">paso</TOKEN>
<TOKEN id="token-80-16" pos="word" morph="none" start_char="6204" end_char="6206">del</TOKEN>
<TOKEN id="token-80-17" pos="word" morph="none" start_char="6208" end_char="6213">tiempo</TOKEN>
<TOKEN id="token-80-18" pos="word" morph="none" start_char="6215" end_char="6218">como</TOKEN>
<TOKEN id="token-80-19" pos="word" morph="none" start_char="6220" end_char="6225">porque</TOKEN>
<TOKEN id="token-80-20" pos="word" morph="none" start_char="6227" end_char="6228">la</TOKEN>
<TOKEN id="token-80-21" pos="word" morph="none" start_char="6230" end_char="6240">información</TOKEN>
<TOKEN id="token-80-22" pos="word" morph="none" start_char="6242" end_char="6243">ya</TOKEN>
<TOKEN id="token-80-23" pos="word" morph="none" start_char="6245" end_char="6246">no</TOKEN>
<TOKEN id="token-80-24" pos="word" morph="none" start_char="6248" end_char="6252">viene</TOKEN>
<TOKEN id="token-80-25" pos="word" morph="none" start_char="6254" end_char="6260">sesgada</TOKEN>
<TOKEN id="token-80-26" pos="word" morph="none" start_char="6262" end_char="6266">desde</TOKEN>
<TOKEN id="token-80-27" pos="word" morph="none" start_char="6268" end_char="6269">su</TOKEN>
<TOKEN id="token-80-28" pos="word" morph="none" start_char="6271" end_char="6276">origen</TOKEN>
<TOKEN id="token-80-29" pos="word" morph="none" start_char="6278" end_char="6278">y</TOKEN>
<TOKEN id="token-80-30" pos="word" morph="none" start_char="6280" end_char="6285">pueden</TOKEN>
<TOKEN id="token-80-31" pos="word" morph="none" start_char="6287" end_char="6296">estudiarlo</TOKEN>
<TOKEN id="token-80-32" pos="word" morph="none" start_char="6298" end_char="6309">directamente</TOKEN>
<TOKEN id="token-80-33" pos="punct" morph="none" start_char="6310" end_char="6310">.</TOKEN>
</SEG>
<SEG id="segment-81" start_char="6316" end_char="6320">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN id="token-81-0" pos="word" morph="none" start_char="6316" end_char="6319">Cita</TOKEN>
<TOKEN id="token-81-1" pos="punct" morph="none" start_char="6320" end_char="6320">:</TOKEN>
</SEG>
<SEG id="segment-82" start_char="6325" end_char="6400">
<ORIGINAL_TEXT>Originalmente Escrito por zirick Lo fácil era cargar la culpa a un pangolin.</ORIGINAL_TEXT>
<TOKEN id="token-82-0" pos="word" morph="none" start_char="6325" end_char="6337">Originalmente</TOKEN>
<TOKEN id="token-82-1" pos="word" morph="none" start_char="6339" end_char="6345">Escrito</TOKEN>
<TOKEN id="token-82-2" pos="word" morph="none" start_char="6347" end_char="6349">por</TOKEN>
<TOKEN id="token-82-3" pos="word" morph="none" start_char="6351" end_char="6356">zirick</TOKEN>
<TOKEN id="token-82-4" pos="word" morph="none" start_char="6358" end_char="6359">Lo</TOKEN>
<TOKEN id="token-82-5" pos="word" morph="none" start_char="6361" end_char="6365">fácil</TOKEN>
<TOKEN id="token-82-6" pos="word" morph="none" start_char="6367" end_char="6369">era</TOKEN>
<TOKEN id="token-82-7" pos="word" morph="none" start_char="6371" end_char="6376">cargar</TOKEN>
<TOKEN id="token-82-8" pos="word" morph="none" start_char="6378" end_char="6379">la</TOKEN>
<TOKEN id="token-82-9" pos="word" morph="none" start_char="6381" end_char="6385">culpa</TOKEN>
<TOKEN id="token-82-10" pos="word" morph="none" start_char="6387" end_char="6387">a</TOKEN>
<TOKEN id="token-82-11" pos="word" morph="none" start_char="6389" end_char="6390">un</TOKEN>
<TOKEN id="token-82-12" pos="word" morph="none" start_char="6392" end_char="6399">pangolin</TOKEN>
<TOKEN id="token-82-13" pos="punct" morph="none" start_char="6400" end_char="6400">.</TOKEN>
</SEG>
<SEG id="segment-83" start_char="6402" end_char="6453">
<ORIGINAL_TEXT>Pero no coló Perdon por haber sospechado de ti, bebé</ORIGINAL_TEXT>
<TOKEN id="token-83-0" pos="word" morph="none" start_char="6402" end_char="6405">Pero</TOKEN>
<TOKEN id="token-83-1" pos="word" morph="none" start_char="6407" end_char="6408">no</TOKEN>
<TOKEN id="token-83-2" pos="word" morph="none" start_char="6410" end_char="6413">coló</TOKEN>
<TOKEN id="token-83-3" pos="word" morph="none" start_char="6415" end_char="6420">Perdon</TOKEN>
<TOKEN id="token-83-4" pos="word" morph="none" start_char="6422" end_char="6424">por</TOKEN>
<TOKEN id="token-83-5" pos="word" morph="none" start_char="6426" end_char="6430">haber</TOKEN>
<TOKEN id="token-83-6" pos="word" morph="none" start_char="6432" end_char="6441">sospechado</TOKEN>
<TOKEN id="token-83-7" pos="word" morph="none" start_char="6443" end_char="6444">de</TOKEN>
<TOKEN id="token-83-8" pos="word" morph="none" start_char="6446" end_char="6447">ti</TOKEN>
<TOKEN id="token-83-9" pos="punct" morph="none" start_char="6448" end_char="6448">,</TOKEN>
<TOKEN id="token-83-10" pos="word" morph="none" start_char="6450" end_char="6453">bebé</TOKEN>
</SEG>
<SEG id="segment-84" start_char="6459" end_char="6587">
<ORIGINAL_TEXT>De todas las ciudades que hay en el mundo resulta que el virus aparece en una ciudad china donde hay un laboratorio de virología.</ORIGINAL_TEXT>
<TOKEN id="token-84-0" pos="word" morph="none" start_char="6459" end_char="6460">De</TOKEN>
<TOKEN id="token-84-1" pos="word" morph="none" start_char="6462" end_char="6466">todas</TOKEN>
<TOKEN id="token-84-2" pos="word" morph="none" start_char="6468" end_char="6470">las</TOKEN>
<TOKEN id="token-84-3" pos="word" morph="none" start_char="6472" end_char="6479">ciudades</TOKEN>
<TOKEN id="token-84-4" pos="word" morph="none" start_char="6481" end_char="6483">que</TOKEN>
<TOKEN id="token-84-5" pos="word" morph="none" start_char="6485" end_char="6487">hay</TOKEN>
<TOKEN id="token-84-6" pos="word" morph="none" start_char="6489" end_char="6490">en</TOKEN>
<TOKEN id="token-84-7" pos="word" morph="none" start_char="6492" end_char="6493">el</TOKEN>
<TOKEN id="token-84-8" pos="word" morph="none" start_char="6495" end_char="6499">mundo</TOKEN>
<TOKEN id="token-84-9" pos="word" morph="none" start_char="6501" end_char="6507">resulta</TOKEN>
<TOKEN id="token-84-10" pos="word" morph="none" start_char="6509" end_char="6511">que</TOKEN>
<TOKEN id="token-84-11" pos="word" morph="none" start_char="6513" end_char="6514">el</TOKEN>
<TOKEN id="token-84-12" pos="word" morph="none" start_char="6516" end_char="6520">virus</TOKEN>
<TOKEN id="token-84-13" pos="word" morph="none" start_char="6522" end_char="6528">aparece</TOKEN>
<TOKEN id="token-84-14" pos="word" morph="none" start_char="6530" end_char="6531">en</TOKEN>
<TOKEN id="token-84-15" pos="word" morph="none" start_char="6533" end_char="6535">una</TOKEN>
<TOKEN id="token-84-16" pos="word" morph="none" start_char="6537" end_char="6542">ciudad</TOKEN>
<TOKEN id="token-84-17" pos="word" morph="none" start_char="6544" end_char="6548">china</TOKEN>
<TOKEN id="token-84-18" pos="word" morph="none" start_char="6550" end_char="6554">donde</TOKEN>
<TOKEN id="token-84-19" pos="word" morph="none" start_char="6556" end_char="6558">hay</TOKEN>
<TOKEN id="token-84-20" pos="word" morph="none" start_char="6560" end_char="6561">un</TOKEN>
<TOKEN id="token-84-21" pos="word" morph="none" start_char="6563" end_char="6573">laboratorio</TOKEN>
<TOKEN id="token-84-22" pos="word" morph="none" start_char="6575" end_char="6576">de</TOKEN>
<TOKEN id="token-84-23" pos="word" morph="none" start_char="6578" end_char="6586">virología</TOKEN>
<TOKEN id="token-84-24" pos="punct" morph="none" start_char="6587" end_char="6587">.</TOKEN>
</SEG>
<SEG id="segment-85" start_char="6589" end_char="6657">
<ORIGINAL_TEXT>Un laboratorio que había tenido quejas por su seguridad en el pasado.</ORIGINAL_TEXT>
<TOKEN id="token-85-0" pos="word" morph="none" start_char="6589" end_char="6590">Un</TOKEN>
<TOKEN id="token-85-1" pos="word" morph="none" start_char="6592" end_char="6602">laboratorio</TOKEN>
<TOKEN id="token-85-2" pos="word" morph="none" start_char="6604" end_char="6606">que</TOKEN>
<TOKEN id="token-85-3" pos="word" morph="none" start_char="6608" end_char="6612">había</TOKEN>
<TOKEN id="token-85-4" pos="word" morph="none" start_char="6614" end_char="6619">tenido</TOKEN>
<TOKEN id="token-85-5" pos="word" morph="none" start_char="6621" end_char="6626">quejas</TOKEN>
<TOKEN id="token-85-6" pos="word" morph="none" start_char="6628" end_char="6630">por</TOKEN>
<TOKEN id="token-85-7" pos="word" morph="none" start_char="6632" end_char="6633">su</TOKEN>
<TOKEN id="token-85-8" pos="word" morph="none" start_char="6635" end_char="6643">seguridad</TOKEN>
<TOKEN id="token-85-9" pos="word" morph="none" start_char="6645" end_char="6646">en</TOKEN>
<TOKEN id="token-85-10" pos="word" morph="none" start_char="6648" end_char="6649">el</TOKEN>
<TOKEN id="token-85-11" pos="word" morph="none" start_char="6651" end_char="6656">pasado</TOKEN>
<TOKEN id="token-85-12" pos="punct" morph="none" start_char="6657" end_char="6657">.</TOKEN>
</SEG>
<SEG id="segment-86" start_char="6659" end_char="6780">
<ORIGINAL_TEXT>Pero lo que me hace pensar que se les ha escapado es sobretodo que se pusieron a construir hospitales desde el minuto uno.</ORIGINAL_TEXT>
<TOKEN id="token-86-0" pos="word" morph="none" start_char="6659" end_char="6662">Pero</TOKEN>
<TOKEN id="token-86-1" pos="word" morph="none" start_char="6664" end_char="6665">lo</TOKEN>
<TOKEN id="token-86-2" pos="word" morph="none" start_char="6667" end_char="6669">que</TOKEN>
<TOKEN id="token-86-3" pos="word" morph="none" start_char="6671" end_char="6672">me</TOKEN>
<TOKEN id="token-86-4" pos="word" morph="none" start_char="6674" end_char="6677">hace</TOKEN>
<TOKEN id="token-86-5" pos="word" morph="none" start_char="6679" end_char="6684">pensar</TOKEN>
<TOKEN id="token-86-6" pos="word" morph="none" start_char="6686" end_char="6688">que</TOKEN>
<TOKEN id="token-86-7" pos="word" morph="none" start_char="6690" end_char="6691">se</TOKEN>
<TOKEN id="token-86-8" pos="word" morph="none" start_char="6693" end_char="6695">les</TOKEN>
<TOKEN id="token-86-9" pos="word" morph="none" start_char="6697" end_char="6698">ha</TOKEN>
<TOKEN id="token-86-10" pos="word" morph="none" start_char="6700" end_char="6707">escapado</TOKEN>
<TOKEN id="token-86-11" pos="word" morph="none" start_char="6709" end_char="6710">es</TOKEN>
<TOKEN id="token-86-12" pos="word" morph="none" start_char="6712" end_char="6720">sobretodo</TOKEN>
<TOKEN id="token-86-13" pos="word" morph="none" start_char="6722" end_char="6724">que</TOKEN>
<TOKEN id="token-86-14" pos="word" morph="none" start_char="6726" end_char="6727">se</TOKEN>
<TOKEN id="token-86-15" pos="word" morph="none" start_char="6729" end_char="6736">pusieron</TOKEN>
<TOKEN id="token-86-16" pos="word" morph="none" start_char="6738" end_char="6738">a</TOKEN>
<TOKEN id="token-86-17" pos="word" morph="none" start_char="6740" end_char="6748">construir</TOKEN>
<TOKEN id="token-86-18" pos="word" morph="none" start_char="6750" end_char="6759">hospitales</TOKEN>
<TOKEN id="token-86-19" pos="word" morph="none" start_char="6761" end_char="6765">desde</TOKEN>
<TOKEN id="token-86-20" pos="word" morph="none" start_char="6767" end_char="6768">el</TOKEN>
<TOKEN id="token-86-21" pos="word" morph="none" start_char="6770" end_char="6775">minuto</TOKEN>
<TOKEN id="token-86-22" pos="word" morph="none" start_char="6777" end_char="6779">uno</TOKEN>
<TOKEN id="token-86-23" pos="punct" morph="none" start_char="6780" end_char="6780">.</TOKEN>
</SEG>
<SEG id="segment-87" start_char="6782" end_char="6941">
<ORIGINAL_TEXT>Coño, eso no lo haces hasta analizar bien la letalidad y la tasa de contagio del virus porque desconoces su gravedad; lo que ha pasado en occidente básicamente.</ORIGINAL_TEXT>
<TOKEN id="token-87-0" pos="word" morph="none" start_char="6782" end_char="6785">Coño</TOKEN>
<TOKEN id="token-87-1" pos="punct" morph="none" start_char="6786" end_char="6786">,</TOKEN>
<TOKEN id="token-87-2" pos="word" morph="none" start_char="6788" end_char="6790">eso</TOKEN>
<TOKEN id="token-87-3" pos="word" morph="none" start_char="6792" end_char="6793">no</TOKEN>
<TOKEN id="token-87-4" pos="word" morph="none" start_char="6795" end_char="6796">lo</TOKEN>
<TOKEN id="token-87-5" pos="word" morph="none" start_char="6798" end_char="6802">haces</TOKEN>
<TOKEN id="token-87-6" pos="word" morph="none" start_char="6804" end_char="6808">hasta</TOKEN>
<TOKEN id="token-87-7" pos="word" morph="none" start_char="6810" end_char="6817">analizar</TOKEN>
<TOKEN id="token-87-8" pos="word" morph="none" start_char="6819" end_char="6822">bien</TOKEN>
<TOKEN id="token-87-9" pos="word" morph="none" start_char="6824" end_char="6825">la</TOKEN>
<TOKEN id="token-87-10" pos="word" morph="none" start_char="6827" end_char="6835">letalidad</TOKEN>
<TOKEN id="token-87-11" pos="word" morph="none" start_char="6837" end_char="6837">y</TOKEN>
<TOKEN id="token-87-12" pos="word" morph="none" start_char="6839" end_char="6840">la</TOKEN>
<TOKEN id="token-87-13" pos="word" morph="none" start_char="6842" end_char="6845">tasa</TOKEN>
<TOKEN id="token-87-14" pos="word" morph="none" start_char="6847" end_char="6848">de</TOKEN>
<TOKEN id="token-87-15" pos="word" morph="none" start_char="6850" end_char="6857">contagio</TOKEN>
<TOKEN id="token-87-16" pos="word" morph="none" start_char="6859" end_char="6861">del</TOKEN>
<TOKEN id="token-87-17" pos="word" morph="none" start_char="6863" end_char="6867">virus</TOKEN>
<TOKEN id="token-87-18" pos="word" morph="none" start_char="6869" end_char="6874">porque</TOKEN>
<TOKEN id="token-87-19" pos="word" morph="none" start_char="6876" end_char="6885">desconoces</TOKEN>
<TOKEN id="token-87-20" pos="word" morph="none" start_char="6887" end_char="6888">su</TOKEN>
<TOKEN id="token-87-21" pos="word" morph="none" start_char="6890" end_char="6897">gravedad</TOKEN>
<TOKEN id="token-87-22" pos="punct" morph="none" start_char="6898" end_char="6898">;</TOKEN>
<TOKEN id="token-87-23" pos="word" morph="none" start_char="6900" end_char="6901">lo</TOKEN>
<TOKEN id="token-87-24" pos="word" morph="none" start_char="6903" end_char="6905">que</TOKEN>
<TOKEN id="token-87-25" pos="word" morph="none" start_char="6907" end_char="6908">ha</TOKEN>
<TOKEN id="token-87-26" pos="word" morph="none" start_char="6910" end_char="6915">pasado</TOKEN>
<TOKEN id="token-87-27" pos="word" morph="none" start_char="6917" end_char="6918">en</TOKEN>
<TOKEN id="token-87-28" pos="word" morph="none" start_char="6920" end_char="6928">occidente</TOKEN>
<TOKEN id="token-87-29" pos="word" morph="none" start_char="6930" end_char="6940">básicamente</TOKEN>
<TOKEN id="token-87-30" pos="punct" morph="none" start_char="6941" end_char="6941">.</TOKEN>
</SEG>
<SEG id="segment-88" start_char="6943" end_char="7030">
<ORIGINAL_TEXT>A no ser que lo supieses desde el primer momento.... porque lo tenías más que analizado.</ORIGINAL_TEXT>
<TOKEN id="token-88-0" pos="word" morph="none" start_char="6943" end_char="6943">A</TOKEN>
<TOKEN id="token-88-1" pos="word" morph="none" start_char="6945" end_char="6946">no</TOKEN>
<TOKEN id="token-88-2" pos="word" morph="none" start_char="6948" end_char="6950">ser</TOKEN>
<TOKEN id="token-88-3" pos="word" morph="none" start_char="6952" end_char="6954">que</TOKEN>
<TOKEN id="token-88-4" pos="word" morph="none" start_char="6956" end_char="6957">lo</TOKEN>
<TOKEN id="token-88-5" pos="word" morph="none" start_char="6959" end_char="6966">supieses</TOKEN>
<TOKEN id="token-88-6" pos="word" morph="none" start_char="6968" end_char="6972">desde</TOKEN>
<TOKEN id="token-88-7" pos="word" morph="none" start_char="6974" end_char="6975">el</TOKEN>
<TOKEN id="token-88-8" pos="word" morph="none" start_char="6977" end_char="6982">primer</TOKEN>
<TOKEN id="token-88-9" pos="word" morph="none" start_char="6984" end_char="6990">momento</TOKEN>
<TOKEN id="token-88-10" pos="punct" morph="none" start_char="6991" end_char="6994">....</TOKEN>
<TOKEN id="token-88-11" pos="word" morph="none" start_char="6996" end_char="7001">porque</TOKEN>
<TOKEN id="token-88-12" pos="word" morph="none" start_char="7003" end_char="7004">lo</TOKEN>
<TOKEN id="token-88-13" pos="word" morph="none" start_char="7006" end_char="7011">tenías</TOKEN>
<TOKEN id="token-88-14" pos="word" morph="none" start_char="7013" end_char="7015">más</TOKEN>
<TOKEN id="token-88-15" pos="word" morph="none" start_char="7017" end_char="7019">que</TOKEN>
<TOKEN id="token-88-16" pos="word" morph="none" start_char="7021" end_char="7029">analizado</TOKEN>
<TOKEN id="token-88-17" pos="punct" morph="none" start_char="7030" end_char="7030">.</TOKEN>
</SEG>
<SEG id="segment-89" start_char="7032" end_char="7062">
<ORIGINAL_TEXT>Vamos, que blanco y en botella.</ORIGINAL_TEXT>
<TOKEN id="token-89-0" pos="word" morph="none" start_char="7032" end_char="7036">Vamos</TOKEN>
<TOKEN id="token-89-1" pos="punct" morph="none" start_char="7037" end_char="7037">,</TOKEN>
<TOKEN id="token-89-2" pos="word" morph="none" start_char="7039" end_char="7041">que</TOKEN>
<TOKEN id="token-89-3" pos="word" morph="none" start_char="7043" end_char="7048">blanco</TOKEN>
<TOKEN id="token-89-4" pos="word" morph="none" start_char="7050" end_char="7050">y</TOKEN>
<TOKEN id="token-89-5" pos="word" morph="none" start_char="7052" end_char="7053">en</TOKEN>
<TOKEN id="token-89-6" pos="word" morph="none" start_char="7055" end_char="7061">botella</TOKEN>
<TOKEN id="token-89-7" pos="punct" morph="none" start_char="7062" end_char="7062">.</TOKEN>
</SEG>
<SEG id="segment-90" start_char="7068" end_char="7120">
<ORIGINAL_TEXT>Montagnier lleva ya muchos años diciendo gilipolleces</ORIGINAL_TEXT>
<TOKEN id="token-90-0" pos="word" morph="none" start_char="7068" end_char="7077">Montagnier</TOKEN>
<TOKEN id="token-90-1" pos="word" morph="none" start_char="7079" end_char="7083">lleva</TOKEN>
<TOKEN id="token-90-2" pos="word" morph="none" start_char="7085" end_char="7086">ya</TOKEN>
<TOKEN id="token-90-3" pos="word" morph="none" start_char="7088" end_char="7093">muchos</TOKEN>
<TOKEN id="token-90-4" pos="word" morph="none" start_char="7095" end_char="7098">años</TOKEN>
<TOKEN id="token-90-5" pos="word" morph="none" start_char="7100" end_char="7107">diciendo</TOKEN>
<TOKEN id="token-90-6" pos="word" morph="none" start_char="7109" end_char="7120">gilipolleces</TOKEN>
</SEG>
<SEG id="segment-91" start_char="7126" end_char="7139">
<ORIGINAL_TEXT>Foropangolines</ORIGINAL_TEXT>
<TOKEN id="token-91-0" pos="word" morph="none" start_char="7126" end_char="7139">Foropangolines</TOKEN>
</SEG>
<SEG id="segment-92" start_char="7145" end_char="7200">
<ORIGINAL_TEXT>si se descubre que asi es, hay que aniquilar al creador.</ORIGINAL_TEXT>
<TOKEN id="token-92-0" pos="word" morph="none" start_char="7145" end_char="7146">si</TOKEN>
<TOKEN id="token-92-1" pos="word" morph="none" start_char="7148" end_char="7149">se</TOKEN>
<TOKEN id="token-92-2" pos="word" morph="none" start_char="7151" end_char="7158">descubre</TOKEN>
<TOKEN id="token-92-3" pos="word" morph="none" start_char="7160" end_char="7162">que</TOKEN>
<TOKEN id="token-92-4" pos="word" morph="none" start_char="7164" end_char="7166">asi</TOKEN>
<TOKEN id="token-92-5" pos="word" morph="none" start_char="7168" end_char="7169">es</TOKEN>
<TOKEN id="token-92-6" pos="punct" morph="none" start_char="7170" end_char="7170">,</TOKEN>
<TOKEN id="token-92-7" pos="word" morph="none" start_char="7172" end_char="7174">hay</TOKEN>
<TOKEN id="token-92-8" pos="word" morph="none" start_char="7176" end_char="7178">que</TOKEN>
<TOKEN id="token-92-9" pos="word" morph="none" start_char="7180" end_char="7188">aniquilar</TOKEN>
<TOKEN id="token-92-10" pos="word" morph="none" start_char="7190" end_char="7191">al</TOKEN>
<TOKEN id="token-92-11" pos="word" morph="none" start_char="7193" end_char="7199">creador</TOKEN>
<TOKEN id="token-92-12" pos="punct" morph="none" start_char="7200" end_char="7200">.</TOKEN>
</SEG>
<SEG id="segment-93" start_char="7206" end_char="7254">
<ORIGINAL_TEXT>Este no es también el que defendia la homeopatia?</ORIGINAL_TEXT>
<TOKEN id="token-93-0" pos="word" morph="none" start_char="7206" end_char="7209">Este</TOKEN>
<TOKEN id="token-93-1" pos="word" morph="none" start_char="7211" end_char="7212">no</TOKEN>
<TOKEN id="token-93-2" pos="word" morph="none" start_char="7214" end_char="7215">es</TOKEN>
<TOKEN id="token-93-3" pos="word" morph="none" start_char="7217" end_char="7223">también</TOKEN>
<TOKEN id="token-93-4" pos="word" morph="none" start_char="7225" end_char="7226">el</TOKEN>
<TOKEN id="token-93-5" pos="word" morph="none" start_char="7228" end_char="7230">que</TOKEN>
<TOKEN id="token-93-6" pos="word" morph="none" start_char="7232" end_char="7239">defendia</TOKEN>
<TOKEN id="token-93-7" pos="word" morph="none" start_char="7241" end_char="7242">la</TOKEN>
<TOKEN id="token-93-8" pos="word" morph="none" start_char="7244" end_char="7253">homeopatia</TOKEN>
<TOKEN id="token-93-9" pos="punct" morph="none" start_char="7254" end_char="7254">?</TOKEN>
</SEG>
<SEG id="segment-94" start_char="7260" end_char="7266">
<ORIGINAL_TEXT>Y esto?</ORIGINAL_TEXT>
<TOKEN id="token-94-0" pos="word" morph="none" start_char="7260" end_char="7260">Y</TOKEN>
<TOKEN id="token-94-1" pos="word" morph="none" start_char="7262" end_char="7265">esto</TOKEN>
<TOKEN id="token-94-2" pos="punct" morph="none" start_char="7266" end_char="7266">?</TOKEN>
</SEG>
<SEG id="segment-95" start_char="7268" end_char="7357">
<ORIGINAL_TEXT>Jaaaaaaaaaaaaaaaaaaaaaaaaaa El premio nobel Luc Montagnier se toma la homeopatía en serio.</ORIGINAL_TEXT>
<TOKEN id="token-95-0" pos="word" morph="none" start_char="7268" end_char="7294">Jaaaaaaaaaaaaaaaaaaaaaaaaaa</TOKEN>
<TOKEN id="token-95-1" pos="word" morph="none" start_char="7296" end_char="7297">El</TOKEN>
<TOKEN id="token-95-2" pos="word" morph="none" start_char="7299" end_char="7304">premio</TOKEN>
<TOKEN id="token-95-3" pos="word" morph="none" start_char="7306" end_char="7310">nobel</TOKEN>
<TOKEN id="token-95-4" pos="word" morph="none" start_char="7312" end_char="7314">Luc</TOKEN>
<TOKEN id="token-95-5" pos="word" morph="none" start_char="7316" end_char="7325">Montagnier</TOKEN>
<TOKEN id="token-95-6" pos="word" morph="none" start_char="7327" end_char="7328">se</TOKEN>
<TOKEN id="token-95-7" pos="word" morph="none" start_char="7330" end_char="7333">toma</TOKEN>
<TOKEN id="token-95-8" pos="word" morph="none" start_char="7335" end_char="7336">la</TOKEN>
<TOKEN id="token-95-9" pos="word" morph="none" start_char="7338" end_char="7347">homeopatía</TOKEN>
<TOKEN id="token-95-10" pos="word" morph="none" start_char="7349" end_char="7350">en</TOKEN>
<TOKEN id="token-95-11" pos="word" morph="none" start_char="7352" end_char="7356">serio</TOKEN>
<TOKEN id="token-95-12" pos="punct" morph="none" start_char="7357" end_char="7357">.</TOKEN>
</SEG>
<SEG id="segment-96" start_char="7359" end_char="7585">
<ORIGINAL_TEXT>https://www.elsevier.es/es-revista-r...88852611700947 El Nobel Luc Montagnier:"La base científica de la homeopatía se ignora porque se silencia lo que molesta a la economía" https://www.google.es/amp/s/amp.20mi...esta-economia/</ORIGINAL_TEXT>
<TOKEN id="token-96-0" pos="url" morph="none" start_char="7359" end_char="7411">https://www.elsevier.es/es-revista-r...88852611700947</TOKEN>
<TOKEN id="token-96-1" pos="word" morph="none" start_char="7413" end_char="7414">El</TOKEN>
<TOKEN id="token-96-2" pos="word" morph="none" start_char="7416" end_char="7420">Nobel</TOKEN>
<TOKEN id="token-96-3" pos="word" morph="none" start_char="7422" end_char="7424">Luc</TOKEN>
<TOKEN id="token-96-4" pos="unknown" morph="none" start_char="7426" end_char="7439">Montagnier:"La</TOKEN>
<TOKEN id="token-96-5" pos="word" morph="none" start_char="7441" end_char="7444">base</TOKEN>
<TOKEN id="token-96-6" pos="word" morph="none" start_char="7446" end_char="7455">científica</TOKEN>
<TOKEN id="token-96-7" pos="word" morph="none" start_char="7457" end_char="7458">de</TOKEN>
<TOKEN id="token-96-8" pos="word" morph="none" start_char="7460" end_char="7461">la</TOKEN>
<TOKEN id="token-96-9" pos="word" morph="none" start_char="7463" end_char="7472">homeopatía</TOKEN>
<TOKEN id="token-96-10" pos="word" morph="none" start_char="7474" end_char="7475">se</TOKEN>
<TOKEN id="token-96-11" pos="word" morph="none" start_char="7477" end_char="7482">ignora</TOKEN>
<TOKEN id="token-96-12" pos="word" morph="none" start_char="7484" end_char="7489">porque</TOKEN>
<TOKEN id="token-96-13" pos="word" morph="none" start_char="7491" end_char="7492">se</TOKEN>
<TOKEN id="token-96-14" pos="word" morph="none" start_char="7494" end_char="7501">silencia</TOKEN>
<TOKEN id="token-96-15" pos="word" morph="none" start_char="7503" end_char="7504">lo</TOKEN>
<TOKEN id="token-96-16" pos="word" morph="none" start_char="7506" end_char="7508">que</TOKEN>
<TOKEN id="token-96-17" pos="word" morph="none" start_char="7510" end_char="7516">molesta</TOKEN>
<TOKEN id="token-96-18" pos="word" morph="none" start_char="7518" end_char="7518">a</TOKEN>
<TOKEN id="token-96-19" pos="word" morph="none" start_char="7520" end_char="7521">la</TOKEN>
<TOKEN id="token-96-20" pos="word" morph="none" start_char="7523" end_char="7530">economía</TOKEN>
<TOKEN id="token-96-21" pos="punct" morph="none" start_char="7531" end_char="7531">"</TOKEN>
<TOKEN id="token-96-22" pos="url" morph="none" start_char="7533" end_char="7585">https://www.google.es/amp/s/amp.20mi...esta-economia/</TOKEN>
</SEG>
<SEG id="segment-97" start_char="7592" end_char="7637">
<ORIGINAL_TEXT>Instagram Embed (@forocoches) Recarga para ver</ORIGINAL_TEXT>
<TOKEN id="token-97-0" pos="word" morph="none" start_char="7592" end_char="7600">Instagram</TOKEN>
<TOKEN id="token-97-1" pos="word" morph="none" start_char="7602" end_char="7606">Embed</TOKEN>
<TOKEN id="token-97-2" pos="punct" morph="none" start_char="7608" end_char="7609">(@</TOKEN>
<TOKEN id="token-97-3" pos="word" morph="none" start_char="7610" end_char="7619">forocoches</TOKEN>
<TOKEN id="token-97-4" pos="punct" morph="none" start_char="7620" end_char="7620">)</TOKEN>
<TOKEN id="token-97-5" pos="word" morph="none" start_char="7622" end_char="7628">Recarga</TOKEN>
<TOKEN id="token-97-6" pos="word" morph="none" start_char="7630" end_char="7633">para</TOKEN>
<TOKEN id="token-97-7" pos="word" morph="none" start_char="7635" end_char="7637">ver</TOKEN>
</SEG>
<SEG id="segment-98" start_char="7640" end_char="7670">
<ORIGINAL_TEXT>Dejaros de conspiraciones anda.</ORIGINAL_TEXT>
<TOKEN id="token-98-0" pos="word" morph="none" start_char="7640" end_char="7646">Dejaros</TOKEN>
<TOKEN id="token-98-1" pos="word" morph="none" start_char="7648" end_char="7649">de</TOKEN>
<TOKEN id="token-98-2" pos="word" morph="none" start_char="7651" end_char="7664">conspiraciones</TOKEN>
<TOKEN id="token-98-3" pos="word" morph="none" start_char="7666" end_char="7669">anda</TOKEN>
<TOKEN id="token-98-4" pos="punct" morph="none" start_char="7670" end_char="7670">.</TOKEN>
</SEG>
<SEG id="segment-99" start_char="7672" end_char="7773">
<ORIGINAL_TEXT>La comunidad científica es clara respecto a esto Ese hombre esta ya chocheando por mucho nobel que sea</ORIGINAL_TEXT>
<TOKEN id="token-99-0" pos="word" morph="none" start_char="7672" end_char="7673">La</TOKEN>
<TOKEN id="token-99-1" pos="word" morph="none" start_char="7675" end_char="7683">comunidad</TOKEN>
<TOKEN id="token-99-2" pos="word" morph="none" start_char="7685" end_char="7694">científica</TOKEN>
<TOKEN id="token-99-3" pos="word" morph="none" start_char="7696" end_char="7697">es</TOKEN>
<TOKEN id="token-99-4" pos="word" morph="none" start_char="7699" end_char="7703">clara</TOKEN>
<TOKEN id="token-99-5" pos="word" morph="none" start_char="7705" end_char="7712">respecto</TOKEN>
<TOKEN id="token-99-6" pos="word" morph="none" start_char="7714" end_char="7714">a</TOKEN>
<TOKEN id="token-99-7" pos="word" morph="none" start_char="7716" end_char="7719">esto</TOKEN>
<TOKEN id="token-99-8" pos="word" morph="none" start_char="7721" end_char="7723">Ese</TOKEN>
<TOKEN id="token-99-9" pos="word" morph="none" start_char="7725" end_char="7730">hombre</TOKEN>
<TOKEN id="token-99-10" pos="word" morph="none" start_char="7732" end_char="7735">esta</TOKEN>
<TOKEN id="token-99-11" pos="word" morph="none" start_char="7737" end_char="7738">ya</TOKEN>
<TOKEN id="token-99-12" pos="word" morph="none" start_char="7740" end_char="7749">chocheando</TOKEN>
<TOKEN id="token-99-13" pos="word" morph="none" start_char="7751" end_char="7753">por</TOKEN>
<TOKEN id="token-99-14" pos="word" morph="none" start_char="7755" end_char="7759">mucho</TOKEN>
<TOKEN id="token-99-15" pos="word" morph="none" start_char="7761" end_char="7765">nobel</TOKEN>
<TOKEN id="token-99-16" pos="word" morph="none" start_char="7767" end_char="7769">que</TOKEN>
<TOKEN id="token-99-17" pos="word" morph="none" start_char="7771" end_char="7773">sea</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
