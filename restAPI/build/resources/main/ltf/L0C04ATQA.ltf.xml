<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATQA" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="3375" raw_text_md5="921297fd1069b7a9d16109f24c3e9c56">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="91">
<ORIGINAL_TEXT>El primer caso oficial de covid en Italia se detectó en Lombardía el 21 de febrero de 2020.</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="2">El</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="4" end_char="9">primer</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="11" end_char="14">caso</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="16" end_char="22">oficial</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="24" end_char="25">de</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="27" end_char="31">covid</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="33" end_char="34">en</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="36" end_char="41">Italia</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="43" end_char="44">se</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="46" end_char="52">detectó</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="54" end_char="55">en</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="57" end_char="65">Lombardía</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="67" end_char="68">el</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="70" end_char="71">21</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="73" end_char="74">de</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="76" end_char="82">febrero</TOKEN>
<TOKEN id="token-0-16" pos="word" morph="none" start_char="84" end_char="85">de</TOKEN>
<TOKEN id="token-0-17" pos="word" morph="none" start_char="87" end_char="90">2020</TOKEN>
<TOKEN id="token-0-18" pos="punct" morph="none" start_char="91" end_char="91">.</TOKEN>
</SEG>
<SEG id="segment-1" start_char="95" end_char="333">
<ORIGINAL_TEXT>Un artículo publicado en Tumori Journal y realizado por el Instituto del Cáncer de Milán, Italia encontró que la Covid-19 ya circulaba en el verano del 2019 en territorio italiano, mucho antes de que se informara del virus en Wuhan, China.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="95" end_char="96">Un</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="98" end_char="105">artículo</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="107" end_char="115">publicado</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="117" end_char="118">en</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="120" end_char="125">Tumori</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="127" end_char="133">Journal</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="135" end_char="135">y</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="137" end_char="145">realizado</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="147" end_char="149">por</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="151" end_char="152">el</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="154" end_char="162">Instituto</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="164" end_char="166">del</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="168" end_char="173">Cáncer</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="175" end_char="176">de</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="178" end_char="182">Milán</TOKEN>
<TOKEN id="token-1-15" pos="punct" morph="none" start_char="183" end_char="183">,</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="185" end_char="190">Italia</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="192" end_char="199">encontró</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="201" end_char="203">que</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="205" end_char="206">la</TOKEN>
<TOKEN id="token-1-20" pos="unknown" morph="none" start_char="208" end_char="215">Covid-19</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="217" end_char="218">ya</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="220" end_char="228">circulaba</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="230" end_char="231">en</TOKEN>
<TOKEN id="token-1-24" pos="word" morph="none" start_char="233" end_char="234">el</TOKEN>
<TOKEN id="token-1-25" pos="word" morph="none" start_char="236" end_char="241">verano</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="243" end_char="245">del</TOKEN>
<TOKEN id="token-1-27" pos="word" morph="none" start_char="247" end_char="250">2019</TOKEN>
<TOKEN id="token-1-28" pos="word" morph="none" start_char="252" end_char="253">en</TOKEN>
<TOKEN id="token-1-29" pos="word" morph="none" start_char="255" end_char="264">territorio</TOKEN>
<TOKEN id="token-1-30" pos="word" morph="none" start_char="266" end_char="273">italiano</TOKEN>
<TOKEN id="token-1-31" pos="punct" morph="none" start_char="274" end_char="274">,</TOKEN>
<TOKEN id="token-1-32" pos="word" morph="none" start_char="276" end_char="280">mucho</TOKEN>
<TOKEN id="token-1-33" pos="word" morph="none" start_char="282" end_char="286">antes</TOKEN>
<TOKEN id="token-1-34" pos="word" morph="none" start_char="288" end_char="289">de</TOKEN>
<TOKEN id="token-1-35" pos="word" morph="none" start_char="291" end_char="293">que</TOKEN>
<TOKEN id="token-1-36" pos="word" morph="none" start_char="295" end_char="296">se</TOKEN>
<TOKEN id="token-1-37" pos="word" morph="none" start_char="298" end_char="306">informara</TOKEN>
<TOKEN id="token-1-38" pos="word" morph="none" start_char="308" end_char="310">del</TOKEN>
<TOKEN id="token-1-39" pos="word" morph="none" start_char="312" end_char="316">virus</TOKEN>
<TOKEN id="token-1-40" pos="word" morph="none" start_char="318" end_char="319">en</TOKEN>
<TOKEN id="token-1-41" pos="word" morph="none" start_char="321" end_char="325">Wuhan</TOKEN>
<TOKEN id="token-1-42" pos="punct" morph="none" start_char="326" end_char="326">,</TOKEN>
<TOKEN id="token-1-43" pos="word" morph="none" start_char="328" end_char="332">China</TOKEN>
<TOKEN id="token-1-44" pos="punct" morph="none" start_char="333" end_char="333">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="335" end_char="492">
<ORIGINAL_TEXT>La circulación en Italia comenzaría aproximadamente desde septiembre de 2019 lo que indicaría que se extendió fuera de China mucho antes de lo que se pensaba.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="335" end_char="336">La</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="338" end_char="348">circulación</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="350" end_char="351">en</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="353" end_char="358">Italia</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="360" end_char="369">comenzaría</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="371" end_char="385">aproximadamente</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="387" end_char="391">desde</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="393" end_char="402">septiembre</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="404" end_char="405">de</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="407" end_char="410">2019</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="412" end_char="413">lo</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="415" end_char="417">que</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="419" end_char="427">indicaría</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="429" end_char="431">que</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="433" end_char="434">se</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="436" end_char="443">extendió</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="445" end_char="449">fuera</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="451" end_char="452">de</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="454" end_char="458">China</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="460" end_char="464">mucho</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="466" end_char="470">antes</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="472" end_char="473">de</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="475" end_char="476">lo</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="478" end_char="480">que</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="482" end_char="483">se</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="485" end_char="491">pensaba</TOKEN>
<TOKEN id="token-2-26" pos="punct" morph="none" start_char="492" end_char="492">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="495" end_char="876">
<ORIGINAL_TEXT>El primer paciente se detectó de manera oficial en Lombardía, en un pequeño pueblo en la región norte del país el 21 de febrero de 2020, sin embargo, un estudio publicado en Tumori Journal encontró que un grupo de personas sanas que se inscribieron en un estudio para la detección del cáncer de pulmón ya habían desarrollado anticuerpos contra el coronavirus desde febrero del 2019.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="495" end_char="496">El</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="498" end_char="503">primer</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="505" end_char="512">paciente</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="514" end_char="515">se</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="517" end_char="523">detectó</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="525" end_char="526">de</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="528" end_char="533">manera</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="535" end_char="541">oficial</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="543" end_char="544">en</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="546" end_char="554">Lombardía</TOKEN>
<TOKEN id="token-3-10" pos="punct" morph="none" start_char="555" end_char="555">,</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="557" end_char="558">en</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="560" end_char="561">un</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="563" end_char="569">pequeño</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="571" end_char="576">pueblo</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="578" end_char="579">en</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="581" end_char="582">la</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="584" end_char="589">región</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="591" end_char="595">norte</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="597" end_char="599">del</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="601" end_char="604">país</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="606" end_char="607">el</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="609" end_char="610">21</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="612" end_char="613">de</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="615" end_char="621">febrero</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="623" end_char="624">de</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="626" end_char="629">2020</TOKEN>
<TOKEN id="token-3-27" pos="punct" morph="none" start_char="630" end_char="630">,</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="632" end_char="634">sin</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="636" end_char="642">embargo</TOKEN>
<TOKEN id="token-3-30" pos="punct" morph="none" start_char="643" end_char="643">,</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="645" end_char="646">un</TOKEN>
<TOKEN id="token-3-32" pos="word" morph="none" start_char="648" end_char="654">estudio</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="656" end_char="664">publicado</TOKEN>
<TOKEN id="token-3-34" pos="word" morph="none" start_char="666" end_char="667">en</TOKEN>
<TOKEN id="token-3-35" pos="word" morph="none" start_char="669" end_char="674">Tumori</TOKEN>
<TOKEN id="token-3-36" pos="word" morph="none" start_char="676" end_char="682">Journal</TOKEN>
<TOKEN id="token-3-37" pos="word" morph="none" start_char="684" end_char="691">encontró</TOKEN>
<TOKEN id="token-3-38" pos="word" morph="none" start_char="693" end_char="695">que</TOKEN>
<TOKEN id="token-3-39" pos="word" morph="none" start_char="697" end_char="698">un</TOKEN>
<TOKEN id="token-3-40" pos="word" morph="none" start_char="700" end_char="704">grupo</TOKEN>
<TOKEN id="token-3-41" pos="word" morph="none" start_char="706" end_char="707">de</TOKEN>
<TOKEN id="token-3-42" pos="word" morph="none" start_char="709" end_char="716">personas</TOKEN>
<TOKEN id="token-3-43" pos="word" morph="none" start_char="718" end_char="722">sanas</TOKEN>
<TOKEN id="token-3-44" pos="word" morph="none" start_char="724" end_char="726">que</TOKEN>
<TOKEN id="token-3-45" pos="word" morph="none" start_char="728" end_char="729">se</TOKEN>
<TOKEN id="token-3-46" pos="word" morph="none" start_char="731" end_char="742">inscribieron</TOKEN>
<TOKEN id="token-3-47" pos="word" morph="none" start_char="744" end_char="745">en</TOKEN>
<TOKEN id="token-3-48" pos="word" morph="none" start_char="747" end_char="748">un</TOKEN>
<TOKEN id="token-3-49" pos="word" morph="none" start_char="750" end_char="756">estudio</TOKEN>
<TOKEN id="token-3-50" pos="word" morph="none" start_char="758" end_char="761">para</TOKEN>
<TOKEN id="token-3-51" pos="word" morph="none" start_char="763" end_char="764">la</TOKEN>
<TOKEN id="token-3-52" pos="word" morph="none" start_char="766" end_char="774">detección</TOKEN>
<TOKEN id="token-3-53" pos="word" morph="none" start_char="776" end_char="778">del</TOKEN>
<TOKEN id="token-3-54" pos="word" morph="none" start_char="780" end_char="785">cáncer</TOKEN>
<TOKEN id="token-3-55" pos="word" morph="none" start_char="787" end_char="788">de</TOKEN>
<TOKEN id="token-3-56" pos="word" morph="none" start_char="790" end_char="795">pulmón</TOKEN>
<TOKEN id="token-3-57" pos="word" morph="none" start_char="797" end_char="798">ya</TOKEN>
<TOKEN id="token-3-58" pos="word" morph="none" start_char="800" end_char="805">habían</TOKEN>
<TOKEN id="token-3-59" pos="word" morph="none" start_char="807" end_char="818">desarrollado</TOKEN>
<TOKEN id="token-3-60" pos="word" morph="none" start_char="820" end_char="830">anticuerpos</TOKEN>
<TOKEN id="token-3-61" pos="word" morph="none" start_char="832" end_char="837">contra</TOKEN>
<TOKEN id="token-3-62" pos="word" morph="none" start_char="839" end_char="840">el</TOKEN>
<TOKEN id="token-3-63" pos="word" morph="none" start_char="842" end_char="852">coronavirus</TOKEN>
<TOKEN id="token-3-64" pos="word" morph="none" start_char="854" end_char="858">desde</TOKEN>
<TOKEN id="token-3-65" pos="word" morph="none" start_char="860" end_char="866">febrero</TOKEN>
<TOKEN id="token-3-66" pos="word" morph="none" start_char="868" end_char="870">del</TOKEN>
<TOKEN id="token-3-67" pos="word" morph="none" start_char="872" end_char="875">2019</TOKEN>
<TOKEN id="token-3-68" pos="punct" morph="none" start_char="876" end_char="876">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="878" end_char="948">
<ORIGINAL_TEXT>Los pacientes se inscribieron entre septiembre de 2019 y marzo de 2020.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="878" end_char="880">Los</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="882" end_char="890">pacientes</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="892" end_char="893">se</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="895" end_char="906">inscribieron</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="908" end_char="912">entre</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="914" end_char="923">septiembre</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="925" end_char="926">de</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="928" end_char="931">2019</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="933" end_char="933">y</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="935" end_char="939">marzo</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="941" end_char="942">de</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="944" end_char="947">2020</TOKEN>
<TOKEN id="token-4-12" pos="punct" morph="none" start_char="948" end_char="948">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="951" end_char="1255">
<ORIGINAL_TEXT>Otra prueba realizada por la Universidad de Siena sobre anticuerpos específicos contra el coronavirus encontró que al menos cuatro casos se remontan a la primera semana de octubre cuando los pacientes ya mostraban anticuerpos que neutralizan el virus, lo que explicarían que se contagiarían en septiembre.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="951" end_char="954">Otra</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="956" end_char="961">prueba</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="963" end_char="971">realizada</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="973" end_char="975">por</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="977" end_char="978">la</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="980" end_char="990">Universidad</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="992" end_char="993">de</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="995" end_char="999">Siena</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="1001" end_char="1005">sobre</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="1007" end_char="1017">anticuerpos</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="1019" end_char="1029">específicos</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="1031" end_char="1036">contra</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="1038" end_char="1039">el</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="1041" end_char="1051">coronavirus</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="1053" end_char="1060">encontró</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="1062" end_char="1064">que</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="1066" end_char="1067">al</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="1069" end_char="1073">menos</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="1075" end_char="1080">cuatro</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="1082" end_char="1086">casos</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="1088" end_char="1089">se</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="1091" end_char="1098">remontan</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="1100" end_char="1100">a</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="1102" end_char="1103">la</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="1105" end_char="1111">primera</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="1113" end_char="1118">semana</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="1120" end_char="1121">de</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="1123" end_char="1129">octubre</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="1131" end_char="1136">cuando</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="1138" end_char="1140">los</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="1142" end_char="1150">pacientes</TOKEN>
<TOKEN id="token-5-31" pos="word" morph="none" start_char="1152" end_char="1153">ya</TOKEN>
<TOKEN id="token-5-32" pos="word" morph="none" start_char="1155" end_char="1163">mostraban</TOKEN>
<TOKEN id="token-5-33" pos="word" morph="none" start_char="1165" end_char="1175">anticuerpos</TOKEN>
<TOKEN id="token-5-34" pos="word" morph="none" start_char="1177" end_char="1179">que</TOKEN>
<TOKEN id="token-5-35" pos="word" morph="none" start_char="1181" end_char="1191">neutralizan</TOKEN>
<TOKEN id="token-5-36" pos="word" morph="none" start_char="1193" end_char="1194">el</TOKEN>
<TOKEN id="token-5-37" pos="word" morph="none" start_char="1196" end_char="1200">virus</TOKEN>
<TOKEN id="token-5-38" pos="punct" morph="none" start_char="1201" end_char="1201">,</TOKEN>
<TOKEN id="token-5-39" pos="word" morph="none" start_char="1203" end_char="1204">lo</TOKEN>
<TOKEN id="token-5-40" pos="word" morph="none" start_char="1206" end_char="1208">que</TOKEN>
<TOKEN id="token-5-41" pos="word" morph="none" start_char="1210" end_char="1220">explicarían</TOKEN>
<TOKEN id="token-5-42" pos="word" morph="none" start_char="1222" end_char="1224">que</TOKEN>
<TOKEN id="token-5-43" pos="word" morph="none" start_char="1226" end_char="1227">se</TOKEN>
<TOKEN id="token-5-44" pos="word" morph="none" start_char="1229" end_char="1240">contagiarían</TOKEN>
<TOKEN id="token-5-45" pos="word" morph="none" start_char="1242" end_char="1243">en</TOKEN>
<TOKEN id="token-5-46" pos="word" morph="none" start_char="1245" end_char="1254">septiembre</TOKEN>
<TOKEN id="token-5-47" pos="punct" morph="none" start_char="1255" end_char="1255">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="1258" end_char="1486">
<ORIGINAL_TEXT>Giovanni Apolone, coautor del estudio, dijo que "Este es el hallazgo principal: las personas sin síntomas no sólo dieron positivo después de las pruebas serológicas, sino que también tenían anticuerpos capaces de matar el virus".</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="1258" end_char="1265">Giovanni</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="1267" end_char="1273">Apolone</TOKEN>
<TOKEN id="token-6-2" pos="punct" morph="none" start_char="1274" end_char="1274">,</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="1276" end_char="1282">coautor</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="1284" end_char="1286">del</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="1288" end_char="1294">estudio</TOKEN>
<TOKEN id="token-6-6" pos="punct" morph="none" start_char="1295" end_char="1295">,</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="1297" end_char="1300">dijo</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="1302" end_char="1304">que</TOKEN>
<TOKEN id="token-6-9" pos="punct" morph="none" start_char="1306" end_char="1306">"</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="1307" end_char="1310">Este</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="1312" end_char="1313">es</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="1315" end_char="1316">el</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="1318" end_char="1325">hallazgo</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="1327" end_char="1335">principal</TOKEN>
<TOKEN id="token-6-15" pos="punct" morph="none" start_char="1336" end_char="1336">:</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="1338" end_char="1340">las</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="1342" end_char="1349">personas</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="1351" end_char="1353">sin</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="1355" end_char="1362">síntomas</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="1364" end_char="1365">no</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="1367" end_char="1370">sólo</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="1372" end_char="1377">dieron</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="1379" end_char="1386">positivo</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="1388" end_char="1394">después</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="1396" end_char="1397">de</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="1399" end_char="1401">las</TOKEN>
<TOKEN id="token-6-27" pos="word" morph="none" start_char="1403" end_char="1409">pruebas</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="1411" end_char="1421">serológicas</TOKEN>
<TOKEN id="token-6-29" pos="punct" morph="none" start_char="1422" end_char="1422">,</TOKEN>
<TOKEN id="token-6-30" pos="word" morph="none" start_char="1424" end_char="1427">sino</TOKEN>
<TOKEN id="token-6-31" pos="word" morph="none" start_char="1429" end_char="1431">que</TOKEN>
<TOKEN id="token-6-32" pos="word" morph="none" start_char="1433" end_char="1439">también</TOKEN>
<TOKEN id="token-6-33" pos="word" morph="none" start_char="1441" end_char="1446">tenían</TOKEN>
<TOKEN id="token-6-34" pos="word" morph="none" start_char="1448" end_char="1458">anticuerpos</TOKEN>
<TOKEN id="token-6-35" pos="word" morph="none" start_char="1460" end_char="1466">capaces</TOKEN>
<TOKEN id="token-6-36" pos="word" morph="none" start_char="1468" end_char="1469">de</TOKEN>
<TOKEN id="token-6-37" pos="word" morph="none" start_char="1471" end_char="1475">matar</TOKEN>
<TOKEN id="token-6-38" pos="word" morph="none" start_char="1477" end_char="1478">el</TOKEN>
<TOKEN id="token-6-39" pos="word" morph="none" start_char="1480" end_char="1484">virus</TOKEN>
<TOKEN id="token-6-40" pos="punct" morph="none" start_char="1485" end_char="1486">".</TOKEN>
</SEG>
<SEG id="segment-7" start_char="1489" end_char="1740">
<ORIGINAL_TEXT>Las pruebas de los participantes en el estudio de detección del cáncer de pulmón indicaron que de 959 sujetos entre septiembre de 2019 y marzo de 2020, el 11,6% de las mismas (111) tenían ya anticuerpos del coronavirus, el 14% ya en septiembre de 2019.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="1489" end_char="1491">Las</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="1493" end_char="1499">pruebas</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="1501" end_char="1502">de</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="1504" end_char="1506">los</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="1508" end_char="1520">participantes</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="1522" end_char="1523">en</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="1525" end_char="1526">el</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="1528" end_char="1534">estudio</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="1536" end_char="1537">de</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="1539" end_char="1547">detección</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="1549" end_char="1551">del</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="1553" end_char="1558">cáncer</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="1560" end_char="1561">de</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="1563" end_char="1568">pulmón</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="1570" end_char="1578">indicaron</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="1580" end_char="1582">que</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="1584" end_char="1585">de</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="1587" end_char="1589">959</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="1591" end_char="1597">sujetos</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="1599" end_char="1603">entre</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="1605" end_char="1614">septiembre</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="1616" end_char="1617">de</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="1619" end_char="1622">2019</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="1624" end_char="1624">y</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="1626" end_char="1630">marzo</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="1632" end_char="1633">de</TOKEN>
<TOKEN id="token-7-26" pos="word" morph="none" start_char="1635" end_char="1638">2020</TOKEN>
<TOKEN id="token-7-27" pos="punct" morph="none" start_char="1639" end_char="1639">,</TOKEN>
<TOKEN id="token-7-28" pos="word" morph="none" start_char="1641" end_char="1642">el</TOKEN>
<TOKEN id="token-7-29" pos="unknown" morph="none" start_char="1644" end_char="1647">11,6</TOKEN>
<TOKEN id="token-7-30" pos="punct" morph="none" start_char="1648" end_char="1648">%</TOKEN>
<TOKEN id="token-7-31" pos="word" morph="none" start_char="1650" end_char="1651">de</TOKEN>
<TOKEN id="token-7-32" pos="word" morph="none" start_char="1653" end_char="1655">las</TOKEN>
<TOKEN id="token-7-33" pos="word" morph="none" start_char="1657" end_char="1662">mismas</TOKEN>
<TOKEN id="token-7-34" pos="punct" morph="none" start_char="1664" end_char="1664">(</TOKEN>
<TOKEN id="token-7-35" pos="word" morph="none" start_char="1665" end_char="1667">111</TOKEN>
<TOKEN id="token-7-36" pos="punct" morph="none" start_char="1668" end_char="1668">)</TOKEN>
<TOKEN id="token-7-37" pos="word" morph="none" start_char="1670" end_char="1675">tenían</TOKEN>
<TOKEN id="token-7-38" pos="word" morph="none" start_char="1677" end_char="1678">ya</TOKEN>
<TOKEN id="token-7-39" pos="word" morph="none" start_char="1680" end_char="1690">anticuerpos</TOKEN>
<TOKEN id="token-7-40" pos="word" morph="none" start_char="1692" end_char="1694">del</TOKEN>
<TOKEN id="token-7-41" pos="word" morph="none" start_char="1696" end_char="1706">coronavirus</TOKEN>
<TOKEN id="token-7-42" pos="punct" morph="none" start_char="1707" end_char="1707">,</TOKEN>
<TOKEN id="token-7-43" pos="word" morph="none" start_char="1709" end_char="1710">el</TOKEN>
<TOKEN id="token-7-44" pos="word" morph="none" start_char="1712" end_char="1713">14</TOKEN>
<TOKEN id="token-7-45" pos="punct" morph="none" start_char="1714" end_char="1714">%</TOKEN>
<TOKEN id="token-7-46" pos="word" morph="none" start_char="1716" end_char="1717">ya</TOKEN>
<TOKEN id="token-7-47" pos="word" morph="none" start_char="1719" end_char="1720">en</TOKEN>
<TOKEN id="token-7-48" pos="word" morph="none" start_char="1722" end_char="1731">septiembre</TOKEN>
<TOKEN id="token-7-49" pos="word" morph="none" start_char="1733" end_char="1734">de</TOKEN>
<TOKEN id="token-7-50" pos="word" morph="none" start_char="1736" end_char="1739">2019</TOKEN>
<TOKEN id="token-7-51" pos="punct" morph="none" start_char="1740" end_char="1740">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1744" end_char="1965">
<ORIGINAL_TEXT>Actualmente Italia registra 1.21 millones de casos acumulados de coronavirus desde el inicio de la pandemia, de los cuales 442 mil se han recuperado y 45 mil 773 personas han muerto a causa de la infección por coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1744" end_char="1754">Actualmente</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1756" end_char="1761">Italia</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1763" end_char="1770">registra</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1772" end_char="1775">1.21</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1777" end_char="1784">millones</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1786" end_char="1787">de</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1789" end_char="1793">casos</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1795" end_char="1804">acumulados</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1806" end_char="1807">de</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1809" end_char="1819">coronavirus</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1821" end_char="1825">desde</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1827" end_char="1828">el</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1830" end_char="1835">inicio</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1837" end_char="1838">de</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1840" end_char="1841">la</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1843" end_char="1850">pandemia</TOKEN>
<TOKEN id="token-8-16" pos="punct" morph="none" start_char="1851" end_char="1851">,</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1853" end_char="1854">de</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1856" end_char="1858">los</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1860" end_char="1865">cuales</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="1867" end_char="1869">442</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="1871" end_char="1873">mil</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="1875" end_char="1876">se</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="1878" end_char="1880">han</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="1882" end_char="1891">recuperado</TOKEN>
<TOKEN id="token-8-25" pos="word" morph="none" start_char="1893" end_char="1893">y</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="1895" end_char="1896">45</TOKEN>
<TOKEN id="token-8-27" pos="word" morph="none" start_char="1898" end_char="1900">mil</TOKEN>
<TOKEN id="token-8-28" pos="word" morph="none" start_char="1902" end_char="1904">773</TOKEN>
<TOKEN id="token-8-29" pos="word" morph="none" start_char="1906" end_char="1913">personas</TOKEN>
<TOKEN id="token-8-30" pos="word" morph="none" start_char="1915" end_char="1917">han</TOKEN>
<TOKEN id="token-8-31" pos="word" morph="none" start_char="1919" end_char="1924">muerto</TOKEN>
<TOKEN id="token-8-32" pos="word" morph="none" start_char="1926" end_char="1926">a</TOKEN>
<TOKEN id="token-8-33" pos="word" morph="none" start_char="1928" end_char="1932">causa</TOKEN>
<TOKEN id="token-8-34" pos="word" morph="none" start_char="1934" end_char="1935">de</TOKEN>
<TOKEN id="token-8-35" pos="word" morph="none" start_char="1937" end_char="1938">la</TOKEN>
<TOKEN id="token-8-36" pos="word" morph="none" start_char="1940" end_char="1948">infección</TOKEN>
<TOKEN id="token-8-37" pos="word" morph="none" start_char="1950" end_char="1952">por</TOKEN>
<TOKEN id="token-8-38" pos="word" morph="none" start_char="1954" end_char="1964">coronavirus</TOKEN>
<TOKEN id="token-8-39" pos="punct" morph="none" start_char="1965" end_char="1965">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1968" end_char="2193">
<ORIGINAL_TEXT>Italia a endurecido las restricciones para evitar un rebrote aún mayor del virus ya que tan sólo en las últimas 24 horas ha llegado a presentar 550 personas fallecidas y al menos 40 mil 902 casos nuevos de personas infectadas.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1968" end_char="1973">Italia</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1975" end_char="1975">a</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1977" end_char="1986">endurecido</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1988" end_char="1990">las</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1992" end_char="2004">restricciones</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="2006" end_char="2009">para</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="2011" end_char="2016">evitar</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="2018" end_char="2019">un</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="2021" end_char="2027">rebrote</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="2029" end_char="2031">aún</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="2033" end_char="2037">mayor</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="2039" end_char="2041">del</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="2043" end_char="2047">virus</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="2049" end_char="2050">ya</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="2052" end_char="2054">que</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="2056" end_char="2058">tan</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="2060" end_char="2063">sólo</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="2065" end_char="2066">en</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="2068" end_char="2070">las</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="2072" end_char="2078">últimas</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="2080" end_char="2081">24</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="2083" end_char="2087">horas</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="2089" end_char="2090">ha</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="2092" end_char="2098">llegado</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="2100" end_char="2100">a</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="2102" end_char="2110">presentar</TOKEN>
<TOKEN id="token-9-26" pos="word" morph="none" start_char="2112" end_char="2114">550</TOKEN>
<TOKEN id="token-9-27" pos="word" morph="none" start_char="2116" end_char="2123">personas</TOKEN>
<TOKEN id="token-9-28" pos="word" morph="none" start_char="2125" end_char="2134">fallecidas</TOKEN>
<TOKEN id="token-9-29" pos="word" morph="none" start_char="2136" end_char="2136">y</TOKEN>
<TOKEN id="token-9-30" pos="word" morph="none" start_char="2138" end_char="2139">al</TOKEN>
<TOKEN id="token-9-31" pos="word" morph="none" start_char="2141" end_char="2145">menos</TOKEN>
<TOKEN id="token-9-32" pos="word" morph="none" start_char="2147" end_char="2148">40</TOKEN>
<TOKEN id="token-9-33" pos="word" morph="none" start_char="2150" end_char="2152">mil</TOKEN>
<TOKEN id="token-9-34" pos="word" morph="none" start_char="2154" end_char="2156">902</TOKEN>
<TOKEN id="token-9-35" pos="word" morph="none" start_char="2158" end_char="2162">casos</TOKEN>
<TOKEN id="token-9-36" pos="word" morph="none" start_char="2164" end_char="2169">nuevos</TOKEN>
<TOKEN id="token-9-37" pos="word" morph="none" start_char="2171" end_char="2172">de</TOKEN>
<TOKEN id="token-9-38" pos="word" morph="none" start_char="2174" end_char="2181">personas</TOKEN>
<TOKEN id="token-9-39" pos="word" morph="none" start_char="2183" end_char="2192">infectadas</TOKEN>
<TOKEN id="token-9-40" pos="punct" morph="none" start_char="2193" end_char="2193">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="2196" end_char="2407">
<ORIGINAL_TEXT>Lombardía, la región donde oficialmente se detectó el primer caso de coronavirus en Italia, es la que más casos concentra con 10 mil 634 contagios en las últimas 24 horas y se acerca a la cifra de 20 mil muertos.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="2196" end_char="2204">Lombardía</TOKEN>
<TOKEN id="token-10-1" pos="punct" morph="none" start_char="2205" end_char="2205">,</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="2207" end_char="2208">la</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="2210" end_char="2215">región</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="2217" end_char="2221">donde</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="2223" end_char="2234">oficialmente</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="2236" end_char="2237">se</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="2239" end_char="2245">detectó</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="2247" end_char="2248">el</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="2250" end_char="2255">primer</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="2257" end_char="2260">caso</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="2262" end_char="2263">de</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="2265" end_char="2275">coronavirus</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="2277" end_char="2278">en</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="2280" end_char="2285">Italia</TOKEN>
<TOKEN id="token-10-15" pos="punct" morph="none" start_char="2286" end_char="2286">,</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="2288" end_char="2289">es</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="2291" end_char="2292">la</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="2294" end_char="2296">que</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="2298" end_char="2300">más</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="2302" end_char="2306">casos</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="2308" end_char="2316">concentra</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="2318" end_char="2320">con</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="2322" end_char="2323">10</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="2325" end_char="2327">mil</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="2329" end_char="2331">634</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="2333" end_char="2341">contagios</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="2343" end_char="2344">en</TOKEN>
<TOKEN id="token-10-28" pos="word" morph="none" start_char="2346" end_char="2348">las</TOKEN>
<TOKEN id="token-10-29" pos="word" morph="none" start_char="2350" end_char="2356">últimas</TOKEN>
<TOKEN id="token-10-30" pos="word" morph="none" start_char="2358" end_char="2359">24</TOKEN>
<TOKEN id="token-10-31" pos="word" morph="none" start_char="2361" end_char="2365">horas</TOKEN>
<TOKEN id="token-10-32" pos="word" morph="none" start_char="2367" end_char="2367">y</TOKEN>
<TOKEN id="token-10-33" pos="word" morph="none" start_char="2369" end_char="2370">se</TOKEN>
<TOKEN id="token-10-34" pos="word" morph="none" start_char="2372" end_char="2377">acerca</TOKEN>
<TOKEN id="token-10-35" pos="word" morph="none" start_char="2379" end_char="2379">a</TOKEN>
<TOKEN id="token-10-36" pos="word" morph="none" start_char="2381" end_char="2382">la</TOKEN>
<TOKEN id="token-10-37" pos="word" morph="none" start_char="2384" end_char="2388">cifra</TOKEN>
<TOKEN id="token-10-38" pos="word" morph="none" start_char="2390" end_char="2391">de</TOKEN>
<TOKEN id="token-10-39" pos="word" morph="none" start_char="2393" end_char="2394">20</TOKEN>
<TOKEN id="token-10-40" pos="word" morph="none" start_char="2396" end_char="2398">mil</TOKEN>
<TOKEN id="token-10-41" pos="word" morph="none" start_char="2400" end_char="2406">muertos</TOKEN>
<TOKEN id="token-10-42" pos="punct" morph="none" start_char="2407" end_char="2407">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="2409" end_char="2497">
<ORIGINAL_TEXT>Le siguen Piamonte, con 5.258 nuevos casos, Campania (sur), con 4.079 y Véneto con 3.605.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="2409" end_char="2410">Le</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="2412" end_char="2417">siguen</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="2419" end_char="2426">Piamonte</TOKEN>
<TOKEN id="token-11-3" pos="punct" morph="none" start_char="2427" end_char="2427">,</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="2429" end_char="2431">con</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="2433" end_char="2437">5.258</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="2439" end_char="2444">nuevos</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="2446" end_char="2450">casos</TOKEN>
<TOKEN id="token-11-8" pos="punct" morph="none" start_char="2451" end_char="2451">,</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="2453" end_char="2460">Campania</TOKEN>
<TOKEN id="token-11-10" pos="punct" morph="none" start_char="2462" end_char="2462">(</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="2463" end_char="2465">sur</TOKEN>
<TOKEN id="token-11-12" pos="punct" morph="none" start_char="2466" end_char="2467">),</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="2469" end_char="2471">con</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="2473" end_char="2477">4.079</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="2479" end_char="2479">y</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="2481" end_char="2486">Véneto</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="2488" end_char="2490">con</TOKEN>
<TOKEN id="token-11-18" pos="unknown" morph="none" start_char="2492" end_char="2496">3.605</TOKEN>
<TOKEN id="token-11-19" pos="punct" morph="none" start_char="2497" end_char="2497">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="2499" end_char="2694">
<ORIGINAL_TEXT>La Toscana y Campania se suman a la lista de las regiones que también deberán endurecer sus restricciones por orden del gobierno italiano, restricciones que entrarán en vigor a partir de este año.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="2499" end_char="2500">La</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="2502" end_char="2508">Toscana</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="2510" end_char="2510">y</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="2512" end_char="2519">Campania</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="2521" end_char="2522">se</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="2524" end_char="2528">suman</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="2530" end_char="2530">a</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="2532" end_char="2533">la</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="2535" end_char="2539">lista</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="2541" end_char="2542">de</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="2544" end_char="2546">las</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="2548" end_char="2555">regiones</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="2557" end_char="2559">que</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="2561" end_char="2567">también</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="2569" end_char="2575">deberán</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="2577" end_char="2585">endurecer</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="2587" end_char="2589">sus</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="2591" end_char="2603">restricciones</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="2605" end_char="2607">por</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="2609" end_char="2613">orden</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="2615" end_char="2617">del</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="2619" end_char="2626">gobierno</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="2628" end_char="2635">italiano</TOKEN>
<TOKEN id="token-12-23" pos="punct" morph="none" start_char="2636" end_char="2636">,</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="2638" end_char="2650">restricciones</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="2652" end_char="2654">que</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="2656" end_char="2663">entrarán</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="2665" end_char="2666">en</TOKEN>
<TOKEN id="token-12-28" pos="word" morph="none" start_char="2668" end_char="2672">vigor</TOKEN>
<TOKEN id="token-12-29" pos="word" morph="none" start_char="2674" end_char="2674">a</TOKEN>
<TOKEN id="token-12-30" pos="word" morph="none" start_char="2676" end_char="2681">partir</TOKEN>
<TOKEN id="token-12-31" pos="word" morph="none" start_char="2683" end_char="2684">de</TOKEN>
<TOKEN id="token-12-32" pos="word" morph="none" start_char="2686" end_char="2689">este</TOKEN>
<TOKEN id="token-12-33" pos="word" morph="none" start_char="2691" end_char="2693">año</TOKEN>
<TOKEN id="token-12-34" pos="punct" morph="none" start_char="2694" end_char="2694">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="2696" end_char="2829">
<ORIGINAL_TEXT>Estas dos regiones se suman a Valle de Aosta, Lombardía, Piamonte, Calabria y la provincia autónoma de Bolzano, que son "zonas rojas".</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="2696" end_char="2700">Estas</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="2702" end_char="2704">dos</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="2706" end_char="2713">regiones</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="2715" end_char="2716">se</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="2718" end_char="2722">suman</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="2724" end_char="2724">a</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="2726" end_char="2730">Valle</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="2732" end_char="2733">de</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="2735" end_char="2739">Aosta</TOKEN>
<TOKEN id="token-13-9" pos="punct" morph="none" start_char="2740" end_char="2740">,</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="2742" end_char="2750">Lombardía</TOKEN>
<TOKEN id="token-13-11" pos="punct" morph="none" start_char="2751" end_char="2751">,</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="2753" end_char="2760">Piamonte</TOKEN>
<TOKEN id="token-13-13" pos="punct" morph="none" start_char="2761" end_char="2761">,</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="2763" end_char="2770">Calabria</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="2772" end_char="2772">y</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="2774" end_char="2775">la</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="2777" end_char="2785">provincia</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="2787" end_char="2794">autónoma</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="2796" end_char="2797">de</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="2799" end_char="2805">Bolzano</TOKEN>
<TOKEN id="token-13-21" pos="punct" morph="none" start_char="2806" end_char="2806">,</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="2808" end_char="2810">que</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="2812" end_char="2814">son</TOKEN>
<TOKEN id="token-13-24" pos="punct" morph="none" start_char="2816" end_char="2816">"</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="2817" end_char="2821">zonas</TOKEN>
<TOKEN id="token-13-26" pos="word" morph="none" start_char="2823" end_char="2827">rojas</TOKEN>
<TOKEN id="token-13-27" pos="punct" morph="none" start_char="2828" end_char="2829">".</TOKEN>
</SEG>
<SEG id="segment-14" start_char="2832" end_char="3047">
<ORIGINAL_TEXT>Diversos países europeos han presentado una escalada significativa de nuevos casos de coronavirus, lo que ha obligado a los gobiernos a dictar medidas más severas para evitar una segunda ola de contagios más severas.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="2832" end_char="2839">Diversos</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="2841" end_char="2846">países</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="2848" end_char="2855">europeos</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="2857" end_char="2859">han</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="2861" end_char="2870">presentado</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="2872" end_char="2874">una</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="2876" end_char="2883">escalada</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="2885" end_char="2897">significativa</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="2899" end_char="2900">de</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="2902" end_char="2907">nuevos</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="2909" end_char="2913">casos</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="2915" end_char="2916">de</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="2918" end_char="2928">coronavirus</TOKEN>
<TOKEN id="token-14-13" pos="punct" morph="none" start_char="2929" end_char="2929">,</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="2931" end_char="2932">lo</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="2934" end_char="2936">que</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="2938" end_char="2939">ha</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="2941" end_char="2948">obligado</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="2950" end_char="2950">a</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="2952" end_char="2954">los</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="2956" end_char="2964">gobiernos</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="2966" end_char="2966">a</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="2968" end_char="2973">dictar</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="2975" end_char="2981">medidas</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="2983" end_char="2985">más</TOKEN>
<TOKEN id="token-14-25" pos="word" morph="none" start_char="2987" end_char="2993">severas</TOKEN>
<TOKEN id="token-14-26" pos="word" morph="none" start_char="2995" end_char="2998">para</TOKEN>
<TOKEN id="token-14-27" pos="word" morph="none" start_char="3000" end_char="3005">evitar</TOKEN>
<TOKEN id="token-14-28" pos="word" morph="none" start_char="3007" end_char="3009">una</TOKEN>
<TOKEN id="token-14-29" pos="word" morph="none" start_char="3011" end_char="3017">segunda</TOKEN>
<TOKEN id="token-14-30" pos="word" morph="none" start_char="3019" end_char="3021">ola</TOKEN>
<TOKEN id="token-14-31" pos="word" morph="none" start_char="3023" end_char="3024">de</TOKEN>
<TOKEN id="token-14-32" pos="word" morph="none" start_char="3026" end_char="3034">contagios</TOKEN>
<TOKEN id="token-14-33" pos="word" morph="none" start_char="3036" end_char="3038">más</TOKEN>
<TOKEN id="token-14-34" pos="word" morph="none" start_char="3040" end_char="3046">severas</TOKEN>
<TOKEN id="token-14-35" pos="punct" morph="none" start_char="3047" end_char="3047">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="3049" end_char="3232">
<ORIGINAL_TEXT>Giuseppe Conte, primer ministro de Italia dijo que aunque se sigue descartando un confinamiento nacional, sí se esperarán medidas parciales para cada región en espera de que funcionen.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="3049" end_char="3056">Giuseppe</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="3058" end_char="3062">Conte</TOKEN>
<TOKEN id="token-15-2" pos="punct" morph="none" start_char="3063" end_char="3063">,</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="3065" end_char="3070">primer</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="3072" end_char="3079">ministro</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="3081" end_char="3082">de</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="3084" end_char="3089">Italia</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="3091" end_char="3094">dijo</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="3096" end_char="3098">que</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="3100" end_char="3105">aunque</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="3107" end_char="3108">se</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="3110" end_char="3114">sigue</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="3116" end_char="3126">descartando</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="3128" end_char="3129">un</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="3131" end_char="3143">confinamiento</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="3145" end_char="3152">nacional</TOKEN>
<TOKEN id="token-15-16" pos="punct" morph="none" start_char="3153" end_char="3153">,</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="3155" end_char="3156">sí</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="3158" end_char="3159">se</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="3161" end_char="3169">esperarán</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="3171" end_char="3177">medidas</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="3179" end_char="3187">parciales</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="3189" end_char="3192">para</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="3194" end_char="3197">cada</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="3199" end_char="3204">región</TOKEN>
<TOKEN id="token-15-25" pos="word" morph="none" start_char="3206" end_char="3207">en</TOKEN>
<TOKEN id="token-15-26" pos="word" morph="none" start_char="3209" end_char="3214">espera</TOKEN>
<TOKEN id="token-15-27" pos="word" morph="none" start_char="3216" end_char="3217">de</TOKEN>
<TOKEN id="token-15-28" pos="word" morph="none" start_char="3219" end_char="3221">que</TOKEN>
<TOKEN id="token-15-29" pos="word" morph="none" start_char="3223" end_char="3231">funcionen</TOKEN>
<TOKEN id="token-15-30" pos="punct" morph="none" start_char="3232" end_char="3232">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="3234" end_char="3371">
<ORIGINAL_TEXT>El pasado viernes dijo que las festividades de Navidad deberán ser distintas y que no es momento de hacer grandes reuniones para celebrar.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="3234" end_char="3235">El</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="3237" end_char="3242">pasado</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="3244" end_char="3250">viernes</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="3252" end_char="3255">dijo</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="3257" end_char="3259">que</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="3261" end_char="3263">las</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="3265" end_char="3276">festividades</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="3278" end_char="3279">de</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="3281" end_char="3287">Navidad</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="3289" end_char="3295">deberán</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="3297" end_char="3299">ser</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="3301" end_char="3309">distintas</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="3311" end_char="3311">y</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="3313" end_char="3315">que</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="3317" end_char="3318">no</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="3320" end_char="3321">es</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="3323" end_char="3329">momento</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="3331" end_char="3332">de</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="3334" end_char="3338">hacer</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="3340" end_char="3346">grandes</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="3348" end_char="3356">reuniones</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="3358" end_char="3361">para</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="3363" end_char="3370">celebrar</TOKEN>
<TOKEN id="token-16-23" pos="punct" morph="none" start_char="3371" end_char="3371">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
