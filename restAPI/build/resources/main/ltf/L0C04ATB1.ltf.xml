<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATB1" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="9211" raw_text_md5="fa67bc500dd117519fd6b9577c776065">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="22">
<ORIGINAL_TEXT>Mascarillas, ¿sí o no?</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="11">Mascarillas</TOKEN>
<TOKEN id="token-0-1" pos="punct" morph="none" start_char="12" end_char="12">,</TOKEN>
<TOKEN id="token-0-2" pos="punct" morph="none" start_char="14" end_char="14">¿</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="15" end_char="16">sí</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="18" end_char="18">o</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="20" end_char="21">no</TOKEN>
<TOKEN id="token-0-6" pos="punct" morph="none" start_char="22" end_char="22">?</TOKEN>
</SEG>
<SEG id="segment-1" start_char="24" end_char="98">
<ORIGINAL_TEXT>Los expertos y Europa piden utilizarlas pero el Gobierno aún no aclara cómo</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="24" end_char="26">Los</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="28" end_char="35">expertos</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="37" end_char="37">y</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="39" end_char="44">Europa</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="46" end_char="50">piden</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="52" end_char="62">utilizarlas</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="64" end_char="67">pero</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="69" end_char="70">el</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="72" end_char="79">Gobierno</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="81" end_char="83">aún</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="85" end_char="86">no</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="88" end_char="93">aclara</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="95" end_char="98">cómo</TOKEN>
</SEG>
<SEG id="segment-2" start_char="102" end_char="159">
<ORIGINAL_TEXT>Sobran comentarios periodísticos y discursos del Gobierno.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="102" end_char="107">Sobran</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="109" end_char="119">comentarios</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="121" end_char="133">periodísticos</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="135" end_char="135">y</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="137" end_char="145">discursos</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="147" end_char="149">del</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="151" end_char="158">Gobierno</TOKEN>
<TOKEN id="token-2-7" pos="punct" morph="none" start_char="159" end_char="159">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="161" end_char="520">
<ORIGINAL_TEXT>Nuestro idioma es tan extenso que permite decir y no decir a la misma vez, Este asunto es diáfano como la luz del Sol, NO HAY mascarillas suficientes para todos (47 millones de habitantes y 8/10 mascarillas al menos a cada uno para usarlas el primer mes suman 470 millones), nos explican hasta como lavarlas y se intenta justificar con argumentos de todo tipo.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="161" end_char="167">Nuestro</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="169" end_char="174">idioma</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="176" end_char="177">es</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="179" end_char="181">tan</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="183" end_char="189">extenso</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="191" end_char="193">que</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="195" end_char="201">permite</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="203" end_char="207">decir</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="209" end_char="209">y</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="211" end_char="212">no</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="214" end_char="218">decir</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="220" end_char="220">a</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="222" end_char="223">la</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="225" end_char="229">misma</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="231" end_char="233">vez</TOKEN>
<TOKEN id="token-3-15" pos="punct" morph="none" start_char="234" end_char="234">,</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="236" end_char="239">Este</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="241" end_char="246">asunto</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="248" end_char="249">es</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="251" end_char="257">diáfano</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="259" end_char="262">como</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="264" end_char="265">la</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="267" end_char="269">luz</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="271" end_char="273">del</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="275" end_char="277">Sol</TOKEN>
<TOKEN id="token-3-25" pos="punct" morph="none" start_char="278" end_char="278">,</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="280" end_char="281">NO</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="283" end_char="285">HAY</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="287" end_char="297">mascarillas</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="299" end_char="309">suficientes</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="311" end_char="314">para</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="316" end_char="320">todos</TOKEN>
<TOKEN id="token-3-32" pos="punct" morph="none" start_char="322" end_char="322">(</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="323" end_char="324">47</TOKEN>
<TOKEN id="token-3-34" pos="word" morph="none" start_char="326" end_char="333">millones</TOKEN>
<TOKEN id="token-3-35" pos="word" morph="none" start_char="335" end_char="336">de</TOKEN>
<TOKEN id="token-3-36" pos="word" morph="none" start_char="338" end_char="347">habitantes</TOKEN>
<TOKEN id="token-3-37" pos="word" morph="none" start_char="349" end_char="349">y</TOKEN>
<TOKEN id="token-3-38" pos="unknown" morph="none" start_char="351" end_char="354">8/10</TOKEN>
<TOKEN id="token-3-39" pos="word" morph="none" start_char="356" end_char="366">mascarillas</TOKEN>
<TOKEN id="token-3-40" pos="word" morph="none" start_char="368" end_char="369">al</TOKEN>
<TOKEN id="token-3-41" pos="word" morph="none" start_char="371" end_char="375">menos</TOKEN>
<TOKEN id="token-3-42" pos="word" morph="none" start_char="377" end_char="377">a</TOKEN>
<TOKEN id="token-3-43" pos="word" morph="none" start_char="379" end_char="382">cada</TOKEN>
<TOKEN id="token-3-44" pos="word" morph="none" start_char="384" end_char="386">uno</TOKEN>
<TOKEN id="token-3-45" pos="word" morph="none" start_char="388" end_char="391">para</TOKEN>
<TOKEN id="token-3-46" pos="word" morph="none" start_char="393" end_char="399">usarlas</TOKEN>
<TOKEN id="token-3-47" pos="word" morph="none" start_char="401" end_char="402">el</TOKEN>
<TOKEN id="token-3-48" pos="word" morph="none" start_char="404" end_char="409">primer</TOKEN>
<TOKEN id="token-3-49" pos="word" morph="none" start_char="411" end_char="413">mes</TOKEN>
<TOKEN id="token-3-50" pos="word" morph="none" start_char="415" end_char="419">suman</TOKEN>
<TOKEN id="token-3-51" pos="word" morph="none" start_char="421" end_char="423">470</TOKEN>
<TOKEN id="token-3-52" pos="word" morph="none" start_char="425" end_char="432">millones</TOKEN>
<TOKEN id="token-3-53" pos="punct" morph="none" start_char="433" end_char="434">),</TOKEN>
<TOKEN id="token-3-54" pos="word" morph="none" start_char="436" end_char="438">nos</TOKEN>
<TOKEN id="token-3-55" pos="word" morph="none" start_char="440" end_char="447">explican</TOKEN>
<TOKEN id="token-3-56" pos="word" morph="none" start_char="449" end_char="453">hasta</TOKEN>
<TOKEN id="token-3-57" pos="word" morph="none" start_char="455" end_char="458">como</TOKEN>
<TOKEN id="token-3-58" pos="word" morph="none" start_char="460" end_char="467">lavarlas</TOKEN>
<TOKEN id="token-3-59" pos="word" morph="none" start_char="469" end_char="469">y</TOKEN>
<TOKEN id="token-3-60" pos="word" morph="none" start_char="471" end_char="472">se</TOKEN>
<TOKEN id="token-3-61" pos="word" morph="none" start_char="474" end_char="480">intenta</TOKEN>
<TOKEN id="token-3-62" pos="word" morph="none" start_char="482" end_char="491">justificar</TOKEN>
<TOKEN id="token-3-63" pos="word" morph="none" start_char="493" end_char="495">con</TOKEN>
<TOKEN id="token-3-64" pos="word" morph="none" start_char="497" end_char="506">argumentos</TOKEN>
<TOKEN id="token-3-65" pos="word" morph="none" start_char="508" end_char="509">de</TOKEN>
<TOKEN id="token-3-66" pos="word" morph="none" start_char="511" end_char="514">todo</TOKEN>
<TOKEN id="token-3-67" pos="word" morph="none" start_char="516" end_char="519">tipo</TOKEN>
<TOKEN id="token-3-68" pos="punct" morph="none" start_char="520" end_char="520">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="522" end_char="528">
<ORIGINAL_TEXT>NO HAY.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="522" end_char="523">NO</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="525" end_char="527">HAY</TOKEN>
<TOKEN id="token-4-2" pos="punct" morph="none" start_char="528" end_char="528">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="532" end_char="849">
<ORIGINAL_TEXT>Me parece un debate estéril si no exiten razones tales como la falta o escasez que se ha demostrado desde el inicio de la sesión de covid y que por algún motivo en el mes que llevamos no se ha generalizado su fabricación y de las buenas, sabiendo como sabemos que hoy día se diseña y se fabrica cualquier cosa en días.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="532" end_char="533">Me</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="535" end_char="540">parece</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="542" end_char="543">un</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="545" end_char="550">debate</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="552" end_char="558">estéril</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="560" end_char="561">si</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="563" end_char="564">no</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="566" end_char="571">exiten</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="573" end_char="579">razones</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="581" end_char="585">tales</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="587" end_char="590">como</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="592" end_char="593">la</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="595" end_char="599">falta</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="601" end_char="601">o</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="603" end_char="609">escasez</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="611" end_char="613">que</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="615" end_char="616">se</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="618" end_char="619">ha</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="621" end_char="630">demostrado</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="632" end_char="636">desde</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="638" end_char="639">el</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="641" end_char="646">inicio</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="648" end_char="649">de</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="651" end_char="652">la</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="654" end_char="659">sesión</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="661" end_char="662">de</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="664" end_char="668">covid</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="670" end_char="670">y</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="672" end_char="674">que</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="676" end_char="678">por</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="680" end_char="684">algún</TOKEN>
<TOKEN id="token-5-31" pos="word" morph="none" start_char="686" end_char="691">motivo</TOKEN>
<TOKEN id="token-5-32" pos="word" morph="none" start_char="693" end_char="694">en</TOKEN>
<TOKEN id="token-5-33" pos="word" morph="none" start_char="696" end_char="697">el</TOKEN>
<TOKEN id="token-5-34" pos="word" morph="none" start_char="699" end_char="701">mes</TOKEN>
<TOKEN id="token-5-35" pos="word" morph="none" start_char="703" end_char="705">que</TOKEN>
<TOKEN id="token-5-36" pos="word" morph="none" start_char="707" end_char="714">llevamos</TOKEN>
<TOKEN id="token-5-37" pos="word" morph="none" start_char="716" end_char="717">no</TOKEN>
<TOKEN id="token-5-38" pos="word" morph="none" start_char="719" end_char="720">se</TOKEN>
<TOKEN id="token-5-39" pos="word" morph="none" start_char="722" end_char="723">ha</TOKEN>
<TOKEN id="token-5-40" pos="word" morph="none" start_char="725" end_char="736">generalizado</TOKEN>
<TOKEN id="token-5-41" pos="word" morph="none" start_char="738" end_char="739">su</TOKEN>
<TOKEN id="token-5-42" pos="word" morph="none" start_char="741" end_char="751">fabricación</TOKEN>
<TOKEN id="token-5-43" pos="word" morph="none" start_char="753" end_char="753">y</TOKEN>
<TOKEN id="token-5-44" pos="word" morph="none" start_char="755" end_char="756">de</TOKEN>
<TOKEN id="token-5-45" pos="word" morph="none" start_char="758" end_char="760">las</TOKEN>
<TOKEN id="token-5-46" pos="word" morph="none" start_char="762" end_char="767">buenas</TOKEN>
<TOKEN id="token-5-47" pos="punct" morph="none" start_char="768" end_char="768">,</TOKEN>
<TOKEN id="token-5-48" pos="word" morph="none" start_char="770" end_char="777">sabiendo</TOKEN>
<TOKEN id="token-5-49" pos="word" morph="none" start_char="779" end_char="782">como</TOKEN>
<TOKEN id="token-5-50" pos="word" morph="none" start_char="784" end_char="790">sabemos</TOKEN>
<TOKEN id="token-5-51" pos="word" morph="none" start_char="792" end_char="794">que</TOKEN>
<TOKEN id="token-5-52" pos="word" morph="none" start_char="796" end_char="798">hoy</TOKEN>
<TOKEN id="token-5-53" pos="word" morph="none" start_char="800" end_char="802">día</TOKEN>
<TOKEN id="token-5-54" pos="word" morph="none" start_char="804" end_char="805">se</TOKEN>
<TOKEN id="token-5-55" pos="word" morph="none" start_char="807" end_char="812">diseña</TOKEN>
<TOKEN id="token-5-56" pos="word" morph="none" start_char="814" end_char="814">y</TOKEN>
<TOKEN id="token-5-57" pos="word" morph="none" start_char="816" end_char="817">se</TOKEN>
<TOKEN id="token-5-58" pos="word" morph="none" start_char="819" end_char="825">fabrica</TOKEN>
<TOKEN id="token-5-59" pos="word" morph="none" start_char="827" end_char="835">cualquier</TOKEN>
<TOKEN id="token-5-60" pos="word" morph="none" start_char="837" end_char="840">cosa</TOKEN>
<TOKEN id="token-5-61" pos="word" morph="none" start_char="842" end_char="843">en</TOKEN>
<TOKEN id="token-5-62" pos="word" morph="none" start_char="845" end_char="848">días</TOKEN>
<TOKEN id="token-5-63" pos="punct" morph="none" start_char="849" end_char="849">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="851" end_char="1115">
<ORIGINAL_TEXT>Ya fuera las malas, las buenas, las muy buenas, o las excelentes y del material que fuera, el gobierno debería, Como ha hecho con otras cuestiones y actividades, caso hospitales de campaña, haber puesto la maquina y las empresas a fabricar mascarillas a todo trapo.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="851" end_char="852">Ya</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="854" end_char="858">fuera</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="860" end_char="862">las</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="864" end_char="868">malas</TOKEN>
<TOKEN id="token-6-4" pos="punct" morph="none" start_char="869" end_char="869">,</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="871" end_char="873">las</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="875" end_char="880">buenas</TOKEN>
<TOKEN id="token-6-7" pos="punct" morph="none" start_char="881" end_char="881">,</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="883" end_char="885">las</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="887" end_char="889">muy</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="891" end_char="896">buenas</TOKEN>
<TOKEN id="token-6-11" pos="punct" morph="none" start_char="897" end_char="897">,</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="899" end_char="899">o</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="901" end_char="903">las</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="905" end_char="914">excelentes</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="916" end_char="916">y</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="918" end_char="920">del</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="922" end_char="929">material</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="931" end_char="933">que</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="935" end_char="939">fuera</TOKEN>
<TOKEN id="token-6-20" pos="punct" morph="none" start_char="940" end_char="940">,</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="942" end_char="943">el</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="945" end_char="952">gobierno</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="954" end_char="960">debería</TOKEN>
<TOKEN id="token-6-24" pos="punct" morph="none" start_char="961" end_char="961">,</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="963" end_char="966">Como</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="968" end_char="969">ha</TOKEN>
<TOKEN id="token-6-27" pos="word" morph="none" start_char="971" end_char="975">hecho</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="977" end_char="979">con</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="981" end_char="985">otras</TOKEN>
<TOKEN id="token-6-30" pos="word" morph="none" start_char="987" end_char="996">cuestiones</TOKEN>
<TOKEN id="token-6-31" pos="word" morph="none" start_char="998" end_char="998">y</TOKEN>
<TOKEN id="token-6-32" pos="word" morph="none" start_char="1000" end_char="1010">actividades</TOKEN>
<TOKEN id="token-6-33" pos="punct" morph="none" start_char="1011" end_char="1011">,</TOKEN>
<TOKEN id="token-6-34" pos="word" morph="none" start_char="1013" end_char="1016">caso</TOKEN>
<TOKEN id="token-6-35" pos="word" morph="none" start_char="1018" end_char="1027">hospitales</TOKEN>
<TOKEN id="token-6-36" pos="word" morph="none" start_char="1029" end_char="1030">de</TOKEN>
<TOKEN id="token-6-37" pos="word" morph="none" start_char="1032" end_char="1038">campaña</TOKEN>
<TOKEN id="token-6-38" pos="punct" morph="none" start_char="1039" end_char="1039">,</TOKEN>
<TOKEN id="token-6-39" pos="word" morph="none" start_char="1041" end_char="1045">haber</TOKEN>
<TOKEN id="token-6-40" pos="word" morph="none" start_char="1047" end_char="1052">puesto</TOKEN>
<TOKEN id="token-6-41" pos="word" morph="none" start_char="1054" end_char="1055">la</TOKEN>
<TOKEN id="token-6-42" pos="word" morph="none" start_char="1057" end_char="1063">maquina</TOKEN>
<TOKEN id="token-6-43" pos="word" morph="none" start_char="1065" end_char="1065">y</TOKEN>
<TOKEN id="token-6-44" pos="word" morph="none" start_char="1067" end_char="1069">las</TOKEN>
<TOKEN id="token-6-45" pos="word" morph="none" start_char="1071" end_char="1078">empresas</TOKEN>
<TOKEN id="token-6-46" pos="word" morph="none" start_char="1080" end_char="1080">a</TOKEN>
<TOKEN id="token-6-47" pos="word" morph="none" start_char="1082" end_char="1089">fabricar</TOKEN>
<TOKEN id="token-6-48" pos="word" morph="none" start_char="1091" end_char="1101">mascarillas</TOKEN>
<TOKEN id="token-6-49" pos="word" morph="none" start_char="1103" end_char="1103">a</TOKEN>
<TOKEN id="token-6-50" pos="word" morph="none" start_char="1105" end_char="1108">todo</TOKEN>
<TOKEN id="token-6-51" pos="word" morph="none" start_char="1110" end_char="1114">trapo</TOKEN>
<TOKEN id="token-6-52" pos="punct" morph="none" start_char="1115" end_char="1115">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="1117" end_char="1139">
<ORIGINAL_TEXT>Por una sencilla razón.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="1117" end_char="1119">Por</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="1121" end_char="1123">una</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="1125" end_char="1132">sencilla</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="1134" end_char="1138">razón</TOKEN>
<TOKEN id="token-7-4" pos="punct" morph="none" start_char="1139" end_char="1139">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1141" end_char="1167">
<ORIGINAL_TEXT>EL PRINCIPIO DE PROTECCIÓN.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1141" end_char="1142">EL</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1144" end_char="1152">PRINCIPIO</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1154" end_char="1155">DE</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1157" end_char="1166">PROTECCIÓN</TOKEN>
<TOKEN id="token-8-4" pos="punct" morph="none" start_char="1167" end_char="1167">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1169" end_char="1196">
<ORIGINAL_TEXT>No las había de ningún tipo.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1169" end_char="1170">No</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1172" end_char="1174">las</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1176" end_char="1180">había</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1182" end_char="1183">de</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1185" end_char="1190">ningún</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1192" end_char="1195">tipo</TOKEN>
<TOKEN id="token-9-6" pos="punct" morph="none" start_char="1196" end_char="1196">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1198" end_char="1274">
<ORIGINAL_TEXT>Cuando llueve el paraguas no es obligatorio, pero lo usamos para no mojarnos.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1198" end_char="1203">Cuando</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1205" end_char="1210">llueve</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1212" end_char="1213">el</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1215" end_char="1222">paraguas</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1224" end_char="1225">no</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1227" end_char="1228">es</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1230" end_char="1240">obligatorio</TOKEN>
<TOKEN id="token-10-7" pos="punct" morph="none" start_char="1241" end_char="1241">,</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1243" end_char="1246">pero</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1248" end_char="1249">lo</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1251" end_char="1256">usamos</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1258" end_char="1261">para</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1263" end_char="1264">no</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1266" end_char="1273">mojarnos</TOKEN>
<TOKEN id="token-10-14" pos="punct" morph="none" start_char="1274" end_char="1274">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1276" end_char="1297">
<ORIGINAL_TEXT>Porqué no se ha hecho?</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1276" end_char="1281">Porqué</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1283" end_char="1284">no</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1286" end_char="1287">se</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1289" end_char="1290">ha</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1292" end_char="1296">hecho</TOKEN>
<TOKEN id="token-11-5" pos="punct" morph="none" start_char="1297" end_char="1297">?</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1299" end_char="1338">
<ORIGINAL_TEXT>O volvemos a lo de siempre y así nos va.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1299" end_char="1299">O</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1301" end_char="1308">volvemos</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1310" end_char="1310">a</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1312" end_char="1313">lo</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1315" end_char="1316">de</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1318" end_char="1324">siempre</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1326" end_char="1326">y</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1328" end_char="1330">así</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1332" end_char="1334">nos</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1336" end_char="1337">va</TOKEN>
<TOKEN id="token-12-10" pos="punct" morph="none" start_char="1338" end_char="1338">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1340" end_char="1365">
<ORIGINAL_TEXT>¡¡¡Qué fabriquen ellos !!!</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="punct" morph="none" start_char="1340" end_char="1342">¡¡¡</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1343" end_char="1345">Qué</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1347" end_char="1355">fabriquen</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1357" end_char="1361">ellos</TOKEN>
<TOKEN id="token-13-4" pos="punct" morph="none" start_char="1363" end_char="1365">!!!</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1367" end_char="1377">
<ORIGINAL_TEXT>Así pienso.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1367" end_char="1369">Así</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1371" end_char="1376">pienso</TOKEN>
<TOKEN id="token-14-2" pos="punct" morph="none" start_char="1377" end_char="1377">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1381" end_char="1527">
<ORIGINAL_TEXT>La mejor de las noticias dsd q el virus llegó a España: el gobierno aprueba ESPECIFICACION UNE 0064-1:2020 Mascarillas higiénicas no reutilizables.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1381" end_char="1382">La</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1384" end_char="1388">mejor</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1390" end_char="1391">de</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1393" end_char="1395">las</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1397" end_char="1404">noticias</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1406" end_char="1408">dsd</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1410" end_char="1410">q</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1412" end_char="1413">el</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1415" end_char="1419">virus</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1421" end_char="1425">llegó</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1427" end_char="1427">a</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1429" end_char="1434">España</TOKEN>
<TOKEN id="token-15-12" pos="punct" morph="none" start_char="1435" end_char="1435">:</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1437" end_char="1438">el</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1440" end_char="1447">gobierno</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="1449" end_char="1455">aprueba</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="1457" end_char="1470">ESPECIFICACION</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="1472" end_char="1474">UNE</TOKEN>
<TOKEN id="token-15-18" pos="unknown" morph="none" start_char="1476" end_char="1486">0064-1:2020</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="1488" end_char="1498">Mascarillas</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="1500" end_char="1509">higiénicas</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="1511" end_char="1512">no</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="1514" end_char="1526">reutilizables</TOKEN>
<TOKEN id="token-15-23" pos="punct" morph="none" start_char="1527" end_char="1527">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1529" end_char="1588">
<ORIGINAL_TEXT>Requisitos de materiales, diseño, confección, marcado y uso.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1529" end_char="1538">Requisitos</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1540" end_char="1541">de</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1543" end_char="1552">materiales</TOKEN>
<TOKEN id="token-16-3" pos="punct" morph="none" start_char="1553" end_char="1553">,</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1555" end_char="1560">diseño</TOKEN>
<TOKEN id="token-16-5" pos="punct" morph="none" start_char="1561" end_char="1561">,</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1563" end_char="1572">confección</TOKEN>
<TOKEN id="token-16-7" pos="punct" morph="none" start_char="1573" end_char="1573">,</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1575" end_char="1581">marcado</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="1583" end_char="1583">y</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="1585" end_char="1587">uso</TOKEN>
<TOKEN id="token-16-11" pos="punct" morph="none" start_char="1588" end_char="1588">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1590" end_char="1673">
<ORIGINAL_TEXT>Parte 1: Para uso en adultos para la generalización de su uso ESTAMOS DE ENHORABUENA</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1590" end_char="1594">Parte</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1596" end_char="1596">1</TOKEN>
<TOKEN id="token-17-2" pos="punct" morph="none" start_char="1597" end_char="1597">:</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="1599" end_char="1602">Para</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="1604" end_char="1606">uso</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="1608" end_char="1609">en</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="1611" end_char="1617">adultos</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="1619" end_char="1622">para</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="1624" end_char="1625">la</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="1627" end_char="1640">generalización</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="1642" end_char="1643">de</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="1645" end_char="1646">su</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="1648" end_char="1650">uso</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="1652" end_char="1658">ESTAMOS</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="1660" end_char="1661">DE</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="1663" end_char="1673">ENHORABUENA</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1677" end_char="2042">
<ORIGINAL_TEXT>La mascarilla si aunque sea un pañuelo y gafas y guantes, comprendo que la OMS y los gobiernos fueran cautos por la srncilla razon de que no había ni hay mascarillas para todo el mundo, yo cre que lo primero era asegurar que el personal sanitario las tuviera y asegurar que se evitaba el acaparamiento, aconsejando que cada uno se hiciera la suya, cosa nada dificil.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="1677" end_char="1678">La</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="1680" end_char="1689">mascarilla</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="1691" end_char="1692">si</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="1694" end_char="1699">aunque</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="1701" end_char="1703">sea</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="1705" end_char="1706">un</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="1708" end_char="1714">pañuelo</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="1716" end_char="1716">y</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="1718" end_char="1722">gafas</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="1724" end_char="1724">y</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="1726" end_char="1732">guantes</TOKEN>
<TOKEN id="token-18-11" pos="punct" morph="none" start_char="1733" end_char="1733">,</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="1735" end_char="1743">comprendo</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="1745" end_char="1747">que</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="1749" end_char="1750">la</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="1752" end_char="1754">OMS</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="1756" end_char="1756">y</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="1758" end_char="1760">los</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="1762" end_char="1770">gobiernos</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="1772" end_char="1777">fueran</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="1779" end_char="1784">cautos</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="1786" end_char="1788">por</TOKEN>
<TOKEN id="token-18-22" pos="word" morph="none" start_char="1790" end_char="1791">la</TOKEN>
<TOKEN id="token-18-23" pos="word" morph="none" start_char="1793" end_char="1800">srncilla</TOKEN>
<TOKEN id="token-18-24" pos="word" morph="none" start_char="1802" end_char="1806">razon</TOKEN>
<TOKEN id="token-18-25" pos="word" morph="none" start_char="1808" end_char="1809">de</TOKEN>
<TOKEN id="token-18-26" pos="word" morph="none" start_char="1811" end_char="1813">que</TOKEN>
<TOKEN id="token-18-27" pos="word" morph="none" start_char="1815" end_char="1816">no</TOKEN>
<TOKEN id="token-18-28" pos="word" morph="none" start_char="1818" end_char="1822">había</TOKEN>
<TOKEN id="token-18-29" pos="word" morph="none" start_char="1824" end_char="1825">ni</TOKEN>
<TOKEN id="token-18-30" pos="word" morph="none" start_char="1827" end_char="1829">hay</TOKEN>
<TOKEN id="token-18-31" pos="word" morph="none" start_char="1831" end_char="1841">mascarillas</TOKEN>
<TOKEN id="token-18-32" pos="word" morph="none" start_char="1843" end_char="1846">para</TOKEN>
<TOKEN id="token-18-33" pos="word" morph="none" start_char="1848" end_char="1851">todo</TOKEN>
<TOKEN id="token-18-34" pos="word" morph="none" start_char="1853" end_char="1854">el</TOKEN>
<TOKEN id="token-18-35" pos="word" morph="none" start_char="1856" end_char="1860">mundo</TOKEN>
<TOKEN id="token-18-36" pos="punct" morph="none" start_char="1861" end_char="1861">,</TOKEN>
<TOKEN id="token-18-37" pos="word" morph="none" start_char="1863" end_char="1864">yo</TOKEN>
<TOKEN id="token-18-38" pos="word" morph="none" start_char="1866" end_char="1868">cre</TOKEN>
<TOKEN id="token-18-39" pos="word" morph="none" start_char="1870" end_char="1872">que</TOKEN>
<TOKEN id="token-18-40" pos="word" morph="none" start_char="1874" end_char="1875">lo</TOKEN>
<TOKEN id="token-18-41" pos="word" morph="none" start_char="1877" end_char="1883">primero</TOKEN>
<TOKEN id="token-18-42" pos="word" morph="none" start_char="1885" end_char="1887">era</TOKEN>
<TOKEN id="token-18-43" pos="word" morph="none" start_char="1889" end_char="1896">asegurar</TOKEN>
<TOKEN id="token-18-44" pos="word" morph="none" start_char="1898" end_char="1900">que</TOKEN>
<TOKEN id="token-18-45" pos="word" morph="none" start_char="1902" end_char="1903">el</TOKEN>
<TOKEN id="token-18-46" pos="word" morph="none" start_char="1905" end_char="1912">personal</TOKEN>
<TOKEN id="token-18-47" pos="word" morph="none" start_char="1914" end_char="1922">sanitario</TOKEN>
<TOKEN id="token-18-48" pos="word" morph="none" start_char="1924" end_char="1926">las</TOKEN>
<TOKEN id="token-18-49" pos="word" morph="none" start_char="1928" end_char="1934">tuviera</TOKEN>
<TOKEN id="token-18-50" pos="word" morph="none" start_char="1936" end_char="1936">y</TOKEN>
<TOKEN id="token-18-51" pos="word" morph="none" start_char="1938" end_char="1945">asegurar</TOKEN>
<TOKEN id="token-18-52" pos="word" morph="none" start_char="1947" end_char="1949">que</TOKEN>
<TOKEN id="token-18-53" pos="word" morph="none" start_char="1951" end_char="1952">se</TOKEN>
<TOKEN id="token-18-54" pos="word" morph="none" start_char="1954" end_char="1960">evitaba</TOKEN>
<TOKEN id="token-18-55" pos="word" morph="none" start_char="1962" end_char="1963">el</TOKEN>
<TOKEN id="token-18-56" pos="word" morph="none" start_char="1965" end_char="1977">acaparamiento</TOKEN>
<TOKEN id="token-18-57" pos="punct" morph="none" start_char="1978" end_char="1978">,</TOKEN>
<TOKEN id="token-18-58" pos="word" morph="none" start_char="1980" end_char="1990">aconsejando</TOKEN>
<TOKEN id="token-18-59" pos="word" morph="none" start_char="1992" end_char="1994">que</TOKEN>
<TOKEN id="token-18-60" pos="word" morph="none" start_char="1996" end_char="1999">cada</TOKEN>
<TOKEN id="token-18-61" pos="word" morph="none" start_char="2001" end_char="2003">uno</TOKEN>
<TOKEN id="token-18-62" pos="word" morph="none" start_char="2005" end_char="2006">se</TOKEN>
<TOKEN id="token-18-63" pos="word" morph="none" start_char="2008" end_char="2014">hiciera</TOKEN>
<TOKEN id="token-18-64" pos="word" morph="none" start_char="2016" end_char="2017">la</TOKEN>
<TOKEN id="token-18-65" pos="word" morph="none" start_char="2019" end_char="2022">suya</TOKEN>
<TOKEN id="token-18-66" pos="punct" morph="none" start_char="2023" end_char="2023">,</TOKEN>
<TOKEN id="token-18-67" pos="word" morph="none" start_char="2025" end_char="2028">cosa</TOKEN>
<TOKEN id="token-18-68" pos="word" morph="none" start_char="2030" end_char="2033">nada</TOKEN>
<TOKEN id="token-18-69" pos="word" morph="none" start_char="2035" end_char="2041">dificil</TOKEN>
<TOKEN id="token-18-70" pos="punct" morph="none" start_char="2042" end_char="2042">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2046" end_char="2172">
<ORIGINAL_TEXT>Lo mejor suele coincidir con lo correcto... deberían reconocer su error, se equivocaron y punto ... hay que ponerse mascarilla.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2046" end_char="2047">Lo</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2049" end_char="2053">mejor</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2055" end_char="2059">suele</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2061" end_char="2069">coincidir</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2071" end_char="2073">con</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2075" end_char="2076">lo</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2078" end_char="2085">correcto</TOKEN>
<TOKEN id="token-19-7" pos="punct" morph="none" start_char="2086" end_char="2088">...</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2090" end_char="2097">deberían</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="2099" end_char="2107">reconocer</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="2109" end_char="2110">su</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="2112" end_char="2116">error</TOKEN>
<TOKEN id="token-19-12" pos="punct" morph="none" start_char="2117" end_char="2117">,</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="2119" end_char="2120">se</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="2122" end_char="2132">equivocaron</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="2134" end_char="2134">y</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="2136" end_char="2140">punto</TOKEN>
<TOKEN id="token-19-17" pos="punct" morph="none" start_char="2142" end_char="2144">...</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="2146" end_char="2148">hay</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="2150" end_char="2152">que</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="2154" end_char="2160">ponerse</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="2162" end_char="2171">mascarilla</TOKEN>
<TOKEN id="token-19-22" pos="punct" morph="none" start_char="2172" end_char="2172">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2175" end_char="2250">
<ORIGINAL_TEXT>Todo esto que estáis montando dando vueltas al rollito de siempre apesta ...</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2175" end_char="2178">Todo</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2180" end_char="2183">esto</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2185" end_char="2187">que</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2189" end_char="2194">estáis</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2196" end_char="2203">montando</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2205" end_char="2209">dando</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2211" end_char="2217">vueltas</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2219" end_char="2220">al</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="2222" end_char="2228">rollito</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2230" end_char="2231">de</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2233" end_char="2239">siempre</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="2241" end_char="2246">apesta</TOKEN>
<TOKEN id="token-20-12" pos="punct" morph="none" start_char="2248" end_char="2250">...</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2253" end_char="2256">
<ORIGINAL_TEXT>P.D.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="unknown" morph="none" start_char="2253" end_char="2255">P.D</TOKEN>
<TOKEN id="token-21-1" pos="punct" morph="none" start_char="2256" end_char="2256">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2258" end_char="2363">
<ORIGINAL_TEXT>: Siento haberme saltado mi cuarentena forera pero no lo he podido evitar ... vuelvo a mi silencio monacal</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="punct" morph="none" start_char="2258" end_char="2258">:</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2260" end_char="2265">Siento</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2267" end_char="2273">haberme</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2275" end_char="2281">saltado</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2283" end_char="2284">mi</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2286" end_char="2295">cuarentena</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2297" end_char="2302">forera</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2304" end_char="2307">pero</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="2309" end_char="2310">no</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="2312" end_char="2313">lo</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="2315" end_char="2316">he</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="2318" end_char="2323">podido</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="2325" end_char="2330">evitar</TOKEN>
<TOKEN id="token-22-13" pos="punct" morph="none" start_char="2332" end_char="2334">...</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="2336" end_char="2341">vuelvo</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="2343" end_char="2343">a</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="2345" end_char="2346">mi</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="2348" end_char="2355">silencio</TOKEN>
<TOKEN id="token-22-18" pos="word" morph="none" start_char="2357" end_char="2363">monacal</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2367" end_char="2415">
<ORIGINAL_TEXT>Antes del cómo el Gobierno deberá aclarar el qué.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2367" end_char="2371">Antes</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2373" end_char="2375">del</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2377" end_char="2380">cómo</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2382" end_char="2383">el</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="2385" end_char="2392">Gobierno</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="2394" end_char="2399">deberá</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="2401" end_char="2407">aclarar</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="2409" end_char="2410">el</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="2412" end_char="2414">qué</TOKEN>
<TOKEN id="token-23-9" pos="punct" morph="none" start_char="2415" end_char="2415">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2417" end_char="2451">
<ORIGINAL_TEXT>Porque sigue sin haber mascarillas.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="2417" end_char="2422">Porque</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="2424" end_char="2428">sigue</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="2430" end_char="2432">sin</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="2434" end_char="2438">haber</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="2440" end_char="2450">mascarillas</TOKEN>
<TOKEN id="token-24-5" pos="punct" morph="none" start_char="2451" end_char="2451">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2453" end_char="2552">
<ORIGINAL_TEXT>Me pregunto quién fabrica nuestro papel, ya sea higiénico, de cocina o los folios para la impresora.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="2453" end_char="2454">Me</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="2456" end_char="2463">pregunto</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="2465" end_char="2469">quién</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="2471" end_char="2477">fabrica</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="2479" end_char="2485">nuestro</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="2487" end_char="2491">papel</TOKEN>
<TOKEN id="token-25-6" pos="punct" morph="none" start_char="2492" end_char="2492">,</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="2494" end_char="2495">ya</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="2497" end_char="2499">sea</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="2501" end_char="2509">higiénico</TOKEN>
<TOKEN id="token-25-10" pos="punct" morph="none" start_char="2510" end_char="2510">,</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="2512" end_char="2513">de</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="2515" end_char="2520">cocina</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="2522" end_char="2522">o</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="2524" end_char="2526">los</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="2528" end_char="2533">folios</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="2535" end_char="2538">para</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="2540" end_char="2541">la</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="2543" end_char="2551">impresora</TOKEN>
<TOKEN id="token-25-19" pos="punct" morph="none" start_char="2552" end_char="2552">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="2554" end_char="2608">
<ORIGINAL_TEXT>Porque fabricar mascarillas no tiene mucha más ciencia.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="2554" end_char="2559">Porque</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="2561" end_char="2568">fabricar</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="2570" end_char="2580">mascarillas</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="2582" end_char="2583">no</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="2585" end_char="2589">tiene</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="2591" end_char="2595">mucha</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="2597" end_char="2599">más</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="2601" end_char="2607">ciencia</TOKEN>
<TOKEN id="token-26-8" pos="punct" morph="none" start_char="2608" end_char="2608">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="2610" end_char="2845">
<ORIGINAL_TEXT>O, ejem, quién fabrica los sostenes de las señoras (que, en caso de apuro, de uno viejo se pueden sacar dos mascarillas: ya lleva la goma puesta) que parecen más complicados que una mascarilla, por lo menos de las que no llevan válvula.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="2610" end_char="2610">O</TOKEN>
<TOKEN id="token-27-1" pos="punct" morph="none" start_char="2611" end_char="2611">,</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="2613" end_char="2616">ejem</TOKEN>
<TOKEN id="token-27-3" pos="punct" morph="none" start_char="2617" end_char="2617">,</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="2619" end_char="2623">quién</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="2625" end_char="2631">fabrica</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="2633" end_char="2635">los</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="2637" end_char="2644">sostenes</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="2646" end_char="2647">de</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="2649" end_char="2651">las</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="2653" end_char="2659">señoras</TOKEN>
<TOKEN id="token-27-11" pos="punct" morph="none" start_char="2661" end_char="2661">(</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="2662" end_char="2664">que</TOKEN>
<TOKEN id="token-27-13" pos="punct" morph="none" start_char="2665" end_char="2665">,</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="2667" end_char="2668">en</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="2670" end_char="2673">caso</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="2675" end_char="2676">de</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="2678" end_char="2682">apuro</TOKEN>
<TOKEN id="token-27-18" pos="punct" morph="none" start_char="2683" end_char="2683">,</TOKEN>
<TOKEN id="token-27-19" pos="word" morph="none" start_char="2685" end_char="2686">de</TOKEN>
<TOKEN id="token-27-20" pos="word" morph="none" start_char="2688" end_char="2690">uno</TOKEN>
<TOKEN id="token-27-21" pos="word" morph="none" start_char="2692" end_char="2696">viejo</TOKEN>
<TOKEN id="token-27-22" pos="word" morph="none" start_char="2698" end_char="2699">se</TOKEN>
<TOKEN id="token-27-23" pos="word" morph="none" start_char="2701" end_char="2706">pueden</TOKEN>
<TOKEN id="token-27-24" pos="word" morph="none" start_char="2708" end_char="2712">sacar</TOKEN>
<TOKEN id="token-27-25" pos="word" morph="none" start_char="2714" end_char="2716">dos</TOKEN>
<TOKEN id="token-27-26" pos="word" morph="none" start_char="2718" end_char="2728">mascarillas</TOKEN>
<TOKEN id="token-27-27" pos="punct" morph="none" start_char="2729" end_char="2729">:</TOKEN>
<TOKEN id="token-27-28" pos="word" morph="none" start_char="2731" end_char="2732">ya</TOKEN>
<TOKEN id="token-27-29" pos="word" morph="none" start_char="2734" end_char="2738">lleva</TOKEN>
<TOKEN id="token-27-30" pos="word" morph="none" start_char="2740" end_char="2741">la</TOKEN>
<TOKEN id="token-27-31" pos="word" morph="none" start_char="2743" end_char="2746">goma</TOKEN>
<TOKEN id="token-27-32" pos="word" morph="none" start_char="2748" end_char="2753">puesta</TOKEN>
<TOKEN id="token-27-33" pos="punct" morph="none" start_char="2754" end_char="2754">)</TOKEN>
<TOKEN id="token-27-34" pos="word" morph="none" start_char="2756" end_char="2758">que</TOKEN>
<TOKEN id="token-27-35" pos="word" morph="none" start_char="2760" end_char="2766">parecen</TOKEN>
<TOKEN id="token-27-36" pos="word" morph="none" start_char="2768" end_char="2770">más</TOKEN>
<TOKEN id="token-27-37" pos="word" morph="none" start_char="2772" end_char="2782">complicados</TOKEN>
<TOKEN id="token-27-38" pos="word" morph="none" start_char="2784" end_char="2786">que</TOKEN>
<TOKEN id="token-27-39" pos="word" morph="none" start_char="2788" end_char="2790">una</TOKEN>
<TOKEN id="token-27-40" pos="word" morph="none" start_char="2792" end_char="2801">mascarilla</TOKEN>
<TOKEN id="token-27-41" pos="punct" morph="none" start_char="2802" end_char="2802">,</TOKEN>
<TOKEN id="token-27-42" pos="word" morph="none" start_char="2804" end_char="2806">por</TOKEN>
<TOKEN id="token-27-43" pos="word" morph="none" start_char="2808" end_char="2809">lo</TOKEN>
<TOKEN id="token-27-44" pos="word" morph="none" start_char="2811" end_char="2815">menos</TOKEN>
<TOKEN id="token-27-45" pos="word" morph="none" start_char="2817" end_char="2818">de</TOKEN>
<TOKEN id="token-27-46" pos="word" morph="none" start_char="2820" end_char="2822">las</TOKEN>
<TOKEN id="token-27-47" pos="word" morph="none" start_char="2824" end_char="2826">que</TOKEN>
<TOKEN id="token-27-48" pos="word" morph="none" start_char="2828" end_char="2829">no</TOKEN>
<TOKEN id="token-27-49" pos="word" morph="none" start_char="2831" end_char="2836">llevan</TOKEN>
<TOKEN id="token-27-50" pos="word" morph="none" start_char="2838" end_char="2844">válvula</TOKEN>
<TOKEN id="token-27-51" pos="punct" morph="none" start_char="2845" end_char="2845">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="2847" end_char="3053">
<ORIGINAL_TEXT>¿Pasa como con casi todo lo demás, que el papel de España se limita a poner un etiqueta con el nombre del importador pero, si busca uno con cuidado, al final encuentra que aquello está fabricado... en China?</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="punct" morph="none" start_char="2847" end_char="2847">¿</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="2848" end_char="2851">Pasa</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="2853" end_char="2856">como</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="2858" end_char="2860">con</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="2862" end_char="2865">casi</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="2867" end_char="2870">todo</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="2872" end_char="2873">lo</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="2875" end_char="2879">demás</TOKEN>
<TOKEN id="token-28-8" pos="punct" morph="none" start_char="2880" end_char="2880">,</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="2882" end_char="2884">que</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="2886" end_char="2887">el</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="2889" end_char="2893">papel</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="2895" end_char="2896">de</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="2898" end_char="2903">España</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="2905" end_char="2906">se</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="2908" end_char="2913">limita</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="2915" end_char="2915">a</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="2917" end_char="2921">poner</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="2923" end_char="2924">un</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="2926" end_char="2933">etiqueta</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="2935" end_char="2937">con</TOKEN>
<TOKEN id="token-28-21" pos="word" morph="none" start_char="2939" end_char="2940">el</TOKEN>
<TOKEN id="token-28-22" pos="word" morph="none" start_char="2942" end_char="2947">nombre</TOKEN>
<TOKEN id="token-28-23" pos="word" morph="none" start_char="2949" end_char="2951">del</TOKEN>
<TOKEN id="token-28-24" pos="word" morph="none" start_char="2953" end_char="2962">importador</TOKEN>
<TOKEN id="token-28-25" pos="word" morph="none" start_char="2964" end_char="2967">pero</TOKEN>
<TOKEN id="token-28-26" pos="punct" morph="none" start_char="2968" end_char="2968">,</TOKEN>
<TOKEN id="token-28-27" pos="word" morph="none" start_char="2970" end_char="2971">si</TOKEN>
<TOKEN id="token-28-28" pos="word" morph="none" start_char="2973" end_char="2977">busca</TOKEN>
<TOKEN id="token-28-29" pos="word" morph="none" start_char="2979" end_char="2981">uno</TOKEN>
<TOKEN id="token-28-30" pos="word" morph="none" start_char="2983" end_char="2985">con</TOKEN>
<TOKEN id="token-28-31" pos="word" morph="none" start_char="2987" end_char="2993">cuidado</TOKEN>
<TOKEN id="token-28-32" pos="punct" morph="none" start_char="2994" end_char="2994">,</TOKEN>
<TOKEN id="token-28-33" pos="word" morph="none" start_char="2996" end_char="2997">al</TOKEN>
<TOKEN id="token-28-34" pos="word" morph="none" start_char="2999" end_char="3003">final</TOKEN>
<TOKEN id="token-28-35" pos="word" morph="none" start_char="3005" end_char="3013">encuentra</TOKEN>
<TOKEN id="token-28-36" pos="word" morph="none" start_char="3015" end_char="3017">que</TOKEN>
<TOKEN id="token-28-37" pos="word" morph="none" start_char="3019" end_char="3025">aquello</TOKEN>
<TOKEN id="token-28-38" pos="word" morph="none" start_char="3027" end_char="3030">está</TOKEN>
<TOKEN id="token-28-39" pos="word" morph="none" start_char="3032" end_char="3040">fabricado</TOKEN>
<TOKEN id="token-28-40" pos="punct" morph="none" start_char="3041" end_char="3043">...</TOKEN>
<TOKEN id="token-28-41" pos="word" morph="none" start_char="3045" end_char="3046">en</TOKEN>
<TOKEN id="token-28-42" pos="word" morph="none" start_char="3048" end_char="3052">China</TOKEN>
<TOKEN id="token-28-43" pos="punct" morph="none" start_char="3053" end_char="3053">?</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3057" end_char="3164">
<ORIGINAL_TEXT>Hasta fechas muy recientes la OMS solo las recomendaba para los infectados y profesionales que los trataban.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="3057" end_char="3061">Hasta</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="3063" end_char="3068">fechas</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="3070" end_char="3072">muy</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="3074" end_char="3082">recientes</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="3084" end_char="3085">la</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="3087" end_char="3089">OMS</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="3091" end_char="3094">solo</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="3096" end_char="3098">las</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="3100" end_char="3110">recomendaba</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="3112" end_char="3115">para</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="3117" end_char="3119">los</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="3121" end_char="3130">infectados</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="3132" end_char="3132">y</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="3134" end_char="3146">profesionales</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="3148" end_char="3150">que</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="3152" end_char="3154">los</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="3156" end_char="3163">trataban</TOKEN>
<TOKEN id="token-29-17" pos="punct" morph="none" start_char="3164" end_char="3164">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3167" end_char="3300">
<ORIGINAL_TEXT>Se trataría de limitar la difusión de las gotitas de Flügge expulsadas por los contaminados al estornudar, toser o simplemente hablar.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="3167" end_char="3168">Se</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="3170" end_char="3177">trataría</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="3179" end_char="3180">de</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="3182" end_char="3188">limitar</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="3190" end_char="3191">la</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="3193" end_char="3200">difusión</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="3202" end_char="3203">de</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="3205" end_char="3207">las</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="3209" end_char="3215">gotitas</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="3217" end_char="3218">de</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="3220" end_char="3225">Flügge</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="3227" end_char="3236">expulsadas</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="3238" end_char="3240">por</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="3242" end_char="3244">los</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="3246" end_char="3257">contaminados</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="3259" end_char="3260">al</TOKEN>
<TOKEN id="token-30-16" pos="word" morph="none" start_char="3262" end_char="3271">estornudar</TOKEN>
<TOKEN id="token-30-17" pos="punct" morph="none" start_char="3272" end_char="3272">,</TOKEN>
<TOKEN id="token-30-18" pos="word" morph="none" start_char="3274" end_char="3278">toser</TOKEN>
<TOKEN id="token-30-19" pos="word" morph="none" start_char="3280" end_char="3280">o</TOKEN>
<TOKEN id="token-30-20" pos="word" morph="none" start_char="3282" end_char="3292">simplemente</TOKEN>
<TOKEN id="token-30-21" pos="word" morph="none" start_char="3294" end_char="3299">hablar</TOKEN>
<TOKEN id="token-30-22" pos="punct" morph="none" start_char="3300" end_char="3300">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="3303" end_char="3516">
<ORIGINAL_TEXT>Y es que las mascarillas más restrictivas (FFP3) que deben filtrar hasta el 99% de partículas de hasta 0,6 micras (0,006 milímetros) dejarían pasar sin problemas el Covid-19 cuyo diámetro es de 0,000130 milímetros.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="3303" end_char="3303">Y</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="3305" end_char="3306">es</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="3308" end_char="3310">que</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="3312" end_char="3314">las</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="3316" end_char="3326">mascarillas</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="3328" end_char="3330">más</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="3332" end_char="3343">restrictivas</TOKEN>
<TOKEN id="token-31-7" pos="punct" morph="none" start_char="3345" end_char="3345">(</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="3346" end_char="3349">FFP3</TOKEN>
<TOKEN id="token-31-9" pos="punct" morph="none" start_char="3350" end_char="3350">)</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="3352" end_char="3354">que</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="3356" end_char="3360">deben</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="3362" end_char="3368">filtrar</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="3370" end_char="3374">hasta</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="3376" end_char="3377">el</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="3379" end_char="3380">99</TOKEN>
<TOKEN id="token-31-16" pos="punct" morph="none" start_char="3381" end_char="3381">%</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="3383" end_char="3384">de</TOKEN>
<TOKEN id="token-31-18" pos="word" morph="none" start_char="3386" end_char="3395">partículas</TOKEN>
<TOKEN id="token-31-19" pos="word" morph="none" start_char="3397" end_char="3398">de</TOKEN>
<TOKEN id="token-31-20" pos="word" morph="none" start_char="3400" end_char="3404">hasta</TOKEN>
<TOKEN id="token-31-21" pos="unknown" morph="none" start_char="3406" end_char="3408">0,6</TOKEN>
<TOKEN id="token-31-22" pos="word" morph="none" start_char="3410" end_char="3415">micras</TOKEN>
<TOKEN id="token-31-23" pos="punct" morph="none" start_char="3417" end_char="3417">(</TOKEN>
<TOKEN id="token-31-24" pos="unknown" morph="none" start_char="3418" end_char="3422">0,006</TOKEN>
<TOKEN id="token-31-25" pos="word" morph="none" start_char="3424" end_char="3433">milímetros</TOKEN>
<TOKEN id="token-31-26" pos="punct" morph="none" start_char="3434" end_char="3434">)</TOKEN>
<TOKEN id="token-31-27" pos="word" morph="none" start_char="3436" end_char="3443">dejarían</TOKEN>
<TOKEN id="token-31-28" pos="word" morph="none" start_char="3445" end_char="3449">pasar</TOKEN>
<TOKEN id="token-31-29" pos="word" morph="none" start_char="3451" end_char="3453">sin</TOKEN>
<TOKEN id="token-31-30" pos="word" morph="none" start_char="3455" end_char="3463">problemas</TOKEN>
<TOKEN id="token-31-31" pos="word" morph="none" start_char="3465" end_char="3466">el</TOKEN>
<TOKEN id="token-31-32" pos="unknown" morph="none" start_char="3468" end_char="3475">Covid-19</TOKEN>
<TOKEN id="token-31-33" pos="word" morph="none" start_char="3477" end_char="3480">cuyo</TOKEN>
<TOKEN id="token-31-34" pos="word" morph="none" start_char="3482" end_char="3489">diámetro</TOKEN>
<TOKEN id="token-31-35" pos="word" morph="none" start_char="3491" end_char="3492">es</TOKEN>
<TOKEN id="token-31-36" pos="word" morph="none" start_char="3494" end_char="3495">de</TOKEN>
<TOKEN id="token-31-37" pos="unknown" morph="none" start_char="3497" end_char="3504">0,000130</TOKEN>
<TOKEN id="token-31-38" pos="word" morph="none" start_char="3506" end_char="3515">milímetros</TOKEN>
<TOKEN id="token-31-39" pos="punct" morph="none" start_char="3516" end_char="3516">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="3519" end_char="3884">
<ORIGINAL_TEXT>No se puede pues culpar a la OMS o los gobiernos de seguir sus dictados ya que se postulaba que serían las gotitas de Flügge, que se depositarían en las manos o en las superficies y objetos de alrededor, los principales agentes de transmisión y las mascarillas, en ningún caso podrían atrapar un virus, que es órdenes de magnitud más pequeño que su alcance efectivo.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="3519" end_char="3520">No</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="3522" end_char="3523">se</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="3525" end_char="3529">puede</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="3531" end_char="3534">pues</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="3536" end_char="3541">culpar</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="3543" end_char="3543">a</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="3545" end_char="3546">la</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="3548" end_char="3550">OMS</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="3552" end_char="3552">o</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="3554" end_char="3556">los</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="3558" end_char="3566">gobiernos</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="3568" end_char="3569">de</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="3571" end_char="3576">seguir</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="3578" end_char="3580">sus</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="3582" end_char="3589">dictados</TOKEN>
<TOKEN id="token-32-15" pos="word" morph="none" start_char="3591" end_char="3592">ya</TOKEN>
<TOKEN id="token-32-16" pos="word" morph="none" start_char="3594" end_char="3596">que</TOKEN>
<TOKEN id="token-32-17" pos="word" morph="none" start_char="3598" end_char="3599">se</TOKEN>
<TOKEN id="token-32-18" pos="word" morph="none" start_char="3601" end_char="3609">postulaba</TOKEN>
<TOKEN id="token-32-19" pos="word" morph="none" start_char="3611" end_char="3613">que</TOKEN>
<TOKEN id="token-32-20" pos="word" morph="none" start_char="3615" end_char="3620">serían</TOKEN>
<TOKEN id="token-32-21" pos="word" morph="none" start_char="3622" end_char="3624">las</TOKEN>
<TOKEN id="token-32-22" pos="word" morph="none" start_char="3626" end_char="3632">gotitas</TOKEN>
<TOKEN id="token-32-23" pos="word" morph="none" start_char="3634" end_char="3635">de</TOKEN>
<TOKEN id="token-32-24" pos="word" morph="none" start_char="3637" end_char="3642">Flügge</TOKEN>
<TOKEN id="token-32-25" pos="punct" morph="none" start_char="3643" end_char="3643">,</TOKEN>
<TOKEN id="token-32-26" pos="word" morph="none" start_char="3645" end_char="3647">que</TOKEN>
<TOKEN id="token-32-27" pos="word" morph="none" start_char="3649" end_char="3650">se</TOKEN>
<TOKEN id="token-32-28" pos="word" morph="none" start_char="3652" end_char="3663">depositarían</TOKEN>
<TOKEN id="token-32-29" pos="word" morph="none" start_char="3665" end_char="3666">en</TOKEN>
<TOKEN id="token-32-30" pos="word" morph="none" start_char="3668" end_char="3670">las</TOKEN>
<TOKEN id="token-32-31" pos="word" morph="none" start_char="3672" end_char="3676">manos</TOKEN>
<TOKEN id="token-32-32" pos="word" morph="none" start_char="3678" end_char="3678">o</TOKEN>
<TOKEN id="token-32-33" pos="word" morph="none" start_char="3680" end_char="3681">en</TOKEN>
<TOKEN id="token-32-34" pos="word" morph="none" start_char="3683" end_char="3685">las</TOKEN>
<TOKEN id="token-32-35" pos="word" morph="none" start_char="3687" end_char="3697">superficies</TOKEN>
<TOKEN id="token-32-36" pos="word" morph="none" start_char="3699" end_char="3699">y</TOKEN>
<TOKEN id="token-32-37" pos="word" morph="none" start_char="3701" end_char="3707">objetos</TOKEN>
<TOKEN id="token-32-38" pos="word" morph="none" start_char="3709" end_char="3710">de</TOKEN>
<TOKEN id="token-32-39" pos="word" morph="none" start_char="3712" end_char="3720">alrededor</TOKEN>
<TOKEN id="token-32-40" pos="punct" morph="none" start_char="3721" end_char="3721">,</TOKEN>
<TOKEN id="token-32-41" pos="word" morph="none" start_char="3723" end_char="3725">los</TOKEN>
<TOKEN id="token-32-42" pos="word" morph="none" start_char="3727" end_char="3737">principales</TOKEN>
<TOKEN id="token-32-43" pos="word" morph="none" start_char="3739" end_char="3745">agentes</TOKEN>
<TOKEN id="token-32-44" pos="word" morph="none" start_char="3747" end_char="3748">de</TOKEN>
<TOKEN id="token-32-45" pos="word" morph="none" start_char="3750" end_char="3760">transmisión</TOKEN>
<TOKEN id="token-32-46" pos="word" morph="none" start_char="3762" end_char="3762">y</TOKEN>
<TOKEN id="token-32-47" pos="word" morph="none" start_char="3764" end_char="3766">las</TOKEN>
<TOKEN id="token-32-48" pos="word" morph="none" start_char="3768" end_char="3778">mascarillas</TOKEN>
<TOKEN id="token-32-49" pos="punct" morph="none" start_char="3779" end_char="3779">,</TOKEN>
<TOKEN id="token-32-50" pos="word" morph="none" start_char="3781" end_char="3782">en</TOKEN>
<TOKEN id="token-32-51" pos="word" morph="none" start_char="3784" end_char="3789">ningún</TOKEN>
<TOKEN id="token-32-52" pos="word" morph="none" start_char="3791" end_char="3794">caso</TOKEN>
<TOKEN id="token-32-53" pos="word" morph="none" start_char="3796" end_char="3802">podrían</TOKEN>
<TOKEN id="token-32-54" pos="word" morph="none" start_char="3804" end_char="3810">atrapar</TOKEN>
<TOKEN id="token-32-55" pos="word" morph="none" start_char="3812" end_char="3813">un</TOKEN>
<TOKEN id="token-32-56" pos="word" morph="none" start_char="3815" end_char="3819">virus</TOKEN>
<TOKEN id="token-32-57" pos="punct" morph="none" start_char="3820" end_char="3820">,</TOKEN>
<TOKEN id="token-32-58" pos="word" morph="none" start_char="3822" end_char="3824">que</TOKEN>
<TOKEN id="token-32-59" pos="word" morph="none" start_char="3826" end_char="3827">es</TOKEN>
<TOKEN id="token-32-60" pos="word" morph="none" start_char="3829" end_char="3835">órdenes</TOKEN>
<TOKEN id="token-32-61" pos="word" morph="none" start_char="3837" end_char="3838">de</TOKEN>
<TOKEN id="token-32-62" pos="word" morph="none" start_char="3840" end_char="3847">magnitud</TOKEN>
<TOKEN id="token-32-63" pos="word" morph="none" start_char="3849" end_char="3851">más</TOKEN>
<TOKEN id="token-32-64" pos="word" morph="none" start_char="3853" end_char="3859">pequeño</TOKEN>
<TOKEN id="token-32-65" pos="word" morph="none" start_char="3861" end_char="3863">que</TOKEN>
<TOKEN id="token-32-66" pos="word" morph="none" start_char="3865" end_char="3866">su</TOKEN>
<TOKEN id="token-32-67" pos="word" morph="none" start_char="3868" end_char="3874">alcance</TOKEN>
<TOKEN id="token-32-68" pos="word" morph="none" start_char="3876" end_char="3883">efectivo</TOKEN>
<TOKEN id="token-32-69" pos="punct" morph="none" start_char="3884" end_char="3884">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="3887" end_char="4322">
<ORIGINAL_TEXT>Pero, en el aire que respiramos hay en suspensión una ingente cantidad de partículas contaminantes de tamaños mucho mayores que los virus y sería casi imposible que en ellas no se depositasen virus como el Covid-19 cuya latencia vendría dada por el tipo de partícula, temperatura y humedad relativa y cuya efectividad de contagio sería mayor cuanto mayor fuera la partícula, ya que en partículas grandes se depositaría más carga vírica.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="3887" end_char="3890">Pero</TOKEN>
<TOKEN id="token-33-1" pos="punct" morph="none" start_char="3891" end_char="3891">,</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="3893" end_char="3894">en</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="3896" end_char="3897">el</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="3899" end_char="3902">aire</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="3904" end_char="3906">que</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="3908" end_char="3917">respiramos</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="3919" end_char="3921">hay</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="3923" end_char="3924">en</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="3926" end_char="3935">suspensión</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="3937" end_char="3939">una</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="3941" end_char="3947">ingente</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="3949" end_char="3956">cantidad</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="3958" end_char="3959">de</TOKEN>
<TOKEN id="token-33-14" pos="word" morph="none" start_char="3961" end_char="3970">partículas</TOKEN>
<TOKEN id="token-33-15" pos="word" morph="none" start_char="3972" end_char="3984">contaminantes</TOKEN>
<TOKEN id="token-33-16" pos="word" morph="none" start_char="3986" end_char="3987">de</TOKEN>
<TOKEN id="token-33-17" pos="word" morph="none" start_char="3989" end_char="3995">tamaños</TOKEN>
<TOKEN id="token-33-18" pos="word" morph="none" start_char="3997" end_char="4001">mucho</TOKEN>
<TOKEN id="token-33-19" pos="word" morph="none" start_char="4003" end_char="4009">mayores</TOKEN>
<TOKEN id="token-33-20" pos="word" morph="none" start_char="4011" end_char="4013">que</TOKEN>
<TOKEN id="token-33-21" pos="word" morph="none" start_char="4015" end_char="4017">los</TOKEN>
<TOKEN id="token-33-22" pos="word" morph="none" start_char="4019" end_char="4023">virus</TOKEN>
<TOKEN id="token-33-23" pos="word" morph="none" start_char="4025" end_char="4025">y</TOKEN>
<TOKEN id="token-33-24" pos="word" morph="none" start_char="4027" end_char="4031">sería</TOKEN>
<TOKEN id="token-33-25" pos="word" morph="none" start_char="4033" end_char="4036">casi</TOKEN>
<TOKEN id="token-33-26" pos="word" morph="none" start_char="4038" end_char="4046">imposible</TOKEN>
<TOKEN id="token-33-27" pos="word" morph="none" start_char="4048" end_char="4050">que</TOKEN>
<TOKEN id="token-33-28" pos="word" morph="none" start_char="4052" end_char="4053">en</TOKEN>
<TOKEN id="token-33-29" pos="word" morph="none" start_char="4055" end_char="4059">ellas</TOKEN>
<TOKEN id="token-33-30" pos="word" morph="none" start_char="4061" end_char="4062">no</TOKEN>
<TOKEN id="token-33-31" pos="word" morph="none" start_char="4064" end_char="4065">se</TOKEN>
<TOKEN id="token-33-32" pos="word" morph="none" start_char="4067" end_char="4077">depositasen</TOKEN>
<TOKEN id="token-33-33" pos="word" morph="none" start_char="4079" end_char="4083">virus</TOKEN>
<TOKEN id="token-33-34" pos="word" morph="none" start_char="4085" end_char="4088">como</TOKEN>
<TOKEN id="token-33-35" pos="word" morph="none" start_char="4090" end_char="4091">el</TOKEN>
<TOKEN id="token-33-36" pos="unknown" morph="none" start_char="4093" end_char="4100">Covid-19</TOKEN>
<TOKEN id="token-33-37" pos="word" morph="none" start_char="4102" end_char="4105">cuya</TOKEN>
<TOKEN id="token-33-38" pos="word" morph="none" start_char="4107" end_char="4114">latencia</TOKEN>
<TOKEN id="token-33-39" pos="word" morph="none" start_char="4116" end_char="4122">vendría</TOKEN>
<TOKEN id="token-33-40" pos="word" morph="none" start_char="4124" end_char="4127">dada</TOKEN>
<TOKEN id="token-33-41" pos="word" morph="none" start_char="4129" end_char="4131">por</TOKEN>
<TOKEN id="token-33-42" pos="word" morph="none" start_char="4133" end_char="4134">el</TOKEN>
<TOKEN id="token-33-43" pos="word" morph="none" start_char="4136" end_char="4139">tipo</TOKEN>
<TOKEN id="token-33-44" pos="word" morph="none" start_char="4141" end_char="4142">de</TOKEN>
<TOKEN id="token-33-45" pos="word" morph="none" start_char="4144" end_char="4152">partícula</TOKEN>
<TOKEN id="token-33-46" pos="punct" morph="none" start_char="4153" end_char="4153">,</TOKEN>
<TOKEN id="token-33-47" pos="word" morph="none" start_char="4155" end_char="4165">temperatura</TOKEN>
<TOKEN id="token-33-48" pos="word" morph="none" start_char="4167" end_char="4167">y</TOKEN>
<TOKEN id="token-33-49" pos="word" morph="none" start_char="4169" end_char="4175">humedad</TOKEN>
<TOKEN id="token-33-50" pos="word" morph="none" start_char="4177" end_char="4184">relativa</TOKEN>
<TOKEN id="token-33-51" pos="word" morph="none" start_char="4186" end_char="4186">y</TOKEN>
<TOKEN id="token-33-52" pos="word" morph="none" start_char="4188" end_char="4191">cuya</TOKEN>
<TOKEN id="token-33-53" pos="word" morph="none" start_char="4193" end_char="4203">efectividad</TOKEN>
<TOKEN id="token-33-54" pos="word" morph="none" start_char="4205" end_char="4206">de</TOKEN>
<TOKEN id="token-33-55" pos="word" morph="none" start_char="4208" end_char="4215">contagio</TOKEN>
<TOKEN id="token-33-56" pos="word" morph="none" start_char="4217" end_char="4221">sería</TOKEN>
<TOKEN id="token-33-57" pos="word" morph="none" start_char="4223" end_char="4227">mayor</TOKEN>
<TOKEN id="token-33-58" pos="word" morph="none" start_char="4229" end_char="4234">cuanto</TOKEN>
<TOKEN id="token-33-59" pos="word" morph="none" start_char="4236" end_char="4240">mayor</TOKEN>
<TOKEN id="token-33-60" pos="word" morph="none" start_char="4242" end_char="4246">fuera</TOKEN>
<TOKEN id="token-33-61" pos="word" morph="none" start_char="4248" end_char="4249">la</TOKEN>
<TOKEN id="token-33-62" pos="word" morph="none" start_char="4251" end_char="4259">partícula</TOKEN>
<TOKEN id="token-33-63" pos="punct" morph="none" start_char="4260" end_char="4260">,</TOKEN>
<TOKEN id="token-33-64" pos="word" morph="none" start_char="4262" end_char="4263">ya</TOKEN>
<TOKEN id="token-33-65" pos="word" morph="none" start_char="4265" end_char="4267">que</TOKEN>
<TOKEN id="token-33-66" pos="word" morph="none" start_char="4269" end_char="4270">en</TOKEN>
<TOKEN id="token-33-67" pos="word" morph="none" start_char="4272" end_char="4281">partículas</TOKEN>
<TOKEN id="token-33-68" pos="word" morph="none" start_char="4283" end_char="4289">grandes</TOKEN>
<TOKEN id="token-33-69" pos="word" morph="none" start_char="4291" end_char="4292">se</TOKEN>
<TOKEN id="token-33-70" pos="word" morph="none" start_char="4294" end_char="4304">depositaría</TOKEN>
<TOKEN id="token-33-71" pos="word" morph="none" start_char="4306" end_char="4308">más</TOKEN>
<TOKEN id="token-33-72" pos="word" morph="none" start_char="4310" end_char="4314">carga</TOKEN>
<TOKEN id="token-33-73" pos="word" morph="none" start_char="4316" end_char="4321">vírica</TOKEN>
<TOKEN id="token-33-74" pos="punct" morph="none" start_char="4322" end_char="4322">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="4325" end_char="4612">
<ORIGINAL_TEXT>Así, mascarillas que en teoría NO podrían servir para proteger de un virus que las atravesaría con facilidad por su tamaño, se mostrarían MUY ÚTILES para atrapar una carga viral, que es en realidad transportada por partículas contaminantes que si atrapan y neutralizarían las mascarillas.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="4325" end_char="4327">Así</TOKEN>
<TOKEN id="token-34-1" pos="punct" morph="none" start_char="4328" end_char="4328">,</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="4330" end_char="4340">mascarillas</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="4342" end_char="4344">que</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="4346" end_char="4347">en</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="4349" end_char="4354">teoría</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="4356" end_char="4357">NO</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="4359" end_char="4365">podrían</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="4367" end_char="4372">servir</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="4374" end_char="4377">para</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="4379" end_char="4386">proteger</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="4388" end_char="4389">de</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="4391" end_char="4392">un</TOKEN>
<TOKEN id="token-34-13" pos="word" morph="none" start_char="4394" end_char="4398">virus</TOKEN>
<TOKEN id="token-34-14" pos="word" morph="none" start_char="4400" end_char="4402">que</TOKEN>
<TOKEN id="token-34-15" pos="word" morph="none" start_char="4404" end_char="4406">las</TOKEN>
<TOKEN id="token-34-16" pos="word" morph="none" start_char="4408" end_char="4418">atravesaría</TOKEN>
<TOKEN id="token-34-17" pos="word" morph="none" start_char="4420" end_char="4422">con</TOKEN>
<TOKEN id="token-34-18" pos="word" morph="none" start_char="4424" end_char="4432">facilidad</TOKEN>
<TOKEN id="token-34-19" pos="word" morph="none" start_char="4434" end_char="4436">por</TOKEN>
<TOKEN id="token-34-20" pos="word" morph="none" start_char="4438" end_char="4439">su</TOKEN>
<TOKEN id="token-34-21" pos="word" morph="none" start_char="4441" end_char="4446">tamaño</TOKEN>
<TOKEN id="token-34-22" pos="punct" morph="none" start_char="4447" end_char="4447">,</TOKEN>
<TOKEN id="token-34-23" pos="word" morph="none" start_char="4449" end_char="4450">se</TOKEN>
<TOKEN id="token-34-24" pos="word" morph="none" start_char="4452" end_char="4461">mostrarían</TOKEN>
<TOKEN id="token-34-25" pos="word" morph="none" start_char="4463" end_char="4465">MUY</TOKEN>
<TOKEN id="token-34-26" pos="word" morph="none" start_char="4467" end_char="4472">ÚTILES</TOKEN>
<TOKEN id="token-34-27" pos="word" morph="none" start_char="4474" end_char="4477">para</TOKEN>
<TOKEN id="token-34-28" pos="word" morph="none" start_char="4479" end_char="4485">atrapar</TOKEN>
<TOKEN id="token-34-29" pos="word" morph="none" start_char="4487" end_char="4489">una</TOKEN>
<TOKEN id="token-34-30" pos="word" morph="none" start_char="4491" end_char="4495">carga</TOKEN>
<TOKEN id="token-34-31" pos="word" morph="none" start_char="4497" end_char="4501">viral</TOKEN>
<TOKEN id="token-34-32" pos="punct" morph="none" start_char="4502" end_char="4502">,</TOKEN>
<TOKEN id="token-34-33" pos="word" morph="none" start_char="4504" end_char="4506">que</TOKEN>
<TOKEN id="token-34-34" pos="word" morph="none" start_char="4508" end_char="4509">es</TOKEN>
<TOKEN id="token-34-35" pos="word" morph="none" start_char="4511" end_char="4512">en</TOKEN>
<TOKEN id="token-34-36" pos="word" morph="none" start_char="4514" end_char="4521">realidad</TOKEN>
<TOKEN id="token-34-37" pos="word" morph="none" start_char="4523" end_char="4534">transportada</TOKEN>
<TOKEN id="token-34-38" pos="word" morph="none" start_char="4536" end_char="4538">por</TOKEN>
<TOKEN id="token-34-39" pos="word" morph="none" start_char="4540" end_char="4549">partículas</TOKEN>
<TOKEN id="token-34-40" pos="word" morph="none" start_char="4551" end_char="4563">contaminantes</TOKEN>
<TOKEN id="token-34-41" pos="word" morph="none" start_char="4565" end_char="4567">que</TOKEN>
<TOKEN id="token-34-42" pos="word" morph="none" start_char="4569" end_char="4570">si</TOKEN>
<TOKEN id="token-34-43" pos="word" morph="none" start_char="4572" end_char="4578">atrapan</TOKEN>
<TOKEN id="token-34-44" pos="word" morph="none" start_char="4580" end_char="4580">y</TOKEN>
<TOKEN id="token-34-45" pos="word" morph="none" start_char="4582" end_char="4595">neutralizarían</TOKEN>
<TOKEN id="token-34-46" pos="word" morph="none" start_char="4597" end_char="4599">las</TOKEN>
<TOKEN id="token-34-47" pos="word" morph="none" start_char="4601" end_char="4611">mascarillas</TOKEN>
<TOKEN id="token-34-48" pos="punct" morph="none" start_char="4612" end_char="4612">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="4615" end_char="4942">
<ORIGINAL_TEXT>De aquí se podrían extraer 3 conclusiones: 1ª.- No sería cierto que 3 metros sea distancia de seguridad, 2ª.- que incluso mascarillas de confección artesanal podrían ser efectivas y 3ª.-que sería conveniente desecharlas o desinfectarlas (con lejía por ejemplo) con frecuencia, porque podrían acumular una peligrosa carga vírica.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="4615" end_char="4616">De</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="4618" end_char="4621">aquí</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="4623" end_char="4624">se</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="4626" end_char="4632">podrían</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="4634" end_char="4640">extraer</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="4642" end_char="4642">3</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="4644" end_char="4655">conclusiones</TOKEN>
<TOKEN id="token-35-7" pos="punct" morph="none" start_char="4656" end_char="4656">:</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="4658" end_char="4659">1ª</TOKEN>
<TOKEN id="token-35-9" pos="punct" morph="none" start_char="4660" end_char="4661">.-</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="4663" end_char="4664">No</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="4666" end_char="4670">sería</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="4672" end_char="4677">cierto</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="4679" end_char="4681">que</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="4683" end_char="4683">3</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="4685" end_char="4690">metros</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="4692" end_char="4694">sea</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="4696" end_char="4704">distancia</TOKEN>
<TOKEN id="token-35-18" pos="word" morph="none" start_char="4706" end_char="4707">de</TOKEN>
<TOKEN id="token-35-19" pos="word" morph="none" start_char="4709" end_char="4717">seguridad</TOKEN>
<TOKEN id="token-35-20" pos="punct" morph="none" start_char="4718" end_char="4718">,</TOKEN>
<TOKEN id="token-35-21" pos="word" morph="none" start_char="4720" end_char="4721">2ª</TOKEN>
<TOKEN id="token-35-22" pos="punct" morph="none" start_char="4722" end_char="4723">.-</TOKEN>
<TOKEN id="token-35-23" pos="word" morph="none" start_char="4725" end_char="4727">que</TOKEN>
<TOKEN id="token-35-24" pos="word" morph="none" start_char="4729" end_char="4735">incluso</TOKEN>
<TOKEN id="token-35-25" pos="word" morph="none" start_char="4737" end_char="4747">mascarillas</TOKEN>
<TOKEN id="token-35-26" pos="word" morph="none" start_char="4749" end_char="4750">de</TOKEN>
<TOKEN id="token-35-27" pos="word" morph="none" start_char="4752" end_char="4761">confección</TOKEN>
<TOKEN id="token-35-28" pos="word" morph="none" start_char="4763" end_char="4771">artesanal</TOKEN>
<TOKEN id="token-35-29" pos="word" morph="none" start_char="4773" end_char="4779">podrían</TOKEN>
<TOKEN id="token-35-30" pos="word" morph="none" start_char="4781" end_char="4783">ser</TOKEN>
<TOKEN id="token-35-31" pos="word" morph="none" start_char="4785" end_char="4793">efectivas</TOKEN>
<TOKEN id="token-35-32" pos="word" morph="none" start_char="4795" end_char="4795">y</TOKEN>
<TOKEN id="token-35-33" pos="unknown" morph="none" start_char="4797" end_char="4803">3ª.-que</TOKEN>
<TOKEN id="token-35-34" pos="word" morph="none" start_char="4805" end_char="4809">sería</TOKEN>
<TOKEN id="token-35-35" pos="word" morph="none" start_char="4811" end_char="4821">conveniente</TOKEN>
<TOKEN id="token-35-36" pos="word" morph="none" start_char="4823" end_char="4833">desecharlas</TOKEN>
<TOKEN id="token-35-37" pos="word" morph="none" start_char="4835" end_char="4835">o</TOKEN>
<TOKEN id="token-35-38" pos="word" morph="none" start_char="4837" end_char="4850">desinfectarlas</TOKEN>
<TOKEN id="token-35-39" pos="punct" morph="none" start_char="4852" end_char="4852">(</TOKEN>
<TOKEN id="token-35-40" pos="word" morph="none" start_char="4853" end_char="4855">con</TOKEN>
<TOKEN id="token-35-41" pos="word" morph="none" start_char="4857" end_char="4861">lejía</TOKEN>
<TOKEN id="token-35-42" pos="word" morph="none" start_char="4863" end_char="4865">por</TOKEN>
<TOKEN id="token-35-43" pos="word" morph="none" start_char="4867" end_char="4873">ejemplo</TOKEN>
<TOKEN id="token-35-44" pos="punct" morph="none" start_char="4874" end_char="4874">)</TOKEN>
<TOKEN id="token-35-45" pos="word" morph="none" start_char="4876" end_char="4878">con</TOKEN>
<TOKEN id="token-35-46" pos="word" morph="none" start_char="4880" end_char="4889">frecuencia</TOKEN>
<TOKEN id="token-35-47" pos="punct" morph="none" start_char="4890" end_char="4890">,</TOKEN>
<TOKEN id="token-35-48" pos="word" morph="none" start_char="4892" end_char="4897">porque</TOKEN>
<TOKEN id="token-35-49" pos="word" morph="none" start_char="4899" end_char="4905">podrían</TOKEN>
<TOKEN id="token-35-50" pos="word" morph="none" start_char="4907" end_char="4914">acumular</TOKEN>
<TOKEN id="token-35-51" pos="word" morph="none" start_char="4916" end_char="4918">una</TOKEN>
<TOKEN id="token-35-52" pos="word" morph="none" start_char="4920" end_char="4928">peligrosa</TOKEN>
<TOKEN id="token-35-53" pos="word" morph="none" start_char="4930" end_char="4934">carga</TOKEN>
<TOKEN id="token-35-54" pos="word" morph="none" start_char="4936" end_char="4941">vírica</TOKEN>
<TOKEN id="token-35-55" pos="punct" morph="none" start_char="4942" end_char="4942">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="4945" end_char="4953">
<ORIGINAL_TEXT>Responder</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="4945" end_char="4953">Responder</TOKEN>
</SEG>
<SEG id="segment-37" start_char="4956" end_char="4975">
<ORIGINAL_TEXT>Denunciar comentario</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="4956" end_char="4964">Denunciar</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="4966" end_char="4975">comentario</TOKEN>
</SEG>
<SEG id="segment-38" start_char="4978" end_char="4997">
<ORIGINAL_TEXT>Ocultar 4 Respuestas</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="4978" end_char="4984">Ocultar</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="4986" end_char="4986">4</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="4988" end_char="4997">Respuestas</TOKEN>
</SEG>
<SEG id="segment-39" start_char="5000" end_char="5000">
<ORIGINAL_TEXT>1</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="5000" end_char="5000">1</TOKEN>
</SEG>
<SEG id="segment-40" start_char="5003" end_char="5003">
<ORIGINAL_TEXT>2</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="5003" end_char="5003">2</TOKEN>
</SEG>
<SEG id="segment-41" start_char="5006" end_char="5012">
<ORIGINAL_TEXT>Cambris</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="5006" end_char="5012">Cambris</TOKEN>
</SEG>
<SEG id="segment-42" start_char="5015" end_char="5028">
<ORIGINAL_TEXT>09/04/20 12:07</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="unknown" morph="none" start_char="5015" end_char="5022">09/04/20</TOKEN>
<TOKEN id="token-42-1" pos="unknown" morph="none" start_char="5024" end_char="5028">12:07</TOKEN>
</SEG>
<SEG id="segment-43" start_char="5031" end_char="5111">
<ORIGINAL_TEXT>La OMS sigue diciendo q solo para personas contagiadas y para quienes las cuiden.</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="5031" end_char="5032">La</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="5034" end_char="5036">OMS</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="5038" end_char="5042">sigue</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="5044" end_char="5051">diciendo</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="5053" end_char="5053">q</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="5055" end_char="5058">solo</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="5060" end_char="5063">para</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="5065" end_char="5072">personas</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="5074" end_char="5084">contagiadas</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="5086" end_char="5086">y</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="5088" end_char="5091">para</TOKEN>
<TOKEN id="token-43-11" pos="word" morph="none" start_char="5093" end_char="5099">quienes</TOKEN>
<TOKEN id="token-43-12" pos="word" morph="none" start_char="5101" end_char="5103">las</TOKEN>
<TOKEN id="token-43-13" pos="word" morph="none" start_char="5105" end_char="5110">cuiden</TOKEN>
<TOKEN id="token-43-14" pos="punct" morph="none" start_char="5111" end_char="5111">.</TOKEN>
</SEG>
<SEG id="segment-44" start_char="5113" end_char="5195">
<ORIGINAL_TEXT>Al menos hasta ayer, a pesar de que lógicamente reducen el Ro, número reproductivo.</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="5113" end_char="5114">Al</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="5116" end_char="5120">menos</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="5122" end_char="5126">hasta</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="5128" end_char="5131">ayer</TOKEN>
<TOKEN id="token-44-4" pos="punct" morph="none" start_char="5132" end_char="5132">,</TOKEN>
<TOKEN id="token-44-5" pos="word" morph="none" start_char="5134" end_char="5134">a</TOKEN>
<TOKEN id="token-44-6" pos="word" morph="none" start_char="5136" end_char="5140">pesar</TOKEN>
<TOKEN id="token-44-7" pos="word" morph="none" start_char="5142" end_char="5143">de</TOKEN>
<TOKEN id="token-44-8" pos="word" morph="none" start_char="5145" end_char="5147">que</TOKEN>
<TOKEN id="token-44-9" pos="word" morph="none" start_char="5149" end_char="5159">lógicamente</TOKEN>
<TOKEN id="token-44-10" pos="word" morph="none" start_char="5161" end_char="5167">reducen</TOKEN>
<TOKEN id="token-44-11" pos="word" morph="none" start_char="5169" end_char="5170">el</TOKEN>
<TOKEN id="token-44-12" pos="word" morph="none" start_char="5172" end_char="5173">Ro</TOKEN>
<TOKEN id="token-44-13" pos="punct" morph="none" start_char="5174" end_char="5174">,</TOKEN>
<TOKEN id="token-44-14" pos="word" morph="none" start_char="5176" end_char="5181">número</TOKEN>
<TOKEN id="token-44-15" pos="word" morph="none" start_char="5183" end_char="5194">reproductivo</TOKEN>
<TOKEN id="token-44-16" pos="punct" morph="none" start_char="5195" end_char="5195">.</TOKEN>
</SEG>
<SEG id="segment-45" start_char="5197" end_char="5272">
<ORIGINAL_TEXT>Ese Ro parece q es igual a 3: cada persona contagiada contagia a otras tres.</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="5197" end_char="5199">Ese</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="5201" end_char="5202">Ro</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="5204" end_char="5209">parece</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="5211" end_char="5211">q</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="5213" end_char="5214">es</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="5216" end_char="5220">igual</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="5222" end_char="5222">a</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="5224" end_char="5224">3</TOKEN>
<TOKEN id="token-45-8" pos="punct" morph="none" start_char="5225" end_char="5225">:</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="5227" end_char="5230">cada</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="5232" end_char="5238">persona</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="5240" end_char="5249">contagiada</TOKEN>
<TOKEN id="token-45-12" pos="word" morph="none" start_char="5251" end_char="5258">contagia</TOKEN>
<TOKEN id="token-45-13" pos="word" morph="none" start_char="5260" end_char="5260">a</TOKEN>
<TOKEN id="token-45-14" pos="word" morph="none" start_char="5262" end_char="5266">otras</TOKEN>
<TOKEN id="token-45-15" pos="word" morph="none" start_char="5268" end_char="5271">tres</TOKEN>
<TOKEN id="token-45-16" pos="punct" morph="none" start_char="5272" end_char="5272">.</TOKEN>
</SEG>
<SEG id="segment-46" start_char="5274" end_char="5356">
<ORIGINAL_TEXT>Generalizar el uso de mascarilla lógicamente hace disminuir el número reproductivo.</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="5274" end_char="5284">Generalizar</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="5286" end_char="5287">el</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="5289" end_char="5291">uso</TOKEN>
<TOKEN id="token-46-3" pos="word" morph="none" start_char="5293" end_char="5294">de</TOKEN>
<TOKEN id="token-46-4" pos="word" morph="none" start_char="5296" end_char="5305">mascarilla</TOKEN>
<TOKEN id="token-46-5" pos="word" morph="none" start_char="5307" end_char="5317">lógicamente</TOKEN>
<TOKEN id="token-46-6" pos="word" morph="none" start_char="5319" end_char="5322">hace</TOKEN>
<TOKEN id="token-46-7" pos="word" morph="none" start_char="5324" end_char="5332">disminuir</TOKEN>
<TOKEN id="token-46-8" pos="word" morph="none" start_char="5334" end_char="5335">el</TOKEN>
<TOKEN id="token-46-9" pos="word" morph="none" start_char="5337" end_char="5342">número</TOKEN>
<TOKEN id="token-46-10" pos="word" morph="none" start_char="5344" end_char="5355">reproductivo</TOKEN>
<TOKEN id="token-46-11" pos="punct" morph="none" start_char="5356" end_char="5356">.</TOKEN>
</SEG>
<SEG id="segment-47" start_char="5358" end_char="5464">
<ORIGINAL_TEXT>Y esto disminuye la demanda de servicios sanitarios Responder Denunciar comentario Ocultar 3 Respuestas 1 2</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="5358" end_char="5358">Y</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="5360" end_char="5363">esto</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="5365" end_char="5373">disminuye</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="5375" end_char="5376">la</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="5378" end_char="5384">demanda</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="5386" end_char="5387">de</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="5389" end_char="5397">servicios</TOKEN>
<TOKEN id="token-47-7" pos="word" morph="none" start_char="5399" end_char="5408">sanitarios</TOKEN>
<TOKEN id="token-47-8" pos="word" morph="none" start_char="5410" end_char="5418">Responder</TOKEN>
<TOKEN id="token-47-9" pos="word" morph="none" start_char="5420" end_char="5428">Denunciar</TOKEN>
<TOKEN id="token-47-10" pos="word" morph="none" start_char="5430" end_char="5439">comentario</TOKEN>
<TOKEN id="token-47-11" pos="word" morph="none" start_char="5441" end_char="5447">Ocultar</TOKEN>
<TOKEN id="token-47-12" pos="word" morph="none" start_char="5449" end_char="5449">3</TOKEN>
<TOKEN id="token-47-13" pos="word" morph="none" start_char="5451" end_char="5460">Respuestas</TOKEN>
<TOKEN id="token-47-14" pos="word" morph="none" start_char="5462" end_char="5462">1</TOKEN>
<TOKEN id="token-47-15" pos="word" morph="none" start_char="5464" end_char="5464">2</TOKEN>
</SEG>
<SEG id="segment-48" start_char="5467" end_char="5473">
<ORIGINAL_TEXT>Macrons</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="5467" end_char="5473">Macrons</TOKEN>
</SEG>
<SEG id="segment-49" start_char="5476" end_char="5489">
<ORIGINAL_TEXT>09/04/20 13:41</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="unknown" morph="none" start_char="5476" end_char="5483">09/04/20</TOKEN>
<TOKEN id="token-49-1" pos="unknown" morph="none" start_char="5485" end_char="5489">13:41</TOKEN>
</SEG>
<SEG id="segment-50" start_char="5492" end_char="6711">
<ORIGINAL_TEXT>Desafortunadamente los expertos en las distintas ramas de salud, parecen saber poco de física del aire.Soy físico de la especialidad y sé que resultaría prácticamente imposible que las gotitas de Flügge expulsadas -por ejemplo al hablar un enfermo (incluso asintomático)- no se depositaran en los millones de partículas que pueblan el aire que respiramos.Así, la distancia de 3 metros que aguantarían en el aire (olvidando las partículas que lo acarrearían) las gotitas de Flügge podría ser un gran error, sobre todo en lugares cerrados.Recientemente he leído una entrevista muy interesante a Sergio Romagnan: https://www.elconfidencial.com/mundo/europa/2020-04-07/coronavirus-oms-italia-veneto-romagnani_2537147/Resalto lo siguiente:"Llegamos a la conclusión de que la circulación del virus alrededor de una misma persona, aunque ya esté infectada, agrava su patología.Es una hipótesis, pero creemos que cuando el virus circula muchas veces por el mismo ambiente, potencia su acción.El virus es muy peligroso en ambientes cerrados donde hay muchas personas.Aún no está del todo claro, pero parece que aunque no estés delante de la persona infectada, aunque no la veas, te puedes llegar a infectar en ambientes cerrados.</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="5492" end_char="5509">Desafortunadamente</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="5511" end_char="5513">los</TOKEN>
<TOKEN id="token-50-2" pos="word" morph="none" start_char="5515" end_char="5522">expertos</TOKEN>
<TOKEN id="token-50-3" pos="word" morph="none" start_char="5524" end_char="5525">en</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="5527" end_char="5529">las</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="5531" end_char="5539">distintas</TOKEN>
<TOKEN id="token-50-6" pos="word" morph="none" start_char="5541" end_char="5545">ramas</TOKEN>
<TOKEN id="token-50-7" pos="word" morph="none" start_char="5547" end_char="5548">de</TOKEN>
<TOKEN id="token-50-8" pos="word" morph="none" start_char="5550" end_char="5554">salud</TOKEN>
<TOKEN id="token-50-9" pos="punct" morph="none" start_char="5555" end_char="5555">,</TOKEN>
<TOKEN id="token-50-10" pos="word" morph="none" start_char="5557" end_char="5563">parecen</TOKEN>
<TOKEN id="token-50-11" pos="word" morph="none" start_char="5565" end_char="5569">saber</TOKEN>
<TOKEN id="token-50-12" pos="word" morph="none" start_char="5571" end_char="5574">poco</TOKEN>
<TOKEN id="token-50-13" pos="word" morph="none" start_char="5576" end_char="5577">de</TOKEN>
<TOKEN id="token-50-14" pos="word" morph="none" start_char="5579" end_char="5584">física</TOKEN>
<TOKEN id="token-50-15" pos="word" morph="none" start_char="5586" end_char="5588">del</TOKEN>
<TOKEN id="token-50-16" pos="unknown" morph="none" start_char="5590" end_char="5597">aire.Soy</TOKEN>
<TOKEN id="token-50-17" pos="word" morph="none" start_char="5599" end_char="5604">físico</TOKEN>
<TOKEN id="token-50-18" pos="word" morph="none" start_char="5606" end_char="5607">de</TOKEN>
<TOKEN id="token-50-19" pos="word" morph="none" start_char="5609" end_char="5610">la</TOKEN>
<TOKEN id="token-50-20" pos="word" morph="none" start_char="5612" end_char="5623">especialidad</TOKEN>
<TOKEN id="token-50-21" pos="word" morph="none" start_char="5625" end_char="5625">y</TOKEN>
<TOKEN id="token-50-22" pos="word" morph="none" start_char="5627" end_char="5628">sé</TOKEN>
<TOKEN id="token-50-23" pos="word" morph="none" start_char="5630" end_char="5632">que</TOKEN>
<TOKEN id="token-50-24" pos="word" morph="none" start_char="5634" end_char="5643">resultaría</TOKEN>
<TOKEN id="token-50-25" pos="word" morph="none" start_char="5645" end_char="5657">prácticamente</TOKEN>
<TOKEN id="token-50-26" pos="word" morph="none" start_char="5659" end_char="5667">imposible</TOKEN>
<TOKEN id="token-50-27" pos="word" morph="none" start_char="5669" end_char="5671">que</TOKEN>
<TOKEN id="token-50-28" pos="word" morph="none" start_char="5673" end_char="5675">las</TOKEN>
<TOKEN id="token-50-29" pos="word" morph="none" start_char="5677" end_char="5683">gotitas</TOKEN>
<TOKEN id="token-50-30" pos="word" morph="none" start_char="5685" end_char="5686">de</TOKEN>
<TOKEN id="token-50-31" pos="word" morph="none" start_char="5688" end_char="5693">Flügge</TOKEN>
<TOKEN id="token-50-32" pos="word" morph="none" start_char="5695" end_char="5704">expulsadas</TOKEN>
<TOKEN id="token-50-33" pos="punct" morph="none" start_char="5706" end_char="5706">-</TOKEN>
<TOKEN id="token-50-34" pos="word" morph="none" start_char="5707" end_char="5709">por</TOKEN>
<TOKEN id="token-50-35" pos="word" morph="none" start_char="5711" end_char="5717">ejemplo</TOKEN>
<TOKEN id="token-50-36" pos="word" morph="none" start_char="5719" end_char="5720">al</TOKEN>
<TOKEN id="token-50-37" pos="word" morph="none" start_char="5722" end_char="5727">hablar</TOKEN>
<TOKEN id="token-50-38" pos="word" morph="none" start_char="5729" end_char="5730">un</TOKEN>
<TOKEN id="token-50-39" pos="word" morph="none" start_char="5732" end_char="5738">enfermo</TOKEN>
<TOKEN id="token-50-40" pos="punct" morph="none" start_char="5740" end_char="5740">(</TOKEN>
<TOKEN id="token-50-41" pos="word" morph="none" start_char="5741" end_char="5747">incluso</TOKEN>
<TOKEN id="token-50-42" pos="word" morph="none" start_char="5749" end_char="5760">asintomático</TOKEN>
<TOKEN id="token-50-43" pos="punct" morph="none" start_char="5761" end_char="5762">)-</TOKEN>
<TOKEN id="token-50-44" pos="word" morph="none" start_char="5764" end_char="5765">no</TOKEN>
<TOKEN id="token-50-45" pos="word" morph="none" start_char="5767" end_char="5768">se</TOKEN>
<TOKEN id="token-50-46" pos="word" morph="none" start_char="5770" end_char="5780">depositaran</TOKEN>
<TOKEN id="token-50-47" pos="word" morph="none" start_char="5782" end_char="5783">en</TOKEN>
<TOKEN id="token-50-48" pos="word" morph="none" start_char="5785" end_char="5787">los</TOKEN>
<TOKEN id="token-50-49" pos="word" morph="none" start_char="5789" end_char="5796">millones</TOKEN>
<TOKEN id="token-50-50" pos="word" morph="none" start_char="5798" end_char="5799">de</TOKEN>
<TOKEN id="token-50-51" pos="word" morph="none" start_char="5801" end_char="5810">partículas</TOKEN>
<TOKEN id="token-50-52" pos="word" morph="none" start_char="5812" end_char="5814">que</TOKEN>
<TOKEN id="token-50-53" pos="word" morph="none" start_char="5816" end_char="5822">pueblan</TOKEN>
<TOKEN id="token-50-54" pos="word" morph="none" start_char="5824" end_char="5825">el</TOKEN>
<TOKEN id="token-50-55" pos="word" morph="none" start_char="5827" end_char="5830">aire</TOKEN>
<TOKEN id="token-50-56" pos="word" morph="none" start_char="5832" end_char="5834">que</TOKEN>
<TOKEN id="token-50-57" pos="unknown" morph="none" start_char="5836" end_char="5849">respiramos.Así</TOKEN>
<TOKEN id="token-50-58" pos="punct" morph="none" start_char="5850" end_char="5850">,</TOKEN>
<TOKEN id="token-50-59" pos="word" morph="none" start_char="5852" end_char="5853">la</TOKEN>
<TOKEN id="token-50-60" pos="word" morph="none" start_char="5855" end_char="5863">distancia</TOKEN>
<TOKEN id="token-50-61" pos="word" morph="none" start_char="5865" end_char="5866">de</TOKEN>
<TOKEN id="token-50-62" pos="word" morph="none" start_char="5868" end_char="5868">3</TOKEN>
<TOKEN id="token-50-63" pos="word" morph="none" start_char="5870" end_char="5875">metros</TOKEN>
<TOKEN id="token-50-64" pos="word" morph="none" start_char="5877" end_char="5879">que</TOKEN>
<TOKEN id="token-50-65" pos="word" morph="none" start_char="5881" end_char="5891">aguantarían</TOKEN>
<TOKEN id="token-50-66" pos="word" morph="none" start_char="5893" end_char="5894">en</TOKEN>
<TOKEN id="token-50-67" pos="word" morph="none" start_char="5896" end_char="5897">el</TOKEN>
<TOKEN id="token-50-68" pos="word" morph="none" start_char="5899" end_char="5902">aire</TOKEN>
<TOKEN id="token-50-69" pos="punct" morph="none" start_char="5904" end_char="5904">(</TOKEN>
<TOKEN id="token-50-70" pos="word" morph="none" start_char="5905" end_char="5913">olvidando</TOKEN>
<TOKEN id="token-50-71" pos="word" morph="none" start_char="5915" end_char="5917">las</TOKEN>
<TOKEN id="token-50-72" pos="word" morph="none" start_char="5919" end_char="5928">partículas</TOKEN>
<TOKEN id="token-50-73" pos="word" morph="none" start_char="5930" end_char="5932">que</TOKEN>
<TOKEN id="token-50-74" pos="word" morph="none" start_char="5934" end_char="5935">lo</TOKEN>
<TOKEN id="token-50-75" pos="word" morph="none" start_char="5937" end_char="5947">acarrearían</TOKEN>
<TOKEN id="token-50-76" pos="punct" morph="none" start_char="5948" end_char="5948">)</TOKEN>
<TOKEN id="token-50-77" pos="word" morph="none" start_char="5950" end_char="5952">las</TOKEN>
<TOKEN id="token-50-78" pos="word" morph="none" start_char="5954" end_char="5960">gotitas</TOKEN>
<TOKEN id="token-50-79" pos="word" morph="none" start_char="5962" end_char="5963">de</TOKEN>
<TOKEN id="token-50-80" pos="word" morph="none" start_char="5965" end_char="5970">Flügge</TOKEN>
<TOKEN id="token-50-81" pos="word" morph="none" start_char="5972" end_char="5977">podría</TOKEN>
<TOKEN id="token-50-82" pos="word" morph="none" start_char="5979" end_char="5981">ser</TOKEN>
<TOKEN id="token-50-83" pos="word" morph="none" start_char="5983" end_char="5984">un</TOKEN>
<TOKEN id="token-50-84" pos="word" morph="none" start_char="5986" end_char="5989">gran</TOKEN>
<TOKEN id="token-50-85" pos="word" morph="none" start_char="5991" end_char="5995">error</TOKEN>
<TOKEN id="token-50-86" pos="punct" morph="none" start_char="5996" end_char="5996">,</TOKEN>
<TOKEN id="token-50-87" pos="word" morph="none" start_char="5998" end_char="6002">sobre</TOKEN>
<TOKEN id="token-50-88" pos="word" morph="none" start_char="6004" end_char="6007">todo</TOKEN>
<TOKEN id="token-50-89" pos="word" morph="none" start_char="6009" end_char="6010">en</TOKEN>
<TOKEN id="token-50-90" pos="word" morph="none" start_char="6012" end_char="6018">lugares</TOKEN>
<TOKEN id="token-50-91" pos="unknown" morph="none" start_char="6020" end_char="6041">cerrados.Recientemente</TOKEN>
<TOKEN id="token-50-92" pos="word" morph="none" start_char="6043" end_char="6044">he</TOKEN>
<TOKEN id="token-50-93" pos="word" morph="none" start_char="6046" end_char="6050">leído</TOKEN>
<TOKEN id="token-50-94" pos="word" morph="none" start_char="6052" end_char="6054">una</TOKEN>
<TOKEN id="token-50-95" pos="word" morph="none" start_char="6056" end_char="6065">entrevista</TOKEN>
<TOKEN id="token-50-96" pos="word" morph="none" start_char="6067" end_char="6069">muy</TOKEN>
<TOKEN id="token-50-97" pos="word" morph="none" start_char="6071" end_char="6081">interesante</TOKEN>
<TOKEN id="token-50-98" pos="word" morph="none" start_char="6083" end_char="6083">a</TOKEN>
<TOKEN id="token-50-99" pos="word" morph="none" start_char="6085" end_char="6090">Sergio</TOKEN>
<TOKEN id="token-50-100" pos="word" morph="none" start_char="6092" end_char="6099">Romagnan</TOKEN>
<TOKEN id="token-50-101" pos="punct" morph="none" start_char="6100" end_char="6100">:</TOKEN>
<TOKEN id="token-50-102" pos="url" morph="none" start_char="6102" end_char="6211">https://www.elconfidencial.com/mundo/europa/2020-04-07/coronavirus-oms-italia-veneto-romagnani_2537147/Resalto</TOKEN>
<TOKEN id="token-50-103" pos="word" morph="none" start_char="6213" end_char="6214">lo</TOKEN>
<TOKEN id="token-50-104" pos="unknown" morph="none" start_char="6216" end_char="6234">siguiente:"Llegamos</TOKEN>
<TOKEN id="token-50-105" pos="word" morph="none" start_char="6236" end_char="6236">a</TOKEN>
<TOKEN id="token-50-106" pos="word" morph="none" start_char="6238" end_char="6239">la</TOKEN>
<TOKEN id="token-50-107" pos="word" morph="none" start_char="6241" end_char="6250">conclusión</TOKEN>
<TOKEN id="token-50-108" pos="word" morph="none" start_char="6252" end_char="6253">de</TOKEN>
<TOKEN id="token-50-109" pos="word" morph="none" start_char="6255" end_char="6257">que</TOKEN>
<TOKEN id="token-50-110" pos="word" morph="none" start_char="6259" end_char="6260">la</TOKEN>
<TOKEN id="token-50-111" pos="word" morph="none" start_char="6262" end_char="6272">circulación</TOKEN>
<TOKEN id="token-50-112" pos="word" morph="none" start_char="6274" end_char="6276">del</TOKEN>
<TOKEN id="token-50-113" pos="word" morph="none" start_char="6278" end_char="6282">virus</TOKEN>
<TOKEN id="token-50-114" pos="word" morph="none" start_char="6284" end_char="6292">alrededor</TOKEN>
<TOKEN id="token-50-115" pos="word" morph="none" start_char="6294" end_char="6295">de</TOKEN>
<TOKEN id="token-50-116" pos="word" morph="none" start_char="6297" end_char="6299">una</TOKEN>
<TOKEN id="token-50-117" pos="word" morph="none" start_char="6301" end_char="6305">misma</TOKEN>
<TOKEN id="token-50-118" pos="word" morph="none" start_char="6307" end_char="6313">persona</TOKEN>
<TOKEN id="token-50-119" pos="punct" morph="none" start_char="6314" end_char="6314">,</TOKEN>
<TOKEN id="token-50-120" pos="word" morph="none" start_char="6316" end_char="6321">aunque</TOKEN>
<TOKEN id="token-50-121" pos="word" morph="none" start_char="6323" end_char="6324">ya</TOKEN>
<TOKEN id="token-50-122" pos="word" morph="none" start_char="6326" end_char="6329">esté</TOKEN>
<TOKEN id="token-50-123" pos="word" morph="none" start_char="6331" end_char="6339">infectada</TOKEN>
<TOKEN id="token-50-124" pos="punct" morph="none" start_char="6340" end_char="6340">,</TOKEN>
<TOKEN id="token-50-125" pos="word" morph="none" start_char="6342" end_char="6347">agrava</TOKEN>
<TOKEN id="token-50-126" pos="word" morph="none" start_char="6349" end_char="6350">su</TOKEN>
<TOKEN id="token-50-127" pos="unknown" morph="none" start_char="6352" end_char="6363">patología.Es</TOKEN>
<TOKEN id="token-50-128" pos="word" morph="none" start_char="6365" end_char="6367">una</TOKEN>
<TOKEN id="token-50-129" pos="word" morph="none" start_char="6369" end_char="6377">hipótesis</TOKEN>
<TOKEN id="token-50-130" pos="punct" morph="none" start_char="6378" end_char="6378">,</TOKEN>
<TOKEN id="token-50-131" pos="word" morph="none" start_char="6380" end_char="6383">pero</TOKEN>
<TOKEN id="token-50-132" pos="word" morph="none" start_char="6385" end_char="6391">creemos</TOKEN>
<TOKEN id="token-50-133" pos="word" morph="none" start_char="6393" end_char="6395">que</TOKEN>
<TOKEN id="token-50-134" pos="word" morph="none" start_char="6397" end_char="6402">cuando</TOKEN>
<TOKEN id="token-50-135" pos="word" morph="none" start_char="6404" end_char="6405">el</TOKEN>
<TOKEN id="token-50-136" pos="word" morph="none" start_char="6407" end_char="6411">virus</TOKEN>
<TOKEN id="token-50-137" pos="word" morph="none" start_char="6413" end_char="6419">circula</TOKEN>
<TOKEN id="token-50-138" pos="word" morph="none" start_char="6421" end_char="6426">muchas</TOKEN>
<TOKEN id="token-50-139" pos="word" morph="none" start_char="6428" end_char="6432">veces</TOKEN>
<TOKEN id="token-50-140" pos="word" morph="none" start_char="6434" end_char="6436">por</TOKEN>
<TOKEN id="token-50-141" pos="word" morph="none" start_char="6438" end_char="6439">el</TOKEN>
<TOKEN id="token-50-142" pos="word" morph="none" start_char="6441" end_char="6445">mismo</TOKEN>
<TOKEN id="token-50-143" pos="word" morph="none" start_char="6447" end_char="6454">ambiente</TOKEN>
<TOKEN id="token-50-144" pos="punct" morph="none" start_char="6455" end_char="6455">,</TOKEN>
<TOKEN id="token-50-145" pos="word" morph="none" start_char="6457" end_char="6464">potencia</TOKEN>
<TOKEN id="token-50-146" pos="word" morph="none" start_char="6466" end_char="6467">su</TOKEN>
<TOKEN id="token-50-147" pos="unknown" morph="none" start_char="6469" end_char="6477">acción.El</TOKEN>
<TOKEN id="token-50-148" pos="word" morph="none" start_char="6479" end_char="6483">virus</TOKEN>
<TOKEN id="token-50-149" pos="word" morph="none" start_char="6485" end_char="6486">es</TOKEN>
<TOKEN id="token-50-150" pos="word" morph="none" start_char="6488" end_char="6490">muy</TOKEN>
<TOKEN id="token-50-151" pos="word" morph="none" start_char="6492" end_char="6500">peligroso</TOKEN>
<TOKEN id="token-50-152" pos="word" morph="none" start_char="6502" end_char="6503">en</TOKEN>
<TOKEN id="token-50-153" pos="word" morph="none" start_char="6505" end_char="6513">ambientes</TOKEN>
<TOKEN id="token-50-154" pos="word" morph="none" start_char="6515" end_char="6522">cerrados</TOKEN>
<TOKEN id="token-50-155" pos="word" morph="none" start_char="6524" end_char="6528">donde</TOKEN>
<TOKEN id="token-50-156" pos="word" morph="none" start_char="6530" end_char="6532">hay</TOKEN>
<TOKEN id="token-50-157" pos="word" morph="none" start_char="6534" end_char="6539">muchas</TOKEN>
<TOKEN id="token-50-158" pos="unknown" morph="none" start_char="6541" end_char="6552">personas.Aún</TOKEN>
<TOKEN id="token-50-159" pos="word" morph="none" start_char="6554" end_char="6555">no</TOKEN>
<TOKEN id="token-50-160" pos="word" morph="none" start_char="6557" end_char="6560">está</TOKEN>
<TOKEN id="token-50-161" pos="word" morph="none" start_char="6562" end_char="6564">del</TOKEN>
<TOKEN id="token-50-162" pos="word" morph="none" start_char="6566" end_char="6569">todo</TOKEN>
<TOKEN id="token-50-163" pos="word" morph="none" start_char="6571" end_char="6575">claro</TOKEN>
<TOKEN id="token-50-164" pos="punct" morph="none" start_char="6576" end_char="6576">,</TOKEN>
<TOKEN id="token-50-165" pos="word" morph="none" start_char="6578" end_char="6581">pero</TOKEN>
<TOKEN id="token-50-166" pos="word" morph="none" start_char="6583" end_char="6588">parece</TOKEN>
<TOKEN id="token-50-167" pos="word" morph="none" start_char="6590" end_char="6592">que</TOKEN>
<TOKEN id="token-50-168" pos="word" morph="none" start_char="6594" end_char="6599">aunque</TOKEN>
<TOKEN id="token-50-169" pos="word" morph="none" start_char="6601" end_char="6602">no</TOKEN>
<TOKEN id="token-50-170" pos="word" morph="none" start_char="6604" end_char="6608">estés</TOKEN>
<TOKEN id="token-50-171" pos="word" morph="none" start_char="6610" end_char="6616">delante</TOKEN>
<TOKEN id="token-50-172" pos="word" morph="none" start_char="6618" end_char="6619">de</TOKEN>
<TOKEN id="token-50-173" pos="word" morph="none" start_char="6621" end_char="6622">la</TOKEN>
<TOKEN id="token-50-174" pos="word" morph="none" start_char="6624" end_char="6630">persona</TOKEN>
<TOKEN id="token-50-175" pos="word" morph="none" start_char="6632" end_char="6640">infectada</TOKEN>
<TOKEN id="token-50-176" pos="punct" morph="none" start_char="6641" end_char="6641">,</TOKEN>
<TOKEN id="token-50-177" pos="word" morph="none" start_char="6643" end_char="6648">aunque</TOKEN>
<TOKEN id="token-50-178" pos="word" morph="none" start_char="6650" end_char="6651">no</TOKEN>
<TOKEN id="token-50-179" pos="word" morph="none" start_char="6653" end_char="6654">la</TOKEN>
<TOKEN id="token-50-180" pos="word" morph="none" start_char="6656" end_char="6659">veas</TOKEN>
<TOKEN id="token-50-181" pos="punct" morph="none" start_char="6660" end_char="6660">,</TOKEN>
<TOKEN id="token-50-182" pos="word" morph="none" start_char="6662" end_char="6663">te</TOKEN>
<TOKEN id="token-50-183" pos="word" morph="none" start_char="6665" end_char="6670">puedes</TOKEN>
<TOKEN id="token-50-184" pos="word" morph="none" start_char="6672" end_char="6677">llegar</TOKEN>
<TOKEN id="token-50-185" pos="word" morph="none" start_char="6679" end_char="6679">a</TOKEN>
<TOKEN id="token-50-186" pos="word" morph="none" start_char="6681" end_char="6688">infectar</TOKEN>
<TOKEN id="token-50-187" pos="word" morph="none" start_char="6690" end_char="6691">en</TOKEN>
<TOKEN id="token-50-188" pos="word" morph="none" start_char="6693" end_char="6701">ambientes</TOKEN>
<TOKEN id="token-50-189" pos="word" morph="none" start_char="6703" end_char="6710">cerrados</TOKEN>
<TOKEN id="token-50-190" pos="punct" morph="none" start_char="6711" end_char="6711">.</TOKEN>
</SEG>
<SEG id="segment-51" start_char="6713" end_char="6902">
<ORIGINAL_TEXT>"Lo que casaría perfectamente con la tesis que vengo manteniendo afirmando que serían las partículas en suspensión en el aire, que acarrearían el COVID-19, agentes activos de su transmisión.</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="punct" morph="none" start_char="6713" end_char="6713">"</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="6714" end_char="6715">Lo</TOKEN>
<TOKEN id="token-51-2" pos="word" morph="none" start_char="6717" end_char="6719">que</TOKEN>
<TOKEN id="token-51-3" pos="word" morph="none" start_char="6721" end_char="6727">casaría</TOKEN>
<TOKEN id="token-51-4" pos="word" morph="none" start_char="6729" end_char="6741">perfectamente</TOKEN>
<TOKEN id="token-51-5" pos="word" morph="none" start_char="6743" end_char="6745">con</TOKEN>
<TOKEN id="token-51-6" pos="word" morph="none" start_char="6747" end_char="6748">la</TOKEN>
<TOKEN id="token-51-7" pos="word" morph="none" start_char="6750" end_char="6754">tesis</TOKEN>
<TOKEN id="token-51-8" pos="word" morph="none" start_char="6756" end_char="6758">que</TOKEN>
<TOKEN id="token-51-9" pos="word" morph="none" start_char="6760" end_char="6764">vengo</TOKEN>
<TOKEN id="token-51-10" pos="word" morph="none" start_char="6766" end_char="6776">manteniendo</TOKEN>
<TOKEN id="token-51-11" pos="word" morph="none" start_char="6778" end_char="6786">afirmando</TOKEN>
<TOKEN id="token-51-12" pos="word" morph="none" start_char="6788" end_char="6790">que</TOKEN>
<TOKEN id="token-51-13" pos="word" morph="none" start_char="6792" end_char="6797">serían</TOKEN>
<TOKEN id="token-51-14" pos="word" morph="none" start_char="6799" end_char="6801">las</TOKEN>
<TOKEN id="token-51-15" pos="word" morph="none" start_char="6803" end_char="6812">partículas</TOKEN>
<TOKEN id="token-51-16" pos="word" morph="none" start_char="6814" end_char="6815">en</TOKEN>
<TOKEN id="token-51-17" pos="word" morph="none" start_char="6817" end_char="6826">suspensión</TOKEN>
<TOKEN id="token-51-18" pos="word" morph="none" start_char="6828" end_char="6829">en</TOKEN>
<TOKEN id="token-51-19" pos="word" morph="none" start_char="6831" end_char="6832">el</TOKEN>
<TOKEN id="token-51-20" pos="word" morph="none" start_char="6834" end_char="6837">aire</TOKEN>
<TOKEN id="token-51-21" pos="punct" morph="none" start_char="6838" end_char="6838">,</TOKEN>
<TOKEN id="token-51-22" pos="word" morph="none" start_char="6840" end_char="6842">que</TOKEN>
<TOKEN id="token-51-23" pos="word" morph="none" start_char="6844" end_char="6854">acarrearían</TOKEN>
<TOKEN id="token-51-24" pos="word" morph="none" start_char="6856" end_char="6857">el</TOKEN>
<TOKEN id="token-51-25" pos="unknown" morph="none" start_char="6859" end_char="6866">COVID-19</TOKEN>
<TOKEN id="token-51-26" pos="punct" morph="none" start_char="6867" end_char="6867">,</TOKEN>
<TOKEN id="token-51-27" pos="word" morph="none" start_char="6869" end_char="6875">agentes</TOKEN>
<TOKEN id="token-51-28" pos="word" morph="none" start_char="6877" end_char="6883">activos</TOKEN>
<TOKEN id="token-51-29" pos="word" morph="none" start_char="6885" end_char="6886">de</TOKEN>
<TOKEN id="token-51-30" pos="word" morph="none" start_char="6888" end_char="6889">su</TOKEN>
<TOKEN id="token-51-31" pos="word" morph="none" start_char="6891" end_char="6901">transmisión</TOKEN>
<TOKEN id="token-51-32" pos="punct" morph="none" start_char="6902" end_char="6902">.</TOKEN>
</SEG>
<SEG id="segment-52" start_char="6904" end_char="6958">
<ORIGINAL_TEXT>Responder Denunciar comentario Ocultar 2 Respuestas 0 2</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="6904" end_char="6912">Responder</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="6914" end_char="6922">Denunciar</TOKEN>
<TOKEN id="token-52-2" pos="word" morph="none" start_char="6924" end_char="6933">comentario</TOKEN>
<TOKEN id="token-52-3" pos="word" morph="none" start_char="6935" end_char="6941">Ocultar</TOKEN>
<TOKEN id="token-52-4" pos="word" morph="none" start_char="6943" end_char="6943">2</TOKEN>
<TOKEN id="token-52-5" pos="word" morph="none" start_char="6945" end_char="6954">Respuestas</TOKEN>
<TOKEN id="token-52-6" pos="word" morph="none" start_char="6956" end_char="6956">0</TOKEN>
<TOKEN id="token-52-7" pos="word" morph="none" start_char="6958" end_char="6958">2</TOKEN>
</SEG>
<SEG id="segment-53" start_char="6961" end_char="6967">
<ORIGINAL_TEXT>Cambris</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="word" morph="none" start_char="6961" end_char="6967">Cambris</TOKEN>
</SEG>
<SEG id="segment-54" start_char="6970" end_char="6983">
<ORIGINAL_TEXT>09/04/20 14:51</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="unknown" morph="none" start_char="6970" end_char="6977">09/04/20</TOKEN>
<TOKEN id="token-54-1" pos="unknown" morph="none" start_char="6979" end_char="6983">14:51</TOKEN>
</SEG>
<SEG id="segment-55" start_char="6986" end_char="7002">
<ORIGINAL_TEXT>Estoy de acuerdo.</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="word" morph="none" start_char="6986" end_char="6990">Estoy</TOKEN>
<TOKEN id="token-55-1" pos="word" morph="none" start_char="6992" end_char="6993">de</TOKEN>
<TOKEN id="token-55-2" pos="word" morph="none" start_char="6995" end_char="7001">acuerdo</TOKEN>
<TOKEN id="token-55-3" pos="punct" morph="none" start_char="7002" end_char="7002">.</TOKEN>
</SEG>
<SEG id="segment-56" start_char="7004" end_char="7113">
<ORIGINAL_TEXT>Y si las gotas de Flugge permanecen en el aire y la cola del supermercado la hacemos sin mascarilla ¿qué pasa?</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="7004" end_char="7004">Y</TOKEN>
<TOKEN id="token-56-1" pos="word" morph="none" start_char="7006" end_char="7007">si</TOKEN>
<TOKEN id="token-56-2" pos="word" morph="none" start_char="7009" end_char="7011">las</TOKEN>
<TOKEN id="token-56-3" pos="word" morph="none" start_char="7013" end_char="7017">gotas</TOKEN>
<TOKEN id="token-56-4" pos="word" morph="none" start_char="7019" end_char="7020">de</TOKEN>
<TOKEN id="token-56-5" pos="word" morph="none" start_char="7022" end_char="7027">Flugge</TOKEN>
<TOKEN id="token-56-6" pos="word" morph="none" start_char="7029" end_char="7038">permanecen</TOKEN>
<TOKEN id="token-56-7" pos="word" morph="none" start_char="7040" end_char="7041">en</TOKEN>
<TOKEN id="token-56-8" pos="word" morph="none" start_char="7043" end_char="7044">el</TOKEN>
<TOKEN id="token-56-9" pos="word" morph="none" start_char="7046" end_char="7049">aire</TOKEN>
<TOKEN id="token-56-10" pos="word" morph="none" start_char="7051" end_char="7051">y</TOKEN>
<TOKEN id="token-56-11" pos="word" morph="none" start_char="7053" end_char="7054">la</TOKEN>
<TOKEN id="token-56-12" pos="word" morph="none" start_char="7056" end_char="7059">cola</TOKEN>
<TOKEN id="token-56-13" pos="word" morph="none" start_char="7061" end_char="7063">del</TOKEN>
<TOKEN id="token-56-14" pos="word" morph="none" start_char="7065" end_char="7076">supermercado</TOKEN>
<TOKEN id="token-56-15" pos="word" morph="none" start_char="7078" end_char="7079">la</TOKEN>
<TOKEN id="token-56-16" pos="word" morph="none" start_char="7081" end_char="7087">hacemos</TOKEN>
<TOKEN id="token-56-17" pos="word" morph="none" start_char="7089" end_char="7091">sin</TOKEN>
<TOKEN id="token-56-18" pos="word" morph="none" start_char="7093" end_char="7102">mascarilla</TOKEN>
<TOKEN id="token-56-19" pos="punct" morph="none" start_char="7104" end_char="7104">¿</TOKEN>
<TOKEN id="token-56-20" pos="word" morph="none" start_char="7105" end_char="7107">qué</TOKEN>
<TOKEN id="token-56-21" pos="word" morph="none" start_char="7109" end_char="7112">pasa</TOKEN>
<TOKEN id="token-56-22" pos="punct" morph="none" start_char="7113" end_char="7113">?</TOKEN>
</SEG>
<SEG id="segment-57" start_char="7115" end_char="7243">
<ORIGINAL_TEXT>Qué quien venga detrás, si tampoco lleva mascarilla... será otro contagio Responder Denunciar comentario Ocultar 1 Respuestas 0 0</ORIGINAL_TEXT>
<TOKEN id="token-57-0" pos="word" morph="none" start_char="7115" end_char="7117">Qué</TOKEN>
<TOKEN id="token-57-1" pos="word" morph="none" start_char="7119" end_char="7123">quien</TOKEN>
<TOKEN id="token-57-2" pos="word" morph="none" start_char="7125" end_char="7129">venga</TOKEN>
<TOKEN id="token-57-3" pos="word" morph="none" start_char="7131" end_char="7136">detrás</TOKEN>
<TOKEN id="token-57-4" pos="punct" morph="none" start_char="7137" end_char="7137">,</TOKEN>
<TOKEN id="token-57-5" pos="word" morph="none" start_char="7139" end_char="7140">si</TOKEN>
<TOKEN id="token-57-6" pos="word" morph="none" start_char="7142" end_char="7148">tampoco</TOKEN>
<TOKEN id="token-57-7" pos="word" morph="none" start_char="7150" end_char="7154">lleva</TOKEN>
<TOKEN id="token-57-8" pos="word" morph="none" start_char="7156" end_char="7165">mascarilla</TOKEN>
<TOKEN id="token-57-9" pos="punct" morph="none" start_char="7166" end_char="7168">...</TOKEN>
<TOKEN id="token-57-10" pos="word" morph="none" start_char="7170" end_char="7173">será</TOKEN>
<TOKEN id="token-57-11" pos="word" morph="none" start_char="7175" end_char="7178">otro</TOKEN>
<TOKEN id="token-57-12" pos="word" morph="none" start_char="7180" end_char="7187">contagio</TOKEN>
<TOKEN id="token-57-13" pos="word" morph="none" start_char="7189" end_char="7197">Responder</TOKEN>
<TOKEN id="token-57-14" pos="word" morph="none" start_char="7199" end_char="7207">Denunciar</TOKEN>
<TOKEN id="token-57-15" pos="word" morph="none" start_char="7209" end_char="7218">comentario</TOKEN>
<TOKEN id="token-57-16" pos="word" morph="none" start_char="7220" end_char="7226">Ocultar</TOKEN>
<TOKEN id="token-57-17" pos="word" morph="none" start_char="7228" end_char="7228">1</TOKEN>
<TOKEN id="token-57-18" pos="word" morph="none" start_char="7230" end_char="7239">Respuestas</TOKEN>
<TOKEN id="token-57-19" pos="word" morph="none" start_char="7241" end_char="7241">0</TOKEN>
<TOKEN id="token-57-20" pos="word" morph="none" start_char="7243" end_char="7243">0</TOKEN>
</SEG>
<SEG id="segment-58" start_char="7246" end_char="7252">
<ORIGINAL_TEXT>Macrons</ORIGINAL_TEXT>
<TOKEN id="token-58-0" pos="word" morph="none" start_char="7246" end_char="7252">Macrons</TOKEN>
</SEG>
<SEG id="segment-59" start_char="7255" end_char="7268">
<ORIGINAL_TEXT>09/04/20 16:28</ORIGINAL_TEXT>
<TOKEN id="token-59-0" pos="unknown" morph="none" start_char="7255" end_char="7262">09/04/20</TOKEN>
<TOKEN id="token-59-1" pos="unknown" morph="none" start_char="7264" end_char="7268">16:28</TOKEN>
</SEG>
<SEG id="segment-60" start_char="7271" end_char="7316">
<ORIGINAL_TEXT>Desgraciadamente las cosas no son tan simples.</ORIGINAL_TEXT>
<TOKEN id="token-60-0" pos="word" morph="none" start_char="7271" end_char="7286">Desgraciadamente</TOKEN>
<TOKEN id="token-60-1" pos="word" morph="none" start_char="7288" end_char="7290">las</TOKEN>
<TOKEN id="token-60-2" pos="word" morph="none" start_char="7292" end_char="7296">cosas</TOKEN>
<TOKEN id="token-60-3" pos="word" morph="none" start_char="7298" end_char="7299">no</TOKEN>
<TOKEN id="token-60-4" pos="word" morph="none" start_char="7301" end_char="7303">son</TOKEN>
<TOKEN id="token-60-5" pos="word" morph="none" start_char="7305" end_char="7307">tan</TOKEN>
<TOKEN id="token-60-6" pos="word" morph="none" start_char="7309" end_char="7315">simples</TOKEN>
<TOKEN id="token-60-7" pos="punct" morph="none" start_char="7316" end_char="7316">.</TOKEN>
</SEG>
<SEG id="segment-61" start_char="7318" end_char="8034">
<ORIGINAL_TEXT>Dejando sentada la utilidad de lasa mascarillas, incluso las artesanales, la eficacia nunca será del 100%.Se deben usar, porque con toda probabilidad reducen el número de infecciones, pero dado que habría coronavirus que escaparían, en ambientes cerrados y pasadas unas horas desde una desinfección efectiva, se seguirían produciendo -aunque en menor número- contagios.Y ahí están las cifras de profesionales muy protegidos (pelo, gafas, mascarilla y cuerpo) que todavía resultan infectados.La razón estaría en que el COVID-19 de tamaño 0,000130 milímetros, podría viajar en partículas en el rango 0,005-0009 milímetros, que no son interceptados ni siquiera por las FFP3, que solo alcanzan hasta los 0,006 milímetros.</ORIGINAL_TEXT>
<TOKEN id="token-61-0" pos="word" morph="none" start_char="7318" end_char="7324">Dejando</TOKEN>
<TOKEN id="token-61-1" pos="word" morph="none" start_char="7326" end_char="7332">sentada</TOKEN>
<TOKEN id="token-61-2" pos="word" morph="none" start_char="7334" end_char="7335">la</TOKEN>
<TOKEN id="token-61-3" pos="word" morph="none" start_char="7337" end_char="7344">utilidad</TOKEN>
<TOKEN id="token-61-4" pos="word" morph="none" start_char="7346" end_char="7347">de</TOKEN>
<TOKEN id="token-61-5" pos="word" morph="none" start_char="7349" end_char="7352">lasa</TOKEN>
<TOKEN id="token-61-6" pos="word" morph="none" start_char="7354" end_char="7364">mascarillas</TOKEN>
<TOKEN id="token-61-7" pos="punct" morph="none" start_char="7365" end_char="7365">,</TOKEN>
<TOKEN id="token-61-8" pos="word" morph="none" start_char="7367" end_char="7373">incluso</TOKEN>
<TOKEN id="token-61-9" pos="word" morph="none" start_char="7375" end_char="7377">las</TOKEN>
<TOKEN id="token-61-10" pos="word" morph="none" start_char="7379" end_char="7389">artesanales</TOKEN>
<TOKEN id="token-61-11" pos="punct" morph="none" start_char="7390" end_char="7390">,</TOKEN>
<TOKEN id="token-61-12" pos="word" morph="none" start_char="7392" end_char="7393">la</TOKEN>
<TOKEN id="token-61-13" pos="word" morph="none" start_char="7395" end_char="7402">eficacia</TOKEN>
<TOKEN id="token-61-14" pos="word" morph="none" start_char="7404" end_char="7408">nunca</TOKEN>
<TOKEN id="token-61-15" pos="word" morph="none" start_char="7410" end_char="7413">será</TOKEN>
<TOKEN id="token-61-16" pos="word" morph="none" start_char="7415" end_char="7417">del</TOKEN>
<TOKEN id="token-61-17" pos="unknown" morph="none" start_char="7419" end_char="7425">100%.Se</TOKEN>
<TOKEN id="token-61-18" pos="word" morph="none" start_char="7427" end_char="7431">deben</TOKEN>
<TOKEN id="token-61-19" pos="word" morph="none" start_char="7433" end_char="7436">usar</TOKEN>
<TOKEN id="token-61-20" pos="punct" morph="none" start_char="7437" end_char="7437">,</TOKEN>
<TOKEN id="token-61-21" pos="word" morph="none" start_char="7439" end_char="7444">porque</TOKEN>
<TOKEN id="token-61-22" pos="word" morph="none" start_char="7446" end_char="7448">con</TOKEN>
<TOKEN id="token-61-23" pos="word" morph="none" start_char="7450" end_char="7453">toda</TOKEN>
<TOKEN id="token-61-24" pos="word" morph="none" start_char="7455" end_char="7466">probabilidad</TOKEN>
<TOKEN id="token-61-25" pos="word" morph="none" start_char="7468" end_char="7474">reducen</TOKEN>
<TOKEN id="token-61-26" pos="word" morph="none" start_char="7476" end_char="7477">el</TOKEN>
<TOKEN id="token-61-27" pos="word" morph="none" start_char="7479" end_char="7484">número</TOKEN>
<TOKEN id="token-61-28" pos="word" morph="none" start_char="7486" end_char="7487">de</TOKEN>
<TOKEN id="token-61-29" pos="word" morph="none" start_char="7489" end_char="7499">infecciones</TOKEN>
<TOKEN id="token-61-30" pos="punct" morph="none" start_char="7500" end_char="7500">,</TOKEN>
<TOKEN id="token-61-31" pos="word" morph="none" start_char="7502" end_char="7505">pero</TOKEN>
<TOKEN id="token-61-32" pos="word" morph="none" start_char="7507" end_char="7510">dado</TOKEN>
<TOKEN id="token-61-33" pos="word" morph="none" start_char="7512" end_char="7514">que</TOKEN>
<TOKEN id="token-61-34" pos="word" morph="none" start_char="7516" end_char="7521">habría</TOKEN>
<TOKEN id="token-61-35" pos="word" morph="none" start_char="7523" end_char="7533">coronavirus</TOKEN>
<TOKEN id="token-61-36" pos="word" morph="none" start_char="7535" end_char="7537">que</TOKEN>
<TOKEN id="token-61-37" pos="word" morph="none" start_char="7539" end_char="7548">escaparían</TOKEN>
<TOKEN id="token-61-38" pos="punct" morph="none" start_char="7549" end_char="7549">,</TOKEN>
<TOKEN id="token-61-39" pos="word" morph="none" start_char="7551" end_char="7552">en</TOKEN>
<TOKEN id="token-61-40" pos="word" morph="none" start_char="7554" end_char="7562">ambientes</TOKEN>
<TOKEN id="token-61-41" pos="word" morph="none" start_char="7564" end_char="7571">cerrados</TOKEN>
<TOKEN id="token-61-42" pos="word" morph="none" start_char="7573" end_char="7573">y</TOKEN>
<TOKEN id="token-61-43" pos="word" morph="none" start_char="7575" end_char="7581">pasadas</TOKEN>
<TOKEN id="token-61-44" pos="word" morph="none" start_char="7583" end_char="7586">unas</TOKEN>
<TOKEN id="token-61-45" pos="word" morph="none" start_char="7588" end_char="7592">horas</TOKEN>
<TOKEN id="token-61-46" pos="word" morph="none" start_char="7594" end_char="7598">desde</TOKEN>
<TOKEN id="token-61-47" pos="word" morph="none" start_char="7600" end_char="7602">una</TOKEN>
<TOKEN id="token-61-48" pos="word" morph="none" start_char="7604" end_char="7615">desinfección</TOKEN>
<TOKEN id="token-61-49" pos="word" morph="none" start_char="7617" end_char="7624">efectiva</TOKEN>
<TOKEN id="token-61-50" pos="punct" morph="none" start_char="7625" end_char="7625">,</TOKEN>
<TOKEN id="token-61-51" pos="word" morph="none" start_char="7627" end_char="7628">se</TOKEN>
<TOKEN id="token-61-52" pos="word" morph="none" start_char="7630" end_char="7638">seguirían</TOKEN>
<TOKEN id="token-61-53" pos="word" morph="none" start_char="7640" end_char="7650">produciendo</TOKEN>
<TOKEN id="token-61-54" pos="punct" morph="none" start_char="7652" end_char="7652">-</TOKEN>
<TOKEN id="token-61-55" pos="word" morph="none" start_char="7653" end_char="7658">aunque</TOKEN>
<TOKEN id="token-61-56" pos="word" morph="none" start_char="7660" end_char="7661">en</TOKEN>
<TOKEN id="token-61-57" pos="word" morph="none" start_char="7663" end_char="7667">menor</TOKEN>
<TOKEN id="token-61-58" pos="word" morph="none" start_char="7669" end_char="7674">número</TOKEN>
<TOKEN id="token-61-59" pos="punct" morph="none" start_char="7675" end_char="7675">-</TOKEN>
<TOKEN id="token-61-60" pos="unknown" morph="none" start_char="7677" end_char="7687">contagios.Y</TOKEN>
<TOKEN id="token-61-61" pos="word" morph="none" start_char="7689" end_char="7691">ahí</TOKEN>
<TOKEN id="token-61-62" pos="word" morph="none" start_char="7693" end_char="7697">están</TOKEN>
<TOKEN id="token-61-63" pos="word" morph="none" start_char="7699" end_char="7701">las</TOKEN>
<TOKEN id="token-61-64" pos="word" morph="none" start_char="7703" end_char="7708">cifras</TOKEN>
<TOKEN id="token-61-65" pos="word" morph="none" start_char="7710" end_char="7711">de</TOKEN>
<TOKEN id="token-61-66" pos="word" morph="none" start_char="7713" end_char="7725">profesionales</TOKEN>
<TOKEN id="token-61-67" pos="word" morph="none" start_char="7727" end_char="7729">muy</TOKEN>
<TOKEN id="token-61-68" pos="word" morph="none" start_char="7731" end_char="7740">protegidos</TOKEN>
<TOKEN id="token-61-69" pos="punct" morph="none" start_char="7742" end_char="7742">(</TOKEN>
<TOKEN id="token-61-70" pos="word" morph="none" start_char="7743" end_char="7746">pelo</TOKEN>
<TOKEN id="token-61-71" pos="punct" morph="none" start_char="7747" end_char="7747">,</TOKEN>
<TOKEN id="token-61-72" pos="word" morph="none" start_char="7749" end_char="7753">gafas</TOKEN>
<TOKEN id="token-61-73" pos="punct" morph="none" start_char="7754" end_char="7754">,</TOKEN>
<TOKEN id="token-61-74" pos="word" morph="none" start_char="7756" end_char="7765">mascarilla</TOKEN>
<TOKEN id="token-61-75" pos="word" morph="none" start_char="7767" end_char="7767">y</TOKEN>
<TOKEN id="token-61-76" pos="word" morph="none" start_char="7769" end_char="7774">cuerpo</TOKEN>
<TOKEN id="token-61-77" pos="punct" morph="none" start_char="7775" end_char="7775">)</TOKEN>
<TOKEN id="token-61-78" pos="word" morph="none" start_char="7777" end_char="7779">que</TOKEN>
<TOKEN id="token-61-79" pos="word" morph="none" start_char="7781" end_char="7787">todavía</TOKEN>
<TOKEN id="token-61-80" pos="word" morph="none" start_char="7789" end_char="7796">resultan</TOKEN>
<TOKEN id="token-61-81" pos="unknown" morph="none" start_char="7798" end_char="7810">infectados.La</TOKEN>
<TOKEN id="token-61-82" pos="word" morph="none" start_char="7812" end_char="7816">razón</TOKEN>
<TOKEN id="token-61-83" pos="word" morph="none" start_char="7818" end_char="7824">estaría</TOKEN>
<TOKEN id="token-61-84" pos="word" morph="none" start_char="7826" end_char="7827">en</TOKEN>
<TOKEN id="token-61-85" pos="word" morph="none" start_char="7829" end_char="7831">que</TOKEN>
<TOKEN id="token-61-86" pos="word" morph="none" start_char="7833" end_char="7834">el</TOKEN>
<TOKEN id="token-61-87" pos="unknown" morph="none" start_char="7836" end_char="7843">COVID-19</TOKEN>
<TOKEN id="token-61-88" pos="word" morph="none" start_char="7845" end_char="7846">de</TOKEN>
<TOKEN id="token-61-89" pos="word" morph="none" start_char="7848" end_char="7853">tamaño</TOKEN>
<TOKEN id="token-61-90" pos="unknown" morph="none" start_char="7855" end_char="7862">0,000130</TOKEN>
<TOKEN id="token-61-91" pos="word" morph="none" start_char="7864" end_char="7873">milímetros</TOKEN>
<TOKEN id="token-61-92" pos="punct" morph="none" start_char="7874" end_char="7874">,</TOKEN>
<TOKEN id="token-61-93" pos="word" morph="none" start_char="7876" end_char="7881">podría</TOKEN>
<TOKEN id="token-61-94" pos="word" morph="none" start_char="7883" end_char="7888">viajar</TOKEN>
<TOKEN id="token-61-95" pos="word" morph="none" start_char="7890" end_char="7891">en</TOKEN>
<TOKEN id="token-61-96" pos="word" morph="none" start_char="7893" end_char="7902">partículas</TOKEN>
<TOKEN id="token-61-97" pos="word" morph="none" start_char="7904" end_char="7905">en</TOKEN>
<TOKEN id="token-61-98" pos="word" morph="none" start_char="7907" end_char="7908">el</TOKEN>
<TOKEN id="token-61-99" pos="word" morph="none" start_char="7910" end_char="7914">rango</TOKEN>
<TOKEN id="token-61-100" pos="unknown" morph="none" start_char="7916" end_char="7925">0,005-0009</TOKEN>
<TOKEN id="token-61-101" pos="word" morph="none" start_char="7927" end_char="7936">milímetros</TOKEN>
<TOKEN id="token-61-102" pos="punct" morph="none" start_char="7937" end_char="7937">,</TOKEN>
<TOKEN id="token-61-103" pos="word" morph="none" start_char="7939" end_char="7941">que</TOKEN>
<TOKEN id="token-61-104" pos="word" morph="none" start_char="7943" end_char="7944">no</TOKEN>
<TOKEN id="token-61-105" pos="word" morph="none" start_char="7946" end_char="7948">son</TOKEN>
<TOKEN id="token-61-106" pos="word" morph="none" start_char="7950" end_char="7962">interceptados</TOKEN>
<TOKEN id="token-61-107" pos="word" morph="none" start_char="7964" end_char="7965">ni</TOKEN>
<TOKEN id="token-61-108" pos="word" morph="none" start_char="7967" end_char="7974">siquiera</TOKEN>
<TOKEN id="token-61-109" pos="word" morph="none" start_char="7976" end_char="7978">por</TOKEN>
<TOKEN id="token-61-110" pos="word" morph="none" start_char="7980" end_char="7982">las</TOKEN>
<TOKEN id="token-61-111" pos="word" morph="none" start_char="7984" end_char="7987">FFP3</TOKEN>
<TOKEN id="token-61-112" pos="punct" morph="none" start_char="7988" end_char="7988">,</TOKEN>
<TOKEN id="token-61-113" pos="word" morph="none" start_char="7990" end_char="7992">que</TOKEN>
<TOKEN id="token-61-114" pos="word" morph="none" start_char="7994" end_char="7997">solo</TOKEN>
<TOKEN id="token-61-115" pos="word" morph="none" start_char="7999" end_char="8006">alcanzan</TOKEN>
<TOKEN id="token-61-116" pos="word" morph="none" start_char="8008" end_char="8012">hasta</TOKEN>
<TOKEN id="token-61-117" pos="word" morph="none" start_char="8014" end_char="8016">los</TOKEN>
<TOKEN id="token-61-118" pos="unknown" morph="none" start_char="8018" end_char="8022">0,006</TOKEN>
<TOKEN id="token-61-119" pos="word" morph="none" start_char="8024" end_char="8033">milímetros</TOKEN>
<TOKEN id="token-61-120" pos="punct" morph="none" start_char="8034" end_char="8034">.</TOKEN>
</SEG>
<SEG id="segment-62" start_char="8036" end_char="8305">
<ORIGINAL_TEXT>Como físico, debo atenerme a los hechos, aunque lamentablemente veo muy poco rigor rodeando el debate sobre la utilidad (que para mí, insisto, es evidente) de las mascarillas.En ausencia de inmunidad o vacuna, la única estrategia realmente efectiva, es el confinamiento.</ORIGINAL_TEXT>
<TOKEN id="token-62-0" pos="word" morph="none" start_char="8036" end_char="8039">Como</TOKEN>
<TOKEN id="token-62-1" pos="word" morph="none" start_char="8041" end_char="8046">físico</TOKEN>
<TOKEN id="token-62-2" pos="punct" morph="none" start_char="8047" end_char="8047">,</TOKEN>
<TOKEN id="token-62-3" pos="word" morph="none" start_char="8049" end_char="8052">debo</TOKEN>
<TOKEN id="token-62-4" pos="word" morph="none" start_char="8054" end_char="8061">atenerme</TOKEN>
<TOKEN id="token-62-5" pos="word" morph="none" start_char="8063" end_char="8063">a</TOKEN>
<TOKEN id="token-62-6" pos="word" morph="none" start_char="8065" end_char="8067">los</TOKEN>
<TOKEN id="token-62-7" pos="word" morph="none" start_char="8069" end_char="8074">hechos</TOKEN>
<TOKEN id="token-62-8" pos="punct" morph="none" start_char="8075" end_char="8075">,</TOKEN>
<TOKEN id="token-62-9" pos="word" morph="none" start_char="8077" end_char="8082">aunque</TOKEN>
<TOKEN id="token-62-10" pos="word" morph="none" start_char="8084" end_char="8098">lamentablemente</TOKEN>
<TOKEN id="token-62-11" pos="word" morph="none" start_char="8100" end_char="8102">veo</TOKEN>
<TOKEN id="token-62-12" pos="word" morph="none" start_char="8104" end_char="8106">muy</TOKEN>
<TOKEN id="token-62-13" pos="word" morph="none" start_char="8108" end_char="8111">poco</TOKEN>
<TOKEN id="token-62-14" pos="word" morph="none" start_char="8113" end_char="8117">rigor</TOKEN>
<TOKEN id="token-62-15" pos="word" morph="none" start_char="8119" end_char="8126">rodeando</TOKEN>
<TOKEN id="token-62-16" pos="word" morph="none" start_char="8128" end_char="8129">el</TOKEN>
<TOKEN id="token-62-17" pos="word" morph="none" start_char="8131" end_char="8136">debate</TOKEN>
<TOKEN id="token-62-18" pos="word" morph="none" start_char="8138" end_char="8142">sobre</TOKEN>
<TOKEN id="token-62-19" pos="word" morph="none" start_char="8144" end_char="8145">la</TOKEN>
<TOKEN id="token-62-20" pos="word" morph="none" start_char="8147" end_char="8154">utilidad</TOKEN>
<TOKEN id="token-62-21" pos="punct" morph="none" start_char="8156" end_char="8156">(</TOKEN>
<TOKEN id="token-62-22" pos="word" morph="none" start_char="8157" end_char="8159">que</TOKEN>
<TOKEN id="token-62-23" pos="word" morph="none" start_char="8161" end_char="8164">para</TOKEN>
<TOKEN id="token-62-24" pos="word" morph="none" start_char="8166" end_char="8167">mí</TOKEN>
<TOKEN id="token-62-25" pos="punct" morph="none" start_char="8168" end_char="8168">,</TOKEN>
<TOKEN id="token-62-26" pos="word" morph="none" start_char="8170" end_char="8176">insisto</TOKEN>
<TOKEN id="token-62-27" pos="punct" morph="none" start_char="8177" end_char="8177">,</TOKEN>
<TOKEN id="token-62-28" pos="word" morph="none" start_char="8179" end_char="8180">es</TOKEN>
<TOKEN id="token-62-29" pos="word" morph="none" start_char="8182" end_char="8189">evidente</TOKEN>
<TOKEN id="token-62-30" pos="punct" morph="none" start_char="8190" end_char="8190">)</TOKEN>
<TOKEN id="token-62-31" pos="word" morph="none" start_char="8192" end_char="8193">de</TOKEN>
<TOKEN id="token-62-32" pos="word" morph="none" start_char="8195" end_char="8197">las</TOKEN>
<TOKEN id="token-62-33" pos="unknown" morph="none" start_char="8199" end_char="8212">mascarillas.En</TOKEN>
<TOKEN id="token-62-34" pos="word" morph="none" start_char="8214" end_char="8221">ausencia</TOKEN>
<TOKEN id="token-62-35" pos="word" morph="none" start_char="8223" end_char="8224">de</TOKEN>
<TOKEN id="token-62-36" pos="word" morph="none" start_char="8226" end_char="8234">inmunidad</TOKEN>
<TOKEN id="token-62-37" pos="word" morph="none" start_char="8236" end_char="8236">o</TOKEN>
<TOKEN id="token-62-38" pos="word" morph="none" start_char="8238" end_char="8243">vacuna</TOKEN>
<TOKEN id="token-62-39" pos="punct" morph="none" start_char="8244" end_char="8244">,</TOKEN>
<TOKEN id="token-62-40" pos="word" morph="none" start_char="8246" end_char="8247">la</TOKEN>
<TOKEN id="token-62-41" pos="word" morph="none" start_char="8249" end_char="8253">única</TOKEN>
<TOKEN id="token-62-42" pos="word" morph="none" start_char="8255" end_char="8264">estrategia</TOKEN>
<TOKEN id="token-62-43" pos="word" morph="none" start_char="8266" end_char="8274">realmente</TOKEN>
<TOKEN id="token-62-44" pos="word" morph="none" start_char="8276" end_char="8283">efectiva</TOKEN>
<TOKEN id="token-62-45" pos="punct" morph="none" start_char="8284" end_char="8284">,</TOKEN>
<TOKEN id="token-62-46" pos="word" morph="none" start_char="8286" end_char="8287">es</TOKEN>
<TOKEN id="token-62-47" pos="word" morph="none" start_char="8289" end_char="8290">el</TOKEN>
<TOKEN id="token-62-48" pos="word" morph="none" start_char="8292" end_char="8304">confinamiento</TOKEN>
<TOKEN id="token-62-49" pos="punct" morph="none" start_char="8305" end_char="8305">.</TOKEN>
</SEG>
<SEG id="segment-63" start_char="8307" end_char="8340">
<ORIGINAL_TEXT>Responder Denunciar comentario 0 2</ORIGINAL_TEXT>
<TOKEN id="token-63-0" pos="word" morph="none" start_char="8307" end_char="8315">Responder</TOKEN>
<TOKEN id="token-63-1" pos="word" morph="none" start_char="8317" end_char="8325">Denunciar</TOKEN>
<TOKEN id="token-63-2" pos="word" morph="none" start_char="8327" end_char="8336">comentario</TOKEN>
<TOKEN id="token-63-3" pos="word" morph="none" start_char="8338" end_char="8338">0</TOKEN>
<TOKEN id="token-63-4" pos="word" morph="none" start_char="8340" end_char="8340">2</TOKEN>
</SEG>
<SEG id="segment-64" start_char="8344" end_char="8402">
<ORIGINAL_TEXT>La ansiedad del confinamiento y la necesidad de decir algo.</ORIGINAL_TEXT>
<TOKEN id="token-64-0" pos="word" morph="none" start_char="8344" end_char="8345">La</TOKEN>
<TOKEN id="token-64-1" pos="word" morph="none" start_char="8347" end_char="8354">ansiedad</TOKEN>
<TOKEN id="token-64-2" pos="word" morph="none" start_char="8356" end_char="8358">del</TOKEN>
<TOKEN id="token-64-3" pos="word" morph="none" start_char="8360" end_char="8372">confinamiento</TOKEN>
<TOKEN id="token-64-4" pos="word" morph="none" start_char="8374" end_char="8374">y</TOKEN>
<TOKEN id="token-64-5" pos="word" morph="none" start_char="8376" end_char="8377">la</TOKEN>
<TOKEN id="token-64-6" pos="word" morph="none" start_char="8379" end_char="8387">necesidad</TOKEN>
<TOKEN id="token-64-7" pos="word" morph="none" start_char="8389" end_char="8390">de</TOKEN>
<TOKEN id="token-64-8" pos="word" morph="none" start_char="8392" end_char="8396">decir</TOKEN>
<TOKEN id="token-64-9" pos="word" morph="none" start_char="8398" end_char="8401">algo</TOKEN>
<TOKEN id="token-64-10" pos="punct" morph="none" start_char="8402" end_char="8402">.</TOKEN>
</SEG>
<SEG id="segment-65" start_char="8404" end_char="8480">
<ORIGINAL_TEXT>Todavía queda hasta el 25 de abril para definir si llevamos mascarillas o no.</ORIGINAL_TEXT>
<TOKEN id="token-65-0" pos="word" morph="none" start_char="8404" end_char="8410">Todavía</TOKEN>
<TOKEN id="token-65-1" pos="word" morph="none" start_char="8412" end_char="8416">queda</TOKEN>
<TOKEN id="token-65-2" pos="word" morph="none" start_char="8418" end_char="8422">hasta</TOKEN>
<TOKEN id="token-65-3" pos="word" morph="none" start_char="8424" end_char="8425">el</TOKEN>
<TOKEN id="token-65-4" pos="word" morph="none" start_char="8427" end_char="8428">25</TOKEN>
<TOKEN id="token-65-5" pos="word" morph="none" start_char="8430" end_char="8431">de</TOKEN>
<TOKEN id="token-65-6" pos="word" morph="none" start_char="8433" end_char="8437">abril</TOKEN>
<TOKEN id="token-65-7" pos="word" morph="none" start_char="8439" end_char="8442">para</TOKEN>
<TOKEN id="token-65-8" pos="word" morph="none" start_char="8444" end_char="8450">definir</TOKEN>
<TOKEN id="token-65-9" pos="word" morph="none" start_char="8452" end_char="8453">si</TOKEN>
<TOKEN id="token-65-10" pos="word" morph="none" start_char="8455" end_char="8462">llevamos</TOKEN>
<TOKEN id="token-65-11" pos="word" morph="none" start_char="8464" end_char="8474">mascarillas</TOKEN>
<TOKEN id="token-65-12" pos="word" morph="none" start_char="8476" end_char="8476">o</TOKEN>
<TOKEN id="token-65-13" pos="word" morph="none" start_char="8478" end_char="8479">no</TOKEN>
<TOKEN id="token-65-14" pos="punct" morph="none" start_char="8480" end_char="8480">.</TOKEN>
</SEG>
<SEG id="segment-66" start_char="8482" end_char="8510">
<ORIGINAL_TEXT>En mi farmacia ya había ayer.</ORIGINAL_TEXT>
<TOKEN id="token-66-0" pos="word" morph="none" start_char="8482" end_char="8483">En</TOKEN>
<TOKEN id="token-66-1" pos="word" morph="none" start_char="8485" end_char="8486">mi</TOKEN>
<TOKEN id="token-66-2" pos="word" morph="none" start_char="8488" end_char="8495">farmacia</TOKEN>
<TOKEN id="token-66-3" pos="word" morph="none" start_char="8497" end_char="8498">ya</TOKEN>
<TOKEN id="token-66-4" pos="word" morph="none" start_char="8500" end_char="8504">había</TOKEN>
<TOKEN id="token-66-5" pos="word" morph="none" start_char="8506" end_char="8509">ayer</TOKEN>
<TOKEN id="token-66-6" pos="punct" morph="none" start_char="8510" end_char="8510">.</TOKEN>
</SEG>
<SEG id="segment-67" start_char="8512" end_char="8534">
<ORIGINAL_TEXT>Las quirúrgicas a 1,50.</ORIGINAL_TEXT>
<TOKEN id="token-67-0" pos="word" morph="none" start_char="8512" end_char="8514">Las</TOKEN>
<TOKEN id="token-67-1" pos="word" morph="none" start_char="8516" end_char="8526">quirúrgicas</TOKEN>
<TOKEN id="token-67-2" pos="word" morph="none" start_char="8528" end_char="8528">a</TOKEN>
<TOKEN id="token-67-3" pos="unknown" morph="none" start_char="8530" end_char="8533">1,50</TOKEN>
<TOKEN id="token-67-4" pos="punct" morph="none" start_char="8534" end_char="8534">.</TOKEN>
</SEG>
<SEG id="segment-68" start_char="8536" end_char="8561">
<ORIGINAL_TEXT>¿Es tan urgente definirlo?</ORIGINAL_TEXT>
<TOKEN id="token-68-0" pos="punct" morph="none" start_char="8536" end_char="8536">¿</TOKEN>
<TOKEN id="token-68-1" pos="word" morph="none" start_char="8537" end_char="8538">Es</TOKEN>
<TOKEN id="token-68-2" pos="word" morph="none" start_char="8540" end_char="8542">tan</TOKEN>
<TOKEN id="token-68-3" pos="word" morph="none" start_char="8544" end_char="8550">urgente</TOKEN>
<TOKEN id="token-68-4" pos="word" morph="none" start_char="8552" end_char="8560">definirlo</TOKEN>
<TOKEN id="token-68-5" pos="punct" morph="none" start_char="8561" end_char="8561">?</TOKEN>
</SEG>
<SEG id="segment-69" start_char="8565" end_char="8824">
<ORIGINAL_TEXT>Los expertos nos dicen que el viros es contagioso a través de la boca, la nariz, y a su vez les vemos a los asiáticos, cubrirse con mascarillas, blanco y en botella, otra cosa es que no haya para TODOS,y que lógicamente por prioridades estén los PROFESIONALES.</ORIGINAL_TEXT>
<TOKEN id="token-69-0" pos="word" morph="none" start_char="8565" end_char="8567">Los</TOKEN>
<TOKEN id="token-69-1" pos="word" morph="none" start_char="8569" end_char="8576">expertos</TOKEN>
<TOKEN id="token-69-2" pos="word" morph="none" start_char="8578" end_char="8580">nos</TOKEN>
<TOKEN id="token-69-3" pos="word" morph="none" start_char="8582" end_char="8586">dicen</TOKEN>
<TOKEN id="token-69-4" pos="word" morph="none" start_char="8588" end_char="8590">que</TOKEN>
<TOKEN id="token-69-5" pos="word" morph="none" start_char="8592" end_char="8593">el</TOKEN>
<TOKEN id="token-69-6" pos="word" morph="none" start_char="8595" end_char="8599">viros</TOKEN>
<TOKEN id="token-69-7" pos="word" morph="none" start_char="8601" end_char="8602">es</TOKEN>
<TOKEN id="token-69-8" pos="word" morph="none" start_char="8604" end_char="8613">contagioso</TOKEN>
<TOKEN id="token-69-9" pos="word" morph="none" start_char="8615" end_char="8615">a</TOKEN>
<TOKEN id="token-69-10" pos="word" morph="none" start_char="8617" end_char="8622">través</TOKEN>
<TOKEN id="token-69-11" pos="word" morph="none" start_char="8624" end_char="8625">de</TOKEN>
<TOKEN id="token-69-12" pos="word" morph="none" start_char="8627" end_char="8628">la</TOKEN>
<TOKEN id="token-69-13" pos="word" morph="none" start_char="8630" end_char="8633">boca</TOKEN>
<TOKEN id="token-69-14" pos="punct" morph="none" start_char="8634" end_char="8634">,</TOKEN>
<TOKEN id="token-69-15" pos="word" morph="none" start_char="8636" end_char="8637">la</TOKEN>
<TOKEN id="token-69-16" pos="word" morph="none" start_char="8639" end_char="8643">nariz</TOKEN>
<TOKEN id="token-69-17" pos="punct" morph="none" start_char="8644" end_char="8644">,</TOKEN>
<TOKEN id="token-69-18" pos="word" morph="none" start_char="8646" end_char="8646">y</TOKEN>
<TOKEN id="token-69-19" pos="word" morph="none" start_char="8648" end_char="8648">a</TOKEN>
<TOKEN id="token-69-20" pos="word" morph="none" start_char="8650" end_char="8651">su</TOKEN>
<TOKEN id="token-69-21" pos="word" morph="none" start_char="8653" end_char="8655">vez</TOKEN>
<TOKEN id="token-69-22" pos="word" morph="none" start_char="8657" end_char="8659">les</TOKEN>
<TOKEN id="token-69-23" pos="word" morph="none" start_char="8661" end_char="8665">vemos</TOKEN>
<TOKEN id="token-69-24" pos="word" morph="none" start_char="8667" end_char="8667">a</TOKEN>
<TOKEN id="token-69-25" pos="word" morph="none" start_char="8669" end_char="8671">los</TOKEN>
<TOKEN id="token-69-26" pos="word" morph="none" start_char="8673" end_char="8681">asiáticos</TOKEN>
<TOKEN id="token-69-27" pos="punct" morph="none" start_char="8682" end_char="8682">,</TOKEN>
<TOKEN id="token-69-28" pos="word" morph="none" start_char="8684" end_char="8691">cubrirse</TOKEN>
<TOKEN id="token-69-29" pos="word" morph="none" start_char="8693" end_char="8695">con</TOKEN>
<TOKEN id="token-69-30" pos="word" morph="none" start_char="8697" end_char="8707">mascarillas</TOKEN>
<TOKEN id="token-69-31" pos="punct" morph="none" start_char="8708" end_char="8708">,</TOKEN>
<TOKEN id="token-69-32" pos="word" morph="none" start_char="8710" end_char="8715">blanco</TOKEN>
<TOKEN id="token-69-33" pos="word" morph="none" start_char="8717" end_char="8717">y</TOKEN>
<TOKEN id="token-69-34" pos="word" morph="none" start_char="8719" end_char="8720">en</TOKEN>
<TOKEN id="token-69-35" pos="word" morph="none" start_char="8722" end_char="8728">botella</TOKEN>
<TOKEN id="token-69-36" pos="punct" morph="none" start_char="8729" end_char="8729">,</TOKEN>
<TOKEN id="token-69-37" pos="word" morph="none" start_char="8731" end_char="8734">otra</TOKEN>
<TOKEN id="token-69-38" pos="word" morph="none" start_char="8736" end_char="8739">cosa</TOKEN>
<TOKEN id="token-69-39" pos="word" morph="none" start_char="8741" end_char="8742">es</TOKEN>
<TOKEN id="token-69-40" pos="word" morph="none" start_char="8744" end_char="8746">que</TOKEN>
<TOKEN id="token-69-41" pos="word" morph="none" start_char="8748" end_char="8749">no</TOKEN>
<TOKEN id="token-69-42" pos="word" morph="none" start_char="8751" end_char="8754">haya</TOKEN>
<TOKEN id="token-69-43" pos="word" morph="none" start_char="8756" end_char="8759">para</TOKEN>
<TOKEN id="token-69-44" pos="unknown" morph="none" start_char="8761" end_char="8767">TODOS,y</TOKEN>
<TOKEN id="token-69-45" pos="word" morph="none" start_char="8769" end_char="8771">que</TOKEN>
<TOKEN id="token-69-46" pos="word" morph="none" start_char="8773" end_char="8783">lógicamente</TOKEN>
<TOKEN id="token-69-47" pos="word" morph="none" start_char="8785" end_char="8787">por</TOKEN>
<TOKEN id="token-69-48" pos="word" morph="none" start_char="8789" end_char="8799">prioridades</TOKEN>
<TOKEN id="token-69-49" pos="word" morph="none" start_char="8801" end_char="8805">estén</TOKEN>
<TOKEN id="token-69-50" pos="word" morph="none" start_char="8807" end_char="8809">los</TOKEN>
<TOKEN id="token-69-51" pos="word" morph="none" start_char="8811" end_char="8823">PROFESIONALES</TOKEN>
<TOKEN id="token-69-52" pos="punct" morph="none" start_char="8824" end_char="8824">.</TOKEN>
</SEG>
<SEG id="segment-70" start_char="8826" end_char="9077">
<ORIGINAL_TEXT>pero hoy por hoy,todos nos podemos hacer una mascarilla casera,que también funciona para lo poco que debemos SALIR.Resumiendo,las mascarillas debemos ponerlas,para evitar contagios,perdonarme por el EJEMPLO, pero cómo el condón en su día para evitar...</ORIGINAL_TEXT>
<TOKEN id="token-70-0" pos="word" morph="none" start_char="8826" end_char="8829">pero</TOKEN>
<TOKEN id="token-70-1" pos="word" morph="none" start_char="8831" end_char="8833">hoy</TOKEN>
<TOKEN id="token-70-2" pos="word" morph="none" start_char="8835" end_char="8837">por</TOKEN>
<TOKEN id="token-70-3" pos="unknown" morph="none" start_char="8839" end_char="8847">hoy,todos</TOKEN>
<TOKEN id="token-70-4" pos="word" morph="none" start_char="8849" end_char="8851">nos</TOKEN>
<TOKEN id="token-70-5" pos="word" morph="none" start_char="8853" end_char="8859">podemos</TOKEN>
<TOKEN id="token-70-6" pos="word" morph="none" start_char="8861" end_char="8865">hacer</TOKEN>
<TOKEN id="token-70-7" pos="word" morph="none" start_char="8867" end_char="8869">una</TOKEN>
<TOKEN id="token-70-8" pos="word" morph="none" start_char="8871" end_char="8880">mascarilla</TOKEN>
<TOKEN id="token-70-9" pos="unknown" morph="none" start_char="8882" end_char="8891">casera,que</TOKEN>
<TOKEN id="token-70-10" pos="word" morph="none" start_char="8893" end_char="8899">también</TOKEN>
<TOKEN id="token-70-11" pos="word" morph="none" start_char="8901" end_char="8908">funciona</TOKEN>
<TOKEN id="token-70-12" pos="word" morph="none" start_char="8910" end_char="8913">para</TOKEN>
<TOKEN id="token-70-13" pos="word" morph="none" start_char="8915" end_char="8916">lo</TOKEN>
<TOKEN id="token-70-14" pos="word" morph="none" start_char="8918" end_char="8921">poco</TOKEN>
<TOKEN id="token-70-15" pos="word" morph="none" start_char="8923" end_char="8925">que</TOKEN>
<TOKEN id="token-70-16" pos="word" morph="none" start_char="8927" end_char="8933">debemos</TOKEN>
<TOKEN id="token-70-17" pos="unknown" morph="none" start_char="8935" end_char="8954">SALIR.Resumiendo,las</TOKEN>
<TOKEN id="token-70-18" pos="word" morph="none" start_char="8956" end_char="8966">mascarillas</TOKEN>
<TOKEN id="token-70-19" pos="word" morph="none" start_char="8968" end_char="8974">debemos</TOKEN>
<TOKEN id="token-70-20" pos="unknown" morph="none" start_char="8976" end_char="8988">ponerlas,para</TOKEN>
<TOKEN id="token-70-21" pos="word" morph="none" start_char="8990" end_char="8995">evitar</TOKEN>
<TOKEN id="token-70-22" pos="unknown" morph="none" start_char="8997" end_char="9016">contagios,perdonarme</TOKEN>
<TOKEN id="token-70-23" pos="word" morph="none" start_char="9018" end_char="9020">por</TOKEN>
<TOKEN id="token-70-24" pos="word" morph="none" start_char="9022" end_char="9023">el</TOKEN>
<TOKEN id="token-70-25" pos="word" morph="none" start_char="9025" end_char="9031">EJEMPLO</TOKEN>
<TOKEN id="token-70-26" pos="punct" morph="none" start_char="9032" end_char="9032">,</TOKEN>
<TOKEN id="token-70-27" pos="word" morph="none" start_char="9034" end_char="9037">pero</TOKEN>
<TOKEN id="token-70-28" pos="word" morph="none" start_char="9039" end_char="9042">cómo</TOKEN>
<TOKEN id="token-70-29" pos="word" morph="none" start_char="9044" end_char="9045">el</TOKEN>
<TOKEN id="token-70-30" pos="word" morph="none" start_char="9047" end_char="9052">condón</TOKEN>
<TOKEN id="token-70-31" pos="word" morph="none" start_char="9054" end_char="9055">en</TOKEN>
<TOKEN id="token-70-32" pos="word" morph="none" start_char="9057" end_char="9058">su</TOKEN>
<TOKEN id="token-70-33" pos="word" morph="none" start_char="9060" end_char="9062">día</TOKEN>
<TOKEN id="token-70-34" pos="word" morph="none" start_char="9064" end_char="9067">para</TOKEN>
<TOKEN id="token-70-35" pos="word" morph="none" start_char="9069" end_char="9074">evitar</TOKEN>
<TOKEN id="token-70-36" pos="punct" morph="none" start_char="9075" end_char="9077">...</TOKEN>
</SEG>
<SEG id="segment-71" start_char="9081" end_char="9114">
<ORIGINAL_TEXT>¿Qué tendría peores consecuencias?</ORIGINAL_TEXT>
<TOKEN id="token-71-0" pos="punct" morph="none" start_char="9081" end_char="9081">¿</TOKEN>
<TOKEN id="token-71-1" pos="word" morph="none" start_char="9082" end_char="9084">Qué</TOKEN>
<TOKEN id="token-71-2" pos="word" morph="none" start_char="9086" end_char="9092">tendría</TOKEN>
<TOKEN id="token-71-3" pos="word" morph="none" start_char="9094" end_char="9099">peores</TOKEN>
<TOKEN id="token-71-4" pos="word" morph="none" start_char="9101" end_char="9113">consecuencias</TOKEN>
<TOKEN id="token-71-5" pos="punct" morph="none" start_char="9114" end_char="9114">?</TOKEN>
</SEG>
<SEG id="segment-72" start_char="9116" end_char="9207">
<ORIGINAL_TEXT>Equivocarse por generalizar el uso de mascarillas o equivocarse por no haberlo generslizado?</ORIGINAL_TEXT>
<TOKEN id="token-72-0" pos="word" morph="none" start_char="9116" end_char="9126">Equivocarse</TOKEN>
<TOKEN id="token-72-1" pos="word" morph="none" start_char="9128" end_char="9130">por</TOKEN>
<TOKEN id="token-72-2" pos="word" morph="none" start_char="9132" end_char="9142">generalizar</TOKEN>
<TOKEN id="token-72-3" pos="word" morph="none" start_char="9144" end_char="9145">el</TOKEN>
<TOKEN id="token-72-4" pos="word" morph="none" start_char="9147" end_char="9149">uso</TOKEN>
<TOKEN id="token-72-5" pos="word" morph="none" start_char="9151" end_char="9152">de</TOKEN>
<TOKEN id="token-72-6" pos="word" morph="none" start_char="9154" end_char="9164">mascarillas</TOKEN>
<TOKEN id="token-72-7" pos="word" morph="none" start_char="9166" end_char="9166">o</TOKEN>
<TOKEN id="token-72-8" pos="word" morph="none" start_char="9168" end_char="9178">equivocarse</TOKEN>
<TOKEN id="token-72-9" pos="word" morph="none" start_char="9180" end_char="9182">por</TOKEN>
<TOKEN id="token-72-10" pos="word" morph="none" start_char="9184" end_char="9185">no</TOKEN>
<TOKEN id="token-72-11" pos="word" morph="none" start_char="9187" end_char="9193">haberlo</TOKEN>
<TOKEN id="token-72-12" pos="word" morph="none" start_char="9195" end_char="9206">generslizado</TOKEN>
<TOKEN id="token-72-13" pos="punct" morph="none" start_char="9207" end_char="9207">?</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
