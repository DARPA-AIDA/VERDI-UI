<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="ukr">
<DOC id="L0C049PGQ" lang="ukr" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="6356" raw_text_md5="2ef077e02870df6a0b2fa3f1dac2a792">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="94">
<ORIGINAL_TEXT>No, Coronavirus Was Not Caused by 'Bat Soup'–But Here's What Researchers Think May Be to Blame</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="2">No</TOKEN>
<TOKEN id="token-0-1" pos="punct" morph="none" start_char="3" end_char="3">,</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="5" end_char="15">Coronavirus</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="17" end_char="19">Was</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="21" end_char="23">Not</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="25" end_char="30">Caused</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="32" end_char="33">by</TOKEN>
<TOKEN id="token-0-7" pos="punct" morph="none" start_char="35" end_char="35">'</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="36" end_char="38">Bat</TOKEN>
<TOKEN id="token-0-9" pos="unknown" morph="none" start_char="40" end_char="48">Soup'–But</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="50" end_char="55">Here's</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="57" end_char="60">What</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="62" end_char="72">Researchers</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="74" end_char="78">Think</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="80" end_char="82">May</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="84" end_char="85">Be</TOKEN>
<TOKEN id="token-0-16" pos="word" morph="none" start_char="87" end_char="88">to</TOKEN>
<TOKEN id="token-0-17" pos="word" morph="none" start_char="90" end_char="94">Blame</TOKEN>
</SEG>
<SEG id="segment-1" start_char="99" end_char="288">
<ORIGINAL_TEXT>When news of any new, fast-spreading virus starts making the rounds, two things happen: public panic ensues and misinformation starts to proliferate—and the new coronavirus has sparked both.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="99" end_char="102">When</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="104" end_char="107">news</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="109" end_char="110">of</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="112" end_char="114">any</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="116" end_char="118">new</TOKEN>
<TOKEN id="token-1-5" pos="punct" morph="none" start_char="119" end_char="119">,</TOKEN>
<TOKEN id="token-1-6" pos="unknown" morph="none" start_char="121" end_char="134">fast-spreading</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="136" end_char="140">virus</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="142" end_char="147">starts</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="149" end_char="154">making</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="156" end_char="158">the</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="160" end_char="165">rounds</TOKEN>
<TOKEN id="token-1-12" pos="punct" morph="none" start_char="166" end_char="166">,</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="168" end_char="170">two</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="172" end_char="177">things</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="179" end_char="184">happen</TOKEN>
<TOKEN id="token-1-16" pos="punct" morph="none" start_char="185" end_char="185">:</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="187" end_char="192">public</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="194" end_char="198">panic</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="200" end_char="205">ensues</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="207" end_char="209">and</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="211" end_char="224">misinformation</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="226" end_char="231">starts</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="233" end_char="234">to</TOKEN>
<TOKEN id="token-1-24" pos="unknown" morph="none" start_char="236" end_char="250">proliferate—and</TOKEN>
<TOKEN id="token-1-25" pos="word" morph="none" start_char="252" end_char="254">the</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="256" end_char="258">new</TOKEN>
<TOKEN id="token-1-27" pos="word" morph="none" start_char="260" end_char="270">coronavirus</TOKEN>
<TOKEN id="token-1-28" pos="word" morph="none" start_char="272" end_char="274">has</TOKEN>
<TOKEN id="token-1-29" pos="word" morph="none" start_char="276" end_char="282">sparked</TOKEN>
<TOKEN id="token-1-30" pos="word" morph="none" start_char="284" end_char="287">both</TOKEN>
<TOKEN id="token-1-31" pos="punct" morph="none" start_char="288" end_char="288">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="291" end_char="458">
<ORIGINAL_TEXT>In December 2019, an outbreak of a novel coronavirus—now known as SAR-CoV-2 (initially named 2019-nCoV)—was detected in Wuhan, a city in Central China's Hubei province.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="291" end_char="292">In</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="294" end_char="301">December</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="303" end_char="306">2019</TOKEN>
<TOKEN id="token-2-3" pos="punct" morph="none" start_char="307" end_char="307">,</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="309" end_char="310">an</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="312" end_char="319">outbreak</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="321" end_char="322">of</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="324" end_char="324">a</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="326" end_char="330">novel</TOKEN>
<TOKEN id="token-2-9" pos="unknown" morph="none" start_char="332" end_char="346">coronavirus—now</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="348" end_char="352">known</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="354" end_char="355">as</TOKEN>
<TOKEN id="token-2-12" pos="unknown" morph="none" start_char="357" end_char="365">SAR-CoV-2</TOKEN>
<TOKEN id="token-2-13" pos="punct" morph="none" start_char="367" end_char="367">(</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="368" end_char="376">initially</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="378" end_char="382">named</TOKEN>
<TOKEN id="token-2-16" pos="unknown" morph="none" start_char="384" end_char="397">2019-nCoV)—was</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="399" end_char="406">detected</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="408" end_char="409">in</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="411" end_char="415">Wuhan</TOKEN>
<TOKEN id="token-2-20" pos="punct" morph="none" start_char="416" end_char="416">,</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="418" end_char="418">a</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="420" end_char="423">city</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="425" end_char="426">in</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="428" end_char="434">Central</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="436" end_char="442">China's</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="444" end_char="448">Hubei</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="450" end_char="457">province</TOKEN>
<TOKEN id="token-2-28" pos="punct" morph="none" start_char="458" end_char="458">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="460" end_char="704">
<ORIGINAL_TEXT>Since then, more than 9.6 million people worldwide have developed the infection, and at least 490,000 people have died, according to Johns Hopkins University's real-time tracker, which maps confirmed cases of the illness we now know as COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="460" end_char="464">Since</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="466" end_char="469">then</TOKEN>
<TOKEN id="token-3-2" pos="punct" morph="none" start_char="470" end_char="470">,</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="472" end_char="475">more</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="477" end_char="480">than</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="482" end_char="484">9.6</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="486" end_char="492">million</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="494" end_char="499">people</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="501" end_char="509">worldwide</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="511" end_char="514">have</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="516" end_char="524">developed</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="526" end_char="528">the</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="530" end_char="538">infection</TOKEN>
<TOKEN id="token-3-13" pos="punct" morph="none" start_char="539" end_char="539">,</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="541" end_char="543">and</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="545" end_char="546">at</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="548" end_char="552">least</TOKEN>
<TOKEN id="token-3-17" pos="unknown" morph="none" start_char="554" end_char="560">490,000</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="562" end_char="567">people</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="569" end_char="572">have</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="574" end_char="577">died</TOKEN>
<TOKEN id="token-3-21" pos="punct" morph="none" start_char="578" end_char="578">,</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="580" end_char="588">according</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="590" end_char="591">to</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="593" end_char="597">Johns</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="599" end_char="605">Hopkins</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="607" end_char="618">University's</TOKEN>
<TOKEN id="token-3-27" pos="unknown" morph="none" start_char="620" end_char="628">real-time</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="630" end_char="636">tracker</TOKEN>
<TOKEN id="token-3-29" pos="punct" morph="none" start_char="637" end_char="637">,</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="639" end_char="643">which</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="645" end_char="648">maps</TOKEN>
<TOKEN id="token-3-32" pos="word" morph="none" start_char="650" end_char="658">confirmed</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="660" end_char="664">cases</TOKEN>
<TOKEN id="token-3-34" pos="word" morph="none" start_char="666" end_char="667">of</TOKEN>
<TOKEN id="token-3-35" pos="word" morph="none" start_char="669" end_char="671">the</TOKEN>
<TOKEN id="token-3-36" pos="word" morph="none" start_char="673" end_char="679">illness</TOKEN>
<TOKEN id="token-3-37" pos="word" morph="none" start_char="681" end_char="682">we</TOKEN>
<TOKEN id="token-3-38" pos="word" morph="none" start_char="684" end_char="686">now</TOKEN>
<TOKEN id="token-3-39" pos="word" morph="none" start_char="688" end_char="691">know</TOKEN>
<TOKEN id="token-3-40" pos="word" morph="none" start_char="693" end_char="694">as</TOKEN>
<TOKEN id="token-3-41" pos="unknown" morph="none" start_char="696" end_char="703">COVID-19</TOKEN>
<TOKEN id="token-3-42" pos="punct" morph="none" start_char="704" end_char="704">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="706" end_char="788">
<ORIGINAL_TEXT>The US accounts for more than 2.4 million of those cases and nearly 125,000 deaths.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="706" end_char="708">The</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="710" end_char="711">US</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="713" end_char="720">accounts</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="722" end_char="724">for</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="726" end_char="729">more</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="731" end_char="734">than</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="736" end_char="738">2.4</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="740" end_char="746">million</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="748" end_char="749">of</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="751" end_char="755">those</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="757" end_char="761">cases</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="763" end_char="765">and</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="767" end_char="772">nearly</TOKEN>
<TOKEN id="token-4-13" pos="unknown" morph="none" start_char="774" end_char="780">125,000</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="782" end_char="787">deaths</TOKEN>
<TOKEN id="token-4-15" pos="punct" morph="none" start_char="788" end_char="788">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="791" end_char="947">
<ORIGINAL_TEXT>While health officials across the world—and, honestly, the entire world in general—try to figure out what exactly the new coronavirus is (Where did it start?</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="791" end_char="795">While</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="797" end_char="802">health</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="804" end_char="812">officials</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="814" end_char="819">across</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="821" end_char="823">the</TOKEN>
<TOKEN id="token-5-5" pos="unknown" morph="none" start_char="825" end_char="833">world—and</TOKEN>
<TOKEN id="token-5-6" pos="punct" morph="none" start_char="834" end_char="834">,</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="836" end_char="843">honestly</TOKEN>
<TOKEN id="token-5-8" pos="punct" morph="none" start_char="844" end_char="844">,</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="846" end_char="848">the</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="850" end_char="855">entire</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="857" end_char="861">world</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="863" end_char="864">in</TOKEN>
<TOKEN id="token-5-13" pos="unknown" morph="none" start_char="866" end_char="876">general—try</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="878" end_char="879">to</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="881" end_char="886">figure</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="888" end_char="890">out</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="892" end_char="895">what</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="897" end_char="903">exactly</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="905" end_char="907">the</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="909" end_char="911">new</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="913" end_char="923">coronavirus</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="925" end_char="926">is</TOKEN>
<TOKEN id="token-5-23" pos="punct" morph="none" start_char="928" end_char="928">(</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="929" end_char="933">Where</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="935" end_char="937">did</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="939" end_char="940">it</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="942" end_char="946">start</TOKEN>
<TOKEN id="token-5-28" pos="punct" morph="none" start_char="947" end_char="947">?</TOKEN>
</SEG>
<SEG id="segment-6" start_char="949" end_char="970">
<ORIGINAL_TEXT>How is it transmitted?</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="949" end_char="951">How</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="953" end_char="954">is</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="956" end_char="957">it</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="959" end_char="969">transmitted</TOKEN>
<TOKEN id="token-6-4" pos="punct" morph="none" start_char="970" end_char="970">?</TOKEN>
</SEG>
<SEG id="segment-7" start_char="972" end_char="1002">
<ORIGINAL_TEXT>What's making it so infectious?</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="972" end_char="977">What's</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="979" end_char="984">making</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="986" end_char="987">it</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="989" end_char="990">so</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="992" end_char="1001">infectious</TOKEN>
<TOKEN id="token-7-5" pos="punct" morph="none" start_char="1002" end_char="1002">?</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1004" end_char="1042">
<ORIGINAL_TEXT>), one thing in particular is certainly</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="punct" morph="none" start_char="1004" end_char="1005">),</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1007" end_char="1009">one</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1011" end_char="1015">thing</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1017" end_char="1018">in</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1020" end_char="1029">particular</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1031" end_char="1032">is</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1034" end_char="1042">certainly</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1045" end_char="1047">
<ORIGINAL_TEXT>not</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1045" end_char="1047">not</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1050" end_char="1169">
<ORIGINAL_TEXT>helping anyone: Claims that it somehow originated with one woman eating something people are referring to as "bat soup."</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1050" end_char="1056">helping</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1058" end_char="1063">anyone</TOKEN>
<TOKEN id="token-10-2" pos="punct" morph="none" start_char="1064" end_char="1064">:</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1066" end_char="1071">Claims</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1073" end_char="1076">that</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1078" end_char="1079">it</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1081" end_char="1087">somehow</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1089" end_char="1098">originated</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1100" end_char="1103">with</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1105" end_char="1107">one</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1109" end_char="1113">woman</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1115" end_char="1120">eating</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1122" end_char="1130">something</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1132" end_char="1137">people</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1139" end_char="1141">are</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1143" end_char="1151">referring</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1153" end_char="1154">to</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1156" end_char="1157">as</TOKEN>
<TOKEN id="token-10-18" pos="punct" morph="none" start_char="1159" end_char="1159">"</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1160" end_char="1162">bat</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1164" end_char="1167">soup</TOKEN>
<TOKEN id="token-10-21" pos="punct" morph="none" start_char="1168" end_char="1169">."</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1171" end_char="1245">
<ORIGINAL_TEXT>(Seriously—the searches for "bat soup" in Google Trends truly skyrocketed).</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="punct" morph="none" start_char="1171" end_char="1171">(</TOKEN>
<TOKEN id="token-11-1" pos="unknown" morph="none" start_char="1172" end_char="1184">Seriously—the</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1186" end_char="1193">searches</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1195" end_char="1197">for</TOKEN>
<TOKEN id="token-11-4" pos="punct" morph="none" start_char="1199" end_char="1199">"</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1200" end_char="1202">bat</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1204" end_char="1207">soup</TOKEN>
<TOKEN id="token-11-7" pos="punct" morph="none" start_char="1208" end_char="1208">"</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1210" end_char="1211">in</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1213" end_char="1218">Google</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1220" end_char="1225">Trends</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1227" end_char="1231">truly</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1233" end_char="1243">skyrocketed</TOKEN>
<TOKEN id="token-11-13" pos="punct" morph="none" start_char="1244" end_char="1245">).</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1248" end_char="1296">
<ORIGINAL_TEXT>Where exactly did the "bat soup" claim come from?</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1248" end_char="1252">Where</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1254" end_char="1260">exactly</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1262" end_char="1264">did</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1266" end_char="1268">the</TOKEN>
<TOKEN id="token-12-4" pos="punct" morph="none" start_char="1270" end_char="1270">"</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1271" end_char="1273">bat</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1275" end_char="1278">soup</TOKEN>
<TOKEN id="token-12-7" pos="punct" morph="none" start_char="1279" end_char="1279">"</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1281" end_char="1285">claim</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1287" end_char="1290">come</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1292" end_char="1295">from</TOKEN>
<TOKEN id="token-12-11" pos="punct" morph="none" start_char="1296" end_char="1296">?</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1300" end_char="1311">
<ORIGINAL_TEXT>According to</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1300" end_char="1308">According</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1310" end_char="1311">to</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1314" end_char="1327">
<ORIGINAL_TEXT>Foreign Policy</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1314" end_char="1320">Foreign</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1322" end_char="1327">Policy</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1330" end_char="1455">
<ORIGINAL_TEXT>, a video recently surfaced of a Chinese woman holding an entire bat with chopsticks, appearing to eat the creature in a soup.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="punct" morph="none" start_char="1330" end_char="1330">,</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1332" end_char="1332">a</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1334" end_char="1338">video</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1340" end_char="1347">recently</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1349" end_char="1356">surfaced</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1358" end_char="1359">of</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1361" end_char="1361">a</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1363" end_char="1369">Chinese</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1371" end_char="1375">woman</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1377" end_char="1383">holding</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1385" end_char="1386">an</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1388" end_char="1393">entire</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1395" end_char="1397">bat</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1399" end_char="1402">with</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1404" end_char="1413">chopsticks</TOKEN>
<TOKEN id="token-15-15" pos="punct" morph="none" start_char="1414" end_char="1414">,</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="1416" end_char="1424">appearing</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="1426" end_char="1427">to</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="1429" end_char="1431">eat</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="1433" end_char="1435">the</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="1437" end_char="1444">creature</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="1446" end_char="1447">in</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="1449" end_char="1449">a</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="1451" end_char="1454">soup</TOKEN>
<TOKEN id="token-15-24" pos="punct" morph="none" start_char="1455" end_char="1455">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1457" end_char="1459">
<ORIGINAL_TEXT>The</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1457" end_char="1459">The</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1462" end_char="1471">
<ORIGINAL_TEXT>Daily Mail</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1462" end_char="1466">Daily</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1468" end_char="1471">Mail</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1474" end_char="1543">
<ORIGINAL_TEXT>also reported on the video, and YouTube channel RT shared the footage.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="1474" end_char="1477">also</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="1479" end_char="1486">reported</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="1488" end_char="1489">on</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="1491" end_char="1493">the</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="1495" end_char="1499">video</TOKEN>
<TOKEN id="token-18-5" pos="punct" morph="none" start_char="1500" end_char="1500">,</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="1502" end_char="1504">and</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="1506" end_char="1512">YouTube</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="1514" end_char="1520">channel</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="1522" end_char="1523">RT</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="1525" end_char="1530">shared</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="1532" end_char="1534">the</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="1536" end_char="1542">footage</TOKEN>
<TOKEN id="token-18-13" pos="punct" morph="none" start_char="1543" end_char="1543">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="1545" end_char="1686">
<ORIGINAL_TEXT>The clip was reportedly met with outrage from Twitter users, who quickly began calling out Chinese eating habits as the cause of the outbreak.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="1545" end_char="1547">The</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="1549" end_char="1552">clip</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="1554" end_char="1556">was</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="1558" end_char="1567">reportedly</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="1569" end_char="1571">met</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="1573" end_char="1576">with</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="1578" end_char="1584">outrage</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="1586" end_char="1589">from</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="1591" end_char="1597">Twitter</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="1599" end_char="1603">users</TOKEN>
<TOKEN id="token-19-10" pos="punct" morph="none" start_char="1604" end_char="1604">,</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="1606" end_char="1608">who</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="1610" end_char="1616">quickly</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="1618" end_char="1622">began</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="1624" end_char="1630">calling</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="1632" end_char="1634">out</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="1636" end_char="1642">Chinese</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="1644" end_char="1649">eating</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="1651" end_char="1656">habits</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="1658" end_char="1659">as</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="1661" end_char="1663">the</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="1665" end_char="1669">cause</TOKEN>
<TOKEN id="token-19-22" pos="word" morph="none" start_char="1671" end_char="1672">of</TOKEN>
<TOKEN id="token-19-23" pos="word" morph="none" start_char="1674" end_char="1676">the</TOKEN>
<TOKEN id="token-19-24" pos="word" morph="none" start_char="1678" end_char="1685">outbreak</TOKEN>
<TOKEN id="token-19-25" pos="punct" morph="none" start_char="1686" end_char="1686">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="1689" end_char="1713">
<ORIGINAL_TEXT>But here's the thing, per</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="1689" end_char="1691">But</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="1693" end_char="1698">here's</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="1700" end_char="1702">the</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="1704" end_char="1708">thing</TOKEN>
<TOKEN id="token-20-4" pos="punct" morph="none" start_char="1709" end_char="1709">,</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="1711" end_char="1713">per</TOKEN>
</SEG>
<SEG id="segment-21" start_char="1716" end_char="1729">
<ORIGINAL_TEXT>Foreign Policy</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="1716" end_char="1722">Foreign</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="1724" end_char="1729">Policy</TOKEN>
</SEG>
<SEG id="segment-22" start_char="1732" end_char="2015">
<ORIGINAL_TEXT>: That video in question reportedly wasn't filmed in Wuhan or China in general—the woman in the video, who news outlets have identified as Wang Mengyun, is a host of an online travel show who was actually eating a dish in Palau, an island country located in the western Pacific ocean.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="punct" morph="none" start_char="1732" end_char="1732">:</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="1734" end_char="1737">That</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="1739" end_char="1743">video</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="1745" end_char="1746">in</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="1748" end_char="1755">question</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="1757" end_char="1766">reportedly</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="1768" end_char="1773">wasn't</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="1775" end_char="1780">filmed</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="1782" end_char="1783">in</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="1785" end_char="1789">Wuhan</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="1791" end_char="1792">or</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="1794" end_char="1798">China</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="1800" end_char="1801">in</TOKEN>
<TOKEN id="token-22-13" pos="unknown" morph="none" start_char="1803" end_char="1813">general—the</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="1815" end_char="1819">woman</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="1821" end_char="1822">in</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="1824" end_char="1826">the</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="1828" end_char="1832">video</TOKEN>
<TOKEN id="token-22-18" pos="punct" morph="none" start_char="1833" end_char="1833">,</TOKEN>
<TOKEN id="token-22-19" pos="word" morph="none" start_char="1835" end_char="1837">who</TOKEN>
<TOKEN id="token-22-20" pos="word" morph="none" start_char="1839" end_char="1842">news</TOKEN>
<TOKEN id="token-22-21" pos="word" morph="none" start_char="1844" end_char="1850">outlets</TOKEN>
<TOKEN id="token-22-22" pos="word" morph="none" start_char="1852" end_char="1855">have</TOKEN>
<TOKEN id="token-22-23" pos="word" morph="none" start_char="1857" end_char="1866">identified</TOKEN>
<TOKEN id="token-22-24" pos="word" morph="none" start_char="1868" end_char="1869">as</TOKEN>
<TOKEN id="token-22-25" pos="word" morph="none" start_char="1871" end_char="1874">Wang</TOKEN>
<TOKEN id="token-22-26" pos="word" morph="none" start_char="1876" end_char="1882">Mengyun</TOKEN>
<TOKEN id="token-22-27" pos="punct" morph="none" start_char="1883" end_char="1883">,</TOKEN>
<TOKEN id="token-22-28" pos="word" morph="none" start_char="1885" end_char="1886">is</TOKEN>
<TOKEN id="token-22-29" pos="word" morph="none" start_char="1888" end_char="1888">a</TOKEN>
<TOKEN id="token-22-30" pos="word" morph="none" start_char="1890" end_char="1893">host</TOKEN>
<TOKEN id="token-22-31" pos="word" morph="none" start_char="1895" end_char="1896">of</TOKEN>
<TOKEN id="token-22-32" pos="word" morph="none" start_char="1898" end_char="1899">an</TOKEN>
<TOKEN id="token-22-33" pos="word" morph="none" start_char="1901" end_char="1906">online</TOKEN>
<TOKEN id="token-22-34" pos="word" morph="none" start_char="1908" end_char="1913">travel</TOKEN>
<TOKEN id="token-22-35" pos="word" morph="none" start_char="1915" end_char="1918">show</TOKEN>
<TOKEN id="token-22-36" pos="word" morph="none" start_char="1920" end_char="1922">who</TOKEN>
<TOKEN id="token-22-37" pos="word" morph="none" start_char="1924" end_char="1926">was</TOKEN>
<TOKEN id="token-22-38" pos="word" morph="none" start_char="1928" end_char="1935">actually</TOKEN>
<TOKEN id="token-22-39" pos="word" morph="none" start_char="1937" end_char="1942">eating</TOKEN>
<TOKEN id="token-22-40" pos="word" morph="none" start_char="1944" end_char="1944">a</TOKEN>
<TOKEN id="token-22-41" pos="word" morph="none" start_char="1946" end_char="1949">dish</TOKEN>
<TOKEN id="token-22-42" pos="word" morph="none" start_char="1951" end_char="1952">in</TOKEN>
<TOKEN id="token-22-43" pos="word" morph="none" start_char="1954" end_char="1958">Palau</TOKEN>
<TOKEN id="token-22-44" pos="punct" morph="none" start_char="1959" end_char="1959">,</TOKEN>
<TOKEN id="token-22-45" pos="word" morph="none" start_char="1961" end_char="1962">an</TOKEN>
<TOKEN id="token-22-46" pos="word" morph="none" start_char="1964" end_char="1969">island</TOKEN>
<TOKEN id="token-22-47" pos="word" morph="none" start_char="1971" end_char="1977">country</TOKEN>
<TOKEN id="token-22-48" pos="word" morph="none" start_char="1979" end_char="1985">located</TOKEN>
<TOKEN id="token-22-49" pos="word" morph="none" start_char="1987" end_char="1988">in</TOKEN>
<TOKEN id="token-22-50" pos="word" morph="none" start_char="1990" end_char="1992">the</TOKEN>
<TOKEN id="token-22-51" pos="word" morph="none" start_char="1994" end_char="2000">western</TOKEN>
<TOKEN id="token-22-52" pos="word" morph="none" start_char="2002" end_char="2008">Pacific</TOKEN>
<TOKEN id="token-22-53" pos="word" morph="none" start_char="2010" end_char="2014">ocean</TOKEN>
<TOKEN id="token-22-54" pos="punct" morph="none" start_char="2015" end_char="2015">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2017" end_char="2107">
<ORIGINAL_TEXT>The video was also reportedly filmed in 2016—well before the coronavirus outbreak in Wuhan.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2017" end_char="2019">The</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2021" end_char="2025">video</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2027" end_char="2029">was</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2031" end_char="2034">also</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="2036" end_char="2045">reportedly</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="2047" end_char="2052">filmed</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="2054" end_char="2055">in</TOKEN>
<TOKEN id="token-23-7" pos="unknown" morph="none" start_char="2057" end_char="2065">2016—well</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="2067" end_char="2072">before</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="2074" end_char="2076">the</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="2078" end_char="2088">coronavirus</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="2090" end_char="2097">outbreak</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="2099" end_char="2100">in</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="2102" end_char="2106">Wuhan</TOKEN>
<TOKEN id="token-23-14" pos="punct" morph="none" start_char="2107" end_char="2107">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2109" end_char="2163">
<ORIGINAL_TEXT>Mengyun has also reportedly apologized for the footage.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="2109" end_char="2115">Mengyun</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="2117" end_char="2119">has</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="2121" end_char="2124">also</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="2126" end_char="2135">reportedly</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="2137" end_char="2146">apologized</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="2148" end_char="2150">for</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="2152" end_char="2154">the</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="2156" end_char="2162">footage</TOKEN>
<TOKEN id="token-24-8" pos="punct" morph="none" start_char="2163" end_char="2163">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2165" end_char="2185">
<ORIGINAL_TEXT>"I am sorry everyone.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="punct" morph="none" start_char="2165" end_char="2165">"</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="2166" end_char="2166">I</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="2168" end_char="2169">am</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="2171" end_char="2175">sorry</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="2177" end_char="2184">everyone</TOKEN>
<TOKEN id="token-25-5" pos="punct" morph="none" start_char="2185" end_char="2185">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="2187" end_char="2244">
<ORIGINAL_TEXT>I should not have eaten a bat," she said, according to the</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="2187" end_char="2187">I</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="2189" end_char="2194">should</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="2196" end_char="2198">not</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="2200" end_char="2203">have</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="2205" end_char="2209">eaten</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="2211" end_char="2211">a</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="2213" end_char="2215">bat</TOKEN>
<TOKEN id="token-26-7" pos="punct" morph="none" start_char="2216" end_char="2217">,"</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="2219" end_char="2221">she</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="2223" end_char="2226">said</TOKEN>
<TOKEN id="token-26-10" pos="punct" morph="none" start_char="2227" end_char="2227">,</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="2229" end_char="2237">according</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="2239" end_char="2240">to</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="2242" end_char="2244">the</TOKEN>
</SEG>
<SEG id="segment-27" start_char="2247" end_char="2270">
<ORIGINAL_TEXT>South China Morning Post</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="2247" end_char="2251">South</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="2253" end_char="2257">China</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="2259" end_char="2265">Morning</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="2267" end_char="2270">Post</TOKEN>
</SEG>
<SEG id="segment-28" start_char="2273" end_char="2273">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="punct" morph="none" start_char="2273" end_char="2273">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="2275" end_char="2350">
<ORIGINAL_TEXT>"[I] had no idea during filming that there was such a virus," she continued.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="punct" morph="none" start_char="2275" end_char="2276">"[</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="2277" end_char="2277">I</TOKEN>
<TOKEN id="token-29-2" pos="punct" morph="none" start_char="2278" end_char="2278">]</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="2280" end_char="2282">had</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="2284" end_char="2285">no</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="2287" end_char="2290">idea</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="2292" end_char="2297">during</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="2299" end_char="2305">filming</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="2307" end_char="2310">that</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="2312" end_char="2316">there</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="2318" end_char="2320">was</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="2322" end_char="2325">such</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="2327" end_char="2327">a</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="2329" end_char="2333">virus</TOKEN>
<TOKEN id="token-29-14" pos="punct" morph="none" start_char="2334" end_char="2335">,"</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="2337" end_char="2339">she</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="2341" end_char="2349">continued</TOKEN>
<TOKEN id="token-29-17" pos="punct" morph="none" start_char="2350" end_char="2350">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="2352" end_char="2381">
<ORIGINAL_TEXT>"I realized it only recently."</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="punct" morph="none" start_char="2352" end_char="2352">"</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="2353" end_char="2353">I</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="2355" end_char="2362">realized</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="2364" end_char="2365">it</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="2367" end_char="2370">only</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="2372" end_char="2379">recently</TOKEN>
<TOKEN id="token-30-6" pos="punct" morph="none" start_char="2380" end_char="2381">."</TOKEN>
</SEG>
<SEG id="segment-31" start_char="2384" end_char="2450">
<ORIGINAL_TEXT>So where did coronavirus originate—and is it linked to bats at all?</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="2384" end_char="2385">So</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="2387" end_char="2391">where</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="2393" end_char="2395">did</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="2397" end_char="2407">coronavirus</TOKEN>
<TOKEN id="token-31-4" pos="unknown" morph="none" start_char="2409" end_char="2421">originate—and</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="2423" end_char="2424">is</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="2426" end_char="2427">it</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="2429" end_char="2434">linked</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="2436" end_char="2437">to</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="2439" end_char="2442">bats</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="2444" end_char="2445">at</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="2447" end_char="2449">all</TOKEN>
<TOKEN id="token-31-12" pos="punct" morph="none" start_char="2450" end_char="2450">?</TOKEN>
</SEG>
<SEG id="segment-32" start_char="2454" end_char="2691">
<ORIGINAL_TEXT>This is where it gets tricky: Coronaviruses in general are a large family of viruses that can affect many different species of animals, including camels, cattle, and bats, according to the Centers for Disease Control and Prevention (CDC).</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="2454" end_char="2457">This</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="2459" end_char="2460">is</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="2462" end_char="2466">where</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="2468" end_char="2469">it</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="2471" end_char="2474">gets</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="2476" end_char="2481">tricky</TOKEN>
<TOKEN id="token-32-6" pos="punct" morph="none" start_char="2482" end_char="2482">:</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="2484" end_char="2496">Coronaviruses</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="2498" end_char="2499">in</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="2501" end_char="2507">general</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="2509" end_char="2511">are</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="2513" end_char="2513">a</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="2515" end_char="2519">large</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="2521" end_char="2526">family</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="2528" end_char="2529">of</TOKEN>
<TOKEN id="token-32-15" pos="word" morph="none" start_char="2531" end_char="2537">viruses</TOKEN>
<TOKEN id="token-32-16" pos="word" morph="none" start_char="2539" end_char="2542">that</TOKEN>
<TOKEN id="token-32-17" pos="word" morph="none" start_char="2544" end_char="2546">can</TOKEN>
<TOKEN id="token-32-18" pos="word" morph="none" start_char="2548" end_char="2553">affect</TOKEN>
<TOKEN id="token-32-19" pos="word" morph="none" start_char="2555" end_char="2558">many</TOKEN>
<TOKEN id="token-32-20" pos="word" morph="none" start_char="2560" end_char="2568">different</TOKEN>
<TOKEN id="token-32-21" pos="word" morph="none" start_char="2570" end_char="2576">species</TOKEN>
<TOKEN id="token-32-22" pos="word" morph="none" start_char="2578" end_char="2579">of</TOKEN>
<TOKEN id="token-32-23" pos="word" morph="none" start_char="2581" end_char="2587">animals</TOKEN>
<TOKEN id="token-32-24" pos="punct" morph="none" start_char="2588" end_char="2588">,</TOKEN>
<TOKEN id="token-32-25" pos="word" morph="none" start_char="2590" end_char="2598">including</TOKEN>
<TOKEN id="token-32-26" pos="word" morph="none" start_char="2600" end_char="2605">camels</TOKEN>
<TOKEN id="token-32-27" pos="punct" morph="none" start_char="2606" end_char="2606">,</TOKEN>
<TOKEN id="token-32-28" pos="word" morph="none" start_char="2608" end_char="2613">cattle</TOKEN>
<TOKEN id="token-32-29" pos="punct" morph="none" start_char="2614" end_char="2614">,</TOKEN>
<TOKEN id="token-32-30" pos="word" morph="none" start_char="2616" end_char="2618">and</TOKEN>
<TOKEN id="token-32-31" pos="word" morph="none" start_char="2620" end_char="2623">bats</TOKEN>
<TOKEN id="token-32-32" pos="punct" morph="none" start_char="2624" end_char="2624">,</TOKEN>
<TOKEN id="token-32-33" pos="word" morph="none" start_char="2626" end_char="2634">according</TOKEN>
<TOKEN id="token-32-34" pos="word" morph="none" start_char="2636" end_char="2637">to</TOKEN>
<TOKEN id="token-32-35" pos="word" morph="none" start_char="2639" end_char="2641">the</TOKEN>
<TOKEN id="token-32-36" pos="word" morph="none" start_char="2643" end_char="2649">Centers</TOKEN>
<TOKEN id="token-32-37" pos="word" morph="none" start_char="2651" end_char="2653">for</TOKEN>
<TOKEN id="token-32-38" pos="word" morph="none" start_char="2655" end_char="2661">Disease</TOKEN>
<TOKEN id="token-32-39" pos="word" morph="none" start_char="2663" end_char="2669">Control</TOKEN>
<TOKEN id="token-32-40" pos="word" morph="none" start_char="2671" end_char="2673">and</TOKEN>
<TOKEN id="token-32-41" pos="word" morph="none" start_char="2675" end_char="2684">Prevention</TOKEN>
<TOKEN id="token-32-42" pos="punct" morph="none" start_char="2686" end_char="2686">(</TOKEN>
<TOKEN id="token-32-43" pos="word" morph="none" start_char="2687" end_char="2689">CDC</TOKEN>
<TOKEN id="token-32-44" pos="punct" morph="none" start_char="2690" end_char="2691">).</TOKEN>
</SEG>
<SEG id="segment-33" start_char="2693" end_char="2933">
<ORIGINAL_TEXT>In rare cases, those viruses are also zoonotic, which means they can pass between humans and animals—as was the case with Middle East respiratory syndrome (MERS) and severe acute respiratory system (SARS), two severe coronaviruses in people.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="2693" end_char="2694">In</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="2696" end_char="2699">rare</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="2701" end_char="2705">cases</TOKEN>
<TOKEN id="token-33-3" pos="punct" morph="none" start_char="2706" end_char="2706">,</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="2708" end_char="2712">those</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="2714" end_char="2720">viruses</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="2722" end_char="2724">are</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="2726" end_char="2729">also</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="2731" end_char="2738">zoonotic</TOKEN>
<TOKEN id="token-33-9" pos="punct" morph="none" start_char="2739" end_char="2739">,</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="2741" end_char="2745">which</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="2747" end_char="2751">means</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="2753" end_char="2756">they</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="2758" end_char="2760">can</TOKEN>
<TOKEN id="token-33-14" pos="word" morph="none" start_char="2762" end_char="2765">pass</TOKEN>
<TOKEN id="token-33-15" pos="word" morph="none" start_char="2767" end_char="2773">between</TOKEN>
<TOKEN id="token-33-16" pos="word" morph="none" start_char="2775" end_char="2780">humans</TOKEN>
<TOKEN id="token-33-17" pos="word" morph="none" start_char="2782" end_char="2784">and</TOKEN>
<TOKEN id="token-33-18" pos="unknown" morph="none" start_char="2786" end_char="2795">animals—as</TOKEN>
<TOKEN id="token-33-19" pos="word" morph="none" start_char="2797" end_char="2799">was</TOKEN>
<TOKEN id="token-33-20" pos="word" morph="none" start_char="2801" end_char="2803">the</TOKEN>
<TOKEN id="token-33-21" pos="word" morph="none" start_char="2805" end_char="2808">case</TOKEN>
<TOKEN id="token-33-22" pos="word" morph="none" start_char="2810" end_char="2813">with</TOKEN>
<TOKEN id="token-33-23" pos="word" morph="none" start_char="2815" end_char="2820">Middle</TOKEN>
<TOKEN id="token-33-24" pos="word" morph="none" start_char="2822" end_char="2825">East</TOKEN>
<TOKEN id="token-33-25" pos="word" morph="none" start_char="2827" end_char="2837">respiratory</TOKEN>
<TOKEN id="token-33-26" pos="word" morph="none" start_char="2839" end_char="2846">syndrome</TOKEN>
<TOKEN id="token-33-27" pos="punct" morph="none" start_char="2848" end_char="2848">(</TOKEN>
<TOKEN id="token-33-28" pos="word" morph="none" start_char="2849" end_char="2852">MERS</TOKEN>
<TOKEN id="token-33-29" pos="punct" morph="none" start_char="2853" end_char="2853">)</TOKEN>
<TOKEN id="token-33-30" pos="word" morph="none" start_char="2855" end_char="2857">and</TOKEN>
<TOKEN id="token-33-31" pos="word" morph="none" start_char="2859" end_char="2864">severe</TOKEN>
<TOKEN id="token-33-32" pos="word" morph="none" start_char="2866" end_char="2870">acute</TOKEN>
<TOKEN id="token-33-33" pos="word" morph="none" start_char="2872" end_char="2882">respiratory</TOKEN>
<TOKEN id="token-33-34" pos="word" morph="none" start_char="2884" end_char="2889">system</TOKEN>
<TOKEN id="token-33-35" pos="punct" morph="none" start_char="2891" end_char="2891">(</TOKEN>
<TOKEN id="token-33-36" pos="word" morph="none" start_char="2892" end_char="2895">SARS</TOKEN>
<TOKEN id="token-33-37" pos="punct" morph="none" start_char="2896" end_char="2897">),</TOKEN>
<TOKEN id="token-33-38" pos="word" morph="none" start_char="2899" end_char="2901">two</TOKEN>
<TOKEN id="token-33-39" pos="word" morph="none" start_char="2903" end_char="2908">severe</TOKEN>
<TOKEN id="token-33-40" pos="word" morph="none" start_char="2910" end_char="2922">coronaviruses</TOKEN>
<TOKEN id="token-33-41" pos="word" morph="none" start_char="2924" end_char="2925">in</TOKEN>
<TOKEN id="token-33-42" pos="word" morph="none" start_char="2927" end_char="2932">people</TOKEN>
<TOKEN id="token-33-43" pos="punct" morph="none" start_char="2933" end_char="2933">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="2936" end_char="3089">
<ORIGINAL_TEXT>Initially, this novel coronavirus was believed to have started in a large seafood or wet market, suggesting animal-to-person spread, according to the CDC.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="2936" end_char="2944">Initially</TOKEN>
<TOKEN id="token-34-1" pos="punct" morph="none" start_char="2945" end_char="2945">,</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="2947" end_char="2950">this</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="2952" end_char="2956">novel</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="2958" end_char="2968">coronavirus</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="2970" end_char="2972">was</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="2974" end_char="2981">believed</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="2983" end_char="2984">to</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="2986" end_char="2989">have</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="2991" end_char="2997">started</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="2999" end_char="3000">in</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="3002" end_char="3002">a</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="3004" end_char="3008">large</TOKEN>
<TOKEN id="token-34-13" pos="word" morph="none" start_char="3010" end_char="3016">seafood</TOKEN>
<TOKEN id="token-34-14" pos="word" morph="none" start_char="3018" end_char="3019">or</TOKEN>
<TOKEN id="token-34-15" pos="word" morph="none" start_char="3021" end_char="3023">wet</TOKEN>
<TOKEN id="token-34-16" pos="word" morph="none" start_char="3025" end_char="3030">market</TOKEN>
<TOKEN id="token-34-17" pos="punct" morph="none" start_char="3031" end_char="3031">,</TOKEN>
<TOKEN id="token-34-18" pos="word" morph="none" start_char="3033" end_char="3042">suggesting</TOKEN>
<TOKEN id="token-34-19" pos="unknown" morph="none" start_char="3044" end_char="3059">animal-to-person</TOKEN>
<TOKEN id="token-34-20" pos="word" morph="none" start_char="3061" end_char="3066">spread</TOKEN>
<TOKEN id="token-34-21" pos="punct" morph="none" start_char="3067" end_char="3067">,</TOKEN>
<TOKEN id="token-34-22" pos="word" morph="none" start_char="3069" end_char="3077">according</TOKEN>
<TOKEN id="token-34-23" pos="word" morph="none" start_char="3079" end_char="3080">to</TOKEN>
<TOKEN id="token-34-24" pos="word" morph="none" start_char="3082" end_char="3084">the</TOKEN>
<TOKEN id="token-34-25" pos="word" morph="none" start_char="3086" end_char="3088">CDC</TOKEN>
<TOKEN id="token-34-26" pos="punct" morph="none" start_char="3089" end_char="3089">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="3091" end_char="3284">
<ORIGINAL_TEXT>But a large number of people diagnosed with the virus reportedly didn't have exposure to the wet markets, and now it's clear that the virus is primarily spreading person-to-person, says the CDC.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="3091" end_char="3093">But</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="3095" end_char="3095">a</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="3097" end_char="3101">large</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="3103" end_char="3108">number</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="3110" end_char="3111">of</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="3113" end_char="3118">people</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="3120" end_char="3128">diagnosed</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="3130" end_char="3133">with</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="3135" end_char="3137">the</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="3139" end_char="3143">virus</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="3145" end_char="3154">reportedly</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="3156" end_char="3161">didn't</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="3163" end_char="3166">have</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="3168" end_char="3175">exposure</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="3177" end_char="3178">to</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="3180" end_char="3182">the</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="3184" end_char="3186">wet</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="3188" end_char="3194">markets</TOKEN>
<TOKEN id="token-35-18" pos="punct" morph="none" start_char="3195" end_char="3195">,</TOKEN>
<TOKEN id="token-35-19" pos="word" morph="none" start_char="3197" end_char="3199">and</TOKEN>
<TOKEN id="token-35-20" pos="word" morph="none" start_char="3201" end_char="3203">now</TOKEN>
<TOKEN id="token-35-21" pos="word" morph="none" start_char="3205" end_char="3208">it's</TOKEN>
<TOKEN id="token-35-22" pos="word" morph="none" start_char="3210" end_char="3214">clear</TOKEN>
<TOKEN id="token-35-23" pos="word" morph="none" start_char="3216" end_char="3219">that</TOKEN>
<TOKEN id="token-35-24" pos="word" morph="none" start_char="3221" end_char="3223">the</TOKEN>
<TOKEN id="token-35-25" pos="word" morph="none" start_char="3225" end_char="3229">virus</TOKEN>
<TOKEN id="token-35-26" pos="word" morph="none" start_char="3231" end_char="3232">is</TOKEN>
<TOKEN id="token-35-27" pos="word" morph="none" start_char="3234" end_char="3242">primarily</TOKEN>
<TOKEN id="token-35-28" pos="word" morph="none" start_char="3244" end_char="3252">spreading</TOKEN>
<TOKEN id="token-35-29" pos="unknown" morph="none" start_char="3254" end_char="3269">person-to-person</TOKEN>
<TOKEN id="token-35-30" pos="punct" morph="none" start_char="3270" end_char="3270">,</TOKEN>
<TOKEN id="token-35-31" pos="word" morph="none" start_char="3272" end_char="3275">says</TOKEN>
<TOKEN id="token-35-32" pos="word" morph="none" start_char="3277" end_char="3279">the</TOKEN>
<TOKEN id="token-35-33" pos="word" morph="none" start_char="3281" end_char="3283">CDC</TOKEN>
<TOKEN id="token-35-34" pos="punct" morph="none" start_char="3284" end_char="3284">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="3287" end_char="3448">
<ORIGINAL_TEXT>Is it possible that the novel coronavirus began with an infected animal at the market—and then went on to person-to-person transmission once people were infected?</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="3287" end_char="3288">Is</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="3290" end_char="3291">it</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="3293" end_char="3300">possible</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="3302" end_char="3305">that</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="3307" end_char="3309">the</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="3311" end_char="3315">novel</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="3317" end_char="3327">coronavirus</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="3329" end_char="3333">began</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="3335" end_char="3338">with</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="3340" end_char="3341">an</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="3343" end_char="3350">infected</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="3352" end_char="3357">animal</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="3359" end_char="3360">at</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="3362" end_char="3364">the</TOKEN>
<TOKEN id="token-36-14" pos="unknown" morph="none" start_char="3366" end_char="3375">market—and</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="3377" end_char="3380">then</TOKEN>
<TOKEN id="token-36-16" pos="word" morph="none" start_char="3382" end_char="3385">went</TOKEN>
<TOKEN id="token-36-17" pos="word" morph="none" start_char="3387" end_char="3388">on</TOKEN>
<TOKEN id="token-36-18" pos="word" morph="none" start_char="3390" end_char="3391">to</TOKEN>
<TOKEN id="token-36-19" pos="unknown" morph="none" start_char="3393" end_char="3408">person-to-person</TOKEN>
<TOKEN id="token-36-20" pos="word" morph="none" start_char="3410" end_char="3421">transmission</TOKEN>
<TOKEN id="token-36-21" pos="word" morph="none" start_char="3423" end_char="3426">once</TOKEN>
<TOKEN id="token-36-22" pos="word" morph="none" start_char="3428" end_char="3433">people</TOKEN>
<TOKEN id="token-36-23" pos="word" morph="none" start_char="3435" end_char="3438">were</TOKEN>
<TOKEN id="token-36-24" pos="word" morph="none" start_char="3440" end_char="3447">infected</TOKEN>
<TOKEN id="token-36-25" pos="punct" morph="none" start_char="3448" end_char="3448">?</TOKEN>
</SEG>
<SEG id="segment-37" start_char="3450" end_char="3732">
<ORIGINAL_TEXT>While experts still haven't pinpointed the actual source, new research released online by the CDC on April 21 concludes that SARS-CoV-2 "is probably a novel recombinant virus"—one that has features closely related to coronaviruses found in bats and pangolins (scaly-skinned mammals).</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="3450" end_char="3454">While</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="3456" end_char="3462">experts</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="3464" end_char="3468">still</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="3470" end_char="3476">haven't</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="3478" end_char="3487">pinpointed</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="3489" end_char="3491">the</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="3493" end_char="3498">actual</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="3500" end_char="3505">source</TOKEN>
<TOKEN id="token-37-8" pos="punct" morph="none" start_char="3506" end_char="3506">,</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="3508" end_char="3510">new</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="3512" end_char="3519">research</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="3521" end_char="3528">released</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="3530" end_char="3535">online</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="3537" end_char="3538">by</TOKEN>
<TOKEN id="token-37-14" pos="word" morph="none" start_char="3540" end_char="3542">the</TOKEN>
<TOKEN id="token-37-15" pos="word" morph="none" start_char="3544" end_char="3546">CDC</TOKEN>
<TOKEN id="token-37-16" pos="word" morph="none" start_char="3548" end_char="3549">on</TOKEN>
<TOKEN id="token-37-17" pos="word" morph="none" start_char="3551" end_char="3555">April</TOKEN>
<TOKEN id="token-37-18" pos="word" morph="none" start_char="3557" end_char="3558">21</TOKEN>
<TOKEN id="token-37-19" pos="word" morph="none" start_char="3560" end_char="3568">concludes</TOKEN>
<TOKEN id="token-37-20" pos="word" morph="none" start_char="3570" end_char="3573">that</TOKEN>
<TOKEN id="token-37-21" pos="unknown" morph="none" start_char="3575" end_char="3584">SARS-CoV-2</TOKEN>
<TOKEN id="token-37-22" pos="punct" morph="none" start_char="3586" end_char="3586">"</TOKEN>
<TOKEN id="token-37-23" pos="word" morph="none" start_char="3587" end_char="3588">is</TOKEN>
<TOKEN id="token-37-24" pos="word" morph="none" start_char="3590" end_char="3597">probably</TOKEN>
<TOKEN id="token-37-25" pos="word" morph="none" start_char="3599" end_char="3599">a</TOKEN>
<TOKEN id="token-37-26" pos="word" morph="none" start_char="3601" end_char="3605">novel</TOKEN>
<TOKEN id="token-37-27" pos="word" morph="none" start_char="3607" end_char="3617">recombinant</TOKEN>
<TOKEN id="token-37-28" pos="unknown" morph="none" start_char="3619" end_char="3628">virus"—one</TOKEN>
<TOKEN id="token-37-29" pos="word" morph="none" start_char="3630" end_char="3633">that</TOKEN>
<TOKEN id="token-37-30" pos="word" morph="none" start_char="3635" end_char="3637">has</TOKEN>
<TOKEN id="token-37-31" pos="word" morph="none" start_char="3639" end_char="3646">features</TOKEN>
<TOKEN id="token-37-32" pos="word" morph="none" start_char="3648" end_char="3654">closely</TOKEN>
<TOKEN id="token-37-33" pos="word" morph="none" start_char="3656" end_char="3662">related</TOKEN>
<TOKEN id="token-37-34" pos="word" morph="none" start_char="3664" end_char="3665">to</TOKEN>
<TOKEN id="token-37-35" pos="word" morph="none" start_char="3667" end_char="3679">coronaviruses</TOKEN>
<TOKEN id="token-37-36" pos="word" morph="none" start_char="3681" end_char="3685">found</TOKEN>
<TOKEN id="token-37-37" pos="word" morph="none" start_char="3687" end_char="3688">in</TOKEN>
<TOKEN id="token-37-38" pos="word" morph="none" start_char="3690" end_char="3693">bats</TOKEN>
<TOKEN id="token-37-39" pos="word" morph="none" start_char="3695" end_char="3697">and</TOKEN>
<TOKEN id="token-37-40" pos="word" morph="none" start_char="3699" end_char="3707">pangolins</TOKEN>
<TOKEN id="token-37-41" pos="punct" morph="none" start_char="3709" end_char="3709">(</TOKEN>
<TOKEN id="token-37-42" pos="unknown" morph="none" start_char="3710" end_char="3722">scaly-skinned</TOKEN>
<TOKEN id="token-37-43" pos="word" morph="none" start_char="3724" end_char="3730">mammals</TOKEN>
<TOKEN id="token-37-44" pos="punct" morph="none" start_char="3731" end_char="3732">).</TOKEN>
</SEG>
<SEG id="segment-38" start_char="3735" end_char="3966">
<ORIGINAL_TEXT>However, none of the existing coronaviruses represents its immediate ancestor, notes Susanna K. P. Lau, MBBS, MD, head of microbiology at the University of Hong Kong, and colleagues, who analyzed the genome of the novel coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="3735" end_char="3741">However</TOKEN>
<TOKEN id="token-38-1" pos="punct" morph="none" start_char="3742" end_char="3742">,</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="3744" end_char="3747">none</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="3749" end_char="3750">of</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="3752" end_char="3754">the</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="3756" end_char="3763">existing</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="3765" end_char="3777">coronaviruses</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="3779" end_char="3788">represents</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="3790" end_char="3792">its</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="3794" end_char="3802">immediate</TOKEN>
<TOKEN id="token-38-10" pos="word" morph="none" start_char="3804" end_char="3811">ancestor</TOKEN>
<TOKEN id="token-38-11" pos="punct" morph="none" start_char="3812" end_char="3812">,</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="3814" end_char="3818">notes</TOKEN>
<TOKEN id="token-38-13" pos="word" morph="none" start_char="3820" end_char="3826">Susanna</TOKEN>
<TOKEN id="token-38-14" pos="word" morph="none" start_char="3828" end_char="3828">K</TOKEN>
<TOKEN id="token-38-15" pos="punct" morph="none" start_char="3829" end_char="3829">.</TOKEN>
<TOKEN id="token-38-16" pos="word" morph="none" start_char="3831" end_char="3831">P</TOKEN>
<TOKEN id="token-38-17" pos="punct" morph="none" start_char="3832" end_char="3832">.</TOKEN>
<TOKEN id="token-38-18" pos="word" morph="none" start_char="3834" end_char="3836">Lau</TOKEN>
<TOKEN id="token-38-19" pos="punct" morph="none" start_char="3837" end_char="3837">,</TOKEN>
<TOKEN id="token-38-20" pos="word" morph="none" start_char="3839" end_char="3842">MBBS</TOKEN>
<TOKEN id="token-38-21" pos="punct" morph="none" start_char="3843" end_char="3843">,</TOKEN>
<TOKEN id="token-38-22" pos="word" morph="none" start_char="3845" end_char="3846">MD</TOKEN>
<TOKEN id="token-38-23" pos="punct" morph="none" start_char="3847" end_char="3847">,</TOKEN>
<TOKEN id="token-38-24" pos="word" morph="none" start_char="3849" end_char="3852">head</TOKEN>
<TOKEN id="token-38-25" pos="word" morph="none" start_char="3854" end_char="3855">of</TOKEN>
<TOKEN id="token-38-26" pos="word" morph="none" start_char="3857" end_char="3868">microbiology</TOKEN>
<TOKEN id="token-38-27" pos="word" morph="none" start_char="3870" end_char="3871">at</TOKEN>
<TOKEN id="token-38-28" pos="word" morph="none" start_char="3873" end_char="3875">the</TOKEN>
<TOKEN id="token-38-29" pos="word" morph="none" start_char="3877" end_char="3886">University</TOKEN>
<TOKEN id="token-38-30" pos="word" morph="none" start_char="3888" end_char="3889">of</TOKEN>
<TOKEN id="token-38-31" pos="word" morph="none" start_char="3891" end_char="3894">Hong</TOKEN>
<TOKEN id="token-38-32" pos="word" morph="none" start_char="3896" end_char="3899">Kong</TOKEN>
<TOKEN id="token-38-33" pos="punct" morph="none" start_char="3900" end_char="3900">,</TOKEN>
<TOKEN id="token-38-34" pos="word" morph="none" start_char="3902" end_char="3904">and</TOKEN>
<TOKEN id="token-38-35" pos="word" morph="none" start_char="3906" end_char="3915">colleagues</TOKEN>
<TOKEN id="token-38-36" pos="punct" morph="none" start_char="3916" end_char="3916">,</TOKEN>
<TOKEN id="token-38-37" pos="word" morph="none" start_char="3918" end_char="3920">who</TOKEN>
<TOKEN id="token-38-38" pos="word" morph="none" start_char="3922" end_char="3929">analyzed</TOKEN>
<TOKEN id="token-38-39" pos="word" morph="none" start_char="3931" end_char="3933">the</TOKEN>
<TOKEN id="token-38-40" pos="word" morph="none" start_char="3935" end_char="3940">genome</TOKEN>
<TOKEN id="token-38-41" pos="word" morph="none" start_char="3942" end_char="3943">of</TOKEN>
<TOKEN id="token-38-42" pos="word" morph="none" start_char="3945" end_char="3947">the</TOKEN>
<TOKEN id="token-38-43" pos="word" morph="none" start_char="3949" end_char="3953">novel</TOKEN>
<TOKEN id="token-38-44" pos="word" morph="none" start_char="3955" end_char="3965">coronavirus</TOKEN>
<TOKEN id="token-38-45" pos="punct" morph="none" start_char="3966" end_char="3966">.</TOKEN>
</SEG>
<SEG id="segment-39" start_char="3969" end_char="4098">
<ORIGINAL_TEXT>"Although the Wuhan market was initially suspected to be the epicenter of the epidemic, the immediate source remains elusive," Dr.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="punct" morph="none" start_char="3969" end_char="3969">"</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="3970" end_char="3977">Although</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="3979" end_char="3981">the</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="3983" end_char="3987">Wuhan</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="3989" end_char="3994">market</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="3996" end_char="3998">was</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="4000" end_char="4008">initially</TOKEN>
<TOKEN id="token-39-7" pos="word" morph="none" start_char="4010" end_char="4018">suspected</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="4020" end_char="4021">to</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="4023" end_char="4024">be</TOKEN>
<TOKEN id="token-39-10" pos="word" morph="none" start_char="4026" end_char="4028">the</TOKEN>
<TOKEN id="token-39-11" pos="word" morph="none" start_char="4030" end_char="4038">epicenter</TOKEN>
<TOKEN id="token-39-12" pos="word" morph="none" start_char="4040" end_char="4041">of</TOKEN>
<TOKEN id="token-39-13" pos="word" morph="none" start_char="4043" end_char="4045">the</TOKEN>
<TOKEN id="token-39-14" pos="word" morph="none" start_char="4047" end_char="4054">epidemic</TOKEN>
<TOKEN id="token-39-15" pos="punct" morph="none" start_char="4055" end_char="4055">,</TOKEN>
<TOKEN id="token-39-16" pos="word" morph="none" start_char="4057" end_char="4059">the</TOKEN>
<TOKEN id="token-39-17" pos="word" morph="none" start_char="4061" end_char="4069">immediate</TOKEN>
<TOKEN id="token-39-18" pos="word" morph="none" start_char="4071" end_char="4076">source</TOKEN>
<TOKEN id="token-39-19" pos="word" morph="none" start_char="4078" end_char="4084">remains</TOKEN>
<TOKEN id="token-39-20" pos="word" morph="none" start_char="4086" end_char="4092">elusive</TOKEN>
<TOKEN id="token-39-21" pos="punct" morph="none" start_char="4093" end_char="4094">,"</TOKEN>
<TOKEN id="token-39-22" pos="word" morph="none" start_char="4096" end_char="4097">Dr</TOKEN>
<TOKEN id="token-39-23" pos="punct" morph="none" start_char="4098" end_char="4098">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="4100" end_char="4124">
<ORIGINAL_TEXT>Lau and colleagues write.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="4100" end_char="4102">Lau</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="4104" end_char="4106">and</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="4108" end_char="4117">colleagues</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="4119" end_char="4123">write</TOKEN>
<TOKEN id="token-40-4" pos="punct" morph="none" start_char="4124" end_char="4124">.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="4126" end_char="4296">
<ORIGINAL_TEXT>If the Wuhan market were the source, it's possible, they say, that bats carrying the bat coronavirus were mixed in the market, enabling a new combination virus to develop.</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="4126" end_char="4127">If</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="4129" end_char="4131">the</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="4133" end_char="4137">Wuhan</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="4139" end_char="4144">market</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="4146" end_char="4149">were</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="4151" end_char="4153">the</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="4155" end_char="4160">source</TOKEN>
<TOKEN id="token-41-7" pos="punct" morph="none" start_char="4161" end_char="4161">,</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="4163" end_char="4166">it's</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="4168" end_char="4175">possible</TOKEN>
<TOKEN id="token-41-10" pos="punct" morph="none" start_char="4176" end_char="4176">,</TOKEN>
<TOKEN id="token-41-11" pos="word" morph="none" start_char="4178" end_char="4181">they</TOKEN>
<TOKEN id="token-41-12" pos="word" morph="none" start_char="4183" end_char="4185">say</TOKEN>
<TOKEN id="token-41-13" pos="punct" morph="none" start_char="4186" end_char="4186">,</TOKEN>
<TOKEN id="token-41-14" pos="word" morph="none" start_char="4188" end_char="4191">that</TOKEN>
<TOKEN id="token-41-15" pos="word" morph="none" start_char="4193" end_char="4196">bats</TOKEN>
<TOKEN id="token-41-16" pos="word" morph="none" start_char="4198" end_char="4205">carrying</TOKEN>
<TOKEN id="token-41-17" pos="word" morph="none" start_char="4207" end_char="4209">the</TOKEN>
<TOKEN id="token-41-18" pos="word" morph="none" start_char="4211" end_char="4213">bat</TOKEN>
<TOKEN id="token-41-19" pos="word" morph="none" start_char="4215" end_char="4225">coronavirus</TOKEN>
<TOKEN id="token-41-20" pos="word" morph="none" start_char="4227" end_char="4230">were</TOKEN>
<TOKEN id="token-41-21" pos="word" morph="none" start_char="4232" end_char="4236">mixed</TOKEN>
<TOKEN id="token-41-22" pos="word" morph="none" start_char="4238" end_char="4239">in</TOKEN>
<TOKEN id="token-41-23" pos="word" morph="none" start_char="4241" end_char="4243">the</TOKEN>
<TOKEN id="token-41-24" pos="word" morph="none" start_char="4245" end_char="4250">market</TOKEN>
<TOKEN id="token-41-25" pos="punct" morph="none" start_char="4251" end_char="4251">,</TOKEN>
<TOKEN id="token-41-26" pos="word" morph="none" start_char="4253" end_char="4260">enabling</TOKEN>
<TOKEN id="token-41-27" pos="word" morph="none" start_char="4262" end_char="4262">a</TOKEN>
<TOKEN id="token-41-28" pos="word" morph="none" start_char="4264" end_char="4266">new</TOKEN>
<TOKEN id="token-41-29" pos="word" morph="none" start_char="4268" end_char="4278">combination</TOKEN>
<TOKEN id="token-41-30" pos="word" morph="none" start_char="4280" end_char="4284">virus</TOKEN>
<TOKEN id="token-41-31" pos="word" morph="none" start_char="4286" end_char="4287">to</TOKEN>
<TOKEN id="token-41-32" pos="word" morph="none" start_char="4289" end_char="4295">develop</TOKEN>
<TOKEN id="token-41-33" pos="punct" morph="none" start_char="4296" end_char="4296">.</TOKEN>
</SEG>
<SEG id="segment-42" start_char="4298" end_char="4392">
<ORIGINAL_TEXT>"However, no animal samples from the market were reported to be positive," the team points out.</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="punct" morph="none" start_char="4298" end_char="4298">"</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="4299" end_char="4305">However</TOKEN>
<TOKEN id="token-42-2" pos="punct" morph="none" start_char="4306" end_char="4306">,</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="4308" end_char="4309">no</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="4311" end_char="4316">animal</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="4318" end_char="4324">samples</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="4326" end_char="4329">from</TOKEN>
<TOKEN id="token-42-7" pos="word" morph="none" start_char="4331" end_char="4333">the</TOKEN>
<TOKEN id="token-42-8" pos="word" morph="none" start_char="4335" end_char="4340">market</TOKEN>
<TOKEN id="token-42-9" pos="word" morph="none" start_char="4342" end_char="4345">were</TOKEN>
<TOKEN id="token-42-10" pos="word" morph="none" start_char="4347" end_char="4354">reported</TOKEN>
<TOKEN id="token-42-11" pos="word" morph="none" start_char="4356" end_char="4357">to</TOKEN>
<TOKEN id="token-42-12" pos="word" morph="none" start_char="4359" end_char="4360">be</TOKEN>
<TOKEN id="token-42-13" pos="word" morph="none" start_char="4362" end_char="4369">positive</TOKEN>
<TOKEN id="token-42-14" pos="punct" morph="none" start_char="4370" end_char="4371">,"</TOKEN>
<TOKEN id="token-42-15" pos="word" morph="none" start_char="4373" end_char="4375">the</TOKEN>
<TOKEN id="token-42-16" pos="word" morph="none" start_char="4377" end_char="4380">team</TOKEN>
<TOKEN id="token-42-17" pos="word" morph="none" start_char="4382" end_char="4387">points</TOKEN>
<TOKEN id="token-42-18" pos="word" morph="none" start_char="4389" end_char="4391">out</TOKEN>
<TOKEN id="token-42-19" pos="punct" morph="none" start_char="4392" end_char="4392">.</TOKEN>
</SEG>
<SEG id="segment-43" start_char="4394" end_char="4554">
<ORIGINAL_TEXT>What's more, neither the first identified case in a human nor other early patients had visited the market, "suggesting the possibility of an alternative source."</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="4394" end_char="4399">What's</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="4401" end_char="4404">more</TOKEN>
<TOKEN id="token-43-2" pos="punct" morph="none" start_char="4405" end_char="4405">,</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="4407" end_char="4413">neither</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="4415" end_char="4417">the</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="4419" end_char="4423">first</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="4425" end_char="4434">identified</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="4436" end_char="4439">case</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="4441" end_char="4442">in</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="4444" end_char="4444">a</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="4446" end_char="4450">human</TOKEN>
<TOKEN id="token-43-11" pos="word" morph="none" start_char="4452" end_char="4454">nor</TOKEN>
<TOKEN id="token-43-12" pos="word" morph="none" start_char="4456" end_char="4460">other</TOKEN>
<TOKEN id="token-43-13" pos="word" morph="none" start_char="4462" end_char="4466">early</TOKEN>
<TOKEN id="token-43-14" pos="word" morph="none" start_char="4468" end_char="4475">patients</TOKEN>
<TOKEN id="token-43-15" pos="word" morph="none" start_char="4477" end_char="4479">had</TOKEN>
<TOKEN id="token-43-16" pos="word" morph="none" start_char="4481" end_char="4487">visited</TOKEN>
<TOKEN id="token-43-17" pos="word" morph="none" start_char="4489" end_char="4491">the</TOKEN>
<TOKEN id="token-43-18" pos="word" morph="none" start_char="4493" end_char="4498">market</TOKEN>
<TOKEN id="token-43-19" pos="punct" morph="none" start_char="4499" end_char="4499">,</TOKEN>
<TOKEN id="token-43-20" pos="punct" morph="none" start_char="4501" end_char="4501">"</TOKEN>
<TOKEN id="token-43-21" pos="word" morph="none" start_char="4502" end_char="4511">suggesting</TOKEN>
<TOKEN id="token-43-22" pos="word" morph="none" start_char="4513" end_char="4515">the</TOKEN>
<TOKEN id="token-43-23" pos="word" morph="none" start_char="4517" end_char="4527">possibility</TOKEN>
<TOKEN id="token-43-24" pos="word" morph="none" start_char="4529" end_char="4530">of</TOKEN>
<TOKEN id="token-43-25" pos="word" morph="none" start_char="4532" end_char="4533">an</TOKEN>
<TOKEN id="token-43-26" pos="word" morph="none" start_char="4535" end_char="4545">alternative</TOKEN>
<TOKEN id="token-43-27" pos="word" morph="none" start_char="4547" end_char="4552">source</TOKEN>
<TOKEN id="token-43-28" pos="punct" morph="none" start_char="4553" end_char="4554">."</TOKEN>
</SEG>
<SEG id="segment-44" start_char="4557" end_char="4559">
<ORIGINAL_TEXT>Dr.</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="4557" end_char="4558">Dr</TOKEN>
<TOKEN id="token-44-1" pos="punct" morph="none" start_char="4559" end_char="4559">.</TOKEN>
</SEG>
<SEG id="segment-45" start_char="4561" end_char="4635">
<ORIGINAL_TEXT>Lau and colleagues' study, released ahead of publication in the CDC journal</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="4561" end_char="4563">Lau</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="4565" end_char="4567">and</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="4569" end_char="4578">colleagues</TOKEN>
<TOKEN id="token-45-3" pos="punct" morph="none" start_char="4579" end_char="4579">'</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="4581" end_char="4585">study</TOKEN>
<TOKEN id="token-45-5" pos="punct" morph="none" start_char="4586" end_char="4586">,</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="4588" end_char="4595">released</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="4597" end_char="4601">ahead</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="4603" end_char="4604">of</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="4606" end_char="4616">publication</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="4618" end_char="4619">in</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="4621" end_char="4623">the</TOKEN>
<TOKEN id="token-45-12" pos="word" morph="none" start_char="4625" end_char="4627">CDC</TOKEN>
<TOKEN id="token-45-13" pos="word" morph="none" start_char="4629" end_char="4635">journal</TOKEN>
</SEG>
<SEG id="segment-46" start_char="4638" end_char="4665">
<ORIGINAL_TEXT>Emerging Infectious Diseases</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="4638" end_char="4645">Emerging</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="4647" end_char="4656">Infectious</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="4658" end_char="4665">Diseases</TOKEN>
</SEG>
<SEG id="segment-47" start_char="4668" end_char="4846">
<ORIGINAL_TEXT>, also throws cold water on an Internet rumor that the virus may have been created in a lab: "there is currently no evidence showing that SARS-CoV-2 is an artificial recombinant."</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="punct" morph="none" start_char="4668" end_char="4668">,</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="4670" end_char="4673">also</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="4675" end_char="4680">throws</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="4682" end_char="4685">cold</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="4687" end_char="4691">water</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="4693" end_char="4694">on</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="4696" end_char="4697">an</TOKEN>
<TOKEN id="token-47-7" pos="word" morph="none" start_char="4699" end_char="4706">Internet</TOKEN>
<TOKEN id="token-47-8" pos="word" morph="none" start_char="4708" end_char="4712">rumor</TOKEN>
<TOKEN id="token-47-9" pos="word" morph="none" start_char="4714" end_char="4717">that</TOKEN>
<TOKEN id="token-47-10" pos="word" morph="none" start_char="4719" end_char="4721">the</TOKEN>
<TOKEN id="token-47-11" pos="word" morph="none" start_char="4723" end_char="4727">virus</TOKEN>
<TOKEN id="token-47-12" pos="word" morph="none" start_char="4729" end_char="4731">may</TOKEN>
<TOKEN id="token-47-13" pos="word" morph="none" start_char="4733" end_char="4736">have</TOKEN>
<TOKEN id="token-47-14" pos="word" morph="none" start_char="4738" end_char="4741">been</TOKEN>
<TOKEN id="token-47-15" pos="word" morph="none" start_char="4743" end_char="4749">created</TOKEN>
<TOKEN id="token-47-16" pos="word" morph="none" start_char="4751" end_char="4752">in</TOKEN>
<TOKEN id="token-47-17" pos="word" morph="none" start_char="4754" end_char="4754">a</TOKEN>
<TOKEN id="token-47-18" pos="word" morph="none" start_char="4756" end_char="4758">lab</TOKEN>
<TOKEN id="token-47-19" pos="punct" morph="none" start_char="4759" end_char="4759">:</TOKEN>
<TOKEN id="token-47-20" pos="punct" morph="none" start_char="4761" end_char="4761">"</TOKEN>
<TOKEN id="token-47-21" pos="word" morph="none" start_char="4762" end_char="4766">there</TOKEN>
<TOKEN id="token-47-22" pos="word" morph="none" start_char="4768" end_char="4769">is</TOKEN>
<TOKEN id="token-47-23" pos="word" morph="none" start_char="4771" end_char="4779">currently</TOKEN>
<TOKEN id="token-47-24" pos="word" morph="none" start_char="4781" end_char="4782">no</TOKEN>
<TOKEN id="token-47-25" pos="word" morph="none" start_char="4784" end_char="4791">evidence</TOKEN>
<TOKEN id="token-47-26" pos="word" morph="none" start_char="4793" end_char="4799">showing</TOKEN>
<TOKEN id="token-47-27" pos="word" morph="none" start_char="4801" end_char="4804">that</TOKEN>
<TOKEN id="token-47-28" pos="unknown" morph="none" start_char="4806" end_char="4815">SARS-CoV-2</TOKEN>
<TOKEN id="token-47-29" pos="word" morph="none" start_char="4817" end_char="4818">is</TOKEN>
<TOKEN id="token-47-30" pos="word" morph="none" start_char="4820" end_char="4821">an</TOKEN>
<TOKEN id="token-47-31" pos="word" morph="none" start_char="4823" end_char="4832">artificial</TOKEN>
<TOKEN id="token-47-32" pos="word" morph="none" start_char="4834" end_char="4844">recombinant</TOKEN>
<TOKEN id="token-47-33" pos="punct" morph="none" start_char="4845" end_char="4846">."</TOKEN>
</SEG>
<SEG id="segment-48" start_char="4849" end_char="4871">
<ORIGINAL_TEXT>Another recent paper in</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="4849" end_char="4855">Another</TOKEN>
<TOKEN id="token-48-1" pos="word" morph="none" start_char="4857" end_char="4862">recent</TOKEN>
<TOKEN id="token-48-2" pos="word" morph="none" start_char="4864" end_char="4868">paper</TOKEN>
<TOKEN id="token-48-3" pos="word" morph="none" start_char="4870" end_char="4871">in</TOKEN>
</SEG>
<SEG id="segment-49" start_char="4874" end_char="4888">
<ORIGINAL_TEXT>Nature Medicine</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="4874" end_char="4879">Nature</TOKEN>
<TOKEN id="token-49-1" pos="word" morph="none" start_char="4881" end_char="4888">Medicine</TOKEN>
</SEG>
<SEG id="segment-50" start_char="4891" end_char="4913">
<ORIGINAL_TEXT>underscores that point.</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="4891" end_char="4901">underscores</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="4903" end_char="4906">that</TOKEN>
<TOKEN id="token-50-2" pos="word" morph="none" start_char="4908" end_char="4912">point</TOKEN>
<TOKEN id="token-50-3" pos="punct" morph="none" start_char="4913" end_char="4913">.</TOKEN>
</SEG>
<SEG id="segment-51" start_char="4915" end_char="5230">
<ORIGINAL_TEXT>"By comparing the available genome sequence data for known coronavirus strains, we can firmly determine that SARS-CoV-2 originated through natural processes," Kristian Andersen, PhD, an associate professor of immunology and microbiology at Scripps Research and corresponding author on the paper, said in a statement.</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="punct" morph="none" start_char="4915" end_char="4915">"</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="4916" end_char="4917">By</TOKEN>
<TOKEN id="token-51-2" pos="word" morph="none" start_char="4919" end_char="4927">comparing</TOKEN>
<TOKEN id="token-51-3" pos="word" morph="none" start_char="4929" end_char="4931">the</TOKEN>
<TOKEN id="token-51-4" pos="word" morph="none" start_char="4933" end_char="4941">available</TOKEN>
<TOKEN id="token-51-5" pos="word" morph="none" start_char="4943" end_char="4948">genome</TOKEN>
<TOKEN id="token-51-6" pos="word" morph="none" start_char="4950" end_char="4957">sequence</TOKEN>
<TOKEN id="token-51-7" pos="word" morph="none" start_char="4959" end_char="4962">data</TOKEN>
<TOKEN id="token-51-8" pos="word" morph="none" start_char="4964" end_char="4966">for</TOKEN>
<TOKEN id="token-51-9" pos="word" morph="none" start_char="4968" end_char="4972">known</TOKEN>
<TOKEN id="token-51-10" pos="word" morph="none" start_char="4974" end_char="4984">coronavirus</TOKEN>
<TOKEN id="token-51-11" pos="word" morph="none" start_char="4986" end_char="4992">strains</TOKEN>
<TOKEN id="token-51-12" pos="punct" morph="none" start_char="4993" end_char="4993">,</TOKEN>
<TOKEN id="token-51-13" pos="word" morph="none" start_char="4995" end_char="4996">we</TOKEN>
<TOKEN id="token-51-14" pos="word" morph="none" start_char="4998" end_char="5000">can</TOKEN>
<TOKEN id="token-51-15" pos="word" morph="none" start_char="5002" end_char="5007">firmly</TOKEN>
<TOKEN id="token-51-16" pos="word" morph="none" start_char="5009" end_char="5017">determine</TOKEN>
<TOKEN id="token-51-17" pos="word" morph="none" start_char="5019" end_char="5022">that</TOKEN>
<TOKEN id="token-51-18" pos="unknown" morph="none" start_char="5024" end_char="5033">SARS-CoV-2</TOKEN>
<TOKEN id="token-51-19" pos="word" morph="none" start_char="5035" end_char="5044">originated</TOKEN>
<TOKEN id="token-51-20" pos="word" morph="none" start_char="5046" end_char="5052">through</TOKEN>
<TOKEN id="token-51-21" pos="word" morph="none" start_char="5054" end_char="5060">natural</TOKEN>
<TOKEN id="token-51-22" pos="word" morph="none" start_char="5062" end_char="5070">processes</TOKEN>
<TOKEN id="token-51-23" pos="punct" morph="none" start_char="5071" end_char="5072">,"</TOKEN>
<TOKEN id="token-51-24" pos="word" morph="none" start_char="5074" end_char="5081">Kristian</TOKEN>
<TOKEN id="token-51-25" pos="word" morph="none" start_char="5083" end_char="5090">Andersen</TOKEN>
<TOKEN id="token-51-26" pos="punct" morph="none" start_char="5091" end_char="5091">,</TOKEN>
<TOKEN id="token-51-27" pos="word" morph="none" start_char="5093" end_char="5095">PhD</TOKEN>
<TOKEN id="token-51-28" pos="punct" morph="none" start_char="5096" end_char="5096">,</TOKEN>
<TOKEN id="token-51-29" pos="word" morph="none" start_char="5098" end_char="5099">an</TOKEN>
<TOKEN id="token-51-30" pos="word" morph="none" start_char="5101" end_char="5109">associate</TOKEN>
<TOKEN id="token-51-31" pos="word" morph="none" start_char="5111" end_char="5119">professor</TOKEN>
<TOKEN id="token-51-32" pos="word" morph="none" start_char="5121" end_char="5122">of</TOKEN>
<TOKEN id="token-51-33" pos="word" morph="none" start_char="5124" end_char="5133">immunology</TOKEN>
<TOKEN id="token-51-34" pos="word" morph="none" start_char="5135" end_char="5137">and</TOKEN>
<TOKEN id="token-51-35" pos="word" morph="none" start_char="5139" end_char="5150">microbiology</TOKEN>
<TOKEN id="token-51-36" pos="word" morph="none" start_char="5152" end_char="5153">at</TOKEN>
<TOKEN id="token-51-37" pos="word" morph="none" start_char="5155" end_char="5161">Scripps</TOKEN>
<TOKEN id="token-51-38" pos="word" morph="none" start_char="5163" end_char="5170">Research</TOKEN>
<TOKEN id="token-51-39" pos="word" morph="none" start_char="5172" end_char="5174">and</TOKEN>
<TOKEN id="token-51-40" pos="word" morph="none" start_char="5176" end_char="5188">corresponding</TOKEN>
<TOKEN id="token-51-41" pos="word" morph="none" start_char="5190" end_char="5195">author</TOKEN>
<TOKEN id="token-51-42" pos="word" morph="none" start_char="5197" end_char="5198">on</TOKEN>
<TOKEN id="token-51-43" pos="word" morph="none" start_char="5200" end_char="5202">the</TOKEN>
<TOKEN id="token-51-44" pos="word" morph="none" start_char="5204" end_char="5208">paper</TOKEN>
<TOKEN id="token-51-45" pos="punct" morph="none" start_char="5209" end_char="5209">,</TOKEN>
<TOKEN id="token-51-46" pos="word" morph="none" start_char="5211" end_char="5214">said</TOKEN>
<TOKEN id="token-51-47" pos="word" morph="none" start_char="5216" end_char="5217">in</TOKEN>
<TOKEN id="token-51-48" pos="word" morph="none" start_char="5219" end_char="5219">a</TOKEN>
<TOKEN id="token-51-49" pos="word" morph="none" start_char="5221" end_char="5229">statement</TOKEN>
<TOKEN id="token-51-50" pos="punct" morph="none" start_char="5230" end_char="5230">.</TOKEN>
</SEG>
<SEG id="segment-52" start_char="5232" end_char="5304">
<ORIGINAL_TEXT>Andersen and colleagues' research implicates bats and possibly pangolins.</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="5232" end_char="5239">Andersen</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="5241" end_char="5243">and</TOKEN>
<TOKEN id="token-52-2" pos="word" morph="none" start_char="5245" end_char="5254">colleagues</TOKEN>
<TOKEN id="token-52-3" pos="punct" morph="none" start_char="5255" end_char="5255">'</TOKEN>
<TOKEN id="token-52-4" pos="word" morph="none" start_char="5257" end_char="5264">research</TOKEN>
<TOKEN id="token-52-5" pos="word" morph="none" start_char="5266" end_char="5275">implicates</TOKEN>
<TOKEN id="token-52-6" pos="word" morph="none" start_char="5277" end_char="5280">bats</TOKEN>
<TOKEN id="token-52-7" pos="word" morph="none" start_char="5282" end_char="5284">and</TOKEN>
<TOKEN id="token-52-8" pos="word" morph="none" start_char="5286" end_char="5293">possibly</TOKEN>
<TOKEN id="token-52-9" pos="word" morph="none" start_char="5295" end_char="5303">pangolins</TOKEN>
<TOKEN id="token-52-10" pos="punct" morph="none" start_char="5304" end_char="5304">.</TOKEN>
</SEG>
<SEG id="segment-53" start_char="5307" end_char="5371">
<ORIGINAL_TEXT>Overall, the origin of the novel coronavirus is still filled with</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="word" morph="none" start_char="5307" end_char="5313">Overall</TOKEN>
<TOKEN id="token-53-1" pos="punct" morph="none" start_char="5314" end_char="5314">,</TOKEN>
<TOKEN id="token-53-2" pos="word" morph="none" start_char="5316" end_char="5318">the</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="5320" end_char="5325">origin</TOKEN>
<TOKEN id="token-53-4" pos="word" morph="none" start_char="5327" end_char="5328">of</TOKEN>
<TOKEN id="token-53-5" pos="word" morph="none" start_char="5330" end_char="5332">the</TOKEN>
<TOKEN id="token-53-6" pos="word" morph="none" start_char="5334" end_char="5338">novel</TOKEN>
<TOKEN id="token-53-7" pos="word" morph="none" start_char="5340" end_char="5350">coronavirus</TOKEN>
<TOKEN id="token-53-8" pos="word" morph="none" start_char="5352" end_char="5353">is</TOKEN>
<TOKEN id="token-53-9" pos="word" morph="none" start_char="5355" end_char="5359">still</TOKEN>
<TOKEN id="token-53-10" pos="word" morph="none" start_char="5361" end_char="5366">filled</TOKEN>
<TOKEN id="token-53-11" pos="word" morph="none" start_char="5368" end_char="5371">with</TOKEN>
</SEG>
<SEG id="segment-54" start_char="5374" end_char="5381">
<ORIGINAL_TEXT>what-ifs</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="unknown" morph="none" start_char="5374" end_char="5381">what-ifs</TOKEN>
</SEG>
<SEG id="segment-55" start_char="5384" end_char="5386">
<ORIGINAL_TEXT>and</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="word" morph="none" start_char="5384" end_char="5386">and</TOKEN>
</SEG>
<SEG id="segment-56" start_char="5389" end_char="5394">
<ORIGINAL_TEXT>maybes</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="5389" end_char="5394">maybes</TOKEN>
</SEG>
<SEG id="segment-57" start_char="5397" end_char="5549">
<ORIGINAL_TEXT>, but even if bats are partly to blame, the likelihood that "bat soup" played a role is just an extremely misinformed (and potentially xenophobic) rumor.</ORIGINAL_TEXT>
<TOKEN id="token-57-0" pos="punct" morph="none" start_char="5397" end_char="5397">,</TOKEN>
<TOKEN id="token-57-1" pos="word" morph="none" start_char="5399" end_char="5401">but</TOKEN>
<TOKEN id="token-57-2" pos="word" morph="none" start_char="5403" end_char="5406">even</TOKEN>
<TOKEN id="token-57-3" pos="word" morph="none" start_char="5408" end_char="5409">if</TOKEN>
<TOKEN id="token-57-4" pos="word" morph="none" start_char="5411" end_char="5414">bats</TOKEN>
<TOKEN id="token-57-5" pos="word" morph="none" start_char="5416" end_char="5418">are</TOKEN>
<TOKEN id="token-57-6" pos="word" morph="none" start_char="5420" end_char="5425">partly</TOKEN>
<TOKEN id="token-57-7" pos="word" morph="none" start_char="5427" end_char="5428">to</TOKEN>
<TOKEN id="token-57-8" pos="word" morph="none" start_char="5430" end_char="5434">blame</TOKEN>
<TOKEN id="token-57-9" pos="punct" morph="none" start_char="5435" end_char="5435">,</TOKEN>
<TOKEN id="token-57-10" pos="word" morph="none" start_char="5437" end_char="5439">the</TOKEN>
<TOKEN id="token-57-11" pos="word" morph="none" start_char="5441" end_char="5450">likelihood</TOKEN>
<TOKEN id="token-57-12" pos="word" morph="none" start_char="5452" end_char="5455">that</TOKEN>
<TOKEN id="token-57-13" pos="punct" morph="none" start_char="5457" end_char="5457">"</TOKEN>
<TOKEN id="token-57-14" pos="word" morph="none" start_char="5458" end_char="5460">bat</TOKEN>
<TOKEN id="token-57-15" pos="word" morph="none" start_char="5462" end_char="5465">soup</TOKEN>
<TOKEN id="token-57-16" pos="punct" morph="none" start_char="5466" end_char="5466">"</TOKEN>
<TOKEN id="token-57-17" pos="word" morph="none" start_char="5468" end_char="5473">played</TOKEN>
<TOKEN id="token-57-18" pos="word" morph="none" start_char="5475" end_char="5475">a</TOKEN>
<TOKEN id="token-57-19" pos="word" morph="none" start_char="5477" end_char="5480">role</TOKEN>
<TOKEN id="token-57-20" pos="word" morph="none" start_char="5482" end_char="5483">is</TOKEN>
<TOKEN id="token-57-21" pos="word" morph="none" start_char="5485" end_char="5488">just</TOKEN>
<TOKEN id="token-57-22" pos="word" morph="none" start_char="5490" end_char="5491">an</TOKEN>
<TOKEN id="token-57-23" pos="word" morph="none" start_char="5493" end_char="5501">extremely</TOKEN>
<TOKEN id="token-57-24" pos="word" morph="none" start_char="5503" end_char="5513">misinformed</TOKEN>
<TOKEN id="token-57-25" pos="punct" morph="none" start_char="5515" end_char="5515">(</TOKEN>
<TOKEN id="token-57-26" pos="word" morph="none" start_char="5516" end_char="5518">and</TOKEN>
<TOKEN id="token-57-27" pos="word" morph="none" start_char="5520" end_char="5530">potentially</TOKEN>
<TOKEN id="token-57-28" pos="word" morph="none" start_char="5532" end_char="5541">xenophobic</TOKEN>
<TOKEN id="token-57-29" pos="punct" morph="none" start_char="5542" end_char="5542">)</TOKEN>
<TOKEN id="token-57-30" pos="word" morph="none" start_char="5544" end_char="5548">rumor</TOKEN>
<TOKEN id="token-57-31" pos="punct" morph="none" start_char="5549" end_char="5549">.</TOKEN>
</SEG>
<SEG id="segment-58" start_char="5552" end_char="5610">
<ORIGINAL_TEXT>The information in this story is accurate as of press time.</ORIGINAL_TEXT>
<TOKEN id="token-58-0" pos="word" morph="none" start_char="5552" end_char="5554">The</TOKEN>
<TOKEN id="token-58-1" pos="word" morph="none" start_char="5556" end_char="5566">information</TOKEN>
<TOKEN id="token-58-2" pos="word" morph="none" start_char="5568" end_char="5569">in</TOKEN>
<TOKEN id="token-58-3" pos="word" morph="none" start_char="5571" end_char="5574">this</TOKEN>
<TOKEN id="token-58-4" pos="word" morph="none" start_char="5576" end_char="5580">story</TOKEN>
<TOKEN id="token-58-5" pos="word" morph="none" start_char="5582" end_char="5583">is</TOKEN>
<TOKEN id="token-58-6" pos="word" morph="none" start_char="5585" end_char="5592">accurate</TOKEN>
<TOKEN id="token-58-7" pos="word" morph="none" start_char="5594" end_char="5595">as</TOKEN>
<TOKEN id="token-58-8" pos="word" morph="none" start_char="5597" end_char="5598">of</TOKEN>
<TOKEN id="token-58-9" pos="word" morph="none" start_char="5600" end_char="5604">press</TOKEN>
<TOKEN id="token-58-10" pos="word" morph="none" start_char="5606" end_char="5609">time</TOKEN>
<TOKEN id="token-58-11" pos="punct" morph="none" start_char="5610" end_char="5610">.</TOKEN>
</SEG>
<SEG id="segment-59" start_char="5612" end_char="5739">
<ORIGINAL_TEXT>However, as the situation surrounding COVID-19 continues to evolve, it's possible that some data have changed since publication.</ORIGINAL_TEXT>
<TOKEN id="token-59-0" pos="word" morph="none" start_char="5612" end_char="5618">However</TOKEN>
<TOKEN id="token-59-1" pos="punct" morph="none" start_char="5619" end_char="5619">,</TOKEN>
<TOKEN id="token-59-2" pos="word" morph="none" start_char="5621" end_char="5622">as</TOKEN>
<TOKEN id="token-59-3" pos="word" morph="none" start_char="5624" end_char="5626">the</TOKEN>
<TOKEN id="token-59-4" pos="word" morph="none" start_char="5628" end_char="5636">situation</TOKEN>
<TOKEN id="token-59-5" pos="word" morph="none" start_char="5638" end_char="5648">surrounding</TOKEN>
<TOKEN id="token-59-6" pos="unknown" morph="none" start_char="5650" end_char="5657">COVID-19</TOKEN>
<TOKEN id="token-59-7" pos="word" morph="none" start_char="5659" end_char="5667">continues</TOKEN>
<TOKEN id="token-59-8" pos="word" morph="none" start_char="5669" end_char="5670">to</TOKEN>
<TOKEN id="token-59-9" pos="word" morph="none" start_char="5672" end_char="5677">evolve</TOKEN>
<TOKEN id="token-59-10" pos="punct" morph="none" start_char="5678" end_char="5678">,</TOKEN>
<TOKEN id="token-59-11" pos="word" morph="none" start_char="5680" end_char="5683">it's</TOKEN>
<TOKEN id="token-59-12" pos="word" morph="none" start_char="5685" end_char="5692">possible</TOKEN>
<TOKEN id="token-59-13" pos="word" morph="none" start_char="5694" end_char="5697">that</TOKEN>
<TOKEN id="token-59-14" pos="word" morph="none" start_char="5699" end_char="5702">some</TOKEN>
<TOKEN id="token-59-15" pos="word" morph="none" start_char="5704" end_char="5707">data</TOKEN>
<TOKEN id="token-59-16" pos="word" morph="none" start_char="5709" end_char="5712">have</TOKEN>
<TOKEN id="token-59-17" pos="word" morph="none" start_char="5714" end_char="5720">changed</TOKEN>
<TOKEN id="token-59-18" pos="word" morph="none" start_char="5722" end_char="5726">since</TOKEN>
<TOKEN id="token-59-19" pos="word" morph="none" start_char="5728" end_char="5738">publication</TOKEN>
<TOKEN id="token-59-20" pos="punct" morph="none" start_char="5739" end_char="5739">.</TOKEN>
</SEG>
<SEG id="segment-60" start_char="5741" end_char="5984">
<ORIGINAL_TEXT>While Health is trying to keep our stories as up-to-date as possible, we also encourage readers to stay informed on news and recommendations for their own communities by using the CDC, WHO, and their local public health department as resources.</ORIGINAL_TEXT>
<TOKEN id="token-60-0" pos="word" morph="none" start_char="5741" end_char="5745">While</TOKEN>
<TOKEN id="token-60-1" pos="word" morph="none" start_char="5747" end_char="5752">Health</TOKEN>
<TOKEN id="token-60-2" pos="word" morph="none" start_char="5754" end_char="5755">is</TOKEN>
<TOKEN id="token-60-3" pos="word" morph="none" start_char="5757" end_char="5762">trying</TOKEN>
<TOKEN id="token-60-4" pos="word" morph="none" start_char="5764" end_char="5765">to</TOKEN>
<TOKEN id="token-60-5" pos="word" morph="none" start_char="5767" end_char="5770">keep</TOKEN>
<TOKEN id="token-60-6" pos="word" morph="none" start_char="5772" end_char="5774">our</TOKEN>
<TOKEN id="token-60-7" pos="word" morph="none" start_char="5776" end_char="5782">stories</TOKEN>
<TOKEN id="token-60-8" pos="word" morph="none" start_char="5784" end_char="5785">as</TOKEN>
<TOKEN id="token-60-9" pos="unknown" morph="none" start_char="5787" end_char="5796">up-to-date</TOKEN>
<TOKEN id="token-60-10" pos="word" morph="none" start_char="5798" end_char="5799">as</TOKEN>
<TOKEN id="token-60-11" pos="word" morph="none" start_char="5801" end_char="5808">possible</TOKEN>
<TOKEN id="token-60-12" pos="punct" morph="none" start_char="5809" end_char="5809">,</TOKEN>
<TOKEN id="token-60-13" pos="word" morph="none" start_char="5811" end_char="5812">we</TOKEN>
<TOKEN id="token-60-14" pos="word" morph="none" start_char="5814" end_char="5817">also</TOKEN>
<TOKEN id="token-60-15" pos="word" morph="none" start_char="5819" end_char="5827">encourage</TOKEN>
<TOKEN id="token-60-16" pos="word" morph="none" start_char="5829" end_char="5835">readers</TOKEN>
<TOKEN id="token-60-17" pos="word" morph="none" start_char="5837" end_char="5838">to</TOKEN>
<TOKEN id="token-60-18" pos="word" morph="none" start_char="5840" end_char="5843">stay</TOKEN>
<TOKEN id="token-60-19" pos="word" morph="none" start_char="5845" end_char="5852">informed</TOKEN>
<TOKEN id="token-60-20" pos="word" morph="none" start_char="5854" end_char="5855">on</TOKEN>
<TOKEN id="token-60-21" pos="word" morph="none" start_char="5857" end_char="5860">news</TOKEN>
<TOKEN id="token-60-22" pos="word" morph="none" start_char="5862" end_char="5864">and</TOKEN>
<TOKEN id="token-60-23" pos="word" morph="none" start_char="5866" end_char="5880">recommendations</TOKEN>
<TOKEN id="token-60-24" pos="word" morph="none" start_char="5882" end_char="5884">for</TOKEN>
<TOKEN id="token-60-25" pos="word" morph="none" start_char="5886" end_char="5890">their</TOKEN>
<TOKEN id="token-60-26" pos="word" morph="none" start_char="5892" end_char="5894">own</TOKEN>
<TOKEN id="token-60-27" pos="word" morph="none" start_char="5896" end_char="5906">communities</TOKEN>
<TOKEN id="token-60-28" pos="word" morph="none" start_char="5908" end_char="5909">by</TOKEN>
<TOKEN id="token-60-29" pos="word" morph="none" start_char="5911" end_char="5915">using</TOKEN>
<TOKEN id="token-60-30" pos="word" morph="none" start_char="5917" end_char="5919">the</TOKEN>
<TOKEN id="token-60-31" pos="word" morph="none" start_char="5921" end_char="5923">CDC</TOKEN>
<TOKEN id="token-60-32" pos="punct" morph="none" start_char="5924" end_char="5924">,</TOKEN>
<TOKEN id="token-60-33" pos="word" morph="none" start_char="5926" end_char="5928">WHO</TOKEN>
<TOKEN id="token-60-34" pos="punct" morph="none" start_char="5929" end_char="5929">,</TOKEN>
<TOKEN id="token-60-35" pos="word" morph="none" start_char="5931" end_char="5933">and</TOKEN>
<TOKEN id="token-60-36" pos="word" morph="none" start_char="5935" end_char="5939">their</TOKEN>
<TOKEN id="token-60-37" pos="word" morph="none" start_char="5941" end_char="5945">local</TOKEN>
<TOKEN id="token-60-38" pos="word" morph="none" start_char="5947" end_char="5952">public</TOKEN>
<TOKEN id="token-60-39" pos="word" morph="none" start_char="5954" end_char="5959">health</TOKEN>
<TOKEN id="token-60-40" pos="word" morph="none" start_char="5961" end_char="5970">department</TOKEN>
<TOKEN id="token-60-41" pos="word" morph="none" start_char="5972" end_char="5973">as</TOKEN>
<TOKEN id="token-60-42" pos="word" morph="none" start_char="5975" end_char="5983">resources</TOKEN>
<TOKEN id="token-60-43" pos="punct" morph="none" start_char="5984" end_char="5984">.</TOKEN>
</SEG>
<SEG id="segment-61" start_char="5988" end_char="6032">
<ORIGINAL_TEXT>Quiz: How Much Do You Know About Coronavirus?</ORIGINAL_TEXT>
<TOKEN id="token-61-0" pos="word" morph="none" start_char="5988" end_char="5991">Quiz</TOKEN>
<TOKEN id="token-61-1" pos="punct" morph="none" start_char="5992" end_char="5992">:</TOKEN>
<TOKEN id="token-61-2" pos="word" morph="none" start_char="5994" end_char="5996">How</TOKEN>
<TOKEN id="token-61-3" pos="word" morph="none" start_char="5998" end_char="6001">Much</TOKEN>
<TOKEN id="token-61-4" pos="word" morph="none" start_char="6003" end_char="6004">Do</TOKEN>
<TOKEN id="token-61-5" pos="word" morph="none" start_char="6006" end_char="6008">You</TOKEN>
<TOKEN id="token-61-6" pos="word" morph="none" start_char="6010" end_char="6013">Know</TOKEN>
<TOKEN id="token-61-7" pos="word" morph="none" start_char="6015" end_char="6019">About</TOKEN>
<TOKEN id="token-61-8" pos="word" morph="none" start_char="6021" end_char="6031">Coronavirus</TOKEN>
<TOKEN id="token-61-9" pos="punct" morph="none" start_char="6032" end_char="6032">?</TOKEN>
</SEG>
<SEG id="segment-62" start_char="6036" end_char="6255">
<ORIGINAL_TEXT>News about the novel coronavirus is breaking nearly 24-7, which makes it challenging at best to keep up with the latest scientific evidence, especially when you’re bombarded by false or misleading claims on social media.</ORIGINAL_TEXT>
<TOKEN id="token-62-0" pos="word" morph="none" start_char="6036" end_char="6039">News</TOKEN>
<TOKEN id="token-62-1" pos="word" morph="none" start_char="6041" end_char="6045">about</TOKEN>
<TOKEN id="token-62-2" pos="word" morph="none" start_char="6047" end_char="6049">the</TOKEN>
<TOKEN id="token-62-3" pos="word" morph="none" start_char="6051" end_char="6055">novel</TOKEN>
<TOKEN id="token-62-4" pos="word" morph="none" start_char="6057" end_char="6067">coronavirus</TOKEN>
<TOKEN id="token-62-5" pos="word" morph="none" start_char="6069" end_char="6070">is</TOKEN>
<TOKEN id="token-62-6" pos="word" morph="none" start_char="6072" end_char="6079">breaking</TOKEN>
<TOKEN id="token-62-7" pos="word" morph="none" start_char="6081" end_char="6086">nearly</TOKEN>
<TOKEN id="token-62-8" pos="unknown" morph="none" start_char="6088" end_char="6091">24-7</TOKEN>
<TOKEN id="token-62-9" pos="punct" morph="none" start_char="6092" end_char="6092">,</TOKEN>
<TOKEN id="token-62-10" pos="word" morph="none" start_char="6094" end_char="6098">which</TOKEN>
<TOKEN id="token-62-11" pos="word" morph="none" start_char="6100" end_char="6104">makes</TOKEN>
<TOKEN id="token-62-12" pos="word" morph="none" start_char="6106" end_char="6107">it</TOKEN>
<TOKEN id="token-62-13" pos="word" morph="none" start_char="6109" end_char="6119">challenging</TOKEN>
<TOKEN id="token-62-14" pos="word" morph="none" start_char="6121" end_char="6122">at</TOKEN>
<TOKEN id="token-62-15" pos="word" morph="none" start_char="6124" end_char="6127">best</TOKEN>
<TOKEN id="token-62-16" pos="word" morph="none" start_char="6129" end_char="6130">to</TOKEN>
<TOKEN id="token-62-17" pos="word" morph="none" start_char="6132" end_char="6135">keep</TOKEN>
<TOKEN id="token-62-18" pos="word" morph="none" start_char="6137" end_char="6138">up</TOKEN>
<TOKEN id="token-62-19" pos="word" morph="none" start_char="6140" end_char="6143">with</TOKEN>
<TOKEN id="token-62-20" pos="word" morph="none" start_char="6145" end_char="6147">the</TOKEN>
<TOKEN id="token-62-21" pos="word" morph="none" start_char="6149" end_char="6154">latest</TOKEN>
<TOKEN id="token-62-22" pos="word" morph="none" start_char="6156" end_char="6165">scientific</TOKEN>
<TOKEN id="token-62-23" pos="word" morph="none" start_char="6167" end_char="6174">evidence</TOKEN>
<TOKEN id="token-62-24" pos="punct" morph="none" start_char="6175" end_char="6175">,</TOKEN>
<TOKEN id="token-62-25" pos="word" morph="none" start_char="6177" end_char="6186">especially</TOKEN>
<TOKEN id="token-62-26" pos="word" morph="none" start_char="6188" end_char="6191">when</TOKEN>
<TOKEN id="token-62-27" pos="word" morph="none" start_char="6193" end_char="6198">you’re</TOKEN>
<TOKEN id="token-62-28" pos="word" morph="none" start_char="6200" end_char="6208">bombarded</TOKEN>
<TOKEN id="token-62-29" pos="word" morph="none" start_char="6210" end_char="6211">by</TOKEN>
<TOKEN id="token-62-30" pos="word" morph="none" start_char="6213" end_char="6217">false</TOKEN>
<TOKEN id="token-62-31" pos="word" morph="none" start_char="6219" end_char="6220">or</TOKEN>
<TOKEN id="token-62-32" pos="word" morph="none" start_char="6222" end_char="6231">misleading</TOKEN>
<TOKEN id="token-62-33" pos="word" morph="none" start_char="6233" end_char="6238">claims</TOKEN>
<TOKEN id="token-62-34" pos="word" morph="none" start_char="6240" end_char="6241">on</TOKEN>
<TOKEN id="token-62-35" pos="word" morph="none" start_char="6243" end_char="6248">social</TOKEN>
<TOKEN id="token-62-36" pos="word" morph="none" start_char="6250" end_char="6254">media</TOKEN>
<TOKEN id="token-62-37" pos="punct" morph="none" start_char="6255" end_char="6255">.</TOKEN>
</SEG>
<SEG id="segment-63" start_char="6257" end_char="6302">
<ORIGINAL_TEXT>So how much do you really know about COVID-19?</ORIGINAL_TEXT>
<TOKEN id="token-63-0" pos="word" morph="none" start_char="6257" end_char="6258">So</TOKEN>
<TOKEN id="token-63-1" pos="word" morph="none" start_char="6260" end_char="6262">how</TOKEN>
<TOKEN id="token-63-2" pos="word" morph="none" start_char="6264" end_char="6267">much</TOKEN>
<TOKEN id="token-63-3" pos="word" morph="none" start_char="6269" end_char="6270">do</TOKEN>
<TOKEN id="token-63-4" pos="word" morph="none" start_char="6272" end_char="6274">you</TOKEN>
<TOKEN id="token-63-5" pos="word" morph="none" start_char="6276" end_char="6281">really</TOKEN>
<TOKEN id="token-63-6" pos="word" morph="none" start_char="6283" end_char="6286">know</TOKEN>
<TOKEN id="token-63-7" pos="word" morph="none" start_char="6288" end_char="6292">about</TOKEN>
<TOKEN id="token-63-8" pos="unknown" morph="none" start_char="6294" end_char="6301">COVID-19</TOKEN>
<TOKEN id="token-63-9" pos="punct" morph="none" start_char="6302" end_char="6302">?</TOKEN>
</SEG>
<SEG id="segment-64" start_char="6304" end_char="6352">
<ORIGINAL_TEXT>Take our quiz to gauge how knowledgeable you are.</ORIGINAL_TEXT>
<TOKEN id="token-64-0" pos="word" morph="none" start_char="6304" end_char="6307">Take</TOKEN>
<TOKEN id="token-64-1" pos="word" morph="none" start_char="6309" end_char="6311">our</TOKEN>
<TOKEN id="token-64-2" pos="word" morph="none" start_char="6313" end_char="6316">quiz</TOKEN>
<TOKEN id="token-64-3" pos="word" morph="none" start_char="6318" end_char="6319">to</TOKEN>
<TOKEN id="token-64-4" pos="word" morph="none" start_char="6321" end_char="6325">gauge</TOKEN>
<TOKEN id="token-64-5" pos="word" morph="none" start_char="6327" end_char="6329">how</TOKEN>
<TOKEN id="token-64-6" pos="word" morph="none" start_char="6331" end_char="6343">knowledgeable</TOKEN>
<TOKEN id="token-64-7" pos="word" morph="none" start_char="6345" end_char="6347">you</TOKEN>
<TOKEN id="token-64-8" pos="word" morph="none" start_char="6349" end_char="6351">are</TOKEN>
<TOKEN id="token-64-9" pos="punct" morph="none" start_char="6352" end_char="6352">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
