<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CABR" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="9705" raw_text_md5="68cb80409f5ee8368842c016846501fb">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="122">
<ORIGINAL_TEXT>Suspicions mount that the coronavirus was spreading in China and Europe as early as October, following a WHO investigation</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="10">Suspicions</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="12" end_char="16">mount</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="18" end_char="21">that</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="23" end_char="25">the</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="27" end_char="37">coronavirus</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="39" end_char="41">was</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="43" end_char="51">spreading</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="53" end_char="54">in</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="56" end_char="60">China</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="62" end_char="64">and</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="66" end_char="71">Europe</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="73" end_char="74">as</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="76" end_char="80">early</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="82" end_char="83">as</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="85" end_char="91">October</TOKEN>
<TOKEN id="token-0-15" pos="punct" morph="none" start_char="92" end_char="92">,</TOKEN>
<TOKEN id="token-0-16" pos="word" morph="none" start_char="94" end_char="102">following</TOKEN>
<TOKEN id="token-0-17" pos="word" morph="none" start_char="104" end_char="104">a</TOKEN>
<TOKEN id="token-0-18" pos="word" morph="none" start_char="106" end_char="108">WHO</TOKEN>
<TOKEN id="token-0-19" pos="word" morph="none" start_char="110" end_char="122">investigation</TOKEN>
</SEG>
<SEG id="segment-1" start_char="127" end_char="314">
<ORIGINAL_TEXT>A worker in protective coverings directs members of the World Health Organization (WHO) team on their arrival at the airport in Wuhan in central China's Hubei province on January 14, 2021.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="127" end_char="127">A</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="129" end_char="134">worker</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="136" end_char="137">in</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="139" end_char="148">protective</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="150" end_char="158">coverings</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="160" end_char="166">directs</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="168" end_char="174">members</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="176" end_char="177">of</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="179" end_char="181">the</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="183" end_char="187">World</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="189" end_char="194">Health</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="196" end_char="207">Organization</TOKEN>
<TOKEN id="token-1-12" pos="punct" morph="none" start_char="209" end_char="209">(</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="210" end_char="212">WHO</TOKEN>
<TOKEN id="token-1-14" pos="punct" morph="none" start_char="213" end_char="213">)</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="215" end_char="218">team</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="220" end_char="221">on</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="223" end_char="227">their</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="229" end_char="235">arrival</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="237" end_char="238">at</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="240" end_char="242">the</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="244" end_char="250">airport</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="252" end_char="253">in</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="255" end_char="259">Wuhan</TOKEN>
<TOKEN id="token-1-24" pos="word" morph="none" start_char="261" end_char="262">in</TOKEN>
<TOKEN id="token-1-25" pos="word" morph="none" start_char="264" end_char="270">central</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="272" end_char="278">China's</TOKEN>
<TOKEN id="token-1-27" pos="word" morph="none" start_char="280" end_char="284">Hubei</TOKEN>
<TOKEN id="token-1-28" pos="word" morph="none" start_char="286" end_char="293">province</TOKEN>
<TOKEN id="token-1-29" pos="word" morph="none" start_char="295" end_char="296">on</TOKEN>
<TOKEN id="token-1-30" pos="word" morph="none" start_char="298" end_char="304">January</TOKEN>
<TOKEN id="token-1-31" pos="word" morph="none" start_char="306" end_char="307">14</TOKEN>
<TOKEN id="token-1-32" pos="punct" morph="none" start_char="308" end_char="308">,</TOKEN>
<TOKEN id="token-1-33" pos="word" morph="none" start_char="310" end_char="313">2021</TOKEN>
<TOKEN id="token-1-34" pos="punct" morph="none" start_char="314" end_char="314">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="317" end_char="336">
<ORIGINAL_TEXT>AP Photo/Ng Han Guan</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="317" end_char="318">AP</TOKEN>
<TOKEN id="token-2-1" pos="unknown" morph="none" start_char="320" end_char="327">Photo/Ng</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="329" end_char="331">Han</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="333" end_char="336">Guan</TOKEN>
</SEG>
<SEG id="segment-3" start_char="341" end_char="437">
<ORIGINAL_TEXT>Experts from the WHO and China conducted an investigation into the coronavirus' origins in Wuhan.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="341" end_char="347">Experts</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="349" end_char="352">from</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="354" end_char="356">the</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="358" end_char="360">WHO</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="362" end_char="364">and</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="366" end_char="370">China</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="372" end_char="380">conducted</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="382" end_char="383">an</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="385" end_char="397">investigation</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="399" end_char="402">into</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="404" end_char="406">the</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="408" end_char="418">coronavirus</TOKEN>
<TOKEN id="token-3-12" pos="punct" morph="none" start_char="419" end_char="419">'</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="421" end_char="427">origins</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="429" end_char="430">in</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="432" end_char="436">Wuhan</TOKEN>
<TOKEN id="token-3-16" pos="punct" morph="none" start_char="437" end_char="437">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="441" end_char="601">
<ORIGINAL_TEXT>The investigation bolstered findings from studies that suggested the virus was circulating in China and Europe months before officials confirmed the first cases.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="441" end_char="443">The</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="445" end_char="457">investigation</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="459" end_char="467">bolstered</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="469" end_char="476">findings</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="478" end_char="481">from</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="483" end_char="489">studies</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="491" end_char="494">that</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="496" end_char="504">suggested</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="506" end_char="508">the</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="510" end_char="514">virus</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="516" end_char="518">was</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="520" end_char="530">circulating</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="532" end_char="533">in</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="535" end_char="539">China</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="541" end_char="543">and</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="545" end_char="550">Europe</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="552" end_char="557">months</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="559" end_char="564">before</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="566" end_char="574">officials</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="576" end_char="584">confirmed</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="586" end_char="588">the</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="590" end_char="594">first</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="596" end_char="600">cases</TOKEN>
<TOKEN id="token-4-23" pos="punct" morph="none" start_char="601" end_char="601">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="605" end_char="691">
<ORIGINAL_TEXT>One study found that some people in the US had coronavirus antibodies in December 2019.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="605" end_char="607">One</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="609" end_char="613">study</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="615" end_char="619">found</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="621" end_char="624">that</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="626" end_char="629">some</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="631" end_char="636">people</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="638" end_char="639">in</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="641" end_char="643">the</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="645" end_char="646">US</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="648" end_char="650">had</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="652" end_char="662">coronavirus</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="664" end_char="673">antibodies</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="675" end_char="676">in</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="678" end_char="685">December</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="687" end_char="690">2019</TOKEN>
<TOKEN id="token-5-15" pos="punct" morph="none" start_char="691" end_char="691">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="695" end_char="745">
<ORIGINAL_TEXT>Visit Business Insider's homepage for more stories.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="695" end_char="699">Visit</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="701" end_char="708">Business</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="710" end_char="718">Insider's</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="720" end_char="727">homepage</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="729" end_char="731">for</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="733" end_char="736">more</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="738" end_char="744">stories</TOKEN>
<TOKEN id="token-6-7" pos="punct" morph="none" start_char="745" end_char="745">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="750" end_char="912">
<ORIGINAL_TEXT>A growing body of evidence suggests the coronavirus was spreading globally months before the first cases in a Wuhan market captured global attention last December.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="750" end_char="750">A</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="752" end_char="758">growing</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="760" end_char="763">body</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="765" end_char="766">of</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="768" end_char="775">evidence</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="777" end_char="784">suggests</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="786" end_char="788">the</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="790" end_char="800">coronavirus</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="802" end_char="804">was</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="806" end_char="814">spreading</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="816" end_char="823">globally</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="825" end_char="830">months</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="832" end_char="837">before</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="839" end_char="841">the</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="843" end_char="847">first</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="849" end_char="853">cases</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="855" end_char="856">in</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="858" end_char="858">a</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="860" end_char="864">Wuhan</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="866" end_char="871">market</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="873" end_char="880">captured</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="882" end_char="887">global</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="889" end_char="897">attention</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="899" end_char="902">last</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="904" end_char="911">December</TOKEN>
<TOKEN id="token-7-25" pos="punct" morph="none" start_char="912" end_char="912">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="915" end_char="1057">
<ORIGINAL_TEXT>The World Health Organization sent an international team to China in January to investigate the virus' origins and when it started circulating.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="915" end_char="917">The</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="919" end_char="923">World</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="925" end_char="930">Health</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="932" end_char="943">Organization</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="945" end_char="948">sent</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="950" end_char="951">an</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="953" end_char="965">international</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="967" end_char="970">team</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="972" end_char="973">to</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="975" end_char="979">China</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="981" end_char="982">in</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="984" end_char="990">January</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="992" end_char="993">to</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="995" end_char="1005">investigate</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1007" end_char="1009">the</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1011" end_char="1015">virus</TOKEN>
<TOKEN id="token-8-16" pos="punct" morph="none" start_char="1016" end_char="1016">'</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1018" end_char="1024">origins</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1026" end_char="1028">and</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1030" end_char="1033">when</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="1035" end_char="1036">it</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="1038" end_char="1044">started</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="1046" end_char="1056">circulating</TOKEN>
<TOKEN id="token-8-23" pos="punct" morph="none" start_char="1057" end_char="1057">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1060" end_char="1191">
<ORIGINAL_TEXT>The team assessed medical records from more than 230 clinics across Hubei — the province where Wuhan is located — to look for clues.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1060" end_char="1062">The</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1064" end_char="1067">team</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1069" end_char="1076">assessed</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1078" end_char="1084">medical</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1086" end_char="1092">records</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1094" end_char="1097">from</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1099" end_char="1102">more</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1104" end_char="1107">than</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1109" end_char="1111">230</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1113" end_char="1119">clinics</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1121" end_char="1126">across</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1128" end_char="1132">Hubei</TOKEN>
<TOKEN id="token-9-12" pos="punct" morph="none" start_char="1134" end_char="1134">—</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1136" end_char="1138">the</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1140" end_char="1147">province</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1149" end_char="1153">where</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1155" end_char="1159">Wuhan</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1161" end_char="1162">is</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1164" end_char="1170">located</TOKEN>
<TOKEN id="token-9-19" pos="punct" morph="none" start_char="1172" end_char="1172">—</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1174" end_char="1175">to</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1177" end_char="1180">look</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1182" end_char="1184">for</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1186" end_char="1190">clues</TOKEN>
<TOKEN id="token-9-24" pos="punct" morph="none" start_char="1191" end_char="1191">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1193" end_char="1365">
<ORIGINAL_TEXT>More than 90 patients in the province were hospitalized with pneumonia or coronavirus-like symptoms in October and November 2019, the Wall Street Journal reported Wednesday.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1193" end_char="1196">More</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1198" end_char="1201">than</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1203" end_char="1204">90</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1206" end_char="1213">patients</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1215" end_char="1216">in</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1218" end_char="1220">the</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1222" end_char="1229">province</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1231" end_char="1234">were</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1236" end_char="1247">hospitalized</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1249" end_char="1252">with</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1254" end_char="1262">pneumonia</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1264" end_char="1265">or</TOKEN>
<TOKEN id="token-10-12" pos="unknown" morph="none" start_char="1267" end_char="1282">coronavirus-like</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1284" end_char="1291">symptoms</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1293" end_char="1294">in</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1296" end_char="1302">October</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1304" end_char="1306">and</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1308" end_char="1315">November</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1317" end_char="1320">2019</TOKEN>
<TOKEN id="token-10-19" pos="punct" morph="none" start_char="1321" end_char="1321">,</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1323" end_char="1325">the</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1327" end_char="1330">Wall</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1332" end_char="1337">Street</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1339" end_char="1345">Journal</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1347" end_char="1354">reported</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="1356" end_char="1364">Wednesday</TOKEN>
<TOKEN id="token-10-26" pos="punct" morph="none" start_char="1365" end_char="1365">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1368" end_char="1500">
<ORIGINAL_TEXT>This finding lends credence to other research from China that shows people were getting sick in Wuhan in November and early December.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1368" end_char="1371">This</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1373" end_char="1379">finding</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1381" end_char="1385">lends</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1387" end_char="1394">credence</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1396" end_char="1397">to</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1399" end_char="1403">other</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1405" end_char="1412">research</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1414" end_char="1417">from</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1419" end_char="1423">China</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1425" end_char="1428">that</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1430" end_char="1434">shows</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1436" end_char="1441">people</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1443" end_char="1446">were</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1448" end_char="1454">getting</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1456" end_char="1459">sick</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1461" end_char="1462">in</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1464" end_char="1468">Wuhan</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1470" end_char="1471">in</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1473" end_char="1480">November</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="1482" end_char="1484">and</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1486" end_char="1490">early</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="1492" end_char="1499">December</TOKEN>
<TOKEN id="token-11-22" pos="punct" morph="none" start_char="1500" end_char="1500">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1502" end_char="1694">
<ORIGINAL_TEXT>One analysis, based on satellite images of Wuhan hospitals and online searches for COVID-19 symptoms in the area, suggested the virus may have started circulating there as early as late summer.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1502" end_char="1504">One</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1506" end_char="1513">analysis</TOKEN>
<TOKEN id="token-12-2" pos="punct" morph="none" start_char="1514" end_char="1514">,</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1516" end_char="1520">based</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1522" end_char="1523">on</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1525" end_char="1533">satellite</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1535" end_char="1540">images</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1542" end_char="1543">of</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1545" end_char="1549">Wuhan</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1551" end_char="1559">hospitals</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1561" end_char="1563">and</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1565" end_char="1570">online</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1572" end_char="1579">searches</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1581" end_char="1583">for</TOKEN>
<TOKEN id="token-12-14" pos="unknown" morph="none" start_char="1585" end_char="1592">COVID-19</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1594" end_char="1601">symptoms</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1603" end_char="1604">in</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1606" end_char="1608">the</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1610" end_char="1613">area</TOKEN>
<TOKEN id="token-12-19" pos="punct" morph="none" start_char="1614" end_char="1614">,</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1616" end_char="1624">suggested</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1626" end_char="1628">the</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1630" end_char="1634">virus</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="1636" end_char="1638">may</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="1640" end_char="1643">have</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="1645" end_char="1651">started</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="1653" end_char="1663">circulating</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="1665" end_char="1669">there</TOKEN>
<TOKEN id="token-12-28" pos="word" morph="none" start_char="1671" end_char="1672">as</TOKEN>
<TOKEN id="token-12-29" pos="word" morph="none" start_char="1674" end_char="1678">early</TOKEN>
<TOKEN id="token-12-30" pos="word" morph="none" start_char="1680" end_char="1681">as</TOKEN>
<TOKEN id="token-12-31" pos="word" morph="none" start_char="1683" end_char="1686">late</TOKEN>
<TOKEN id="token-12-32" pos="word" morph="none" start_char="1688" end_char="1693">summer</TOKEN>
<TOKEN id="token-12-33" pos="punct" morph="none" start_char="1694" end_char="1694">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1697" end_char="1706">
<ORIGINAL_TEXT>Newsletter</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1697" end_char="1706">Newsletter</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1709" end_char="1752">
<ORIGINAL_TEXT>Get the latest healthcare news and analysis.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1709" end_char="1711">Get</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1713" end_char="1715">the</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1717" end_char="1722">latest</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1724" end_char="1733">healthcare</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1735" end_char="1738">news</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1740" end_char="1742">and</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1744" end_char="1751">analysis</TOKEN>
<TOKEN id="token-14-7" pos="punct" morph="none" start_char="1752" end_char="1752">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1755" end_char="1775">
<ORIGINAL_TEXT>Something is loading.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1755" end_char="1763">Something</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1765" end_char="1766">is</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1768" end_char="1774">loading</TOKEN>
<TOKEN id="token-15-3" pos="punct" morph="none" start_char="1775" end_char="1775">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1779" end_char="1791">
<ORIGINAL_TEXT>Email address</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1779" end_char="1783">Email</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1785" end_char="1791">address</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1794" end_char="1950">
<ORIGINAL_TEXT>By clicking ‘Sign up’, you agree to receive marketing emails from Insider as well as other partner offers and accept our Terms of Service and Privacy Policy.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1794" end_char="1795">By</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1797" end_char="1804">clicking</TOKEN>
<TOKEN id="token-17-2" pos="punct" morph="none" start_char="1806" end_char="1806">‘</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="1807" end_char="1810">Sign</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="1812" end_char="1813">up</TOKEN>
<TOKEN id="token-17-5" pos="punct" morph="none" start_char="1814" end_char="1815">’,</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="1817" end_char="1819">you</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="1821" end_char="1825">agree</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="1827" end_char="1828">to</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="1830" end_char="1836">receive</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="1838" end_char="1846">marketing</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="1848" end_char="1853">emails</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="1855" end_char="1858">from</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="1860" end_char="1866">Insider</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="1868" end_char="1869">as</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="1871" end_char="1874">well</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="1876" end_char="1877">as</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="1879" end_char="1883">other</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="1885" end_char="1891">partner</TOKEN>
<TOKEN id="token-17-19" pos="word" morph="none" start_char="1893" end_char="1898">offers</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="1900" end_char="1902">and</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="1904" end_char="1909">accept</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="1911" end_char="1913">our</TOKEN>
<TOKEN id="token-17-23" pos="word" morph="none" start_char="1915" end_char="1919">Terms</TOKEN>
<TOKEN id="token-17-24" pos="word" morph="none" start_char="1921" end_char="1922">of</TOKEN>
<TOKEN id="token-17-25" pos="word" morph="none" start_char="1924" end_char="1930">Service</TOKEN>
<TOKEN id="token-17-26" pos="word" morph="none" start_char="1932" end_char="1934">and</TOKEN>
<TOKEN id="token-17-27" pos="word" morph="none" start_char="1936" end_char="1942">Privacy</TOKEN>
<TOKEN id="token-17-28" pos="word" morph="none" start_char="1944" end_char="1949">Policy</TOKEN>
<TOKEN id="token-17-29" pos="punct" morph="none" start_char="1950" end_char="1950">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1953" end_char="2076">
<ORIGINAL_TEXT>A study from Milan's National Cancer Institute also found that four of Italy's coronavirus cases dated back to October 2019.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="1953" end_char="1953">A</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="1955" end_char="1959">study</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="1961" end_char="1964">from</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="1966" end_char="1972">Milan's</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="1974" end_char="1981">National</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="1983" end_char="1988">Cancer</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="1990" end_char="1998">Institute</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2000" end_char="2003">also</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2005" end_char="2009">found</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="2011" end_char="2014">that</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="2016" end_char="2019">four</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="2021" end_char="2022">of</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2024" end_char="2030">Italy's</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="2032" end_char="2042">coronavirus</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="2044" end_char="2048">cases</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="2050" end_char="2054">dated</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="2056" end_char="2059">back</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="2061" end_char="2062">to</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="2064" end_char="2070">October</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="2072" end_char="2075">2019</TOKEN>
<TOKEN id="token-18-20" pos="punct" morph="none" start_char="2076" end_char="2076">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2078" end_char="2154">
<ORIGINAL_TEXT>Another study suggests the virus reached the US' West Coast in December 2019.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2078" end_char="2084">Another</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2086" end_char="2090">study</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2092" end_char="2099">suggests</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2101" end_char="2103">the</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2105" end_char="2109">virus</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2111" end_char="2117">reached</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2119" end_char="2121">the</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2123" end_char="2124">US</TOKEN>
<TOKEN id="token-19-8" pos="punct" morph="none" start_char="2125" end_char="2125">'</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="2127" end_char="2130">West</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="2132" end_char="2136">Coast</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="2138" end_char="2139">in</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="2141" end_char="2148">December</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="2150" end_char="2153">2019</TOKEN>
<TOKEN id="token-19-14" pos="punct" morph="none" start_char="2154" end_char="2154">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2157" end_char="2345">
<ORIGINAL_TEXT>Although pinpointing the exact date of the virus' first jump from animals to people is impossible without more data, these findings suggest the pandemic's December anniversary is arbitrary.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2157" end_char="2164">Although</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2166" end_char="2176">pinpointing</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2178" end_char="2180">the</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2182" end_char="2186">exact</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2188" end_char="2191">date</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2193" end_char="2194">of</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2196" end_char="2198">the</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2200" end_char="2204">virus</TOKEN>
<TOKEN id="token-20-8" pos="punct" morph="none" start_char="2205" end_char="2205">'</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2207" end_char="2211">first</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2213" end_char="2216">jump</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="2218" end_char="2221">from</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="2223" end_char="2229">animals</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="2231" end_char="2232">to</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="2234" end_char="2239">people</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="2241" end_char="2242">is</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="2244" end_char="2253">impossible</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="2255" end_char="2261">without</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="2263" end_char="2266">more</TOKEN>
<TOKEN id="token-20-19" pos="word" morph="none" start_char="2268" end_char="2271">data</TOKEN>
<TOKEN id="token-20-20" pos="punct" morph="none" start_char="2272" end_char="2272">,</TOKEN>
<TOKEN id="token-20-21" pos="word" morph="none" start_char="2274" end_char="2278">these</TOKEN>
<TOKEN id="token-20-22" pos="word" morph="none" start_char="2280" end_char="2287">findings</TOKEN>
<TOKEN id="token-20-23" pos="word" morph="none" start_char="2289" end_char="2295">suggest</TOKEN>
<TOKEN id="token-20-24" pos="word" morph="none" start_char="2297" end_char="2299">the</TOKEN>
<TOKEN id="token-20-25" pos="word" morph="none" start_char="2301" end_char="2310">pandemic's</TOKEN>
<TOKEN id="token-20-26" pos="word" morph="none" start_char="2312" end_char="2319">December</TOKEN>
<TOKEN id="token-20-27" pos="word" morph="none" start_char="2321" end_char="2331">anniversary</TOKEN>
<TOKEN id="token-20-28" pos="word" morph="none" start_char="2333" end_char="2334">is</TOKEN>
<TOKEN id="token-20-29" pos="word" morph="none" start_char="2336" end_char="2344">arbitrary</TOKEN>
<TOKEN id="token-20-30" pos="punct" morph="none" start_char="2345" end_char="2345">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2348" end_char="2399">
<ORIGINAL_TEXT>The virus was spreading in Wuhan before the December</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2348" end_char="2350">The</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2352" end_char="2356">virus</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2358" end_char="2360">was</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2362" end_char="2370">spreading</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2372" end_char="2373">in</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="2375" end_char="2379">Wuhan</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2381" end_char="2386">before</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="2388" end_char="2390">the</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="2392" end_char="2399">December</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2404" end_char="2492">
<ORIGINAL_TEXT>Healthcare workers transport bodies outside a hospital in Wuhan, China, February 5, 2020.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2404" end_char="2413">Healthcare</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2415" end_char="2421">workers</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2423" end_char="2431">transport</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2433" end_char="2438">bodies</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2440" end_char="2446">outside</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2448" end_char="2448">a</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2450" end_char="2457">hospital</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2459" end_char="2460">in</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="2462" end_char="2466">Wuhan</TOKEN>
<TOKEN id="token-22-9" pos="punct" morph="none" start_char="2467" end_char="2467">,</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="2469" end_char="2473">China</TOKEN>
<TOKEN id="token-22-11" pos="punct" morph="none" start_char="2474" end_char="2474">,</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="2476" end_char="2483">February</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="2485" end_char="2485">5</TOKEN>
<TOKEN id="token-22-14" pos="punct" morph="none" start_char="2486" end_char="2486">,</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="2488" end_char="2491">2020</TOKEN>
<TOKEN id="token-22-16" pos="punct" morph="none" start_char="2492" end_char="2492">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2495" end_char="2499">
<ORIGINAL_TEXT>Getty</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2495" end_char="2499">Getty</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2503" end_char="2651">
<ORIGINAL_TEXT>Wuhan public-health officials initially told the WHO about a mysterious illness that would later be named the novel coronavirus on December 31, 2019.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="2503" end_char="2507">Wuhan</TOKEN>
<TOKEN id="token-24-1" pos="unknown" morph="none" start_char="2509" end_char="2521">public-health</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="2523" end_char="2531">officials</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="2533" end_char="2541">initially</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="2543" end_char="2546">told</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="2548" end_char="2550">the</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="2552" end_char="2554">WHO</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="2556" end_char="2560">about</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="2562" end_char="2562">a</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="2564" end_char="2573">mysterious</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="2575" end_char="2581">illness</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="2583" end_char="2586">that</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="2588" end_char="2592">would</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="2594" end_char="2598">later</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="2600" end_char="2601">be</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="2603" end_char="2607">named</TOKEN>
<TOKEN id="token-24-16" pos="word" morph="none" start_char="2609" end_char="2611">the</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="2613" end_char="2617">novel</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="2619" end_char="2629">coronavirus</TOKEN>
<TOKEN id="token-24-19" pos="word" morph="none" start_char="2631" end_char="2632">on</TOKEN>
<TOKEN id="token-24-20" pos="word" morph="none" start_char="2634" end_char="2641">December</TOKEN>
<TOKEN id="token-24-21" pos="word" morph="none" start_char="2643" end_char="2644">31</TOKEN>
<TOKEN id="token-24-22" pos="punct" morph="none" start_char="2645" end_char="2645">,</TOKEN>
<TOKEN id="token-24-23" pos="word" morph="none" start_char="2647" end_char="2650">2019</TOKEN>
<TOKEN id="token-24-24" pos="punct" morph="none" start_char="2651" end_char="2651">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2654" end_char="2805">
<ORIGINAL_TEXT>But government records show China's first coronavirus case happened on November 17, 2019, according to an investigation by the South China Morning Post.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="2654" end_char="2656">But</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="2658" end_char="2667">government</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="2669" end_char="2675">records</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="2677" end_char="2680">show</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="2682" end_char="2688">China's</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="2690" end_char="2694">first</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="2696" end_char="2706">coronavirus</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="2708" end_char="2711">case</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="2713" end_char="2720">happened</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="2722" end_char="2723">on</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="2725" end_char="2732">November</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="2734" end_char="2735">17</TOKEN>
<TOKEN id="token-25-12" pos="punct" morph="none" start_char="2736" end_char="2736">,</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="2738" end_char="2741">2019</TOKEN>
<TOKEN id="token-25-14" pos="punct" morph="none" start_char="2742" end_char="2742">,</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="2744" end_char="2752">according</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="2754" end_char="2755">to</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="2757" end_char="2758">an</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="2760" end_char="2772">investigation</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="2774" end_char="2775">by</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="2777" end_char="2779">the</TOKEN>
<TOKEN id="token-25-21" pos="word" morph="none" start_char="2781" end_char="2785">South</TOKEN>
<TOKEN id="token-25-22" pos="word" morph="none" start_char="2787" end_char="2791">China</TOKEN>
<TOKEN id="token-25-23" pos="word" morph="none" start_char="2793" end_char="2799">Morning</TOKEN>
<TOKEN id="token-25-24" pos="word" morph="none" start_char="2801" end_char="2804">Post</TOKEN>
<TOKEN id="token-25-25" pos="punct" morph="none" start_char="2805" end_char="2805">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="2808" end_char="2978">
<ORIGINAL_TEXT>According to the SCMP, Chinese medical experts pinpointed 60 coronavirus cases from November and December by reanalyzing samples taken from patients seen during that time.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="2808" end_char="2816">According</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="2818" end_char="2819">to</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="2821" end_char="2823">the</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="2825" end_char="2828">SCMP</TOKEN>
<TOKEN id="token-26-4" pos="punct" morph="none" start_char="2829" end_char="2829">,</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="2831" end_char="2837">Chinese</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="2839" end_char="2845">medical</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="2847" end_char="2853">experts</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="2855" end_char="2864">pinpointed</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="2866" end_char="2867">60</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="2869" end_char="2879">coronavirus</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="2881" end_char="2885">cases</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="2887" end_char="2890">from</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="2892" end_char="2899">November</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="2901" end_char="2903">and</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="2905" end_char="2912">December</TOKEN>
<TOKEN id="token-26-16" pos="word" morph="none" start_char="2914" end_char="2915">by</TOKEN>
<TOKEN id="token-26-17" pos="word" morph="none" start_char="2917" end_char="2927">reanalyzing</TOKEN>
<TOKEN id="token-26-18" pos="word" morph="none" start_char="2929" end_char="2935">samples</TOKEN>
<TOKEN id="token-26-19" pos="word" morph="none" start_char="2937" end_char="2941">taken</TOKEN>
<TOKEN id="token-26-20" pos="word" morph="none" start_char="2943" end_char="2946">from</TOKEN>
<TOKEN id="token-26-21" pos="word" morph="none" start_char="2948" end_char="2955">patients</TOKEN>
<TOKEN id="token-26-22" pos="word" morph="none" start_char="2957" end_char="2960">seen</TOKEN>
<TOKEN id="token-26-23" pos="word" morph="none" start_char="2962" end_char="2967">during</TOKEN>
<TOKEN id="token-26-24" pos="word" morph="none" start_char="2969" end_char="2972">that</TOKEN>
<TOKEN id="token-26-25" pos="word" morph="none" start_char="2974" end_char="2977">time</TOKEN>
<TOKEN id="token-26-26" pos="punct" morph="none" start_char="2978" end_char="2978">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="2980" end_char="3136">
<ORIGINAL_TEXT>That analysis showed that a 55-year-old from Hubei was the first known case of COVID-19 in the world, though the disease hadn't been identified at that time.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="2980" end_char="2983">That</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="2985" end_char="2992">analysis</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="2994" end_char="2999">showed</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="3001" end_char="3004">that</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="3006" end_char="3006">a</TOKEN>
<TOKEN id="token-27-5" pos="unknown" morph="none" start_char="3008" end_char="3018">55-year-old</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="3020" end_char="3023">from</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="3025" end_char="3029">Hubei</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="3031" end_char="3033">was</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="3035" end_char="3037">the</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="3039" end_char="3043">first</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="3045" end_char="3049">known</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="3051" end_char="3054">case</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="3056" end_char="3057">of</TOKEN>
<TOKEN id="token-27-14" pos="unknown" morph="none" start_char="3059" end_char="3066">COVID-19</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="3068" end_char="3069">in</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="3071" end_char="3073">the</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="3075" end_char="3079">world</TOKEN>
<TOKEN id="token-27-18" pos="punct" morph="none" start_char="3080" end_char="3080">,</TOKEN>
<TOKEN id="token-27-19" pos="word" morph="none" start_char="3082" end_char="3087">though</TOKEN>
<TOKEN id="token-27-20" pos="word" morph="none" start_char="3089" end_char="3091">the</TOKEN>
<TOKEN id="token-27-21" pos="word" morph="none" start_char="3093" end_char="3099">disease</TOKEN>
<TOKEN id="token-27-22" pos="word" morph="none" start_char="3101" end_char="3106">hadn't</TOKEN>
<TOKEN id="token-27-23" pos="word" morph="none" start_char="3108" end_char="3111">been</TOKEN>
<TOKEN id="token-27-24" pos="word" morph="none" start_char="3113" end_char="3122">identified</TOKEN>
<TOKEN id="token-27-25" pos="word" morph="none" start_char="3124" end_char="3125">at</TOKEN>
<TOKEN id="token-27-26" pos="word" morph="none" start_char="3127" end_char="3130">that</TOKEN>
<TOKEN id="token-27-27" pos="word" morph="none" start_char="3132" end_char="3135">time</TOKEN>
<TOKEN id="token-27-28" pos="punct" morph="none" start_char="3136" end_char="3136">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3139" end_char="3333">
<ORIGINAL_TEXT>Prior to the January WHO investigation, Chinese authorities worked to sample blood from 92 people in Hubei who were hospitalized with coronavirus-like symptoms prior to the start of the pandemic.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="3139" end_char="3143">Prior</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="3145" end_char="3146">to</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="3148" end_char="3150">the</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="3152" end_char="3158">January</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="3160" end_char="3162">WHO</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="3164" end_char="3176">investigation</TOKEN>
<TOKEN id="token-28-6" pos="punct" morph="none" start_char="3177" end_char="3177">,</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="3179" end_char="3185">Chinese</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="3187" end_char="3197">authorities</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="3199" end_char="3204">worked</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="3206" end_char="3207">to</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="3209" end_char="3214">sample</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="3216" end_char="3220">blood</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="3222" end_char="3225">from</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="3227" end_char="3228">92</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="3230" end_char="3235">people</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="3237" end_char="3238">in</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="3240" end_char="3244">Hubei</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="3246" end_char="3248">who</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="3250" end_char="3253">were</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="3255" end_char="3266">hospitalized</TOKEN>
<TOKEN id="token-28-21" pos="word" morph="none" start_char="3268" end_char="3271">with</TOKEN>
<TOKEN id="token-28-22" pos="unknown" morph="none" start_char="3273" end_char="3288">coronavirus-like</TOKEN>
<TOKEN id="token-28-23" pos="word" morph="none" start_char="3290" end_char="3297">symptoms</TOKEN>
<TOKEN id="token-28-24" pos="word" morph="none" start_char="3299" end_char="3303">prior</TOKEN>
<TOKEN id="token-28-25" pos="word" morph="none" start_char="3305" end_char="3306">to</TOKEN>
<TOKEN id="token-28-26" pos="word" morph="none" start_char="3308" end_char="3310">the</TOKEN>
<TOKEN id="token-28-27" pos="word" morph="none" start_char="3312" end_char="3316">start</TOKEN>
<TOKEN id="token-28-28" pos="word" morph="none" start_char="3318" end_char="3319">of</TOKEN>
<TOKEN id="token-28-29" pos="word" morph="none" start_char="3321" end_char="3323">the</TOKEN>
<TOKEN id="token-28-30" pos="word" morph="none" start_char="3325" end_char="3332">pandemic</TOKEN>
<TOKEN id="token-28-31" pos="punct" morph="none" start_char="3333" end_char="3333">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3336" end_char="3517">
<ORIGINAL_TEXT>They sampled blood from two-thirds of those patients that to check for coronavirus-specific antibodies, which would indicate the patients had previously been infected with the virus.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="3336" end_char="3339">They</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="3341" end_char="3347">sampled</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="3349" end_char="3353">blood</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="3355" end_char="3358">from</TOKEN>
<TOKEN id="token-29-4" pos="unknown" morph="none" start_char="3360" end_char="3369">two-thirds</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="3371" end_char="3372">of</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="3374" end_char="3378">those</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="3380" end_char="3387">patients</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="3389" end_char="3392">that</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="3394" end_char="3395">to</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="3397" end_char="3401">check</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="3403" end_char="3405">for</TOKEN>
<TOKEN id="token-29-12" pos="unknown" morph="none" start_char="3407" end_char="3426">coronavirus-specific</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="3428" end_char="3437">antibodies</TOKEN>
<TOKEN id="token-29-14" pos="punct" morph="none" start_char="3438" end_char="3438">,</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="3440" end_char="3444">which</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="3446" end_char="3450">would</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="3452" end_char="3459">indicate</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="3461" end_char="3463">the</TOKEN>
<TOKEN id="token-29-19" pos="word" morph="none" start_char="3465" end_char="3472">patients</TOKEN>
<TOKEN id="token-29-20" pos="word" morph="none" start_char="3474" end_char="3476">had</TOKEN>
<TOKEN id="token-29-21" pos="word" morph="none" start_char="3478" end_char="3487">previously</TOKEN>
<TOKEN id="token-29-22" pos="word" morph="none" start_char="3489" end_char="3492">been</TOKEN>
<TOKEN id="token-29-23" pos="word" morph="none" start_char="3494" end_char="3501">infected</TOKEN>
<TOKEN id="token-29-24" pos="word" morph="none" start_char="3503" end_char="3506">with</TOKEN>
<TOKEN id="token-29-25" pos="word" morph="none" start_char="3508" end_char="3510">the</TOKEN>
<TOKEN id="token-29-26" pos="word" morph="none" start_char="3512" end_char="3516">virus</TOKEN>
<TOKEN id="token-29-27" pos="punct" morph="none" start_char="3517" end_char="3517">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3519" end_char="3608">
<ORIGINAL_TEXT>All of the samples tested negative for those antibodies, the Wall Street Journal reported.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="3519" end_char="3521">All</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="3523" end_char="3524">of</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="3526" end_char="3528">the</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="3530" end_char="3536">samples</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="3538" end_char="3543">tested</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="3545" end_char="3552">negative</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="3554" end_char="3556">for</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="3558" end_char="3562">those</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="3564" end_char="3573">antibodies</TOKEN>
<TOKEN id="token-30-9" pos="punct" morph="none" start_char="3574" end_char="3574">,</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="3576" end_char="3578">the</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="3580" end_char="3583">Wall</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="3585" end_char="3590">Street</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="3592" end_char="3598">Journal</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="3600" end_char="3607">reported</TOKEN>
<TOKEN id="token-30-15" pos="punct" morph="none" start_char="3608" end_char="3608">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="3611" end_char="3717">
<ORIGINAL_TEXT>The remaining one-third of those 92 patients had either died or refused to participate in antibody testing.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="3611" end_char="3613">The</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="3615" end_char="3623">remaining</TOKEN>
<TOKEN id="token-31-2" pos="unknown" morph="none" start_char="3625" end_char="3633">one-third</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="3635" end_char="3636">of</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="3638" end_char="3642">those</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="3644" end_char="3645">92</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="3647" end_char="3654">patients</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="3656" end_char="3658">had</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="3660" end_char="3665">either</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="3667" end_char="3670">died</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="3672" end_char="3673">or</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="3675" end_char="3681">refused</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="3683" end_char="3684">to</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="3686" end_char="3696">participate</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="3698" end_char="3699">in</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="3701" end_char="3708">antibody</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="3710" end_char="3716">testing</TOKEN>
<TOKEN id="token-31-17" pos="punct" morph="none" start_char="3717" end_char="3717">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="3720" end_char="3787">
<ORIGINAL_TEXT>The negative results may not mean those people didn't have COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="3720" end_char="3722">The</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="3724" end_char="3731">negative</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="3733" end_char="3739">results</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="3741" end_char="3743">may</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="3745" end_char="3747">not</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="3749" end_char="3752">mean</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="3754" end_char="3758">those</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="3760" end_char="3765">people</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="3767" end_char="3772">didn't</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="3774" end_char="3777">have</TOKEN>
<TOKEN id="token-32-10" pos="unknown" morph="none" start_char="3779" end_char="3786">COVID-19</TOKEN>
<TOKEN id="token-32-11" pos="punct" morph="none" start_char="3787" end_char="3787">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="3789" end_char="3857">
<ORIGINAL_TEXT>Antibody levels do decrease over time, particularly after mild cases.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="3789" end_char="3796">Antibody</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="3798" end_char="3803">levels</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="3805" end_char="3806">do</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="3808" end_char="3815">decrease</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="3817" end_char="3820">over</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="3822" end_char="3825">time</TOKEN>
<TOKEN id="token-33-6" pos="punct" morph="none" start_char="3826" end_char="3826">,</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="3828" end_char="3839">particularly</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="3841" end_char="3845">after</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="3847" end_char="3850">mild</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="3852" end_char="3856">cases</TOKEN>
<TOKEN id="token-33-11" pos="punct" morph="none" start_char="3857" end_char="3857">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="3859" end_char="3934">
<ORIGINAL_TEXT>But those patients were also hospitalized, suggesting a more severe illness.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="3859" end_char="3861">But</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="3863" end_char="3867">those</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="3869" end_char="3876">patients</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="3878" end_char="3881">were</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="3883" end_char="3886">also</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="3888" end_char="3899">hospitalized</TOKEN>
<TOKEN id="token-34-6" pos="punct" morph="none" start_char="3900" end_char="3900">,</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="3902" end_char="3911">suggesting</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="3913" end_char="3913">a</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="3915" end_char="3918">more</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="3920" end_char="3925">severe</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="3927" end_char="3933">illness</TOKEN>
<TOKEN id="token-34-12" pos="punct" morph="none" start_char="3934" end_char="3934">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="3937" end_char="3957">
<ORIGINAL_TEXT>"Antibodies do clear.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="punct" morph="none" start_char="3937" end_char="3937">"</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="3938" end_char="3947">Antibodies</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="3949" end_char="3950">do</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="3952" end_char="3956">clear</TOKEN>
<TOKEN id="token-35-4" pos="punct" morph="none" start_char="3957" end_char="3957">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="3959" end_char="4097">
<ORIGINAL_TEXT>The levels go down, but less so in cases of severe infection," Marion Koopmans, a virologist on the WHO team, told the Wall Street Journal.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="3959" end_char="3961">The</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="3963" end_char="3968">levels</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="3970" end_char="3971">go</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="3973" end_char="3976">down</TOKEN>
<TOKEN id="token-36-4" pos="punct" morph="none" start_char="3977" end_char="3977">,</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="3979" end_char="3981">but</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="3983" end_char="3986">less</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="3988" end_char="3989">so</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="3991" end_char="3992">in</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="3994" end_char="3998">cases</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="4000" end_char="4001">of</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="4003" end_char="4008">severe</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="4010" end_char="4018">infection</TOKEN>
<TOKEN id="token-36-13" pos="punct" morph="none" start_char="4019" end_char="4020">,"</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="4022" end_char="4027">Marion</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="4029" end_char="4036">Koopmans</TOKEN>
<TOKEN id="token-36-16" pos="punct" morph="none" start_char="4037" end_char="4037">,</TOKEN>
<TOKEN id="token-36-17" pos="word" morph="none" start_char="4039" end_char="4039">a</TOKEN>
<TOKEN id="token-36-18" pos="word" morph="none" start_char="4041" end_char="4050">virologist</TOKEN>
<TOKEN id="token-36-19" pos="word" morph="none" start_char="4052" end_char="4053">on</TOKEN>
<TOKEN id="token-36-20" pos="word" morph="none" start_char="4055" end_char="4057">the</TOKEN>
<TOKEN id="token-36-21" pos="word" morph="none" start_char="4059" end_char="4061">WHO</TOKEN>
<TOKEN id="token-36-22" pos="word" morph="none" start_char="4063" end_char="4066">team</TOKEN>
<TOKEN id="token-36-23" pos="punct" morph="none" start_char="4067" end_char="4067">,</TOKEN>
<TOKEN id="token-36-24" pos="word" morph="none" start_char="4069" end_char="4072">told</TOKEN>
<TOKEN id="token-36-25" pos="word" morph="none" start_char="4074" end_char="4076">the</TOKEN>
<TOKEN id="token-36-26" pos="word" morph="none" start_char="4078" end_char="4081">Wall</TOKEN>
<TOKEN id="token-36-27" pos="word" morph="none" start_char="4083" end_char="4088">Street</TOKEN>
<TOKEN id="token-36-28" pos="word" morph="none" start_char="4090" end_char="4096">Journal</TOKEN>
<TOKEN id="token-36-29" pos="punct" morph="none" start_char="4097" end_char="4097">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="4099" end_char="4189">
<ORIGINAL_TEXT>"From what we know about serology, out of 92 cases you would at least have some positives."</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="punct" morph="none" start_char="4099" end_char="4099">"</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="4100" end_char="4103">From</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="4105" end_char="4108">what</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="4110" end_char="4111">we</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="4113" end_char="4116">know</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="4118" end_char="4122">about</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="4124" end_char="4131">serology</TOKEN>
<TOKEN id="token-37-7" pos="punct" morph="none" start_char="4132" end_char="4132">,</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="4134" end_char="4136">out</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="4138" end_char="4139">of</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="4141" end_char="4142">92</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="4144" end_char="4148">cases</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="4150" end_char="4152">you</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="4154" end_char="4158">would</TOKEN>
<TOKEN id="token-37-14" pos="word" morph="none" start_char="4160" end_char="4161">at</TOKEN>
<TOKEN id="token-37-15" pos="word" morph="none" start_char="4163" end_char="4167">least</TOKEN>
<TOKEN id="token-37-16" pos="word" morph="none" start_char="4169" end_char="4172">have</TOKEN>
<TOKEN id="token-37-17" pos="word" morph="none" start_char="4174" end_char="4177">some</TOKEN>
<TOKEN id="token-37-18" pos="word" morph="none" start_char="4179" end_char="4187">positives</TOKEN>
<TOKEN id="token-37-19" pos="punct" morph="none" start_char="4188" end_char="4189">."</TOKEN>
</SEG>
<SEG id="segment-38" start_char="4192" end_char="4203">
<ORIGINAL_TEXT>A study from</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="4192" end_char="4192">A</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="4194" end_char="4198">study</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="4200" end_char="4203">from</TOKEN>
</SEG>
<SEG id="segment-39" start_char="4206" end_char="4238">
<ORIGINAL_TEXT>researchers at Harvard University</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="4206" end_char="4216">researchers</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="4218" end_char="4219">at</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="4221" end_char="4227">Harvard</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="4229" end_char="4238">University</TOKEN>
</SEG>
<SEG id="segment-40" start_char="4241" end_char="4318">
<ORIGINAL_TEXT>did find more people were visiting Wuhan hospitals in the latter half of 2019.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="4241" end_char="4243">did</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="4245" end_char="4248">find</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="4250" end_char="4253">more</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="4255" end_char="4260">people</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="4262" end_char="4265">were</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="4267" end_char="4274">visiting</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="4276" end_char="4280">Wuhan</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="4282" end_char="4290">hospitals</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="4292" end_char="4293">in</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="4295" end_char="4297">the</TOKEN>
<TOKEN id="token-40-10" pos="word" morph="none" start_char="4299" end_char="4304">latter</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="4306" end_char="4309">half</TOKEN>
<TOKEN id="token-40-12" pos="word" morph="none" start_char="4311" end_char="4312">of</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="4314" end_char="4317">2019</TOKEN>
<TOKEN id="token-40-14" pos="punct" morph="none" start_char="4318" end_char="4318">.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="4320" end_char="4413">
<ORIGINAL_TEXT>The study authors used satellite imagery of the city to measure traffic to six city hospitals.</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="4320" end_char="4322">The</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="4324" end_char="4328">study</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="4330" end_char="4336">authors</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="4338" end_char="4341">used</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="4343" end_char="4351">satellite</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="4353" end_char="4359">imagery</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="4361" end_char="4362">of</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="4364" end_char="4366">the</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="4368" end_char="4371">city</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="4373" end_char="4374">to</TOKEN>
<TOKEN id="token-41-10" pos="word" morph="none" start_char="4376" end_char="4382">measure</TOKEN>
<TOKEN id="token-41-11" pos="word" morph="none" start_char="4384" end_char="4390">traffic</TOKEN>
<TOKEN id="token-41-12" pos="word" morph="none" start_char="4392" end_char="4393">to</TOKEN>
<TOKEN id="token-41-13" pos="word" morph="none" start_char="4395" end_char="4397">six</TOKEN>
<TOKEN id="token-41-14" pos="word" morph="none" start_char="4399" end_char="4402">city</TOKEN>
<TOKEN id="token-41-15" pos="word" morph="none" start_char="4404" end_char="4412">hospitals</TOKEN>
<TOKEN id="token-41-16" pos="punct" morph="none" start_char="4413" end_char="4413">.</TOKEN>
</SEG>
<SEG id="segment-42" start_char="4415" end_char="4488">
<ORIGINAL_TEXT>They saw an uptick starting in August 2019, which peaked six months later.</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="4415" end_char="4418">They</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="4420" end_char="4422">saw</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="4424" end_char="4425">an</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="4427" end_char="4432">uptick</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="4434" end_char="4441">starting</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="4443" end_char="4444">in</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="4446" end_char="4451">August</TOKEN>
<TOKEN id="token-42-7" pos="word" morph="none" start_char="4453" end_char="4456">2019</TOKEN>
<TOKEN id="token-42-8" pos="punct" morph="none" start_char="4457" end_char="4457">,</TOKEN>
<TOKEN id="token-42-9" pos="word" morph="none" start_char="4459" end_char="4463">which</TOKEN>
<TOKEN id="token-42-10" pos="word" morph="none" start_char="4465" end_char="4470">peaked</TOKEN>
<TOKEN id="token-42-11" pos="word" morph="none" start_char="4472" end_char="4474">six</TOKEN>
<TOKEN id="token-42-12" pos="word" morph="none" start_char="4476" end_char="4481">months</TOKEN>
<TOKEN id="token-42-13" pos="word" morph="none" start_char="4483" end_char="4487">later</TOKEN>
<TOKEN id="token-42-14" pos="punct" morph="none" start_char="4488" end_char="4488">.</TOKEN>
</SEG>
<SEG id="segment-43" start_char="4490" end_char="4593">
<ORIGINAL_TEXT>This timeline coincided with an increase in online search traffic for terms like "diarrhea" and "cough."</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="4490" end_char="4493">This</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="4495" end_char="4502">timeline</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="4504" end_char="4512">coincided</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="4514" end_char="4517">with</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="4519" end_char="4520">an</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="4522" end_char="4529">increase</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="4531" end_char="4532">in</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="4534" end_char="4539">online</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="4541" end_char="4546">search</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="4548" end_char="4554">traffic</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="4556" end_char="4558">for</TOKEN>
<TOKEN id="token-43-11" pos="word" morph="none" start_char="4560" end_char="4564">terms</TOKEN>
<TOKEN id="token-43-12" pos="word" morph="none" start_char="4566" end_char="4569">like</TOKEN>
<TOKEN id="token-43-13" pos="punct" morph="none" start_char="4571" end_char="4571">"</TOKEN>
<TOKEN id="token-43-14" pos="word" morph="none" start_char="4572" end_char="4579">diarrhea</TOKEN>
<TOKEN id="token-43-15" pos="punct" morph="none" start_char="4580" end_char="4580">"</TOKEN>
<TOKEN id="token-43-16" pos="word" morph="none" start_char="4582" end_char="4584">and</TOKEN>
<TOKEN id="token-43-17" pos="punct" morph="none" start_char="4586" end_char="4586">"</TOKEN>
<TOKEN id="token-43-18" pos="word" morph="none" start_char="4587" end_char="4591">cough</TOKEN>
<TOKEN id="token-43-19" pos="punct" morph="none" start_char="4592" end_char="4593">."</TOKEN>
</SEG>
<SEG id="segment-44" start_char="4596" end_char="4646">
<ORIGINAL_TEXT>The Wuhan market was not the origin of the pandemic</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="4596" end_char="4598">The</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="4600" end_char="4604">Wuhan</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="4606" end_char="4611">market</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="4613" end_char="4615">was</TOKEN>
<TOKEN id="token-44-4" pos="word" morph="none" start_char="4617" end_char="4619">not</TOKEN>
<TOKEN id="token-44-5" pos="word" morph="none" start_char="4621" end_char="4623">the</TOKEN>
<TOKEN id="token-44-6" pos="word" morph="none" start_char="4625" end_char="4630">origin</TOKEN>
<TOKEN id="token-44-7" pos="word" morph="none" start_char="4632" end_char="4633">of</TOKEN>
<TOKEN id="token-44-8" pos="word" morph="none" start_char="4635" end_char="4637">the</TOKEN>
<TOKEN id="token-44-9" pos="word" morph="none" start_char="4639" end_char="4646">pandemic</TOKEN>
</SEG>
<SEG id="segment-45" start_char="4651" end_char="4740">
<ORIGINAL_TEXT>Security personnel wear masks walk in front of a field hospital in Wuhan on April 9, 2020.</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="4651" end_char="4658">Security</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="4660" end_char="4668">personnel</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="4670" end_char="4673">wear</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="4675" end_char="4679">masks</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="4681" end_char="4684">walk</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="4686" end_char="4687">in</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="4689" end_char="4693">front</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="4695" end_char="4696">of</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="4698" end_char="4698">a</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="4700" end_char="4704">field</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="4706" end_char="4713">hospital</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="4715" end_char="4716">in</TOKEN>
<TOKEN id="token-45-12" pos="word" morph="none" start_char="4718" end_char="4722">Wuhan</TOKEN>
<TOKEN id="token-45-13" pos="word" morph="none" start_char="4724" end_char="4725">on</TOKEN>
<TOKEN id="token-45-14" pos="word" morph="none" start_char="4727" end_char="4731">April</TOKEN>
<TOKEN id="token-45-15" pos="word" morph="none" start_char="4733" end_char="4733">9</TOKEN>
<TOKEN id="token-45-16" pos="punct" morph="none" start_char="4734" end_char="4734">,</TOKEN>
<TOKEN id="token-45-17" pos="word" morph="none" start_char="4736" end_char="4739">2020</TOKEN>
<TOKEN id="token-45-18" pos="punct" morph="none" start_char="4740" end_char="4740">.</TOKEN>
</SEG>
<SEG id="segment-46" start_char="4743" end_char="4769">
<ORIGINAL_TEXT>Noel Celis/AFP/Getty Images</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="4743" end_char="4746">Noel</TOKEN>
<TOKEN id="token-46-1" pos="unknown" morph="none" start_char="4748" end_char="4762">Celis/AFP/Getty</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="4764" end_char="4769">Images</TOKEN>
</SEG>
<SEG id="segment-47" start_char="4773" end_char="4911">
<ORIGINAL_TEXT>Among the 41 coronavirus cases, Wuhan first reported, many were people who visited or worked at the city's Huanan Seafood Wholesale Market.</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="4773" end_char="4777">Among</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="4779" end_char="4781">the</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="4783" end_char="4784">41</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="4786" end_char="4796">coronavirus</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="4798" end_char="4802">cases</TOKEN>
<TOKEN id="token-47-5" pos="punct" morph="none" start_char="4803" end_char="4803">,</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="4805" end_char="4809">Wuhan</TOKEN>
<TOKEN id="token-47-7" pos="word" morph="none" start_char="4811" end_char="4815">first</TOKEN>
<TOKEN id="token-47-8" pos="word" morph="none" start_char="4817" end_char="4824">reported</TOKEN>
<TOKEN id="token-47-9" pos="punct" morph="none" start_char="4825" end_char="4825">,</TOKEN>
<TOKEN id="token-47-10" pos="word" morph="none" start_char="4827" end_char="4830">many</TOKEN>
<TOKEN id="token-47-11" pos="word" morph="none" start_char="4832" end_char="4835">were</TOKEN>
<TOKEN id="token-47-12" pos="word" morph="none" start_char="4837" end_char="4842">people</TOKEN>
<TOKEN id="token-47-13" pos="word" morph="none" start_char="4844" end_char="4846">who</TOKEN>
<TOKEN id="token-47-14" pos="word" morph="none" start_char="4848" end_char="4854">visited</TOKEN>
<TOKEN id="token-47-15" pos="word" morph="none" start_char="4856" end_char="4857">or</TOKEN>
<TOKEN id="token-47-16" pos="word" morph="none" start_char="4859" end_char="4864">worked</TOKEN>
<TOKEN id="token-47-17" pos="word" morph="none" start_char="4866" end_char="4867">at</TOKEN>
<TOKEN id="token-47-18" pos="word" morph="none" start_char="4869" end_char="4871">the</TOKEN>
<TOKEN id="token-47-19" pos="word" morph="none" start_char="4873" end_char="4878">city's</TOKEN>
<TOKEN id="token-47-20" pos="word" morph="none" start_char="4880" end_char="4885">Huanan</TOKEN>
<TOKEN id="token-47-21" pos="word" morph="none" start_char="4887" end_char="4893">Seafood</TOKEN>
<TOKEN id="token-47-22" pos="word" morph="none" start_char="4895" end_char="4903">Wholesale</TOKEN>
<TOKEN id="token-47-23" pos="word" morph="none" start_char="4905" end_char="4910">Market</TOKEN>
<TOKEN id="token-47-24" pos="punct" morph="none" start_char="4911" end_char="4911">.</TOKEN>
</SEG>
<SEG id="segment-48" start_char="4914" end_char="5068">
<ORIGINAL_TEXT>But according to an April report, 13 of the 41 original cases had no link to the market — which suggests the market wasn't the origin site of the pandemic.</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="4914" end_char="4916">But</TOKEN>
<TOKEN id="token-48-1" pos="word" morph="none" start_char="4918" end_char="4926">according</TOKEN>
<TOKEN id="token-48-2" pos="word" morph="none" start_char="4928" end_char="4929">to</TOKEN>
<TOKEN id="token-48-3" pos="word" morph="none" start_char="4931" end_char="4932">an</TOKEN>
<TOKEN id="token-48-4" pos="word" morph="none" start_char="4934" end_char="4938">April</TOKEN>
<TOKEN id="token-48-5" pos="word" morph="none" start_char="4940" end_char="4945">report</TOKEN>
<TOKEN id="token-48-6" pos="punct" morph="none" start_char="4946" end_char="4946">,</TOKEN>
<TOKEN id="token-48-7" pos="word" morph="none" start_char="4948" end_char="4949">13</TOKEN>
<TOKEN id="token-48-8" pos="word" morph="none" start_char="4951" end_char="4952">of</TOKEN>
<TOKEN id="token-48-9" pos="word" morph="none" start_char="4954" end_char="4956">the</TOKEN>
<TOKEN id="token-48-10" pos="word" morph="none" start_char="4958" end_char="4959">41</TOKEN>
<TOKEN id="token-48-11" pos="word" morph="none" start_char="4961" end_char="4968">original</TOKEN>
<TOKEN id="token-48-12" pos="word" morph="none" start_char="4970" end_char="4974">cases</TOKEN>
<TOKEN id="token-48-13" pos="word" morph="none" start_char="4976" end_char="4978">had</TOKEN>
<TOKEN id="token-48-14" pos="word" morph="none" start_char="4980" end_char="4981">no</TOKEN>
<TOKEN id="token-48-15" pos="word" morph="none" start_char="4983" end_char="4986">link</TOKEN>
<TOKEN id="token-48-16" pos="word" morph="none" start_char="4988" end_char="4989">to</TOKEN>
<TOKEN id="token-48-17" pos="word" morph="none" start_char="4991" end_char="4993">the</TOKEN>
<TOKEN id="token-48-18" pos="word" morph="none" start_char="4995" end_char="5000">market</TOKEN>
<TOKEN id="token-48-19" pos="punct" morph="none" start_char="5002" end_char="5002">—</TOKEN>
<TOKEN id="token-48-20" pos="word" morph="none" start_char="5004" end_char="5008">which</TOKEN>
<TOKEN id="token-48-21" pos="word" morph="none" start_char="5010" end_char="5017">suggests</TOKEN>
<TOKEN id="token-48-22" pos="word" morph="none" start_char="5019" end_char="5021">the</TOKEN>
<TOKEN id="token-48-23" pos="word" morph="none" start_char="5023" end_char="5028">market</TOKEN>
<TOKEN id="token-48-24" pos="word" morph="none" start_char="5030" end_char="5035">wasn't</TOKEN>
<TOKEN id="token-48-25" pos="word" morph="none" start_char="5037" end_char="5039">the</TOKEN>
<TOKEN id="token-48-26" pos="word" morph="none" start_char="5041" end_char="5046">origin</TOKEN>
<TOKEN id="token-48-27" pos="word" morph="none" start_char="5048" end_char="5051">site</TOKEN>
<TOKEN id="token-48-28" pos="word" morph="none" start_char="5053" end_char="5054">of</TOKEN>
<TOKEN id="token-48-29" pos="word" morph="none" start_char="5056" end_char="5058">the</TOKEN>
<TOKEN id="token-48-30" pos="word" morph="none" start_char="5060" end_char="5067">pandemic</TOKEN>
<TOKEN id="token-48-31" pos="punct" morph="none" start_char="5068" end_char="5068">.</TOKEN>
</SEG>
<SEG id="segment-49" start_char="5071" end_char="5176">
<ORIGINAL_TEXT>The WHO team confirmed the virus didn't make its initial jump from animals to humans at the Huanan market.</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="5071" end_char="5073">The</TOKEN>
<TOKEN id="token-49-1" pos="word" morph="none" start_char="5075" end_char="5077">WHO</TOKEN>
<TOKEN id="token-49-2" pos="word" morph="none" start_char="5079" end_char="5082">team</TOKEN>
<TOKEN id="token-49-3" pos="word" morph="none" start_char="5084" end_char="5092">confirmed</TOKEN>
<TOKEN id="token-49-4" pos="word" morph="none" start_char="5094" end_char="5096">the</TOKEN>
<TOKEN id="token-49-5" pos="word" morph="none" start_char="5098" end_char="5102">virus</TOKEN>
<TOKEN id="token-49-6" pos="word" morph="none" start_char="5104" end_char="5109">didn't</TOKEN>
<TOKEN id="token-49-7" pos="word" morph="none" start_char="5111" end_char="5114">make</TOKEN>
<TOKEN id="token-49-8" pos="word" morph="none" start_char="5116" end_char="5118">its</TOKEN>
<TOKEN id="token-49-9" pos="word" morph="none" start_char="5120" end_char="5126">initial</TOKEN>
<TOKEN id="token-49-10" pos="word" morph="none" start_char="5128" end_char="5131">jump</TOKEN>
<TOKEN id="token-49-11" pos="word" morph="none" start_char="5133" end_char="5136">from</TOKEN>
<TOKEN id="token-49-12" pos="word" morph="none" start_char="5138" end_char="5144">animals</TOKEN>
<TOKEN id="token-49-13" pos="word" morph="none" start_char="5146" end_char="5147">to</TOKEN>
<TOKEN id="token-49-14" pos="word" morph="none" start_char="5149" end_char="5154">humans</TOKEN>
<TOKEN id="token-49-15" pos="word" morph="none" start_char="5156" end_char="5157">at</TOKEN>
<TOKEN id="token-49-16" pos="word" morph="none" start_char="5159" end_char="5161">the</TOKEN>
<TOKEN id="token-49-17" pos="word" morph="none" start_char="5163" end_char="5168">Huanan</TOKEN>
<TOKEN id="token-49-18" pos="word" morph="none" start_char="5170" end_char="5175">market</TOKEN>
<TOKEN id="token-49-19" pos="punct" morph="none" start_char="5176" end_char="5176">.</TOKEN>
</SEG>
<SEG id="segment-50" start_char="5178" end_char="5415">
<ORIGINAL_TEXT>Evidence suggests the virus was circulating elsewhere in Wuhan before the market outbreak happened, Liang Wannian, a member of China's National Health Commission who assisted with the WHO investigation, said in a press conference Tuesday.</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="5178" end_char="5185">Evidence</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="5187" end_char="5194">suggests</TOKEN>
<TOKEN id="token-50-2" pos="word" morph="none" start_char="5196" end_char="5198">the</TOKEN>
<TOKEN id="token-50-3" pos="word" morph="none" start_char="5200" end_char="5204">virus</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="5206" end_char="5208">was</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="5210" end_char="5220">circulating</TOKEN>
<TOKEN id="token-50-6" pos="word" morph="none" start_char="5222" end_char="5230">elsewhere</TOKEN>
<TOKEN id="token-50-7" pos="word" morph="none" start_char="5232" end_char="5233">in</TOKEN>
<TOKEN id="token-50-8" pos="word" morph="none" start_char="5235" end_char="5239">Wuhan</TOKEN>
<TOKEN id="token-50-9" pos="word" morph="none" start_char="5241" end_char="5246">before</TOKEN>
<TOKEN id="token-50-10" pos="word" morph="none" start_char="5248" end_char="5250">the</TOKEN>
<TOKEN id="token-50-11" pos="word" morph="none" start_char="5252" end_char="5257">market</TOKEN>
<TOKEN id="token-50-12" pos="word" morph="none" start_char="5259" end_char="5266">outbreak</TOKEN>
<TOKEN id="token-50-13" pos="word" morph="none" start_char="5268" end_char="5275">happened</TOKEN>
<TOKEN id="token-50-14" pos="punct" morph="none" start_char="5276" end_char="5276">,</TOKEN>
<TOKEN id="token-50-15" pos="word" morph="none" start_char="5278" end_char="5282">Liang</TOKEN>
<TOKEN id="token-50-16" pos="word" morph="none" start_char="5284" end_char="5290">Wannian</TOKEN>
<TOKEN id="token-50-17" pos="punct" morph="none" start_char="5291" end_char="5291">,</TOKEN>
<TOKEN id="token-50-18" pos="word" morph="none" start_char="5293" end_char="5293">a</TOKEN>
<TOKEN id="token-50-19" pos="word" morph="none" start_char="5295" end_char="5300">member</TOKEN>
<TOKEN id="token-50-20" pos="word" morph="none" start_char="5302" end_char="5303">of</TOKEN>
<TOKEN id="token-50-21" pos="word" morph="none" start_char="5305" end_char="5311">China's</TOKEN>
<TOKEN id="token-50-22" pos="word" morph="none" start_char="5313" end_char="5320">National</TOKEN>
<TOKEN id="token-50-23" pos="word" morph="none" start_char="5322" end_char="5327">Health</TOKEN>
<TOKEN id="token-50-24" pos="word" morph="none" start_char="5329" end_char="5338">Commission</TOKEN>
<TOKEN id="token-50-25" pos="word" morph="none" start_char="5340" end_char="5342">who</TOKEN>
<TOKEN id="token-50-26" pos="word" morph="none" start_char="5344" end_char="5351">assisted</TOKEN>
<TOKEN id="token-50-27" pos="word" morph="none" start_char="5353" end_char="5356">with</TOKEN>
<TOKEN id="token-50-28" pos="word" morph="none" start_char="5358" end_char="5360">the</TOKEN>
<TOKEN id="token-50-29" pos="word" morph="none" start_char="5362" end_char="5364">WHO</TOKEN>
<TOKEN id="token-50-30" pos="word" morph="none" start_char="5366" end_char="5378">investigation</TOKEN>
<TOKEN id="token-50-31" pos="punct" morph="none" start_char="5379" end_char="5379">,</TOKEN>
<TOKEN id="token-50-32" pos="word" morph="none" start_char="5381" end_char="5384">said</TOKEN>
<TOKEN id="token-50-33" pos="word" morph="none" start_char="5386" end_char="5387">in</TOKEN>
<TOKEN id="token-50-34" pos="word" morph="none" start_char="5389" end_char="5389">a</TOKEN>
<TOKEN id="token-50-35" pos="word" morph="none" start_char="5391" end_char="5395">press</TOKEN>
<TOKEN id="token-50-36" pos="word" morph="none" start_char="5397" end_char="5406">conference</TOKEN>
<TOKEN id="token-50-37" pos="word" morph="none" start_char="5408" end_char="5414">Tuesday</TOKEN>
<TOKEN id="token-50-38" pos="punct" morph="none" start_char="5415" end_char="5415">.</TOKEN>
</SEG>
<SEG id="segment-51" start_char="5420" end_char="5538">
<ORIGINAL_TEXT>This wet market in Wuhan, China, pictured on January 21, 2020, was linked to one of the earliest coronavirus outbreaks.</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="word" morph="none" start_char="5420" end_char="5423">This</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="5425" end_char="5427">wet</TOKEN>
<TOKEN id="token-51-2" pos="word" morph="none" start_char="5429" end_char="5434">market</TOKEN>
<TOKEN id="token-51-3" pos="word" morph="none" start_char="5436" end_char="5437">in</TOKEN>
<TOKEN id="token-51-4" pos="word" morph="none" start_char="5439" end_char="5443">Wuhan</TOKEN>
<TOKEN id="token-51-5" pos="punct" morph="none" start_char="5444" end_char="5444">,</TOKEN>
<TOKEN id="token-51-6" pos="word" morph="none" start_char="5446" end_char="5450">China</TOKEN>
<TOKEN id="token-51-7" pos="punct" morph="none" start_char="5451" end_char="5451">,</TOKEN>
<TOKEN id="token-51-8" pos="word" morph="none" start_char="5453" end_char="5460">pictured</TOKEN>
<TOKEN id="token-51-9" pos="word" morph="none" start_char="5462" end_char="5463">on</TOKEN>
<TOKEN id="token-51-10" pos="word" morph="none" start_char="5465" end_char="5471">January</TOKEN>
<TOKEN id="token-51-11" pos="word" morph="none" start_char="5473" end_char="5474">21</TOKEN>
<TOKEN id="token-51-12" pos="punct" morph="none" start_char="5475" end_char="5475">,</TOKEN>
<TOKEN id="token-51-13" pos="word" morph="none" start_char="5477" end_char="5480">2020</TOKEN>
<TOKEN id="token-51-14" pos="punct" morph="none" start_char="5481" end_char="5481">,</TOKEN>
<TOKEN id="token-51-15" pos="word" morph="none" start_char="5483" end_char="5485">was</TOKEN>
<TOKEN id="token-51-16" pos="word" morph="none" start_char="5487" end_char="5492">linked</TOKEN>
<TOKEN id="token-51-17" pos="word" morph="none" start_char="5494" end_char="5495">to</TOKEN>
<TOKEN id="token-51-18" pos="word" morph="none" start_char="5497" end_char="5499">one</TOKEN>
<TOKEN id="token-51-19" pos="word" morph="none" start_char="5501" end_char="5502">of</TOKEN>
<TOKEN id="token-51-20" pos="word" morph="none" start_char="5504" end_char="5506">the</TOKEN>
<TOKEN id="token-51-21" pos="word" morph="none" start_char="5508" end_char="5515">earliest</TOKEN>
<TOKEN id="token-51-22" pos="word" morph="none" start_char="5517" end_char="5527">coronavirus</TOKEN>
<TOKEN id="token-51-23" pos="word" morph="none" start_char="5529" end_char="5537">outbreaks</TOKEN>
<TOKEN id="token-51-24" pos="punct" morph="none" start_char="5538" end_char="5538">.</TOKEN>
</SEG>
<SEG id="segment-52" start_char="5541" end_char="5552">
<ORIGINAL_TEXT>Dake Kang/AP</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="5541" end_char="5544">Dake</TOKEN>
<TOKEN id="token-52-1" pos="unknown" morph="none" start_char="5546" end_char="5552">Kang/AP</TOKEN>
</SEG>
<SEG id="segment-53" start_char="5556" end_char="5697">
<ORIGINAL_TEXT>A May investigation also led the Chinese Center for Disease Control and Prevention to rule the market out as the origin place of the outbreak.</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="word" morph="none" start_char="5556" end_char="5556">A</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="5558" end_char="5560">May</TOKEN>
<TOKEN id="token-53-2" pos="word" morph="none" start_char="5562" end_char="5574">investigation</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="5576" end_char="5579">also</TOKEN>
<TOKEN id="token-53-4" pos="word" morph="none" start_char="5581" end_char="5583">led</TOKEN>
<TOKEN id="token-53-5" pos="word" morph="none" start_char="5585" end_char="5587">the</TOKEN>
<TOKEN id="token-53-6" pos="word" morph="none" start_char="5589" end_char="5595">Chinese</TOKEN>
<TOKEN id="token-53-7" pos="word" morph="none" start_char="5597" end_char="5602">Center</TOKEN>
<TOKEN id="token-53-8" pos="word" morph="none" start_char="5604" end_char="5606">for</TOKEN>
<TOKEN id="token-53-9" pos="word" morph="none" start_char="5608" end_char="5614">Disease</TOKEN>
<TOKEN id="token-53-10" pos="word" morph="none" start_char="5616" end_char="5622">Control</TOKEN>
<TOKEN id="token-53-11" pos="word" morph="none" start_char="5624" end_char="5626">and</TOKEN>
<TOKEN id="token-53-12" pos="word" morph="none" start_char="5628" end_char="5637">Prevention</TOKEN>
<TOKEN id="token-53-13" pos="word" morph="none" start_char="5639" end_char="5640">to</TOKEN>
<TOKEN id="token-53-14" pos="word" morph="none" start_char="5642" end_char="5645">rule</TOKEN>
<TOKEN id="token-53-15" pos="word" morph="none" start_char="5647" end_char="5649">the</TOKEN>
<TOKEN id="token-53-16" pos="word" morph="none" start_char="5651" end_char="5656">market</TOKEN>
<TOKEN id="token-53-17" pos="word" morph="none" start_char="5658" end_char="5660">out</TOKEN>
<TOKEN id="token-53-18" pos="word" morph="none" start_char="5662" end_char="5663">as</TOKEN>
<TOKEN id="token-53-19" pos="word" morph="none" start_char="5665" end_char="5667">the</TOKEN>
<TOKEN id="token-53-20" pos="word" morph="none" start_char="5669" end_char="5674">origin</TOKEN>
<TOKEN id="token-53-21" pos="word" morph="none" start_char="5676" end_char="5680">place</TOKEN>
<TOKEN id="token-53-22" pos="word" morph="none" start_char="5682" end_char="5683">of</TOKEN>
<TOKEN id="token-53-23" pos="word" morph="none" start_char="5685" end_char="5687">the</TOKEN>
<TOKEN id="token-53-24" pos="word" morph="none" start_char="5689" end_char="5696">outbreak</TOKEN>
<TOKEN id="token-53-25" pos="punct" morph="none" start_char="5697" end_char="5697">.</TOKEN>
</SEG>
<SEG id="segment-54" start_char="5699" end_char="5769">
<ORIGINAL_TEXT>That's because none of the animals there tested positive for the virus.</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="word" morph="none" start_char="5699" end_char="5704">That's</TOKEN>
<TOKEN id="token-54-1" pos="word" morph="none" start_char="5706" end_char="5712">because</TOKEN>
<TOKEN id="token-54-2" pos="word" morph="none" start_char="5714" end_char="5717">none</TOKEN>
<TOKEN id="token-54-3" pos="word" morph="none" start_char="5719" end_char="5720">of</TOKEN>
<TOKEN id="token-54-4" pos="word" morph="none" start_char="5722" end_char="5724">the</TOKEN>
<TOKEN id="token-54-5" pos="word" morph="none" start_char="5726" end_char="5732">animals</TOKEN>
<TOKEN id="token-54-6" pos="word" morph="none" start_char="5734" end_char="5738">there</TOKEN>
<TOKEN id="token-54-7" pos="word" morph="none" start_char="5740" end_char="5745">tested</TOKEN>
<TOKEN id="token-54-8" pos="word" morph="none" start_char="5747" end_char="5754">positive</TOKEN>
<TOKEN id="token-54-9" pos="word" morph="none" start_char="5756" end_char="5758">for</TOKEN>
<TOKEN id="token-54-10" pos="word" morph="none" start_char="5760" end_char="5762">the</TOKEN>
<TOKEN id="token-54-11" pos="word" morph="none" start_char="5764" end_char="5768">virus</TOKEN>
<TOKEN id="token-54-12" pos="punct" morph="none" start_char="5769" end_char="5769">.</TOKEN>
</SEG>
<SEG id="segment-55" start_char="5772" end_char="5916">
<ORIGINAL_TEXT>Most likely, the market was simply the site of an early superspreader event, with one sick person infecting an atypically large number of others.</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="word" morph="none" start_char="5772" end_char="5775">Most</TOKEN>
<TOKEN id="token-55-1" pos="word" morph="none" start_char="5777" end_char="5782">likely</TOKEN>
<TOKEN id="token-55-2" pos="punct" morph="none" start_char="5783" end_char="5783">,</TOKEN>
<TOKEN id="token-55-3" pos="word" morph="none" start_char="5785" end_char="5787">the</TOKEN>
<TOKEN id="token-55-4" pos="word" morph="none" start_char="5789" end_char="5794">market</TOKEN>
<TOKEN id="token-55-5" pos="word" morph="none" start_char="5796" end_char="5798">was</TOKEN>
<TOKEN id="token-55-6" pos="word" morph="none" start_char="5800" end_char="5805">simply</TOKEN>
<TOKEN id="token-55-7" pos="word" morph="none" start_char="5807" end_char="5809">the</TOKEN>
<TOKEN id="token-55-8" pos="word" morph="none" start_char="5811" end_char="5814">site</TOKEN>
<TOKEN id="token-55-9" pos="word" morph="none" start_char="5816" end_char="5817">of</TOKEN>
<TOKEN id="token-55-10" pos="word" morph="none" start_char="5819" end_char="5820">an</TOKEN>
<TOKEN id="token-55-11" pos="word" morph="none" start_char="5822" end_char="5826">early</TOKEN>
<TOKEN id="token-55-12" pos="word" morph="none" start_char="5828" end_char="5840">superspreader</TOKEN>
<TOKEN id="token-55-13" pos="word" morph="none" start_char="5842" end_char="5846">event</TOKEN>
<TOKEN id="token-55-14" pos="punct" morph="none" start_char="5847" end_char="5847">,</TOKEN>
<TOKEN id="token-55-15" pos="word" morph="none" start_char="5849" end_char="5852">with</TOKEN>
<TOKEN id="token-55-16" pos="word" morph="none" start_char="5854" end_char="5856">one</TOKEN>
<TOKEN id="token-55-17" pos="word" morph="none" start_char="5858" end_char="5861">sick</TOKEN>
<TOKEN id="token-55-18" pos="word" morph="none" start_char="5863" end_char="5868">person</TOKEN>
<TOKEN id="token-55-19" pos="word" morph="none" start_char="5870" end_char="5878">infecting</TOKEN>
<TOKEN id="token-55-20" pos="word" morph="none" start_char="5880" end_char="5881">an</TOKEN>
<TOKEN id="token-55-21" pos="word" morph="none" start_char="5883" end_char="5892">atypically</TOKEN>
<TOKEN id="token-55-22" pos="word" morph="none" start_char="5894" end_char="5898">large</TOKEN>
<TOKEN id="token-55-23" pos="word" morph="none" start_char="5900" end_char="5905">number</TOKEN>
<TOKEN id="token-55-24" pos="word" morph="none" start_char="5907" end_char="5908">of</TOKEN>
<TOKEN id="token-55-25" pos="word" morph="none" start_char="5910" end_char="5915">others</TOKEN>
<TOKEN id="token-55-26" pos="punct" morph="none" start_char="5916" end_char="5916">.</TOKEN>
</SEG>
<SEG id="segment-56" start_char="5918" end_char="6024">
<ORIGINAL_TEXT>Superspreader events around the world have created clusters of infections that cropped up almost overnight.</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="5918" end_char="5930">Superspreader</TOKEN>
<TOKEN id="token-56-1" pos="word" morph="none" start_char="5932" end_char="5937">events</TOKEN>
<TOKEN id="token-56-2" pos="word" morph="none" start_char="5939" end_char="5944">around</TOKEN>
<TOKEN id="token-56-3" pos="word" morph="none" start_char="5946" end_char="5948">the</TOKEN>
<TOKEN id="token-56-4" pos="word" morph="none" start_char="5950" end_char="5954">world</TOKEN>
<TOKEN id="token-56-5" pos="word" morph="none" start_char="5956" end_char="5959">have</TOKEN>
<TOKEN id="token-56-6" pos="word" morph="none" start_char="5961" end_char="5967">created</TOKEN>
<TOKEN id="token-56-7" pos="word" morph="none" start_char="5969" end_char="5976">clusters</TOKEN>
<TOKEN id="token-56-8" pos="word" morph="none" start_char="5978" end_char="5979">of</TOKEN>
<TOKEN id="token-56-9" pos="word" morph="none" start_char="5981" end_char="5990">infections</TOKEN>
<TOKEN id="token-56-10" pos="word" morph="none" start_char="5992" end_char="5995">that</TOKEN>
<TOKEN id="token-56-11" pos="word" morph="none" start_char="5997" end_char="6003">cropped</TOKEN>
<TOKEN id="token-56-12" pos="word" morph="none" start_char="6005" end_char="6006">up</TOKEN>
<TOKEN id="token-56-13" pos="word" morph="none" start_char="6008" end_char="6013">almost</TOKEN>
<TOKEN id="token-56-14" pos="word" morph="none" start_char="6015" end_char="6023">overnight</TOKEN>
<TOKEN id="token-56-15" pos="punct" morph="none" start_char="6024" end_char="6024">.</TOKEN>
</SEG>
<SEG id="segment-57" start_char="6027" end_char="6086">
<ORIGINAL_TEXT>Research suggests the virus was in Italy in the fall of 2019</ORIGINAL_TEXT>
<TOKEN id="token-57-0" pos="word" morph="none" start_char="6027" end_char="6034">Research</TOKEN>
<TOKEN id="token-57-1" pos="word" morph="none" start_char="6036" end_char="6043">suggests</TOKEN>
<TOKEN id="token-57-2" pos="word" morph="none" start_char="6045" end_char="6047">the</TOKEN>
<TOKEN id="token-57-3" pos="word" morph="none" start_char="6049" end_char="6053">virus</TOKEN>
<TOKEN id="token-57-4" pos="word" morph="none" start_char="6055" end_char="6057">was</TOKEN>
<TOKEN id="token-57-5" pos="word" morph="none" start_char="6059" end_char="6060">in</TOKEN>
<TOKEN id="token-57-6" pos="word" morph="none" start_char="6062" end_char="6066">Italy</TOKEN>
<TOKEN id="token-57-7" pos="word" morph="none" start_char="6068" end_char="6069">in</TOKEN>
<TOKEN id="token-57-8" pos="word" morph="none" start_char="6071" end_char="6073">the</TOKEN>
<TOKEN id="token-57-9" pos="word" morph="none" start_char="6075" end_char="6078">fall</TOKEN>
<TOKEN id="token-57-10" pos="word" morph="none" start_char="6080" end_char="6081">of</TOKEN>
<TOKEN id="token-57-11" pos="word" morph="none" start_char="6083" end_char="6086">2019</TOKEN>
</SEG>
<SEG id="segment-58" start_char="6091" end_char="6236">
<ORIGINAL_TEXT>A COVID-19 patient is transported by nurses inside a biological containment stretcher in the Da Procida Hospital in Salerno, Italy, April 8, 2020.</ORIGINAL_TEXT>
<TOKEN id="token-58-0" pos="word" morph="none" start_char="6091" end_char="6091">A</TOKEN>
<TOKEN id="token-58-1" pos="unknown" morph="none" start_char="6093" end_char="6100">COVID-19</TOKEN>
<TOKEN id="token-58-2" pos="word" morph="none" start_char="6102" end_char="6108">patient</TOKEN>
<TOKEN id="token-58-3" pos="word" morph="none" start_char="6110" end_char="6111">is</TOKEN>
<TOKEN id="token-58-4" pos="word" morph="none" start_char="6113" end_char="6123">transported</TOKEN>
<TOKEN id="token-58-5" pos="word" morph="none" start_char="6125" end_char="6126">by</TOKEN>
<TOKEN id="token-58-6" pos="word" morph="none" start_char="6128" end_char="6133">nurses</TOKEN>
<TOKEN id="token-58-7" pos="word" morph="none" start_char="6135" end_char="6140">inside</TOKEN>
<TOKEN id="token-58-8" pos="word" morph="none" start_char="6142" end_char="6142">a</TOKEN>
<TOKEN id="token-58-9" pos="word" morph="none" start_char="6144" end_char="6153">biological</TOKEN>
<TOKEN id="token-58-10" pos="word" morph="none" start_char="6155" end_char="6165">containment</TOKEN>
<TOKEN id="token-58-11" pos="word" morph="none" start_char="6167" end_char="6175">stretcher</TOKEN>
<TOKEN id="token-58-12" pos="word" morph="none" start_char="6177" end_char="6178">in</TOKEN>
<TOKEN id="token-58-13" pos="word" morph="none" start_char="6180" end_char="6182">the</TOKEN>
<TOKEN id="token-58-14" pos="word" morph="none" start_char="6184" end_char="6185">Da</TOKEN>
<TOKEN id="token-58-15" pos="word" morph="none" start_char="6187" end_char="6193">Procida</TOKEN>
<TOKEN id="token-58-16" pos="word" morph="none" start_char="6195" end_char="6202">Hospital</TOKEN>
<TOKEN id="token-58-17" pos="word" morph="none" start_char="6204" end_char="6205">in</TOKEN>
<TOKEN id="token-58-18" pos="word" morph="none" start_char="6207" end_char="6213">Salerno</TOKEN>
<TOKEN id="token-58-19" pos="punct" morph="none" start_char="6214" end_char="6214">,</TOKEN>
<TOKEN id="token-58-20" pos="word" morph="none" start_char="6216" end_char="6220">Italy</TOKEN>
<TOKEN id="token-58-21" pos="punct" morph="none" start_char="6221" end_char="6221">,</TOKEN>
<TOKEN id="token-58-22" pos="word" morph="none" start_char="6223" end_char="6227">April</TOKEN>
<TOKEN id="token-58-23" pos="word" morph="none" start_char="6229" end_char="6229">8</TOKEN>
<TOKEN id="token-58-24" pos="punct" morph="none" start_char="6230" end_char="6230">,</TOKEN>
<TOKEN id="token-58-25" pos="word" morph="none" start_char="6232" end_char="6235">2020</TOKEN>
<TOKEN id="token-58-26" pos="punct" morph="none" start_char="6236" end_char="6236">.</TOKEN>
</SEG>
<SEG id="segment-59" start_char="6239" end_char="6262">
<ORIGINAL_TEXT>Ivan Romano/Getty Images</ORIGINAL_TEXT>
<TOKEN id="token-59-0" pos="word" morph="none" start_char="6239" end_char="6242">Ivan</TOKEN>
<TOKEN id="token-59-1" pos="unknown" morph="none" start_char="6244" end_char="6255">Romano/Getty</TOKEN>
<TOKEN id="token-59-2" pos="word" morph="none" start_char="6257" end_char="6262">Images</TOKEN>
</SEG>
<SEG id="segment-60" start_char="6266" end_char="6349">
<ORIGINAL_TEXT>Italy recorded its first official coronavirus case in Lombardy on February 21, 2020.</ORIGINAL_TEXT>
<TOKEN id="token-60-0" pos="word" morph="none" start_char="6266" end_char="6270">Italy</TOKEN>
<TOKEN id="token-60-1" pos="word" morph="none" start_char="6272" end_char="6279">recorded</TOKEN>
<TOKEN id="token-60-2" pos="word" morph="none" start_char="6281" end_char="6283">its</TOKEN>
<TOKEN id="token-60-3" pos="word" morph="none" start_char="6285" end_char="6289">first</TOKEN>
<TOKEN id="token-60-4" pos="word" morph="none" start_char="6291" end_char="6298">official</TOKEN>
<TOKEN id="token-60-5" pos="word" morph="none" start_char="6300" end_char="6310">coronavirus</TOKEN>
<TOKEN id="token-60-6" pos="word" morph="none" start_char="6312" end_char="6315">case</TOKEN>
<TOKEN id="token-60-7" pos="word" morph="none" start_char="6317" end_char="6318">in</TOKEN>
<TOKEN id="token-60-8" pos="word" morph="none" start_char="6320" end_char="6327">Lombardy</TOKEN>
<TOKEN id="token-60-9" pos="word" morph="none" start_char="6329" end_char="6330">on</TOKEN>
<TOKEN id="token-60-10" pos="word" morph="none" start_char="6332" end_char="6339">February</TOKEN>
<TOKEN id="token-60-11" pos="word" morph="none" start_char="6341" end_char="6342">21</TOKEN>
<TOKEN id="token-60-12" pos="punct" morph="none" start_char="6343" end_char="6343">,</TOKEN>
<TOKEN id="token-60-13" pos="word" morph="none" start_char="6345" end_char="6348">2020</TOKEN>
<TOKEN id="token-60-14" pos="punct" morph="none" start_char="6349" end_char="6349">.</TOKEN>
</SEG>
<SEG id="segment-61" start_char="6351" end_char="6483">
<ORIGINAL_TEXT>Yet a recent study found coronavirus antibodies in blood samples collected from 23 Italians in September 2019 and 27 in October 2019.</ORIGINAL_TEXT>
<TOKEN id="token-61-0" pos="word" morph="none" start_char="6351" end_char="6353">Yet</TOKEN>
<TOKEN id="token-61-1" pos="word" morph="none" start_char="6355" end_char="6355">a</TOKEN>
<TOKEN id="token-61-2" pos="word" morph="none" start_char="6357" end_char="6362">recent</TOKEN>
<TOKEN id="token-61-3" pos="word" morph="none" start_char="6364" end_char="6368">study</TOKEN>
<TOKEN id="token-61-4" pos="word" morph="none" start_char="6370" end_char="6374">found</TOKEN>
<TOKEN id="token-61-5" pos="word" morph="none" start_char="6376" end_char="6386">coronavirus</TOKEN>
<TOKEN id="token-61-6" pos="word" morph="none" start_char="6388" end_char="6397">antibodies</TOKEN>
<TOKEN id="token-61-7" pos="word" morph="none" start_char="6399" end_char="6400">in</TOKEN>
<TOKEN id="token-61-8" pos="word" morph="none" start_char="6402" end_char="6406">blood</TOKEN>
<TOKEN id="token-61-9" pos="word" morph="none" start_char="6408" end_char="6414">samples</TOKEN>
<TOKEN id="token-61-10" pos="word" morph="none" start_char="6416" end_char="6424">collected</TOKEN>
<TOKEN id="token-61-11" pos="word" morph="none" start_char="6426" end_char="6429">from</TOKEN>
<TOKEN id="token-61-12" pos="word" morph="none" start_char="6431" end_char="6432">23</TOKEN>
<TOKEN id="token-61-13" pos="word" morph="none" start_char="6434" end_char="6441">Italians</TOKEN>
<TOKEN id="token-61-14" pos="word" morph="none" start_char="6443" end_char="6444">in</TOKEN>
<TOKEN id="token-61-15" pos="word" morph="none" start_char="6446" end_char="6454">September</TOKEN>
<TOKEN id="token-61-16" pos="word" morph="none" start_char="6456" end_char="6459">2019</TOKEN>
<TOKEN id="token-61-17" pos="word" morph="none" start_char="6461" end_char="6463">and</TOKEN>
<TOKEN id="token-61-18" pos="word" morph="none" start_char="6465" end_char="6466">27</TOKEN>
<TOKEN id="token-61-19" pos="word" morph="none" start_char="6468" end_char="6469">in</TOKEN>
<TOKEN id="token-61-20" pos="word" morph="none" start_char="6471" end_char="6477">October</TOKEN>
<TOKEN id="token-61-21" pos="word" morph="none" start_char="6479" end_char="6482">2019</TOKEN>
<TOKEN id="token-61-22" pos="punct" morph="none" start_char="6483" end_char="6483">.</TOKEN>
</SEG>
<SEG id="segment-62" start_char="6486" end_char="6779">
<ORIGINAL_TEXT>"Our results indicate that SARS-CoV-2 circulated in Italy earlier than the first official COVID-19 cases were diagnosed in Lombardy, even long before the first official reports from the Chinese authorities, casting new light on the onset and spread of the COVID-19 pandemic," the authors wrote.</ORIGINAL_TEXT>
<TOKEN id="token-62-0" pos="punct" morph="none" start_char="6486" end_char="6486">"</TOKEN>
<TOKEN id="token-62-1" pos="word" morph="none" start_char="6487" end_char="6489">Our</TOKEN>
<TOKEN id="token-62-2" pos="word" morph="none" start_char="6491" end_char="6497">results</TOKEN>
<TOKEN id="token-62-3" pos="word" morph="none" start_char="6499" end_char="6506">indicate</TOKEN>
<TOKEN id="token-62-4" pos="word" morph="none" start_char="6508" end_char="6511">that</TOKEN>
<TOKEN id="token-62-5" pos="unknown" morph="none" start_char="6513" end_char="6522">SARS-CoV-2</TOKEN>
<TOKEN id="token-62-6" pos="word" morph="none" start_char="6524" end_char="6533">circulated</TOKEN>
<TOKEN id="token-62-7" pos="word" morph="none" start_char="6535" end_char="6536">in</TOKEN>
<TOKEN id="token-62-8" pos="word" morph="none" start_char="6538" end_char="6542">Italy</TOKEN>
<TOKEN id="token-62-9" pos="word" morph="none" start_char="6544" end_char="6550">earlier</TOKEN>
<TOKEN id="token-62-10" pos="word" morph="none" start_char="6552" end_char="6555">than</TOKEN>
<TOKEN id="token-62-11" pos="word" morph="none" start_char="6557" end_char="6559">the</TOKEN>
<TOKEN id="token-62-12" pos="word" morph="none" start_char="6561" end_char="6565">first</TOKEN>
<TOKEN id="token-62-13" pos="word" morph="none" start_char="6567" end_char="6574">official</TOKEN>
<TOKEN id="token-62-14" pos="unknown" morph="none" start_char="6576" end_char="6583">COVID-19</TOKEN>
<TOKEN id="token-62-15" pos="word" morph="none" start_char="6585" end_char="6589">cases</TOKEN>
<TOKEN id="token-62-16" pos="word" morph="none" start_char="6591" end_char="6594">were</TOKEN>
<TOKEN id="token-62-17" pos="word" morph="none" start_char="6596" end_char="6604">diagnosed</TOKEN>
<TOKEN id="token-62-18" pos="word" morph="none" start_char="6606" end_char="6607">in</TOKEN>
<TOKEN id="token-62-19" pos="word" morph="none" start_char="6609" end_char="6616">Lombardy</TOKEN>
<TOKEN id="token-62-20" pos="punct" morph="none" start_char="6617" end_char="6617">,</TOKEN>
<TOKEN id="token-62-21" pos="word" morph="none" start_char="6619" end_char="6622">even</TOKEN>
<TOKEN id="token-62-22" pos="word" morph="none" start_char="6624" end_char="6627">long</TOKEN>
<TOKEN id="token-62-23" pos="word" morph="none" start_char="6629" end_char="6634">before</TOKEN>
<TOKEN id="token-62-24" pos="word" morph="none" start_char="6636" end_char="6638">the</TOKEN>
<TOKEN id="token-62-25" pos="word" morph="none" start_char="6640" end_char="6644">first</TOKEN>
<TOKEN id="token-62-26" pos="word" morph="none" start_char="6646" end_char="6653">official</TOKEN>
<TOKEN id="token-62-27" pos="word" morph="none" start_char="6655" end_char="6661">reports</TOKEN>
<TOKEN id="token-62-28" pos="word" morph="none" start_char="6663" end_char="6666">from</TOKEN>
<TOKEN id="token-62-29" pos="word" morph="none" start_char="6668" end_char="6670">the</TOKEN>
<TOKEN id="token-62-30" pos="word" morph="none" start_char="6672" end_char="6678">Chinese</TOKEN>
<TOKEN id="token-62-31" pos="word" morph="none" start_char="6680" end_char="6690">authorities</TOKEN>
<TOKEN id="token-62-32" pos="punct" morph="none" start_char="6691" end_char="6691">,</TOKEN>
<TOKEN id="token-62-33" pos="word" morph="none" start_char="6693" end_char="6699">casting</TOKEN>
<TOKEN id="token-62-34" pos="word" morph="none" start_char="6701" end_char="6703">new</TOKEN>
<TOKEN id="token-62-35" pos="word" morph="none" start_char="6705" end_char="6709">light</TOKEN>
<TOKEN id="token-62-36" pos="word" morph="none" start_char="6711" end_char="6712">on</TOKEN>
<TOKEN id="token-62-37" pos="word" morph="none" start_char="6714" end_char="6716">the</TOKEN>
<TOKEN id="token-62-38" pos="word" morph="none" start_char="6718" end_char="6722">onset</TOKEN>
<TOKEN id="token-62-39" pos="word" morph="none" start_char="6724" end_char="6726">and</TOKEN>
<TOKEN id="token-62-40" pos="word" morph="none" start_char="6728" end_char="6733">spread</TOKEN>
<TOKEN id="token-62-41" pos="word" morph="none" start_char="6735" end_char="6736">of</TOKEN>
<TOKEN id="token-62-42" pos="word" morph="none" start_char="6738" end_char="6740">the</TOKEN>
<TOKEN id="token-62-43" pos="unknown" morph="none" start_char="6742" end_char="6749">COVID-19</TOKEN>
<TOKEN id="token-62-44" pos="word" morph="none" start_char="6751" end_char="6758">pandemic</TOKEN>
<TOKEN id="token-62-45" pos="punct" morph="none" start_char="6759" end_char="6760">,"</TOKEN>
<TOKEN id="token-62-46" pos="word" morph="none" start_char="6762" end_char="6764">the</TOKEN>
<TOKEN id="token-62-47" pos="word" morph="none" start_char="6766" end_char="6772">authors</TOKEN>
<TOKEN id="token-62-48" pos="word" morph="none" start_char="6774" end_char="6778">wrote</TOKEN>
<TOKEN id="token-62-49" pos="punct" morph="none" start_char="6779" end_char="6779">.</TOKEN>
</SEG>
<SEG id="segment-63" start_char="6781" end_char="6827">
<ORIGINAL_TEXT>(SARS-CoV-2 is the clinical name of the virus.)</ORIGINAL_TEXT>
<TOKEN id="token-63-0" pos="punct" morph="none" start_char="6781" end_char="6781">(</TOKEN>
<TOKEN id="token-63-1" pos="unknown" morph="none" start_char="6782" end_char="6791">SARS-CoV-2</TOKEN>
<TOKEN id="token-63-2" pos="word" morph="none" start_char="6793" end_char="6794">is</TOKEN>
<TOKEN id="token-63-3" pos="word" morph="none" start_char="6796" end_char="6798">the</TOKEN>
<TOKEN id="token-63-4" pos="word" morph="none" start_char="6800" end_char="6807">clinical</TOKEN>
<TOKEN id="token-63-5" pos="word" morph="none" start_char="6809" end_char="6812">name</TOKEN>
<TOKEN id="token-63-6" pos="word" morph="none" start_char="6814" end_char="6815">of</TOKEN>
<TOKEN id="token-63-7" pos="word" morph="none" start_char="6817" end_char="6819">the</TOKEN>
<TOKEN id="token-63-8" pos="word" morph="none" start_char="6821" end_char="6825">virus</TOKEN>
<TOKEN id="token-63-9" pos="punct" morph="none" start_char="6826" end_char="6827">.)</TOKEN>
</SEG>
<SEG id="segment-64" start_char="6830" end_char="7044">
<ORIGINAL_TEXT>A study conducted by Rome's Department of Environment and Health supports that conclusion: Researchers found the coronavirus' genetic material in sewage samples from Milan and Turin dating back to December 18, 2019.</ORIGINAL_TEXT>
<TOKEN id="token-64-0" pos="word" morph="none" start_char="6830" end_char="6830">A</TOKEN>
<TOKEN id="token-64-1" pos="word" morph="none" start_char="6832" end_char="6836">study</TOKEN>
<TOKEN id="token-64-2" pos="word" morph="none" start_char="6838" end_char="6846">conducted</TOKEN>
<TOKEN id="token-64-3" pos="word" morph="none" start_char="6848" end_char="6849">by</TOKEN>
<TOKEN id="token-64-4" pos="word" morph="none" start_char="6851" end_char="6856">Rome's</TOKEN>
<TOKEN id="token-64-5" pos="word" morph="none" start_char="6858" end_char="6867">Department</TOKEN>
<TOKEN id="token-64-6" pos="word" morph="none" start_char="6869" end_char="6870">of</TOKEN>
<TOKEN id="token-64-7" pos="word" morph="none" start_char="6872" end_char="6882">Environment</TOKEN>
<TOKEN id="token-64-8" pos="word" morph="none" start_char="6884" end_char="6886">and</TOKEN>
<TOKEN id="token-64-9" pos="word" morph="none" start_char="6888" end_char="6893">Health</TOKEN>
<TOKEN id="token-64-10" pos="word" morph="none" start_char="6895" end_char="6902">supports</TOKEN>
<TOKEN id="token-64-11" pos="word" morph="none" start_char="6904" end_char="6907">that</TOKEN>
<TOKEN id="token-64-12" pos="word" morph="none" start_char="6909" end_char="6918">conclusion</TOKEN>
<TOKEN id="token-64-13" pos="punct" morph="none" start_char="6919" end_char="6919">:</TOKEN>
<TOKEN id="token-64-14" pos="word" morph="none" start_char="6921" end_char="6931">Researchers</TOKEN>
<TOKEN id="token-64-15" pos="word" morph="none" start_char="6933" end_char="6937">found</TOKEN>
<TOKEN id="token-64-16" pos="word" morph="none" start_char="6939" end_char="6941">the</TOKEN>
<TOKEN id="token-64-17" pos="word" morph="none" start_char="6943" end_char="6953">coronavirus</TOKEN>
<TOKEN id="token-64-18" pos="punct" morph="none" start_char="6954" end_char="6954">'</TOKEN>
<TOKEN id="token-64-19" pos="word" morph="none" start_char="6956" end_char="6962">genetic</TOKEN>
<TOKEN id="token-64-20" pos="word" morph="none" start_char="6964" end_char="6971">material</TOKEN>
<TOKEN id="token-64-21" pos="word" morph="none" start_char="6973" end_char="6974">in</TOKEN>
<TOKEN id="token-64-22" pos="word" morph="none" start_char="6976" end_char="6981">sewage</TOKEN>
<TOKEN id="token-64-23" pos="word" morph="none" start_char="6983" end_char="6989">samples</TOKEN>
<TOKEN id="token-64-24" pos="word" morph="none" start_char="6991" end_char="6994">from</TOKEN>
<TOKEN id="token-64-25" pos="word" morph="none" start_char="6996" end_char="7000">Milan</TOKEN>
<TOKEN id="token-64-26" pos="word" morph="none" start_char="7002" end_char="7004">and</TOKEN>
<TOKEN id="token-64-27" pos="word" morph="none" start_char="7006" end_char="7010">Turin</TOKEN>
<TOKEN id="token-64-28" pos="word" morph="none" start_char="7012" end_char="7017">dating</TOKEN>
<TOKEN id="token-64-29" pos="word" morph="none" start_char="7019" end_char="7022">back</TOKEN>
<TOKEN id="token-64-30" pos="word" morph="none" start_char="7024" end_char="7025">to</TOKEN>
<TOKEN id="token-64-31" pos="word" morph="none" start_char="7027" end_char="7034">December</TOKEN>
<TOKEN id="token-64-32" pos="word" morph="none" start_char="7036" end_char="7037">18</TOKEN>
<TOKEN id="token-64-33" pos="punct" morph="none" start_char="7038" end_char="7038">,</TOKEN>
<TOKEN id="token-64-34" pos="word" morph="none" start_char="7040" end_char="7043">2019</TOKEN>
<TOKEN id="token-64-35" pos="punct" morph="none" start_char="7044" end_char="7044">.</TOKEN>
</SEG>
<SEG id="segment-65" start_char="7048" end_char="7196">
<ORIGINAL_TEXT>A man walks past a billboard raising awareness about the new coronavirus that reads "All together, without fear," in Naples, Italy on March 22, 2020.</ORIGINAL_TEXT>
<TOKEN id="token-65-0" pos="word" morph="none" start_char="7048" end_char="7048">A</TOKEN>
<TOKEN id="token-65-1" pos="word" morph="none" start_char="7050" end_char="7052">man</TOKEN>
<TOKEN id="token-65-2" pos="word" morph="none" start_char="7054" end_char="7058">walks</TOKEN>
<TOKEN id="token-65-3" pos="word" morph="none" start_char="7060" end_char="7063">past</TOKEN>
<TOKEN id="token-65-4" pos="word" morph="none" start_char="7065" end_char="7065">a</TOKEN>
<TOKEN id="token-65-5" pos="word" morph="none" start_char="7067" end_char="7075">billboard</TOKEN>
<TOKEN id="token-65-6" pos="word" morph="none" start_char="7077" end_char="7083">raising</TOKEN>
<TOKEN id="token-65-7" pos="word" morph="none" start_char="7085" end_char="7093">awareness</TOKEN>
<TOKEN id="token-65-8" pos="word" morph="none" start_char="7095" end_char="7099">about</TOKEN>
<TOKEN id="token-65-9" pos="word" morph="none" start_char="7101" end_char="7103">the</TOKEN>
<TOKEN id="token-65-10" pos="word" morph="none" start_char="7105" end_char="7107">new</TOKEN>
<TOKEN id="token-65-11" pos="word" morph="none" start_char="7109" end_char="7119">coronavirus</TOKEN>
<TOKEN id="token-65-12" pos="word" morph="none" start_char="7121" end_char="7124">that</TOKEN>
<TOKEN id="token-65-13" pos="word" morph="none" start_char="7126" end_char="7130">reads</TOKEN>
<TOKEN id="token-65-14" pos="punct" morph="none" start_char="7132" end_char="7132">"</TOKEN>
<TOKEN id="token-65-15" pos="word" morph="none" start_char="7133" end_char="7135">All</TOKEN>
<TOKEN id="token-65-16" pos="word" morph="none" start_char="7137" end_char="7144">together</TOKEN>
<TOKEN id="token-65-17" pos="punct" morph="none" start_char="7145" end_char="7145">,</TOKEN>
<TOKEN id="token-65-18" pos="word" morph="none" start_char="7147" end_char="7153">without</TOKEN>
<TOKEN id="token-65-19" pos="word" morph="none" start_char="7155" end_char="7158">fear</TOKEN>
<TOKEN id="token-65-20" pos="punct" morph="none" start_char="7159" end_char="7160">,"</TOKEN>
<TOKEN id="token-65-21" pos="word" morph="none" start_char="7162" end_char="7163">in</TOKEN>
<TOKEN id="token-65-22" pos="word" morph="none" start_char="7165" end_char="7170">Naples</TOKEN>
<TOKEN id="token-65-23" pos="punct" morph="none" start_char="7171" end_char="7171">,</TOKEN>
<TOKEN id="token-65-24" pos="word" morph="none" start_char="7173" end_char="7177">Italy</TOKEN>
<TOKEN id="token-65-25" pos="word" morph="none" start_char="7179" end_char="7180">on</TOKEN>
<TOKEN id="token-65-26" pos="word" morph="none" start_char="7182" end_char="7186">March</TOKEN>
<TOKEN id="token-65-27" pos="word" morph="none" start_char="7188" end_char="7189">22</TOKEN>
<TOKEN id="token-65-28" pos="punct" morph="none" start_char="7190" end_char="7190">,</TOKEN>
<TOKEN id="token-65-29" pos="word" morph="none" start_char="7192" end_char="7195">2020</TOKEN>
<TOKEN id="token-65-30" pos="punct" morph="none" start_char="7196" end_char="7196">.</TOKEN>
</SEG>
<SEG id="segment-66" start_char="7199" end_char="7222">
<ORIGINAL_TEXT>Carlo Hermann /AFP/Getty</ORIGINAL_TEXT>
<TOKEN id="token-66-0" pos="word" morph="none" start_char="7199" end_char="7203">Carlo</TOKEN>
<TOKEN id="token-66-1" pos="word" morph="none" start_char="7205" end_char="7211">Hermann</TOKEN>
<TOKEN id="token-66-2" pos="punct" morph="none" start_char="7213" end_char="7213">/</TOKEN>
<TOKEN id="token-66-3" pos="unknown" morph="none" start_char="7214" end_char="7222">AFP/Getty</TOKEN>
</SEG>
<SEG id="segment-67" start_char="7226" end_char="7297">
<ORIGINAL_TEXT>Spain and France also found clues that the virus was circulating in 2019</ORIGINAL_TEXT>
<TOKEN id="token-67-0" pos="word" morph="none" start_char="7226" end_char="7230">Spain</TOKEN>
<TOKEN id="token-67-1" pos="word" morph="none" start_char="7232" end_char="7234">and</TOKEN>
<TOKEN id="token-67-2" pos="word" morph="none" start_char="7236" end_char="7241">France</TOKEN>
<TOKEN id="token-67-3" pos="word" morph="none" start_char="7243" end_char="7246">also</TOKEN>
<TOKEN id="token-67-4" pos="word" morph="none" start_char="7248" end_char="7252">found</TOKEN>
<TOKEN id="token-67-5" pos="word" morph="none" start_char="7254" end_char="7258">clues</TOKEN>
<TOKEN id="token-67-6" pos="word" morph="none" start_char="7260" end_char="7263">that</TOKEN>
<TOKEN id="token-67-7" pos="word" morph="none" start_char="7265" end_char="7267">the</TOKEN>
<TOKEN id="token-67-8" pos="word" morph="none" start_char="7269" end_char="7273">virus</TOKEN>
<TOKEN id="token-67-9" pos="word" morph="none" start_char="7275" end_char="7277">was</TOKEN>
<TOKEN id="token-67-10" pos="word" morph="none" start_char="7279" end_char="7289">circulating</TOKEN>
<TOKEN id="token-67-11" pos="word" morph="none" start_char="7291" end_char="7292">in</TOKEN>
<TOKEN id="token-67-12" pos="word" morph="none" start_char="7294" end_char="7297">2019</TOKEN>
</SEG>
<SEG id="segment-68" start_char="7301" end_char="7440">
<ORIGINAL_TEXT>In May, doctors at a Paris hospital discovered that patients they'd treated for pneumonia on December 27, 2019, had been sick with COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-68-0" pos="word" morph="none" start_char="7301" end_char="7302">In</TOKEN>
<TOKEN id="token-68-1" pos="word" morph="none" start_char="7304" end_char="7306">May</TOKEN>
<TOKEN id="token-68-2" pos="punct" morph="none" start_char="7307" end_char="7307">,</TOKEN>
<TOKEN id="token-68-3" pos="word" morph="none" start_char="7309" end_char="7315">doctors</TOKEN>
<TOKEN id="token-68-4" pos="word" morph="none" start_char="7317" end_char="7318">at</TOKEN>
<TOKEN id="token-68-5" pos="word" morph="none" start_char="7320" end_char="7320">a</TOKEN>
<TOKEN id="token-68-6" pos="word" morph="none" start_char="7322" end_char="7326">Paris</TOKEN>
<TOKEN id="token-68-7" pos="word" morph="none" start_char="7328" end_char="7335">hospital</TOKEN>
<TOKEN id="token-68-8" pos="word" morph="none" start_char="7337" end_char="7346">discovered</TOKEN>
<TOKEN id="token-68-9" pos="word" morph="none" start_char="7348" end_char="7351">that</TOKEN>
<TOKEN id="token-68-10" pos="word" morph="none" start_char="7353" end_char="7360">patients</TOKEN>
<TOKEN id="token-68-11" pos="word" morph="none" start_char="7362" end_char="7367">they'd</TOKEN>
<TOKEN id="token-68-12" pos="word" morph="none" start_char="7369" end_char="7375">treated</TOKEN>
<TOKEN id="token-68-13" pos="word" morph="none" start_char="7377" end_char="7379">for</TOKEN>
<TOKEN id="token-68-14" pos="word" morph="none" start_char="7381" end_char="7389">pneumonia</TOKEN>
<TOKEN id="token-68-15" pos="word" morph="none" start_char="7391" end_char="7392">on</TOKEN>
<TOKEN id="token-68-16" pos="word" morph="none" start_char="7394" end_char="7401">December</TOKEN>
<TOKEN id="token-68-17" pos="word" morph="none" start_char="7403" end_char="7404">27</TOKEN>
<TOKEN id="token-68-18" pos="punct" morph="none" start_char="7405" end_char="7405">,</TOKEN>
<TOKEN id="token-68-19" pos="word" morph="none" start_char="7407" end_char="7410">2019</TOKEN>
<TOKEN id="token-68-20" pos="punct" morph="none" start_char="7411" end_char="7411">,</TOKEN>
<TOKEN id="token-68-21" pos="word" morph="none" start_char="7413" end_char="7415">had</TOKEN>
<TOKEN id="token-68-22" pos="word" morph="none" start_char="7417" end_char="7420">been</TOKEN>
<TOKEN id="token-68-23" pos="word" morph="none" start_char="7422" end_char="7425">sick</TOKEN>
<TOKEN id="token-68-24" pos="word" morph="none" start_char="7427" end_char="7430">with</TOKEN>
<TOKEN id="token-68-25" pos="unknown" morph="none" start_char="7432" end_char="7439">COVID-19</TOKEN>
<TOKEN id="token-68-26" pos="punct" morph="none" start_char="7440" end_char="7440">.</TOKEN>
</SEG>
<SEG id="segment-69" start_char="7442" end_char="7512">
<ORIGINAL_TEXT>France didn't record its first official case until January 24, however.</ORIGINAL_TEXT>
<TOKEN id="token-69-0" pos="word" morph="none" start_char="7442" end_char="7447">France</TOKEN>
<TOKEN id="token-69-1" pos="word" morph="none" start_char="7449" end_char="7454">didn't</TOKEN>
<TOKEN id="token-69-2" pos="word" morph="none" start_char="7456" end_char="7461">record</TOKEN>
<TOKEN id="token-69-3" pos="word" morph="none" start_char="7463" end_char="7465">its</TOKEN>
<TOKEN id="token-69-4" pos="word" morph="none" start_char="7467" end_char="7471">first</TOKEN>
<TOKEN id="token-69-5" pos="word" morph="none" start_char="7473" end_char="7480">official</TOKEN>
<TOKEN id="token-69-6" pos="word" morph="none" start_char="7482" end_char="7485">case</TOKEN>
<TOKEN id="token-69-7" pos="word" morph="none" start_char="7487" end_char="7491">until</TOKEN>
<TOKEN id="token-69-8" pos="word" morph="none" start_char="7493" end_char="7499">January</TOKEN>
<TOKEN id="token-69-9" pos="word" morph="none" start_char="7501" end_char="7502">24</TOKEN>
<TOKEN id="token-69-10" pos="punct" morph="none" start_char="7503" end_char="7503">,</TOKEN>
<TOKEN id="token-69-11" pos="word" morph="none" start_char="7505" end_char="7511">however</TOKEN>
<TOKEN id="token-69-12" pos="punct" morph="none" start_char="7512" end_char="7512">.</TOKEN>
</SEG>
<SEG id="segment-70" start_char="7516" end_char="7592">
<ORIGINAL_TEXT>People in line for coronavirus tests in Barcelona, Spain, on August 31, 2020.</ORIGINAL_TEXT>
<TOKEN id="token-70-0" pos="word" morph="none" start_char="7516" end_char="7521">People</TOKEN>
<TOKEN id="token-70-1" pos="word" morph="none" start_char="7523" end_char="7524">in</TOKEN>
<TOKEN id="token-70-2" pos="word" morph="none" start_char="7526" end_char="7529">line</TOKEN>
<TOKEN id="token-70-3" pos="word" morph="none" start_char="7531" end_char="7533">for</TOKEN>
<TOKEN id="token-70-4" pos="word" morph="none" start_char="7535" end_char="7545">coronavirus</TOKEN>
<TOKEN id="token-70-5" pos="word" morph="none" start_char="7547" end_char="7551">tests</TOKEN>
<TOKEN id="token-70-6" pos="word" morph="none" start_char="7553" end_char="7554">in</TOKEN>
<TOKEN id="token-70-7" pos="word" morph="none" start_char="7556" end_char="7564">Barcelona</TOKEN>
<TOKEN id="token-70-8" pos="punct" morph="none" start_char="7565" end_char="7565">,</TOKEN>
<TOKEN id="token-70-9" pos="word" morph="none" start_char="7567" end_char="7571">Spain</TOKEN>
<TOKEN id="token-70-10" pos="punct" morph="none" start_char="7572" end_char="7572">,</TOKEN>
<TOKEN id="token-70-11" pos="word" morph="none" start_char="7574" end_char="7575">on</TOKEN>
<TOKEN id="token-70-12" pos="word" morph="none" start_char="7577" end_char="7582">August</TOKEN>
<TOKEN id="token-70-13" pos="word" morph="none" start_char="7584" end_char="7585">31</TOKEN>
<TOKEN id="token-70-14" pos="punct" morph="none" start_char="7586" end_char="7586">,</TOKEN>
<TOKEN id="token-70-15" pos="word" morph="none" start_char="7588" end_char="7591">2020</TOKEN>
<TOKEN id="token-70-16" pos="punct" morph="none" start_char="7592" end_char="7592">.</TOKEN>
</SEG>
<SEG id="segment-71" start_char="7595" end_char="7619">
<ORIGINAL_TEXT>AP Photo/Emilio Morenatti</ORIGINAL_TEXT>
<TOKEN id="token-71-0" pos="word" morph="none" start_char="7595" end_char="7596">AP</TOKEN>
<TOKEN id="token-71-1" pos="unknown" morph="none" start_char="7598" end_char="7609">Photo/Emilio</TOKEN>
<TOKEN id="token-71-2" pos="word" morph="none" start_char="7611" end_char="7619">Morenatti</TOKEN>
</SEG>
<SEG id="segment-72" start_char="7623" end_char="7827">
<ORIGINAL_TEXT>In Spain, meanwhile, researchers from the University of Barcelona found evidence of the coronavirus in city sewage samples collected in mid-January 2020, six weeks before the country's first official case.</ORIGINAL_TEXT>
<TOKEN id="token-72-0" pos="word" morph="none" start_char="7623" end_char="7624">In</TOKEN>
<TOKEN id="token-72-1" pos="word" morph="none" start_char="7626" end_char="7630">Spain</TOKEN>
<TOKEN id="token-72-2" pos="punct" morph="none" start_char="7631" end_char="7631">,</TOKEN>
<TOKEN id="token-72-3" pos="word" morph="none" start_char="7633" end_char="7641">meanwhile</TOKEN>
<TOKEN id="token-72-4" pos="punct" morph="none" start_char="7642" end_char="7642">,</TOKEN>
<TOKEN id="token-72-5" pos="word" morph="none" start_char="7644" end_char="7654">researchers</TOKEN>
<TOKEN id="token-72-6" pos="word" morph="none" start_char="7656" end_char="7659">from</TOKEN>
<TOKEN id="token-72-7" pos="word" morph="none" start_char="7661" end_char="7663">the</TOKEN>
<TOKEN id="token-72-8" pos="word" morph="none" start_char="7665" end_char="7674">University</TOKEN>
<TOKEN id="token-72-9" pos="word" morph="none" start_char="7676" end_char="7677">of</TOKEN>
<TOKEN id="token-72-10" pos="word" morph="none" start_char="7679" end_char="7687">Barcelona</TOKEN>
<TOKEN id="token-72-11" pos="word" morph="none" start_char="7689" end_char="7693">found</TOKEN>
<TOKEN id="token-72-12" pos="word" morph="none" start_char="7695" end_char="7702">evidence</TOKEN>
<TOKEN id="token-72-13" pos="word" morph="none" start_char="7704" end_char="7705">of</TOKEN>
<TOKEN id="token-72-14" pos="word" morph="none" start_char="7707" end_char="7709">the</TOKEN>
<TOKEN id="token-72-15" pos="word" morph="none" start_char="7711" end_char="7721">coronavirus</TOKEN>
<TOKEN id="token-72-16" pos="word" morph="none" start_char="7723" end_char="7724">in</TOKEN>
<TOKEN id="token-72-17" pos="word" morph="none" start_char="7726" end_char="7729">city</TOKEN>
<TOKEN id="token-72-18" pos="word" morph="none" start_char="7731" end_char="7736">sewage</TOKEN>
<TOKEN id="token-72-19" pos="word" morph="none" start_char="7738" end_char="7744">samples</TOKEN>
<TOKEN id="token-72-20" pos="word" morph="none" start_char="7746" end_char="7754">collected</TOKEN>
<TOKEN id="token-72-21" pos="word" morph="none" start_char="7756" end_char="7757">in</TOKEN>
<TOKEN id="token-72-22" pos="unknown" morph="none" start_char="7759" end_char="7769">mid-January</TOKEN>
<TOKEN id="token-72-23" pos="word" morph="none" start_char="7771" end_char="7774">2020</TOKEN>
<TOKEN id="token-72-24" pos="punct" morph="none" start_char="7775" end_char="7775">,</TOKEN>
<TOKEN id="token-72-25" pos="word" morph="none" start_char="7777" end_char="7779">six</TOKEN>
<TOKEN id="token-72-26" pos="word" morph="none" start_char="7781" end_char="7785">weeks</TOKEN>
<TOKEN id="token-72-27" pos="word" morph="none" start_char="7787" end_char="7792">before</TOKEN>
<TOKEN id="token-72-28" pos="word" morph="none" start_char="7794" end_char="7796">the</TOKEN>
<TOKEN id="token-72-29" pos="word" morph="none" start_char="7798" end_char="7806">country's</TOKEN>
<TOKEN id="token-72-30" pos="word" morph="none" start_char="7808" end_char="7812">first</TOKEN>
<TOKEN id="token-72-31" pos="word" morph="none" start_char="7814" end_char="7821">official</TOKEN>
<TOKEN id="token-72-32" pos="word" morph="none" start_char="7823" end_char="7826">case</TOKEN>
<TOKEN id="token-72-33" pos="punct" morph="none" start_char="7827" end_char="7827">.</TOKEN>
</SEG>
<SEG id="segment-73" start_char="7830" end_char="7939">
<ORIGINAL_TEXT>Surprisingly, a sewage sample collected on March 12, 2019, also tested positive for traces of the coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-73-0" pos="word" morph="none" start_char="7830" end_char="7841">Surprisingly</TOKEN>
<TOKEN id="token-73-1" pos="punct" morph="none" start_char="7842" end_char="7842">,</TOKEN>
<TOKEN id="token-73-2" pos="word" morph="none" start_char="7844" end_char="7844">a</TOKEN>
<TOKEN id="token-73-3" pos="word" morph="none" start_char="7846" end_char="7851">sewage</TOKEN>
<TOKEN id="token-73-4" pos="word" morph="none" start_char="7853" end_char="7858">sample</TOKEN>
<TOKEN id="token-73-5" pos="word" morph="none" start_char="7860" end_char="7868">collected</TOKEN>
<TOKEN id="token-73-6" pos="word" morph="none" start_char="7870" end_char="7871">on</TOKEN>
<TOKEN id="token-73-7" pos="word" morph="none" start_char="7873" end_char="7877">March</TOKEN>
<TOKEN id="token-73-8" pos="word" morph="none" start_char="7879" end_char="7880">12</TOKEN>
<TOKEN id="token-73-9" pos="punct" morph="none" start_char="7881" end_char="7881">,</TOKEN>
<TOKEN id="token-73-10" pos="word" morph="none" start_char="7883" end_char="7886">2019</TOKEN>
<TOKEN id="token-73-11" pos="punct" morph="none" start_char="7887" end_char="7887">,</TOKEN>
<TOKEN id="token-73-12" pos="word" morph="none" start_char="7889" end_char="7892">also</TOKEN>
<TOKEN id="token-73-13" pos="word" morph="none" start_char="7894" end_char="7899">tested</TOKEN>
<TOKEN id="token-73-14" pos="word" morph="none" start_char="7901" end_char="7908">positive</TOKEN>
<TOKEN id="token-73-15" pos="word" morph="none" start_char="7910" end_char="7912">for</TOKEN>
<TOKEN id="token-73-16" pos="word" morph="none" start_char="7914" end_char="7919">traces</TOKEN>
<TOKEN id="token-73-17" pos="word" morph="none" start_char="7921" end_char="7922">of</TOKEN>
<TOKEN id="token-73-18" pos="word" morph="none" start_char="7924" end_char="7926">the</TOKEN>
<TOKEN id="token-73-19" pos="word" morph="none" start_char="7928" end_char="7938">coronavirus</TOKEN>
<TOKEN id="token-73-20" pos="punct" morph="none" start_char="7939" end_char="7939">.</TOKEN>
</SEG>
<SEG id="segment-74" start_char="7941" end_char="8048">
<ORIGINAL_TEXT>But testing wastewater isn't a perfect way to detect outbreaks, as Claire Crossan wrote in The Conversation.</ORIGINAL_TEXT>
<TOKEN id="token-74-0" pos="word" morph="none" start_char="7941" end_char="7943">But</TOKEN>
<TOKEN id="token-74-1" pos="word" morph="none" start_char="7945" end_char="7951">testing</TOKEN>
<TOKEN id="token-74-2" pos="word" morph="none" start_char="7953" end_char="7962">wastewater</TOKEN>
<TOKEN id="token-74-3" pos="word" morph="none" start_char="7964" end_char="7968">isn't</TOKEN>
<TOKEN id="token-74-4" pos="word" morph="none" start_char="7970" end_char="7970">a</TOKEN>
<TOKEN id="token-74-5" pos="word" morph="none" start_char="7972" end_char="7978">perfect</TOKEN>
<TOKEN id="token-74-6" pos="word" morph="none" start_char="7980" end_char="7982">way</TOKEN>
<TOKEN id="token-74-7" pos="word" morph="none" start_char="7984" end_char="7985">to</TOKEN>
<TOKEN id="token-74-8" pos="word" morph="none" start_char="7987" end_char="7992">detect</TOKEN>
<TOKEN id="token-74-9" pos="word" morph="none" start_char="7994" end_char="8002">outbreaks</TOKEN>
<TOKEN id="token-74-10" pos="punct" morph="none" start_char="8003" end_char="8003">,</TOKEN>
<TOKEN id="token-74-11" pos="word" morph="none" start_char="8005" end_char="8006">as</TOKEN>
<TOKEN id="token-74-12" pos="word" morph="none" start_char="8008" end_char="8013">Claire</TOKEN>
<TOKEN id="token-74-13" pos="word" morph="none" start_char="8015" end_char="8021">Crossan</TOKEN>
<TOKEN id="token-74-14" pos="word" morph="none" start_char="8023" end_char="8027">wrote</TOKEN>
<TOKEN id="token-74-15" pos="word" morph="none" start_char="8029" end_char="8030">in</TOKEN>
<TOKEN id="token-74-16" pos="word" morph="none" start_char="8032" end_char="8034">The</TOKEN>
<TOKEN id="token-74-17" pos="word" morph="none" start_char="8036" end_char="8047">Conversation</TOKEN>
<TOKEN id="token-74-18" pos="punct" morph="none" start_char="8048" end_char="8048">.</TOKEN>
</SEG>
<SEG id="segment-75" start_char="8050" end_char="8127">
<ORIGINAL_TEXT>So it's possible that the March sample had been contaminated during the study.</ORIGINAL_TEXT>
<TOKEN id="token-75-0" pos="word" morph="none" start_char="8050" end_char="8051">So</TOKEN>
<TOKEN id="token-75-1" pos="word" morph="none" start_char="8053" end_char="8056">it's</TOKEN>
<TOKEN id="token-75-2" pos="word" morph="none" start_char="8058" end_char="8065">possible</TOKEN>
<TOKEN id="token-75-3" pos="word" morph="none" start_char="8067" end_char="8070">that</TOKEN>
<TOKEN id="token-75-4" pos="word" morph="none" start_char="8072" end_char="8074">the</TOKEN>
<TOKEN id="token-75-5" pos="word" morph="none" start_char="8076" end_char="8080">March</TOKEN>
<TOKEN id="token-75-6" pos="word" morph="none" start_char="8082" end_char="8087">sample</TOKEN>
<TOKEN id="token-75-7" pos="word" morph="none" start_char="8089" end_char="8091">had</TOKEN>
<TOKEN id="token-75-8" pos="word" morph="none" start_char="8093" end_char="8096">been</TOKEN>
<TOKEN id="token-75-9" pos="word" morph="none" start_char="8098" end_char="8109">contaminated</TOKEN>
<TOKEN id="token-75-10" pos="word" morph="none" start_char="8111" end_char="8116">during</TOKEN>
<TOKEN id="token-75-11" pos="word" morph="none" start_char="8118" end_char="8120">the</TOKEN>
<TOKEN id="token-75-12" pos="word" morph="none" start_char="8122" end_char="8126">study</TOKEN>
<TOKEN id="token-75-13" pos="punct" morph="none" start_char="8127" end_char="8127">.</TOKEN>
</SEG>
<SEG id="segment-76" start_char="8130" end_char="8175">
<ORIGINAL_TEXT>By December 2019, the virus had reached the US</ORIGINAL_TEXT>
<TOKEN id="token-76-0" pos="word" morph="none" start_char="8130" end_char="8131">By</TOKEN>
<TOKEN id="token-76-1" pos="word" morph="none" start_char="8133" end_char="8140">December</TOKEN>
<TOKEN id="token-76-2" pos="word" morph="none" start_char="8142" end_char="8145">2019</TOKEN>
<TOKEN id="token-76-3" pos="punct" morph="none" start_char="8146" end_char="8146">,</TOKEN>
<TOKEN id="token-76-4" pos="word" morph="none" start_char="8148" end_char="8150">the</TOKEN>
<TOKEN id="token-76-5" pos="word" morph="none" start_char="8152" end_char="8156">virus</TOKEN>
<TOKEN id="token-76-6" pos="word" morph="none" start_char="8158" end_char="8160">had</TOKEN>
<TOKEN id="token-76-7" pos="word" morph="none" start_char="8162" end_char="8168">reached</TOKEN>
<TOKEN id="token-76-8" pos="word" morph="none" start_char="8170" end_char="8172">the</TOKEN>
<TOKEN id="token-76-9" pos="word" morph="none" start_char="8174" end_char="8175">US</TOKEN>
</SEG>
<SEG id="segment-77" start_char="8180" end_char="8251">
<ORIGINAL_TEXT>Few people wear masks on a pier in Oceanside, California, June 22, 2020.</ORIGINAL_TEXT>
<TOKEN id="token-77-0" pos="word" morph="none" start_char="8180" end_char="8182">Few</TOKEN>
<TOKEN id="token-77-1" pos="word" morph="none" start_char="8184" end_char="8189">people</TOKEN>
<TOKEN id="token-77-2" pos="word" morph="none" start_char="8191" end_char="8194">wear</TOKEN>
<TOKEN id="token-77-3" pos="word" morph="none" start_char="8196" end_char="8200">masks</TOKEN>
<TOKEN id="token-77-4" pos="word" morph="none" start_char="8202" end_char="8203">on</TOKEN>
<TOKEN id="token-77-5" pos="word" morph="none" start_char="8205" end_char="8205">a</TOKEN>
<TOKEN id="token-77-6" pos="word" morph="none" start_char="8207" end_char="8210">pier</TOKEN>
<TOKEN id="token-77-7" pos="word" morph="none" start_char="8212" end_char="8213">in</TOKEN>
<TOKEN id="token-77-8" pos="word" morph="none" start_char="8215" end_char="8223">Oceanside</TOKEN>
<TOKEN id="token-77-9" pos="punct" morph="none" start_char="8224" end_char="8224">,</TOKEN>
<TOKEN id="token-77-10" pos="word" morph="none" start_char="8226" end_char="8235">California</TOKEN>
<TOKEN id="token-77-11" pos="punct" morph="none" start_char="8236" end_char="8236">,</TOKEN>
<TOKEN id="token-77-12" pos="word" morph="none" start_char="8238" end_char="8241">June</TOKEN>
<TOKEN id="token-77-13" pos="word" morph="none" start_char="8243" end_char="8244">22</TOKEN>
<TOKEN id="token-77-14" pos="punct" morph="none" start_char="8245" end_char="8245">,</TOKEN>
<TOKEN id="token-77-15" pos="word" morph="none" start_char="8247" end_char="8250">2020</TOKEN>
<TOKEN id="token-77-16" pos="punct" morph="none" start_char="8251" end_char="8251">.</TOKEN>
</SEG>
<SEG id="segment-78" start_char="8254" end_char="8271">
<ORIGINAL_TEXT>Mike Blake/Reuters</ORIGINAL_TEXT>
<TOKEN id="token-78-0" pos="word" morph="none" start_char="8254" end_char="8257">Mike</TOKEN>
<TOKEN id="token-78-1" pos="unknown" morph="none" start_char="8259" end_char="8271">Blake/Reuters</TOKEN>
</SEG>
<SEG id="segment-79" start_char="8275" end_char="8383">
<ORIGINAL_TEXT>Research in the US, too, offers evidence that the virus had gone global before humanity even knew it existed.</ORIGINAL_TEXT>
<TOKEN id="token-79-0" pos="word" morph="none" start_char="8275" end_char="8282">Research</TOKEN>
<TOKEN id="token-79-1" pos="word" morph="none" start_char="8284" end_char="8285">in</TOKEN>
<TOKEN id="token-79-2" pos="word" morph="none" start_char="8287" end_char="8289">the</TOKEN>
<TOKEN id="token-79-3" pos="word" morph="none" start_char="8291" end_char="8292">US</TOKEN>
<TOKEN id="token-79-4" pos="punct" morph="none" start_char="8293" end_char="8293">,</TOKEN>
<TOKEN id="token-79-5" pos="word" morph="none" start_char="8295" end_char="8297">too</TOKEN>
<TOKEN id="token-79-6" pos="punct" morph="none" start_char="8298" end_char="8298">,</TOKEN>
<TOKEN id="token-79-7" pos="word" morph="none" start_char="8300" end_char="8305">offers</TOKEN>
<TOKEN id="token-79-8" pos="word" morph="none" start_char="8307" end_char="8314">evidence</TOKEN>
<TOKEN id="token-79-9" pos="word" morph="none" start_char="8316" end_char="8319">that</TOKEN>
<TOKEN id="token-79-10" pos="word" morph="none" start_char="8321" end_char="8323">the</TOKEN>
<TOKEN id="token-79-11" pos="word" morph="none" start_char="8325" end_char="8329">virus</TOKEN>
<TOKEN id="token-79-12" pos="word" morph="none" start_char="8331" end_char="8333">had</TOKEN>
<TOKEN id="token-79-13" pos="word" morph="none" start_char="8335" end_char="8338">gone</TOKEN>
<TOKEN id="token-79-14" pos="word" morph="none" start_char="8340" end_char="8345">global</TOKEN>
<TOKEN id="token-79-15" pos="word" morph="none" start_char="8347" end_char="8352">before</TOKEN>
<TOKEN id="token-79-16" pos="word" morph="none" start_char="8354" end_char="8361">humanity</TOKEN>
<TOKEN id="token-79-17" pos="word" morph="none" start_char="8363" end_char="8366">even</TOKEN>
<TOKEN id="token-79-18" pos="word" morph="none" start_char="8368" end_char="8371">knew</TOKEN>
<TOKEN id="token-79-19" pos="word" morph="none" start_char="8373" end_char="8374">it</TOKEN>
<TOKEN id="token-79-20" pos="word" morph="none" start_char="8376" end_char="8382">existed</TOKEN>
<TOKEN id="token-79-21" pos="punct" morph="none" start_char="8383" end_char="8383">.</TOKEN>
</SEG>
<SEG id="segment-80" start_char="8386" end_char="8448">
<ORIGINAL_TEXT>The US recorded its first coronavirus case on January 20, 2020.</ORIGINAL_TEXT>
<TOKEN id="token-80-0" pos="word" morph="none" start_char="8386" end_char="8388">The</TOKEN>
<TOKEN id="token-80-1" pos="word" morph="none" start_char="8390" end_char="8391">US</TOKEN>
<TOKEN id="token-80-2" pos="word" morph="none" start_char="8393" end_char="8400">recorded</TOKEN>
<TOKEN id="token-80-3" pos="word" morph="none" start_char="8402" end_char="8404">its</TOKEN>
<TOKEN id="token-80-4" pos="word" morph="none" start_char="8406" end_char="8410">first</TOKEN>
<TOKEN id="token-80-5" pos="word" morph="none" start_char="8412" end_char="8422">coronavirus</TOKEN>
<TOKEN id="token-80-6" pos="word" morph="none" start_char="8424" end_char="8427">case</TOKEN>
<TOKEN id="token-80-7" pos="word" morph="none" start_char="8429" end_char="8430">on</TOKEN>
<TOKEN id="token-80-8" pos="word" morph="none" start_char="8432" end_char="8438">January</TOKEN>
<TOKEN id="token-80-9" pos="word" morph="none" start_char="8440" end_char="8441">20</TOKEN>
<TOKEN id="token-80-10" pos="punct" morph="none" start_char="8442" end_char="8442">,</TOKEN>
<TOKEN id="token-80-11" pos="word" morph="none" start_char="8444" end_char="8447">2020</TOKEN>
<TOKEN id="token-80-12" pos="punct" morph="none" start_char="8448" end_char="8448">.</TOKEN>
</SEG>
<SEG id="segment-81" start_char="8450" end_char="8546">
<ORIGINAL_TEXT>But according to one study, the virus had reached the Pacific Northwest at least a month earlier.</ORIGINAL_TEXT>
<TOKEN id="token-81-0" pos="word" morph="none" start_char="8450" end_char="8452">But</TOKEN>
<TOKEN id="token-81-1" pos="word" morph="none" start_char="8454" end_char="8462">according</TOKEN>
<TOKEN id="token-81-2" pos="word" morph="none" start_char="8464" end_char="8465">to</TOKEN>
<TOKEN id="token-81-3" pos="word" morph="none" start_char="8467" end_char="8469">one</TOKEN>
<TOKEN id="token-81-4" pos="word" morph="none" start_char="8471" end_char="8475">study</TOKEN>
<TOKEN id="token-81-5" pos="punct" morph="none" start_char="8476" end_char="8476">,</TOKEN>
<TOKEN id="token-81-6" pos="word" morph="none" start_char="8478" end_char="8480">the</TOKEN>
<TOKEN id="token-81-7" pos="word" morph="none" start_char="8482" end_char="8486">virus</TOKEN>
<TOKEN id="token-81-8" pos="word" morph="none" start_char="8488" end_char="8490">had</TOKEN>
<TOKEN id="token-81-9" pos="word" morph="none" start_char="8492" end_char="8498">reached</TOKEN>
<TOKEN id="token-81-10" pos="word" morph="none" start_char="8500" end_char="8502">the</TOKEN>
<TOKEN id="token-81-11" pos="word" morph="none" start_char="8504" end_char="8510">Pacific</TOKEN>
<TOKEN id="token-81-12" pos="word" morph="none" start_char="8512" end_char="8520">Northwest</TOKEN>
<TOKEN id="token-81-13" pos="word" morph="none" start_char="8522" end_char="8523">at</TOKEN>
<TOKEN id="token-81-14" pos="word" morph="none" start_char="8525" end_char="8529">least</TOKEN>
<TOKEN id="token-81-15" pos="word" morph="none" start_char="8531" end_char="8531">a</TOKEN>
<TOKEN id="token-81-16" pos="word" morph="none" start_char="8533" end_char="8537">month</TOKEN>
<TOKEN id="token-81-17" pos="word" morph="none" start_char="8539" end_char="8545">earlier</TOKEN>
<TOKEN id="token-81-18" pos="punct" morph="none" start_char="8546" end_char="8546">.</TOKEN>
</SEG>
<SEG id="segment-82" start_char="8548" end_char="8743">
<ORIGINAL_TEXT>Blood samples collected by the American Red Cross in nine states, including California, Oregon, and Washington, showed that some Americans had coronavirus antibodies as early as December 13, 2019.</ORIGINAL_TEXT>
<TOKEN id="token-82-0" pos="word" morph="none" start_char="8548" end_char="8552">Blood</TOKEN>
<TOKEN id="token-82-1" pos="word" morph="none" start_char="8554" end_char="8560">samples</TOKEN>
<TOKEN id="token-82-2" pos="word" morph="none" start_char="8562" end_char="8570">collected</TOKEN>
<TOKEN id="token-82-3" pos="word" morph="none" start_char="8572" end_char="8573">by</TOKEN>
<TOKEN id="token-82-4" pos="word" morph="none" start_char="8575" end_char="8577">the</TOKEN>
<TOKEN id="token-82-5" pos="word" morph="none" start_char="8579" end_char="8586">American</TOKEN>
<TOKEN id="token-82-6" pos="word" morph="none" start_char="8588" end_char="8590">Red</TOKEN>
<TOKEN id="token-82-7" pos="word" morph="none" start_char="8592" end_char="8596">Cross</TOKEN>
<TOKEN id="token-82-8" pos="word" morph="none" start_char="8598" end_char="8599">in</TOKEN>
<TOKEN id="token-82-9" pos="word" morph="none" start_char="8601" end_char="8604">nine</TOKEN>
<TOKEN id="token-82-10" pos="word" morph="none" start_char="8606" end_char="8611">states</TOKEN>
<TOKEN id="token-82-11" pos="punct" morph="none" start_char="8612" end_char="8612">,</TOKEN>
<TOKEN id="token-82-12" pos="word" morph="none" start_char="8614" end_char="8622">including</TOKEN>
<TOKEN id="token-82-13" pos="word" morph="none" start_char="8624" end_char="8633">California</TOKEN>
<TOKEN id="token-82-14" pos="punct" morph="none" start_char="8634" end_char="8634">,</TOKEN>
<TOKEN id="token-82-15" pos="word" morph="none" start_char="8636" end_char="8641">Oregon</TOKEN>
<TOKEN id="token-82-16" pos="punct" morph="none" start_char="8642" end_char="8642">,</TOKEN>
<TOKEN id="token-82-17" pos="word" morph="none" start_char="8644" end_char="8646">and</TOKEN>
<TOKEN id="token-82-18" pos="word" morph="none" start_char="8648" end_char="8657">Washington</TOKEN>
<TOKEN id="token-82-19" pos="punct" morph="none" start_char="8658" end_char="8658">,</TOKEN>
<TOKEN id="token-82-20" pos="word" morph="none" start_char="8660" end_char="8665">showed</TOKEN>
<TOKEN id="token-82-21" pos="word" morph="none" start_char="8667" end_char="8670">that</TOKEN>
<TOKEN id="token-82-22" pos="word" morph="none" start_char="8672" end_char="8675">some</TOKEN>
<TOKEN id="token-82-23" pos="word" morph="none" start_char="8677" end_char="8685">Americans</TOKEN>
<TOKEN id="token-82-24" pos="word" morph="none" start_char="8687" end_char="8689">had</TOKEN>
<TOKEN id="token-82-25" pos="word" morph="none" start_char="8691" end_char="8701">coronavirus</TOKEN>
<TOKEN id="token-82-26" pos="word" morph="none" start_char="8703" end_char="8712">antibodies</TOKEN>
<TOKEN id="token-82-27" pos="word" morph="none" start_char="8714" end_char="8715">as</TOKEN>
<TOKEN id="token-82-28" pos="word" morph="none" start_char="8717" end_char="8721">early</TOKEN>
<TOKEN id="token-82-29" pos="word" morph="none" start_char="8723" end_char="8724">as</TOKEN>
<TOKEN id="token-82-30" pos="word" morph="none" start_char="8726" end_char="8733">December</TOKEN>
<TOKEN id="token-82-31" pos="word" morph="none" start_char="8735" end_char="8736">13</TOKEN>
<TOKEN id="token-82-32" pos="punct" morph="none" start_char="8737" end_char="8737">,</TOKEN>
<TOKEN id="token-82-33" pos="word" morph="none" start_char="8739" end_char="8742">2019</TOKEN>
<TOKEN id="token-82-34" pos="punct" morph="none" start_char="8743" end_char="8743">.</TOKEN>
</SEG>
<SEG id="segment-83" start_char="8747" end_char="8840">
<ORIGINAL_TEXT>A young resident of Detroit, Michigan, is tested for coronavirus antibodies on April 28, 2020.</ORIGINAL_TEXT>
<TOKEN id="token-83-0" pos="word" morph="none" start_char="8747" end_char="8747">A</TOKEN>
<TOKEN id="token-83-1" pos="word" morph="none" start_char="8749" end_char="8753">young</TOKEN>
<TOKEN id="token-83-2" pos="word" morph="none" start_char="8755" end_char="8762">resident</TOKEN>
<TOKEN id="token-83-3" pos="word" morph="none" start_char="8764" end_char="8765">of</TOKEN>
<TOKEN id="token-83-4" pos="word" morph="none" start_char="8767" end_char="8773">Detroit</TOKEN>
<TOKEN id="token-83-5" pos="punct" morph="none" start_char="8774" end_char="8774">,</TOKEN>
<TOKEN id="token-83-6" pos="word" morph="none" start_char="8776" end_char="8783">Michigan</TOKEN>
<TOKEN id="token-83-7" pos="punct" morph="none" start_char="8784" end_char="8784">,</TOKEN>
<TOKEN id="token-83-8" pos="word" morph="none" start_char="8786" end_char="8787">is</TOKEN>
<TOKEN id="token-83-9" pos="word" morph="none" start_char="8789" end_char="8794">tested</TOKEN>
<TOKEN id="token-83-10" pos="word" morph="none" start_char="8796" end_char="8798">for</TOKEN>
<TOKEN id="token-83-11" pos="word" morph="none" start_char="8800" end_char="8810">coronavirus</TOKEN>
<TOKEN id="token-83-12" pos="word" morph="none" start_char="8812" end_char="8821">antibodies</TOKEN>
<TOKEN id="token-83-13" pos="word" morph="none" start_char="8823" end_char="8824">on</TOKEN>
<TOKEN id="token-83-14" pos="word" morph="none" start_char="8826" end_char="8830">April</TOKEN>
<TOKEN id="token-83-15" pos="word" morph="none" start_char="8832" end_char="8833">28</TOKEN>
<TOKEN id="token-83-16" pos="punct" morph="none" start_char="8834" end_char="8834">,</TOKEN>
<TOKEN id="token-83-17" pos="word" morph="none" start_char="8836" end_char="8839">2020</TOKEN>
<TOKEN id="token-83-18" pos="punct" morph="none" start_char="8840" end_char="8840">.</TOKEN>
</SEG>
<SEG id="segment-84" start_char="8843" end_char="8862">
<ORIGINAL_TEXT>REUTERS/Rebecca Cook</ORIGINAL_TEXT>
<TOKEN id="token-84-0" pos="unknown" morph="none" start_char="8843" end_char="8857">REUTERS/Rebecca</TOKEN>
<TOKEN id="token-84-1" pos="word" morph="none" start_char="8859" end_char="8862">Cook</TOKEN>
</SEG>
<SEG id="segment-85" start_char="8866" end_char="9055">
<ORIGINAL_TEXT>Antibodies are an imperfect measure of the outbreak since some research suggests our immune systems can create antibodies that recognize the new coronavirus in response to some common colds.</ORIGINAL_TEXT>
<TOKEN id="token-85-0" pos="word" morph="none" start_char="8866" end_char="8875">Antibodies</TOKEN>
<TOKEN id="token-85-1" pos="word" morph="none" start_char="8877" end_char="8879">are</TOKEN>
<TOKEN id="token-85-2" pos="word" morph="none" start_char="8881" end_char="8882">an</TOKEN>
<TOKEN id="token-85-3" pos="word" morph="none" start_char="8884" end_char="8892">imperfect</TOKEN>
<TOKEN id="token-85-4" pos="word" morph="none" start_char="8894" end_char="8900">measure</TOKEN>
<TOKEN id="token-85-5" pos="word" morph="none" start_char="8902" end_char="8903">of</TOKEN>
<TOKEN id="token-85-6" pos="word" morph="none" start_char="8905" end_char="8907">the</TOKEN>
<TOKEN id="token-85-7" pos="word" morph="none" start_char="8909" end_char="8916">outbreak</TOKEN>
<TOKEN id="token-85-8" pos="word" morph="none" start_char="8918" end_char="8922">since</TOKEN>
<TOKEN id="token-85-9" pos="word" morph="none" start_char="8924" end_char="8927">some</TOKEN>
<TOKEN id="token-85-10" pos="word" morph="none" start_char="8929" end_char="8936">research</TOKEN>
<TOKEN id="token-85-11" pos="word" morph="none" start_char="8938" end_char="8945">suggests</TOKEN>
<TOKEN id="token-85-12" pos="word" morph="none" start_char="8947" end_char="8949">our</TOKEN>
<TOKEN id="token-85-13" pos="word" morph="none" start_char="8951" end_char="8956">immune</TOKEN>
<TOKEN id="token-85-14" pos="word" morph="none" start_char="8958" end_char="8964">systems</TOKEN>
<TOKEN id="token-85-15" pos="word" morph="none" start_char="8966" end_char="8968">can</TOKEN>
<TOKEN id="token-85-16" pos="word" morph="none" start_char="8970" end_char="8975">create</TOKEN>
<TOKEN id="token-85-17" pos="word" morph="none" start_char="8977" end_char="8986">antibodies</TOKEN>
<TOKEN id="token-85-18" pos="word" morph="none" start_char="8988" end_char="8991">that</TOKEN>
<TOKEN id="token-85-19" pos="word" morph="none" start_char="8993" end_char="9001">recognize</TOKEN>
<TOKEN id="token-85-20" pos="word" morph="none" start_char="9003" end_char="9005">the</TOKEN>
<TOKEN id="token-85-21" pos="word" morph="none" start_char="9007" end_char="9009">new</TOKEN>
<TOKEN id="token-85-22" pos="word" morph="none" start_char="9011" end_char="9021">coronavirus</TOKEN>
<TOKEN id="token-85-23" pos="word" morph="none" start_char="9023" end_char="9024">in</TOKEN>
<TOKEN id="token-85-24" pos="word" morph="none" start_char="9026" end_char="9033">response</TOKEN>
<TOKEN id="token-85-25" pos="word" morph="none" start_char="9035" end_char="9036">to</TOKEN>
<TOKEN id="token-85-26" pos="word" morph="none" start_char="9038" end_char="9041">some</TOKEN>
<TOKEN id="token-85-27" pos="word" morph="none" start_char="9043" end_char="9048">common</TOKEN>
<TOKEN id="token-85-28" pos="word" morph="none" start_char="9050" end_char="9054">colds</TOKEN>
<TOKEN id="token-85-29" pos="punct" morph="none" start_char="9055" end_char="9055">.</TOKEN>
</SEG>
<SEG id="segment-86" start_char="9057" end_char="9102">
<ORIGINAL_TEXT>Antibody tests can also yield false positives.</ORIGINAL_TEXT>
<TOKEN id="token-86-0" pos="word" morph="none" start_char="9057" end_char="9064">Antibody</TOKEN>
<TOKEN id="token-86-1" pos="word" morph="none" start_char="9066" end_char="9070">tests</TOKEN>
<TOKEN id="token-86-2" pos="word" morph="none" start_char="9072" end_char="9074">can</TOKEN>
<TOKEN id="token-86-3" pos="word" morph="none" start_char="9076" end_char="9079">also</TOKEN>
<TOKEN id="token-86-4" pos="word" morph="none" start_char="9081" end_char="9085">yield</TOKEN>
<TOKEN id="token-86-5" pos="word" morph="none" start_char="9087" end_char="9091">false</TOKEN>
<TOKEN id="token-86-6" pos="word" morph="none" start_char="9093" end_char="9101">positives</TOKEN>
<TOKEN id="token-86-7" pos="punct" morph="none" start_char="9102" end_char="9102">.</TOKEN>
</SEG>
<SEG id="segment-87" start_char="9105" end_char="9275">
<ORIGINAL_TEXT>Yet in the past, scientists successfully used retrospective antibody studies to trace the origins of SARS and Middle East respiratory syndrome (MERS) — both coronaviruses.</ORIGINAL_TEXT>
<TOKEN id="token-87-0" pos="word" morph="none" start_char="9105" end_char="9107">Yet</TOKEN>
<TOKEN id="token-87-1" pos="word" morph="none" start_char="9109" end_char="9110">in</TOKEN>
<TOKEN id="token-87-2" pos="word" morph="none" start_char="9112" end_char="9114">the</TOKEN>
<TOKEN id="token-87-3" pos="word" morph="none" start_char="9116" end_char="9119">past</TOKEN>
<TOKEN id="token-87-4" pos="punct" morph="none" start_char="9120" end_char="9120">,</TOKEN>
<TOKEN id="token-87-5" pos="word" morph="none" start_char="9122" end_char="9131">scientists</TOKEN>
<TOKEN id="token-87-6" pos="word" morph="none" start_char="9133" end_char="9144">successfully</TOKEN>
<TOKEN id="token-87-7" pos="word" morph="none" start_char="9146" end_char="9149">used</TOKEN>
<TOKEN id="token-87-8" pos="word" morph="none" start_char="9151" end_char="9163">retrospective</TOKEN>
<TOKEN id="token-87-9" pos="word" morph="none" start_char="9165" end_char="9172">antibody</TOKEN>
<TOKEN id="token-87-10" pos="word" morph="none" start_char="9174" end_char="9180">studies</TOKEN>
<TOKEN id="token-87-11" pos="word" morph="none" start_char="9182" end_char="9183">to</TOKEN>
<TOKEN id="token-87-12" pos="word" morph="none" start_char="9185" end_char="9189">trace</TOKEN>
<TOKEN id="token-87-13" pos="word" morph="none" start_char="9191" end_char="9193">the</TOKEN>
<TOKEN id="token-87-14" pos="word" morph="none" start_char="9195" end_char="9201">origins</TOKEN>
<TOKEN id="token-87-15" pos="word" morph="none" start_char="9203" end_char="9204">of</TOKEN>
<TOKEN id="token-87-16" pos="word" morph="none" start_char="9206" end_char="9209">SARS</TOKEN>
<TOKEN id="token-87-17" pos="word" morph="none" start_char="9211" end_char="9213">and</TOKEN>
<TOKEN id="token-87-18" pos="word" morph="none" start_char="9215" end_char="9220">Middle</TOKEN>
<TOKEN id="token-87-19" pos="word" morph="none" start_char="9222" end_char="9225">East</TOKEN>
<TOKEN id="token-87-20" pos="word" morph="none" start_char="9227" end_char="9237">respiratory</TOKEN>
<TOKEN id="token-87-21" pos="word" morph="none" start_char="9239" end_char="9246">syndrome</TOKEN>
<TOKEN id="token-87-22" pos="punct" morph="none" start_char="9248" end_char="9248">(</TOKEN>
<TOKEN id="token-87-23" pos="word" morph="none" start_char="9249" end_char="9252">MERS</TOKEN>
<TOKEN id="token-87-24" pos="punct" morph="none" start_char="9253" end_char="9253">)</TOKEN>
<TOKEN id="token-87-25" pos="punct" morph="none" start_char="9255" end_char="9255">—</TOKEN>
<TOKEN id="token-87-26" pos="word" morph="none" start_char="9257" end_char="9260">both</TOKEN>
<TOKEN id="token-87-27" pos="word" morph="none" start_char="9262" end_char="9274">coronaviruses</TOKEN>
<TOKEN id="token-87-28" pos="punct" morph="none" start_char="9275" end_char="9275">.</TOKEN>
</SEG>
<SEG id="segment-88" start_char="9277" end_char="9451">
<ORIGINAL_TEXT>Virologists found antibodies specific to SARS in civet cats, and antibodies specific to MERS in camels, which is how they determined those to be each virus' animal progenitor.</ORIGINAL_TEXT>
<TOKEN id="token-88-0" pos="word" morph="none" start_char="9277" end_char="9287">Virologists</TOKEN>
<TOKEN id="token-88-1" pos="word" morph="none" start_char="9289" end_char="9293">found</TOKEN>
<TOKEN id="token-88-2" pos="word" morph="none" start_char="9295" end_char="9304">antibodies</TOKEN>
<TOKEN id="token-88-3" pos="word" morph="none" start_char="9306" end_char="9313">specific</TOKEN>
<TOKEN id="token-88-4" pos="word" morph="none" start_char="9315" end_char="9316">to</TOKEN>
<TOKEN id="token-88-5" pos="word" morph="none" start_char="9318" end_char="9321">SARS</TOKEN>
<TOKEN id="token-88-6" pos="word" morph="none" start_char="9323" end_char="9324">in</TOKEN>
<TOKEN id="token-88-7" pos="word" morph="none" start_char="9326" end_char="9330">civet</TOKEN>
<TOKEN id="token-88-8" pos="word" morph="none" start_char="9332" end_char="9335">cats</TOKEN>
<TOKEN id="token-88-9" pos="punct" morph="none" start_char="9336" end_char="9336">,</TOKEN>
<TOKEN id="token-88-10" pos="word" morph="none" start_char="9338" end_char="9340">and</TOKEN>
<TOKEN id="token-88-11" pos="word" morph="none" start_char="9342" end_char="9351">antibodies</TOKEN>
<TOKEN id="token-88-12" pos="word" morph="none" start_char="9353" end_char="9360">specific</TOKEN>
<TOKEN id="token-88-13" pos="word" morph="none" start_char="9362" end_char="9363">to</TOKEN>
<TOKEN id="token-88-14" pos="word" morph="none" start_char="9365" end_char="9368">MERS</TOKEN>
<TOKEN id="token-88-15" pos="word" morph="none" start_char="9370" end_char="9371">in</TOKEN>
<TOKEN id="token-88-16" pos="word" morph="none" start_char="9373" end_char="9378">camels</TOKEN>
<TOKEN id="token-88-17" pos="punct" morph="none" start_char="9379" end_char="9379">,</TOKEN>
<TOKEN id="token-88-18" pos="word" morph="none" start_char="9381" end_char="9385">which</TOKEN>
<TOKEN id="token-88-19" pos="word" morph="none" start_char="9387" end_char="9388">is</TOKEN>
<TOKEN id="token-88-20" pos="word" morph="none" start_char="9390" end_char="9392">how</TOKEN>
<TOKEN id="token-88-21" pos="word" morph="none" start_char="9394" end_char="9397">they</TOKEN>
<TOKEN id="token-88-22" pos="word" morph="none" start_char="9399" end_char="9408">determined</TOKEN>
<TOKEN id="token-88-23" pos="word" morph="none" start_char="9410" end_char="9414">those</TOKEN>
<TOKEN id="token-88-24" pos="word" morph="none" start_char="9416" end_char="9417">to</TOKEN>
<TOKEN id="token-88-25" pos="word" morph="none" start_char="9419" end_char="9420">be</TOKEN>
<TOKEN id="token-88-26" pos="word" morph="none" start_char="9422" end_char="9425">each</TOKEN>
<TOKEN id="token-88-27" pos="word" morph="none" start_char="9427" end_char="9431">virus</TOKEN>
<TOKEN id="token-88-28" pos="punct" morph="none" start_char="9432" end_char="9432">'</TOKEN>
<TOKEN id="token-88-29" pos="word" morph="none" start_char="9434" end_char="9439">animal</TOKEN>
<TOKEN id="token-88-30" pos="word" morph="none" start_char="9441" end_char="9450">progenitor</TOKEN>
<TOKEN id="token-88-31" pos="punct" morph="none" start_char="9451" end_char="9451">.</TOKEN>
</SEG>
<SEG id="segment-89" start_char="9454" end_char="9570">
<ORIGINAL_TEXT>Further examination of blood samples taken in 2019 could be the best way to find out when this pandemic really began.</ORIGINAL_TEXT>
<TOKEN id="token-89-0" pos="word" morph="none" start_char="9454" end_char="9460">Further</TOKEN>
<TOKEN id="token-89-1" pos="word" morph="none" start_char="9462" end_char="9472">examination</TOKEN>
<TOKEN id="token-89-2" pos="word" morph="none" start_char="9474" end_char="9475">of</TOKEN>
<TOKEN id="token-89-3" pos="word" morph="none" start_char="9477" end_char="9481">blood</TOKEN>
<TOKEN id="token-89-4" pos="word" morph="none" start_char="9483" end_char="9489">samples</TOKEN>
<TOKEN id="token-89-5" pos="word" morph="none" start_char="9491" end_char="9495">taken</TOKEN>
<TOKEN id="token-89-6" pos="word" morph="none" start_char="9497" end_char="9498">in</TOKEN>
<TOKEN id="token-89-7" pos="word" morph="none" start_char="9500" end_char="9503">2019</TOKEN>
<TOKEN id="token-89-8" pos="word" morph="none" start_char="9505" end_char="9509">could</TOKEN>
<TOKEN id="token-89-9" pos="word" morph="none" start_char="9511" end_char="9512">be</TOKEN>
<TOKEN id="token-89-10" pos="word" morph="none" start_char="9514" end_char="9516">the</TOKEN>
<TOKEN id="token-89-11" pos="word" morph="none" start_char="9518" end_char="9521">best</TOKEN>
<TOKEN id="token-89-12" pos="word" morph="none" start_char="9523" end_char="9525">way</TOKEN>
<TOKEN id="token-89-13" pos="word" morph="none" start_char="9527" end_char="9528">to</TOKEN>
<TOKEN id="token-89-14" pos="word" morph="none" start_char="9530" end_char="9533">find</TOKEN>
<TOKEN id="token-89-15" pos="word" morph="none" start_char="9535" end_char="9537">out</TOKEN>
<TOKEN id="token-89-16" pos="word" morph="none" start_char="9539" end_char="9542">when</TOKEN>
<TOKEN id="token-89-17" pos="word" morph="none" start_char="9544" end_char="9547">this</TOKEN>
<TOKEN id="token-89-18" pos="word" morph="none" start_char="9549" end_char="9556">pandemic</TOKEN>
<TOKEN id="token-89-19" pos="word" morph="none" start_char="9558" end_char="9563">really</TOKEN>
<TOKEN id="token-89-20" pos="word" morph="none" start_char="9565" end_char="9569">began</TOKEN>
<TOKEN id="token-89-21" pos="punct" morph="none" start_char="9570" end_char="9570">.</TOKEN>
</SEG>
<SEG id="segment-90" start_char="9573" end_char="9593">
<ORIGINAL_TEXT>Something is loading.</ORIGINAL_TEXT>
<TOKEN id="token-90-0" pos="word" morph="none" start_char="9573" end_char="9581">Something</TOKEN>
<TOKEN id="token-90-1" pos="word" morph="none" start_char="9583" end_char="9584">is</TOKEN>
<TOKEN id="token-90-2" pos="word" morph="none" start_char="9586" end_char="9592">loading</TOKEN>
<TOKEN id="token-90-3" pos="punct" morph="none" start_char="9593" end_char="9593">.</TOKEN>
</SEG>
<SEG id="segment-91" start_char="9596" end_char="9630">
<ORIGINAL_TEXT>Two crossed lines that form an 'X'.</ORIGINAL_TEXT>
<TOKEN id="token-91-0" pos="word" morph="none" start_char="9596" end_char="9598">Two</TOKEN>
<TOKEN id="token-91-1" pos="word" morph="none" start_char="9600" end_char="9606">crossed</TOKEN>
<TOKEN id="token-91-2" pos="word" morph="none" start_char="9608" end_char="9612">lines</TOKEN>
<TOKEN id="token-91-3" pos="word" morph="none" start_char="9614" end_char="9617">that</TOKEN>
<TOKEN id="token-91-4" pos="word" morph="none" start_char="9619" end_char="9622">form</TOKEN>
<TOKEN id="token-91-5" pos="word" morph="none" start_char="9624" end_char="9625">an</TOKEN>
<TOKEN id="token-91-6" pos="punct" morph="none" start_char="9627" end_char="9627">'</TOKEN>
<TOKEN id="token-91-7" pos="word" morph="none" start_char="9628" end_char="9628">X</TOKEN>
<TOKEN id="token-91-8" pos="punct" morph="none" start_char="9629" end_char="9630">'.</TOKEN>
</SEG>
<SEG id="segment-92" start_char="9632" end_char="9701">
<ORIGINAL_TEXT>It indicates a way to close an interaction, or dismiss a notification.</ORIGINAL_TEXT>
<TOKEN id="token-92-0" pos="word" morph="none" start_char="9632" end_char="9633">It</TOKEN>
<TOKEN id="token-92-1" pos="word" morph="none" start_char="9635" end_char="9643">indicates</TOKEN>
<TOKEN id="token-92-2" pos="word" morph="none" start_char="9645" end_char="9645">a</TOKEN>
<TOKEN id="token-92-3" pos="word" morph="none" start_char="9647" end_char="9649">way</TOKEN>
<TOKEN id="token-92-4" pos="word" morph="none" start_char="9651" end_char="9652">to</TOKEN>
<TOKEN id="token-92-5" pos="word" morph="none" start_char="9654" end_char="9658">close</TOKEN>
<TOKEN id="token-92-6" pos="word" morph="none" start_char="9660" end_char="9661">an</TOKEN>
<TOKEN id="token-92-7" pos="word" morph="none" start_char="9663" end_char="9673">interaction</TOKEN>
<TOKEN id="token-92-8" pos="punct" morph="none" start_char="9674" end_char="9674">,</TOKEN>
<TOKEN id="token-92-9" pos="word" morph="none" start_char="9676" end_char="9677">or</TOKEN>
<TOKEN id="token-92-10" pos="word" morph="none" start_char="9679" end_char="9685">dismiss</TOKEN>
<TOKEN id="token-92-11" pos="word" morph="none" start_char="9687" end_char="9687">a</TOKEN>
<TOKEN id="token-92-12" pos="word" morph="none" start_char="9689" end_char="9700">notification</TOKEN>
<TOKEN id="token-92-13" pos="punct" morph="none" start_char="9701" end_char="9701">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
