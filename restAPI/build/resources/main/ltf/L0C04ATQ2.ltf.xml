<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATQ2" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="1949" raw_text_md5="ea461344ad183073af7deaf74fe2126a">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="50">
<ORIGINAL_TEXT>¿A un año del primer caso de COVID-19 en el mundo?</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="punct" morph="none" start_char="1" end_char="1">¿</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="2" end_char="2">A</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="4" end_char="5">un</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="7" end_char="9">año</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="11" end_char="13">del</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="15" end_char="20">primer</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="22" end_char="25">caso</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="27" end_char="28">de</TOKEN>
<TOKEN id="token-0-8" pos="unknown" morph="none" start_char="30" end_char="37">COVID-19</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="39" end_char="40">en</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="42" end_char="43">el</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="45" end_char="49">mundo</TOKEN>
<TOKEN id="token-0-12" pos="punct" morph="none" start_char="50" end_char="50">?</TOKEN>
</SEG>
<SEG id="segment-1" start_char="54" end_char="62">
<ORIGINAL_TEXT>(Archivo)</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="punct" morph="none" start_char="54" end_char="54">(</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="55" end_char="61">Archivo</TOKEN>
<TOKEN id="token-1-2" pos="punct" morph="none" start_char="62" end_char="62">)</TOKEN>
</SEG>
<SEG id="segment-2" start_char="65" end_char="140">
<ORIGINAL_TEXT>Fotografía de archivo de un paciente con coronavirus en cuidados intensivos.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="65" end_char="74">Fotografía</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="76" end_char="77">de</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="79" end_char="85">archivo</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="87" end_char="88">de</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="90" end_char="91">un</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="93" end_char="100">paciente</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="102" end_char="104">con</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="106" end_char="116">coronavirus</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="118" end_char="119">en</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="121" end_char="128">cuidados</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="130" end_char="139">intensivos</TOKEN>
<TOKEN id="token-2-11" pos="punct" morph="none" start_char="140" end_char="140">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="144" end_char="455">
<ORIGINAL_TEXT>Pese a que el COVID-19 empezó a expandirse en diciembre del 2019 supuestamente en un mercado de Wuhan, la capital de la provincia Hubei, en China, existen varias posiciones sobre cuando se registró el primer caso de la enfermedad, información que publica la Organización Mundial de la Salud en su página oficial.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="144" end_char="147">Pese</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="149" end_char="149">a</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="151" end_char="153">que</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="155" end_char="156">el</TOKEN>
<TOKEN id="token-3-4" pos="unknown" morph="none" start_char="158" end_char="165">COVID-19</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="167" end_char="172">empezó</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="174" end_char="174">a</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="176" end_char="185">expandirse</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="187" end_char="188">en</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="190" end_char="198">diciembre</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="200" end_char="202">del</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="204" end_char="207">2019</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="209" end_char="221">supuestamente</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="223" end_char="224">en</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="226" end_char="227">un</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="229" end_char="235">mercado</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="237" end_char="238">de</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="240" end_char="244">Wuhan</TOKEN>
<TOKEN id="token-3-18" pos="punct" morph="none" start_char="245" end_char="245">,</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="247" end_char="248">la</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="250" end_char="256">capital</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="258" end_char="259">de</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="261" end_char="262">la</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="264" end_char="272">provincia</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="274" end_char="278">Hubei</TOKEN>
<TOKEN id="token-3-25" pos="punct" morph="none" start_char="279" end_char="279">,</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="281" end_char="282">en</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="284" end_char="288">China</TOKEN>
<TOKEN id="token-3-28" pos="punct" morph="none" start_char="289" end_char="289">,</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="291" end_char="297">existen</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="299" end_char="304">varias</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="306" end_char="315">posiciones</TOKEN>
<TOKEN id="token-3-32" pos="word" morph="none" start_char="317" end_char="321">sobre</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="323" end_char="328">cuando</TOKEN>
<TOKEN id="token-3-34" pos="word" morph="none" start_char="330" end_char="331">se</TOKEN>
<TOKEN id="token-3-35" pos="word" morph="none" start_char="333" end_char="340">registró</TOKEN>
<TOKEN id="token-3-36" pos="word" morph="none" start_char="342" end_char="343">el</TOKEN>
<TOKEN id="token-3-37" pos="word" morph="none" start_char="345" end_char="350">primer</TOKEN>
<TOKEN id="token-3-38" pos="word" morph="none" start_char="352" end_char="355">caso</TOKEN>
<TOKEN id="token-3-39" pos="word" morph="none" start_char="357" end_char="358">de</TOKEN>
<TOKEN id="token-3-40" pos="word" morph="none" start_char="360" end_char="361">la</TOKEN>
<TOKEN id="token-3-41" pos="word" morph="none" start_char="363" end_char="372">enfermedad</TOKEN>
<TOKEN id="token-3-42" pos="punct" morph="none" start_char="373" end_char="373">,</TOKEN>
<TOKEN id="token-3-43" pos="word" morph="none" start_char="375" end_char="385">información</TOKEN>
<TOKEN id="token-3-44" pos="word" morph="none" start_char="387" end_char="389">que</TOKEN>
<TOKEN id="token-3-45" pos="word" morph="none" start_char="391" end_char="397">publica</TOKEN>
<TOKEN id="token-3-46" pos="word" morph="none" start_char="399" end_char="400">la</TOKEN>
<TOKEN id="token-3-47" pos="word" morph="none" start_char="402" end_char="413">Organización</TOKEN>
<TOKEN id="token-3-48" pos="word" morph="none" start_char="415" end_char="421">Mundial</TOKEN>
<TOKEN id="token-3-49" pos="word" morph="none" start_char="423" end_char="424">de</TOKEN>
<TOKEN id="token-3-50" pos="word" morph="none" start_char="426" end_char="427">la</TOKEN>
<TOKEN id="token-3-51" pos="word" morph="none" start_char="429" end_char="433">Salud</TOKEN>
<TOKEN id="token-3-52" pos="word" morph="none" start_char="435" end_char="436">en</TOKEN>
<TOKEN id="token-3-53" pos="word" morph="none" start_char="438" end_char="439">su</TOKEN>
<TOKEN id="token-3-54" pos="word" morph="none" start_char="441" end_char="446">página</TOKEN>
<TOKEN id="token-3-55" pos="word" morph="none" start_char="448" end_char="454">oficial</TOKEN>
<TOKEN id="token-3-56" pos="punct" morph="none" start_char="455" end_char="455">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="458" end_char="623">
<ORIGINAL_TEXT>El diario chino South China Morning Post (SCMP), sostiene que el primer infectado se reportó el 17 de noviembre del 2019 en un residente de Hubei, de 55 años de edad.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="458" end_char="459">El</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="461" end_char="466">diario</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="468" end_char="472">chino</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="474" end_char="478">South</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="480" end_char="484">China</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="486" end_char="492">Morning</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="494" end_char="497">Post</TOKEN>
<TOKEN id="token-4-7" pos="punct" morph="none" start_char="499" end_char="499">(</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="500" end_char="503">SCMP</TOKEN>
<TOKEN id="token-4-9" pos="punct" morph="none" start_char="504" end_char="505">),</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="507" end_char="514">sostiene</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="516" end_char="518">que</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="520" end_char="521">el</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="523" end_char="528">primer</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="530" end_char="538">infectado</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="540" end_char="541">se</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="543" end_char="549">reportó</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="551" end_char="552">el</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="554" end_char="555">17</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="557" end_char="558">de</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="560" end_char="568">noviembre</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="570" end_char="572">del</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="574" end_char="577">2019</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="579" end_char="580">en</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="582" end_char="583">un</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="585" end_char="593">residente</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="595" end_char="596">de</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="598" end_char="602">Hubei</TOKEN>
<TOKEN id="token-4-28" pos="punct" morph="none" start_char="603" end_char="603">,</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="605" end_char="606">de</TOKEN>
<TOKEN id="token-4-30" pos="word" morph="none" start_char="608" end_char="609">55</TOKEN>
<TOKEN id="token-4-31" pos="word" morph="none" start_char="611" end_char="614">años</TOKEN>
<TOKEN id="token-4-32" pos="word" morph="none" start_char="616" end_char="617">de</TOKEN>
<TOKEN id="token-4-33" pos="word" morph="none" start_char="619" end_char="622">edad</TOKEN>
<TOKEN id="token-4-34" pos="punct" morph="none" start_char="623" end_char="623">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="625" end_char="752">
<ORIGINAL_TEXT>Sin embargo, la Organización Mundial de la Salud (OMS) notificó que el paciente cero fue confirmado el 31 de diciembre del 2019.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="625" end_char="627">Sin</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="629" end_char="635">embargo</TOKEN>
<TOKEN id="token-5-2" pos="punct" morph="none" start_char="636" end_char="636">,</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="638" end_char="639">la</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="641" end_char="652">Organización</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="654" end_char="660">Mundial</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="662" end_char="663">de</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="665" end_char="666">la</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="668" end_char="672">Salud</TOKEN>
<TOKEN id="token-5-9" pos="punct" morph="none" start_char="674" end_char="674">(</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="675" end_char="677">OMS</TOKEN>
<TOKEN id="token-5-11" pos="punct" morph="none" start_char="678" end_char="678">)</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="680" end_char="687">notificó</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="689" end_char="691">que</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="693" end_char="694">el</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="696" end_char="703">paciente</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="705" end_char="708">cero</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="710" end_char="712">fue</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="714" end_char="723">confirmado</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="725" end_char="726">el</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="728" end_char="729">31</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="731" end_char="732">de</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="734" end_char="742">diciembre</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="744" end_char="746">del</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="748" end_char="751">2019</TOKEN>
<TOKEN id="token-5-25" pos="punct" morph="none" start_char="752" end_char="752">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="755" end_char="1052">
<ORIGINAL_TEXT>El informe , en el SCMP dijo que las autoridades chinas habían identificado al menos a 266 personas que contrajeron el virus el año pasado y que estuvieron bajo vigilancia médica, y el primer caso fue el 17 de noviembre, semanas antes de que las autoridades anunciaran la aparición del nuevo virus.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="755" end_char="756">El</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="758" end_char="764">informe</TOKEN>
<TOKEN id="token-6-2" pos="punct" morph="none" start_char="766" end_char="766">,</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="768" end_char="769">en</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="771" end_char="772">el</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="774" end_char="777">SCMP</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="779" end_char="782">dijo</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="784" end_char="786">que</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="788" end_char="790">las</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="792" end_char="802">autoridades</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="804" end_char="809">chinas</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="811" end_char="816">habían</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="818" end_char="829">identificado</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="831" end_char="832">al</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="834" end_char="838">menos</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="840" end_char="840">a</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="842" end_char="844">266</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="846" end_char="853">personas</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="855" end_char="857">que</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="859" end_char="869">contrajeron</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="871" end_char="872">el</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="874" end_char="878">virus</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="880" end_char="881">el</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="883" end_char="885">año</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="887" end_char="892">pasado</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="894" end_char="894">y</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="896" end_char="898">que</TOKEN>
<TOKEN id="token-6-27" pos="word" morph="none" start_char="900" end_char="909">estuvieron</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="911" end_char="914">bajo</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="916" end_char="925">vigilancia</TOKEN>
<TOKEN id="token-6-30" pos="word" morph="none" start_char="927" end_char="932">médica</TOKEN>
<TOKEN id="token-6-31" pos="punct" morph="none" start_char="933" end_char="933">,</TOKEN>
<TOKEN id="token-6-32" pos="word" morph="none" start_char="935" end_char="935">y</TOKEN>
<TOKEN id="token-6-33" pos="word" morph="none" start_char="937" end_char="938">el</TOKEN>
<TOKEN id="token-6-34" pos="word" morph="none" start_char="940" end_char="945">primer</TOKEN>
<TOKEN id="token-6-35" pos="word" morph="none" start_char="947" end_char="950">caso</TOKEN>
<TOKEN id="token-6-36" pos="word" morph="none" start_char="952" end_char="954">fue</TOKEN>
<TOKEN id="token-6-37" pos="word" morph="none" start_char="956" end_char="957">el</TOKEN>
<TOKEN id="token-6-38" pos="word" morph="none" start_char="959" end_char="960">17</TOKEN>
<TOKEN id="token-6-39" pos="word" morph="none" start_char="962" end_char="963">de</TOKEN>
<TOKEN id="token-6-40" pos="word" morph="none" start_char="965" end_char="973">noviembre</TOKEN>
<TOKEN id="token-6-41" pos="punct" morph="none" start_char="974" end_char="974">,</TOKEN>
<TOKEN id="token-6-42" pos="word" morph="none" start_char="976" end_char="982">semanas</TOKEN>
<TOKEN id="token-6-43" pos="word" morph="none" start_char="984" end_char="988">antes</TOKEN>
<TOKEN id="token-6-44" pos="word" morph="none" start_char="990" end_char="991">de</TOKEN>
<TOKEN id="token-6-45" pos="word" morph="none" start_char="993" end_char="995">que</TOKEN>
<TOKEN id="token-6-46" pos="word" morph="none" start_char="997" end_char="999">las</TOKEN>
<TOKEN id="token-6-47" pos="word" morph="none" start_char="1001" end_char="1011">autoridades</TOKEN>
<TOKEN id="token-6-48" pos="word" morph="none" start_char="1013" end_char="1022">anunciaran</TOKEN>
<TOKEN id="token-6-49" pos="word" morph="none" start_char="1024" end_char="1025">la</TOKEN>
<TOKEN id="token-6-50" pos="word" morph="none" start_char="1027" end_char="1035">aparición</TOKEN>
<TOKEN id="token-6-51" pos="word" morph="none" start_char="1037" end_char="1039">del</TOKEN>
<TOKEN id="token-6-52" pos="word" morph="none" start_char="1041" end_char="1045">nuevo</TOKEN>
<TOKEN id="token-6-53" pos="word" morph="none" start_char="1047" end_char="1051">virus</TOKEN>
<TOKEN id="token-6-54" pos="punct" morph="none" start_char="1052" end_char="1052">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="1055" end_char="1210">
<ORIGINAL_TEXT>Los datos obtenidos por el Post, indican que sería un hombre de 55 años de la provincia de Hubei podría haber sido la primera persona en contratar Covid-19.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="1055" end_char="1057">Los</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="1059" end_char="1063">datos</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="1065" end_char="1073">obtenidos</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="1075" end_char="1077">por</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="1079" end_char="1080">el</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="1082" end_char="1085">Post</TOKEN>
<TOKEN id="token-7-6" pos="punct" morph="none" start_char="1086" end_char="1086">,</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="1088" end_char="1094">indican</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="1096" end_char="1098">que</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="1100" end_char="1104">sería</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="1106" end_char="1107">un</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="1109" end_char="1114">hombre</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="1116" end_char="1117">de</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="1119" end_char="1120">55</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="1122" end_char="1125">años</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="1127" end_char="1128">de</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="1130" end_char="1131">la</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="1133" end_char="1141">provincia</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="1143" end_char="1144">de</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="1146" end_char="1150">Hubei</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="1152" end_char="1157">podría</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="1159" end_char="1163">haber</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="1165" end_char="1168">sido</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="1170" end_char="1171">la</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="1173" end_char="1179">primera</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="1181" end_char="1187">persona</TOKEN>
<TOKEN id="token-7-26" pos="word" morph="none" start_char="1189" end_char="1190">en</TOKEN>
<TOKEN id="token-7-27" pos="word" morph="none" start_char="1192" end_char="1200">contratar</TOKEN>
<TOKEN id="token-7-28" pos="unknown" morph="none" start_char="1202" end_char="1209">Covid-19</TOKEN>
<TOKEN id="token-7-29" pos="punct" morph="none" start_char="1210" end_char="1210">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1212" end_char="1387">
<ORIGINAL_TEXT>Durante aproximadamente un mes después de esa fecha, se informaron de uno a cinco nuevos casos cada día, según el informe, y para el 20 de diciembre había 60 casos confirmados.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1212" end_char="1218">Durante</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1220" end_char="1234">aproximadamente</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1236" end_char="1237">un</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1239" end_char="1241">mes</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1243" end_char="1249">después</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1251" end_char="1252">de</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1254" end_char="1256">esa</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1258" end_char="1262">fecha</TOKEN>
<TOKEN id="token-8-8" pos="punct" morph="none" start_char="1263" end_char="1263">,</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1265" end_char="1266">se</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1268" end_char="1277">informaron</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1279" end_char="1280">de</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1282" end_char="1284">uno</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1286" end_char="1286">a</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1288" end_char="1292">cinco</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1294" end_char="1299">nuevos</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1301" end_char="1305">casos</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1307" end_char="1310">cada</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1312" end_char="1314">día</TOKEN>
<TOKEN id="token-8-19" pos="punct" morph="none" start_char="1315" end_char="1315">,</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="1317" end_char="1321">según</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="1323" end_char="1324">el</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="1326" end_char="1332">informe</TOKEN>
<TOKEN id="token-8-23" pos="punct" morph="none" start_char="1333" end_char="1333">,</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="1335" end_char="1335">y</TOKEN>
<TOKEN id="token-8-25" pos="word" morph="none" start_char="1337" end_char="1340">para</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="1342" end_char="1343">el</TOKEN>
<TOKEN id="token-8-27" pos="word" morph="none" start_char="1345" end_char="1346">20</TOKEN>
<TOKEN id="token-8-28" pos="word" morph="none" start_char="1348" end_char="1349">de</TOKEN>
<TOKEN id="token-8-29" pos="word" morph="none" start_char="1351" end_char="1359">diciembre</TOKEN>
<TOKEN id="token-8-30" pos="word" morph="none" start_char="1361" end_char="1365">había</TOKEN>
<TOKEN id="token-8-31" pos="word" morph="none" start_char="1367" end_char="1368">60</TOKEN>
<TOKEN id="token-8-32" pos="word" morph="none" start_char="1370" end_char="1374">casos</TOKEN>
<TOKEN id="token-8-33" pos="word" morph="none" start_char="1376" end_char="1386">confirmados</TOKEN>
<TOKEN id="token-8-34" pos="punct" morph="none" start_char="1387" end_char="1387">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1390" end_char="1633">
<ORIGINAL_TEXT>Según diarios internacionales, el inicio del contagio por la enfermedad fue entre en 1 y el 17 de diciembre del 2019 con unos pacientes que presentaron una extraña neumonía luego de haber estado en el mercado de Mayoristas de Mariscos de Wuhan.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1390" end_char="1394">Según</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1396" end_char="1402">diarios</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1404" end_char="1418">internacionales</TOKEN>
<TOKEN id="token-9-3" pos="punct" morph="none" start_char="1419" end_char="1419">,</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1421" end_char="1422">el</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1424" end_char="1429">inicio</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1431" end_char="1433">del</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1435" end_char="1442">contagio</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1444" end_char="1446">por</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1448" end_char="1449">la</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1451" end_char="1460">enfermedad</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1462" end_char="1464">fue</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1466" end_char="1470">entre</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1472" end_char="1473">en</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1475" end_char="1475">1</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1477" end_char="1477">y</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1479" end_char="1480">el</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1482" end_char="1483">17</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1485" end_char="1486">de</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1488" end_char="1496">diciembre</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1498" end_char="1500">del</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1502" end_char="1505">2019</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1507" end_char="1509">con</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1511" end_char="1514">unos</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1516" end_char="1524">pacientes</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1526" end_char="1528">que</TOKEN>
<TOKEN id="token-9-26" pos="word" morph="none" start_char="1530" end_char="1540">presentaron</TOKEN>
<TOKEN id="token-9-27" pos="word" morph="none" start_char="1542" end_char="1544">una</TOKEN>
<TOKEN id="token-9-28" pos="word" morph="none" start_char="1546" end_char="1552">extraña</TOKEN>
<TOKEN id="token-9-29" pos="word" morph="none" start_char="1554" end_char="1561">neumonía</TOKEN>
<TOKEN id="token-9-30" pos="word" morph="none" start_char="1563" end_char="1567">luego</TOKEN>
<TOKEN id="token-9-31" pos="word" morph="none" start_char="1569" end_char="1570">de</TOKEN>
<TOKEN id="token-9-32" pos="word" morph="none" start_char="1572" end_char="1576">haber</TOKEN>
<TOKEN id="token-9-33" pos="word" morph="none" start_char="1578" end_char="1583">estado</TOKEN>
<TOKEN id="token-9-34" pos="word" morph="none" start_char="1585" end_char="1586">en</TOKEN>
<TOKEN id="token-9-35" pos="word" morph="none" start_char="1588" end_char="1589">el</TOKEN>
<TOKEN id="token-9-36" pos="word" morph="none" start_char="1591" end_char="1597">mercado</TOKEN>
<TOKEN id="token-9-37" pos="word" morph="none" start_char="1599" end_char="1600">de</TOKEN>
<TOKEN id="token-9-38" pos="word" morph="none" start_char="1602" end_char="1611">Mayoristas</TOKEN>
<TOKEN id="token-9-39" pos="word" morph="none" start_char="1613" end_char="1614">de</TOKEN>
<TOKEN id="token-9-40" pos="word" morph="none" start_char="1616" end_char="1623">Mariscos</TOKEN>
<TOKEN id="token-9-41" pos="word" morph="none" start_char="1625" end_char="1626">de</TOKEN>
<TOKEN id="token-9-42" pos="word" morph="none" start_char="1628" end_char="1632">Wuhan</TOKEN>
<TOKEN id="token-9-43" pos="punct" morph="none" start_char="1633" end_char="1633">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1636" end_char="1945">
<ORIGINAL_TEXT>En el mes de abril investigadores de la Universidad de Cambridge publicaron un informe en el cual apuntaron que a pesar de que varios expertos situaron el inicio de brote en Wuhan, la infección pudo haber surgido a mediados de septiembre y que dicha ciudad podría no ser el epicentro, según el diario La Razón.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1636" end_char="1637">En</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1639" end_char="1640">el</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1642" end_char="1644">mes</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1646" end_char="1647">de</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1649" end_char="1653">abril</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1655" end_char="1668">investigadores</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1670" end_char="1671">de</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1673" end_char="1674">la</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1676" end_char="1686">Universidad</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1688" end_char="1689">de</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1691" end_char="1699">Cambridge</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1701" end_char="1710">publicaron</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1712" end_char="1713">un</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1715" end_char="1721">informe</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1723" end_char="1724">en</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1726" end_char="1727">el</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1729" end_char="1732">cual</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1734" end_char="1742">apuntaron</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1744" end_char="1746">que</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1748" end_char="1748">a</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1750" end_char="1754">pesar</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1756" end_char="1757">de</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1759" end_char="1761">que</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1763" end_char="1768">varios</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1770" end_char="1777">expertos</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="1779" end_char="1786">situaron</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="1788" end_char="1789">el</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="1791" end_char="1796">inicio</TOKEN>
<TOKEN id="token-10-28" pos="word" morph="none" start_char="1798" end_char="1799">de</TOKEN>
<TOKEN id="token-10-29" pos="word" morph="none" start_char="1801" end_char="1805">brote</TOKEN>
<TOKEN id="token-10-30" pos="word" morph="none" start_char="1807" end_char="1808">en</TOKEN>
<TOKEN id="token-10-31" pos="word" morph="none" start_char="1810" end_char="1814">Wuhan</TOKEN>
<TOKEN id="token-10-32" pos="punct" morph="none" start_char="1815" end_char="1815">,</TOKEN>
<TOKEN id="token-10-33" pos="word" morph="none" start_char="1817" end_char="1818">la</TOKEN>
<TOKEN id="token-10-34" pos="word" morph="none" start_char="1820" end_char="1828">infección</TOKEN>
<TOKEN id="token-10-35" pos="word" morph="none" start_char="1830" end_char="1833">pudo</TOKEN>
<TOKEN id="token-10-36" pos="word" morph="none" start_char="1835" end_char="1839">haber</TOKEN>
<TOKEN id="token-10-37" pos="word" morph="none" start_char="1841" end_char="1847">surgido</TOKEN>
<TOKEN id="token-10-38" pos="word" morph="none" start_char="1849" end_char="1849">a</TOKEN>
<TOKEN id="token-10-39" pos="word" morph="none" start_char="1851" end_char="1858">mediados</TOKEN>
<TOKEN id="token-10-40" pos="word" morph="none" start_char="1860" end_char="1861">de</TOKEN>
<TOKEN id="token-10-41" pos="word" morph="none" start_char="1863" end_char="1872">septiembre</TOKEN>
<TOKEN id="token-10-42" pos="word" morph="none" start_char="1874" end_char="1874">y</TOKEN>
<TOKEN id="token-10-43" pos="word" morph="none" start_char="1876" end_char="1878">que</TOKEN>
<TOKEN id="token-10-44" pos="word" morph="none" start_char="1880" end_char="1884">dicha</TOKEN>
<TOKEN id="token-10-45" pos="word" morph="none" start_char="1886" end_char="1891">ciudad</TOKEN>
<TOKEN id="token-10-46" pos="word" morph="none" start_char="1893" end_char="1898">podría</TOKEN>
<TOKEN id="token-10-47" pos="word" morph="none" start_char="1900" end_char="1901">no</TOKEN>
<TOKEN id="token-10-48" pos="word" morph="none" start_char="1903" end_char="1905">ser</TOKEN>
<TOKEN id="token-10-49" pos="word" morph="none" start_char="1907" end_char="1908">el</TOKEN>
<TOKEN id="token-10-50" pos="word" morph="none" start_char="1910" end_char="1918">epicentro</TOKEN>
<TOKEN id="token-10-51" pos="punct" morph="none" start_char="1919" end_char="1919">,</TOKEN>
<TOKEN id="token-10-52" pos="word" morph="none" start_char="1921" end_char="1925">según</TOKEN>
<TOKEN id="token-10-53" pos="word" morph="none" start_char="1927" end_char="1928">el</TOKEN>
<TOKEN id="token-10-54" pos="word" morph="none" start_char="1930" end_char="1935">diario</TOKEN>
<TOKEN id="token-10-55" pos="word" morph="none" start_char="1937" end_char="1938">La</TOKEN>
<TOKEN id="token-10-56" pos="word" morph="none" start_char="1940" end_char="1944">Razón</TOKEN>
<TOKEN id="token-10-57" pos="punct" morph="none" start_char="1945" end_char="1945">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
