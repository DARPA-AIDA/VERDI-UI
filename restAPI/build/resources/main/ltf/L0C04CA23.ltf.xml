<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CA23" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="2334" raw_text_md5="28c616f55dd6b096c08a865763d76748">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="76">
<ORIGINAL_TEXT>Chinese researchers now claim coronavirus originated in India in summer 2019</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="7">Chinese</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="9" end_char="19">researchers</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="21" end_char="23">now</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="25" end_char="29">claim</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="31" end_char="41">coronavirus</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="43" end_char="52">originated</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="54" end_char="55">in</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="57" end_char="61">India</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="63" end_char="64">in</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="66" end_char="71">summer</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="73" end_char="76">2019</TOKEN>
</SEG>
<SEG id="segment-1" start_char="80" end_char="99">
<ORIGINAL_TEXT>Representative image</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="80" end_char="93">Representative</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="95" end_char="99">image</TOKEN>
</SEG>
<SEG id="segment-2" start_char="103" end_char="122">
<ORIGINAL_TEXT>Representative image</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="103" end_char="116">Representative</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="118" end_char="122">image</TOKEN>
</SEG>
<SEG id="segment-3" start_char="126" end_char="270">
<ORIGINAL_TEXT>Battling global adversity over COVID-19, Chinese scientists are now arguing that the novel coronavirus originated in India in the summer of 2019.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="126" end_char="133">Battling</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="135" end_char="140">global</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="142" end_char="150">adversity</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="152" end_char="155">over</TOKEN>
<TOKEN id="token-3-4" pos="unknown" morph="none" start_char="157" end_char="164">COVID-19</TOKEN>
<TOKEN id="token-3-5" pos="punct" morph="none" start_char="165" end_char="165">,</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="167" end_char="173">Chinese</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="175" end_char="184">scientists</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="186" end_char="188">are</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="190" end_char="192">now</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="194" end_char="200">arguing</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="202" end_char="205">that</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="207" end_char="209">the</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="211" end_char="215">novel</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="217" end_char="227">coronavirus</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="229" end_char="238">originated</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="240" end_char="241">in</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="243" end_char="247">India</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="249" end_char="250">in</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="252" end_char="254">the</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="256" end_char="261">summer</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="263" end_char="264">of</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="266" end_char="269">2019</TOKEN>
<TOKEN id="token-3-23" pos="punct" morph="none" start_char="270" end_char="270">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="273" end_char="518">
<ORIGINAL_TEXT>A team of researchers from the Chinese Academy of Sciences claimed that the deadly virus emerged by transferring from animals to humans via contaminated water before travelling unnoticed to Wuhan, where it was first detected, reported Daily mail.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="273" end_char="273">A</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="275" end_char="278">team</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="280" end_char="281">of</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="283" end_char="293">researchers</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="295" end_char="298">from</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="300" end_char="302">the</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="304" end_char="310">Chinese</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="312" end_char="318">Academy</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="320" end_char="321">of</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="323" end_char="330">Sciences</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="332" end_char="338">claimed</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="340" end_char="343">that</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="345" end_char="347">the</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="349" end_char="354">deadly</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="356" end_char="360">virus</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="362" end_char="368">emerged</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="370" end_char="371">by</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="373" end_char="384">transferring</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="386" end_char="389">from</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="391" end_char="397">animals</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="399" end_char="400">to</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="402" end_char="407">humans</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="409" end_char="411">via</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="413" end_char="424">contaminated</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="426" end_char="430">water</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="432" end_char="437">before</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="439" end_char="448">travelling</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="450" end_char="458">unnoticed</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="460" end_char="461">to</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="463" end_char="467">Wuhan</TOKEN>
<TOKEN id="token-4-30" pos="punct" morph="none" start_char="468" end_char="468">,</TOKEN>
<TOKEN id="token-4-31" pos="word" morph="none" start_char="470" end_char="474">where</TOKEN>
<TOKEN id="token-4-32" pos="word" morph="none" start_char="476" end_char="477">it</TOKEN>
<TOKEN id="token-4-33" pos="word" morph="none" start_char="479" end_char="481">was</TOKEN>
<TOKEN id="token-4-34" pos="word" morph="none" start_char="483" end_char="487">first</TOKEN>
<TOKEN id="token-4-35" pos="word" morph="none" start_char="489" end_char="496">detected</TOKEN>
<TOKEN id="token-4-36" pos="punct" morph="none" start_char="497" end_char="497">,</TOKEN>
<TOKEN id="token-4-37" pos="word" morph="none" start_char="499" end_char="506">reported</TOKEN>
<TOKEN id="token-4-38" pos="word" morph="none" start_char="508" end_char="512">Daily</TOKEN>
<TOKEN id="token-4-39" pos="word" morph="none" start_char="514" end_char="517">mail</TOKEN>
<TOKEN id="token-4-40" pos="punct" morph="none" start_char="518" end_char="518">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="521" end_char="613">
<ORIGINAL_TEXT>It is not the first time that Chinese authorities have pointed the finger of blame elsewhere.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="521" end_char="522">It</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="524" end_char="525">is</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="527" end_char="529">not</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="531" end_char="533">the</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="535" end_char="539">first</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="541" end_char="544">time</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="546" end_char="549">that</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="551" end_char="557">Chinese</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="559" end_char="569">authorities</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="571" end_char="574">have</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="576" end_char="582">pointed</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="584" end_char="586">the</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="588" end_char="593">finger</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="595" end_char="596">of</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="598" end_char="602">blame</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="604" end_char="612">elsewhere</TOKEN>
<TOKEN id="token-5-16" pos="punct" morph="none" start_char="613" end_char="613">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="615" end_char="723">
<ORIGINAL_TEXT>Earlier, it blamed Italy and the United States, largely without evidence, for the novel coronavirus outbreak.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="615" end_char="621">Earlier</TOKEN>
<TOKEN id="token-6-1" pos="punct" morph="none" start_char="622" end_char="622">,</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="624" end_char="625">it</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="627" end_char="632">blamed</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="634" end_char="638">Italy</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="640" end_char="642">and</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="644" end_char="646">the</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="648" end_char="653">United</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="655" end_char="660">States</TOKEN>
<TOKEN id="token-6-9" pos="punct" morph="none" start_char="661" end_char="661">,</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="663" end_char="669">largely</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="671" end_char="677">without</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="679" end_char="686">evidence</TOKEN>
<TOKEN id="token-6-13" pos="punct" morph="none" start_char="687" end_char="687">,</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="689" end_char="691">for</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="693" end_char="695">the</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="697" end_char="701">novel</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="703" end_char="713">coronavirus</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="715" end_char="722">outbreak</TOKEN>
<TOKEN id="token-6-19" pos="punct" morph="none" start_char="723" end_char="723">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="726" end_char="801">
<ORIGINAL_TEXT>The researchers used phylogenetic analysis to trace the origins of COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="726" end_char="728">The</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="730" end_char="740">researchers</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="742" end_char="745">used</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="747" end_char="758">phylogenetic</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="760" end_char="767">analysis</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="769" end_char="770">to</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="772" end_char="776">trace</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="778" end_char="780">the</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="782" end_char="788">origins</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="790" end_char="791">of</TOKEN>
<TOKEN id="token-7-10" pos="unknown" morph="none" start_char="793" end_char="800">COVID-19</TOKEN>
<TOKEN id="token-7-11" pos="punct" morph="none" start_char="801" end_char="801">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="803" end_char="929">
<ORIGINAL_TEXT>Viruses, like all cells, mutate as they reproduce, meaning tiny changes occur in their DNA each time they replicate themselves.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="803" end_char="809">Viruses</TOKEN>
<TOKEN id="token-8-1" pos="punct" morph="none" start_char="810" end_char="810">,</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="812" end_char="815">like</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="817" end_char="819">all</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="821" end_char="825">cells</TOKEN>
<TOKEN id="token-8-5" pos="punct" morph="none" start_char="826" end_char="826">,</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="828" end_char="833">mutate</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="835" end_char="836">as</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="838" end_char="841">they</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="843" end_char="851">reproduce</TOKEN>
<TOKEN id="token-8-10" pos="punct" morph="none" start_char="852" end_char="852">,</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="854" end_char="860">meaning</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="862" end_char="865">tiny</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="867" end_char="873">changes</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="875" end_char="879">occur</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="881" end_char="882">in</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="884" end_char="888">their</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="890" end_char="892">DNA</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="894" end_char="897">each</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="899" end_char="902">time</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="904" end_char="907">they</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="909" end_char="917">replicate</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="919" end_char="928">themselves</TOKEN>
<TOKEN id="token-8-23" pos="punct" morph="none" start_char="929" end_char="929">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="931" end_char="1070">
<ORIGINAL_TEXT>Therefore, it should be possible to track down the original version of the virus by finding the sample with the fewest mutations, they said.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="931" end_char="939">Therefore</TOKEN>
<TOKEN id="token-9-1" pos="punct" morph="none" start_char="940" end_char="940">,</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="942" end_char="943">it</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="945" end_char="950">should</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="952" end_char="953">be</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="955" end_char="962">possible</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="964" end_char="965">to</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="967" end_char="971">track</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="973" end_char="976">down</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="978" end_char="980">the</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="982" end_char="989">original</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="991" end_char="997">version</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="999" end_char="1000">of</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1002" end_char="1004">the</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1006" end_char="1010">virus</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1012" end_char="1013">by</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1015" end_char="1021">finding</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1023" end_char="1025">the</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1027" end_char="1032">sample</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1034" end_char="1037">with</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1039" end_char="1041">the</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1043" end_char="1048">fewest</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1050" end_char="1058">mutations</TOKEN>
<TOKEN id="token-9-23" pos="punct" morph="none" start_char="1059" end_char="1059">,</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1061" end_char="1064">they</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1066" end_char="1069">said</TOKEN>
<TOKEN id="token-9-26" pos="punct" morph="none" start_char="1070" end_char="1070">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1073" end_char="1149">
<ORIGINAL_TEXT>Follow our LIVE blog for the latest updates of the novel coronavirus pandemic</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1073" end_char="1078">Follow</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1080" end_char="1082">our</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1084" end_char="1087">LIVE</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1089" end_char="1092">blog</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1094" end_char="1096">for</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1098" end_char="1100">the</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1102" end_char="1107">latest</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1109" end_char="1115">updates</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1117" end_char="1118">of</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1120" end_char="1122">the</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1124" end_char="1128">novel</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1130" end_char="1140">coronavirus</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1142" end_char="1149">pandemic</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1153" end_char="1287">
<ORIGINAL_TEXT>According to the report, the scientists further said that using this method rules out the virus found in Wuhan as the 'original' virus.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1153" end_char="1161">According</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1163" end_char="1164">to</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1166" end_char="1168">the</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1170" end_char="1175">report</TOKEN>
<TOKEN id="token-11-4" pos="punct" morph="none" start_char="1176" end_char="1176">,</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1178" end_char="1180">the</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1182" end_char="1191">scientists</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1193" end_char="1199">further</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1201" end_char="1204">said</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1206" end_char="1209">that</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1211" end_char="1215">using</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1217" end_char="1220">this</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1222" end_char="1227">method</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1229" end_char="1233">rules</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1235" end_char="1237">out</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1239" end_char="1241">the</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1243" end_char="1247">virus</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1249" end_char="1253">found</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1255" end_char="1256">in</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="1258" end_char="1262">Wuhan</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1264" end_char="1265">as</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="1267" end_char="1269">the</TOKEN>
<TOKEN id="token-11-22" pos="punct" morph="none" start_char="1271" end_char="1271">'</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="1272" end_char="1279">original</TOKEN>
<TOKEN id="token-11-24" pos="punct" morph="none" start_char="1280" end_char="1280">'</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="1282" end_char="1286">virus</TOKEN>
<TOKEN id="token-11-26" pos="punct" morph="none" start_char="1287" end_char="1287">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1289" end_char="1421">
<ORIGINAL_TEXT>They instead points to eight other countries: Bangladesh, the USA, Greece, Australia, India, Italy, Czech Republic, Russia or Serbia.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1289" end_char="1292">They</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1294" end_char="1300">instead</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1302" end_char="1307">points</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1309" end_char="1310">to</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1312" end_char="1316">eight</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1318" end_char="1322">other</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1324" end_char="1332">countries</TOKEN>
<TOKEN id="token-12-7" pos="punct" morph="none" start_char="1333" end_char="1333">:</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1335" end_char="1344">Bangladesh</TOKEN>
<TOKEN id="token-12-9" pos="punct" morph="none" start_char="1345" end_char="1345">,</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1347" end_char="1349">the</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1351" end_char="1353">USA</TOKEN>
<TOKEN id="token-12-12" pos="punct" morph="none" start_char="1354" end_char="1354">,</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1356" end_char="1361">Greece</TOKEN>
<TOKEN id="token-12-14" pos="punct" morph="none" start_char="1362" end_char="1362">,</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1364" end_char="1372">Australia</TOKEN>
<TOKEN id="token-12-16" pos="punct" morph="none" start_char="1373" end_char="1373">,</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1375" end_char="1379">India</TOKEN>
<TOKEN id="token-12-18" pos="punct" morph="none" start_char="1380" end_char="1380">,</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1382" end_char="1386">Italy</TOKEN>
<TOKEN id="token-12-20" pos="punct" morph="none" start_char="1387" end_char="1387">,</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1389" end_char="1393">Czech</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1395" end_char="1402">Republic</TOKEN>
<TOKEN id="token-12-23" pos="punct" morph="none" start_char="1403" end_char="1403">,</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="1405" end_char="1410">Russia</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="1412" end_char="1413">or</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="1415" end_char="1420">Serbia</TOKEN>
<TOKEN id="token-12-27" pos="punct" morph="none" start_char="1421" end_char="1421">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1424" end_char="1558">
<ORIGINAL_TEXT>The blame comes against a backdrop of increased political tensions between India and China amid their border dispute in eastern Ladakh.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1424" end_char="1426">The</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1428" end_char="1432">blame</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1434" end_char="1438">comes</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1440" end_char="1446">against</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1448" end_char="1448">a</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1450" end_char="1457">backdrop</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1459" end_char="1460">of</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1462" end_char="1470">increased</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1472" end_char="1480">political</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1482" end_char="1489">tensions</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1491" end_char="1497">between</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1499" end_char="1503">India</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1505" end_char="1507">and</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1509" end_char="1513">China</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1515" end_char="1518">amid</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1520" end_char="1524">their</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1526" end_char="1531">border</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1533" end_char="1539">dispute</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1541" end_char="1542">in</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1544" end_char="1550">eastern</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1552" end_char="1557">Ladakh</TOKEN>
<TOKEN id="token-13-21" pos="punct" morph="none" start_char="1558" end_char="1558">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1561" end_char="1763">
<ORIGINAL_TEXT>The unproven theory further said that from May to June 2019, the second-longest recorded heatwave had rampaged in northern-central India and Pakistan, which created a serious water crisis in this region.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1561" end_char="1563">The</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1565" end_char="1572">unproven</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1574" end_char="1579">theory</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1581" end_char="1587">further</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1589" end_char="1592">said</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1594" end_char="1597">that</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1599" end_char="1602">from</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1604" end_char="1606">May</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1608" end_char="1609">to</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1611" end_char="1614">June</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1616" end_char="1619">2019</TOKEN>
<TOKEN id="token-14-11" pos="punct" morph="none" start_char="1620" end_char="1620">,</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1622" end_char="1624">the</TOKEN>
<TOKEN id="token-14-13" pos="unknown" morph="none" start_char="1626" end_char="1639">second-longest</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="1641" end_char="1648">recorded</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1650" end_char="1657">heatwave</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1659" end_char="1661">had</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="1663" end_char="1670">rampaged</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="1672" end_char="1673">in</TOKEN>
<TOKEN id="token-14-19" pos="unknown" morph="none" start_char="1675" end_char="1690">northern-central</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="1692" end_char="1696">India</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="1698" end_char="1700">and</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="1702" end_char="1709">Pakistan</TOKEN>
<TOKEN id="token-14-23" pos="punct" morph="none" start_char="1710" end_char="1710">,</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="1712" end_char="1716">which</TOKEN>
<TOKEN id="token-14-25" pos="word" morph="none" start_char="1718" end_char="1724">created</TOKEN>
<TOKEN id="token-14-26" pos="word" morph="none" start_char="1726" end_char="1726">a</TOKEN>
<TOKEN id="token-14-27" pos="word" morph="none" start_char="1728" end_char="1734">serious</TOKEN>
<TOKEN id="token-14-28" pos="word" morph="none" start_char="1736" end_char="1740">water</TOKEN>
<TOKEN id="token-14-29" pos="word" morph="none" start_char="1742" end_char="1747">crisis</TOKEN>
<TOKEN id="token-14-30" pos="word" morph="none" start_char="1749" end_char="1750">in</TOKEN>
<TOKEN id="token-14-31" pos="word" morph="none" start_char="1752" end_char="1755">this</TOKEN>
<TOKEN id="token-14-32" pos="word" morph="none" start_char="1757" end_char="1762">region</TOKEN>
<TOKEN id="token-14-33" pos="punct" morph="none" start_char="1763" end_char="1763">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1766" end_char="1873">
<ORIGINAL_TEXT>The water shortage made wild animals such as monkeys engage in the deadly fight over water among each other.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1766" end_char="1768">The</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1770" end_char="1774">water</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1776" end_char="1783">shortage</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1785" end_char="1788">made</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1790" end_char="1793">wild</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1795" end_char="1801">animals</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1803" end_char="1806">such</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1808" end_char="1809">as</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1811" end_char="1817">monkeys</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1819" end_char="1824">engage</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1826" end_char="1827">in</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1829" end_char="1831">the</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1833" end_char="1838">deadly</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1840" end_char="1844">fight</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1846" end_char="1849">over</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="1851" end_char="1855">water</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="1857" end_char="1861">among</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="1863" end_char="1866">each</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="1868" end_char="1872">other</TOKEN>
<TOKEN id="token-15-19" pos="punct" morph="none" start_char="1873" end_char="1873">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1875" end_char="2097">
<ORIGINAL_TEXT>This would have surely increased the chance of human-wild animal interactions, the researchers said, as they speculated that "the [animal to human] transmission of SARS-CoV-2 might be associated with this unusual heatwave."</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1875" end_char="1878">This</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1880" end_char="1884">would</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1886" end_char="1889">have</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1891" end_char="1896">surely</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1898" end_char="1906">increased</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1908" end_char="1910">the</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1912" end_char="1917">chance</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1919" end_char="1920">of</TOKEN>
<TOKEN id="token-16-8" pos="unknown" morph="none" start_char="1922" end_char="1931">human-wild</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="1933" end_char="1938">animal</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="1940" end_char="1951">interactions</TOKEN>
<TOKEN id="token-16-11" pos="punct" morph="none" start_char="1952" end_char="1952">,</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="1954" end_char="1956">the</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="1958" end_char="1968">researchers</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="1970" end_char="1973">said</TOKEN>
<TOKEN id="token-16-15" pos="punct" morph="none" start_char="1974" end_char="1974">,</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="1976" end_char="1977">as</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="1979" end_char="1982">they</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="1984" end_char="1993">speculated</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="1995" end_char="1998">that</TOKEN>
<TOKEN id="token-16-20" pos="punct" morph="none" start_char="2000" end_char="2000">"</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="2001" end_char="2003">the</TOKEN>
<TOKEN id="token-16-22" pos="punct" morph="none" start_char="2005" end_char="2005">[</TOKEN>
<TOKEN id="token-16-23" pos="word" morph="none" start_char="2006" end_char="2011">animal</TOKEN>
<TOKEN id="token-16-24" pos="word" morph="none" start_char="2013" end_char="2014">to</TOKEN>
<TOKEN id="token-16-25" pos="word" morph="none" start_char="2016" end_char="2020">human</TOKEN>
<TOKEN id="token-16-26" pos="punct" morph="none" start_char="2021" end_char="2021">]</TOKEN>
<TOKEN id="token-16-27" pos="word" morph="none" start_char="2023" end_char="2034">transmission</TOKEN>
<TOKEN id="token-16-28" pos="word" morph="none" start_char="2036" end_char="2037">of</TOKEN>
<TOKEN id="token-16-29" pos="unknown" morph="none" start_char="2039" end_char="2048">SARS-CoV-2</TOKEN>
<TOKEN id="token-16-30" pos="word" morph="none" start_char="2050" end_char="2054">might</TOKEN>
<TOKEN id="token-16-31" pos="word" morph="none" start_char="2056" end_char="2057">be</TOKEN>
<TOKEN id="token-16-32" pos="word" morph="none" start_char="2059" end_char="2068">associated</TOKEN>
<TOKEN id="token-16-33" pos="word" morph="none" start_char="2070" end_char="2073">with</TOKEN>
<TOKEN id="token-16-34" pos="word" morph="none" start_char="2075" end_char="2078">this</TOKEN>
<TOKEN id="token-16-35" pos="word" morph="none" start_char="2080" end_char="2086">unusual</TOKEN>
<TOKEN id="token-16-36" pos="word" morph="none" start_char="2088" end_char="2095">heatwave</TOKEN>
<TOKEN id="token-16-37" pos="punct" morph="none" start_char="2096" end_char="2097">."</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2100" end_char="2183">
<ORIGINAL_TEXT>The claim, however, rejected by David Robertson, and expert from Glasgow University.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2100" end_char="2102">The</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2104" end_char="2108">claim</TOKEN>
<TOKEN id="token-17-2" pos="punct" morph="none" start_char="2109" end_char="2109">,</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2111" end_char="2117">however</TOKEN>
<TOKEN id="token-17-4" pos="punct" morph="none" start_char="2118" end_char="2118">,</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2120" end_char="2127">rejected</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2129" end_char="2130">by</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2132" end_char="2136">David</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2138" end_char="2146">Robertson</TOKEN>
<TOKEN id="token-17-9" pos="punct" morph="none" start_char="2147" end_char="2147">,</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2149" end_char="2151">and</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2153" end_char="2158">expert</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2160" end_char="2163">from</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2165" end_char="2171">Glasgow</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2173" end_char="2182">University</TOKEN>
<TOKEN id="token-17-15" pos="punct" morph="none" start_char="2183" end_char="2183">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2185" end_char="2286">
<ORIGINAL_TEXT>He called the paper 'very flawed' and concluded 'it adds nothing to our understanding of coronavirus'.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2185" end_char="2186">He</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2188" end_char="2193">called</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2195" end_char="2197">the</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2199" end_char="2203">paper</TOKEN>
<TOKEN id="token-18-4" pos="punct" morph="none" start_char="2205" end_char="2205">'</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2206" end_char="2209">very</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2211" end_char="2216">flawed</TOKEN>
<TOKEN id="token-18-7" pos="punct" morph="none" start_char="2217" end_char="2217">'</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2219" end_char="2221">and</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="2223" end_char="2231">concluded</TOKEN>
<TOKEN id="token-18-10" pos="punct" morph="none" start_char="2233" end_char="2233">'</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="2234" end_char="2235">it</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2237" end_char="2240">adds</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="2242" end_char="2248">nothing</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="2250" end_char="2251">to</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="2253" end_char="2255">our</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="2257" end_char="2269">understanding</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="2271" end_char="2272">of</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="2274" end_char="2284">coronavirus</TOKEN>
<TOKEN id="token-18-19" pos="punct" morph="none" start_char="2285" end_char="2286">'.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2289" end_char="2330">
<ORIGINAL_TEXT>Follow our full coverage on COVID-19 here.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2289" end_char="2294">Follow</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2296" end_char="2298">our</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2300" end_char="2303">full</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2305" end_char="2312">coverage</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2314" end_char="2315">on</TOKEN>
<TOKEN id="token-19-5" pos="unknown" morph="none" start_char="2317" end_char="2324">COVID-19</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2326" end_char="2329">here</TOKEN>
<TOKEN id="token-19-7" pos="punct" morph="none" start_char="2330" end_char="2330">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
