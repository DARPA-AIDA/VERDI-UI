<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATLD" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="9641" raw_text_md5="2e07a7a4a32006ba4d0a793afe1f3f9f">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="73">
<ORIGINAL_TEXT>7 reasons supporting the use of electric hand dryers in times of Covid-19</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="1">7</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="3" end_char="9">reasons</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="11" end_char="20">supporting</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="22" end_char="24">the</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="26" end_char="28">use</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="30" end_char="31">of</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="33" end_char="40">electric</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="42" end_char="45">hand</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="47" end_char="52">dryers</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="54" end_char="55">in</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="57" end_char="61">times</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="63" end_char="64">of</TOKEN>
<TOKEN id="token-0-12" pos="unknown" morph="none" start_char="66" end_char="73">Covid-19</TOKEN>
</SEG>
<SEG id="segment-1" start_char="78" end_char="136">
<ORIGINAL_TEXT>I remember my time in the hospital as if it were yesterday.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="78" end_char="78">I</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="80" end_char="87">remember</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="89" end_char="90">my</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="92" end_char="95">time</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="97" end_char="98">in</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="100" end_char="102">the</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="104" end_char="111">hospital</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="113" end_char="114">as</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="116" end_char="117">if</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="119" end_char="120">it</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="122" end_char="125">were</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="127" end_char="135">yesterday</TOKEN>
<TOKEN id="token-1-12" pos="punct" morph="none" start_char="136" end_char="136">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="138" end_char="223">
<ORIGINAL_TEXT>I am very aware of how my friend, Gonzalo, left me in front of the emergency entrance.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="138" end_char="138">I</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="140" end_char="141">am</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="143" end_char="146">very</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="148" end_char="152">aware</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="154" end_char="155">of</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="157" end_char="159">how</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="161" end_char="162">my</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="164" end_char="169">friend</TOKEN>
<TOKEN id="token-2-8" pos="punct" morph="none" start_char="170" end_char="170">,</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="172" end_char="178">Gonzalo</TOKEN>
<TOKEN id="token-2-10" pos="punct" morph="none" start_char="179" end_char="179">,</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="181" end_char="184">left</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="186" end_char="187">me</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="189" end_char="190">in</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="192" end_char="196">front</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="198" end_char="199">of</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="201" end_char="203">the</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="205" end_char="213">emergency</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="215" end_char="222">entrance</TOKEN>
<TOKEN id="token-2-19" pos="punct" morph="none" start_char="223" end_char="223">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="225" end_char="366">
<ORIGINAL_TEXT>In my mind, I keep hearing my name resounding through the speakers of an inhospitable cold and empty room, inviting me to go to box number 35.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="225" end_char="226">In</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="228" end_char="229">my</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="231" end_char="234">mind</TOKEN>
<TOKEN id="token-3-3" pos="punct" morph="none" start_char="235" end_char="235">,</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="237" end_char="237">I</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="239" end_char="242">keep</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="244" end_char="250">hearing</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="252" end_char="253">my</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="255" end_char="258">name</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="260" end_char="269">resounding</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="271" end_char="277">through</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="279" end_char="281">the</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="283" end_char="290">speakers</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="292" end_char="293">of</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="295" end_char="296">an</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="298" end_char="309">inhospitable</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="311" end_char="314">cold</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="316" end_char="318">and</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="320" end_char="324">empty</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="326" end_char="329">room</TOKEN>
<TOKEN id="token-3-20" pos="punct" morph="none" start_char="330" end_char="330">,</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="332" end_char="339">inviting</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="341" end_char="342">me</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="344" end_char="345">to</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="347" end_char="348">go</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="350" end_char="351">to</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="353" end_char="355">box</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="357" end_char="362">number</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="364" end_char="365">35</TOKEN>
<TOKEN id="token-3-29" pos="punct" morph="none" start_char="366" end_char="366">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="368" end_char="503">
<ORIGINAL_TEXT>I can't stop thinking about the doctor on duty from the box door that wouldn’t dare to enter completely out of fear of getting infected.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="368" end_char="368">I</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="370" end_char="374">can't</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="376" end_char="379">stop</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="381" end_char="388">thinking</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="390" end_char="394">about</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="396" end_char="398">the</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="400" end_char="405">doctor</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="407" end_char="408">on</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="410" end_char="413">duty</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="415" end_char="418">from</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="420" end_char="422">the</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="424" end_char="426">box</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="428" end_char="431">door</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="433" end_char="436">that</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="438" end_char="445">wouldn’t</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="447" end_char="450">dare</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="452" end_char="453">to</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="455" end_char="459">enter</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="461" end_char="470">completely</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="472" end_char="474">out</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="476" end_char="477">of</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="479" end_char="482">fear</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="484" end_char="485">of</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="487" end_char="493">getting</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="495" end_char="502">infected</TOKEN>
<TOKEN id="token-4-25" pos="punct" morph="none" start_char="503" end_char="503">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="505" end_char="619">
<ORIGINAL_TEXT>He said to me, "I regret to inform you that you have a severe bilateral pneumonia caused by the SARS-CoV-2 virus.".</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="505" end_char="506">He</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="508" end_char="511">said</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="513" end_char="514">to</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="516" end_char="517">me</TOKEN>
<TOKEN id="token-5-4" pos="punct" morph="none" start_char="518" end_char="518">,</TOKEN>
<TOKEN id="token-5-5" pos="punct" morph="none" start_char="520" end_char="520">"</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="521" end_char="521">I</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="523" end_char="528">regret</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="530" end_char="531">to</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="533" end_char="538">inform</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="540" end_char="542">you</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="544" end_char="547">that</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="549" end_char="551">you</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="553" end_char="556">have</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="558" end_char="558">a</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="560" end_char="565">severe</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="567" end_char="575">bilateral</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="577" end_char="585">pneumonia</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="587" end_char="592">caused</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="594" end_char="595">by</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="597" end_char="599">the</TOKEN>
<TOKEN id="token-5-21" pos="unknown" morph="none" start_char="601" end_char="610">SARS-CoV-2</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="612" end_char="616">virus</TOKEN>
<TOKEN id="token-5-23" pos="punct" morph="none" start_char="617" end_char="619">.".</TOKEN>
</SEG>
<SEG id="segment-6" start_char="621" end_char="703">
<ORIGINAL_TEXT>But above all, I remember that at that very moment, I thought to myself, "Now what?</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="621" end_char="623">But</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="625" end_char="629">above</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="631" end_char="633">all</TOKEN>
<TOKEN id="token-6-3" pos="punct" morph="none" start_char="634" end_char="634">,</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="636" end_char="636">I</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="638" end_char="645">remember</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="647" end_char="650">that</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="652" end_char="653">at</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="655" end_char="658">that</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="660" end_char="663">very</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="665" end_char="670">moment</TOKEN>
<TOKEN id="token-6-11" pos="punct" morph="none" start_char="671" end_char="671">,</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="673" end_char="673">I</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="675" end_char="681">thought</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="683" end_char="684">to</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="686" end_char="691">myself</TOKEN>
<TOKEN id="token-6-16" pos="punct" morph="none" start_char="692" end_char="692">,</TOKEN>
<TOKEN id="token-6-17" pos="punct" morph="none" start_char="694" end_char="694">"</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="695" end_char="697">Now</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="699" end_char="702">what</TOKEN>
<TOKEN id="token-6-20" pos="punct" morph="none" start_char="703" end_char="703">?</TOKEN>
</SEG>
<SEG id="segment-7" start_char="705" end_char="727">
<ORIGINAL_TEXT>Will I get out of this?</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="705" end_char="708">Will</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="710" end_char="710">I</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="712" end_char="714">get</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="716" end_char="718">out</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="720" end_char="721">of</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="723" end_char="726">this</TOKEN>
<TOKEN id="token-7-6" pos="punct" morph="none" start_char="727" end_char="727">?</TOKEN>
</SEG>
<SEG id="segment-8" start_char="729" end_char="763">
<ORIGINAL_TEXT>Will I be able to defeat the virus?</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="729" end_char="732">Will</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="734" end_char="734">I</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="736" end_char="737">be</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="739" end_char="742">able</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="744" end_char="745">to</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="747" end_char="752">defeat</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="754" end_char="756">the</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="758" end_char="762">virus</TOKEN>
<TOKEN id="token-8-8" pos="punct" morph="none" start_char="763" end_char="763">?</TOKEN>
</SEG>
<SEG id="segment-9" start_char="765" end_char="833">
<ORIGINAL_TEXT>How can they cure me if there is no specific remedy for this virus?".</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="765" end_char="767">How</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="769" end_char="771">can</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="773" end_char="776">they</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="778" end_char="781">cure</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="783" end_char="784">me</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="786" end_char="787">if</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="789" end_char="793">there</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="795" end_char="796">is</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="798" end_char="799">no</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="801" end_char="808">specific</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="810" end_char="815">remedy</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="817" end_char="819">for</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="821" end_char="824">this</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="826" end_char="830">virus</TOKEN>
<TOKEN id="token-9-14" pos="punct" morph="none" start_char="831" end_char="833">?".</TOKEN>
</SEG>
<SEG id="segment-10" start_char="836" end_char="956">
<ORIGINAL_TEXT>At that time, it was the beginning of the Covid-19 pandemic in Spain and we hardly knew anything about this deadly virus.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="836" end_char="837">At</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="839" end_char="842">that</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="844" end_char="847">time</TOKEN>
<TOKEN id="token-10-3" pos="punct" morph="none" start_char="848" end_char="848">,</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="850" end_char="851">it</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="853" end_char="855">was</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="857" end_char="859">the</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="861" end_char="869">beginning</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="871" end_char="872">of</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="874" end_char="876">the</TOKEN>
<TOKEN id="token-10-10" pos="unknown" morph="none" start_char="878" end_char="885">Covid-19</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="887" end_char="894">pandemic</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="896" end_char="897">in</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="899" end_char="903">Spain</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="905" end_char="907">and</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="909" end_char="910">we</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="912" end_char="917">hardly</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="919" end_char="922">knew</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="924" end_char="931">anything</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="933" end_char="937">about</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="939" end_char="942">this</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="944" end_char="949">deadly</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="951" end_char="955">virus</TOKEN>
<TOKEN id="token-10-23" pos="punct" morph="none" start_char="956" end_char="956">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="958" end_char="1131">
<ORIGINAL_TEXT>To this day, we continue to have many unknowns but luckily, we’ve also begun to have some certainties and above all hope, a hope that is reaching us in the form of a vaccine.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="958" end_char="959">To</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="961" end_char="964">this</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="966" end_char="968">day</TOKEN>
<TOKEN id="token-11-3" pos="punct" morph="none" start_char="969" end_char="969">,</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="971" end_char="972">we</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="974" end_char="981">continue</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="983" end_char="984">to</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="986" end_char="989">have</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="991" end_char="994">many</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="996" end_char="1003">unknowns</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1005" end_char="1007">but</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1009" end_char="1015">luckily</TOKEN>
<TOKEN id="token-11-12" pos="punct" morph="none" start_char="1016" end_char="1016">,</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1018" end_char="1022">we’ve</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1024" end_char="1027">also</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1029" end_char="1033">begun</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1035" end_char="1036">to</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1038" end_char="1041">have</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1043" end_char="1046">some</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="1048" end_char="1058">certainties</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1060" end_char="1062">and</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="1064" end_char="1068">above</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="1070" end_char="1072">all</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="1074" end_char="1077">hope</TOKEN>
<TOKEN id="token-11-24" pos="punct" morph="none" start_char="1078" end_char="1078">,</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="1080" end_char="1080">a</TOKEN>
<TOKEN id="token-11-26" pos="word" morph="none" start_char="1082" end_char="1085">hope</TOKEN>
<TOKEN id="token-11-27" pos="word" morph="none" start_char="1087" end_char="1090">that</TOKEN>
<TOKEN id="token-11-28" pos="word" morph="none" start_char="1092" end_char="1093">is</TOKEN>
<TOKEN id="token-11-29" pos="word" morph="none" start_char="1095" end_char="1102">reaching</TOKEN>
<TOKEN id="token-11-30" pos="word" morph="none" start_char="1104" end_char="1105">us</TOKEN>
<TOKEN id="token-11-31" pos="word" morph="none" start_char="1107" end_char="1108">in</TOKEN>
<TOKEN id="token-11-32" pos="word" morph="none" start_char="1110" end_char="1112">the</TOKEN>
<TOKEN id="token-11-33" pos="word" morph="none" start_char="1114" end_char="1117">form</TOKEN>
<TOKEN id="token-11-34" pos="word" morph="none" start_char="1119" end_char="1120">of</TOKEN>
<TOKEN id="token-11-35" pos="word" morph="none" start_char="1122" end_char="1122">a</TOKEN>
<TOKEN id="token-11-36" pos="word" morph="none" start_char="1124" end_char="1130">vaccine</TOKEN>
<TOKEN id="token-11-37" pos="punct" morph="none" start_char="1131" end_char="1131">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1134" end_char="1229">
<ORIGINAL_TEXT>All these uncertainties accompanied me during the two weeks that I was admitted to the hospital.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1134" end_char="1136">All</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1138" end_char="1142">these</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1144" end_char="1156">uncertainties</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1158" end_char="1168">accompanied</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1170" end_char="1171">me</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1173" end_char="1178">during</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1180" end_char="1182">the</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1184" end_char="1186">two</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1188" end_char="1192">weeks</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1194" end_char="1197">that</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1199" end_char="1199">I</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1201" end_char="1203">was</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1205" end_char="1212">admitted</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1214" end_char="1215">to</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1217" end_char="1219">the</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1221" end_char="1228">hospital</TOKEN>
<TOKEN id="token-12-16" pos="punct" morph="none" start_char="1229" end_char="1229">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1231" end_char="1374">
<ORIGINAL_TEXT>As you can imagine, the hours in a hospital room pass very slowly, especially if you are totally isolated and with practically no human contact.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1231" end_char="1232">As</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1234" end_char="1236">you</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1238" end_char="1240">can</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1242" end_char="1248">imagine</TOKEN>
<TOKEN id="token-13-4" pos="punct" morph="none" start_char="1249" end_char="1249">,</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1251" end_char="1253">the</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1255" end_char="1259">hours</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1261" end_char="1262">in</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1264" end_char="1264">a</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1266" end_char="1273">hospital</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1275" end_char="1278">room</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1280" end_char="1283">pass</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1285" end_char="1288">very</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1290" end_char="1295">slowly</TOKEN>
<TOKEN id="token-13-14" pos="punct" morph="none" start_char="1296" end_char="1296">,</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1298" end_char="1307">especially</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1309" end_char="1310">if</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1312" end_char="1314">you</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1316" end_char="1318">are</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1320" end_char="1326">totally</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1328" end_char="1335">isolated</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="1337" end_char="1339">and</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="1341" end_char="1344">with</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="1346" end_char="1356">practically</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="1358" end_char="1359">no</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="1361" end_char="1365">human</TOKEN>
<TOKEN id="token-13-26" pos="word" morph="none" start_char="1367" end_char="1373">contact</TOKEN>
<TOKEN id="token-13-27" pos="punct" morph="none" start_char="1374" end_char="1374">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1376" end_char="1494">
<ORIGINAL_TEXT>It is for this reason that, more than ever, I was connected to the outside world and to my family through the internet.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1376" end_char="1377">It</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1379" end_char="1380">is</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1382" end_char="1384">for</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1386" end_char="1389">this</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1391" end_char="1396">reason</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1398" end_char="1401">that</TOKEN>
<TOKEN id="token-14-6" pos="punct" morph="none" start_char="1402" end_char="1402">,</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1404" end_char="1407">more</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1409" end_char="1412">than</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1414" end_char="1417">ever</TOKEN>
<TOKEN id="token-14-10" pos="punct" morph="none" start_char="1418" end_char="1418">,</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1420" end_char="1420">I</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1422" end_char="1424">was</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1426" end_char="1434">connected</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="1436" end_char="1437">to</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1439" end_char="1441">the</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1443" end_char="1449">outside</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="1451" end_char="1455">world</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="1457" end_char="1459">and</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="1461" end_char="1462">to</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="1464" end_char="1465">my</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="1467" end_char="1472">family</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="1474" end_char="1480">through</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="1482" end_char="1484">the</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="1486" end_char="1493">internet</TOKEN>
<TOKEN id="token-14-25" pos="punct" morph="none" start_char="1494" end_char="1494">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1496" end_char="1684">
<ORIGINAL_TEXT>It was here that I really realized that we did not know anything about the virus and that the information that was spread by the media, in many cases, were neither reliable nor trustworthy.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1496" end_char="1497">It</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1499" end_char="1501">was</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1503" end_char="1506">here</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1508" end_char="1511">that</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1513" end_char="1513">I</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1515" end_char="1520">really</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1522" end_char="1529">realized</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1531" end_char="1534">that</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1536" end_char="1537">we</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1539" end_char="1541">did</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1543" end_char="1545">not</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1547" end_char="1550">know</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1552" end_char="1559">anything</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1561" end_char="1565">about</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1567" end_char="1569">the</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="1571" end_char="1575">virus</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="1577" end_char="1579">and</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="1581" end_char="1584">that</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="1586" end_char="1588">the</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="1590" end_char="1600">information</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="1602" end_char="1605">that</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="1607" end_char="1609">was</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="1611" end_char="1616">spread</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="1618" end_char="1619">by</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="1621" end_char="1623">the</TOKEN>
<TOKEN id="token-15-25" pos="word" morph="none" start_char="1625" end_char="1629">media</TOKEN>
<TOKEN id="token-15-26" pos="punct" morph="none" start_char="1630" end_char="1630">,</TOKEN>
<TOKEN id="token-15-27" pos="word" morph="none" start_char="1632" end_char="1633">in</TOKEN>
<TOKEN id="token-15-28" pos="word" morph="none" start_char="1635" end_char="1638">many</TOKEN>
<TOKEN id="token-15-29" pos="word" morph="none" start_char="1640" end_char="1644">cases</TOKEN>
<TOKEN id="token-15-30" pos="punct" morph="none" start_char="1645" end_char="1645">,</TOKEN>
<TOKEN id="token-15-31" pos="word" morph="none" start_char="1647" end_char="1650">were</TOKEN>
<TOKEN id="token-15-32" pos="word" morph="none" start_char="1652" end_char="1658">neither</TOKEN>
<TOKEN id="token-15-33" pos="word" morph="none" start_char="1660" end_char="1667">reliable</TOKEN>
<TOKEN id="token-15-34" pos="word" morph="none" start_char="1669" end_char="1671">nor</TOKEN>
<TOKEN id="token-15-35" pos="word" morph="none" start_char="1673" end_char="1683">trustworthy</TOKEN>
<TOKEN id="token-15-36" pos="punct" morph="none" start_char="1684" end_char="1684">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1687" end_char="1846">
<ORIGINAL_TEXT>Out of all news spreading at the time about Covid-19 that put me on alert-mode was the one that mentioned that hand dryers spread the virus inside of restrooms.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1687" end_char="1689">Out</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1691" end_char="1692">of</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1694" end_char="1696">all</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1698" end_char="1701">news</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1703" end_char="1711">spreading</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1713" end_char="1714">at</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1716" end_char="1718">the</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1720" end_char="1723">time</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1725" end_char="1729">about</TOKEN>
<TOKEN id="token-16-9" pos="unknown" morph="none" start_char="1731" end_char="1738">Covid-19</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="1740" end_char="1743">that</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="1745" end_char="1747">put</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="1749" end_char="1750">me</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="1752" end_char="1753">on</TOKEN>
<TOKEN id="token-16-14" pos="unknown" morph="none" start_char="1755" end_char="1764">alert-mode</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="1766" end_char="1768">was</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="1770" end_char="1772">the</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="1774" end_char="1776">one</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="1778" end_char="1781">that</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="1783" end_char="1791">mentioned</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="1793" end_char="1796">that</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="1798" end_char="1801">hand</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="1803" end_char="1808">dryers</TOKEN>
<TOKEN id="token-16-23" pos="word" morph="none" start_char="1810" end_char="1815">spread</TOKEN>
<TOKEN id="token-16-24" pos="word" morph="none" start_char="1817" end_char="1819">the</TOKEN>
<TOKEN id="token-16-25" pos="word" morph="none" start_char="1821" end_char="1825">virus</TOKEN>
<TOKEN id="token-16-26" pos="word" morph="none" start_char="1827" end_char="1832">inside</TOKEN>
<TOKEN id="token-16-27" pos="word" morph="none" start_char="1834" end_char="1835">of</TOKEN>
<TOKEN id="token-16-28" pos="word" morph="none" start_char="1837" end_char="1845">restrooms</TOKEN>
<TOKEN id="token-16-29" pos="punct" morph="none" start_char="1846" end_char="1846">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1848" end_char="2076">
<ORIGINAL_TEXT>As a person who has worked for almost 20 years at Mediclinics, a company that designs, manufactures and markets electric hand dryers- and therefore knows these types of products perfectly- I could not disagree more with the news.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1848" end_char="1849">As</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1851" end_char="1851">a</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="1853" end_char="1858">person</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="1860" end_char="1862">who</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="1864" end_char="1866">has</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="1868" end_char="1873">worked</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="1875" end_char="1877">for</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="1879" end_char="1884">almost</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="1886" end_char="1887">20</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="1889" end_char="1893">years</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="1895" end_char="1896">at</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="1898" end_char="1908">Mediclinics</TOKEN>
<TOKEN id="token-17-12" pos="punct" morph="none" start_char="1909" end_char="1909">,</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="1911" end_char="1911">a</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="1913" end_char="1919">company</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="1921" end_char="1924">that</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="1926" end_char="1932">designs</TOKEN>
<TOKEN id="token-17-17" pos="punct" morph="none" start_char="1933" end_char="1933">,</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="1935" end_char="1946">manufactures</TOKEN>
<TOKEN id="token-17-19" pos="word" morph="none" start_char="1948" end_char="1950">and</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="1952" end_char="1958">markets</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="1960" end_char="1967">electric</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="1969" end_char="1972">hand</TOKEN>
<TOKEN id="token-17-23" pos="word" morph="none" start_char="1974" end_char="1979">dryers</TOKEN>
<TOKEN id="token-17-24" pos="punct" morph="none" start_char="1980" end_char="1980">-</TOKEN>
<TOKEN id="token-17-25" pos="word" morph="none" start_char="1982" end_char="1984">and</TOKEN>
<TOKEN id="token-17-26" pos="word" morph="none" start_char="1986" end_char="1994">therefore</TOKEN>
<TOKEN id="token-17-27" pos="word" morph="none" start_char="1996" end_char="2000">knows</TOKEN>
<TOKEN id="token-17-28" pos="word" morph="none" start_char="2002" end_char="2006">these</TOKEN>
<TOKEN id="token-17-29" pos="word" morph="none" start_char="2008" end_char="2012">types</TOKEN>
<TOKEN id="token-17-30" pos="word" morph="none" start_char="2014" end_char="2015">of</TOKEN>
<TOKEN id="token-17-31" pos="word" morph="none" start_char="2017" end_char="2024">products</TOKEN>
<TOKEN id="token-17-32" pos="word" morph="none" start_char="2026" end_char="2034">perfectly</TOKEN>
<TOKEN id="token-17-33" pos="punct" morph="none" start_char="2035" end_char="2035">-</TOKEN>
<TOKEN id="token-17-34" pos="word" morph="none" start_char="2037" end_char="2037">I</TOKEN>
<TOKEN id="token-17-35" pos="word" morph="none" start_char="2039" end_char="2043">could</TOKEN>
<TOKEN id="token-17-36" pos="word" morph="none" start_char="2045" end_char="2047">not</TOKEN>
<TOKEN id="token-17-37" pos="word" morph="none" start_char="2049" end_char="2056">disagree</TOKEN>
<TOKEN id="token-17-38" pos="word" morph="none" start_char="2058" end_char="2061">more</TOKEN>
<TOKEN id="token-17-39" pos="word" morph="none" start_char="2063" end_char="2066">with</TOKEN>
<TOKEN id="token-17-40" pos="word" morph="none" start_char="2068" end_char="2070">the</TOKEN>
<TOKEN id="token-17-41" pos="word" morph="none" start_char="2072" end_char="2075">news</TOKEN>
<TOKEN id="token-17-42" pos="punct" morph="none" start_char="2076" end_char="2076">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2078" end_char="2219">
<ORIGINAL_TEXT>I know firsthand that this is totally false and it is for this reason that I immediately began to think about how to refute these "fake news".</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2078" end_char="2078">I</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2080" end_char="2083">know</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2085" end_char="2093">firsthand</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2095" end_char="2098">that</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2100" end_char="2103">this</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2105" end_char="2106">is</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2108" end_char="2114">totally</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2116" end_char="2120">false</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2122" end_char="2124">and</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="2126" end_char="2127">it</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="2129" end_char="2130">is</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="2132" end_char="2134">for</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2136" end_char="2139">this</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="2141" end_char="2146">reason</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="2148" end_char="2151">that</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="2153" end_char="2153">I</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="2155" end_char="2165">immediately</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="2167" end_char="2171">began</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="2173" end_char="2174">to</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="2176" end_char="2180">think</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="2182" end_char="2186">about</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="2188" end_char="2190">how</TOKEN>
<TOKEN id="token-18-22" pos="word" morph="none" start_char="2192" end_char="2193">to</TOKEN>
<TOKEN id="token-18-23" pos="word" morph="none" start_char="2195" end_char="2200">refute</TOKEN>
<TOKEN id="token-18-24" pos="word" morph="none" start_char="2202" end_char="2206">these</TOKEN>
<TOKEN id="token-18-25" pos="punct" morph="none" start_char="2208" end_char="2208">"</TOKEN>
<TOKEN id="token-18-26" pos="word" morph="none" start_char="2209" end_char="2212">fake</TOKEN>
<TOKEN id="token-18-27" pos="word" morph="none" start_char="2214" end_char="2217">news</TOKEN>
<TOKEN id="token-18-28" pos="punct" morph="none" start_char="2218" end_char="2219">".</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2222" end_char="2458">
<ORIGINAL_TEXT>I thought that the best way to do this was to speak with the highest authority on health matters in Spain to argue, with proper technical and scientific data, that our product was not a danger to the human health, but quite the opposite.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2222" end_char="2222">I</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2224" end_char="2230">thought</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2232" end_char="2235">that</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2237" end_char="2239">the</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2241" end_char="2244">best</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2246" end_char="2248">way</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2250" end_char="2251">to</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2253" end_char="2254">do</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2256" end_char="2259">this</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="2261" end_char="2263">was</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="2265" end_char="2266">to</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="2268" end_char="2272">speak</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="2274" end_char="2277">with</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="2279" end_char="2281">the</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="2283" end_char="2289">highest</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="2291" end_char="2299">authority</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="2301" end_char="2302">on</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="2304" end_char="2309">health</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="2311" end_char="2317">matters</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="2319" end_char="2320">in</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="2322" end_char="2326">Spain</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="2328" end_char="2329">to</TOKEN>
<TOKEN id="token-19-22" pos="word" morph="none" start_char="2331" end_char="2335">argue</TOKEN>
<TOKEN id="token-19-23" pos="punct" morph="none" start_char="2336" end_char="2336">,</TOKEN>
<TOKEN id="token-19-24" pos="word" morph="none" start_char="2338" end_char="2341">with</TOKEN>
<TOKEN id="token-19-25" pos="word" morph="none" start_char="2343" end_char="2348">proper</TOKEN>
<TOKEN id="token-19-26" pos="word" morph="none" start_char="2350" end_char="2358">technical</TOKEN>
<TOKEN id="token-19-27" pos="word" morph="none" start_char="2360" end_char="2362">and</TOKEN>
<TOKEN id="token-19-28" pos="word" morph="none" start_char="2364" end_char="2373">scientific</TOKEN>
<TOKEN id="token-19-29" pos="word" morph="none" start_char="2375" end_char="2378">data</TOKEN>
<TOKEN id="token-19-30" pos="punct" morph="none" start_char="2379" end_char="2379">,</TOKEN>
<TOKEN id="token-19-31" pos="word" morph="none" start_char="2381" end_char="2384">that</TOKEN>
<TOKEN id="token-19-32" pos="word" morph="none" start_char="2386" end_char="2388">our</TOKEN>
<TOKEN id="token-19-33" pos="word" morph="none" start_char="2390" end_char="2396">product</TOKEN>
<TOKEN id="token-19-34" pos="word" morph="none" start_char="2398" end_char="2400">was</TOKEN>
<TOKEN id="token-19-35" pos="word" morph="none" start_char="2402" end_char="2404">not</TOKEN>
<TOKEN id="token-19-36" pos="word" morph="none" start_char="2406" end_char="2406">a</TOKEN>
<TOKEN id="token-19-37" pos="word" morph="none" start_char="2408" end_char="2413">danger</TOKEN>
<TOKEN id="token-19-38" pos="word" morph="none" start_char="2415" end_char="2416">to</TOKEN>
<TOKEN id="token-19-39" pos="word" morph="none" start_char="2418" end_char="2420">the</TOKEN>
<TOKEN id="token-19-40" pos="word" morph="none" start_char="2422" end_char="2426">human</TOKEN>
<TOKEN id="token-19-41" pos="word" morph="none" start_char="2428" end_char="2433">health</TOKEN>
<TOKEN id="token-19-42" pos="punct" morph="none" start_char="2434" end_char="2434">,</TOKEN>
<TOKEN id="token-19-43" pos="word" morph="none" start_char="2436" end_char="2438">but</TOKEN>
<TOKEN id="token-19-44" pos="word" morph="none" start_char="2440" end_char="2444">quite</TOKEN>
<TOKEN id="token-19-45" pos="word" morph="none" start_char="2446" end_char="2448">the</TOKEN>
<TOKEN id="token-19-46" pos="word" morph="none" start_char="2450" end_char="2457">opposite</TOKEN>
<TOKEN id="token-19-47" pos="punct" morph="none" start_char="2458" end_char="2458">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2460" end_char="2535">
<ORIGINAL_TEXT>I hoped that after reviewing our solid arguments, they would be on our side.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2460" end_char="2460">I</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2462" end_char="2466">hoped</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2468" end_char="2471">that</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2473" end_char="2477">after</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2479" end_char="2487">reviewing</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2489" end_char="2491">our</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2493" end_char="2497">solid</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2499" end_char="2507">arguments</TOKEN>
<TOKEN id="token-20-8" pos="punct" morph="none" start_char="2508" end_char="2508">,</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2510" end_char="2513">they</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2515" end_char="2519">would</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="2521" end_char="2522">be</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="2524" end_char="2525">on</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="2527" end_char="2529">our</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="2531" end_char="2534">side</TOKEN>
<TOKEN id="token-20-15" pos="punct" morph="none" start_char="2535" end_char="2535">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2538" end_char="3053">
<ORIGINAL_TEXT>When all was said and done and upon leaving the hospital, the first thing I did was contact all of our competitors in Spain who are also dedicated to the automatic hand dryer business because I have always thought that unity is strength, and with the help of a an important communication agency accustomed to interacting with the public administration, we would all set out on the road to the Spanish Ministry of Health… just as Dorothy did when she decided to follow the yellow brick road that would take her to Oz.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2538" end_char="2541">When</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2543" end_char="2545">all</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2547" end_char="2549">was</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2551" end_char="2554">said</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2556" end_char="2558">and</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="2560" end_char="2563">done</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2565" end_char="2567">and</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="2569" end_char="2572">upon</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="2574" end_char="2580">leaving</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="2582" end_char="2584">the</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="2586" end_char="2593">hospital</TOKEN>
<TOKEN id="token-21-11" pos="punct" morph="none" start_char="2594" end_char="2594">,</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="2596" end_char="2598">the</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="2600" end_char="2604">first</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="2606" end_char="2610">thing</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="2612" end_char="2612">I</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="2614" end_char="2616">did</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="2618" end_char="2620">was</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="2622" end_char="2628">contact</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="2630" end_char="2632">all</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="2634" end_char="2635">of</TOKEN>
<TOKEN id="token-21-21" pos="word" morph="none" start_char="2637" end_char="2639">our</TOKEN>
<TOKEN id="token-21-22" pos="word" morph="none" start_char="2641" end_char="2651">competitors</TOKEN>
<TOKEN id="token-21-23" pos="word" morph="none" start_char="2653" end_char="2654">in</TOKEN>
<TOKEN id="token-21-24" pos="word" morph="none" start_char="2656" end_char="2660">Spain</TOKEN>
<TOKEN id="token-21-25" pos="word" morph="none" start_char="2662" end_char="2664">who</TOKEN>
<TOKEN id="token-21-26" pos="word" morph="none" start_char="2666" end_char="2668">are</TOKEN>
<TOKEN id="token-21-27" pos="word" morph="none" start_char="2670" end_char="2673">also</TOKEN>
<TOKEN id="token-21-28" pos="word" morph="none" start_char="2675" end_char="2683">dedicated</TOKEN>
<TOKEN id="token-21-29" pos="word" morph="none" start_char="2685" end_char="2686">to</TOKEN>
<TOKEN id="token-21-30" pos="word" morph="none" start_char="2688" end_char="2690">the</TOKEN>
<TOKEN id="token-21-31" pos="word" morph="none" start_char="2692" end_char="2700">automatic</TOKEN>
<TOKEN id="token-21-32" pos="word" morph="none" start_char="2702" end_char="2705">hand</TOKEN>
<TOKEN id="token-21-33" pos="word" morph="none" start_char="2707" end_char="2711">dryer</TOKEN>
<TOKEN id="token-21-34" pos="word" morph="none" start_char="2713" end_char="2720">business</TOKEN>
<TOKEN id="token-21-35" pos="word" morph="none" start_char="2722" end_char="2728">because</TOKEN>
<TOKEN id="token-21-36" pos="word" morph="none" start_char="2730" end_char="2730">I</TOKEN>
<TOKEN id="token-21-37" pos="word" morph="none" start_char="2732" end_char="2735">have</TOKEN>
<TOKEN id="token-21-38" pos="word" morph="none" start_char="2737" end_char="2742">always</TOKEN>
<TOKEN id="token-21-39" pos="word" morph="none" start_char="2744" end_char="2750">thought</TOKEN>
<TOKEN id="token-21-40" pos="word" morph="none" start_char="2752" end_char="2755">that</TOKEN>
<TOKEN id="token-21-41" pos="word" morph="none" start_char="2757" end_char="2761">unity</TOKEN>
<TOKEN id="token-21-42" pos="word" morph="none" start_char="2763" end_char="2764">is</TOKEN>
<TOKEN id="token-21-43" pos="word" morph="none" start_char="2766" end_char="2773">strength</TOKEN>
<TOKEN id="token-21-44" pos="punct" morph="none" start_char="2774" end_char="2774">,</TOKEN>
<TOKEN id="token-21-45" pos="word" morph="none" start_char="2776" end_char="2778">and</TOKEN>
<TOKEN id="token-21-46" pos="word" morph="none" start_char="2780" end_char="2783">with</TOKEN>
<TOKEN id="token-21-47" pos="word" morph="none" start_char="2785" end_char="2787">the</TOKEN>
<TOKEN id="token-21-48" pos="word" morph="none" start_char="2789" end_char="2792">help</TOKEN>
<TOKEN id="token-21-49" pos="word" morph="none" start_char="2794" end_char="2795">of</TOKEN>
<TOKEN id="token-21-50" pos="word" morph="none" start_char="2797" end_char="2797">a</TOKEN>
<TOKEN id="token-21-51" pos="word" morph="none" start_char="2799" end_char="2800">an</TOKEN>
<TOKEN id="token-21-52" pos="word" morph="none" start_char="2802" end_char="2810">important</TOKEN>
<TOKEN id="token-21-53" pos="word" morph="none" start_char="2812" end_char="2824">communication</TOKEN>
<TOKEN id="token-21-54" pos="word" morph="none" start_char="2826" end_char="2831">agency</TOKEN>
<TOKEN id="token-21-55" pos="word" morph="none" start_char="2833" end_char="2842">accustomed</TOKEN>
<TOKEN id="token-21-56" pos="word" morph="none" start_char="2844" end_char="2845">to</TOKEN>
<TOKEN id="token-21-57" pos="word" morph="none" start_char="2847" end_char="2857">interacting</TOKEN>
<TOKEN id="token-21-58" pos="word" morph="none" start_char="2859" end_char="2862">with</TOKEN>
<TOKEN id="token-21-59" pos="word" morph="none" start_char="2864" end_char="2866">the</TOKEN>
<TOKEN id="token-21-60" pos="word" morph="none" start_char="2868" end_char="2873">public</TOKEN>
<TOKEN id="token-21-61" pos="word" morph="none" start_char="2875" end_char="2888">administration</TOKEN>
<TOKEN id="token-21-62" pos="punct" morph="none" start_char="2889" end_char="2889">,</TOKEN>
<TOKEN id="token-21-63" pos="word" morph="none" start_char="2891" end_char="2892">we</TOKEN>
<TOKEN id="token-21-64" pos="word" morph="none" start_char="2894" end_char="2898">would</TOKEN>
<TOKEN id="token-21-65" pos="word" morph="none" start_char="2900" end_char="2902">all</TOKEN>
<TOKEN id="token-21-66" pos="word" morph="none" start_char="2904" end_char="2906">set</TOKEN>
<TOKEN id="token-21-67" pos="word" morph="none" start_char="2908" end_char="2910">out</TOKEN>
<TOKEN id="token-21-68" pos="word" morph="none" start_char="2912" end_char="2913">on</TOKEN>
<TOKEN id="token-21-69" pos="word" morph="none" start_char="2915" end_char="2917">the</TOKEN>
<TOKEN id="token-21-70" pos="word" morph="none" start_char="2919" end_char="2922">road</TOKEN>
<TOKEN id="token-21-71" pos="word" morph="none" start_char="2924" end_char="2925">to</TOKEN>
<TOKEN id="token-21-72" pos="word" morph="none" start_char="2927" end_char="2929">the</TOKEN>
<TOKEN id="token-21-73" pos="word" morph="none" start_char="2931" end_char="2937">Spanish</TOKEN>
<TOKEN id="token-21-74" pos="word" morph="none" start_char="2939" end_char="2946">Ministry</TOKEN>
<TOKEN id="token-21-75" pos="word" morph="none" start_char="2948" end_char="2949">of</TOKEN>
<TOKEN id="token-21-76" pos="word" morph="none" start_char="2951" end_char="2956">Health</TOKEN>
<TOKEN id="token-21-77" pos="punct" morph="none" start_char="2957" end_char="2957">…</TOKEN>
<TOKEN id="token-21-78" pos="word" morph="none" start_char="2959" end_char="2962">just</TOKEN>
<TOKEN id="token-21-79" pos="word" morph="none" start_char="2964" end_char="2965">as</TOKEN>
<TOKEN id="token-21-80" pos="word" morph="none" start_char="2967" end_char="2973">Dorothy</TOKEN>
<TOKEN id="token-21-81" pos="word" morph="none" start_char="2975" end_char="2977">did</TOKEN>
<TOKEN id="token-21-82" pos="word" morph="none" start_char="2979" end_char="2982">when</TOKEN>
<TOKEN id="token-21-83" pos="word" morph="none" start_char="2984" end_char="2986">she</TOKEN>
<TOKEN id="token-21-84" pos="word" morph="none" start_char="2988" end_char="2994">decided</TOKEN>
<TOKEN id="token-21-85" pos="word" morph="none" start_char="2996" end_char="2997">to</TOKEN>
<TOKEN id="token-21-86" pos="word" morph="none" start_char="2999" end_char="3004">follow</TOKEN>
<TOKEN id="token-21-87" pos="word" morph="none" start_char="3006" end_char="3008">the</TOKEN>
<TOKEN id="token-21-88" pos="word" morph="none" start_char="3010" end_char="3015">yellow</TOKEN>
<TOKEN id="token-21-89" pos="word" morph="none" start_char="3017" end_char="3021">brick</TOKEN>
<TOKEN id="token-21-90" pos="word" morph="none" start_char="3023" end_char="3026">road</TOKEN>
<TOKEN id="token-21-91" pos="word" morph="none" start_char="3028" end_char="3031">that</TOKEN>
<TOKEN id="token-21-92" pos="word" morph="none" start_char="3033" end_char="3037">would</TOKEN>
<TOKEN id="token-21-93" pos="word" morph="none" start_char="3039" end_char="3042">take</TOKEN>
<TOKEN id="token-21-94" pos="word" morph="none" start_char="3044" end_char="3046">her</TOKEN>
<TOKEN id="token-21-95" pos="word" morph="none" start_char="3048" end_char="3049">to</TOKEN>
<TOKEN id="token-21-96" pos="word" morph="none" start_char="3051" end_char="3052">Oz</TOKEN>
<TOKEN id="token-21-97" pos="punct" morph="none" start_char="3053" end_char="3053">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="3055" end_char="3229">
<ORIGINAL_TEXT>Our objective was clear: to obtain a clear and unequivocal statement, from the Spanish Ministry of Health, in favor of the use of hand dryers, even during times in a pandemic.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="3055" end_char="3057">Our</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="3059" end_char="3067">objective</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="3069" end_char="3071">was</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="3073" end_char="3077">clear</TOKEN>
<TOKEN id="token-22-4" pos="punct" morph="none" start_char="3078" end_char="3078">:</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="3080" end_char="3081">to</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="3083" end_char="3088">obtain</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="3090" end_char="3090">a</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="3092" end_char="3096">clear</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="3098" end_char="3100">and</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="3102" end_char="3112">unequivocal</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="3114" end_char="3122">statement</TOKEN>
<TOKEN id="token-22-12" pos="punct" morph="none" start_char="3123" end_char="3123">,</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="3125" end_char="3128">from</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="3130" end_char="3132">the</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="3134" end_char="3140">Spanish</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="3142" end_char="3149">Ministry</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="3151" end_char="3152">of</TOKEN>
<TOKEN id="token-22-18" pos="word" morph="none" start_char="3154" end_char="3159">Health</TOKEN>
<TOKEN id="token-22-19" pos="punct" morph="none" start_char="3160" end_char="3160">,</TOKEN>
<TOKEN id="token-22-20" pos="word" morph="none" start_char="3162" end_char="3163">in</TOKEN>
<TOKEN id="token-22-21" pos="word" morph="none" start_char="3165" end_char="3169">favor</TOKEN>
<TOKEN id="token-22-22" pos="word" morph="none" start_char="3171" end_char="3172">of</TOKEN>
<TOKEN id="token-22-23" pos="word" morph="none" start_char="3174" end_char="3176">the</TOKEN>
<TOKEN id="token-22-24" pos="word" morph="none" start_char="3178" end_char="3180">use</TOKEN>
<TOKEN id="token-22-25" pos="word" morph="none" start_char="3182" end_char="3183">of</TOKEN>
<TOKEN id="token-22-26" pos="word" morph="none" start_char="3185" end_char="3188">hand</TOKEN>
<TOKEN id="token-22-27" pos="word" morph="none" start_char="3190" end_char="3195">dryers</TOKEN>
<TOKEN id="token-22-28" pos="punct" morph="none" start_char="3196" end_char="3196">,</TOKEN>
<TOKEN id="token-22-29" pos="word" morph="none" start_char="3198" end_char="3201">even</TOKEN>
<TOKEN id="token-22-30" pos="word" morph="none" start_char="3203" end_char="3208">during</TOKEN>
<TOKEN id="token-22-31" pos="word" morph="none" start_char="3210" end_char="3214">times</TOKEN>
<TOKEN id="token-22-32" pos="word" morph="none" start_char="3216" end_char="3217">in</TOKEN>
<TOKEN id="token-22-33" pos="word" morph="none" start_char="3219" end_char="3219">a</TOKEN>
<TOKEN id="token-22-34" pos="word" morph="none" start_char="3221" end_char="3228">pandemic</TOKEN>
<TOKEN id="token-22-35" pos="punct" morph="none" start_char="3229" end_char="3229">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="3232" end_char="3294">
<ORIGINAL_TEXT>We did not go to the secretariat of this Ministry empty-handed.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="3232" end_char="3233">We</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="3235" end_char="3237">did</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="3239" end_char="3241">not</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="3243" end_char="3244">go</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="3246" end_char="3247">to</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="3249" end_char="3251">the</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="3253" end_char="3263">secretariat</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="3265" end_char="3266">of</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="3268" end_char="3271">this</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="3273" end_char="3280">Ministry</TOKEN>
<TOKEN id="token-23-10" pos="unknown" morph="none" start_char="3282" end_char="3293">empty-handed</TOKEN>
<TOKEN id="token-23-11" pos="punct" morph="none" start_char="3294" end_char="3294">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="3296" end_char="3563">
<ORIGINAL_TEXT>Prior to the meetings we held with them, we compiled a whole dossier with reliable and trustworthy technical and scientific information that argued in favor of the use of electric hand dryers as an effective, safe and reliable method to dry hands in a public restroom.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="3296" end_char="3300">Prior</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="3302" end_char="3303">to</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="3305" end_char="3307">the</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="3309" end_char="3316">meetings</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="3318" end_char="3319">we</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="3321" end_char="3324">held</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="3326" end_char="3329">with</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="3331" end_char="3334">them</TOKEN>
<TOKEN id="token-24-8" pos="punct" morph="none" start_char="3335" end_char="3335">,</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="3337" end_char="3338">we</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="3340" end_char="3347">compiled</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="3349" end_char="3349">a</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="3351" end_char="3355">whole</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="3357" end_char="3363">dossier</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="3365" end_char="3368">with</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="3370" end_char="3377">reliable</TOKEN>
<TOKEN id="token-24-16" pos="word" morph="none" start_char="3379" end_char="3381">and</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="3383" end_char="3393">trustworthy</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="3395" end_char="3403">technical</TOKEN>
<TOKEN id="token-24-19" pos="word" morph="none" start_char="3405" end_char="3407">and</TOKEN>
<TOKEN id="token-24-20" pos="word" morph="none" start_char="3409" end_char="3418">scientific</TOKEN>
<TOKEN id="token-24-21" pos="word" morph="none" start_char="3420" end_char="3430">information</TOKEN>
<TOKEN id="token-24-22" pos="word" morph="none" start_char="3432" end_char="3435">that</TOKEN>
<TOKEN id="token-24-23" pos="word" morph="none" start_char="3437" end_char="3442">argued</TOKEN>
<TOKEN id="token-24-24" pos="word" morph="none" start_char="3444" end_char="3445">in</TOKEN>
<TOKEN id="token-24-25" pos="word" morph="none" start_char="3447" end_char="3451">favor</TOKEN>
<TOKEN id="token-24-26" pos="word" morph="none" start_char="3453" end_char="3454">of</TOKEN>
<TOKEN id="token-24-27" pos="word" morph="none" start_char="3456" end_char="3458">the</TOKEN>
<TOKEN id="token-24-28" pos="word" morph="none" start_char="3460" end_char="3462">use</TOKEN>
<TOKEN id="token-24-29" pos="word" morph="none" start_char="3464" end_char="3465">of</TOKEN>
<TOKEN id="token-24-30" pos="word" morph="none" start_char="3467" end_char="3474">electric</TOKEN>
<TOKEN id="token-24-31" pos="word" morph="none" start_char="3476" end_char="3479">hand</TOKEN>
<TOKEN id="token-24-32" pos="word" morph="none" start_char="3481" end_char="3486">dryers</TOKEN>
<TOKEN id="token-24-33" pos="word" morph="none" start_char="3488" end_char="3489">as</TOKEN>
<TOKEN id="token-24-34" pos="word" morph="none" start_char="3491" end_char="3492">an</TOKEN>
<TOKEN id="token-24-35" pos="word" morph="none" start_char="3494" end_char="3502">effective</TOKEN>
<TOKEN id="token-24-36" pos="punct" morph="none" start_char="3503" end_char="3503">,</TOKEN>
<TOKEN id="token-24-37" pos="word" morph="none" start_char="3505" end_char="3508">safe</TOKEN>
<TOKEN id="token-24-38" pos="word" morph="none" start_char="3510" end_char="3512">and</TOKEN>
<TOKEN id="token-24-39" pos="word" morph="none" start_char="3514" end_char="3521">reliable</TOKEN>
<TOKEN id="token-24-40" pos="word" morph="none" start_char="3523" end_char="3528">method</TOKEN>
<TOKEN id="token-24-41" pos="word" morph="none" start_char="3530" end_char="3531">to</TOKEN>
<TOKEN id="token-24-42" pos="word" morph="none" start_char="3533" end_char="3535">dry</TOKEN>
<TOKEN id="token-24-43" pos="word" morph="none" start_char="3537" end_char="3541">hands</TOKEN>
<TOKEN id="token-24-44" pos="word" morph="none" start_char="3543" end_char="3544">in</TOKEN>
<TOKEN id="token-24-45" pos="word" morph="none" start_char="3546" end_char="3546">a</TOKEN>
<TOKEN id="token-24-46" pos="word" morph="none" start_char="3548" end_char="3553">public</TOKEN>
<TOKEN id="token-24-47" pos="word" morph="none" start_char="3555" end_char="3562">restroom</TOKEN>
<TOKEN id="token-24-48" pos="punct" morph="none" start_char="3563" end_char="3563">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="3565" end_char="3779">
<ORIGINAL_TEXT>Reliable information that I would now like to share with you so that you can see that commercial hand dryers are not a danger to human health, but quite the opposite, since they help to maintain better hand hygiene.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="3565" end_char="3572">Reliable</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="3574" end_char="3584">information</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="3586" end_char="3589">that</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="3591" end_char="3591">I</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="3593" end_char="3597">would</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="3599" end_char="3601">now</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="3603" end_char="3606">like</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="3608" end_char="3609">to</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="3611" end_char="3615">share</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="3617" end_char="3620">with</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="3622" end_char="3624">you</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="3626" end_char="3627">so</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="3629" end_char="3632">that</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="3634" end_char="3636">you</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="3638" end_char="3640">can</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="3642" end_char="3644">see</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="3646" end_char="3649">that</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="3651" end_char="3660">commercial</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="3662" end_char="3665">hand</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="3667" end_char="3672">dryers</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="3674" end_char="3676">are</TOKEN>
<TOKEN id="token-25-21" pos="word" morph="none" start_char="3678" end_char="3680">not</TOKEN>
<TOKEN id="token-25-22" pos="word" morph="none" start_char="3682" end_char="3682">a</TOKEN>
<TOKEN id="token-25-23" pos="word" morph="none" start_char="3684" end_char="3689">danger</TOKEN>
<TOKEN id="token-25-24" pos="word" morph="none" start_char="3691" end_char="3692">to</TOKEN>
<TOKEN id="token-25-25" pos="word" morph="none" start_char="3694" end_char="3698">human</TOKEN>
<TOKEN id="token-25-26" pos="word" morph="none" start_char="3700" end_char="3705">health</TOKEN>
<TOKEN id="token-25-27" pos="punct" morph="none" start_char="3706" end_char="3706">,</TOKEN>
<TOKEN id="token-25-28" pos="word" morph="none" start_char="3708" end_char="3710">but</TOKEN>
<TOKEN id="token-25-29" pos="word" morph="none" start_char="3712" end_char="3716">quite</TOKEN>
<TOKEN id="token-25-30" pos="word" morph="none" start_char="3718" end_char="3720">the</TOKEN>
<TOKEN id="token-25-31" pos="word" morph="none" start_char="3722" end_char="3729">opposite</TOKEN>
<TOKEN id="token-25-32" pos="punct" morph="none" start_char="3730" end_char="3730">,</TOKEN>
<TOKEN id="token-25-33" pos="word" morph="none" start_char="3732" end_char="3736">since</TOKEN>
<TOKEN id="token-25-34" pos="word" morph="none" start_char="3738" end_char="3741">they</TOKEN>
<TOKEN id="token-25-35" pos="word" morph="none" start_char="3743" end_char="3746">help</TOKEN>
<TOKEN id="token-25-36" pos="word" morph="none" start_char="3748" end_char="3749">to</TOKEN>
<TOKEN id="token-25-37" pos="word" morph="none" start_char="3751" end_char="3758">maintain</TOKEN>
<TOKEN id="token-25-38" pos="word" morph="none" start_char="3760" end_char="3765">better</TOKEN>
<TOKEN id="token-25-39" pos="word" morph="none" start_char="3767" end_char="3770">hand</TOKEN>
<TOKEN id="token-25-40" pos="word" morph="none" start_char="3772" end_char="3778">hygiene</TOKEN>
<TOKEN id="token-25-41" pos="punct" morph="none" start_char="3779" end_char="3779">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="3782" end_char="3826">
<ORIGINAL_TEXT>Science and technology help us fight Covid-19</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="3782" end_char="3788">Science</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="3790" end_char="3792">and</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="3794" end_char="3803">technology</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="3805" end_char="3808">help</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="3810" end_char="3811">us</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="3813" end_char="3817">fight</TOKEN>
<TOKEN id="token-26-6" pos="unknown" morph="none" start_char="3819" end_char="3826">Covid-19</TOKEN>
</SEG>
<SEG id="segment-27" start_char="3829" end_char="3901">
<ORIGINAL_TEXT>Most of the latest generation hand dryers are equipped with HEPA filters.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="3829" end_char="3832">Most</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="3834" end_char="3835">of</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="3837" end_char="3839">the</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="3841" end_char="3846">latest</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="3848" end_char="3857">generation</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="3859" end_char="3862">hand</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="3864" end_char="3869">dryers</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="3871" end_char="3873">are</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="3875" end_char="3882">equipped</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="3884" end_char="3887">with</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="3889" end_char="3892">HEPA</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="3894" end_char="3900">filters</TOKEN>
<TOKEN id="token-27-12" pos="punct" morph="none" start_char="3901" end_char="3901">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3903" end_char="4166">
<ORIGINAL_TEXT>A HEPA air filter media (High Efficiency Particulate Air) is a mechanical filter that retains most of the particles harmful to human health contained in the air including viruses, bacteria, mold spores, dust, dust mites, pet dander, and other irritating allergens.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="3903" end_char="3903">A</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="3905" end_char="3908">HEPA</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="3910" end_char="3912">air</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="3914" end_char="3919">filter</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="3921" end_char="3925">media</TOKEN>
<TOKEN id="token-28-5" pos="punct" morph="none" start_char="3927" end_char="3927">(</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="3928" end_char="3931">High</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="3933" end_char="3942">Efficiency</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="3944" end_char="3954">Particulate</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="3956" end_char="3958">Air</TOKEN>
<TOKEN id="token-28-10" pos="punct" morph="none" start_char="3959" end_char="3959">)</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="3961" end_char="3962">is</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="3964" end_char="3964">a</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="3966" end_char="3975">mechanical</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="3977" end_char="3982">filter</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="3984" end_char="3987">that</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="3989" end_char="3995">retains</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="3997" end_char="4000">most</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="4002" end_char="4003">of</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="4005" end_char="4007">the</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="4009" end_char="4017">particles</TOKEN>
<TOKEN id="token-28-21" pos="word" morph="none" start_char="4019" end_char="4025">harmful</TOKEN>
<TOKEN id="token-28-22" pos="word" morph="none" start_char="4027" end_char="4028">to</TOKEN>
<TOKEN id="token-28-23" pos="word" morph="none" start_char="4030" end_char="4034">human</TOKEN>
<TOKEN id="token-28-24" pos="word" morph="none" start_char="4036" end_char="4041">health</TOKEN>
<TOKEN id="token-28-25" pos="word" morph="none" start_char="4043" end_char="4051">contained</TOKEN>
<TOKEN id="token-28-26" pos="word" morph="none" start_char="4053" end_char="4054">in</TOKEN>
<TOKEN id="token-28-27" pos="word" morph="none" start_char="4056" end_char="4058">the</TOKEN>
<TOKEN id="token-28-28" pos="word" morph="none" start_char="4060" end_char="4062">air</TOKEN>
<TOKEN id="token-28-29" pos="word" morph="none" start_char="4064" end_char="4072">including</TOKEN>
<TOKEN id="token-28-30" pos="word" morph="none" start_char="4074" end_char="4080">viruses</TOKEN>
<TOKEN id="token-28-31" pos="punct" morph="none" start_char="4081" end_char="4081">,</TOKEN>
<TOKEN id="token-28-32" pos="word" morph="none" start_char="4083" end_char="4090">bacteria</TOKEN>
<TOKEN id="token-28-33" pos="punct" morph="none" start_char="4091" end_char="4091">,</TOKEN>
<TOKEN id="token-28-34" pos="word" morph="none" start_char="4093" end_char="4096">mold</TOKEN>
<TOKEN id="token-28-35" pos="word" morph="none" start_char="4098" end_char="4103">spores</TOKEN>
<TOKEN id="token-28-36" pos="punct" morph="none" start_char="4104" end_char="4104">,</TOKEN>
<TOKEN id="token-28-37" pos="word" morph="none" start_char="4106" end_char="4109">dust</TOKEN>
<TOKEN id="token-28-38" pos="punct" morph="none" start_char="4110" end_char="4110">,</TOKEN>
<TOKEN id="token-28-39" pos="word" morph="none" start_char="4112" end_char="4115">dust</TOKEN>
<TOKEN id="token-28-40" pos="word" morph="none" start_char="4117" end_char="4121">mites</TOKEN>
<TOKEN id="token-28-41" pos="punct" morph="none" start_char="4122" end_char="4122">,</TOKEN>
<TOKEN id="token-28-42" pos="word" morph="none" start_char="4124" end_char="4126">pet</TOKEN>
<TOKEN id="token-28-43" pos="word" morph="none" start_char="4128" end_char="4133">dander</TOKEN>
<TOKEN id="token-28-44" pos="punct" morph="none" start_char="4134" end_char="4134">,</TOKEN>
<TOKEN id="token-28-45" pos="word" morph="none" start_char="4136" end_char="4138">and</TOKEN>
<TOKEN id="token-28-46" pos="word" morph="none" start_char="4140" end_char="4144">other</TOKEN>
<TOKEN id="token-28-47" pos="word" morph="none" start_char="4146" end_char="4155">irritating</TOKEN>
<TOKEN id="token-28-48" pos="word" morph="none" start_char="4157" end_char="4165">allergens</TOKEN>
<TOKEN id="token-28-49" pos="punct" morph="none" start_char="4166" end_char="4166">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="4168" end_char="4302">
<ORIGINAL_TEXT>Using this type of filter makes it so that the air with which we dry our hands is clean of impurities, particles, viruses and bacteria.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="4168" end_char="4172">Using</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="4174" end_char="4177">this</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="4179" end_char="4182">type</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="4184" end_char="4185">of</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="4187" end_char="4192">filter</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="4194" end_char="4198">makes</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="4200" end_char="4201">it</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="4203" end_char="4204">so</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="4206" end_char="4209">that</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="4211" end_char="4213">the</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="4215" end_char="4217">air</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="4219" end_char="4222">with</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="4224" end_char="4228">which</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="4230" end_char="4231">we</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="4233" end_char="4235">dry</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="4237" end_char="4239">our</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="4241" end_char="4245">hands</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="4247" end_char="4248">is</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="4250" end_char="4254">clean</TOKEN>
<TOKEN id="token-29-19" pos="word" morph="none" start_char="4256" end_char="4257">of</TOKEN>
<TOKEN id="token-29-20" pos="word" morph="none" start_char="4259" end_char="4268">impurities</TOKEN>
<TOKEN id="token-29-21" pos="punct" morph="none" start_char="4269" end_char="4269">,</TOKEN>
<TOKEN id="token-29-22" pos="word" morph="none" start_char="4271" end_char="4279">particles</TOKEN>
<TOKEN id="token-29-23" pos="punct" morph="none" start_char="4280" end_char="4280">,</TOKEN>
<TOKEN id="token-29-24" pos="word" morph="none" start_char="4282" end_char="4288">viruses</TOKEN>
<TOKEN id="token-29-25" pos="word" morph="none" start_char="4290" end_char="4292">and</TOKEN>
<TOKEN id="token-29-26" pos="word" morph="none" start_char="4294" end_char="4301">bacteria</TOKEN>
<TOKEN id="token-29-27" pos="punct" morph="none" start_char="4302" end_char="4302">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="4305" end_char="4434">
<ORIGINAL_TEXT>In addition to HEPA filters, electric hand dryers can incorporate other technologies that further enhance hygiene on washed hands.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="4305" end_char="4306">In</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="4308" end_char="4315">addition</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="4317" end_char="4318">to</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="4320" end_char="4323">HEPA</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="4325" end_char="4331">filters</TOKEN>
<TOKEN id="token-30-5" pos="punct" morph="none" start_char="4332" end_char="4332">,</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="4334" end_char="4341">electric</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="4343" end_char="4346">hand</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="4348" end_char="4353">dryers</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="4355" end_char="4357">can</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="4359" end_char="4369">incorporate</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="4371" end_char="4375">other</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="4377" end_char="4388">technologies</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="4390" end_char="4393">that</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="4395" end_char="4401">further</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="4403" end_char="4409">enhance</TOKEN>
<TOKEN id="token-30-16" pos="word" morph="none" start_char="4411" end_char="4417">hygiene</TOKEN>
<TOKEN id="token-30-17" pos="word" morph="none" start_char="4419" end_char="4420">on</TOKEN>
<TOKEN id="token-30-18" pos="word" morph="none" start_char="4422" end_char="4427">washed</TOKEN>
<TOKEN id="token-30-19" pos="word" morph="none" start_char="4429" end_char="4433">hands</TOKEN>
<TOKEN id="token-30-20" pos="punct" morph="none" start_char="4434" end_char="4434">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="4436" end_char="4671">
<ORIGINAL_TEXT>For example, we’re talking about the antibacterial additives that inhibit the growth of viruses and bacteria on the surfaces of the unit or ionizers that, through negatively charged particles, also aid in cleaning and purifying the air.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="4436" end_char="4438">For</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="4440" end_char="4446">example</TOKEN>
<TOKEN id="token-31-2" pos="punct" morph="none" start_char="4447" end_char="4447">,</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="4449" end_char="4453">we’re</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="4455" end_char="4461">talking</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="4463" end_char="4467">about</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="4469" end_char="4471">the</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="4473" end_char="4485">antibacterial</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="4487" end_char="4495">additives</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="4497" end_char="4500">that</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="4502" end_char="4508">inhibit</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="4510" end_char="4512">the</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="4514" end_char="4519">growth</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="4521" end_char="4522">of</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="4524" end_char="4530">viruses</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="4532" end_char="4534">and</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="4536" end_char="4543">bacteria</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="4545" end_char="4546">on</TOKEN>
<TOKEN id="token-31-18" pos="word" morph="none" start_char="4548" end_char="4550">the</TOKEN>
<TOKEN id="token-31-19" pos="word" morph="none" start_char="4552" end_char="4559">surfaces</TOKEN>
<TOKEN id="token-31-20" pos="word" morph="none" start_char="4561" end_char="4562">of</TOKEN>
<TOKEN id="token-31-21" pos="word" morph="none" start_char="4564" end_char="4566">the</TOKEN>
<TOKEN id="token-31-22" pos="word" morph="none" start_char="4568" end_char="4571">unit</TOKEN>
<TOKEN id="token-31-23" pos="word" morph="none" start_char="4573" end_char="4574">or</TOKEN>
<TOKEN id="token-31-24" pos="word" morph="none" start_char="4576" end_char="4583">ionizers</TOKEN>
<TOKEN id="token-31-25" pos="word" morph="none" start_char="4585" end_char="4588">that</TOKEN>
<TOKEN id="token-31-26" pos="punct" morph="none" start_char="4589" end_char="4589">,</TOKEN>
<TOKEN id="token-31-27" pos="word" morph="none" start_char="4591" end_char="4597">through</TOKEN>
<TOKEN id="token-31-28" pos="word" morph="none" start_char="4599" end_char="4608">negatively</TOKEN>
<TOKEN id="token-31-29" pos="word" morph="none" start_char="4610" end_char="4616">charged</TOKEN>
<TOKEN id="token-31-30" pos="word" morph="none" start_char="4618" end_char="4626">particles</TOKEN>
<TOKEN id="token-31-31" pos="punct" morph="none" start_char="4627" end_char="4627">,</TOKEN>
<TOKEN id="token-31-32" pos="word" morph="none" start_char="4629" end_char="4632">also</TOKEN>
<TOKEN id="token-31-33" pos="word" morph="none" start_char="4634" end_char="4636">aid</TOKEN>
<TOKEN id="token-31-34" pos="word" morph="none" start_char="4638" end_char="4639">in</TOKEN>
<TOKEN id="token-31-35" pos="word" morph="none" start_char="4641" end_char="4648">cleaning</TOKEN>
<TOKEN id="token-31-36" pos="word" morph="none" start_char="4650" end_char="4652">and</TOKEN>
<TOKEN id="token-31-37" pos="word" morph="none" start_char="4654" end_char="4662">purifying</TOKEN>
<TOKEN id="token-31-38" pos="word" morph="none" start_char="4664" end_char="4666">the</TOKEN>
<TOKEN id="token-31-39" pos="word" morph="none" start_char="4668" end_char="4670">air</TOKEN>
<TOKEN id="token-31-40" pos="punct" morph="none" start_char="4671" end_char="4671">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="4674" end_char="4898">
<ORIGINAL_TEXT>Another significant technical aspect, which also helps to mitigate the contagion of contact diseases, is the fact that currently most hand dryers are sensor-operated: users don’t need to touch the unit at any time during use.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="4674" end_char="4680">Another</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="4682" end_char="4692">significant</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="4694" end_char="4702">technical</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="4704" end_char="4709">aspect</TOKEN>
<TOKEN id="token-32-4" pos="punct" morph="none" start_char="4710" end_char="4710">,</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="4712" end_char="4716">which</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="4718" end_char="4721">also</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="4723" end_char="4727">helps</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="4729" end_char="4730">to</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="4732" end_char="4739">mitigate</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="4741" end_char="4743">the</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="4745" end_char="4753">contagion</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="4755" end_char="4756">of</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="4758" end_char="4764">contact</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="4766" end_char="4773">diseases</TOKEN>
<TOKEN id="token-32-15" pos="punct" morph="none" start_char="4774" end_char="4774">,</TOKEN>
<TOKEN id="token-32-16" pos="word" morph="none" start_char="4776" end_char="4777">is</TOKEN>
<TOKEN id="token-32-17" pos="word" morph="none" start_char="4779" end_char="4781">the</TOKEN>
<TOKEN id="token-32-18" pos="word" morph="none" start_char="4783" end_char="4786">fact</TOKEN>
<TOKEN id="token-32-19" pos="word" morph="none" start_char="4788" end_char="4791">that</TOKEN>
<TOKEN id="token-32-20" pos="word" morph="none" start_char="4793" end_char="4801">currently</TOKEN>
<TOKEN id="token-32-21" pos="word" morph="none" start_char="4803" end_char="4806">most</TOKEN>
<TOKEN id="token-32-22" pos="word" morph="none" start_char="4808" end_char="4811">hand</TOKEN>
<TOKEN id="token-32-23" pos="word" morph="none" start_char="4813" end_char="4818">dryers</TOKEN>
<TOKEN id="token-32-24" pos="word" morph="none" start_char="4820" end_char="4822">are</TOKEN>
<TOKEN id="token-32-25" pos="unknown" morph="none" start_char="4824" end_char="4838">sensor-operated</TOKEN>
<TOKEN id="token-32-26" pos="punct" morph="none" start_char="4839" end_char="4839">:</TOKEN>
<TOKEN id="token-32-27" pos="word" morph="none" start_char="4841" end_char="4845">users</TOKEN>
<TOKEN id="token-32-28" pos="word" morph="none" start_char="4847" end_char="4851">don’t</TOKEN>
<TOKEN id="token-32-29" pos="word" morph="none" start_char="4853" end_char="4856">need</TOKEN>
<TOKEN id="token-32-30" pos="word" morph="none" start_char="4858" end_char="4859">to</TOKEN>
<TOKEN id="token-32-31" pos="word" morph="none" start_char="4861" end_char="4865">touch</TOKEN>
<TOKEN id="token-32-32" pos="word" morph="none" start_char="4867" end_char="4869">the</TOKEN>
<TOKEN id="token-32-33" pos="word" morph="none" start_char="4871" end_char="4874">unit</TOKEN>
<TOKEN id="token-32-34" pos="word" morph="none" start_char="4876" end_char="4877">at</TOKEN>
<TOKEN id="token-32-35" pos="word" morph="none" start_char="4879" end_char="4881">any</TOKEN>
<TOKEN id="token-32-36" pos="word" morph="none" start_char="4883" end_char="4886">time</TOKEN>
<TOKEN id="token-32-37" pos="word" morph="none" start_char="4888" end_char="4893">during</TOKEN>
<TOKEN id="token-32-38" pos="word" morph="none" start_char="4895" end_char="4897">use</TOKEN>
<TOKEN id="token-32-39" pos="punct" morph="none" start_char="4898" end_char="4898">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="4900" end_char="4991">
<ORIGINAL_TEXT>This "touchless technology" helps prevent the spread of disease through cross-contamination.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="4900" end_char="4903">This</TOKEN>
<TOKEN id="token-33-1" pos="punct" morph="none" start_char="4905" end_char="4905">"</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="4906" end_char="4914">touchless</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="4916" end_char="4925">technology</TOKEN>
<TOKEN id="token-33-4" pos="punct" morph="none" start_char="4926" end_char="4926">"</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="4928" end_char="4932">helps</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="4934" end_char="4940">prevent</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="4942" end_char="4944">the</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="4946" end_char="4951">spread</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="4953" end_char="4954">of</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="4956" end_char="4962">disease</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="4964" end_char="4970">through</TOKEN>
<TOKEN id="token-33-12" pos="unknown" morph="none" start_char="4972" end_char="4990">cross-contamination</TOKEN>
<TOKEN id="token-33-13" pos="punct" morph="none" start_char="4991" end_char="4991">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="4994" end_char="5115">
<ORIGINAL_TEXT>You can clearly see that technology is on our side and helps us make our electric hand dryers 100% hygienic and 100% safe.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="4994" end_char="4996">You</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="4998" end_char="5000">can</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="5002" end_char="5008">clearly</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="5010" end_char="5012">see</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="5014" end_char="5017">that</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="5019" end_char="5028">technology</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="5030" end_char="5031">is</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="5033" end_char="5034">on</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="5036" end_char="5038">our</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="5040" end_char="5043">side</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="5045" end_char="5047">and</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="5049" end_char="5053">helps</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="5055" end_char="5056">us</TOKEN>
<TOKEN id="token-34-13" pos="word" morph="none" start_char="5058" end_char="5061">make</TOKEN>
<TOKEN id="token-34-14" pos="word" morph="none" start_char="5063" end_char="5065">our</TOKEN>
<TOKEN id="token-34-15" pos="word" morph="none" start_char="5067" end_char="5074">electric</TOKEN>
<TOKEN id="token-34-16" pos="word" morph="none" start_char="5076" end_char="5079">hand</TOKEN>
<TOKEN id="token-34-17" pos="word" morph="none" start_char="5081" end_char="5086">dryers</TOKEN>
<TOKEN id="token-34-18" pos="word" morph="none" start_char="5088" end_char="5090">100</TOKEN>
<TOKEN id="token-34-19" pos="punct" morph="none" start_char="5091" end_char="5091">%</TOKEN>
<TOKEN id="token-34-20" pos="word" morph="none" start_char="5093" end_char="5100">hygienic</TOKEN>
<TOKEN id="token-34-21" pos="word" morph="none" start_char="5102" end_char="5104">and</TOKEN>
<TOKEN id="token-34-22" pos="word" morph="none" start_char="5106" end_char="5108">100</TOKEN>
<TOKEN id="token-34-23" pos="punct" morph="none" start_char="5109" end_char="5109">%</TOKEN>
<TOKEN id="token-34-24" pos="word" morph="none" start_char="5111" end_char="5114">safe</TOKEN>
<TOKEN id="token-34-25" pos="punct" morph="none" start_char="5115" end_char="5115">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="5118" end_char="5187">
<ORIGINAL_TEXT>What criteria does the World Health Organization set for hand hygiene?</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="5118" end_char="5121">What</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="5123" end_char="5130">criteria</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="5132" end_char="5135">does</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="5137" end_char="5139">the</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="5141" end_char="5145">World</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="5147" end_char="5152">Health</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="5154" end_char="5165">Organization</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="5167" end_char="5169">set</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="5171" end_char="5173">for</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="5175" end_char="5178">hand</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="5180" end_char="5186">hygiene</TOKEN>
<TOKEN id="token-35-11" pos="punct" morph="none" start_char="5187" end_char="5187">?</TOKEN>
</SEG>
<SEG id="segment-36" start_char="5190" end_char="5461">
<ORIGINAL_TEXT>Being aware that commercial hand dryers are totally safe and hygienic, the World Health Organization (WHO), within its guidelines on hand hygiene, recommends that washed hands are thoroughly and completely dried with the use of an electric hand dryer or with paper towels.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="5190" end_char="5194">Being</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="5196" end_char="5200">aware</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="5202" end_char="5205">that</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="5207" end_char="5216">commercial</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="5218" end_char="5221">hand</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="5223" end_char="5228">dryers</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="5230" end_char="5232">are</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="5234" end_char="5240">totally</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="5242" end_char="5245">safe</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="5247" end_char="5249">and</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="5251" end_char="5258">hygienic</TOKEN>
<TOKEN id="token-36-11" pos="punct" morph="none" start_char="5259" end_char="5259">,</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="5261" end_char="5263">the</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="5265" end_char="5269">World</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="5271" end_char="5276">Health</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="5278" end_char="5289">Organization</TOKEN>
<TOKEN id="token-36-16" pos="punct" morph="none" start_char="5291" end_char="5291">(</TOKEN>
<TOKEN id="token-36-17" pos="word" morph="none" start_char="5292" end_char="5294">WHO</TOKEN>
<TOKEN id="token-36-18" pos="punct" morph="none" start_char="5295" end_char="5296">),</TOKEN>
<TOKEN id="token-36-19" pos="word" morph="none" start_char="5298" end_char="5303">within</TOKEN>
<TOKEN id="token-36-20" pos="word" morph="none" start_char="5305" end_char="5307">its</TOKEN>
<TOKEN id="token-36-21" pos="word" morph="none" start_char="5309" end_char="5318">guidelines</TOKEN>
<TOKEN id="token-36-22" pos="word" morph="none" start_char="5320" end_char="5321">on</TOKEN>
<TOKEN id="token-36-23" pos="word" morph="none" start_char="5323" end_char="5326">hand</TOKEN>
<TOKEN id="token-36-24" pos="word" morph="none" start_char="5328" end_char="5334">hygiene</TOKEN>
<TOKEN id="token-36-25" pos="punct" morph="none" start_char="5335" end_char="5335">,</TOKEN>
<TOKEN id="token-36-26" pos="word" morph="none" start_char="5337" end_char="5346">recommends</TOKEN>
<TOKEN id="token-36-27" pos="word" morph="none" start_char="5348" end_char="5351">that</TOKEN>
<TOKEN id="token-36-28" pos="word" morph="none" start_char="5353" end_char="5358">washed</TOKEN>
<TOKEN id="token-36-29" pos="word" morph="none" start_char="5360" end_char="5364">hands</TOKEN>
<TOKEN id="token-36-30" pos="word" morph="none" start_char="5366" end_char="5368">are</TOKEN>
<TOKEN id="token-36-31" pos="word" morph="none" start_char="5370" end_char="5379">thoroughly</TOKEN>
<TOKEN id="token-36-32" pos="word" morph="none" start_char="5381" end_char="5383">and</TOKEN>
<TOKEN id="token-36-33" pos="word" morph="none" start_char="5385" end_char="5394">completely</TOKEN>
<TOKEN id="token-36-34" pos="word" morph="none" start_char="5396" end_char="5400">dried</TOKEN>
<TOKEN id="token-36-35" pos="word" morph="none" start_char="5402" end_char="5405">with</TOKEN>
<TOKEN id="token-36-36" pos="word" morph="none" start_char="5407" end_char="5409">the</TOKEN>
<TOKEN id="token-36-37" pos="word" morph="none" start_char="5411" end_char="5413">use</TOKEN>
<TOKEN id="token-36-38" pos="word" morph="none" start_char="5415" end_char="5416">of</TOKEN>
<TOKEN id="token-36-39" pos="word" morph="none" start_char="5418" end_char="5419">an</TOKEN>
<TOKEN id="token-36-40" pos="word" morph="none" start_char="5421" end_char="5428">electric</TOKEN>
<TOKEN id="token-36-41" pos="word" morph="none" start_char="5430" end_char="5433">hand</TOKEN>
<TOKEN id="token-36-42" pos="word" morph="none" start_char="5435" end_char="5439">dryer</TOKEN>
<TOKEN id="token-36-43" pos="word" morph="none" start_char="5441" end_char="5442">or</TOKEN>
<TOKEN id="token-36-44" pos="word" morph="none" start_char="5444" end_char="5447">with</TOKEN>
<TOKEN id="token-36-45" pos="word" morph="none" start_char="5449" end_char="5453">paper</TOKEN>
<TOKEN id="token-36-46" pos="word" morph="none" start_char="5455" end_char="5460">towels</TOKEN>
<TOKEN id="token-36-47" pos="punct" morph="none" start_char="5461" end_char="5461">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="5465" end_char="5667">
<ORIGINAL_TEXT>It is very significant and enlightening that a reassuring that an organization like the WHO, guarantor of human health worldwide, recommends the use of warm-air hand dryers in its hand hygiene protocols.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="5465" end_char="5466">It</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="5468" end_char="5469">is</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="5471" end_char="5474">very</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="5476" end_char="5486">significant</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="5488" end_char="5490">and</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="5492" end_char="5503">enlightening</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="5505" end_char="5508">that</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="5510" end_char="5510">a</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="5512" end_char="5521">reassuring</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="5523" end_char="5526">that</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="5528" end_char="5529">an</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="5531" end_char="5542">organization</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="5544" end_char="5547">like</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="5549" end_char="5551">the</TOKEN>
<TOKEN id="token-37-14" pos="word" morph="none" start_char="5553" end_char="5555">WHO</TOKEN>
<TOKEN id="token-37-15" pos="punct" morph="none" start_char="5556" end_char="5556">,</TOKEN>
<TOKEN id="token-37-16" pos="word" morph="none" start_char="5558" end_char="5566">guarantor</TOKEN>
<TOKEN id="token-37-17" pos="word" morph="none" start_char="5568" end_char="5569">of</TOKEN>
<TOKEN id="token-37-18" pos="word" morph="none" start_char="5571" end_char="5575">human</TOKEN>
<TOKEN id="token-37-19" pos="word" morph="none" start_char="5577" end_char="5582">health</TOKEN>
<TOKEN id="token-37-20" pos="word" morph="none" start_char="5584" end_char="5592">worldwide</TOKEN>
<TOKEN id="token-37-21" pos="punct" morph="none" start_char="5593" end_char="5593">,</TOKEN>
<TOKEN id="token-37-22" pos="word" morph="none" start_char="5595" end_char="5604">recommends</TOKEN>
<TOKEN id="token-37-23" pos="word" morph="none" start_char="5606" end_char="5608">the</TOKEN>
<TOKEN id="token-37-24" pos="word" morph="none" start_char="5610" end_char="5612">use</TOKEN>
<TOKEN id="token-37-25" pos="word" morph="none" start_char="5614" end_char="5615">of</TOKEN>
<TOKEN id="token-37-26" pos="unknown" morph="none" start_char="5617" end_char="5624">warm-air</TOKEN>
<TOKEN id="token-37-27" pos="word" morph="none" start_char="5626" end_char="5629">hand</TOKEN>
<TOKEN id="token-37-28" pos="word" morph="none" start_char="5631" end_char="5636">dryers</TOKEN>
<TOKEN id="token-37-29" pos="word" morph="none" start_char="5638" end_char="5639">in</TOKEN>
<TOKEN id="token-37-30" pos="word" morph="none" start_char="5641" end_char="5643">its</TOKEN>
<TOKEN id="token-37-31" pos="word" morph="none" start_char="5645" end_char="5648">hand</TOKEN>
<TOKEN id="token-37-32" pos="word" morph="none" start_char="5650" end_char="5656">hygiene</TOKEN>
<TOKEN id="token-37-33" pos="word" morph="none" start_char="5658" end_char="5666">protocols</TOKEN>
<TOKEN id="token-37-34" pos="punct" morph="none" start_char="5667" end_char="5667">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="5670" end_char="5743">
<ORIGINAL_TEXT>Johns Hopkins Hospital, the voice of a world leader in infectious diseases</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="5670" end_char="5674">Johns</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="5676" end_char="5682">Hopkins</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="5684" end_char="5691">Hospital</TOKEN>
<TOKEN id="token-38-3" pos="punct" morph="none" start_char="5692" end_char="5692">,</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="5694" end_char="5696">the</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="5698" end_char="5702">voice</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="5704" end_char="5705">of</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="5707" end_char="5707">a</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="5709" end_char="5713">world</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="5715" end_char="5720">leader</TOKEN>
<TOKEN id="token-38-10" pos="word" morph="none" start_char="5722" end_char="5723">in</TOKEN>
<TOKEN id="token-38-11" pos="word" morph="none" start_char="5725" end_char="5734">infectious</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="5736" end_char="5743">diseases</TOKEN>
</SEG>
<SEG id="segment-39" start_char="5746" end_char="5851">
<ORIGINAL_TEXT>Johns Hopkins Hospital in Baltimore, Maryland, is one of the world's most prestigious health care systems.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="5746" end_char="5750">Johns</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="5752" end_char="5758">Hopkins</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="5760" end_char="5767">Hospital</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="5769" end_char="5770">in</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="5772" end_char="5780">Baltimore</TOKEN>
<TOKEN id="token-39-5" pos="punct" morph="none" start_char="5781" end_char="5781">,</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="5783" end_char="5790">Maryland</TOKEN>
<TOKEN id="token-39-7" pos="punct" morph="none" start_char="5791" end_char="5791">,</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="5793" end_char="5794">is</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="5796" end_char="5798">one</TOKEN>
<TOKEN id="token-39-10" pos="word" morph="none" start_char="5800" end_char="5801">of</TOKEN>
<TOKEN id="token-39-11" pos="word" morph="none" start_char="5803" end_char="5805">the</TOKEN>
<TOKEN id="token-39-12" pos="word" morph="none" start_char="5807" end_char="5813">world's</TOKEN>
<TOKEN id="token-39-13" pos="word" morph="none" start_char="5815" end_char="5818">most</TOKEN>
<TOKEN id="token-39-14" pos="word" morph="none" start_char="5820" end_char="5830">prestigious</TOKEN>
<TOKEN id="token-39-15" pos="word" morph="none" start_char="5832" end_char="5837">health</TOKEN>
<TOKEN id="token-39-16" pos="word" morph="none" start_char="5839" end_char="5842">care</TOKEN>
<TOKEN id="token-39-17" pos="word" morph="none" start_char="5844" end_char="5850">systems</TOKEN>
<TOKEN id="token-39-18" pos="punct" morph="none" start_char="5851" end_char="5851">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="5853" end_char="5998">
<ORIGINAL_TEXT>It has experts in all fields of medicine working in a hospital setting that is equipped with advance cutting-edge treatments and medical sciences.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="5853" end_char="5854">It</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="5856" end_char="5858">has</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="5860" end_char="5866">experts</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="5868" end_char="5869">in</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="5871" end_char="5873">all</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="5875" end_char="5880">fields</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="5882" end_char="5883">of</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="5885" end_char="5892">medicine</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="5894" end_char="5900">working</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="5902" end_char="5903">in</TOKEN>
<TOKEN id="token-40-10" pos="word" morph="none" start_char="5905" end_char="5905">a</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="5907" end_char="5914">hospital</TOKEN>
<TOKEN id="token-40-12" pos="word" morph="none" start_char="5916" end_char="5922">setting</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="5924" end_char="5927">that</TOKEN>
<TOKEN id="token-40-14" pos="word" morph="none" start_char="5929" end_char="5930">is</TOKEN>
<TOKEN id="token-40-15" pos="word" morph="none" start_char="5932" end_char="5939">equipped</TOKEN>
<TOKEN id="token-40-16" pos="word" morph="none" start_char="5941" end_char="5944">with</TOKEN>
<TOKEN id="token-40-17" pos="word" morph="none" start_char="5946" end_char="5952">advance</TOKEN>
<TOKEN id="token-40-18" pos="unknown" morph="none" start_char="5954" end_char="5965">cutting-edge</TOKEN>
<TOKEN id="token-40-19" pos="word" morph="none" start_char="5967" end_char="5976">treatments</TOKEN>
<TOKEN id="token-40-20" pos="word" morph="none" start_char="5978" end_char="5980">and</TOKEN>
<TOKEN id="token-40-21" pos="word" morph="none" start_char="5982" end_char="5988">medical</TOKEN>
<TOKEN id="token-40-22" pos="word" morph="none" start_char="5990" end_char="5997">sciences</TOKEN>
<TOKEN id="token-40-23" pos="punct" morph="none" start_char="5998" end_char="5998">.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="6001" end_char="6054">
<ORIGINAL_TEXT>One of the experts at this prestigious hospital is Dr.</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="6001" end_char="6003">One</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="6005" end_char="6006">of</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="6008" end_char="6010">the</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="6012" end_char="6018">experts</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="6020" end_char="6021">at</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="6023" end_char="6026">this</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="6028" end_char="6038">prestigious</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="6040" end_char="6047">hospital</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="6049" end_char="6050">is</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="6052" end_char="6053">Dr</TOKEN>
<TOKEN id="token-41-10" pos="punct" morph="none" start_char="6054" end_char="6054">.</TOKEN>
</SEG>
<SEG id="segment-42" start_char="6056" end_char="6101">
<ORIGINAL_TEXT>Larry Chang, an infectious disease specialist.</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="6056" end_char="6060">Larry</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="6062" end_char="6066">Chang</TOKEN>
<TOKEN id="token-42-2" pos="punct" morph="none" start_char="6067" end_char="6067">,</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="6069" end_char="6070">an</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="6072" end_char="6081">infectious</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="6083" end_char="6089">disease</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="6091" end_char="6100">specialist</TOKEN>
<TOKEN id="token-42-7" pos="punct" morph="none" start_char="6101" end_char="6101">.</TOKEN>
</SEG>
<SEG id="segment-43" start_char="6103" end_char="6191">
<ORIGINAL_TEXT>To the question asked about whether hand dryers spread the virus, his response was blunt:</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="6103" end_char="6104">To</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="6106" end_char="6108">the</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="6110" end_char="6117">question</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="6119" end_char="6123">asked</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="6125" end_char="6129">about</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="6131" end_char="6137">whether</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="6139" end_char="6142">hand</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="6144" end_char="6149">dryers</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="6151" end_char="6156">spread</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="6158" end_char="6160">the</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="6162" end_char="6166">virus</TOKEN>
<TOKEN id="token-43-11" pos="punct" morph="none" start_char="6167" end_char="6167">,</TOKEN>
<TOKEN id="token-43-12" pos="word" morph="none" start_char="6169" end_char="6171">his</TOKEN>
<TOKEN id="token-43-13" pos="word" morph="none" start_char="6173" end_char="6180">response</TOKEN>
<TOKEN id="token-43-14" pos="word" morph="none" start_char="6182" end_char="6184">was</TOKEN>
<TOKEN id="token-43-15" pos="word" morph="none" start_char="6186" end_char="6190">blunt</TOKEN>
<TOKEN id="token-43-16" pos="punct" morph="none" start_char="6191" end_char="6191">:</TOKEN>
</SEG>
<SEG id="segment-44" start_char="6194" end_char="6196">
<ORIGINAL_TEXT>Dr.</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="6194" end_char="6195">Dr</TOKEN>
<TOKEN id="token-44-1" pos="punct" morph="none" start_char="6196" end_char="6196">.</TOKEN>
</SEG>
<SEG id="segment-45" start_char="6198" end_char="6303">
<ORIGINAL_TEXT>Chang is not the only expert in the field to say that hand dryers do not spread the virus through the air.</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="6198" end_char="6202">Chang</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="6204" end_char="6205">is</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="6207" end_char="6209">not</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="6211" end_char="6213">the</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="6215" end_char="6218">only</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="6220" end_char="6225">expert</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="6227" end_char="6228">in</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="6230" end_char="6232">the</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="6234" end_char="6238">field</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="6240" end_char="6241">to</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="6243" end_char="6245">say</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="6247" end_char="6250">that</TOKEN>
<TOKEN id="token-45-12" pos="word" morph="none" start_char="6252" end_char="6255">hand</TOKEN>
<TOKEN id="token-45-13" pos="word" morph="none" start_char="6257" end_char="6262">dryers</TOKEN>
<TOKEN id="token-45-14" pos="word" morph="none" start_char="6264" end_char="6265">do</TOKEN>
<TOKEN id="token-45-15" pos="word" morph="none" start_char="6267" end_char="6269">not</TOKEN>
<TOKEN id="token-45-16" pos="word" morph="none" start_char="6271" end_char="6276">spread</TOKEN>
<TOKEN id="token-45-17" pos="word" morph="none" start_char="6278" end_char="6280">the</TOKEN>
<TOKEN id="token-45-18" pos="word" morph="none" start_char="6282" end_char="6286">virus</TOKEN>
<TOKEN id="token-45-19" pos="word" morph="none" start_char="6288" end_char="6294">through</TOKEN>
<TOKEN id="token-45-20" pos="word" morph="none" start_char="6296" end_char="6298">the</TOKEN>
<TOKEN id="token-45-21" pos="word" morph="none" start_char="6300" end_char="6302">air</TOKEN>
<TOKEN id="token-45-22" pos="punct" morph="none" start_char="6303" end_char="6303">.</TOKEN>
</SEG>
<SEG id="segment-46" start_char="6305" end_char="6307">
<ORIGINAL_TEXT>Dr.</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="6305" end_char="6306">Dr</TOKEN>
<TOKEN id="token-46-1" pos="punct" morph="none" start_char="6307" end_char="6307">.</TOKEN>
</SEG>
<SEG id="segment-47" start_char="6309" end_char="6346">
<ORIGINAL_TEXT>Williams Hathaway, Medical Director of</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="6309" end_char="6316">Williams</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="6318" end_char="6325">Hathaway</TOKEN>
<TOKEN id="token-47-2" pos="punct" morph="none" start_char="6326" end_char="6326">,</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="6328" end_char="6334">Medical</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="6336" end_char="6343">Director</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="6345" end_char="6346">of</TOKEN>
</SEG>
<SEG id="segment-48" start_char="6350" end_char="6425">
<ORIGINAL_TEXT>Mission Health Hospitals in the United States, corroborates the words of Dr.</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="6350" end_char="6356">Mission</TOKEN>
<TOKEN id="token-48-1" pos="word" morph="none" start_char="6358" end_char="6363">Health</TOKEN>
<TOKEN id="token-48-2" pos="word" morph="none" start_char="6365" end_char="6373">Hospitals</TOKEN>
<TOKEN id="token-48-3" pos="word" morph="none" start_char="6375" end_char="6376">in</TOKEN>
<TOKEN id="token-48-4" pos="word" morph="none" start_char="6378" end_char="6380">the</TOKEN>
<TOKEN id="token-48-5" pos="word" morph="none" start_char="6382" end_char="6387">United</TOKEN>
<TOKEN id="token-48-6" pos="word" morph="none" start_char="6389" end_char="6394">States</TOKEN>
<TOKEN id="token-48-7" pos="punct" morph="none" start_char="6395" end_char="6395">,</TOKEN>
<TOKEN id="token-48-8" pos="word" morph="none" start_char="6397" end_char="6408">corroborates</TOKEN>
<TOKEN id="token-48-9" pos="word" morph="none" start_char="6410" end_char="6412">the</TOKEN>
<TOKEN id="token-48-10" pos="word" morph="none" start_char="6414" end_char="6418">words</TOKEN>
<TOKEN id="token-48-11" pos="word" morph="none" start_char="6420" end_char="6421">of</TOKEN>
<TOKEN id="token-48-12" pos="word" morph="none" start_char="6423" end_char="6424">Dr</TOKEN>
<TOKEN id="token-48-13" pos="punct" morph="none" start_char="6425" end_char="6425">.</TOKEN>
</SEG>
<SEG id="segment-49" start_char="6427" end_char="6446">
<ORIGINAL_TEXT>Chang in this video.</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="6427" end_char="6431">Chang</TOKEN>
<TOKEN id="token-49-1" pos="word" morph="none" start_char="6433" end_char="6434">in</TOKEN>
<TOKEN id="token-49-2" pos="word" morph="none" start_char="6436" end_char="6439">this</TOKEN>
<TOKEN id="token-49-3" pos="word" morph="none" start_char="6441" end_char="6445">video</TOKEN>
<TOKEN id="token-49-4" pos="punct" morph="none" start_char="6446" end_char="6446">.</TOKEN>
</SEG>
<SEG id="segment-50" start_char="6449" end_char="6571">
<ORIGINAL_TEXT>Are the US Centers for Disease Control and Prevention (CDC) in accordance with the WHO and Johns Hopkins Hospital criteria?</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="6449" end_char="6451">Are</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="6453" end_char="6455">the</TOKEN>
<TOKEN id="token-50-2" pos="word" morph="none" start_char="6457" end_char="6458">US</TOKEN>
<TOKEN id="token-50-3" pos="word" morph="none" start_char="6460" end_char="6466">Centers</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="6468" end_char="6470">for</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="6472" end_char="6478">Disease</TOKEN>
<TOKEN id="token-50-6" pos="word" morph="none" start_char="6480" end_char="6486">Control</TOKEN>
<TOKEN id="token-50-7" pos="word" morph="none" start_char="6488" end_char="6490">and</TOKEN>
<TOKEN id="token-50-8" pos="word" morph="none" start_char="6492" end_char="6501">Prevention</TOKEN>
<TOKEN id="token-50-9" pos="punct" morph="none" start_char="6503" end_char="6503">(</TOKEN>
<TOKEN id="token-50-10" pos="word" morph="none" start_char="6504" end_char="6506">CDC</TOKEN>
<TOKEN id="token-50-11" pos="punct" morph="none" start_char="6507" end_char="6507">)</TOKEN>
<TOKEN id="token-50-12" pos="word" morph="none" start_char="6509" end_char="6510">in</TOKEN>
<TOKEN id="token-50-13" pos="word" morph="none" start_char="6512" end_char="6521">accordance</TOKEN>
<TOKEN id="token-50-14" pos="word" morph="none" start_char="6523" end_char="6526">with</TOKEN>
<TOKEN id="token-50-15" pos="word" morph="none" start_char="6528" end_char="6530">the</TOKEN>
<TOKEN id="token-50-16" pos="word" morph="none" start_char="6532" end_char="6534">WHO</TOKEN>
<TOKEN id="token-50-17" pos="word" morph="none" start_char="6536" end_char="6538">and</TOKEN>
<TOKEN id="token-50-18" pos="word" morph="none" start_char="6540" end_char="6544">Johns</TOKEN>
<TOKEN id="token-50-19" pos="word" morph="none" start_char="6546" end_char="6552">Hopkins</TOKEN>
<TOKEN id="token-50-20" pos="word" morph="none" start_char="6554" end_char="6561">Hospital</TOKEN>
<TOKEN id="token-50-21" pos="word" morph="none" start_char="6563" end_char="6570">criteria</TOKEN>
<TOKEN id="token-50-22" pos="punct" morph="none" start_char="6571" end_char="6571">?</TOKEN>
</SEG>
<SEG id="segment-51" start_char="6574" end_char="6694">
<ORIGINAL_TEXT>The CDC is one of the most important operational components of the United States Department of Health and Human Services.</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="word" morph="none" start_char="6574" end_char="6576">The</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="6578" end_char="6580">CDC</TOKEN>
<TOKEN id="token-51-2" pos="word" morph="none" start_char="6582" end_char="6583">is</TOKEN>
<TOKEN id="token-51-3" pos="word" morph="none" start_char="6585" end_char="6587">one</TOKEN>
<TOKEN id="token-51-4" pos="word" morph="none" start_char="6589" end_char="6590">of</TOKEN>
<TOKEN id="token-51-5" pos="word" morph="none" start_char="6592" end_char="6594">the</TOKEN>
<TOKEN id="token-51-6" pos="word" morph="none" start_char="6596" end_char="6599">most</TOKEN>
<TOKEN id="token-51-7" pos="word" morph="none" start_char="6601" end_char="6609">important</TOKEN>
<TOKEN id="token-51-8" pos="word" morph="none" start_char="6611" end_char="6621">operational</TOKEN>
<TOKEN id="token-51-9" pos="word" morph="none" start_char="6623" end_char="6632">components</TOKEN>
<TOKEN id="token-51-10" pos="word" morph="none" start_char="6634" end_char="6635">of</TOKEN>
<TOKEN id="token-51-11" pos="word" morph="none" start_char="6637" end_char="6639">the</TOKEN>
<TOKEN id="token-51-12" pos="word" morph="none" start_char="6641" end_char="6646">United</TOKEN>
<TOKEN id="token-51-13" pos="word" morph="none" start_char="6648" end_char="6653">States</TOKEN>
<TOKEN id="token-51-14" pos="word" morph="none" start_char="6655" end_char="6664">Department</TOKEN>
<TOKEN id="token-51-15" pos="word" morph="none" start_char="6666" end_char="6667">of</TOKEN>
<TOKEN id="token-51-16" pos="word" morph="none" start_char="6669" end_char="6674">Health</TOKEN>
<TOKEN id="token-51-17" pos="word" morph="none" start_char="6676" end_char="6678">and</TOKEN>
<TOKEN id="token-51-18" pos="word" morph="none" start_char="6680" end_char="6684">Human</TOKEN>
<TOKEN id="token-51-19" pos="word" morph="none" start_char="6686" end_char="6693">Services</TOKEN>
<TOKEN id="token-51-20" pos="punct" morph="none" start_char="6694" end_char="6694">.</TOKEN>
</SEG>
<SEG id="segment-52" start_char="6696" end_char="6822">
<ORIGINAL_TEXT>They work around the clock to protect all Americans from threats to their health and safety, from within the country or abroad.</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="6696" end_char="6699">They</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="6701" end_char="6704">work</TOKEN>
<TOKEN id="token-52-2" pos="word" morph="none" start_char="6706" end_char="6711">around</TOKEN>
<TOKEN id="token-52-3" pos="word" morph="none" start_char="6713" end_char="6715">the</TOKEN>
<TOKEN id="token-52-4" pos="word" morph="none" start_char="6717" end_char="6721">clock</TOKEN>
<TOKEN id="token-52-5" pos="word" morph="none" start_char="6723" end_char="6724">to</TOKEN>
<TOKEN id="token-52-6" pos="word" morph="none" start_char="6726" end_char="6732">protect</TOKEN>
<TOKEN id="token-52-7" pos="word" morph="none" start_char="6734" end_char="6736">all</TOKEN>
<TOKEN id="token-52-8" pos="word" morph="none" start_char="6738" end_char="6746">Americans</TOKEN>
<TOKEN id="token-52-9" pos="word" morph="none" start_char="6748" end_char="6751">from</TOKEN>
<TOKEN id="token-52-10" pos="word" morph="none" start_char="6753" end_char="6759">threats</TOKEN>
<TOKEN id="token-52-11" pos="word" morph="none" start_char="6761" end_char="6762">to</TOKEN>
<TOKEN id="token-52-12" pos="word" morph="none" start_char="6764" end_char="6768">their</TOKEN>
<TOKEN id="token-52-13" pos="word" morph="none" start_char="6770" end_char="6775">health</TOKEN>
<TOKEN id="token-52-14" pos="word" morph="none" start_char="6777" end_char="6779">and</TOKEN>
<TOKEN id="token-52-15" pos="word" morph="none" start_char="6781" end_char="6786">safety</TOKEN>
<TOKEN id="token-52-16" pos="punct" morph="none" start_char="6787" end_char="6787">,</TOKEN>
<TOKEN id="token-52-17" pos="word" morph="none" start_char="6789" end_char="6792">from</TOKEN>
<TOKEN id="token-52-18" pos="word" morph="none" start_char="6794" end_char="6799">within</TOKEN>
<TOKEN id="token-52-19" pos="word" morph="none" start_char="6801" end_char="6803">the</TOKEN>
<TOKEN id="token-52-20" pos="word" morph="none" start_char="6805" end_char="6811">country</TOKEN>
<TOKEN id="token-52-21" pos="word" morph="none" start_char="6813" end_char="6814">or</TOKEN>
<TOKEN id="token-52-22" pos="word" morph="none" start_char="6816" end_char="6821">abroad</TOKEN>
<TOKEN id="token-52-23" pos="punct" morph="none" start_char="6822" end_char="6822">.</TOKEN>
</SEG>
<SEG id="segment-53" start_char="6824" end_char="7059">
<ORIGINAL_TEXT>They are, like Johns Hopkins, a benchmark in infectious diseases and, as you can see in this video, they also recommend effective hand cleaning with soap and water, then drying hands with electric hand dryers or disposable paper towels.</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="word" morph="none" start_char="6824" end_char="6827">They</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="6829" end_char="6831">are</TOKEN>
<TOKEN id="token-53-2" pos="punct" morph="none" start_char="6832" end_char="6832">,</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="6834" end_char="6837">like</TOKEN>
<TOKEN id="token-53-4" pos="word" morph="none" start_char="6839" end_char="6843">Johns</TOKEN>
<TOKEN id="token-53-5" pos="word" morph="none" start_char="6845" end_char="6851">Hopkins</TOKEN>
<TOKEN id="token-53-6" pos="punct" morph="none" start_char="6852" end_char="6852">,</TOKEN>
<TOKEN id="token-53-7" pos="word" morph="none" start_char="6854" end_char="6854">a</TOKEN>
<TOKEN id="token-53-8" pos="word" morph="none" start_char="6856" end_char="6864">benchmark</TOKEN>
<TOKEN id="token-53-9" pos="word" morph="none" start_char="6866" end_char="6867">in</TOKEN>
<TOKEN id="token-53-10" pos="word" morph="none" start_char="6869" end_char="6878">infectious</TOKEN>
<TOKEN id="token-53-11" pos="word" morph="none" start_char="6880" end_char="6887">diseases</TOKEN>
<TOKEN id="token-53-12" pos="word" morph="none" start_char="6889" end_char="6891">and</TOKEN>
<TOKEN id="token-53-13" pos="punct" morph="none" start_char="6892" end_char="6892">,</TOKEN>
<TOKEN id="token-53-14" pos="word" morph="none" start_char="6894" end_char="6895">as</TOKEN>
<TOKEN id="token-53-15" pos="word" morph="none" start_char="6897" end_char="6899">you</TOKEN>
<TOKEN id="token-53-16" pos="word" morph="none" start_char="6901" end_char="6903">can</TOKEN>
<TOKEN id="token-53-17" pos="word" morph="none" start_char="6905" end_char="6907">see</TOKEN>
<TOKEN id="token-53-18" pos="word" morph="none" start_char="6909" end_char="6910">in</TOKEN>
<TOKEN id="token-53-19" pos="word" morph="none" start_char="6912" end_char="6915">this</TOKEN>
<TOKEN id="token-53-20" pos="word" morph="none" start_char="6917" end_char="6921">video</TOKEN>
<TOKEN id="token-53-21" pos="punct" morph="none" start_char="6922" end_char="6922">,</TOKEN>
<TOKEN id="token-53-22" pos="word" morph="none" start_char="6924" end_char="6927">they</TOKEN>
<TOKEN id="token-53-23" pos="word" morph="none" start_char="6929" end_char="6932">also</TOKEN>
<TOKEN id="token-53-24" pos="word" morph="none" start_char="6934" end_char="6942">recommend</TOKEN>
<TOKEN id="token-53-25" pos="word" morph="none" start_char="6944" end_char="6952">effective</TOKEN>
<TOKEN id="token-53-26" pos="word" morph="none" start_char="6954" end_char="6957">hand</TOKEN>
<TOKEN id="token-53-27" pos="word" morph="none" start_char="6959" end_char="6966">cleaning</TOKEN>
<TOKEN id="token-53-28" pos="word" morph="none" start_char="6968" end_char="6971">with</TOKEN>
<TOKEN id="token-53-29" pos="word" morph="none" start_char="6973" end_char="6976">soap</TOKEN>
<TOKEN id="token-53-30" pos="word" morph="none" start_char="6978" end_char="6980">and</TOKEN>
<TOKEN id="token-53-31" pos="word" morph="none" start_char="6982" end_char="6986">water</TOKEN>
<TOKEN id="token-53-32" pos="punct" morph="none" start_char="6987" end_char="6987">,</TOKEN>
<TOKEN id="token-53-33" pos="word" morph="none" start_char="6989" end_char="6992">then</TOKEN>
<TOKEN id="token-53-34" pos="word" morph="none" start_char="6994" end_char="6999">drying</TOKEN>
<TOKEN id="token-53-35" pos="word" morph="none" start_char="7001" end_char="7005">hands</TOKEN>
<TOKEN id="token-53-36" pos="word" morph="none" start_char="7007" end_char="7010">with</TOKEN>
<TOKEN id="token-53-37" pos="word" morph="none" start_char="7012" end_char="7019">electric</TOKEN>
<TOKEN id="token-53-38" pos="word" morph="none" start_char="7021" end_char="7024">hand</TOKEN>
<TOKEN id="token-53-39" pos="word" morph="none" start_char="7026" end_char="7031">dryers</TOKEN>
<TOKEN id="token-53-40" pos="word" morph="none" start_char="7033" end_char="7034">or</TOKEN>
<TOKEN id="token-53-41" pos="word" morph="none" start_char="7036" end_char="7045">disposable</TOKEN>
<TOKEN id="token-53-42" pos="word" morph="none" start_char="7047" end_char="7051">paper</TOKEN>
<TOKEN id="token-53-43" pos="word" morph="none" start_char="7053" end_char="7058">towels</TOKEN>
<TOKEN id="token-53-44" pos="punct" morph="none" start_char="7059" end_char="7059">.</TOKEN>
</SEG>
<SEG id="segment-54" start_char="7062" end_char="7111">
<ORIGINAL_TEXT>European Center for Disease Prevention and Control</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="word" morph="none" start_char="7062" end_char="7069">European</TOKEN>
<TOKEN id="token-54-1" pos="word" morph="none" start_char="7071" end_char="7076">Center</TOKEN>
<TOKEN id="token-54-2" pos="word" morph="none" start_char="7078" end_char="7080">for</TOKEN>
<TOKEN id="token-54-3" pos="word" morph="none" start_char="7082" end_char="7088">Disease</TOKEN>
<TOKEN id="token-54-4" pos="word" morph="none" start_char="7090" end_char="7099">Prevention</TOKEN>
<TOKEN id="token-54-5" pos="word" morph="none" start_char="7101" end_char="7103">and</TOKEN>
<TOKEN id="token-54-6" pos="word" morph="none" start_char="7105" end_char="7111">Control</TOKEN>
</SEG>
<SEG id="segment-55" start_char="7114" end_char="7297">
<ORIGINAL_TEXT>The European Center for Disease Prevention and Control (ECDC) analyzes and interprets data from EU countries on communicable diseases, through the European Surveillance System (TESSy).</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="word" morph="none" start_char="7114" end_char="7116">The</TOKEN>
<TOKEN id="token-55-1" pos="word" morph="none" start_char="7118" end_char="7125">European</TOKEN>
<TOKEN id="token-55-2" pos="word" morph="none" start_char="7127" end_char="7132">Center</TOKEN>
<TOKEN id="token-55-3" pos="word" morph="none" start_char="7134" end_char="7136">for</TOKEN>
<TOKEN id="token-55-4" pos="word" morph="none" start_char="7138" end_char="7144">Disease</TOKEN>
<TOKEN id="token-55-5" pos="word" morph="none" start_char="7146" end_char="7155">Prevention</TOKEN>
<TOKEN id="token-55-6" pos="word" morph="none" start_char="7157" end_char="7159">and</TOKEN>
<TOKEN id="token-55-7" pos="word" morph="none" start_char="7161" end_char="7167">Control</TOKEN>
<TOKEN id="token-55-8" pos="punct" morph="none" start_char="7169" end_char="7169">(</TOKEN>
<TOKEN id="token-55-9" pos="word" morph="none" start_char="7170" end_char="7173">ECDC</TOKEN>
<TOKEN id="token-55-10" pos="punct" morph="none" start_char="7174" end_char="7174">)</TOKEN>
<TOKEN id="token-55-11" pos="word" morph="none" start_char="7176" end_char="7183">analyzes</TOKEN>
<TOKEN id="token-55-12" pos="word" morph="none" start_char="7185" end_char="7187">and</TOKEN>
<TOKEN id="token-55-13" pos="word" morph="none" start_char="7189" end_char="7198">interprets</TOKEN>
<TOKEN id="token-55-14" pos="word" morph="none" start_char="7200" end_char="7203">data</TOKEN>
<TOKEN id="token-55-15" pos="word" morph="none" start_char="7205" end_char="7208">from</TOKEN>
<TOKEN id="token-55-16" pos="word" morph="none" start_char="7210" end_char="7211">EU</TOKEN>
<TOKEN id="token-55-17" pos="word" morph="none" start_char="7213" end_char="7221">countries</TOKEN>
<TOKEN id="token-55-18" pos="word" morph="none" start_char="7223" end_char="7224">on</TOKEN>
<TOKEN id="token-55-19" pos="word" morph="none" start_char="7226" end_char="7237">communicable</TOKEN>
<TOKEN id="token-55-20" pos="word" morph="none" start_char="7239" end_char="7246">diseases</TOKEN>
<TOKEN id="token-55-21" pos="punct" morph="none" start_char="7247" end_char="7247">,</TOKEN>
<TOKEN id="token-55-22" pos="word" morph="none" start_char="7249" end_char="7255">through</TOKEN>
<TOKEN id="token-55-23" pos="word" morph="none" start_char="7257" end_char="7259">the</TOKEN>
<TOKEN id="token-55-24" pos="word" morph="none" start_char="7261" end_char="7268">European</TOKEN>
<TOKEN id="token-55-25" pos="word" morph="none" start_char="7270" end_char="7281">Surveillance</TOKEN>
<TOKEN id="token-55-26" pos="word" morph="none" start_char="7283" end_char="7288">System</TOKEN>
<TOKEN id="token-55-27" pos="punct" morph="none" start_char="7290" end_char="7290">(</TOKEN>
<TOKEN id="token-55-28" pos="word" morph="none" start_char="7291" end_char="7295">TESSy</TOKEN>
<TOKEN id="token-55-29" pos="punct" morph="none" start_char="7296" end_char="7297">).</TOKEN>
</SEG>
<SEG id="segment-56" start_char="7299" end_char="7447">
<ORIGINAL_TEXT>This provides scientific advice to governments and institutions of the EU and ensures the early detection and analysis of emerging threats to the EU.</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="7299" end_char="7302">This</TOKEN>
<TOKEN id="token-56-1" pos="word" morph="none" start_char="7304" end_char="7311">provides</TOKEN>
<TOKEN id="token-56-2" pos="word" morph="none" start_char="7313" end_char="7322">scientific</TOKEN>
<TOKEN id="token-56-3" pos="word" morph="none" start_char="7324" end_char="7329">advice</TOKEN>
<TOKEN id="token-56-4" pos="word" morph="none" start_char="7331" end_char="7332">to</TOKEN>
<TOKEN id="token-56-5" pos="word" morph="none" start_char="7334" end_char="7344">governments</TOKEN>
<TOKEN id="token-56-6" pos="word" morph="none" start_char="7346" end_char="7348">and</TOKEN>
<TOKEN id="token-56-7" pos="word" morph="none" start_char="7350" end_char="7361">institutions</TOKEN>
<TOKEN id="token-56-8" pos="word" morph="none" start_char="7363" end_char="7364">of</TOKEN>
<TOKEN id="token-56-9" pos="word" morph="none" start_char="7366" end_char="7368">the</TOKEN>
<TOKEN id="token-56-10" pos="word" morph="none" start_char="7370" end_char="7371">EU</TOKEN>
<TOKEN id="token-56-11" pos="word" morph="none" start_char="7373" end_char="7375">and</TOKEN>
<TOKEN id="token-56-12" pos="word" morph="none" start_char="7377" end_char="7383">ensures</TOKEN>
<TOKEN id="token-56-13" pos="word" morph="none" start_char="7385" end_char="7387">the</TOKEN>
<TOKEN id="token-56-14" pos="word" morph="none" start_char="7389" end_char="7393">early</TOKEN>
<TOKEN id="token-56-15" pos="word" morph="none" start_char="7395" end_char="7403">detection</TOKEN>
<TOKEN id="token-56-16" pos="word" morph="none" start_char="7405" end_char="7407">and</TOKEN>
<TOKEN id="token-56-17" pos="word" morph="none" start_char="7409" end_char="7416">analysis</TOKEN>
<TOKEN id="token-56-18" pos="word" morph="none" start_char="7418" end_char="7419">of</TOKEN>
<TOKEN id="token-56-19" pos="word" morph="none" start_char="7421" end_char="7428">emerging</TOKEN>
<TOKEN id="token-56-20" pos="word" morph="none" start_char="7430" end_char="7436">threats</TOKEN>
<TOKEN id="token-56-21" pos="word" morph="none" start_char="7438" end_char="7439">to</TOKEN>
<TOKEN id="token-56-22" pos="word" morph="none" start_char="7441" end_char="7443">the</TOKEN>
<TOKEN id="token-56-23" pos="word" morph="none" start_char="7445" end_char="7446">EU</TOKEN>
<TOKEN id="token-56-24" pos="punct" morph="none" start_char="7447" end_char="7447">.</TOKEN>
</SEG>
<SEG id="segment-57" start_char="7450" end_char="7677">
<ORIGINAL_TEXT>Here on the preventive measures to avoid the spread of the common flu, very similar to SARS-CoV-2, the ECDC recommends proper hand washing with soap water and subsequent drying with a hand dryer or disposable paper towels/wipes.</ORIGINAL_TEXT>
<TOKEN id="token-57-0" pos="word" morph="none" start_char="7450" end_char="7453">Here</TOKEN>
<TOKEN id="token-57-1" pos="word" morph="none" start_char="7455" end_char="7456">on</TOKEN>
<TOKEN id="token-57-2" pos="word" morph="none" start_char="7458" end_char="7460">the</TOKEN>
<TOKEN id="token-57-3" pos="word" morph="none" start_char="7462" end_char="7471">preventive</TOKEN>
<TOKEN id="token-57-4" pos="word" morph="none" start_char="7473" end_char="7480">measures</TOKEN>
<TOKEN id="token-57-5" pos="word" morph="none" start_char="7482" end_char="7483">to</TOKEN>
<TOKEN id="token-57-6" pos="word" morph="none" start_char="7485" end_char="7489">avoid</TOKEN>
<TOKEN id="token-57-7" pos="word" morph="none" start_char="7491" end_char="7493">the</TOKEN>
<TOKEN id="token-57-8" pos="word" morph="none" start_char="7495" end_char="7500">spread</TOKEN>
<TOKEN id="token-57-9" pos="word" morph="none" start_char="7502" end_char="7503">of</TOKEN>
<TOKEN id="token-57-10" pos="word" morph="none" start_char="7505" end_char="7507">the</TOKEN>
<TOKEN id="token-57-11" pos="word" morph="none" start_char="7509" end_char="7514">common</TOKEN>
<TOKEN id="token-57-12" pos="word" morph="none" start_char="7516" end_char="7518">flu</TOKEN>
<TOKEN id="token-57-13" pos="punct" morph="none" start_char="7519" end_char="7519">,</TOKEN>
<TOKEN id="token-57-14" pos="word" morph="none" start_char="7521" end_char="7524">very</TOKEN>
<TOKEN id="token-57-15" pos="word" morph="none" start_char="7526" end_char="7532">similar</TOKEN>
<TOKEN id="token-57-16" pos="word" morph="none" start_char="7534" end_char="7535">to</TOKEN>
<TOKEN id="token-57-17" pos="unknown" morph="none" start_char="7537" end_char="7546">SARS-CoV-2</TOKEN>
<TOKEN id="token-57-18" pos="punct" morph="none" start_char="7547" end_char="7547">,</TOKEN>
<TOKEN id="token-57-19" pos="word" morph="none" start_char="7549" end_char="7551">the</TOKEN>
<TOKEN id="token-57-20" pos="word" morph="none" start_char="7553" end_char="7556">ECDC</TOKEN>
<TOKEN id="token-57-21" pos="word" morph="none" start_char="7558" end_char="7567">recommends</TOKEN>
<TOKEN id="token-57-22" pos="word" morph="none" start_char="7569" end_char="7574">proper</TOKEN>
<TOKEN id="token-57-23" pos="word" morph="none" start_char="7576" end_char="7579">hand</TOKEN>
<TOKEN id="token-57-24" pos="word" morph="none" start_char="7581" end_char="7587">washing</TOKEN>
<TOKEN id="token-57-25" pos="word" morph="none" start_char="7589" end_char="7592">with</TOKEN>
<TOKEN id="token-57-26" pos="word" morph="none" start_char="7594" end_char="7597">soap</TOKEN>
<TOKEN id="token-57-27" pos="word" morph="none" start_char="7599" end_char="7603">water</TOKEN>
<TOKEN id="token-57-28" pos="word" morph="none" start_char="7605" end_char="7607">and</TOKEN>
<TOKEN id="token-57-29" pos="word" morph="none" start_char="7609" end_char="7618">subsequent</TOKEN>
<TOKEN id="token-57-30" pos="word" morph="none" start_char="7620" end_char="7625">drying</TOKEN>
<TOKEN id="token-57-31" pos="word" morph="none" start_char="7627" end_char="7630">with</TOKEN>
<TOKEN id="token-57-32" pos="word" morph="none" start_char="7632" end_char="7632">a</TOKEN>
<TOKEN id="token-57-33" pos="word" morph="none" start_char="7634" end_char="7637">hand</TOKEN>
<TOKEN id="token-57-34" pos="word" morph="none" start_char="7639" end_char="7643">dryer</TOKEN>
<TOKEN id="token-57-35" pos="word" morph="none" start_char="7645" end_char="7646">or</TOKEN>
<TOKEN id="token-57-36" pos="word" morph="none" start_char="7648" end_char="7657">disposable</TOKEN>
<TOKEN id="token-57-37" pos="word" morph="none" start_char="7659" end_char="7663">paper</TOKEN>
<TOKEN id="token-57-38" pos="unknown" morph="none" start_char="7665" end_char="7676">towels/wipes</TOKEN>
<TOKEN id="token-57-39" pos="punct" morph="none" start_char="7677" end_char="7677">.</TOKEN>
</SEG>
<SEG id="segment-58" start_char="7680" end_char="7737">
<ORIGINAL_TEXT>What guidelines does the Ministry of Health give in Spain?</ORIGINAL_TEXT>
<TOKEN id="token-58-0" pos="word" morph="none" start_char="7680" end_char="7683">What</TOKEN>
<TOKEN id="token-58-1" pos="word" morph="none" start_char="7685" end_char="7694">guidelines</TOKEN>
<TOKEN id="token-58-2" pos="word" morph="none" start_char="7696" end_char="7699">does</TOKEN>
<TOKEN id="token-58-3" pos="word" morph="none" start_char="7701" end_char="7703">the</TOKEN>
<TOKEN id="token-58-4" pos="word" morph="none" start_char="7705" end_char="7712">Ministry</TOKEN>
<TOKEN id="token-58-5" pos="word" morph="none" start_char="7714" end_char="7715">of</TOKEN>
<TOKEN id="token-58-6" pos="word" morph="none" start_char="7717" end_char="7722">Health</TOKEN>
<TOKEN id="token-58-7" pos="word" morph="none" start_char="7724" end_char="7727">give</TOKEN>
<TOKEN id="token-58-8" pos="word" morph="none" start_char="7729" end_char="7730">in</TOKEN>
<TOKEN id="token-58-9" pos="word" morph="none" start_char="7732" end_char="7736">Spain</TOKEN>
<TOKEN id="token-58-10" pos="punct" morph="none" start_char="7737" end_char="7737">?</TOKEN>
</SEG>
<SEG id="segment-59" start_char="7740" end_char="7866">
<ORIGINAL_TEXT>At this point, and with the information presented so far, you can imagine how the Spanish Ministry of Health positioned itself.</ORIGINAL_TEXT>
<TOKEN id="token-59-0" pos="word" morph="none" start_char="7740" end_char="7741">At</TOKEN>
<TOKEN id="token-59-1" pos="word" morph="none" start_char="7743" end_char="7746">this</TOKEN>
<TOKEN id="token-59-2" pos="word" morph="none" start_char="7748" end_char="7752">point</TOKEN>
<TOKEN id="token-59-3" pos="punct" morph="none" start_char="7753" end_char="7753">,</TOKEN>
<TOKEN id="token-59-4" pos="word" morph="none" start_char="7755" end_char="7757">and</TOKEN>
<TOKEN id="token-59-5" pos="word" morph="none" start_char="7759" end_char="7762">with</TOKEN>
<TOKEN id="token-59-6" pos="word" morph="none" start_char="7764" end_char="7766">the</TOKEN>
<TOKEN id="token-59-7" pos="word" morph="none" start_char="7768" end_char="7778">information</TOKEN>
<TOKEN id="token-59-8" pos="word" morph="none" start_char="7780" end_char="7788">presented</TOKEN>
<TOKEN id="token-59-9" pos="word" morph="none" start_char="7790" end_char="7791">so</TOKEN>
<TOKEN id="token-59-10" pos="word" morph="none" start_char="7793" end_char="7795">far</TOKEN>
<TOKEN id="token-59-11" pos="punct" morph="none" start_char="7796" end_char="7796">,</TOKEN>
<TOKEN id="token-59-12" pos="word" morph="none" start_char="7798" end_char="7800">you</TOKEN>
<TOKEN id="token-59-13" pos="word" morph="none" start_char="7802" end_char="7804">can</TOKEN>
<TOKEN id="token-59-14" pos="word" morph="none" start_char="7806" end_char="7812">imagine</TOKEN>
<TOKEN id="token-59-15" pos="word" morph="none" start_char="7814" end_char="7816">how</TOKEN>
<TOKEN id="token-59-16" pos="word" morph="none" start_char="7818" end_char="7820">the</TOKEN>
<TOKEN id="token-59-17" pos="word" morph="none" start_char="7822" end_char="7828">Spanish</TOKEN>
<TOKEN id="token-59-18" pos="word" morph="none" start_char="7830" end_char="7837">Ministry</TOKEN>
<TOKEN id="token-59-19" pos="word" morph="none" start_char="7839" end_char="7840">of</TOKEN>
<TOKEN id="token-59-20" pos="word" morph="none" start_char="7842" end_char="7847">Health</TOKEN>
<TOKEN id="token-59-21" pos="word" morph="none" start_char="7849" end_char="7858">positioned</TOKEN>
<TOKEN id="token-59-22" pos="word" morph="none" start_char="7860" end_char="7865">itself</TOKEN>
<TOKEN id="token-59-23" pos="punct" morph="none" start_char="7866" end_char="7866">.</TOKEN>
</SEG>
<SEG id="segment-60" start_char="7868" end_char="7906">
<ORIGINAL_TEXT>Indeed, they immediately took our side.</ORIGINAL_TEXT>
<TOKEN id="token-60-0" pos="word" morph="none" start_char="7868" end_char="7873">Indeed</TOKEN>
<TOKEN id="token-60-1" pos="punct" morph="none" start_char="7874" end_char="7874">,</TOKEN>
<TOKEN id="token-60-2" pos="word" morph="none" start_char="7876" end_char="7879">they</TOKEN>
<TOKEN id="token-60-3" pos="word" morph="none" start_char="7881" end_char="7891">immediately</TOKEN>
<TOKEN id="token-60-4" pos="word" morph="none" start_char="7893" end_char="7896">took</TOKEN>
<TOKEN id="token-60-5" pos="word" morph="none" start_char="7898" end_char="7900">our</TOKEN>
<TOKEN id="token-60-6" pos="word" morph="none" start_char="7902" end_char="7905">side</TOKEN>
<TOKEN id="token-60-7" pos="punct" morph="none" start_char="7906" end_char="7906">.</TOKEN>
</SEG>
<SEG id="segment-61" start_char="7908" end_char="7986">
<ORIGINAL_TEXT>With all this information on the table, it would have been difficult to ignore.</ORIGINAL_TEXT>
<TOKEN id="token-61-0" pos="word" morph="none" start_char="7908" end_char="7911">With</TOKEN>
<TOKEN id="token-61-1" pos="word" morph="none" start_char="7913" end_char="7915">all</TOKEN>
<TOKEN id="token-61-2" pos="word" morph="none" start_char="7917" end_char="7920">this</TOKEN>
<TOKEN id="token-61-3" pos="word" morph="none" start_char="7922" end_char="7932">information</TOKEN>
<TOKEN id="token-61-4" pos="word" morph="none" start_char="7934" end_char="7935">on</TOKEN>
<TOKEN id="token-61-5" pos="word" morph="none" start_char="7937" end_char="7939">the</TOKEN>
<TOKEN id="token-61-6" pos="word" morph="none" start_char="7941" end_char="7945">table</TOKEN>
<TOKEN id="token-61-7" pos="punct" morph="none" start_char="7946" end_char="7946">,</TOKEN>
<TOKEN id="token-61-8" pos="word" morph="none" start_char="7948" end_char="7949">it</TOKEN>
<TOKEN id="token-61-9" pos="word" morph="none" start_char="7951" end_char="7955">would</TOKEN>
<TOKEN id="token-61-10" pos="word" morph="none" start_char="7957" end_char="7960">have</TOKEN>
<TOKEN id="token-61-11" pos="word" morph="none" start_char="7962" end_char="7965">been</TOKEN>
<TOKEN id="token-61-12" pos="word" morph="none" start_char="7967" end_char="7975">difficult</TOKEN>
<TOKEN id="token-61-13" pos="word" morph="none" start_char="7977" end_char="7978">to</TOKEN>
<TOKEN id="token-61-14" pos="word" morph="none" start_char="7980" end_char="7985">ignore</TOKEN>
<TOKEN id="token-61-15" pos="punct" morph="none" start_char="7986" end_char="7986">.</TOKEN>
</SEG>
<SEG id="segment-62" start_char="7988" end_char="8163">
<ORIGINAL_TEXT>After a couple of meetings with the main officials of the Ministry, they sent us a note where they positively positioned themselves in favor of the use of electric hand dryers.</ORIGINAL_TEXT>
<TOKEN id="token-62-0" pos="word" morph="none" start_char="7988" end_char="7992">After</TOKEN>
<TOKEN id="token-62-1" pos="word" morph="none" start_char="7994" end_char="7994">a</TOKEN>
<TOKEN id="token-62-2" pos="word" morph="none" start_char="7996" end_char="8001">couple</TOKEN>
<TOKEN id="token-62-3" pos="word" morph="none" start_char="8003" end_char="8004">of</TOKEN>
<TOKEN id="token-62-4" pos="word" morph="none" start_char="8006" end_char="8013">meetings</TOKEN>
<TOKEN id="token-62-5" pos="word" morph="none" start_char="8015" end_char="8018">with</TOKEN>
<TOKEN id="token-62-6" pos="word" morph="none" start_char="8020" end_char="8022">the</TOKEN>
<TOKEN id="token-62-7" pos="word" morph="none" start_char="8024" end_char="8027">main</TOKEN>
<TOKEN id="token-62-8" pos="word" morph="none" start_char="8029" end_char="8037">officials</TOKEN>
<TOKEN id="token-62-9" pos="word" morph="none" start_char="8039" end_char="8040">of</TOKEN>
<TOKEN id="token-62-10" pos="word" morph="none" start_char="8042" end_char="8044">the</TOKEN>
<TOKEN id="token-62-11" pos="word" morph="none" start_char="8046" end_char="8053">Ministry</TOKEN>
<TOKEN id="token-62-12" pos="punct" morph="none" start_char="8054" end_char="8054">,</TOKEN>
<TOKEN id="token-62-13" pos="word" morph="none" start_char="8056" end_char="8059">they</TOKEN>
<TOKEN id="token-62-14" pos="word" morph="none" start_char="8061" end_char="8064">sent</TOKEN>
<TOKEN id="token-62-15" pos="word" morph="none" start_char="8066" end_char="8067">us</TOKEN>
<TOKEN id="token-62-16" pos="word" morph="none" start_char="8069" end_char="8069">a</TOKEN>
<TOKEN id="token-62-17" pos="word" morph="none" start_char="8071" end_char="8074">note</TOKEN>
<TOKEN id="token-62-18" pos="word" morph="none" start_char="8076" end_char="8080">where</TOKEN>
<TOKEN id="token-62-19" pos="word" morph="none" start_char="8082" end_char="8085">they</TOKEN>
<TOKEN id="token-62-20" pos="word" morph="none" start_char="8087" end_char="8096">positively</TOKEN>
<TOKEN id="token-62-21" pos="word" morph="none" start_char="8098" end_char="8107">positioned</TOKEN>
<TOKEN id="token-62-22" pos="word" morph="none" start_char="8109" end_char="8118">themselves</TOKEN>
<TOKEN id="token-62-23" pos="word" morph="none" start_char="8120" end_char="8121">in</TOKEN>
<TOKEN id="token-62-24" pos="word" morph="none" start_char="8123" end_char="8127">favor</TOKEN>
<TOKEN id="token-62-25" pos="word" morph="none" start_char="8129" end_char="8130">of</TOKEN>
<TOKEN id="token-62-26" pos="word" morph="none" start_char="8132" end_char="8134">the</TOKEN>
<TOKEN id="token-62-27" pos="word" morph="none" start_char="8136" end_char="8138">use</TOKEN>
<TOKEN id="token-62-28" pos="word" morph="none" start_char="8140" end_char="8141">of</TOKEN>
<TOKEN id="token-62-29" pos="word" morph="none" start_char="8143" end_char="8150">electric</TOKEN>
<TOKEN id="token-62-30" pos="word" morph="none" start_char="8152" end_char="8155">hand</TOKEN>
<TOKEN id="token-62-31" pos="word" morph="none" start_char="8157" end_char="8162">dryers</TOKEN>
<TOKEN id="token-62-32" pos="punct" morph="none" start_char="8163" end_char="8163">.</TOKEN>
</SEG>
<SEG id="segment-63" start_char="8166" end_char="8266">
<ORIGINAL_TEXT>Like Dorothy, we managed to get to Oz, talk to the wizard, and return home with an accomplished goal.</ORIGINAL_TEXT>
<TOKEN id="token-63-0" pos="word" morph="none" start_char="8166" end_char="8169">Like</TOKEN>
<TOKEN id="token-63-1" pos="word" morph="none" start_char="8171" end_char="8177">Dorothy</TOKEN>
<TOKEN id="token-63-2" pos="punct" morph="none" start_char="8178" end_char="8178">,</TOKEN>
<TOKEN id="token-63-3" pos="word" morph="none" start_char="8180" end_char="8181">we</TOKEN>
<TOKEN id="token-63-4" pos="word" morph="none" start_char="8183" end_char="8189">managed</TOKEN>
<TOKEN id="token-63-5" pos="word" morph="none" start_char="8191" end_char="8192">to</TOKEN>
<TOKEN id="token-63-6" pos="word" morph="none" start_char="8194" end_char="8196">get</TOKEN>
<TOKEN id="token-63-7" pos="word" morph="none" start_char="8198" end_char="8199">to</TOKEN>
<TOKEN id="token-63-8" pos="word" morph="none" start_char="8201" end_char="8202">Oz</TOKEN>
<TOKEN id="token-63-9" pos="punct" morph="none" start_char="8203" end_char="8203">,</TOKEN>
<TOKEN id="token-63-10" pos="word" morph="none" start_char="8205" end_char="8208">talk</TOKEN>
<TOKEN id="token-63-11" pos="word" morph="none" start_char="8210" end_char="8211">to</TOKEN>
<TOKEN id="token-63-12" pos="word" morph="none" start_char="8213" end_char="8215">the</TOKEN>
<TOKEN id="token-63-13" pos="word" morph="none" start_char="8217" end_char="8222">wizard</TOKEN>
<TOKEN id="token-63-14" pos="punct" morph="none" start_char="8223" end_char="8223">,</TOKEN>
<TOKEN id="token-63-15" pos="word" morph="none" start_char="8225" end_char="8227">and</TOKEN>
<TOKEN id="token-63-16" pos="word" morph="none" start_char="8229" end_char="8234">return</TOKEN>
<TOKEN id="token-63-17" pos="word" morph="none" start_char="8236" end_char="8239">home</TOKEN>
<TOKEN id="token-63-18" pos="word" morph="none" start_char="8241" end_char="8244">with</TOKEN>
<TOKEN id="token-63-19" pos="word" morph="none" start_char="8246" end_char="8247">an</TOKEN>
<TOKEN id="token-63-20" pos="word" morph="none" start_char="8249" end_char="8260">accomplished</TOKEN>
<TOKEN id="token-63-21" pos="word" morph="none" start_char="8262" end_char="8265">goal</TOKEN>
<TOKEN id="token-63-22" pos="punct" morph="none" start_char="8266" end_char="8266">.</TOKEN>
</SEG>
<SEG id="segment-64" start_char="8269" end_char="8311">
<ORIGINAL_TEXT>University of Arizona study dictates ruling</ORIGINAL_TEXT>
<TOKEN id="token-64-0" pos="word" morph="none" start_char="8269" end_char="8278">University</TOKEN>
<TOKEN id="token-64-1" pos="word" morph="none" start_char="8280" end_char="8281">of</TOKEN>
<TOKEN id="token-64-2" pos="word" morph="none" start_char="8283" end_char="8289">Arizona</TOKEN>
<TOKEN id="token-64-3" pos="word" morph="none" start_char="8291" end_char="8295">study</TOKEN>
<TOKEN id="token-64-4" pos="word" morph="none" start_char="8297" end_char="8304">dictates</TOKEN>
<TOKEN id="token-64-5" pos="word" morph="none" start_char="8306" end_char="8311">ruling</TOKEN>
</SEG>
<SEG id="segment-65" start_char="8315" end_char="8559">
<ORIGINAL_TEXT>There is no better corollary than to end this article with the study that the University of Arizona published on August 14, 2020 titled: "Comparison of electric hand dryers and paper towels for hand hygiene: a critical review of the literature".</ORIGINAL_TEXT>
<TOKEN id="token-65-0" pos="word" morph="none" start_char="8315" end_char="8319">There</TOKEN>
<TOKEN id="token-65-1" pos="word" morph="none" start_char="8321" end_char="8322">is</TOKEN>
<TOKEN id="token-65-2" pos="word" morph="none" start_char="8324" end_char="8325">no</TOKEN>
<TOKEN id="token-65-3" pos="word" morph="none" start_char="8327" end_char="8332">better</TOKEN>
<TOKEN id="token-65-4" pos="word" morph="none" start_char="8334" end_char="8342">corollary</TOKEN>
<TOKEN id="token-65-5" pos="word" morph="none" start_char="8344" end_char="8347">than</TOKEN>
<TOKEN id="token-65-6" pos="word" morph="none" start_char="8349" end_char="8350">to</TOKEN>
<TOKEN id="token-65-7" pos="word" morph="none" start_char="8352" end_char="8354">end</TOKEN>
<TOKEN id="token-65-8" pos="word" morph="none" start_char="8356" end_char="8359">this</TOKEN>
<TOKEN id="token-65-9" pos="word" morph="none" start_char="8361" end_char="8367">article</TOKEN>
<TOKEN id="token-65-10" pos="word" morph="none" start_char="8369" end_char="8372">with</TOKEN>
<TOKEN id="token-65-11" pos="word" morph="none" start_char="8374" end_char="8376">the</TOKEN>
<TOKEN id="token-65-12" pos="word" morph="none" start_char="8378" end_char="8382">study</TOKEN>
<TOKEN id="token-65-13" pos="word" morph="none" start_char="8384" end_char="8387">that</TOKEN>
<TOKEN id="token-65-14" pos="word" morph="none" start_char="8389" end_char="8391">the</TOKEN>
<TOKEN id="token-65-15" pos="word" morph="none" start_char="8393" end_char="8402">University</TOKEN>
<TOKEN id="token-65-16" pos="word" morph="none" start_char="8404" end_char="8405">of</TOKEN>
<TOKEN id="token-65-17" pos="word" morph="none" start_char="8407" end_char="8413">Arizona</TOKEN>
<TOKEN id="token-65-18" pos="word" morph="none" start_char="8415" end_char="8423">published</TOKEN>
<TOKEN id="token-65-19" pos="word" morph="none" start_char="8425" end_char="8426">on</TOKEN>
<TOKEN id="token-65-20" pos="word" morph="none" start_char="8428" end_char="8433">August</TOKEN>
<TOKEN id="token-65-21" pos="word" morph="none" start_char="8435" end_char="8436">14</TOKEN>
<TOKEN id="token-65-22" pos="punct" morph="none" start_char="8437" end_char="8437">,</TOKEN>
<TOKEN id="token-65-23" pos="word" morph="none" start_char="8439" end_char="8442">2020</TOKEN>
<TOKEN id="token-65-24" pos="word" morph="none" start_char="8444" end_char="8449">titled</TOKEN>
<TOKEN id="token-65-25" pos="punct" morph="none" start_char="8450" end_char="8450">:</TOKEN>
<TOKEN id="token-65-26" pos="punct" morph="none" start_char="8452" end_char="8452">"</TOKEN>
<TOKEN id="token-65-27" pos="word" morph="none" start_char="8453" end_char="8462">Comparison</TOKEN>
<TOKEN id="token-65-28" pos="word" morph="none" start_char="8464" end_char="8465">of</TOKEN>
<TOKEN id="token-65-29" pos="word" morph="none" start_char="8467" end_char="8474">electric</TOKEN>
<TOKEN id="token-65-30" pos="word" morph="none" start_char="8476" end_char="8479">hand</TOKEN>
<TOKEN id="token-65-31" pos="word" morph="none" start_char="8481" end_char="8486">dryers</TOKEN>
<TOKEN id="token-65-32" pos="word" morph="none" start_char="8488" end_char="8490">and</TOKEN>
<TOKEN id="token-65-33" pos="word" morph="none" start_char="8492" end_char="8496">paper</TOKEN>
<TOKEN id="token-65-34" pos="word" morph="none" start_char="8498" end_char="8503">towels</TOKEN>
<TOKEN id="token-65-35" pos="word" morph="none" start_char="8505" end_char="8507">for</TOKEN>
<TOKEN id="token-65-36" pos="word" morph="none" start_char="8509" end_char="8512">hand</TOKEN>
<TOKEN id="token-65-37" pos="word" morph="none" start_char="8514" end_char="8520">hygiene</TOKEN>
<TOKEN id="token-65-38" pos="punct" morph="none" start_char="8521" end_char="8521">:</TOKEN>
<TOKEN id="token-65-39" pos="word" morph="none" start_char="8523" end_char="8523">a</TOKEN>
<TOKEN id="token-65-40" pos="word" morph="none" start_char="8525" end_char="8532">critical</TOKEN>
<TOKEN id="token-65-41" pos="word" morph="none" start_char="8534" end_char="8539">review</TOKEN>
<TOKEN id="token-65-42" pos="word" morph="none" start_char="8541" end_char="8542">of</TOKEN>
<TOKEN id="token-65-43" pos="word" morph="none" start_char="8544" end_char="8546">the</TOKEN>
<TOKEN id="token-65-44" pos="word" morph="none" start_char="8548" end_char="8557">literature</TOKEN>
<TOKEN id="token-65-45" pos="punct" morph="none" start_char="8558" end_char="8559">".</TOKEN>
</SEG>
<SEG id="segment-66" start_char="8562" end_char="8728">
<ORIGINAL_TEXT>The authors of this rigorous study analyzed a total of 293 studies on the benefits and drawbacks of drying hands with electric hand dryers and disposable paper towels.</ORIGINAL_TEXT>
<TOKEN id="token-66-0" pos="word" morph="none" start_char="8562" end_char="8564">The</TOKEN>
<TOKEN id="token-66-1" pos="word" morph="none" start_char="8566" end_char="8572">authors</TOKEN>
<TOKEN id="token-66-2" pos="word" morph="none" start_char="8574" end_char="8575">of</TOKEN>
<TOKEN id="token-66-3" pos="word" morph="none" start_char="8577" end_char="8580">this</TOKEN>
<TOKEN id="token-66-4" pos="word" morph="none" start_char="8582" end_char="8589">rigorous</TOKEN>
<TOKEN id="token-66-5" pos="word" morph="none" start_char="8591" end_char="8595">study</TOKEN>
<TOKEN id="token-66-6" pos="word" morph="none" start_char="8597" end_char="8604">analyzed</TOKEN>
<TOKEN id="token-66-7" pos="word" morph="none" start_char="8606" end_char="8606">a</TOKEN>
<TOKEN id="token-66-8" pos="word" morph="none" start_char="8608" end_char="8612">total</TOKEN>
<TOKEN id="token-66-9" pos="word" morph="none" start_char="8614" end_char="8615">of</TOKEN>
<TOKEN id="token-66-10" pos="word" morph="none" start_char="8617" end_char="8619">293</TOKEN>
<TOKEN id="token-66-11" pos="word" morph="none" start_char="8621" end_char="8627">studies</TOKEN>
<TOKEN id="token-66-12" pos="word" morph="none" start_char="8629" end_char="8630">on</TOKEN>
<TOKEN id="token-66-13" pos="word" morph="none" start_char="8632" end_char="8634">the</TOKEN>
<TOKEN id="token-66-14" pos="word" morph="none" start_char="8636" end_char="8643">benefits</TOKEN>
<TOKEN id="token-66-15" pos="word" morph="none" start_char="8645" end_char="8647">and</TOKEN>
<TOKEN id="token-66-16" pos="word" morph="none" start_char="8649" end_char="8657">drawbacks</TOKEN>
<TOKEN id="token-66-17" pos="word" morph="none" start_char="8659" end_char="8660">of</TOKEN>
<TOKEN id="token-66-18" pos="word" morph="none" start_char="8662" end_char="8667">drying</TOKEN>
<TOKEN id="token-66-19" pos="word" morph="none" start_char="8669" end_char="8673">hands</TOKEN>
<TOKEN id="token-66-20" pos="word" morph="none" start_char="8675" end_char="8678">with</TOKEN>
<TOKEN id="token-66-21" pos="word" morph="none" start_char="8680" end_char="8687">electric</TOKEN>
<TOKEN id="token-66-22" pos="word" morph="none" start_char="8689" end_char="8692">hand</TOKEN>
<TOKEN id="token-66-23" pos="word" morph="none" start_char="8694" end_char="8699">dryers</TOKEN>
<TOKEN id="token-66-24" pos="word" morph="none" start_char="8701" end_char="8703">and</TOKEN>
<TOKEN id="token-66-25" pos="word" morph="none" start_char="8705" end_char="8714">disposable</TOKEN>
<TOKEN id="token-66-26" pos="word" morph="none" start_char="8716" end_char="8720">paper</TOKEN>
<TOKEN id="token-66-27" pos="word" morph="none" start_char="8722" end_char="8727">towels</TOKEN>
<TOKEN id="token-66-28" pos="punct" morph="none" start_char="8728" end_char="8728">.</TOKEN>
</SEG>
<SEG id="segment-67" start_char="8730" end_char="8919">
<ORIGINAL_TEXT>The final conclusion was that none of the studied reports provide reliable scientific evidence that one method of drying hands, at the level of disease transmission, is safer than the other.</ORIGINAL_TEXT>
<TOKEN id="token-67-0" pos="word" morph="none" start_char="8730" end_char="8732">The</TOKEN>
<TOKEN id="token-67-1" pos="word" morph="none" start_char="8734" end_char="8738">final</TOKEN>
<TOKEN id="token-67-2" pos="word" morph="none" start_char="8740" end_char="8749">conclusion</TOKEN>
<TOKEN id="token-67-3" pos="word" morph="none" start_char="8751" end_char="8753">was</TOKEN>
<TOKEN id="token-67-4" pos="word" morph="none" start_char="8755" end_char="8758">that</TOKEN>
<TOKEN id="token-67-5" pos="word" morph="none" start_char="8760" end_char="8763">none</TOKEN>
<TOKEN id="token-67-6" pos="word" morph="none" start_char="8765" end_char="8766">of</TOKEN>
<TOKEN id="token-67-7" pos="word" morph="none" start_char="8768" end_char="8770">the</TOKEN>
<TOKEN id="token-67-8" pos="word" morph="none" start_char="8772" end_char="8778">studied</TOKEN>
<TOKEN id="token-67-9" pos="word" morph="none" start_char="8780" end_char="8786">reports</TOKEN>
<TOKEN id="token-67-10" pos="word" morph="none" start_char="8788" end_char="8794">provide</TOKEN>
<TOKEN id="token-67-11" pos="word" morph="none" start_char="8796" end_char="8803">reliable</TOKEN>
<TOKEN id="token-67-12" pos="word" morph="none" start_char="8805" end_char="8814">scientific</TOKEN>
<TOKEN id="token-67-13" pos="word" morph="none" start_char="8816" end_char="8823">evidence</TOKEN>
<TOKEN id="token-67-14" pos="word" morph="none" start_char="8825" end_char="8828">that</TOKEN>
<TOKEN id="token-67-15" pos="word" morph="none" start_char="8830" end_char="8832">one</TOKEN>
<TOKEN id="token-67-16" pos="word" morph="none" start_char="8834" end_char="8839">method</TOKEN>
<TOKEN id="token-67-17" pos="word" morph="none" start_char="8841" end_char="8842">of</TOKEN>
<TOKEN id="token-67-18" pos="word" morph="none" start_char="8844" end_char="8849">drying</TOKEN>
<TOKEN id="token-67-19" pos="word" morph="none" start_char="8851" end_char="8855">hands</TOKEN>
<TOKEN id="token-67-20" pos="punct" morph="none" start_char="8856" end_char="8856">,</TOKEN>
<TOKEN id="token-67-21" pos="word" morph="none" start_char="8858" end_char="8859">at</TOKEN>
<TOKEN id="token-67-22" pos="word" morph="none" start_char="8861" end_char="8863">the</TOKEN>
<TOKEN id="token-67-23" pos="word" morph="none" start_char="8865" end_char="8869">level</TOKEN>
<TOKEN id="token-67-24" pos="word" morph="none" start_char="8871" end_char="8872">of</TOKEN>
<TOKEN id="token-67-25" pos="word" morph="none" start_char="8874" end_char="8880">disease</TOKEN>
<TOKEN id="token-67-26" pos="word" morph="none" start_char="8882" end_char="8893">transmission</TOKEN>
<TOKEN id="token-67-27" pos="punct" morph="none" start_char="8894" end_char="8894">,</TOKEN>
<TOKEN id="token-67-28" pos="word" morph="none" start_char="8896" end_char="8897">is</TOKEN>
<TOKEN id="token-67-29" pos="word" morph="none" start_char="8899" end_char="8903">safer</TOKEN>
<TOKEN id="token-67-30" pos="word" morph="none" start_char="8905" end_char="8908">than</TOKEN>
<TOKEN id="token-67-31" pos="word" morph="none" start_char="8910" end_char="8912">the</TOKEN>
<TOKEN id="token-67-32" pos="word" morph="none" start_char="8914" end_char="8918">other</TOKEN>
<TOKEN id="token-67-33" pos="punct" morph="none" start_char="8919" end_char="8919">.</TOKEN>
</SEG>
<SEG id="segment-68" start_char="8921" end_char="8989">
<ORIGINAL_TEXT>Both methods of hand drying are essentially no better than the other.</ORIGINAL_TEXT>
<TOKEN id="token-68-0" pos="word" morph="none" start_char="8921" end_char="8924">Both</TOKEN>
<TOKEN id="token-68-1" pos="word" morph="none" start_char="8926" end_char="8932">methods</TOKEN>
<TOKEN id="token-68-2" pos="word" morph="none" start_char="8934" end_char="8935">of</TOKEN>
<TOKEN id="token-68-3" pos="word" morph="none" start_char="8937" end_char="8940">hand</TOKEN>
<TOKEN id="token-68-4" pos="word" morph="none" start_char="8942" end_char="8947">drying</TOKEN>
<TOKEN id="token-68-5" pos="word" morph="none" start_char="8949" end_char="8951">are</TOKEN>
<TOKEN id="token-68-6" pos="word" morph="none" start_char="8953" end_char="8963">essentially</TOKEN>
<TOKEN id="token-68-7" pos="word" morph="none" start_char="8965" end_char="8966">no</TOKEN>
<TOKEN id="token-68-8" pos="word" morph="none" start_char="8968" end_char="8973">better</TOKEN>
<TOKEN id="token-68-9" pos="word" morph="none" start_char="8975" end_char="8978">than</TOKEN>
<TOKEN id="token-68-10" pos="word" morph="none" start_char="8980" end_char="8982">the</TOKEN>
<TOKEN id="token-68-11" pos="word" morph="none" start_char="8984" end_char="8988">other</TOKEN>
<TOKEN id="token-68-12" pos="punct" morph="none" start_char="8989" end_char="8989">.</TOKEN>
</SEG>
<SEG id="segment-69" start_char="8992" end_char="9107">
<ORIGINAL_TEXT>I have always believed in science, but today more than ever, I am convinced that without science there is no future.</ORIGINAL_TEXT>
<TOKEN id="token-69-0" pos="word" morph="none" start_char="8992" end_char="8992">I</TOKEN>
<TOKEN id="token-69-1" pos="word" morph="none" start_char="8994" end_char="8997">have</TOKEN>
<TOKEN id="token-69-2" pos="word" morph="none" start_char="8999" end_char="9004">always</TOKEN>
<TOKEN id="token-69-3" pos="word" morph="none" start_char="9006" end_char="9013">believed</TOKEN>
<TOKEN id="token-69-4" pos="word" morph="none" start_char="9015" end_char="9016">in</TOKEN>
<TOKEN id="token-69-5" pos="word" morph="none" start_char="9018" end_char="9024">science</TOKEN>
<TOKEN id="token-69-6" pos="punct" morph="none" start_char="9025" end_char="9025">,</TOKEN>
<TOKEN id="token-69-7" pos="word" morph="none" start_char="9027" end_char="9029">but</TOKEN>
<TOKEN id="token-69-8" pos="word" morph="none" start_char="9031" end_char="9035">today</TOKEN>
<TOKEN id="token-69-9" pos="word" morph="none" start_char="9037" end_char="9040">more</TOKEN>
<TOKEN id="token-69-10" pos="word" morph="none" start_char="9042" end_char="9045">than</TOKEN>
<TOKEN id="token-69-11" pos="word" morph="none" start_char="9047" end_char="9050">ever</TOKEN>
<TOKEN id="token-69-12" pos="punct" morph="none" start_char="9051" end_char="9051">,</TOKEN>
<TOKEN id="token-69-13" pos="word" morph="none" start_char="9053" end_char="9053">I</TOKEN>
<TOKEN id="token-69-14" pos="word" morph="none" start_char="9055" end_char="9056">am</TOKEN>
<TOKEN id="token-69-15" pos="word" morph="none" start_char="9058" end_char="9066">convinced</TOKEN>
<TOKEN id="token-69-16" pos="word" morph="none" start_char="9068" end_char="9071">that</TOKEN>
<TOKEN id="token-69-17" pos="word" morph="none" start_char="9073" end_char="9079">without</TOKEN>
<TOKEN id="token-69-18" pos="word" morph="none" start_char="9081" end_char="9087">science</TOKEN>
<TOKEN id="token-69-19" pos="word" morph="none" start_char="9089" end_char="9093">there</TOKEN>
<TOKEN id="token-69-20" pos="word" morph="none" start_char="9095" end_char="9096">is</TOKEN>
<TOKEN id="token-69-21" pos="word" morph="none" start_char="9098" end_char="9099">no</TOKEN>
<TOKEN id="token-69-22" pos="word" morph="none" start_char="9101" end_char="9106">future</TOKEN>
<TOKEN id="token-69-23" pos="punct" morph="none" start_char="9107" end_char="9107">.</TOKEN>
</SEG>
<SEG id="segment-70" start_char="9109" end_char="9212">
<ORIGINAL_TEXT>Once again, scientists have shown us that it is possible to find solutions to humanity's great problems.</ORIGINAL_TEXT>
<TOKEN id="token-70-0" pos="word" morph="none" start_char="9109" end_char="9112">Once</TOKEN>
<TOKEN id="token-70-1" pos="word" morph="none" start_char="9114" end_char="9118">again</TOKEN>
<TOKEN id="token-70-2" pos="punct" morph="none" start_char="9119" end_char="9119">,</TOKEN>
<TOKEN id="token-70-3" pos="word" morph="none" start_char="9121" end_char="9130">scientists</TOKEN>
<TOKEN id="token-70-4" pos="word" morph="none" start_char="9132" end_char="9135">have</TOKEN>
<TOKEN id="token-70-5" pos="word" morph="none" start_char="9137" end_char="9141">shown</TOKEN>
<TOKEN id="token-70-6" pos="word" morph="none" start_char="9143" end_char="9144">us</TOKEN>
<TOKEN id="token-70-7" pos="word" morph="none" start_char="9146" end_char="9149">that</TOKEN>
<TOKEN id="token-70-8" pos="word" morph="none" start_char="9151" end_char="9152">it</TOKEN>
<TOKEN id="token-70-9" pos="word" morph="none" start_char="9154" end_char="9155">is</TOKEN>
<TOKEN id="token-70-10" pos="word" morph="none" start_char="9157" end_char="9164">possible</TOKEN>
<TOKEN id="token-70-11" pos="word" morph="none" start_char="9166" end_char="9167">to</TOKEN>
<TOKEN id="token-70-12" pos="word" morph="none" start_char="9169" end_char="9172">find</TOKEN>
<TOKEN id="token-70-13" pos="word" morph="none" start_char="9174" end_char="9182">solutions</TOKEN>
<TOKEN id="token-70-14" pos="word" morph="none" start_char="9184" end_char="9185">to</TOKEN>
<TOKEN id="token-70-15" pos="word" morph="none" start_char="9187" end_char="9196">humanity's</TOKEN>
<TOKEN id="token-70-16" pos="word" morph="none" start_char="9198" end_char="9202">great</TOKEN>
<TOKEN id="token-70-17" pos="word" morph="none" start_char="9204" end_char="9211">problems</TOKEN>
<TOKEN id="token-70-18" pos="punct" morph="none" start_char="9212" end_char="9212">.</TOKEN>
</SEG>
<SEG id="segment-71" start_char="9214" end_char="9362">
<ORIGINAL_TEXT>Personally, I am very proud to be able to contribute to the well-being and safety of other individuals, helping them in their daily personal hygiene.</ORIGINAL_TEXT>
<TOKEN id="token-71-0" pos="word" morph="none" start_char="9214" end_char="9223">Personally</TOKEN>
<TOKEN id="token-71-1" pos="punct" morph="none" start_char="9224" end_char="9224">,</TOKEN>
<TOKEN id="token-71-2" pos="word" morph="none" start_char="9226" end_char="9226">I</TOKEN>
<TOKEN id="token-71-3" pos="word" morph="none" start_char="9228" end_char="9229">am</TOKEN>
<TOKEN id="token-71-4" pos="word" morph="none" start_char="9231" end_char="9234">very</TOKEN>
<TOKEN id="token-71-5" pos="word" morph="none" start_char="9236" end_char="9240">proud</TOKEN>
<TOKEN id="token-71-6" pos="word" morph="none" start_char="9242" end_char="9243">to</TOKEN>
<TOKEN id="token-71-7" pos="word" morph="none" start_char="9245" end_char="9246">be</TOKEN>
<TOKEN id="token-71-8" pos="word" morph="none" start_char="9248" end_char="9251">able</TOKEN>
<TOKEN id="token-71-9" pos="word" morph="none" start_char="9253" end_char="9254">to</TOKEN>
<TOKEN id="token-71-10" pos="word" morph="none" start_char="9256" end_char="9265">contribute</TOKEN>
<TOKEN id="token-71-11" pos="word" morph="none" start_char="9267" end_char="9268">to</TOKEN>
<TOKEN id="token-71-12" pos="word" morph="none" start_char="9270" end_char="9272">the</TOKEN>
<TOKEN id="token-71-13" pos="unknown" morph="none" start_char="9274" end_char="9283">well-being</TOKEN>
<TOKEN id="token-71-14" pos="word" morph="none" start_char="9285" end_char="9287">and</TOKEN>
<TOKEN id="token-71-15" pos="word" morph="none" start_char="9289" end_char="9294">safety</TOKEN>
<TOKEN id="token-71-16" pos="word" morph="none" start_char="9296" end_char="9297">of</TOKEN>
<TOKEN id="token-71-17" pos="word" morph="none" start_char="9299" end_char="9303">other</TOKEN>
<TOKEN id="token-71-18" pos="word" morph="none" start_char="9305" end_char="9315">individuals</TOKEN>
<TOKEN id="token-71-19" pos="punct" morph="none" start_char="9316" end_char="9316">,</TOKEN>
<TOKEN id="token-71-20" pos="word" morph="none" start_char="9318" end_char="9324">helping</TOKEN>
<TOKEN id="token-71-21" pos="word" morph="none" start_char="9326" end_char="9329">them</TOKEN>
<TOKEN id="token-71-22" pos="word" morph="none" start_char="9331" end_char="9332">in</TOKEN>
<TOKEN id="token-71-23" pos="word" morph="none" start_char="9334" end_char="9338">their</TOKEN>
<TOKEN id="token-71-24" pos="word" morph="none" start_char="9340" end_char="9344">daily</TOKEN>
<TOKEN id="token-71-25" pos="word" morph="none" start_char="9346" end_char="9353">personal</TOKEN>
<TOKEN id="token-71-26" pos="word" morph="none" start_char="9355" end_char="9361">hygiene</TOKEN>
<TOKEN id="token-71-27" pos="punct" morph="none" start_char="9362" end_char="9362">.</TOKEN>
</SEG>
<SEG id="segment-72" start_char="9364" end_char="9573">
<ORIGINAL_TEXT>It is for this reason that I want to send my sincere thanks to science for continuously providing the tools necessary for us to work with at our fingertips, and thus helping us to learn and be better every day.</ORIGINAL_TEXT>
<TOKEN id="token-72-0" pos="word" morph="none" start_char="9364" end_char="9365">It</TOKEN>
<TOKEN id="token-72-1" pos="word" morph="none" start_char="9367" end_char="9368">is</TOKEN>
<TOKEN id="token-72-2" pos="word" morph="none" start_char="9370" end_char="9372">for</TOKEN>
<TOKEN id="token-72-3" pos="word" morph="none" start_char="9374" end_char="9377">this</TOKEN>
<TOKEN id="token-72-4" pos="word" morph="none" start_char="9379" end_char="9384">reason</TOKEN>
<TOKEN id="token-72-5" pos="word" morph="none" start_char="9386" end_char="9389">that</TOKEN>
<TOKEN id="token-72-6" pos="word" morph="none" start_char="9391" end_char="9391">I</TOKEN>
<TOKEN id="token-72-7" pos="word" morph="none" start_char="9393" end_char="9396">want</TOKEN>
<TOKEN id="token-72-8" pos="word" morph="none" start_char="9398" end_char="9399">to</TOKEN>
<TOKEN id="token-72-9" pos="word" morph="none" start_char="9401" end_char="9404">send</TOKEN>
<TOKEN id="token-72-10" pos="word" morph="none" start_char="9406" end_char="9407">my</TOKEN>
<TOKEN id="token-72-11" pos="word" morph="none" start_char="9409" end_char="9415">sincere</TOKEN>
<TOKEN id="token-72-12" pos="word" morph="none" start_char="9417" end_char="9422">thanks</TOKEN>
<TOKEN id="token-72-13" pos="word" morph="none" start_char="9424" end_char="9425">to</TOKEN>
<TOKEN id="token-72-14" pos="word" morph="none" start_char="9427" end_char="9433">science</TOKEN>
<TOKEN id="token-72-15" pos="word" morph="none" start_char="9435" end_char="9437">for</TOKEN>
<TOKEN id="token-72-16" pos="word" morph="none" start_char="9439" end_char="9450">continuously</TOKEN>
<TOKEN id="token-72-17" pos="word" morph="none" start_char="9452" end_char="9460">providing</TOKEN>
<TOKEN id="token-72-18" pos="word" morph="none" start_char="9462" end_char="9464">the</TOKEN>
<TOKEN id="token-72-19" pos="word" morph="none" start_char="9466" end_char="9470">tools</TOKEN>
<TOKEN id="token-72-20" pos="word" morph="none" start_char="9472" end_char="9480">necessary</TOKEN>
<TOKEN id="token-72-21" pos="word" morph="none" start_char="9482" end_char="9484">for</TOKEN>
<TOKEN id="token-72-22" pos="word" morph="none" start_char="9486" end_char="9487">us</TOKEN>
<TOKEN id="token-72-23" pos="word" morph="none" start_char="9489" end_char="9490">to</TOKEN>
<TOKEN id="token-72-24" pos="word" morph="none" start_char="9492" end_char="9495">work</TOKEN>
<TOKEN id="token-72-25" pos="word" morph="none" start_char="9497" end_char="9500">with</TOKEN>
<TOKEN id="token-72-26" pos="word" morph="none" start_char="9502" end_char="9503">at</TOKEN>
<TOKEN id="token-72-27" pos="word" morph="none" start_char="9505" end_char="9507">our</TOKEN>
<TOKEN id="token-72-28" pos="word" morph="none" start_char="9509" end_char="9518">fingertips</TOKEN>
<TOKEN id="token-72-29" pos="punct" morph="none" start_char="9519" end_char="9519">,</TOKEN>
<TOKEN id="token-72-30" pos="word" morph="none" start_char="9521" end_char="9523">and</TOKEN>
<TOKEN id="token-72-31" pos="word" morph="none" start_char="9525" end_char="9528">thus</TOKEN>
<TOKEN id="token-72-32" pos="word" morph="none" start_char="9530" end_char="9536">helping</TOKEN>
<TOKEN id="token-72-33" pos="word" morph="none" start_char="9538" end_char="9539">us</TOKEN>
<TOKEN id="token-72-34" pos="word" morph="none" start_char="9541" end_char="9542">to</TOKEN>
<TOKEN id="token-72-35" pos="word" morph="none" start_char="9544" end_char="9548">learn</TOKEN>
<TOKEN id="token-72-36" pos="word" morph="none" start_char="9550" end_char="9552">and</TOKEN>
<TOKEN id="token-72-37" pos="word" morph="none" start_char="9554" end_char="9555">be</TOKEN>
<TOKEN id="token-72-38" pos="word" morph="none" start_char="9557" end_char="9562">better</TOKEN>
<TOKEN id="token-72-39" pos="word" morph="none" start_char="9564" end_char="9568">every</TOKEN>
<TOKEN id="token-72-40" pos="word" morph="none" start_char="9570" end_char="9572">day</TOKEN>
<TOKEN id="token-72-41" pos="punct" morph="none" start_char="9573" end_char="9573">.</TOKEN>
</SEG>
<SEG id="segment-73" start_char="9576" end_char="9596">
<ORIGINAL_TEXT>German Muñoz Bassedas</ORIGINAL_TEXT>
<TOKEN id="token-73-0" pos="word" morph="none" start_char="9576" end_char="9581">German</TOKEN>
<TOKEN id="token-73-1" pos="word" morph="none" start_char="9583" end_char="9587">Muñoz</TOKEN>
<TOKEN id="token-73-2" pos="word" morph="none" start_char="9589" end_char="9596">Bassedas</TOKEN>
</SEG>
<SEG id="segment-74" start_char="9600" end_char="9637">
<ORIGINAL_TEXT>Marketing Director at Mediclinics S.A.</ORIGINAL_TEXT>
<TOKEN id="token-74-0" pos="word" morph="none" start_char="9600" end_char="9608">Marketing</TOKEN>
<TOKEN id="token-74-1" pos="word" morph="none" start_char="9610" end_char="9617">Director</TOKEN>
<TOKEN id="token-74-2" pos="word" morph="none" start_char="9619" end_char="9620">at</TOKEN>
<TOKEN id="token-74-3" pos="word" morph="none" start_char="9622" end_char="9632">Mediclinics</TOKEN>
<TOKEN id="token-74-4" pos="unknown" morph="none" start_char="9634" end_char="9636">S.A</TOKEN>
<TOKEN id="token-74-5" pos="punct" morph="none" start_char="9637" end_char="9637">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
