<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="ukr">
<DOC id="L0C049PAM" lang="ukr" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="5956" raw_text_md5="72c8a22f8f4ed27392e55c2b07e62f23">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="73">
<ORIGINAL_TEXT>Scientists are still searching for the source of COVID-19: why it matters</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="10">Scientists</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="12" end_char="14">are</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="16" end_char="20">still</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="22" end_char="30">searching</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="32" end_char="34">for</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="36" end_char="38">the</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="40" end_char="45">source</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="47" end_char="48">of</TOKEN>
<TOKEN id="token-0-8" pos="unknown" morph="none" start_char="50" end_char="57">COVID-19</TOKEN>
<TOKEN id="token-0-9" pos="punct" morph="none" start_char="58" end_char="58">:</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="60" end_char="62">why</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="64" end_char="65">it</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="67" end_char="73">matters</TOKEN>
</SEG>
<SEG id="segment-1" start_char="77" end_char="170">
<ORIGINAL_TEXT>The number of new cases at the epicentre of China’s coronavirus epidemic dropped to a new low.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="77" end_char="79">The</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="81" end_char="86">number</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="88" end_char="89">of</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="91" end_char="93">new</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="95" end_char="99">cases</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="101" end_char="102">at</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="104" end_char="106">the</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="108" end_char="116">epicentre</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="118" end_char="119">of</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="121" end_char="127">China’s</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="129" end_char="139">coronavirus</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="141" end_char="148">epidemic</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="150" end_char="156">dropped</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="158" end_char="159">to</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="161" end_char="161">a</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="163" end_char="165">new</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="167" end_char="169">low</TOKEN>
<TOKEN id="token-1-17" pos="punct" morph="none" start_char="170" end_char="170">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="174" end_char="282">
<ORIGINAL_TEXT>The current COVID-19 outbreak is driven by a novel coronavirus (SARS CoV-2) that is spreading between people.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="174" end_char="176">The</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="178" end_char="184">current</TOKEN>
<TOKEN id="token-2-2" pos="unknown" morph="none" start_char="186" end_char="193">COVID-19</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="195" end_char="202">outbreak</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="204" end_char="205">is</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="207" end_char="212">driven</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="214" end_char="215">by</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="217" end_char="217">a</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="219" end_char="223">novel</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="225" end_char="235">coronavirus</TOKEN>
<TOKEN id="token-2-10" pos="punct" morph="none" start_char="237" end_char="237">(</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="238" end_char="241">SARS</TOKEN>
<TOKEN id="token-2-12" pos="unknown" morph="none" start_char="243" end_char="247">CoV-2</TOKEN>
<TOKEN id="token-2-13" pos="punct" morph="none" start_char="248" end_char="248">)</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="250" end_char="253">that</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="255" end_char="256">is</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="258" end_char="266">spreading</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="268" end_char="274">between</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="276" end_char="281">people</TOKEN>
<TOKEN id="token-2-19" pos="punct" morph="none" start_char="282" end_char="282">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="284" end_char="438">
<ORIGINAL_TEXT>The first human infections were reported at the end of December 2019 in Wuhan, Hubei province in China when a cluster of 41 pneumonia cases was identified.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="284" end_char="286">The</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="288" end_char="292">first</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="294" end_char="298">human</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="300" end_char="309">infections</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="311" end_char="314">were</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="316" end_char="323">reported</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="325" end_char="326">at</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="328" end_char="330">the</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="332" end_char="334">end</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="336" end_char="337">of</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="339" end_char="346">December</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="348" end_char="351">2019</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="353" end_char="354">in</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="356" end_char="360">Wuhan</TOKEN>
<TOKEN id="token-3-14" pos="punct" morph="none" start_char="361" end_char="361">,</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="363" end_char="367">Hubei</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="369" end_char="376">province</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="378" end_char="379">in</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="381" end_char="385">China</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="387" end_char="390">when</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="392" end_char="392">a</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="394" end_char="400">cluster</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="402" end_char="403">of</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="405" end_char="406">41</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="408" end_char="416">pneumonia</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="418" end_char="422">cases</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="424" end_char="426">was</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="428" end_char="437">identified</TOKEN>
<TOKEN id="token-3-28" pos="punct" morph="none" start_char="438" end_char="438">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="440" end_char="494">
<ORIGINAL_TEXT>Deeper analysis showed that it was a novel coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="440" end_char="445">Deeper</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="447" end_char="454">analysis</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="456" end_char="461">showed</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="463" end_char="466">that</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="468" end_char="469">it</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="471" end_char="473">was</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="475" end_char="475">a</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="477" end_char="481">novel</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="483" end_char="493">coronavirus</TOKEN>
<TOKEN id="token-4-9" pos="punct" morph="none" start_char="494" end_char="494">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="497" end_char="574">
<ORIGINAL_TEXT>A third – 66% of the cases – had direct exposure to the Huanan Seafood market.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="497" end_char="497">A</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="499" end_char="503">third</TOKEN>
<TOKEN id="token-5-2" pos="punct" morph="none" start_char="505" end_char="505">–</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="507" end_char="508">66</TOKEN>
<TOKEN id="token-5-4" pos="punct" morph="none" start_char="509" end_char="509">%</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="511" end_char="512">of</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="514" end_char="516">the</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="518" end_char="522">cases</TOKEN>
<TOKEN id="token-5-8" pos="punct" morph="none" start_char="524" end_char="524">–</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="526" end_char="528">had</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="530" end_char="535">direct</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="537" end_char="544">exposure</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="546" end_char="547">to</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="549" end_char="551">the</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="553" end_char="558">Huanan</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="560" end_char="566">Seafood</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="568" end_char="573">market</TOKEN>
<TOKEN id="token-5-17" pos="punct" morph="none" start_char="574" end_char="574">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="576" end_char="691">
<ORIGINAL_TEXT>Fish, shellfish, wildlife, snakes, birds and several different types of meat and carcasses were sold at this market.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="576" end_char="579">Fish</TOKEN>
<TOKEN id="token-6-1" pos="punct" morph="none" start_char="580" end_char="580">,</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="582" end_char="590">shellfish</TOKEN>
<TOKEN id="token-6-3" pos="punct" morph="none" start_char="591" end_char="591">,</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="593" end_char="600">wildlife</TOKEN>
<TOKEN id="token-6-5" pos="punct" morph="none" start_char="601" end_char="601">,</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="603" end_char="608">snakes</TOKEN>
<TOKEN id="token-6-7" pos="punct" morph="none" start_char="609" end_char="609">,</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="611" end_char="615">birds</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="617" end_char="619">and</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="621" end_char="627">several</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="629" end_char="637">different</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="639" end_char="643">types</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="645" end_char="646">of</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="648" end_char="651">meat</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="653" end_char="655">and</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="657" end_char="665">carcasses</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="667" end_char="670">were</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="672" end_char="675">sold</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="677" end_char="678">at</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="680" end_char="683">this</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="685" end_char="690">market</TOKEN>
<TOKEN id="token-6-22" pos="punct" morph="none" start_char="691" end_char="691">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="693" end_char="757">
<ORIGINAL_TEXT>The market was closed immediately, and it has not reopened since.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="693" end_char="695">The</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="697" end_char="702">market</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="704" end_char="706">was</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="708" end_char="713">closed</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="715" end_char="725">immediately</TOKEN>
<TOKEN id="token-7-5" pos="punct" morph="none" start_char="726" end_char="726">,</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="728" end_char="730">and</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="732" end_char="733">it</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="735" end_char="737">has</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="739" end_char="741">not</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="743" end_char="750">reopened</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="752" end_char="756">since</TOKEN>
<TOKEN id="token-7-12" pos="punct" morph="none" start_char="757" end_char="757">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="760" end_char="870">
<ORIGINAL_TEXT>Scientists around the world have been working around the clock to identify the pathogen behind the new illness.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="760" end_char="769">Scientists</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="771" end_char="776">around</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="778" end_char="780">the</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="782" end_char="786">world</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="788" end_char="791">have</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="793" end_char="796">been</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="798" end_char="804">working</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="806" end_char="811">around</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="813" end_char="815">the</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="817" end_char="821">clock</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="823" end_char="824">to</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="826" end_char="833">identify</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="835" end_char="837">the</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="839" end_char="846">pathogen</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="848" end_char="853">behind</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="855" end_char="857">the</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="859" end_char="861">new</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="863" end_char="869">illness</TOKEN>
<TOKEN id="token-8-18" pos="punct" morph="none" start_char="870" end_char="870">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="873" end_char="1039">
<ORIGINAL_TEXT>Information that gave the first clues was released in mid-January 2020 when the full viral genomic sequence of the new coronavirus from a patient sample was published.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="873" end_char="883">Information</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="885" end_char="888">that</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="890" end_char="893">gave</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="895" end_char="897">the</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="899" end_char="903">first</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="905" end_char="909">clues</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="911" end_char="913">was</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="915" end_char="922">released</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="924" end_char="925">in</TOKEN>
<TOKEN id="token-9-9" pos="unknown" morph="none" start_char="927" end_char="937">mid-January</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="939" end_char="942">2020</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="944" end_char="947">when</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="949" end_char="951">the</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="953" end_char="956">full</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="958" end_char="962">viral</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="964" end_char="970">genomic</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="972" end_char="979">sequence</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="981" end_char="982">of</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="984" end_char="986">the</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="988" end_char="990">new</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="992" end_char="1002">coronavirus</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1004" end_char="1007">from</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1009" end_char="1009">a</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1011" end_char="1017">patient</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1019" end_char="1024">sample</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1026" end_char="1028">was</TOKEN>
<TOKEN id="token-9-26" pos="word" morph="none" start_char="1030" end_char="1038">published</TOKEN>
<TOKEN id="token-9-27" pos="punct" morph="none" start_char="1039" end_char="1039">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1041" end_char="1218">
<ORIGINAL_TEXT>It showed a new coronavirus – SARS-CoV2 – belonging to the same group as the severe acute respiratory syndrome-related coronavirus (SARS-CoV) which caused the 2003 SARS outbreak.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1041" end_char="1042">It</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1044" end_char="1049">showed</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1051" end_char="1051">a</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1053" end_char="1055">new</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1057" end_char="1067">coronavirus</TOKEN>
<TOKEN id="token-10-5" pos="punct" morph="none" start_char="1069" end_char="1069">–</TOKEN>
<TOKEN id="token-10-6" pos="unknown" morph="none" start_char="1071" end_char="1079">SARS-CoV2</TOKEN>
<TOKEN id="token-10-7" pos="punct" morph="none" start_char="1081" end_char="1081">–</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1083" end_char="1091">belonging</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1093" end_char="1094">to</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1096" end_char="1098">the</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1100" end_char="1103">same</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1105" end_char="1109">group</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1111" end_char="1112">as</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1114" end_char="1116">the</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1118" end_char="1123">severe</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1125" end_char="1129">acute</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1131" end_char="1141">respiratory</TOKEN>
<TOKEN id="token-10-18" pos="unknown" morph="none" start_char="1143" end_char="1158">syndrome-related</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1160" end_char="1170">coronavirus</TOKEN>
<TOKEN id="token-10-20" pos="punct" morph="none" start_char="1172" end_char="1172">(</TOKEN>
<TOKEN id="token-10-21" pos="unknown" morph="none" start_char="1173" end_char="1180">SARS-CoV</TOKEN>
<TOKEN id="token-10-22" pos="punct" morph="none" start_char="1181" end_char="1181">)</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1183" end_char="1187">which</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1189" end_char="1194">caused</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="1196" end_char="1198">the</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="1200" end_char="1203">2003</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="1205" end_char="1208">SARS</TOKEN>
<TOKEN id="token-10-28" pos="word" morph="none" start_char="1210" end_char="1217">outbreak</TOKEN>
<TOKEN id="token-10-29" pos="punct" morph="none" start_char="1218" end_char="1218">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1221" end_char="1297">
<ORIGINAL_TEXT>But the new virus differed significantly, raising questions about its origin.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1221" end_char="1223">But</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1225" end_char="1227">the</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1229" end_char="1231">new</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1233" end_char="1237">virus</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1239" end_char="1246">differed</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1248" end_char="1260">significantly</TOKEN>
<TOKEN id="token-11-6" pos="punct" morph="none" start_char="1261" end_char="1261">,</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1263" end_char="1269">raising</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1271" end_char="1279">questions</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1281" end_char="1285">about</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1287" end_char="1289">its</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1291" end_char="1296">origin</TOKEN>
<TOKEN id="token-11-12" pos="punct" morph="none" start_char="1297" end_char="1297">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1299" end_char="1456">
<ORIGINAL_TEXT>The strongest speculation has been that the virus is somehow linked to the market given two thirds of the first batch of people infected had had ties with it.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1299" end_char="1301">The</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1303" end_char="1311">strongest</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1313" end_char="1323">speculation</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1325" end_char="1327">has</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1329" end_char="1332">been</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1334" end_char="1337">that</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1339" end_char="1341">the</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1343" end_char="1347">virus</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1349" end_char="1350">is</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1352" end_char="1358">somehow</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1360" end_char="1365">linked</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1367" end_char="1368">to</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1370" end_char="1372">the</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1374" end_char="1379">market</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1381" end_char="1385">given</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1387" end_char="1389">two</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1391" end_char="1396">thirds</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1398" end_char="1399">of</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1401" end_char="1403">the</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1405" end_char="1409">first</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1411" end_char="1415">batch</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1417" end_char="1418">of</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1420" end_char="1425">people</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="1427" end_char="1434">infected</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="1436" end_char="1438">had</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="1440" end_char="1442">had</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="1444" end_char="1447">ties</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="1449" end_char="1452">with</TOKEN>
<TOKEN id="token-12-28" pos="word" morph="none" start_char="1454" end_char="1455">it</TOKEN>
<TOKEN id="token-12-29" pos="punct" morph="none" start_char="1456" end_char="1456">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1458" end_char="1494">
<ORIGINAL_TEXT>But even this hasn’t been proved yet.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1458" end_char="1460">But</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1462" end_char="1465">even</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1467" end_char="1470">this</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1472" end_char="1477">hasn’t</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1479" end_char="1482">been</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1484" end_char="1489">proved</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1491" end_char="1493">yet</TOKEN>
<TOKEN id="token-13-7" pos="punct" morph="none" start_char="1494" end_char="1494">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1496" end_char="1681">
<ORIGINAL_TEXT>And subsequent investigations indicate that the first patient – who started experiencing symptoms as early as 1 December 2019 – had no reported link to the market, or the other patients.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1496" end_char="1498">And</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1500" end_char="1509">subsequent</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1511" end_char="1524">investigations</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1526" end_char="1533">indicate</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1535" end_char="1538">that</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1540" end_char="1542">the</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1544" end_char="1548">first</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1550" end_char="1556">patient</TOKEN>
<TOKEN id="token-14-8" pos="punct" morph="none" start_char="1558" end_char="1558">–</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1560" end_char="1562">who</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1564" end_char="1570">started</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1572" end_char="1583">experiencing</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1585" end_char="1592">symptoms</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1594" end_char="1595">as</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="1597" end_char="1601">early</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1603" end_char="1604">as</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1606" end_char="1606">1</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="1608" end_char="1615">December</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="1617" end_char="1620">2019</TOKEN>
<TOKEN id="token-14-19" pos="punct" morph="none" start_char="1622" end_char="1622">–</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="1624" end_char="1626">had</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="1628" end_char="1629">no</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="1631" end_char="1638">reported</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="1640" end_char="1643">link</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="1645" end_char="1646">to</TOKEN>
<TOKEN id="token-14-25" pos="word" morph="none" start_char="1648" end_char="1650">the</TOKEN>
<TOKEN id="token-14-26" pos="word" morph="none" start_char="1652" end_char="1657">market</TOKEN>
<TOKEN id="token-14-27" pos="punct" morph="none" start_char="1658" end_char="1658">,</TOKEN>
<TOKEN id="token-14-28" pos="word" morph="none" start_char="1660" end_char="1661">or</TOKEN>
<TOKEN id="token-14-29" pos="word" morph="none" start_char="1663" end_char="1665">the</TOKEN>
<TOKEN id="token-14-30" pos="word" morph="none" start_char="1667" end_char="1671">other</TOKEN>
<TOKEN id="token-14-31" pos="word" morph="none" start_char="1673" end_char="1680">patients</TOKEN>
<TOKEN id="token-14-32" pos="punct" morph="none" start_char="1681" end_char="1681">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1684" end_char="1708">
<ORIGINAL_TEXT>Several questions remain.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1684" end_char="1690">Several</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1692" end_char="1700">questions</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1702" end_char="1707">remain</TOKEN>
<TOKEN id="token-15-3" pos="punct" morph="none" start_char="1708" end_char="1708">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1710" end_char="1772">
<ORIGINAL_TEXT>Most importantly, there’s no clear data on what the source was.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1710" end_char="1713">Most</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1715" end_char="1725">importantly</TOKEN>
<TOKEN id="token-16-2" pos="punct" morph="none" start_char="1726" end_char="1726">,</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1728" end_char="1734">there’s</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1736" end_char="1737">no</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1739" end_char="1743">clear</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1745" end_char="1748">data</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1750" end_char="1751">on</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1753" end_char="1756">what</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="1758" end_char="1760">the</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="1762" end_char="1767">source</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="1769" end_char="1771">was</TOKEN>
<TOKEN id="token-16-12" pos="punct" morph="none" start_char="1772" end_char="1772">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1774" end_char="1897">
<ORIGINAL_TEXT>But tracking down the origin of the illness is important because it’s essential to know who or what infected "patient zero".</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1774" end_char="1776">But</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1778" end_char="1785">tracking</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="1787" end_char="1790">down</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="1792" end_char="1794">the</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="1796" end_char="1801">origin</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="1803" end_char="1804">of</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="1806" end_char="1808">the</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="1810" end_char="1816">illness</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="1818" end_char="1819">is</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="1821" end_char="1829">important</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="1831" end_char="1837">because</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="1839" end_char="1842">it’s</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="1844" end_char="1852">essential</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="1854" end_char="1855">to</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="1857" end_char="1860">know</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="1862" end_char="1864">who</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="1866" end_char="1867">or</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="1869" end_char="1872">what</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="1874" end_char="1881">infected</TOKEN>
<TOKEN id="token-17-19" pos="punct" morph="none" start_char="1883" end_char="1883">"</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="1884" end_char="1890">patient</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="1892" end_char="1895">zero</TOKEN>
<TOKEN id="token-17-22" pos="punct" morph="none" start_char="1896" end_char="1897">".</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1899" end_char="2066">
<ORIGINAL_TEXT>Understanding the specific circumstances, including human behaviour and activities, that led to this pandemic may provide clues about risk factors for future outbreaks.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="1899" end_char="1911">Understanding</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="1913" end_char="1915">the</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="1917" end_char="1924">specific</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="1926" end_char="1938">circumstances</TOKEN>
<TOKEN id="token-18-4" pos="punct" morph="none" start_char="1939" end_char="1939">,</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="1941" end_char="1949">including</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="1951" end_char="1955">human</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="1957" end_char="1965">behaviour</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="1967" end_char="1969">and</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="1971" end_char="1980">activities</TOKEN>
<TOKEN id="token-18-10" pos="punct" morph="none" start_char="1981" end_char="1981">,</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="1983" end_char="1986">that</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="1988" end_char="1990">led</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="1992" end_char="1993">to</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="1995" end_char="1998">this</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="2000" end_char="2007">pandemic</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="2009" end_char="2011">may</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="2013" end_char="2019">provide</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="2021" end_char="2025">clues</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="2027" end_char="2031">about</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="2033" end_char="2036">risk</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="2038" end_char="2044">factors</TOKEN>
<TOKEN id="token-18-22" pos="word" morph="none" start_char="2046" end_char="2048">for</TOKEN>
<TOKEN id="token-18-23" pos="word" morph="none" start_char="2050" end_char="2055">future</TOKEN>
<TOKEN id="token-18-24" pos="word" morph="none" start_char="2057" end_char="2065">outbreaks</TOKEN>
<TOKEN id="token-18-25" pos="punct" morph="none" start_char="2066" end_char="2066">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2069" end_char="2085">
<ORIGINAL_TEXT>Shots in the dark</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2069" end_char="2073">Shots</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2075" end_char="2076">in</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2078" end_char="2080">the</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2082" end_char="2085">dark</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2089" end_char="2171">
<ORIGINAL_TEXT>There has been a great deal of speculation about the source of the new coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2089" end_char="2093">There</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2095" end_char="2097">has</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2099" end_char="2102">been</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2104" end_char="2104">a</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2106" end_char="2110">great</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2112" end_char="2115">deal</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2117" end_char="2118">of</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2120" end_char="2130">speculation</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="2132" end_char="2136">about</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2138" end_char="2140">the</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2142" end_char="2147">source</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="2149" end_char="2150">of</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="2152" end_char="2154">the</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="2156" end_char="2158">new</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="2160" end_char="2170">coronavirus</TOKEN>
<TOKEN id="token-20-15" pos="punct" morph="none" start_char="2171" end_char="2171">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2173" end_char="2264">
<ORIGINAL_TEXT>Soon after the reports of the first cases being identified a range of theories were floated.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2173" end_char="2176">Soon</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2178" end_char="2182">after</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2184" end_char="2186">the</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2188" end_char="2194">reports</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2196" end_char="2197">of</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="2199" end_char="2201">the</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2203" end_char="2207">first</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="2209" end_char="2213">cases</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="2215" end_char="2219">being</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="2221" end_char="2230">identified</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="2232" end_char="2232">a</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="2234" end_char="2238">range</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="2240" end_char="2241">of</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="2243" end_char="2250">theories</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="2252" end_char="2255">were</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="2257" end_char="2263">floated</TOKEN>
<TOKEN id="token-21-16" pos="punct" morph="none" start_char="2264" end_char="2264">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2266" end_char="2374">
<ORIGINAL_TEXT>These included reports that the virus was leaked from the laboratory at the Wuhan Centre for Disease Control.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2266" end_char="2270">These</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2272" end_char="2279">included</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2281" end_char="2287">reports</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2289" end_char="2292">that</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2294" end_char="2296">the</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2298" end_char="2302">virus</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2304" end_char="2306">was</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2308" end_char="2313">leaked</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="2315" end_char="2318">from</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="2320" end_char="2322">the</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="2324" end_char="2333">laboratory</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="2335" end_char="2336">at</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="2338" end_char="2340">the</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="2342" end_char="2346">Wuhan</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="2348" end_char="2353">Centre</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="2355" end_char="2357">for</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="2359" end_char="2365">Disease</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="2367" end_char="2373">Control</TOKEN>
<TOKEN id="token-22-18" pos="punct" morph="none" start_char="2374" end_char="2374">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2376" end_char="2515">
<ORIGINAL_TEXT>A number of renowned scientists issued a statement condemning "conspiracy theories suggesting that COVID-19 does not have a natural origin".</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2376" end_char="2376">A</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2378" end_char="2383">number</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2385" end_char="2386">of</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2388" end_char="2395">renowned</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="2397" end_char="2406">scientists</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="2408" end_char="2413">issued</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="2415" end_char="2415">a</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="2417" end_char="2425">statement</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="2427" end_char="2436">condemning</TOKEN>
<TOKEN id="token-23-9" pos="punct" morph="none" start_char="2438" end_char="2438">"</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="2439" end_char="2448">conspiracy</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="2450" end_char="2457">theories</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="2459" end_char="2468">suggesting</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="2470" end_char="2473">that</TOKEN>
<TOKEN id="token-23-14" pos="unknown" morph="none" start_char="2475" end_char="2482">COVID-19</TOKEN>
<TOKEN id="token-23-15" pos="word" morph="none" start_char="2484" end_char="2487">does</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="2489" end_char="2491">not</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="2493" end_char="2496">have</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="2498" end_char="2498">a</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="2500" end_char="2506">natural</TOKEN>
<TOKEN id="token-23-20" pos="word" morph="none" start_char="2508" end_char="2513">origin</TOKEN>
<TOKEN id="token-23-21" pos="punct" morph="none" start_char="2514" end_char="2515">".</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2518" end_char="2603">
<ORIGINAL_TEXT>Similarly, the theory that the virus originated from snakes was subsequently debunked.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="2518" end_char="2526">Similarly</TOKEN>
<TOKEN id="token-24-1" pos="punct" morph="none" start_char="2527" end_char="2527">,</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="2529" end_char="2531">the</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="2533" end_char="2538">theory</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="2540" end_char="2543">that</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="2545" end_char="2547">the</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="2549" end_char="2553">virus</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="2555" end_char="2564">originated</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="2566" end_char="2569">from</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="2571" end_char="2576">snakes</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="2578" end_char="2580">was</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="2582" end_char="2593">subsequently</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="2595" end_char="2602">debunked</TOKEN>
<TOKEN id="token-24-13" pos="punct" morph="none" start_char="2603" end_char="2603">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2606" end_char="2733">
<ORIGINAL_TEXT>Misinformation like this was fuelled by early reports that suggested a link between the market, animals and the new coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="2606" end_char="2619">Misinformation</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="2621" end_char="2624">like</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="2626" end_char="2629">this</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="2631" end_char="2633">was</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="2635" end_char="2641">fuelled</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="2643" end_char="2644">by</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="2646" end_char="2650">early</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="2652" end_char="2658">reports</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="2660" end_char="2663">that</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="2665" end_char="2673">suggested</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="2675" end_char="2675">a</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="2677" end_char="2680">link</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="2682" end_char="2688">between</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="2690" end_char="2692">the</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="2694" end_char="2699">market</TOKEN>
<TOKEN id="token-25-15" pos="punct" morph="none" start_char="2700" end_char="2700">,</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="2702" end_char="2708">animals</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="2710" end_char="2712">and</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="2714" end_char="2716">the</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="2718" end_char="2720">new</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="2722" end_char="2732">coronavirus</TOKEN>
<TOKEN id="token-25-21" pos="punct" morph="none" start_char="2733" end_char="2733">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="2735" end_char="2772">
<ORIGINAL_TEXT>But this has never been substantiated.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="2735" end_char="2737">But</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="2739" end_char="2742">this</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="2744" end_char="2746">has</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="2748" end_char="2752">never</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="2754" end_char="2757">been</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="2759" end_char="2771">substantiated</TOKEN>
<TOKEN id="token-26-6" pos="punct" morph="none" start_char="2772" end_char="2772">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="2775" end_char="2846">
<ORIGINAL_TEXT>Nevertheless, it’s a line of inquiry that scientists continue to pursue.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="2775" end_char="2786">Nevertheless</TOKEN>
<TOKEN id="token-27-1" pos="punct" morph="none" start_char="2787" end_char="2787">,</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="2789" end_char="2792">it’s</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="2794" end_char="2794">a</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="2796" end_char="2799">line</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="2801" end_char="2802">of</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="2804" end_char="2810">inquiry</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="2812" end_char="2815">that</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="2817" end_char="2826">scientists</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="2828" end_char="2835">continue</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="2837" end_char="2838">to</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="2840" end_char="2845">pursue</TOKEN>
<TOKEN id="token-27-12" pos="punct" morph="none" start_char="2846" end_char="2846">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="2848" end_char="2962">
<ORIGINAL_TEXT>Bats, in particular, have been studied closely because they are considered to be the natural host of coronaviruses.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="2848" end_char="2851">Bats</TOKEN>
<TOKEN id="token-28-1" pos="punct" morph="none" start_char="2852" end_char="2852">,</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="2854" end_char="2855">in</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="2857" end_char="2866">particular</TOKEN>
<TOKEN id="token-28-4" pos="punct" morph="none" start_char="2867" end_char="2867">,</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="2869" end_char="2872">have</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="2874" end_char="2877">been</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="2879" end_char="2885">studied</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="2887" end_char="2893">closely</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="2895" end_char="2901">because</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="2903" end_char="2906">they</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="2908" end_char="2910">are</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="2912" end_char="2921">considered</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="2923" end_char="2924">to</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="2926" end_char="2927">be</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="2929" end_char="2931">the</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="2933" end_char="2939">natural</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="2941" end_char="2944">host</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="2946" end_char="2947">of</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="2949" end_char="2961">coronaviruses</TOKEN>
<TOKEN id="token-28-20" pos="punct" morph="none" start_char="2962" end_char="2962">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="2965" end_char="3108">
<ORIGINAL_TEXT>Previous research has shown that most pathogenic human coronaviruses, including SARS-CoV and MERS-CoV, have genetically similar viruses in bats.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="2965" end_char="2972">Previous</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="2974" end_char="2981">research</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="2983" end_char="2985">has</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="2987" end_char="2991">shown</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="2993" end_char="2996">that</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="2998" end_char="3001">most</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="3003" end_char="3012">pathogenic</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="3014" end_char="3018">human</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="3020" end_char="3032">coronaviruses</TOKEN>
<TOKEN id="token-29-9" pos="punct" morph="none" start_char="3033" end_char="3033">,</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="3035" end_char="3043">including</TOKEN>
<TOKEN id="token-29-11" pos="unknown" morph="none" start_char="3045" end_char="3052">SARS-CoV</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="3054" end_char="3056">and</TOKEN>
<TOKEN id="token-29-13" pos="unknown" morph="none" start_char="3058" end_char="3065">MERS-CoV</TOKEN>
<TOKEN id="token-29-14" pos="punct" morph="none" start_char="3066" end_char="3066">,</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="3068" end_char="3071">have</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="3073" end_char="3083">genetically</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="3085" end_char="3091">similar</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="3093" end_char="3099">viruses</TOKEN>
<TOKEN id="token-29-19" pos="word" morph="none" start_char="3101" end_char="3102">in</TOKEN>
<TOKEN id="token-29-20" pos="word" morph="none" start_char="3104" end_char="3107">bats</TOKEN>
<TOKEN id="token-29-21" pos="punct" morph="none" start_char="3108" end_char="3108">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3110" end_char="3274">
<ORIGINAL_TEXT>This diversity creates a pool of viruses that can spill over when and where the opportunity arises, most often into an intermediate animal source and then to humans.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="3110" end_char="3113">This</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="3115" end_char="3123">diversity</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="3125" end_char="3131">creates</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="3133" end_char="3133">a</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="3135" end_char="3138">pool</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="3140" end_char="3141">of</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="3143" end_char="3149">viruses</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="3151" end_char="3154">that</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="3156" end_char="3158">can</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="3160" end_char="3164">spill</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="3166" end_char="3169">over</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="3171" end_char="3174">when</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="3176" end_char="3178">and</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="3180" end_char="3184">where</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="3186" end_char="3188">the</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="3190" end_char="3200">opportunity</TOKEN>
<TOKEN id="token-30-16" pos="word" morph="none" start_char="3202" end_char="3207">arises</TOKEN>
<TOKEN id="token-30-17" pos="punct" morph="none" start_char="3208" end_char="3208">,</TOKEN>
<TOKEN id="token-30-18" pos="word" morph="none" start_char="3210" end_char="3213">most</TOKEN>
<TOKEN id="token-30-19" pos="word" morph="none" start_char="3215" end_char="3219">often</TOKEN>
<TOKEN id="token-30-20" pos="word" morph="none" start_char="3221" end_char="3224">into</TOKEN>
<TOKEN id="token-30-21" pos="word" morph="none" start_char="3226" end_char="3227">an</TOKEN>
<TOKEN id="token-30-22" pos="word" morph="none" start_char="3229" end_char="3240">intermediate</TOKEN>
<TOKEN id="token-30-23" pos="word" morph="none" start_char="3242" end_char="3247">animal</TOKEN>
<TOKEN id="token-30-24" pos="word" morph="none" start_char="3249" end_char="3254">source</TOKEN>
<TOKEN id="token-30-25" pos="word" morph="none" start_char="3256" end_char="3258">and</TOKEN>
<TOKEN id="token-30-26" pos="word" morph="none" start_char="3260" end_char="3263">then</TOKEN>
<TOKEN id="token-30-27" pos="word" morph="none" start_char="3265" end_char="3266">to</TOKEN>
<TOKEN id="token-30-28" pos="word" morph="none" start_char="3268" end_char="3273">humans</TOKEN>
<TOKEN id="token-30-29" pos="punct" morph="none" start_char="3274" end_char="3274">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="3277" end_char="3424">
<ORIGINAL_TEXT>For example, bio-surveillance studies focused on finding the reservoir of SARS coronavirus showed that the closest related virus was in horse bats (</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="3277" end_char="3279">For</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="3281" end_char="3287">example</TOKEN>
<TOKEN id="token-31-2" pos="punct" morph="none" start_char="3288" end_char="3288">,</TOKEN>
<TOKEN id="token-31-3" pos="unknown" morph="none" start_char="3290" end_char="3305">bio-surveillance</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="3307" end_char="3313">studies</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="3315" end_char="3321">focused</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="3323" end_char="3324">on</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="3326" end_char="3332">finding</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="3334" end_char="3336">the</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="3338" end_char="3346">reservoir</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="3348" end_char="3349">of</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="3351" end_char="3354">SARS</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="3356" end_char="3366">coronavirus</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="3368" end_char="3373">showed</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="3375" end_char="3378">that</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="3380" end_char="3382">the</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="3384" end_char="3390">closest</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="3392" end_char="3398">related</TOKEN>
<TOKEN id="token-31-18" pos="word" morph="none" start_char="3400" end_char="3404">virus</TOKEN>
<TOKEN id="token-31-19" pos="word" morph="none" start_char="3406" end_char="3408">was</TOKEN>
<TOKEN id="token-31-20" pos="word" morph="none" start_char="3410" end_char="3411">in</TOKEN>
<TOKEN id="token-31-21" pos="word" morph="none" start_char="3413" end_char="3417">horse</TOKEN>
<TOKEN id="token-31-22" pos="word" morph="none" start_char="3419" end_char="3422">bats</TOKEN>
<TOKEN id="token-31-23" pos="punct" morph="none" start_char="3424" end_char="3424">(</TOKEN>
</SEG>
<SEG id="segment-32" start_char="3427" end_char="3441">
<ORIGINAL_TEXT>Rhinolophus spp</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="3427" end_char="3437">Rhinolophus</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="3439" end_char="3441">spp</TOKEN>
</SEG>
<SEG id="segment-33" start_char="3444" end_char="3454">
<ORIGINAL_TEXT>) in China.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="punct" morph="none" start_char="3444" end_char="3444">)</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="3446" end_char="3447">in</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="3449" end_char="3453">China</TOKEN>
<TOKEN id="token-33-3" pos="punct" morph="none" start_char="3454" end_char="3454">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="3456" end_char="3505">
<ORIGINAL_TEXT>Civets were an intermediate host infecting humans.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="3456" end_char="3461">Civets</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="3463" end_char="3466">were</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="3468" end_char="3469">an</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="3471" end_char="3482">intermediate</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="3484" end_char="3487">host</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="3489" end_char="3497">infecting</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="3499" end_char="3504">humans</TOKEN>
<TOKEN id="token-34-7" pos="punct" morph="none" start_char="3505" end_char="3505">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="3508" end_char="3680">
<ORIGINAL_TEXT>And fresh new data was released recently showing a close relationship – over 96% similarity – between a virus from a horseshoe bat sample collected in Yunnan and SARS CoV-2.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="3508" end_char="3510">And</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="3512" end_char="3516">fresh</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="3518" end_char="3520">new</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="3522" end_char="3525">data</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="3527" end_char="3529">was</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="3531" end_char="3538">released</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="3540" end_char="3547">recently</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="3549" end_char="3555">showing</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="3557" end_char="3557">a</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="3559" end_char="3563">close</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="3565" end_char="3576">relationship</TOKEN>
<TOKEN id="token-35-11" pos="punct" morph="none" start_char="3578" end_char="3578">–</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="3580" end_char="3583">over</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="3585" end_char="3586">96</TOKEN>
<TOKEN id="token-35-14" pos="punct" morph="none" start_char="3587" end_char="3587">%</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="3589" end_char="3598">similarity</TOKEN>
<TOKEN id="token-35-16" pos="punct" morph="none" start_char="3600" end_char="3600">–</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="3602" end_char="3608">between</TOKEN>
<TOKEN id="token-35-18" pos="word" morph="none" start_char="3610" end_char="3610">a</TOKEN>
<TOKEN id="token-35-19" pos="word" morph="none" start_char="3612" end_char="3616">virus</TOKEN>
<TOKEN id="token-35-20" pos="word" morph="none" start_char="3618" end_char="3621">from</TOKEN>
<TOKEN id="token-35-21" pos="word" morph="none" start_char="3623" end_char="3623">a</TOKEN>
<TOKEN id="token-35-22" pos="word" morph="none" start_char="3625" end_char="3633">horseshoe</TOKEN>
<TOKEN id="token-35-23" pos="word" morph="none" start_char="3635" end_char="3637">bat</TOKEN>
<TOKEN id="token-35-24" pos="word" morph="none" start_char="3639" end_char="3644">sample</TOKEN>
<TOKEN id="token-35-25" pos="word" morph="none" start_char="3646" end_char="3654">collected</TOKEN>
<TOKEN id="token-35-26" pos="word" morph="none" start_char="3656" end_char="3657">in</TOKEN>
<TOKEN id="token-35-27" pos="word" morph="none" start_char="3659" end_char="3664">Yunnan</TOKEN>
<TOKEN id="token-35-28" pos="word" morph="none" start_char="3666" end_char="3668">and</TOKEN>
<TOKEN id="token-35-29" pos="word" morph="none" start_char="3670" end_char="3673">SARS</TOKEN>
<TOKEN id="token-35-30" pos="unknown" morph="none" start_char="3675" end_char="3679">CoV-2</TOKEN>
<TOKEN id="token-35-31" pos="punct" morph="none" start_char="3680" end_char="3680">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="3683" end_char="3828">
<ORIGINAL_TEXT>A second paper reported similarity – 89% similarity – between SARS CoV-2 and a group of SARS-like coronaviruses previously found in bats in China.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="3683" end_char="3683">A</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="3685" end_char="3690">second</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="3692" end_char="3696">paper</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="3698" end_char="3705">reported</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="3707" end_char="3716">similarity</TOKEN>
<TOKEN id="token-36-5" pos="punct" morph="none" start_char="3718" end_char="3718">–</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="3720" end_char="3721">89</TOKEN>
<TOKEN id="token-36-7" pos="punct" morph="none" start_char="3722" end_char="3722">%</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="3724" end_char="3733">similarity</TOKEN>
<TOKEN id="token-36-9" pos="punct" morph="none" start_char="3735" end_char="3735">–</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="3737" end_char="3743">between</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="3745" end_char="3748">SARS</TOKEN>
<TOKEN id="token-36-12" pos="unknown" morph="none" start_char="3750" end_char="3754">CoV-2</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="3756" end_char="3758">and</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="3760" end_char="3760">a</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="3762" end_char="3766">group</TOKEN>
<TOKEN id="token-36-16" pos="word" morph="none" start_char="3768" end_char="3769">of</TOKEN>
<TOKEN id="token-36-17" pos="unknown" morph="none" start_char="3771" end_char="3779">SARS-like</TOKEN>
<TOKEN id="token-36-18" pos="word" morph="none" start_char="3781" end_char="3793">coronaviruses</TOKEN>
<TOKEN id="token-36-19" pos="word" morph="none" start_char="3795" end_char="3804">previously</TOKEN>
<TOKEN id="token-36-20" pos="word" morph="none" start_char="3806" end_char="3810">found</TOKEN>
<TOKEN id="token-36-21" pos="word" morph="none" start_char="3812" end_char="3813">in</TOKEN>
<TOKEN id="token-36-22" pos="word" morph="none" start_char="3815" end_char="3818">bats</TOKEN>
<TOKEN id="token-36-23" pos="word" morph="none" start_char="3820" end_char="3821">in</TOKEN>
<TOKEN id="token-36-24" pos="word" morph="none" start_char="3823" end_char="3827">China</TOKEN>
<TOKEN id="token-36-25" pos="punct" morph="none" start_char="3828" end_char="3828">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="3831" end_char="3942">
<ORIGINAL_TEXT>But these similarities are still not enough to identify the direct spillover virus causing the current outbreak.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="3831" end_char="3833">But</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="3835" end_char="3839">these</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="3841" end_char="3852">similarities</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="3854" end_char="3856">are</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="3858" end_char="3862">still</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="3864" end_char="3866">not</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="3868" end_char="3873">enough</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="3875" end_char="3876">to</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="3878" end_char="3885">identify</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="3887" end_char="3889">the</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="3891" end_char="3896">direct</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="3898" end_char="3906">spillover</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="3908" end_char="3912">virus</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="3914" end_char="3920">causing</TOKEN>
<TOKEN id="token-37-14" pos="word" morph="none" start_char="3922" end_char="3924">the</TOKEN>
<TOKEN id="token-37-15" pos="word" morph="none" start_char="3926" end_char="3932">current</TOKEN>
<TOKEN id="token-37-16" pos="word" morph="none" start_char="3934" end_char="3941">outbreak</TOKEN>
<TOKEN id="token-37-17" pos="punct" morph="none" start_char="3942" end_char="3942">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="3945" end_char="4053">
<ORIGINAL_TEXT>A key issue is that although the similarities appear high, the mutation rate of coronaviruses is complicated.</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="3945" end_char="3945">A</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="3947" end_char="3949">key</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="3951" end_char="3955">issue</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="3957" end_char="3958">is</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="3960" end_char="3963">that</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="3965" end_char="3972">although</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="3974" end_char="3976">the</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="3978" end_char="3989">similarities</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="3991" end_char="3996">appear</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="3998" end_char="4001">high</TOKEN>
<TOKEN id="token-38-10" pos="punct" morph="none" start_char="4002" end_char="4002">,</TOKEN>
<TOKEN id="token-38-11" pos="word" morph="none" start_char="4004" end_char="4006">the</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="4008" end_char="4015">mutation</TOKEN>
<TOKEN id="token-38-13" pos="word" morph="none" start_char="4017" end_char="4020">rate</TOKEN>
<TOKEN id="token-38-14" pos="word" morph="none" start_char="4022" end_char="4023">of</TOKEN>
<TOKEN id="token-38-15" pos="word" morph="none" start_char="4025" end_char="4037">coronaviruses</TOKEN>
<TOKEN id="token-38-16" pos="word" morph="none" start_char="4039" end_char="4040">is</TOKEN>
<TOKEN id="token-38-17" pos="word" morph="none" start_char="4042" end_char="4052">complicated</TOKEN>
<TOKEN id="token-38-18" pos="punct" morph="none" start_char="4053" end_char="4053">.</TOKEN>
</SEG>
<SEG id="segment-39" start_char="4055" end_char="4179">
<ORIGINAL_TEXT>Added to the complexity of the story is that there’s as a high probability that an intermediate host is part of the equation.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="4055" end_char="4059">Added</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="4061" end_char="4062">to</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="4064" end_char="4066">the</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="4068" end_char="4077">complexity</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="4079" end_char="4080">of</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="4082" end_char="4084">the</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="4086" end_char="4090">story</TOKEN>
<TOKEN id="token-39-7" pos="word" morph="none" start_char="4092" end_char="4093">is</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="4095" end_char="4098">that</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="4100" end_char="4106">there’s</TOKEN>
<TOKEN id="token-39-10" pos="word" morph="none" start_char="4108" end_char="4109">as</TOKEN>
<TOKEN id="token-39-11" pos="word" morph="none" start_char="4111" end_char="4111">a</TOKEN>
<TOKEN id="token-39-12" pos="word" morph="none" start_char="4113" end_char="4116">high</TOKEN>
<TOKEN id="token-39-13" pos="word" morph="none" start_char="4118" end_char="4128">probability</TOKEN>
<TOKEN id="token-39-14" pos="word" morph="none" start_char="4130" end_char="4133">that</TOKEN>
<TOKEN id="token-39-15" pos="word" morph="none" start_char="4135" end_char="4136">an</TOKEN>
<TOKEN id="token-39-16" pos="word" morph="none" start_char="4138" end_char="4149">intermediate</TOKEN>
<TOKEN id="token-39-17" pos="word" morph="none" start_char="4151" end_char="4154">host</TOKEN>
<TOKEN id="token-39-18" pos="word" morph="none" start_char="4156" end_char="4157">is</TOKEN>
<TOKEN id="token-39-19" pos="word" morph="none" start_char="4159" end_char="4162">part</TOKEN>
<TOKEN id="token-39-20" pos="word" morph="none" start_char="4164" end_char="4165">of</TOKEN>
<TOKEN id="token-39-21" pos="word" morph="none" start_char="4167" end_char="4169">the</TOKEN>
<TOKEN id="token-39-22" pos="word" morph="none" start_char="4171" end_char="4178">equation</TOKEN>
<TOKEN id="token-39-23" pos="punct" morph="none" start_char="4179" end_char="4179">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="4181" end_char="4348">
<ORIGINAL_TEXT>This insight comes from the fact that most bat viruses are present in low amounts in bats and need to amplify in a different host before they can spillover into humans.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="4181" end_char="4184">This</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="4186" end_char="4192">insight</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="4194" end_char="4198">comes</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="4200" end_char="4203">from</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="4205" end_char="4207">the</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="4209" end_char="4212">fact</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="4214" end_char="4217">that</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="4219" end_char="4222">most</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="4224" end_char="4226">bat</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="4228" end_char="4234">viruses</TOKEN>
<TOKEN id="token-40-10" pos="word" morph="none" start_char="4236" end_char="4238">are</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="4240" end_char="4246">present</TOKEN>
<TOKEN id="token-40-12" pos="word" morph="none" start_char="4248" end_char="4249">in</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="4251" end_char="4253">low</TOKEN>
<TOKEN id="token-40-14" pos="word" morph="none" start_char="4255" end_char="4261">amounts</TOKEN>
<TOKEN id="token-40-15" pos="word" morph="none" start_char="4263" end_char="4264">in</TOKEN>
<TOKEN id="token-40-16" pos="word" morph="none" start_char="4266" end_char="4269">bats</TOKEN>
<TOKEN id="token-40-17" pos="word" morph="none" start_char="4271" end_char="4273">and</TOKEN>
<TOKEN id="token-40-18" pos="word" morph="none" start_char="4275" end_char="4278">need</TOKEN>
<TOKEN id="token-40-19" pos="word" morph="none" start_char="4280" end_char="4281">to</TOKEN>
<TOKEN id="token-40-20" pos="word" morph="none" start_char="4283" end_char="4289">amplify</TOKEN>
<TOKEN id="token-40-21" pos="word" morph="none" start_char="4291" end_char="4292">in</TOKEN>
<TOKEN id="token-40-22" pos="word" morph="none" start_char="4294" end_char="4294">a</TOKEN>
<TOKEN id="token-40-23" pos="word" morph="none" start_char="4296" end_char="4304">different</TOKEN>
<TOKEN id="token-40-24" pos="word" morph="none" start_char="4306" end_char="4309">host</TOKEN>
<TOKEN id="token-40-25" pos="word" morph="none" start_char="4311" end_char="4316">before</TOKEN>
<TOKEN id="token-40-26" pos="word" morph="none" start_char="4318" end_char="4321">they</TOKEN>
<TOKEN id="token-40-27" pos="word" morph="none" start_char="4323" end_char="4325">can</TOKEN>
<TOKEN id="token-40-28" pos="word" morph="none" start_char="4327" end_char="4335">spillover</TOKEN>
<TOKEN id="token-40-29" pos="word" morph="none" start_char="4337" end_char="4340">into</TOKEN>
<TOKEN id="token-40-30" pos="word" morph="none" start_char="4342" end_char="4347">humans</TOKEN>
<TOKEN id="token-40-31" pos="punct" morph="none" start_char="4348" end_char="4348">.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="4351" end_char="4446">
<ORIGINAL_TEXT>For example, in the 2002/2003 SARS-CoV outbreak civets were identified as the intermediate host.</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="4351" end_char="4353">For</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="4355" end_char="4361">example</TOKEN>
<TOKEN id="token-41-2" pos="punct" morph="none" start_char="4362" end_char="4362">,</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="4364" end_char="4365">in</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="4367" end_char="4369">the</TOKEN>
<TOKEN id="token-41-5" pos="unknown" morph="none" start_char="4371" end_char="4379">2002/2003</TOKEN>
<TOKEN id="token-41-6" pos="unknown" morph="none" start_char="4381" end_char="4388">SARS-CoV</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="4390" end_char="4397">outbreak</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="4399" end_char="4404">civets</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="4406" end_char="4409">were</TOKEN>
<TOKEN id="token-41-10" pos="word" morph="none" start_char="4411" end_char="4420">identified</TOKEN>
<TOKEN id="token-41-11" pos="word" morph="none" start_char="4422" end_char="4423">as</TOKEN>
<TOKEN id="token-41-12" pos="word" morph="none" start_char="4425" end_char="4427">the</TOKEN>
<TOKEN id="token-41-13" pos="word" morph="none" start_char="4429" end_char="4440">intermediate</TOKEN>
<TOKEN id="token-41-14" pos="word" morph="none" start_char="4442" end_char="4445">host</TOKEN>
<TOKEN id="token-41-15" pos="punct" morph="none" start_char="4446" end_char="4446">.</TOKEN>
</SEG>
<SEG id="segment-42" start_char="4448" end_char="4506">
<ORIGINAL_TEXT>In the most recent outbreak pangolins have been implicated.</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="4448" end_char="4449">In</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="4451" end_char="4453">the</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="4455" end_char="4458">most</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="4460" end_char="4465">recent</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="4467" end_char="4474">outbreak</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="4476" end_char="4484">pangolins</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="4486" end_char="4489">have</TOKEN>
<TOKEN id="token-42-7" pos="word" morph="none" start_char="4491" end_char="4494">been</TOKEN>
<TOKEN id="token-42-8" pos="word" morph="none" start_char="4496" end_char="4505">implicated</TOKEN>
<TOKEN id="token-42-9" pos="punct" morph="none" start_char="4506" end_char="4506">.</TOKEN>
</SEG>
<SEG id="segment-43" start_char="4508" end_char="4646">
<ORIGINAL_TEXT>But there are huge gaps in this theory given that the coronavirus identified in pangolins has only a 90% similarity with the human viruses.</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="4508" end_char="4510">But</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="4512" end_char="4516">there</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="4518" end_char="4520">are</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="4522" end_char="4525">huge</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="4527" end_char="4530">gaps</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="4532" end_char="4533">in</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="4535" end_char="4538">this</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="4540" end_char="4545">theory</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="4547" end_char="4551">given</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="4553" end_char="4556">that</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="4558" end_char="4560">the</TOKEN>
<TOKEN id="token-43-11" pos="word" morph="none" start_char="4562" end_char="4572">coronavirus</TOKEN>
<TOKEN id="token-43-12" pos="word" morph="none" start_char="4574" end_char="4583">identified</TOKEN>
<TOKEN id="token-43-13" pos="word" morph="none" start_char="4585" end_char="4586">in</TOKEN>
<TOKEN id="token-43-14" pos="word" morph="none" start_char="4588" end_char="4596">pangolins</TOKEN>
<TOKEN id="token-43-15" pos="word" morph="none" start_char="4598" end_char="4600">has</TOKEN>
<TOKEN id="token-43-16" pos="word" morph="none" start_char="4602" end_char="4605">only</TOKEN>
<TOKEN id="token-43-17" pos="word" morph="none" start_char="4607" end_char="4607">a</TOKEN>
<TOKEN id="token-43-18" pos="word" morph="none" start_char="4609" end_char="4610">90</TOKEN>
<TOKEN id="token-43-19" pos="punct" morph="none" start_char="4611" end_char="4611">%</TOKEN>
<TOKEN id="token-43-20" pos="word" morph="none" start_char="4613" end_char="4622">similarity</TOKEN>
<TOKEN id="token-43-21" pos="word" morph="none" start_char="4624" end_char="4627">with</TOKEN>
<TOKEN id="token-43-22" pos="word" morph="none" start_char="4629" end_char="4631">the</TOKEN>
<TOKEN id="token-43-23" pos="word" morph="none" start_char="4633" end_char="4637">human</TOKEN>
<TOKEN id="token-43-24" pos="word" morph="none" start_char="4639" end_char="4645">viruses</TOKEN>
<TOKEN id="token-43-25" pos="punct" morph="none" start_char="4646" end_char="4646">.</TOKEN>
</SEG>
<SEG id="segment-44" start_char="4649" end_char="4671">
<ORIGINAL_TEXT>Designing interventions</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="4649" end_char="4657">Designing</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="4659" end_char="4671">interventions</TOKEN>
</SEG>
<SEG id="segment-45" start_char="4675" end_char="4778">
<ORIGINAL_TEXT>Preventing the spillover of a virus from animals to humans can save billions of dollars and human lives.</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="4675" end_char="4684">Preventing</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="4686" end_char="4688">the</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="4690" end_char="4698">spillover</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="4700" end_char="4701">of</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="4703" end_char="4703">a</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="4705" end_char="4709">virus</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="4711" end_char="4714">from</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="4716" end_char="4722">animals</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="4724" end_char="4725">to</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="4727" end_char="4732">humans</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="4734" end_char="4736">can</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="4738" end_char="4741">save</TOKEN>
<TOKEN id="token-45-12" pos="word" morph="none" start_char="4743" end_char="4750">billions</TOKEN>
<TOKEN id="token-45-13" pos="word" morph="none" start_char="4752" end_char="4753">of</TOKEN>
<TOKEN id="token-45-14" pos="word" morph="none" start_char="4755" end_char="4761">dollars</TOKEN>
<TOKEN id="token-45-15" pos="word" morph="none" start_char="4763" end_char="4765">and</TOKEN>
<TOKEN id="token-45-16" pos="word" morph="none" start_char="4767" end_char="4771">human</TOKEN>
<TOKEN id="token-45-17" pos="word" morph="none" start_char="4773" end_char="4777">lives</TOKEN>
<TOKEN id="token-45-18" pos="punct" morph="none" start_char="4778" end_char="4778">.</TOKEN>
</SEG>
<SEG id="segment-46" start_char="4781" end_char="4845">
<ORIGINAL_TEXT>A pool of diverse viruses will continue to circulate in wildlife.</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="4781" end_char="4781">A</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="4783" end_char="4786">pool</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="4788" end_char="4789">of</TOKEN>
<TOKEN id="token-46-3" pos="word" morph="none" start_char="4791" end_char="4797">diverse</TOKEN>
<TOKEN id="token-46-4" pos="word" morph="none" start_char="4799" end_char="4805">viruses</TOKEN>
<TOKEN id="token-46-5" pos="word" morph="none" start_char="4807" end_char="4810">will</TOKEN>
<TOKEN id="token-46-6" pos="word" morph="none" start_char="4812" end_char="4819">continue</TOKEN>
<TOKEN id="token-46-7" pos="word" morph="none" start_char="4821" end_char="4822">to</TOKEN>
<TOKEN id="token-46-8" pos="word" morph="none" start_char="4824" end_char="4832">circulate</TOKEN>
<TOKEN id="token-46-9" pos="word" morph="none" start_char="4834" end_char="4835">in</TOKEN>
<TOKEN id="token-46-10" pos="word" morph="none" start_char="4837" end_char="4844">wildlife</TOKEN>
<TOKEN id="token-46-11" pos="punct" morph="none" start_char="4845" end_char="4845">.</TOKEN>
</SEG>
<SEG id="segment-47" start_char="4847" end_char="5095">
<ORIGINAL_TEXT>Knowing the diversity, species implicated, and geographical distribution – together with understanding specific human activities that can increase the risk of spillover – is essential to prevent future outbreaks and sustain a healthy global economy.</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="4847" end_char="4853">Knowing</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="4855" end_char="4857">the</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="4859" end_char="4867">diversity</TOKEN>
<TOKEN id="token-47-3" pos="punct" morph="none" start_char="4868" end_char="4868">,</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="4870" end_char="4876">species</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="4878" end_char="4887">implicated</TOKEN>
<TOKEN id="token-47-6" pos="punct" morph="none" start_char="4888" end_char="4888">,</TOKEN>
<TOKEN id="token-47-7" pos="word" morph="none" start_char="4890" end_char="4892">and</TOKEN>
<TOKEN id="token-47-8" pos="word" morph="none" start_char="4894" end_char="4905">geographical</TOKEN>
<TOKEN id="token-47-9" pos="word" morph="none" start_char="4907" end_char="4918">distribution</TOKEN>
<TOKEN id="token-47-10" pos="punct" morph="none" start_char="4920" end_char="4920">–</TOKEN>
<TOKEN id="token-47-11" pos="word" morph="none" start_char="4922" end_char="4929">together</TOKEN>
<TOKEN id="token-47-12" pos="word" morph="none" start_char="4931" end_char="4934">with</TOKEN>
<TOKEN id="token-47-13" pos="word" morph="none" start_char="4936" end_char="4948">understanding</TOKEN>
<TOKEN id="token-47-14" pos="word" morph="none" start_char="4950" end_char="4957">specific</TOKEN>
<TOKEN id="token-47-15" pos="word" morph="none" start_char="4959" end_char="4963">human</TOKEN>
<TOKEN id="token-47-16" pos="word" morph="none" start_char="4965" end_char="4974">activities</TOKEN>
<TOKEN id="token-47-17" pos="word" morph="none" start_char="4976" end_char="4979">that</TOKEN>
<TOKEN id="token-47-18" pos="word" morph="none" start_char="4981" end_char="4983">can</TOKEN>
<TOKEN id="token-47-19" pos="word" morph="none" start_char="4985" end_char="4992">increase</TOKEN>
<TOKEN id="token-47-20" pos="word" morph="none" start_char="4994" end_char="4996">the</TOKEN>
<TOKEN id="token-47-21" pos="word" morph="none" start_char="4998" end_char="5001">risk</TOKEN>
<TOKEN id="token-47-22" pos="word" morph="none" start_char="5003" end_char="5004">of</TOKEN>
<TOKEN id="token-47-23" pos="word" morph="none" start_char="5006" end_char="5014">spillover</TOKEN>
<TOKEN id="token-47-24" pos="punct" morph="none" start_char="5016" end_char="5016">–</TOKEN>
<TOKEN id="token-47-25" pos="word" morph="none" start_char="5018" end_char="5019">is</TOKEN>
<TOKEN id="token-47-26" pos="word" morph="none" start_char="5021" end_char="5029">essential</TOKEN>
<TOKEN id="token-47-27" pos="word" morph="none" start_char="5031" end_char="5032">to</TOKEN>
<TOKEN id="token-47-28" pos="word" morph="none" start_char="5034" end_char="5040">prevent</TOKEN>
<TOKEN id="token-47-29" pos="word" morph="none" start_char="5042" end_char="5047">future</TOKEN>
<TOKEN id="token-47-30" pos="word" morph="none" start_char="5049" end_char="5057">outbreaks</TOKEN>
<TOKEN id="token-47-31" pos="word" morph="none" start_char="5059" end_char="5061">and</TOKEN>
<TOKEN id="token-47-32" pos="word" morph="none" start_char="5063" end_char="5069">sustain</TOKEN>
<TOKEN id="token-47-33" pos="word" morph="none" start_char="5071" end_char="5071">a</TOKEN>
<TOKEN id="token-47-34" pos="word" morph="none" start_char="5073" end_char="5079">healthy</TOKEN>
<TOKEN id="token-47-35" pos="word" morph="none" start_char="5081" end_char="5086">global</TOKEN>
<TOKEN id="token-47-36" pos="word" morph="none" start_char="5088" end_char="5094">economy</TOKEN>
<TOKEN id="token-47-37" pos="punct" morph="none" start_char="5095" end_char="5095">.</TOKEN>
</SEG>
<SEG id="segment-48" start_char="5098" end_char="5175">
<ORIGINAL_TEXT>Finding the source of a virus can sometimes lead to very simple interventions.</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="5098" end_char="5104">Finding</TOKEN>
<TOKEN id="token-48-1" pos="word" morph="none" start_char="5106" end_char="5108">the</TOKEN>
<TOKEN id="token-48-2" pos="word" morph="none" start_char="5110" end_char="5115">source</TOKEN>
<TOKEN id="token-48-3" pos="word" morph="none" start_char="5117" end_char="5118">of</TOKEN>
<TOKEN id="token-48-4" pos="word" morph="none" start_char="5120" end_char="5120">a</TOKEN>
<TOKEN id="token-48-5" pos="word" morph="none" start_char="5122" end_char="5126">virus</TOKEN>
<TOKEN id="token-48-6" pos="word" morph="none" start_char="5128" end_char="5130">can</TOKEN>
<TOKEN id="token-48-7" pos="word" morph="none" start_char="5132" end_char="5140">sometimes</TOKEN>
<TOKEN id="token-48-8" pos="word" morph="none" start_char="5142" end_char="5145">lead</TOKEN>
<TOKEN id="token-48-9" pos="word" morph="none" start_char="5147" end_char="5148">to</TOKEN>
<TOKEN id="token-48-10" pos="word" morph="none" start_char="5150" end_char="5153">very</TOKEN>
<TOKEN id="token-48-11" pos="word" morph="none" start_char="5155" end_char="5160">simple</TOKEN>
<TOKEN id="token-48-12" pos="word" morph="none" start_char="5162" end_char="5174">interventions</TOKEN>
<TOKEN id="token-48-13" pos="punct" morph="none" start_char="5175" end_char="5175">.</TOKEN>
</SEG>
<SEG id="segment-49" start_char="5177" end_char="5348">
<ORIGINAL_TEXT>For example, scientists identified the flying fox bat in Bangladesh as the natural host of the Nipah virus which can cause acute respiratory illness and fatal encephalitis.</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="5177" end_char="5179">For</TOKEN>
<TOKEN id="token-49-1" pos="word" morph="none" start_char="5181" end_char="5187">example</TOKEN>
<TOKEN id="token-49-2" pos="punct" morph="none" start_char="5188" end_char="5188">,</TOKEN>
<TOKEN id="token-49-3" pos="word" morph="none" start_char="5190" end_char="5199">scientists</TOKEN>
<TOKEN id="token-49-4" pos="word" morph="none" start_char="5201" end_char="5210">identified</TOKEN>
<TOKEN id="token-49-5" pos="word" morph="none" start_char="5212" end_char="5214">the</TOKEN>
<TOKEN id="token-49-6" pos="word" morph="none" start_char="5216" end_char="5221">flying</TOKEN>
<TOKEN id="token-49-7" pos="word" morph="none" start_char="5223" end_char="5225">fox</TOKEN>
<TOKEN id="token-49-8" pos="word" morph="none" start_char="5227" end_char="5229">bat</TOKEN>
<TOKEN id="token-49-9" pos="word" morph="none" start_char="5231" end_char="5232">in</TOKEN>
<TOKEN id="token-49-10" pos="word" morph="none" start_char="5234" end_char="5243">Bangladesh</TOKEN>
<TOKEN id="token-49-11" pos="word" morph="none" start_char="5245" end_char="5246">as</TOKEN>
<TOKEN id="token-49-12" pos="word" morph="none" start_char="5248" end_char="5250">the</TOKEN>
<TOKEN id="token-49-13" pos="word" morph="none" start_char="5252" end_char="5258">natural</TOKEN>
<TOKEN id="token-49-14" pos="word" morph="none" start_char="5260" end_char="5263">host</TOKEN>
<TOKEN id="token-49-15" pos="word" morph="none" start_char="5265" end_char="5266">of</TOKEN>
<TOKEN id="token-49-16" pos="word" morph="none" start_char="5268" end_char="5270">the</TOKEN>
<TOKEN id="token-49-17" pos="word" morph="none" start_char="5272" end_char="5276">Nipah</TOKEN>
<TOKEN id="token-49-18" pos="word" morph="none" start_char="5278" end_char="5282">virus</TOKEN>
<TOKEN id="token-49-19" pos="word" morph="none" start_char="5284" end_char="5288">which</TOKEN>
<TOKEN id="token-49-20" pos="word" morph="none" start_char="5290" end_char="5292">can</TOKEN>
<TOKEN id="token-49-21" pos="word" morph="none" start_char="5294" end_char="5298">cause</TOKEN>
<TOKEN id="token-49-22" pos="word" morph="none" start_char="5300" end_char="5304">acute</TOKEN>
<TOKEN id="token-49-23" pos="word" morph="none" start_char="5306" end_char="5316">respiratory</TOKEN>
<TOKEN id="token-49-24" pos="word" morph="none" start_char="5318" end_char="5324">illness</TOKEN>
<TOKEN id="token-49-25" pos="word" morph="none" start_char="5326" end_char="5328">and</TOKEN>
<TOKEN id="token-49-26" pos="word" morph="none" start_char="5330" end_char="5334">fatal</TOKEN>
<TOKEN id="token-49-27" pos="word" morph="none" start_char="5336" end_char="5347">encephalitis</TOKEN>
<TOKEN id="token-49-28" pos="punct" morph="none" start_char="5348" end_char="5348">.</TOKEN>
</SEG>
<SEG id="segment-50" start_char="5350" end_char="5407">
<ORIGINAL_TEXT>Researchers found that the virus was carried in bat urine.</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="5350" end_char="5360">Researchers</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="5362" end_char="5366">found</TOKEN>
<TOKEN id="token-50-2" pos="word" morph="none" start_char="5368" end_char="5371">that</TOKEN>
<TOKEN id="token-50-3" pos="word" morph="none" start_char="5373" end_char="5375">the</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="5377" end_char="5381">virus</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="5383" end_char="5385">was</TOKEN>
<TOKEN id="token-50-6" pos="word" morph="none" start_char="5387" end_char="5393">carried</TOKEN>
<TOKEN id="token-50-7" pos="word" morph="none" start_char="5395" end_char="5396">in</TOKEN>
<TOKEN id="token-50-8" pos="word" morph="none" start_char="5398" end_char="5400">bat</TOKEN>
<TOKEN id="token-50-9" pos="word" morph="none" start_char="5402" end_char="5406">urine</TOKEN>
<TOKEN id="token-50-10" pos="punct" morph="none" start_char="5407" end_char="5407">.</TOKEN>
</SEG>
<SEG id="segment-51" start_char="5409" end_char="5509">
<ORIGINAL_TEXT>People became infected when they consumed raw date palm sap from palm trees that had bat urine in it.</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="word" morph="none" start_char="5409" end_char="5414">People</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="5416" end_char="5421">became</TOKEN>
<TOKEN id="token-51-2" pos="word" morph="none" start_char="5423" end_char="5430">infected</TOKEN>
<TOKEN id="token-51-3" pos="word" morph="none" start_char="5432" end_char="5435">when</TOKEN>
<TOKEN id="token-51-4" pos="word" morph="none" start_char="5437" end_char="5440">they</TOKEN>
<TOKEN id="token-51-5" pos="word" morph="none" start_char="5442" end_char="5449">consumed</TOKEN>
<TOKEN id="token-51-6" pos="word" morph="none" start_char="5451" end_char="5453">raw</TOKEN>
<TOKEN id="token-51-7" pos="word" morph="none" start_char="5455" end_char="5458">date</TOKEN>
<TOKEN id="token-51-8" pos="word" morph="none" start_char="5460" end_char="5463">palm</TOKEN>
<TOKEN id="token-51-9" pos="word" morph="none" start_char="5465" end_char="5467">sap</TOKEN>
<TOKEN id="token-51-10" pos="word" morph="none" start_char="5469" end_char="5472">from</TOKEN>
<TOKEN id="token-51-11" pos="word" morph="none" start_char="5474" end_char="5477">palm</TOKEN>
<TOKEN id="token-51-12" pos="word" morph="none" start_char="5479" end_char="5483">trees</TOKEN>
<TOKEN id="token-51-13" pos="word" morph="none" start_char="5485" end_char="5488">that</TOKEN>
<TOKEN id="token-51-14" pos="word" morph="none" start_char="5490" end_char="5492">had</TOKEN>
<TOKEN id="token-51-15" pos="word" morph="none" start_char="5494" end_char="5496">bat</TOKEN>
<TOKEN id="token-51-16" pos="word" morph="none" start_char="5498" end_char="5502">urine</TOKEN>
<TOKEN id="token-51-17" pos="word" morph="none" start_char="5504" end_char="5505">in</TOKEN>
<TOKEN id="token-51-18" pos="word" morph="none" start_char="5507" end_char="5508">it</TOKEN>
<TOKEN id="token-51-19" pos="punct" morph="none" start_char="5509" end_char="5509">.</TOKEN>
</SEG>
<SEG id="segment-52" start_char="5511" end_char="5603">
<ORIGINAL_TEXT>Interventions included education campaigns to discourage the drinking of fresh date palm sap.</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="5511" end_char="5523">Interventions</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="5525" end_char="5532">included</TOKEN>
<TOKEN id="token-52-2" pos="word" morph="none" start_char="5534" end_char="5542">education</TOKEN>
<TOKEN id="token-52-3" pos="word" morph="none" start_char="5544" end_char="5552">campaigns</TOKEN>
<TOKEN id="token-52-4" pos="word" morph="none" start_char="5554" end_char="5555">to</TOKEN>
<TOKEN id="token-52-5" pos="word" morph="none" start_char="5557" end_char="5566">discourage</TOKEN>
<TOKEN id="token-52-6" pos="word" morph="none" start_char="5568" end_char="5570">the</TOKEN>
<TOKEN id="token-52-7" pos="word" morph="none" start_char="5572" end_char="5579">drinking</TOKEN>
<TOKEN id="token-52-8" pos="word" morph="none" start_char="5581" end_char="5582">of</TOKEN>
<TOKEN id="token-52-9" pos="word" morph="none" start_char="5584" end_char="5588">fresh</TOKEN>
<TOKEN id="token-52-10" pos="word" morph="none" start_char="5590" end_char="5593">date</TOKEN>
<TOKEN id="token-52-11" pos="word" morph="none" start_char="5595" end_char="5598">palm</TOKEN>
<TOKEN id="token-52-12" pos="word" morph="none" start_char="5600" end_char="5602">sap</TOKEN>
<TOKEN id="token-52-13" pos="punct" morph="none" start_char="5603" end_char="5603">.</TOKEN>
</SEG>
<SEG id="segment-53" start_char="5605" end_char="5720">
<ORIGINAL_TEXT>People were also encouraged to close collection containers to prevent the sap from being contaminated by bat urine .</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="word" morph="none" start_char="5605" end_char="5610">People</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="5612" end_char="5615">were</TOKEN>
<TOKEN id="token-53-2" pos="word" morph="none" start_char="5617" end_char="5620">also</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="5622" end_char="5631">encouraged</TOKEN>
<TOKEN id="token-53-4" pos="word" morph="none" start_char="5633" end_char="5634">to</TOKEN>
<TOKEN id="token-53-5" pos="word" morph="none" start_char="5636" end_char="5640">close</TOKEN>
<TOKEN id="token-53-6" pos="word" morph="none" start_char="5642" end_char="5651">collection</TOKEN>
<TOKEN id="token-53-7" pos="word" morph="none" start_char="5653" end_char="5662">containers</TOKEN>
<TOKEN id="token-53-8" pos="word" morph="none" start_char="5664" end_char="5665">to</TOKEN>
<TOKEN id="token-53-9" pos="word" morph="none" start_char="5667" end_char="5673">prevent</TOKEN>
<TOKEN id="token-53-10" pos="word" morph="none" start_char="5675" end_char="5677">the</TOKEN>
<TOKEN id="token-53-11" pos="word" morph="none" start_char="5679" end_char="5681">sap</TOKEN>
<TOKEN id="token-53-12" pos="word" morph="none" start_char="5683" end_char="5686">from</TOKEN>
<TOKEN id="token-53-13" pos="word" morph="none" start_char="5688" end_char="5692">being</TOKEN>
<TOKEN id="token-53-14" pos="word" morph="none" start_char="5694" end_char="5705">contaminated</TOKEN>
<TOKEN id="token-53-15" pos="word" morph="none" start_char="5707" end_char="5708">by</TOKEN>
<TOKEN id="token-53-16" pos="word" morph="none" start_char="5710" end_char="5712">bat</TOKEN>
<TOKEN id="token-53-17" pos="word" morph="none" start_char="5714" end_char="5718">urine</TOKEN>
<TOKEN id="token-53-18" pos="punct" morph="none" start_char="5720" end_char="5720">.</TOKEN>
</SEG>
<SEG id="segment-54" start_char="5723" end_char="5790">
<ORIGINAL_TEXT>Interventions will differ for every virus and geographical location.</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="word" morph="none" start_char="5723" end_char="5735">Interventions</TOKEN>
<TOKEN id="token-54-1" pos="word" morph="none" start_char="5737" end_char="5740">will</TOKEN>
<TOKEN id="token-54-2" pos="word" morph="none" start_char="5742" end_char="5747">differ</TOKEN>
<TOKEN id="token-54-3" pos="word" morph="none" start_char="5749" end_char="5751">for</TOKEN>
<TOKEN id="token-54-4" pos="word" morph="none" start_char="5753" end_char="5757">every</TOKEN>
<TOKEN id="token-54-5" pos="word" morph="none" start_char="5759" end_char="5763">virus</TOKEN>
<TOKEN id="token-54-6" pos="word" morph="none" start_char="5765" end_char="5767">and</TOKEN>
<TOKEN id="token-54-7" pos="word" morph="none" start_char="5769" end_char="5780">geographical</TOKEN>
<TOKEN id="token-54-8" pos="word" morph="none" start_char="5782" end_char="5789">location</TOKEN>
<TOKEN id="token-54-9" pos="punct" morph="none" start_char="5790" end_char="5790">.</TOKEN>
</SEG>
<SEG id="segment-55" start_char="5792" end_char="5952">
<ORIGINAL_TEXT>But basic virological, epidemiological and anthropological data is desperately needed for known outbreaks and to lessen the burden of future potential outbreaks.</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="word" morph="none" start_char="5792" end_char="5794">But</TOKEN>
<TOKEN id="token-55-1" pos="word" morph="none" start_char="5796" end_char="5800">basic</TOKEN>
<TOKEN id="token-55-2" pos="word" morph="none" start_char="5802" end_char="5812">virological</TOKEN>
<TOKEN id="token-55-3" pos="punct" morph="none" start_char="5813" end_char="5813">,</TOKEN>
<TOKEN id="token-55-4" pos="word" morph="none" start_char="5815" end_char="5829">epidemiological</TOKEN>
<TOKEN id="token-55-5" pos="word" morph="none" start_char="5831" end_char="5833">and</TOKEN>
<TOKEN id="token-55-6" pos="word" morph="none" start_char="5835" end_char="5849">anthropological</TOKEN>
<TOKEN id="token-55-7" pos="word" morph="none" start_char="5851" end_char="5854">data</TOKEN>
<TOKEN id="token-55-8" pos="word" morph="none" start_char="5856" end_char="5857">is</TOKEN>
<TOKEN id="token-55-9" pos="word" morph="none" start_char="5859" end_char="5869">desperately</TOKEN>
<TOKEN id="token-55-10" pos="word" morph="none" start_char="5871" end_char="5876">needed</TOKEN>
<TOKEN id="token-55-11" pos="word" morph="none" start_char="5878" end_char="5880">for</TOKEN>
<TOKEN id="token-55-12" pos="word" morph="none" start_char="5882" end_char="5886">known</TOKEN>
<TOKEN id="token-55-13" pos="word" morph="none" start_char="5888" end_char="5896">outbreaks</TOKEN>
<TOKEN id="token-55-14" pos="word" morph="none" start_char="5898" end_char="5900">and</TOKEN>
<TOKEN id="token-55-15" pos="word" morph="none" start_char="5902" end_char="5903">to</TOKEN>
<TOKEN id="token-55-16" pos="word" morph="none" start_char="5905" end_char="5910">lessen</TOKEN>
<TOKEN id="token-55-17" pos="word" morph="none" start_char="5912" end_char="5914">the</TOKEN>
<TOKEN id="token-55-18" pos="word" morph="none" start_char="5916" end_char="5921">burden</TOKEN>
<TOKEN id="token-55-19" pos="word" morph="none" start_char="5923" end_char="5924">of</TOKEN>
<TOKEN id="token-55-20" pos="word" morph="none" start_char="5926" end_char="5931">future</TOKEN>
<TOKEN id="token-55-21" pos="word" morph="none" start_char="5933" end_char="5941">potential</TOKEN>
<TOKEN id="token-55-22" pos="word" morph="none" start_char="5943" end_char="5951">outbreaks</TOKEN>
<TOKEN id="token-55-23" pos="punct" morph="none" start_char="5952" end_char="5952">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
