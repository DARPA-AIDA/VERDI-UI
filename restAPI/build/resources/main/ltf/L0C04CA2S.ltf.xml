<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CA2S" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="2419" raw_text_md5="cbd67431dcd95deb5cf7220c8a049e66">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="118">
<ORIGINAL_TEXT>Nos preguntáis por el vídeo de la televisión italiana RAI de 2015 que se comparte ahora relacionándolo con el COVID-19</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="3">Nos</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="5" end_char="14">preguntáis</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="16" end_char="18">por</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="20" end_char="21">el</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="23" end_char="27">vídeo</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="29" end_char="30">de</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="32" end_char="33">la</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="35" end_char="44">televisión</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="46" end_char="53">italiana</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="55" end_char="57">RAI</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="59" end_char="60">de</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="62" end_char="65">2015</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="67" end_char="69">que</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="71" end_char="72">se</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="74" end_char="81">comparte</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="83" end_char="87">ahora</TOKEN>
<TOKEN id="token-0-16" pos="word" morph="none" start_char="89" end_char="102">relacionándolo</TOKEN>
<TOKEN id="token-0-17" pos="word" morph="none" start_char="104" end_char="106">con</TOKEN>
<TOKEN id="token-0-18" pos="word" morph="none" start_char="108" end_char="109">el</TOKEN>
<TOKEN id="token-0-19" pos="unknown" morph="none" start_char="111" end_char="118">COVID-19</TOKEN>
</SEG>
<SEG id="segment-1" start_char="122" end_char="390">
<ORIGINAL_TEXT>Nos habéis preguntado a través de nuestro servicio de verificación de WhatsApp (+34 682 58 96 64) por un vídeo de la RAI, el canal de televisión italiano, en el que el presentador menciona un coronavirus creado en un laboratorio chino a partir de murciélagos y ratones.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="122" end_char="124">Nos</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="126" end_char="131">habéis</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="133" end_char="142">preguntado</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="144" end_char="144">a</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="146" end_char="151">través</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="153" end_char="154">de</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="156" end_char="162">nuestro</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="164" end_char="171">servicio</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="173" end_char="174">de</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="176" end_char="187">verificación</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="189" end_char="190">de</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="192" end_char="199">WhatsApp</TOKEN>
<TOKEN id="token-1-12" pos="unknown" morph="none" start_char="201" end_char="204">(+34</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="206" end_char="208">682</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="210" end_char="211">58</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="213" end_char="214">96</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="216" end_char="217">64</TOKEN>
<TOKEN id="token-1-17" pos="punct" morph="none" start_char="218" end_char="218">)</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="220" end_char="222">por</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="224" end_char="225">un</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="227" end_char="231">vídeo</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="233" end_char="234">de</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="236" end_char="237">la</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="239" end_char="241">RAI</TOKEN>
<TOKEN id="token-1-24" pos="punct" morph="none" start_char="242" end_char="242">,</TOKEN>
<TOKEN id="token-1-25" pos="word" morph="none" start_char="244" end_char="245">el</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="247" end_char="251">canal</TOKEN>
<TOKEN id="token-1-27" pos="word" morph="none" start_char="253" end_char="254">de</TOKEN>
<TOKEN id="token-1-28" pos="word" morph="none" start_char="256" end_char="265">televisión</TOKEN>
<TOKEN id="token-1-29" pos="word" morph="none" start_char="267" end_char="274">italiano</TOKEN>
<TOKEN id="token-1-30" pos="punct" morph="none" start_char="275" end_char="275">,</TOKEN>
<TOKEN id="token-1-31" pos="word" morph="none" start_char="277" end_char="278">en</TOKEN>
<TOKEN id="token-1-32" pos="word" morph="none" start_char="280" end_char="281">el</TOKEN>
<TOKEN id="token-1-33" pos="word" morph="none" start_char="283" end_char="285">que</TOKEN>
<TOKEN id="token-1-34" pos="word" morph="none" start_char="287" end_char="288">el</TOKEN>
<TOKEN id="token-1-35" pos="word" morph="none" start_char="290" end_char="300">presentador</TOKEN>
<TOKEN id="token-1-36" pos="word" morph="none" start_char="302" end_char="309">menciona</TOKEN>
<TOKEN id="token-1-37" pos="word" morph="none" start_char="311" end_char="312">un</TOKEN>
<TOKEN id="token-1-38" pos="word" morph="none" start_char="314" end_char="324">coronavirus</TOKEN>
<TOKEN id="token-1-39" pos="word" morph="none" start_char="326" end_char="331">creado</TOKEN>
<TOKEN id="token-1-40" pos="word" morph="none" start_char="333" end_char="334">en</TOKEN>
<TOKEN id="token-1-41" pos="word" morph="none" start_char="336" end_char="337">un</TOKEN>
<TOKEN id="token-1-42" pos="word" morph="none" start_char="339" end_char="349">laboratorio</TOKEN>
<TOKEN id="token-1-43" pos="word" morph="none" start_char="351" end_char="355">chino</TOKEN>
<TOKEN id="token-1-44" pos="word" morph="none" start_char="357" end_char="357">a</TOKEN>
<TOKEN id="token-1-45" pos="word" morph="none" start_char="359" end_char="364">partir</TOKEN>
<TOKEN id="token-1-46" pos="word" morph="none" start_char="366" end_char="367">de</TOKEN>
<TOKEN id="token-1-47" pos="word" morph="none" start_char="369" end_char="379">murciélagos</TOKEN>
<TOKEN id="token-1-48" pos="word" morph="none" start_char="381" end_char="381">y</TOKEN>
<TOKEN id="token-1-49" pos="word" morph="none" start_char="383" end_char="389">ratones</TOKEN>
<TOKEN id="token-1-50" pos="punct" morph="none" start_char="390" end_char="390">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="392" end_char="418">
<ORIGINAL_TEXT>Te contamos lo que sabemos.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="392" end_char="393">Te</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="395" end_char="402">contamos</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="404" end_char="405">lo</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="407" end_char="409">que</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="411" end_char="417">sabemos</TOKEN>
<TOKEN id="token-2-5" pos="punct" morph="none" start_char="418" end_char="418">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="421" end_char="578">
<ORIGINAL_TEXT>El experimento que se menciona en el programa TGR Leonardo del 16 de noviembre de 2015 había sido publicado cuatro días antes en la revista científica Nature.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="421" end_char="422">El</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="424" end_char="434">experimento</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="436" end_char="438">que</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="440" end_char="441">se</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="443" end_char="450">menciona</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="452" end_char="453">en</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="455" end_char="456">el</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="458" end_char="465">programa</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="467" end_char="469">TGR</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="471" end_char="478">Leonardo</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="480" end_char="482">del</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="484" end_char="485">16</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="487" end_char="488">de</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="490" end_char="498">noviembre</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="500" end_char="501">de</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="503" end_char="506">2015</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="508" end_char="512">había</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="514" end_char="517">sido</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="519" end_char="527">publicado</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="529" end_char="534">cuatro</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="536" end_char="539">días</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="541" end_char="545">antes</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="547" end_char="548">en</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="550" end_char="551">la</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="553" end_char="559">revista</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="561" end_char="570">científica</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="572" end_char="577">Nature</TOKEN>
<TOKEN id="token-3-27" pos="punct" morph="none" start_char="578" end_char="578">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="580" end_char="719">
<ORIGINAL_TEXT>En el artículo, se cuenta los hallazgos de una investigación que logró «infectar con coronavirus de murciélago directamente a los humanos «.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="580" end_char="581">En</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="583" end_char="584">el</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="586" end_char="593">artículo</TOKEN>
<TOKEN id="token-4-3" pos="punct" morph="none" start_char="594" end_char="594">,</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="596" end_char="597">se</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="599" end_char="604">cuenta</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="606" end_char="608">los</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="610" end_char="618">hallazgos</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="620" end_char="621">de</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="623" end_char="625">una</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="627" end_char="639">investigación</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="641" end_char="643">que</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="645" end_char="649">logró</TOKEN>
<TOKEN id="token-4-13" pos="punct" morph="none" start_char="651" end_char="651">«</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="652" end_char="659">infectar</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="661" end_char="663">con</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="665" end_char="675">coronavirus</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="677" end_char="678">de</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="680" end_char="689">murciélago</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="691" end_char="702">directamente</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="704" end_char="704">a</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="706" end_char="708">los</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="710" end_char="716">humanos</TOKEN>
<TOKEN id="token-4-23" pos="punct" morph="none" start_char="718" end_char="719">«.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="721" end_char="808">
<ORIGINAL_TEXT>También, que ese coronavirus «relacionado con el SARS» podía infectar a células humanas.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="721" end_char="727">También</TOKEN>
<TOKEN id="token-5-1" pos="punct" morph="none" start_char="728" end_char="728">,</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="730" end_char="732">que</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="734" end_char="736">ese</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="738" end_char="748">coronavirus</TOKEN>
<TOKEN id="token-5-5" pos="punct" morph="none" start_char="750" end_char="750">«</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="751" end_char="761">relacionado</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="763" end_char="765">con</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="767" end_char="768">el</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="770" end_char="773">SARS</TOKEN>
<TOKEN id="token-5-10" pos="punct" morph="none" start_char="774" end_char="774">»</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="776" end_char="780">podía</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="782" end_char="789">infectar</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="791" end_char="791">a</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="793" end_char="799">células</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="801" end_char="807">humanas</TOKEN>
<TOKEN id="token-5-16" pos="punct" morph="none" start_char="808" end_char="808">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="811" end_char="1057">
<ORIGINAL_TEXT>El fragmento del vídeo difundido en la televisión italiana ha sido retomado estos días para justificar la idea de que la actual cepa del coronavirus ha sido creado en un laboratorio chino, entre otros por el exministro del Interior Matteo Salvini.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="811" end_char="812">El</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="814" end_char="822">fragmento</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="824" end_char="826">del</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="828" end_char="832">vídeo</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="834" end_char="842">difundido</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="844" end_char="845">en</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="847" end_char="848">la</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="850" end_char="859">televisión</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="861" end_char="868">italiana</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="870" end_char="871">ha</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="873" end_char="876">sido</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="878" end_char="885">retomado</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="887" end_char="891">estos</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="893" end_char="896">días</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="898" end_char="901">para</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="903" end_char="912">justificar</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="914" end_char="915">la</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="917" end_char="920">idea</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="922" end_char="923">de</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="925" end_char="927">que</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="929" end_char="930">la</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="932" end_char="937">actual</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="939" end_char="942">cepa</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="944" end_char="946">del</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="948" end_char="958">coronavirus</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="960" end_char="961">ha</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="963" end_char="966">sido</TOKEN>
<TOKEN id="token-6-27" pos="word" morph="none" start_char="968" end_char="973">creado</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="975" end_char="976">en</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="978" end_char="979">un</TOKEN>
<TOKEN id="token-6-30" pos="word" morph="none" start_char="981" end_char="991">laboratorio</TOKEN>
<TOKEN id="token-6-31" pos="word" morph="none" start_char="993" end_char="997">chino</TOKEN>
<TOKEN id="token-6-32" pos="punct" morph="none" start_char="998" end_char="998">,</TOKEN>
<TOKEN id="token-6-33" pos="word" morph="none" start_char="1000" end_char="1004">entre</TOKEN>
<TOKEN id="token-6-34" pos="word" morph="none" start_char="1006" end_char="1010">otros</TOKEN>
<TOKEN id="token-6-35" pos="word" morph="none" start_char="1012" end_char="1014">por</TOKEN>
<TOKEN id="token-6-36" pos="word" morph="none" start_char="1016" end_char="1017">el</TOKEN>
<TOKEN id="token-6-37" pos="word" morph="none" start_char="1019" end_char="1028">exministro</TOKEN>
<TOKEN id="token-6-38" pos="word" morph="none" start_char="1030" end_char="1032">del</TOKEN>
<TOKEN id="token-6-39" pos="word" morph="none" start_char="1034" end_char="1041">Interior</TOKEN>
<TOKEN id="token-6-40" pos="word" morph="none" start_char="1043" end_char="1048">Matteo</TOKEN>
<TOKEN id="token-6-41" pos="word" morph="none" start_char="1050" end_char="1056">Salvini</TOKEN>
<TOKEN id="token-6-42" pos="punct" morph="none" start_char="1057" end_char="1057">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="1059" end_char="1165">
<ORIGINAL_TEXT>Sin embargo, no existe evidencia científica de que la actual cepa del virus fuese creado en un laboratorio.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="1059" end_char="1061">Sin</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="1063" end_char="1069">embargo</TOKEN>
<TOKEN id="token-7-2" pos="punct" morph="none" start_char="1070" end_char="1070">,</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="1072" end_char="1073">no</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="1075" end_char="1080">existe</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="1082" end_char="1090">evidencia</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="1092" end_char="1101">científica</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="1103" end_char="1104">de</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="1106" end_char="1108">que</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="1110" end_char="1111">la</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="1113" end_char="1118">actual</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="1120" end_char="1123">cepa</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="1125" end_char="1127">del</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="1129" end_char="1133">virus</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="1135" end_char="1139">fuese</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="1141" end_char="1146">creado</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="1148" end_char="1149">en</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="1151" end_char="1152">un</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="1154" end_char="1164">laboratorio</TOKEN>
<TOKEN id="token-7-19" pos="punct" morph="none" start_char="1165" end_char="1165">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1167" end_char="1254">
<ORIGINAL_TEXT>Al contrario, la comunidad científica asegura que el SARS-CoV-2 tiene un origen natural.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1167" end_char="1168">Al</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1170" end_char="1178">contrario</TOKEN>
<TOKEN id="token-8-2" pos="punct" morph="none" start_char="1179" end_char="1179">,</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1181" end_char="1182">la</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1184" end_char="1192">comunidad</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1194" end_char="1203">científica</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1205" end_char="1211">asegura</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1213" end_char="1215">que</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1217" end_char="1218">el</TOKEN>
<TOKEN id="token-8-9" pos="unknown" morph="none" start_char="1220" end_char="1229">SARS-CoV-2</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1231" end_char="1235">tiene</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1237" end_char="1238">un</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1240" end_char="1245">origen</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1247" end_char="1253">natural</TOKEN>
<TOKEN id="token-8-14" pos="punct" morph="none" start_char="1254" end_char="1254">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1256" end_char="1476">
<ORIGINAL_TEXT>De hecho, el pasado 19 de febrero, la revista The Lancet publicó un comunicado en el que científicos de múltiples países condenaban «las teorías de la conspiración que sugieren que el COVID-19 no tiene un origen natural».</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1256" end_char="1257">De</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1259" end_char="1263">hecho</TOKEN>
<TOKEN id="token-9-2" pos="punct" morph="none" start_char="1264" end_char="1264">,</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1266" end_char="1267">el</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1269" end_char="1274">pasado</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1276" end_char="1277">19</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1279" end_char="1280">de</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1282" end_char="1288">febrero</TOKEN>
<TOKEN id="token-9-8" pos="punct" morph="none" start_char="1289" end_char="1289">,</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1291" end_char="1292">la</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1294" end_char="1300">revista</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1302" end_char="1304">The</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1306" end_char="1311">Lancet</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1313" end_char="1319">publicó</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1321" end_char="1322">un</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1324" end_char="1333">comunicado</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1335" end_char="1336">en</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1338" end_char="1339">el</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1341" end_char="1343">que</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1345" end_char="1355">científicos</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1357" end_char="1358">de</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1360" end_char="1368">múltiples</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1370" end_char="1375">países</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1377" end_char="1386">condenaban</TOKEN>
<TOKEN id="token-9-24" pos="punct" morph="none" start_char="1388" end_char="1388">«</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1389" end_char="1391">las</TOKEN>
<TOKEN id="token-9-26" pos="word" morph="none" start_char="1393" end_char="1399">teorías</TOKEN>
<TOKEN id="token-9-27" pos="word" morph="none" start_char="1401" end_char="1402">de</TOKEN>
<TOKEN id="token-9-28" pos="word" morph="none" start_char="1404" end_char="1405">la</TOKEN>
<TOKEN id="token-9-29" pos="word" morph="none" start_char="1407" end_char="1418">conspiración</TOKEN>
<TOKEN id="token-9-30" pos="word" morph="none" start_char="1420" end_char="1422">que</TOKEN>
<TOKEN id="token-9-31" pos="word" morph="none" start_char="1424" end_char="1431">sugieren</TOKEN>
<TOKEN id="token-9-32" pos="word" morph="none" start_char="1433" end_char="1435">que</TOKEN>
<TOKEN id="token-9-33" pos="word" morph="none" start_char="1437" end_char="1438">el</TOKEN>
<TOKEN id="token-9-34" pos="unknown" morph="none" start_char="1440" end_char="1447">COVID-19</TOKEN>
<TOKEN id="token-9-35" pos="word" morph="none" start_char="1449" end_char="1450">no</TOKEN>
<TOKEN id="token-9-36" pos="word" morph="none" start_char="1452" end_char="1456">tiene</TOKEN>
<TOKEN id="token-9-37" pos="word" morph="none" start_char="1458" end_char="1459">un</TOKEN>
<TOKEN id="token-9-38" pos="word" morph="none" start_char="1461" end_char="1466">origen</TOKEN>
<TOKEN id="token-9-39" pos="word" morph="none" start_char="1468" end_char="1474">natural</TOKEN>
<TOKEN id="token-9-40" pos="punct" morph="none" start_char="1475" end_char="1476">».</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1479" end_char="1651">
<ORIGINAL_TEXT>Además, en una nota añadida este mes de marzo, la revista Nature ha querido especificar que el coronavirus del que hablan en el artículo no tiene nada que ver con el actual.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1479" end_char="1484">Además</TOKEN>
<TOKEN id="token-10-1" pos="punct" morph="none" start_char="1485" end_char="1485">,</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1487" end_char="1488">en</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1490" end_char="1492">una</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1494" end_char="1497">nota</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1499" end_char="1505">añadida</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1507" end_char="1510">este</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1512" end_char="1514">mes</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1516" end_char="1517">de</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1519" end_char="1523">marzo</TOKEN>
<TOKEN id="token-10-10" pos="punct" morph="none" start_char="1524" end_char="1524">,</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1526" end_char="1527">la</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1529" end_char="1535">revista</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1537" end_char="1542">Nature</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1544" end_char="1545">ha</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1547" end_char="1553">querido</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1555" end_char="1565">especificar</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1567" end_char="1569">que</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1571" end_char="1572">el</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1574" end_char="1584">coronavirus</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1586" end_char="1588">del</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1590" end_char="1592">que</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1594" end_char="1599">hablan</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1601" end_char="1602">en</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1604" end_char="1605">el</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="1607" end_char="1614">artículo</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="1616" end_char="1617">no</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="1619" end_char="1623">tiene</TOKEN>
<TOKEN id="token-10-28" pos="word" morph="none" start_char="1625" end_char="1628">nada</TOKEN>
<TOKEN id="token-10-29" pos="word" morph="none" start_char="1630" end_char="1632">que</TOKEN>
<TOKEN id="token-10-30" pos="word" morph="none" start_char="1634" end_char="1636">ver</TOKEN>
<TOKEN id="token-10-31" pos="word" morph="none" start_char="1638" end_char="1640">con</TOKEN>
<TOKEN id="token-10-32" pos="word" morph="none" start_char="1642" end_char="1643">el</TOKEN>
<TOKEN id="token-10-33" pos="word" morph="none" start_char="1645" end_char="1650">actual</TOKEN>
<TOKEN id="token-10-34" pos="punct" morph="none" start_char="1651" end_char="1651">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1653" end_char="1834">
<ORIGINAL_TEXT>«Somos conscientes de que este experimento se está utilizando como base para las teorías no verificadas de que el nuevo coronavirus que causa COVID-19 fue diseñado en un laboratorio.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="punct" morph="none" start_char="1653" end_char="1653">«</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1654" end_char="1658">Somos</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1660" end_char="1670">conscientes</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1672" end_char="1673">de</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1675" end_char="1677">que</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1679" end_char="1682">este</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1684" end_char="1694">experimento</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1696" end_char="1697">se</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1699" end_char="1702">está</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1704" end_char="1713">utilizando</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1715" end_char="1718">como</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1720" end_char="1723">base</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1725" end_char="1728">para</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1730" end_char="1732">las</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1734" end_char="1740">teorías</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1742" end_char="1743">no</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1745" end_char="1755">verificadas</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1757" end_char="1758">de</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1760" end_char="1762">que</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="1764" end_char="1765">el</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1767" end_char="1771">nuevo</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="1773" end_char="1783">coronavirus</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="1785" end_char="1787">que</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="1789" end_char="1793">causa</TOKEN>
<TOKEN id="token-11-24" pos="unknown" morph="none" start_char="1795" end_char="1802">COVID-19</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="1804" end_char="1806">fue</TOKEN>
<TOKEN id="token-11-26" pos="word" morph="none" start_char="1808" end_char="1815">diseñado</TOKEN>
<TOKEN id="token-11-27" pos="word" morph="none" start_char="1817" end_char="1818">en</TOKEN>
<TOKEN id="token-11-28" pos="word" morph="none" start_char="1820" end_char="1821">un</TOKEN>
<TOKEN id="token-11-29" pos="word" morph="none" start_char="1823" end_char="1833">laboratorio</TOKEN>
<TOKEN id="token-11-30" pos="punct" morph="none" start_char="1834" end_char="1834">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1836" end_char="1898">
<ORIGINAL_TEXT>No hay ninguna evidencia de que esto sea cierto», dice la nota.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1836" end_char="1837">No</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1839" end_char="1841">hay</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1843" end_char="1849">ninguna</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1851" end_char="1859">evidencia</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1861" end_char="1862">de</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1864" end_char="1866">que</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1868" end_char="1871">esto</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1873" end_char="1875">sea</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1877" end_char="1882">cierto</TOKEN>
<TOKEN id="token-12-9" pos="punct" morph="none" start_char="1883" end_char="1884">»,</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1886" end_char="1889">dice</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1891" end_char="1892">la</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1894" end_char="1897">nota</TOKEN>
<TOKEN id="token-12-13" pos="punct" morph="none" start_char="1898" end_char="1898">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1901" end_char="2054">
<ORIGINAL_TEXT>El pasado 25 de marzo, el diario italiano Corriere della Sera publicó un artículo precisando también que la actual cepa del virus tiene un origen natural.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1901" end_char="1902">El</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1904" end_char="1909">pasado</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1911" end_char="1912">25</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1914" end_char="1915">de</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1917" end_char="1921">marzo</TOKEN>
<TOKEN id="token-13-5" pos="punct" morph="none" start_char="1922" end_char="1922">,</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1924" end_char="1925">el</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1927" end_char="1932">diario</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1934" end_char="1941">italiano</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1943" end_char="1950">Corriere</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1952" end_char="1956">della</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1958" end_char="1961">Sera</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1963" end_char="1969">publicó</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1971" end_char="1972">un</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1974" end_char="1981">artículo</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1983" end_char="1992">precisando</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1994" end_char="2000">también</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="2002" end_char="2004">que</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="2006" end_char="2007">la</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="2009" end_char="2014">actual</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="2016" end_char="2019">cepa</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="2021" end_char="2023">del</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="2025" end_char="2029">virus</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="2031" end_char="2035">tiene</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="2037" end_char="2038">un</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="2040" end_char="2045">origen</TOKEN>
<TOKEN id="token-13-26" pos="word" morph="none" start_char="2047" end_char="2053">natural</TOKEN>
<TOKEN id="token-13-27" pos="punct" morph="none" start_char="2054" end_char="2054">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="2056" end_char="2212">
<ORIGINAL_TEXT>Además, cita que el mismo director de la RAI, Alessandro Casarin, explicó cómo el programa de ese día usó como fuente «una publicación de la revista Nature».</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="2056" end_char="2061">Además</TOKEN>
<TOKEN id="token-14-1" pos="punct" morph="none" start_char="2062" end_char="2062">,</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="2064" end_char="2067">cita</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="2069" end_char="2071">que</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="2073" end_char="2074">el</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="2076" end_char="2080">mismo</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="2082" end_char="2089">director</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="2091" end_char="2092">de</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="2094" end_char="2095">la</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="2097" end_char="2099">RAI</TOKEN>
<TOKEN id="token-14-10" pos="punct" morph="none" start_char="2100" end_char="2100">,</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="2102" end_char="2111">Alessandro</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="2113" end_char="2119">Casarin</TOKEN>
<TOKEN id="token-14-13" pos="punct" morph="none" start_char="2120" end_char="2120">,</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="2122" end_char="2128">explicó</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="2130" end_char="2133">cómo</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="2135" end_char="2136">el</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="2138" end_char="2145">programa</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="2147" end_char="2148">de</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="2150" end_char="2152">ese</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="2154" end_char="2156">día</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="2158" end_char="2160">usó</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="2162" end_char="2165">como</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="2167" end_char="2172">fuente</TOKEN>
<TOKEN id="token-14-24" pos="punct" morph="none" start_char="2174" end_char="2174">«</TOKEN>
<TOKEN id="token-14-25" pos="word" morph="none" start_char="2175" end_char="2177">una</TOKEN>
<TOKEN id="token-14-26" pos="word" morph="none" start_char="2179" end_char="2189">publicación</TOKEN>
<TOKEN id="token-14-27" pos="word" morph="none" start_char="2191" end_char="2192">de</TOKEN>
<TOKEN id="token-14-28" pos="word" morph="none" start_char="2194" end_char="2195">la</TOKEN>
<TOKEN id="token-14-29" pos="word" morph="none" start_char="2197" end_char="2203">revista</TOKEN>
<TOKEN id="token-14-30" pos="word" morph="none" start_char="2205" end_char="2210">Nature</TOKEN>
<TOKEN id="token-14-31" pos="punct" morph="none" start_char="2211" end_char="2212">».</TOKEN>
</SEG>
<SEG id="segment-15" start_char="2214" end_char="2406">
<ORIGINAL_TEXT>Casarin también subrayó que «hace solo tres días la misma revista aclaró que el virus mencionado en el programa, creado en el laboratorio, no tiene relación con el virus que causa el Covid-19».</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="2214" end_char="2220">Casarin</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="2222" end_char="2228">también</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="2230" end_char="2236">subrayó</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="2238" end_char="2240">que</TOKEN>
<TOKEN id="token-15-4" pos="punct" morph="none" start_char="2242" end_char="2242">«</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="2243" end_char="2246">hace</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="2248" end_char="2251">solo</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="2253" end_char="2256">tres</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="2258" end_char="2261">días</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="2263" end_char="2264">la</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="2266" end_char="2270">misma</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="2272" end_char="2278">revista</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="2280" end_char="2285">aclaró</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="2287" end_char="2289">que</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="2291" end_char="2292">el</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="2294" end_char="2298">virus</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="2300" end_char="2309">mencionado</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="2311" end_char="2312">en</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="2314" end_char="2315">el</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="2317" end_char="2324">programa</TOKEN>
<TOKEN id="token-15-20" pos="punct" morph="none" start_char="2325" end_char="2325">,</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="2327" end_char="2332">creado</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="2334" end_char="2335">en</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="2337" end_char="2338">el</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="2340" end_char="2350">laboratorio</TOKEN>
<TOKEN id="token-15-25" pos="punct" morph="none" start_char="2351" end_char="2351">,</TOKEN>
<TOKEN id="token-15-26" pos="word" morph="none" start_char="2353" end_char="2354">no</TOKEN>
<TOKEN id="token-15-27" pos="word" morph="none" start_char="2356" end_char="2360">tiene</TOKEN>
<TOKEN id="token-15-28" pos="word" morph="none" start_char="2362" end_char="2369">relación</TOKEN>
<TOKEN id="token-15-29" pos="word" morph="none" start_char="2371" end_char="2373">con</TOKEN>
<TOKEN id="token-15-30" pos="word" morph="none" start_char="2375" end_char="2376">el</TOKEN>
<TOKEN id="token-15-31" pos="word" morph="none" start_char="2378" end_char="2382">virus</TOKEN>
<TOKEN id="token-15-32" pos="word" morph="none" start_char="2384" end_char="2386">que</TOKEN>
<TOKEN id="token-15-33" pos="word" morph="none" start_char="2388" end_char="2392">causa</TOKEN>
<TOKEN id="token-15-34" pos="word" morph="none" start_char="2394" end_char="2395">el</TOKEN>
<TOKEN id="token-15-35" pos="unknown" morph="none" start_char="2397" end_char="2404">Covid-19</TOKEN>
<TOKEN id="token-15-36" pos="punct" morph="none" start_char="2405" end_char="2406">».</TOKEN>
</SEG>
<SEG id="segment-16" start_char="2409" end_char="2415">
<ORIGINAL_TEXT>Fuentes</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="2409" end_char="2415">Fuentes</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
