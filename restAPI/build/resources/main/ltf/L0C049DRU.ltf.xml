<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="eng">
<DOC id="L0C049DRU" lang="eng" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="2831" raw_text_md5="327f4af48dba96817fb06df91cc1f90f">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="94">
<ORIGINAL_TEXT>Claims That the Obama Administration Gave $3.7 Million To Research Institute In China Is False</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="6">Claims</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="8" end_char="11">That</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="13" end_char="15">the</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="17" end_char="21">Obama</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="23" end_char="36">Administration</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="38" end_char="41">Gave</TOKEN>
<TOKEN id="token-0-6" pos="unknown" morph="none" start_char="43" end_char="46">$3.7</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="48" end_char="54">Million</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="56" end_char="57">To</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="59" end_char="66">Research</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="68" end_char="76">Institute</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="78" end_char="79">In</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="81" end_char="85">China</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="87" end_char="88">Is</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="90" end_char="94">False</TOKEN>
</SEG>
<SEG id="segment-1" start_char="98" end_char="119">
<ORIGINAL_TEXT>(Flickr/Gage Skidmore)</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="punct" morph="none" start_char="98" end_char="98">(</TOKEN>
<TOKEN id="token-1-1" pos="unknown" morph="none" start_char="99" end_char="109">Flickr/Gage</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="111" end_char="118">Skidmore</TOKEN>
<TOKEN id="token-1-3" pos="punct" morph="none" start_char="119" end_char="119">)</TOKEN>
</SEG>
<SEG id="segment-2" start_char="123" end_char="279">
<ORIGINAL_TEXT>A claim that the Obama administration gave almost $4 million to a Wuhan research facility has gained traction online, however, the actual story is different.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="123" end_char="123">A</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="125" end_char="129">claim</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="131" end_char="134">that</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="136" end_char="138">the</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="140" end_char="144">Obama</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="146" end_char="159">administration</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="161" end_char="164">gave</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="166" end_char="171">almost</TOKEN>
<TOKEN id="token-2-8" pos="unknown" morph="none" start_char="173" end_char="174">$4</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="176" end_char="182">million</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="184" end_char="185">to</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="187" end_char="187">a</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="189" end_char="193">Wuhan</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="195" end_char="202">research</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="204" end_char="211">facility</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="213" end_char="215">has</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="217" end_char="222">gained</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="224" end_char="231">traction</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="233" end_char="238">online</TOKEN>
<TOKEN id="token-2-19" pos="punct" morph="none" start_char="239" end_char="239">,</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="241" end_char="247">however</TOKEN>
<TOKEN id="token-2-21" pos="punct" morph="none" start_char="248" end_char="248">,</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="250" end_char="252">the</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="254" end_char="259">actual</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="261" end_char="265">story</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="267" end_char="268">is</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="270" end_char="278">different</TOKEN>
<TOKEN id="token-2-27" pos="punct" morph="none" start_char="279" end_char="279">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="282" end_char="546">
<ORIGINAL_TEXT>According to Yahoo News, the claim that the U.S. government helped fund research into coronaviruses, spread after a Daily Mail report said it obtained documents showing the Wuhan Institute of Virology undertook coronavirus experiments on mammals captured in Yunnan.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="282" end_char="290">According</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="292" end_char="293">to</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="295" end_char="299">Yahoo</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="301" end_char="304">News</TOKEN>
<TOKEN id="token-3-4" pos="punct" morph="none" start_char="305" end_char="305">,</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="307" end_char="309">the</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="311" end_char="315">claim</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="317" end_char="320">that</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="322" end_char="324">the</TOKEN>
<TOKEN id="token-3-9" pos="unknown" morph="none" start_char="326" end_char="328">U.S</TOKEN>
<TOKEN id="token-3-10" pos="punct" morph="none" start_char="329" end_char="329">.</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="331" end_char="340">government</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="342" end_char="347">helped</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="349" end_char="352">fund</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="354" end_char="361">research</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="363" end_char="366">into</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="368" end_char="380">coronaviruses</TOKEN>
<TOKEN id="token-3-17" pos="punct" morph="none" start_char="381" end_char="381">,</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="383" end_char="388">spread</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="390" end_char="394">after</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="396" end_char="396">a</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="398" end_char="402">Daily</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="404" end_char="407">Mail</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="409" end_char="414">report</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="416" end_char="419">said</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="421" end_char="422">it</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="424" end_char="431">obtained</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="433" end_char="441">documents</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="443" end_char="449">showing</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="451" end_char="453">the</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="455" end_char="459">Wuhan</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="461" end_char="469">Institute</TOKEN>
<TOKEN id="token-3-32" pos="word" morph="none" start_char="471" end_char="472">of</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="474" end_char="481">Virology</TOKEN>
<TOKEN id="token-3-34" pos="word" morph="none" start_char="483" end_char="491">undertook</TOKEN>
<TOKEN id="token-3-35" pos="word" morph="none" start_char="493" end_char="503">coronavirus</TOKEN>
<TOKEN id="token-3-36" pos="word" morph="none" start_char="505" end_char="515">experiments</TOKEN>
<TOKEN id="token-3-37" pos="word" morph="none" start_char="517" end_char="518">on</TOKEN>
<TOKEN id="token-3-38" pos="word" morph="none" start_char="520" end_char="526">mammals</TOKEN>
<TOKEN id="token-3-39" pos="word" morph="none" start_char="528" end_char="535">captured</TOKEN>
<TOKEN id="token-3-40" pos="word" morph="none" start_char="537" end_char="538">in</TOKEN>
<TOKEN id="token-3-41" pos="word" morph="none" start_char="540" end_char="545">Yunnan</TOKEN>
<TOKEN id="token-3-42" pos="punct" morph="none" start_char="546" end_char="546">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="549" end_char="632">
<ORIGINAL_TEXT>The report added that the Obama administration funded coronavirus research in China.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="549" end_char="551">The</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="553" end_char="558">report</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="560" end_char="564">added</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="566" end_char="569">that</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="571" end_char="573">the</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="575" end_char="579">Obama</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="581" end_char="594">administration</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="596" end_char="601">funded</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="603" end_char="613">coronavirus</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="615" end_char="622">research</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="624" end_char="625">in</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="627" end_char="631">China</TOKEN>
<TOKEN id="token-4-12" pos="punct" morph="none" start_char="632" end_char="632">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="634" end_char="748">
<ORIGINAL_TEXT>However, the truth is a grant overseen by the National Institutes of Health was provided to the EcoHealth Alliance.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="634" end_char="640">However</TOKEN>
<TOKEN id="token-5-1" pos="punct" morph="none" start_char="641" end_char="641">,</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="643" end_char="645">the</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="647" end_char="651">truth</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="653" end_char="654">is</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="656" end_char="656">a</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="658" end_char="662">grant</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="664" end_char="671">overseen</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="673" end_char="674">by</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="676" end_char="678">the</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="680" end_char="687">National</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="689" end_char="698">Institutes</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="700" end_char="701">of</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="703" end_char="708">Health</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="710" end_char="712">was</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="714" end_char="721">provided</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="723" end_char="724">to</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="726" end_char="728">the</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="730" end_char="738">EcoHealth</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="740" end_char="747">Alliance</TOKEN>
<TOKEN id="token-5-20" pos="punct" morph="none" start_char="748" end_char="748">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="750" end_char="832">
<ORIGINAL_TEXT>The grant continued under the Trump administration until it was recently rescinded.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="750" end_char="752">The</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="754" end_char="758">grant</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="760" end_char="768">continued</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="770" end_char="774">under</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="776" end_char="778">the</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="780" end_char="784">Trump</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="786" end_char="799">administration</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="801" end_char="805">until</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="807" end_char="808">it</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="810" end_char="812">was</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="814" end_char="821">recently</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="823" end_char="831">rescinded</TOKEN>
<TOKEN id="token-6-12" pos="punct" morph="none" start_char="832" end_char="832">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="835" end_char="967">
<ORIGINAL_TEXT>The EcoHealth Alliance is a nongovernmental research group that focuses on emerging diseases caused by human and animal interactions.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="835" end_char="837">The</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="839" end_char="847">EcoHealth</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="849" end_char="856">Alliance</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="858" end_char="859">is</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="861" end_char="861">a</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="863" end_char="877">nongovernmental</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="879" end_char="886">research</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="888" end_char="892">group</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="894" end_char="897">that</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="899" end_char="905">focuses</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="907" end_char="908">on</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="910" end_char="917">emerging</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="919" end_char="926">diseases</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="928" end_char="933">caused</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="935" end_char="936">by</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="938" end_char="942">human</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="944" end_char="946">and</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="948" end_char="953">animal</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="955" end_char="966">interactions</TOKEN>
<TOKEN id="token-7-19" pos="punct" morph="none" start_char="967" end_char="967">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="969" end_char="1011">
<ORIGINAL_TEXT>The NIH has funded the alliance since 2002.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="969" end_char="971">The</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="973" end_char="975">NIH</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="977" end_char="979">has</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="981" end_char="986">funded</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="988" end_char="990">the</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="992" end_char="999">alliance</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1001" end_char="1005">since</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1007" end_char="1010">2002</TOKEN>
<TOKEN id="token-8-8" pos="punct" morph="none" start_char="1011" end_char="1011">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1014" end_char="1146">
<ORIGINAL_TEXT>In 2014, the NIH approved a grant to the alliance designated for research into "Understanding the Risk of Bat Coronavirus Emergence."</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1014" end_char="1015">In</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1017" end_char="1020">2014</TOKEN>
<TOKEN id="token-9-2" pos="punct" morph="none" start_char="1021" end_char="1021">,</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1023" end_char="1025">the</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1027" end_char="1029">NIH</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1031" end_char="1038">approved</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1040" end_char="1040">a</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1042" end_char="1046">grant</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1048" end_char="1049">to</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1051" end_char="1053">the</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1055" end_char="1062">alliance</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1064" end_char="1073">designated</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1075" end_char="1077">for</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1079" end_char="1086">research</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1088" end_char="1091">into</TOKEN>
<TOKEN id="token-9-15" pos="punct" morph="none" start_char="1093" end_char="1093">"</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1094" end_char="1106">Understanding</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1108" end_char="1110">the</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1112" end_char="1115">Risk</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1117" end_char="1118">of</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1120" end_char="1122">Bat</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1124" end_char="1134">Coronavirus</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1136" end_char="1144">Emergence</TOKEN>
<TOKEN id="token-9-23" pos="punct" morph="none" start_char="1145" end_char="1146">."</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1149" end_char="1311">
<ORIGINAL_TEXT>The project involved collaborating with researchers at the Wuhan Institute of Virology to study coronaviruses in bats and the risk of potential transfer to humans.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1149" end_char="1151">The</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1153" end_char="1159">project</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1161" end_char="1168">involved</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1170" end_char="1182">collaborating</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1184" end_char="1187">with</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1189" end_char="1199">researchers</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1201" end_char="1202">at</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1204" end_char="1206">the</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1208" end_char="1212">Wuhan</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1214" end_char="1222">Institute</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1224" end_char="1225">of</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1227" end_char="1234">Virology</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1236" end_char="1237">to</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1239" end_char="1243">study</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1245" end_char="1257">coronaviruses</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1259" end_char="1260">in</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1262" end_char="1265">bats</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1267" end_char="1269">and</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1271" end_char="1273">the</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1275" end_char="1278">risk</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1280" end_char="1281">of</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1283" end_char="1291">potential</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1293" end_char="1300">transfer</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1302" end_char="1303">to</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1305" end_char="1310">humans</TOKEN>
<TOKEN id="token-10-25" pos="punct" morph="none" start_char="1311" end_char="1311">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1313" end_char="1466">
<ORIGINAL_TEXT>The project was created "to understand what factors allow coronaviruses, including close relatives to SARS, to evolve and jump into the human population."</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1313" end_char="1315">The</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1317" end_char="1323">project</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1325" end_char="1327">was</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1329" end_char="1335">created</TOKEN>
<TOKEN id="token-11-4" pos="punct" morph="none" start_char="1337" end_char="1337">"</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1338" end_char="1339">to</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1341" end_char="1350">understand</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1352" end_char="1355">what</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1357" end_char="1363">factors</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1365" end_char="1369">allow</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1371" end_char="1383">coronaviruses</TOKEN>
<TOKEN id="token-11-11" pos="punct" morph="none" start_char="1384" end_char="1384">,</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1386" end_char="1394">including</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1396" end_char="1400">close</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1402" end_char="1410">relatives</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1412" end_char="1413">to</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1415" end_char="1418">SARS</TOKEN>
<TOKEN id="token-11-17" pos="punct" morph="none" start_char="1419" end_char="1419">,</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1421" end_char="1422">to</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="1424" end_char="1429">evolve</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1431" end_char="1433">and</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="1435" end_char="1438">jump</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="1440" end_char="1443">into</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="1445" end_char="1447">the</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="1449" end_char="1453">human</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="1455" end_char="1464">population</TOKEN>
<TOKEN id="token-11-26" pos="punct" morph="none" start_char="1465" end_char="1466">."</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1469" end_char="1553">
<ORIGINAL_TEXT>The original five-year grant was reapproved by the Trump administration in July 2019.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1469" end_char="1471">The</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1473" end_char="1480">original</TOKEN>
<TOKEN id="token-12-2" pos="unknown" morph="none" start_char="1482" end_char="1490">five-year</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1492" end_char="1496">grant</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1498" end_char="1500">was</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1502" end_char="1511">reapproved</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1513" end_char="1514">by</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1516" end_char="1518">the</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1520" end_char="1524">Trump</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1526" end_char="1539">administration</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1541" end_char="1542">in</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1544" end_char="1547">July</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1549" end_char="1552">2019</TOKEN>
<TOKEN id="token-12-13" pos="punct" morph="none" start_char="1553" end_char="1553">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1555" end_char="1678">
<ORIGINAL_TEXT>The effort spent $3,378,896 and resulted in 20 scientific reports on how zoonotic diseases may transfer from bats to humans.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1555" end_char="1557">The</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1559" end_char="1564">effort</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1566" end_char="1570">spent</TOKEN>
<TOKEN id="token-13-3" pos="unknown" morph="none" start_char="1572" end_char="1581">$3,378,896</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1583" end_char="1585">and</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1587" end_char="1594">resulted</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1596" end_char="1597">in</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1599" end_char="1600">20</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1602" end_char="1611">scientific</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1613" end_char="1619">reports</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1621" end_char="1622">on</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1624" end_char="1626">how</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1628" end_char="1635">zoonotic</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1637" end_char="1644">diseases</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1646" end_char="1648">may</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1650" end_char="1657">transfer</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1659" end_char="1662">from</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1664" end_char="1667">bats</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1669" end_char="1670">to</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1672" end_char="1677">humans</TOKEN>
<TOKEN id="token-13-20" pos="punct" morph="none" start_char="1678" end_char="1678">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1681" end_char="1830">
<ORIGINAL_TEXT>The Daily Mail reported April 11, the research was funded by a $3.7 million grant from the Obama administration and the claim quickly gained traction.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1681" end_char="1683">The</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1685" end_char="1689">Daily</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1691" end_char="1694">Mail</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1696" end_char="1703">reported</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1705" end_char="1709">April</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1711" end_char="1712">11</TOKEN>
<TOKEN id="token-14-6" pos="punct" morph="none" start_char="1713" end_char="1713">,</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1715" end_char="1717">the</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1719" end_char="1726">research</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1728" end_char="1730">was</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1732" end_char="1737">funded</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1739" end_char="1740">by</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1742" end_char="1742">a</TOKEN>
<TOKEN id="token-14-13" pos="unknown" morph="none" start_char="1744" end_char="1747">$3.7</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="1749" end_char="1755">million</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1757" end_char="1761">grant</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1763" end_char="1766">from</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="1768" end_char="1770">the</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="1772" end_char="1776">Obama</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="1778" end_char="1791">administration</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="1793" end_char="1795">and</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="1797" end_char="1799">the</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="1801" end_char="1805">claim</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="1807" end_char="1813">quickly</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="1815" end_char="1820">gained</TOKEN>
<TOKEN id="token-14-25" pos="word" morph="none" start_char="1822" end_char="1829">traction</TOKEN>
<TOKEN id="token-14-26" pos="punct" morph="none" start_char="1830" end_char="1830">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1833" end_char="2006">
<ORIGINAL_TEXT>"For years, the US government has been funding cruel animal experiments at the Wuhan Institute of Virology, which may have contributed to the global spread of COVID-19," Rep.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="punct" morph="none" start_char="1833" end_char="1833">"</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1834" end_char="1836">For</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1838" end_char="1842">years</TOKEN>
<TOKEN id="token-15-3" pos="punct" morph="none" start_char="1843" end_char="1843">,</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1845" end_char="1847">the</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1849" end_char="1850">US</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1852" end_char="1861">government</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1863" end_char="1865">has</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1867" end_char="1870">been</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1872" end_char="1878">funding</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1880" end_char="1884">cruel</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1886" end_char="1891">animal</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1893" end_char="1903">experiments</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1905" end_char="1906">at</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1908" end_char="1910">the</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="1912" end_char="1916">Wuhan</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="1918" end_char="1926">Institute</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="1928" end_char="1929">of</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="1931" end_char="1938">Virology</TOKEN>
<TOKEN id="token-15-19" pos="punct" morph="none" start_char="1939" end_char="1939">,</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="1941" end_char="1945">which</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="1947" end_char="1949">may</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="1951" end_char="1954">have</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="1956" end_char="1966">contributed</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="1968" end_char="1969">to</TOKEN>
<TOKEN id="token-15-25" pos="word" morph="none" start_char="1971" end_char="1973">the</TOKEN>
<TOKEN id="token-15-26" pos="word" morph="none" start_char="1975" end_char="1980">global</TOKEN>
<TOKEN id="token-15-27" pos="word" morph="none" start_char="1982" end_char="1987">spread</TOKEN>
<TOKEN id="token-15-28" pos="word" morph="none" start_char="1989" end_char="1990">of</TOKEN>
<TOKEN id="token-15-29" pos="unknown" morph="none" start_char="1992" end_char="1999">COVID-19</TOKEN>
<TOKEN id="token-15-30" pos="punct" morph="none" start_char="2000" end_char="2001">,"</TOKEN>
<TOKEN id="token-15-31" pos="word" morph="none" start_char="2003" end_char="2005">Rep</TOKEN>
<TOKEN id="token-15-32" pos="punct" morph="none" start_char="2006" end_char="2006">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="2008" end_char="2044">
<ORIGINAL_TEXT>Matt Gaetz, R-Fla., tweeted April 13.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="2008" end_char="2011">Matt</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="2013" end_char="2017">Gaetz</TOKEN>
<TOKEN id="token-16-2" pos="punct" morph="none" start_char="2018" end_char="2018">,</TOKEN>
<TOKEN id="token-16-3" pos="unknown" morph="none" start_char="2020" end_char="2024">R-Fla</TOKEN>
<TOKEN id="token-16-4" pos="punct" morph="none" start_char="2025" end_char="2026">.,</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="2028" end_char="2034">tweeted</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="2036" end_char="2040">April</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="2042" end_char="2043">13</TOKEN>
<TOKEN id="token-16-8" pos="punct" morph="none" start_char="2044" end_char="2044">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2047" end_char="2111">
<ORIGINAL_TEXT>Gaetz praised President Trump for ending the program on Fox News.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2047" end_char="2051">Gaetz</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2053" end_char="2059">praised</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2061" end_char="2069">President</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2071" end_char="2075">Trump</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2077" end_char="2079">for</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2081" end_char="2086">ending</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2088" end_char="2090">the</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2092" end_char="2098">program</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2100" end_char="2101">on</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2103" end_char="2105">Fox</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2107" end_char="2110">News</TOKEN>
<TOKEN id="token-17-11" pos="punct" morph="none" start_char="2111" end_char="2111">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2114" end_char="2228">
<ORIGINAL_TEXT>When a reporter asked Trump about the grant money, he responded, "We will end that grant very quickly," Trump said.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2114" end_char="2117">When</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2119" end_char="2119">a</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2121" end_char="2128">reporter</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2130" end_char="2134">asked</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2136" end_char="2140">Trump</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2142" end_char="2146">about</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2148" end_char="2150">the</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2152" end_char="2156">grant</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2158" end_char="2162">money</TOKEN>
<TOKEN id="token-18-9" pos="punct" morph="none" start_char="2163" end_char="2163">,</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="2165" end_char="2166">he</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="2168" end_char="2176">responded</TOKEN>
<TOKEN id="token-18-12" pos="punct" morph="none" start_char="2177" end_char="2177">,</TOKEN>
<TOKEN id="token-18-13" pos="punct" morph="none" start_char="2179" end_char="2179">"</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="2180" end_char="2181">We</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="2183" end_char="2186">will</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="2188" end_char="2190">end</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="2192" end_char="2195">that</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="2197" end_char="2201">grant</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="2203" end_char="2206">very</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="2208" end_char="2214">quickly</TOKEN>
<TOKEN id="token-18-21" pos="punct" morph="none" start_char="2215" end_char="2216">,"</TOKEN>
<TOKEN id="token-18-22" pos="word" morph="none" start_char="2218" end_char="2222">Trump</TOKEN>
<TOKEN id="token-18-23" pos="word" morph="none" start_char="2224" end_char="2227">said</TOKEN>
<TOKEN id="token-18-24" pos="punct" morph="none" start_char="2228" end_char="2228">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2230" end_char="2264">
<ORIGINAL_TEXT>"It was made a number of years ago.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="punct" morph="none" start_char="2230" end_char="2230">"</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2231" end_char="2232">It</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2234" end_char="2236">was</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2238" end_char="2241">made</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2243" end_char="2243">a</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2245" end_char="2250">number</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2252" end_char="2253">of</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2255" end_char="2259">years</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2261" end_char="2263">ago</TOKEN>
<TOKEN id="token-19-9" pos="punct" morph="none" start_char="2264" end_char="2264">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2266" end_char="2299">
<ORIGINAL_TEXT>Who was president then, I wonder?"</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2266" end_char="2268">Who</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2270" end_char="2272">was</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2274" end_char="2282">president</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2284" end_char="2287">then</TOKEN>
<TOKEN id="token-20-4" pos="punct" morph="none" start_char="2288" end_char="2288">,</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2290" end_char="2290">I</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2292" end_char="2297">wonder</TOKEN>
<TOKEN id="token-20-7" pos="punct" morph="none" start_char="2298" end_char="2299">?"</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2302" end_char="2344">
<ORIGINAL_TEXT>Other politicians also jumped on the claim.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2302" end_char="2306">Other</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2308" end_char="2318">politicians</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2320" end_char="2323">also</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2325" end_char="2330">jumped</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2332" end_char="2333">on</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="2335" end_char="2337">the</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2339" end_char="2343">claim</TOKEN>
<TOKEN id="token-21-7" pos="punct" morph="none" start_char="2344" end_char="2344">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2346" end_char="2349">
<ORIGINAL_TEXT>Sen.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2346" end_char="2348">Sen</TOKEN>
<TOKEN id="token-22-1" pos="punct" morph="none" start_char="2349" end_char="2349">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2351" end_char="2369">
<ORIGINAL_TEXT>Tom Cotton (R-Ark.)</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2351" end_char="2353">Tom</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2355" end_char="2360">Cotton</TOKEN>
<TOKEN id="token-23-2" pos="punct" morph="none" start_char="2362" end_char="2362">(</TOKEN>
<TOKEN id="token-23-3" pos="unknown" morph="none" start_char="2363" end_char="2367">R-Ark</TOKEN>
<TOKEN id="token-23-4" pos="punct" morph="none" start_char="2368" end_char="2369">.)</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2371" end_char="2454">
<ORIGINAL_TEXT>accused the Chinese government of covering up its involvement in the virus’ origins.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="2371" end_char="2377">accused</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="2379" end_char="2381">the</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="2383" end_char="2389">Chinese</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="2391" end_char="2400">government</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="2402" end_char="2403">of</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="2405" end_char="2412">covering</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="2414" end_char="2415">up</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="2417" end_char="2419">its</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="2421" end_char="2431">involvement</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="2433" end_char="2434">in</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="2436" end_char="2438">the</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="2440" end_char="2444">virus</TOKEN>
<TOKEN id="token-24-12" pos="punct" morph="none" start_char="2445" end_char="2445">’</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="2447" end_char="2453">origins</TOKEN>
<TOKEN id="token-24-14" pos="punct" morph="none" start_char="2454" end_char="2454">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2456" end_char="2601">
<ORIGINAL_TEXT>"This evidence is circumstantial, to be sure, but it all points toward the Wuhan labs," the senator wrote in an op-ed for The Wall Street Journal.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="punct" morph="none" start_char="2456" end_char="2456">"</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="2457" end_char="2460">This</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="2462" end_char="2469">evidence</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="2471" end_char="2472">is</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="2474" end_char="2487">circumstantial</TOKEN>
<TOKEN id="token-25-5" pos="punct" morph="none" start_char="2488" end_char="2488">,</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="2490" end_char="2491">to</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="2493" end_char="2494">be</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="2496" end_char="2499">sure</TOKEN>
<TOKEN id="token-25-9" pos="punct" morph="none" start_char="2500" end_char="2500">,</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="2502" end_char="2504">but</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="2506" end_char="2507">it</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="2509" end_char="2511">all</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="2513" end_char="2518">points</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="2520" end_char="2525">toward</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="2527" end_char="2529">the</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="2531" end_char="2535">Wuhan</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="2537" end_char="2540">labs</TOKEN>
<TOKEN id="token-25-18" pos="punct" morph="none" start_char="2541" end_char="2542">,"</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="2544" end_char="2546">the</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="2548" end_char="2554">senator</TOKEN>
<TOKEN id="token-25-21" pos="word" morph="none" start_char="2556" end_char="2560">wrote</TOKEN>
<TOKEN id="token-25-22" pos="word" morph="none" start_char="2562" end_char="2563">in</TOKEN>
<TOKEN id="token-25-23" pos="word" morph="none" start_char="2565" end_char="2566">an</TOKEN>
<TOKEN id="token-25-24" pos="unknown" morph="none" start_char="2568" end_char="2572">op-ed</TOKEN>
<TOKEN id="token-25-25" pos="word" morph="none" start_char="2574" end_char="2576">for</TOKEN>
<TOKEN id="token-25-26" pos="word" morph="none" start_char="2578" end_char="2580">The</TOKEN>
<TOKEN id="token-25-27" pos="word" morph="none" start_char="2582" end_char="2585">Wall</TOKEN>
<TOKEN id="token-25-28" pos="word" morph="none" start_char="2587" end_char="2592">Street</TOKEN>
<TOKEN id="token-25-29" pos="word" morph="none" start_char="2594" end_char="2600">Journal</TOKEN>
<TOKEN id="token-25-30" pos="punct" morph="none" start_char="2601" end_char="2601">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="2604" end_char="2695">
<ORIGINAL_TEXT>Last week, President Trump also blamed Obama for the lack of coronavirus testing in the U.S.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="2604" end_char="2607">Last</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="2609" end_char="2612">week</TOKEN>
<TOKEN id="token-26-2" pos="punct" morph="none" start_char="2613" end_char="2613">,</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="2615" end_char="2623">President</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="2625" end_char="2629">Trump</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="2631" end_char="2634">also</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="2636" end_char="2641">blamed</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="2643" end_char="2647">Obama</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="2649" end_char="2651">for</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="2653" end_char="2655">the</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="2657" end_char="2660">lack</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="2662" end_char="2663">of</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="2665" end_char="2675">coronavirus</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="2677" end_char="2683">testing</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="2685" end_char="2686">in</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="2688" end_char="2690">the</TOKEN>
<TOKEN id="token-26-16" pos="unknown" morph="none" start_char="2692" end_char="2694">U.S</TOKEN>
<TOKEN id="token-26-17" pos="punct" morph="none" start_char="2695" end_char="2695">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="2698" end_char="2827">
<ORIGINAL_TEXT>In April, Trump also wondered why Obama hadn’t endorsed Joe Biden days after Bernie Sanders dropped out of the Democratic primary.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="2698" end_char="2699">In</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="2701" end_char="2705">April</TOKEN>
<TOKEN id="token-27-2" pos="punct" morph="none" start_char="2706" end_char="2706">,</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="2708" end_char="2712">Trump</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="2714" end_char="2717">also</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="2719" end_char="2726">wondered</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="2728" end_char="2730">why</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="2732" end_char="2736">Obama</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="2738" end_char="2743">hadn’t</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="2745" end_char="2752">endorsed</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="2754" end_char="2756">Joe</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="2758" end_char="2762">Biden</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="2764" end_char="2767">days</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="2769" end_char="2773">after</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="2775" end_char="2780">Bernie</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="2782" end_char="2788">Sanders</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="2790" end_char="2796">dropped</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="2798" end_char="2800">out</TOKEN>
<TOKEN id="token-27-18" pos="word" morph="none" start_char="2802" end_char="2803">of</TOKEN>
<TOKEN id="token-27-19" pos="word" morph="none" start_char="2805" end_char="2807">the</TOKEN>
<TOKEN id="token-27-20" pos="word" morph="none" start_char="2809" end_char="2818">Democratic</TOKEN>
<TOKEN id="token-27-21" pos="word" morph="none" start_char="2820" end_char="2826">primary</TOKEN>
<TOKEN id="token-27-22" pos="punct" morph="none" start_char="2827" end_char="2827">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
