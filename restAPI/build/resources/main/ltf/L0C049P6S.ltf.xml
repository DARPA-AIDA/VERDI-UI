<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="ukr">
<DOC id="L0C049P6S" lang="ukr" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="7366" raw_text_md5="399705cbecb81005c08b4ddd7c49b891">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="83">
<ORIGINAL_TEXT>Fact Check: There is NOT An 'Irrefutable Paper Trail' To Prove COVID-19 Is Lab-made</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="4">Fact</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="6" end_char="10">Check</TOKEN>
<TOKEN id="token-0-2" pos="punct" morph="none" start_char="11" end_char="11">:</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="13" end_char="17">There</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="19" end_char="20">is</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="22" end_char="24">NOT</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="26" end_char="27">An</TOKEN>
<TOKEN id="token-0-7" pos="punct" morph="none" start_char="29" end_char="29">'</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="30" end_char="40">Irrefutable</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="42" end_char="46">Paper</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="48" end_char="52">Trail</TOKEN>
<TOKEN id="token-0-11" pos="punct" morph="none" start_char="53" end_char="53">'</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="55" end_char="56">To</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="58" end_char="62">Prove</TOKEN>
<TOKEN id="token-0-14" pos="unknown" morph="none" start_char="64" end_char="71">COVID-19</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="73" end_char="74">Is</TOKEN>
<TOKEN id="token-0-16" pos="unknown" morph="none" start_char="76" end_char="83">Lab-made</TOKEN>
</SEG>
<SEG id="segment-1" start_char="88" end_char="99">
<ORIGINAL_TEXT>Loaded Query</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="88" end_char="93">Loaded</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="95" end_char="99">Query</TOKEN>
</SEG>
<SEG id="segment-2" start_char="103" end_char="193">
<ORIGINAL_TEXT>Is there an "irrefutable paper trail" that shows COVID-19 was manufactured in a laboratory?</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="103" end_char="104">Is</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="106" end_char="110">there</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="112" end_char="113">an</TOKEN>
<TOKEN id="token-2-3" pos="punct" morph="none" start_char="115" end_char="115">"</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="116" end_char="126">irrefutable</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="128" end_char="132">paper</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="134" end_char="138">trail</TOKEN>
<TOKEN id="token-2-7" pos="punct" morph="none" start_char="139" end_char="139">"</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="141" end_char="144">that</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="146" end_char="150">shows</TOKEN>
<TOKEN id="token-2-10" pos="unknown" morph="none" start_char="152" end_char="159">COVID-19</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="161" end_char="163">was</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="165" end_char="176">manufactured</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="178" end_char="179">in</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="181" end_char="181">a</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="183" end_char="192">laboratory</TOKEN>
<TOKEN id="token-2-16" pos="punct" morph="none" start_char="193" end_char="193">?</TOKEN>
</SEG>
<SEG id="segment-3" start_char="195" end_char="632">
<ORIGINAL_TEXT>No, that's not true: Screenshots taken from the rapid-fire display of documents in the video making that claim show only that a number of scientists have in the past worried that lab tests on a coronavirus could lead to an outbreak, that the U.S. Centers for Disease Control and Prevention once patented methods to detect a non-COVID-19 coronavirus, and that other conspiracy-mongers claim to have proven the pandemic of 2020 is man-made.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="195" end_char="196">No</TOKEN>
<TOKEN id="token-3-1" pos="punct" morph="none" start_char="197" end_char="197">,</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="199" end_char="204">that's</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="206" end_char="208">not</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="210" end_char="213">true</TOKEN>
<TOKEN id="token-3-5" pos="punct" morph="none" start_char="214" end_char="214">:</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="216" end_char="226">Screenshots</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="228" end_char="232">taken</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="234" end_char="237">from</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="239" end_char="241">the</TOKEN>
<TOKEN id="token-3-10" pos="unknown" morph="none" start_char="243" end_char="252">rapid-fire</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="254" end_char="260">display</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="262" end_char="263">of</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="265" end_char="273">documents</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="275" end_char="276">in</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="278" end_char="280">the</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="282" end_char="286">video</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="288" end_char="293">making</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="295" end_char="298">that</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="300" end_char="304">claim</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="306" end_char="309">show</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="311" end_char="314">only</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="316" end_char="319">that</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="321" end_char="321">a</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="323" end_char="328">number</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="330" end_char="331">of</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="333" end_char="342">scientists</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="344" end_char="347">have</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="349" end_char="350">in</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="352" end_char="354">the</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="356" end_char="359">past</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="361" end_char="367">worried</TOKEN>
<TOKEN id="token-3-32" pos="word" morph="none" start_char="369" end_char="372">that</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="374" end_char="376">lab</TOKEN>
<TOKEN id="token-3-34" pos="word" morph="none" start_char="378" end_char="382">tests</TOKEN>
<TOKEN id="token-3-35" pos="word" morph="none" start_char="384" end_char="385">on</TOKEN>
<TOKEN id="token-3-36" pos="word" morph="none" start_char="387" end_char="387">a</TOKEN>
<TOKEN id="token-3-37" pos="word" morph="none" start_char="389" end_char="399">coronavirus</TOKEN>
<TOKEN id="token-3-38" pos="word" morph="none" start_char="401" end_char="405">could</TOKEN>
<TOKEN id="token-3-39" pos="word" morph="none" start_char="407" end_char="410">lead</TOKEN>
<TOKEN id="token-3-40" pos="word" morph="none" start_char="412" end_char="413">to</TOKEN>
<TOKEN id="token-3-41" pos="word" morph="none" start_char="415" end_char="416">an</TOKEN>
<TOKEN id="token-3-42" pos="word" morph="none" start_char="418" end_char="425">outbreak</TOKEN>
<TOKEN id="token-3-43" pos="punct" morph="none" start_char="426" end_char="426">,</TOKEN>
<TOKEN id="token-3-44" pos="word" morph="none" start_char="428" end_char="431">that</TOKEN>
<TOKEN id="token-3-45" pos="word" morph="none" start_char="433" end_char="435">the</TOKEN>
<TOKEN id="token-3-46" pos="unknown" morph="none" start_char="437" end_char="439">U.S</TOKEN>
<TOKEN id="token-3-47" pos="punct" morph="none" start_char="440" end_char="440">.</TOKEN>
<TOKEN id="token-3-48" pos="word" morph="none" start_char="442" end_char="448">Centers</TOKEN>
<TOKEN id="token-3-49" pos="word" morph="none" start_char="450" end_char="452">for</TOKEN>
<TOKEN id="token-3-50" pos="word" morph="none" start_char="454" end_char="460">Disease</TOKEN>
<TOKEN id="token-3-51" pos="word" morph="none" start_char="462" end_char="468">Control</TOKEN>
<TOKEN id="token-3-52" pos="word" morph="none" start_char="470" end_char="472">and</TOKEN>
<TOKEN id="token-3-53" pos="word" morph="none" start_char="474" end_char="483">Prevention</TOKEN>
<TOKEN id="token-3-54" pos="word" morph="none" start_char="485" end_char="488">once</TOKEN>
<TOKEN id="token-3-55" pos="word" morph="none" start_char="490" end_char="497">patented</TOKEN>
<TOKEN id="token-3-56" pos="word" morph="none" start_char="499" end_char="505">methods</TOKEN>
<TOKEN id="token-3-57" pos="word" morph="none" start_char="507" end_char="508">to</TOKEN>
<TOKEN id="token-3-58" pos="word" morph="none" start_char="510" end_char="515">detect</TOKEN>
<TOKEN id="token-3-59" pos="word" morph="none" start_char="517" end_char="517">a</TOKEN>
<TOKEN id="token-3-60" pos="unknown" morph="none" start_char="519" end_char="530">non-COVID-19</TOKEN>
<TOKEN id="token-3-61" pos="word" morph="none" start_char="532" end_char="542">coronavirus</TOKEN>
<TOKEN id="token-3-62" pos="punct" morph="none" start_char="543" end_char="543">,</TOKEN>
<TOKEN id="token-3-63" pos="word" morph="none" start_char="545" end_char="547">and</TOKEN>
<TOKEN id="token-3-64" pos="word" morph="none" start_char="549" end_char="552">that</TOKEN>
<TOKEN id="token-3-65" pos="word" morph="none" start_char="554" end_char="558">other</TOKEN>
<TOKEN id="token-3-66" pos="unknown" morph="none" start_char="560" end_char="577">conspiracy-mongers</TOKEN>
<TOKEN id="token-3-67" pos="word" morph="none" start_char="579" end_char="583">claim</TOKEN>
<TOKEN id="token-3-68" pos="word" morph="none" start_char="585" end_char="586">to</TOKEN>
<TOKEN id="token-3-69" pos="word" morph="none" start_char="588" end_char="591">have</TOKEN>
<TOKEN id="token-3-70" pos="word" morph="none" start_char="593" end_char="598">proven</TOKEN>
<TOKEN id="token-3-71" pos="word" morph="none" start_char="600" end_char="602">the</TOKEN>
<TOKEN id="token-3-72" pos="word" morph="none" start_char="604" end_char="611">pandemic</TOKEN>
<TOKEN id="token-3-73" pos="word" morph="none" start_char="613" end_char="614">of</TOKEN>
<TOKEN id="token-3-74" pos="word" morph="none" start_char="616" end_char="619">2020</TOKEN>
<TOKEN id="token-3-75" pos="word" morph="none" start_char="621" end_char="622">is</TOKEN>
<TOKEN id="token-3-76" pos="unknown" morph="none" start_char="624" end_char="631">man-made</TOKEN>
<TOKEN id="token-3-77" pos="punct" morph="none" start_char="632" end_char="632">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="635" end_char="757">
<ORIGINAL_TEXT>The claim appears in a Facebook video (archived here) posted by Ben Swann, a host of a Kremlin-controlled TV show, on Sept.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="635" end_char="637">The</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="639" end_char="643">claim</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="645" end_char="651">appears</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="653" end_char="654">in</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="656" end_char="656">a</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="658" end_char="665">Facebook</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="667" end_char="671">video</TOKEN>
<TOKEN id="token-4-7" pos="punct" morph="none" start_char="673" end_char="673">(</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="674" end_char="681">archived</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="683" end_char="686">here</TOKEN>
<TOKEN id="token-4-10" pos="punct" morph="none" start_char="687" end_char="687">)</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="689" end_char="694">posted</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="696" end_char="697">by</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="699" end_char="701">Ben</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="703" end_char="707">Swann</TOKEN>
<TOKEN id="token-4-15" pos="punct" morph="none" start_char="708" end_char="708">,</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="710" end_char="710">a</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="712" end_char="715">host</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="717" end_char="718">of</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="720" end_char="720">a</TOKEN>
<TOKEN id="token-4-20" pos="unknown" morph="none" start_char="722" end_char="739">Kremlin-controlled</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="741" end_char="742">TV</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="744" end_char="747">show</TOKEN>
<TOKEN id="token-4-23" pos="punct" morph="none" start_char="748" end_char="748">,</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="750" end_char="751">on</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="753" end_char="756">Sept</TOKEN>
<TOKEN id="token-4-26" pos="punct" morph="none" start_char="757" end_char="757">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="759" end_char="791">
<ORIGINAL_TEXT>5, 2020, with the following text:</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="759" end_char="759">5</TOKEN>
<TOKEN id="token-5-1" pos="punct" morph="none" start_char="760" end_char="760">,</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="762" end_char="765">2020</TOKEN>
<TOKEN id="token-5-3" pos="punct" morph="none" start_char="766" end_char="766">,</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="768" end_char="771">with</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="773" end_char="775">the</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="777" end_char="785">following</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="787" end_char="790">text</TOKEN>
<TOKEN id="token-5-8" pos="punct" morph="none" start_char="791" end_char="791">:</TOKEN>
</SEG>
<SEG id="segment-6" start_char="794" end_char="796">
<ORIGINAL_TEXT>Dr.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="794" end_char="795">Dr</TOKEN>
<TOKEN id="token-6-1" pos="punct" morph="none" start_char="796" end_char="796">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="798" end_char="922">
<ORIGINAL_TEXT>David Martin discusses the irrefutable paper trail that shows C0R0NAVlRUS was manipulated by DARPA, the NIH and Chinese Labs.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="798" end_char="802">David</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="804" end_char="809">Martin</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="811" end_char="819">discusses</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="821" end_char="823">the</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="825" end_char="835">irrefutable</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="837" end_char="841">paper</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="843" end_char="847">trail</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="849" end_char="852">that</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="854" end_char="858">shows</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="860" end_char="870">C0R0NAVlRUS</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="872" end_char="874">was</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="876" end_char="886">manipulated</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="888" end_char="889">by</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="891" end_char="895">DARPA</TOKEN>
<TOKEN id="token-7-14" pos="punct" morph="none" start_char="896" end_char="896">,</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="898" end_char="900">the</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="902" end_char="904">NIH</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="906" end_char="908">and</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="910" end_char="916">Chinese</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="918" end_char="921">Labs</TOKEN>
<TOKEN id="token-7-20" pos="punct" morph="none" start_char="922" end_char="922">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="924" end_char="985">
<ORIGINAL_TEXT>Nothing in this report is "theory", it is all documented fact.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="924" end_char="930">Nothing</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="932" end_char="933">in</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="935" end_char="938">this</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="940" end_char="945">report</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="947" end_char="948">is</TOKEN>
<TOKEN id="token-8-5" pos="punct" morph="none" start_char="950" end_char="950">"</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="951" end_char="956">theory</TOKEN>
<TOKEN id="token-8-7" pos="punct" morph="none" start_char="957" end_char="958">",</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="960" end_char="961">it</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="963" end_char="964">is</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="966" end_char="968">all</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="970" end_char="979">documented</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="981" end_char="984">fact</TOKEN>
<TOKEN id="token-8-13" pos="punct" morph="none" start_char="985" end_char="985">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="989" end_char="1057">
<ORIGINAL_TEXT>This is what the post looked like on Facebook at the time of writing:</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="989" end_char="992">This</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="994" end_char="995">is</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="997" end_char="1000">what</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1002" end_char="1004">the</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1006" end_char="1009">post</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1011" end_char="1016">looked</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1018" end_char="1021">like</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1023" end_char="1024">on</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1026" end_char="1033">Facebook</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1035" end_char="1036">at</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1038" end_char="1040">the</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1042" end_char="1045">time</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1047" end_char="1048">of</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1050" end_char="1056">writing</TOKEN>
<TOKEN id="token-9-14" pos="punct" morph="none" start_char="1057" end_char="1057">:</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1062" end_char="1127">
<ORIGINAL_TEXT>(Source: Facebook screenshot taken on Tue Sep 8 20:46:47 2020 UTC)</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="punct" morph="none" start_char="1062" end_char="1062">(</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1063" end_char="1068">Source</TOKEN>
<TOKEN id="token-10-2" pos="punct" morph="none" start_char="1069" end_char="1069">:</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1071" end_char="1078">Facebook</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1080" end_char="1089">screenshot</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1091" end_char="1095">taken</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1097" end_char="1098">on</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1100" end_char="1102">Tue</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1104" end_char="1106">Sep</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1108" end_char="1108">8</TOKEN>
<TOKEN id="token-10-10" pos="unknown" morph="none" start_char="1110" end_char="1117">20:46:47</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1119" end_char="1122">2020</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1124" end_char="1126">UTC</TOKEN>
<TOKEN id="token-10-13" pos="punct" morph="none" start_char="1127" end_char="1127">)</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1131" end_char="1247">
<ORIGINAL_TEXT>The video features Ben Swann, a host for Russia's global propaganda network -- RT -- and a businessman named David E.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1131" end_char="1133">The</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1135" end_char="1139">video</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1141" end_char="1148">features</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1150" end_char="1152">Ben</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1154" end_char="1158">Swann</TOKEN>
<TOKEN id="token-11-5" pos="punct" morph="none" start_char="1159" end_char="1159">,</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1161" end_char="1161">a</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1163" end_char="1166">host</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1168" end_char="1170">for</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1172" end_char="1179">Russia's</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1181" end_char="1186">global</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1188" end_char="1197">propaganda</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1199" end_char="1205">network</TOKEN>
<TOKEN id="token-11-13" pos="punct" morph="none" start_char="1207" end_char="1208">--</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1210" end_char="1211">RT</TOKEN>
<TOKEN id="token-11-15" pos="punct" morph="none" start_char="1213" end_char="1214">--</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1216" end_char="1218">and</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1220" end_char="1220">a</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1222" end_char="1232">businessman</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="1234" end_char="1238">named</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1240" end_char="1244">David</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="1246" end_char="1246">E</TOKEN>
<TOKEN id="token-11-22" pos="punct" morph="none" start_char="1247" end_char="1247">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1249" end_char="1427">
<ORIGINAL_TEXT>Martin who sells self-actualization books and has operated two small (sub $1.5 million) hedge funds and a trio of exchange-traded mutual funds, among other investing-related jobs.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1249" end_char="1254">Martin</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1256" end_char="1258">who</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1260" end_char="1264">sells</TOKEN>
<TOKEN id="token-12-3" pos="unknown" morph="none" start_char="1266" end_char="1283">self-actualization</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1285" end_char="1289">books</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1291" end_char="1293">and</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1295" end_char="1297">has</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1299" end_char="1306">operated</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1308" end_char="1310">two</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1312" end_char="1316">small</TOKEN>
<TOKEN id="token-12-10" pos="punct" morph="none" start_char="1318" end_char="1318">(</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1319" end_char="1321">sub</TOKEN>
<TOKEN id="token-12-12" pos="unknown" morph="none" start_char="1323" end_char="1326">$1.5</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1328" end_char="1334">million</TOKEN>
<TOKEN id="token-12-14" pos="punct" morph="none" start_char="1335" end_char="1335">)</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1337" end_char="1341">hedge</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1343" end_char="1347">funds</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1349" end_char="1351">and</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1353" end_char="1353">a</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1355" end_char="1358">trio</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1360" end_char="1361">of</TOKEN>
<TOKEN id="token-12-21" pos="unknown" morph="none" start_char="1363" end_char="1377">exchange-traded</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1379" end_char="1384">mutual</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="1386" end_char="1390">funds</TOKEN>
<TOKEN id="token-12-24" pos="punct" morph="none" start_char="1391" end_char="1391">,</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="1393" end_char="1397">among</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="1399" end_char="1403">other</TOKEN>
<TOKEN id="token-12-27" pos="unknown" morph="none" start_char="1405" end_char="1421">investing-related</TOKEN>
<TOKEN id="token-12-28" pos="word" morph="none" start_char="1423" end_char="1426">jobs</TOKEN>
<TOKEN id="token-12-29" pos="punct" morph="none" start_char="1427" end_char="1427">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1429" end_char="1515">
<ORIGINAL_TEXT>Although Martin is referred to as "doctor" throughout the video, he is not a physician.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1429" end_char="1436">Although</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1438" end_char="1443">Martin</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1445" end_char="1446">is</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1448" end_char="1455">referred</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1457" end_char="1458">to</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1460" end_char="1461">as</TOKEN>
<TOKEN id="token-13-6" pos="punct" morph="none" start_char="1463" end_char="1463">"</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1464" end_char="1469">doctor</TOKEN>
<TOKEN id="token-13-8" pos="punct" morph="none" start_char="1470" end_char="1470">"</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1472" end_char="1481">throughout</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1483" end_char="1485">the</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1487" end_char="1491">video</TOKEN>
<TOKEN id="token-13-12" pos="punct" morph="none" start_char="1492" end_char="1492">,</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1494" end_char="1495">he</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1497" end_char="1498">is</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1500" end_char="1502">not</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1504" end_char="1504">a</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1506" end_char="1514">physician</TOKEN>
<TOKEN id="token-13-18" pos="punct" morph="none" start_char="1515" end_char="1515">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1517" end_char="1660">
<ORIGINAL_TEXT>He has a Ph.D., but neither Martin's office nor the University of Virginia will confirm the discipline in which he received his doctoral degree.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1517" end_char="1518">He</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1520" end_char="1522">has</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1524" end_char="1524">a</TOKEN>
<TOKEN id="token-14-3" pos="unknown" morph="none" start_char="1526" end_char="1529">Ph.D</TOKEN>
<TOKEN id="token-14-4" pos="punct" morph="none" start_char="1530" end_char="1531">.,</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1533" end_char="1535">but</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1537" end_char="1543">neither</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1545" end_char="1552">Martin's</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1554" end_char="1559">office</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1561" end_char="1563">nor</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1565" end_char="1567">the</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1569" end_char="1578">University</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1580" end_char="1581">of</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1583" end_char="1590">Virginia</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="1592" end_char="1595">will</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1597" end_char="1603">confirm</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1605" end_char="1607">the</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="1609" end_char="1618">discipline</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="1620" end_char="1621">in</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="1623" end_char="1627">which</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="1629" end_char="1630">he</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="1632" end_char="1639">received</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="1641" end_char="1643">his</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="1645" end_char="1652">doctoral</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="1654" end_char="1659">degree</TOKEN>
<TOKEN id="token-14-25" pos="punct" morph="none" start_char="1660" end_char="1660">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1663" end_char="2009">
<ORIGINAL_TEXT>The video -- which opens with a fund-raising pitch for Swann's streaming video business -- uses quick-cut editing techniques and ominous added shadows to create the impression of documentary evidence piling up in support of a conspiracy theory: That the Defense Advanced Research Projects Agency paid for the creation of pandemic-creating viruses.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1663" end_char="1665">The</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1667" end_char="1671">video</TOKEN>
<TOKEN id="token-15-2" pos="punct" morph="none" start_char="1673" end_char="1674">--</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1676" end_char="1680">which</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1682" end_char="1686">opens</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1688" end_char="1691">with</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1693" end_char="1693">a</TOKEN>
<TOKEN id="token-15-7" pos="unknown" morph="none" start_char="1695" end_char="1706">fund-raising</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1708" end_char="1712">pitch</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1714" end_char="1716">for</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1718" end_char="1724">Swann's</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1726" end_char="1734">streaming</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1736" end_char="1740">video</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1742" end_char="1749">business</TOKEN>
<TOKEN id="token-15-14" pos="punct" morph="none" start_char="1751" end_char="1752">--</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="1754" end_char="1757">uses</TOKEN>
<TOKEN id="token-15-16" pos="unknown" morph="none" start_char="1759" end_char="1767">quick-cut</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="1769" end_char="1775">editing</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="1777" end_char="1786">techniques</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="1788" end_char="1790">and</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="1792" end_char="1798">ominous</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="1800" end_char="1804">added</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="1806" end_char="1812">shadows</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="1814" end_char="1815">to</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="1817" end_char="1822">create</TOKEN>
<TOKEN id="token-15-25" pos="word" morph="none" start_char="1824" end_char="1826">the</TOKEN>
<TOKEN id="token-15-26" pos="word" morph="none" start_char="1828" end_char="1837">impression</TOKEN>
<TOKEN id="token-15-27" pos="word" morph="none" start_char="1839" end_char="1840">of</TOKEN>
<TOKEN id="token-15-28" pos="word" morph="none" start_char="1842" end_char="1852">documentary</TOKEN>
<TOKEN id="token-15-29" pos="word" morph="none" start_char="1854" end_char="1861">evidence</TOKEN>
<TOKEN id="token-15-30" pos="word" morph="none" start_char="1863" end_char="1868">piling</TOKEN>
<TOKEN id="token-15-31" pos="word" morph="none" start_char="1870" end_char="1871">up</TOKEN>
<TOKEN id="token-15-32" pos="word" morph="none" start_char="1873" end_char="1874">in</TOKEN>
<TOKEN id="token-15-33" pos="word" morph="none" start_char="1876" end_char="1882">support</TOKEN>
<TOKEN id="token-15-34" pos="word" morph="none" start_char="1884" end_char="1885">of</TOKEN>
<TOKEN id="token-15-35" pos="word" morph="none" start_char="1887" end_char="1887">a</TOKEN>
<TOKEN id="token-15-36" pos="word" morph="none" start_char="1889" end_char="1898">conspiracy</TOKEN>
<TOKEN id="token-15-37" pos="word" morph="none" start_char="1900" end_char="1905">theory</TOKEN>
<TOKEN id="token-15-38" pos="punct" morph="none" start_char="1906" end_char="1906">:</TOKEN>
<TOKEN id="token-15-39" pos="word" morph="none" start_char="1908" end_char="1911">That</TOKEN>
<TOKEN id="token-15-40" pos="word" morph="none" start_char="1913" end_char="1915">the</TOKEN>
<TOKEN id="token-15-41" pos="word" morph="none" start_char="1917" end_char="1923">Defense</TOKEN>
<TOKEN id="token-15-42" pos="word" morph="none" start_char="1925" end_char="1932">Advanced</TOKEN>
<TOKEN id="token-15-43" pos="word" morph="none" start_char="1934" end_char="1941">Research</TOKEN>
<TOKEN id="token-15-44" pos="word" morph="none" start_char="1943" end_char="1950">Projects</TOKEN>
<TOKEN id="token-15-45" pos="word" morph="none" start_char="1952" end_char="1957">Agency</TOKEN>
<TOKEN id="token-15-46" pos="word" morph="none" start_char="1959" end_char="1962">paid</TOKEN>
<TOKEN id="token-15-47" pos="word" morph="none" start_char="1964" end_char="1966">for</TOKEN>
<TOKEN id="token-15-48" pos="word" morph="none" start_char="1968" end_char="1970">the</TOKEN>
<TOKEN id="token-15-49" pos="word" morph="none" start_char="1972" end_char="1979">creation</TOKEN>
<TOKEN id="token-15-50" pos="word" morph="none" start_char="1981" end_char="1982">of</TOKEN>
<TOKEN id="token-15-51" pos="unknown" morph="none" start_char="1984" end_char="2000">pandemic-creating</TOKEN>
<TOKEN id="token-15-52" pos="word" morph="none" start_char="2002" end_char="2008">viruses</TOKEN>
<TOKEN id="token-15-53" pos="punct" morph="none" start_char="2009" end_char="2009">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="2011" end_char="2266">
<ORIGINAL_TEXT>By examining each document, Lead Stories is able to show the gap in the evidentiary chain: No document shown in the video establishes that a lab-created virus caused the pandemic of 2020 and one of the documents offered as "proof" makes the opposite point.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="2011" end_char="2012">By</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="2014" end_char="2022">examining</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="2024" end_char="2027">each</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="2029" end_char="2036">document</TOKEN>
<TOKEN id="token-16-4" pos="punct" morph="none" start_char="2037" end_char="2037">,</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="2039" end_char="2042">Lead</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="2044" end_char="2050">Stories</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="2052" end_char="2053">is</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="2055" end_char="2058">able</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="2060" end_char="2061">to</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="2063" end_char="2066">show</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="2068" end_char="2070">the</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="2072" end_char="2074">gap</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="2076" end_char="2077">in</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="2079" end_char="2081">the</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="2083" end_char="2093">evidentiary</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="2095" end_char="2099">chain</TOKEN>
<TOKEN id="token-16-17" pos="punct" morph="none" start_char="2100" end_char="2100">:</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="2102" end_char="2103">No</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="2105" end_char="2112">document</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="2114" end_char="2118">shown</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="2120" end_char="2121">in</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="2123" end_char="2125">the</TOKEN>
<TOKEN id="token-16-23" pos="word" morph="none" start_char="2127" end_char="2131">video</TOKEN>
<TOKEN id="token-16-24" pos="word" morph="none" start_char="2133" end_char="2143">establishes</TOKEN>
<TOKEN id="token-16-25" pos="word" morph="none" start_char="2145" end_char="2148">that</TOKEN>
<TOKEN id="token-16-26" pos="word" morph="none" start_char="2150" end_char="2150">a</TOKEN>
<TOKEN id="token-16-27" pos="unknown" morph="none" start_char="2152" end_char="2162">lab-created</TOKEN>
<TOKEN id="token-16-28" pos="word" morph="none" start_char="2164" end_char="2168">virus</TOKEN>
<TOKEN id="token-16-29" pos="word" morph="none" start_char="2170" end_char="2175">caused</TOKEN>
<TOKEN id="token-16-30" pos="word" morph="none" start_char="2177" end_char="2179">the</TOKEN>
<TOKEN id="token-16-31" pos="word" morph="none" start_char="2181" end_char="2188">pandemic</TOKEN>
<TOKEN id="token-16-32" pos="word" morph="none" start_char="2190" end_char="2191">of</TOKEN>
<TOKEN id="token-16-33" pos="word" morph="none" start_char="2193" end_char="2196">2020</TOKEN>
<TOKEN id="token-16-34" pos="word" morph="none" start_char="2198" end_char="2200">and</TOKEN>
<TOKEN id="token-16-35" pos="word" morph="none" start_char="2202" end_char="2204">one</TOKEN>
<TOKEN id="token-16-36" pos="word" morph="none" start_char="2206" end_char="2207">of</TOKEN>
<TOKEN id="token-16-37" pos="word" morph="none" start_char="2209" end_char="2211">the</TOKEN>
<TOKEN id="token-16-38" pos="word" morph="none" start_char="2213" end_char="2221">documents</TOKEN>
<TOKEN id="token-16-39" pos="word" morph="none" start_char="2223" end_char="2229">offered</TOKEN>
<TOKEN id="token-16-40" pos="word" morph="none" start_char="2231" end_char="2232">as</TOKEN>
<TOKEN id="token-16-41" pos="punct" morph="none" start_char="2234" end_char="2234">"</TOKEN>
<TOKEN id="token-16-42" pos="word" morph="none" start_char="2235" end_char="2239">proof</TOKEN>
<TOKEN id="token-16-43" pos="punct" morph="none" start_char="2240" end_char="2240">"</TOKEN>
<TOKEN id="token-16-44" pos="word" morph="none" start_char="2242" end_char="2246">makes</TOKEN>
<TOKEN id="token-16-45" pos="word" morph="none" start_char="2248" end_char="2250">the</TOKEN>
<TOKEN id="token-16-46" pos="word" morph="none" start_char="2252" end_char="2259">opposite</TOKEN>
<TOKEN id="token-16-47" pos="word" morph="none" start_char="2261" end_char="2265">point</TOKEN>
<TOKEN id="token-16-48" pos="punct" morph="none" start_char="2266" end_char="2266">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2269" end_char="2367">
<ORIGINAL_TEXT>The video makes claims easily disproved in public documents, DARPA Chief of Communications Jared B.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2269" end_char="2271">The</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2273" end_char="2277">video</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2279" end_char="2283">makes</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2285" end_char="2290">claims</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2292" end_char="2297">easily</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2299" end_char="2307">disproved</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2309" end_char="2310">in</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2312" end_char="2317">public</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2319" end_char="2327">documents</TOKEN>
<TOKEN id="token-17-9" pos="punct" morph="none" start_char="2328" end_char="2328">,</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2330" end_char="2334">DARPA</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2336" end_char="2340">Chief</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2342" end_char="2343">of</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2345" end_char="2358">Communications</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2360" end_char="2364">Jared</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2366" end_char="2366">B</TOKEN>
<TOKEN id="token-17-16" pos="punct" morph="none" start_char="2367" end_char="2367">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2369" end_char="2389">
<ORIGINAL_TEXT>Adams said in a Sept.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2369" end_char="2373">Adams</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2375" end_char="2378">said</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2380" end_char="2381">in</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2383" end_char="2383">a</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2385" end_char="2388">Sept</TOKEN>
<TOKEN id="token-18-5" pos="punct" morph="none" start_char="2389" end_char="2389">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2391" end_char="2421">
<ORIGINAL_TEXT>9, 2020, email to Lead Stories.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2391" end_char="2391">9</TOKEN>
<TOKEN id="token-19-1" pos="punct" morph="none" start_char="2392" end_char="2392">,</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2394" end_char="2397">2020</TOKEN>
<TOKEN id="token-19-3" pos="punct" morph="none" start_char="2398" end_char="2398">,</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2400" end_char="2404">email</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2406" end_char="2407">to</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2409" end_char="2412">Lead</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2414" end_char="2420">Stories</TOKEN>
<TOKEN id="token-19-8" pos="punct" morph="none" start_char="2421" end_char="2421">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2423" end_char="2476">
<ORIGINAL_TEXT>For starters, he said, DARPA has never worked with Dr.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2423" end_char="2425">For</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2427" end_char="2434">starters</TOKEN>
<TOKEN id="token-20-2" pos="punct" morph="none" start_char="2435" end_char="2435">,</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2437" end_char="2438">he</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2440" end_char="2443">said</TOKEN>
<TOKEN id="token-20-5" pos="punct" morph="none" start_char="2444" end_char="2444">,</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2446" end_char="2450">DARPA</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2452" end_char="2454">has</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="2456" end_char="2460">never</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2462" end_char="2467">worked</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2469" end_char="2472">with</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="2474" end_char="2475">Dr</TOKEN>
<TOKEN id="token-20-12" pos="punct" morph="none" start_char="2476" end_char="2476">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2478" end_char="2598">
<ORIGINAL_TEXT>Ralph Baric, the University of North Carolina virologist Swann and Martin claim is in the thick of a COVID-19 conspiracy.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2478" end_char="2482">Ralph</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2484" end_char="2488">Baric</TOKEN>
<TOKEN id="token-21-2" pos="punct" morph="none" start_char="2489" end_char="2489">,</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2491" end_char="2493">the</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2495" end_char="2504">University</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="2506" end_char="2507">of</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2509" end_char="2513">North</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="2515" end_char="2522">Carolina</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="2524" end_char="2533">virologist</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="2535" end_char="2539">Swann</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="2541" end_char="2543">and</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="2545" end_char="2550">Martin</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="2552" end_char="2556">claim</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="2558" end_char="2559">is</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="2561" end_char="2562">in</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="2564" end_char="2566">the</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="2568" end_char="2572">thick</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="2574" end_char="2575">of</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="2577" end_char="2577">a</TOKEN>
<TOKEN id="token-21-19" pos="unknown" morph="none" start_char="2579" end_char="2586">COVID-19</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="2588" end_char="2597">conspiracy</TOKEN>
<TOKEN id="token-21-21" pos="punct" morph="none" start_char="2598" end_char="2598">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2600" end_char="2610">
<ORIGINAL_TEXT>From Adams:</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2600" end_char="2603">From</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2605" end_char="2609">Adams</TOKEN>
<TOKEN id="token-22-2" pos="punct" morph="none" start_char="2610" end_char="2610">:</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2613" end_char="2895">
<ORIGINAL_TEXT>Like all conspiracy theorists, Swann and Martin build on elements of truth and then add false and/or misleading claims...DARPA's research concerning zoonosis or the animal origins of viral pathogens began in 2018, not earlier in 2005 nor in 1999-2001 as the video incorrectly claims.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2613" end_char="2616">Like</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2618" end_char="2620">all</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2622" end_char="2631">conspiracy</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2633" end_char="2641">theorists</TOKEN>
<TOKEN id="token-23-4" pos="punct" morph="none" start_char="2642" end_char="2642">,</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="2644" end_char="2648">Swann</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="2650" end_char="2652">and</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="2654" end_char="2659">Martin</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="2661" end_char="2665">build</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="2667" end_char="2668">on</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="2670" end_char="2677">elements</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="2679" end_char="2680">of</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="2682" end_char="2686">truth</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="2688" end_char="2690">and</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="2692" end_char="2695">then</TOKEN>
<TOKEN id="token-23-15" pos="word" morph="none" start_char="2697" end_char="2699">add</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="2701" end_char="2705">false</TOKEN>
<TOKEN id="token-23-17" pos="unknown" morph="none" start_char="2707" end_char="2712">and/or</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="2714" end_char="2723">misleading</TOKEN>
<TOKEN id="token-23-19" pos="unknown" morph="none" start_char="2725" end_char="2740">claims...DARPA's</TOKEN>
<TOKEN id="token-23-20" pos="word" morph="none" start_char="2742" end_char="2749">research</TOKEN>
<TOKEN id="token-23-21" pos="word" morph="none" start_char="2751" end_char="2760">concerning</TOKEN>
<TOKEN id="token-23-22" pos="word" morph="none" start_char="2762" end_char="2769">zoonosis</TOKEN>
<TOKEN id="token-23-23" pos="word" morph="none" start_char="2771" end_char="2772">or</TOKEN>
<TOKEN id="token-23-24" pos="word" morph="none" start_char="2774" end_char="2776">the</TOKEN>
<TOKEN id="token-23-25" pos="word" morph="none" start_char="2778" end_char="2783">animal</TOKEN>
<TOKEN id="token-23-26" pos="word" morph="none" start_char="2785" end_char="2791">origins</TOKEN>
<TOKEN id="token-23-27" pos="word" morph="none" start_char="2793" end_char="2794">of</TOKEN>
<TOKEN id="token-23-28" pos="word" morph="none" start_char="2796" end_char="2800">viral</TOKEN>
<TOKEN id="token-23-29" pos="word" morph="none" start_char="2802" end_char="2810">pathogens</TOKEN>
<TOKEN id="token-23-30" pos="word" morph="none" start_char="2812" end_char="2816">began</TOKEN>
<TOKEN id="token-23-31" pos="word" morph="none" start_char="2818" end_char="2819">in</TOKEN>
<TOKEN id="token-23-32" pos="word" morph="none" start_char="2821" end_char="2824">2018</TOKEN>
<TOKEN id="token-23-33" pos="punct" morph="none" start_char="2825" end_char="2825">,</TOKEN>
<TOKEN id="token-23-34" pos="word" morph="none" start_char="2827" end_char="2829">not</TOKEN>
<TOKEN id="token-23-35" pos="word" morph="none" start_char="2831" end_char="2837">earlier</TOKEN>
<TOKEN id="token-23-36" pos="word" morph="none" start_char="2839" end_char="2840">in</TOKEN>
<TOKEN id="token-23-37" pos="word" morph="none" start_char="2842" end_char="2845">2005</TOKEN>
<TOKEN id="token-23-38" pos="word" morph="none" start_char="2847" end_char="2849">nor</TOKEN>
<TOKEN id="token-23-39" pos="word" morph="none" start_char="2851" end_char="2852">in</TOKEN>
<TOKEN id="token-23-40" pos="unknown" morph="none" start_char="2854" end_char="2862">1999-2001</TOKEN>
<TOKEN id="token-23-41" pos="word" morph="none" start_char="2864" end_char="2865">as</TOKEN>
<TOKEN id="token-23-42" pos="word" morph="none" start_char="2867" end_char="2869">the</TOKEN>
<TOKEN id="token-23-43" pos="word" morph="none" start_char="2871" end_char="2875">video</TOKEN>
<TOKEN id="token-23-44" pos="word" morph="none" start_char="2877" end_char="2887">incorrectly</TOKEN>
<TOKEN id="token-23-45" pos="word" morph="none" start_char="2889" end_char="2894">claims</TOKEN>
<TOKEN id="token-23-46" pos="punct" morph="none" start_char="2895" end_char="2895">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2897" end_char="3144">
<ORIGINAL_TEXT>DARPA would certainly welcome seeing the "trail of evidence" Swann has that ties the good professor to the agency considering the micro flashes of paper in the YouTube video prove nothing other than that Baric is active in publishing and patenting.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="2897" end_char="2901">DARPA</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="2903" end_char="2907">would</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="2909" end_char="2917">certainly</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="2919" end_char="2925">welcome</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="2927" end_char="2932">seeing</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="2934" end_char="2936">the</TOKEN>
<TOKEN id="token-24-6" pos="punct" morph="none" start_char="2938" end_char="2938">"</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="2939" end_char="2943">trail</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="2945" end_char="2946">of</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="2948" end_char="2955">evidence</TOKEN>
<TOKEN id="token-24-10" pos="punct" morph="none" start_char="2956" end_char="2956">"</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="2958" end_char="2962">Swann</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="2964" end_char="2966">has</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="2968" end_char="2971">that</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="2973" end_char="2976">ties</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="2978" end_char="2980">the</TOKEN>
<TOKEN id="token-24-16" pos="word" morph="none" start_char="2982" end_char="2985">good</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="2987" end_char="2995">professor</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="2997" end_char="2998">to</TOKEN>
<TOKEN id="token-24-19" pos="word" morph="none" start_char="3000" end_char="3002">the</TOKEN>
<TOKEN id="token-24-20" pos="word" morph="none" start_char="3004" end_char="3009">agency</TOKEN>
<TOKEN id="token-24-21" pos="word" morph="none" start_char="3011" end_char="3021">considering</TOKEN>
<TOKEN id="token-24-22" pos="word" morph="none" start_char="3023" end_char="3025">the</TOKEN>
<TOKEN id="token-24-23" pos="word" morph="none" start_char="3027" end_char="3031">micro</TOKEN>
<TOKEN id="token-24-24" pos="word" morph="none" start_char="3033" end_char="3039">flashes</TOKEN>
<TOKEN id="token-24-25" pos="word" morph="none" start_char="3041" end_char="3042">of</TOKEN>
<TOKEN id="token-24-26" pos="word" morph="none" start_char="3044" end_char="3048">paper</TOKEN>
<TOKEN id="token-24-27" pos="word" morph="none" start_char="3050" end_char="3051">in</TOKEN>
<TOKEN id="token-24-28" pos="word" morph="none" start_char="3053" end_char="3055">the</TOKEN>
<TOKEN id="token-24-29" pos="word" morph="none" start_char="3057" end_char="3063">YouTube</TOKEN>
<TOKEN id="token-24-30" pos="word" morph="none" start_char="3065" end_char="3069">video</TOKEN>
<TOKEN id="token-24-31" pos="word" morph="none" start_char="3071" end_char="3075">prove</TOKEN>
<TOKEN id="token-24-32" pos="word" morph="none" start_char="3077" end_char="3083">nothing</TOKEN>
<TOKEN id="token-24-33" pos="word" morph="none" start_char="3085" end_char="3089">other</TOKEN>
<TOKEN id="token-24-34" pos="word" morph="none" start_char="3091" end_char="3094">than</TOKEN>
<TOKEN id="token-24-35" pos="word" morph="none" start_char="3096" end_char="3099">that</TOKEN>
<TOKEN id="token-24-36" pos="word" morph="none" start_char="3101" end_char="3105">Baric</TOKEN>
<TOKEN id="token-24-37" pos="word" morph="none" start_char="3107" end_char="3108">is</TOKEN>
<TOKEN id="token-24-38" pos="word" morph="none" start_char="3110" end_char="3115">active</TOKEN>
<TOKEN id="token-24-39" pos="word" morph="none" start_char="3117" end_char="3118">in</TOKEN>
<TOKEN id="token-24-40" pos="word" morph="none" start_char="3120" end_char="3129">publishing</TOKEN>
<TOKEN id="token-24-41" pos="word" morph="none" start_char="3131" end_char="3133">and</TOKEN>
<TOKEN id="token-24-42" pos="word" morph="none" start_char="3135" end_char="3143">patenting</TOKEN>
<TOKEN id="token-24-43" pos="punct" morph="none" start_char="3144" end_char="3144">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="3146" end_char="3279">
<ORIGINAL_TEXT>More important than these supposed ties, however, is that DARPA is not now nor has it ever been involved in gain of function research.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="3146" end_char="3149">More</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="3151" end_char="3159">important</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="3161" end_char="3164">than</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="3166" end_char="3170">these</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="3172" end_char="3179">supposed</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="3181" end_char="3184">ties</TOKEN>
<TOKEN id="token-25-6" pos="punct" morph="none" start_char="3185" end_char="3185">,</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="3187" end_char="3193">however</TOKEN>
<TOKEN id="token-25-8" pos="punct" morph="none" start_char="3194" end_char="3194">,</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="3196" end_char="3197">is</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="3199" end_char="3202">that</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="3204" end_char="3208">DARPA</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="3210" end_char="3211">is</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="3213" end_char="3215">not</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="3217" end_char="3219">now</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="3221" end_char="3223">nor</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="3225" end_char="3227">has</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="3229" end_char="3230">it</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="3232" end_char="3235">ever</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="3237" end_char="3240">been</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="3242" end_char="3249">involved</TOKEN>
<TOKEN id="token-25-21" pos="word" morph="none" start_char="3251" end_char="3252">in</TOKEN>
<TOKEN id="token-25-22" pos="word" morph="none" start_char="3254" end_char="3257">gain</TOKEN>
<TOKEN id="token-25-23" pos="word" morph="none" start_char="3259" end_char="3260">of</TOKEN>
<TOKEN id="token-25-24" pos="word" morph="none" start_char="3262" end_char="3269">function</TOKEN>
<TOKEN id="token-25-25" pos="word" morph="none" start_char="3271" end_char="3278">research</TOKEN>
<TOKEN id="token-25-26" pos="punct" morph="none" start_char="3279" end_char="3279">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="3281" end_char="3547">
<ORIGINAL_TEXT>If Swann had an ounce of journalistic integrity, which he obviously does not, he could easily talk to any of our PREEMPT researchers and/or review extant literature and realize pretty quickly that DARPA is not making bioweapons: (Full listing of PREEPMT researchers).</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="3281" end_char="3282">If</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="3284" end_char="3288">Swann</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="3290" end_char="3292">had</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="3294" end_char="3295">an</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="3297" end_char="3301">ounce</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="3303" end_char="3304">of</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="3306" end_char="3317">journalistic</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="3319" end_char="3327">integrity</TOKEN>
<TOKEN id="token-26-8" pos="punct" morph="none" start_char="3328" end_char="3328">,</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="3330" end_char="3334">which</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="3336" end_char="3337">he</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="3339" end_char="3347">obviously</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="3349" end_char="3352">does</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="3354" end_char="3356">not</TOKEN>
<TOKEN id="token-26-14" pos="punct" morph="none" start_char="3357" end_char="3357">,</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="3359" end_char="3360">he</TOKEN>
<TOKEN id="token-26-16" pos="word" morph="none" start_char="3362" end_char="3366">could</TOKEN>
<TOKEN id="token-26-17" pos="word" morph="none" start_char="3368" end_char="3373">easily</TOKEN>
<TOKEN id="token-26-18" pos="word" morph="none" start_char="3375" end_char="3378">talk</TOKEN>
<TOKEN id="token-26-19" pos="word" morph="none" start_char="3380" end_char="3381">to</TOKEN>
<TOKEN id="token-26-20" pos="word" morph="none" start_char="3383" end_char="3385">any</TOKEN>
<TOKEN id="token-26-21" pos="word" morph="none" start_char="3387" end_char="3388">of</TOKEN>
<TOKEN id="token-26-22" pos="word" morph="none" start_char="3390" end_char="3392">our</TOKEN>
<TOKEN id="token-26-23" pos="word" morph="none" start_char="3394" end_char="3400">PREEMPT</TOKEN>
<TOKEN id="token-26-24" pos="word" morph="none" start_char="3402" end_char="3412">researchers</TOKEN>
<TOKEN id="token-26-25" pos="unknown" morph="none" start_char="3414" end_char="3419">and/or</TOKEN>
<TOKEN id="token-26-26" pos="word" morph="none" start_char="3421" end_char="3426">review</TOKEN>
<TOKEN id="token-26-27" pos="word" morph="none" start_char="3428" end_char="3433">extant</TOKEN>
<TOKEN id="token-26-28" pos="word" morph="none" start_char="3435" end_char="3444">literature</TOKEN>
<TOKEN id="token-26-29" pos="word" morph="none" start_char="3446" end_char="3448">and</TOKEN>
<TOKEN id="token-26-30" pos="word" morph="none" start_char="3450" end_char="3456">realize</TOKEN>
<TOKEN id="token-26-31" pos="word" morph="none" start_char="3458" end_char="3463">pretty</TOKEN>
<TOKEN id="token-26-32" pos="word" morph="none" start_char="3465" end_char="3471">quickly</TOKEN>
<TOKEN id="token-26-33" pos="word" morph="none" start_char="3473" end_char="3476">that</TOKEN>
<TOKEN id="token-26-34" pos="word" morph="none" start_char="3478" end_char="3482">DARPA</TOKEN>
<TOKEN id="token-26-35" pos="word" morph="none" start_char="3484" end_char="3485">is</TOKEN>
<TOKEN id="token-26-36" pos="word" morph="none" start_char="3487" end_char="3489">not</TOKEN>
<TOKEN id="token-26-37" pos="word" morph="none" start_char="3491" end_char="3496">making</TOKEN>
<TOKEN id="token-26-38" pos="word" morph="none" start_char="3498" end_char="3507">bioweapons</TOKEN>
<TOKEN id="token-26-39" pos="punct" morph="none" start_char="3508" end_char="3508">:</TOKEN>
<TOKEN id="token-26-40" pos="punct" morph="none" start_char="3510" end_char="3510">(</TOKEN>
<TOKEN id="token-26-41" pos="word" morph="none" start_char="3511" end_char="3514">Full</TOKEN>
<TOKEN id="token-26-42" pos="word" morph="none" start_char="3516" end_char="3522">listing</TOKEN>
<TOKEN id="token-26-43" pos="word" morph="none" start_char="3524" end_char="3525">of</TOKEN>
<TOKEN id="token-26-44" pos="word" morph="none" start_char="3527" end_char="3533">PREEPMT</TOKEN>
<TOKEN id="token-26-45" pos="word" morph="none" start_char="3535" end_char="3545">researchers</TOKEN>
<TOKEN id="token-26-46" pos="punct" morph="none" start_char="3546" end_char="3547">).</TOKEN>
</SEG>
<SEG id="segment-27" start_char="3549" end_char="3710">
<ORIGINAL_TEXT>Further, DARPA and the PREEMPT teams receive guidance from independent expert advisors in the ethical, legal, social, and regulatory aspects of the life sciences.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="3549" end_char="3555">Further</TOKEN>
<TOKEN id="token-27-1" pos="punct" morph="none" start_char="3556" end_char="3556">,</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="3558" end_char="3562">DARPA</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="3564" end_char="3566">and</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="3568" end_char="3570">the</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="3572" end_char="3578">PREEMPT</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="3580" end_char="3584">teams</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="3586" end_char="3592">receive</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="3594" end_char="3601">guidance</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="3603" end_char="3606">from</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="3608" end_char="3618">independent</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="3620" end_char="3625">expert</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="3627" end_char="3634">advisors</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="3636" end_char="3637">in</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="3639" end_char="3641">the</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="3643" end_char="3649">ethical</TOKEN>
<TOKEN id="token-27-16" pos="punct" morph="none" start_char="3650" end_char="3650">,</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="3652" end_char="3656">legal</TOKEN>
<TOKEN id="token-27-18" pos="punct" morph="none" start_char="3657" end_char="3657">,</TOKEN>
<TOKEN id="token-27-19" pos="word" morph="none" start_char="3659" end_char="3664">social</TOKEN>
<TOKEN id="token-27-20" pos="punct" morph="none" start_char="3665" end_char="3665">,</TOKEN>
<TOKEN id="token-27-21" pos="word" morph="none" start_char="3667" end_char="3669">and</TOKEN>
<TOKEN id="token-27-22" pos="word" morph="none" start_char="3671" end_char="3680">regulatory</TOKEN>
<TOKEN id="token-27-23" pos="word" morph="none" start_char="3682" end_char="3688">aspects</TOKEN>
<TOKEN id="token-27-24" pos="word" morph="none" start_char="3690" end_char="3691">of</TOKEN>
<TOKEN id="token-27-25" pos="word" morph="none" start_char="3693" end_char="3695">the</TOKEN>
<TOKEN id="token-27-26" pos="word" morph="none" start_char="3697" end_char="3700">life</TOKEN>
<TOKEN id="token-27-27" pos="word" morph="none" start_char="3702" end_char="3709">sciences</TOKEN>
<TOKEN id="token-27-28" pos="punct" morph="none" start_char="3710" end_char="3710">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3712" end_char="3843">
<ORIGINAL_TEXT>These individuals include Dr. Claudia Emerson, director of the Institute on Ethics Policy for Innovation at McMaster University; Dr.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="3712" end_char="3716">These</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="3718" end_char="3728">individuals</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="3730" end_char="3736">include</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="3738" end_char="3739">Dr</TOKEN>
<TOKEN id="token-28-4" pos="punct" morph="none" start_char="3740" end_char="3740">.</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="3742" end_char="3748">Claudia</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="3750" end_char="3756">Emerson</TOKEN>
<TOKEN id="token-28-7" pos="punct" morph="none" start_char="3757" end_char="3757">,</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="3759" end_char="3766">director</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="3768" end_char="3769">of</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="3771" end_char="3773">the</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="3775" end_char="3783">Institute</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="3785" end_char="3786">on</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="3788" end_char="3793">Ethics</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="3795" end_char="3800">Policy</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="3802" end_char="3804">for</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="3806" end_char="3815">Innovation</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="3817" end_char="3818">at</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="3820" end_char="3827">McMaster</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="3829" end_char="3838">University</TOKEN>
<TOKEN id="token-28-20" pos="punct" morph="none" start_char="3839" end_char="3839">;</TOKEN>
<TOKEN id="token-28-21" pos="word" morph="none" start_char="3841" end_char="3842">Dr</TOKEN>
<TOKEN id="token-28-22" pos="punct" morph="none" start_char="3843" end_char="3843">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3845" end_char="4034">
<ORIGINAL_TEXT>Matt Kasper, legislative liaison for the U.S. Navy's Bureau of Medicine and Surgery, and a former deputy director of field laboratory operations at the Naval Medical Research Center; and Dr.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="3845" end_char="3848">Matt</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="3850" end_char="3855">Kasper</TOKEN>
<TOKEN id="token-29-2" pos="punct" morph="none" start_char="3856" end_char="3856">,</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="3858" end_char="3868">legislative</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="3870" end_char="3876">liaison</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="3878" end_char="3880">for</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="3882" end_char="3884">the</TOKEN>
<TOKEN id="token-29-7" pos="unknown" morph="none" start_char="3886" end_char="3888">U.S</TOKEN>
<TOKEN id="token-29-8" pos="punct" morph="none" start_char="3889" end_char="3889">.</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="3891" end_char="3896">Navy's</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="3898" end_char="3903">Bureau</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="3905" end_char="3906">of</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="3908" end_char="3915">Medicine</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="3917" end_char="3919">and</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="3921" end_char="3927">Surgery</TOKEN>
<TOKEN id="token-29-15" pos="punct" morph="none" start_char="3928" end_char="3928">,</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="3930" end_char="3932">and</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="3934" end_char="3934">a</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="3936" end_char="3941">former</TOKEN>
<TOKEN id="token-29-19" pos="word" morph="none" start_char="3943" end_char="3948">deputy</TOKEN>
<TOKEN id="token-29-20" pos="word" morph="none" start_char="3950" end_char="3957">director</TOKEN>
<TOKEN id="token-29-21" pos="word" morph="none" start_char="3959" end_char="3960">of</TOKEN>
<TOKEN id="token-29-22" pos="word" morph="none" start_char="3962" end_char="3966">field</TOKEN>
<TOKEN id="token-29-23" pos="word" morph="none" start_char="3968" end_char="3977">laboratory</TOKEN>
<TOKEN id="token-29-24" pos="word" morph="none" start_char="3979" end_char="3988">operations</TOKEN>
<TOKEN id="token-29-25" pos="word" morph="none" start_char="3990" end_char="3991">at</TOKEN>
<TOKEN id="token-29-26" pos="word" morph="none" start_char="3993" end_char="3995">the</TOKEN>
<TOKEN id="token-29-27" pos="word" morph="none" start_char="3997" end_char="4001">Naval</TOKEN>
<TOKEN id="token-29-28" pos="word" morph="none" start_char="4003" end_char="4009">Medical</TOKEN>
<TOKEN id="token-29-29" pos="word" morph="none" start_char="4011" end_char="4018">Research</TOKEN>
<TOKEN id="token-29-30" pos="word" morph="none" start_char="4020" end_char="4025">Center</TOKEN>
<TOKEN id="token-29-31" pos="punct" morph="none" start_char="4026" end_char="4026">;</TOKEN>
<TOKEN id="token-29-32" pos="word" morph="none" start_char="4028" end_char="4030">and</TOKEN>
<TOKEN id="token-29-33" pos="word" morph="none" start_char="4032" end_char="4033">Dr</TOKEN>
<TOKEN id="token-29-34" pos="punct" morph="none" start_char="4034" end_char="4034">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="4036" end_char="4218">
<ORIGINAL_TEXT>Steve Monroe, associate director for Laboratory Science and Safety at the CDC, and a former deputy director of the CDC's National Center for Emerging and Zoonotic Infectious Diseases.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="4036" end_char="4040">Steve</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="4042" end_char="4047">Monroe</TOKEN>
<TOKEN id="token-30-2" pos="punct" morph="none" start_char="4048" end_char="4048">,</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="4050" end_char="4058">associate</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="4060" end_char="4067">director</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="4069" end_char="4071">for</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="4073" end_char="4082">Laboratory</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="4084" end_char="4090">Science</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="4092" end_char="4094">and</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="4096" end_char="4101">Safety</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="4103" end_char="4104">at</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="4106" end_char="4108">the</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="4110" end_char="4112">CDC</TOKEN>
<TOKEN id="token-30-13" pos="punct" morph="none" start_char="4113" end_char="4113">,</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="4115" end_char="4117">and</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="4119" end_char="4119">a</TOKEN>
<TOKEN id="token-30-16" pos="word" morph="none" start_char="4121" end_char="4126">former</TOKEN>
<TOKEN id="token-30-17" pos="word" morph="none" start_char="4128" end_char="4133">deputy</TOKEN>
<TOKEN id="token-30-18" pos="word" morph="none" start_char="4135" end_char="4142">director</TOKEN>
<TOKEN id="token-30-19" pos="word" morph="none" start_char="4144" end_char="4145">of</TOKEN>
<TOKEN id="token-30-20" pos="word" morph="none" start_char="4147" end_char="4149">the</TOKEN>
<TOKEN id="token-30-21" pos="word" morph="none" start_char="4151" end_char="4155">CDC's</TOKEN>
<TOKEN id="token-30-22" pos="word" morph="none" start_char="4157" end_char="4164">National</TOKEN>
<TOKEN id="token-30-23" pos="word" morph="none" start_char="4166" end_char="4171">Center</TOKEN>
<TOKEN id="token-30-24" pos="word" morph="none" start_char="4173" end_char="4175">for</TOKEN>
<TOKEN id="token-30-25" pos="word" morph="none" start_char="4177" end_char="4184">Emerging</TOKEN>
<TOKEN id="token-30-26" pos="word" morph="none" start_char="4186" end_char="4188">and</TOKEN>
<TOKEN id="token-30-27" pos="word" morph="none" start_char="4190" end_char="4197">Zoonotic</TOKEN>
<TOKEN id="token-30-28" pos="word" morph="none" start_char="4199" end_char="4208">Infectious</TOKEN>
<TOKEN id="token-30-29" pos="word" morph="none" start_char="4210" end_char="4217">Diseases</TOKEN>
<TOKEN id="token-30-30" pos="punct" morph="none" start_char="4218" end_char="4218">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="4220" end_char="4285">
<ORIGINAL_TEXT>You are welcome to call anyone above to inquire about the program.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="4220" end_char="4222">You</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="4224" end_char="4226">are</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="4228" end_char="4234">welcome</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="4236" end_char="4237">to</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="4239" end_char="4242">call</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="4244" end_char="4249">anyone</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="4251" end_char="4255">above</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="4257" end_char="4258">to</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="4260" end_char="4266">inquire</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="4268" end_char="4272">about</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="4274" end_char="4276">the</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="4278" end_char="4284">program</TOKEN>
<TOKEN id="token-31-12" pos="punct" morph="none" start_char="4285" end_char="4285">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="4289" end_char="4366">
<ORIGINAL_TEXT>Here's a review of the documents the film-makers pasted into their production:</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="4289" end_char="4294">Here's</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="4296" end_char="4296">a</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="4298" end_char="4303">review</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="4305" end_char="4306">of</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="4308" end_char="4310">the</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="4312" end_char="4320">documents</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="4322" end_char="4324">the</TOKEN>
<TOKEN id="token-32-7" pos="unknown" morph="none" start_char="4326" end_char="4336">film-makers</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="4338" end_char="4343">pasted</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="4345" end_char="4348">into</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="4350" end_char="4354">their</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="4356" end_char="4365">production</TOKEN>
<TOKEN id="token-32-12" pos="punct" morph="none" start_char="4366" end_char="4366">:</TOKEN>
</SEG>
<SEG id="segment-33" start_char="4369" end_char="4436">
<ORIGINAL_TEXT>One 'proof' document explicitly contradicts Swann and Martin's claim</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="4369" end_char="4371">One</TOKEN>
<TOKEN id="token-33-1" pos="punct" morph="none" start_char="4373" end_char="4373">'</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="4374" end_char="4378">proof</TOKEN>
<TOKEN id="token-33-3" pos="punct" morph="none" start_char="4379" end_char="4379">'</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="4381" end_char="4388">document</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="4390" end_char="4399">explicitly</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="4401" end_char="4411">contradicts</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="4413" end_char="4417">Swann</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="4419" end_char="4421">and</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="4423" end_char="4430">Martin's</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="4432" end_char="4436">claim</TOKEN>
</SEG>
<SEG id="segment-34" start_char="4440" end_char="4521">
<ORIGINAL_TEXT>Following is a screenshot of one of the documents Swann and Martin offer as proof.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="4440" end_char="4448">Following</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="4450" end_char="4451">is</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="4453" end_char="4453">a</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="4455" end_char="4464">screenshot</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="4466" end_char="4467">of</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="4469" end_char="4471">one</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="4473" end_char="4474">of</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="4476" end_char="4478">the</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="4480" end_char="4488">documents</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="4490" end_char="4494">Swann</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="4496" end_char="4498">and</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="4500" end_char="4505">Martin</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="4507" end_char="4511">offer</TOKEN>
<TOKEN id="token-34-13" pos="word" morph="none" start_char="4513" end_char="4514">as</TOKEN>
<TOKEN id="token-34-14" pos="word" morph="none" start_char="4516" end_char="4520">proof</TOKEN>
<TOKEN id="token-34-15" pos="punct" morph="none" start_char="4521" end_char="4521">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="4523" end_char="4619">
<ORIGINAL_TEXT>Lead Stories has highlighted in yellow an update added by the publisher that refutes their claim.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="4523" end_char="4526">Lead</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="4528" end_char="4534">Stories</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="4536" end_char="4538">has</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="4540" end_char="4550">highlighted</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="4552" end_char="4553">in</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="4555" end_char="4560">yellow</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="4562" end_char="4563">an</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="4565" end_char="4570">update</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="4572" end_char="4576">added</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="4578" end_char="4579">by</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="4581" end_char="4583">the</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="4585" end_char="4593">publisher</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="4595" end_char="4598">that</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="4600" end_char="4606">refutes</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="4608" end_char="4612">their</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="4614" end_char="4618">claim</TOKEN>
<TOKEN id="token-35-16" pos="punct" morph="none" start_char="4619" end_char="4619">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="4622" end_char="4706">
<ORIGINAL_TEXT>(Source: Lead Stories Screenshot from paused Facebook video Wed Sep 9 17:07 2020 UTC)</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="punct" morph="none" start_char="4622" end_char="4622">(</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="4623" end_char="4628">Source</TOKEN>
<TOKEN id="token-36-2" pos="punct" morph="none" start_char="4629" end_char="4629">:</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="4631" end_char="4634">Lead</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="4636" end_char="4642">Stories</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="4644" end_char="4653">Screenshot</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="4655" end_char="4658">from</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="4660" end_char="4665">paused</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="4667" end_char="4674">Facebook</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="4676" end_char="4680">video</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="4682" end_char="4684">Wed</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="4686" end_char="4688">Sep</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="4690" end_char="4690">9</TOKEN>
<TOKEN id="token-36-13" pos="unknown" morph="none" start_char="4692" end_char="4696">17:07</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="4698" end_char="4701">2020</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="4703" end_char="4705">UTC</TOKEN>
<TOKEN id="token-36-16" pos="punct" morph="none" start_char="4706" end_char="4706">)</TOKEN>
</SEG>
<SEG id="segment-37" start_char="4710" end_char="4803">
<ORIGINAL_TEXT>The November, 2015 article in The Scientist is a favorite among COVID-19 conspiracy theorists.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="4710" end_char="4712">The</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="4714" end_char="4721">November</TOKEN>
<TOKEN id="token-37-2" pos="punct" morph="none" start_char="4722" end_char="4722">,</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="4724" end_char="4727">2015</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="4729" end_char="4735">article</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="4737" end_char="4738">in</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="4740" end_char="4742">The</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="4744" end_char="4752">Scientist</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="4754" end_char="4755">is</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="4757" end_char="4757">a</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="4759" end_char="4766">favorite</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="4768" end_char="4772">among</TOKEN>
<TOKEN id="token-37-12" pos="unknown" morph="none" start_char="4774" end_char="4781">COVID-19</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="4783" end_char="4792">conspiracy</TOKEN>
<TOKEN id="token-37-14" pos="word" morph="none" start_char="4794" end_char="4802">theorists</TOKEN>
<TOKEN id="token-37-15" pos="punct" morph="none" start_char="4803" end_char="4803">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="4805" end_char="4974">
<ORIGINAL_TEXT>The repeated mischaracterization of it was the subject of a January, 2020, Lead Stories fact check: "Fact Check: 2015 Article About Lab-Made Coronavirus Triggers Debate".</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="4805" end_char="4807">The</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="4809" end_char="4816">repeated</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="4818" end_char="4836">mischaracterization</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="4838" end_char="4839">of</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="4841" end_char="4842">it</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="4844" end_char="4846">was</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="4848" end_char="4850">the</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="4852" end_char="4858">subject</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="4860" end_char="4861">of</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="4863" end_char="4863">a</TOKEN>
<TOKEN id="token-38-10" pos="word" morph="none" start_char="4865" end_char="4871">January</TOKEN>
<TOKEN id="token-38-11" pos="punct" morph="none" start_char="4872" end_char="4872">,</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="4874" end_char="4877">2020</TOKEN>
<TOKEN id="token-38-13" pos="punct" morph="none" start_char="4878" end_char="4878">,</TOKEN>
<TOKEN id="token-38-14" pos="word" morph="none" start_char="4880" end_char="4883">Lead</TOKEN>
<TOKEN id="token-38-15" pos="word" morph="none" start_char="4885" end_char="4891">Stories</TOKEN>
<TOKEN id="token-38-16" pos="word" morph="none" start_char="4893" end_char="4896">fact</TOKEN>
<TOKEN id="token-38-17" pos="word" morph="none" start_char="4898" end_char="4902">check</TOKEN>
<TOKEN id="token-38-18" pos="punct" morph="none" start_char="4903" end_char="4903">:</TOKEN>
<TOKEN id="token-38-19" pos="punct" morph="none" start_char="4905" end_char="4905">"</TOKEN>
<TOKEN id="token-38-20" pos="word" morph="none" start_char="4906" end_char="4909">Fact</TOKEN>
<TOKEN id="token-38-21" pos="word" morph="none" start_char="4911" end_char="4915">Check</TOKEN>
<TOKEN id="token-38-22" pos="punct" morph="none" start_char="4916" end_char="4916">:</TOKEN>
<TOKEN id="token-38-23" pos="word" morph="none" start_char="4918" end_char="4921">2015</TOKEN>
<TOKEN id="token-38-24" pos="word" morph="none" start_char="4923" end_char="4929">Article</TOKEN>
<TOKEN id="token-38-25" pos="word" morph="none" start_char="4931" end_char="4935">About</TOKEN>
<TOKEN id="token-38-26" pos="unknown" morph="none" start_char="4937" end_char="4944">Lab-Made</TOKEN>
<TOKEN id="token-38-27" pos="word" morph="none" start_char="4946" end_char="4956">Coronavirus</TOKEN>
<TOKEN id="token-38-28" pos="word" morph="none" start_char="4958" end_char="4965">Triggers</TOKEN>
<TOKEN id="token-38-29" pos="word" morph="none" start_char="4967" end_char="4972">Debate</TOKEN>
<TOKEN id="token-38-30" pos="punct" morph="none" start_char="4973" end_char="4974">".</TOKEN>
</SEG>
<SEG id="segment-39" start_char="4977" end_char="5051">
<ORIGINAL_TEXT>This 'proof' document refers to six-year-old concerns about virus research.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="4977" end_char="4980">This</TOKEN>
<TOKEN id="token-39-1" pos="punct" morph="none" start_char="4982" end_char="4982">'</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="4983" end_char="4987">proof</TOKEN>
<TOKEN id="token-39-3" pos="punct" morph="none" start_char="4988" end_char="4988">'</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="4990" end_char="4997">document</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="4999" end_char="5004">refers</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="5006" end_char="5007">to</TOKEN>
<TOKEN id="token-39-7" pos="unknown" morph="none" start_char="5009" end_char="5020">six-year-old</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="5022" end_char="5029">concerns</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="5031" end_char="5035">about</TOKEN>
<TOKEN id="token-39-10" pos="word" morph="none" start_char="5037" end_char="5041">virus</TOKEN>
<TOKEN id="token-39-11" pos="word" morph="none" start_char="5043" end_char="5050">research</TOKEN>
<TOKEN id="token-39-12" pos="punct" morph="none" start_char="5051" end_char="5051">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="5055" end_char="5203">
<ORIGINAL_TEXT>Science Magazine reported, in October of 2014, on the U.S. government's moratorium on "gain-of-function" research until new rules could be developed.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="5055" end_char="5061">Science</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="5063" end_char="5070">Magazine</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="5072" end_char="5079">reported</TOKEN>
<TOKEN id="token-40-3" pos="punct" morph="none" start_char="5080" end_char="5080">,</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="5082" end_char="5083">in</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="5085" end_char="5091">October</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="5093" end_char="5094">of</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="5096" end_char="5099">2014</TOKEN>
<TOKEN id="token-40-8" pos="punct" morph="none" start_char="5100" end_char="5100">,</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="5102" end_char="5103">on</TOKEN>
<TOKEN id="token-40-10" pos="word" morph="none" start_char="5105" end_char="5107">the</TOKEN>
<TOKEN id="token-40-11" pos="unknown" morph="none" start_char="5109" end_char="5111">U.S</TOKEN>
<TOKEN id="token-40-12" pos="punct" morph="none" start_char="5112" end_char="5112">.</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="5114" end_char="5125">government's</TOKEN>
<TOKEN id="token-40-14" pos="word" morph="none" start_char="5127" end_char="5136">moratorium</TOKEN>
<TOKEN id="token-40-15" pos="word" morph="none" start_char="5138" end_char="5139">on</TOKEN>
<TOKEN id="token-40-16" pos="punct" morph="none" start_char="5141" end_char="5141">"</TOKEN>
<TOKEN id="token-40-17" pos="unknown" morph="none" start_char="5142" end_char="5157">gain-of-function</TOKEN>
<TOKEN id="token-40-18" pos="punct" morph="none" start_char="5158" end_char="5158">"</TOKEN>
<TOKEN id="token-40-19" pos="word" morph="none" start_char="5160" end_char="5167">research</TOKEN>
<TOKEN id="token-40-20" pos="word" morph="none" start_char="5169" end_char="5173">until</TOKEN>
<TOKEN id="token-40-21" pos="word" morph="none" start_char="5175" end_char="5177">new</TOKEN>
<TOKEN id="token-40-22" pos="word" morph="none" start_char="5179" end_char="5183">rules</TOKEN>
<TOKEN id="token-40-23" pos="word" morph="none" start_char="5185" end_char="5189">could</TOKEN>
<TOKEN id="token-40-24" pos="word" morph="none" start_char="5191" end_char="5192">be</TOKEN>
<TOKEN id="token-40-25" pos="word" morph="none" start_char="5194" end_char="5202">developed</TOKEN>
<TOKEN id="token-40-26" pos="punct" morph="none" start_char="5203" end_char="5203">.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="5205" end_char="5352">
<ORIGINAL_TEXT>Virologists deconstruct and reconstruct viruses to understand how viruses change in the wild and what characteristics make them dangerous to humans.</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="5205" end_char="5215">Virologists</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="5217" end_char="5227">deconstruct</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="5229" end_char="5231">and</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="5233" end_char="5243">reconstruct</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="5245" end_char="5251">viruses</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="5253" end_char="5254">to</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="5256" end_char="5265">understand</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="5267" end_char="5269">how</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="5271" end_char="5277">viruses</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="5279" end_char="5284">change</TOKEN>
<TOKEN id="token-41-10" pos="word" morph="none" start_char="5286" end_char="5287">in</TOKEN>
<TOKEN id="token-41-11" pos="word" morph="none" start_char="5289" end_char="5291">the</TOKEN>
<TOKEN id="token-41-12" pos="word" morph="none" start_char="5293" end_char="5296">wild</TOKEN>
<TOKEN id="token-41-13" pos="word" morph="none" start_char="5298" end_char="5300">and</TOKEN>
<TOKEN id="token-41-14" pos="word" morph="none" start_char="5302" end_char="5305">what</TOKEN>
<TOKEN id="token-41-15" pos="word" morph="none" start_char="5307" end_char="5321">characteristics</TOKEN>
<TOKEN id="token-41-16" pos="word" morph="none" start_char="5323" end_char="5326">make</TOKEN>
<TOKEN id="token-41-17" pos="word" morph="none" start_char="5328" end_char="5331">them</TOKEN>
<TOKEN id="token-41-18" pos="word" morph="none" start_char="5333" end_char="5341">dangerous</TOKEN>
<TOKEN id="token-41-19" pos="word" morph="none" start_char="5343" end_char="5344">to</TOKEN>
<TOKEN id="token-41-20" pos="word" morph="none" start_char="5346" end_char="5351">humans</TOKEN>
<TOKEN id="token-41-21" pos="punct" morph="none" start_char="5352" end_char="5352">.</TOKEN>
</SEG>
<SEG id="segment-42" start_char="5354" end_char="5390">
<ORIGINAL_TEXT>The moratorium has since been lifted.</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="5354" end_char="5356">The</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="5358" end_char="5367">moratorium</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="5369" end_char="5371">has</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="5373" end_char="5377">since</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="5379" end_char="5382">been</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="5384" end_char="5389">lifted</TOKEN>
<TOKEN id="token-42-6" pos="punct" morph="none" start_char="5390" end_char="5390">.</TOKEN>
</SEG>
<SEG id="segment-43" start_char="5392" end_char="5484">
<ORIGINAL_TEXT>At that time, they were studying SARS, one of the seven coronavirus forms that infect humans.</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="5392" end_char="5393">At</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="5395" end_char="5398">that</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="5400" end_char="5403">time</TOKEN>
<TOKEN id="token-43-3" pos="punct" morph="none" start_char="5404" end_char="5404">,</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="5406" end_char="5409">they</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="5411" end_char="5414">were</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="5416" end_char="5423">studying</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="5425" end_char="5428">SARS</TOKEN>
<TOKEN id="token-43-8" pos="punct" morph="none" start_char="5429" end_char="5429">,</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="5431" end_char="5433">one</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="5435" end_char="5436">of</TOKEN>
<TOKEN id="token-43-11" pos="word" morph="none" start_char="5438" end_char="5440">the</TOKEN>
<TOKEN id="token-43-12" pos="word" morph="none" start_char="5442" end_char="5446">seven</TOKEN>
<TOKEN id="token-43-13" pos="word" morph="none" start_char="5448" end_char="5458">coronavirus</TOKEN>
<TOKEN id="token-43-14" pos="word" morph="none" start_char="5460" end_char="5464">forms</TOKEN>
<TOKEN id="token-43-15" pos="word" morph="none" start_char="5466" end_char="5469">that</TOKEN>
<TOKEN id="token-43-16" pos="word" morph="none" start_char="5471" end_char="5476">infect</TOKEN>
<TOKEN id="token-43-17" pos="word" morph="none" start_char="5478" end_char="5483">humans</TOKEN>
<TOKEN id="token-43-18" pos="punct" morph="none" start_char="5484" end_char="5484">.</TOKEN>
</SEG>
<SEG id="segment-44" start_char="5487" end_char="5571">
<ORIGINAL_TEXT>(Source: Lead Stories Screenshot from paused Facebook video Wed Sep 9 17:21 2020 UTC)</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="punct" morph="none" start_char="5487" end_char="5487">(</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="5488" end_char="5493">Source</TOKEN>
<TOKEN id="token-44-2" pos="punct" morph="none" start_char="5494" end_char="5494">:</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="5496" end_char="5499">Lead</TOKEN>
<TOKEN id="token-44-4" pos="word" morph="none" start_char="5501" end_char="5507">Stories</TOKEN>
<TOKEN id="token-44-5" pos="word" morph="none" start_char="5509" end_char="5518">Screenshot</TOKEN>
<TOKEN id="token-44-6" pos="word" morph="none" start_char="5520" end_char="5523">from</TOKEN>
<TOKEN id="token-44-7" pos="word" morph="none" start_char="5525" end_char="5530">paused</TOKEN>
<TOKEN id="token-44-8" pos="word" morph="none" start_char="5532" end_char="5539">Facebook</TOKEN>
<TOKEN id="token-44-9" pos="word" morph="none" start_char="5541" end_char="5545">video</TOKEN>
<TOKEN id="token-44-10" pos="word" morph="none" start_char="5547" end_char="5549">Wed</TOKEN>
<TOKEN id="token-44-11" pos="word" morph="none" start_char="5551" end_char="5553">Sep</TOKEN>
<TOKEN id="token-44-12" pos="word" morph="none" start_char="5555" end_char="5555">9</TOKEN>
<TOKEN id="token-44-13" pos="unknown" morph="none" start_char="5557" end_char="5561">17:21</TOKEN>
<TOKEN id="token-44-14" pos="word" morph="none" start_char="5563" end_char="5566">2020</TOKEN>
<TOKEN id="token-44-15" pos="word" morph="none" start_char="5568" end_char="5570">UTC</TOKEN>
<TOKEN id="token-44-16" pos="punct" morph="none" start_char="5571" end_char="5571">)</TOKEN>
</SEG>
<SEG id="segment-45" start_char="5575" end_char="5662">
<ORIGINAL_TEXT>This 'proof' document is a position paper about influenza bio-weapons, not coronaviruses</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="5575" end_char="5578">This</TOKEN>
<TOKEN id="token-45-1" pos="punct" morph="none" start_char="5580" end_char="5580">'</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="5581" end_char="5585">proof</TOKEN>
<TOKEN id="token-45-3" pos="punct" morph="none" start_char="5586" end_char="5586">'</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="5588" end_char="5595">document</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="5597" end_char="5598">is</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="5600" end_char="5600">a</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="5602" end_char="5609">position</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="5611" end_char="5615">paper</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="5617" end_char="5621">about</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="5623" end_char="5631">influenza</TOKEN>
<TOKEN id="token-45-11" pos="unknown" morph="none" start_char="5633" end_char="5643">bio-weapons</TOKEN>
<TOKEN id="token-45-12" pos="punct" morph="none" start_char="5644" end_char="5644">,</TOKEN>
<TOKEN id="token-45-13" pos="word" morph="none" start_char="5646" end_char="5648">not</TOKEN>
<TOKEN id="token-45-14" pos="word" morph="none" start_char="5650" end_char="5662">coronaviruses</TOKEN>
</SEG>
<SEG id="segment-46" start_char="5666" end_char="5750">
<ORIGINAL_TEXT>(Source: Lead Stories Screenshot from paused Facebook video Wed Sep 9 17:29 2020 UTC)</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="punct" morph="none" start_char="5666" end_char="5666">(</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="5667" end_char="5672">Source</TOKEN>
<TOKEN id="token-46-2" pos="punct" morph="none" start_char="5673" end_char="5673">:</TOKEN>
<TOKEN id="token-46-3" pos="word" morph="none" start_char="5675" end_char="5678">Lead</TOKEN>
<TOKEN id="token-46-4" pos="word" morph="none" start_char="5680" end_char="5686">Stories</TOKEN>
<TOKEN id="token-46-5" pos="word" morph="none" start_char="5688" end_char="5697">Screenshot</TOKEN>
<TOKEN id="token-46-6" pos="word" morph="none" start_char="5699" end_char="5702">from</TOKEN>
<TOKEN id="token-46-7" pos="word" morph="none" start_char="5704" end_char="5709">paused</TOKEN>
<TOKEN id="token-46-8" pos="word" morph="none" start_char="5711" end_char="5718">Facebook</TOKEN>
<TOKEN id="token-46-9" pos="word" morph="none" start_char="5720" end_char="5724">video</TOKEN>
<TOKEN id="token-46-10" pos="word" morph="none" start_char="5726" end_char="5728">Wed</TOKEN>
<TOKEN id="token-46-11" pos="word" morph="none" start_char="5730" end_char="5732">Sep</TOKEN>
<TOKEN id="token-46-12" pos="word" morph="none" start_char="5734" end_char="5734">9</TOKEN>
<TOKEN id="token-46-13" pos="unknown" morph="none" start_char="5736" end_char="5740">17:29</TOKEN>
<TOKEN id="token-46-14" pos="word" morph="none" start_char="5742" end_char="5745">2020</TOKEN>
<TOKEN id="token-46-15" pos="word" morph="none" start_char="5747" end_char="5749">UTC</TOKEN>
<TOKEN id="token-46-16" pos="punct" morph="none" start_char="5750" end_char="5750">)</TOKEN>
</SEG>
<SEG id="segment-47" start_char="5754" end_char="6043">
<ORIGINAL_TEXT>In 2014, scientists at the Center for Arms Control and Non-proliferation wrote to the National Science Advisory Board for Biosecurity to express their support for proposed safety measures to prevent pathogens from being released from labs and to limit the development of biological weapons.</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="5754" end_char="5755">In</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="5757" end_char="5760">2014</TOKEN>
<TOKEN id="token-47-2" pos="punct" morph="none" start_char="5761" end_char="5761">,</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="5763" end_char="5772">scientists</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="5774" end_char="5775">at</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="5777" end_char="5779">the</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="5781" end_char="5786">Center</TOKEN>
<TOKEN id="token-47-7" pos="word" morph="none" start_char="5788" end_char="5790">for</TOKEN>
<TOKEN id="token-47-8" pos="word" morph="none" start_char="5792" end_char="5795">Arms</TOKEN>
<TOKEN id="token-47-9" pos="word" morph="none" start_char="5797" end_char="5803">Control</TOKEN>
<TOKEN id="token-47-10" pos="word" morph="none" start_char="5805" end_char="5807">and</TOKEN>
<TOKEN id="token-47-11" pos="unknown" morph="none" start_char="5809" end_char="5825">Non-proliferation</TOKEN>
<TOKEN id="token-47-12" pos="word" morph="none" start_char="5827" end_char="5831">wrote</TOKEN>
<TOKEN id="token-47-13" pos="word" morph="none" start_char="5833" end_char="5834">to</TOKEN>
<TOKEN id="token-47-14" pos="word" morph="none" start_char="5836" end_char="5838">the</TOKEN>
<TOKEN id="token-47-15" pos="word" morph="none" start_char="5840" end_char="5847">National</TOKEN>
<TOKEN id="token-47-16" pos="word" morph="none" start_char="5849" end_char="5855">Science</TOKEN>
<TOKEN id="token-47-17" pos="word" morph="none" start_char="5857" end_char="5864">Advisory</TOKEN>
<TOKEN id="token-47-18" pos="word" morph="none" start_char="5866" end_char="5870">Board</TOKEN>
<TOKEN id="token-47-19" pos="word" morph="none" start_char="5872" end_char="5874">for</TOKEN>
<TOKEN id="token-47-20" pos="word" morph="none" start_char="5876" end_char="5886">Biosecurity</TOKEN>
<TOKEN id="token-47-21" pos="word" morph="none" start_char="5888" end_char="5889">to</TOKEN>
<TOKEN id="token-47-22" pos="word" morph="none" start_char="5891" end_char="5897">express</TOKEN>
<TOKEN id="token-47-23" pos="word" morph="none" start_char="5899" end_char="5903">their</TOKEN>
<TOKEN id="token-47-24" pos="word" morph="none" start_char="5905" end_char="5911">support</TOKEN>
<TOKEN id="token-47-25" pos="word" morph="none" start_char="5913" end_char="5915">for</TOKEN>
<TOKEN id="token-47-26" pos="word" morph="none" start_char="5917" end_char="5924">proposed</TOKEN>
<TOKEN id="token-47-27" pos="word" morph="none" start_char="5926" end_char="5931">safety</TOKEN>
<TOKEN id="token-47-28" pos="word" morph="none" start_char="5933" end_char="5940">measures</TOKEN>
<TOKEN id="token-47-29" pos="word" morph="none" start_char="5942" end_char="5943">to</TOKEN>
<TOKEN id="token-47-30" pos="word" morph="none" start_char="5945" end_char="5951">prevent</TOKEN>
<TOKEN id="token-47-31" pos="word" morph="none" start_char="5953" end_char="5961">pathogens</TOKEN>
<TOKEN id="token-47-32" pos="word" morph="none" start_char="5963" end_char="5966">from</TOKEN>
<TOKEN id="token-47-33" pos="word" morph="none" start_char="5968" end_char="5972">being</TOKEN>
<TOKEN id="token-47-34" pos="word" morph="none" start_char="5974" end_char="5981">released</TOKEN>
<TOKEN id="token-47-35" pos="word" morph="none" start_char="5983" end_char="5986">from</TOKEN>
<TOKEN id="token-47-36" pos="word" morph="none" start_char="5988" end_char="5991">labs</TOKEN>
<TOKEN id="token-47-37" pos="word" morph="none" start_char="5993" end_char="5995">and</TOKEN>
<TOKEN id="token-47-38" pos="word" morph="none" start_char="5997" end_char="5998">to</TOKEN>
<TOKEN id="token-47-39" pos="word" morph="none" start_char="6000" end_char="6004">limit</TOKEN>
<TOKEN id="token-47-40" pos="word" morph="none" start_char="6006" end_char="6008">the</TOKEN>
<TOKEN id="token-47-41" pos="word" morph="none" start_char="6010" end_char="6020">development</TOKEN>
<TOKEN id="token-47-42" pos="word" morph="none" start_char="6022" end_char="6023">of</TOKEN>
<TOKEN id="token-47-43" pos="word" morph="none" start_char="6025" end_char="6034">biological</TOKEN>
<TOKEN id="token-47-44" pos="word" morph="none" start_char="6036" end_char="6042">weapons</TOKEN>
<TOKEN id="token-47-45" pos="punct" morph="none" start_char="6043" end_char="6043">.</TOKEN>
</SEG>
<SEG id="segment-48" start_char="6045" end_char="6173">
<ORIGINAL_TEXT>While the letter raises the possibility of a pandemic caused by human actions, it does not in itself prove COVID-19 was lab-made.</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="6045" end_char="6049">While</TOKEN>
<TOKEN id="token-48-1" pos="word" morph="none" start_char="6051" end_char="6053">the</TOKEN>
<TOKEN id="token-48-2" pos="word" morph="none" start_char="6055" end_char="6060">letter</TOKEN>
<TOKEN id="token-48-3" pos="word" morph="none" start_char="6062" end_char="6067">raises</TOKEN>
<TOKEN id="token-48-4" pos="word" morph="none" start_char="6069" end_char="6071">the</TOKEN>
<TOKEN id="token-48-5" pos="word" morph="none" start_char="6073" end_char="6083">possibility</TOKEN>
<TOKEN id="token-48-6" pos="word" morph="none" start_char="6085" end_char="6086">of</TOKEN>
<TOKEN id="token-48-7" pos="word" morph="none" start_char="6088" end_char="6088">a</TOKEN>
<TOKEN id="token-48-8" pos="word" morph="none" start_char="6090" end_char="6097">pandemic</TOKEN>
<TOKEN id="token-48-9" pos="word" morph="none" start_char="6099" end_char="6104">caused</TOKEN>
<TOKEN id="token-48-10" pos="word" morph="none" start_char="6106" end_char="6107">by</TOKEN>
<TOKEN id="token-48-11" pos="word" morph="none" start_char="6109" end_char="6113">human</TOKEN>
<TOKEN id="token-48-12" pos="word" morph="none" start_char="6115" end_char="6121">actions</TOKEN>
<TOKEN id="token-48-13" pos="punct" morph="none" start_char="6122" end_char="6122">,</TOKEN>
<TOKEN id="token-48-14" pos="word" morph="none" start_char="6124" end_char="6125">it</TOKEN>
<TOKEN id="token-48-15" pos="word" morph="none" start_char="6127" end_char="6130">does</TOKEN>
<TOKEN id="token-48-16" pos="word" morph="none" start_char="6132" end_char="6134">not</TOKEN>
<TOKEN id="token-48-17" pos="word" morph="none" start_char="6136" end_char="6137">in</TOKEN>
<TOKEN id="token-48-18" pos="word" morph="none" start_char="6139" end_char="6144">itself</TOKEN>
<TOKEN id="token-48-19" pos="word" morph="none" start_char="6146" end_char="6150">prove</TOKEN>
<TOKEN id="token-48-20" pos="unknown" morph="none" start_char="6152" end_char="6159">COVID-19</TOKEN>
<TOKEN id="token-48-21" pos="word" morph="none" start_char="6161" end_char="6163">was</TOKEN>
<TOKEN id="token-48-22" pos="unknown" morph="none" start_char="6165" end_char="6172">lab-made</TOKEN>
<TOKEN id="token-48-23" pos="punct" morph="none" start_char="6173" end_char="6173">.</TOKEN>
</SEG>
<SEG id="segment-49" start_char="6176" end_char="6230">
<ORIGINAL_TEXT>This 'proof' document is just a copy of a U.S. law book</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="6176" end_char="6179">This</TOKEN>
<TOKEN id="token-49-1" pos="punct" morph="none" start_char="6181" end_char="6181">'</TOKEN>
<TOKEN id="token-49-2" pos="word" morph="none" start_char="6182" end_char="6186">proof</TOKEN>
<TOKEN id="token-49-3" pos="punct" morph="none" start_char="6187" end_char="6187">'</TOKEN>
<TOKEN id="token-49-4" pos="word" morph="none" start_char="6189" end_char="6196">document</TOKEN>
<TOKEN id="token-49-5" pos="word" morph="none" start_char="6198" end_char="6199">is</TOKEN>
<TOKEN id="token-49-6" pos="word" morph="none" start_char="6201" end_char="6204">just</TOKEN>
<TOKEN id="token-49-7" pos="word" morph="none" start_char="6206" end_char="6206">a</TOKEN>
<TOKEN id="token-49-8" pos="word" morph="none" start_char="6208" end_char="6211">copy</TOKEN>
<TOKEN id="token-49-9" pos="word" morph="none" start_char="6213" end_char="6214">of</TOKEN>
<TOKEN id="token-49-10" pos="word" morph="none" start_char="6216" end_char="6216">a</TOKEN>
<TOKEN id="token-49-11" pos="unknown" morph="none" start_char="6218" end_char="6220">U.S</TOKEN>
<TOKEN id="token-49-12" pos="punct" morph="none" start_char="6221" end_char="6221">.</TOKEN>
<TOKEN id="token-49-13" pos="word" morph="none" start_char="6223" end_char="6225">law</TOKEN>
<TOKEN id="token-49-14" pos="word" morph="none" start_char="6227" end_char="6230">book</TOKEN>
</SEG>
<SEG id="segment-50" start_char="6234" end_char="6337">
<ORIGINAL_TEXT>The photo shows the section of U.S. law that defines the powers of the U.S. Patent and Trademark Office.</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="6234" end_char="6236">The</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="6238" end_char="6242">photo</TOKEN>
<TOKEN id="token-50-2" pos="word" morph="none" start_char="6244" end_char="6248">shows</TOKEN>
<TOKEN id="token-50-3" pos="word" morph="none" start_char="6250" end_char="6252">the</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="6254" end_char="6260">section</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="6262" end_char="6263">of</TOKEN>
<TOKEN id="token-50-6" pos="unknown" morph="none" start_char="6265" end_char="6267">U.S</TOKEN>
<TOKEN id="token-50-7" pos="punct" morph="none" start_char="6268" end_char="6268">.</TOKEN>
<TOKEN id="token-50-8" pos="word" morph="none" start_char="6270" end_char="6272">law</TOKEN>
<TOKEN id="token-50-9" pos="word" morph="none" start_char="6274" end_char="6277">that</TOKEN>
<TOKEN id="token-50-10" pos="word" morph="none" start_char="6279" end_char="6285">defines</TOKEN>
<TOKEN id="token-50-11" pos="word" morph="none" start_char="6287" end_char="6289">the</TOKEN>
<TOKEN id="token-50-12" pos="word" morph="none" start_char="6291" end_char="6296">powers</TOKEN>
<TOKEN id="token-50-13" pos="word" morph="none" start_char="6298" end_char="6299">of</TOKEN>
<TOKEN id="token-50-14" pos="word" morph="none" start_char="6301" end_char="6303">the</TOKEN>
<TOKEN id="token-50-15" pos="unknown" morph="none" start_char="6305" end_char="6307">U.S</TOKEN>
<TOKEN id="token-50-16" pos="punct" morph="none" start_char="6308" end_char="6308">.</TOKEN>
<TOKEN id="token-50-17" pos="word" morph="none" start_char="6310" end_char="6315">Patent</TOKEN>
<TOKEN id="token-50-18" pos="word" morph="none" start_char="6317" end_char="6319">and</TOKEN>
<TOKEN id="token-50-19" pos="word" morph="none" start_char="6321" end_char="6329">Trademark</TOKEN>
<TOKEN id="token-50-20" pos="word" morph="none" start_char="6331" end_char="6336">Office</TOKEN>
<TOKEN id="token-50-21" pos="punct" morph="none" start_char="6337" end_char="6337">.</TOKEN>
</SEG>
<SEG id="segment-51" start_char="6339" end_char="6488">
<ORIGINAL_TEXT>Swann and Martin claim federal judges and attorneys all got it wrong when the CDC applied for a patent to keep virus information in the public domain.</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="word" morph="none" start_char="6339" end_char="6343">Swann</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="6345" end_char="6347">and</TOKEN>
<TOKEN id="token-51-2" pos="word" morph="none" start_char="6349" end_char="6354">Martin</TOKEN>
<TOKEN id="token-51-3" pos="word" morph="none" start_char="6356" end_char="6360">claim</TOKEN>
<TOKEN id="token-51-4" pos="word" morph="none" start_char="6362" end_char="6368">federal</TOKEN>
<TOKEN id="token-51-5" pos="word" morph="none" start_char="6370" end_char="6375">judges</TOKEN>
<TOKEN id="token-51-6" pos="word" morph="none" start_char="6377" end_char="6379">and</TOKEN>
<TOKEN id="token-51-7" pos="word" morph="none" start_char="6381" end_char="6389">attorneys</TOKEN>
<TOKEN id="token-51-8" pos="word" morph="none" start_char="6391" end_char="6393">all</TOKEN>
<TOKEN id="token-51-9" pos="word" morph="none" start_char="6395" end_char="6397">got</TOKEN>
<TOKEN id="token-51-10" pos="word" morph="none" start_char="6399" end_char="6400">it</TOKEN>
<TOKEN id="token-51-11" pos="word" morph="none" start_char="6402" end_char="6406">wrong</TOKEN>
<TOKEN id="token-51-12" pos="word" morph="none" start_char="6408" end_char="6411">when</TOKEN>
<TOKEN id="token-51-13" pos="word" morph="none" start_char="6413" end_char="6415">the</TOKEN>
<TOKEN id="token-51-14" pos="word" morph="none" start_char="6417" end_char="6419">CDC</TOKEN>
<TOKEN id="token-51-15" pos="word" morph="none" start_char="6421" end_char="6427">applied</TOKEN>
<TOKEN id="token-51-16" pos="word" morph="none" start_char="6429" end_char="6431">for</TOKEN>
<TOKEN id="token-51-17" pos="word" morph="none" start_char="6433" end_char="6433">a</TOKEN>
<TOKEN id="token-51-18" pos="word" morph="none" start_char="6435" end_char="6440">patent</TOKEN>
<TOKEN id="token-51-19" pos="word" morph="none" start_char="6442" end_char="6443">to</TOKEN>
<TOKEN id="token-51-20" pos="word" morph="none" start_char="6445" end_char="6448">keep</TOKEN>
<TOKEN id="token-51-21" pos="word" morph="none" start_char="6450" end_char="6454">virus</TOKEN>
<TOKEN id="token-51-22" pos="word" morph="none" start_char="6456" end_char="6466">information</TOKEN>
<TOKEN id="token-51-23" pos="word" morph="none" start_char="6468" end_char="6469">in</TOKEN>
<TOKEN id="token-51-24" pos="word" morph="none" start_char="6471" end_char="6473">the</TOKEN>
<TOKEN id="token-51-25" pos="word" morph="none" start_char="6475" end_char="6480">public</TOKEN>
<TOKEN id="token-51-26" pos="word" morph="none" start_char="6482" end_char="6487">domain</TOKEN>
<TOKEN id="token-51-27" pos="punct" morph="none" start_char="6488" end_char="6488">.</TOKEN>
</SEG>
<SEG id="segment-52" start_char="6491" end_char="6575">
<ORIGINAL_TEXT>(Source: Lead Stories Screenshot from paused Facebook video Wed Sep 9 17:16 2020 UTC)</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="punct" morph="none" start_char="6491" end_char="6491">(</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="6492" end_char="6497">Source</TOKEN>
<TOKEN id="token-52-2" pos="punct" morph="none" start_char="6498" end_char="6498">:</TOKEN>
<TOKEN id="token-52-3" pos="word" morph="none" start_char="6500" end_char="6503">Lead</TOKEN>
<TOKEN id="token-52-4" pos="word" morph="none" start_char="6505" end_char="6511">Stories</TOKEN>
<TOKEN id="token-52-5" pos="word" morph="none" start_char="6513" end_char="6522">Screenshot</TOKEN>
<TOKEN id="token-52-6" pos="word" morph="none" start_char="6524" end_char="6527">from</TOKEN>
<TOKEN id="token-52-7" pos="word" morph="none" start_char="6529" end_char="6534">paused</TOKEN>
<TOKEN id="token-52-8" pos="word" morph="none" start_char="6536" end_char="6543">Facebook</TOKEN>
<TOKEN id="token-52-9" pos="word" morph="none" start_char="6545" end_char="6549">video</TOKEN>
<TOKEN id="token-52-10" pos="word" morph="none" start_char="6551" end_char="6553">Wed</TOKEN>
<TOKEN id="token-52-11" pos="word" morph="none" start_char="6555" end_char="6557">Sep</TOKEN>
<TOKEN id="token-52-12" pos="word" morph="none" start_char="6559" end_char="6559">9</TOKEN>
<TOKEN id="token-52-13" pos="unknown" morph="none" start_char="6561" end_char="6565">17:16</TOKEN>
<TOKEN id="token-52-14" pos="word" morph="none" start_char="6567" end_char="6570">2020</TOKEN>
<TOKEN id="token-52-15" pos="word" morph="none" start_char="6572" end_char="6574">UTC</TOKEN>
<TOKEN id="token-52-16" pos="punct" morph="none" start_char="6575" end_char="6575">)</TOKEN>
</SEG>
<SEG id="segment-53" start_char="6579" end_char="6633">
<ORIGINAL_TEXT>This Supreme Court decision does not prove a conspiracy</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="word" morph="none" start_char="6579" end_char="6582">This</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="6584" end_char="6590">Supreme</TOKEN>
<TOKEN id="token-53-2" pos="word" morph="none" start_char="6592" end_char="6596">Court</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="6598" end_char="6605">decision</TOKEN>
<TOKEN id="token-53-4" pos="word" morph="none" start_char="6607" end_char="6610">does</TOKEN>
<TOKEN id="token-53-5" pos="word" morph="none" start_char="6612" end_char="6614">not</TOKEN>
<TOKEN id="token-53-6" pos="word" morph="none" start_char="6616" end_char="6620">prove</TOKEN>
<TOKEN id="token-53-7" pos="word" morph="none" start_char="6622" end_char="6622">a</TOKEN>
<TOKEN id="token-53-8" pos="word" morph="none" start_char="6624" end_char="6633">conspiracy</TOKEN>
</SEG>
<SEG id="segment-54" start_char="6637" end_char="6729">
<ORIGINAL_TEXT>Martin claims the CDC had nefarious intent when it patented methods to detect the SARS virus.</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="word" morph="none" start_char="6637" end_char="6642">Martin</TOKEN>
<TOKEN id="token-54-1" pos="word" morph="none" start_char="6644" end_char="6649">claims</TOKEN>
<TOKEN id="token-54-2" pos="word" morph="none" start_char="6651" end_char="6653">the</TOKEN>
<TOKEN id="token-54-3" pos="word" morph="none" start_char="6655" end_char="6657">CDC</TOKEN>
<TOKEN id="token-54-4" pos="word" morph="none" start_char="6659" end_char="6661">had</TOKEN>
<TOKEN id="token-54-5" pos="word" morph="none" start_char="6663" end_char="6671">nefarious</TOKEN>
<TOKEN id="token-54-6" pos="word" morph="none" start_char="6673" end_char="6678">intent</TOKEN>
<TOKEN id="token-54-7" pos="word" morph="none" start_char="6680" end_char="6683">when</TOKEN>
<TOKEN id="token-54-8" pos="word" morph="none" start_char="6685" end_char="6686">it</TOKEN>
<TOKEN id="token-54-9" pos="word" morph="none" start_char="6688" end_char="6695">patented</TOKEN>
<TOKEN id="token-54-10" pos="word" morph="none" start_char="6697" end_char="6703">methods</TOKEN>
<TOKEN id="token-54-11" pos="word" morph="none" start_char="6705" end_char="6706">to</TOKEN>
<TOKEN id="token-54-12" pos="word" morph="none" start_char="6708" end_char="6713">detect</TOKEN>
<TOKEN id="token-54-13" pos="word" morph="none" start_char="6715" end_char="6717">the</TOKEN>
<TOKEN id="token-54-14" pos="word" morph="none" start_char="6719" end_char="6722">SARS</TOKEN>
<TOKEN id="token-54-15" pos="word" morph="none" start_char="6724" end_char="6728">virus</TOKEN>
<TOKEN id="token-54-16" pos="punct" morph="none" start_char="6729" end_char="6729">.</TOKEN>
</SEG>
<SEG id="segment-55" start_char="6731" end_char="6915">
<ORIGINAL_TEXT>The Wall Street Journal reported at the time that CDC officials were clear that they were trying the patent route to prevent commercial firms from monopolizing public health technology.</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="word" morph="none" start_char="6731" end_char="6733">The</TOKEN>
<TOKEN id="token-55-1" pos="word" morph="none" start_char="6735" end_char="6738">Wall</TOKEN>
<TOKEN id="token-55-2" pos="word" morph="none" start_char="6740" end_char="6745">Street</TOKEN>
<TOKEN id="token-55-3" pos="word" morph="none" start_char="6747" end_char="6753">Journal</TOKEN>
<TOKEN id="token-55-4" pos="word" morph="none" start_char="6755" end_char="6762">reported</TOKEN>
<TOKEN id="token-55-5" pos="word" morph="none" start_char="6764" end_char="6765">at</TOKEN>
<TOKEN id="token-55-6" pos="word" morph="none" start_char="6767" end_char="6769">the</TOKEN>
<TOKEN id="token-55-7" pos="word" morph="none" start_char="6771" end_char="6774">time</TOKEN>
<TOKEN id="token-55-8" pos="word" morph="none" start_char="6776" end_char="6779">that</TOKEN>
<TOKEN id="token-55-9" pos="word" morph="none" start_char="6781" end_char="6783">CDC</TOKEN>
<TOKEN id="token-55-10" pos="word" morph="none" start_char="6785" end_char="6793">officials</TOKEN>
<TOKEN id="token-55-11" pos="word" morph="none" start_char="6795" end_char="6798">were</TOKEN>
<TOKEN id="token-55-12" pos="word" morph="none" start_char="6800" end_char="6804">clear</TOKEN>
<TOKEN id="token-55-13" pos="word" morph="none" start_char="6806" end_char="6809">that</TOKEN>
<TOKEN id="token-55-14" pos="word" morph="none" start_char="6811" end_char="6814">they</TOKEN>
<TOKEN id="token-55-15" pos="word" morph="none" start_char="6816" end_char="6819">were</TOKEN>
<TOKEN id="token-55-16" pos="word" morph="none" start_char="6821" end_char="6826">trying</TOKEN>
<TOKEN id="token-55-17" pos="word" morph="none" start_char="6828" end_char="6830">the</TOKEN>
<TOKEN id="token-55-18" pos="word" morph="none" start_char="6832" end_char="6837">patent</TOKEN>
<TOKEN id="token-55-19" pos="word" morph="none" start_char="6839" end_char="6843">route</TOKEN>
<TOKEN id="token-55-20" pos="word" morph="none" start_char="6845" end_char="6846">to</TOKEN>
<TOKEN id="token-55-21" pos="word" morph="none" start_char="6848" end_char="6854">prevent</TOKEN>
<TOKEN id="token-55-22" pos="word" morph="none" start_char="6856" end_char="6865">commercial</TOKEN>
<TOKEN id="token-55-23" pos="word" morph="none" start_char="6867" end_char="6871">firms</TOKEN>
<TOKEN id="token-55-24" pos="word" morph="none" start_char="6873" end_char="6876">from</TOKEN>
<TOKEN id="token-55-25" pos="word" morph="none" start_char="6878" end_char="6889">monopolizing</TOKEN>
<TOKEN id="token-55-26" pos="word" morph="none" start_char="6891" end_char="6896">public</TOKEN>
<TOKEN id="token-55-27" pos="word" morph="none" start_char="6898" end_char="6903">health</TOKEN>
<TOKEN id="token-55-28" pos="word" morph="none" start_char="6905" end_char="6914">technology</TOKEN>
<TOKEN id="token-55-29" pos="punct" morph="none" start_char="6915" end_char="6915">.</TOKEN>
</SEG>
<SEG id="segment-56" start_char="6917" end_char="7044">
<ORIGINAL_TEXT>Martin also claims the patent was itself illegal, a claim that has also been disputed by patent attorneys and professors of law.</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="6917" end_char="6922">Martin</TOKEN>
<TOKEN id="token-56-1" pos="word" morph="none" start_char="6924" end_char="6927">also</TOKEN>
<TOKEN id="token-56-2" pos="word" morph="none" start_char="6929" end_char="6934">claims</TOKEN>
<TOKEN id="token-56-3" pos="word" morph="none" start_char="6936" end_char="6938">the</TOKEN>
<TOKEN id="token-56-4" pos="word" morph="none" start_char="6940" end_char="6945">patent</TOKEN>
<TOKEN id="token-56-5" pos="word" morph="none" start_char="6947" end_char="6949">was</TOKEN>
<TOKEN id="token-56-6" pos="word" morph="none" start_char="6951" end_char="6956">itself</TOKEN>
<TOKEN id="token-56-7" pos="word" morph="none" start_char="6958" end_char="6964">illegal</TOKEN>
<TOKEN id="token-56-8" pos="punct" morph="none" start_char="6965" end_char="6965">,</TOKEN>
<TOKEN id="token-56-9" pos="word" morph="none" start_char="6967" end_char="6967">a</TOKEN>
<TOKEN id="token-56-10" pos="word" morph="none" start_char="6969" end_char="6973">claim</TOKEN>
<TOKEN id="token-56-11" pos="word" morph="none" start_char="6975" end_char="6978">that</TOKEN>
<TOKEN id="token-56-12" pos="word" morph="none" start_char="6980" end_char="6982">has</TOKEN>
<TOKEN id="token-56-13" pos="word" morph="none" start_char="6984" end_char="6987">also</TOKEN>
<TOKEN id="token-56-14" pos="word" morph="none" start_char="6989" end_char="6992">been</TOKEN>
<TOKEN id="token-56-15" pos="word" morph="none" start_char="6994" end_char="7001">disputed</TOKEN>
<TOKEN id="token-56-16" pos="word" morph="none" start_char="7003" end_char="7004">by</TOKEN>
<TOKEN id="token-56-17" pos="word" morph="none" start_char="7006" end_char="7011">patent</TOKEN>
<TOKEN id="token-56-18" pos="word" morph="none" start_char="7013" end_char="7021">attorneys</TOKEN>
<TOKEN id="token-56-19" pos="word" morph="none" start_char="7023" end_char="7025">and</TOKEN>
<TOKEN id="token-56-20" pos="word" morph="none" start_char="7027" end_char="7036">professors</TOKEN>
<TOKEN id="token-56-21" pos="word" morph="none" start_char="7038" end_char="7039">of</TOKEN>
<TOKEN id="token-56-22" pos="word" morph="none" start_char="7041" end_char="7043">law</TOKEN>
<TOKEN id="token-56-23" pos="punct" morph="none" start_char="7044" end_char="7044">.</TOKEN>
</SEG>
<SEG id="segment-57" start_char="7046" end_char="7086">
<ORIGINAL_TEXT>In Association for Molecular Pathology v.</ORIGINAL_TEXT>
<TOKEN id="token-57-0" pos="word" morph="none" start_char="7046" end_char="7047">In</TOKEN>
<TOKEN id="token-57-1" pos="word" morph="none" start_char="7049" end_char="7059">Association</TOKEN>
<TOKEN id="token-57-2" pos="word" morph="none" start_char="7061" end_char="7063">for</TOKEN>
<TOKEN id="token-57-3" pos="word" morph="none" start_char="7065" end_char="7073">Molecular</TOKEN>
<TOKEN id="token-57-4" pos="word" morph="none" start_char="7075" end_char="7083">Pathology</TOKEN>
<TOKEN id="token-57-5" pos="word" morph="none" start_char="7085" end_char="7085">v</TOKEN>
<TOKEN id="token-57-6" pos="punct" morph="none" start_char="7086" end_char="7086">.</TOKEN>
</SEG>
<SEG id="segment-58" start_char="7088" end_char="7275">
<ORIGINAL_TEXT>Myriad Genetics, the court ruled that isolated strands of DNA code could not be patented, which Martin claims is proof of CDC illegality in patenting its SARS testing methods and findings.</ORIGINAL_TEXT>
<TOKEN id="token-58-0" pos="word" morph="none" start_char="7088" end_char="7093">Myriad</TOKEN>
<TOKEN id="token-58-1" pos="word" morph="none" start_char="7095" end_char="7102">Genetics</TOKEN>
<TOKEN id="token-58-2" pos="punct" morph="none" start_char="7103" end_char="7103">,</TOKEN>
<TOKEN id="token-58-3" pos="word" morph="none" start_char="7105" end_char="7107">the</TOKEN>
<TOKEN id="token-58-4" pos="word" morph="none" start_char="7109" end_char="7113">court</TOKEN>
<TOKEN id="token-58-5" pos="word" morph="none" start_char="7115" end_char="7119">ruled</TOKEN>
<TOKEN id="token-58-6" pos="word" morph="none" start_char="7121" end_char="7124">that</TOKEN>
<TOKEN id="token-58-7" pos="word" morph="none" start_char="7126" end_char="7133">isolated</TOKEN>
<TOKEN id="token-58-8" pos="word" morph="none" start_char="7135" end_char="7141">strands</TOKEN>
<TOKEN id="token-58-9" pos="word" morph="none" start_char="7143" end_char="7144">of</TOKEN>
<TOKEN id="token-58-10" pos="word" morph="none" start_char="7146" end_char="7148">DNA</TOKEN>
<TOKEN id="token-58-11" pos="word" morph="none" start_char="7150" end_char="7153">code</TOKEN>
<TOKEN id="token-58-12" pos="word" morph="none" start_char="7155" end_char="7159">could</TOKEN>
<TOKEN id="token-58-13" pos="word" morph="none" start_char="7161" end_char="7163">not</TOKEN>
<TOKEN id="token-58-14" pos="word" morph="none" start_char="7165" end_char="7166">be</TOKEN>
<TOKEN id="token-58-15" pos="word" morph="none" start_char="7168" end_char="7175">patented</TOKEN>
<TOKEN id="token-58-16" pos="punct" morph="none" start_char="7176" end_char="7176">,</TOKEN>
<TOKEN id="token-58-17" pos="word" morph="none" start_char="7178" end_char="7182">which</TOKEN>
<TOKEN id="token-58-18" pos="word" morph="none" start_char="7184" end_char="7189">Martin</TOKEN>
<TOKEN id="token-58-19" pos="word" morph="none" start_char="7191" end_char="7196">claims</TOKEN>
<TOKEN id="token-58-20" pos="word" morph="none" start_char="7198" end_char="7199">is</TOKEN>
<TOKEN id="token-58-21" pos="word" morph="none" start_char="7201" end_char="7205">proof</TOKEN>
<TOKEN id="token-58-22" pos="word" morph="none" start_char="7207" end_char="7208">of</TOKEN>
<TOKEN id="token-58-23" pos="word" morph="none" start_char="7210" end_char="7212">CDC</TOKEN>
<TOKEN id="token-58-24" pos="word" morph="none" start_char="7214" end_char="7223">illegality</TOKEN>
<TOKEN id="token-58-25" pos="word" morph="none" start_char="7225" end_char="7226">in</TOKEN>
<TOKEN id="token-58-26" pos="word" morph="none" start_char="7228" end_char="7236">patenting</TOKEN>
<TOKEN id="token-58-27" pos="word" morph="none" start_char="7238" end_char="7240">its</TOKEN>
<TOKEN id="token-58-28" pos="word" morph="none" start_char="7242" end_char="7245">SARS</TOKEN>
<TOKEN id="token-58-29" pos="word" morph="none" start_char="7247" end_char="7253">testing</TOKEN>
<TOKEN id="token-58-30" pos="word" morph="none" start_char="7255" end_char="7261">methods</TOKEN>
<TOKEN id="token-58-31" pos="word" morph="none" start_char="7263" end_char="7265">and</TOKEN>
<TOKEN id="token-58-32" pos="word" morph="none" start_char="7267" end_char="7274">findings</TOKEN>
<TOKEN id="token-58-33" pos="punct" morph="none" start_char="7275" end_char="7275">.</TOKEN>
</SEG>
<SEG id="segment-59" start_char="7278" end_char="7362">
<ORIGINAL_TEXT>(Source: Lead Stories Screenshot from paused Facebook video Wed Sep 9 17:17 2020 UTC)</ORIGINAL_TEXT>
<TOKEN id="token-59-0" pos="punct" morph="none" start_char="7278" end_char="7278">(</TOKEN>
<TOKEN id="token-59-1" pos="word" morph="none" start_char="7279" end_char="7284">Source</TOKEN>
<TOKEN id="token-59-2" pos="punct" morph="none" start_char="7285" end_char="7285">:</TOKEN>
<TOKEN id="token-59-3" pos="word" morph="none" start_char="7287" end_char="7290">Lead</TOKEN>
<TOKEN id="token-59-4" pos="word" morph="none" start_char="7292" end_char="7298">Stories</TOKEN>
<TOKEN id="token-59-5" pos="word" morph="none" start_char="7300" end_char="7309">Screenshot</TOKEN>
<TOKEN id="token-59-6" pos="word" morph="none" start_char="7311" end_char="7314">from</TOKEN>
<TOKEN id="token-59-7" pos="word" morph="none" start_char="7316" end_char="7321">paused</TOKEN>
<TOKEN id="token-59-8" pos="word" morph="none" start_char="7323" end_char="7330">Facebook</TOKEN>
<TOKEN id="token-59-9" pos="word" morph="none" start_char="7332" end_char="7336">video</TOKEN>
<TOKEN id="token-59-10" pos="word" morph="none" start_char="7338" end_char="7340">Wed</TOKEN>
<TOKEN id="token-59-11" pos="word" morph="none" start_char="7342" end_char="7344">Sep</TOKEN>
<TOKEN id="token-59-12" pos="word" morph="none" start_char="7346" end_char="7346">9</TOKEN>
<TOKEN id="token-59-13" pos="unknown" morph="none" start_char="7348" end_char="7352">17:17</TOKEN>
<TOKEN id="token-59-14" pos="word" morph="none" start_char="7354" end_char="7357">2020</TOKEN>
<TOKEN id="token-59-15" pos="word" morph="none" start_char="7359" end_char="7361">UTC</TOKEN>
<TOKEN id="token-59-16" pos="punct" morph="none" start_char="7362" end_char="7362">)</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
