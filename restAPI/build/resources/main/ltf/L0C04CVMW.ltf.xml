<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CVMW" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="10488" raw_text_md5="48758e5f01d246a0f617abc754e6af8e">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="174">
<ORIGINAL_TEXT>Current data from clinical trials offer no reliable evidence that ivermectin is effective against COVID-19; better-quality clinical trials are needed to resolve this question</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="7">Current</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="9" end_char="12">data</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="14" end_char="17">from</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="19" end_char="26">clinical</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="28" end_char="33">trials</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="35" end_char="39">offer</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="41" end_char="42">no</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="44" end_char="51">reliable</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="53" end_char="60">evidence</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="62" end_char="65">that</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="67" end_char="76">ivermectin</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="78" end_char="79">is</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="81" end_char="89">effective</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="91" end_char="97">against</TOKEN>
<TOKEN id="token-0-14" pos="unknown" morph="none" start_char="99" end_char="106">COVID-19</TOKEN>
<TOKEN id="token-0-15" pos="punct" morph="none" start_char="107" end_char="107">;</TOKEN>
<TOKEN id="token-0-16" pos="unknown" morph="none" start_char="109" end_char="122">better-quality</TOKEN>
<TOKEN id="token-0-17" pos="word" morph="none" start_char="124" end_char="131">clinical</TOKEN>
<TOKEN id="token-0-18" pos="word" morph="none" start_char="133" end_char="138">trials</TOKEN>
<TOKEN id="token-0-19" pos="word" morph="none" start_char="140" end_char="142">are</TOKEN>
<TOKEN id="token-0-20" pos="word" morph="none" start_char="144" end_char="149">needed</TOKEN>
<TOKEN id="token-0-21" pos="word" morph="none" start_char="151" end_char="152">to</TOKEN>
<TOKEN id="token-0-22" pos="word" morph="none" start_char="154" end_char="160">resolve</TOKEN>
<TOKEN id="token-0-23" pos="word" morph="none" start_char="162" end_char="165">this</TOKEN>
<TOKEN id="token-0-24" pos="word" morph="none" start_char="167" end_char="174">question</TOKEN>
</SEG>
<SEG id="segment-1" start_char="178" end_char="634">
<ORIGINAL_TEXT>FULL CLAIM: "Ivermectin is the only thing we have that treats COVID at all stages […] Ivermectin substantially reduces deaths from COVID and prevents infections"; "If you go to Dr. Tess Lawrie, there are 51 studies published in the medical literature, 50 of them show ivermectin is not just effective, but highly effective"; "There are 12 [prophylaxis] studies showing that ivermectin has a close to 90% efficacy, which is equal or superior to the vaccines"</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="178" end_char="181">FULL</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="183" end_char="187">CLAIM</TOKEN>
<TOKEN id="token-1-2" pos="punct" morph="none" start_char="188" end_char="188">:</TOKEN>
<TOKEN id="token-1-3" pos="punct" morph="none" start_char="190" end_char="190">"</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="191" end_char="200">Ivermectin</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="202" end_char="203">is</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="205" end_char="207">the</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="209" end_char="212">only</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="214" end_char="218">thing</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="220" end_char="221">we</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="223" end_char="226">have</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="228" end_char="231">that</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="233" end_char="238">treats</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="240" end_char="244">COVID</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="246" end_char="247">at</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="249" end_char="251">all</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="253" end_char="258">stages</TOKEN>
<TOKEN id="token-1-17" pos="punct" morph="none" start_char="260" end_char="262">[…]</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="264" end_char="273">Ivermectin</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="275" end_char="287">substantially</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="289" end_char="295">reduces</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="297" end_char="302">deaths</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="304" end_char="307">from</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="309" end_char="313">COVID</TOKEN>
<TOKEN id="token-1-24" pos="word" morph="none" start_char="315" end_char="317">and</TOKEN>
<TOKEN id="token-1-25" pos="word" morph="none" start_char="319" end_char="326">prevents</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="328" end_char="337">infections</TOKEN>
<TOKEN id="token-1-27" pos="punct" morph="none" start_char="338" end_char="339">";</TOKEN>
<TOKEN id="token-1-28" pos="punct" morph="none" start_char="341" end_char="341">"</TOKEN>
<TOKEN id="token-1-29" pos="word" morph="none" start_char="342" end_char="343">If</TOKEN>
<TOKEN id="token-1-30" pos="word" morph="none" start_char="345" end_char="347">you</TOKEN>
<TOKEN id="token-1-31" pos="word" morph="none" start_char="349" end_char="350">go</TOKEN>
<TOKEN id="token-1-32" pos="word" morph="none" start_char="352" end_char="353">to</TOKEN>
<TOKEN id="token-1-33" pos="word" morph="none" start_char="355" end_char="356">Dr</TOKEN>
<TOKEN id="token-1-34" pos="punct" morph="none" start_char="357" end_char="357">.</TOKEN>
<TOKEN id="token-1-35" pos="word" morph="none" start_char="359" end_char="362">Tess</TOKEN>
<TOKEN id="token-1-36" pos="word" morph="none" start_char="364" end_char="369">Lawrie</TOKEN>
<TOKEN id="token-1-37" pos="punct" morph="none" start_char="370" end_char="370">,</TOKEN>
<TOKEN id="token-1-38" pos="word" morph="none" start_char="372" end_char="376">there</TOKEN>
<TOKEN id="token-1-39" pos="word" morph="none" start_char="378" end_char="380">are</TOKEN>
<TOKEN id="token-1-40" pos="word" morph="none" start_char="382" end_char="383">51</TOKEN>
<TOKEN id="token-1-41" pos="word" morph="none" start_char="385" end_char="391">studies</TOKEN>
<TOKEN id="token-1-42" pos="word" morph="none" start_char="393" end_char="401">published</TOKEN>
<TOKEN id="token-1-43" pos="word" morph="none" start_char="403" end_char="404">in</TOKEN>
<TOKEN id="token-1-44" pos="word" morph="none" start_char="406" end_char="408">the</TOKEN>
<TOKEN id="token-1-45" pos="word" morph="none" start_char="410" end_char="416">medical</TOKEN>
<TOKEN id="token-1-46" pos="word" morph="none" start_char="418" end_char="427">literature</TOKEN>
<TOKEN id="token-1-47" pos="punct" morph="none" start_char="428" end_char="428">,</TOKEN>
<TOKEN id="token-1-48" pos="word" morph="none" start_char="430" end_char="431">50</TOKEN>
<TOKEN id="token-1-49" pos="word" morph="none" start_char="433" end_char="434">of</TOKEN>
<TOKEN id="token-1-50" pos="word" morph="none" start_char="436" end_char="439">them</TOKEN>
<TOKEN id="token-1-51" pos="word" morph="none" start_char="441" end_char="444">show</TOKEN>
<TOKEN id="token-1-52" pos="word" morph="none" start_char="446" end_char="455">ivermectin</TOKEN>
<TOKEN id="token-1-53" pos="word" morph="none" start_char="457" end_char="458">is</TOKEN>
<TOKEN id="token-1-54" pos="word" morph="none" start_char="460" end_char="462">not</TOKEN>
<TOKEN id="token-1-55" pos="word" morph="none" start_char="464" end_char="467">just</TOKEN>
<TOKEN id="token-1-56" pos="word" morph="none" start_char="469" end_char="477">effective</TOKEN>
<TOKEN id="token-1-57" pos="punct" morph="none" start_char="478" end_char="478">,</TOKEN>
<TOKEN id="token-1-58" pos="word" morph="none" start_char="480" end_char="482">but</TOKEN>
<TOKEN id="token-1-59" pos="word" morph="none" start_char="484" end_char="489">highly</TOKEN>
<TOKEN id="token-1-60" pos="word" morph="none" start_char="491" end_char="499">effective</TOKEN>
<TOKEN id="token-1-61" pos="punct" morph="none" start_char="500" end_char="501">";</TOKEN>
<TOKEN id="token-1-62" pos="punct" morph="none" start_char="503" end_char="503">"</TOKEN>
<TOKEN id="token-1-63" pos="word" morph="none" start_char="504" end_char="508">There</TOKEN>
<TOKEN id="token-1-64" pos="word" morph="none" start_char="510" end_char="512">are</TOKEN>
<TOKEN id="token-1-65" pos="word" morph="none" start_char="514" end_char="515">12</TOKEN>
<TOKEN id="token-1-66" pos="punct" morph="none" start_char="517" end_char="517">[</TOKEN>
<TOKEN id="token-1-67" pos="word" morph="none" start_char="518" end_char="528">prophylaxis</TOKEN>
<TOKEN id="token-1-68" pos="punct" morph="none" start_char="529" end_char="529">]</TOKEN>
<TOKEN id="token-1-69" pos="word" morph="none" start_char="531" end_char="537">studies</TOKEN>
<TOKEN id="token-1-70" pos="word" morph="none" start_char="539" end_char="545">showing</TOKEN>
<TOKEN id="token-1-71" pos="word" morph="none" start_char="547" end_char="550">that</TOKEN>
<TOKEN id="token-1-72" pos="word" morph="none" start_char="552" end_char="561">ivermectin</TOKEN>
<TOKEN id="token-1-73" pos="word" morph="none" start_char="563" end_char="565">has</TOKEN>
<TOKEN id="token-1-74" pos="word" morph="none" start_char="567" end_char="567">a</TOKEN>
<TOKEN id="token-1-75" pos="word" morph="none" start_char="569" end_char="573">close</TOKEN>
<TOKEN id="token-1-76" pos="word" morph="none" start_char="575" end_char="576">to</TOKEN>
<TOKEN id="token-1-77" pos="word" morph="none" start_char="578" end_char="579">90</TOKEN>
<TOKEN id="token-1-78" pos="punct" morph="none" start_char="580" end_char="580">%</TOKEN>
<TOKEN id="token-1-79" pos="word" morph="none" start_char="582" end_char="589">efficacy</TOKEN>
<TOKEN id="token-1-80" pos="punct" morph="none" start_char="590" end_char="590">,</TOKEN>
<TOKEN id="token-1-81" pos="word" morph="none" start_char="592" end_char="596">which</TOKEN>
<TOKEN id="token-1-82" pos="word" morph="none" start_char="598" end_char="599">is</TOKEN>
<TOKEN id="token-1-83" pos="word" morph="none" start_char="601" end_char="605">equal</TOKEN>
<TOKEN id="token-1-84" pos="word" morph="none" start_char="607" end_char="608">or</TOKEN>
<TOKEN id="token-1-85" pos="word" morph="none" start_char="610" end_char="617">superior</TOKEN>
<TOKEN id="token-1-86" pos="word" morph="none" start_char="619" end_char="620">to</TOKEN>
<TOKEN id="token-1-87" pos="word" morph="none" start_char="622" end_char="624">the</TOKEN>
<TOKEN id="token-1-88" pos="word" morph="none" start_char="626" end_char="633">vaccines</TOKEN>
<TOKEN id="token-1-89" pos="punct" morph="none" start_char="634" end_char="634">"</TOKEN>
</SEG>
<SEG id="segment-2" start_char="638" end_char="829">
<ORIGINAL_TEXT>A Sky News segment hosted by Alan Jones and featuring Craig Kelly, a Member of the Australian Parliament, claimed that scientific studies supported the use of ivermectin for treating COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="638" end_char="638">A</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="640" end_char="642">Sky</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="644" end_char="647">News</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="649" end_char="655">segment</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="657" end_char="662">hosted</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="664" end_char="665">by</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="667" end_char="670">Alan</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="672" end_char="676">Jones</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="678" end_char="680">and</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="682" end_char="690">featuring</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="692" end_char="696">Craig</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="698" end_char="702">Kelly</TOKEN>
<TOKEN id="token-2-12" pos="punct" morph="none" start_char="703" end_char="703">,</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="705" end_char="705">a</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="707" end_char="712">Member</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="714" end_char="715">of</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="717" end_char="719">the</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="721" end_char="730">Australian</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="732" end_char="741">Parliament</TOKEN>
<TOKEN id="token-2-19" pos="punct" morph="none" start_char="742" end_char="742">,</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="744" end_char="750">claimed</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="752" end_char="755">that</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="757" end_char="766">scientific</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="768" end_char="774">studies</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="776" end_char="784">supported</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="786" end_char="788">the</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="790" end_char="792">use</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="794" end_char="795">of</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="797" end_char="806">ivermectin</TOKEN>
<TOKEN id="token-2-29" pos="word" morph="none" start_char="808" end_char="810">for</TOKEN>
<TOKEN id="token-2-30" pos="word" morph="none" start_char="812" end_char="819">treating</TOKEN>
<TOKEN id="token-2-31" pos="unknown" morph="none" start_char="821" end_char="828">COVID-19</TOKEN>
<TOKEN id="token-2-32" pos="punct" morph="none" start_char="829" end_char="829">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="831" end_char="1004">
<ORIGINAL_TEXT>Published on 15 April 2021, the segment was shared on Kelly’s Facebook page, receiving more than 150,000 views and more than 6,500 interactions, including likes and comments.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="831" end_char="839">Published</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="841" end_char="842">on</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="844" end_char="845">15</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="847" end_char="851">April</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="853" end_char="856">2021</TOKEN>
<TOKEN id="token-3-5" pos="punct" morph="none" start_char="857" end_char="857">,</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="859" end_char="861">the</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="863" end_char="869">segment</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="871" end_char="873">was</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="875" end_char="880">shared</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="882" end_char="883">on</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="885" end_char="891">Kelly’s</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="893" end_char="900">Facebook</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="902" end_char="905">page</TOKEN>
<TOKEN id="token-3-14" pos="punct" morph="none" start_char="906" end_char="906">,</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="908" end_char="916">receiving</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="918" end_char="921">more</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="923" end_char="926">than</TOKEN>
<TOKEN id="token-3-18" pos="unknown" morph="none" start_char="928" end_char="934">150,000</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="936" end_char="940">views</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="942" end_char="944">and</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="946" end_char="949">more</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="951" end_char="954">than</TOKEN>
<TOKEN id="token-3-23" pos="unknown" morph="none" start_char="956" end_char="960">6,500</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="962" end_char="973">interactions</TOKEN>
<TOKEN id="token-3-25" pos="punct" morph="none" start_char="974" end_char="974">,</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="976" end_char="984">including</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="986" end_char="990">likes</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="992" end_char="994">and</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="996" end_char="1003">comments</TOKEN>
<TOKEN id="token-3-30" pos="punct" morph="none" start_char="1004" end_char="1004">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="1007" end_char="1159">
<ORIGINAL_TEXT>This isn’t the first time that Kelly, who has no scientific training, made unsubstantiated claims about the efficacy of ivermectin for treating COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="1007" end_char="1010">This</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="1012" end_char="1016">isn’t</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="1018" end_char="1020">the</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="1022" end_char="1026">first</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="1028" end_char="1031">time</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="1033" end_char="1036">that</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="1038" end_char="1042">Kelly</TOKEN>
<TOKEN id="token-4-7" pos="punct" morph="none" start_char="1043" end_char="1043">,</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="1045" end_char="1047">who</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="1049" end_char="1051">has</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="1053" end_char="1054">no</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="1056" end_char="1065">scientific</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="1067" end_char="1074">training</TOKEN>
<TOKEN id="token-4-13" pos="punct" morph="none" start_char="1075" end_char="1075">,</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="1077" end_char="1080">made</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="1082" end_char="1096">unsubstantiated</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="1098" end_char="1103">claims</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="1105" end_char="1109">about</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="1111" end_char="1113">the</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="1115" end_char="1122">efficacy</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="1124" end_char="1125">of</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="1127" end_char="1136">ivermectin</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="1138" end_char="1140">for</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="1142" end_char="1149">treating</TOKEN>
<TOKEN id="token-4-24" pos="unknown" morph="none" start_char="1151" end_char="1158">COVID-19</TOKEN>
<TOKEN id="token-4-25" pos="punct" morph="none" start_char="1159" end_char="1159">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="1161" end_char="1335">
<ORIGINAL_TEXT>During the interview, Kelly also cited the findings of physician Tess Lawrie, alleging that 50 out of 51 studies show "ivermectin is not just effective, but highly effective".</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="1161" end_char="1166">During</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="1168" end_char="1170">the</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="1172" end_char="1180">interview</TOKEN>
<TOKEN id="token-5-3" pos="punct" morph="none" start_char="1181" end_char="1181">,</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="1183" end_char="1187">Kelly</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="1189" end_char="1192">also</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="1194" end_char="1198">cited</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="1200" end_char="1202">the</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="1204" end_char="1211">findings</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="1213" end_char="1214">of</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="1216" end_char="1224">physician</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="1226" end_char="1229">Tess</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="1231" end_char="1236">Lawrie</TOKEN>
<TOKEN id="token-5-13" pos="punct" morph="none" start_char="1237" end_char="1237">,</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="1239" end_char="1246">alleging</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="1248" end_char="1251">that</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="1253" end_char="1254">50</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="1256" end_char="1258">out</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="1260" end_char="1261">of</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="1263" end_char="1264">51</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="1266" end_char="1272">studies</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="1274" end_char="1277">show</TOKEN>
<TOKEN id="token-5-22" pos="punct" morph="none" start_char="1279" end_char="1279">"</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="1280" end_char="1289">ivermectin</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="1291" end_char="1292">is</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="1294" end_char="1296">not</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="1298" end_char="1301">just</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="1303" end_char="1311">effective</TOKEN>
<TOKEN id="token-5-28" pos="punct" morph="none" start_char="1312" end_char="1312">,</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="1314" end_char="1316">but</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="1318" end_char="1323">highly</TOKEN>
<TOKEN id="token-5-31" pos="word" morph="none" start_char="1325" end_char="1333">effective</TOKEN>
<TOKEN id="token-5-32" pos="punct" morph="none" start_char="1334" end_char="1335">".</TOKEN>
</SEG>
<SEG id="segment-6" start_char="1338" end_char="1373">
<ORIGINAL_TEXT>Ivermectin is an antiparasitic drug.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="1338" end_char="1347">Ivermectin</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="1349" end_char="1350">is</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="1352" end_char="1353">an</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="1355" end_char="1367">antiparasitic</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="1369" end_char="1372">drug</TOKEN>
<TOKEN id="token-6-5" pos="punct" morph="none" start_char="1373" end_char="1373">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="1375" end_char="1507">
<ORIGINAL_TEXT>Health Feedback addressed the unsupported claim that ivermectin is effective against COVID-19 in several reviews (see here and here).</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="1375" end_char="1380">Health</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="1382" end_char="1389">Feedback</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="1391" end_char="1399">addressed</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="1401" end_char="1403">the</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="1405" end_char="1415">unsupported</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="1417" end_char="1421">claim</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="1423" end_char="1426">that</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="1428" end_char="1437">ivermectin</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="1439" end_char="1440">is</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="1442" end_char="1450">effective</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="1452" end_char="1458">against</TOKEN>
<TOKEN id="token-7-11" pos="unknown" morph="none" start_char="1460" end_char="1467">COVID-19</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="1469" end_char="1470">in</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="1472" end_char="1478">several</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="1480" end_char="1486">reviews</TOKEN>
<TOKEN id="token-7-15" pos="punct" morph="none" start_char="1488" end_char="1488">(</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="1489" end_char="1491">see</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="1493" end_char="1496">here</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="1498" end_char="1500">and</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="1502" end_char="1505">here</TOKEN>
<TOKEN id="token-7-20" pos="punct" morph="none" start_char="1506" end_char="1507">).</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1509" end_char="1648">
<ORIGINAL_TEXT>Claims about ivermectin’s efficacy began with a study that reported that ivermectin reduced viral replication of SARS-CoV-2 in cell cultures</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1509" end_char="1514">Claims</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1516" end_char="1520">about</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1522" end_char="1533">ivermectin’s</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1535" end_char="1542">efficacy</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1544" end_char="1548">began</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1550" end_char="1553">with</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1555" end_char="1555">a</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1557" end_char="1561">study</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1563" end_char="1566">that</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1568" end_char="1575">reported</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1577" end_char="1580">that</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1582" end_char="1591">ivermectin</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1593" end_char="1599">reduced</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1601" end_char="1605">viral</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1607" end_char="1617">replication</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1619" end_char="1620">of</TOKEN>
<TOKEN id="token-8-16" pos="unknown" morph="none" start_char="1622" end_char="1631">SARS-CoV-2</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1633" end_char="1634">in</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1636" end_char="1639">cell</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1641" end_char="1648">cultures</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1651" end_char="1653">
<ORIGINAL_TEXT>[1]</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="punct" morph="none" start_char="1651" end_char="1651">[</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1652" end_char="1652">1</TOKEN>
<TOKEN id="token-9-2" pos="punct" morph="none" start_char="1653" end_char="1653">]</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1656" end_char="1656">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="punct" morph="none" start_char="1656" end_char="1656">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1659" end_char="1822">
<ORIGINAL_TEXT>However, other scientists pointed out that this only occurred at "physiologically unattainable concentrations", as seen in this June 2020 editorial published in the</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1659" end_char="1665">However</TOKEN>
<TOKEN id="token-11-1" pos="punct" morph="none" start_char="1666" end_char="1666">,</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1668" end_char="1672">other</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1674" end_char="1683">scientists</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1685" end_char="1691">pointed</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1693" end_char="1695">out</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1697" end_char="1700">that</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1702" end_char="1705">this</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1707" end_char="1710">only</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1712" end_char="1719">occurred</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1721" end_char="1722">at</TOKEN>
<TOKEN id="token-11-11" pos="punct" morph="none" start_char="1724" end_char="1724">"</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1725" end_char="1739">physiologically</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1741" end_char="1752">unattainable</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1754" end_char="1767">concentrations</TOKEN>
<TOKEN id="token-11-15" pos="punct" morph="none" start_char="1768" end_char="1769">",</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1771" end_char="1772">as</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1774" end_char="1777">seen</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1779" end_char="1780">in</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="1782" end_char="1785">this</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1787" end_char="1790">June</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="1792" end_char="1795">2020</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="1797" end_char="1805">editorial</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="1807" end_char="1815">published</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="1817" end_char="1818">in</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="1820" end_char="1822">the</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1825" end_char="1873">
<ORIGINAL_TEXT>American Journal of Tropical Medicine and Hygiene</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1825" end_char="1832">American</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1834" end_char="1840">Journal</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1842" end_char="1843">of</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1845" end_char="1852">Tropical</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1854" end_char="1861">Medicine</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1863" end_char="1865">and</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1867" end_char="1873">Hygiene</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1876" end_char="1878">
<ORIGINAL_TEXT>[2]</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="punct" morph="none" start_char="1876" end_char="1876">[</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1877" end_char="1877">2</TOKEN>
<TOKEN id="token-13-2" pos="punct" morph="none" start_char="1878" end_char="1878">]</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1881" end_char="1881">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="punct" morph="none" start_char="1881" end_char="1881">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1883" end_char="2067">
<ORIGINAL_TEXT>The same editorial acknowledged that this alone wouldn’t rule out the possibility that ivermectin had some beneficial effect in people, hence clinical trials would still be of interest.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1883" end_char="1885">The</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1887" end_char="1890">same</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1892" end_char="1900">editorial</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1902" end_char="1913">acknowledged</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1915" end_char="1918">that</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1920" end_char="1923">this</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1925" end_char="1929">alone</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1931" end_char="1938">wouldn’t</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1940" end_char="1943">rule</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1945" end_char="1947">out</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1949" end_char="1951">the</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1953" end_char="1963">possibility</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1965" end_char="1968">that</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1970" end_char="1979">ivermectin</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1981" end_char="1983">had</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="1985" end_char="1988">some</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="1990" end_char="1999">beneficial</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="2001" end_char="2006">effect</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="2008" end_char="2009">in</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="2011" end_char="2016">people</TOKEN>
<TOKEN id="token-15-20" pos="punct" morph="none" start_char="2017" end_char="2017">,</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="2019" end_char="2023">hence</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="2025" end_char="2032">clinical</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="2034" end_char="2039">trials</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="2041" end_char="2045">would</TOKEN>
<TOKEN id="token-15-25" pos="word" morph="none" start_char="2047" end_char="2051">still</TOKEN>
<TOKEN id="token-15-26" pos="word" morph="none" start_char="2053" end_char="2054">be</TOKEN>
<TOKEN id="token-15-27" pos="word" morph="none" start_char="2056" end_char="2057">of</TOKEN>
<TOKEN id="token-15-28" pos="word" morph="none" start_char="2059" end_char="2066">interest</TOKEN>
<TOKEN id="token-15-29" pos="punct" morph="none" start_char="2067" end_char="2067">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="2070" end_char="2203">
<ORIGINAL_TEXT>Since that editorial’s publication, numerous clinical trials studying the efficacy of ivermectin against COVID-19 have been conducted.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="2070" end_char="2074">Since</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="2076" end_char="2079">that</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="2081" end_char="2091">editorial’s</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="2093" end_char="2103">publication</TOKEN>
<TOKEN id="token-16-4" pos="punct" morph="none" start_char="2104" end_char="2104">,</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="2106" end_char="2113">numerous</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="2115" end_char="2122">clinical</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="2124" end_char="2129">trials</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="2131" end_char="2138">studying</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="2140" end_char="2142">the</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="2144" end_char="2151">efficacy</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="2153" end_char="2154">of</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="2156" end_char="2165">ivermectin</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="2167" end_char="2173">against</TOKEN>
<TOKEN id="token-16-14" pos="unknown" morph="none" start_char="2175" end_char="2182">COVID-19</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="2184" end_char="2187">have</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="2189" end_char="2192">been</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="2194" end_char="2202">conducted</TOKEN>
<TOKEN id="token-16-18" pos="punct" morph="none" start_char="2203" end_char="2203">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2205" end_char="2355">
<ORIGINAL_TEXT>Public health authorities have attempted to use currently available data to provide the best possible guidance, at this time, on the use of ivermectin.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2205" end_char="2210">Public</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2212" end_char="2217">health</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2219" end_char="2229">authorities</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2231" end_char="2234">have</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2236" end_char="2244">attempted</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2246" end_char="2247">to</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2249" end_char="2251">use</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2253" end_char="2261">currently</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2263" end_char="2271">available</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2273" end_char="2276">data</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2278" end_char="2279">to</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2281" end_char="2287">provide</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2289" end_char="2291">the</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2293" end_char="2296">best</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2298" end_char="2305">possible</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2307" end_char="2314">guidance</TOKEN>
<TOKEN id="token-17-16" pos="punct" morph="none" start_char="2315" end_char="2315">,</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="2317" end_char="2318">at</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="2320" end_char="2323">this</TOKEN>
<TOKEN id="token-17-19" pos="word" morph="none" start_char="2325" end_char="2328">time</TOKEN>
<TOKEN id="token-17-20" pos="punct" morph="none" start_char="2329" end_char="2329">,</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="2331" end_char="2332">on</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="2334" end_char="2336">the</TOKEN>
<TOKEN id="token-17-23" pos="word" morph="none" start_char="2338" end_char="2340">use</TOKEN>
<TOKEN id="token-17-24" pos="word" morph="none" start_char="2342" end_char="2343">of</TOKEN>
<TOKEN id="token-17-25" pos="word" morph="none" start_char="2345" end_char="2354">ivermectin</TOKEN>
<TOKEN id="token-17-26" pos="punct" morph="none" start_char="2355" end_char="2355">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2358" end_char="2493">
<ORIGINAL_TEXT>For example, the World Health Organization (WHO) evaluated data from 16 randomized controlled trials, which included 2,407 participants.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2358" end_char="2360">For</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2362" end_char="2368">example</TOKEN>
<TOKEN id="token-18-2" pos="punct" morph="none" start_char="2369" end_char="2369">,</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2371" end_char="2373">the</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2375" end_char="2379">World</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2381" end_char="2386">Health</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2388" end_char="2399">Organization</TOKEN>
<TOKEN id="token-18-7" pos="punct" morph="none" start_char="2401" end_char="2401">(</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2402" end_char="2404">WHO</TOKEN>
<TOKEN id="token-18-9" pos="punct" morph="none" start_char="2405" end_char="2405">)</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="2407" end_char="2415">evaluated</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="2417" end_char="2420">data</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2422" end_char="2425">from</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="2427" end_char="2428">16</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="2430" end_char="2439">randomized</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="2441" end_char="2450">controlled</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="2452" end_char="2457">trials</TOKEN>
<TOKEN id="token-18-17" pos="punct" morph="none" start_char="2458" end_char="2458">,</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="2460" end_char="2464">which</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="2466" end_char="2473">included</TOKEN>
<TOKEN id="token-18-20" pos="unknown" morph="none" start_char="2475" end_char="2479">2,407</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="2481" end_char="2492">participants</TOKEN>
<TOKEN id="token-18-22" pos="punct" morph="none" start_char="2493" end_char="2493">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2495" end_char="2698">
<ORIGINAL_TEXT>Its living guideline on proposed therapeutics for COVID-19, most recently updated on 31 March 2021, recommended "not to use ivermectin in patients with COVID-19 except in the context of a clinical trial".</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2495" end_char="2497">Its</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2499" end_char="2504">living</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2506" end_char="2514">guideline</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2516" end_char="2517">on</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2519" end_char="2526">proposed</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2528" end_char="2539">therapeutics</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2541" end_char="2543">for</TOKEN>
<TOKEN id="token-19-7" pos="unknown" morph="none" start_char="2545" end_char="2552">COVID-19</TOKEN>
<TOKEN id="token-19-8" pos="punct" morph="none" start_char="2553" end_char="2553">,</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="2555" end_char="2558">most</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="2560" end_char="2567">recently</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="2569" end_char="2575">updated</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="2577" end_char="2578">on</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="2580" end_char="2581">31</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="2583" end_char="2587">March</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="2589" end_char="2592">2021</TOKEN>
<TOKEN id="token-19-16" pos="punct" morph="none" start_char="2593" end_char="2593">,</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="2595" end_char="2605">recommended</TOKEN>
<TOKEN id="token-19-18" pos="punct" morph="none" start_char="2607" end_char="2607">"</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="2608" end_char="2610">not</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="2612" end_char="2613">to</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="2615" end_char="2617">use</TOKEN>
<TOKEN id="token-19-22" pos="word" morph="none" start_char="2619" end_char="2628">ivermectin</TOKEN>
<TOKEN id="token-19-23" pos="word" morph="none" start_char="2630" end_char="2631">in</TOKEN>
<TOKEN id="token-19-24" pos="word" morph="none" start_char="2633" end_char="2640">patients</TOKEN>
<TOKEN id="token-19-25" pos="word" morph="none" start_char="2642" end_char="2645">with</TOKEN>
<TOKEN id="token-19-26" pos="unknown" morph="none" start_char="2647" end_char="2654">COVID-19</TOKEN>
<TOKEN id="token-19-27" pos="word" morph="none" start_char="2656" end_char="2661">except</TOKEN>
<TOKEN id="token-19-28" pos="word" morph="none" start_char="2663" end_char="2664">in</TOKEN>
<TOKEN id="token-19-29" pos="word" morph="none" start_char="2666" end_char="2668">the</TOKEN>
<TOKEN id="token-19-30" pos="word" morph="none" start_char="2670" end_char="2676">context</TOKEN>
<TOKEN id="token-19-31" pos="word" morph="none" start_char="2678" end_char="2679">of</TOKEN>
<TOKEN id="token-19-32" pos="word" morph="none" start_char="2681" end_char="2681">a</TOKEN>
<TOKEN id="token-19-33" pos="word" morph="none" start_char="2683" end_char="2690">clinical</TOKEN>
<TOKEN id="token-19-34" pos="word" morph="none" start_char="2692" end_char="2696">trial</TOKEN>
<TOKEN id="token-19-35" pos="punct" morph="none" start_char="2697" end_char="2698">".</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2701" end_char="2770">
<ORIGINAL_TEXT>The guideline also explained the decision not to recommend ivermectin:</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2701" end_char="2703">The</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2705" end_char="2713">guideline</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2715" end_char="2718">also</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2720" end_char="2728">explained</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2730" end_char="2732">the</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2734" end_char="2741">decision</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2743" end_char="2745">not</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2747" end_char="2748">to</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="2750" end_char="2758">recommend</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2760" end_char="2769">ivermectin</TOKEN>
<TOKEN id="token-20-10" pos="punct" morph="none" start_char="2770" end_char="2770">:</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2773" end_char="2773">
<ORIGINAL_TEXT>"</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="punct" morph="none" start_char="2773" end_char="2773">"</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2776" end_char="2993">
<ORIGINAL_TEXT>The effects of ivermectin on mortality, need for invasive mechanical ventilation, hospital admission, duration of hospitalization and time to viral clearance all remain very uncertain (all very low certainty evidence).</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2776" end_char="2778">The</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2780" end_char="2786">effects</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2788" end_char="2789">of</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2791" end_char="2800">ivermectin</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2802" end_char="2803">on</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2805" end_char="2813">mortality</TOKEN>
<TOKEN id="token-22-6" pos="punct" morph="none" start_char="2814" end_char="2814">,</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2816" end_char="2819">need</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="2821" end_char="2823">for</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="2825" end_char="2832">invasive</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="2834" end_char="2843">mechanical</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="2845" end_char="2855">ventilation</TOKEN>
<TOKEN id="token-22-12" pos="punct" morph="none" start_char="2856" end_char="2856">,</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="2858" end_char="2865">hospital</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="2867" end_char="2875">admission</TOKEN>
<TOKEN id="token-22-15" pos="punct" morph="none" start_char="2876" end_char="2876">,</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="2878" end_char="2885">duration</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="2887" end_char="2888">of</TOKEN>
<TOKEN id="token-22-18" pos="word" morph="none" start_char="2890" end_char="2904">hospitalization</TOKEN>
<TOKEN id="token-22-19" pos="word" morph="none" start_char="2906" end_char="2908">and</TOKEN>
<TOKEN id="token-22-20" pos="word" morph="none" start_char="2910" end_char="2913">time</TOKEN>
<TOKEN id="token-22-21" pos="word" morph="none" start_char="2915" end_char="2916">to</TOKEN>
<TOKEN id="token-22-22" pos="word" morph="none" start_char="2918" end_char="2922">viral</TOKEN>
<TOKEN id="token-22-23" pos="word" morph="none" start_char="2924" end_char="2932">clearance</TOKEN>
<TOKEN id="token-22-24" pos="word" morph="none" start_char="2934" end_char="2936">all</TOKEN>
<TOKEN id="token-22-25" pos="word" morph="none" start_char="2938" end_char="2943">remain</TOKEN>
<TOKEN id="token-22-26" pos="word" morph="none" start_char="2945" end_char="2948">very</TOKEN>
<TOKEN id="token-22-27" pos="word" morph="none" start_char="2950" end_char="2958">uncertain</TOKEN>
<TOKEN id="token-22-28" pos="punct" morph="none" start_char="2960" end_char="2960">(</TOKEN>
<TOKEN id="token-22-29" pos="word" morph="none" start_char="2961" end_char="2963">all</TOKEN>
<TOKEN id="token-22-30" pos="word" morph="none" start_char="2965" end_char="2968">very</TOKEN>
<TOKEN id="token-22-31" pos="word" morph="none" start_char="2970" end_char="2972">low</TOKEN>
<TOKEN id="token-22-32" pos="word" morph="none" start_char="2974" end_char="2982">certainty</TOKEN>
<TOKEN id="token-22-33" pos="word" morph="none" start_char="2984" end_char="2991">evidence</TOKEN>
<TOKEN id="token-22-34" pos="punct" morph="none" start_char="2992" end_char="2993">).</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2995" end_char="3212">
<ORIGINAL_TEXT>The uncertainty results from important concerns related to risk of bias in the included studies, and imprecision from a very low number of events and, in some cases, wide confidence intervals (CIs) in pooled estimates.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2995" end_char="2997">The</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2999" end_char="3009">uncertainty</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="3011" end_char="3017">results</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="3019" end_char="3022">from</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="3024" end_char="3032">important</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="3034" end_char="3041">concerns</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="3043" end_char="3049">related</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="3051" end_char="3052">to</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="3054" end_char="3057">risk</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="3059" end_char="3060">of</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="3062" end_char="3065">bias</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="3067" end_char="3068">in</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="3070" end_char="3072">the</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="3074" end_char="3081">included</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="3083" end_char="3089">studies</TOKEN>
<TOKEN id="token-23-15" pos="punct" morph="none" start_char="3090" end_char="3090">,</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="3092" end_char="3094">and</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="3096" end_char="3106">imprecision</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="3108" end_char="3111">from</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="3113" end_char="3113">a</TOKEN>
<TOKEN id="token-23-20" pos="word" morph="none" start_char="3115" end_char="3118">very</TOKEN>
<TOKEN id="token-23-21" pos="word" morph="none" start_char="3120" end_char="3122">low</TOKEN>
<TOKEN id="token-23-22" pos="word" morph="none" start_char="3124" end_char="3129">number</TOKEN>
<TOKEN id="token-23-23" pos="word" morph="none" start_char="3131" end_char="3132">of</TOKEN>
<TOKEN id="token-23-24" pos="word" morph="none" start_char="3134" end_char="3139">events</TOKEN>
<TOKEN id="token-23-25" pos="word" morph="none" start_char="3141" end_char="3143">and</TOKEN>
<TOKEN id="token-23-26" pos="punct" morph="none" start_char="3144" end_char="3144">,</TOKEN>
<TOKEN id="token-23-27" pos="word" morph="none" start_char="3146" end_char="3147">in</TOKEN>
<TOKEN id="token-23-28" pos="word" morph="none" start_char="3149" end_char="3152">some</TOKEN>
<TOKEN id="token-23-29" pos="word" morph="none" start_char="3154" end_char="3158">cases</TOKEN>
<TOKEN id="token-23-30" pos="punct" morph="none" start_char="3159" end_char="3159">,</TOKEN>
<TOKEN id="token-23-31" pos="word" morph="none" start_char="3161" end_char="3164">wide</TOKEN>
<TOKEN id="token-23-32" pos="word" morph="none" start_char="3166" end_char="3175">confidence</TOKEN>
<TOKEN id="token-23-33" pos="word" morph="none" start_char="3177" end_char="3185">intervals</TOKEN>
<TOKEN id="token-23-34" pos="punct" morph="none" start_char="3187" end_char="3187">(</TOKEN>
<TOKEN id="token-23-35" pos="word" morph="none" start_char="3188" end_char="3190">CIs</TOKEN>
<TOKEN id="token-23-36" pos="punct" morph="none" start_char="3191" end_char="3191">)</TOKEN>
<TOKEN id="token-23-37" pos="word" morph="none" start_char="3193" end_char="3194">in</TOKEN>
<TOKEN id="token-23-38" pos="word" morph="none" start_char="3196" end_char="3201">pooled</TOKEN>
<TOKEN id="token-23-39" pos="word" morph="none" start_char="3203" end_char="3211">estimates</TOKEN>
<TOKEN id="token-23-40" pos="punct" morph="none" start_char="3212" end_char="3212">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="3215" end_char="3215">
<ORIGINAL_TEXT>"</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="punct" morph="none" start_char="3215" end_char="3215">"</TOKEN>
</SEG>
<SEG id="segment-25" start_char="3219" end_char="3386">
<ORIGINAL_TEXT>The guideline also stated that "further high-quality clinical trials examining this drug would be essential before any recommendation for use as part of clinical care".</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="3219" end_char="3221">The</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="3223" end_char="3231">guideline</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="3233" end_char="3236">also</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="3238" end_char="3243">stated</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="3245" end_char="3248">that</TOKEN>
<TOKEN id="token-25-5" pos="punct" morph="none" start_char="3250" end_char="3250">"</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="3251" end_char="3257">further</TOKEN>
<TOKEN id="token-25-7" pos="unknown" morph="none" start_char="3259" end_char="3270">high-quality</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="3272" end_char="3279">clinical</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="3281" end_char="3286">trials</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="3288" end_char="3296">examining</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="3298" end_char="3301">this</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="3303" end_char="3306">drug</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="3308" end_char="3312">would</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="3314" end_char="3315">be</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="3317" end_char="3325">essential</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="3327" end_char="3332">before</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="3334" end_char="3336">any</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="3338" end_char="3351">recommendation</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="3353" end_char="3355">for</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="3357" end_char="3359">use</TOKEN>
<TOKEN id="token-25-21" pos="word" morph="none" start_char="3361" end_char="3362">as</TOKEN>
<TOKEN id="token-25-22" pos="word" morph="none" start_char="3364" end_char="3367">part</TOKEN>
<TOKEN id="token-25-23" pos="word" morph="none" start_char="3369" end_char="3370">of</TOKEN>
<TOKEN id="token-25-24" pos="word" morph="none" start_char="3372" end_char="3379">clinical</TOKEN>
<TOKEN id="token-25-25" pos="word" morph="none" start_char="3381" end_char="3384">care</TOKEN>
<TOKEN id="token-25-26" pos="punct" morph="none" start_char="3385" end_char="3386">".</TOKEN>
</SEG>
<SEG id="segment-26" start_char="3389" end_char="3518">
<ORIGINAL_TEXT>Likewise, the U.S. National Institutes of Health evaluated multiple clinical trials, some of which are listed here, and concluded:</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="3389" end_char="3396">Likewise</TOKEN>
<TOKEN id="token-26-1" pos="punct" morph="none" start_char="3397" end_char="3397">,</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="3399" end_char="3401">the</TOKEN>
<TOKEN id="token-26-3" pos="unknown" morph="none" start_char="3403" end_char="3405">U.S</TOKEN>
<TOKEN id="token-26-4" pos="punct" morph="none" start_char="3406" end_char="3406">.</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="3408" end_char="3415">National</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="3417" end_char="3426">Institutes</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="3428" end_char="3429">of</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="3431" end_char="3436">Health</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="3438" end_char="3446">evaluated</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="3448" end_char="3455">multiple</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="3457" end_char="3464">clinical</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="3466" end_char="3471">trials</TOKEN>
<TOKEN id="token-26-13" pos="punct" morph="none" start_char="3472" end_char="3472">,</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="3474" end_char="3477">some</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="3479" end_char="3480">of</TOKEN>
<TOKEN id="token-26-16" pos="word" morph="none" start_char="3482" end_char="3486">which</TOKEN>
<TOKEN id="token-26-17" pos="word" morph="none" start_char="3488" end_char="3490">are</TOKEN>
<TOKEN id="token-26-18" pos="word" morph="none" start_char="3492" end_char="3497">listed</TOKEN>
<TOKEN id="token-26-19" pos="word" morph="none" start_char="3499" end_char="3502">here</TOKEN>
<TOKEN id="token-26-20" pos="punct" morph="none" start_char="3503" end_char="3503">,</TOKEN>
<TOKEN id="token-26-21" pos="word" morph="none" start_char="3505" end_char="3507">and</TOKEN>
<TOKEN id="token-26-22" pos="word" morph="none" start_char="3509" end_char="3517">concluded</TOKEN>
<TOKEN id="token-26-23" pos="punct" morph="none" start_char="3518" end_char="3518">:</TOKEN>
</SEG>
<SEG id="segment-27" start_char="3521" end_char="3650">
<ORIGINAL_TEXT>"There are insufficient data for the Panel to recommend either for or against the use of ivermectin for the treatment of COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="punct" morph="none" start_char="3521" end_char="3521">"</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="3522" end_char="3526">There</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="3528" end_char="3530">are</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="3532" end_char="3543">insufficient</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="3545" end_char="3548">data</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="3550" end_char="3552">for</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="3554" end_char="3556">the</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="3558" end_char="3562">Panel</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="3564" end_char="3565">to</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="3567" end_char="3575">recommend</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="3577" end_char="3582">either</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="3584" end_char="3586">for</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="3588" end_char="3589">or</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="3591" end_char="3597">against</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="3599" end_char="3601">the</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="3603" end_char="3605">use</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="3607" end_char="3608">of</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="3610" end_char="3619">ivermectin</TOKEN>
<TOKEN id="token-27-18" pos="word" morph="none" start_char="3621" end_char="3623">for</TOKEN>
<TOKEN id="token-27-19" pos="word" morph="none" start_char="3625" end_char="3627">the</TOKEN>
<TOKEN id="token-27-20" pos="word" morph="none" start_char="3629" end_char="3637">treatment</TOKEN>
<TOKEN id="token-27-21" pos="word" morph="none" start_char="3639" end_char="3640">of</TOKEN>
<TOKEN id="token-27-22" pos="unknown" morph="none" start_char="3642" end_char="3649">COVID-19</TOKEN>
<TOKEN id="token-27-23" pos="punct" morph="none" start_char="3650" end_char="3650">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3652" end_char="3851">
<ORIGINAL_TEXT>Results from adequately powered, well-designed, and well-conducted clinical trials are needed to provide more specific, evidence-based guidance on the role of ivermectin in the treatment of COVID-19."</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="3652" end_char="3658">Results</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="3660" end_char="3663">from</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="3665" end_char="3674">adequately</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="3676" end_char="3682">powered</TOKEN>
<TOKEN id="token-28-4" pos="punct" morph="none" start_char="3683" end_char="3683">,</TOKEN>
<TOKEN id="token-28-5" pos="unknown" morph="none" start_char="3685" end_char="3697">well-designed</TOKEN>
<TOKEN id="token-28-6" pos="punct" morph="none" start_char="3698" end_char="3698">,</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="3700" end_char="3702">and</TOKEN>
<TOKEN id="token-28-8" pos="unknown" morph="none" start_char="3704" end_char="3717">well-conducted</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="3719" end_char="3726">clinical</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="3728" end_char="3733">trials</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="3735" end_char="3737">are</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="3739" end_char="3744">needed</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="3746" end_char="3747">to</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="3749" end_char="3755">provide</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="3757" end_char="3760">more</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="3762" end_char="3769">specific</TOKEN>
<TOKEN id="token-28-17" pos="punct" morph="none" start_char="3770" end_char="3770">,</TOKEN>
<TOKEN id="token-28-18" pos="unknown" morph="none" start_char="3772" end_char="3785">evidence-based</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="3787" end_char="3794">guidance</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="3796" end_char="3797">on</TOKEN>
<TOKEN id="token-28-21" pos="word" morph="none" start_char="3799" end_char="3801">the</TOKEN>
<TOKEN id="token-28-22" pos="word" morph="none" start_char="3803" end_char="3806">role</TOKEN>
<TOKEN id="token-28-23" pos="word" morph="none" start_char="3808" end_char="3809">of</TOKEN>
<TOKEN id="token-28-24" pos="word" morph="none" start_char="3811" end_char="3820">ivermectin</TOKEN>
<TOKEN id="token-28-25" pos="word" morph="none" start_char="3822" end_char="3823">in</TOKEN>
<TOKEN id="token-28-26" pos="word" morph="none" start_char="3825" end_char="3827">the</TOKEN>
<TOKEN id="token-28-27" pos="word" morph="none" start_char="3829" end_char="3837">treatment</TOKEN>
<TOKEN id="token-28-28" pos="word" morph="none" start_char="3839" end_char="3840">of</TOKEN>
<TOKEN id="token-28-29" pos="unknown" morph="none" start_char="3842" end_char="3849">COVID-19</TOKEN>
<TOKEN id="token-28-30" pos="punct" morph="none" start_char="3850" end_char="3851">."</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3855" end_char="3979">
<ORIGINAL_TEXT>Overall, clinical trials have thus far failed to provide reliable evidence supporting the use of ivermectin against COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="3855" end_char="3861">Overall</TOKEN>
<TOKEN id="token-29-1" pos="punct" morph="none" start_char="3862" end_char="3862">,</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="3864" end_char="3871">clinical</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="3873" end_char="3878">trials</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="3880" end_char="3883">have</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="3885" end_char="3888">thus</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="3890" end_char="3892">far</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="3894" end_char="3899">failed</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="3901" end_char="3902">to</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="3904" end_char="3910">provide</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="3912" end_char="3919">reliable</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="3921" end_char="3928">evidence</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="3930" end_char="3939">supporting</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="3941" end_char="3943">the</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="3945" end_char="3947">use</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="3949" end_char="3950">of</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="3952" end_char="3961">ivermectin</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="3963" end_char="3969">against</TOKEN>
<TOKEN id="token-29-18" pos="unknown" morph="none" start_char="3971" end_char="3978">COVID-19</TOKEN>
<TOKEN id="token-29-19" pos="punct" morph="none" start_char="3979" end_char="3979">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3981" end_char="4071">
<ORIGINAL_TEXT>This is because the trials varied in terms of quality and many were at a high risk of bias.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="3981" end_char="3984">This</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="3986" end_char="3987">is</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="3989" end_char="3995">because</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="3997" end_char="3999">the</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="4001" end_char="4006">trials</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="4008" end_char="4013">varied</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="4015" end_char="4016">in</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="4018" end_char="4022">terms</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="4024" end_char="4025">of</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="4027" end_char="4033">quality</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="4035" end_char="4037">and</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="4039" end_char="4042">many</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="4044" end_char="4047">were</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="4049" end_char="4050">at</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="4052" end_char="4052">a</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="4054" end_char="4057">high</TOKEN>
<TOKEN id="token-30-16" pos="word" morph="none" start_char="4059" end_char="4062">risk</TOKEN>
<TOKEN id="token-30-17" pos="word" morph="none" start_char="4064" end_char="4065">of</TOKEN>
<TOKEN id="token-30-18" pos="word" morph="none" start_char="4067" end_char="4070">bias</TOKEN>
<TOKEN id="token-30-19" pos="punct" morph="none" start_char="4071" end_char="4071">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="4073" end_char="4175">
<ORIGINAL_TEXT>These limitations are the result of several factors, such as the trial design and the study population.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="4073" end_char="4077">These</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="4079" end_char="4089">limitations</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="4091" end_char="4093">are</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="4095" end_char="4097">the</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="4099" end_char="4104">result</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="4106" end_char="4107">of</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="4109" end_char="4115">several</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="4117" end_char="4123">factors</TOKEN>
<TOKEN id="token-31-8" pos="punct" morph="none" start_char="4124" end_char="4124">,</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="4126" end_char="4129">such</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="4131" end_char="4132">as</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="4134" end_char="4136">the</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="4138" end_char="4142">trial</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="4144" end_char="4149">design</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="4151" end_char="4153">and</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="4155" end_char="4157">the</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="4159" end_char="4163">study</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="4165" end_char="4174">population</TOKEN>
<TOKEN id="token-31-18" pos="punct" morph="none" start_char="4175" end_char="4175">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="4177" end_char="4334">
<ORIGINAL_TEXT>And as scientists pointed out in this Health Feedback review, more rigorously designed studies found that ivermectin provided no benefit to COVID-19 patients.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="4177" end_char="4179">And</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="4181" end_char="4182">as</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="4184" end_char="4193">scientists</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="4195" end_char="4201">pointed</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="4203" end_char="4205">out</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="4207" end_char="4208">in</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="4210" end_char="4213">this</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="4215" end_char="4220">Health</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="4222" end_char="4229">Feedback</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="4231" end_char="4236">review</TOKEN>
<TOKEN id="token-32-10" pos="punct" morph="none" start_char="4237" end_char="4237">,</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="4239" end_char="4242">more</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="4244" end_char="4253">rigorously</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="4255" end_char="4262">designed</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="4264" end_char="4270">studies</TOKEN>
<TOKEN id="token-32-15" pos="word" morph="none" start_char="4272" end_char="4276">found</TOKEN>
<TOKEN id="token-32-16" pos="word" morph="none" start_char="4278" end_char="4281">that</TOKEN>
<TOKEN id="token-32-17" pos="word" morph="none" start_char="4283" end_char="4292">ivermectin</TOKEN>
<TOKEN id="token-32-18" pos="word" morph="none" start_char="4294" end_char="4301">provided</TOKEN>
<TOKEN id="token-32-19" pos="word" morph="none" start_char="4303" end_char="4304">no</TOKEN>
<TOKEN id="token-32-20" pos="word" morph="none" start_char="4306" end_char="4312">benefit</TOKEN>
<TOKEN id="token-32-21" pos="word" morph="none" start_char="4314" end_char="4315">to</TOKEN>
<TOKEN id="token-32-22" pos="unknown" morph="none" start_char="4317" end_char="4324">COVID-19</TOKEN>
<TOKEN id="token-32-23" pos="word" morph="none" start_char="4326" end_char="4333">patients</TOKEN>
<TOKEN id="token-32-24" pos="punct" morph="none" start_char="4334" end_char="4334">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="4337" end_char="4425">
<ORIGINAL_TEXT>Kelly cited physician Tess Lawrie when claiming that 51 studies showed ivermectin worked.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="4337" end_char="4341">Kelly</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="4343" end_char="4347">cited</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="4349" end_char="4357">physician</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="4359" end_char="4362">Tess</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="4364" end_char="4369">Lawrie</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="4371" end_char="4374">when</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="4376" end_char="4383">claiming</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="4385" end_char="4388">that</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="4390" end_char="4391">51</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="4393" end_char="4399">studies</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="4401" end_char="4406">showed</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="4408" end_char="4417">ivermectin</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="4419" end_char="4424">worked</TOKEN>
<TOKEN id="token-33-13" pos="punct" morph="none" start_char="4425" end_char="4425">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="4427" end_char="4642">
<ORIGINAL_TEXT>While Lawrie and her colleagues published a meta-analysis of ivermectin studies, which itself was rife with problems as detailed in this Health Feedback review, that meta-analysis only examined fewer than 30 studies.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="4427" end_char="4431">While</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="4433" end_char="4438">Lawrie</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="4440" end_char="4442">and</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="4444" end_char="4446">her</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="4448" end_char="4457">colleagues</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="4459" end_char="4467">published</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="4469" end_char="4469">a</TOKEN>
<TOKEN id="token-34-7" pos="unknown" morph="none" start_char="4471" end_char="4483">meta-analysis</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="4485" end_char="4486">of</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="4488" end_char="4497">ivermectin</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="4499" end_char="4505">studies</TOKEN>
<TOKEN id="token-34-11" pos="punct" morph="none" start_char="4506" end_char="4506">,</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="4508" end_char="4512">which</TOKEN>
<TOKEN id="token-34-13" pos="word" morph="none" start_char="4514" end_char="4519">itself</TOKEN>
<TOKEN id="token-34-14" pos="word" morph="none" start_char="4521" end_char="4523">was</TOKEN>
<TOKEN id="token-34-15" pos="word" morph="none" start_char="4525" end_char="4528">rife</TOKEN>
<TOKEN id="token-34-16" pos="word" morph="none" start_char="4530" end_char="4533">with</TOKEN>
<TOKEN id="token-34-17" pos="word" morph="none" start_char="4535" end_char="4542">problems</TOKEN>
<TOKEN id="token-34-18" pos="word" morph="none" start_char="4544" end_char="4545">as</TOKEN>
<TOKEN id="token-34-19" pos="word" morph="none" start_char="4547" end_char="4554">detailed</TOKEN>
<TOKEN id="token-34-20" pos="word" morph="none" start_char="4556" end_char="4557">in</TOKEN>
<TOKEN id="token-34-21" pos="word" morph="none" start_char="4559" end_char="4562">this</TOKEN>
<TOKEN id="token-34-22" pos="word" morph="none" start_char="4564" end_char="4569">Health</TOKEN>
<TOKEN id="token-34-23" pos="word" morph="none" start_char="4571" end_char="4578">Feedback</TOKEN>
<TOKEN id="token-34-24" pos="word" morph="none" start_char="4580" end_char="4585">review</TOKEN>
<TOKEN id="token-34-25" pos="punct" morph="none" start_char="4586" end_char="4586">,</TOKEN>
<TOKEN id="token-34-26" pos="word" morph="none" start_char="4588" end_char="4591">that</TOKEN>
<TOKEN id="token-34-27" pos="unknown" morph="none" start_char="4593" end_char="4605">meta-analysis</TOKEN>
<TOKEN id="token-34-28" pos="word" morph="none" start_char="4607" end_char="4610">only</TOKEN>
<TOKEN id="token-34-29" pos="word" morph="none" start_char="4612" end_char="4619">examined</TOKEN>
<TOKEN id="token-34-30" pos="word" morph="none" start_char="4621" end_char="4625">fewer</TOKEN>
<TOKEN id="token-34-31" pos="word" morph="none" start_char="4627" end_char="4630">than</TOKEN>
<TOKEN id="token-34-32" pos="word" morph="none" start_char="4632" end_char="4633">30</TOKEN>
<TOKEN id="token-34-33" pos="word" morph="none" start_char="4635" end_char="4641">studies</TOKEN>
<TOKEN id="token-34-34" pos="punct" morph="none" start_char="4642" end_char="4642">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="4644" end_char="4838">
<ORIGINAL_TEXT>Kelly may have instead been referencing the website run by a group named CovidAnalysis, which claimed that there have been 52 trials for ivermectin to date, a figure much more similar to Kelly’s.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="4644" end_char="4648">Kelly</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="4650" end_char="4652">may</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="4654" end_char="4657">have</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="4659" end_char="4665">instead</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="4667" end_char="4670">been</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="4672" end_char="4682">referencing</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="4684" end_char="4686">the</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="4688" end_char="4694">website</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="4696" end_char="4698">run</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="4700" end_char="4701">by</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="4703" end_char="4703">a</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="4705" end_char="4709">group</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="4711" end_char="4715">named</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="4717" end_char="4729">CovidAnalysis</TOKEN>
<TOKEN id="token-35-14" pos="punct" morph="none" start_char="4730" end_char="4730">,</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="4732" end_char="4736">which</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="4738" end_char="4744">claimed</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="4746" end_char="4749">that</TOKEN>
<TOKEN id="token-35-18" pos="word" morph="none" start_char="4751" end_char="4755">there</TOKEN>
<TOKEN id="token-35-19" pos="word" morph="none" start_char="4757" end_char="4760">have</TOKEN>
<TOKEN id="token-35-20" pos="word" morph="none" start_char="4762" end_char="4765">been</TOKEN>
<TOKEN id="token-35-21" pos="word" morph="none" start_char="4767" end_char="4768">52</TOKEN>
<TOKEN id="token-35-22" pos="word" morph="none" start_char="4770" end_char="4775">trials</TOKEN>
<TOKEN id="token-35-23" pos="word" morph="none" start_char="4777" end_char="4779">for</TOKEN>
<TOKEN id="token-35-24" pos="word" morph="none" start_char="4781" end_char="4790">ivermectin</TOKEN>
<TOKEN id="token-35-25" pos="word" morph="none" start_char="4792" end_char="4793">to</TOKEN>
<TOKEN id="token-35-26" pos="word" morph="none" start_char="4795" end_char="4798">date</TOKEN>
<TOKEN id="token-35-27" pos="punct" morph="none" start_char="4799" end_char="4799">,</TOKEN>
<TOKEN id="token-35-28" pos="word" morph="none" start_char="4801" end_char="4801">a</TOKEN>
<TOKEN id="token-35-29" pos="word" morph="none" start_char="4803" end_char="4808">figure</TOKEN>
<TOKEN id="token-35-30" pos="word" morph="none" start_char="4810" end_char="4813">much</TOKEN>
<TOKEN id="token-35-31" pos="word" morph="none" start_char="4815" end_char="4818">more</TOKEN>
<TOKEN id="token-35-32" pos="word" morph="none" start_char="4820" end_char="4826">similar</TOKEN>
<TOKEN id="token-35-33" pos="word" morph="none" start_char="4828" end_char="4829">to</TOKEN>
<TOKEN id="token-35-34" pos="word" morph="none" start_char="4831" end_char="4837">Kelly’s</TOKEN>
<TOKEN id="token-35-35" pos="punct" morph="none" start_char="4838" end_char="4838">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="4841" end_char="4984">
<ORIGINAL_TEXT>CovidAnalysis conducted a meta-analysis of ivermectin studies and claimed that ivermectin works to treat and prevent (prophylaxis) for COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="4841" end_char="4853">CovidAnalysis</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="4855" end_char="4863">conducted</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="4865" end_char="4865">a</TOKEN>
<TOKEN id="token-36-3" pos="unknown" morph="none" start_char="4867" end_char="4879">meta-analysis</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="4881" end_char="4882">of</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="4884" end_char="4893">ivermectin</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="4895" end_char="4901">studies</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="4903" end_char="4905">and</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="4907" end_char="4913">claimed</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="4915" end_char="4918">that</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="4920" end_char="4929">ivermectin</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="4931" end_char="4935">works</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="4937" end_char="4938">to</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="4940" end_char="4944">treat</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="4946" end_char="4948">and</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="4950" end_char="4956">prevent</TOKEN>
<TOKEN id="token-36-16" pos="punct" morph="none" start_char="4958" end_char="4958">(</TOKEN>
<TOKEN id="token-36-17" pos="word" morph="none" start_char="4959" end_char="4969">prophylaxis</TOKEN>
<TOKEN id="token-36-18" pos="punct" morph="none" start_char="4970" end_char="4970">)</TOKEN>
<TOKEN id="token-36-19" pos="word" morph="none" start_char="4972" end_char="4974">for</TOKEN>
<TOKEN id="token-36-20" pos="unknown" morph="none" start_char="4976" end_char="4983">COVID-19</TOKEN>
<TOKEN id="token-36-21" pos="punct" morph="none" start_char="4984" end_char="4984">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="4986" end_char="5055">
<ORIGINAL_TEXT>However, its own analysis indicates that its conclusions aren’t sound.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="4986" end_char="4992">However</TOKEN>
<TOKEN id="token-37-1" pos="punct" morph="none" start_char="4993" end_char="4993">,</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="4995" end_char="4997">its</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="4999" end_char="5001">own</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="5003" end_char="5010">analysis</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="5012" end_char="5020">indicates</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="5022" end_char="5025">that</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="5027" end_char="5029">its</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="5031" end_char="5041">conclusions</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="5043" end_char="5048">aren’t</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="5050" end_char="5054">sound</TOKEN>
<TOKEN id="token-37-11" pos="punct" morph="none" start_char="5055" end_char="5055">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="5058" end_char="5136">
<ORIGINAL_TEXT>For example, one important measure to note in a meta-analysis is heterogeneity.</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="5058" end_char="5060">For</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="5062" end_char="5068">example</TOKEN>
<TOKEN id="token-38-2" pos="punct" morph="none" start_char="5069" end_char="5069">,</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="5071" end_char="5073">one</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="5075" end_char="5083">important</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="5085" end_char="5091">measure</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="5093" end_char="5094">to</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="5096" end_char="5099">note</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="5101" end_char="5102">in</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="5104" end_char="5104">a</TOKEN>
<TOKEN id="token-38-10" pos="unknown" morph="none" start_char="5106" end_char="5118">meta-analysis</TOKEN>
<TOKEN id="token-38-11" pos="word" morph="none" start_char="5120" end_char="5121">is</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="5123" end_char="5135">heterogeneity</TOKEN>
<TOKEN id="token-38-13" pos="punct" morph="none" start_char="5136" end_char="5136">.</TOKEN>
</SEG>
<SEG id="segment-39" start_char="5138" end_char="5244">
<ORIGINAL_TEXT>This measure tells us whether the results of the studies in a meta-analysis are consistent with each other.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="5138" end_char="5141">This</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="5143" end_char="5149">measure</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="5151" end_char="5155">tells</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="5157" end_char="5158">us</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="5160" end_char="5166">whether</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="5168" end_char="5170">the</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="5172" end_char="5178">results</TOKEN>
<TOKEN id="token-39-7" pos="word" morph="none" start_char="5180" end_char="5181">of</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="5183" end_char="5185">the</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="5187" end_char="5193">studies</TOKEN>
<TOKEN id="token-39-10" pos="word" morph="none" start_char="5195" end_char="5196">in</TOKEN>
<TOKEN id="token-39-11" pos="word" morph="none" start_char="5198" end_char="5198">a</TOKEN>
<TOKEN id="token-39-12" pos="unknown" morph="none" start_char="5200" end_char="5212">meta-analysis</TOKEN>
<TOKEN id="token-39-13" pos="word" morph="none" start_char="5214" end_char="5216">are</TOKEN>
<TOKEN id="token-39-14" pos="word" morph="none" start_char="5218" end_char="5227">consistent</TOKEN>
<TOKEN id="token-39-15" pos="word" morph="none" start_char="5229" end_char="5232">with</TOKEN>
<TOKEN id="token-39-16" pos="word" morph="none" start_char="5234" end_char="5237">each</TOKEN>
<TOKEN id="token-39-17" pos="word" morph="none" start_char="5239" end_char="5243">other</TOKEN>
<TOKEN id="token-39-18" pos="punct" morph="none" start_char="5244" end_char="5244">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="5246" end_char="5379">
<ORIGINAL_TEXT>Variability in results can arise from different factors, such as the study population and the way outcomes in the study were measured.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="5246" end_char="5256">Variability</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="5258" end_char="5259">in</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="5261" end_char="5267">results</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="5269" end_char="5271">can</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="5273" end_char="5277">arise</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="5279" end_char="5282">from</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="5284" end_char="5292">different</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="5294" end_char="5300">factors</TOKEN>
<TOKEN id="token-40-8" pos="punct" morph="none" start_char="5301" end_char="5301">,</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="5303" end_char="5306">such</TOKEN>
<TOKEN id="token-40-10" pos="word" morph="none" start_char="5308" end_char="5309">as</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="5311" end_char="5313">the</TOKEN>
<TOKEN id="token-40-12" pos="word" morph="none" start_char="5315" end_char="5319">study</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="5321" end_char="5330">population</TOKEN>
<TOKEN id="token-40-14" pos="word" morph="none" start_char="5332" end_char="5334">and</TOKEN>
<TOKEN id="token-40-15" pos="word" morph="none" start_char="5336" end_char="5338">the</TOKEN>
<TOKEN id="token-40-16" pos="word" morph="none" start_char="5340" end_char="5342">way</TOKEN>
<TOKEN id="token-40-17" pos="word" morph="none" start_char="5344" end_char="5351">outcomes</TOKEN>
<TOKEN id="token-40-18" pos="word" morph="none" start_char="5353" end_char="5354">in</TOKEN>
<TOKEN id="token-40-19" pos="word" morph="none" start_char="5356" end_char="5358">the</TOKEN>
<TOKEN id="token-40-20" pos="word" morph="none" start_char="5360" end_char="5364">study</TOKEN>
<TOKEN id="token-40-21" pos="word" morph="none" start_char="5366" end_char="5369">were</TOKEN>
<TOKEN id="token-40-22" pos="word" morph="none" start_char="5371" end_char="5378">measured</TOKEN>
<TOKEN id="token-40-23" pos="punct" morph="none" start_char="5379" end_char="5379">.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="5381" end_char="5422">
<ORIGINAL_TEXT>A common way to measure heterogeneity is I</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="5381" end_char="5381">A</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="5383" end_char="5388">common</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="5390" end_char="5392">way</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="5394" end_char="5395">to</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="5397" end_char="5403">measure</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="5405" end_char="5417">heterogeneity</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="5419" end_char="5420">is</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="5422" end_char="5422">I</TOKEN>
</SEG>
<SEG id="segment-42" start_char="5425" end_char="5425">
<ORIGINAL_TEXT>2</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="5425" end_char="5425">2</TOKEN>
</SEG>
<SEG id="segment-43" start_char="5428" end_char="5428">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="punct" morph="none" start_char="5428" end_char="5428">.</TOKEN>
</SEG>
<SEG id="segment-44" start_char="5431" end_char="5750">
<ORIGINAL_TEXT>The Cochrane Network, a not-for-profit organization which conducts "systematic reviews and other synthesized research evidence", stated that "Meta-analysis should only be considered when a group of studies is sufficiently homogeneous in terms of participants, interventions and outcomes to provide a meaningful summary".</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="5431" end_char="5433">The</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="5435" end_char="5442">Cochrane</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="5444" end_char="5450">Network</TOKEN>
<TOKEN id="token-44-3" pos="punct" morph="none" start_char="5451" end_char="5451">,</TOKEN>
<TOKEN id="token-44-4" pos="word" morph="none" start_char="5453" end_char="5453">a</TOKEN>
<TOKEN id="token-44-5" pos="unknown" morph="none" start_char="5455" end_char="5468">not-for-profit</TOKEN>
<TOKEN id="token-44-6" pos="word" morph="none" start_char="5470" end_char="5481">organization</TOKEN>
<TOKEN id="token-44-7" pos="word" morph="none" start_char="5483" end_char="5487">which</TOKEN>
<TOKEN id="token-44-8" pos="word" morph="none" start_char="5489" end_char="5496">conducts</TOKEN>
<TOKEN id="token-44-9" pos="punct" morph="none" start_char="5498" end_char="5498">"</TOKEN>
<TOKEN id="token-44-10" pos="word" morph="none" start_char="5499" end_char="5508">systematic</TOKEN>
<TOKEN id="token-44-11" pos="word" morph="none" start_char="5510" end_char="5516">reviews</TOKEN>
<TOKEN id="token-44-12" pos="word" morph="none" start_char="5518" end_char="5520">and</TOKEN>
<TOKEN id="token-44-13" pos="word" morph="none" start_char="5522" end_char="5526">other</TOKEN>
<TOKEN id="token-44-14" pos="word" morph="none" start_char="5528" end_char="5538">synthesized</TOKEN>
<TOKEN id="token-44-15" pos="word" morph="none" start_char="5540" end_char="5547">research</TOKEN>
<TOKEN id="token-44-16" pos="word" morph="none" start_char="5549" end_char="5556">evidence</TOKEN>
<TOKEN id="token-44-17" pos="punct" morph="none" start_char="5557" end_char="5558">",</TOKEN>
<TOKEN id="token-44-18" pos="word" morph="none" start_char="5560" end_char="5565">stated</TOKEN>
<TOKEN id="token-44-19" pos="word" morph="none" start_char="5567" end_char="5570">that</TOKEN>
<TOKEN id="token-44-20" pos="punct" morph="none" start_char="5572" end_char="5572">"</TOKEN>
<TOKEN id="token-44-21" pos="unknown" morph="none" start_char="5573" end_char="5585">Meta-analysis</TOKEN>
<TOKEN id="token-44-22" pos="word" morph="none" start_char="5587" end_char="5592">should</TOKEN>
<TOKEN id="token-44-23" pos="word" morph="none" start_char="5594" end_char="5597">only</TOKEN>
<TOKEN id="token-44-24" pos="word" morph="none" start_char="5599" end_char="5600">be</TOKEN>
<TOKEN id="token-44-25" pos="word" morph="none" start_char="5602" end_char="5611">considered</TOKEN>
<TOKEN id="token-44-26" pos="word" morph="none" start_char="5613" end_char="5616">when</TOKEN>
<TOKEN id="token-44-27" pos="word" morph="none" start_char="5618" end_char="5618">a</TOKEN>
<TOKEN id="token-44-28" pos="word" morph="none" start_char="5620" end_char="5624">group</TOKEN>
<TOKEN id="token-44-29" pos="word" morph="none" start_char="5626" end_char="5627">of</TOKEN>
<TOKEN id="token-44-30" pos="word" morph="none" start_char="5629" end_char="5635">studies</TOKEN>
<TOKEN id="token-44-31" pos="word" morph="none" start_char="5637" end_char="5638">is</TOKEN>
<TOKEN id="token-44-32" pos="word" morph="none" start_char="5640" end_char="5651">sufficiently</TOKEN>
<TOKEN id="token-44-33" pos="word" morph="none" start_char="5653" end_char="5663">homogeneous</TOKEN>
<TOKEN id="token-44-34" pos="word" morph="none" start_char="5665" end_char="5666">in</TOKEN>
<TOKEN id="token-44-35" pos="word" morph="none" start_char="5668" end_char="5672">terms</TOKEN>
<TOKEN id="token-44-36" pos="word" morph="none" start_char="5674" end_char="5675">of</TOKEN>
<TOKEN id="token-44-37" pos="word" morph="none" start_char="5677" end_char="5688">participants</TOKEN>
<TOKEN id="token-44-38" pos="punct" morph="none" start_char="5689" end_char="5689">,</TOKEN>
<TOKEN id="token-44-39" pos="word" morph="none" start_char="5691" end_char="5703">interventions</TOKEN>
<TOKEN id="token-44-40" pos="word" morph="none" start_char="5705" end_char="5707">and</TOKEN>
<TOKEN id="token-44-41" pos="word" morph="none" start_char="5709" end_char="5716">outcomes</TOKEN>
<TOKEN id="token-44-42" pos="word" morph="none" start_char="5718" end_char="5719">to</TOKEN>
<TOKEN id="token-44-43" pos="word" morph="none" start_char="5721" end_char="5727">provide</TOKEN>
<TOKEN id="token-44-44" pos="word" morph="none" start_char="5729" end_char="5729">a</TOKEN>
<TOKEN id="token-44-45" pos="word" morph="none" start_char="5731" end_char="5740">meaningful</TOKEN>
<TOKEN id="token-44-46" pos="word" morph="none" start_char="5742" end_char="5748">summary</TOKEN>
<TOKEN id="token-44-47" pos="punct" morph="none" start_char="5749" end_char="5750">".</TOKEN>
</SEG>
<SEG id="segment-45" start_char="5752" end_char="5806">
<ORIGINAL_TEXT>It also provided a "rough guide to interpretation [of I</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="5752" end_char="5753">It</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="5755" end_char="5758">also</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="5760" end_char="5767">provided</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="5769" end_char="5769">a</TOKEN>
<TOKEN id="token-45-4" pos="punct" morph="none" start_char="5771" end_char="5771">"</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="5772" end_char="5776">rough</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="5778" end_char="5782">guide</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="5784" end_char="5785">to</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="5787" end_char="5800">interpretation</TOKEN>
<TOKEN id="token-45-9" pos="punct" morph="none" start_char="5802" end_char="5802">[</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="5803" end_char="5804">of</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="5806" end_char="5806">I</TOKEN>
</SEG>
<SEG id="segment-46" start_char="5809" end_char="5809">
<ORIGINAL_TEXT>2</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="5809" end_char="5809">2</TOKEN>
</SEG>
<SEG id="segment-47" start_char="5812" end_char="5867">
<ORIGINAL_TEXT>] in the context of meta-analyses of randomized trials":</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="punct" morph="none" start_char="5812" end_char="5812">]</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="5814" end_char="5815">in</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="5817" end_char="5819">the</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="5821" end_char="5827">context</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="5829" end_char="5830">of</TOKEN>
<TOKEN id="token-47-5" pos="unknown" morph="none" start_char="5832" end_char="5844">meta-analyses</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="5846" end_char="5847">of</TOKEN>
<TOKEN id="token-47-7" pos="word" morph="none" start_char="5849" end_char="5858">randomized</TOKEN>
<TOKEN id="token-47-8" pos="word" morph="none" start_char="5860" end_char="5865">trials</TOKEN>
<TOKEN id="token-47-9" pos="punct" morph="none" start_char="5866" end_char="5867">":</TOKEN>
</SEG>
<SEG id="segment-48" start_char="5870" end_char="5870">
<ORIGINAL_TEXT>"</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="punct" morph="none" start_char="5870" end_char="5870">"</TOKEN>
</SEG>
<SEG id="segment-49" start_char="5873" end_char="5906">
<ORIGINAL_TEXT>0% to 40%: might not be important;</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="5873" end_char="5873">0</TOKEN>
<TOKEN id="token-49-1" pos="punct" morph="none" start_char="5874" end_char="5874">%</TOKEN>
<TOKEN id="token-49-2" pos="word" morph="none" start_char="5876" end_char="5877">to</TOKEN>
<TOKEN id="token-49-3" pos="word" morph="none" start_char="5879" end_char="5880">40</TOKEN>
<TOKEN id="token-49-4" pos="punct" morph="none" start_char="5881" end_char="5882">%:</TOKEN>
<TOKEN id="token-49-5" pos="word" morph="none" start_char="5884" end_char="5888">might</TOKEN>
<TOKEN id="token-49-6" pos="word" morph="none" start_char="5890" end_char="5892">not</TOKEN>
<TOKEN id="token-49-7" pos="word" morph="none" start_char="5894" end_char="5895">be</TOKEN>
<TOKEN id="token-49-8" pos="word" morph="none" start_char="5897" end_char="5905">important</TOKEN>
<TOKEN id="token-49-9" pos="punct" morph="none" start_char="5906" end_char="5906">;</TOKEN>
</SEG>
<SEG id="segment-50" start_char="5910" end_char="5959">
<ORIGINAL_TEXT>30% to 60%: may represent moderate heterogeneity*;</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="5910" end_char="5911">30</TOKEN>
<TOKEN id="token-50-1" pos="punct" morph="none" start_char="5912" end_char="5912">%</TOKEN>
<TOKEN id="token-50-2" pos="word" morph="none" start_char="5914" end_char="5915">to</TOKEN>
<TOKEN id="token-50-3" pos="word" morph="none" start_char="5917" end_char="5918">60</TOKEN>
<TOKEN id="token-50-4" pos="punct" morph="none" start_char="5919" end_char="5920">%:</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="5922" end_char="5924">may</TOKEN>
<TOKEN id="token-50-6" pos="word" morph="none" start_char="5926" end_char="5934">represent</TOKEN>
<TOKEN id="token-50-7" pos="word" morph="none" start_char="5936" end_char="5943">moderate</TOKEN>
<TOKEN id="token-50-8" pos="word" morph="none" start_char="5945" end_char="5957">heterogeneity</TOKEN>
<TOKEN id="token-50-9" pos="punct" morph="none" start_char="5958" end_char="5959">*;</TOKEN>
</SEG>
<SEG id="segment-51" start_char="5963" end_char="6015">
<ORIGINAL_TEXT>50% to 90%: may represent substantial heterogeneity*;</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="word" morph="none" start_char="5963" end_char="5964">50</TOKEN>
<TOKEN id="token-51-1" pos="punct" morph="none" start_char="5965" end_char="5965">%</TOKEN>
<TOKEN id="token-51-2" pos="word" morph="none" start_char="5967" end_char="5968">to</TOKEN>
<TOKEN id="token-51-3" pos="word" morph="none" start_char="5970" end_char="5971">90</TOKEN>
<TOKEN id="token-51-4" pos="punct" morph="none" start_char="5972" end_char="5973">%:</TOKEN>
<TOKEN id="token-51-5" pos="word" morph="none" start_char="5975" end_char="5977">may</TOKEN>
<TOKEN id="token-51-6" pos="word" morph="none" start_char="5979" end_char="5987">represent</TOKEN>
<TOKEN id="token-51-7" pos="word" morph="none" start_char="5989" end_char="5999">substantial</TOKEN>
<TOKEN id="token-51-8" pos="word" morph="none" start_char="6001" end_char="6013">heterogeneity</TOKEN>
<TOKEN id="token-51-9" pos="punct" morph="none" start_char="6014" end_char="6015">*;</TOKEN>
</SEG>
<SEG id="segment-52" start_char="6019" end_char="6059">
<ORIGINAL_TEXT>75% to 100%: considerable heterogeneity*.</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="6019" end_char="6020">75</TOKEN>
<TOKEN id="token-52-1" pos="punct" morph="none" start_char="6021" end_char="6021">%</TOKEN>
<TOKEN id="token-52-2" pos="word" morph="none" start_char="6023" end_char="6024">to</TOKEN>
<TOKEN id="token-52-3" pos="word" morph="none" start_char="6026" end_char="6028">100</TOKEN>
<TOKEN id="token-52-4" pos="punct" morph="none" start_char="6029" end_char="6030">%:</TOKEN>
<TOKEN id="token-52-5" pos="word" morph="none" start_char="6032" end_char="6043">considerable</TOKEN>
<TOKEN id="token-52-6" pos="word" morph="none" start_char="6045" end_char="6057">heterogeneity</TOKEN>
<TOKEN id="token-52-7" pos="punct" morph="none" start_char="6058" end_char="6059">*.</TOKEN>
</SEG>
<SEG id="segment-53" start_char="6063" end_char="6104">
<ORIGINAL_TEXT>*The importance of the observed value of I</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="punct" morph="none" start_char="6063" end_char="6063">*</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="6064" end_char="6066">The</TOKEN>
<TOKEN id="token-53-2" pos="word" morph="none" start_char="6068" end_char="6077">importance</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="6079" end_char="6080">of</TOKEN>
<TOKEN id="token-53-4" pos="word" morph="none" start_char="6082" end_char="6084">the</TOKEN>
<TOKEN id="token-53-5" pos="word" morph="none" start_char="6086" end_char="6093">observed</TOKEN>
<TOKEN id="token-53-6" pos="word" morph="none" start_char="6095" end_char="6099">value</TOKEN>
<TOKEN id="token-53-7" pos="word" morph="none" start_char="6101" end_char="6102">of</TOKEN>
<TOKEN id="token-53-8" pos="word" morph="none" start_char="6104" end_char="6104">I</TOKEN>
</SEG>
<SEG id="segment-54" start_char="6107" end_char="6107">
<ORIGINAL_TEXT>2</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="word" morph="none" start_char="6107" end_char="6107">2</TOKEN>
</SEG>
<SEG id="segment-55" start_char="6110" end_char="6233">
<ORIGINAL_TEXT>depends on (1) magnitude and direction of effects, and (2) strength of evidence for heterogeneity (e.g. P value from the Chi</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="word" morph="none" start_char="6110" end_char="6116">depends</TOKEN>
<TOKEN id="token-55-1" pos="word" morph="none" start_char="6118" end_char="6119">on</TOKEN>
<TOKEN id="token-55-2" pos="punct" morph="none" start_char="6121" end_char="6121">(</TOKEN>
<TOKEN id="token-55-3" pos="word" morph="none" start_char="6122" end_char="6122">1</TOKEN>
<TOKEN id="token-55-4" pos="punct" morph="none" start_char="6123" end_char="6123">)</TOKEN>
<TOKEN id="token-55-5" pos="word" morph="none" start_char="6125" end_char="6133">magnitude</TOKEN>
<TOKEN id="token-55-6" pos="word" morph="none" start_char="6135" end_char="6137">and</TOKEN>
<TOKEN id="token-55-7" pos="word" morph="none" start_char="6139" end_char="6147">direction</TOKEN>
<TOKEN id="token-55-8" pos="word" morph="none" start_char="6149" end_char="6150">of</TOKEN>
<TOKEN id="token-55-9" pos="word" morph="none" start_char="6152" end_char="6158">effects</TOKEN>
<TOKEN id="token-55-10" pos="punct" morph="none" start_char="6159" end_char="6159">,</TOKEN>
<TOKEN id="token-55-11" pos="word" morph="none" start_char="6161" end_char="6163">and</TOKEN>
<TOKEN id="token-55-12" pos="punct" morph="none" start_char="6165" end_char="6165">(</TOKEN>
<TOKEN id="token-55-13" pos="word" morph="none" start_char="6166" end_char="6166">2</TOKEN>
<TOKEN id="token-55-14" pos="punct" morph="none" start_char="6167" end_char="6167">)</TOKEN>
<TOKEN id="token-55-15" pos="word" morph="none" start_char="6169" end_char="6176">strength</TOKEN>
<TOKEN id="token-55-16" pos="word" morph="none" start_char="6178" end_char="6179">of</TOKEN>
<TOKEN id="token-55-17" pos="word" morph="none" start_char="6181" end_char="6188">evidence</TOKEN>
<TOKEN id="token-55-18" pos="word" morph="none" start_char="6190" end_char="6192">for</TOKEN>
<TOKEN id="token-55-19" pos="word" morph="none" start_char="6194" end_char="6206">heterogeneity</TOKEN>
<TOKEN id="token-55-20" pos="punct" morph="none" start_char="6208" end_char="6208">(</TOKEN>
<TOKEN id="token-55-21" pos="unknown" morph="none" start_char="6209" end_char="6211">e.g</TOKEN>
<TOKEN id="token-55-22" pos="punct" morph="none" start_char="6212" end_char="6212">.</TOKEN>
<TOKEN id="token-55-23" pos="word" morph="none" start_char="6214" end_char="6214">P</TOKEN>
<TOKEN id="token-55-24" pos="word" morph="none" start_char="6216" end_char="6220">value</TOKEN>
<TOKEN id="token-55-25" pos="word" morph="none" start_char="6222" end_char="6225">from</TOKEN>
<TOKEN id="token-55-26" pos="word" morph="none" start_char="6227" end_char="6229">the</TOKEN>
<TOKEN id="token-55-27" pos="word" morph="none" start_char="6231" end_char="6233">Chi</TOKEN>
</SEG>
<SEG id="segment-56" start_char="6236" end_char="6236">
<ORIGINAL_TEXT>2</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="6236" end_char="6236">2</TOKEN>
</SEG>
<SEG id="segment-57" start_char="6239" end_char="6274">
<ORIGINAL_TEXT>test, or a confidence interval for I</ORIGINAL_TEXT>
<TOKEN id="token-57-0" pos="word" morph="none" start_char="6239" end_char="6242">test</TOKEN>
<TOKEN id="token-57-1" pos="punct" morph="none" start_char="6243" end_char="6243">,</TOKEN>
<TOKEN id="token-57-2" pos="word" morph="none" start_char="6245" end_char="6246">or</TOKEN>
<TOKEN id="token-57-3" pos="word" morph="none" start_char="6248" end_char="6248">a</TOKEN>
<TOKEN id="token-57-4" pos="word" morph="none" start_char="6250" end_char="6259">confidence</TOKEN>
<TOKEN id="token-57-5" pos="word" morph="none" start_char="6261" end_char="6268">interval</TOKEN>
<TOKEN id="token-57-6" pos="word" morph="none" start_char="6270" end_char="6272">for</TOKEN>
<TOKEN id="token-57-7" pos="word" morph="none" start_char="6274" end_char="6274">I</TOKEN>
</SEG>
<SEG id="segment-58" start_char="6277" end_char="6277">
<ORIGINAL_TEXT>2</ORIGINAL_TEXT>
<TOKEN id="token-58-0" pos="word" morph="none" start_char="6277" end_char="6277">2</TOKEN>
</SEG>
<SEG id="segment-59" start_char="6280" end_char="6310">
<ORIGINAL_TEXT>: uncertainty in the value of I</ORIGINAL_TEXT>
<TOKEN id="token-59-0" pos="punct" morph="none" start_char="6280" end_char="6280">:</TOKEN>
<TOKEN id="token-59-1" pos="word" morph="none" start_char="6282" end_char="6292">uncertainty</TOKEN>
<TOKEN id="token-59-2" pos="word" morph="none" start_char="6294" end_char="6295">in</TOKEN>
<TOKEN id="token-59-3" pos="word" morph="none" start_char="6297" end_char="6299">the</TOKEN>
<TOKEN id="token-59-4" pos="word" morph="none" start_char="6301" end_char="6305">value</TOKEN>
<TOKEN id="token-59-5" pos="word" morph="none" start_char="6307" end_char="6308">of</TOKEN>
<TOKEN id="token-59-6" pos="word" morph="none" start_char="6310" end_char="6310">I</TOKEN>
</SEG>
<SEG id="segment-60" start_char="6313" end_char="6313">
<ORIGINAL_TEXT>2</ORIGINAL_TEXT>
<TOKEN id="token-60-0" pos="word" morph="none" start_char="6313" end_char="6313">2</TOKEN>
</SEG>
<SEG id="segment-61" start_char="6316" end_char="6367">
<ORIGINAL_TEXT>is substantial when the number of studies is small).</ORIGINAL_TEXT>
<TOKEN id="token-61-0" pos="word" morph="none" start_char="6316" end_char="6317">is</TOKEN>
<TOKEN id="token-61-1" pos="word" morph="none" start_char="6319" end_char="6329">substantial</TOKEN>
<TOKEN id="token-61-2" pos="word" morph="none" start_char="6331" end_char="6334">when</TOKEN>
<TOKEN id="token-61-3" pos="word" morph="none" start_char="6336" end_char="6338">the</TOKEN>
<TOKEN id="token-61-4" pos="word" morph="none" start_char="6340" end_char="6345">number</TOKEN>
<TOKEN id="token-61-5" pos="word" morph="none" start_char="6347" end_char="6348">of</TOKEN>
<TOKEN id="token-61-6" pos="word" morph="none" start_char="6350" end_char="6356">studies</TOKEN>
<TOKEN id="token-61-7" pos="word" morph="none" start_char="6358" end_char="6359">is</TOKEN>
<TOKEN id="token-61-8" pos="word" morph="none" start_char="6361" end_char="6365">small</TOKEN>
<TOKEN id="token-61-9" pos="punct" morph="none" start_char="6366" end_char="6367">).</TOKEN>
</SEG>
<SEG id="segment-62" start_char="6370" end_char="6370">
<ORIGINAL_TEXT>"</ORIGINAL_TEXT>
<TOKEN id="token-62-0" pos="punct" morph="none" start_char="6370" end_char="6370">"</TOKEN>
</SEG>
<SEG id="segment-63" start_char="6373" end_char="6398">
<ORIGINAL_TEXT>In an article published by</ORIGINAL_TEXT>
<TOKEN id="token-63-0" pos="word" morph="none" start_char="6373" end_char="6374">In</TOKEN>
<TOKEN id="token-63-1" pos="word" morph="none" start_char="6376" end_char="6377">an</TOKEN>
<TOKEN id="token-63-2" pos="word" morph="none" start_char="6379" end_char="6385">article</TOKEN>
<TOKEN id="token-63-3" pos="word" morph="none" start_char="6387" end_char="6395">published</TOKEN>
<TOKEN id="token-63-4" pos="word" morph="none" start_char="6397" end_char="6398">by</TOKEN>
</SEG>
<SEG id="segment-64" start_char="6401" end_char="6403">
<ORIGINAL_TEXT>BMJ</ORIGINAL_TEXT>
<TOKEN id="token-64-0" pos="word" morph="none" start_char="6401" end_char="6403">BMJ</TOKEN>
</SEG>
<SEG id="segment-65" start_char="6406" end_char="6408">
<ORIGINAL_TEXT>[3]</ORIGINAL_TEXT>
<TOKEN id="token-65-0" pos="punct" morph="none" start_char="6406" end_char="6406">[</TOKEN>
<TOKEN id="token-65-1" pos="word" morph="none" start_char="6407" end_char="6407">3</TOKEN>
<TOKEN id="token-65-2" pos="punct" morph="none" start_char="6408" end_char="6408">]</TOKEN>
</SEG>
<SEG id="segment-66" start_char="6411" end_char="6419">
<ORIGINAL_TEXT>, Higgins</ORIGINAL_TEXT>
<TOKEN id="token-66-0" pos="punct" morph="none" start_char="6411" end_char="6411">,</TOKEN>
<TOKEN id="token-66-1" pos="word" morph="none" start_char="6413" end_char="6419">Higgins</TOKEN>
</SEG>
<SEG id="segment-67" start_char="6422" end_char="6427">
<ORIGINAL_TEXT>et al.</ORIGINAL_TEXT>
<TOKEN id="token-67-0" pos="word" morph="none" start_char="6422" end_char="6423">et</TOKEN>
<TOKEN id="token-67-1" pos="word" morph="none" start_char="6425" end_char="6426">al</TOKEN>
<TOKEN id="token-67-2" pos="punct" morph="none" start_char="6427" end_char="6427">.</TOKEN>
</SEG>
<SEG id="segment-68" start_char="6430" end_char="6439">
<ORIGINAL_TEXT>explained:</ORIGINAL_TEXT>
<TOKEN id="token-68-0" pos="word" morph="none" start_char="6430" end_char="6438">explained</TOKEN>
<TOKEN id="token-68-1" pos="punct" morph="none" start_char="6439" end_char="6439">:</TOKEN>
</SEG>
<SEG id="segment-69" start_char="6442" end_char="6442">
<ORIGINAL_TEXT>"</ORIGINAL_TEXT>
<TOKEN id="token-69-0" pos="punct" morph="none" start_char="6442" end_char="6442">"</TOKEN>
</SEG>
<SEG id="segment-70" start_char="6445" end_char="6538">
<ORIGINAL_TEXT>Assessment of the consistency of effects across studies is an essential part of meta-analysis.</ORIGINAL_TEXT>
<TOKEN id="token-70-0" pos="word" morph="none" start_char="6445" end_char="6454">Assessment</TOKEN>
<TOKEN id="token-70-1" pos="word" morph="none" start_char="6456" end_char="6457">of</TOKEN>
<TOKEN id="token-70-2" pos="word" morph="none" start_char="6459" end_char="6461">the</TOKEN>
<TOKEN id="token-70-3" pos="word" morph="none" start_char="6463" end_char="6473">consistency</TOKEN>
<TOKEN id="token-70-4" pos="word" morph="none" start_char="6475" end_char="6476">of</TOKEN>
<TOKEN id="token-70-5" pos="word" morph="none" start_char="6478" end_char="6484">effects</TOKEN>
<TOKEN id="token-70-6" pos="word" morph="none" start_char="6486" end_char="6491">across</TOKEN>
<TOKEN id="token-70-7" pos="word" morph="none" start_char="6493" end_char="6499">studies</TOKEN>
<TOKEN id="token-70-8" pos="word" morph="none" start_char="6501" end_char="6502">is</TOKEN>
<TOKEN id="token-70-9" pos="word" morph="none" start_char="6504" end_char="6505">an</TOKEN>
<TOKEN id="token-70-10" pos="word" morph="none" start_char="6507" end_char="6515">essential</TOKEN>
<TOKEN id="token-70-11" pos="word" morph="none" start_char="6517" end_char="6520">part</TOKEN>
<TOKEN id="token-70-12" pos="word" morph="none" start_char="6522" end_char="6523">of</TOKEN>
<TOKEN id="token-70-13" pos="unknown" morph="none" start_char="6525" end_char="6537">meta-analysis</TOKEN>
<TOKEN id="token-70-14" pos="punct" morph="none" start_char="6538" end_char="6538">.</TOKEN>
</SEG>
<SEG id="segment-71" start_char="6540" end_char="6675">
<ORIGINAL_TEXT>Unless we know how consistent the results of studies are, we cannot determine the generalisability of the findings of the meta-analysis.</ORIGINAL_TEXT>
<TOKEN id="token-71-0" pos="word" morph="none" start_char="6540" end_char="6545">Unless</TOKEN>
<TOKEN id="token-71-1" pos="word" morph="none" start_char="6547" end_char="6548">we</TOKEN>
<TOKEN id="token-71-2" pos="word" morph="none" start_char="6550" end_char="6553">know</TOKEN>
<TOKEN id="token-71-3" pos="word" morph="none" start_char="6555" end_char="6557">how</TOKEN>
<TOKEN id="token-71-4" pos="word" morph="none" start_char="6559" end_char="6568">consistent</TOKEN>
<TOKEN id="token-71-5" pos="word" morph="none" start_char="6570" end_char="6572">the</TOKEN>
<TOKEN id="token-71-6" pos="word" morph="none" start_char="6574" end_char="6580">results</TOKEN>
<TOKEN id="token-71-7" pos="word" morph="none" start_char="6582" end_char="6583">of</TOKEN>
<TOKEN id="token-71-8" pos="word" morph="none" start_char="6585" end_char="6591">studies</TOKEN>
<TOKEN id="token-71-9" pos="word" morph="none" start_char="6593" end_char="6595">are</TOKEN>
<TOKEN id="token-71-10" pos="punct" morph="none" start_char="6596" end_char="6596">,</TOKEN>
<TOKEN id="token-71-11" pos="word" morph="none" start_char="6598" end_char="6599">we</TOKEN>
<TOKEN id="token-71-12" pos="word" morph="none" start_char="6601" end_char="6606">cannot</TOKEN>
<TOKEN id="token-71-13" pos="word" morph="none" start_char="6608" end_char="6616">determine</TOKEN>
<TOKEN id="token-71-14" pos="word" morph="none" start_char="6618" end_char="6620">the</TOKEN>
<TOKEN id="token-71-15" pos="word" morph="none" start_char="6622" end_char="6637">generalisability</TOKEN>
<TOKEN id="token-71-16" pos="word" morph="none" start_char="6639" end_char="6640">of</TOKEN>
<TOKEN id="token-71-17" pos="word" morph="none" start_char="6642" end_char="6644">the</TOKEN>
<TOKEN id="token-71-18" pos="word" morph="none" start_char="6646" end_char="6653">findings</TOKEN>
<TOKEN id="token-71-19" pos="word" morph="none" start_char="6655" end_char="6656">of</TOKEN>
<TOKEN id="token-71-20" pos="word" morph="none" start_char="6658" end_char="6660">the</TOKEN>
<TOKEN id="token-71-21" pos="unknown" morph="none" start_char="6662" end_char="6674">meta-analysis</TOKEN>
<TOKEN id="token-71-22" pos="punct" morph="none" start_char="6675" end_char="6675">.</TOKEN>
</SEG>
<SEG id="segment-72" start_char="6678" end_char="6678">
<ORIGINAL_TEXT>"</ORIGINAL_TEXT>
<TOKEN id="token-72-0" pos="punct" morph="none" start_char="6678" end_char="6678">"</TOKEN>
</SEG>
<SEG id="segment-73" start_char="6682" end_char="6701">
<ORIGINAL_TEXT>Overall, the lower I</ORIGINAL_TEXT>
<TOKEN id="token-73-0" pos="word" morph="none" start_char="6682" end_char="6688">Overall</TOKEN>
<TOKEN id="token-73-1" pos="punct" morph="none" start_char="6689" end_char="6689">,</TOKEN>
<TOKEN id="token-73-2" pos="word" morph="none" start_char="6691" end_char="6693">the</TOKEN>
<TOKEN id="token-73-3" pos="word" morph="none" start_char="6695" end_char="6699">lower</TOKEN>
<TOKEN id="token-73-4" pos="word" morph="none" start_char="6701" end_char="6701">I</TOKEN>
</SEG>
<SEG id="segment-74" start_char="6704" end_char="6704">
<ORIGINAL_TEXT>2</ORIGINAL_TEXT>
<TOKEN id="token-74-0" pos="word" morph="none" start_char="6704" end_char="6704">2</TOKEN>
</SEG>
<SEG id="segment-75" start_char="6707" end_char="6830">
<ORIGINAL_TEXT>is, the smaller the heterogeneity is, and the greater the confidence researchers can have in the reliability of the results.</ORIGINAL_TEXT>
<TOKEN id="token-75-0" pos="word" morph="none" start_char="6707" end_char="6708">is</TOKEN>
<TOKEN id="token-75-1" pos="punct" morph="none" start_char="6709" end_char="6709">,</TOKEN>
<TOKEN id="token-75-2" pos="word" morph="none" start_char="6711" end_char="6713">the</TOKEN>
<TOKEN id="token-75-3" pos="word" morph="none" start_char="6715" end_char="6721">smaller</TOKEN>
<TOKEN id="token-75-4" pos="word" morph="none" start_char="6723" end_char="6725">the</TOKEN>
<TOKEN id="token-75-5" pos="word" morph="none" start_char="6727" end_char="6739">heterogeneity</TOKEN>
<TOKEN id="token-75-6" pos="word" morph="none" start_char="6741" end_char="6742">is</TOKEN>
<TOKEN id="token-75-7" pos="punct" morph="none" start_char="6743" end_char="6743">,</TOKEN>
<TOKEN id="token-75-8" pos="word" morph="none" start_char="6745" end_char="6747">and</TOKEN>
<TOKEN id="token-75-9" pos="word" morph="none" start_char="6749" end_char="6751">the</TOKEN>
<TOKEN id="token-75-10" pos="word" morph="none" start_char="6753" end_char="6759">greater</TOKEN>
<TOKEN id="token-75-11" pos="word" morph="none" start_char="6761" end_char="6763">the</TOKEN>
<TOKEN id="token-75-12" pos="word" morph="none" start_char="6765" end_char="6774">confidence</TOKEN>
<TOKEN id="token-75-13" pos="word" morph="none" start_char="6776" end_char="6786">researchers</TOKEN>
<TOKEN id="token-75-14" pos="word" morph="none" start_char="6788" end_char="6790">can</TOKEN>
<TOKEN id="token-75-15" pos="word" morph="none" start_char="6792" end_char="6795">have</TOKEN>
<TOKEN id="token-75-16" pos="word" morph="none" start_char="6797" end_char="6798">in</TOKEN>
<TOKEN id="token-75-17" pos="word" morph="none" start_char="6800" end_char="6802">the</TOKEN>
<TOKEN id="token-75-18" pos="word" morph="none" start_char="6804" end_char="6814">reliability</TOKEN>
<TOKEN id="token-75-19" pos="word" morph="none" start_char="6816" end_char="6817">of</TOKEN>
<TOKEN id="token-75-20" pos="word" morph="none" start_char="6819" end_char="6821">the</TOKEN>
<TOKEN id="token-75-21" pos="word" morph="none" start_char="6823" end_char="6829">results</TOKEN>
<TOKEN id="token-75-22" pos="punct" morph="none" start_char="6830" end_char="6830">.</TOKEN>
</SEG>
<SEG id="segment-76" start_char="6833" end_char="6919">
<ORIGINAL_TEXT>Looking at CovidAnalysis’ ivermectin analysis (see figure below), we can see that the I</ORIGINAL_TEXT>
<TOKEN id="token-76-0" pos="word" morph="none" start_char="6833" end_char="6839">Looking</TOKEN>
<TOKEN id="token-76-1" pos="word" morph="none" start_char="6841" end_char="6842">at</TOKEN>
<TOKEN id="token-76-2" pos="word" morph="none" start_char="6844" end_char="6856">CovidAnalysis</TOKEN>
<TOKEN id="token-76-3" pos="punct" morph="none" start_char="6857" end_char="6857">’</TOKEN>
<TOKEN id="token-76-4" pos="word" morph="none" start_char="6859" end_char="6868">ivermectin</TOKEN>
<TOKEN id="token-76-5" pos="word" morph="none" start_char="6870" end_char="6877">analysis</TOKEN>
<TOKEN id="token-76-6" pos="punct" morph="none" start_char="6879" end_char="6879">(</TOKEN>
<TOKEN id="token-76-7" pos="word" morph="none" start_char="6880" end_char="6882">see</TOKEN>
<TOKEN id="token-76-8" pos="word" morph="none" start_char="6884" end_char="6889">figure</TOKEN>
<TOKEN id="token-76-9" pos="word" morph="none" start_char="6891" end_char="6895">below</TOKEN>
<TOKEN id="token-76-10" pos="punct" morph="none" start_char="6896" end_char="6897">),</TOKEN>
<TOKEN id="token-76-11" pos="word" morph="none" start_char="6899" end_char="6900">we</TOKEN>
<TOKEN id="token-76-12" pos="word" morph="none" start_char="6902" end_char="6904">can</TOKEN>
<TOKEN id="token-76-13" pos="word" morph="none" start_char="6906" end_char="6908">see</TOKEN>
<TOKEN id="token-76-14" pos="word" morph="none" start_char="6910" end_char="6913">that</TOKEN>
<TOKEN id="token-76-15" pos="word" morph="none" start_char="6915" end_char="6917">the</TOKEN>
<TOKEN id="token-76-16" pos="word" morph="none" start_char="6919" end_char="6919">I</TOKEN>
</SEG>
<SEG id="segment-77" start_char="6922" end_char="6922">
<ORIGINAL_TEXT>2</ORIGINAL_TEXT>
<TOKEN id="token-77-0" pos="word" morph="none" start_char="6922" end_char="6922">2</TOKEN>
</SEG>
<SEG id="segment-78" start_char="6925" end_char="7039">
<ORIGINAL_TEXT>values reported for "early treatment", "late treatment", and "prophylaxis" are 85%, 65.6%, and 83.8%, respectively.</ORIGINAL_TEXT>
<TOKEN id="token-78-0" pos="word" morph="none" start_char="6925" end_char="6930">values</TOKEN>
<TOKEN id="token-78-1" pos="word" morph="none" start_char="6932" end_char="6939">reported</TOKEN>
<TOKEN id="token-78-2" pos="word" morph="none" start_char="6941" end_char="6943">for</TOKEN>
<TOKEN id="token-78-3" pos="punct" morph="none" start_char="6945" end_char="6945">"</TOKEN>
<TOKEN id="token-78-4" pos="word" morph="none" start_char="6946" end_char="6950">early</TOKEN>
<TOKEN id="token-78-5" pos="word" morph="none" start_char="6952" end_char="6960">treatment</TOKEN>
<TOKEN id="token-78-6" pos="punct" morph="none" start_char="6961" end_char="6962">",</TOKEN>
<TOKEN id="token-78-7" pos="punct" morph="none" start_char="6964" end_char="6964">"</TOKEN>
<TOKEN id="token-78-8" pos="word" morph="none" start_char="6965" end_char="6968">late</TOKEN>
<TOKEN id="token-78-9" pos="word" morph="none" start_char="6970" end_char="6978">treatment</TOKEN>
<TOKEN id="token-78-10" pos="punct" morph="none" start_char="6979" end_char="6980">",</TOKEN>
<TOKEN id="token-78-11" pos="word" morph="none" start_char="6982" end_char="6984">and</TOKEN>
<TOKEN id="token-78-12" pos="punct" morph="none" start_char="6986" end_char="6986">"</TOKEN>
<TOKEN id="token-78-13" pos="word" morph="none" start_char="6987" end_char="6997">prophylaxis</TOKEN>
<TOKEN id="token-78-14" pos="punct" morph="none" start_char="6998" end_char="6998">"</TOKEN>
<TOKEN id="token-78-15" pos="word" morph="none" start_char="7000" end_char="7002">are</TOKEN>
<TOKEN id="token-78-16" pos="word" morph="none" start_char="7004" end_char="7005">85</TOKEN>
<TOKEN id="token-78-17" pos="punct" morph="none" start_char="7006" end_char="7007">%,</TOKEN>
<TOKEN id="token-78-18" pos="unknown" morph="none" start_char="7009" end_char="7012">65.6</TOKEN>
<TOKEN id="token-78-19" pos="punct" morph="none" start_char="7013" end_char="7014">%,</TOKEN>
<TOKEN id="token-78-20" pos="word" morph="none" start_char="7016" end_char="7018">and</TOKEN>
<TOKEN id="token-78-21" pos="unknown" morph="none" start_char="7020" end_char="7023">83.8</TOKEN>
<TOKEN id="token-78-22" pos="punct" morph="none" start_char="7024" end_char="7025">%,</TOKEN>
<TOKEN id="token-78-23" pos="word" morph="none" start_char="7027" end_char="7038">respectively</TOKEN>
<TOKEN id="token-78-24" pos="punct" morph="none" start_char="7039" end_char="7039">.</TOKEN>
</SEG>
<SEG id="segment-79" start_char="7041" end_char="7173">
<ORIGINAL_TEXT>These values indicate that the results of the studies in the meta-analysis are very different from one another, or very heterogenous.</ORIGINAL_TEXT>
<TOKEN id="token-79-0" pos="word" morph="none" start_char="7041" end_char="7045">These</TOKEN>
<TOKEN id="token-79-1" pos="word" morph="none" start_char="7047" end_char="7052">values</TOKEN>
<TOKEN id="token-79-2" pos="word" morph="none" start_char="7054" end_char="7061">indicate</TOKEN>
<TOKEN id="token-79-3" pos="word" morph="none" start_char="7063" end_char="7066">that</TOKEN>
<TOKEN id="token-79-4" pos="word" morph="none" start_char="7068" end_char="7070">the</TOKEN>
<TOKEN id="token-79-5" pos="word" morph="none" start_char="7072" end_char="7078">results</TOKEN>
<TOKEN id="token-79-6" pos="word" morph="none" start_char="7080" end_char="7081">of</TOKEN>
<TOKEN id="token-79-7" pos="word" morph="none" start_char="7083" end_char="7085">the</TOKEN>
<TOKEN id="token-79-8" pos="word" morph="none" start_char="7087" end_char="7093">studies</TOKEN>
<TOKEN id="token-79-9" pos="word" morph="none" start_char="7095" end_char="7096">in</TOKEN>
<TOKEN id="token-79-10" pos="word" morph="none" start_char="7098" end_char="7100">the</TOKEN>
<TOKEN id="token-79-11" pos="unknown" morph="none" start_char="7102" end_char="7114">meta-analysis</TOKEN>
<TOKEN id="token-79-12" pos="word" morph="none" start_char="7116" end_char="7118">are</TOKEN>
<TOKEN id="token-79-13" pos="word" morph="none" start_char="7120" end_char="7123">very</TOKEN>
<TOKEN id="token-79-14" pos="word" morph="none" start_char="7125" end_char="7133">different</TOKEN>
<TOKEN id="token-79-15" pos="word" morph="none" start_char="7135" end_char="7138">from</TOKEN>
<TOKEN id="token-79-16" pos="word" morph="none" start_char="7140" end_char="7142">one</TOKEN>
<TOKEN id="token-79-17" pos="word" morph="none" start_char="7144" end_char="7150">another</TOKEN>
<TOKEN id="token-79-18" pos="punct" morph="none" start_char="7151" end_char="7151">,</TOKEN>
<TOKEN id="token-79-19" pos="word" morph="none" start_char="7153" end_char="7154">or</TOKEN>
<TOKEN id="token-79-20" pos="word" morph="none" start_char="7156" end_char="7159">very</TOKEN>
<TOKEN id="token-79-21" pos="word" morph="none" start_char="7161" end_char="7172">heterogenous</TOKEN>
<TOKEN id="token-79-22" pos="punct" morph="none" start_char="7173" end_char="7173">.</TOKEN>
</SEG>
<SEG id="segment-80" start_char="7175" end_char="7257">
<ORIGINAL_TEXT>As explained above, this reduces the reliability of the meta-analysis’ conclusions.</ORIGINAL_TEXT>
<TOKEN id="token-80-0" pos="word" morph="none" start_char="7175" end_char="7176">As</TOKEN>
<TOKEN id="token-80-1" pos="word" morph="none" start_char="7178" end_char="7186">explained</TOKEN>
<TOKEN id="token-80-2" pos="word" morph="none" start_char="7188" end_char="7192">above</TOKEN>
<TOKEN id="token-80-3" pos="punct" morph="none" start_char="7193" end_char="7193">,</TOKEN>
<TOKEN id="token-80-4" pos="word" morph="none" start_char="7195" end_char="7198">this</TOKEN>
<TOKEN id="token-80-5" pos="word" morph="none" start_char="7200" end_char="7206">reduces</TOKEN>
<TOKEN id="token-80-6" pos="word" morph="none" start_char="7208" end_char="7210">the</TOKEN>
<TOKEN id="token-80-7" pos="word" morph="none" start_char="7212" end_char="7222">reliability</TOKEN>
<TOKEN id="token-80-8" pos="word" morph="none" start_char="7224" end_char="7225">of</TOKEN>
<TOKEN id="token-80-9" pos="word" morph="none" start_char="7227" end_char="7229">the</TOKEN>
<TOKEN id="token-80-10" pos="unknown" morph="none" start_char="7231" end_char="7243">meta-analysis</TOKEN>
<TOKEN id="token-80-11" pos="punct" morph="none" start_char="7244" end_char="7244">’</TOKEN>
<TOKEN id="token-80-12" pos="word" morph="none" start_char="7246" end_char="7256">conclusions</TOKEN>
<TOKEN id="token-80-13" pos="punct" morph="none" start_char="7257" end_char="7257">.</TOKEN>
</SEG>
<SEG id="segment-81" start_char="7260" end_char="7268">
<ORIGINAL_TEXT>Figure 1.</ORIGINAL_TEXT>
<TOKEN id="token-81-0" pos="word" morph="none" start_char="7260" end_char="7265">Figure</TOKEN>
<TOKEN id="token-81-1" pos="word" morph="none" start_char="7267" end_char="7267">1</TOKEN>
<TOKEN id="token-81-2" pos="punct" morph="none" start_char="7268" end_char="7268">.</TOKEN>
</SEG>
<SEG id="segment-82" start_char="7270" end_char="7382">
<ORIGINAL_TEXT>A forest plot showing the meta-analysis of ivermectin’s effect on different outcomes, conducted by CovidAnalysis.</ORIGINAL_TEXT>
<TOKEN id="token-82-0" pos="word" morph="none" start_char="7270" end_char="7270">A</TOKEN>
<TOKEN id="token-82-1" pos="word" morph="none" start_char="7272" end_char="7277">forest</TOKEN>
<TOKEN id="token-82-2" pos="word" morph="none" start_char="7279" end_char="7282">plot</TOKEN>
<TOKEN id="token-82-3" pos="word" morph="none" start_char="7284" end_char="7290">showing</TOKEN>
<TOKEN id="token-82-4" pos="word" morph="none" start_char="7292" end_char="7294">the</TOKEN>
<TOKEN id="token-82-5" pos="unknown" morph="none" start_char="7296" end_char="7308">meta-analysis</TOKEN>
<TOKEN id="token-82-6" pos="word" morph="none" start_char="7310" end_char="7311">of</TOKEN>
<TOKEN id="token-82-7" pos="word" morph="none" start_char="7313" end_char="7324">ivermectin’s</TOKEN>
<TOKEN id="token-82-8" pos="word" morph="none" start_char="7326" end_char="7331">effect</TOKEN>
<TOKEN id="token-82-9" pos="word" morph="none" start_char="7333" end_char="7334">on</TOKEN>
<TOKEN id="token-82-10" pos="word" morph="none" start_char="7336" end_char="7344">different</TOKEN>
<TOKEN id="token-82-11" pos="word" morph="none" start_char="7346" end_char="7353">outcomes</TOKEN>
<TOKEN id="token-82-12" pos="punct" morph="none" start_char="7354" end_char="7354">,</TOKEN>
<TOKEN id="token-82-13" pos="word" morph="none" start_char="7356" end_char="7364">conducted</TOKEN>
<TOKEN id="token-82-14" pos="word" morph="none" start_char="7366" end_char="7367">by</TOKEN>
<TOKEN id="token-82-15" pos="word" morph="none" start_char="7369" end_char="7381">CovidAnalysis</TOKEN>
<TOKEN id="token-82-16" pos="punct" morph="none" start_char="7382" end_char="7382">.</TOKEN>
</SEG>
<SEG id="segment-83" start_char="7386" end_char="7613">
<ORIGINAL_TEXT>Yet at no point did CovidAnalysis acknowledge the limitations in its analysis or express any uncertainty about its conclusions, misleading readers into believing that there is already reliable evidence for ivermectin’s efficacy.</ORIGINAL_TEXT>
<TOKEN id="token-83-0" pos="word" morph="none" start_char="7386" end_char="7388">Yet</TOKEN>
<TOKEN id="token-83-1" pos="word" morph="none" start_char="7390" end_char="7391">at</TOKEN>
<TOKEN id="token-83-2" pos="word" morph="none" start_char="7393" end_char="7394">no</TOKEN>
<TOKEN id="token-83-3" pos="word" morph="none" start_char="7396" end_char="7400">point</TOKEN>
<TOKEN id="token-83-4" pos="word" morph="none" start_char="7402" end_char="7404">did</TOKEN>
<TOKEN id="token-83-5" pos="word" morph="none" start_char="7406" end_char="7418">CovidAnalysis</TOKEN>
<TOKEN id="token-83-6" pos="word" morph="none" start_char="7420" end_char="7430">acknowledge</TOKEN>
<TOKEN id="token-83-7" pos="word" morph="none" start_char="7432" end_char="7434">the</TOKEN>
<TOKEN id="token-83-8" pos="word" morph="none" start_char="7436" end_char="7446">limitations</TOKEN>
<TOKEN id="token-83-9" pos="word" morph="none" start_char="7448" end_char="7449">in</TOKEN>
<TOKEN id="token-83-10" pos="word" morph="none" start_char="7451" end_char="7453">its</TOKEN>
<TOKEN id="token-83-11" pos="word" morph="none" start_char="7455" end_char="7462">analysis</TOKEN>
<TOKEN id="token-83-12" pos="word" morph="none" start_char="7464" end_char="7465">or</TOKEN>
<TOKEN id="token-83-13" pos="word" morph="none" start_char="7467" end_char="7473">express</TOKEN>
<TOKEN id="token-83-14" pos="word" morph="none" start_char="7475" end_char="7477">any</TOKEN>
<TOKEN id="token-83-15" pos="word" morph="none" start_char="7479" end_char="7489">uncertainty</TOKEN>
<TOKEN id="token-83-16" pos="word" morph="none" start_char="7491" end_char="7495">about</TOKEN>
<TOKEN id="token-83-17" pos="word" morph="none" start_char="7497" end_char="7499">its</TOKEN>
<TOKEN id="token-83-18" pos="word" morph="none" start_char="7501" end_char="7511">conclusions</TOKEN>
<TOKEN id="token-83-19" pos="punct" morph="none" start_char="7512" end_char="7512">,</TOKEN>
<TOKEN id="token-83-20" pos="word" morph="none" start_char="7514" end_char="7523">misleading</TOKEN>
<TOKEN id="token-83-21" pos="word" morph="none" start_char="7525" end_char="7531">readers</TOKEN>
<TOKEN id="token-83-22" pos="word" morph="none" start_char="7533" end_char="7536">into</TOKEN>
<TOKEN id="token-83-23" pos="word" morph="none" start_char="7538" end_char="7546">believing</TOKEN>
<TOKEN id="token-83-24" pos="word" morph="none" start_char="7548" end_char="7551">that</TOKEN>
<TOKEN id="token-83-25" pos="word" morph="none" start_char="7553" end_char="7557">there</TOKEN>
<TOKEN id="token-83-26" pos="word" morph="none" start_char="7559" end_char="7560">is</TOKEN>
<TOKEN id="token-83-27" pos="word" morph="none" start_char="7562" end_char="7568">already</TOKEN>
<TOKEN id="token-83-28" pos="word" morph="none" start_char="7570" end_char="7577">reliable</TOKEN>
<TOKEN id="token-83-29" pos="word" morph="none" start_char="7579" end_char="7586">evidence</TOKEN>
<TOKEN id="token-83-30" pos="word" morph="none" start_char="7588" end_char="7590">for</TOKEN>
<TOKEN id="token-83-31" pos="word" morph="none" start_char="7592" end_char="7603">ivermectin’s</TOKEN>
<TOKEN id="token-83-32" pos="word" morph="none" start_char="7605" end_char="7612">efficacy</TOKEN>
<TOKEN id="token-83-33" pos="punct" morph="none" start_char="7613" end_char="7613">.</TOKEN>
</SEG>
<SEG id="segment-84" start_char="7615" end_char="7753">
<ORIGINAL_TEXT>This behavior is consistent with its earlier, misleading "analysis" purporting to show that hydroxychloroquine effectively treats COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-84-0" pos="word" morph="none" start_char="7615" end_char="7618">This</TOKEN>
<TOKEN id="token-84-1" pos="word" morph="none" start_char="7620" end_char="7627">behavior</TOKEN>
<TOKEN id="token-84-2" pos="word" morph="none" start_char="7629" end_char="7630">is</TOKEN>
<TOKEN id="token-84-3" pos="word" morph="none" start_char="7632" end_char="7641">consistent</TOKEN>
<TOKEN id="token-84-4" pos="word" morph="none" start_char="7643" end_char="7646">with</TOKEN>
<TOKEN id="token-84-5" pos="word" morph="none" start_char="7648" end_char="7650">its</TOKEN>
<TOKEN id="token-84-6" pos="word" morph="none" start_char="7652" end_char="7658">earlier</TOKEN>
<TOKEN id="token-84-7" pos="punct" morph="none" start_char="7659" end_char="7659">,</TOKEN>
<TOKEN id="token-84-8" pos="word" morph="none" start_char="7661" end_char="7670">misleading</TOKEN>
<TOKEN id="token-84-9" pos="punct" morph="none" start_char="7672" end_char="7672">"</TOKEN>
<TOKEN id="token-84-10" pos="word" morph="none" start_char="7673" end_char="7680">analysis</TOKEN>
<TOKEN id="token-84-11" pos="punct" morph="none" start_char="7681" end_char="7681">"</TOKEN>
<TOKEN id="token-84-12" pos="word" morph="none" start_char="7683" end_char="7692">purporting</TOKEN>
<TOKEN id="token-84-13" pos="word" morph="none" start_char="7694" end_char="7695">to</TOKEN>
<TOKEN id="token-84-14" pos="word" morph="none" start_char="7697" end_char="7700">show</TOKEN>
<TOKEN id="token-84-15" pos="word" morph="none" start_char="7702" end_char="7705">that</TOKEN>
<TOKEN id="token-84-16" pos="word" morph="none" start_char="7707" end_char="7724">hydroxychloroquine</TOKEN>
<TOKEN id="token-84-17" pos="word" morph="none" start_char="7726" end_char="7736">effectively</TOKEN>
<TOKEN id="token-84-18" pos="word" morph="none" start_char="7738" end_char="7743">treats</TOKEN>
<TOKEN id="token-84-19" pos="unknown" morph="none" start_char="7745" end_char="7752">COVID-19</TOKEN>
<TOKEN id="token-84-20" pos="punct" morph="none" start_char="7753" end_char="7753">.</TOKEN>
</SEG>
<SEG id="segment-85" start_char="7756" end_char="7939">
<ORIGINAL_TEXT>Indeed, by examining the details of each study provided in Figure 6, we can see details of how the studies differed from each other, which can suggest how the heterogeneity came about.</ORIGINAL_TEXT>
<TOKEN id="token-85-0" pos="word" morph="none" start_char="7756" end_char="7761">Indeed</TOKEN>
<TOKEN id="token-85-1" pos="punct" morph="none" start_char="7762" end_char="7762">,</TOKEN>
<TOKEN id="token-85-2" pos="word" morph="none" start_char="7764" end_char="7765">by</TOKEN>
<TOKEN id="token-85-3" pos="word" morph="none" start_char="7767" end_char="7775">examining</TOKEN>
<TOKEN id="token-85-4" pos="word" morph="none" start_char="7777" end_char="7779">the</TOKEN>
<TOKEN id="token-85-5" pos="word" morph="none" start_char="7781" end_char="7787">details</TOKEN>
<TOKEN id="token-85-6" pos="word" morph="none" start_char="7789" end_char="7790">of</TOKEN>
<TOKEN id="token-85-7" pos="word" morph="none" start_char="7792" end_char="7795">each</TOKEN>
<TOKEN id="token-85-8" pos="word" morph="none" start_char="7797" end_char="7801">study</TOKEN>
<TOKEN id="token-85-9" pos="word" morph="none" start_char="7803" end_char="7810">provided</TOKEN>
<TOKEN id="token-85-10" pos="word" morph="none" start_char="7812" end_char="7813">in</TOKEN>
<TOKEN id="token-85-11" pos="word" morph="none" start_char="7815" end_char="7820">Figure</TOKEN>
<TOKEN id="token-85-12" pos="word" morph="none" start_char="7822" end_char="7822">6</TOKEN>
<TOKEN id="token-85-13" pos="punct" morph="none" start_char="7823" end_char="7823">,</TOKEN>
<TOKEN id="token-85-14" pos="word" morph="none" start_char="7825" end_char="7826">we</TOKEN>
<TOKEN id="token-85-15" pos="word" morph="none" start_char="7828" end_char="7830">can</TOKEN>
<TOKEN id="token-85-16" pos="word" morph="none" start_char="7832" end_char="7834">see</TOKEN>
<TOKEN id="token-85-17" pos="word" morph="none" start_char="7836" end_char="7842">details</TOKEN>
<TOKEN id="token-85-18" pos="word" morph="none" start_char="7844" end_char="7845">of</TOKEN>
<TOKEN id="token-85-19" pos="word" morph="none" start_char="7847" end_char="7849">how</TOKEN>
<TOKEN id="token-85-20" pos="word" morph="none" start_char="7851" end_char="7853">the</TOKEN>
<TOKEN id="token-85-21" pos="word" morph="none" start_char="7855" end_char="7861">studies</TOKEN>
<TOKEN id="token-85-22" pos="word" morph="none" start_char="7863" end_char="7870">differed</TOKEN>
<TOKEN id="token-85-23" pos="word" morph="none" start_char="7872" end_char="7875">from</TOKEN>
<TOKEN id="token-85-24" pos="word" morph="none" start_char="7877" end_char="7880">each</TOKEN>
<TOKEN id="token-85-25" pos="word" morph="none" start_char="7882" end_char="7886">other</TOKEN>
<TOKEN id="token-85-26" pos="punct" morph="none" start_char="7887" end_char="7887">,</TOKEN>
<TOKEN id="token-85-27" pos="word" morph="none" start_char="7889" end_char="7893">which</TOKEN>
<TOKEN id="token-85-28" pos="word" morph="none" start_char="7895" end_char="7897">can</TOKEN>
<TOKEN id="token-85-29" pos="word" morph="none" start_char="7899" end_char="7905">suggest</TOKEN>
<TOKEN id="token-85-30" pos="word" morph="none" start_char="7907" end_char="7909">how</TOKEN>
<TOKEN id="token-85-31" pos="word" morph="none" start_char="7911" end_char="7913">the</TOKEN>
<TOKEN id="token-85-32" pos="word" morph="none" start_char="7915" end_char="7927">heterogeneity</TOKEN>
<TOKEN id="token-85-33" pos="word" morph="none" start_char="7929" end_char="7932">came</TOKEN>
<TOKEN id="token-85-34" pos="word" morph="none" start_char="7934" end_char="7938">about</TOKEN>
<TOKEN id="token-85-35" pos="punct" morph="none" start_char="7939" end_char="7939">.</TOKEN>
</SEG>
<SEG id="segment-86" start_char="7942" end_char="8045">
<ORIGINAL_TEXT>For example, 12 of the 52 ivermectin studies involved combined treatment of ivermectin with other drugs.</ORIGINAL_TEXT>
<TOKEN id="token-86-0" pos="word" morph="none" start_char="7942" end_char="7944">For</TOKEN>
<TOKEN id="token-86-1" pos="word" morph="none" start_char="7946" end_char="7952">example</TOKEN>
<TOKEN id="token-86-2" pos="punct" morph="none" start_char="7953" end_char="7953">,</TOKEN>
<TOKEN id="token-86-3" pos="word" morph="none" start_char="7955" end_char="7956">12</TOKEN>
<TOKEN id="token-86-4" pos="word" morph="none" start_char="7958" end_char="7959">of</TOKEN>
<TOKEN id="token-86-5" pos="word" morph="none" start_char="7961" end_char="7963">the</TOKEN>
<TOKEN id="token-86-6" pos="word" morph="none" start_char="7965" end_char="7966">52</TOKEN>
<TOKEN id="token-86-7" pos="word" morph="none" start_char="7968" end_char="7977">ivermectin</TOKEN>
<TOKEN id="token-86-8" pos="word" morph="none" start_char="7979" end_char="7985">studies</TOKEN>
<TOKEN id="token-86-9" pos="word" morph="none" start_char="7987" end_char="7994">involved</TOKEN>
<TOKEN id="token-86-10" pos="word" morph="none" start_char="7996" end_char="8003">combined</TOKEN>
<TOKEN id="token-86-11" pos="word" morph="none" start_char="8005" end_char="8013">treatment</TOKEN>
<TOKEN id="token-86-12" pos="word" morph="none" start_char="8015" end_char="8016">of</TOKEN>
<TOKEN id="token-86-13" pos="word" morph="none" start_char="8018" end_char="8027">ivermectin</TOKEN>
<TOKEN id="token-86-14" pos="word" morph="none" start_char="8029" end_char="8032">with</TOKEN>
<TOKEN id="token-86-15" pos="word" morph="none" start_char="8034" end_char="8038">other</TOKEN>
<TOKEN id="token-86-16" pos="word" morph="none" start_char="8040" end_char="8044">drugs</TOKEN>
<TOKEN id="token-86-17" pos="punct" morph="none" start_char="8045" end_char="8045">.</TOKEN>
</SEG>
<SEG id="segment-87" start_char="8047" end_char="8141">
<ORIGINAL_TEXT>This means that the effects observed in these studies cannot be attributed to ivermectin alone.</ORIGINAL_TEXT>
<TOKEN id="token-87-0" pos="word" morph="none" start_char="8047" end_char="8050">This</TOKEN>
<TOKEN id="token-87-1" pos="word" morph="none" start_char="8052" end_char="8056">means</TOKEN>
<TOKEN id="token-87-2" pos="word" morph="none" start_char="8058" end_char="8061">that</TOKEN>
<TOKEN id="token-87-3" pos="word" morph="none" start_char="8063" end_char="8065">the</TOKEN>
<TOKEN id="token-87-4" pos="word" morph="none" start_char="8067" end_char="8073">effects</TOKEN>
<TOKEN id="token-87-5" pos="word" morph="none" start_char="8075" end_char="8082">observed</TOKEN>
<TOKEN id="token-87-6" pos="word" morph="none" start_char="8084" end_char="8085">in</TOKEN>
<TOKEN id="token-87-7" pos="word" morph="none" start_char="8087" end_char="8091">these</TOKEN>
<TOKEN id="token-87-8" pos="word" morph="none" start_char="8093" end_char="8099">studies</TOKEN>
<TOKEN id="token-87-9" pos="word" morph="none" start_char="8101" end_char="8106">cannot</TOKEN>
<TOKEN id="token-87-10" pos="word" morph="none" start_char="8108" end_char="8109">be</TOKEN>
<TOKEN id="token-87-11" pos="word" morph="none" start_char="8111" end_char="8120">attributed</TOKEN>
<TOKEN id="token-87-12" pos="word" morph="none" start_char="8122" end_char="8123">to</TOKEN>
<TOKEN id="token-87-13" pos="word" morph="none" start_char="8125" end_char="8134">ivermectin</TOKEN>
<TOKEN id="token-87-14" pos="word" morph="none" start_char="8136" end_char="8140">alone</TOKEN>
<TOKEN id="token-87-15" pos="punct" morph="none" start_char="8141" end_char="8141">.</TOKEN>
</SEG>
<SEG id="segment-88" start_char="8144" end_char="8360">
<ORIGINAL_TEXT>Another source of variability is that the studies measured different outcomes, ranging from mortality, length of hospital stay, changes in viral load, and recovery time, which were all combined into a single analysis.</ORIGINAL_TEXT>
<TOKEN id="token-88-0" pos="word" morph="none" start_char="8144" end_char="8150">Another</TOKEN>
<TOKEN id="token-88-1" pos="word" morph="none" start_char="8152" end_char="8157">source</TOKEN>
<TOKEN id="token-88-2" pos="word" morph="none" start_char="8159" end_char="8160">of</TOKEN>
<TOKEN id="token-88-3" pos="word" morph="none" start_char="8162" end_char="8172">variability</TOKEN>
<TOKEN id="token-88-4" pos="word" morph="none" start_char="8174" end_char="8175">is</TOKEN>
<TOKEN id="token-88-5" pos="word" morph="none" start_char="8177" end_char="8180">that</TOKEN>
<TOKEN id="token-88-6" pos="word" morph="none" start_char="8182" end_char="8184">the</TOKEN>
<TOKEN id="token-88-7" pos="word" morph="none" start_char="8186" end_char="8192">studies</TOKEN>
<TOKEN id="token-88-8" pos="word" morph="none" start_char="8194" end_char="8201">measured</TOKEN>
<TOKEN id="token-88-9" pos="word" morph="none" start_char="8203" end_char="8211">different</TOKEN>
<TOKEN id="token-88-10" pos="word" morph="none" start_char="8213" end_char="8220">outcomes</TOKEN>
<TOKEN id="token-88-11" pos="punct" morph="none" start_char="8221" end_char="8221">,</TOKEN>
<TOKEN id="token-88-12" pos="word" morph="none" start_char="8223" end_char="8229">ranging</TOKEN>
<TOKEN id="token-88-13" pos="word" morph="none" start_char="8231" end_char="8234">from</TOKEN>
<TOKEN id="token-88-14" pos="word" morph="none" start_char="8236" end_char="8244">mortality</TOKEN>
<TOKEN id="token-88-15" pos="punct" morph="none" start_char="8245" end_char="8245">,</TOKEN>
<TOKEN id="token-88-16" pos="word" morph="none" start_char="8247" end_char="8252">length</TOKEN>
<TOKEN id="token-88-17" pos="word" morph="none" start_char="8254" end_char="8255">of</TOKEN>
<TOKEN id="token-88-18" pos="word" morph="none" start_char="8257" end_char="8264">hospital</TOKEN>
<TOKEN id="token-88-19" pos="word" morph="none" start_char="8266" end_char="8269">stay</TOKEN>
<TOKEN id="token-88-20" pos="punct" morph="none" start_char="8270" end_char="8270">,</TOKEN>
<TOKEN id="token-88-21" pos="word" morph="none" start_char="8272" end_char="8278">changes</TOKEN>
<TOKEN id="token-88-22" pos="word" morph="none" start_char="8280" end_char="8281">in</TOKEN>
<TOKEN id="token-88-23" pos="word" morph="none" start_char="8283" end_char="8287">viral</TOKEN>
<TOKEN id="token-88-24" pos="word" morph="none" start_char="8289" end_char="8292">load</TOKEN>
<TOKEN id="token-88-25" pos="punct" morph="none" start_char="8293" end_char="8293">,</TOKEN>
<TOKEN id="token-88-26" pos="word" morph="none" start_char="8295" end_char="8297">and</TOKEN>
<TOKEN id="token-88-27" pos="word" morph="none" start_char="8299" end_char="8306">recovery</TOKEN>
<TOKEN id="token-88-28" pos="word" morph="none" start_char="8308" end_char="8311">time</TOKEN>
<TOKEN id="token-88-29" pos="punct" morph="none" start_char="8312" end_char="8312">,</TOKEN>
<TOKEN id="token-88-30" pos="word" morph="none" start_char="8314" end_char="8318">which</TOKEN>
<TOKEN id="token-88-31" pos="word" morph="none" start_char="8320" end_char="8323">were</TOKEN>
<TOKEN id="token-88-32" pos="word" morph="none" start_char="8325" end_char="8327">all</TOKEN>
<TOKEN id="token-88-33" pos="word" morph="none" start_char="8329" end_char="8336">combined</TOKEN>
<TOKEN id="token-88-34" pos="word" morph="none" start_char="8338" end_char="8341">into</TOKEN>
<TOKEN id="token-88-35" pos="word" morph="none" start_char="8343" end_char="8343">a</TOKEN>
<TOKEN id="token-88-36" pos="word" morph="none" start_char="8345" end_char="8350">single</TOKEN>
<TOKEN id="token-88-37" pos="word" morph="none" start_char="8352" end_char="8359">analysis</TOKEN>
<TOKEN id="token-88-38" pos="punct" morph="none" start_char="8360" end_char="8360">.</TOKEN>
</SEG>
<SEG id="segment-89" start_char="8363" end_char="8615">
<ORIGINAL_TEXT>In other words, far from providing reliable evidence that "ivermectin works", as the website claimed, the findings of CovidAnalysis only reinforce the fact that clinical trials so far provide a low level of certainty—as highlighted in the WHO guideline.</ORIGINAL_TEXT>
<TOKEN id="token-89-0" pos="word" morph="none" start_char="8363" end_char="8364">In</TOKEN>
<TOKEN id="token-89-1" pos="word" morph="none" start_char="8366" end_char="8370">other</TOKEN>
<TOKEN id="token-89-2" pos="word" morph="none" start_char="8372" end_char="8376">words</TOKEN>
<TOKEN id="token-89-3" pos="punct" morph="none" start_char="8377" end_char="8377">,</TOKEN>
<TOKEN id="token-89-4" pos="word" morph="none" start_char="8379" end_char="8381">far</TOKEN>
<TOKEN id="token-89-5" pos="word" morph="none" start_char="8383" end_char="8386">from</TOKEN>
<TOKEN id="token-89-6" pos="word" morph="none" start_char="8388" end_char="8396">providing</TOKEN>
<TOKEN id="token-89-7" pos="word" morph="none" start_char="8398" end_char="8405">reliable</TOKEN>
<TOKEN id="token-89-8" pos="word" morph="none" start_char="8407" end_char="8414">evidence</TOKEN>
<TOKEN id="token-89-9" pos="word" morph="none" start_char="8416" end_char="8419">that</TOKEN>
<TOKEN id="token-89-10" pos="punct" morph="none" start_char="8421" end_char="8421">"</TOKEN>
<TOKEN id="token-89-11" pos="word" morph="none" start_char="8422" end_char="8431">ivermectin</TOKEN>
<TOKEN id="token-89-12" pos="word" morph="none" start_char="8433" end_char="8437">works</TOKEN>
<TOKEN id="token-89-13" pos="punct" morph="none" start_char="8438" end_char="8439">",</TOKEN>
<TOKEN id="token-89-14" pos="word" morph="none" start_char="8441" end_char="8442">as</TOKEN>
<TOKEN id="token-89-15" pos="word" morph="none" start_char="8444" end_char="8446">the</TOKEN>
<TOKEN id="token-89-16" pos="word" morph="none" start_char="8448" end_char="8454">website</TOKEN>
<TOKEN id="token-89-17" pos="word" morph="none" start_char="8456" end_char="8462">claimed</TOKEN>
<TOKEN id="token-89-18" pos="punct" morph="none" start_char="8463" end_char="8463">,</TOKEN>
<TOKEN id="token-89-19" pos="word" morph="none" start_char="8465" end_char="8467">the</TOKEN>
<TOKEN id="token-89-20" pos="word" morph="none" start_char="8469" end_char="8476">findings</TOKEN>
<TOKEN id="token-89-21" pos="word" morph="none" start_char="8478" end_char="8479">of</TOKEN>
<TOKEN id="token-89-22" pos="word" morph="none" start_char="8481" end_char="8493">CovidAnalysis</TOKEN>
<TOKEN id="token-89-23" pos="word" morph="none" start_char="8495" end_char="8498">only</TOKEN>
<TOKEN id="token-89-24" pos="word" morph="none" start_char="8500" end_char="8508">reinforce</TOKEN>
<TOKEN id="token-89-25" pos="word" morph="none" start_char="8510" end_char="8512">the</TOKEN>
<TOKEN id="token-89-26" pos="word" morph="none" start_char="8514" end_char="8517">fact</TOKEN>
<TOKEN id="token-89-27" pos="word" morph="none" start_char="8519" end_char="8522">that</TOKEN>
<TOKEN id="token-89-28" pos="word" morph="none" start_char="8524" end_char="8531">clinical</TOKEN>
<TOKEN id="token-89-29" pos="word" morph="none" start_char="8533" end_char="8538">trials</TOKEN>
<TOKEN id="token-89-30" pos="word" morph="none" start_char="8540" end_char="8541">so</TOKEN>
<TOKEN id="token-89-31" pos="word" morph="none" start_char="8543" end_char="8545">far</TOKEN>
<TOKEN id="token-89-32" pos="word" morph="none" start_char="8547" end_char="8553">provide</TOKEN>
<TOKEN id="token-89-33" pos="word" morph="none" start_char="8555" end_char="8555">a</TOKEN>
<TOKEN id="token-89-34" pos="word" morph="none" start_char="8557" end_char="8559">low</TOKEN>
<TOKEN id="token-89-35" pos="word" morph="none" start_char="8561" end_char="8565">level</TOKEN>
<TOKEN id="token-89-36" pos="word" morph="none" start_char="8567" end_char="8568">of</TOKEN>
<TOKEN id="token-89-37" pos="unknown" morph="none" start_char="8570" end_char="8581">certainty—as</TOKEN>
<TOKEN id="token-89-38" pos="word" morph="none" start_char="8583" end_char="8593">highlighted</TOKEN>
<TOKEN id="token-89-39" pos="word" morph="none" start_char="8595" end_char="8596">in</TOKEN>
<TOKEN id="token-89-40" pos="word" morph="none" start_char="8598" end_char="8600">the</TOKEN>
<TOKEN id="token-89-41" pos="word" morph="none" start_char="8602" end_char="8604">WHO</TOKEN>
<TOKEN id="token-89-42" pos="word" morph="none" start_char="8606" end_char="8614">guideline</TOKEN>
<TOKEN id="token-89-43" pos="punct" morph="none" start_char="8615" end_char="8615">.</TOKEN>
</SEG>
<SEG id="segment-90" start_char="8618" end_char="8780">
<ORIGINAL_TEXT>It is useful to note that among the voices discouraging the use of ivermectin for COVID-19 treatment is Merck, the pharmaceutical company that produces ivermectin.</ORIGINAL_TEXT>
<TOKEN id="token-90-0" pos="word" morph="none" start_char="8618" end_char="8619">It</TOKEN>
<TOKEN id="token-90-1" pos="word" morph="none" start_char="8621" end_char="8622">is</TOKEN>
<TOKEN id="token-90-2" pos="word" morph="none" start_char="8624" end_char="8629">useful</TOKEN>
<TOKEN id="token-90-3" pos="word" morph="none" start_char="8631" end_char="8632">to</TOKEN>
<TOKEN id="token-90-4" pos="word" morph="none" start_char="8634" end_char="8637">note</TOKEN>
<TOKEN id="token-90-5" pos="word" morph="none" start_char="8639" end_char="8642">that</TOKEN>
<TOKEN id="token-90-6" pos="word" morph="none" start_char="8644" end_char="8648">among</TOKEN>
<TOKEN id="token-90-7" pos="word" morph="none" start_char="8650" end_char="8652">the</TOKEN>
<TOKEN id="token-90-8" pos="word" morph="none" start_char="8654" end_char="8659">voices</TOKEN>
<TOKEN id="token-90-9" pos="word" morph="none" start_char="8661" end_char="8672">discouraging</TOKEN>
<TOKEN id="token-90-10" pos="word" morph="none" start_char="8674" end_char="8676">the</TOKEN>
<TOKEN id="token-90-11" pos="word" morph="none" start_char="8678" end_char="8680">use</TOKEN>
<TOKEN id="token-90-12" pos="word" morph="none" start_char="8682" end_char="8683">of</TOKEN>
<TOKEN id="token-90-13" pos="word" morph="none" start_char="8685" end_char="8694">ivermectin</TOKEN>
<TOKEN id="token-90-14" pos="word" morph="none" start_char="8696" end_char="8698">for</TOKEN>
<TOKEN id="token-90-15" pos="unknown" morph="none" start_char="8700" end_char="8707">COVID-19</TOKEN>
<TOKEN id="token-90-16" pos="word" morph="none" start_char="8709" end_char="8717">treatment</TOKEN>
<TOKEN id="token-90-17" pos="word" morph="none" start_char="8719" end_char="8720">is</TOKEN>
<TOKEN id="token-90-18" pos="word" morph="none" start_char="8722" end_char="8726">Merck</TOKEN>
<TOKEN id="token-90-19" pos="punct" morph="none" start_char="8727" end_char="8727">,</TOKEN>
<TOKEN id="token-90-20" pos="word" morph="none" start_char="8729" end_char="8731">the</TOKEN>
<TOKEN id="token-90-21" pos="word" morph="none" start_char="8733" end_char="8746">pharmaceutical</TOKEN>
<TOKEN id="token-90-22" pos="word" morph="none" start_char="8748" end_char="8754">company</TOKEN>
<TOKEN id="token-90-23" pos="word" morph="none" start_char="8756" end_char="8759">that</TOKEN>
<TOKEN id="token-90-24" pos="word" morph="none" start_char="8761" end_char="8768">produces</TOKEN>
<TOKEN id="token-90-25" pos="word" morph="none" start_char="8770" end_char="8779">ivermectin</TOKEN>
<TOKEN id="token-90-26" pos="punct" morph="none" start_char="8780" end_char="8780">.</TOKEN>
</SEG>
<SEG id="segment-91" start_char="8782" end_char="9020">
<ORIGINAL_TEXT>Given that it would stand to profit if ivermectin were used for COVID-19 treatment, it is significant that the company stated that it doesn’t recommend ivermectin for COVID-19 because there is no meaningful clinical evidence supporting it.</ORIGINAL_TEXT>
<TOKEN id="token-91-0" pos="word" morph="none" start_char="8782" end_char="8786">Given</TOKEN>
<TOKEN id="token-91-1" pos="word" morph="none" start_char="8788" end_char="8791">that</TOKEN>
<TOKEN id="token-91-2" pos="word" morph="none" start_char="8793" end_char="8794">it</TOKEN>
<TOKEN id="token-91-3" pos="word" morph="none" start_char="8796" end_char="8800">would</TOKEN>
<TOKEN id="token-91-4" pos="word" morph="none" start_char="8802" end_char="8806">stand</TOKEN>
<TOKEN id="token-91-5" pos="word" morph="none" start_char="8808" end_char="8809">to</TOKEN>
<TOKEN id="token-91-6" pos="word" morph="none" start_char="8811" end_char="8816">profit</TOKEN>
<TOKEN id="token-91-7" pos="word" morph="none" start_char="8818" end_char="8819">if</TOKEN>
<TOKEN id="token-91-8" pos="word" morph="none" start_char="8821" end_char="8830">ivermectin</TOKEN>
<TOKEN id="token-91-9" pos="word" morph="none" start_char="8832" end_char="8835">were</TOKEN>
<TOKEN id="token-91-10" pos="word" morph="none" start_char="8837" end_char="8840">used</TOKEN>
<TOKEN id="token-91-11" pos="word" morph="none" start_char="8842" end_char="8844">for</TOKEN>
<TOKEN id="token-91-12" pos="unknown" morph="none" start_char="8846" end_char="8853">COVID-19</TOKEN>
<TOKEN id="token-91-13" pos="word" morph="none" start_char="8855" end_char="8863">treatment</TOKEN>
<TOKEN id="token-91-14" pos="punct" morph="none" start_char="8864" end_char="8864">,</TOKEN>
<TOKEN id="token-91-15" pos="word" morph="none" start_char="8866" end_char="8867">it</TOKEN>
<TOKEN id="token-91-16" pos="word" morph="none" start_char="8869" end_char="8870">is</TOKEN>
<TOKEN id="token-91-17" pos="word" morph="none" start_char="8872" end_char="8882">significant</TOKEN>
<TOKEN id="token-91-18" pos="word" morph="none" start_char="8884" end_char="8887">that</TOKEN>
<TOKEN id="token-91-19" pos="word" morph="none" start_char="8889" end_char="8891">the</TOKEN>
<TOKEN id="token-91-20" pos="word" morph="none" start_char="8893" end_char="8899">company</TOKEN>
<TOKEN id="token-91-21" pos="word" morph="none" start_char="8901" end_char="8906">stated</TOKEN>
<TOKEN id="token-91-22" pos="word" morph="none" start_char="8908" end_char="8911">that</TOKEN>
<TOKEN id="token-91-23" pos="word" morph="none" start_char="8913" end_char="8914">it</TOKEN>
<TOKEN id="token-91-24" pos="word" morph="none" start_char="8916" end_char="8922">doesn’t</TOKEN>
<TOKEN id="token-91-25" pos="word" morph="none" start_char="8924" end_char="8932">recommend</TOKEN>
<TOKEN id="token-91-26" pos="word" morph="none" start_char="8934" end_char="8943">ivermectin</TOKEN>
<TOKEN id="token-91-27" pos="word" morph="none" start_char="8945" end_char="8947">for</TOKEN>
<TOKEN id="token-91-28" pos="unknown" morph="none" start_char="8949" end_char="8956">COVID-19</TOKEN>
<TOKEN id="token-91-29" pos="word" morph="none" start_char="8958" end_char="8964">because</TOKEN>
<TOKEN id="token-91-30" pos="word" morph="none" start_char="8966" end_char="8970">there</TOKEN>
<TOKEN id="token-91-31" pos="word" morph="none" start_char="8972" end_char="8973">is</TOKEN>
<TOKEN id="token-91-32" pos="word" morph="none" start_char="8975" end_char="8976">no</TOKEN>
<TOKEN id="token-91-33" pos="word" morph="none" start_char="8978" end_char="8987">meaningful</TOKEN>
<TOKEN id="token-91-34" pos="word" morph="none" start_char="8989" end_char="8996">clinical</TOKEN>
<TOKEN id="token-91-35" pos="word" morph="none" start_char="8998" end_char="9005">evidence</TOKEN>
<TOKEN id="token-91-36" pos="word" morph="none" start_char="9007" end_char="9016">supporting</TOKEN>
<TOKEN id="token-91-37" pos="word" morph="none" start_char="9018" end_char="9019">it</TOKEN>
<TOKEN id="token-91-38" pos="punct" morph="none" start_char="9020" end_char="9020">.</TOKEN>
</SEG>
<SEG id="segment-92" start_char="9023" end_char="9147">
<ORIGINAL_TEXT>Finally, Kelly accused "the people that are pushing the vaccines" of suppressing the use of ivermectin for treating COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-92-0" pos="word" morph="none" start_char="9023" end_char="9029">Finally</TOKEN>
<TOKEN id="token-92-1" pos="punct" morph="none" start_char="9030" end_char="9030">,</TOKEN>
<TOKEN id="token-92-2" pos="word" morph="none" start_char="9032" end_char="9036">Kelly</TOKEN>
<TOKEN id="token-92-3" pos="word" morph="none" start_char="9038" end_char="9044">accused</TOKEN>
<TOKEN id="token-92-4" pos="punct" morph="none" start_char="9046" end_char="9046">"</TOKEN>
<TOKEN id="token-92-5" pos="word" morph="none" start_char="9047" end_char="9049">the</TOKEN>
<TOKEN id="token-92-6" pos="word" morph="none" start_char="9051" end_char="9056">people</TOKEN>
<TOKEN id="token-92-7" pos="word" morph="none" start_char="9058" end_char="9061">that</TOKEN>
<TOKEN id="token-92-8" pos="word" morph="none" start_char="9063" end_char="9065">are</TOKEN>
<TOKEN id="token-92-9" pos="word" morph="none" start_char="9067" end_char="9073">pushing</TOKEN>
<TOKEN id="token-92-10" pos="word" morph="none" start_char="9075" end_char="9077">the</TOKEN>
<TOKEN id="token-92-11" pos="word" morph="none" start_char="9079" end_char="9086">vaccines</TOKEN>
<TOKEN id="token-92-12" pos="punct" morph="none" start_char="9087" end_char="9087">"</TOKEN>
<TOKEN id="token-92-13" pos="word" morph="none" start_char="9089" end_char="9090">of</TOKEN>
<TOKEN id="token-92-14" pos="word" morph="none" start_char="9092" end_char="9102">suppressing</TOKEN>
<TOKEN id="token-92-15" pos="word" morph="none" start_char="9104" end_char="9106">the</TOKEN>
<TOKEN id="token-92-16" pos="word" morph="none" start_char="9108" end_char="9110">use</TOKEN>
<TOKEN id="token-92-17" pos="word" morph="none" start_char="9112" end_char="9113">of</TOKEN>
<TOKEN id="token-92-18" pos="word" morph="none" start_char="9115" end_char="9124">ivermectin</TOKEN>
<TOKEN id="token-92-19" pos="word" morph="none" start_char="9126" end_char="9128">for</TOKEN>
<TOKEN id="token-92-20" pos="word" morph="none" start_char="9130" end_char="9137">treating</TOKEN>
<TOKEN id="token-92-21" pos="unknown" morph="none" start_char="9139" end_char="9146">COVID-19</TOKEN>
<TOKEN id="token-92-22" pos="punct" morph="none" start_char="9147" end_char="9147">.</TOKEN>
</SEG>
<SEG id="segment-93" start_char="9149" end_char="9244">
<ORIGINAL_TEXT>He provided no evidence for this claim nor did he provide any examples of who these people were.</ORIGINAL_TEXT>
<TOKEN id="token-93-0" pos="word" morph="none" start_char="9149" end_char="9150">He</TOKEN>
<TOKEN id="token-93-1" pos="word" morph="none" start_char="9152" end_char="9159">provided</TOKEN>
<TOKEN id="token-93-2" pos="word" morph="none" start_char="9161" end_char="9162">no</TOKEN>
<TOKEN id="token-93-3" pos="word" morph="none" start_char="9164" end_char="9171">evidence</TOKEN>
<TOKEN id="token-93-4" pos="word" morph="none" start_char="9173" end_char="9175">for</TOKEN>
<TOKEN id="token-93-5" pos="word" morph="none" start_char="9177" end_char="9180">this</TOKEN>
<TOKEN id="token-93-6" pos="word" morph="none" start_char="9182" end_char="9186">claim</TOKEN>
<TOKEN id="token-93-7" pos="word" morph="none" start_char="9188" end_char="9190">nor</TOKEN>
<TOKEN id="token-93-8" pos="word" morph="none" start_char="9192" end_char="9194">did</TOKEN>
<TOKEN id="token-93-9" pos="word" morph="none" start_char="9196" end_char="9197">he</TOKEN>
<TOKEN id="token-93-10" pos="word" morph="none" start_char="9199" end_char="9205">provide</TOKEN>
<TOKEN id="token-93-11" pos="word" morph="none" start_char="9207" end_char="9209">any</TOKEN>
<TOKEN id="token-93-12" pos="word" morph="none" start_char="9211" end_char="9218">examples</TOKEN>
<TOKEN id="token-93-13" pos="word" morph="none" start_char="9220" end_char="9221">of</TOKEN>
<TOKEN id="token-93-14" pos="word" morph="none" start_char="9223" end_char="9225">who</TOKEN>
<TOKEN id="token-93-15" pos="word" morph="none" start_char="9227" end_char="9231">these</TOKEN>
<TOKEN id="token-93-16" pos="word" morph="none" start_char="9233" end_char="9238">people</TOKEN>
<TOKEN id="token-93-17" pos="word" morph="none" start_char="9240" end_char="9243">were</TOKEN>
<TOKEN id="token-93-18" pos="punct" morph="none" start_char="9244" end_char="9244">.</TOKEN>
</SEG>
<SEG id="segment-94" start_char="9246" end_char="9283">
<ORIGINAL_TEXT>The claim is also flawed in reasoning.</ORIGINAL_TEXT>
<TOKEN id="token-94-0" pos="word" morph="none" start_char="9246" end_char="9248">The</TOKEN>
<TOKEN id="token-94-1" pos="word" morph="none" start_char="9250" end_char="9254">claim</TOKEN>
<TOKEN id="token-94-2" pos="word" morph="none" start_char="9256" end_char="9257">is</TOKEN>
<TOKEN id="token-94-3" pos="word" morph="none" start_char="9259" end_char="9262">also</TOKEN>
<TOKEN id="token-94-4" pos="word" morph="none" start_char="9264" end_char="9269">flawed</TOKEN>
<TOKEN id="token-94-5" pos="word" morph="none" start_char="9271" end_char="9272">in</TOKEN>
<TOKEN id="token-94-6" pos="word" morph="none" start_char="9274" end_char="9282">reasoning</TOKEN>
<TOKEN id="token-94-7" pos="punct" morph="none" start_char="9283" end_char="9283">.</TOKEN>
</SEG>
<SEG id="segment-95" start_char="9285" end_char="9484">
<ORIGINAL_TEXT>Even if ivermectin were eventually proven to be an effective drug for COVID-19, it wouldn’t make vaccines useless (or vice versa), just as seat belts don’t render brakes or airbags in a car redundant.</ORIGINAL_TEXT>
<TOKEN id="token-95-0" pos="word" morph="none" start_char="9285" end_char="9288">Even</TOKEN>
<TOKEN id="token-95-1" pos="word" morph="none" start_char="9290" end_char="9291">if</TOKEN>
<TOKEN id="token-95-2" pos="word" morph="none" start_char="9293" end_char="9302">ivermectin</TOKEN>
<TOKEN id="token-95-3" pos="word" morph="none" start_char="9304" end_char="9307">were</TOKEN>
<TOKEN id="token-95-4" pos="word" morph="none" start_char="9309" end_char="9318">eventually</TOKEN>
<TOKEN id="token-95-5" pos="word" morph="none" start_char="9320" end_char="9325">proven</TOKEN>
<TOKEN id="token-95-6" pos="word" morph="none" start_char="9327" end_char="9328">to</TOKEN>
<TOKEN id="token-95-7" pos="word" morph="none" start_char="9330" end_char="9331">be</TOKEN>
<TOKEN id="token-95-8" pos="word" morph="none" start_char="9333" end_char="9334">an</TOKEN>
<TOKEN id="token-95-9" pos="word" morph="none" start_char="9336" end_char="9344">effective</TOKEN>
<TOKEN id="token-95-10" pos="word" morph="none" start_char="9346" end_char="9349">drug</TOKEN>
<TOKEN id="token-95-11" pos="word" morph="none" start_char="9351" end_char="9353">for</TOKEN>
<TOKEN id="token-95-12" pos="unknown" morph="none" start_char="9355" end_char="9362">COVID-19</TOKEN>
<TOKEN id="token-95-13" pos="punct" morph="none" start_char="9363" end_char="9363">,</TOKEN>
<TOKEN id="token-95-14" pos="word" morph="none" start_char="9365" end_char="9366">it</TOKEN>
<TOKEN id="token-95-15" pos="word" morph="none" start_char="9368" end_char="9375">wouldn’t</TOKEN>
<TOKEN id="token-95-16" pos="word" morph="none" start_char="9377" end_char="9380">make</TOKEN>
<TOKEN id="token-95-17" pos="word" morph="none" start_char="9382" end_char="9389">vaccines</TOKEN>
<TOKEN id="token-95-18" pos="word" morph="none" start_char="9391" end_char="9397">useless</TOKEN>
<TOKEN id="token-95-19" pos="punct" morph="none" start_char="9399" end_char="9399">(</TOKEN>
<TOKEN id="token-95-20" pos="word" morph="none" start_char="9400" end_char="9401">or</TOKEN>
<TOKEN id="token-95-21" pos="word" morph="none" start_char="9403" end_char="9406">vice</TOKEN>
<TOKEN id="token-95-22" pos="word" morph="none" start_char="9408" end_char="9412">versa</TOKEN>
<TOKEN id="token-95-23" pos="punct" morph="none" start_char="9413" end_char="9414">),</TOKEN>
<TOKEN id="token-95-24" pos="word" morph="none" start_char="9416" end_char="9419">just</TOKEN>
<TOKEN id="token-95-25" pos="word" morph="none" start_char="9421" end_char="9422">as</TOKEN>
<TOKEN id="token-95-26" pos="word" morph="none" start_char="9424" end_char="9427">seat</TOKEN>
<TOKEN id="token-95-27" pos="word" morph="none" start_char="9429" end_char="9433">belts</TOKEN>
<TOKEN id="token-95-28" pos="word" morph="none" start_char="9435" end_char="9439">don’t</TOKEN>
<TOKEN id="token-95-29" pos="word" morph="none" start_char="9441" end_char="9446">render</TOKEN>
<TOKEN id="token-95-30" pos="word" morph="none" start_char="9448" end_char="9453">brakes</TOKEN>
<TOKEN id="token-95-31" pos="word" morph="none" start_char="9455" end_char="9456">or</TOKEN>
<TOKEN id="token-95-32" pos="word" morph="none" start_char="9458" end_char="9464">airbags</TOKEN>
<TOKEN id="token-95-33" pos="word" morph="none" start_char="9466" end_char="9467">in</TOKEN>
<TOKEN id="token-95-34" pos="word" morph="none" start_char="9469" end_char="9469">a</TOKEN>
<TOKEN id="token-95-35" pos="word" morph="none" start_char="9471" end_char="9473">car</TOKEN>
<TOKEN id="token-95-36" pos="word" morph="none" start_char="9475" end_char="9483">redundant</TOKEN>
<TOKEN id="token-95-37" pos="punct" morph="none" start_char="9484" end_char="9484">.</TOKEN>
</SEG>
<SEG id="segment-96" start_char="9487" end_char="9609">
<ORIGINAL_TEXT>Overall, the claim that ivermectin can effectively treat and prevent COVID-19 remains unsubstantiated by reliable evidence.</ORIGINAL_TEXT>
<TOKEN id="token-96-0" pos="word" morph="none" start_char="9487" end_char="9493">Overall</TOKEN>
<TOKEN id="token-96-1" pos="punct" morph="none" start_char="9494" end_char="9494">,</TOKEN>
<TOKEN id="token-96-2" pos="word" morph="none" start_char="9496" end_char="9498">the</TOKEN>
<TOKEN id="token-96-3" pos="word" morph="none" start_char="9500" end_char="9504">claim</TOKEN>
<TOKEN id="token-96-4" pos="word" morph="none" start_char="9506" end_char="9509">that</TOKEN>
<TOKEN id="token-96-5" pos="word" morph="none" start_char="9511" end_char="9520">ivermectin</TOKEN>
<TOKEN id="token-96-6" pos="word" morph="none" start_char="9522" end_char="9524">can</TOKEN>
<TOKEN id="token-96-7" pos="word" morph="none" start_char="9526" end_char="9536">effectively</TOKEN>
<TOKEN id="token-96-8" pos="word" morph="none" start_char="9538" end_char="9542">treat</TOKEN>
<TOKEN id="token-96-9" pos="word" morph="none" start_char="9544" end_char="9546">and</TOKEN>
<TOKEN id="token-96-10" pos="word" morph="none" start_char="9548" end_char="9554">prevent</TOKEN>
<TOKEN id="token-96-11" pos="unknown" morph="none" start_char="9556" end_char="9563">COVID-19</TOKEN>
<TOKEN id="token-96-12" pos="word" morph="none" start_char="9565" end_char="9571">remains</TOKEN>
<TOKEN id="token-96-13" pos="word" morph="none" start_char="9573" end_char="9587">unsubstantiated</TOKEN>
<TOKEN id="token-96-14" pos="word" morph="none" start_char="9589" end_char="9590">by</TOKEN>
<TOKEN id="token-96-15" pos="word" morph="none" start_char="9592" end_char="9599">reliable</TOKEN>
<TOKEN id="token-96-16" pos="word" morph="none" start_char="9601" end_char="9608">evidence</TOKEN>
<TOKEN id="token-96-17" pos="punct" morph="none" start_char="9609" end_char="9609">.</TOKEN>
</SEG>
<SEG id="segment-97" start_char="9611" end_char="9692">
<ORIGINAL_TEXT>Researchers have called for high-quality clinical trials to resolve this question.</ORIGINAL_TEXT>
<TOKEN id="token-97-0" pos="word" morph="none" start_char="9611" end_char="9621">Researchers</TOKEN>
<TOKEN id="token-97-1" pos="word" morph="none" start_char="9623" end_char="9626">have</TOKEN>
<TOKEN id="token-97-2" pos="word" morph="none" start_char="9628" end_char="9633">called</TOKEN>
<TOKEN id="token-97-3" pos="word" morph="none" start_char="9635" end_char="9637">for</TOKEN>
<TOKEN id="token-97-4" pos="unknown" morph="none" start_char="9639" end_char="9650">high-quality</TOKEN>
<TOKEN id="token-97-5" pos="word" morph="none" start_char="9652" end_char="9659">clinical</TOKEN>
<TOKEN id="token-97-6" pos="word" morph="none" start_char="9661" end_char="9666">trials</TOKEN>
<TOKEN id="token-97-7" pos="word" morph="none" start_char="9668" end_char="9669">to</TOKEN>
<TOKEN id="token-97-8" pos="word" morph="none" start_char="9671" end_char="9677">resolve</TOKEN>
<TOKEN id="token-97-9" pos="word" morph="none" start_char="9679" end_char="9682">this</TOKEN>
<TOKEN id="token-97-10" pos="word" morph="none" start_char="9684" end_char="9691">question</TOKEN>
<TOKEN id="token-97-11" pos="punct" morph="none" start_char="9692" end_char="9692">.</TOKEN>
</SEG>
<SEG id="segment-98" start_char="9694" end_char="9996">
<ORIGINAL_TEXT>While recommendations may change in the future, should reliable evidence emerge, many health authorities, including the WHO, don’t currently recommend ivermectin as a COVID-19 treatment or preventative due to the lack of evidence supporting it, except as part of clinical trials evaluating its efficacy.</ORIGINAL_TEXT>
<TOKEN id="token-98-0" pos="word" morph="none" start_char="9694" end_char="9698">While</TOKEN>
<TOKEN id="token-98-1" pos="word" morph="none" start_char="9700" end_char="9714">recommendations</TOKEN>
<TOKEN id="token-98-2" pos="word" morph="none" start_char="9716" end_char="9718">may</TOKEN>
<TOKEN id="token-98-3" pos="word" morph="none" start_char="9720" end_char="9725">change</TOKEN>
<TOKEN id="token-98-4" pos="word" morph="none" start_char="9727" end_char="9728">in</TOKEN>
<TOKEN id="token-98-5" pos="word" morph="none" start_char="9730" end_char="9732">the</TOKEN>
<TOKEN id="token-98-6" pos="word" morph="none" start_char="9734" end_char="9739">future</TOKEN>
<TOKEN id="token-98-7" pos="punct" morph="none" start_char="9740" end_char="9740">,</TOKEN>
<TOKEN id="token-98-8" pos="word" morph="none" start_char="9742" end_char="9747">should</TOKEN>
<TOKEN id="token-98-9" pos="word" morph="none" start_char="9749" end_char="9756">reliable</TOKEN>
<TOKEN id="token-98-10" pos="word" morph="none" start_char="9758" end_char="9765">evidence</TOKEN>
<TOKEN id="token-98-11" pos="word" morph="none" start_char="9767" end_char="9772">emerge</TOKEN>
<TOKEN id="token-98-12" pos="punct" morph="none" start_char="9773" end_char="9773">,</TOKEN>
<TOKEN id="token-98-13" pos="word" morph="none" start_char="9775" end_char="9778">many</TOKEN>
<TOKEN id="token-98-14" pos="word" morph="none" start_char="9780" end_char="9785">health</TOKEN>
<TOKEN id="token-98-15" pos="word" morph="none" start_char="9787" end_char="9797">authorities</TOKEN>
<TOKEN id="token-98-16" pos="punct" morph="none" start_char="9798" end_char="9798">,</TOKEN>
<TOKEN id="token-98-17" pos="word" morph="none" start_char="9800" end_char="9808">including</TOKEN>
<TOKEN id="token-98-18" pos="word" morph="none" start_char="9810" end_char="9812">the</TOKEN>
<TOKEN id="token-98-19" pos="word" morph="none" start_char="9814" end_char="9816">WHO</TOKEN>
<TOKEN id="token-98-20" pos="punct" morph="none" start_char="9817" end_char="9817">,</TOKEN>
<TOKEN id="token-98-21" pos="word" morph="none" start_char="9819" end_char="9823">don’t</TOKEN>
<TOKEN id="token-98-22" pos="word" morph="none" start_char="9825" end_char="9833">currently</TOKEN>
<TOKEN id="token-98-23" pos="word" morph="none" start_char="9835" end_char="9843">recommend</TOKEN>
<TOKEN id="token-98-24" pos="word" morph="none" start_char="9845" end_char="9854">ivermectin</TOKEN>
<TOKEN id="token-98-25" pos="word" morph="none" start_char="9856" end_char="9857">as</TOKEN>
<TOKEN id="token-98-26" pos="word" morph="none" start_char="9859" end_char="9859">a</TOKEN>
<TOKEN id="token-98-27" pos="unknown" morph="none" start_char="9861" end_char="9868">COVID-19</TOKEN>
<TOKEN id="token-98-28" pos="word" morph="none" start_char="9870" end_char="9878">treatment</TOKEN>
<TOKEN id="token-98-29" pos="word" morph="none" start_char="9880" end_char="9881">or</TOKEN>
<TOKEN id="token-98-30" pos="word" morph="none" start_char="9883" end_char="9894">preventative</TOKEN>
<TOKEN id="token-98-31" pos="word" morph="none" start_char="9896" end_char="9898">due</TOKEN>
<TOKEN id="token-98-32" pos="word" morph="none" start_char="9900" end_char="9901">to</TOKEN>
<TOKEN id="token-98-33" pos="word" morph="none" start_char="9903" end_char="9905">the</TOKEN>
<TOKEN id="token-98-34" pos="word" morph="none" start_char="9907" end_char="9910">lack</TOKEN>
<TOKEN id="token-98-35" pos="word" morph="none" start_char="9912" end_char="9913">of</TOKEN>
<TOKEN id="token-98-36" pos="word" morph="none" start_char="9915" end_char="9922">evidence</TOKEN>
<TOKEN id="token-98-37" pos="word" morph="none" start_char="9924" end_char="9933">supporting</TOKEN>
<TOKEN id="token-98-38" pos="word" morph="none" start_char="9935" end_char="9936">it</TOKEN>
<TOKEN id="token-98-39" pos="punct" morph="none" start_char="9937" end_char="9937">,</TOKEN>
<TOKEN id="token-98-40" pos="word" morph="none" start_char="9939" end_char="9944">except</TOKEN>
<TOKEN id="token-98-41" pos="word" morph="none" start_char="9946" end_char="9947">as</TOKEN>
<TOKEN id="token-98-42" pos="word" morph="none" start_char="9949" end_char="9952">part</TOKEN>
<TOKEN id="token-98-43" pos="word" morph="none" start_char="9954" end_char="9955">of</TOKEN>
<TOKEN id="token-98-44" pos="word" morph="none" start_char="9957" end_char="9964">clinical</TOKEN>
<TOKEN id="token-98-45" pos="word" morph="none" start_char="9966" end_char="9971">trials</TOKEN>
<TOKEN id="token-98-46" pos="word" morph="none" start_char="9973" end_char="9982">evaluating</TOKEN>
<TOKEN id="token-98-47" pos="word" morph="none" start_char="9984" end_char="9986">its</TOKEN>
<TOKEN id="token-98-48" pos="word" morph="none" start_char="9988" end_char="9995">efficacy</TOKEN>
<TOKEN id="token-98-49" pos="punct" morph="none" start_char="9996" end_char="9996">.</TOKEN>
</SEG>
<SEG id="segment-99" start_char="9999" end_char="10007">
<ORIGINAL_TEXT>READ MORE</ORIGINAL_TEXT>
<TOKEN id="token-99-0" pos="word" morph="none" start_char="9999" end_char="10002">READ</TOKEN>
<TOKEN id="token-99-1" pos="word" morph="none" start_char="10004" end_char="10007">MORE</TOKEN>
</SEG>
<SEG id="segment-100" start_char="10011" end_char="10128">
<ORIGINAL_TEXT>Scientist Hilda Bastian published several blog posts explaining how to interpret a meta-analysis here, here, and here.</ORIGINAL_TEXT>
<TOKEN id="token-100-0" pos="word" morph="none" start_char="10011" end_char="10019">Scientist</TOKEN>
<TOKEN id="token-100-1" pos="word" morph="none" start_char="10021" end_char="10025">Hilda</TOKEN>
<TOKEN id="token-100-2" pos="word" morph="none" start_char="10027" end_char="10033">Bastian</TOKEN>
<TOKEN id="token-100-3" pos="word" morph="none" start_char="10035" end_char="10043">published</TOKEN>
<TOKEN id="token-100-4" pos="word" morph="none" start_char="10045" end_char="10051">several</TOKEN>
<TOKEN id="token-100-5" pos="word" morph="none" start_char="10053" end_char="10056">blog</TOKEN>
<TOKEN id="token-100-6" pos="word" morph="none" start_char="10058" end_char="10062">posts</TOKEN>
<TOKEN id="token-100-7" pos="word" morph="none" start_char="10064" end_char="10073">explaining</TOKEN>
<TOKEN id="token-100-8" pos="word" morph="none" start_char="10075" end_char="10077">how</TOKEN>
<TOKEN id="token-100-9" pos="word" morph="none" start_char="10079" end_char="10080">to</TOKEN>
<TOKEN id="token-100-10" pos="word" morph="none" start_char="10082" end_char="10090">interpret</TOKEN>
<TOKEN id="token-100-11" pos="word" morph="none" start_char="10092" end_char="10092">a</TOKEN>
<TOKEN id="token-100-12" pos="unknown" morph="none" start_char="10094" end_char="10106">meta-analysis</TOKEN>
<TOKEN id="token-100-13" pos="word" morph="none" start_char="10108" end_char="10111">here</TOKEN>
<TOKEN id="token-100-14" pos="punct" morph="none" start_char="10112" end_char="10112">,</TOKEN>
<TOKEN id="token-100-15" pos="word" morph="none" start_char="10114" end_char="10117">here</TOKEN>
<TOKEN id="token-100-16" pos="punct" morph="none" start_char="10118" end_char="10118">,</TOKEN>
<TOKEN id="token-100-17" pos="word" morph="none" start_char="10120" end_char="10122">and</TOKEN>
<TOKEN id="token-100-18" pos="word" morph="none" start_char="10124" end_char="10127">here</TOKEN>
<TOKEN id="token-100-19" pos="punct" morph="none" start_char="10128" end_char="10128">.</TOKEN>
</SEG>
<SEG id="segment-101" start_char="10131" end_char="10140">
<ORIGINAL_TEXT>REFERENCES</ORIGINAL_TEXT>
<TOKEN id="token-101-0" pos="word" morph="none" start_char="10131" end_char="10140">REFERENCES</TOKEN>
</SEG>
<SEG id="segment-102" start_char="10145" end_char="10159">
<ORIGINAL_TEXT>1 – Caly et al.</ORIGINAL_TEXT>
<TOKEN id="token-102-0" pos="word" morph="none" start_char="10145" end_char="10145">1</TOKEN>
<TOKEN id="token-102-1" pos="punct" morph="none" start_char="10147" end_char="10147">–</TOKEN>
<TOKEN id="token-102-2" pos="word" morph="none" start_char="10149" end_char="10152">Caly</TOKEN>
<TOKEN id="token-102-3" pos="word" morph="none" start_char="10154" end_char="10155">et</TOKEN>
<TOKEN id="token-102-4" pos="word" morph="none" start_char="10157" end_char="10158">al</TOKEN>
<TOKEN id="token-102-5" pos="punct" morph="none" start_char="10159" end_char="10159">.</TOKEN>
</SEG>
<SEG id="segment-103" start_char="10161" end_char="10248">
<ORIGINAL_TEXT>(2020) The FDA-approved drug ivermectin inhibits the replication of SARS-CoV-2 in vitro.</ORIGINAL_TEXT>
<TOKEN id="token-103-0" pos="punct" morph="none" start_char="10161" end_char="10161">(</TOKEN>
<TOKEN id="token-103-1" pos="word" morph="none" start_char="10162" end_char="10165">2020</TOKEN>
<TOKEN id="token-103-2" pos="punct" morph="none" start_char="10166" end_char="10166">)</TOKEN>
<TOKEN id="token-103-3" pos="word" morph="none" start_char="10168" end_char="10170">The</TOKEN>
<TOKEN id="token-103-4" pos="unknown" morph="none" start_char="10172" end_char="10183">FDA-approved</TOKEN>
<TOKEN id="token-103-5" pos="word" morph="none" start_char="10185" end_char="10188">drug</TOKEN>
<TOKEN id="token-103-6" pos="word" morph="none" start_char="10190" end_char="10199">ivermectin</TOKEN>
<TOKEN id="token-103-7" pos="word" morph="none" start_char="10201" end_char="10208">inhibits</TOKEN>
<TOKEN id="token-103-8" pos="word" morph="none" start_char="10210" end_char="10212">the</TOKEN>
<TOKEN id="token-103-9" pos="word" morph="none" start_char="10214" end_char="10224">replication</TOKEN>
<TOKEN id="token-103-10" pos="word" morph="none" start_char="10226" end_char="10227">of</TOKEN>
<TOKEN id="token-103-11" pos="unknown" morph="none" start_char="10229" end_char="10238">SARS-CoV-2</TOKEN>
<TOKEN id="token-103-12" pos="word" morph="none" start_char="10240" end_char="10241">in</TOKEN>
<TOKEN id="token-103-13" pos="word" morph="none" start_char="10243" end_char="10247">vitro</TOKEN>
<TOKEN id="token-103-14" pos="punct" morph="none" start_char="10248" end_char="10248">.</TOKEN>
</SEG>
<SEG id="segment-104" start_char="10250" end_char="10268">
<ORIGINAL_TEXT>Antiviral Research.</ORIGINAL_TEXT>
<TOKEN id="token-104-0" pos="word" morph="none" start_char="10250" end_char="10258">Antiviral</TOKEN>
<TOKEN id="token-104-1" pos="word" morph="none" start_char="10260" end_char="10267">Research</TOKEN>
<TOKEN id="token-104-2" pos="punct" morph="none" start_char="10268" end_char="10268">.</TOKEN>
</SEG>
<SEG id="segment-105" start_char="10272" end_char="10290">
<ORIGINAL_TEXT>2 – Chaccour et al.</ORIGINAL_TEXT>
<TOKEN id="token-105-0" pos="word" morph="none" start_char="10272" end_char="10272">2</TOKEN>
<TOKEN id="token-105-1" pos="punct" morph="none" start_char="10274" end_char="10274">–</TOKEN>
<TOKEN id="token-105-2" pos="word" morph="none" start_char="10276" end_char="10283">Chaccour</TOKEN>
<TOKEN id="token-105-3" pos="word" morph="none" start_char="10285" end_char="10286">et</TOKEN>
<TOKEN id="token-105-4" pos="word" morph="none" start_char="10288" end_char="10289">al</TOKEN>
<TOKEN id="token-105-5" pos="punct" morph="none" start_char="10290" end_char="10290">.</TOKEN>
</SEG>
<SEG id="segment-106" start_char="10292" end_char="10357">
<ORIGINAL_TEXT>(2020) Ivermectin and COVID-19: Keeping Rigor in Times of Urgency.</ORIGINAL_TEXT>
<TOKEN id="token-106-0" pos="punct" morph="none" start_char="10292" end_char="10292">(</TOKEN>
<TOKEN id="token-106-1" pos="word" morph="none" start_char="10293" end_char="10296">2020</TOKEN>
<TOKEN id="token-106-2" pos="punct" morph="none" start_char="10297" end_char="10297">)</TOKEN>
<TOKEN id="token-106-3" pos="word" morph="none" start_char="10299" end_char="10308">Ivermectin</TOKEN>
<TOKEN id="token-106-4" pos="word" morph="none" start_char="10310" end_char="10312">and</TOKEN>
<TOKEN id="token-106-5" pos="unknown" morph="none" start_char="10314" end_char="10321">COVID-19</TOKEN>
<TOKEN id="token-106-6" pos="punct" morph="none" start_char="10322" end_char="10322">:</TOKEN>
<TOKEN id="token-106-7" pos="word" morph="none" start_char="10324" end_char="10330">Keeping</TOKEN>
<TOKEN id="token-106-8" pos="word" morph="none" start_char="10332" end_char="10336">Rigor</TOKEN>
<TOKEN id="token-106-9" pos="word" morph="none" start_char="10338" end_char="10339">in</TOKEN>
<TOKEN id="token-106-10" pos="word" morph="none" start_char="10341" end_char="10345">Times</TOKEN>
<TOKEN id="token-106-11" pos="word" morph="none" start_char="10347" end_char="10348">of</TOKEN>
<TOKEN id="token-106-12" pos="word" morph="none" start_char="10350" end_char="10356">Urgency</TOKEN>
<TOKEN id="token-106-13" pos="punct" morph="none" start_char="10357" end_char="10357">.</TOKEN>
</SEG>
<SEG id="segment-107" start_char="10359" end_char="10408">
<ORIGINAL_TEXT>American Journal of Tropical Medicine and Hygiene.</ORIGINAL_TEXT>
<TOKEN id="token-107-0" pos="word" morph="none" start_char="10359" end_char="10366">American</TOKEN>
<TOKEN id="token-107-1" pos="word" morph="none" start_char="10368" end_char="10374">Journal</TOKEN>
<TOKEN id="token-107-2" pos="word" morph="none" start_char="10376" end_char="10377">of</TOKEN>
<TOKEN id="token-107-3" pos="word" morph="none" start_char="10379" end_char="10386">Tropical</TOKEN>
<TOKEN id="token-107-4" pos="word" morph="none" start_char="10388" end_char="10395">Medicine</TOKEN>
<TOKEN id="token-107-5" pos="word" morph="none" start_char="10397" end_char="10399">and</TOKEN>
<TOKEN id="token-107-6" pos="word" morph="none" start_char="10401" end_char="10407">Hygiene</TOKEN>
<TOKEN id="token-107-7" pos="punct" morph="none" start_char="10408" end_char="10408">.</TOKEN>
</SEG>
<SEG id="segment-108" start_char="10412" end_char="10429">
<ORIGINAL_TEXT>3 – Higgins et al.</ORIGINAL_TEXT>
<TOKEN id="token-108-0" pos="word" morph="none" start_char="10412" end_char="10412">3</TOKEN>
<TOKEN id="token-108-1" pos="punct" morph="none" start_char="10414" end_char="10414">–</TOKEN>
<TOKEN id="token-108-2" pos="word" morph="none" start_char="10416" end_char="10422">Higgins</TOKEN>
<TOKEN id="token-108-3" pos="word" morph="none" start_char="10424" end_char="10425">et</TOKEN>
<TOKEN id="token-108-4" pos="word" morph="none" start_char="10427" end_char="10428">al</TOKEN>
<TOKEN id="token-108-5" pos="punct" morph="none" start_char="10429" end_char="10429">.</TOKEN>
</SEG>
<SEG id="segment-109" start_char="10431" end_char="10478">
<ORIGINAL_TEXT>(2003) Measuring inconsistency in meta-analyses.</ORIGINAL_TEXT>
<TOKEN id="token-109-0" pos="punct" morph="none" start_char="10431" end_char="10431">(</TOKEN>
<TOKEN id="token-109-1" pos="word" morph="none" start_char="10432" end_char="10435">2003</TOKEN>
<TOKEN id="token-109-2" pos="punct" morph="none" start_char="10436" end_char="10436">)</TOKEN>
<TOKEN id="token-109-3" pos="word" morph="none" start_char="10438" end_char="10446">Measuring</TOKEN>
<TOKEN id="token-109-4" pos="word" morph="none" start_char="10448" end_char="10460">inconsistency</TOKEN>
<TOKEN id="token-109-5" pos="word" morph="none" start_char="10462" end_char="10463">in</TOKEN>
<TOKEN id="token-109-6" pos="unknown" morph="none" start_char="10465" end_char="10477">meta-analyses</TOKEN>
<TOKEN id="token-109-7" pos="punct" morph="none" start_char="10478" end_char="10478">.</TOKEN>
</SEG>
<SEG id="segment-110" start_char="10480" end_char="10483">
<ORIGINAL_TEXT>BMJ.</ORIGINAL_TEXT>
<TOKEN id="token-110-0" pos="word" morph="none" start_char="10480" end_char="10482">BMJ</TOKEN>
<TOKEN id="token-110-1" pos="punct" morph="none" start_char="10483" end_char="10483">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
