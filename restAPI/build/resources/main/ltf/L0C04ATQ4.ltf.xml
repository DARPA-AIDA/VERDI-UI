<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATQ4" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="6242" raw_text_md5="1bdc36d88dd43de63f81ba4221be007f">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="80">
<ORIGINAL_TEXT>El coronavirus comenzó a circular en China en octubre de 2019, afirma un estudio</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="2">El</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="4" end_char="14">coronavirus</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="16" end_char="22">comenzó</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="24" end_char="24">a</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="26" end_char="33">circular</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="35" end_char="36">en</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="38" end_char="42">China</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="44" end_char="45">en</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="47" end_char="53">octubre</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="55" end_char="56">de</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="58" end_char="61">2019</TOKEN>
<TOKEN id="token-0-11" pos="punct" morph="none" start_char="62" end_char="62">,</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="64" end_char="69">afirma</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="71" end_char="72">un</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="74" end_char="80">estudio</TOKEN>
</SEG>
<SEG id="segment-1" start_char="85" end_char="211">
<ORIGINAL_TEXT>El coronavirus surgió en China ‘ya en octubre de 2019’, dos meses ANTES de los primeros casos diagnosticados, afirma un estudio</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="85" end_char="86">El</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="88" end_char="98">coronavirus</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="100" end_char="105">surgió</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="107" end_char="108">en</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="110" end_char="114">China</TOKEN>
<TOKEN id="token-1-5" pos="punct" morph="none" start_char="116" end_char="116">‘</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="117" end_char="118">ya</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="120" end_char="121">en</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="123" end_char="129">octubre</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="131" end_char="132">de</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="134" end_char="137">2019</TOKEN>
<TOKEN id="token-1-11" pos="punct" morph="none" start_char="138" end_char="139">’,</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="141" end_char="143">dos</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="145" end_char="149">meses</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="151" end_char="155">ANTES</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="157" end_char="158">de</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="160" end_char="162">los</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="164" end_char="171">primeros</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="173" end_char="177">casos</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="179" end_char="192">diagnosticados</TOKEN>
<TOKEN id="token-1-20" pos="punct" morph="none" start_char="193" end_char="193">,</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="195" end_char="200">afirma</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="202" end_char="203">un</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="205" end_char="211">estudio</TOKEN>
</SEG>
<SEG id="segment-2" start_char="216" end_char="304">
<ORIGINAL_TEXT>Los investigadores rastrearon los orígenes del SARS-CoV-2 en la provincia de Hubei, China</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="216" end_char="218">Los</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="220" end_char="233">investigadores</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="235" end_char="244">rastrearon</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="246" end_char="248">los</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="250" end_char="257">orígenes</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="259" end_char="261">del</TOKEN>
<TOKEN id="token-2-6" pos="unknown" morph="none" start_char="263" end_char="272">SARS-CoV-2</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="274" end_char="275">en</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="277" end_char="278">la</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="280" end_char="288">provincia</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="290" end_char="291">de</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="293" end_char="297">Hubei</TOKEN>
<TOKEN id="token-2-12" pos="punct" morph="none" start_char="298" end_char="298">,</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="300" end_char="304">China</TOKEN>
</SEG>
<SEG id="segment-3" start_char="308" end_char="388">
<ORIGINAL_TEXT>Encontrado el antepasado genético común de 583 casos se remonta al 9 de diciembre</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="308" end_char="317">Encontrado</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="319" end_char="320">el</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="322" end_char="331">antepasado</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="333" end_char="340">genético</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="342" end_char="346">común</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="348" end_char="349">de</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="351" end_char="353">583</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="355" end_char="359">casos</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="361" end_char="362">se</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="364" end_char="370">remonta</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="372" end_char="373">al</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="375" end_char="375">9</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="377" end_char="378">de</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="380" end_char="388">diciembre</TOKEN>
</SEG>
<SEG id="segment-4" start_char="392" end_char="494">
<ORIGINAL_TEXT>Pero los investigadores dicen que esto es de la cepa de coronavirus que primero se propagó rápidamente.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="392" end_char="395">Pero</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="397" end_char="399">los</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="401" end_char="414">investigadores</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="416" end_char="420">dicen</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="422" end_char="424">que</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="426" end_char="429">esto</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="431" end_char="432">es</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="434" end_char="435">de</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="437" end_char="438">la</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="440" end_char="443">cepa</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="445" end_char="446">de</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="448" end_char="458">coronavirus</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="460" end_char="462">que</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="464" end_char="470">primero</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="472" end_char="473">se</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="475" end_char="481">propagó</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="483" end_char="493">rápidamente</TOKEN>
<TOKEN id="token-4-17" pos="punct" morph="none" start_char="494" end_char="494">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="498" end_char="589">
<ORIGINAL_TEXT>El primer caso documentado de una versión más débil probablemente ocurrió el 17 de noviembre</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="498" end_char="499">El</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="501" end_char="506">primer</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="508" end_char="511">caso</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="513" end_char="523">documentado</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="525" end_char="526">de</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="528" end_char="530">una</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="532" end_char="538">versión</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="540" end_char="542">más</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="544" end_char="548">débil</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="550" end_char="562">probablemente</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="564" end_char="570">ocurrió</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="572" end_char="573">el</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="575" end_char="576">17</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="578" end_char="579">de</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="581" end_char="589">noviembre</TOKEN>
</SEG>
<SEG id="segment-6" start_char="593" end_char="704">
<ORIGINAL_TEXT>Al tener en cuenta un retraso en los informes, es probable que esta persona se haya infectado el 4 de noviembre.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="593" end_char="594">Al</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="596" end_char="600">tener</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="602" end_char="603">en</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="605" end_char="610">cuenta</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="612" end_char="613">un</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="615" end_char="621">retraso</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="623" end_char="624">en</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="626" end_char="628">los</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="630" end_char="637">informes</TOKEN>
<TOKEN id="token-6-9" pos="punct" morph="none" start_char="638" end_char="638">,</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="640" end_char="641">es</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="643" end_char="650">probable</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="652" end_char="654">que</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="656" end_char="659">esta</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="661" end_char="667">persona</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="669" end_char="670">se</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="672" end_char="675">haya</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="677" end_char="685">infectado</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="687" end_char="688">el</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="690" end_char="690">4</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="692" end_char="693">de</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="695" end_char="703">noviembre</TOKEN>
<TOKEN id="token-6-22" pos="punct" morph="none" start_char="704" end_char="704">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="708" end_char="799">
<ORIGINAL_TEXT>Pero los investigadores dicen que esta cifra podría ser confiable a partir del 7 de octubre.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="708" end_char="711">Pero</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="713" end_char="715">los</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="717" end_char="730">investigadores</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="732" end_char="736">dicen</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="738" end_char="740">que</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="742" end_char="745">esta</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="747" end_char="751">cifra</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="753" end_char="758">podría</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="760" end_char="762">ser</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="764" end_char="772">confiable</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="774" end_char="774">a</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="776" end_char="781">partir</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="783" end_char="785">del</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="787" end_char="787">7</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="789" end_char="790">de</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="792" end_char="798">octubre</TOKEN>
<TOKEN id="token-7-16" pos="punct" morph="none" start_char="799" end_char="799">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="804" end_char="964">
<ORIGINAL_TEXT>El primer caso de un humano infectado con SARS-CoV-2, el virus que causa el Covid-19, pudo haber ocurrido en la provincia china de Hubei el 7 de octubre de 2019.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="804" end_char="805">El</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="807" end_char="812">primer</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="814" end_char="817">caso</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="819" end_char="820">de</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="822" end_char="823">un</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="825" end_char="830">humano</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="832" end_char="840">infectado</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="842" end_char="844">con</TOKEN>
<TOKEN id="token-8-8" pos="unknown" morph="none" start_char="846" end_char="855">SARS-CoV-2</TOKEN>
<TOKEN id="token-8-9" pos="punct" morph="none" start_char="856" end_char="856">,</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="858" end_char="859">el</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="861" end_char="865">virus</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="867" end_char="869">que</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="871" end_char="875">causa</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="877" end_char="878">el</TOKEN>
<TOKEN id="token-8-15" pos="unknown" morph="none" start_char="880" end_char="887">Covid-19</TOKEN>
<TOKEN id="token-8-16" pos="punct" morph="none" start_char="888" end_char="888">,</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="890" end_char="893">pudo</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="895" end_char="899">haber</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="901" end_char="908">ocurrido</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="910" end_char="911">en</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="913" end_char="914">la</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="916" end_char="924">provincia</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="926" end_char="930">china</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="932" end_char="933">de</TOKEN>
<TOKEN id="token-8-25" pos="word" morph="none" start_char="935" end_char="939">Hubei</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="941" end_char="942">el</TOKEN>
<TOKEN id="token-8-27" pos="word" morph="none" start_char="944" end_char="944">7</TOKEN>
<TOKEN id="token-8-28" pos="word" morph="none" start_char="946" end_char="947">de</TOKEN>
<TOKEN id="token-8-29" pos="word" morph="none" start_char="949" end_char="955">octubre</TOKEN>
<TOKEN id="token-8-30" pos="word" morph="none" start_char="957" end_char="958">de</TOKEN>
<TOKEN id="token-8-31" pos="word" morph="none" start_char="960" end_char="963">2019</TOKEN>
<TOKEN id="token-8-32" pos="punct" morph="none" start_char="964" end_char="964">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="967" end_char="1117">
<ORIGINAL_TEXT>Solo a mediados de diciembre, dos meses después, se describieron oficialmente los primeros casos en Wuhan en el ahora notorio mercado húmedo de Huanan.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="967" end_char="970">Solo</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="972" end_char="972">a</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="974" end_char="981">mediados</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="983" end_char="984">de</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="986" end_char="994">diciembre</TOKEN>
<TOKEN id="token-9-5" pos="punct" morph="none" start_char="995" end_char="995">,</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="997" end_char="999">dos</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1001" end_char="1005">meses</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1007" end_char="1013">después</TOKEN>
<TOKEN id="token-9-9" pos="punct" morph="none" start_char="1014" end_char="1014">,</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1016" end_char="1017">se</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1019" end_char="1030">describieron</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1032" end_char="1043">oficialmente</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1045" end_char="1047">los</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1049" end_char="1056">primeros</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1058" end_char="1062">casos</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1064" end_char="1065">en</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1067" end_char="1071">Wuhan</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1073" end_char="1074">en</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1076" end_char="1077">el</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1079" end_char="1083">ahora</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1085" end_char="1091">notorio</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1093" end_char="1099">mercado</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1101" end_char="1106">húmedo</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1108" end_char="1109">de</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1111" end_char="1116">Huanan</TOKEN>
<TOKEN id="token-9-26" pos="punct" morph="none" start_char="1117" end_char="1117">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1120" end_char="1382">
<ORIGINAL_TEXT>Un nuevo análisis de la propagación del virus y su ‘reloj molecular’ reveló que probablemente ya estaba establecido en Wuhan en este punto y había estado circulando en Hubei en niveles bajos a principios de noviembre de 2019, y posiblemente a mediados de octubre.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1120" end_char="1121">Un</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1123" end_char="1127">nuevo</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1129" end_char="1136">análisis</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1138" end_char="1139">de</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1141" end_char="1142">la</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1144" end_char="1154">propagación</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1156" end_char="1158">del</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1160" end_char="1164">virus</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1166" end_char="1166">y</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1168" end_char="1169">su</TOKEN>
<TOKEN id="token-10-10" pos="punct" morph="none" start_char="1171" end_char="1171">‘</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1172" end_char="1176">reloj</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1178" end_char="1186">molecular</TOKEN>
<TOKEN id="token-10-13" pos="punct" morph="none" start_char="1187" end_char="1187">’</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1189" end_char="1194">reveló</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1196" end_char="1198">que</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1200" end_char="1212">probablemente</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1214" end_char="1215">ya</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1217" end_char="1222">estaba</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1224" end_char="1234">establecido</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1236" end_char="1237">en</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1239" end_char="1243">Wuhan</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1245" end_char="1246">en</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1248" end_char="1251">este</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1253" end_char="1257">punto</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="1259" end_char="1259">y</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="1261" end_char="1265">había</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="1267" end_char="1272">estado</TOKEN>
<TOKEN id="token-10-28" pos="word" morph="none" start_char="1274" end_char="1283">circulando</TOKEN>
<TOKEN id="token-10-29" pos="word" morph="none" start_char="1285" end_char="1286">en</TOKEN>
<TOKEN id="token-10-30" pos="word" morph="none" start_char="1288" end_char="1292">Hubei</TOKEN>
<TOKEN id="token-10-31" pos="word" morph="none" start_char="1294" end_char="1295">en</TOKEN>
<TOKEN id="token-10-32" pos="word" morph="none" start_char="1297" end_char="1303">niveles</TOKEN>
<TOKEN id="token-10-33" pos="word" morph="none" start_char="1305" end_char="1309">bajos</TOKEN>
<TOKEN id="token-10-34" pos="word" morph="none" start_char="1311" end_char="1311">a</TOKEN>
<TOKEN id="token-10-35" pos="word" morph="none" start_char="1313" end_char="1322">principios</TOKEN>
<TOKEN id="token-10-36" pos="word" morph="none" start_char="1324" end_char="1325">de</TOKEN>
<TOKEN id="token-10-37" pos="word" morph="none" start_char="1327" end_char="1335">noviembre</TOKEN>
<TOKEN id="token-10-38" pos="word" morph="none" start_char="1337" end_char="1338">de</TOKEN>
<TOKEN id="token-10-39" pos="word" morph="none" start_char="1340" end_char="1343">2019</TOKEN>
<TOKEN id="token-10-40" pos="punct" morph="none" start_char="1344" end_char="1344">,</TOKEN>
<TOKEN id="token-10-41" pos="word" morph="none" start_char="1346" end_char="1346">y</TOKEN>
<TOKEN id="token-10-42" pos="word" morph="none" start_char="1348" end_char="1359">posiblemente</TOKEN>
<TOKEN id="token-10-43" pos="word" morph="none" start_char="1361" end_char="1361">a</TOKEN>
<TOKEN id="token-10-44" pos="word" morph="none" start_char="1363" end_char="1370">mediados</TOKEN>
<TOKEN id="token-10-45" pos="word" morph="none" start_char="1372" end_char="1373">de</TOKEN>
<TOKEN id="token-10-46" pos="word" morph="none" start_char="1375" end_char="1381">octubre</TOKEN>
<TOKEN id="token-10-47" pos="punct" morph="none" start_char="1382" end_char="1382">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1385" end_char="1424">
<ORIGINAL_TEXT>Desplácese hacia abajo para ver el video</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1385" end_char="1394">Desplácese</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1396" end_char="1400">hacia</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1402" end_char="1406">abajo</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1408" end_char="1411">para</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1413" end_char="1415">ver</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1417" end_char="1418">el</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1420" end_char="1424">video</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1427" end_char="1562">
<ORIGINAL_TEXT>Pero debido a los nuevos síntomas de Covid-19 y a una cantidad inicialmente pequeña de infecciones, fue difícil identificar el patógeno.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1427" end_char="1430">Pero</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1432" end_char="1437">debido</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1439" end_char="1439">a</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1441" end_char="1443">los</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1445" end_char="1450">nuevos</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1452" end_char="1459">síntomas</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1461" end_char="1462">de</TOKEN>
<TOKEN id="token-12-7" pos="unknown" morph="none" start_char="1464" end_char="1471">Covid-19</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1473" end_char="1473">y</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1475" end_char="1475">a</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1477" end_char="1479">una</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1481" end_char="1488">cantidad</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1490" end_char="1501">inicialmente</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1503" end_char="1509">pequeña</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1511" end_char="1512">de</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1514" end_char="1524">infecciones</TOKEN>
<TOKEN id="token-12-16" pos="punct" morph="none" start_char="1525" end_char="1525">,</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1527" end_char="1529">fue</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1531" end_char="1537">difícil</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1539" end_char="1549">identificar</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1551" end_char="1552">el</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1554" end_char="1561">patógeno</TOKEN>
<TOKEN id="token-12-22" pos="punct" morph="none" start_char="1562" end_char="1562">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1565" end_char="1745">
<ORIGINAL_TEXT>Como resultado, el virus solo llamó la atención de las autoridades cuando en diciembre se observó un grupo de síntomas misteriosos relacionados con el mercado de mariscos de Huanan.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1565" end_char="1568">Como</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1570" end_char="1578">resultado</TOKEN>
<TOKEN id="token-13-2" pos="punct" morph="none" start_char="1579" end_char="1579">,</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1581" end_char="1582">el</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1584" end_char="1588">virus</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1590" end_char="1593">solo</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1595" end_char="1599">llamó</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1601" end_char="1602">la</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1604" end_char="1611">atención</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1613" end_char="1614">de</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1616" end_char="1618">las</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1620" end_char="1630">autoridades</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1632" end_char="1637">cuando</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1639" end_char="1640">en</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1642" end_char="1650">diciembre</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1652" end_char="1653">se</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1655" end_char="1661">observó</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1663" end_char="1664">un</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1666" end_char="1670">grupo</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1672" end_char="1673">de</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1675" end_char="1682">síntomas</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="1684" end_char="1694">misteriosos</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="1696" end_char="1707">relacionados</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="1709" end_char="1711">con</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="1713" end_char="1714">el</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="1716" end_char="1722">mercado</TOKEN>
<TOKEN id="token-13-26" pos="word" morph="none" start_char="1724" end_char="1725">de</TOKEN>
<TOKEN id="token-13-27" pos="word" morph="none" start_char="1727" end_char="1734">mariscos</TOKEN>
<TOKEN id="token-13-28" pos="word" morph="none" start_char="1736" end_char="1737">de</TOKEN>
<TOKEN id="token-13-29" pos="word" morph="none" start_char="1739" end_char="1744">Huanan</TOKEN>
<TOKEN id="token-13-30" pos="punct" morph="none" start_char="1745" end_char="1745">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1748" end_char="1913">
<ORIGINAL_TEXT>Esto llevó a la teoría ahora desacreditada de que el mercado húmedo, donde se vende una amplia variedad de animales vivos y muertos, fue donde se originó la pandemia.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1748" end_char="1751">Esto</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1753" end_char="1757">llevó</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1759" end_char="1759">a</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1761" end_char="1762">la</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1764" end_char="1769">teoría</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1771" end_char="1775">ahora</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1777" end_char="1789">desacreditada</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1791" end_char="1792">de</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1794" end_char="1796">que</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1798" end_char="1799">el</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1801" end_char="1807">mercado</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1809" end_char="1814">húmedo</TOKEN>
<TOKEN id="token-14-12" pos="punct" morph="none" start_char="1815" end_char="1815">,</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1817" end_char="1821">donde</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="1823" end_char="1824">se</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1826" end_char="1830">vende</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1832" end_char="1834">una</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="1836" end_char="1841">amplia</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="1843" end_char="1850">variedad</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="1852" end_char="1853">de</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="1855" end_char="1862">animales</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="1864" end_char="1868">vivos</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="1870" end_char="1870">y</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="1872" end_char="1878">muertos</TOKEN>
<TOKEN id="token-14-24" pos="punct" morph="none" start_char="1879" end_char="1879">,</TOKEN>
<TOKEN id="token-14-25" pos="word" morph="none" start_char="1881" end_char="1883">fue</TOKEN>
<TOKEN id="token-14-26" pos="word" morph="none" start_char="1885" end_char="1889">donde</TOKEN>
<TOKEN id="token-14-27" pos="word" morph="none" start_char="1891" end_char="1892">se</TOKEN>
<TOKEN id="token-14-28" pos="word" morph="none" start_char="1894" end_char="1900">originó</TOKEN>
<TOKEN id="token-14-29" pos="word" morph="none" start_char="1902" end_char="1903">la</TOKEN>
<TOKEN id="token-14-30" pos="word" morph="none" start_char="1905" end_char="1912">pandemia</TOKEN>
<TOKEN id="token-14-31" pos="punct" morph="none" start_char="1913" end_char="1913">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1916" end_char="2060">
<ORIGINAL_TEXT>El Dr. Jonathan Pekar de la Universidad de California en San Diego realizó un estudio matemático para determinar cuándo y dónde surgió realmente.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1916" end_char="1917">El</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1919" end_char="1920">Dr</TOKEN>
<TOKEN id="token-15-2" pos="punct" morph="none" start_char="1921" end_char="1921">.</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1923" end_char="1930">Jonathan</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1932" end_char="1936">Pekar</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1938" end_char="1939">de</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1941" end_char="1942">la</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1944" end_char="1954">Universidad</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1956" end_char="1957">de</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1959" end_char="1968">California</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1970" end_char="1971">en</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1973" end_char="1975">San</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1977" end_char="1981">Diego</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1983" end_char="1989">realizó</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1991" end_char="1992">un</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="1994" end_char="2000">estudio</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="2002" end_char="2011">matemático</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="2013" end_char="2016">para</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="2018" end_char="2027">determinar</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="2029" end_char="2034">cuándo</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="2036" end_char="2036">y</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="2038" end_char="2042">dónde</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="2044" end_char="2049">surgió</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="2051" end_char="2059">realmente</TOKEN>
<TOKEN id="token-15-24" pos="punct" morph="none" start_char="2060" end_char="2060">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="2064" end_char="2264">
<ORIGINAL_TEXT>‘En nuestro análisis principal, asumimos que el 17 de noviembre [thick dotted line] representa el primer caso documentado de Covid-19 ‘, escriben los investigadores en su estudio, publicado en Science.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="punct" morph="none" start_char="2064" end_char="2064">‘</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="2065" end_char="2066">En</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="2068" end_char="2074">nuestro</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="2076" end_char="2083">análisis</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="2085" end_char="2093">principal</TOKEN>
<TOKEN id="token-16-5" pos="punct" morph="none" start_char="2094" end_char="2094">,</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="2096" end_char="2103">asumimos</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="2105" end_char="2107">que</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="2109" end_char="2110">el</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="2112" end_char="2113">17</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="2115" end_char="2116">de</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="2118" end_char="2126">noviembre</TOKEN>
<TOKEN id="token-16-12" pos="punct" morph="none" start_char="2128" end_char="2128">[</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="2129" end_char="2133">thick</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="2135" end_char="2140">dotted</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="2142" end_char="2145">line</TOKEN>
<TOKEN id="token-16-16" pos="punct" morph="none" start_char="2146" end_char="2146">]</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="2148" end_char="2157">representa</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="2159" end_char="2160">el</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="2162" end_char="2167">primer</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="2169" end_char="2172">caso</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="2174" end_char="2184">documentado</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="2186" end_char="2187">de</TOKEN>
<TOKEN id="token-16-23" pos="unknown" morph="none" start_char="2189" end_char="2196">Covid-19</TOKEN>
<TOKEN id="token-16-24" pos="punct" morph="none" start_char="2198" end_char="2199">‘,</TOKEN>
<TOKEN id="token-16-25" pos="word" morph="none" start_char="2201" end_char="2208">escriben</TOKEN>
<TOKEN id="token-16-26" pos="word" morph="none" start_char="2210" end_char="2212">los</TOKEN>
<TOKEN id="token-16-27" pos="word" morph="none" start_char="2214" end_char="2227">investigadores</TOKEN>
<TOKEN id="token-16-28" pos="word" morph="none" start_char="2229" end_char="2230">en</TOKEN>
<TOKEN id="token-16-29" pos="word" morph="none" start_char="2232" end_char="2233">su</TOKEN>
<TOKEN id="token-16-30" pos="word" morph="none" start_char="2235" end_char="2241">estudio</TOKEN>
<TOKEN id="token-16-31" pos="punct" morph="none" start_char="2242" end_char="2242">,</TOKEN>
<TOKEN id="token-16-32" pos="word" morph="none" start_char="2244" end_char="2252">publicado</TOKEN>
<TOKEN id="token-16-33" pos="word" morph="none" start_char="2254" end_char="2255">en</TOKEN>
<TOKEN id="token-16-34" pos="word" morph="none" start_char="2257" end_char="2263">Science</TOKEN>
<TOKEN id="token-16-35" pos="punct" morph="none" start_char="2264" end_char="2264">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2266" end_char="2325">
<ORIGINAL_TEXT>Llevaron a cabo un análisis más detallado bajo este supuesto</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2266" end_char="2273">Llevaron</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2275" end_char="2275">a</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2277" end_char="2280">cabo</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2282" end_char="2283">un</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2285" end_char="2292">análisis</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2294" end_char="2296">más</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2298" end_char="2306">detallado</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2308" end_char="2311">bajo</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2313" end_char="2316">este</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2318" end_char="2325">supuesto</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2329" end_char="2481">
<ORIGINAL_TEXT>Los investigadores creen que la fecha del 17 de noviembre [dashed line] fue la primera infección de la cepa SARS-CoV-2 que se extendió por todo el mundo.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2329" end_char="2331">Los</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2333" end_char="2346">investigadores</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2348" end_char="2352">creen</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2354" end_char="2356">que</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2358" end_char="2359">la</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2361" end_char="2365">fecha</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2367" end_char="2369">del</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2371" end_char="2372">17</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2374" end_char="2375">de</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="2377" end_char="2385">noviembre</TOKEN>
<TOKEN id="token-18-10" pos="punct" morph="none" start_char="2387" end_char="2387">[</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="2388" end_char="2393">dashed</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2395" end_char="2398">line</TOKEN>
<TOKEN id="token-18-13" pos="punct" morph="none" start_char="2399" end_char="2399">]</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="2401" end_char="2403">fue</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="2405" end_char="2406">la</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="2408" end_char="2414">primera</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="2416" end_char="2424">infección</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="2426" end_char="2427">de</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="2429" end_char="2430">la</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="2432" end_char="2435">cepa</TOKEN>
<TOKEN id="token-18-21" pos="unknown" morph="none" start_char="2437" end_char="2446">SARS-CoV-2</TOKEN>
<TOKEN id="token-18-22" pos="word" morph="none" start_char="2448" end_char="2450">que</TOKEN>
<TOKEN id="token-18-23" pos="word" morph="none" start_char="2452" end_char="2453">se</TOKEN>
<TOKEN id="token-18-24" pos="word" morph="none" start_char="2455" end_char="2462">extendió</TOKEN>
<TOKEN id="token-18-25" pos="word" morph="none" start_char="2464" end_char="2466">por</TOKEN>
<TOKEN id="token-18-26" pos="word" morph="none" start_char="2468" end_char="2471">todo</TOKEN>
<TOKEN id="token-18-27" pos="word" morph="none" start_char="2473" end_char="2474">el</TOKEN>
<TOKEN id="token-18-28" pos="word" morph="none" start_char="2476" end_char="2480">mundo</TOKEN>
<TOKEN id="token-18-29" pos="punct" morph="none" start_char="2481" end_char="2481">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2483" end_char="2608">
<ORIGINAL_TEXT>Pero es probable que existiera una versión más débil de antemano y es esta la que primero saltó de los animales a los humanos.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2483" end_char="2486">Pero</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2488" end_char="2489">es</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2491" end_char="2498">probable</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2500" end_char="2502">que</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2504" end_char="2512">existiera</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2514" end_char="2516">una</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2518" end_char="2524">versión</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2526" end_char="2528">más</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2530" end_char="2534">débil</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="2536" end_char="2537">de</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="2539" end_char="2546">antemano</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="2548" end_char="2548">y</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="2550" end_char="2551">es</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="2553" end_char="2556">esta</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="2558" end_char="2559">la</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="2561" end_char="2563">que</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="2565" end_char="2571">primero</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="2573" end_char="2577">saltó</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="2579" end_char="2580">de</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="2582" end_char="2584">los</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="2586" end_char="2593">animales</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="2595" end_char="2595">a</TOKEN>
<TOKEN id="token-19-22" pos="word" morph="none" start_char="2597" end_char="2599">los</TOKEN>
<TOKEN id="token-19-23" pos="word" morph="none" start_char="2601" end_char="2607">humanos</TOKEN>
<TOKEN id="token-19-24" pos="punct" morph="none" start_char="2608" end_char="2608">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2610" end_char="2722">
<ORIGINAL_TEXT>Creen que esta infección transespecífica podría haber ocurrido ya el 7 de octubre (inicio de la pendiente rosada)</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2610" end_char="2614">Creen</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2616" end_char="2618">que</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2620" end_char="2623">esta</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2625" end_char="2633">infección</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2635" end_char="2649">transespecífica</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2651" end_char="2656">podría</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2658" end_char="2662">haber</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2664" end_char="2671">ocurrido</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="2673" end_char="2674">ya</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2676" end_char="2677">el</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2679" end_char="2679">7</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="2681" end_char="2682">de</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="2684" end_char="2690">octubre</TOKEN>
<TOKEN id="token-20-13" pos="punct" morph="none" start_char="2692" end_char="2692">(</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="2693" end_char="2698">inicio</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="2700" end_char="2701">de</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="2703" end_char="2704">la</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="2706" end_char="2714">pendiente</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="2716" end_char="2721">rosada</TOKEN>
<TOKEN id="token-20-19" pos="punct" morph="none" start_char="2722" end_char="2722">)</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2725" end_char="2815">
<ORIGINAL_TEXT>La teoría del laboratorio de Wuhan es ABANDONADA por el equipo conjunto de la OMS y Beijing</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2725" end_char="2726">La</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2728" end_char="2733">teoría</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2735" end_char="2737">del</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2739" end_char="2749">laboratorio</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2751" end_char="2752">de</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="2754" end_char="2758">Wuhan</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2760" end_char="2761">es</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="2763" end_char="2772">ABANDONADA</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="2774" end_char="2776">por</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="2778" end_char="2779">el</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="2781" end_char="2786">equipo</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="2788" end_char="2795">conjunto</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="2797" end_char="2798">de</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="2800" end_char="2801">la</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="2803" end_char="2805">OMS</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="2807" end_char="2807">y</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="2809" end_char="2815">Beijing</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2819" end_char="2996">
<ORIGINAL_TEXT>La teoría de que Covid-19 se filtró de un laboratorio de Wuhan ha sido abandonada por los expertos de la OMS que investigan los orígenes de la pandemia, dice un científico chino.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2819" end_char="2820">La</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2822" end_char="2827">teoría</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2829" end_char="2830">de</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2832" end_char="2834">que</TOKEN>
<TOKEN id="token-22-4" pos="unknown" morph="none" start_char="2836" end_char="2843">Covid-19</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2845" end_char="2846">se</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2848" end_char="2853">filtró</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2855" end_char="2856">de</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="2858" end_char="2859">un</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="2861" end_char="2871">laboratorio</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="2873" end_char="2874">de</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="2876" end_char="2880">Wuhan</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="2882" end_char="2883">ha</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="2885" end_char="2888">sido</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="2890" end_char="2899">abandonada</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="2901" end_char="2903">por</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="2905" end_char="2907">los</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="2909" end_char="2916">expertos</TOKEN>
<TOKEN id="token-22-18" pos="word" morph="none" start_char="2918" end_char="2919">de</TOKEN>
<TOKEN id="token-22-19" pos="word" morph="none" start_char="2921" end_char="2922">la</TOKEN>
<TOKEN id="token-22-20" pos="word" morph="none" start_char="2924" end_char="2926">OMS</TOKEN>
<TOKEN id="token-22-21" pos="word" morph="none" start_char="2928" end_char="2930">que</TOKEN>
<TOKEN id="token-22-22" pos="word" morph="none" start_char="2932" end_char="2941">investigan</TOKEN>
<TOKEN id="token-22-23" pos="word" morph="none" start_char="2943" end_char="2945">los</TOKEN>
<TOKEN id="token-22-24" pos="word" morph="none" start_char="2947" end_char="2954">orígenes</TOKEN>
<TOKEN id="token-22-25" pos="word" morph="none" start_char="2956" end_char="2957">de</TOKEN>
<TOKEN id="token-22-26" pos="word" morph="none" start_char="2959" end_char="2960">la</TOKEN>
<TOKEN id="token-22-27" pos="word" morph="none" start_char="2962" end_char="2969">pandemia</TOKEN>
<TOKEN id="token-22-28" pos="punct" morph="none" start_char="2970" end_char="2970">,</TOKEN>
<TOKEN id="token-22-29" pos="word" morph="none" start_char="2972" end_char="2975">dice</TOKEN>
<TOKEN id="token-22-30" pos="word" morph="none" start_char="2977" end_char="2978">un</TOKEN>
<TOKEN id="token-22-31" pos="word" morph="none" start_char="2980" end_char="2989">científico</TOKEN>
<TOKEN id="token-22-32" pos="word" morph="none" start_char="2991" end_char="2995">chino</TOKEN>
<TOKEN id="token-22-33" pos="punct" morph="none" start_char="2996" end_char="2996">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2999" end_char="3197">
<ORIGINAL_TEXT>El panel conjunto OMS-Beijing debe emitir su informe políticamente sensible la próxima semana luego de una visita a Wuhan en enero y febrero, que generó más preguntas sobre la transparencia de China.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2999" end_char="3000">El</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="3002" end_char="3006">panel</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="3008" end_char="3015">conjunto</TOKEN>
<TOKEN id="token-23-3" pos="unknown" morph="none" start_char="3017" end_char="3027">OMS-Beijing</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="3029" end_char="3032">debe</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="3034" end_char="3039">emitir</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="3041" end_char="3042">su</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="3044" end_char="3050">informe</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="3052" end_char="3064">políticamente</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="3066" end_char="3073">sensible</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="3075" end_char="3076">la</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="3078" end_char="3084">próxima</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="3086" end_char="3091">semana</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="3093" end_char="3097">luego</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="3099" end_char="3100">de</TOKEN>
<TOKEN id="token-23-15" pos="word" morph="none" start_char="3102" end_char="3104">una</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="3106" end_char="3111">visita</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="3113" end_char="3113">a</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="3115" end_char="3119">Wuhan</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="3121" end_char="3122">en</TOKEN>
<TOKEN id="token-23-20" pos="word" morph="none" start_char="3124" end_char="3128">enero</TOKEN>
<TOKEN id="token-23-21" pos="word" morph="none" start_char="3130" end_char="3130">y</TOKEN>
<TOKEN id="token-23-22" pos="word" morph="none" start_char="3132" end_char="3138">febrero</TOKEN>
<TOKEN id="token-23-23" pos="punct" morph="none" start_char="3139" end_char="3139">,</TOKEN>
<TOKEN id="token-23-24" pos="word" morph="none" start_char="3141" end_char="3143">que</TOKEN>
<TOKEN id="token-23-25" pos="word" morph="none" start_char="3145" end_char="3150">generó</TOKEN>
<TOKEN id="token-23-26" pos="word" morph="none" start_char="3152" end_char="3154">más</TOKEN>
<TOKEN id="token-23-27" pos="word" morph="none" start_char="3156" end_char="3164">preguntas</TOKEN>
<TOKEN id="token-23-28" pos="word" morph="none" start_char="3166" end_char="3170">sobre</TOKEN>
<TOKEN id="token-23-29" pos="word" morph="none" start_char="3172" end_char="3173">la</TOKEN>
<TOKEN id="token-23-30" pos="word" morph="none" start_char="3175" end_char="3187">transparencia</TOKEN>
<TOKEN id="token-23-31" pos="word" morph="none" start_char="3189" end_char="3190">de</TOKEN>
<TOKEN id="token-23-32" pos="word" morph="none" start_char="3192" end_char="3196">China</TOKEN>
<TOKEN id="token-23-33" pos="punct" morph="none" start_char="3197" end_char="3197">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="3200" end_char="3444">
<ORIGINAL_TEXT>La OMS dice que el informe aún no está terminado, pero Liang Wannian, el jefe del ala china del panel, dijo a los medios estatales que la teoría de la fuga de laboratorio se había considerado «extremadamente improbable» y no se investigaría más.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="3200" end_char="3201">La</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="3203" end_char="3205">OMS</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="3207" end_char="3210">dice</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="3212" end_char="3214">que</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="3216" end_char="3217">el</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="3219" end_char="3225">informe</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="3227" end_char="3229">aún</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="3231" end_char="3232">no</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="3234" end_char="3237">está</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="3239" end_char="3247">terminado</TOKEN>
<TOKEN id="token-24-10" pos="punct" morph="none" start_char="3248" end_char="3248">,</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="3250" end_char="3253">pero</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="3255" end_char="3259">Liang</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="3261" end_char="3267">Wannian</TOKEN>
<TOKEN id="token-24-14" pos="punct" morph="none" start_char="3268" end_char="3268">,</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="3270" end_char="3271">el</TOKEN>
<TOKEN id="token-24-16" pos="word" morph="none" start_char="3273" end_char="3276">jefe</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="3278" end_char="3280">del</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="3282" end_char="3284">ala</TOKEN>
<TOKEN id="token-24-19" pos="word" morph="none" start_char="3286" end_char="3290">china</TOKEN>
<TOKEN id="token-24-20" pos="word" morph="none" start_char="3292" end_char="3294">del</TOKEN>
<TOKEN id="token-24-21" pos="word" morph="none" start_char="3296" end_char="3300">panel</TOKEN>
<TOKEN id="token-24-22" pos="punct" morph="none" start_char="3301" end_char="3301">,</TOKEN>
<TOKEN id="token-24-23" pos="word" morph="none" start_char="3303" end_char="3306">dijo</TOKEN>
<TOKEN id="token-24-24" pos="word" morph="none" start_char="3308" end_char="3308">a</TOKEN>
<TOKEN id="token-24-25" pos="word" morph="none" start_char="3310" end_char="3312">los</TOKEN>
<TOKEN id="token-24-26" pos="word" morph="none" start_char="3314" end_char="3319">medios</TOKEN>
<TOKEN id="token-24-27" pos="word" morph="none" start_char="3321" end_char="3329">estatales</TOKEN>
<TOKEN id="token-24-28" pos="word" morph="none" start_char="3331" end_char="3333">que</TOKEN>
<TOKEN id="token-24-29" pos="word" morph="none" start_char="3335" end_char="3336">la</TOKEN>
<TOKEN id="token-24-30" pos="word" morph="none" start_char="3338" end_char="3343">teoría</TOKEN>
<TOKEN id="token-24-31" pos="word" morph="none" start_char="3345" end_char="3346">de</TOKEN>
<TOKEN id="token-24-32" pos="word" morph="none" start_char="3348" end_char="3349">la</TOKEN>
<TOKEN id="token-24-33" pos="word" morph="none" start_char="3351" end_char="3354">fuga</TOKEN>
<TOKEN id="token-24-34" pos="word" morph="none" start_char="3356" end_char="3357">de</TOKEN>
<TOKEN id="token-24-35" pos="word" morph="none" start_char="3359" end_char="3369">laboratorio</TOKEN>
<TOKEN id="token-24-36" pos="word" morph="none" start_char="3371" end_char="3372">se</TOKEN>
<TOKEN id="token-24-37" pos="word" morph="none" start_char="3374" end_char="3378">había</TOKEN>
<TOKEN id="token-24-38" pos="word" morph="none" start_char="3380" end_char="3390">considerado</TOKEN>
<TOKEN id="token-24-39" pos="punct" morph="none" start_char="3392" end_char="3392">«</TOKEN>
<TOKEN id="token-24-40" pos="word" morph="none" start_char="3393" end_char="3406">extremadamente</TOKEN>
<TOKEN id="token-24-41" pos="word" morph="none" start_char="3408" end_char="3417">improbable</TOKEN>
<TOKEN id="token-24-42" pos="punct" morph="none" start_char="3418" end_char="3418">»</TOKEN>
<TOKEN id="token-24-43" pos="word" morph="none" start_char="3420" end_char="3420">y</TOKEN>
<TOKEN id="token-24-44" pos="word" morph="none" start_char="3422" end_char="3423">no</TOKEN>
<TOKEN id="token-24-45" pos="word" morph="none" start_char="3425" end_char="3426">se</TOKEN>
<TOKEN id="token-24-46" pos="word" morph="none" start_char="3428" end_char="3439">investigaría</TOKEN>
<TOKEN id="token-24-47" pos="word" morph="none" start_char="3441" end_char="3443">más</TOKEN>
<TOKEN id="token-24-48" pos="punct" morph="none" start_char="3444" end_char="3444">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="3447" end_char="3581">
<ORIGINAL_TEXT>«Las futuras misiones de rastreo del origen de los virus ya no se centrarán en esta área, a menos que haya nuevas pruebas», dijo Liang.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="punct" morph="none" start_char="3447" end_char="3447">«</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="3448" end_char="3450">Las</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="3452" end_char="3458">futuras</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="3460" end_char="3467">misiones</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="3469" end_char="3470">de</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="3472" end_char="3478">rastreo</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="3480" end_char="3482">del</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="3484" end_char="3489">origen</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="3491" end_char="3492">de</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="3494" end_char="3496">los</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="3498" end_char="3502">virus</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="3504" end_char="3505">ya</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="3507" end_char="3508">no</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="3510" end_char="3511">se</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="3513" end_char="3521">centrarán</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="3523" end_char="3524">en</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="3526" end_char="3529">esta</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="3531" end_char="3534">área</TOKEN>
<TOKEN id="token-25-18" pos="punct" morph="none" start_char="3535" end_char="3535">,</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="3537" end_char="3537">a</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="3539" end_char="3543">menos</TOKEN>
<TOKEN id="token-25-21" pos="word" morph="none" start_char="3545" end_char="3547">que</TOKEN>
<TOKEN id="token-25-22" pos="word" morph="none" start_char="3549" end_char="3552">haya</TOKEN>
<TOKEN id="token-25-23" pos="word" morph="none" start_char="3554" end_char="3559">nuevas</TOKEN>
<TOKEN id="token-25-24" pos="word" morph="none" start_char="3561" end_char="3567">pruebas</TOKEN>
<TOKEN id="token-25-25" pos="punct" morph="none" start_char="3568" end_char="3569">»,</TOKEN>
<TOKEN id="token-25-26" pos="word" morph="none" start_char="3571" end_char="3574">dijo</TOKEN>
<TOKEN id="token-25-27" pos="word" morph="none" start_char="3576" end_char="3580">Liang</TOKEN>
<TOKEN id="token-25-28" pos="punct" morph="none" start_char="3581" end_char="3581">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="3583" end_char="3745">
<ORIGINAL_TEXT>Añadió que los hallazgos fueron el ‘consenso’ de la OMS y los científicos chinos, negando que el informe se haya retrasado debido a desacuerdos entre los expertos.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="3583" end_char="3588">Añadió</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="3590" end_char="3592">que</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="3594" end_char="3596">los</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="3598" end_char="3606">hallazgos</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="3608" end_char="3613">fueron</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="3615" end_char="3616">el</TOKEN>
<TOKEN id="token-26-6" pos="punct" morph="none" start_char="3618" end_char="3618">‘</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="3619" end_char="3626">consenso</TOKEN>
<TOKEN id="token-26-8" pos="punct" morph="none" start_char="3627" end_char="3627">’</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="3629" end_char="3630">de</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="3632" end_char="3633">la</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="3635" end_char="3637">OMS</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="3639" end_char="3639">y</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="3641" end_char="3643">los</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="3645" end_char="3655">científicos</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="3657" end_char="3662">chinos</TOKEN>
<TOKEN id="token-26-16" pos="punct" morph="none" start_char="3663" end_char="3663">,</TOKEN>
<TOKEN id="token-26-17" pos="word" morph="none" start_char="3665" end_char="3671">negando</TOKEN>
<TOKEN id="token-26-18" pos="word" morph="none" start_char="3673" end_char="3675">que</TOKEN>
<TOKEN id="token-26-19" pos="word" morph="none" start_char="3677" end_char="3678">el</TOKEN>
<TOKEN id="token-26-20" pos="word" morph="none" start_char="3680" end_char="3686">informe</TOKEN>
<TOKEN id="token-26-21" pos="word" morph="none" start_char="3688" end_char="3689">se</TOKEN>
<TOKEN id="token-26-22" pos="word" morph="none" start_char="3691" end_char="3694">haya</TOKEN>
<TOKEN id="token-26-23" pos="word" morph="none" start_char="3696" end_char="3704">retrasado</TOKEN>
<TOKEN id="token-26-24" pos="word" morph="none" start_char="3706" end_char="3711">debido</TOKEN>
<TOKEN id="token-26-25" pos="word" morph="none" start_char="3713" end_char="3713">a</TOKEN>
<TOKEN id="token-26-26" pos="word" morph="none" start_char="3715" end_char="3725">desacuerdos</TOKEN>
<TOKEN id="token-26-27" pos="word" morph="none" start_char="3727" end_char="3731">entre</TOKEN>
<TOKEN id="token-26-28" pos="word" morph="none" start_char="3733" end_char="3735">los</TOKEN>
<TOKEN id="token-26-29" pos="word" morph="none" start_char="3737" end_char="3744">expertos</TOKEN>
<TOKEN id="token-26-30" pos="punct" morph="none" start_char="3745" end_char="3745">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="3748" end_char="3936">
<ORIGINAL_TEXT>El informe tan esperado debe examinar una variedad de teorías sobre cómo el virus saltó por primera vez de los animales a los humanos, con los murciélagos entre los principales sospechosos.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="3748" end_char="3749">El</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="3751" end_char="3757">informe</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="3759" end_char="3761">tan</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="3763" end_char="3770">esperado</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="3772" end_char="3775">debe</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="3777" end_char="3784">examinar</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="3786" end_char="3788">una</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="3790" end_char="3797">variedad</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="3799" end_char="3800">de</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="3802" end_char="3808">teorías</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="3810" end_char="3814">sobre</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="3816" end_char="3819">cómo</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="3821" end_char="3822">el</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="3824" end_char="3828">virus</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="3830" end_char="3834">saltó</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="3836" end_char="3838">por</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="3840" end_char="3846">primera</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="3848" end_char="3850">vez</TOKEN>
<TOKEN id="token-27-18" pos="word" morph="none" start_char="3852" end_char="3853">de</TOKEN>
<TOKEN id="token-27-19" pos="word" morph="none" start_char="3855" end_char="3857">los</TOKEN>
<TOKEN id="token-27-20" pos="word" morph="none" start_char="3859" end_char="3866">animales</TOKEN>
<TOKEN id="token-27-21" pos="word" morph="none" start_char="3868" end_char="3868">a</TOKEN>
<TOKEN id="token-27-22" pos="word" morph="none" start_char="3870" end_char="3872">los</TOKEN>
<TOKEN id="token-27-23" pos="word" morph="none" start_char="3874" end_char="3880">humanos</TOKEN>
<TOKEN id="token-27-24" pos="punct" morph="none" start_char="3881" end_char="3881">,</TOKEN>
<TOKEN id="token-27-25" pos="word" morph="none" start_char="3883" end_char="3885">con</TOKEN>
<TOKEN id="token-27-26" pos="word" morph="none" start_char="3887" end_char="3889">los</TOKEN>
<TOKEN id="token-27-27" pos="word" morph="none" start_char="3891" end_char="3901">murciélagos</TOKEN>
<TOKEN id="token-27-28" pos="word" morph="none" start_char="3903" end_char="3907">entre</TOKEN>
<TOKEN id="token-27-29" pos="word" morph="none" start_char="3909" end_char="3911">los</TOKEN>
<TOKEN id="token-27-30" pos="word" morph="none" start_char="3913" end_char="3923">principales</TOKEN>
<TOKEN id="token-27-31" pos="word" morph="none" start_char="3925" end_char="3935">sospechosos</TOKEN>
<TOKEN id="token-27-32" pos="punct" morph="none" start_char="3936" end_char="3936">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3939" end_char="4117">
<ORIGINAL_TEXT>Pero Washington y otros han promocionado teorías de que el brote no fue causado por la naturaleza sino por una fuga o un accidente en un laboratorio de virología secreto de Wuhan.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="3939" end_char="3942">Pero</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="3944" end_char="3953">Washington</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="3955" end_char="3955">y</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="3957" end_char="3961">otros</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="3963" end_char="3965">han</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="3967" end_char="3978">promocionado</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="3980" end_char="3986">teorías</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="3988" end_char="3989">de</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="3991" end_char="3993">que</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="3995" end_char="3996">el</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="3998" end_char="4002">brote</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="4004" end_char="4005">no</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="4007" end_char="4009">fue</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="4011" end_char="4017">causado</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="4019" end_char="4021">por</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="4023" end_char="4024">la</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="4026" end_char="4035">naturaleza</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="4037" end_char="4040">sino</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="4042" end_char="4044">por</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="4046" end_char="4048">una</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="4050" end_char="4053">fuga</TOKEN>
<TOKEN id="token-28-21" pos="word" morph="none" start_char="4055" end_char="4055">o</TOKEN>
<TOKEN id="token-28-22" pos="word" morph="none" start_char="4057" end_char="4058">un</TOKEN>
<TOKEN id="token-28-23" pos="word" morph="none" start_char="4060" end_char="4068">accidente</TOKEN>
<TOKEN id="token-28-24" pos="word" morph="none" start_char="4070" end_char="4071">en</TOKEN>
<TOKEN id="token-28-25" pos="word" morph="none" start_char="4073" end_char="4074">un</TOKEN>
<TOKEN id="token-28-26" pos="word" morph="none" start_char="4076" end_char="4086">laboratorio</TOKEN>
<TOKEN id="token-28-27" pos="word" morph="none" start_char="4088" end_char="4089">de</TOKEN>
<TOKEN id="token-28-28" pos="word" morph="none" start_char="4091" end_char="4099">virología</TOKEN>
<TOKEN id="token-28-29" pos="word" morph="none" start_char="4101" end_char="4107">secreto</TOKEN>
<TOKEN id="token-28-30" pos="word" morph="none" start_char="4109" end_char="4110">de</TOKEN>
<TOKEN id="token-28-31" pos="word" morph="none" start_char="4112" end_char="4116">Wuhan</TOKEN>
<TOKEN id="token-28-32" pos="punct" morph="none" start_char="4117" end_char="4117">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="4120" end_char="4245">
<ORIGINAL_TEXT>Su equipo analizó 583 muestras de virus tempranas de Hubei para encontrar su último ancestro común del que todos descendieron.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="4120" end_char="4121">Su</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="4123" end_char="4128">equipo</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="4130" end_char="4136">analizó</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="4138" end_char="4140">583</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="4142" end_char="4149">muestras</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="4151" end_char="4152">de</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="4154" end_char="4158">virus</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="4160" end_char="4168">tempranas</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="4170" end_char="4171">de</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="4173" end_char="4177">Hubei</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="4179" end_char="4182">para</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="4184" end_char="4192">encontrar</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="4194" end_char="4195">su</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="4197" end_char="4202">último</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="4204" end_char="4211">ancestro</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="4213" end_char="4217">común</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="4219" end_char="4221">del</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="4223" end_char="4225">que</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="4227" end_char="4231">todos</TOKEN>
<TOKEN id="token-29-19" pos="word" morph="none" start_char="4233" end_char="4244">descendieron</TOKEN>
<TOKEN id="token-29-20" pos="punct" morph="none" start_char="4245" end_char="4245">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="4247" end_char="4311">
<ORIGINAL_TEXT>Descubrieron que se remontaban aproximadamente al 9 de diciembre.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="4247" end_char="4258">Descubrieron</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="4260" end_char="4262">que</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="4264" end_char="4265">se</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="4267" end_char="4276">remontaban</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="4278" end_char="4292">aproximadamente</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="4294" end_char="4295">al</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="4297" end_char="4297">9</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="4299" end_char="4300">de</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="4302" end_char="4310">diciembre</TOKEN>
<TOKEN id="token-30-9" pos="punct" morph="none" start_char="4311" end_char="4311">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="4314" end_char="4417">
<ORIGINAL_TEXT>Pero los medios chinos informaron sobre una condición inusual similar a la neumonía antes de esta fecha.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="4314" end_char="4317">Pero</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="4319" end_char="4321">los</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="4323" end_char="4328">medios</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="4330" end_char="4335">chinos</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="4337" end_char="4346">informaron</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="4348" end_char="4352">sobre</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="4354" end_char="4356">una</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="4358" end_char="4366">condición</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="4368" end_char="4374">inusual</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="4376" end_char="4382">similar</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="4384" end_char="4384">a</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="4386" end_char="4387">la</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="4389" end_char="4396">neumonía</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="4398" end_char="4402">antes</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="4404" end_char="4405">de</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="4407" end_char="4410">esta</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="4412" end_char="4416">fecha</TOKEN>
<TOKEN id="token-31-17" pos="punct" morph="none" start_char="4417" end_char="4417">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="4420" end_char="4617">
<ORIGINAL_TEXT>Como resultado de esto, los investigadores dicen que la única explicación lógica es que la primera forma del virus que saltó de un animal a un humano fue una cepa débil que se extinguió rápidamente.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="4420" end_char="4423">Como</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="4425" end_char="4433">resultado</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="4435" end_char="4436">de</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="4438" end_char="4441">esto</TOKEN>
<TOKEN id="token-32-4" pos="punct" morph="none" start_char="4442" end_char="4442">,</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="4444" end_char="4446">los</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="4448" end_char="4461">investigadores</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="4463" end_char="4467">dicen</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="4469" end_char="4471">que</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="4473" end_char="4474">la</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="4476" end_char="4480">única</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="4482" end_char="4492">explicación</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="4494" end_char="4499">lógica</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="4501" end_char="4502">es</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="4504" end_char="4506">que</TOKEN>
<TOKEN id="token-32-15" pos="word" morph="none" start_char="4508" end_char="4509">la</TOKEN>
<TOKEN id="token-32-16" pos="word" morph="none" start_char="4511" end_char="4517">primera</TOKEN>
<TOKEN id="token-32-17" pos="word" morph="none" start_char="4519" end_char="4523">forma</TOKEN>
<TOKEN id="token-32-18" pos="word" morph="none" start_char="4525" end_char="4527">del</TOKEN>
<TOKEN id="token-32-19" pos="word" morph="none" start_char="4529" end_char="4533">virus</TOKEN>
<TOKEN id="token-32-20" pos="word" morph="none" start_char="4535" end_char="4537">que</TOKEN>
<TOKEN id="token-32-21" pos="word" morph="none" start_char="4539" end_char="4543">saltó</TOKEN>
<TOKEN id="token-32-22" pos="word" morph="none" start_char="4545" end_char="4546">de</TOKEN>
<TOKEN id="token-32-23" pos="word" morph="none" start_char="4548" end_char="4549">un</TOKEN>
<TOKEN id="token-32-24" pos="word" morph="none" start_char="4551" end_char="4556">animal</TOKEN>
<TOKEN id="token-32-25" pos="word" morph="none" start_char="4558" end_char="4558">a</TOKEN>
<TOKEN id="token-32-26" pos="word" morph="none" start_char="4560" end_char="4561">un</TOKEN>
<TOKEN id="token-32-27" pos="word" morph="none" start_char="4563" end_char="4568">humano</TOKEN>
<TOKEN id="token-32-28" pos="word" morph="none" start_char="4570" end_char="4572">fue</TOKEN>
<TOKEN id="token-32-29" pos="word" morph="none" start_char="4574" end_char="4576">una</TOKEN>
<TOKEN id="token-32-30" pos="word" morph="none" start_char="4578" end_char="4581">cepa</TOKEN>
<TOKEN id="token-32-31" pos="word" morph="none" start_char="4583" end_char="4587">débil</TOKEN>
<TOKEN id="token-32-32" pos="word" morph="none" start_char="4589" end_char="4591">que</TOKEN>
<TOKEN id="token-32-33" pos="word" morph="none" start_char="4593" end_char="4594">se</TOKEN>
<TOKEN id="token-32-34" pos="word" morph="none" start_char="4596" end_char="4604">extinguió</TOKEN>
<TOKEN id="token-32-35" pos="word" morph="none" start_char="4606" end_char="4616">rápidamente</TOKEN>
<TOKEN id="token-32-36" pos="punct" morph="none" start_char="4617" end_char="4617">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="4620" end_char="4790">
<ORIGINAL_TEXT>Pero antes de que desapareciera, los investigadores especulan que mutó para volverse más potente y esta variante luego se extendió por Wuhan y más tarde por todo el mundo.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="4620" end_char="4623">Pero</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="4625" end_char="4629">antes</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="4631" end_char="4632">de</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="4634" end_char="4636">que</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="4638" end_char="4650">desapareciera</TOKEN>
<TOKEN id="token-33-5" pos="punct" morph="none" start_char="4651" end_char="4651">,</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="4653" end_char="4655">los</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="4657" end_char="4670">investigadores</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="4672" end_char="4680">especulan</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="4682" end_char="4684">que</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="4686" end_char="4689">mutó</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="4691" end_char="4694">para</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="4696" end_char="4703">volverse</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="4705" end_char="4707">más</TOKEN>
<TOKEN id="token-33-14" pos="word" morph="none" start_char="4709" end_char="4715">potente</TOKEN>
<TOKEN id="token-33-15" pos="word" morph="none" start_char="4717" end_char="4717">y</TOKEN>
<TOKEN id="token-33-16" pos="word" morph="none" start_char="4719" end_char="4722">esta</TOKEN>
<TOKEN id="token-33-17" pos="word" morph="none" start_char="4724" end_char="4731">variante</TOKEN>
<TOKEN id="token-33-18" pos="word" morph="none" start_char="4733" end_char="4737">luego</TOKEN>
<TOKEN id="token-33-19" pos="word" morph="none" start_char="4739" end_char="4740">se</TOKEN>
<TOKEN id="token-33-20" pos="word" morph="none" start_char="4742" end_char="4749">extendió</TOKEN>
<TOKEN id="token-33-21" pos="word" morph="none" start_char="4751" end_char="4753">por</TOKEN>
<TOKEN id="token-33-22" pos="word" morph="none" start_char="4755" end_char="4759">Wuhan</TOKEN>
<TOKEN id="token-33-23" pos="word" morph="none" start_char="4761" end_char="4761">y</TOKEN>
<TOKEN id="token-33-24" pos="word" morph="none" start_char="4763" end_char="4765">más</TOKEN>
<TOKEN id="token-33-25" pos="word" morph="none" start_char="4767" end_char="4771">tarde</TOKEN>
<TOKEN id="token-33-26" pos="word" morph="none" start_char="4773" end_char="4775">por</TOKEN>
<TOKEN id="token-33-27" pos="word" morph="none" start_char="4777" end_char="4780">todo</TOKEN>
<TOKEN id="token-33-28" pos="word" morph="none" start_char="4782" end_char="4783">el</TOKEN>
<TOKEN id="token-33-29" pos="word" morph="none" start_char="4785" end_char="4789">mundo</TOKEN>
<TOKEN id="token-33-30" pos="punct" morph="none" start_char="4790" end_char="4790">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="4793" end_char="4975">
<ORIGINAL_TEXT>« En nuestro análisis principal, asumimos que el 17 de noviembre representa el primer caso documentado de Covid-19 », escriben los investigadores en su estudio, publicado en Ciencias.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="punct" morph="none" start_char="4793" end_char="4793">«</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="4795" end_char="4796">En</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="4798" end_char="4804">nuestro</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="4806" end_char="4813">análisis</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="4815" end_char="4823">principal</TOKEN>
<TOKEN id="token-34-5" pos="punct" morph="none" start_char="4824" end_char="4824">,</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="4826" end_char="4833">asumimos</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="4835" end_char="4837">que</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="4839" end_char="4840">el</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="4842" end_char="4843">17</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="4845" end_char="4846">de</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="4848" end_char="4856">noviembre</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="4858" end_char="4867">representa</TOKEN>
<TOKEN id="token-34-13" pos="word" morph="none" start_char="4869" end_char="4870">el</TOKEN>
<TOKEN id="token-34-14" pos="word" morph="none" start_char="4872" end_char="4877">primer</TOKEN>
<TOKEN id="token-34-15" pos="word" morph="none" start_char="4879" end_char="4882">caso</TOKEN>
<TOKEN id="token-34-16" pos="word" morph="none" start_char="4884" end_char="4894">documentado</TOKEN>
<TOKEN id="token-34-17" pos="word" morph="none" start_char="4896" end_char="4897">de</TOKEN>
<TOKEN id="token-34-18" pos="unknown" morph="none" start_char="4899" end_char="4906">Covid-19</TOKEN>
<TOKEN id="token-34-19" pos="punct" morph="none" start_char="4908" end_char="4909">»,</TOKEN>
<TOKEN id="token-34-20" pos="word" morph="none" start_char="4911" end_char="4918">escriben</TOKEN>
<TOKEN id="token-34-21" pos="word" morph="none" start_char="4920" end_char="4922">los</TOKEN>
<TOKEN id="token-34-22" pos="word" morph="none" start_char="4924" end_char="4937">investigadores</TOKEN>
<TOKEN id="token-34-23" pos="word" morph="none" start_char="4939" end_char="4940">en</TOKEN>
<TOKEN id="token-34-24" pos="word" morph="none" start_char="4942" end_char="4943">su</TOKEN>
<TOKEN id="token-34-25" pos="word" morph="none" start_char="4945" end_char="4951">estudio</TOKEN>
<TOKEN id="token-34-26" pos="punct" morph="none" start_char="4952" end_char="4952">,</TOKEN>
<TOKEN id="token-34-27" pos="word" morph="none" start_char="4954" end_char="4962">publicado</TOKEN>
<TOKEN id="token-34-28" pos="word" morph="none" start_char="4964" end_char="4965">en</TOKEN>
<TOKEN id="token-34-29" pos="word" morph="none" start_char="4967" end_char="4974">Ciencias</TOKEN>
<TOKEN id="token-34-30" pos="punct" morph="none" start_char="4975" end_char="4975">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="4978" end_char="5071">
<ORIGINAL_TEXT>Llevaron a cabo un análisis más detallado bajo este supuesto utilizando un modelo informático.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="4978" end_char="4985">Llevaron</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="4987" end_char="4987">a</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="4989" end_char="4992">cabo</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="4994" end_char="4995">un</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="4997" end_char="5004">análisis</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="5006" end_char="5008">más</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="5010" end_char="5018">detallado</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="5020" end_char="5023">bajo</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="5025" end_char="5028">este</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="5030" end_char="5037">supuesto</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="5039" end_char="5048">utilizando</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="5050" end_char="5051">un</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="5053" end_char="5058">modelo</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="5060" end_char="5070">informático</TOKEN>
<TOKEN id="token-35-14" pos="punct" morph="none" start_char="5071" end_char="5071">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="5074" end_char="5306">
<ORIGINAL_TEXT>Al tener en cuenta un retraso en la transmisión, la detección y el desarrollo de los síntomas, el primer caso de infección por Covid-19 ocurrió en Hubei el 4 de noviembre de 2019 o alrededor de esa fecha, calculan los investigadores.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="5074" end_char="5075">Al</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="5077" end_char="5081">tener</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="5083" end_char="5084">en</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="5086" end_char="5091">cuenta</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="5093" end_char="5094">un</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="5096" end_char="5102">retraso</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="5104" end_char="5105">en</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="5107" end_char="5108">la</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="5110" end_char="5120">transmisión</TOKEN>
<TOKEN id="token-36-9" pos="punct" morph="none" start_char="5121" end_char="5121">,</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="5123" end_char="5124">la</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="5126" end_char="5134">detección</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="5136" end_char="5136">y</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="5138" end_char="5139">el</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="5141" end_char="5150">desarrollo</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="5152" end_char="5153">de</TOKEN>
<TOKEN id="token-36-16" pos="word" morph="none" start_char="5155" end_char="5157">los</TOKEN>
<TOKEN id="token-36-17" pos="word" morph="none" start_char="5159" end_char="5166">síntomas</TOKEN>
<TOKEN id="token-36-18" pos="punct" morph="none" start_char="5167" end_char="5167">,</TOKEN>
<TOKEN id="token-36-19" pos="word" morph="none" start_char="5169" end_char="5170">el</TOKEN>
<TOKEN id="token-36-20" pos="word" morph="none" start_char="5172" end_char="5177">primer</TOKEN>
<TOKEN id="token-36-21" pos="word" morph="none" start_char="5179" end_char="5182">caso</TOKEN>
<TOKEN id="token-36-22" pos="word" morph="none" start_char="5184" end_char="5185">de</TOKEN>
<TOKEN id="token-36-23" pos="word" morph="none" start_char="5187" end_char="5195">infección</TOKEN>
<TOKEN id="token-36-24" pos="word" morph="none" start_char="5197" end_char="5199">por</TOKEN>
<TOKEN id="token-36-25" pos="unknown" morph="none" start_char="5201" end_char="5208">Covid-19</TOKEN>
<TOKEN id="token-36-26" pos="word" morph="none" start_char="5210" end_char="5216">ocurrió</TOKEN>
<TOKEN id="token-36-27" pos="word" morph="none" start_char="5218" end_char="5219">en</TOKEN>
<TOKEN id="token-36-28" pos="word" morph="none" start_char="5221" end_char="5225">Hubei</TOKEN>
<TOKEN id="token-36-29" pos="word" morph="none" start_char="5227" end_char="5228">el</TOKEN>
<TOKEN id="token-36-30" pos="word" morph="none" start_char="5230" end_char="5230">4</TOKEN>
<TOKEN id="token-36-31" pos="word" morph="none" start_char="5232" end_char="5233">de</TOKEN>
<TOKEN id="token-36-32" pos="word" morph="none" start_char="5235" end_char="5243">noviembre</TOKEN>
<TOKEN id="token-36-33" pos="word" morph="none" start_char="5245" end_char="5246">de</TOKEN>
<TOKEN id="token-36-34" pos="word" morph="none" start_char="5248" end_char="5251">2019</TOKEN>
<TOKEN id="token-36-35" pos="word" morph="none" start_char="5253" end_char="5253">o</TOKEN>
<TOKEN id="token-36-36" pos="word" morph="none" start_char="5255" end_char="5263">alrededor</TOKEN>
<TOKEN id="token-36-37" pos="word" morph="none" start_char="5265" end_char="5266">de</TOKEN>
<TOKEN id="token-36-38" pos="word" morph="none" start_char="5268" end_char="5270">esa</TOKEN>
<TOKEN id="token-36-39" pos="word" morph="none" start_char="5272" end_char="5276">fecha</TOKEN>
<TOKEN id="token-36-40" pos="punct" morph="none" start_char="5277" end_char="5277">,</TOKEN>
<TOKEN id="token-36-41" pos="word" morph="none" start_char="5279" end_char="5286">calculan</TOKEN>
<TOKEN id="token-36-42" pos="word" morph="none" start_char="5288" end_char="5290">los</TOKEN>
<TOKEN id="token-36-43" pos="word" morph="none" start_char="5292" end_char="5305">investigadores</TOKEN>
<TOKEN id="token-36-44" pos="punct" morph="none" start_char="5306" end_char="5306">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="5309" end_char="5404">
<ORIGINAL_TEXT>Sin embargo, esta cifra podría ser tan temprana como el 7 de octubre, añaden los investigadores.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="5309" end_char="5311">Sin</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="5313" end_char="5319">embargo</TOKEN>
<TOKEN id="token-37-2" pos="punct" morph="none" start_char="5320" end_char="5320">,</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="5322" end_char="5325">esta</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="5327" end_char="5331">cifra</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="5333" end_char="5338">podría</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="5340" end_char="5342">ser</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="5344" end_char="5346">tan</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="5348" end_char="5355">temprana</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="5357" end_char="5360">como</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="5362" end_char="5363">el</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="5365" end_char="5365">7</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="5367" end_char="5368">de</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="5370" end_char="5376">octubre</TOKEN>
<TOKEN id="token-37-14" pos="punct" morph="none" start_char="5377" end_char="5377">,</TOKEN>
<TOKEN id="token-37-15" pos="word" morph="none" start_char="5379" end_char="5384">añaden</TOKEN>
<TOKEN id="token-37-16" pos="word" morph="none" start_char="5386" end_char="5388">los</TOKEN>
<TOKEN id="token-37-17" pos="word" morph="none" start_char="5390" end_char="5403">investigadores</TOKEN>
<TOKEN id="token-37-18" pos="punct" morph="none" start_char="5404" end_char="5404">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="5407" end_char="5712">
<ORIGINAL_TEXT>Los investigadores lucharon por identificar una ubicación geográfica para el origen del virus, pero dicen que si la cepa inicial, que era más débil que la variante de Wuhan y todas las mutaciones posteriores, surgiera en una ubicación rural, habría tenido que migrar a una ubicación urbana para sobrevivir.</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="5407" end_char="5409">Los</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="5411" end_char="5424">investigadores</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="5426" end_char="5433">lucharon</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="5435" end_char="5437">por</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="5439" end_char="5449">identificar</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="5451" end_char="5453">una</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="5455" end_char="5463">ubicación</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="5465" end_char="5474">geográfica</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="5476" end_char="5479">para</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="5481" end_char="5482">el</TOKEN>
<TOKEN id="token-38-10" pos="word" morph="none" start_char="5484" end_char="5489">origen</TOKEN>
<TOKEN id="token-38-11" pos="word" morph="none" start_char="5491" end_char="5493">del</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="5495" end_char="5499">virus</TOKEN>
<TOKEN id="token-38-13" pos="punct" morph="none" start_char="5500" end_char="5500">,</TOKEN>
<TOKEN id="token-38-14" pos="word" morph="none" start_char="5502" end_char="5505">pero</TOKEN>
<TOKEN id="token-38-15" pos="word" morph="none" start_char="5507" end_char="5511">dicen</TOKEN>
<TOKEN id="token-38-16" pos="word" morph="none" start_char="5513" end_char="5515">que</TOKEN>
<TOKEN id="token-38-17" pos="word" morph="none" start_char="5517" end_char="5518">si</TOKEN>
<TOKEN id="token-38-18" pos="word" morph="none" start_char="5520" end_char="5521">la</TOKEN>
<TOKEN id="token-38-19" pos="word" morph="none" start_char="5523" end_char="5526">cepa</TOKEN>
<TOKEN id="token-38-20" pos="word" morph="none" start_char="5528" end_char="5534">inicial</TOKEN>
<TOKEN id="token-38-21" pos="punct" morph="none" start_char="5535" end_char="5535">,</TOKEN>
<TOKEN id="token-38-22" pos="word" morph="none" start_char="5537" end_char="5539">que</TOKEN>
<TOKEN id="token-38-23" pos="word" morph="none" start_char="5541" end_char="5543">era</TOKEN>
<TOKEN id="token-38-24" pos="word" morph="none" start_char="5545" end_char="5547">más</TOKEN>
<TOKEN id="token-38-25" pos="word" morph="none" start_char="5549" end_char="5553">débil</TOKEN>
<TOKEN id="token-38-26" pos="word" morph="none" start_char="5555" end_char="5557">que</TOKEN>
<TOKEN id="token-38-27" pos="word" morph="none" start_char="5559" end_char="5560">la</TOKEN>
<TOKEN id="token-38-28" pos="word" morph="none" start_char="5562" end_char="5569">variante</TOKEN>
<TOKEN id="token-38-29" pos="word" morph="none" start_char="5571" end_char="5572">de</TOKEN>
<TOKEN id="token-38-30" pos="word" morph="none" start_char="5574" end_char="5578">Wuhan</TOKEN>
<TOKEN id="token-38-31" pos="word" morph="none" start_char="5580" end_char="5580">y</TOKEN>
<TOKEN id="token-38-32" pos="word" morph="none" start_char="5582" end_char="5586">todas</TOKEN>
<TOKEN id="token-38-33" pos="word" morph="none" start_char="5588" end_char="5590">las</TOKEN>
<TOKEN id="token-38-34" pos="word" morph="none" start_char="5592" end_char="5601">mutaciones</TOKEN>
<TOKEN id="token-38-35" pos="word" morph="none" start_char="5603" end_char="5613">posteriores</TOKEN>
<TOKEN id="token-38-36" pos="punct" morph="none" start_char="5614" end_char="5614">,</TOKEN>
<TOKEN id="token-38-37" pos="word" morph="none" start_char="5616" end_char="5623">surgiera</TOKEN>
<TOKEN id="token-38-38" pos="word" morph="none" start_char="5625" end_char="5626">en</TOKEN>
<TOKEN id="token-38-39" pos="word" morph="none" start_char="5628" end_char="5630">una</TOKEN>
<TOKEN id="token-38-40" pos="word" morph="none" start_char="5632" end_char="5640">ubicación</TOKEN>
<TOKEN id="token-38-41" pos="word" morph="none" start_char="5642" end_char="5646">rural</TOKEN>
<TOKEN id="token-38-42" pos="punct" morph="none" start_char="5647" end_char="5647">,</TOKEN>
<TOKEN id="token-38-43" pos="word" morph="none" start_char="5649" end_char="5654">habría</TOKEN>
<TOKEN id="token-38-44" pos="word" morph="none" start_char="5656" end_char="5661">tenido</TOKEN>
<TOKEN id="token-38-45" pos="word" morph="none" start_char="5663" end_char="5665">que</TOKEN>
<TOKEN id="token-38-46" pos="word" morph="none" start_char="5667" end_char="5672">migrar</TOKEN>
<TOKEN id="token-38-47" pos="word" morph="none" start_char="5674" end_char="5674">a</TOKEN>
<TOKEN id="token-38-48" pos="word" morph="none" start_char="5676" end_char="5678">una</TOKEN>
<TOKEN id="token-38-49" pos="word" morph="none" start_char="5680" end_char="5688">ubicación</TOKEN>
<TOKEN id="token-38-50" pos="word" morph="none" start_char="5690" end_char="5695">urbana</TOKEN>
<TOKEN id="token-38-51" pos="word" morph="none" start_char="5697" end_char="5700">para</TOKEN>
<TOKEN id="token-38-52" pos="word" morph="none" start_char="5702" end_char="5711">sobrevivir</TOKEN>
<TOKEN id="token-38-53" pos="punct" morph="none" start_char="5712" end_char="5712">.</TOKEN>
</SEG>
<SEG id="segment-39" start_char="5714" end_char="5714">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="punct" morph="none" start_char="5714" end_char="5714">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="5717" end_char="5961">
<ORIGINAL_TEXT>«La falta de informes de Covid-19 en otras partes de China en noviembre y principios de diciembre sugiere que la provincia de Hubei es el lugar donde se establecieron las cadenas de transmisión de persona a persona», escriben los investigadores.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="punct" morph="none" start_char="5717" end_char="5717">«</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="5718" end_char="5719">La</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="5721" end_char="5725">falta</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="5727" end_char="5728">de</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="5730" end_char="5737">informes</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="5739" end_char="5740">de</TOKEN>
<TOKEN id="token-40-6" pos="unknown" morph="none" start_char="5742" end_char="5749">Covid-19</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="5751" end_char="5752">en</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="5754" end_char="5758">otras</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="5760" end_char="5765">partes</TOKEN>
<TOKEN id="token-40-10" pos="word" morph="none" start_char="5767" end_char="5768">de</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="5770" end_char="5774">China</TOKEN>
<TOKEN id="token-40-12" pos="word" morph="none" start_char="5776" end_char="5777">en</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="5779" end_char="5787">noviembre</TOKEN>
<TOKEN id="token-40-14" pos="word" morph="none" start_char="5789" end_char="5789">y</TOKEN>
<TOKEN id="token-40-15" pos="word" morph="none" start_char="5791" end_char="5800">principios</TOKEN>
<TOKEN id="token-40-16" pos="word" morph="none" start_char="5802" end_char="5803">de</TOKEN>
<TOKEN id="token-40-17" pos="word" morph="none" start_char="5805" end_char="5813">diciembre</TOKEN>
<TOKEN id="token-40-18" pos="word" morph="none" start_char="5815" end_char="5821">sugiere</TOKEN>
<TOKEN id="token-40-19" pos="word" morph="none" start_char="5823" end_char="5825">que</TOKEN>
<TOKEN id="token-40-20" pos="word" morph="none" start_char="5827" end_char="5828">la</TOKEN>
<TOKEN id="token-40-21" pos="word" morph="none" start_char="5830" end_char="5838">provincia</TOKEN>
<TOKEN id="token-40-22" pos="word" morph="none" start_char="5840" end_char="5841">de</TOKEN>
<TOKEN id="token-40-23" pos="word" morph="none" start_char="5843" end_char="5847">Hubei</TOKEN>
<TOKEN id="token-40-24" pos="word" morph="none" start_char="5849" end_char="5850">es</TOKEN>
<TOKEN id="token-40-25" pos="word" morph="none" start_char="5852" end_char="5853">el</TOKEN>
<TOKEN id="token-40-26" pos="word" morph="none" start_char="5855" end_char="5859">lugar</TOKEN>
<TOKEN id="token-40-27" pos="word" morph="none" start_char="5861" end_char="5865">donde</TOKEN>
<TOKEN id="token-40-28" pos="word" morph="none" start_char="5867" end_char="5868">se</TOKEN>
<TOKEN id="token-40-29" pos="word" morph="none" start_char="5870" end_char="5882">establecieron</TOKEN>
<TOKEN id="token-40-30" pos="word" morph="none" start_char="5884" end_char="5886">las</TOKEN>
<TOKEN id="token-40-31" pos="word" morph="none" start_char="5888" end_char="5894">cadenas</TOKEN>
<TOKEN id="token-40-32" pos="word" morph="none" start_char="5896" end_char="5897">de</TOKEN>
<TOKEN id="token-40-33" pos="word" morph="none" start_char="5899" end_char="5909">transmisión</TOKEN>
<TOKEN id="token-40-34" pos="word" morph="none" start_char="5911" end_char="5912">de</TOKEN>
<TOKEN id="token-40-35" pos="word" morph="none" start_char="5914" end_char="5920">persona</TOKEN>
<TOKEN id="token-40-36" pos="word" morph="none" start_char="5922" end_char="5922">a</TOKEN>
<TOKEN id="token-40-37" pos="word" morph="none" start_char="5924" end_char="5930">persona</TOKEN>
<TOKEN id="token-40-38" pos="punct" morph="none" start_char="5931" end_char="5932">»,</TOKEN>
<TOKEN id="token-40-39" pos="word" morph="none" start_char="5934" end_char="5941">escriben</TOKEN>
<TOKEN id="token-40-40" pos="word" morph="none" start_char="5943" end_char="5945">los</TOKEN>
<TOKEN id="token-40-41" pos="word" morph="none" start_char="5947" end_char="5960">investigadores</TOKEN>
<TOKEN id="token-40-42" pos="punct" morph="none" start_char="5961" end_char="5961">.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="5964" end_char="6216">
<ORIGINAL_TEXT>Los investigadores añaden que sus hallazgos no arrojan luz sobre si el primer caso contrajo el virus directamente de los murciélagos o a través de un huésped intermedio, pero sí «aleja aún más» el primer caso del mercado mayorista de mariscos de Huanan.</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="5964" end_char="5966">Los</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="5968" end_char="5981">investigadores</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="5983" end_char="5988">añaden</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="5990" end_char="5992">que</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="5994" end_char="5996">sus</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="5998" end_char="6006">hallazgos</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="6008" end_char="6009">no</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="6011" end_char="6017">arrojan</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="6019" end_char="6021">luz</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="6023" end_char="6027">sobre</TOKEN>
<TOKEN id="token-41-10" pos="word" morph="none" start_char="6029" end_char="6030">si</TOKEN>
<TOKEN id="token-41-11" pos="word" morph="none" start_char="6032" end_char="6033">el</TOKEN>
<TOKEN id="token-41-12" pos="word" morph="none" start_char="6035" end_char="6040">primer</TOKEN>
<TOKEN id="token-41-13" pos="word" morph="none" start_char="6042" end_char="6045">caso</TOKEN>
<TOKEN id="token-41-14" pos="word" morph="none" start_char="6047" end_char="6054">contrajo</TOKEN>
<TOKEN id="token-41-15" pos="word" morph="none" start_char="6056" end_char="6057">el</TOKEN>
<TOKEN id="token-41-16" pos="word" morph="none" start_char="6059" end_char="6063">virus</TOKEN>
<TOKEN id="token-41-17" pos="word" morph="none" start_char="6065" end_char="6076">directamente</TOKEN>
<TOKEN id="token-41-18" pos="word" morph="none" start_char="6078" end_char="6079">de</TOKEN>
<TOKEN id="token-41-19" pos="word" morph="none" start_char="6081" end_char="6083">los</TOKEN>
<TOKEN id="token-41-20" pos="word" morph="none" start_char="6085" end_char="6095">murciélagos</TOKEN>
<TOKEN id="token-41-21" pos="word" morph="none" start_char="6097" end_char="6097">o</TOKEN>
<TOKEN id="token-41-22" pos="word" morph="none" start_char="6099" end_char="6099">a</TOKEN>
<TOKEN id="token-41-23" pos="word" morph="none" start_char="6101" end_char="6106">través</TOKEN>
<TOKEN id="token-41-24" pos="word" morph="none" start_char="6108" end_char="6109">de</TOKEN>
<TOKEN id="token-41-25" pos="word" morph="none" start_char="6111" end_char="6112">un</TOKEN>
<TOKEN id="token-41-26" pos="word" morph="none" start_char="6114" end_char="6120">huésped</TOKEN>
<TOKEN id="token-41-27" pos="word" morph="none" start_char="6122" end_char="6131">intermedio</TOKEN>
<TOKEN id="token-41-28" pos="punct" morph="none" start_char="6132" end_char="6132">,</TOKEN>
<TOKEN id="token-41-29" pos="word" morph="none" start_char="6134" end_char="6137">pero</TOKEN>
<TOKEN id="token-41-30" pos="word" morph="none" start_char="6139" end_char="6140">sí</TOKEN>
<TOKEN id="token-41-31" pos="punct" morph="none" start_char="6142" end_char="6142">«</TOKEN>
<TOKEN id="token-41-32" pos="word" morph="none" start_char="6143" end_char="6147">aleja</TOKEN>
<TOKEN id="token-41-33" pos="word" morph="none" start_char="6149" end_char="6151">aún</TOKEN>
<TOKEN id="token-41-34" pos="word" morph="none" start_char="6153" end_char="6155">más</TOKEN>
<TOKEN id="token-41-35" pos="punct" morph="none" start_char="6156" end_char="6156">»</TOKEN>
<TOKEN id="token-41-36" pos="word" morph="none" start_char="6158" end_char="6159">el</TOKEN>
<TOKEN id="token-41-37" pos="word" morph="none" start_char="6161" end_char="6166">primer</TOKEN>
<TOKEN id="token-41-38" pos="word" morph="none" start_char="6168" end_char="6171">caso</TOKEN>
<TOKEN id="token-41-39" pos="word" morph="none" start_char="6173" end_char="6175">del</TOKEN>
<TOKEN id="token-41-40" pos="word" morph="none" start_char="6177" end_char="6183">mercado</TOKEN>
<TOKEN id="token-41-41" pos="word" morph="none" start_char="6185" end_char="6193">mayorista</TOKEN>
<TOKEN id="token-41-42" pos="word" morph="none" start_char="6195" end_char="6196">de</TOKEN>
<TOKEN id="token-41-43" pos="word" morph="none" start_char="6198" end_char="6205">mariscos</TOKEN>
<TOKEN id="token-41-44" pos="word" morph="none" start_char="6207" end_char="6208">de</TOKEN>
<TOKEN id="token-41-45" pos="word" morph="none" start_char="6210" end_char="6215">Huanan</TOKEN>
<TOKEN id="token-41-46" pos="punct" morph="none" start_char="6216" end_char="6216">.</TOKEN>
</SEG>
<SEG id="segment-42" start_char="6219" end_char="6238">
<ORIGINAL_TEXT>Anuncio publicitario</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="6219" end_char="6225">Anuncio</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="6227" end_char="6238">publicitario</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
