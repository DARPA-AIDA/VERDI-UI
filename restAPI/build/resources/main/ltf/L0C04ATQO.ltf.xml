<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATQO" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="1857" raw_text_md5="dd75f12b24be94bdcf5de7aea5af7e18">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="84">
<ORIGINAL_TEXT>Se cumple un año desde que el primer paciente de COVID-19 presentó síntomas en China</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="2">Se</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="4" end_char="9">cumple</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="11" end_char="12">un</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="14" end_char="16">año</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="18" end_char="22">desde</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="24" end_char="26">que</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="28" end_char="29">el</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="31" end_char="36">primer</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="38" end_char="45">paciente</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="47" end_char="48">de</TOKEN>
<TOKEN id="token-0-10" pos="unknown" morph="none" start_char="50" end_char="57">COVID-19</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="59" end_char="66">presentó</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="68" end_char="75">síntomas</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="77" end_char="78">en</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="80" end_char="84">China</TOKEN>
</SEG>
<SEG id="segment-1" start_char="88" end_char="356">
<ORIGINAL_TEXT>Hoy se cumple un año desde que la primera persona en quien se confirmó la infección de coronavirus en Wuhan, China, empezara a mostrar síntomas de la enfermedad que 365 días después ja matado a millón y medio de personas en prácticamente todos los rincones del planeta.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="88" end_char="90">Hoy</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="92" end_char="93">se</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="95" end_char="100">cumple</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="102" end_char="103">un</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="105" end_char="107">año</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="109" end_char="113">desde</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="115" end_char="117">que</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="119" end_char="120">la</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="122" end_char="128">primera</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="130" end_char="136">persona</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="138" end_char="139">en</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="141" end_char="145">quien</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="147" end_char="148">se</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="150" end_char="157">confirmó</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="159" end_char="160">la</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="162" end_char="170">infección</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="172" end_char="173">de</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="175" end_char="185">coronavirus</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="187" end_char="188">en</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="190" end_char="194">Wuhan</TOKEN>
<TOKEN id="token-1-20" pos="punct" morph="none" start_char="195" end_char="195">,</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="197" end_char="201">China</TOKEN>
<TOKEN id="token-1-22" pos="punct" morph="none" start_char="202" end_char="202">,</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="204" end_char="211">empezara</TOKEN>
<TOKEN id="token-1-24" pos="word" morph="none" start_char="213" end_char="213">a</TOKEN>
<TOKEN id="token-1-25" pos="word" morph="none" start_char="215" end_char="221">mostrar</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="223" end_char="230">síntomas</TOKEN>
<TOKEN id="token-1-27" pos="word" morph="none" start_char="232" end_char="233">de</TOKEN>
<TOKEN id="token-1-28" pos="word" morph="none" start_char="235" end_char="236">la</TOKEN>
<TOKEN id="token-1-29" pos="word" morph="none" start_char="238" end_char="247">enfermedad</TOKEN>
<TOKEN id="token-1-30" pos="word" morph="none" start_char="249" end_char="251">que</TOKEN>
<TOKEN id="token-1-31" pos="word" morph="none" start_char="253" end_char="255">365</TOKEN>
<TOKEN id="token-1-32" pos="word" morph="none" start_char="257" end_char="260">días</TOKEN>
<TOKEN id="token-1-33" pos="word" morph="none" start_char="262" end_char="268">después</TOKEN>
<TOKEN id="token-1-34" pos="word" morph="none" start_char="270" end_char="271">ja</TOKEN>
<TOKEN id="token-1-35" pos="word" morph="none" start_char="273" end_char="278">matado</TOKEN>
<TOKEN id="token-1-36" pos="word" morph="none" start_char="280" end_char="280">a</TOKEN>
<TOKEN id="token-1-37" pos="word" morph="none" start_char="282" end_char="287">millón</TOKEN>
<TOKEN id="token-1-38" pos="word" morph="none" start_char="289" end_char="289">y</TOKEN>
<TOKEN id="token-1-39" pos="word" morph="none" start_char="291" end_char="295">medio</TOKEN>
<TOKEN id="token-1-40" pos="word" morph="none" start_char="297" end_char="298">de</TOKEN>
<TOKEN id="token-1-41" pos="word" morph="none" start_char="300" end_char="307">personas</TOKEN>
<TOKEN id="token-1-42" pos="word" morph="none" start_char="309" end_char="310">en</TOKEN>
<TOKEN id="token-1-43" pos="word" morph="none" start_char="312" end_char="324">prácticamente</TOKEN>
<TOKEN id="token-1-44" pos="word" morph="none" start_char="326" end_char="330">todos</TOKEN>
<TOKEN id="token-1-45" pos="word" morph="none" start_char="332" end_char="334">los</TOKEN>
<TOKEN id="token-1-46" pos="word" morph="none" start_char="336" end_char="343">rincones</TOKEN>
<TOKEN id="token-1-47" pos="word" morph="none" start_char="345" end_char="347">del</TOKEN>
<TOKEN id="token-1-48" pos="word" morph="none" start_char="349" end_char="355">planeta</TOKEN>
<TOKEN id="token-1-49" pos="punct" morph="none" start_char="356" end_char="356">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="359" end_char="468">
<ORIGINAL_TEXT>Según las autoridades chinas, el paciente cero del mortal virus desarrolló neumonía el 8 de diciembre de 2019.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="359" end_char="363">Según</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="365" end_char="367">las</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="369" end_char="379">autoridades</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="381" end_char="386">chinas</TOKEN>
<TOKEN id="token-2-4" pos="punct" morph="none" start_char="387" end_char="387">,</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="389" end_char="390">el</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="392" end_char="399">paciente</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="401" end_char="404">cero</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="406" end_char="408">del</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="410" end_char="415">mortal</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="417" end_char="421">virus</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="423" end_char="432">desarrolló</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="434" end_char="441">neumonía</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="443" end_char="444">el</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="446" end_char="446">8</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="448" end_char="449">de</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="451" end_char="459">diciembre</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="461" end_char="462">de</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="464" end_char="467">2019</TOKEN>
<TOKEN id="token-2-19" pos="punct" morph="none" start_char="468" end_char="468">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="471" end_char="580">
<ORIGINAL_TEXT>Pasado un año, la ciencia no logrado determinar de dónde procede el virus ni cómo se transmitió a los humanos.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="471" end_char="476">Pasado</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="478" end_char="479">un</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="481" end_char="483">año</TOKEN>
<TOKEN id="token-3-3" pos="punct" morph="none" start_char="484" end_char="484">,</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="486" end_char="487">la</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="489" end_char="495">ciencia</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="497" end_char="498">no</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="500" end_char="506">logrado</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="508" end_char="517">determinar</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="519" end_char="520">de</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="522" end_char="526">dónde</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="528" end_char="534">procede</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="536" end_char="537">el</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="539" end_char="543">virus</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="545" end_char="546">ni</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="548" end_char="551">cómo</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="553" end_char="554">se</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="556" end_char="565">transmitió</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="567" end_char="567">a</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="569" end_char="571">los</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="573" end_char="579">humanos</TOKEN>
<TOKEN id="token-3-21" pos="punct" morph="none" start_char="580" end_char="580">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="582" end_char="676">
<ORIGINAL_TEXT>Eso sí, en ese lapso, la ciencia está a las puertas del tener la vacuna en un suceso histórico.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="582" end_char="584">Eso</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="586" end_char="587">sí</TOKEN>
<TOKEN id="token-4-2" pos="punct" morph="none" start_char="588" end_char="588">,</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="590" end_char="591">en</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="593" end_char="595">ese</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="597" end_char="601">lapso</TOKEN>
<TOKEN id="token-4-6" pos="punct" morph="none" start_char="602" end_char="602">,</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="604" end_char="605">la</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="607" end_char="613">ciencia</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="615" end_char="618">está</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="620" end_char="620">a</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="622" end_char="624">las</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="626" end_char="632">puertas</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="634" end_char="636">del</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="638" end_char="642">tener</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="644" end_char="645">la</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="647" end_char="652">vacuna</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="654" end_char="655">en</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="657" end_char="658">un</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="660" end_char="665">suceso</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="667" end_char="675">histórico</TOKEN>
<TOKEN id="token-4-21" pos="punct" morph="none" start_char="676" end_char="676">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="679" end_char="841">
<ORIGINAL_TEXT>En febrero pasado, expertos del Gobierno chino explicaron que probablemente el patógeno tuvo su origen en murciélagos y saltó a los humanos a través de pangolines.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="679" end_char="680">En</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="682" end_char="688">febrero</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="690" end_char="695">pasado</TOKEN>
<TOKEN id="token-5-3" pos="punct" morph="none" start_char="696" end_char="696">,</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="698" end_char="705">expertos</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="707" end_char="709">del</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="711" end_char="718">Gobierno</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="720" end_char="724">chino</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="726" end_char="735">explicaron</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="737" end_char="739">que</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="741" end_char="753">probablemente</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="755" end_char="756">el</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="758" end_char="765">patógeno</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="767" end_char="770">tuvo</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="772" end_char="773">su</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="775" end_char="780">origen</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="782" end_char="783">en</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="785" end_char="795">murciélagos</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="797" end_char="797">y</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="799" end_char="803">saltó</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="805" end_char="805">a</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="807" end_char="809">los</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="811" end_char="817">humanos</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="819" end_char="819">a</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="821" end_char="826">través</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="828" end_char="829">de</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="831" end_char="840">pangolines</TOKEN>
<TOKEN id="token-5-27" pos="punct" morph="none" start_char="841" end_char="841">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="844" end_char="1019">
<ORIGINAL_TEXT>Sin embargo, tiempo después insinuaron que el coronavirus se detectó en alimentos importados y que no se podía descartar la posibilidad de que se haya originado fuera de China.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="844" end_char="846">Sin</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="848" end_char="854">embargo</TOKEN>
<TOKEN id="token-6-2" pos="punct" morph="none" start_char="855" end_char="855">,</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="857" end_char="862">tiempo</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="864" end_char="870">después</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="872" end_char="881">insinuaron</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="883" end_char="885">que</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="887" end_char="888">el</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="890" end_char="900">coronavirus</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="902" end_char="903">se</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="905" end_char="911">detectó</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="913" end_char="914">en</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="916" end_char="924">alimentos</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="926" end_char="935">importados</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="937" end_char="937">y</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="939" end_char="941">que</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="943" end_char="944">no</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="946" end_char="947">se</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="949" end_char="953">podía</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="955" end_char="963">descartar</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="965" end_char="966">la</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="968" end_char="978">posibilidad</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="980" end_char="981">de</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="983" end_char="985">que</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="987" end_char="988">se</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="990" end_char="993">haya</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="995" end_char="1003">originado</TOKEN>
<TOKEN id="token-6-27" pos="word" morph="none" start_char="1005" end_char="1009">fuera</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="1011" end_char="1012">de</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="1014" end_char="1018">China</TOKEN>
<TOKEN id="token-6-30" pos="punct" morph="none" start_char="1019" end_char="1019">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="1022" end_char="1248">
<ORIGINAL_TEXT>En julio, la Organización Mundial de la Salud envió un equipo de investigadores a Pekín como parte de los esfuerzos para identificar el origen del patógeno, pero no ha podido llevar a cabo un estudio detallado todavía en Wuhan.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="1022" end_char="1023">En</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="1025" end_char="1029">julio</TOKEN>
<TOKEN id="token-7-2" pos="punct" morph="none" start_char="1030" end_char="1030">,</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="1032" end_char="1033">la</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="1035" end_char="1046">Organización</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="1048" end_char="1054">Mundial</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="1056" end_char="1057">de</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="1059" end_char="1060">la</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="1062" end_char="1066">Salud</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="1068" end_char="1072">envió</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="1074" end_char="1075">un</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="1077" end_char="1082">equipo</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="1084" end_char="1085">de</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="1087" end_char="1100">investigadores</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="1102" end_char="1102">a</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="1104" end_char="1108">Pekín</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="1110" end_char="1113">como</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="1115" end_char="1119">parte</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="1121" end_char="1122">de</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="1124" end_char="1126">los</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="1128" end_char="1136">esfuerzos</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="1138" end_char="1141">para</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="1143" end_char="1153">identificar</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="1155" end_char="1156">el</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="1158" end_char="1163">origen</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="1165" end_char="1167">del</TOKEN>
<TOKEN id="token-7-26" pos="word" morph="none" start_char="1169" end_char="1176">patógeno</TOKEN>
<TOKEN id="token-7-27" pos="punct" morph="none" start_char="1177" end_char="1177">,</TOKEN>
<TOKEN id="token-7-28" pos="word" morph="none" start_char="1179" end_char="1182">pero</TOKEN>
<TOKEN id="token-7-29" pos="word" morph="none" start_char="1184" end_char="1185">no</TOKEN>
<TOKEN id="token-7-30" pos="word" morph="none" start_char="1187" end_char="1188">ha</TOKEN>
<TOKEN id="token-7-31" pos="word" morph="none" start_char="1190" end_char="1195">podido</TOKEN>
<TOKEN id="token-7-32" pos="word" morph="none" start_char="1197" end_char="1202">llevar</TOKEN>
<TOKEN id="token-7-33" pos="word" morph="none" start_char="1204" end_char="1204">a</TOKEN>
<TOKEN id="token-7-34" pos="word" morph="none" start_char="1206" end_char="1209">cabo</TOKEN>
<TOKEN id="token-7-35" pos="word" morph="none" start_char="1211" end_char="1212">un</TOKEN>
<TOKEN id="token-7-36" pos="word" morph="none" start_char="1214" end_char="1220">estudio</TOKEN>
<TOKEN id="token-7-37" pos="word" morph="none" start_char="1222" end_char="1230">detallado</TOKEN>
<TOKEN id="token-7-38" pos="word" morph="none" start_char="1232" end_char="1238">todavía</TOKEN>
<TOKEN id="token-7-39" pos="word" morph="none" start_char="1240" end_char="1241">en</TOKEN>
<TOKEN id="token-7-40" pos="word" morph="none" start_char="1243" end_char="1247">Wuhan</TOKEN>
<TOKEN id="token-7-41" pos="punct" morph="none" start_char="1248" end_char="1248">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1251" end_char="1427">
<ORIGINAL_TEXT>La pandemia aún no está bajo control pero el principio de la solución puede iniciar este 8 de diciembre cuando Reino Unido inicie su campaña de vacunación contra el coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1251" end_char="1252">La</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1254" end_char="1261">pandemia</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1263" end_char="1265">aún</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1267" end_char="1268">no</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1270" end_char="1273">está</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1275" end_char="1278">bajo</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1280" end_char="1286">control</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1288" end_char="1291">pero</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1293" end_char="1294">el</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1296" end_char="1304">principio</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1306" end_char="1307">de</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1309" end_char="1310">la</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1312" end_char="1319">solución</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1321" end_char="1325">puede</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1327" end_char="1333">iniciar</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1335" end_char="1338">este</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1340" end_char="1340">8</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1342" end_char="1343">de</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1345" end_char="1353">diciembre</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1355" end_char="1360">cuando</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="1362" end_char="1366">Reino</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="1368" end_char="1372">Unido</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="1374" end_char="1379">inicie</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="1381" end_char="1382">su</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="1384" end_char="1390">campaña</TOKEN>
<TOKEN id="token-8-25" pos="word" morph="none" start_char="1392" end_char="1393">de</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="1395" end_char="1404">vacunación</TOKEN>
<TOKEN id="token-8-27" pos="word" morph="none" start_char="1406" end_char="1411">contra</TOKEN>
<TOKEN id="token-8-28" pos="word" morph="none" start_char="1413" end_char="1414">el</TOKEN>
<TOKEN id="token-8-29" pos="word" morph="none" start_char="1416" end_char="1426">coronavirus</TOKEN>
<TOKEN id="token-8-30" pos="punct" morph="none" start_char="1427" end_char="1427">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1430" end_char="1694">
<ORIGINAL_TEXT>El doctor Peter Ben Embarek, experto de la Organización Mundial de la Salud, ha declarado a la NHK que es lógico pensar que el coronavirus se originó en China, ya que se parece a un virus que se detectó en 2013 en una cueva de murciélagos de la provincia de Yunnan.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1430" end_char="1431">El</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1433" end_char="1438">doctor</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1440" end_char="1444">Peter</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1446" end_char="1448">Ben</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1450" end_char="1456">Embarek</TOKEN>
<TOKEN id="token-9-5" pos="punct" morph="none" start_char="1457" end_char="1457">,</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1459" end_char="1465">experto</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1467" end_char="1468">de</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1470" end_char="1471">la</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1473" end_char="1484">Organización</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1486" end_char="1492">Mundial</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1494" end_char="1495">de</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1497" end_char="1498">la</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1500" end_char="1504">Salud</TOKEN>
<TOKEN id="token-9-14" pos="punct" morph="none" start_char="1505" end_char="1505">,</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1507" end_char="1508">ha</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1510" end_char="1518">declarado</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1520" end_char="1520">a</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1522" end_char="1523">la</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1525" end_char="1527">NHK</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1529" end_char="1531">que</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1533" end_char="1534">es</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1536" end_char="1541">lógico</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1543" end_char="1548">pensar</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1550" end_char="1552">que</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1554" end_char="1555">el</TOKEN>
<TOKEN id="token-9-26" pos="word" morph="none" start_char="1557" end_char="1567">coronavirus</TOKEN>
<TOKEN id="token-9-27" pos="word" morph="none" start_char="1569" end_char="1570">se</TOKEN>
<TOKEN id="token-9-28" pos="word" morph="none" start_char="1572" end_char="1578">originó</TOKEN>
<TOKEN id="token-9-29" pos="word" morph="none" start_char="1580" end_char="1581">en</TOKEN>
<TOKEN id="token-9-30" pos="word" morph="none" start_char="1583" end_char="1587">China</TOKEN>
<TOKEN id="token-9-31" pos="punct" morph="none" start_char="1588" end_char="1588">,</TOKEN>
<TOKEN id="token-9-32" pos="word" morph="none" start_char="1590" end_char="1591">ya</TOKEN>
<TOKEN id="token-9-33" pos="word" morph="none" start_char="1593" end_char="1595">que</TOKEN>
<TOKEN id="token-9-34" pos="word" morph="none" start_char="1597" end_char="1598">se</TOKEN>
<TOKEN id="token-9-35" pos="word" morph="none" start_char="1600" end_char="1605">parece</TOKEN>
<TOKEN id="token-9-36" pos="word" morph="none" start_char="1607" end_char="1607">a</TOKEN>
<TOKEN id="token-9-37" pos="word" morph="none" start_char="1609" end_char="1610">un</TOKEN>
<TOKEN id="token-9-38" pos="word" morph="none" start_char="1612" end_char="1616">virus</TOKEN>
<TOKEN id="token-9-39" pos="word" morph="none" start_char="1618" end_char="1620">que</TOKEN>
<TOKEN id="token-9-40" pos="word" morph="none" start_char="1622" end_char="1623">se</TOKEN>
<TOKEN id="token-9-41" pos="word" morph="none" start_char="1625" end_char="1631">detectó</TOKEN>
<TOKEN id="token-9-42" pos="word" morph="none" start_char="1633" end_char="1634">en</TOKEN>
<TOKEN id="token-9-43" pos="word" morph="none" start_char="1636" end_char="1639">2013</TOKEN>
<TOKEN id="token-9-44" pos="word" morph="none" start_char="1641" end_char="1642">en</TOKEN>
<TOKEN id="token-9-45" pos="word" morph="none" start_char="1644" end_char="1646">una</TOKEN>
<TOKEN id="token-9-46" pos="word" morph="none" start_char="1648" end_char="1652">cueva</TOKEN>
<TOKEN id="token-9-47" pos="word" morph="none" start_char="1654" end_char="1655">de</TOKEN>
<TOKEN id="token-9-48" pos="word" morph="none" start_char="1657" end_char="1667">murciélagos</TOKEN>
<TOKEN id="token-9-49" pos="word" morph="none" start_char="1669" end_char="1670">de</TOKEN>
<TOKEN id="token-9-50" pos="word" morph="none" start_char="1672" end_char="1673">la</TOKEN>
<TOKEN id="token-9-51" pos="word" morph="none" start_char="1675" end_char="1683">provincia</TOKEN>
<TOKEN id="token-9-52" pos="word" morph="none" start_char="1685" end_char="1686">de</TOKEN>
<TOKEN id="token-9-53" pos="word" morph="none" start_char="1688" end_char="1693">Yunnan</TOKEN>
<TOKEN id="token-9-54" pos="punct" morph="none" start_char="1694" end_char="1694">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1697" end_char="1853">
<ORIGINAL_TEXT>Sin embargo, subrayó que es necesario investigar en Wuhan y alrededores y examinar con más meticulosidad los primeros casos que se registraron en esa ciudad.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1697" end_char="1699">Sin</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1701" end_char="1707">embargo</TOKEN>
<TOKEN id="token-10-2" pos="punct" morph="none" start_char="1708" end_char="1708">,</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1710" end_char="1716">subrayó</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1718" end_char="1720">que</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1722" end_char="1723">es</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1725" end_char="1733">necesario</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1735" end_char="1744">investigar</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1746" end_char="1747">en</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1749" end_char="1753">Wuhan</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1755" end_char="1755">y</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1757" end_char="1767">alrededores</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1769" end_char="1769">y</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1771" end_char="1778">examinar</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1780" end_char="1782">con</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1784" end_char="1786">más</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1788" end_char="1800">meticulosidad</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1802" end_char="1804">los</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1806" end_char="1813">primeros</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1815" end_char="1819">casos</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1821" end_char="1823">que</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1825" end_char="1826">se</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1828" end_char="1838">registraron</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1840" end_char="1841">en</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1843" end_char="1845">esa</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="1847" end_char="1852">ciudad</TOKEN>
<TOKEN id="token-10-26" pos="punct" morph="none" start_char="1853" end_char="1853">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
