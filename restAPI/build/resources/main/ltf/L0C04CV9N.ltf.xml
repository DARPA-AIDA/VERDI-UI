<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CV9N" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="5373" raw_text_md5="87a9f725d0cfa24313c97f2d4b8916c6">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="112">
<ORIGINAL_TEXT>Coronavirus: en un estudio nacional, concluyeron que el plasma de recuperados no es eficaz para los casos graves</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="11">Coronavirus</TOKEN>
<TOKEN id="token-0-1" pos="punct" morph="none" start_char="12" end_char="12">:</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="14" end_char="15">en</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="17" end_char="18">un</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="20" end_char="26">estudio</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="28" end_char="35">nacional</TOKEN>
<TOKEN id="token-0-6" pos="punct" morph="none" start_char="36" end_char="36">,</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="38" end_char="48">concluyeron</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="50" end_char="52">que</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="54" end_char="55">el</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="57" end_char="62">plasma</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="64" end_char="65">de</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="67" end_char="77">recuperados</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="79" end_char="80">no</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="82" end_char="83">es</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="85" end_char="90">eficaz</TOKEN>
<TOKEN id="token-0-16" pos="word" morph="none" start_char="92" end_char="95">para</TOKEN>
<TOKEN id="token-0-17" pos="word" morph="none" start_char="97" end_char="99">los</TOKEN>
<TOKEN id="token-0-18" pos="word" morph="none" start_char="101" end_char="105">casos</TOKEN>
<TOKEN id="token-0-19" pos="word" morph="none" start_char="107" end_char="112">graves</TOKEN>
</SEG>
<SEG id="segment-1" start_char="116" end_char="269">
<ORIGINAL_TEXT>El trabajo, que impulsaron 12 centros médicos del país, se hizo en 334 pacientes, de los cuales a 222 se les dio plasma y a los demás, una solución salina</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="116" end_char="117">El</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="119" end_char="125">trabajo</TOKEN>
<TOKEN id="token-1-2" pos="punct" morph="none" start_char="126" end_char="126">,</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="128" end_char="130">que</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="132" end_char="141">impulsaron</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="143" end_char="144">12</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="146" end_char="152">centros</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="154" end_char="160">médicos</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="162" end_char="164">del</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="166" end_char="169">país</TOKEN>
<TOKEN id="token-1-10" pos="punct" morph="none" start_char="170" end_char="170">,</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="172" end_char="173">se</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="175" end_char="178">hizo</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="180" end_char="181">en</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="183" end_char="185">334</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="187" end_char="195">pacientes</TOKEN>
<TOKEN id="token-1-16" pos="punct" morph="none" start_char="196" end_char="196">,</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="198" end_char="199">de</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="201" end_char="203">los</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="205" end_char="210">cuales</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="212" end_char="212">a</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="214" end_char="216">222</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="218" end_char="219">se</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="221" end_char="223">les</TOKEN>
<TOKEN id="token-1-24" pos="word" morph="none" start_char="225" end_char="227">dio</TOKEN>
<TOKEN id="token-1-25" pos="word" morph="none" start_char="229" end_char="234">plasma</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="236" end_char="236">y</TOKEN>
<TOKEN id="token-1-27" pos="word" morph="none" start_char="238" end_char="238">a</TOKEN>
<TOKEN id="token-1-28" pos="word" morph="none" start_char="240" end_char="242">los</TOKEN>
<TOKEN id="token-1-29" pos="word" morph="none" start_char="244" end_char="248">demás</TOKEN>
<TOKEN id="token-1-30" pos="punct" morph="none" start_char="249" end_char="249">,</TOKEN>
<TOKEN id="token-1-31" pos="word" morph="none" start_char="251" end_char="253">una</TOKEN>
<TOKEN id="token-1-32" pos="word" morph="none" start_char="255" end_char="262">solución</TOKEN>
<TOKEN id="token-1-33" pos="word" morph="none" start_char="264" end_char="269">salina</TOKEN>
</SEG>
<SEG id="segment-2" start_char="273" end_char="284">
<ORIGINAL_TEXT>No funciona.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="273" end_char="274">No</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="276" end_char="283">funciona</TOKEN>
<TOKEN id="token-2-2" pos="punct" morph="none" start_char="284" end_char="284">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="286" end_char="526">
<ORIGINAL_TEXT>Pese a que se usaba ampliamente, y se lo anunció como que salvaba vidas, el plasma de convalecientes del Covid-19 aún no contaba con evidencia suficiente para saber con qué grado de efectividad puede convertirse en un tratamiento comprobado.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="286" end_char="289">Pese</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="291" end_char="291">a</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="293" end_char="295">que</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="297" end_char="298">se</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="300" end_char="304">usaba</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="306" end_char="316">ampliamente</TOKEN>
<TOKEN id="token-3-6" pos="punct" morph="none" start_char="317" end_char="317">,</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="319" end_char="319">y</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="321" end_char="322">se</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="324" end_char="325">lo</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="327" end_char="333">anunció</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="335" end_char="338">como</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="340" end_char="342">que</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="344" end_char="350">salvaba</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="352" end_char="356">vidas</TOKEN>
<TOKEN id="token-3-15" pos="punct" morph="none" start_char="357" end_char="357">,</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="359" end_char="360">el</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="362" end_char="367">plasma</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="369" end_char="370">de</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="372" end_char="385">convalecientes</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="387" end_char="389">del</TOKEN>
<TOKEN id="token-3-21" pos="unknown" morph="none" start_char="391" end_char="398">Covid-19</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="400" end_char="402">aún</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="404" end_char="405">no</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="407" end_char="413">contaba</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="415" end_char="417">con</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="419" end_char="427">evidencia</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="429" end_char="438">suficiente</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="440" end_char="443">para</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="445" end_char="449">saber</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="451" end_char="453">con</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="455" end_char="457">qué</TOKEN>
<TOKEN id="token-3-32" pos="word" morph="none" start_char="459" end_char="463">grado</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="465" end_char="466">de</TOKEN>
<TOKEN id="token-3-34" pos="word" morph="none" start_char="468" end_char="478">efectividad</TOKEN>
<TOKEN id="token-3-35" pos="word" morph="none" start_char="480" end_char="484">puede</TOKEN>
<TOKEN id="token-3-36" pos="word" morph="none" start_char="486" end_char="496">convertirse</TOKEN>
<TOKEN id="token-3-37" pos="word" morph="none" start_char="498" end_char="499">en</TOKEN>
<TOKEN id="token-3-38" pos="word" morph="none" start_char="501" end_char="502">un</TOKEN>
<TOKEN id="token-3-39" pos="word" morph="none" start_char="504" end_char="514">tratamiento</TOKEN>
<TOKEN id="token-3-40" pos="word" morph="none" start_char="516" end_char="525">comprobado</TOKEN>
<TOKEN id="token-3-41" pos="punct" morph="none" start_char="526" end_char="526">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="528" end_char="635">
<ORIGINAL_TEXT>Y el primer trabajo realizado en profundidad sobre el potencial tratamiento no caminó por la senda esperada.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="528" end_char="528">Y</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="530" end_char="531">el</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="533" end_char="538">primer</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="540" end_char="546">trabajo</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="548" end_char="556">realizado</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="558" end_char="559">en</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="561" end_char="571">profundidad</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="573" end_char="577">sobre</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="579" end_char="580">el</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="582" end_char="590">potencial</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="592" end_char="602">tratamiento</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="604" end_char="605">no</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="607" end_char="612">caminó</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="614" end_char="616">por</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="618" end_char="619">la</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="621" end_char="625">senda</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="627" end_char="634">esperada</TOKEN>
<TOKEN id="token-4-17" pos="punct" morph="none" start_char="635" end_char="635">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="638" end_char="1086">
<ORIGINAL_TEXT>"Los resultados del estudio PlasmAr muestran que entre los pacientes hospitalizados con neumonía por Covid-19 con criterios de gravedad el uso de plasma de convalecientes no produjo un beneficio clínico significativo a los 7, 14 o 30 días de seguimiento en comparación con el uso de placebo", dice la información de prensa filtrada en redes sociales, pese a que había una convocatoria a periodistas para mañana, donde los médicos darán más detalles.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="punct" morph="none" start_char="638" end_char="638">"</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="639" end_char="641">Los</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="643" end_char="652">resultados</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="654" end_char="656">del</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="658" end_char="664">estudio</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="666" end_char="672">PlasmAr</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="674" end_char="681">muestran</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="683" end_char="685">que</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="687" end_char="691">entre</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="693" end_char="695">los</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="697" end_char="705">pacientes</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="707" end_char="720">hospitalizados</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="722" end_char="724">con</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="726" end_char="733">neumonía</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="735" end_char="737">por</TOKEN>
<TOKEN id="token-5-15" pos="unknown" morph="none" start_char="739" end_char="746">Covid-19</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="748" end_char="750">con</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="752" end_char="760">criterios</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="762" end_char="763">de</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="765" end_char="772">gravedad</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="774" end_char="775">el</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="777" end_char="779">uso</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="781" end_char="782">de</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="784" end_char="789">plasma</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="791" end_char="792">de</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="794" end_char="807">convalecientes</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="809" end_char="810">no</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="812" end_char="818">produjo</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="820" end_char="821">un</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="823" end_char="831">beneficio</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="833" end_char="839">clínico</TOKEN>
<TOKEN id="token-5-31" pos="word" morph="none" start_char="841" end_char="853">significativo</TOKEN>
<TOKEN id="token-5-32" pos="word" morph="none" start_char="855" end_char="855">a</TOKEN>
<TOKEN id="token-5-33" pos="word" morph="none" start_char="857" end_char="859">los</TOKEN>
<TOKEN id="token-5-34" pos="word" morph="none" start_char="861" end_char="861">7</TOKEN>
<TOKEN id="token-5-35" pos="punct" morph="none" start_char="862" end_char="862">,</TOKEN>
<TOKEN id="token-5-36" pos="word" morph="none" start_char="864" end_char="865">14</TOKEN>
<TOKEN id="token-5-37" pos="word" morph="none" start_char="867" end_char="867">o</TOKEN>
<TOKEN id="token-5-38" pos="word" morph="none" start_char="869" end_char="870">30</TOKEN>
<TOKEN id="token-5-39" pos="word" morph="none" start_char="872" end_char="875">días</TOKEN>
<TOKEN id="token-5-40" pos="word" morph="none" start_char="877" end_char="878">de</TOKEN>
<TOKEN id="token-5-41" pos="word" morph="none" start_char="880" end_char="890">seguimiento</TOKEN>
<TOKEN id="token-5-42" pos="word" morph="none" start_char="892" end_char="893">en</TOKEN>
<TOKEN id="token-5-43" pos="word" morph="none" start_char="895" end_char="905">comparación</TOKEN>
<TOKEN id="token-5-44" pos="word" morph="none" start_char="907" end_char="909">con</TOKEN>
<TOKEN id="token-5-45" pos="word" morph="none" start_char="911" end_char="912">el</TOKEN>
<TOKEN id="token-5-46" pos="word" morph="none" start_char="914" end_char="916">uso</TOKEN>
<TOKEN id="token-5-47" pos="word" morph="none" start_char="918" end_char="919">de</TOKEN>
<TOKEN id="token-5-48" pos="word" morph="none" start_char="921" end_char="927">placebo</TOKEN>
<TOKEN id="token-5-49" pos="punct" morph="none" start_char="928" end_char="929">",</TOKEN>
<TOKEN id="token-5-50" pos="word" morph="none" start_char="931" end_char="934">dice</TOKEN>
<TOKEN id="token-5-51" pos="word" morph="none" start_char="936" end_char="937">la</TOKEN>
<TOKEN id="token-5-52" pos="word" morph="none" start_char="939" end_char="949">información</TOKEN>
<TOKEN id="token-5-53" pos="word" morph="none" start_char="951" end_char="952">de</TOKEN>
<TOKEN id="token-5-54" pos="word" morph="none" start_char="954" end_char="959">prensa</TOKEN>
<TOKEN id="token-5-55" pos="word" morph="none" start_char="961" end_char="968">filtrada</TOKEN>
<TOKEN id="token-5-56" pos="word" morph="none" start_char="970" end_char="971">en</TOKEN>
<TOKEN id="token-5-57" pos="word" morph="none" start_char="973" end_char="977">redes</TOKEN>
<TOKEN id="token-5-58" pos="word" morph="none" start_char="979" end_char="986">sociales</TOKEN>
<TOKEN id="token-5-59" pos="punct" morph="none" start_char="987" end_char="987">,</TOKEN>
<TOKEN id="token-5-60" pos="word" morph="none" start_char="989" end_char="992">pese</TOKEN>
<TOKEN id="token-5-61" pos="word" morph="none" start_char="994" end_char="994">a</TOKEN>
<TOKEN id="token-5-62" pos="word" morph="none" start_char="996" end_char="998">que</TOKEN>
<TOKEN id="token-5-63" pos="word" morph="none" start_char="1000" end_char="1004">había</TOKEN>
<TOKEN id="token-5-64" pos="word" morph="none" start_char="1006" end_char="1008">una</TOKEN>
<TOKEN id="token-5-65" pos="word" morph="none" start_char="1010" end_char="1021">convocatoria</TOKEN>
<TOKEN id="token-5-66" pos="word" morph="none" start_char="1023" end_char="1023">a</TOKEN>
<TOKEN id="token-5-67" pos="word" morph="none" start_char="1025" end_char="1035">periodistas</TOKEN>
<TOKEN id="token-5-68" pos="word" morph="none" start_char="1037" end_char="1040">para</TOKEN>
<TOKEN id="token-5-69" pos="word" morph="none" start_char="1042" end_char="1047">mañana</TOKEN>
<TOKEN id="token-5-70" pos="punct" morph="none" start_char="1048" end_char="1048">,</TOKEN>
<TOKEN id="token-5-71" pos="word" morph="none" start_char="1050" end_char="1054">donde</TOKEN>
<TOKEN id="token-5-72" pos="word" morph="none" start_char="1056" end_char="1058">los</TOKEN>
<TOKEN id="token-5-73" pos="word" morph="none" start_char="1060" end_char="1066">médicos</TOKEN>
<TOKEN id="token-5-74" pos="word" morph="none" start_char="1068" end_char="1072">darán</TOKEN>
<TOKEN id="token-5-75" pos="word" morph="none" start_char="1074" end_char="1076">más</TOKEN>
<TOKEN id="token-5-76" pos="word" morph="none" start_char="1078" end_char="1085">detalles</TOKEN>
<TOKEN id="token-5-77" pos="punct" morph="none" start_char="1086" end_char="1086">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="1089" end_char="1344">
<ORIGINAL_TEXT>El trabajo fue hecho por un grupo de investigadores argentinos del Hospital Italiano de Buenos Aires y otros once hospitales del país, y es la primera investigación hecha en todo el mundo con los debidos requerimientos de la mejor prueba médica científica.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="1089" end_char="1090">El</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="1092" end_char="1098">trabajo</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="1100" end_char="1102">fue</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="1104" end_char="1108">hecho</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="1110" end_char="1112">por</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="1114" end_char="1115">un</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="1117" end_char="1121">grupo</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="1123" end_char="1124">de</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="1126" end_char="1139">investigadores</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="1141" end_char="1150">argentinos</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="1152" end_char="1154">del</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="1156" end_char="1163">Hospital</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="1165" end_char="1172">Italiano</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="1174" end_char="1175">de</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="1177" end_char="1182">Buenos</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="1184" end_char="1188">Aires</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="1190" end_char="1190">y</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="1192" end_char="1196">otros</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="1198" end_char="1201">once</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="1203" end_char="1212">hospitales</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="1214" end_char="1216">del</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="1218" end_char="1221">país</TOKEN>
<TOKEN id="token-6-22" pos="punct" morph="none" start_char="1222" end_char="1222">,</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="1224" end_char="1224">y</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="1226" end_char="1227">es</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="1229" end_char="1230">la</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="1232" end_char="1238">primera</TOKEN>
<TOKEN id="token-6-27" pos="word" morph="none" start_char="1240" end_char="1252">investigación</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="1254" end_char="1258">hecha</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="1260" end_char="1261">en</TOKEN>
<TOKEN id="token-6-30" pos="word" morph="none" start_char="1263" end_char="1266">todo</TOKEN>
<TOKEN id="token-6-31" pos="word" morph="none" start_char="1268" end_char="1269">el</TOKEN>
<TOKEN id="token-6-32" pos="word" morph="none" start_char="1271" end_char="1275">mundo</TOKEN>
<TOKEN id="token-6-33" pos="word" morph="none" start_char="1277" end_char="1279">con</TOKEN>
<TOKEN id="token-6-34" pos="word" morph="none" start_char="1281" end_char="1283">los</TOKEN>
<TOKEN id="token-6-35" pos="word" morph="none" start_char="1285" end_char="1291">debidos</TOKEN>
<TOKEN id="token-6-36" pos="word" morph="none" start_char="1293" end_char="1306">requerimientos</TOKEN>
<TOKEN id="token-6-37" pos="word" morph="none" start_char="1308" end_char="1309">de</TOKEN>
<TOKEN id="token-6-38" pos="word" morph="none" start_char="1311" end_char="1312">la</TOKEN>
<TOKEN id="token-6-39" pos="word" morph="none" start_char="1314" end_char="1318">mejor</TOKEN>
<TOKEN id="token-6-40" pos="word" morph="none" start_char="1320" end_char="1325">prueba</TOKEN>
<TOKEN id="token-6-41" pos="word" morph="none" start_char="1327" end_char="1332">médica</TOKEN>
<TOKEN id="token-6-42" pos="word" morph="none" start_char="1334" end_char="1343">científica</TOKEN>
<TOKEN id="token-6-43" pos="punct" morph="none" start_char="1344" end_char="1344">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="1346" end_char="1513">
<ORIGINAL_TEXT>El trabajo se hizo en 334 pacientes, de los cuales a 222 se les dio plasma y a los demás, una solución salina; el promedio de edad fue de 62 años con un 68% de hombres.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="1346" end_char="1347">El</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="1349" end_char="1355">trabajo</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="1357" end_char="1358">se</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="1360" end_char="1363">hizo</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="1365" end_char="1366">en</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="1368" end_char="1370">334</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="1372" end_char="1380">pacientes</TOKEN>
<TOKEN id="token-7-7" pos="punct" morph="none" start_char="1381" end_char="1381">,</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="1383" end_char="1384">de</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="1386" end_char="1388">los</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="1390" end_char="1395">cuales</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="1397" end_char="1397">a</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="1399" end_char="1401">222</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="1403" end_char="1404">se</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="1406" end_char="1408">les</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="1410" end_char="1412">dio</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="1414" end_char="1419">plasma</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="1421" end_char="1421">y</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="1423" end_char="1423">a</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="1425" end_char="1427">los</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="1429" end_char="1433">demás</TOKEN>
<TOKEN id="token-7-21" pos="punct" morph="none" start_char="1434" end_char="1434">,</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="1436" end_char="1438">una</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="1440" end_char="1447">solución</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="1449" end_char="1454">salina</TOKEN>
<TOKEN id="token-7-25" pos="punct" morph="none" start_char="1455" end_char="1455">;</TOKEN>
<TOKEN id="token-7-26" pos="word" morph="none" start_char="1457" end_char="1458">el</TOKEN>
<TOKEN id="token-7-27" pos="word" morph="none" start_char="1460" end_char="1467">promedio</TOKEN>
<TOKEN id="token-7-28" pos="word" morph="none" start_char="1469" end_char="1470">de</TOKEN>
<TOKEN id="token-7-29" pos="word" morph="none" start_char="1472" end_char="1475">edad</TOKEN>
<TOKEN id="token-7-30" pos="word" morph="none" start_char="1477" end_char="1479">fue</TOKEN>
<TOKEN id="token-7-31" pos="word" morph="none" start_char="1481" end_char="1482">de</TOKEN>
<TOKEN id="token-7-32" pos="word" morph="none" start_char="1484" end_char="1485">62</TOKEN>
<TOKEN id="token-7-33" pos="word" morph="none" start_char="1487" end_char="1490">años</TOKEN>
<TOKEN id="token-7-34" pos="word" morph="none" start_char="1492" end_char="1494">con</TOKEN>
<TOKEN id="token-7-35" pos="word" morph="none" start_char="1496" end_char="1497">un</TOKEN>
<TOKEN id="token-7-36" pos="word" morph="none" start_char="1499" end_char="1500">68</TOKEN>
<TOKEN id="token-7-37" pos="punct" morph="none" start_char="1501" end_char="1501">%</TOKEN>
<TOKEN id="token-7-38" pos="word" morph="none" start_char="1503" end_char="1504">de</TOKEN>
<TOKEN id="token-7-39" pos="word" morph="none" start_char="1506" end_char="1512">hombres</TOKEN>
<TOKEN id="token-7-40" pos="punct" morph="none" start_char="1513" end_char="1513">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1516" end_char="1631">
<ORIGINAL_TEXT>El resto de los detalles técnicos serán publicados en las próximas semanas, primero mediante la opción conocida como</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1516" end_char="1517">El</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1519" end_char="1523">resto</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1525" end_char="1526">de</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1528" end_char="1530">los</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1532" end_char="1539">detalles</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1541" end_char="1548">técnicos</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1550" end_char="1554">serán</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1556" end_char="1565">publicados</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1567" end_char="1568">en</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1570" end_char="1572">las</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1574" end_char="1581">próximas</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1583" end_char="1589">semanas</TOKEN>
<TOKEN id="token-8-12" pos="punct" morph="none" start_char="1590" end_char="1590">,</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1592" end_char="1598">primero</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1600" end_char="1607">mediante</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1609" end_char="1610">la</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1612" end_char="1617">opción</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1619" end_char="1626">conocida</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1628" end_char="1631">como</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1634" end_char="1641">
<ORIGINAL_TEXT>preprint</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1634" end_char="1641">preprint</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1644" end_char="1723">
<ORIGINAL_TEXT>y luego posiblemente en una de las revistas de medicina más importante del mundo</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1644" end_char="1644">y</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1646" end_char="1650">luego</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1652" end_char="1663">posiblemente</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1665" end_char="1666">en</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1668" end_char="1670">una</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1672" end_char="1673">de</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1675" end_char="1677">las</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1679" end_char="1686">revistas</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1688" end_char="1689">de</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1691" end_char="1698">medicina</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1700" end_char="1702">más</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1704" end_char="1713">importante</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1715" end_char="1717">del</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1719" end_char="1723">mundo</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1726" end_char="1726">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="punct" morph="none" start_char="1726" end_char="1726">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1730" end_char="1992">
<ORIGINAL_TEXT>El plasma de convaleciente, es decir, de personas que tuvieron la enfermedad y se recuperaron, fue uno de los primeros tratamientos para el Covid usados, porque funciona para otras enfermedades infecciosas con éxito (por ejemplo, la fiebre hemorrágica argentina).</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1730" end_char="1731">El</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1733" end_char="1738">plasma</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1740" end_char="1741">de</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1743" end_char="1755">convaleciente</TOKEN>
<TOKEN id="token-12-4" pos="punct" morph="none" start_char="1756" end_char="1756">,</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1758" end_char="1759">es</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1761" end_char="1765">decir</TOKEN>
<TOKEN id="token-12-7" pos="punct" morph="none" start_char="1766" end_char="1766">,</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1768" end_char="1769">de</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1771" end_char="1778">personas</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1780" end_char="1782">que</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1784" end_char="1791">tuvieron</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1793" end_char="1794">la</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1796" end_char="1805">enfermedad</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1807" end_char="1807">y</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1809" end_char="1810">se</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1812" end_char="1822">recuperaron</TOKEN>
<TOKEN id="token-12-17" pos="punct" morph="none" start_char="1823" end_char="1823">,</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1825" end_char="1827">fue</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1829" end_char="1831">uno</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1833" end_char="1834">de</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1836" end_char="1838">los</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1840" end_char="1847">primeros</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="1849" end_char="1860">tratamientos</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="1862" end_char="1865">para</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="1867" end_char="1868">el</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="1870" end_char="1874">Covid</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="1876" end_char="1881">usados</TOKEN>
<TOKEN id="token-12-28" pos="punct" morph="none" start_char="1882" end_char="1882">,</TOKEN>
<TOKEN id="token-12-29" pos="word" morph="none" start_char="1884" end_char="1889">porque</TOKEN>
<TOKEN id="token-12-30" pos="word" morph="none" start_char="1891" end_char="1898">funciona</TOKEN>
<TOKEN id="token-12-31" pos="word" morph="none" start_char="1900" end_char="1903">para</TOKEN>
<TOKEN id="token-12-32" pos="word" morph="none" start_char="1905" end_char="1909">otras</TOKEN>
<TOKEN id="token-12-33" pos="word" morph="none" start_char="1911" end_char="1922">enfermedades</TOKEN>
<TOKEN id="token-12-34" pos="word" morph="none" start_char="1924" end_char="1934">infecciosas</TOKEN>
<TOKEN id="token-12-35" pos="word" morph="none" start_char="1936" end_char="1938">con</TOKEN>
<TOKEN id="token-12-36" pos="word" morph="none" start_char="1940" end_char="1944">éxito</TOKEN>
<TOKEN id="token-12-37" pos="punct" morph="none" start_char="1946" end_char="1946">(</TOKEN>
<TOKEN id="token-12-38" pos="word" morph="none" start_char="1947" end_char="1949">por</TOKEN>
<TOKEN id="token-12-39" pos="word" morph="none" start_char="1951" end_char="1957">ejemplo</TOKEN>
<TOKEN id="token-12-40" pos="punct" morph="none" start_char="1958" end_char="1958">,</TOKEN>
<TOKEN id="token-12-41" pos="word" morph="none" start_char="1960" end_char="1961">la</TOKEN>
<TOKEN id="token-12-42" pos="word" morph="none" start_char="1963" end_char="1968">fiebre</TOKEN>
<TOKEN id="token-12-43" pos="word" morph="none" start_char="1970" end_char="1980">hemorrágica</TOKEN>
<TOKEN id="token-12-44" pos="word" morph="none" start_char="1982" end_char="1990">argentina</TOKEN>
<TOKEN id="token-12-45" pos="punct" morph="none" start_char="1991" end_char="1992">).</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1994" end_char="2130">
<ORIGINAL_TEXT>Y se basa en la idea de que los anticuerpos de una persona pueden responder en otra hasta que se genera la respuesta inmunológica propia.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1994" end_char="1994">Y</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1996" end_char="1997">se</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1999" end_char="2002">basa</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="2004" end_char="2005">en</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="2007" end_char="2008">la</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="2010" end_char="2013">idea</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="2015" end_char="2016">de</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="2018" end_char="2020">que</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="2022" end_char="2024">los</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="2026" end_char="2036">anticuerpos</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="2038" end_char="2039">de</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="2041" end_char="2043">una</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="2045" end_char="2051">persona</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="2053" end_char="2058">pueden</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="2060" end_char="2068">responder</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="2070" end_char="2071">en</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="2073" end_char="2076">otra</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="2078" end_char="2082">hasta</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="2084" end_char="2086">que</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="2088" end_char="2089">se</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="2091" end_char="2096">genera</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="2098" end_char="2099">la</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="2101" end_char="2109">respuesta</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="2111" end_char="2122">inmunológica</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="2124" end_char="2129">propia</TOKEN>
<TOKEN id="token-13-25" pos="punct" morph="none" start_char="2130" end_char="2130">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="2133" end_char="2480">
<ORIGINAL_TEXT>Pero, por raro que parezca y a más de nueve meses de aparecer el nuevo coronavirus, aún no existía un trabajo así de completo como el llevado a cabo por el equipo argentino, pese a que diversos estados de todo el mundo han gastado millones de dólares en la promoción y el uso del plasma como si se tratara de un tratamiento convencional y aprobado.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="2133" end_char="2136">Pero</TOKEN>
<TOKEN id="token-14-1" pos="punct" morph="none" start_char="2137" end_char="2137">,</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="2139" end_char="2141">por</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="2143" end_char="2146">raro</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="2148" end_char="2150">que</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="2152" end_char="2158">parezca</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="2160" end_char="2160">y</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="2162" end_char="2162">a</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="2164" end_char="2166">más</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="2168" end_char="2169">de</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="2171" end_char="2175">nueve</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="2177" end_char="2181">meses</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="2183" end_char="2184">de</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="2186" end_char="2193">aparecer</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="2195" end_char="2196">el</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="2198" end_char="2202">nuevo</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="2204" end_char="2214">coronavirus</TOKEN>
<TOKEN id="token-14-17" pos="punct" morph="none" start_char="2215" end_char="2215">,</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="2217" end_char="2219">aún</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="2221" end_char="2222">no</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="2224" end_char="2230">existía</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="2232" end_char="2233">un</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="2235" end_char="2241">trabajo</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="2243" end_char="2245">así</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="2247" end_char="2248">de</TOKEN>
<TOKEN id="token-14-25" pos="word" morph="none" start_char="2250" end_char="2257">completo</TOKEN>
<TOKEN id="token-14-26" pos="word" morph="none" start_char="2259" end_char="2262">como</TOKEN>
<TOKEN id="token-14-27" pos="word" morph="none" start_char="2264" end_char="2265">el</TOKEN>
<TOKEN id="token-14-28" pos="word" morph="none" start_char="2267" end_char="2273">llevado</TOKEN>
<TOKEN id="token-14-29" pos="word" morph="none" start_char="2275" end_char="2275">a</TOKEN>
<TOKEN id="token-14-30" pos="word" morph="none" start_char="2277" end_char="2280">cabo</TOKEN>
<TOKEN id="token-14-31" pos="word" morph="none" start_char="2282" end_char="2284">por</TOKEN>
<TOKEN id="token-14-32" pos="word" morph="none" start_char="2286" end_char="2287">el</TOKEN>
<TOKEN id="token-14-33" pos="word" morph="none" start_char="2289" end_char="2294">equipo</TOKEN>
<TOKEN id="token-14-34" pos="word" morph="none" start_char="2296" end_char="2304">argentino</TOKEN>
<TOKEN id="token-14-35" pos="punct" morph="none" start_char="2305" end_char="2305">,</TOKEN>
<TOKEN id="token-14-36" pos="word" morph="none" start_char="2307" end_char="2310">pese</TOKEN>
<TOKEN id="token-14-37" pos="word" morph="none" start_char="2312" end_char="2312">a</TOKEN>
<TOKEN id="token-14-38" pos="word" morph="none" start_char="2314" end_char="2316">que</TOKEN>
<TOKEN id="token-14-39" pos="word" morph="none" start_char="2318" end_char="2325">diversos</TOKEN>
<TOKEN id="token-14-40" pos="word" morph="none" start_char="2327" end_char="2333">estados</TOKEN>
<TOKEN id="token-14-41" pos="word" morph="none" start_char="2335" end_char="2336">de</TOKEN>
<TOKEN id="token-14-42" pos="word" morph="none" start_char="2338" end_char="2341">todo</TOKEN>
<TOKEN id="token-14-43" pos="word" morph="none" start_char="2343" end_char="2344">el</TOKEN>
<TOKEN id="token-14-44" pos="word" morph="none" start_char="2346" end_char="2350">mundo</TOKEN>
<TOKEN id="token-14-45" pos="word" morph="none" start_char="2352" end_char="2354">han</TOKEN>
<TOKEN id="token-14-46" pos="word" morph="none" start_char="2356" end_char="2362">gastado</TOKEN>
<TOKEN id="token-14-47" pos="word" morph="none" start_char="2364" end_char="2371">millones</TOKEN>
<TOKEN id="token-14-48" pos="word" morph="none" start_char="2373" end_char="2374">de</TOKEN>
<TOKEN id="token-14-49" pos="word" morph="none" start_char="2376" end_char="2382">dólares</TOKEN>
<TOKEN id="token-14-50" pos="word" morph="none" start_char="2384" end_char="2385">en</TOKEN>
<TOKEN id="token-14-51" pos="word" morph="none" start_char="2387" end_char="2388">la</TOKEN>
<TOKEN id="token-14-52" pos="word" morph="none" start_char="2390" end_char="2398">promoción</TOKEN>
<TOKEN id="token-14-53" pos="word" morph="none" start_char="2400" end_char="2400">y</TOKEN>
<TOKEN id="token-14-54" pos="word" morph="none" start_char="2402" end_char="2403">el</TOKEN>
<TOKEN id="token-14-55" pos="word" morph="none" start_char="2405" end_char="2407">uso</TOKEN>
<TOKEN id="token-14-56" pos="word" morph="none" start_char="2409" end_char="2411">del</TOKEN>
<TOKEN id="token-14-57" pos="word" morph="none" start_char="2413" end_char="2418">plasma</TOKEN>
<TOKEN id="token-14-58" pos="word" morph="none" start_char="2420" end_char="2423">como</TOKEN>
<TOKEN id="token-14-59" pos="word" morph="none" start_char="2425" end_char="2426">si</TOKEN>
<TOKEN id="token-14-60" pos="word" morph="none" start_char="2428" end_char="2429">se</TOKEN>
<TOKEN id="token-14-61" pos="word" morph="none" start_char="2431" end_char="2437">tratara</TOKEN>
<TOKEN id="token-14-62" pos="word" morph="none" start_char="2439" end_char="2440">de</TOKEN>
<TOKEN id="token-14-63" pos="word" morph="none" start_char="2442" end_char="2443">un</TOKEN>
<TOKEN id="token-14-64" pos="word" morph="none" start_char="2445" end_char="2455">tratamiento</TOKEN>
<TOKEN id="token-14-65" pos="word" morph="none" start_char="2457" end_char="2468">convencional</TOKEN>
<TOKEN id="token-14-66" pos="word" morph="none" start_char="2470" end_char="2470">y</TOKEN>
<TOKEN id="token-14-67" pos="word" morph="none" start_char="2472" end_char="2479">aprobado</TOKEN>
<TOKEN id="token-14-68" pos="punct" morph="none" start_char="2480" end_char="2480">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="2482" end_char="2634">
<ORIGINAL_TEXT>Hasta ahora sólo había de los llamados "estudios observacionales", en los que no es posible medir qué hubiera pasado con el paciente sin ese tratamiento.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="2482" end_char="2486">Hasta</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="2488" end_char="2492">ahora</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="2494" end_char="2497">sólo</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="2499" end_char="2503">había</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="2505" end_char="2506">de</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="2508" end_char="2510">los</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="2512" end_char="2519">llamados</TOKEN>
<TOKEN id="token-15-7" pos="punct" morph="none" start_char="2521" end_char="2521">"</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="2522" end_char="2529">estudios</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="2531" end_char="2545">observacionales</TOKEN>
<TOKEN id="token-15-10" pos="punct" morph="none" start_char="2546" end_char="2547">",</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="2549" end_char="2550">en</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="2552" end_char="2554">los</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="2556" end_char="2558">que</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="2560" end_char="2561">no</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="2563" end_char="2564">es</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="2566" end_char="2572">posible</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="2574" end_char="2578">medir</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="2580" end_char="2582">qué</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="2584" end_char="2590">hubiera</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="2592" end_char="2597">pasado</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="2599" end_char="2601">con</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="2603" end_char="2604">el</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="2606" end_char="2613">paciente</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="2615" end_char="2617">sin</TOKEN>
<TOKEN id="token-15-25" pos="word" morph="none" start_char="2619" end_char="2621">ese</TOKEN>
<TOKEN id="token-15-26" pos="word" morph="none" start_char="2623" end_char="2633">tratamiento</TOKEN>
<TOKEN id="token-15-27" pos="punct" morph="none" start_char="2634" end_char="2634">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="2636" end_char="2804">
<ORIGINAL_TEXT>Ese sesgo es lo que busca eliminar los ensayos con placebo (una solución salina, en lugar del plasma) y "doble ciego" (ni el paciente ni el médico sabe qué da y recibe).</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="2636" end_char="2638">Ese</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="2640" end_char="2644">sesgo</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="2646" end_char="2647">es</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="2649" end_char="2650">lo</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="2652" end_char="2654">que</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="2656" end_char="2660">busca</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="2662" end_char="2669">eliminar</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="2671" end_char="2673">los</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="2675" end_char="2681">ensayos</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="2683" end_char="2685">con</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="2687" end_char="2693">placebo</TOKEN>
<TOKEN id="token-16-11" pos="punct" morph="none" start_char="2695" end_char="2695">(</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="2696" end_char="2698">una</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="2700" end_char="2707">solución</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="2709" end_char="2714">salina</TOKEN>
<TOKEN id="token-16-15" pos="punct" morph="none" start_char="2715" end_char="2715">,</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="2717" end_char="2718">en</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="2720" end_char="2724">lugar</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="2726" end_char="2728">del</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="2730" end_char="2735">plasma</TOKEN>
<TOKEN id="token-16-20" pos="punct" morph="none" start_char="2736" end_char="2736">)</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="2738" end_char="2738">y</TOKEN>
<TOKEN id="token-16-22" pos="punct" morph="none" start_char="2740" end_char="2740">"</TOKEN>
<TOKEN id="token-16-23" pos="word" morph="none" start_char="2741" end_char="2745">doble</TOKEN>
<TOKEN id="token-16-24" pos="word" morph="none" start_char="2747" end_char="2751">ciego</TOKEN>
<TOKEN id="token-16-25" pos="punct" morph="none" start_char="2752" end_char="2752">"</TOKEN>
<TOKEN id="token-16-26" pos="punct" morph="none" start_char="2754" end_char="2754">(</TOKEN>
<TOKEN id="token-16-27" pos="word" morph="none" start_char="2755" end_char="2756">ni</TOKEN>
<TOKEN id="token-16-28" pos="word" morph="none" start_char="2758" end_char="2759">el</TOKEN>
<TOKEN id="token-16-29" pos="word" morph="none" start_char="2761" end_char="2768">paciente</TOKEN>
<TOKEN id="token-16-30" pos="word" morph="none" start_char="2770" end_char="2771">ni</TOKEN>
<TOKEN id="token-16-31" pos="word" morph="none" start_char="2773" end_char="2774">el</TOKEN>
<TOKEN id="token-16-32" pos="word" morph="none" start_char="2776" end_char="2781">médico</TOKEN>
<TOKEN id="token-16-33" pos="word" morph="none" start_char="2783" end_char="2786">sabe</TOKEN>
<TOKEN id="token-16-34" pos="word" morph="none" start_char="2788" end_char="2790">qué</TOKEN>
<TOKEN id="token-16-35" pos="word" morph="none" start_char="2792" end_char="2793">da</TOKEN>
<TOKEN id="token-16-36" pos="word" morph="none" start_char="2795" end_char="2795">y</TOKEN>
<TOKEN id="token-16-37" pos="word" morph="none" start_char="2797" end_char="2802">recibe</TOKEN>
<TOKEN id="token-16-38" pos="punct" morph="none" start_char="2803" end_char="2804">).</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2807" end_char="2819">
<ORIGINAL_TEXT>Comparaciones</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2807" end_char="2819">Comparaciones</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2823" end_char="2952">
<ORIGINAL_TEXT>Hasta ahora, de los 408 estudios en todo el mundo registrados con plasma para Covid-19, no había ninguno de estas características.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2823" end_char="2827">Hasta</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2829" end_char="2833">ahora</TOKEN>
<TOKEN id="token-18-2" pos="punct" morph="none" start_char="2834" end_char="2834">,</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2836" end_char="2837">de</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2839" end_char="2841">los</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2843" end_char="2845">408</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2847" end_char="2854">estudios</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2856" end_char="2857">en</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2859" end_char="2862">todo</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="2864" end_char="2865">el</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="2867" end_char="2871">mundo</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="2873" end_char="2883">registrados</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2885" end_char="2887">con</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="2889" end_char="2894">plasma</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="2896" end_char="2899">para</TOKEN>
<TOKEN id="token-18-15" pos="unknown" morph="none" start_char="2901" end_char="2908">Covid-19</TOKEN>
<TOKEN id="token-18-16" pos="punct" morph="none" start_char="2909" end_char="2909">,</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="2911" end_char="2912">no</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="2914" end_char="2918">había</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="2920" end_char="2926">ninguno</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="2928" end_char="2929">de</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="2931" end_char="2935">estas</TOKEN>
<TOKEN id="token-18-22" pos="word" morph="none" start_char="2937" end_char="2951">características</TOKEN>
<TOKEN id="token-18-23" pos="punct" morph="none" start_char="2952" end_char="2952">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2954" end_char="3049">
<ORIGINAL_TEXT>Los trabajos observacionales habían encontrado buenos resultados, pero no comparados en placebo.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2954" end_char="2956">Los</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2958" end_char="2965">trabajos</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2967" end_char="2981">observacionales</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2983" end_char="2988">habían</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2990" end_char="2999">encontrado</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="3001" end_char="3006">buenos</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="3008" end_char="3017">resultados</TOKEN>
<TOKEN id="token-19-7" pos="punct" morph="none" start_char="3018" end_char="3018">,</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="3020" end_char="3023">pero</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="3025" end_char="3026">no</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="3028" end_char="3037">comparados</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="3039" end_char="3040">en</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="3042" end_char="3048">placebo</TOKEN>
<TOKEN id="token-19-13" pos="punct" morph="none" start_char="3049" end_char="3049">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="3051" end_char="3402">
<ORIGINAL_TEXT>Desde la Clínica Mayo de los Estados Unidos, una de las principales en el uso del plasma, se dio a conocer un estudio titulado "Efecto del plasma de convalecientes en pacientes hospitalizados por Covid-19: experiencia inicial de tres meses", donde se había hallado una relación entre la transfusión de plasma y una menor mortalidad en 35.322 pacientes.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="3051" end_char="3055">Desde</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="3057" end_char="3058">la</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="3060" end_char="3066">Clínica</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="3068" end_char="3071">Mayo</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="3073" end_char="3074">de</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="3076" end_char="3078">los</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="3080" end_char="3086">Estados</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="3088" end_char="3093">Unidos</TOKEN>
<TOKEN id="token-20-8" pos="punct" morph="none" start_char="3094" end_char="3094">,</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="3096" end_char="3098">una</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="3100" end_char="3101">de</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="3103" end_char="3105">las</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="3107" end_char="3117">principales</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="3119" end_char="3120">en</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="3122" end_char="3123">el</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="3125" end_char="3127">uso</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="3129" end_char="3131">del</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="3133" end_char="3138">plasma</TOKEN>
<TOKEN id="token-20-18" pos="punct" morph="none" start_char="3139" end_char="3139">,</TOKEN>
<TOKEN id="token-20-19" pos="word" morph="none" start_char="3141" end_char="3142">se</TOKEN>
<TOKEN id="token-20-20" pos="word" morph="none" start_char="3144" end_char="3146">dio</TOKEN>
<TOKEN id="token-20-21" pos="word" morph="none" start_char="3148" end_char="3148">a</TOKEN>
<TOKEN id="token-20-22" pos="word" morph="none" start_char="3150" end_char="3156">conocer</TOKEN>
<TOKEN id="token-20-23" pos="word" morph="none" start_char="3158" end_char="3159">un</TOKEN>
<TOKEN id="token-20-24" pos="word" morph="none" start_char="3161" end_char="3167">estudio</TOKEN>
<TOKEN id="token-20-25" pos="word" morph="none" start_char="3169" end_char="3176">titulado</TOKEN>
<TOKEN id="token-20-26" pos="punct" morph="none" start_char="3178" end_char="3178">"</TOKEN>
<TOKEN id="token-20-27" pos="word" morph="none" start_char="3179" end_char="3184">Efecto</TOKEN>
<TOKEN id="token-20-28" pos="word" morph="none" start_char="3186" end_char="3188">del</TOKEN>
<TOKEN id="token-20-29" pos="word" morph="none" start_char="3190" end_char="3195">plasma</TOKEN>
<TOKEN id="token-20-30" pos="word" morph="none" start_char="3197" end_char="3198">de</TOKEN>
<TOKEN id="token-20-31" pos="word" morph="none" start_char="3200" end_char="3213">convalecientes</TOKEN>
<TOKEN id="token-20-32" pos="word" morph="none" start_char="3215" end_char="3216">en</TOKEN>
<TOKEN id="token-20-33" pos="word" morph="none" start_char="3218" end_char="3226">pacientes</TOKEN>
<TOKEN id="token-20-34" pos="word" morph="none" start_char="3228" end_char="3241">hospitalizados</TOKEN>
<TOKEN id="token-20-35" pos="word" morph="none" start_char="3243" end_char="3245">por</TOKEN>
<TOKEN id="token-20-36" pos="unknown" morph="none" start_char="3247" end_char="3254">Covid-19</TOKEN>
<TOKEN id="token-20-37" pos="punct" morph="none" start_char="3255" end_char="3255">:</TOKEN>
<TOKEN id="token-20-38" pos="word" morph="none" start_char="3257" end_char="3267">experiencia</TOKEN>
<TOKEN id="token-20-39" pos="word" morph="none" start_char="3269" end_char="3275">inicial</TOKEN>
<TOKEN id="token-20-40" pos="word" morph="none" start_char="3277" end_char="3278">de</TOKEN>
<TOKEN id="token-20-41" pos="word" morph="none" start_char="3280" end_char="3283">tres</TOKEN>
<TOKEN id="token-20-42" pos="word" morph="none" start_char="3285" end_char="3289">meses</TOKEN>
<TOKEN id="token-20-43" pos="punct" morph="none" start_char="3290" end_char="3291">",</TOKEN>
<TOKEN id="token-20-44" pos="word" morph="none" start_char="3293" end_char="3297">donde</TOKEN>
<TOKEN id="token-20-45" pos="word" morph="none" start_char="3299" end_char="3300">se</TOKEN>
<TOKEN id="token-20-46" pos="word" morph="none" start_char="3302" end_char="3306">había</TOKEN>
<TOKEN id="token-20-47" pos="word" morph="none" start_char="3308" end_char="3314">hallado</TOKEN>
<TOKEN id="token-20-48" pos="word" morph="none" start_char="3316" end_char="3318">una</TOKEN>
<TOKEN id="token-20-49" pos="word" morph="none" start_char="3320" end_char="3327">relación</TOKEN>
<TOKEN id="token-20-50" pos="word" morph="none" start_char="3329" end_char="3333">entre</TOKEN>
<TOKEN id="token-20-51" pos="word" morph="none" start_char="3335" end_char="3336">la</TOKEN>
<TOKEN id="token-20-52" pos="word" morph="none" start_char="3338" end_char="3348">transfusión</TOKEN>
<TOKEN id="token-20-53" pos="word" morph="none" start_char="3350" end_char="3351">de</TOKEN>
<TOKEN id="token-20-54" pos="word" morph="none" start_char="3353" end_char="3358">plasma</TOKEN>
<TOKEN id="token-20-55" pos="word" morph="none" start_char="3360" end_char="3360">y</TOKEN>
<TOKEN id="token-20-56" pos="word" morph="none" start_char="3362" end_char="3364">una</TOKEN>
<TOKEN id="token-20-57" pos="word" morph="none" start_char="3366" end_char="3370">menor</TOKEN>
<TOKEN id="token-20-58" pos="word" morph="none" start_char="3372" end_char="3381">mortalidad</TOKEN>
<TOKEN id="token-20-59" pos="word" morph="none" start_char="3383" end_char="3384">en</TOKEN>
<TOKEN id="token-20-60" pos="word" morph="none" start_char="3386" end_char="3391">35.322</TOKEN>
<TOKEN id="token-20-61" pos="word" morph="none" start_char="3393" end_char="3401">pacientes</TOKEN>
<TOKEN id="token-20-62" pos="punct" morph="none" start_char="3402" end_char="3402">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="3404" end_char="3538">
<ORIGINAL_TEXT>Pero a la vez habían reconocido que, en medio de la emergencia, no se había hecho el procedimiento mediante un protocolo estandarizado.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="3404" end_char="3407">Pero</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="3409" end_char="3409">a</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="3411" end_char="3412">la</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="3414" end_char="3416">vez</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="3418" end_char="3423">habían</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="3425" end_char="3434">reconocido</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="3436" end_char="3438">que</TOKEN>
<TOKEN id="token-21-7" pos="punct" morph="none" start_char="3439" end_char="3439">,</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="3441" end_char="3442">en</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="3444" end_char="3448">medio</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="3450" end_char="3451">de</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="3453" end_char="3454">la</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="3456" end_char="3465">emergencia</TOKEN>
<TOKEN id="token-21-13" pos="punct" morph="none" start_char="3466" end_char="3466">,</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="3468" end_char="3469">no</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="3471" end_char="3472">se</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="3474" end_char="3478">había</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="3480" end_char="3484">hecho</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="3486" end_char="3487">el</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="3489" end_char="3501">procedimiento</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="3503" end_char="3510">mediante</TOKEN>
<TOKEN id="token-21-21" pos="word" morph="none" start_char="3512" end_char="3513">un</TOKEN>
<TOKEN id="token-21-22" pos="word" morph="none" start_char="3515" end_char="3523">protocolo</TOKEN>
<TOKEN id="token-21-23" pos="word" morph="none" start_char="3525" end_char="3537">estandarizado</TOKEN>
<TOKEN id="token-21-24" pos="punct" morph="none" start_char="3538" end_char="3538">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="3541" end_char="3816">
<ORIGINAL_TEXT>Esa cuestión, la emergencia pandémica, fue justamente uno de los hechos que conspiraron contra la idea de generar ensayos con placebo: si el plasma es tan bueno, se pensaba, darle solución salina a un paciente que podía morir, podría ser intolerable para los comités de ética.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="3541" end_char="3543">Esa</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="3545" end_char="3552">cuestión</TOKEN>
<TOKEN id="token-22-2" pos="punct" morph="none" start_char="3553" end_char="3553">,</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="3555" end_char="3556">la</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="3558" end_char="3567">emergencia</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="3569" end_char="3577">pandémica</TOKEN>
<TOKEN id="token-22-6" pos="punct" morph="none" start_char="3578" end_char="3578">,</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="3580" end_char="3582">fue</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="3584" end_char="3593">justamente</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="3595" end_char="3597">uno</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="3599" end_char="3600">de</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="3602" end_char="3604">los</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="3606" end_char="3611">hechos</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="3613" end_char="3615">que</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="3617" end_char="3627">conspiraron</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="3629" end_char="3634">contra</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="3636" end_char="3637">la</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="3639" end_char="3642">idea</TOKEN>
<TOKEN id="token-22-18" pos="word" morph="none" start_char="3644" end_char="3645">de</TOKEN>
<TOKEN id="token-22-19" pos="word" morph="none" start_char="3647" end_char="3653">generar</TOKEN>
<TOKEN id="token-22-20" pos="word" morph="none" start_char="3655" end_char="3661">ensayos</TOKEN>
<TOKEN id="token-22-21" pos="word" morph="none" start_char="3663" end_char="3665">con</TOKEN>
<TOKEN id="token-22-22" pos="word" morph="none" start_char="3667" end_char="3673">placebo</TOKEN>
<TOKEN id="token-22-23" pos="punct" morph="none" start_char="3674" end_char="3674">:</TOKEN>
<TOKEN id="token-22-24" pos="word" morph="none" start_char="3676" end_char="3677">si</TOKEN>
<TOKEN id="token-22-25" pos="word" morph="none" start_char="3679" end_char="3680">el</TOKEN>
<TOKEN id="token-22-26" pos="word" morph="none" start_char="3682" end_char="3687">plasma</TOKEN>
<TOKEN id="token-22-27" pos="word" morph="none" start_char="3689" end_char="3690">es</TOKEN>
<TOKEN id="token-22-28" pos="word" morph="none" start_char="3692" end_char="3694">tan</TOKEN>
<TOKEN id="token-22-29" pos="word" morph="none" start_char="3696" end_char="3700">bueno</TOKEN>
<TOKEN id="token-22-30" pos="punct" morph="none" start_char="3701" end_char="3701">,</TOKEN>
<TOKEN id="token-22-31" pos="word" morph="none" start_char="3703" end_char="3704">se</TOKEN>
<TOKEN id="token-22-32" pos="word" morph="none" start_char="3706" end_char="3712">pensaba</TOKEN>
<TOKEN id="token-22-33" pos="punct" morph="none" start_char="3713" end_char="3713">,</TOKEN>
<TOKEN id="token-22-34" pos="word" morph="none" start_char="3715" end_char="3719">darle</TOKEN>
<TOKEN id="token-22-35" pos="word" morph="none" start_char="3721" end_char="3728">solución</TOKEN>
<TOKEN id="token-22-36" pos="word" morph="none" start_char="3730" end_char="3735">salina</TOKEN>
<TOKEN id="token-22-37" pos="word" morph="none" start_char="3737" end_char="3737">a</TOKEN>
<TOKEN id="token-22-38" pos="word" morph="none" start_char="3739" end_char="3740">un</TOKEN>
<TOKEN id="token-22-39" pos="word" morph="none" start_char="3742" end_char="3749">paciente</TOKEN>
<TOKEN id="token-22-40" pos="word" morph="none" start_char="3751" end_char="3753">que</TOKEN>
<TOKEN id="token-22-41" pos="word" morph="none" start_char="3755" end_char="3759">podía</TOKEN>
<TOKEN id="token-22-42" pos="word" morph="none" start_char="3761" end_char="3765">morir</TOKEN>
<TOKEN id="token-22-43" pos="punct" morph="none" start_char="3766" end_char="3766">,</TOKEN>
<TOKEN id="token-22-44" pos="word" morph="none" start_char="3768" end_char="3773">podría</TOKEN>
<TOKEN id="token-22-45" pos="word" morph="none" start_char="3775" end_char="3777">ser</TOKEN>
<TOKEN id="token-22-46" pos="word" morph="none" start_char="3779" end_char="3789">intolerable</TOKEN>
<TOKEN id="token-22-47" pos="word" morph="none" start_char="3791" end_char="3794">para</TOKEN>
<TOKEN id="token-22-48" pos="word" morph="none" start_char="3796" end_char="3798">los</TOKEN>
<TOKEN id="token-22-49" pos="word" morph="none" start_char="3800" end_char="3806">comités</TOKEN>
<TOKEN id="token-22-50" pos="word" morph="none" start_char="3808" end_char="3809">de</TOKEN>
<TOKEN id="token-22-51" pos="word" morph="none" start_char="3811" end_char="3815">ética</TOKEN>
<TOKEN id="token-22-52" pos="punct" morph="none" start_char="3816" end_char="3816">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="3819" end_char="3832">
<ORIGINAL_TEXT>Otros estudios</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="3819" end_char="3823">Otros</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="3825" end_char="3832">estudios</TOKEN>
</SEG>
<SEG id="segment-24" start_char="3836" end_char="3986">
<ORIGINAL_TEXT>De todos modos, tras el estudio del Hospital Italiano se espera que otros estudios en el mismo sentido corroboren o no la futilidad del uso del plasma.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="3836" end_char="3837">De</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="3839" end_char="3843">todos</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="3845" end_char="3849">modos</TOKEN>
<TOKEN id="token-24-3" pos="punct" morph="none" start_char="3850" end_char="3850">,</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="3852" end_char="3855">tras</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="3857" end_char="3858">el</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="3860" end_char="3866">estudio</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="3868" end_char="3870">del</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="3872" end_char="3879">Hospital</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="3881" end_char="3888">Italiano</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="3890" end_char="3891">se</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="3893" end_char="3898">espera</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="3900" end_char="3902">que</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="3904" end_char="3908">otros</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="3910" end_char="3917">estudios</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="3919" end_char="3920">en</TOKEN>
<TOKEN id="token-24-16" pos="word" morph="none" start_char="3922" end_char="3923">el</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="3925" end_char="3929">mismo</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="3931" end_char="3937">sentido</TOKEN>
<TOKEN id="token-24-19" pos="word" morph="none" start_char="3939" end_char="3948">corroboren</TOKEN>
<TOKEN id="token-24-20" pos="word" morph="none" start_char="3950" end_char="3950">o</TOKEN>
<TOKEN id="token-24-21" pos="word" morph="none" start_char="3952" end_char="3953">no</TOKEN>
<TOKEN id="token-24-22" pos="word" morph="none" start_char="3955" end_char="3956">la</TOKEN>
<TOKEN id="token-24-23" pos="word" morph="none" start_char="3958" end_char="3966">futilidad</TOKEN>
<TOKEN id="token-24-24" pos="word" morph="none" start_char="3968" end_char="3970">del</TOKEN>
<TOKEN id="token-24-25" pos="word" morph="none" start_char="3972" end_char="3974">uso</TOKEN>
<TOKEN id="token-24-26" pos="word" morph="none" start_char="3976" end_char="3978">del</TOKEN>
<TOKEN id="token-24-27" pos="word" morph="none" start_char="3980" end_char="3985">plasma</TOKEN>
<TOKEN id="token-24-28" pos="punct" morph="none" start_char="3986" end_char="3986">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="3988" end_char="4163">
<ORIGINAL_TEXT>De hecho, los propios Institutos Nacionales de Salud de los Estados Unidos han anunciado que pronto comenzarán a reclutar pacientes para dar una respuesta científica al asunto.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="3988" end_char="3989">De</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="3991" end_char="3995">hecho</TOKEN>
<TOKEN id="token-25-2" pos="punct" morph="none" start_char="3996" end_char="3996">,</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="3998" end_char="4000">los</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="4002" end_char="4008">propios</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="4010" end_char="4019">Institutos</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="4021" end_char="4030">Nacionales</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="4032" end_char="4033">de</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="4035" end_char="4039">Salud</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="4041" end_char="4042">de</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="4044" end_char="4046">los</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="4048" end_char="4054">Estados</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="4056" end_char="4061">Unidos</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="4063" end_char="4065">han</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="4067" end_char="4075">anunciado</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="4077" end_char="4079">que</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="4081" end_char="4086">pronto</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="4088" end_char="4097">comenzarán</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="4099" end_char="4099">a</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="4101" end_char="4108">reclutar</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="4110" end_char="4118">pacientes</TOKEN>
<TOKEN id="token-25-21" pos="word" morph="none" start_char="4120" end_char="4123">para</TOKEN>
<TOKEN id="token-25-22" pos="word" morph="none" start_char="4125" end_char="4127">dar</TOKEN>
<TOKEN id="token-25-23" pos="word" morph="none" start_char="4129" end_char="4131">una</TOKEN>
<TOKEN id="token-25-24" pos="word" morph="none" start_char="4133" end_char="4141">respuesta</TOKEN>
<TOKEN id="token-25-25" pos="word" morph="none" start_char="4143" end_char="4152">científica</TOKEN>
<TOKEN id="token-25-26" pos="word" morph="none" start_char="4154" end_char="4155">al</TOKEN>
<TOKEN id="token-25-27" pos="word" morph="none" start_char="4157" end_char="4162">asunto</TOKEN>
<TOKEN id="token-25-28" pos="punct" morph="none" start_char="4163" end_char="4163">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="4165" end_char="4318">
<ORIGINAL_TEXT>Y, en la Argentina, aún se esperan los resultados de un estudio similar realizado por investigadores de la Fundación Infant y el Hospital Militar Central.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="4165" end_char="4165">Y</TOKEN>
<TOKEN id="token-26-1" pos="punct" morph="none" start_char="4166" end_char="4166">,</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="4168" end_char="4169">en</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="4171" end_char="4172">la</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="4174" end_char="4182">Argentina</TOKEN>
<TOKEN id="token-26-5" pos="punct" morph="none" start_char="4183" end_char="4183">,</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="4185" end_char="4187">aún</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="4189" end_char="4190">se</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="4192" end_char="4198">esperan</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="4200" end_char="4202">los</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="4204" end_char="4213">resultados</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="4215" end_char="4216">de</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="4218" end_char="4219">un</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="4221" end_char="4227">estudio</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="4229" end_char="4235">similar</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="4237" end_char="4245">realizado</TOKEN>
<TOKEN id="token-26-16" pos="word" morph="none" start_char="4247" end_char="4249">por</TOKEN>
<TOKEN id="token-26-17" pos="word" morph="none" start_char="4251" end_char="4264">investigadores</TOKEN>
<TOKEN id="token-26-18" pos="word" morph="none" start_char="4266" end_char="4267">de</TOKEN>
<TOKEN id="token-26-19" pos="word" morph="none" start_char="4269" end_char="4270">la</TOKEN>
<TOKEN id="token-26-20" pos="word" morph="none" start_char="4272" end_char="4280">Fundación</TOKEN>
<TOKEN id="token-26-21" pos="word" morph="none" start_char="4282" end_char="4287">Infant</TOKEN>
<TOKEN id="token-26-22" pos="word" morph="none" start_char="4289" end_char="4289">y</TOKEN>
<TOKEN id="token-26-23" pos="word" morph="none" start_char="4291" end_char="4292">el</TOKEN>
<TOKEN id="token-26-24" pos="word" morph="none" start_char="4294" end_char="4301">Hospital</TOKEN>
<TOKEN id="token-26-25" pos="word" morph="none" start_char="4303" end_char="4309">Militar</TOKEN>
<TOKEN id="token-26-26" pos="word" morph="none" start_char="4311" end_char="4317">Central</TOKEN>
<TOKEN id="token-26-27" pos="punct" morph="none" start_char="4318" end_char="4318">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="4321" end_char="4601">
<ORIGINAL_TEXT>Gonzalo Pérez Marc, que trabaja en este ensayo clínico, indicó que la investigación del Hospital Italiano es de buena calidad y está muy bien diseñada, pero que no va en contra de lo ideado por su grupo, que pensó que sería interesante la opción del plasma apenas dado el contagio.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="4321" end_char="4327">Gonzalo</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="4329" end_char="4333">Pérez</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="4335" end_char="4338">Marc</TOKEN>
<TOKEN id="token-27-3" pos="punct" morph="none" start_char="4339" end_char="4339">,</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="4341" end_char="4343">que</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="4345" end_char="4351">trabaja</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="4353" end_char="4354">en</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="4356" end_char="4359">este</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="4361" end_char="4366">ensayo</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="4368" end_char="4374">clínico</TOKEN>
<TOKEN id="token-27-10" pos="punct" morph="none" start_char="4375" end_char="4375">,</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="4377" end_char="4382">indicó</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="4384" end_char="4386">que</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="4388" end_char="4389">la</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="4391" end_char="4403">investigación</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="4405" end_char="4407">del</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="4409" end_char="4416">Hospital</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="4418" end_char="4425">Italiano</TOKEN>
<TOKEN id="token-27-18" pos="word" morph="none" start_char="4427" end_char="4428">es</TOKEN>
<TOKEN id="token-27-19" pos="word" morph="none" start_char="4430" end_char="4431">de</TOKEN>
<TOKEN id="token-27-20" pos="word" morph="none" start_char="4433" end_char="4437">buena</TOKEN>
<TOKEN id="token-27-21" pos="word" morph="none" start_char="4439" end_char="4445">calidad</TOKEN>
<TOKEN id="token-27-22" pos="word" morph="none" start_char="4447" end_char="4447">y</TOKEN>
<TOKEN id="token-27-23" pos="word" morph="none" start_char="4449" end_char="4452">está</TOKEN>
<TOKEN id="token-27-24" pos="word" morph="none" start_char="4454" end_char="4456">muy</TOKEN>
<TOKEN id="token-27-25" pos="word" morph="none" start_char="4458" end_char="4461">bien</TOKEN>
<TOKEN id="token-27-26" pos="word" morph="none" start_char="4463" end_char="4470">diseñada</TOKEN>
<TOKEN id="token-27-27" pos="punct" morph="none" start_char="4471" end_char="4471">,</TOKEN>
<TOKEN id="token-27-28" pos="word" morph="none" start_char="4473" end_char="4476">pero</TOKEN>
<TOKEN id="token-27-29" pos="word" morph="none" start_char="4478" end_char="4480">que</TOKEN>
<TOKEN id="token-27-30" pos="word" morph="none" start_char="4482" end_char="4483">no</TOKEN>
<TOKEN id="token-27-31" pos="word" morph="none" start_char="4485" end_char="4486">va</TOKEN>
<TOKEN id="token-27-32" pos="word" morph="none" start_char="4488" end_char="4489">en</TOKEN>
<TOKEN id="token-27-33" pos="word" morph="none" start_char="4491" end_char="4496">contra</TOKEN>
<TOKEN id="token-27-34" pos="word" morph="none" start_char="4498" end_char="4499">de</TOKEN>
<TOKEN id="token-27-35" pos="word" morph="none" start_char="4501" end_char="4502">lo</TOKEN>
<TOKEN id="token-27-36" pos="word" morph="none" start_char="4504" end_char="4509">ideado</TOKEN>
<TOKEN id="token-27-37" pos="word" morph="none" start_char="4511" end_char="4513">por</TOKEN>
<TOKEN id="token-27-38" pos="word" morph="none" start_char="4515" end_char="4516">su</TOKEN>
<TOKEN id="token-27-39" pos="word" morph="none" start_char="4518" end_char="4522">grupo</TOKEN>
<TOKEN id="token-27-40" pos="punct" morph="none" start_char="4523" end_char="4523">,</TOKEN>
<TOKEN id="token-27-41" pos="word" morph="none" start_char="4525" end_char="4527">que</TOKEN>
<TOKEN id="token-27-42" pos="word" morph="none" start_char="4529" end_char="4533">pensó</TOKEN>
<TOKEN id="token-27-43" pos="word" morph="none" start_char="4535" end_char="4537">que</TOKEN>
<TOKEN id="token-27-44" pos="word" morph="none" start_char="4539" end_char="4543">sería</TOKEN>
<TOKEN id="token-27-45" pos="word" morph="none" start_char="4545" end_char="4555">interesante</TOKEN>
<TOKEN id="token-27-46" pos="word" morph="none" start_char="4557" end_char="4558">la</TOKEN>
<TOKEN id="token-27-47" pos="word" morph="none" start_char="4560" end_char="4565">opción</TOKEN>
<TOKEN id="token-27-48" pos="word" morph="none" start_char="4567" end_char="4569">del</TOKEN>
<TOKEN id="token-27-49" pos="word" morph="none" start_char="4571" end_char="4576">plasma</TOKEN>
<TOKEN id="token-27-50" pos="word" morph="none" start_char="4578" end_char="4583">apenas</TOKEN>
<TOKEN id="token-27-51" pos="word" morph="none" start_char="4585" end_char="4588">dado</TOKEN>
<TOKEN id="token-27-52" pos="word" morph="none" start_char="4590" end_char="4591">el</TOKEN>
<TOKEN id="token-27-53" pos="word" morph="none" start_char="4593" end_char="4600">contagio</TOKEN>
<TOKEN id="token-27-54" pos="punct" morph="none" start_char="4601" end_char="4601">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="4603" end_char="4838">
<ORIGINAL_TEXT>"Nuestra instancia es para uso temprano, antes de que se instale la enfermedad, en las primeras 48 horas, de modo que de alguna manera nuestra hipótesis aún se sostiene con el resultado negativo del Hospital Italiano", dijo a LA NACIÓN.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="punct" morph="none" start_char="4603" end_char="4603">"</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="4604" end_char="4610">Nuestra</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="4612" end_char="4620">instancia</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="4622" end_char="4623">es</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="4625" end_char="4628">para</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="4630" end_char="4632">uso</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="4634" end_char="4641">temprano</TOKEN>
<TOKEN id="token-28-7" pos="punct" morph="none" start_char="4642" end_char="4642">,</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="4644" end_char="4648">antes</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="4650" end_char="4651">de</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="4653" end_char="4655">que</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="4657" end_char="4658">se</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="4660" end_char="4666">instale</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="4668" end_char="4669">la</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="4671" end_char="4680">enfermedad</TOKEN>
<TOKEN id="token-28-15" pos="punct" morph="none" start_char="4681" end_char="4681">,</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="4683" end_char="4684">en</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="4686" end_char="4688">las</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="4690" end_char="4697">primeras</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="4699" end_char="4700">48</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="4702" end_char="4706">horas</TOKEN>
<TOKEN id="token-28-21" pos="punct" morph="none" start_char="4707" end_char="4707">,</TOKEN>
<TOKEN id="token-28-22" pos="word" morph="none" start_char="4709" end_char="4710">de</TOKEN>
<TOKEN id="token-28-23" pos="word" morph="none" start_char="4712" end_char="4715">modo</TOKEN>
<TOKEN id="token-28-24" pos="word" morph="none" start_char="4717" end_char="4719">que</TOKEN>
<TOKEN id="token-28-25" pos="word" morph="none" start_char="4721" end_char="4722">de</TOKEN>
<TOKEN id="token-28-26" pos="word" morph="none" start_char="4724" end_char="4729">alguna</TOKEN>
<TOKEN id="token-28-27" pos="word" morph="none" start_char="4731" end_char="4736">manera</TOKEN>
<TOKEN id="token-28-28" pos="word" morph="none" start_char="4738" end_char="4744">nuestra</TOKEN>
<TOKEN id="token-28-29" pos="word" morph="none" start_char="4746" end_char="4754">hipótesis</TOKEN>
<TOKEN id="token-28-30" pos="word" morph="none" start_char="4756" end_char="4758">aún</TOKEN>
<TOKEN id="token-28-31" pos="word" morph="none" start_char="4760" end_char="4761">se</TOKEN>
<TOKEN id="token-28-32" pos="word" morph="none" start_char="4763" end_char="4770">sostiene</TOKEN>
<TOKEN id="token-28-33" pos="word" morph="none" start_char="4772" end_char="4774">con</TOKEN>
<TOKEN id="token-28-34" pos="word" morph="none" start_char="4776" end_char="4777">el</TOKEN>
<TOKEN id="token-28-35" pos="word" morph="none" start_char="4779" end_char="4787">resultado</TOKEN>
<TOKEN id="token-28-36" pos="word" morph="none" start_char="4789" end_char="4796">negativo</TOKEN>
<TOKEN id="token-28-37" pos="word" morph="none" start_char="4798" end_char="4800">del</TOKEN>
<TOKEN id="token-28-38" pos="word" morph="none" start_char="4802" end_char="4809">Hospital</TOKEN>
<TOKEN id="token-28-39" pos="word" morph="none" start_char="4811" end_char="4818">Italiano</TOKEN>
<TOKEN id="token-28-40" pos="punct" morph="none" start_char="4819" end_char="4820">",</TOKEN>
<TOKEN id="token-28-41" pos="word" morph="none" start_char="4822" end_char="4825">dijo</TOKEN>
<TOKEN id="token-28-42" pos="word" morph="none" start_char="4827" end_char="4827">a</TOKEN>
<TOKEN id="token-28-43" pos="word" morph="none" start_char="4829" end_char="4830">LA</TOKEN>
<TOKEN id="token-28-44" pos="word" morph="none" start_char="4832" end_char="4837">NACIÓN</TOKEN>
<TOKEN id="token-28-45" pos="punct" morph="none" start_char="4838" end_char="4838">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="4840" end_char="5002">
<ORIGINAL_TEXT>Pérez Marc agregó que quizá tengan resultados la semana próxima y que ya tienen más de 150 pacientes enrolados, también con un grupo de control que recibe placebo.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="4840" end_char="4844">Pérez</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="4846" end_char="4849">Marc</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="4851" end_char="4856">agregó</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="4858" end_char="4860">que</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="4862" end_char="4866">quizá</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="4868" end_char="4873">tengan</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="4875" end_char="4884">resultados</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="4886" end_char="4887">la</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="4889" end_char="4894">semana</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="4896" end_char="4902">próxima</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="4904" end_char="4904">y</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="4906" end_char="4908">que</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="4910" end_char="4911">ya</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="4913" end_char="4918">tienen</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="4920" end_char="4922">más</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="4924" end_char="4925">de</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="4927" end_char="4929">150</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="4931" end_char="4939">pacientes</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="4941" end_char="4949">enrolados</TOKEN>
<TOKEN id="token-29-19" pos="punct" morph="none" start_char="4950" end_char="4950">,</TOKEN>
<TOKEN id="token-29-20" pos="word" morph="none" start_char="4952" end_char="4958">también</TOKEN>
<TOKEN id="token-29-21" pos="word" morph="none" start_char="4960" end_char="4962">con</TOKEN>
<TOKEN id="token-29-22" pos="word" morph="none" start_char="4964" end_char="4965">un</TOKEN>
<TOKEN id="token-29-23" pos="word" morph="none" start_char="4967" end_char="4971">grupo</TOKEN>
<TOKEN id="token-29-24" pos="word" morph="none" start_char="4973" end_char="4974">de</TOKEN>
<TOKEN id="token-29-25" pos="word" morph="none" start_char="4976" end_char="4982">control</TOKEN>
<TOKEN id="token-29-26" pos="word" morph="none" start_char="4984" end_char="4986">que</TOKEN>
<TOKEN id="token-29-27" pos="word" morph="none" start_char="4988" end_char="4993">recibe</TOKEN>
<TOKEN id="token-29-28" pos="word" morph="none" start_char="4995" end_char="5001">placebo</TOKEN>
<TOKEN id="token-29-29" pos="punct" morph="none" start_char="5002" end_char="5002">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="5004" end_char="5166">
<ORIGINAL_TEXT>Si los resultados son buenos, sería una opción para pacientes que son contactos estrechos y tienen algún tipo de condición de riesgo, por edad o enfermedad previa.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="5004" end_char="5005">Si</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="5007" end_char="5009">los</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="5011" end_char="5020">resultados</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="5022" end_char="5024">son</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="5026" end_char="5031">buenos</TOKEN>
<TOKEN id="token-30-5" pos="punct" morph="none" start_char="5032" end_char="5032">,</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="5034" end_char="5038">sería</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="5040" end_char="5042">una</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="5044" end_char="5049">opción</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="5051" end_char="5054">para</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="5056" end_char="5064">pacientes</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="5066" end_char="5068">que</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="5070" end_char="5072">son</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="5074" end_char="5082">contactos</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="5084" end_char="5092">estrechos</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="5094" end_char="5094">y</TOKEN>
<TOKEN id="token-30-16" pos="word" morph="none" start_char="5096" end_char="5101">tienen</TOKEN>
<TOKEN id="token-30-17" pos="word" morph="none" start_char="5103" end_char="5107">algún</TOKEN>
<TOKEN id="token-30-18" pos="word" morph="none" start_char="5109" end_char="5112">tipo</TOKEN>
<TOKEN id="token-30-19" pos="word" morph="none" start_char="5114" end_char="5115">de</TOKEN>
<TOKEN id="token-30-20" pos="word" morph="none" start_char="5117" end_char="5125">condición</TOKEN>
<TOKEN id="token-30-21" pos="word" morph="none" start_char="5127" end_char="5128">de</TOKEN>
<TOKEN id="token-30-22" pos="word" morph="none" start_char="5130" end_char="5135">riesgo</TOKEN>
<TOKEN id="token-30-23" pos="punct" morph="none" start_char="5136" end_char="5136">,</TOKEN>
<TOKEN id="token-30-24" pos="word" morph="none" start_char="5138" end_char="5140">por</TOKEN>
<TOKEN id="token-30-25" pos="word" morph="none" start_char="5142" end_char="5145">edad</TOKEN>
<TOKEN id="token-30-26" pos="word" morph="none" start_char="5147" end_char="5147">o</TOKEN>
<TOKEN id="token-30-27" pos="word" morph="none" start_char="5149" end_char="5158">enfermedad</TOKEN>
<TOKEN id="token-30-28" pos="word" morph="none" start_char="5160" end_char="5165">previa</TOKEN>
<TOKEN id="token-30-29" pos="punct" morph="none" start_char="5166" end_char="5166">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="5169" end_char="5369">
<ORIGINAL_TEXT>El plasma había sido incluso objeto de disputa cuando se popularizó la idea de que su uso había curado a algunas celebridades y hasta hubo reclamos judiciales para que se otorgue a todos los pacientes.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="5169" end_char="5170">El</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="5172" end_char="5177">plasma</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="5179" end_char="5183">había</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="5185" end_char="5188">sido</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="5190" end_char="5196">incluso</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="5198" end_char="5203">objeto</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="5205" end_char="5206">de</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="5208" end_char="5214">disputa</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="5216" end_char="5221">cuando</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="5223" end_char="5224">se</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="5226" end_char="5235">popularizó</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="5237" end_char="5238">la</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="5240" end_char="5243">idea</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="5245" end_char="5246">de</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="5248" end_char="5250">que</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="5252" end_char="5253">su</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="5255" end_char="5257">uso</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="5259" end_char="5263">había</TOKEN>
<TOKEN id="token-31-18" pos="word" morph="none" start_char="5265" end_char="5270">curado</TOKEN>
<TOKEN id="token-31-19" pos="word" morph="none" start_char="5272" end_char="5272">a</TOKEN>
<TOKEN id="token-31-20" pos="word" morph="none" start_char="5274" end_char="5280">algunas</TOKEN>
<TOKEN id="token-31-21" pos="word" morph="none" start_char="5282" end_char="5293">celebridades</TOKEN>
<TOKEN id="token-31-22" pos="word" morph="none" start_char="5295" end_char="5295">y</TOKEN>
<TOKEN id="token-31-23" pos="word" morph="none" start_char="5297" end_char="5301">hasta</TOKEN>
<TOKEN id="token-31-24" pos="word" morph="none" start_char="5303" end_char="5306">hubo</TOKEN>
<TOKEN id="token-31-25" pos="word" morph="none" start_char="5308" end_char="5315">reclamos</TOKEN>
<TOKEN id="token-31-26" pos="word" morph="none" start_char="5317" end_char="5326">judiciales</TOKEN>
<TOKEN id="token-31-27" pos="word" morph="none" start_char="5328" end_char="5331">para</TOKEN>
<TOKEN id="token-31-28" pos="word" morph="none" start_char="5333" end_char="5335">que</TOKEN>
<TOKEN id="token-31-29" pos="word" morph="none" start_char="5337" end_char="5338">se</TOKEN>
<TOKEN id="token-31-30" pos="word" morph="none" start_char="5340" end_char="5346">otorgue</TOKEN>
<TOKEN id="token-31-31" pos="word" morph="none" start_char="5348" end_char="5348">a</TOKEN>
<TOKEN id="token-31-32" pos="word" morph="none" start_char="5350" end_char="5354">todos</TOKEN>
<TOKEN id="token-31-33" pos="word" morph="none" start_char="5356" end_char="5358">los</TOKEN>
<TOKEN id="token-31-34" pos="word" morph="none" start_char="5360" end_char="5368">pacientes</TOKEN>
<TOKEN id="token-31-35" pos="punct" morph="none" start_char="5369" end_char="5369">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
