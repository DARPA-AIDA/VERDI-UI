<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C0495B4" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="9306" raw_text_md5="9ac01ec827a3abca60ee36977cea6b8c">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="62">
<ORIGINAL_TEXT>El nuevo coronavirus no fue patentado por el Instituto Pasteur</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="2">El</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="4" end_char="8">nuevo</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="10" end_char="20">coronavirus</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="22" end_char="23">no</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="25" end_char="27">fue</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="29" end_char="37">patentado</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="39" end_char="41">por</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="43" end_char="44">el</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="46" end_char="54">Instituto</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="56" end_char="62">Pasteur</TOKEN>
</SEG>
<SEG id="segment-1" start_char="66" end_char="317">
<ORIGINAL_TEXT>Una publicación compartida alrededor de 1.000 veces en Facebook asegura que el COVID-19 fue creado en 2003 por el Instituto Pasteur de Francia, del cual dice que tiene la patente, además de otras afirmaciones que señalan que la enfermedad fue inducida.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="66" end_char="68">Una</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="70" end_char="80">publicación</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="82" end_char="91">compartida</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="93" end_char="101">alrededor</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="103" end_char="104">de</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="106" end_char="110">1.000</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="112" end_char="116">veces</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="118" end_char="119">en</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="121" end_char="128">Facebook</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="130" end_char="136">asegura</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="138" end_char="140">que</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="142" end_char="143">el</TOKEN>
<TOKEN id="token-1-12" pos="unknown" morph="none" start_char="145" end_char="152">COVID-19</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="154" end_char="156">fue</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="158" end_char="163">creado</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="165" end_char="166">en</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="168" end_char="171">2003</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="173" end_char="175">por</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="177" end_char="178">el</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="180" end_char="188">Instituto</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="190" end_char="196">Pasteur</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="198" end_char="199">de</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="201" end_char="207">Francia</TOKEN>
<TOKEN id="token-1-23" pos="punct" morph="none" start_char="208" end_char="208">,</TOKEN>
<TOKEN id="token-1-24" pos="word" morph="none" start_char="210" end_char="212">del</TOKEN>
<TOKEN id="token-1-25" pos="word" morph="none" start_char="214" end_char="217">cual</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="219" end_char="222">dice</TOKEN>
<TOKEN id="token-1-27" pos="word" morph="none" start_char="224" end_char="226">que</TOKEN>
<TOKEN id="token-1-28" pos="word" morph="none" start_char="228" end_char="232">tiene</TOKEN>
<TOKEN id="token-1-29" pos="word" morph="none" start_char="234" end_char="235">la</TOKEN>
<TOKEN id="token-1-30" pos="word" morph="none" start_char="237" end_char="243">patente</TOKEN>
<TOKEN id="token-1-31" pos="punct" morph="none" start_char="244" end_char="244">,</TOKEN>
<TOKEN id="token-1-32" pos="word" morph="none" start_char="246" end_char="251">además</TOKEN>
<TOKEN id="token-1-33" pos="word" morph="none" start_char="253" end_char="254">de</TOKEN>
<TOKEN id="token-1-34" pos="word" morph="none" start_char="256" end_char="260">otras</TOKEN>
<TOKEN id="token-1-35" pos="word" morph="none" start_char="262" end_char="273">afirmaciones</TOKEN>
<TOKEN id="token-1-36" pos="word" morph="none" start_char="275" end_char="277">que</TOKEN>
<TOKEN id="token-1-37" pos="word" morph="none" start_char="279" end_char="285">señalan</TOKEN>
<TOKEN id="token-1-38" pos="word" morph="none" start_char="287" end_char="289">que</TOKEN>
<TOKEN id="token-1-39" pos="word" morph="none" start_char="291" end_char="292">la</TOKEN>
<TOKEN id="token-1-40" pos="word" morph="none" start_char="294" end_char="303">enfermedad</TOKEN>
<TOKEN id="token-1-41" pos="word" morph="none" start_char="305" end_char="307">fue</TOKEN>
<TOKEN id="token-1-42" pos="word" morph="none" start_char="309" end_char="316">inducida</TOKEN>
<TOKEN id="token-1-43" pos="punct" morph="none" start_char="317" end_char="317">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="319" end_char="413">
<ORIGINAL_TEXT>Aunque el Instituto Pasteur tiene una patente de coronavirus de 2004, no se trata del COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="319" end_char="324">Aunque</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="326" end_char="327">el</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="329" end_char="337">Instituto</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="339" end_char="345">Pasteur</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="347" end_char="351">tiene</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="353" end_char="355">una</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="357" end_char="363">patente</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="365" end_char="366">de</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="368" end_char="378">coronavirus</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="380" end_char="381">de</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="383" end_char="386">2004</TOKEN>
<TOKEN id="token-2-11" pos="punct" morph="none" start_char="387" end_char="387">,</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="389" end_char="390">no</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="392" end_char="393">se</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="395" end_char="399">trata</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="401" end_char="403">del</TOKEN>
<TOKEN id="token-2-16" pos="unknown" morph="none" start_char="405" end_char="412">COVID-19</TOKEN>
<TOKEN id="token-2-17" pos="punct" morph="none" start_char="413" end_char="413">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="415" end_char="493">
<ORIGINAL_TEXT>De hecho, que se presenten patentes de virus, no significa que se hayan creado.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="415" end_char="416">De</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="418" end_char="422">hecho</TOKEN>
<TOKEN id="token-3-2" pos="punct" morph="none" start_char="423" end_char="423">,</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="425" end_char="427">que</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="429" end_char="430">se</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="432" end_char="440">presenten</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="442" end_char="449">patentes</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="451" end_char="452">de</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="454" end_char="458">virus</TOKEN>
<TOKEN id="token-3-9" pos="punct" morph="none" start_char="459" end_char="459">,</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="461" end_char="462">no</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="464" end_char="472">significa</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="474" end_char="476">que</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="478" end_char="479">se</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="481" end_char="485">hayan</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="487" end_char="492">creado</TOKEN>
<TOKEN id="token-3-16" pos="punct" morph="none" start_char="493" end_char="493">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="496" end_char="698">
<ORIGINAL_TEXT>"En este post les doy información y las fuentes del origen del COVID-19, que existe desde 2003, una patente legal internacional que prueba que fue creado por personas con conocimientos en armas químicas.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="punct" morph="none" start_char="496" end_char="496">"</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="497" end_char="498">En</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="500" end_char="503">este</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="505" end_char="508">post</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="510" end_char="512">les</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="514" end_char="516">doy</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="518" end_char="528">información</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="530" end_char="530">y</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="532" end_char="534">las</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="536" end_char="542">fuentes</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="544" end_char="546">del</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="548" end_char="553">origen</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="555" end_char="557">del</TOKEN>
<TOKEN id="token-4-13" pos="unknown" morph="none" start_char="559" end_char="566">COVID-19</TOKEN>
<TOKEN id="token-4-14" pos="punct" morph="none" start_char="567" end_char="567">,</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="569" end_char="571">que</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="573" end_char="578">existe</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="580" end_char="584">desde</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="586" end_char="589">2003</TOKEN>
<TOKEN id="token-4-19" pos="punct" morph="none" start_char="590" end_char="590">,</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="592" end_char="594">una</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="596" end_char="602">patente</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="604" end_char="608">legal</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="610" end_char="622">internacional</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="624" end_char="626">que</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="628" end_char="633">prueba</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="635" end_char="637">que</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="639" end_char="641">fue</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="643" end_char="648">creado</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="650" end_char="652">por</TOKEN>
<TOKEN id="token-4-30" pos="word" morph="none" start_char="654" end_char="661">personas</TOKEN>
<TOKEN id="token-4-31" pos="word" morph="none" start_char="663" end_char="665">con</TOKEN>
<TOKEN id="token-4-32" pos="word" morph="none" start_char="667" end_char="679">conocimientos</TOKEN>
<TOKEN id="token-4-33" pos="word" morph="none" start_char="681" end_char="682">en</TOKEN>
<TOKEN id="token-4-34" pos="word" morph="none" start_char="684" end_char="688">armas</TOKEN>
<TOKEN id="token-4-35" pos="word" morph="none" start_char="690" end_char="697">químicas</TOKEN>
<TOKEN id="token-4-36" pos="punct" morph="none" start_char="698" end_char="698">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="700" end_char="854">
<ORIGINAL_TEXT>El documento en cuestión contiene 300 páginas, ya que es todo un trabajo científico realizado e incluso tiene su vacuna en el Instituto Pasteur de Francia.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="700" end_char="701">El</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="703" end_char="711">documento</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="713" end_char="714">en</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="716" end_char="723">cuestión</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="725" end_char="732">contiene</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="734" end_char="736">300</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="738" end_char="744">páginas</TOKEN>
<TOKEN id="token-5-7" pos="punct" morph="none" start_char="745" end_char="745">,</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="747" end_char="748">ya</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="750" end_char="752">que</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="754" end_char="755">es</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="757" end_char="760">todo</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="762" end_char="763">un</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="765" end_char="771">trabajo</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="773" end_char="782">científico</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="784" end_char="792">realizado</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="794" end_char="794">e</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="796" end_char="802">incluso</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="804" end_char="808">tiene</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="810" end_char="811">su</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="813" end_char="818">vacuna</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="820" end_char="821">en</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="823" end_char="824">el</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="826" end_char="834">Instituto</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="836" end_char="842">Pasteur</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="844" end_char="845">de</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="847" end_char="853">Francia</TOKEN>
<TOKEN id="token-5-27" pos="punct" morph="none" start_char="854" end_char="854">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="856" end_char="944">
<ORIGINAL_TEXT>Se trata de un acto de asesinato en masa con la intención de matar a millones de personas</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="856" end_char="857">Se</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="859" end_char="863">trata</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="865" end_char="866">de</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="868" end_char="869">un</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="871" end_char="874">acto</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="876" end_char="877">de</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="879" end_char="887">asesinato</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="889" end_char="890">en</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="892" end_char="895">masa</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="897" end_char="899">con</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="901" end_char="902">la</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="904" end_char="912">intención</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="914" end_char="915">de</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="917" end_char="921">matar</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="923" end_char="923">a</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="925" end_char="932">millones</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="934" end_char="935">de</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="937" end_char="944">personas</TOKEN>
</SEG>
<SEG id="segment-7" start_char="947" end_char="951">
<ORIGINAL_TEXT>(...)</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="punct" morph="none" start_char="947" end_char="951">(...)</TOKEN>
</SEG>
<SEG id="segment-8" start_char="954" end_char="954">
<ORIGINAL_TEXT>"</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="punct" morph="none" start_char="954" end_char="954">"</TOKEN>
</SEG>
<SEG id="segment-9" start_char="957" end_char="1053">
<ORIGINAL_TEXT>, comienza el largo texto de la publicación en Facebook, que circula desde el 18 de marzo pasado.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="punct" morph="none" start_char="957" end_char="957">,</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="959" end_char="966">comienza</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="968" end_char="969">el</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="971" end_char="975">largo</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="977" end_char="981">texto</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="983" end_char="984">de</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="986" end_char="987">la</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="989" end_char="999">publicación</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1001" end_char="1002">en</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1004" end_char="1011">Facebook</TOKEN>
<TOKEN id="token-9-10" pos="punct" morph="none" start_char="1012" end_char="1012">,</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1014" end_char="1016">que</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1018" end_char="1024">circula</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1026" end_char="1030">desde</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1032" end_char="1033">el</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1035" end_char="1036">18</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1038" end_char="1039">de</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1041" end_char="1045">marzo</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1047" end_char="1052">pasado</TOKEN>
<TOKEN id="token-9-19" pos="punct" morph="none" start_char="1053" end_char="1053">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1056" end_char="1100">
<ORIGINAL_TEXT>El texto contiene otras afirmaciones como que</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1056" end_char="1057">El</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1059" end_char="1063">texto</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1065" end_char="1072">contiene</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1074" end_char="1078">otras</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1080" end_char="1091">afirmaciones</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1093" end_char="1096">como</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1098" end_char="1100">que</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1103" end_char="1133">
<ORIGINAL_TEXT>"la cepa fue tomada en Vietnam"</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="punct" morph="none" start_char="1103" end_char="1103">"</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1104" end_char="1105">la</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1107" end_char="1110">cepa</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1112" end_char="1114">fue</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1116" end_char="1121">tomada</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1123" end_char="1124">en</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1126" end_char="1132">Vietnam</TOKEN>
<TOKEN id="token-11-7" pos="punct" morph="none" start_char="1133" end_char="1133">"</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1136" end_char="1169">
<ORIGINAL_TEXT>, que el coronavirus fue expandido</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="punct" morph="none" start_char="1136" end_char="1136">,</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1138" end_char="1140">que</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1142" end_char="1143">el</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1145" end_char="1155">coronavirus</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1157" end_char="1159">fue</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1161" end_char="1169">expandido</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1172" end_char="1183">
<ORIGINAL_TEXT>"con drones"</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="punct" morph="none" start_char="1172" end_char="1172">"</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1173" end_char="1175">con</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1177" end_char="1182">drones</TOKEN>
<TOKEN id="token-13-3" pos="punct" morph="none" start_char="1183" end_char="1183">"</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1186" end_char="1220">
<ORIGINAL_TEXT>en la ciudad china de Wuhan, que el</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1186" end_char="1187">en</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1189" end_char="1190">la</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1192" end_char="1197">ciudad</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1199" end_char="1203">china</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1205" end_char="1206">de</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1208" end_char="1212">Wuhan</TOKEN>
<TOKEN id="token-14-6" pos="punct" morph="none" start_char="1213" end_char="1213">,</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1215" end_char="1217">que</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1219" end_char="1220">el</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1223" end_char="1235">
<ORIGINAL_TEXT>"experimento"</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="punct" morph="none" start_char="1223" end_char="1223">"</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1224" end_char="1234">experimento</TOKEN>
<TOKEN id="token-15-2" pos="punct" morph="none" start_char="1235" end_char="1235">"</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1238" end_char="1241">
<ORIGINAL_TEXT>está</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1238" end_char="1241">está</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1244" end_char="1298">
<ORIGINAL_TEXT>"unido a la red 5G, chemtrails entre otros tóxicos más"</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="punct" morph="none" start_char="1244" end_char="1244">"</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1245" end_char="1249">unido</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="1251" end_char="1251">a</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="1253" end_char="1254">la</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="1256" end_char="1258">red</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="1260" end_char="1261">5G</TOKEN>
<TOKEN id="token-17-6" pos="punct" morph="none" start_char="1262" end_char="1262">,</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="1264" end_char="1273">chemtrails</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="1275" end_char="1279">entre</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="1281" end_char="1285">otros</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="1287" end_char="1293">tóxicos</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="1295" end_char="1297">más</TOKEN>
<TOKEN id="token-17-12" pos="punct" morph="none" start_char="1298" end_char="1298">"</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1301" end_char="1380">
<ORIGINAL_TEXT>o que realmente se pretende la expansión del virus a través de una falsa vacuna.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="1301" end_char="1301">o</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="1303" end_char="1305">que</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="1307" end_char="1315">realmente</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="1317" end_char="1318">se</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="1320" end_char="1327">pretende</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="1329" end_char="1330">la</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="1332" end_char="1340">expansión</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="1342" end_char="1344">del</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="1346" end_char="1350">virus</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="1352" end_char="1352">a</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="1354" end_char="1359">través</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="1361" end_char="1362">de</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="1364" end_char="1366">una</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="1368" end_char="1372">falsa</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="1374" end_char="1379">vacuna</TOKEN>
<TOKEN id="token-18-15" pos="punct" morph="none" start_char="1380" end_char="1380">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="1383" end_char="1462">
<ORIGINAL_TEXT>Captura de pantalla de una publicación en Facebook, hecha el 20 de marzo de 2020</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="1383" end_char="1389">Captura</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="1391" end_char="1392">de</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="1394" end_char="1401">pantalla</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="1403" end_char="1404">de</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="1406" end_char="1408">una</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="1410" end_char="1420">publicación</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="1422" end_char="1423">en</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="1425" end_char="1432">Facebook</TOKEN>
<TOKEN id="token-19-8" pos="punct" morph="none" start_char="1433" end_char="1433">,</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="1435" end_char="1439">hecha</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="1441" end_char="1442">el</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="1444" end_char="1445">20</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="1447" end_char="1448">de</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="1450" end_char="1454">marzo</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="1456" end_char="1457">de</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="1459" end_char="1462">2020</TOKEN>
</SEG>
<SEG id="segment-20" start_char="1466" end_char="1683">
<ORIGINAL_TEXT>En francés, la afirmación de que el virus fue creado por este Instituto, ha circulado a través de un vídeo -ya eliminado- en Facebook (1) desde el 17 de marzo y compartido más de 125.000 veces en las primeras 24 horas.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="1466" end_char="1467">En</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="1469" end_char="1475">francés</TOKEN>
<TOKEN id="token-20-2" pos="punct" morph="none" start_char="1476" end_char="1476">,</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="1478" end_char="1479">la</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="1481" end_char="1490">afirmación</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="1492" end_char="1493">de</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="1495" end_char="1497">que</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="1499" end_char="1500">el</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="1502" end_char="1506">virus</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="1508" end_char="1510">fue</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="1512" end_char="1517">creado</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="1519" end_char="1521">por</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="1523" end_char="1526">este</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="1528" end_char="1536">Instituto</TOKEN>
<TOKEN id="token-20-14" pos="punct" morph="none" start_char="1537" end_char="1537">,</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="1539" end_char="1540">ha</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="1542" end_char="1550">circulado</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="1552" end_char="1552">a</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="1554" end_char="1559">través</TOKEN>
<TOKEN id="token-20-19" pos="word" morph="none" start_char="1561" end_char="1562">de</TOKEN>
<TOKEN id="token-20-20" pos="word" morph="none" start_char="1564" end_char="1565">un</TOKEN>
<TOKEN id="token-20-21" pos="word" morph="none" start_char="1567" end_char="1571">vídeo</TOKEN>
<TOKEN id="token-20-22" pos="punct" morph="none" start_char="1573" end_char="1573">-</TOKEN>
<TOKEN id="token-20-23" pos="word" morph="none" start_char="1574" end_char="1575">ya</TOKEN>
<TOKEN id="token-20-24" pos="word" morph="none" start_char="1577" end_char="1585">eliminado</TOKEN>
<TOKEN id="token-20-25" pos="punct" morph="none" start_char="1586" end_char="1586">-</TOKEN>
<TOKEN id="token-20-26" pos="word" morph="none" start_char="1588" end_char="1589">en</TOKEN>
<TOKEN id="token-20-27" pos="word" morph="none" start_char="1591" end_char="1598">Facebook</TOKEN>
<TOKEN id="token-20-28" pos="punct" morph="none" start_char="1600" end_char="1600">(</TOKEN>
<TOKEN id="token-20-29" pos="word" morph="none" start_char="1601" end_char="1601">1</TOKEN>
<TOKEN id="token-20-30" pos="punct" morph="none" start_char="1602" end_char="1602">)</TOKEN>
<TOKEN id="token-20-31" pos="word" morph="none" start_char="1604" end_char="1608">desde</TOKEN>
<TOKEN id="token-20-32" pos="word" morph="none" start_char="1610" end_char="1611">el</TOKEN>
<TOKEN id="token-20-33" pos="word" morph="none" start_char="1613" end_char="1614">17</TOKEN>
<TOKEN id="token-20-34" pos="word" morph="none" start_char="1616" end_char="1617">de</TOKEN>
<TOKEN id="token-20-35" pos="word" morph="none" start_char="1619" end_char="1623">marzo</TOKEN>
<TOKEN id="token-20-36" pos="word" morph="none" start_char="1625" end_char="1625">y</TOKEN>
<TOKEN id="token-20-37" pos="word" morph="none" start_char="1627" end_char="1636">compartido</TOKEN>
<TOKEN id="token-20-38" pos="word" morph="none" start_char="1638" end_char="1640">más</TOKEN>
<TOKEN id="token-20-39" pos="word" morph="none" start_char="1642" end_char="1643">de</TOKEN>
<TOKEN id="token-20-40" pos="word" morph="none" start_char="1645" end_char="1651">125.000</TOKEN>
<TOKEN id="token-20-41" pos="word" morph="none" start_char="1653" end_char="1657">veces</TOKEN>
<TOKEN id="token-20-42" pos="word" morph="none" start_char="1659" end_char="1660">en</TOKEN>
<TOKEN id="token-20-43" pos="word" morph="none" start_char="1662" end_char="1664">las</TOKEN>
<TOKEN id="token-20-44" pos="word" morph="none" start_char="1666" end_char="1673">primeras</TOKEN>
<TOKEN id="token-20-45" pos="word" morph="none" start_char="1675" end_char="1676">24</TOKEN>
<TOKEN id="token-20-46" pos="word" morph="none" start_char="1678" end_char="1682">horas</TOKEN>
<TOKEN id="token-20-47" pos="punct" morph="none" start_char="1683" end_char="1683">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="1685" end_char="1742">
<ORIGINAL_TEXT>Las imágenes circularon igualmente por WhatsApp y YouTube.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="1685" end_char="1687">Las</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="1689" end_char="1696">imágenes</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="1698" end_char="1707">circularon</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="1709" end_char="1718">igualmente</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="1720" end_char="1722">por</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="1724" end_char="1731">WhatsApp</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="1733" end_char="1733">y</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="1735" end_char="1741">YouTube</TOKEN>
<TOKEN id="token-21-8" pos="punct" morph="none" start_char="1742" end_char="1742">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="1745" end_char="1815">
<ORIGINAL_TEXT>La teoría sobre la patente también circula en otros idiomas como turco.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="1745" end_char="1746">La</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="1748" end_char="1753">teoría</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="1755" end_char="1759">sobre</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="1761" end_char="1762">la</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="1764" end_char="1770">patente</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="1772" end_char="1778">también</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="1780" end_char="1786">circula</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="1788" end_char="1789">en</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="1791" end_char="1795">otros</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="1797" end_char="1803">idiomas</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="1805" end_char="1808">como</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="1810" end_char="1814">turco</TOKEN>
<TOKEN id="token-22-12" pos="punct" morph="none" start_char="1815" end_char="1815">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="1818" end_char="1854">
<ORIGINAL_TEXT>Los coronavirus SARS-Cov y SARS-Cov-2</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="1818" end_char="1820">Los</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="1822" end_char="1832">coronavirus</TOKEN>
<TOKEN id="token-23-2" pos="unknown" morph="none" start_char="1834" end_char="1841">SARS-Cov</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="1843" end_char="1843">y</TOKEN>
<TOKEN id="token-23-4" pos="unknown" morph="none" start_char="1845" end_char="1854">SARS-Cov-2</TOKEN>
</SEG>
<SEG id="segment-24" start_char="1858" end_char="2076">
<ORIGINAL_TEXT>La patente a la que se refiere la publicación, la EP 1 694 829 B1, existe y está disponible aquí, en francés, según confirmó a la AFP Olivier Schwartz, director de la unidad de virus e inmunología del Instituto Pasteur.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="1858" end_char="1859">La</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="1861" end_char="1867">patente</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="1869" end_char="1869">a</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="1871" end_char="1872">la</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="1874" end_char="1876">que</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="1878" end_char="1879">se</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="1881" end_char="1887">refiere</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="1889" end_char="1890">la</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="1892" end_char="1902">publicación</TOKEN>
<TOKEN id="token-24-9" pos="punct" morph="none" start_char="1903" end_char="1903">,</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="1905" end_char="1906">la</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="1908" end_char="1909">EP</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="1911" end_char="1911">1</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="1913" end_char="1915">694</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="1917" end_char="1919">829</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="1921" end_char="1922">B1</TOKEN>
<TOKEN id="token-24-16" pos="punct" morph="none" start_char="1923" end_char="1923">,</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="1925" end_char="1930">existe</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="1932" end_char="1932">y</TOKEN>
<TOKEN id="token-24-19" pos="word" morph="none" start_char="1934" end_char="1937">está</TOKEN>
<TOKEN id="token-24-20" pos="word" morph="none" start_char="1939" end_char="1948">disponible</TOKEN>
<TOKEN id="token-24-21" pos="word" morph="none" start_char="1950" end_char="1953">aquí</TOKEN>
<TOKEN id="token-24-22" pos="punct" morph="none" start_char="1954" end_char="1954">,</TOKEN>
<TOKEN id="token-24-23" pos="word" morph="none" start_char="1956" end_char="1957">en</TOKEN>
<TOKEN id="token-24-24" pos="word" morph="none" start_char="1959" end_char="1965">francés</TOKEN>
<TOKEN id="token-24-25" pos="punct" morph="none" start_char="1966" end_char="1966">,</TOKEN>
<TOKEN id="token-24-26" pos="word" morph="none" start_char="1968" end_char="1972">según</TOKEN>
<TOKEN id="token-24-27" pos="word" morph="none" start_char="1974" end_char="1981">confirmó</TOKEN>
<TOKEN id="token-24-28" pos="word" morph="none" start_char="1983" end_char="1983">a</TOKEN>
<TOKEN id="token-24-29" pos="word" morph="none" start_char="1985" end_char="1986">la</TOKEN>
<TOKEN id="token-24-30" pos="word" morph="none" start_char="1988" end_char="1990">AFP</TOKEN>
<TOKEN id="token-24-31" pos="word" morph="none" start_char="1992" end_char="1998">Olivier</TOKEN>
<TOKEN id="token-24-32" pos="word" morph="none" start_char="2000" end_char="2007">Schwartz</TOKEN>
<TOKEN id="token-24-33" pos="punct" morph="none" start_char="2008" end_char="2008">,</TOKEN>
<TOKEN id="token-24-34" pos="word" morph="none" start_char="2010" end_char="2017">director</TOKEN>
<TOKEN id="token-24-35" pos="word" morph="none" start_char="2019" end_char="2020">de</TOKEN>
<TOKEN id="token-24-36" pos="word" morph="none" start_char="2022" end_char="2023">la</TOKEN>
<TOKEN id="token-24-37" pos="word" morph="none" start_char="2025" end_char="2030">unidad</TOKEN>
<TOKEN id="token-24-38" pos="word" morph="none" start_char="2032" end_char="2033">de</TOKEN>
<TOKEN id="token-24-39" pos="word" morph="none" start_char="2035" end_char="2039">virus</TOKEN>
<TOKEN id="token-24-40" pos="word" morph="none" start_char="2041" end_char="2041">e</TOKEN>
<TOKEN id="token-24-41" pos="word" morph="none" start_char="2043" end_char="2053">inmunología</TOKEN>
<TOKEN id="token-24-42" pos="word" morph="none" start_char="2055" end_char="2057">del</TOKEN>
<TOKEN id="token-24-43" pos="word" morph="none" start_char="2059" end_char="2067">Instituto</TOKEN>
<TOKEN id="token-24-44" pos="word" morph="none" start_char="2069" end_char="2075">Pasteur</TOKEN>
<TOKEN id="token-24-45" pos="punct" morph="none" start_char="2076" end_char="2076">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2078" end_char="2182">
<ORIGINAL_TEXT>Sin embargo, hace referencia a un virus diferente del detectado por primera vez a fines de 2019 en China.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="2078" end_char="2080">Sin</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="2082" end_char="2088">embargo</TOKEN>
<TOKEN id="token-25-2" pos="punct" morph="none" start_char="2089" end_char="2089">,</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="2091" end_char="2094">hace</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="2096" end_char="2105">referencia</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="2107" end_char="2107">a</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="2109" end_char="2110">un</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="2112" end_char="2116">virus</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="2118" end_char="2126">diferente</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="2128" end_char="2130">del</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="2132" end_char="2140">detectado</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="2142" end_char="2144">por</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="2146" end_char="2152">primera</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="2154" end_char="2156">vez</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="2158" end_char="2158">a</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="2160" end_char="2164">fines</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="2166" end_char="2167">de</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="2169" end_char="2172">2019</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="2174" end_char="2175">en</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="2177" end_char="2181">China</TOKEN>
<TOKEN id="token-25-20" pos="punct" morph="none" start_char="2182" end_char="2182">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="2185" end_char="2251">
<ORIGINAL_TEXT>"No patentamos un virus, sino la codificación genética de un virus"</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="punct" morph="none" start_char="2185" end_char="2185">"</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="2186" end_char="2187">No</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="2189" end_char="2198">patentamos</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="2200" end_char="2201">un</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="2203" end_char="2207">virus</TOKEN>
<TOKEN id="token-26-5" pos="punct" morph="none" start_char="2208" end_char="2208">,</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="2210" end_char="2213">sino</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="2215" end_char="2216">la</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="2218" end_char="2229">codificación</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="2231" end_char="2238">genética</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="2240" end_char="2241">de</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="2243" end_char="2244">un</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="2246" end_char="2250">virus</TOKEN>
<TOKEN id="token-26-13" pos="punct" morph="none" start_char="2251" end_char="2251">"</TOKEN>
</SEG>
<SEG id="segment-27" start_char="2254" end_char="2281">
<ORIGINAL_TEXT>, aseguró Schwartz a la AFP.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="punct" morph="none" start_char="2254" end_char="2254">,</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="2256" end_char="2262">aseguró</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="2264" end_char="2271">Schwartz</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="2273" end_char="2273">a</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="2275" end_char="2276">la</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="2278" end_char="2280">AFP</TOKEN>
<TOKEN id="token-27-6" pos="punct" morph="none" start_char="2281" end_char="2281">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="2284" end_char="2395">
<ORIGINAL_TEXT>El código genético en la patente presentada en 2004 por el Instituto Pasteur se relaciona con una cepa de SRAS (</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="2284" end_char="2285">El</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="2287" end_char="2292">código</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="2294" end_char="2301">genético</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="2303" end_char="2304">en</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="2306" end_char="2307">la</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="2309" end_char="2315">patente</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="2317" end_char="2326">presentada</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="2328" end_char="2329">en</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="2331" end_char="2334">2004</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="2336" end_char="2338">por</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="2340" end_char="2341">el</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="2343" end_char="2351">Instituto</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="2353" end_char="2359">Pasteur</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="2361" end_char="2362">se</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="2364" end_char="2372">relaciona</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="2374" end_char="2376">con</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="2378" end_char="2380">una</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="2382" end_char="2385">cepa</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="2387" end_char="2388">de</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="2390" end_char="2393">SRAS</TOKEN>
<TOKEN id="token-28-20" pos="punct" morph="none" start_char="2395" end_char="2395">(</TOKEN>
</SEG>
<SEG id="segment-29" start_char="2398" end_char="2441">
<ORIGINAL_TEXT>"Síndrome Respiratorio Agudo Severo o Grave"</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="punct" morph="none" start_char="2398" end_char="2398">"</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="2399" end_char="2406">Síndrome</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="2408" end_char="2419">Respiratorio</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="2421" end_char="2425">Agudo</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="2427" end_char="2432">Severo</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="2434" end_char="2434">o</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="2436" end_char="2440">Grave</TOKEN>
<TOKEN id="token-29-7" pos="punct" morph="none" start_char="2441" end_char="2441">"</TOKEN>
</SEG>
<SEG id="segment-30" start_char="2444" end_char="2444">
<ORIGINAL_TEXT>o</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="2444" end_char="2444">o</TOKEN>
</SEG>
<SEG id="segment-31" start_char="2447" end_char="2456">
<ORIGINAL_TEXT>"SARS-CoV"</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="punct" morph="none" start_char="2447" end_char="2447">"</TOKEN>
<TOKEN id="token-31-1" pos="unknown" morph="none" start_char="2448" end_char="2455">SARS-CoV</TOKEN>
<TOKEN id="token-31-2" pos="punct" morph="none" start_char="2456" end_char="2456">"</TOKEN>
</SEG>
<SEG id="segment-32" start_char="2459" end_char="2640">
<ORIGINAL_TEXT>, su nombre científico), otro coronavirus que afectó a 8.000 personas en 30 países entre 2002 y 2003, y que causó más de 700 muertes, según la Organización Mundial de la Salud (OMS).</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="punct" morph="none" start_char="2459" end_char="2459">,</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="2461" end_char="2462">su</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="2464" end_char="2469">nombre</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="2471" end_char="2480">científico</TOKEN>
<TOKEN id="token-32-4" pos="punct" morph="none" start_char="2481" end_char="2482">),</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="2484" end_char="2487">otro</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="2489" end_char="2499">coronavirus</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="2501" end_char="2503">que</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="2505" end_char="2510">afectó</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="2512" end_char="2512">a</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="2514" end_char="2518">8.000</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="2520" end_char="2527">personas</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="2529" end_char="2530">en</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="2532" end_char="2533">30</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="2535" end_char="2540">países</TOKEN>
<TOKEN id="token-32-15" pos="word" morph="none" start_char="2542" end_char="2546">entre</TOKEN>
<TOKEN id="token-32-16" pos="word" morph="none" start_char="2548" end_char="2551">2002</TOKEN>
<TOKEN id="token-32-17" pos="word" morph="none" start_char="2553" end_char="2553">y</TOKEN>
<TOKEN id="token-32-18" pos="word" morph="none" start_char="2555" end_char="2558">2003</TOKEN>
<TOKEN id="token-32-19" pos="punct" morph="none" start_char="2559" end_char="2559">,</TOKEN>
<TOKEN id="token-32-20" pos="word" morph="none" start_char="2561" end_char="2561">y</TOKEN>
<TOKEN id="token-32-21" pos="word" morph="none" start_char="2563" end_char="2565">que</TOKEN>
<TOKEN id="token-32-22" pos="word" morph="none" start_char="2567" end_char="2571">causó</TOKEN>
<TOKEN id="token-32-23" pos="word" morph="none" start_char="2573" end_char="2575">más</TOKEN>
<TOKEN id="token-32-24" pos="word" morph="none" start_char="2577" end_char="2578">de</TOKEN>
<TOKEN id="token-32-25" pos="word" morph="none" start_char="2580" end_char="2582">700</TOKEN>
<TOKEN id="token-32-26" pos="word" morph="none" start_char="2584" end_char="2590">muertes</TOKEN>
<TOKEN id="token-32-27" pos="punct" morph="none" start_char="2591" end_char="2591">,</TOKEN>
<TOKEN id="token-32-28" pos="word" morph="none" start_char="2593" end_char="2597">según</TOKEN>
<TOKEN id="token-32-29" pos="word" morph="none" start_char="2599" end_char="2600">la</TOKEN>
<TOKEN id="token-32-30" pos="word" morph="none" start_char="2602" end_char="2613">Organización</TOKEN>
<TOKEN id="token-32-31" pos="word" morph="none" start_char="2615" end_char="2621">Mundial</TOKEN>
<TOKEN id="token-32-32" pos="word" morph="none" start_char="2623" end_char="2624">de</TOKEN>
<TOKEN id="token-32-33" pos="word" morph="none" start_char="2626" end_char="2627">la</TOKEN>
<TOKEN id="token-32-34" pos="word" morph="none" start_char="2629" end_char="2633">Salud</TOKEN>
<TOKEN id="token-32-35" pos="punct" morph="none" start_char="2635" end_char="2635">(</TOKEN>
<TOKEN id="token-32-36" pos="word" morph="none" start_char="2636" end_char="2638">OMS</TOKEN>
<TOKEN id="token-32-37" pos="punct" morph="none" start_char="2639" end_char="2640">).</TOKEN>
</SEG>
<SEG id="segment-33" start_char="2643" end_char="2737">
<ORIGINAL_TEXT>"No hay un solo coronavirus, existen al menos siete, por lo que, el contenido de esta secuencia</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="punct" morph="none" start_char="2643" end_char="2643">"</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="2644" end_char="2645">No</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="2647" end_char="2649">hay</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="2651" end_char="2652">un</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="2654" end_char="2657">solo</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="2659" end_char="2669">coronavirus</TOKEN>
<TOKEN id="token-33-6" pos="punct" morph="none" start_char="2670" end_char="2670">,</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="2672" end_char="2678">existen</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="2680" end_char="2681">al</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="2683" end_char="2687">menos</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="2689" end_char="2693">siete</TOKEN>
<TOKEN id="token-33-11" pos="punct" morph="none" start_char="2694" end_char="2694">,</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="2696" end_char="2698">por</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="2700" end_char="2701">lo</TOKEN>
<TOKEN id="token-33-14" pos="word" morph="none" start_char="2703" end_char="2705">que</TOKEN>
<TOKEN id="token-33-15" pos="punct" morph="none" start_char="2706" end_char="2706">,</TOKEN>
<TOKEN id="token-33-16" pos="word" morph="none" start_char="2708" end_char="2709">el</TOKEN>
<TOKEN id="token-33-17" pos="word" morph="none" start_char="2711" end_char="2719">contenido</TOKEN>
<TOKEN id="token-33-18" pos="word" morph="none" start_char="2721" end_char="2722">de</TOKEN>
<TOKEN id="token-33-19" pos="word" morph="none" start_char="2724" end_char="2727">esta</TOKEN>
<TOKEN id="token-33-20" pos="word" morph="none" start_char="2729" end_char="2737">secuencia</TOKEN>
</SEG>
<SEG id="segment-34" start_char="2740" end_char="2764">
<ORIGINAL_TEXT>(o código genético, ndlr)</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="punct" morph="none" start_char="2740" end_char="2740">(</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="2741" end_char="2741">o</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="2743" end_char="2748">código</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="2750" end_char="2757">genético</TOKEN>
<TOKEN id="token-34-4" pos="punct" morph="none" start_char="2758" end_char="2758">,</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="2760" end_char="2763">ndlr</TOKEN>
<TOKEN id="token-34-6" pos="punct" morph="none" start_char="2764" end_char="2764">)</TOKEN>
</SEG>
<SEG id="segment-35" start_char="2767" end_char="2853">
<ORIGINAL_TEXT>corresponde a la epidemia de 2003, es un primo del virus que centra la epidemia actual"</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="2767" end_char="2777">corresponde</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="2779" end_char="2779">a</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="2781" end_char="2782">la</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="2784" end_char="2791">epidemia</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="2793" end_char="2794">de</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="2796" end_char="2799">2003</TOKEN>
<TOKEN id="token-35-6" pos="punct" morph="none" start_char="2800" end_char="2800">,</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="2802" end_char="2803">es</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="2805" end_char="2806">un</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="2808" end_char="2812">primo</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="2814" end_char="2816">del</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="2818" end_char="2822">virus</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="2824" end_char="2826">que</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="2828" end_char="2833">centra</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="2835" end_char="2836">la</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="2838" end_char="2845">epidemia</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="2847" end_char="2852">actual</TOKEN>
<TOKEN id="token-35-17" pos="punct" morph="none" start_char="2853" end_char="2853">"</TOKEN>
</SEG>
<SEG id="segment-36" start_char="2856" end_char="2874">
<ORIGINAL_TEXT>, detalló Schwartz.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="punct" morph="none" start_char="2856" end_char="2856">,</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="2858" end_char="2864">detalló</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="2866" end_char="2873">Schwartz</TOKEN>
<TOKEN id="token-36-3" pos="punct" morph="none" start_char="2874" end_char="2874">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="2877" end_char="3029">
<ORIGINAL_TEXT>"El virus responsable del COVID-19 y el virus que causa el síndrome respiratorio agudo severo (SRAS) están genéticamente vinculados, pero son diferentes"</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="punct" morph="none" start_char="2877" end_char="2877">"</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="2878" end_char="2879">El</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="2881" end_char="2885">virus</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="2887" end_char="2897">responsable</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="2899" end_char="2901">del</TOKEN>
<TOKEN id="token-37-5" pos="unknown" morph="none" start_char="2903" end_char="2910">COVID-19</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="2912" end_char="2912">y</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="2914" end_char="2915">el</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="2917" end_char="2921">virus</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="2923" end_char="2925">que</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="2927" end_char="2931">causa</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="2933" end_char="2934">el</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="2936" end_char="2943">síndrome</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="2945" end_char="2956">respiratorio</TOKEN>
<TOKEN id="token-37-14" pos="word" morph="none" start_char="2958" end_char="2962">agudo</TOKEN>
<TOKEN id="token-37-15" pos="word" morph="none" start_char="2964" end_char="2969">severo</TOKEN>
<TOKEN id="token-37-16" pos="punct" morph="none" start_char="2971" end_char="2971">(</TOKEN>
<TOKEN id="token-37-17" pos="word" morph="none" start_char="2972" end_char="2975">SRAS</TOKEN>
<TOKEN id="token-37-18" pos="punct" morph="none" start_char="2976" end_char="2976">)</TOKEN>
<TOKEN id="token-37-19" pos="word" morph="none" start_char="2978" end_char="2982">están</TOKEN>
<TOKEN id="token-37-20" pos="word" morph="none" start_char="2984" end_char="2996">genéticamente</TOKEN>
<TOKEN id="token-37-21" pos="word" morph="none" start_char="2998" end_char="3007">vinculados</TOKEN>
<TOKEN id="token-37-22" pos="punct" morph="none" start_char="3008" end_char="3008">,</TOKEN>
<TOKEN id="token-37-23" pos="word" morph="none" start_char="3010" end_char="3013">pero</TOKEN>
<TOKEN id="token-37-24" pos="word" morph="none" start_char="3015" end_char="3017">son</TOKEN>
<TOKEN id="token-37-25" pos="word" morph="none" start_char="3019" end_char="3028">diferentes</TOKEN>
<TOKEN id="token-37-26" pos="punct" morph="none" start_char="3029" end_char="3029">"</TOKEN>
</SEG>
<SEG id="segment-38" start_char="3032" end_char="3058">
<ORIGINAL_TEXT>, explica la web de la OMS.</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="punct" morph="none" start_char="3032" end_char="3032">,</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="3034" end_char="3040">explica</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="3042" end_char="3043">la</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="3045" end_char="3047">web</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="3049" end_char="3050">de</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="3052" end_char="3053">la</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="3055" end_char="3057">OMS</TOKEN>
<TOKEN id="token-38-7" pos="punct" morph="none" start_char="3058" end_char="3058">.</TOKEN>
</SEG>
<SEG id="segment-39" start_char="3060" end_char="3166">
<ORIGINAL_TEXT>El virus que provoca la enfermedad COVID-19, de hecho, se nombra como SARS-CoV-2, según el mismo organismo.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="3060" end_char="3061">El</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="3063" end_char="3067">virus</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="3069" end_char="3071">que</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="3073" end_char="3079">provoca</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="3081" end_char="3082">la</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="3084" end_char="3093">enfermedad</TOKEN>
<TOKEN id="token-39-6" pos="unknown" morph="none" start_char="3095" end_char="3102">COVID-19</TOKEN>
<TOKEN id="token-39-7" pos="punct" morph="none" start_char="3103" end_char="3103">,</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="3105" end_char="3106">de</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="3108" end_char="3112">hecho</TOKEN>
<TOKEN id="token-39-10" pos="punct" morph="none" start_char="3113" end_char="3113">,</TOKEN>
<TOKEN id="token-39-11" pos="word" morph="none" start_char="3115" end_char="3116">se</TOKEN>
<TOKEN id="token-39-12" pos="word" morph="none" start_char="3118" end_char="3123">nombra</TOKEN>
<TOKEN id="token-39-13" pos="word" morph="none" start_char="3125" end_char="3128">como</TOKEN>
<TOKEN id="token-39-14" pos="unknown" morph="none" start_char="3130" end_char="3139">SARS-CoV-2</TOKEN>
<TOKEN id="token-39-15" pos="punct" morph="none" start_char="3140" end_char="3140">,</TOKEN>
<TOKEN id="token-39-16" pos="word" morph="none" start_char="3142" end_char="3146">según</TOKEN>
<TOKEN id="token-39-17" pos="word" morph="none" start_char="3148" end_char="3149">el</TOKEN>
<TOKEN id="token-39-18" pos="word" morph="none" start_char="3151" end_char="3155">mismo</TOKEN>
<TOKEN id="token-39-19" pos="word" morph="none" start_char="3157" end_char="3165">organismo</TOKEN>
<TOKEN id="token-39-20" pos="punct" morph="none" start_char="3166" end_char="3166">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="3169" end_char="3265">
<ORIGINAL_TEXT>"Existe un 80% de similitudes en su secuencia genética con el virus de 2003, pero no es la misma"</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="punct" morph="none" start_char="3169" end_char="3169">"</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="3170" end_char="3175">Existe</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="3177" end_char="3178">un</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="3180" end_char="3181">80</TOKEN>
<TOKEN id="token-40-4" pos="punct" morph="none" start_char="3182" end_char="3182">%</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="3184" end_char="3185">de</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="3187" end_char="3197">similitudes</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="3199" end_char="3200">en</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="3202" end_char="3203">su</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="3205" end_char="3213">secuencia</TOKEN>
<TOKEN id="token-40-10" pos="word" morph="none" start_char="3215" end_char="3222">genética</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="3224" end_char="3226">con</TOKEN>
<TOKEN id="token-40-12" pos="word" morph="none" start_char="3228" end_char="3229">el</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="3231" end_char="3235">virus</TOKEN>
<TOKEN id="token-40-14" pos="word" morph="none" start_char="3237" end_char="3238">de</TOKEN>
<TOKEN id="token-40-15" pos="word" morph="none" start_char="3240" end_char="3243">2003</TOKEN>
<TOKEN id="token-40-16" pos="punct" morph="none" start_char="3244" end_char="3244">,</TOKEN>
<TOKEN id="token-40-17" pos="word" morph="none" start_char="3246" end_char="3249">pero</TOKEN>
<TOKEN id="token-40-18" pos="word" morph="none" start_char="3251" end_char="3252">no</TOKEN>
<TOKEN id="token-40-19" pos="word" morph="none" start_char="3254" end_char="3255">es</TOKEN>
<TOKEN id="token-40-20" pos="word" morph="none" start_char="3257" end_char="3258">la</TOKEN>
<TOKEN id="token-40-21" pos="word" morph="none" start_char="3260" end_char="3264">misma</TOKEN>
<TOKEN id="token-40-22" pos="punct" morph="none" start_char="3265" end_char="3265">"</TOKEN>
</SEG>
<SEG id="segment-41" start_char="3268" end_char="3345">
<ORIGINAL_TEXT>, añade el director de la unidad de virus e inmunología del Instituto Pasteur.</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="punct" morph="none" start_char="3268" end_char="3268">,</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="3270" end_char="3274">añade</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="3276" end_char="3277">el</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="3279" end_char="3286">director</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="3288" end_char="3289">de</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="3291" end_char="3292">la</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="3294" end_char="3299">unidad</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="3301" end_char="3302">de</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="3304" end_char="3308">virus</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="3310" end_char="3310">e</TOKEN>
<TOKEN id="token-41-10" pos="word" morph="none" start_char="3312" end_char="3322">inmunología</TOKEN>
<TOKEN id="token-41-11" pos="word" morph="none" start_char="3324" end_char="3326">del</TOKEN>
<TOKEN id="token-41-12" pos="word" morph="none" start_char="3328" end_char="3336">Instituto</TOKEN>
<TOKEN id="token-41-13" pos="word" morph="none" start_char="3338" end_char="3344">Pasteur</TOKEN>
<TOKEN id="token-41-14" pos="punct" morph="none" start_char="3345" end_char="3345">.</TOKEN>
</SEG>
<SEG id="segment-42" start_char="3348" end_char="3474">
<ORIGINAL_TEXT>Las vacunas que se probaron en la patente presentada en 2004 no pueden reutilizarse para el nuevo coronavirus, aclaró Schwartz,</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="3348" end_char="3350">Las</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="3352" end_char="3358">vacunas</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="3360" end_char="3362">que</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="3364" end_char="3365">se</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="3367" end_char="3374">probaron</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="3376" end_char="3377">en</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="3379" end_char="3380">la</TOKEN>
<TOKEN id="token-42-7" pos="word" morph="none" start_char="3382" end_char="3388">patente</TOKEN>
<TOKEN id="token-42-8" pos="word" morph="none" start_char="3390" end_char="3399">presentada</TOKEN>
<TOKEN id="token-42-9" pos="word" morph="none" start_char="3401" end_char="3402">en</TOKEN>
<TOKEN id="token-42-10" pos="word" morph="none" start_char="3404" end_char="3407">2004</TOKEN>
<TOKEN id="token-42-11" pos="word" morph="none" start_char="3409" end_char="3410">no</TOKEN>
<TOKEN id="token-42-12" pos="word" morph="none" start_char="3412" end_char="3417">pueden</TOKEN>
<TOKEN id="token-42-13" pos="word" morph="none" start_char="3419" end_char="3430">reutilizarse</TOKEN>
<TOKEN id="token-42-14" pos="word" morph="none" start_char="3432" end_char="3435">para</TOKEN>
<TOKEN id="token-42-15" pos="word" morph="none" start_char="3437" end_char="3438">el</TOKEN>
<TOKEN id="token-42-16" pos="word" morph="none" start_char="3440" end_char="3444">nuevo</TOKEN>
<TOKEN id="token-42-17" pos="word" morph="none" start_char="3446" end_char="3456">coronavirus</TOKEN>
<TOKEN id="token-42-18" pos="punct" morph="none" start_char="3457" end_char="3457">,</TOKEN>
<TOKEN id="token-42-19" pos="word" morph="none" start_char="3459" end_char="3464">aclaró</TOKEN>
<TOKEN id="token-42-20" pos="word" morph="none" start_char="3466" end_char="3473">Schwartz</TOKEN>
<TOKEN id="token-42-21" pos="punct" morph="none" start_char="3474" end_char="3474">,</TOKEN>
</SEG>
<SEG id="segment-43" start_char="3477" end_char="3504">
<ORIGINAL_TEXT>"debido a estas diferencias"</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="punct" morph="none" start_char="3477" end_char="3477">"</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="3478" end_char="3483">debido</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="3485" end_char="3485">a</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="3487" end_char="3491">estas</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="3493" end_char="3503">diferencias</TOKEN>
<TOKEN id="token-43-5" pos="punct" morph="none" start_char="3504" end_char="3504">"</TOKEN>
</SEG>
<SEG id="segment-44" start_char="3507" end_char="3507">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="punct" morph="none" start_char="3507" end_char="3507">.</TOKEN>
</SEG>
<SEG id="segment-45" start_char="3510" end_char="3529">
<ORIGINAL_TEXT>Patentar no es crear</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="3510" end_char="3517">Patentar</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="3519" end_char="3520">no</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="3522" end_char="3523">es</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="3525" end_char="3529">crear</TOKEN>
</SEG>
<SEG id="segment-46" start_char="3533" end_char="3600">
<ORIGINAL_TEXT>La publicación viral vincula al COVID-19 con el SARS-CoV, y detalla:</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="3533" end_char="3534">La</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="3536" end_char="3546">publicación</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="3548" end_char="3552">viral</TOKEN>
<TOKEN id="token-46-3" pos="word" morph="none" start_char="3554" end_char="3560">vincula</TOKEN>
<TOKEN id="token-46-4" pos="word" morph="none" start_char="3562" end_char="3563">al</TOKEN>
<TOKEN id="token-46-5" pos="unknown" morph="none" start_char="3565" end_char="3572">COVID-19</TOKEN>
<TOKEN id="token-46-6" pos="word" morph="none" start_char="3574" end_char="3576">con</TOKEN>
<TOKEN id="token-46-7" pos="word" morph="none" start_char="3578" end_char="3579">el</TOKEN>
<TOKEN id="token-46-8" pos="unknown" morph="none" start_char="3581" end_char="3588">SARS-CoV</TOKEN>
<TOKEN id="token-46-9" pos="punct" morph="none" start_char="3589" end_char="3589">,</TOKEN>
<TOKEN id="token-46-10" pos="word" morph="none" start_char="3591" end_char="3591">y</TOKEN>
<TOKEN id="token-46-11" pos="word" morph="none" start_char="3593" end_char="3599">detalla</TOKEN>
<TOKEN id="token-46-12" pos="punct" morph="none" start_char="3600" end_char="3600">:</TOKEN>
</SEG>
<SEG id="segment-47" start_char="3603" end_char="4073">
<ORIGINAL_TEXT>"En las primeras líneas de la patente explica.. 'La presente invención se refiere a una nueva cepa de coronavirus asociada con el síndrome respiratorio agudo severo (SRAS), resultante de una muestra registrada con el número 031589 y tomada en Hanoi (Vietnam), moléculas de ácido nucleico derivadas de su genoma, las proteínas y péptidos codificados por dichas moléculas de ácido nucleico y sus aplicaciones, especialmente como reactivos de diagnóstico y / o como vacuna'"</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="punct" morph="none" start_char="3603" end_char="3603">"</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="3604" end_char="3605">En</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="3607" end_char="3609">las</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="3611" end_char="3618">primeras</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="3620" end_char="3625">líneas</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="3627" end_char="3628">de</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="3630" end_char="3631">la</TOKEN>
<TOKEN id="token-47-7" pos="word" morph="none" start_char="3633" end_char="3639">patente</TOKEN>
<TOKEN id="token-47-8" pos="word" morph="none" start_char="3641" end_char="3647">explica</TOKEN>
<TOKEN id="token-47-9" pos="punct" morph="none" start_char="3648" end_char="3649">..</TOKEN>
<TOKEN id="token-47-10" pos="punct" morph="none" start_char="3651" end_char="3651">'</TOKEN>
<TOKEN id="token-47-11" pos="word" morph="none" start_char="3652" end_char="3653">La</TOKEN>
<TOKEN id="token-47-12" pos="word" morph="none" start_char="3655" end_char="3662">presente</TOKEN>
<TOKEN id="token-47-13" pos="word" morph="none" start_char="3664" end_char="3672">invención</TOKEN>
<TOKEN id="token-47-14" pos="word" morph="none" start_char="3674" end_char="3675">se</TOKEN>
<TOKEN id="token-47-15" pos="word" morph="none" start_char="3677" end_char="3683">refiere</TOKEN>
<TOKEN id="token-47-16" pos="word" morph="none" start_char="3685" end_char="3685">a</TOKEN>
<TOKEN id="token-47-17" pos="word" morph="none" start_char="3687" end_char="3689">una</TOKEN>
<TOKEN id="token-47-18" pos="word" morph="none" start_char="3691" end_char="3695">nueva</TOKEN>
<TOKEN id="token-47-19" pos="word" morph="none" start_char="3697" end_char="3700">cepa</TOKEN>
<TOKEN id="token-47-20" pos="word" morph="none" start_char="3702" end_char="3703">de</TOKEN>
<TOKEN id="token-47-21" pos="word" morph="none" start_char="3705" end_char="3715">coronavirus</TOKEN>
<TOKEN id="token-47-22" pos="word" morph="none" start_char="3717" end_char="3724">asociada</TOKEN>
<TOKEN id="token-47-23" pos="word" morph="none" start_char="3726" end_char="3728">con</TOKEN>
<TOKEN id="token-47-24" pos="word" morph="none" start_char="3730" end_char="3731">el</TOKEN>
<TOKEN id="token-47-25" pos="word" morph="none" start_char="3733" end_char="3740">síndrome</TOKEN>
<TOKEN id="token-47-26" pos="word" morph="none" start_char="3742" end_char="3753">respiratorio</TOKEN>
<TOKEN id="token-47-27" pos="word" morph="none" start_char="3755" end_char="3759">agudo</TOKEN>
<TOKEN id="token-47-28" pos="word" morph="none" start_char="3761" end_char="3766">severo</TOKEN>
<TOKEN id="token-47-29" pos="punct" morph="none" start_char="3768" end_char="3768">(</TOKEN>
<TOKEN id="token-47-30" pos="word" morph="none" start_char="3769" end_char="3772">SRAS</TOKEN>
<TOKEN id="token-47-31" pos="punct" morph="none" start_char="3773" end_char="3774">),</TOKEN>
<TOKEN id="token-47-32" pos="word" morph="none" start_char="3776" end_char="3785">resultante</TOKEN>
<TOKEN id="token-47-33" pos="word" morph="none" start_char="3787" end_char="3788">de</TOKEN>
<TOKEN id="token-47-34" pos="word" morph="none" start_char="3790" end_char="3792">una</TOKEN>
<TOKEN id="token-47-35" pos="word" morph="none" start_char="3794" end_char="3800">muestra</TOKEN>
<TOKEN id="token-47-36" pos="word" morph="none" start_char="3802" end_char="3811">registrada</TOKEN>
<TOKEN id="token-47-37" pos="word" morph="none" start_char="3813" end_char="3815">con</TOKEN>
<TOKEN id="token-47-38" pos="word" morph="none" start_char="3817" end_char="3818">el</TOKEN>
<TOKEN id="token-47-39" pos="word" morph="none" start_char="3820" end_char="3825">número</TOKEN>
<TOKEN id="token-47-40" pos="word" morph="none" start_char="3827" end_char="3832">031589</TOKEN>
<TOKEN id="token-47-41" pos="word" morph="none" start_char="3834" end_char="3834">y</TOKEN>
<TOKEN id="token-47-42" pos="word" morph="none" start_char="3836" end_char="3841">tomada</TOKEN>
<TOKEN id="token-47-43" pos="word" morph="none" start_char="3843" end_char="3844">en</TOKEN>
<TOKEN id="token-47-44" pos="word" morph="none" start_char="3846" end_char="3850">Hanoi</TOKEN>
<TOKEN id="token-47-45" pos="punct" morph="none" start_char="3852" end_char="3852">(</TOKEN>
<TOKEN id="token-47-46" pos="word" morph="none" start_char="3853" end_char="3859">Vietnam</TOKEN>
<TOKEN id="token-47-47" pos="punct" morph="none" start_char="3860" end_char="3861">),</TOKEN>
<TOKEN id="token-47-48" pos="word" morph="none" start_char="3863" end_char="3871">moléculas</TOKEN>
<TOKEN id="token-47-49" pos="word" morph="none" start_char="3873" end_char="3874">de</TOKEN>
<TOKEN id="token-47-50" pos="word" morph="none" start_char="3876" end_char="3880">ácido</TOKEN>
<TOKEN id="token-47-51" pos="word" morph="none" start_char="3882" end_char="3889">nucleico</TOKEN>
<TOKEN id="token-47-52" pos="word" morph="none" start_char="3891" end_char="3899">derivadas</TOKEN>
<TOKEN id="token-47-53" pos="word" morph="none" start_char="3901" end_char="3902">de</TOKEN>
<TOKEN id="token-47-54" pos="word" morph="none" start_char="3904" end_char="3905">su</TOKEN>
<TOKEN id="token-47-55" pos="word" morph="none" start_char="3907" end_char="3912">genoma</TOKEN>
<TOKEN id="token-47-56" pos="punct" morph="none" start_char="3913" end_char="3913">,</TOKEN>
<TOKEN id="token-47-57" pos="word" morph="none" start_char="3915" end_char="3917">las</TOKEN>
<TOKEN id="token-47-58" pos="word" morph="none" start_char="3919" end_char="3927">proteínas</TOKEN>
<TOKEN id="token-47-59" pos="word" morph="none" start_char="3929" end_char="3929">y</TOKEN>
<TOKEN id="token-47-60" pos="word" morph="none" start_char="3931" end_char="3938">péptidos</TOKEN>
<TOKEN id="token-47-61" pos="word" morph="none" start_char="3940" end_char="3950">codificados</TOKEN>
<TOKEN id="token-47-62" pos="word" morph="none" start_char="3952" end_char="3954">por</TOKEN>
<TOKEN id="token-47-63" pos="word" morph="none" start_char="3956" end_char="3961">dichas</TOKEN>
<TOKEN id="token-47-64" pos="word" morph="none" start_char="3963" end_char="3971">moléculas</TOKEN>
<TOKEN id="token-47-65" pos="word" morph="none" start_char="3973" end_char="3974">de</TOKEN>
<TOKEN id="token-47-66" pos="word" morph="none" start_char="3976" end_char="3980">ácido</TOKEN>
<TOKEN id="token-47-67" pos="word" morph="none" start_char="3982" end_char="3989">nucleico</TOKEN>
<TOKEN id="token-47-68" pos="word" morph="none" start_char="3991" end_char="3991">y</TOKEN>
<TOKEN id="token-47-69" pos="word" morph="none" start_char="3993" end_char="3995">sus</TOKEN>
<TOKEN id="token-47-70" pos="word" morph="none" start_char="3997" end_char="4008">aplicaciones</TOKEN>
<TOKEN id="token-47-71" pos="punct" morph="none" start_char="4009" end_char="4009">,</TOKEN>
<TOKEN id="token-47-72" pos="word" morph="none" start_char="4011" end_char="4023">especialmente</TOKEN>
<TOKEN id="token-47-73" pos="word" morph="none" start_char="4025" end_char="4028">como</TOKEN>
<TOKEN id="token-47-74" pos="word" morph="none" start_char="4030" end_char="4038">reactivos</TOKEN>
<TOKEN id="token-47-75" pos="word" morph="none" start_char="4040" end_char="4041">de</TOKEN>
<TOKEN id="token-47-76" pos="word" morph="none" start_char="4043" end_char="4053">diagnóstico</TOKEN>
<TOKEN id="token-47-77" pos="word" morph="none" start_char="4055" end_char="4055">y</TOKEN>
<TOKEN id="token-47-78" pos="punct" morph="none" start_char="4057" end_char="4057">/</TOKEN>
<TOKEN id="token-47-79" pos="word" morph="none" start_char="4059" end_char="4059">o</TOKEN>
<TOKEN id="token-47-80" pos="word" morph="none" start_char="4061" end_char="4064">como</TOKEN>
<TOKEN id="token-47-81" pos="word" morph="none" start_char="4066" end_char="4071">vacuna</TOKEN>
<TOKEN id="token-47-82" pos="punct" morph="none" start_char="4072" end_char="4073">'"</TOKEN>
</SEG>
<SEG id="segment-48" start_char="4076" end_char="4076">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="punct" morph="none" start_char="4076" end_char="4076">.</TOKEN>
</SEG>
<SEG id="segment-49" start_char="4079" end_char="4186">
<ORIGINAL_TEXT>Esa afirmación citada aparece en el documento de la patente, como puede verse en el extracto a continuación:</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="4079" end_char="4081">Esa</TOKEN>
<TOKEN id="token-49-1" pos="word" morph="none" start_char="4083" end_char="4092">afirmación</TOKEN>
<TOKEN id="token-49-2" pos="word" morph="none" start_char="4094" end_char="4099">citada</TOKEN>
<TOKEN id="token-49-3" pos="word" morph="none" start_char="4101" end_char="4107">aparece</TOKEN>
<TOKEN id="token-49-4" pos="word" morph="none" start_char="4109" end_char="4110">en</TOKEN>
<TOKEN id="token-49-5" pos="word" morph="none" start_char="4112" end_char="4113">el</TOKEN>
<TOKEN id="token-49-6" pos="word" morph="none" start_char="4115" end_char="4123">documento</TOKEN>
<TOKEN id="token-49-7" pos="word" morph="none" start_char="4125" end_char="4126">de</TOKEN>
<TOKEN id="token-49-8" pos="word" morph="none" start_char="4128" end_char="4129">la</TOKEN>
<TOKEN id="token-49-9" pos="word" morph="none" start_char="4131" end_char="4137">patente</TOKEN>
<TOKEN id="token-49-10" pos="punct" morph="none" start_char="4138" end_char="4138">,</TOKEN>
<TOKEN id="token-49-11" pos="word" morph="none" start_char="4140" end_char="4143">como</TOKEN>
<TOKEN id="token-49-12" pos="word" morph="none" start_char="4145" end_char="4149">puede</TOKEN>
<TOKEN id="token-49-13" pos="word" morph="none" start_char="4151" end_char="4155">verse</TOKEN>
<TOKEN id="token-49-14" pos="word" morph="none" start_char="4157" end_char="4158">en</TOKEN>
<TOKEN id="token-49-15" pos="word" morph="none" start_char="4160" end_char="4161">el</TOKEN>
<TOKEN id="token-49-16" pos="word" morph="none" start_char="4163" end_char="4170">extracto</TOKEN>
<TOKEN id="token-49-17" pos="word" morph="none" start_char="4172" end_char="4172">a</TOKEN>
<TOKEN id="token-49-18" pos="word" morph="none" start_char="4174" end_char="4185">continuación</TOKEN>
<TOKEN id="token-49-19" pos="punct" morph="none" start_char="4186" end_char="4186">:</TOKEN>
</SEG>
<SEG id="segment-50" start_char="4189" end_char="4295">
<ORIGINAL_TEXT>Captura de pantalla de la patente presentada por el Instituto Pasteur en 2004, hecha el 18 de marzo de 2020</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="4189" end_char="4195">Captura</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="4197" end_char="4198">de</TOKEN>
<TOKEN id="token-50-2" pos="word" morph="none" start_char="4200" end_char="4207">pantalla</TOKEN>
<TOKEN id="token-50-3" pos="word" morph="none" start_char="4209" end_char="4210">de</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="4212" end_char="4213">la</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="4215" end_char="4221">patente</TOKEN>
<TOKEN id="token-50-6" pos="word" morph="none" start_char="4223" end_char="4232">presentada</TOKEN>
<TOKEN id="token-50-7" pos="word" morph="none" start_char="4234" end_char="4236">por</TOKEN>
<TOKEN id="token-50-8" pos="word" morph="none" start_char="4238" end_char="4239">el</TOKEN>
<TOKEN id="token-50-9" pos="word" morph="none" start_char="4241" end_char="4249">Instituto</TOKEN>
<TOKEN id="token-50-10" pos="word" morph="none" start_char="4251" end_char="4257">Pasteur</TOKEN>
<TOKEN id="token-50-11" pos="word" morph="none" start_char="4259" end_char="4260">en</TOKEN>
<TOKEN id="token-50-12" pos="word" morph="none" start_char="4262" end_char="4265">2004</TOKEN>
<TOKEN id="token-50-13" pos="punct" morph="none" start_char="4266" end_char="4266">,</TOKEN>
<TOKEN id="token-50-14" pos="word" morph="none" start_char="4268" end_char="4272">hecha</TOKEN>
<TOKEN id="token-50-15" pos="word" morph="none" start_char="4274" end_char="4275">el</TOKEN>
<TOKEN id="token-50-16" pos="word" morph="none" start_char="4277" end_char="4278">18</TOKEN>
<TOKEN id="token-50-17" pos="word" morph="none" start_char="4280" end_char="4281">de</TOKEN>
<TOKEN id="token-50-18" pos="word" morph="none" start_char="4283" end_char="4287">marzo</TOKEN>
<TOKEN id="token-50-19" pos="word" morph="none" start_char="4289" end_char="4290">de</TOKEN>
<TOKEN id="token-50-20" pos="word" morph="none" start_char="4292" end_char="4295">2020</TOKEN>
</SEG>
<SEG id="segment-51" start_char="4299" end_char="4431">
<ORIGINAL_TEXT>A raíz de este fragmento, la publicación en Facebook pretende asegurar que la codificación genética del SARS-CoV se habría usado para</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="word" morph="none" start_char="4299" end_char="4299">A</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="4301" end_char="4304">raíz</TOKEN>
<TOKEN id="token-51-2" pos="word" morph="none" start_char="4306" end_char="4307">de</TOKEN>
<TOKEN id="token-51-3" pos="word" morph="none" start_char="4309" end_char="4312">este</TOKEN>
<TOKEN id="token-51-4" pos="word" morph="none" start_char="4314" end_char="4322">fragmento</TOKEN>
<TOKEN id="token-51-5" pos="punct" morph="none" start_char="4323" end_char="4323">,</TOKEN>
<TOKEN id="token-51-6" pos="word" morph="none" start_char="4325" end_char="4326">la</TOKEN>
<TOKEN id="token-51-7" pos="word" morph="none" start_char="4328" end_char="4338">publicación</TOKEN>
<TOKEN id="token-51-8" pos="word" morph="none" start_char="4340" end_char="4341">en</TOKEN>
<TOKEN id="token-51-9" pos="word" morph="none" start_char="4343" end_char="4350">Facebook</TOKEN>
<TOKEN id="token-51-10" pos="word" morph="none" start_char="4352" end_char="4359">pretende</TOKEN>
<TOKEN id="token-51-11" pos="word" morph="none" start_char="4361" end_char="4368">asegurar</TOKEN>
<TOKEN id="token-51-12" pos="word" morph="none" start_char="4370" end_char="4372">que</TOKEN>
<TOKEN id="token-51-13" pos="word" morph="none" start_char="4374" end_char="4375">la</TOKEN>
<TOKEN id="token-51-14" pos="word" morph="none" start_char="4377" end_char="4388">codificación</TOKEN>
<TOKEN id="token-51-15" pos="word" morph="none" start_char="4390" end_char="4397">genética</TOKEN>
<TOKEN id="token-51-16" pos="word" morph="none" start_char="4399" end_char="4401">del</TOKEN>
<TOKEN id="token-51-17" pos="unknown" morph="none" start_char="4403" end_char="4410">SARS-CoV</TOKEN>
<TOKEN id="token-51-18" pos="word" morph="none" start_char="4412" end_char="4413">se</TOKEN>
<TOKEN id="token-51-19" pos="word" morph="none" start_char="4415" end_char="4420">habría</TOKEN>
<TOKEN id="token-51-20" pos="word" morph="none" start_char="4422" end_char="4426">usado</TOKEN>
<TOKEN id="token-51-21" pos="word" morph="none" start_char="4428" end_char="4431">para</TOKEN>
</SEG>
<SEG id="segment-52" start_char="4434" end_char="4443">
<ORIGINAL_TEXT>"inventar"</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="punct" morph="none" start_char="4434" end_char="4434">"</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="4435" end_char="4442">inventar</TOKEN>
<TOKEN id="token-52-2" pos="punct" morph="none" start_char="4443" end_char="4443">"</TOKEN>
</SEG>
<SEG id="segment-53" start_char="4446" end_char="4519">
<ORIGINAL_TEXT>en laboratorio una evolución del virus que sería el SARS-CoV-2 (COVID-19).</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="word" morph="none" start_char="4446" end_char="4447">en</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="4449" end_char="4459">laboratorio</TOKEN>
<TOKEN id="token-53-2" pos="word" morph="none" start_char="4461" end_char="4463">una</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="4465" end_char="4473">evolución</TOKEN>
<TOKEN id="token-53-4" pos="word" morph="none" start_char="4475" end_char="4477">del</TOKEN>
<TOKEN id="token-53-5" pos="word" morph="none" start_char="4479" end_char="4483">virus</TOKEN>
<TOKEN id="token-53-6" pos="word" morph="none" start_char="4485" end_char="4487">que</TOKEN>
<TOKEN id="token-53-7" pos="word" morph="none" start_char="4489" end_char="4493">sería</TOKEN>
<TOKEN id="token-53-8" pos="word" morph="none" start_char="4495" end_char="4496">el</TOKEN>
<TOKEN id="token-53-9" pos="unknown" morph="none" start_char="4498" end_char="4507">SARS-CoV-2</TOKEN>
<TOKEN id="token-53-10" pos="punct" morph="none" start_char="4509" end_char="4509">(</TOKEN>
<TOKEN id="token-53-11" pos="unknown" morph="none" start_char="4510" end_char="4517">COVID-19</TOKEN>
<TOKEN id="token-53-12" pos="punct" morph="none" start_char="4518" end_char="4519">).</TOKEN>
</SEG>
<SEG id="segment-54" start_char="4522" end_char="4632">
<ORIGINAL_TEXT>Pero, si bien existen patentes de los códigos genéticos de virus, no significa que éstos hayan sido creados por</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="word" morph="none" start_char="4522" end_char="4525">Pero</TOKEN>
<TOKEN id="token-54-1" pos="punct" morph="none" start_char="4526" end_char="4526">,</TOKEN>
<TOKEN id="token-54-2" pos="word" morph="none" start_char="4528" end_char="4529">si</TOKEN>
<TOKEN id="token-54-3" pos="word" morph="none" start_char="4531" end_char="4534">bien</TOKEN>
<TOKEN id="token-54-4" pos="word" morph="none" start_char="4536" end_char="4542">existen</TOKEN>
<TOKEN id="token-54-5" pos="word" morph="none" start_char="4544" end_char="4551">patentes</TOKEN>
<TOKEN id="token-54-6" pos="word" morph="none" start_char="4553" end_char="4554">de</TOKEN>
<TOKEN id="token-54-7" pos="word" morph="none" start_char="4556" end_char="4558">los</TOKEN>
<TOKEN id="token-54-8" pos="word" morph="none" start_char="4560" end_char="4566">códigos</TOKEN>
<TOKEN id="token-54-9" pos="word" morph="none" start_char="4568" end_char="4576">genéticos</TOKEN>
<TOKEN id="token-54-10" pos="word" morph="none" start_char="4578" end_char="4579">de</TOKEN>
<TOKEN id="token-54-11" pos="word" morph="none" start_char="4581" end_char="4585">virus</TOKEN>
<TOKEN id="token-54-12" pos="punct" morph="none" start_char="4586" end_char="4586">,</TOKEN>
<TOKEN id="token-54-13" pos="word" morph="none" start_char="4588" end_char="4589">no</TOKEN>
<TOKEN id="token-54-14" pos="word" morph="none" start_char="4591" end_char="4599">significa</TOKEN>
<TOKEN id="token-54-15" pos="word" morph="none" start_char="4601" end_char="4603">que</TOKEN>
<TOKEN id="token-54-16" pos="word" morph="none" start_char="4605" end_char="4609">éstos</TOKEN>
<TOKEN id="token-54-17" pos="word" morph="none" start_char="4611" end_char="4615">hayan</TOKEN>
<TOKEN id="token-54-18" pos="word" morph="none" start_char="4617" end_char="4620">sido</TOKEN>
<TOKEN id="token-54-19" pos="word" morph="none" start_char="4622" end_char="4628">creados</TOKEN>
<TOKEN id="token-54-20" pos="word" morph="none" start_char="4630" end_char="4632">por</TOKEN>
</SEG>
<SEG id="segment-55" start_char="4635" end_char="4654">
<ORIGINAL_TEXT>"la mano del hombre"</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="punct" morph="none" start_char="4635" end_char="4635">"</TOKEN>
<TOKEN id="token-55-1" pos="word" morph="none" start_char="4636" end_char="4637">la</TOKEN>
<TOKEN id="token-55-2" pos="word" morph="none" start_char="4639" end_char="4642">mano</TOKEN>
<TOKEN id="token-55-3" pos="word" morph="none" start_char="4644" end_char="4646">del</TOKEN>
<TOKEN id="token-55-4" pos="word" morph="none" start_char="4648" end_char="4653">hombre</TOKEN>
<TOKEN id="token-55-5" pos="punct" morph="none" start_char="4654" end_char="4654">"</TOKEN>
</SEG>
<SEG id="segment-56" start_char="4657" end_char="4685">
<ORIGINAL_TEXT>como sostiene la publicación.</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="4657" end_char="4660">como</TOKEN>
<TOKEN id="token-56-1" pos="word" morph="none" start_char="4662" end_char="4669">sostiene</TOKEN>
<TOKEN id="token-56-2" pos="word" morph="none" start_char="4671" end_char="4672">la</TOKEN>
<TOKEN id="token-56-3" pos="word" morph="none" start_char="4674" end_char="4684">publicación</TOKEN>
<TOKEN id="token-56-4" pos="punct" morph="none" start_char="4685" end_char="4685">.</TOKEN>
</SEG>
<SEG id="segment-57" start_char="4687" end_char="4713">
<ORIGINAL_TEXT>En este sentido, el término</ORIGINAL_TEXT>
<TOKEN id="token-57-0" pos="word" morph="none" start_char="4687" end_char="4688">En</TOKEN>
<TOKEN id="token-57-1" pos="word" morph="none" start_char="4690" end_char="4693">este</TOKEN>
<TOKEN id="token-57-2" pos="word" morph="none" start_char="4695" end_char="4701">sentido</TOKEN>
<TOKEN id="token-57-3" pos="punct" morph="none" start_char="4702" end_char="4702">,</TOKEN>
<TOKEN id="token-57-4" pos="word" morph="none" start_char="4704" end_char="4705">el</TOKEN>
<TOKEN id="token-57-5" pos="word" morph="none" start_char="4707" end_char="4713">término</TOKEN>
</SEG>
<SEG id="segment-58" start_char="4716" end_char="4726">
<ORIGINAL_TEXT>"invención"</ORIGINAL_TEXT>
<TOKEN id="token-58-0" pos="punct" morph="none" start_char="4716" end_char="4716">"</TOKEN>
<TOKEN id="token-58-1" pos="word" morph="none" start_char="4717" end_char="4725">invención</TOKEN>
<TOKEN id="token-58-2" pos="punct" morph="none" start_char="4726" end_char="4726">"</TOKEN>
</SEG>
<SEG id="segment-59" start_char="4729" end_char="4813">
<ORIGINAL_TEXT>utilizado en el texto de la patente tiene, en francés, un significado diferente al de</ORIGINAL_TEXT>
<TOKEN id="token-59-0" pos="word" morph="none" start_char="4729" end_char="4737">utilizado</TOKEN>
<TOKEN id="token-59-1" pos="word" morph="none" start_char="4739" end_char="4740">en</TOKEN>
<TOKEN id="token-59-2" pos="word" morph="none" start_char="4742" end_char="4743">el</TOKEN>
<TOKEN id="token-59-3" pos="word" morph="none" start_char="4745" end_char="4749">texto</TOKEN>
<TOKEN id="token-59-4" pos="word" morph="none" start_char="4751" end_char="4752">de</TOKEN>
<TOKEN id="token-59-5" pos="word" morph="none" start_char="4754" end_char="4755">la</TOKEN>
<TOKEN id="token-59-6" pos="word" morph="none" start_char="4757" end_char="4763">patente</TOKEN>
<TOKEN id="token-59-7" pos="word" morph="none" start_char="4765" end_char="4769">tiene</TOKEN>
<TOKEN id="token-59-8" pos="punct" morph="none" start_char="4770" end_char="4770">,</TOKEN>
<TOKEN id="token-59-9" pos="word" morph="none" start_char="4772" end_char="4773">en</TOKEN>
<TOKEN id="token-59-10" pos="word" morph="none" start_char="4775" end_char="4781">francés</TOKEN>
<TOKEN id="token-59-11" pos="punct" morph="none" start_char="4782" end_char="4782">,</TOKEN>
<TOKEN id="token-59-12" pos="word" morph="none" start_char="4784" end_char="4785">un</TOKEN>
<TOKEN id="token-59-13" pos="word" morph="none" start_char="4787" end_char="4797">significado</TOKEN>
<TOKEN id="token-59-14" pos="word" morph="none" start_char="4799" end_char="4807">diferente</TOKEN>
<TOKEN id="token-59-15" pos="word" morph="none" start_char="4809" end_char="4810">al</TOKEN>
<TOKEN id="token-59-16" pos="word" morph="none" start_char="4812" end_char="4813">de</TOKEN>
</SEG>
<SEG id="segment-60" start_char="4816" end_char="4822">
<ORIGINAL_TEXT>"crear"</ORIGINAL_TEXT>
<TOKEN id="token-60-0" pos="punct" morph="none" start_char="4816" end_char="4816">"</TOKEN>
<TOKEN id="token-60-1" pos="word" morph="none" start_char="4817" end_char="4821">crear</TOKEN>
<TOKEN id="token-60-2" pos="punct" morph="none" start_char="4822" end_char="4822">"</TOKEN>
</SEG>
<SEG id="segment-61" start_char="4825" end_char="4825">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN id="token-61-0" pos="punct" morph="none" start_char="4825" end_char="4825">.</TOKEN>
</SEG>
<SEG id="segment-62" start_char="4827" end_char="4836">
<ORIGINAL_TEXT>La palabra</ORIGINAL_TEXT>
<TOKEN id="token-62-0" pos="word" morph="none" start_char="4827" end_char="4828">La</TOKEN>
<TOKEN id="token-62-1" pos="word" morph="none" start_char="4830" end_char="4836">palabra</TOKEN>
</SEG>
<SEG id="segment-63" start_char="4839" end_char="4848">
<ORIGINAL_TEXT>"inventor"</ORIGINAL_TEXT>
<TOKEN id="token-63-0" pos="punct" morph="none" start_char="4839" end_char="4839">"</TOKEN>
<TOKEN id="token-63-1" pos="word" morph="none" start_char="4840" end_char="4847">inventor</TOKEN>
<TOKEN id="token-63-2" pos="punct" morph="none" start_char="4848" end_char="4848">"</TOKEN>
</SEG>
<SEG id="segment-64" start_char="4851" end_char="4851">
<ORIGINAL_TEXT>o</ORIGINAL_TEXT>
<TOKEN id="token-64-0" pos="word" morph="none" start_char="4851" end_char="4851">o</TOKEN>
</SEG>
<SEG id="segment-65" start_char="4854" end_char="4864">
<ORIGINAL_TEXT>"invención"</ORIGINAL_TEXT>
<TOKEN id="token-65-0" pos="punct" morph="none" start_char="4854" end_char="4854">"</TOKEN>
<TOKEN id="token-65-1" pos="word" morph="none" start_char="4855" end_char="4863">invención</TOKEN>
<TOKEN id="token-65-2" pos="punct" morph="none" start_char="4864" end_char="4864">"</TOKEN>
</SEG>
<SEG id="segment-66" start_char="4867" end_char="4883">
<ORIGINAL_TEXT>puede referirse a</ORIGINAL_TEXT>
<TOKEN id="token-66-0" pos="word" morph="none" start_char="4867" end_char="4871">puede</TOKEN>
<TOKEN id="token-66-1" pos="word" morph="none" start_char="4873" end_char="4881">referirse</TOKEN>
<TOKEN id="token-66-2" pos="word" morph="none" start_char="4883" end_char="4883">a</TOKEN>
</SEG>
<SEG id="segment-67" start_char="4886" end_char="4898">
<ORIGINAL_TEXT>"descubridor"</ORIGINAL_TEXT>
<TOKEN id="token-67-0" pos="punct" morph="none" start_char="4886" end_char="4886">"</TOKEN>
<TOKEN id="token-67-1" pos="word" morph="none" start_char="4887" end_char="4897">descubridor</TOKEN>
<TOKEN id="token-67-2" pos="punct" morph="none" start_char="4898" end_char="4898">"</TOKEN>
</SEG>
<SEG id="segment-68" start_char="4901" end_char="4901">
<ORIGINAL_TEXT>o</ORIGINAL_TEXT>
<TOKEN id="token-68-0" pos="word" morph="none" start_char="4901" end_char="4901">o</TOKEN>
</SEG>
<SEG id="segment-69" start_char="4904" end_char="4929">
<ORIGINAL_TEXT>"descubrimiento, hallazgo"</ORIGINAL_TEXT>
<TOKEN id="token-69-0" pos="punct" morph="none" start_char="4904" end_char="4904">"</TOKEN>
<TOKEN id="token-69-1" pos="word" morph="none" start_char="4905" end_char="4918">descubrimiento</TOKEN>
<TOKEN id="token-69-2" pos="punct" morph="none" start_char="4919" end_char="4919">,</TOKEN>
<TOKEN id="token-69-3" pos="word" morph="none" start_char="4921" end_char="4928">hallazgo</TOKEN>
<TOKEN id="token-69-4" pos="punct" morph="none" start_char="4929" end_char="4929">"</TOKEN>
</SEG>
<SEG id="segment-70" start_char="4932" end_char="4983">
<ORIGINAL_TEXT>(según la cuarta acepción del diccionario Larousse).</ORIGINAL_TEXT>
<TOKEN id="token-70-0" pos="punct" morph="none" start_char="4932" end_char="4932">(</TOKEN>
<TOKEN id="token-70-1" pos="word" morph="none" start_char="4933" end_char="4937">según</TOKEN>
<TOKEN id="token-70-2" pos="word" morph="none" start_char="4939" end_char="4940">la</TOKEN>
<TOKEN id="token-70-3" pos="word" morph="none" start_char="4942" end_char="4947">cuarta</TOKEN>
<TOKEN id="token-70-4" pos="word" morph="none" start_char="4949" end_char="4956">acepción</TOKEN>
<TOKEN id="token-70-5" pos="word" morph="none" start_char="4958" end_char="4960">del</TOKEN>
<TOKEN id="token-70-6" pos="word" morph="none" start_char="4962" end_char="4972">diccionario</TOKEN>
<TOKEN id="token-70-7" pos="word" morph="none" start_char="4974" end_char="4981">Larousse</TOKEN>
<TOKEN id="token-70-8" pos="punct" morph="none" start_char="4982" end_char="4983">).</TOKEN>
</SEG>
<SEG id="segment-71" start_char="4986" end_char="5078">
<ORIGINAL_TEXT>Por otro lado, la presentación de patentes relacionadas con virus son comunes y, a menudo son</ORIGINAL_TEXT>
<TOKEN id="token-71-0" pos="word" morph="none" start_char="4986" end_char="4988">Por</TOKEN>
<TOKEN id="token-71-1" pos="word" morph="none" start_char="4990" end_char="4993">otro</TOKEN>
<TOKEN id="token-71-2" pos="word" morph="none" start_char="4995" end_char="4998">lado</TOKEN>
<TOKEN id="token-71-3" pos="punct" morph="none" start_char="4999" end_char="4999">,</TOKEN>
<TOKEN id="token-71-4" pos="word" morph="none" start_char="5001" end_char="5002">la</TOKEN>
<TOKEN id="token-71-5" pos="word" morph="none" start_char="5004" end_char="5015">presentación</TOKEN>
<TOKEN id="token-71-6" pos="word" morph="none" start_char="5017" end_char="5018">de</TOKEN>
<TOKEN id="token-71-7" pos="word" morph="none" start_char="5020" end_char="5027">patentes</TOKEN>
<TOKEN id="token-71-8" pos="word" morph="none" start_char="5029" end_char="5040">relacionadas</TOKEN>
<TOKEN id="token-71-9" pos="word" morph="none" start_char="5042" end_char="5044">con</TOKEN>
<TOKEN id="token-71-10" pos="word" morph="none" start_char="5046" end_char="5050">virus</TOKEN>
<TOKEN id="token-71-11" pos="word" morph="none" start_char="5052" end_char="5054">son</TOKEN>
<TOKEN id="token-71-12" pos="word" morph="none" start_char="5056" end_char="5062">comunes</TOKEN>
<TOKEN id="token-71-13" pos="word" morph="none" start_char="5064" end_char="5064">y</TOKEN>
<TOKEN id="token-71-14" pos="punct" morph="none" start_char="5065" end_char="5065">,</TOKEN>
<TOKEN id="token-71-15" pos="word" morph="none" start_char="5067" end_char="5067">a</TOKEN>
<TOKEN id="token-71-16" pos="word" morph="none" start_char="5069" end_char="5074">menudo</TOKEN>
<TOKEN id="token-71-17" pos="word" morph="none" start_char="5076" end_char="5078">son</TOKEN>
</SEG>
<SEG id="segment-72" start_char="5081" end_char="5118">
<ORIGINAL_TEXT>"solo declaraciones de descubrimiento"</ORIGINAL_TEXT>
<TOKEN id="token-72-0" pos="punct" morph="none" start_char="5081" end_char="5081">"</TOKEN>
<TOKEN id="token-72-1" pos="word" morph="none" start_char="5082" end_char="5085">solo</TOKEN>
<TOKEN id="token-72-2" pos="word" morph="none" start_char="5087" end_char="5099">declaraciones</TOKEN>
<TOKEN id="token-72-3" pos="word" morph="none" start_char="5101" end_char="5102">de</TOKEN>
<TOKEN id="token-72-4" pos="word" morph="none" start_char="5104" end_char="5117">descubrimiento</TOKEN>
<TOKEN id="token-72-5" pos="punct" morph="none" start_char="5118" end_char="5118">"</TOKEN>
</SEG>
<SEG id="segment-73" start_char="5121" end_char="5285">
<ORIGINAL_TEXT>, explicó a la AFP Vincent Enouf, director adjunto del Centro Nacional de Referencia (CNR) para virus de infecciones de sistemas respiratorios del Instituto Pasteur.</ORIGINAL_TEXT>
<TOKEN id="token-73-0" pos="punct" morph="none" start_char="5121" end_char="5121">,</TOKEN>
<TOKEN id="token-73-1" pos="word" morph="none" start_char="5123" end_char="5129">explicó</TOKEN>
<TOKEN id="token-73-2" pos="word" morph="none" start_char="5131" end_char="5131">a</TOKEN>
<TOKEN id="token-73-3" pos="word" morph="none" start_char="5133" end_char="5134">la</TOKEN>
<TOKEN id="token-73-4" pos="word" morph="none" start_char="5136" end_char="5138">AFP</TOKEN>
<TOKEN id="token-73-5" pos="word" morph="none" start_char="5140" end_char="5146">Vincent</TOKEN>
<TOKEN id="token-73-6" pos="word" morph="none" start_char="5148" end_char="5152">Enouf</TOKEN>
<TOKEN id="token-73-7" pos="punct" morph="none" start_char="5153" end_char="5153">,</TOKEN>
<TOKEN id="token-73-8" pos="word" morph="none" start_char="5155" end_char="5162">director</TOKEN>
<TOKEN id="token-73-9" pos="word" morph="none" start_char="5164" end_char="5170">adjunto</TOKEN>
<TOKEN id="token-73-10" pos="word" morph="none" start_char="5172" end_char="5174">del</TOKEN>
<TOKEN id="token-73-11" pos="word" morph="none" start_char="5176" end_char="5181">Centro</TOKEN>
<TOKEN id="token-73-12" pos="word" morph="none" start_char="5183" end_char="5190">Nacional</TOKEN>
<TOKEN id="token-73-13" pos="word" morph="none" start_char="5192" end_char="5193">de</TOKEN>
<TOKEN id="token-73-14" pos="word" morph="none" start_char="5195" end_char="5204">Referencia</TOKEN>
<TOKEN id="token-73-15" pos="punct" morph="none" start_char="5206" end_char="5206">(</TOKEN>
<TOKEN id="token-73-16" pos="word" morph="none" start_char="5207" end_char="5209">CNR</TOKEN>
<TOKEN id="token-73-17" pos="punct" morph="none" start_char="5210" end_char="5210">)</TOKEN>
<TOKEN id="token-73-18" pos="word" morph="none" start_char="5212" end_char="5215">para</TOKEN>
<TOKEN id="token-73-19" pos="word" morph="none" start_char="5217" end_char="5221">virus</TOKEN>
<TOKEN id="token-73-20" pos="word" morph="none" start_char="5223" end_char="5224">de</TOKEN>
<TOKEN id="token-73-21" pos="word" morph="none" start_char="5226" end_char="5236">infecciones</TOKEN>
<TOKEN id="token-73-22" pos="word" morph="none" start_char="5238" end_char="5239">de</TOKEN>
<TOKEN id="token-73-23" pos="word" morph="none" start_char="5241" end_char="5248">sistemas</TOKEN>
<TOKEN id="token-73-24" pos="word" morph="none" start_char="5250" end_char="5262">respiratorios</TOKEN>
<TOKEN id="token-73-25" pos="word" morph="none" start_char="5264" end_char="5266">del</TOKEN>
<TOKEN id="token-73-26" pos="word" morph="none" start_char="5268" end_char="5276">Instituto</TOKEN>
<TOKEN id="token-73-27" pos="word" morph="none" start_char="5278" end_char="5284">Pasteur</TOKEN>
<TOKEN id="token-73-28" pos="punct" morph="none" start_char="5285" end_char="5285">.</TOKEN>
</SEG>
<SEG id="segment-74" start_char="5288" end_char="5384">
<ORIGINAL_TEXT>"Puede existir una patente sobre una tecnología, sobre un diagnóstico o sobre muchas otras cosas"</ORIGINAL_TEXT>
<TOKEN id="token-74-0" pos="punct" morph="none" start_char="5288" end_char="5288">"</TOKEN>
<TOKEN id="token-74-1" pos="word" morph="none" start_char="5289" end_char="5293">Puede</TOKEN>
<TOKEN id="token-74-2" pos="word" morph="none" start_char="5295" end_char="5301">existir</TOKEN>
<TOKEN id="token-74-3" pos="word" morph="none" start_char="5303" end_char="5305">una</TOKEN>
<TOKEN id="token-74-4" pos="word" morph="none" start_char="5307" end_char="5313">patente</TOKEN>
<TOKEN id="token-74-5" pos="word" morph="none" start_char="5315" end_char="5319">sobre</TOKEN>
<TOKEN id="token-74-6" pos="word" morph="none" start_char="5321" end_char="5323">una</TOKEN>
<TOKEN id="token-74-7" pos="word" morph="none" start_char="5325" end_char="5334">tecnología</TOKEN>
<TOKEN id="token-74-8" pos="punct" morph="none" start_char="5335" end_char="5335">,</TOKEN>
<TOKEN id="token-74-9" pos="word" morph="none" start_char="5337" end_char="5341">sobre</TOKEN>
<TOKEN id="token-74-10" pos="word" morph="none" start_char="5343" end_char="5344">un</TOKEN>
<TOKEN id="token-74-11" pos="word" morph="none" start_char="5346" end_char="5356">diagnóstico</TOKEN>
<TOKEN id="token-74-12" pos="word" morph="none" start_char="5358" end_char="5358">o</TOKEN>
<TOKEN id="token-74-13" pos="word" morph="none" start_char="5360" end_char="5364">sobre</TOKEN>
<TOKEN id="token-74-14" pos="word" morph="none" start_char="5366" end_char="5371">muchas</TOKEN>
<TOKEN id="token-74-15" pos="word" morph="none" start_char="5373" end_char="5377">otras</TOKEN>
<TOKEN id="token-74-16" pos="word" morph="none" start_char="5379" end_char="5383">cosas</TOKEN>
<TOKEN id="token-74-17" pos="punct" morph="none" start_char="5384" end_char="5384">"</TOKEN>
</SEG>
<SEG id="segment-75" start_char="5387" end_char="5434">
<ORIGINAL_TEXT>, continuó, añadiendo que se trata sobre todo de</ORIGINAL_TEXT>
<TOKEN id="token-75-0" pos="punct" morph="none" start_char="5387" end_char="5387">,</TOKEN>
<TOKEN id="token-75-1" pos="word" morph="none" start_char="5389" end_char="5396">continuó</TOKEN>
<TOKEN id="token-75-2" pos="punct" morph="none" start_char="5397" end_char="5397">,</TOKEN>
<TOKEN id="token-75-3" pos="word" morph="none" start_char="5399" end_char="5407">añadiendo</TOKEN>
<TOKEN id="token-75-4" pos="word" morph="none" start_char="5409" end_char="5411">que</TOKEN>
<TOKEN id="token-75-5" pos="word" morph="none" start_char="5413" end_char="5414">se</TOKEN>
<TOKEN id="token-75-6" pos="word" morph="none" start_char="5416" end_char="5420">trata</TOKEN>
<TOKEN id="token-75-7" pos="word" morph="none" start_char="5422" end_char="5426">sobre</TOKEN>
<TOKEN id="token-75-8" pos="word" morph="none" start_char="5428" end_char="5431">todo</TOKEN>
<TOKEN id="token-75-9" pos="word" morph="none" start_char="5433" end_char="5434">de</TOKEN>
</SEG>
<SEG id="segment-76" start_char="5437" end_char="5464">
<ORIGINAL_TEXT>"proteger el descubrimiento"</ORIGINAL_TEXT>
<TOKEN id="token-76-0" pos="punct" morph="none" start_char="5437" end_char="5437">"</TOKEN>
<TOKEN id="token-76-1" pos="word" morph="none" start_char="5438" end_char="5445">proteger</TOKEN>
<TOKEN id="token-76-2" pos="word" morph="none" start_char="5447" end_char="5448">el</TOKEN>
<TOKEN id="token-76-3" pos="word" morph="none" start_char="5450" end_char="5463">descubrimiento</TOKEN>
<TOKEN id="token-76-4" pos="punct" morph="none" start_char="5464" end_char="5464">"</TOKEN>
</SEG>
<SEG id="segment-77" start_char="5467" end_char="5539">
<ORIGINAL_TEXT>hasta que, por ejemplo, se publica un artículo en una revista científica.</ORIGINAL_TEXT>
<TOKEN id="token-77-0" pos="word" morph="none" start_char="5467" end_char="5471">hasta</TOKEN>
<TOKEN id="token-77-1" pos="word" morph="none" start_char="5473" end_char="5475">que</TOKEN>
<TOKEN id="token-77-2" pos="punct" morph="none" start_char="5476" end_char="5476">,</TOKEN>
<TOKEN id="token-77-3" pos="word" morph="none" start_char="5478" end_char="5480">por</TOKEN>
<TOKEN id="token-77-4" pos="word" morph="none" start_char="5482" end_char="5488">ejemplo</TOKEN>
<TOKEN id="token-77-5" pos="punct" morph="none" start_char="5489" end_char="5489">,</TOKEN>
<TOKEN id="token-77-6" pos="word" morph="none" start_char="5491" end_char="5492">se</TOKEN>
<TOKEN id="token-77-7" pos="word" morph="none" start_char="5494" end_char="5500">publica</TOKEN>
<TOKEN id="token-77-8" pos="word" morph="none" start_char="5502" end_char="5503">un</TOKEN>
<TOKEN id="token-77-9" pos="word" morph="none" start_char="5505" end_char="5512">artículo</TOKEN>
<TOKEN id="token-77-10" pos="word" morph="none" start_char="5514" end_char="5515">en</TOKEN>
<TOKEN id="token-77-11" pos="word" morph="none" start_char="5517" end_char="5519">una</TOKEN>
<TOKEN id="token-77-12" pos="word" morph="none" start_char="5521" end_char="5527">revista</TOKEN>
<TOKEN id="token-77-13" pos="word" morph="none" start_char="5529" end_char="5538">científica</TOKEN>
<TOKEN id="token-77-14" pos="punct" morph="none" start_char="5539" end_char="5539">.</TOKEN>
</SEG>
<SEG id="segment-78" start_char="5542" end_char="5586">
<ORIGINAL_TEXT>Cuando uno presenta una solicitud de patente,</ORIGINAL_TEXT>
<TOKEN id="token-78-0" pos="word" morph="none" start_char="5542" end_char="5547">Cuando</TOKEN>
<TOKEN id="token-78-1" pos="word" morph="none" start_char="5549" end_char="5551">uno</TOKEN>
<TOKEN id="token-78-2" pos="word" morph="none" start_char="5553" end_char="5560">presenta</TOKEN>
<TOKEN id="token-78-3" pos="word" morph="none" start_char="5562" end_char="5564">una</TOKEN>
<TOKEN id="token-78-4" pos="word" morph="none" start_char="5566" end_char="5574">solicitud</TOKEN>
<TOKEN id="token-78-5" pos="word" morph="none" start_char="5576" end_char="5577">de</TOKEN>
<TOKEN id="token-78-6" pos="word" morph="none" start_char="5579" end_char="5585">patente</TOKEN>
<TOKEN id="token-78-7" pos="punct" morph="none" start_char="5586" end_char="5586">,</TOKEN>
</SEG>
<SEG id="segment-79" start_char="5589" end_char="5609">
<ORIGINAL_TEXT>"describe su técnica"</ORIGINAL_TEXT>
<TOKEN id="token-79-0" pos="punct" morph="none" start_char="5589" end_char="5589">"</TOKEN>
<TOKEN id="token-79-1" pos="word" morph="none" start_char="5590" end_char="5597">describe</TOKEN>
<TOKEN id="token-79-2" pos="word" morph="none" start_char="5599" end_char="5600">su</TOKEN>
<TOKEN id="token-79-3" pos="word" morph="none" start_char="5602" end_char="5608">técnica</TOKEN>
<TOKEN id="token-79-4" pos="punct" morph="none" start_char="5609" end_char="5609">"</TOKEN>
</SEG>
<SEG id="segment-80" start_char="5612" end_char="5711">
<ORIGINAL_TEXT>, como por ejemplo la elección de un área particular del genoma del virus para realizar las pruebas.</ORIGINAL_TEXT>
<TOKEN id="token-80-0" pos="punct" morph="none" start_char="5612" end_char="5612">,</TOKEN>
<TOKEN id="token-80-1" pos="word" morph="none" start_char="5614" end_char="5617">como</TOKEN>
<TOKEN id="token-80-2" pos="word" morph="none" start_char="5619" end_char="5621">por</TOKEN>
<TOKEN id="token-80-3" pos="word" morph="none" start_char="5623" end_char="5629">ejemplo</TOKEN>
<TOKEN id="token-80-4" pos="word" morph="none" start_char="5631" end_char="5632">la</TOKEN>
<TOKEN id="token-80-5" pos="word" morph="none" start_char="5634" end_char="5641">elección</TOKEN>
<TOKEN id="token-80-6" pos="word" morph="none" start_char="5643" end_char="5644">de</TOKEN>
<TOKEN id="token-80-7" pos="word" morph="none" start_char="5646" end_char="5647">un</TOKEN>
<TOKEN id="token-80-8" pos="word" morph="none" start_char="5649" end_char="5652">área</TOKEN>
<TOKEN id="token-80-9" pos="word" morph="none" start_char="5654" end_char="5663">particular</TOKEN>
<TOKEN id="token-80-10" pos="word" morph="none" start_char="5665" end_char="5667">del</TOKEN>
<TOKEN id="token-80-11" pos="word" morph="none" start_char="5669" end_char="5674">genoma</TOKEN>
<TOKEN id="token-80-12" pos="word" morph="none" start_char="5676" end_char="5678">del</TOKEN>
<TOKEN id="token-80-13" pos="word" morph="none" start_char="5680" end_char="5684">virus</TOKEN>
<TOKEN id="token-80-14" pos="word" morph="none" start_char="5686" end_char="5689">para</TOKEN>
<TOKEN id="token-80-15" pos="word" morph="none" start_char="5691" end_char="5698">realizar</TOKEN>
<TOKEN id="token-80-16" pos="word" morph="none" start_char="5700" end_char="5702">las</TOKEN>
<TOKEN id="token-80-17" pos="word" morph="none" start_char="5704" end_char="5710">pruebas</TOKEN>
<TOKEN id="token-80-18" pos="punct" morph="none" start_char="5711" end_char="5711">.</TOKEN>
</SEG>
<SEG id="segment-81" start_char="5714" end_char="5746">
<ORIGINAL_TEXT>SARS-CoV-2, una evolución natural</ORIGINAL_TEXT>
<TOKEN id="token-81-0" pos="unknown" morph="none" start_char="5714" end_char="5723">SARS-CoV-2</TOKEN>
<TOKEN id="token-81-1" pos="punct" morph="none" start_char="5724" end_char="5724">,</TOKEN>
<TOKEN id="token-81-2" pos="word" morph="none" start_char="5726" end_char="5728">una</TOKEN>
<TOKEN id="token-81-3" pos="word" morph="none" start_char="5730" end_char="5738">evolución</TOKEN>
<TOKEN id="token-81-4" pos="word" morph="none" start_char="5740" end_char="5746">natural</TOKEN>
</SEG>
<SEG id="segment-82" start_char="5750" end_char="6036">
<ORIGINAL_TEXT>En consonancia con las aclaraciones del Instituto Pasteur, un estudio publicado en la revista Nature Medicine y llevado a cabo por científicos del instituto de investigación Scripps de Estados Unidos, concluye que el coronavirus causante del COVID-19 es producto de la evolución natural.</ORIGINAL_TEXT>
<TOKEN id="token-82-0" pos="word" morph="none" start_char="5750" end_char="5751">En</TOKEN>
<TOKEN id="token-82-1" pos="word" morph="none" start_char="5753" end_char="5763">consonancia</TOKEN>
<TOKEN id="token-82-2" pos="word" morph="none" start_char="5765" end_char="5767">con</TOKEN>
<TOKEN id="token-82-3" pos="word" morph="none" start_char="5769" end_char="5771">las</TOKEN>
<TOKEN id="token-82-4" pos="word" morph="none" start_char="5773" end_char="5784">aclaraciones</TOKEN>
<TOKEN id="token-82-5" pos="word" morph="none" start_char="5786" end_char="5788">del</TOKEN>
<TOKEN id="token-82-6" pos="word" morph="none" start_char="5790" end_char="5798">Instituto</TOKEN>
<TOKEN id="token-82-7" pos="word" morph="none" start_char="5800" end_char="5806">Pasteur</TOKEN>
<TOKEN id="token-82-8" pos="punct" morph="none" start_char="5807" end_char="5807">,</TOKEN>
<TOKEN id="token-82-9" pos="word" morph="none" start_char="5809" end_char="5810">un</TOKEN>
<TOKEN id="token-82-10" pos="word" morph="none" start_char="5812" end_char="5818">estudio</TOKEN>
<TOKEN id="token-82-11" pos="word" morph="none" start_char="5820" end_char="5828">publicado</TOKEN>
<TOKEN id="token-82-12" pos="word" morph="none" start_char="5830" end_char="5831">en</TOKEN>
<TOKEN id="token-82-13" pos="word" morph="none" start_char="5833" end_char="5834">la</TOKEN>
<TOKEN id="token-82-14" pos="word" morph="none" start_char="5836" end_char="5842">revista</TOKEN>
<TOKEN id="token-82-15" pos="word" morph="none" start_char="5844" end_char="5849">Nature</TOKEN>
<TOKEN id="token-82-16" pos="word" morph="none" start_char="5851" end_char="5858">Medicine</TOKEN>
<TOKEN id="token-82-17" pos="word" morph="none" start_char="5860" end_char="5860">y</TOKEN>
<TOKEN id="token-82-18" pos="word" morph="none" start_char="5862" end_char="5868">llevado</TOKEN>
<TOKEN id="token-82-19" pos="word" morph="none" start_char="5870" end_char="5870">a</TOKEN>
<TOKEN id="token-82-20" pos="word" morph="none" start_char="5872" end_char="5875">cabo</TOKEN>
<TOKEN id="token-82-21" pos="word" morph="none" start_char="5877" end_char="5879">por</TOKEN>
<TOKEN id="token-82-22" pos="word" morph="none" start_char="5881" end_char="5891">científicos</TOKEN>
<TOKEN id="token-82-23" pos="word" morph="none" start_char="5893" end_char="5895">del</TOKEN>
<TOKEN id="token-82-24" pos="word" morph="none" start_char="5897" end_char="5905">instituto</TOKEN>
<TOKEN id="token-82-25" pos="word" morph="none" start_char="5907" end_char="5908">de</TOKEN>
<TOKEN id="token-82-26" pos="word" morph="none" start_char="5910" end_char="5922">investigación</TOKEN>
<TOKEN id="token-82-27" pos="word" morph="none" start_char="5924" end_char="5930">Scripps</TOKEN>
<TOKEN id="token-82-28" pos="word" morph="none" start_char="5932" end_char="5933">de</TOKEN>
<TOKEN id="token-82-29" pos="word" morph="none" start_char="5935" end_char="5941">Estados</TOKEN>
<TOKEN id="token-82-30" pos="word" morph="none" start_char="5943" end_char="5948">Unidos</TOKEN>
<TOKEN id="token-82-31" pos="punct" morph="none" start_char="5949" end_char="5949">,</TOKEN>
<TOKEN id="token-82-32" pos="word" morph="none" start_char="5951" end_char="5958">concluye</TOKEN>
<TOKEN id="token-82-33" pos="word" morph="none" start_char="5960" end_char="5962">que</TOKEN>
<TOKEN id="token-82-34" pos="word" morph="none" start_char="5964" end_char="5965">el</TOKEN>
<TOKEN id="token-82-35" pos="word" morph="none" start_char="5967" end_char="5977">coronavirus</TOKEN>
<TOKEN id="token-82-36" pos="word" morph="none" start_char="5979" end_char="5986">causante</TOKEN>
<TOKEN id="token-82-37" pos="word" morph="none" start_char="5988" end_char="5990">del</TOKEN>
<TOKEN id="token-82-38" pos="unknown" morph="none" start_char="5992" end_char="5999">COVID-19</TOKEN>
<TOKEN id="token-82-39" pos="word" morph="none" start_char="6001" end_char="6002">es</TOKEN>
<TOKEN id="token-82-40" pos="word" morph="none" start_char="6004" end_char="6011">producto</TOKEN>
<TOKEN id="token-82-41" pos="word" morph="none" start_char="6013" end_char="6014">de</TOKEN>
<TOKEN id="token-82-42" pos="word" morph="none" start_char="6016" end_char="6017">la</TOKEN>
<TOKEN id="token-82-43" pos="word" morph="none" start_char="6019" end_char="6027">evolución</TOKEN>
<TOKEN id="token-82-44" pos="word" morph="none" start_char="6029" end_char="6035">natural</TOKEN>
<TOKEN id="token-82-45" pos="punct" morph="none" start_char="6036" end_char="6036">.</TOKEN>
</SEG>
<SEG id="segment-83" start_char="6039" end_char="6228">
<ORIGINAL_TEXT>"Comparando los datos de secuencia del genoma disponibles para las cepas de coronavirus conocidas, podemos determinar con firmeza que el SARS-CoV-2 se originó a través de procesos naturales"</ORIGINAL_TEXT>
<TOKEN id="token-83-0" pos="punct" morph="none" start_char="6039" end_char="6039">"</TOKEN>
<TOKEN id="token-83-1" pos="word" morph="none" start_char="6040" end_char="6049">Comparando</TOKEN>
<TOKEN id="token-83-2" pos="word" morph="none" start_char="6051" end_char="6053">los</TOKEN>
<TOKEN id="token-83-3" pos="word" morph="none" start_char="6055" end_char="6059">datos</TOKEN>
<TOKEN id="token-83-4" pos="word" morph="none" start_char="6061" end_char="6062">de</TOKEN>
<TOKEN id="token-83-5" pos="word" morph="none" start_char="6064" end_char="6072">secuencia</TOKEN>
<TOKEN id="token-83-6" pos="word" morph="none" start_char="6074" end_char="6076">del</TOKEN>
<TOKEN id="token-83-7" pos="word" morph="none" start_char="6078" end_char="6083">genoma</TOKEN>
<TOKEN id="token-83-8" pos="word" morph="none" start_char="6085" end_char="6095">disponibles</TOKEN>
<TOKEN id="token-83-9" pos="word" morph="none" start_char="6097" end_char="6100">para</TOKEN>
<TOKEN id="token-83-10" pos="word" morph="none" start_char="6102" end_char="6104">las</TOKEN>
<TOKEN id="token-83-11" pos="word" morph="none" start_char="6106" end_char="6110">cepas</TOKEN>
<TOKEN id="token-83-12" pos="word" morph="none" start_char="6112" end_char="6113">de</TOKEN>
<TOKEN id="token-83-13" pos="word" morph="none" start_char="6115" end_char="6125">coronavirus</TOKEN>
<TOKEN id="token-83-14" pos="word" morph="none" start_char="6127" end_char="6135">conocidas</TOKEN>
<TOKEN id="token-83-15" pos="punct" morph="none" start_char="6136" end_char="6136">,</TOKEN>
<TOKEN id="token-83-16" pos="word" morph="none" start_char="6138" end_char="6144">podemos</TOKEN>
<TOKEN id="token-83-17" pos="word" morph="none" start_char="6146" end_char="6155">determinar</TOKEN>
<TOKEN id="token-83-18" pos="word" morph="none" start_char="6157" end_char="6159">con</TOKEN>
<TOKEN id="token-83-19" pos="word" morph="none" start_char="6161" end_char="6167">firmeza</TOKEN>
<TOKEN id="token-83-20" pos="word" morph="none" start_char="6169" end_char="6171">que</TOKEN>
<TOKEN id="token-83-21" pos="word" morph="none" start_char="6173" end_char="6174">el</TOKEN>
<TOKEN id="token-83-22" pos="unknown" morph="none" start_char="6176" end_char="6185">SARS-CoV-2</TOKEN>
<TOKEN id="token-83-23" pos="word" morph="none" start_char="6187" end_char="6188">se</TOKEN>
<TOKEN id="token-83-24" pos="word" morph="none" start_char="6190" end_char="6196">originó</TOKEN>
<TOKEN id="token-83-25" pos="word" morph="none" start_char="6198" end_char="6198">a</TOKEN>
<TOKEN id="token-83-26" pos="word" morph="none" start_char="6200" end_char="6205">través</TOKEN>
<TOKEN id="token-83-27" pos="word" morph="none" start_char="6207" end_char="6208">de</TOKEN>
<TOKEN id="token-83-28" pos="word" morph="none" start_char="6210" end_char="6217">procesos</TOKEN>
<TOKEN id="token-83-29" pos="word" morph="none" start_char="6219" end_char="6227">naturales</TOKEN>
<TOKEN id="token-83-30" pos="punct" morph="none" start_char="6228" end_char="6228">"</TOKEN>
</SEG>
<SEG id="segment-84" start_char="6231" end_char="6290">
<ORIGINAL_TEXT>, aseguró Kristian Andersen, uno de los autores del estudio.</ORIGINAL_TEXT>
<TOKEN id="token-84-0" pos="punct" morph="none" start_char="6231" end_char="6231">,</TOKEN>
<TOKEN id="token-84-1" pos="word" morph="none" start_char="6233" end_char="6239">aseguró</TOKEN>
<TOKEN id="token-84-2" pos="word" morph="none" start_char="6241" end_char="6248">Kristian</TOKEN>
<TOKEN id="token-84-3" pos="word" morph="none" start_char="6250" end_char="6257">Andersen</TOKEN>
<TOKEN id="token-84-4" pos="punct" morph="none" start_char="6258" end_char="6258">,</TOKEN>
<TOKEN id="token-84-5" pos="word" morph="none" start_char="6260" end_char="6262">uno</TOKEN>
<TOKEN id="token-84-6" pos="word" morph="none" start_char="6264" end_char="6265">de</TOKEN>
<TOKEN id="token-84-7" pos="word" morph="none" start_char="6267" end_char="6269">los</TOKEN>
<TOKEN id="token-84-8" pos="word" morph="none" start_char="6271" end_char="6277">autores</TOKEN>
<TOKEN id="token-84-9" pos="word" morph="none" start_char="6279" end_char="6281">del</TOKEN>
<TOKEN id="token-84-10" pos="word" morph="none" start_char="6283" end_char="6289">estudio</TOKEN>
<TOKEN id="token-84-11" pos="punct" morph="none" start_char="6290" end_char="6290">.</TOKEN>
</SEG>
<SEG id="segment-85" start_char="6293" end_char="6482">
<ORIGINAL_TEXT>El estudio subraya también la rapidez con que los científicos chinos extrajeron la codificación genética del nuevo virus y lo pusieron a disposición de la comunidad científica internacional.</ORIGINAL_TEXT>
<TOKEN id="token-85-0" pos="word" morph="none" start_char="6293" end_char="6294">El</TOKEN>
<TOKEN id="token-85-1" pos="word" morph="none" start_char="6296" end_char="6302">estudio</TOKEN>
<TOKEN id="token-85-2" pos="word" morph="none" start_char="6304" end_char="6310">subraya</TOKEN>
<TOKEN id="token-85-3" pos="word" morph="none" start_char="6312" end_char="6318">también</TOKEN>
<TOKEN id="token-85-4" pos="word" morph="none" start_char="6320" end_char="6321">la</TOKEN>
<TOKEN id="token-85-5" pos="word" morph="none" start_char="6323" end_char="6329">rapidez</TOKEN>
<TOKEN id="token-85-6" pos="word" morph="none" start_char="6331" end_char="6333">con</TOKEN>
<TOKEN id="token-85-7" pos="word" morph="none" start_char="6335" end_char="6337">que</TOKEN>
<TOKEN id="token-85-8" pos="word" morph="none" start_char="6339" end_char="6341">los</TOKEN>
<TOKEN id="token-85-9" pos="word" morph="none" start_char="6343" end_char="6353">científicos</TOKEN>
<TOKEN id="token-85-10" pos="word" morph="none" start_char="6355" end_char="6360">chinos</TOKEN>
<TOKEN id="token-85-11" pos="word" morph="none" start_char="6362" end_char="6371">extrajeron</TOKEN>
<TOKEN id="token-85-12" pos="word" morph="none" start_char="6373" end_char="6374">la</TOKEN>
<TOKEN id="token-85-13" pos="word" morph="none" start_char="6376" end_char="6387">codificación</TOKEN>
<TOKEN id="token-85-14" pos="word" morph="none" start_char="6389" end_char="6396">genética</TOKEN>
<TOKEN id="token-85-15" pos="word" morph="none" start_char="6398" end_char="6400">del</TOKEN>
<TOKEN id="token-85-16" pos="word" morph="none" start_char="6402" end_char="6406">nuevo</TOKEN>
<TOKEN id="token-85-17" pos="word" morph="none" start_char="6408" end_char="6412">virus</TOKEN>
<TOKEN id="token-85-18" pos="word" morph="none" start_char="6414" end_char="6414">y</TOKEN>
<TOKEN id="token-85-19" pos="word" morph="none" start_char="6416" end_char="6417">lo</TOKEN>
<TOKEN id="token-85-20" pos="word" morph="none" start_char="6419" end_char="6426">pusieron</TOKEN>
<TOKEN id="token-85-21" pos="word" morph="none" start_char="6428" end_char="6428">a</TOKEN>
<TOKEN id="token-85-22" pos="word" morph="none" start_char="6430" end_char="6440">disposición</TOKEN>
<TOKEN id="token-85-23" pos="word" morph="none" start_char="6442" end_char="6443">de</TOKEN>
<TOKEN id="token-85-24" pos="word" morph="none" start_char="6445" end_char="6446">la</TOKEN>
<TOKEN id="token-85-25" pos="word" morph="none" start_char="6448" end_char="6456">comunidad</TOKEN>
<TOKEN id="token-85-26" pos="word" morph="none" start_char="6458" end_char="6467">científica</TOKEN>
<TOKEN id="token-85-27" pos="word" morph="none" start_char="6469" end_char="6481">internacional</TOKEN>
<TOKEN id="token-85-28" pos="punct" morph="none" start_char="6482" end_char="6482">.</TOKEN>
</SEG>
<SEG id="segment-86" start_char="6485" end_char="6619">
<ORIGINAL_TEXT>Los autores del estudio se centraron en analizar las proteínas del virus que este emplea para entrar en las células humanas y animales.</ORIGINAL_TEXT>
<TOKEN id="token-86-0" pos="word" morph="none" start_char="6485" end_char="6487">Los</TOKEN>
<TOKEN id="token-86-1" pos="word" morph="none" start_char="6489" end_char="6495">autores</TOKEN>
<TOKEN id="token-86-2" pos="word" morph="none" start_char="6497" end_char="6499">del</TOKEN>
<TOKEN id="token-86-3" pos="word" morph="none" start_char="6501" end_char="6507">estudio</TOKEN>
<TOKEN id="token-86-4" pos="word" morph="none" start_char="6509" end_char="6510">se</TOKEN>
<TOKEN id="token-86-5" pos="word" morph="none" start_char="6512" end_char="6520">centraron</TOKEN>
<TOKEN id="token-86-6" pos="word" morph="none" start_char="6522" end_char="6523">en</TOKEN>
<TOKEN id="token-86-7" pos="word" morph="none" start_char="6525" end_char="6532">analizar</TOKEN>
<TOKEN id="token-86-8" pos="word" morph="none" start_char="6534" end_char="6536">las</TOKEN>
<TOKEN id="token-86-9" pos="word" morph="none" start_char="6538" end_char="6546">proteínas</TOKEN>
<TOKEN id="token-86-10" pos="word" morph="none" start_char="6548" end_char="6550">del</TOKEN>
<TOKEN id="token-86-11" pos="word" morph="none" start_char="6552" end_char="6556">virus</TOKEN>
<TOKEN id="token-86-12" pos="word" morph="none" start_char="6558" end_char="6560">que</TOKEN>
<TOKEN id="token-86-13" pos="word" morph="none" start_char="6562" end_char="6565">este</TOKEN>
<TOKEN id="token-86-14" pos="word" morph="none" start_char="6567" end_char="6572">emplea</TOKEN>
<TOKEN id="token-86-15" pos="word" morph="none" start_char="6574" end_char="6577">para</TOKEN>
<TOKEN id="token-86-16" pos="word" morph="none" start_char="6579" end_char="6584">entrar</TOKEN>
<TOKEN id="token-86-17" pos="word" morph="none" start_char="6586" end_char="6587">en</TOKEN>
<TOKEN id="token-86-18" pos="word" morph="none" start_char="6589" end_char="6591">las</TOKEN>
<TOKEN id="token-86-19" pos="word" morph="none" start_char="6593" end_char="6599">células</TOKEN>
<TOKEN id="token-86-20" pos="word" morph="none" start_char="6601" end_char="6607">humanas</TOKEN>
<TOKEN id="token-86-21" pos="word" morph="none" start_char="6609" end_char="6609">y</TOKEN>
<TOKEN id="token-86-22" pos="word" morph="none" start_char="6611" end_char="6618">animales</TOKEN>
<TOKEN id="token-86-23" pos="punct" morph="none" start_char="6619" end_char="6619">.</TOKEN>
</SEG>
<SEG id="segment-87" start_char="6621" end_char="6636">
<ORIGINAL_TEXT>Descubrieron que</ORIGINAL_TEXT>
<TOKEN id="token-87-0" pos="word" morph="none" start_char="6621" end_char="6632">Descubrieron</TOKEN>
<TOKEN id="token-87-1" pos="word" morph="none" start_char="6634" end_char="6636">que</TOKEN>
</SEG>
<SEG id="segment-88" start_char="6639" end_char="6670">
<ORIGINAL_TEXT>"el dominio de unión al receptor</ORIGINAL_TEXT>
<TOKEN id="token-88-0" pos="punct" morph="none" start_char="6639" end_char="6639">"</TOKEN>
<TOKEN id="token-88-1" pos="word" morph="none" start_char="6640" end_char="6641">el</TOKEN>
<TOKEN id="token-88-2" pos="word" morph="none" start_char="6643" end_char="6649">dominio</TOKEN>
<TOKEN id="token-88-3" pos="word" morph="none" start_char="6651" end_char="6652">de</TOKEN>
<TOKEN id="token-88-4" pos="word" morph="none" start_char="6654" end_char="6658">unión</TOKEN>
<TOKEN id="token-88-5" pos="word" morph="none" start_char="6660" end_char="6661">al</TOKEN>
<TOKEN id="token-88-6" pos="word" morph="none" start_char="6663" end_char="6670">receptor</TOKEN>
</SEG>
<SEG id="segment-89" start_char="6673" end_char="6703">
<ORIGINAL_TEXT>(RBD, por sus siglas en inglés)</ORIGINAL_TEXT>
<TOKEN id="token-89-0" pos="punct" morph="none" start_char="6673" end_char="6673">(</TOKEN>
<TOKEN id="token-89-1" pos="word" morph="none" start_char="6674" end_char="6676">RBD</TOKEN>
<TOKEN id="token-89-2" pos="punct" morph="none" start_char="6677" end_char="6677">,</TOKEN>
<TOKEN id="token-89-3" pos="word" morph="none" start_char="6679" end_char="6681">por</TOKEN>
<TOKEN id="token-89-4" pos="word" morph="none" start_char="6683" end_char="6685">sus</TOKEN>
<TOKEN id="token-89-5" pos="word" morph="none" start_char="6687" end_char="6692">siglas</TOKEN>
<TOKEN id="token-89-6" pos="word" morph="none" start_char="6694" end_char="6695">en</TOKEN>
<TOKEN id="token-89-7" pos="word" morph="none" start_char="6697" end_char="6702">inglés</TOKEN>
<TOKEN id="token-89-8" pos="punct" morph="none" start_char="6703" end_char="6703">)</TOKEN>
</SEG>
<SEG id="segment-90" start_char="6706" end_char="6706">
<ORIGINAL_TEXT>"</ORIGINAL_TEXT>
<TOKEN id="token-90-0" pos="punct" morph="none" start_char="6706" end_char="6706">"</TOKEN>
</SEG>
<SEG id="segment-91" start_char="6709" end_char="6835">
<ORIGINAL_TEXT>de una de esas proteínas había evolucionado para atacar eficazmente una característica molecular en el exterior de las células.</ORIGINAL_TEXT>
<TOKEN id="token-91-0" pos="word" morph="none" start_char="6709" end_char="6710">de</TOKEN>
<TOKEN id="token-91-1" pos="word" morph="none" start_char="6712" end_char="6714">una</TOKEN>
<TOKEN id="token-91-2" pos="word" morph="none" start_char="6716" end_char="6717">de</TOKEN>
<TOKEN id="token-91-3" pos="word" morph="none" start_char="6719" end_char="6722">esas</TOKEN>
<TOKEN id="token-91-4" pos="word" morph="none" start_char="6724" end_char="6732">proteínas</TOKEN>
<TOKEN id="token-91-5" pos="word" morph="none" start_char="6734" end_char="6738">había</TOKEN>
<TOKEN id="token-91-6" pos="word" morph="none" start_char="6740" end_char="6751">evolucionado</TOKEN>
<TOKEN id="token-91-7" pos="word" morph="none" start_char="6753" end_char="6756">para</TOKEN>
<TOKEN id="token-91-8" pos="word" morph="none" start_char="6758" end_char="6763">atacar</TOKEN>
<TOKEN id="token-91-9" pos="word" morph="none" start_char="6765" end_char="6775">eficazmente</TOKEN>
<TOKEN id="token-91-10" pos="word" morph="none" start_char="6777" end_char="6779">una</TOKEN>
<TOKEN id="token-91-11" pos="word" morph="none" start_char="6781" end_char="6794">característica</TOKEN>
<TOKEN id="token-91-12" pos="word" morph="none" start_char="6796" end_char="6804">molecular</TOKEN>
<TOKEN id="token-91-13" pos="word" morph="none" start_char="6806" end_char="6807">en</TOKEN>
<TOKEN id="token-91-14" pos="word" morph="none" start_char="6809" end_char="6810">el</TOKEN>
<TOKEN id="token-91-15" pos="word" morph="none" start_char="6812" end_char="6819">exterior</TOKEN>
<TOKEN id="token-91-16" pos="word" morph="none" start_char="6821" end_char="6822">de</TOKEN>
<TOKEN id="token-91-17" pos="word" morph="none" start_char="6824" end_char="6826">las</TOKEN>
<TOKEN id="token-91-18" pos="word" morph="none" start_char="6828" end_char="6834">células</TOKEN>
<TOKEN id="token-91-19" pos="punct" morph="none" start_char="6835" end_char="6835">.</TOKEN>
</SEG>
<SEG id="segment-92" start_char="6839" end_char="6909">
<ORIGINAL_TEXT>Así, esa proteína tenía una enorme capacidad para unir células humanas.</ORIGINAL_TEXT>
<TOKEN id="token-92-0" pos="word" morph="none" start_char="6839" end_char="6841">Así</TOKEN>
<TOKEN id="token-92-1" pos="punct" morph="none" start_char="6842" end_char="6842">,</TOKEN>
<TOKEN id="token-92-2" pos="word" morph="none" start_char="6844" end_char="6846">esa</TOKEN>
<TOKEN id="token-92-3" pos="word" morph="none" start_char="6848" end_char="6855">proteína</TOKEN>
<TOKEN id="token-92-4" pos="word" morph="none" start_char="6857" end_char="6861">tenía</TOKEN>
<TOKEN id="token-92-5" pos="word" morph="none" start_char="6863" end_char="6865">una</TOKEN>
<TOKEN id="token-92-6" pos="word" morph="none" start_char="6867" end_char="6872">enorme</TOKEN>
<TOKEN id="token-92-7" pos="word" morph="none" start_char="6874" end_char="6882">capacidad</TOKEN>
<TOKEN id="token-92-8" pos="word" morph="none" start_char="6884" end_char="6887">para</TOKEN>
<TOKEN id="token-92-9" pos="word" morph="none" start_char="6889" end_char="6892">unir</TOKEN>
<TOKEN id="token-92-10" pos="word" morph="none" start_char="6894" end_char="6900">células</TOKEN>
<TOKEN id="token-92-11" pos="word" morph="none" start_char="6902" end_char="6908">humanas</TOKEN>
<TOKEN id="token-92-12" pos="punct" morph="none" start_char="6909" end_char="6909">.</TOKEN>
</SEG>
<SEG id="segment-93" start_char="6911" end_char="7000">
<ORIGINAL_TEXT>Esto dio indicios a los científicos para concluir que se trataba de una evolución natural.</ORIGINAL_TEXT>
<TOKEN id="token-93-0" pos="word" morph="none" start_char="6911" end_char="6914">Esto</TOKEN>
<TOKEN id="token-93-1" pos="word" morph="none" start_char="6916" end_char="6918">dio</TOKEN>
<TOKEN id="token-93-2" pos="word" morph="none" start_char="6920" end_char="6927">indicios</TOKEN>
<TOKEN id="token-93-3" pos="word" morph="none" start_char="6929" end_char="6929">a</TOKEN>
<TOKEN id="token-93-4" pos="word" morph="none" start_char="6931" end_char="6933">los</TOKEN>
<TOKEN id="token-93-5" pos="word" morph="none" start_char="6935" end_char="6945">científicos</TOKEN>
<TOKEN id="token-93-6" pos="word" morph="none" start_char="6947" end_char="6950">para</TOKEN>
<TOKEN id="token-93-7" pos="word" morph="none" start_char="6952" end_char="6959">concluir</TOKEN>
<TOKEN id="token-93-8" pos="word" morph="none" start_char="6961" end_char="6963">que</TOKEN>
<TOKEN id="token-93-9" pos="word" morph="none" start_char="6965" end_char="6966">se</TOKEN>
<TOKEN id="token-93-10" pos="word" morph="none" start_char="6968" end_char="6974">trataba</TOKEN>
<TOKEN id="token-93-11" pos="word" morph="none" start_char="6976" end_char="6977">de</TOKEN>
<TOKEN id="token-93-12" pos="word" morph="none" start_char="6979" end_char="6981">una</TOKEN>
<TOKEN id="token-93-13" pos="word" morph="none" start_char="6983" end_char="6991">evolución</TOKEN>
<TOKEN id="token-93-14" pos="word" morph="none" start_char="6993" end_char="6999">natural</TOKEN>
<TOKEN id="token-93-15" pos="punct" morph="none" start_char="7000" end_char="7000">.</TOKEN>
</SEG>
<SEG id="segment-94" start_char="7003" end_char="7210">
<ORIGINAL_TEXT>Si el COVID-19 hubiese sido alterado genéticamente en un laboratorio o diseñado como patógeno, los científicos advierten que se habría construido a partir de un virus que causa enfermedades, como el SARS-CoV.</ORIGINAL_TEXT>
<TOKEN id="token-94-0" pos="word" morph="none" start_char="7003" end_char="7004">Si</TOKEN>
<TOKEN id="token-94-1" pos="word" morph="none" start_char="7006" end_char="7007">el</TOKEN>
<TOKEN id="token-94-2" pos="unknown" morph="none" start_char="7009" end_char="7016">COVID-19</TOKEN>
<TOKEN id="token-94-3" pos="word" morph="none" start_char="7018" end_char="7024">hubiese</TOKEN>
<TOKEN id="token-94-4" pos="word" morph="none" start_char="7026" end_char="7029">sido</TOKEN>
<TOKEN id="token-94-5" pos="word" morph="none" start_char="7031" end_char="7038">alterado</TOKEN>
<TOKEN id="token-94-6" pos="word" morph="none" start_char="7040" end_char="7052">genéticamente</TOKEN>
<TOKEN id="token-94-7" pos="word" morph="none" start_char="7054" end_char="7055">en</TOKEN>
<TOKEN id="token-94-8" pos="word" morph="none" start_char="7057" end_char="7058">un</TOKEN>
<TOKEN id="token-94-9" pos="word" morph="none" start_char="7060" end_char="7070">laboratorio</TOKEN>
<TOKEN id="token-94-10" pos="word" morph="none" start_char="7072" end_char="7072">o</TOKEN>
<TOKEN id="token-94-11" pos="word" morph="none" start_char="7074" end_char="7081">diseñado</TOKEN>
<TOKEN id="token-94-12" pos="word" morph="none" start_char="7083" end_char="7086">como</TOKEN>
<TOKEN id="token-94-13" pos="word" morph="none" start_char="7088" end_char="7095">patógeno</TOKEN>
<TOKEN id="token-94-14" pos="punct" morph="none" start_char="7096" end_char="7096">,</TOKEN>
<TOKEN id="token-94-15" pos="word" morph="none" start_char="7098" end_char="7100">los</TOKEN>
<TOKEN id="token-94-16" pos="word" morph="none" start_char="7102" end_char="7112">científicos</TOKEN>
<TOKEN id="token-94-17" pos="word" morph="none" start_char="7114" end_char="7122">advierten</TOKEN>
<TOKEN id="token-94-18" pos="word" morph="none" start_char="7124" end_char="7126">que</TOKEN>
<TOKEN id="token-94-19" pos="word" morph="none" start_char="7128" end_char="7129">se</TOKEN>
<TOKEN id="token-94-20" pos="word" morph="none" start_char="7131" end_char="7136">habría</TOKEN>
<TOKEN id="token-94-21" pos="word" morph="none" start_char="7138" end_char="7147">construido</TOKEN>
<TOKEN id="token-94-22" pos="word" morph="none" start_char="7149" end_char="7149">a</TOKEN>
<TOKEN id="token-94-23" pos="word" morph="none" start_char="7151" end_char="7156">partir</TOKEN>
<TOKEN id="token-94-24" pos="word" morph="none" start_char="7158" end_char="7159">de</TOKEN>
<TOKEN id="token-94-25" pos="word" morph="none" start_char="7161" end_char="7162">un</TOKEN>
<TOKEN id="token-94-26" pos="word" morph="none" start_char="7164" end_char="7168">virus</TOKEN>
<TOKEN id="token-94-27" pos="word" morph="none" start_char="7170" end_char="7172">que</TOKEN>
<TOKEN id="token-94-28" pos="word" morph="none" start_char="7174" end_char="7178">causa</TOKEN>
<TOKEN id="token-94-29" pos="word" morph="none" start_char="7180" end_char="7191">enfermedades</TOKEN>
<TOKEN id="token-94-30" pos="punct" morph="none" start_char="7192" end_char="7192">,</TOKEN>
<TOKEN id="token-94-31" pos="word" morph="none" start_char="7194" end_char="7197">como</TOKEN>
<TOKEN id="token-94-32" pos="word" morph="none" start_char="7199" end_char="7200">el</TOKEN>
<TOKEN id="token-94-33" pos="unknown" morph="none" start_char="7202" end_char="7209">SARS-CoV</TOKEN>
<TOKEN id="token-94-34" pos="punct" morph="none" start_char="7210" end_char="7210">.</TOKEN>
</SEG>
<SEG id="segment-95" start_char="7213" end_char="7488">
<ORIGINAL_TEXT>La estructura básica SARS-CoV-2 difiere, según el estudio, de los coronavirus ya conocidos, y se parece a la que tienen la mayoría de los virus relacionados que se encuentran en murciélagos y pangolines, hecho que también apoya la tesis de que no fue manipulado genéticamente.</ORIGINAL_TEXT>
<TOKEN id="token-95-0" pos="word" morph="none" start_char="7213" end_char="7214">La</TOKEN>
<TOKEN id="token-95-1" pos="word" morph="none" start_char="7216" end_char="7225">estructura</TOKEN>
<TOKEN id="token-95-2" pos="word" morph="none" start_char="7227" end_char="7232">básica</TOKEN>
<TOKEN id="token-95-3" pos="unknown" morph="none" start_char="7234" end_char="7243">SARS-CoV-2</TOKEN>
<TOKEN id="token-95-4" pos="word" morph="none" start_char="7245" end_char="7251">difiere</TOKEN>
<TOKEN id="token-95-5" pos="punct" morph="none" start_char="7252" end_char="7252">,</TOKEN>
<TOKEN id="token-95-6" pos="word" morph="none" start_char="7254" end_char="7258">según</TOKEN>
<TOKEN id="token-95-7" pos="word" morph="none" start_char="7260" end_char="7261">el</TOKEN>
<TOKEN id="token-95-8" pos="word" morph="none" start_char="7263" end_char="7269">estudio</TOKEN>
<TOKEN id="token-95-9" pos="punct" morph="none" start_char="7270" end_char="7270">,</TOKEN>
<TOKEN id="token-95-10" pos="word" morph="none" start_char="7272" end_char="7273">de</TOKEN>
<TOKEN id="token-95-11" pos="word" morph="none" start_char="7275" end_char="7277">los</TOKEN>
<TOKEN id="token-95-12" pos="word" morph="none" start_char="7279" end_char="7289">coronavirus</TOKEN>
<TOKEN id="token-95-13" pos="word" morph="none" start_char="7291" end_char="7292">ya</TOKEN>
<TOKEN id="token-95-14" pos="word" morph="none" start_char="7294" end_char="7302">conocidos</TOKEN>
<TOKEN id="token-95-15" pos="punct" morph="none" start_char="7303" end_char="7303">,</TOKEN>
<TOKEN id="token-95-16" pos="word" morph="none" start_char="7305" end_char="7305">y</TOKEN>
<TOKEN id="token-95-17" pos="word" morph="none" start_char="7307" end_char="7308">se</TOKEN>
<TOKEN id="token-95-18" pos="word" morph="none" start_char="7310" end_char="7315">parece</TOKEN>
<TOKEN id="token-95-19" pos="word" morph="none" start_char="7317" end_char="7317">a</TOKEN>
<TOKEN id="token-95-20" pos="word" morph="none" start_char="7319" end_char="7320">la</TOKEN>
<TOKEN id="token-95-21" pos="word" morph="none" start_char="7322" end_char="7324">que</TOKEN>
<TOKEN id="token-95-22" pos="word" morph="none" start_char="7326" end_char="7331">tienen</TOKEN>
<TOKEN id="token-95-23" pos="word" morph="none" start_char="7333" end_char="7334">la</TOKEN>
<TOKEN id="token-95-24" pos="word" morph="none" start_char="7336" end_char="7342">mayoría</TOKEN>
<TOKEN id="token-95-25" pos="word" morph="none" start_char="7344" end_char="7345">de</TOKEN>
<TOKEN id="token-95-26" pos="word" morph="none" start_char="7347" end_char="7349">los</TOKEN>
<TOKEN id="token-95-27" pos="word" morph="none" start_char="7351" end_char="7355">virus</TOKEN>
<TOKEN id="token-95-28" pos="word" morph="none" start_char="7357" end_char="7368">relacionados</TOKEN>
<TOKEN id="token-95-29" pos="word" morph="none" start_char="7370" end_char="7372">que</TOKEN>
<TOKEN id="token-95-30" pos="word" morph="none" start_char="7374" end_char="7375">se</TOKEN>
<TOKEN id="token-95-31" pos="word" morph="none" start_char="7377" end_char="7386">encuentran</TOKEN>
<TOKEN id="token-95-32" pos="word" morph="none" start_char="7388" end_char="7389">en</TOKEN>
<TOKEN id="token-95-33" pos="word" morph="none" start_char="7391" end_char="7401">murciélagos</TOKEN>
<TOKEN id="token-95-34" pos="word" morph="none" start_char="7403" end_char="7403">y</TOKEN>
<TOKEN id="token-95-35" pos="word" morph="none" start_char="7405" end_char="7414">pangolines</TOKEN>
<TOKEN id="token-95-36" pos="punct" morph="none" start_char="7415" end_char="7415">,</TOKEN>
<TOKEN id="token-95-37" pos="word" morph="none" start_char="7417" end_char="7421">hecho</TOKEN>
<TOKEN id="token-95-38" pos="word" morph="none" start_char="7423" end_char="7425">que</TOKEN>
<TOKEN id="token-95-39" pos="word" morph="none" start_char="7427" end_char="7433">también</TOKEN>
<TOKEN id="token-95-40" pos="word" morph="none" start_char="7435" end_char="7439">apoya</TOKEN>
<TOKEN id="token-95-41" pos="word" morph="none" start_char="7441" end_char="7442">la</TOKEN>
<TOKEN id="token-95-42" pos="word" morph="none" start_char="7444" end_char="7448">tesis</TOKEN>
<TOKEN id="token-95-43" pos="word" morph="none" start_char="7450" end_char="7451">de</TOKEN>
<TOKEN id="token-95-44" pos="word" morph="none" start_char="7453" end_char="7455">que</TOKEN>
<TOKEN id="token-95-45" pos="word" morph="none" start_char="7457" end_char="7458">no</TOKEN>
<TOKEN id="token-95-46" pos="word" morph="none" start_char="7460" end_char="7462">fue</TOKEN>
<TOKEN id="token-95-47" pos="word" morph="none" start_char="7464" end_char="7473">manipulado</TOKEN>
<TOKEN id="token-95-48" pos="word" morph="none" start_char="7475" end_char="7487">genéticamente</TOKEN>
<TOKEN id="token-95-49" pos="punct" morph="none" start_char="7488" end_char="7488">.</TOKEN>
</SEG>
<SEG id="segment-96" start_char="7491" end_char="7517">
<ORIGINAL_TEXT>¿Por qué se patentan virus?</ORIGINAL_TEXT>
<TOKEN id="token-96-0" pos="punct" morph="none" start_char="7491" end_char="7491">¿</TOKEN>
<TOKEN id="token-96-1" pos="word" morph="none" start_char="7492" end_char="7494">Por</TOKEN>
<TOKEN id="token-96-2" pos="word" morph="none" start_char="7496" end_char="7498">qué</TOKEN>
<TOKEN id="token-96-3" pos="word" morph="none" start_char="7500" end_char="7501">se</TOKEN>
<TOKEN id="token-96-4" pos="word" morph="none" start_char="7503" end_char="7510">patentan</TOKEN>
<TOKEN id="token-96-5" pos="word" morph="none" start_char="7512" end_char="7516">virus</TOKEN>
<TOKEN id="token-96-6" pos="punct" morph="none" start_char="7517" end_char="7517">?</TOKEN>
</SEG>
<SEG id="segment-97" start_char="7520" end_char="7635">
<ORIGINAL_TEXT>"El interés de patentar es proteger esta secuencia para poder desarrollar pruebas de diagnóstico y posibles vacunas"</ORIGINAL_TEXT>
<TOKEN id="token-97-0" pos="punct" morph="none" start_char="7520" end_char="7520">"</TOKEN>
<TOKEN id="token-97-1" pos="word" morph="none" start_char="7521" end_char="7522">El</TOKEN>
<TOKEN id="token-97-2" pos="word" morph="none" start_char="7524" end_char="7530">interés</TOKEN>
<TOKEN id="token-97-3" pos="word" morph="none" start_char="7532" end_char="7533">de</TOKEN>
<TOKEN id="token-97-4" pos="word" morph="none" start_char="7535" end_char="7542">patentar</TOKEN>
<TOKEN id="token-97-5" pos="word" morph="none" start_char="7544" end_char="7545">es</TOKEN>
<TOKEN id="token-97-6" pos="word" morph="none" start_char="7547" end_char="7554">proteger</TOKEN>
<TOKEN id="token-97-7" pos="word" morph="none" start_char="7556" end_char="7559">esta</TOKEN>
<TOKEN id="token-97-8" pos="word" morph="none" start_char="7561" end_char="7569">secuencia</TOKEN>
<TOKEN id="token-97-9" pos="word" morph="none" start_char="7571" end_char="7574">para</TOKEN>
<TOKEN id="token-97-10" pos="word" morph="none" start_char="7576" end_char="7580">poder</TOKEN>
<TOKEN id="token-97-11" pos="word" morph="none" start_char="7582" end_char="7592">desarrollar</TOKEN>
<TOKEN id="token-97-12" pos="word" morph="none" start_char="7594" end_char="7600">pruebas</TOKEN>
<TOKEN id="token-97-13" pos="word" morph="none" start_char="7602" end_char="7603">de</TOKEN>
<TOKEN id="token-97-14" pos="word" morph="none" start_char="7605" end_char="7615">diagnóstico</TOKEN>
<TOKEN id="token-97-15" pos="word" morph="none" start_char="7617" end_char="7617">y</TOKEN>
<TOKEN id="token-97-16" pos="word" morph="none" start_char="7619" end_char="7626">posibles</TOKEN>
<TOKEN id="token-97-17" pos="word" morph="none" start_char="7628" end_char="7634">vacunas</TOKEN>
<TOKEN id="token-97-18" pos="punct" morph="none" start_char="7635" end_char="7635">"</TOKEN>
</SEG>
<SEG id="segment-98" start_char="7638" end_char="7673">
<ORIGINAL_TEXT>, explicó Olivier Schwartz a la AFP.</ORIGINAL_TEXT>
<TOKEN id="token-98-0" pos="punct" morph="none" start_char="7638" end_char="7638">,</TOKEN>
<TOKEN id="token-98-1" pos="word" morph="none" start_char="7640" end_char="7646">explicó</TOKEN>
<TOKEN id="token-98-2" pos="word" morph="none" start_char="7648" end_char="7654">Olivier</TOKEN>
<TOKEN id="token-98-3" pos="word" morph="none" start_char="7656" end_char="7663">Schwartz</TOKEN>
<TOKEN id="token-98-4" pos="word" morph="none" start_char="7665" end_char="7665">a</TOKEN>
<TOKEN id="token-98-5" pos="word" morph="none" start_char="7667" end_char="7668">la</TOKEN>
<TOKEN id="token-98-6" pos="word" morph="none" start_char="7670" end_char="7672">AFP</TOKEN>
<TOKEN id="token-98-7" pos="punct" morph="none" start_char="7673" end_char="7673">.</TOKEN>
</SEG>
<SEG id="segment-99" start_char="7676" end_char="7813">
<ORIGINAL_TEXT>El papel del Instituto Pasteur, fundado en 1888, es precisamente trabajar en los virus emergentes para desarrollar tratamientos y vacunas.</ORIGINAL_TEXT>
<TOKEN id="token-99-0" pos="word" morph="none" start_char="7676" end_char="7677">El</TOKEN>
<TOKEN id="token-99-1" pos="word" morph="none" start_char="7679" end_char="7683">papel</TOKEN>
<TOKEN id="token-99-2" pos="word" morph="none" start_char="7685" end_char="7687">del</TOKEN>
<TOKEN id="token-99-3" pos="word" morph="none" start_char="7689" end_char="7697">Instituto</TOKEN>
<TOKEN id="token-99-4" pos="word" morph="none" start_char="7699" end_char="7705">Pasteur</TOKEN>
<TOKEN id="token-99-5" pos="punct" morph="none" start_char="7706" end_char="7706">,</TOKEN>
<TOKEN id="token-99-6" pos="word" morph="none" start_char="7708" end_char="7714">fundado</TOKEN>
<TOKEN id="token-99-7" pos="word" morph="none" start_char="7716" end_char="7717">en</TOKEN>
<TOKEN id="token-99-8" pos="word" morph="none" start_char="7719" end_char="7722">1888</TOKEN>
<TOKEN id="token-99-9" pos="punct" morph="none" start_char="7723" end_char="7723">,</TOKEN>
<TOKEN id="token-99-10" pos="word" morph="none" start_char="7725" end_char="7726">es</TOKEN>
<TOKEN id="token-99-11" pos="word" morph="none" start_char="7728" end_char="7739">precisamente</TOKEN>
<TOKEN id="token-99-12" pos="word" morph="none" start_char="7741" end_char="7748">trabajar</TOKEN>
<TOKEN id="token-99-13" pos="word" morph="none" start_char="7750" end_char="7751">en</TOKEN>
<TOKEN id="token-99-14" pos="word" morph="none" start_char="7753" end_char="7755">los</TOKEN>
<TOKEN id="token-99-15" pos="word" morph="none" start_char="7757" end_char="7761">virus</TOKEN>
<TOKEN id="token-99-16" pos="word" morph="none" start_char="7763" end_char="7772">emergentes</TOKEN>
<TOKEN id="token-99-17" pos="word" morph="none" start_char="7774" end_char="7777">para</TOKEN>
<TOKEN id="token-99-18" pos="word" morph="none" start_char="7779" end_char="7789">desarrollar</TOKEN>
<TOKEN id="token-99-19" pos="word" morph="none" start_char="7791" end_char="7802">tratamientos</TOKEN>
<TOKEN id="token-99-20" pos="word" morph="none" start_char="7804" end_char="7804">y</TOKEN>
<TOKEN id="token-99-21" pos="word" morph="none" start_char="7806" end_char="7812">vacunas</TOKEN>
<TOKEN id="token-99-22" pos="punct" morph="none" start_char="7813" end_char="7813">.</TOKEN>
</SEG>
<SEG id="segment-100" start_char="7816" end_char="7859">
<ORIGINAL_TEXT>En el caso del documento presentado en 2004,</ORIGINAL_TEXT>
<TOKEN id="token-100-0" pos="word" morph="none" start_char="7816" end_char="7817">En</TOKEN>
<TOKEN id="token-100-1" pos="word" morph="none" start_char="7819" end_char="7820">el</TOKEN>
<TOKEN id="token-100-2" pos="word" morph="none" start_char="7822" end_char="7825">caso</TOKEN>
<TOKEN id="token-100-3" pos="word" morph="none" start_char="7827" end_char="7829">del</TOKEN>
<TOKEN id="token-100-4" pos="word" morph="none" start_char="7831" end_char="7839">documento</TOKEN>
<TOKEN id="token-100-5" pos="word" morph="none" start_char="7841" end_char="7850">presentado</TOKEN>
<TOKEN id="token-100-6" pos="word" morph="none" start_char="7852" end_char="7853">en</TOKEN>
<TOKEN id="token-100-7" pos="word" morph="none" start_char="7855" end_char="7858">2004</TOKEN>
<TOKEN id="token-100-8" pos="punct" morph="none" start_char="7859" end_char="7859">,</TOKEN>
</SEG>
<SEG id="segment-101" start_char="7862" end_char="7988">
<ORIGINAL_TEXT>"patentamos o protegimos la secuencia, el código genético, de un virus aislado en Vietnam en el momento de la epidemia de SRAS"</ORIGINAL_TEXT>
<TOKEN id="token-101-0" pos="punct" morph="none" start_char="7862" end_char="7862">"</TOKEN>
<TOKEN id="token-101-1" pos="word" morph="none" start_char="7863" end_char="7872">patentamos</TOKEN>
<TOKEN id="token-101-2" pos="word" morph="none" start_char="7874" end_char="7874">o</TOKEN>
<TOKEN id="token-101-3" pos="word" morph="none" start_char="7876" end_char="7885">protegimos</TOKEN>
<TOKEN id="token-101-4" pos="word" morph="none" start_char="7887" end_char="7888">la</TOKEN>
<TOKEN id="token-101-5" pos="word" morph="none" start_char="7890" end_char="7898">secuencia</TOKEN>
<TOKEN id="token-101-6" pos="punct" morph="none" start_char="7899" end_char="7899">,</TOKEN>
<TOKEN id="token-101-7" pos="word" morph="none" start_char="7901" end_char="7902">el</TOKEN>
<TOKEN id="token-101-8" pos="word" morph="none" start_char="7904" end_char="7909">código</TOKEN>
<TOKEN id="token-101-9" pos="word" morph="none" start_char="7911" end_char="7918">genético</TOKEN>
<TOKEN id="token-101-10" pos="punct" morph="none" start_char="7919" end_char="7919">,</TOKEN>
<TOKEN id="token-101-11" pos="word" morph="none" start_char="7921" end_char="7922">de</TOKEN>
<TOKEN id="token-101-12" pos="word" morph="none" start_char="7924" end_char="7925">un</TOKEN>
<TOKEN id="token-101-13" pos="word" morph="none" start_char="7927" end_char="7931">virus</TOKEN>
<TOKEN id="token-101-14" pos="word" morph="none" start_char="7933" end_char="7939">aislado</TOKEN>
<TOKEN id="token-101-15" pos="word" morph="none" start_char="7941" end_char="7942">en</TOKEN>
<TOKEN id="token-101-16" pos="word" morph="none" start_char="7944" end_char="7950">Vietnam</TOKEN>
<TOKEN id="token-101-17" pos="word" morph="none" start_char="7952" end_char="7953">en</TOKEN>
<TOKEN id="token-101-18" pos="word" morph="none" start_char="7955" end_char="7956">el</TOKEN>
<TOKEN id="token-101-19" pos="word" morph="none" start_char="7958" end_char="7964">momento</TOKEN>
<TOKEN id="token-101-20" pos="word" morph="none" start_char="7966" end_char="7967">de</TOKEN>
<TOKEN id="token-101-21" pos="word" morph="none" start_char="7969" end_char="7970">la</TOKEN>
<TOKEN id="token-101-22" pos="word" morph="none" start_char="7972" end_char="7979">epidemia</TOKEN>
<TOKEN id="token-101-23" pos="word" morph="none" start_char="7981" end_char="7982">de</TOKEN>
<TOKEN id="token-101-24" pos="word" morph="none" start_char="7984" end_char="7987">SRAS</TOKEN>
<TOKEN id="token-101-25" pos="punct" morph="none" start_char="7988" end_char="7988">"</TOKEN>
</SEG>
<SEG id="segment-102" start_char="7991" end_char="8008">
<ORIGINAL_TEXT>, añadió Schwartz.</ORIGINAL_TEXT>
<TOKEN id="token-102-0" pos="punct" morph="none" start_char="7991" end_char="7991">,</TOKEN>
<TOKEN id="token-102-1" pos="word" morph="none" start_char="7993" end_char="7998">añadió</TOKEN>
<TOKEN id="token-102-2" pos="word" morph="none" start_char="8000" end_char="8007">Schwartz</TOKEN>
<TOKEN id="token-102-3" pos="punct" morph="none" start_char="8008" end_char="8008">.</TOKEN>
</SEG>
<SEG id="segment-103" start_char="8011" end_char="8338">
<ORIGINAL_TEXT>"En ese momento, los equipos del Instituto Pasteur se movilizaron, proponiendo numerosas estrategias de vacunas, incluida una posible vacuna basada en la del sarampión (la vacuna contra el sarampión puede recombinarse y utilizarse como vehículo para inducir una respuesta inmune contra otros agentes patógenos como el SARS-CoV)"</ORIGINAL_TEXT>
<TOKEN id="token-103-0" pos="punct" morph="none" start_char="8011" end_char="8011">"</TOKEN>
<TOKEN id="token-103-1" pos="word" morph="none" start_char="8012" end_char="8013">En</TOKEN>
<TOKEN id="token-103-2" pos="word" morph="none" start_char="8015" end_char="8017">ese</TOKEN>
<TOKEN id="token-103-3" pos="word" morph="none" start_char="8019" end_char="8025">momento</TOKEN>
<TOKEN id="token-103-4" pos="punct" morph="none" start_char="8026" end_char="8026">,</TOKEN>
<TOKEN id="token-103-5" pos="word" morph="none" start_char="8028" end_char="8030">los</TOKEN>
<TOKEN id="token-103-6" pos="word" morph="none" start_char="8032" end_char="8038">equipos</TOKEN>
<TOKEN id="token-103-7" pos="word" morph="none" start_char="8040" end_char="8042">del</TOKEN>
<TOKEN id="token-103-8" pos="word" morph="none" start_char="8044" end_char="8052">Instituto</TOKEN>
<TOKEN id="token-103-9" pos="word" morph="none" start_char="8054" end_char="8060">Pasteur</TOKEN>
<TOKEN id="token-103-10" pos="word" morph="none" start_char="8062" end_char="8063">se</TOKEN>
<TOKEN id="token-103-11" pos="word" morph="none" start_char="8065" end_char="8075">movilizaron</TOKEN>
<TOKEN id="token-103-12" pos="punct" morph="none" start_char="8076" end_char="8076">,</TOKEN>
<TOKEN id="token-103-13" pos="word" morph="none" start_char="8078" end_char="8088">proponiendo</TOKEN>
<TOKEN id="token-103-14" pos="word" morph="none" start_char="8090" end_char="8098">numerosas</TOKEN>
<TOKEN id="token-103-15" pos="word" morph="none" start_char="8100" end_char="8110">estrategias</TOKEN>
<TOKEN id="token-103-16" pos="word" morph="none" start_char="8112" end_char="8113">de</TOKEN>
<TOKEN id="token-103-17" pos="word" morph="none" start_char="8115" end_char="8121">vacunas</TOKEN>
<TOKEN id="token-103-18" pos="punct" morph="none" start_char="8122" end_char="8122">,</TOKEN>
<TOKEN id="token-103-19" pos="word" morph="none" start_char="8124" end_char="8131">incluida</TOKEN>
<TOKEN id="token-103-20" pos="word" morph="none" start_char="8133" end_char="8135">una</TOKEN>
<TOKEN id="token-103-21" pos="word" morph="none" start_char="8137" end_char="8143">posible</TOKEN>
<TOKEN id="token-103-22" pos="word" morph="none" start_char="8145" end_char="8150">vacuna</TOKEN>
<TOKEN id="token-103-23" pos="word" morph="none" start_char="8152" end_char="8157">basada</TOKEN>
<TOKEN id="token-103-24" pos="word" morph="none" start_char="8159" end_char="8160">en</TOKEN>
<TOKEN id="token-103-25" pos="word" morph="none" start_char="8162" end_char="8163">la</TOKEN>
<TOKEN id="token-103-26" pos="word" morph="none" start_char="8165" end_char="8167">del</TOKEN>
<TOKEN id="token-103-27" pos="word" morph="none" start_char="8169" end_char="8177">sarampión</TOKEN>
<TOKEN id="token-103-28" pos="punct" morph="none" start_char="8179" end_char="8179">(</TOKEN>
<TOKEN id="token-103-29" pos="word" morph="none" start_char="8180" end_char="8181">la</TOKEN>
<TOKEN id="token-103-30" pos="word" morph="none" start_char="8183" end_char="8188">vacuna</TOKEN>
<TOKEN id="token-103-31" pos="word" morph="none" start_char="8190" end_char="8195">contra</TOKEN>
<TOKEN id="token-103-32" pos="word" morph="none" start_char="8197" end_char="8198">el</TOKEN>
<TOKEN id="token-103-33" pos="word" morph="none" start_char="8200" end_char="8208">sarampión</TOKEN>
<TOKEN id="token-103-34" pos="word" morph="none" start_char="8210" end_char="8214">puede</TOKEN>
<TOKEN id="token-103-35" pos="word" morph="none" start_char="8216" end_char="8227">recombinarse</TOKEN>
<TOKEN id="token-103-36" pos="word" morph="none" start_char="8229" end_char="8229">y</TOKEN>
<TOKEN id="token-103-37" pos="word" morph="none" start_char="8231" end_char="8240">utilizarse</TOKEN>
<TOKEN id="token-103-38" pos="word" morph="none" start_char="8242" end_char="8245">como</TOKEN>
<TOKEN id="token-103-39" pos="word" morph="none" start_char="8247" end_char="8254">vehículo</TOKEN>
<TOKEN id="token-103-40" pos="word" morph="none" start_char="8256" end_char="8259">para</TOKEN>
<TOKEN id="token-103-41" pos="word" morph="none" start_char="8261" end_char="8267">inducir</TOKEN>
<TOKEN id="token-103-42" pos="word" morph="none" start_char="8269" end_char="8271">una</TOKEN>
<TOKEN id="token-103-43" pos="word" morph="none" start_char="8273" end_char="8281">respuesta</TOKEN>
<TOKEN id="token-103-44" pos="word" morph="none" start_char="8283" end_char="8288">inmune</TOKEN>
<TOKEN id="token-103-45" pos="word" morph="none" start_char="8290" end_char="8295">contra</TOKEN>
<TOKEN id="token-103-46" pos="word" morph="none" start_char="8297" end_char="8301">otros</TOKEN>
<TOKEN id="token-103-47" pos="word" morph="none" start_char="8303" end_char="8309">agentes</TOKEN>
<TOKEN id="token-103-48" pos="word" morph="none" start_char="8311" end_char="8319">patógenos</TOKEN>
<TOKEN id="token-103-49" pos="word" morph="none" start_char="8321" end_char="8324">como</TOKEN>
<TOKEN id="token-103-50" pos="word" morph="none" start_char="8326" end_char="8327">el</TOKEN>
<TOKEN id="token-103-51" pos="unknown" morph="none" start_char="8329" end_char="8336">SARS-CoV</TOKEN>
<TOKEN id="token-103-52" pos="punct" morph="none" start_char="8337" end_char="8338">)"</TOKEN>
</SEG>
<SEG id="segment-104" start_char="8341" end_char="8450">
<ORIGINAL_TEXT>, explicó el Instituto Pasteur en un comunicado que desmiente la desinformación que ha circulado en las redes.</ORIGINAL_TEXT>
<TOKEN id="token-104-0" pos="punct" morph="none" start_char="8341" end_char="8341">,</TOKEN>
<TOKEN id="token-104-1" pos="word" morph="none" start_char="8343" end_char="8349">explicó</TOKEN>
<TOKEN id="token-104-2" pos="word" morph="none" start_char="8351" end_char="8352">el</TOKEN>
<TOKEN id="token-104-3" pos="word" morph="none" start_char="8354" end_char="8362">Instituto</TOKEN>
<TOKEN id="token-104-4" pos="word" morph="none" start_char="8364" end_char="8370">Pasteur</TOKEN>
<TOKEN id="token-104-5" pos="word" morph="none" start_char="8372" end_char="8373">en</TOKEN>
<TOKEN id="token-104-6" pos="word" morph="none" start_char="8375" end_char="8376">un</TOKEN>
<TOKEN id="token-104-7" pos="word" morph="none" start_char="8378" end_char="8387">comunicado</TOKEN>
<TOKEN id="token-104-8" pos="word" morph="none" start_char="8389" end_char="8391">que</TOKEN>
<TOKEN id="token-104-9" pos="word" morph="none" start_char="8393" end_char="8401">desmiente</TOKEN>
<TOKEN id="token-104-10" pos="word" morph="none" start_char="8403" end_char="8404">la</TOKEN>
<TOKEN id="token-104-11" pos="word" morph="none" start_char="8406" end_char="8419">desinformación</TOKEN>
<TOKEN id="token-104-12" pos="word" morph="none" start_char="8421" end_char="8423">que</TOKEN>
<TOKEN id="token-104-13" pos="word" morph="none" start_char="8425" end_char="8426">ha</TOKEN>
<TOKEN id="token-104-14" pos="word" morph="none" start_char="8428" end_char="8436">circulado</TOKEN>
<TOKEN id="token-104-15" pos="word" morph="none" start_char="8438" end_char="8439">en</TOKEN>
<TOKEN id="token-104-16" pos="word" morph="none" start_char="8441" end_char="8443">las</TOKEN>
<TOKEN id="token-104-17" pos="word" morph="none" start_char="8445" end_char="8449">redes</TOKEN>
<TOKEN id="token-104-18" pos="punct" morph="none" start_char="8450" end_char="8450">.</TOKEN>
</SEG>
<SEG id="segment-105" start_char="8453" end_char="8703">
<ORIGINAL_TEXT>"El conocimiento adquirido en 2003 contra el SARS-CoV, y la posible vacuna patentada en 2004, son actualmente aplicados por los científicos que trabajan en un proyecto de vacuna potencial contra el SARS-CoV-2, usando como base la vacuna del sarampión"</ORIGINAL_TEXT>
<TOKEN id="token-105-0" pos="punct" morph="none" start_char="8453" end_char="8453">"</TOKEN>
<TOKEN id="token-105-1" pos="word" morph="none" start_char="8454" end_char="8455">El</TOKEN>
<TOKEN id="token-105-2" pos="word" morph="none" start_char="8457" end_char="8468">conocimiento</TOKEN>
<TOKEN id="token-105-3" pos="word" morph="none" start_char="8470" end_char="8478">adquirido</TOKEN>
<TOKEN id="token-105-4" pos="word" morph="none" start_char="8480" end_char="8481">en</TOKEN>
<TOKEN id="token-105-5" pos="word" morph="none" start_char="8483" end_char="8486">2003</TOKEN>
<TOKEN id="token-105-6" pos="word" morph="none" start_char="8488" end_char="8493">contra</TOKEN>
<TOKEN id="token-105-7" pos="word" morph="none" start_char="8495" end_char="8496">el</TOKEN>
<TOKEN id="token-105-8" pos="unknown" morph="none" start_char="8498" end_char="8505">SARS-CoV</TOKEN>
<TOKEN id="token-105-9" pos="punct" morph="none" start_char="8506" end_char="8506">,</TOKEN>
<TOKEN id="token-105-10" pos="word" morph="none" start_char="8508" end_char="8508">y</TOKEN>
<TOKEN id="token-105-11" pos="word" morph="none" start_char="8510" end_char="8511">la</TOKEN>
<TOKEN id="token-105-12" pos="word" morph="none" start_char="8513" end_char="8519">posible</TOKEN>
<TOKEN id="token-105-13" pos="word" morph="none" start_char="8521" end_char="8526">vacuna</TOKEN>
<TOKEN id="token-105-14" pos="word" morph="none" start_char="8528" end_char="8536">patentada</TOKEN>
<TOKEN id="token-105-15" pos="word" morph="none" start_char="8538" end_char="8539">en</TOKEN>
<TOKEN id="token-105-16" pos="word" morph="none" start_char="8541" end_char="8544">2004</TOKEN>
<TOKEN id="token-105-17" pos="punct" morph="none" start_char="8545" end_char="8545">,</TOKEN>
<TOKEN id="token-105-18" pos="word" morph="none" start_char="8547" end_char="8549">son</TOKEN>
<TOKEN id="token-105-19" pos="word" morph="none" start_char="8551" end_char="8561">actualmente</TOKEN>
<TOKEN id="token-105-20" pos="word" morph="none" start_char="8563" end_char="8571">aplicados</TOKEN>
<TOKEN id="token-105-21" pos="word" morph="none" start_char="8573" end_char="8575">por</TOKEN>
<TOKEN id="token-105-22" pos="word" morph="none" start_char="8577" end_char="8579">los</TOKEN>
<TOKEN id="token-105-23" pos="word" morph="none" start_char="8581" end_char="8591">científicos</TOKEN>
<TOKEN id="token-105-24" pos="word" morph="none" start_char="8593" end_char="8595">que</TOKEN>
<TOKEN id="token-105-25" pos="word" morph="none" start_char="8597" end_char="8604">trabajan</TOKEN>
<TOKEN id="token-105-26" pos="word" morph="none" start_char="8606" end_char="8607">en</TOKEN>
<TOKEN id="token-105-27" pos="word" morph="none" start_char="8609" end_char="8610">un</TOKEN>
<TOKEN id="token-105-28" pos="word" morph="none" start_char="8612" end_char="8619">proyecto</TOKEN>
<TOKEN id="token-105-29" pos="word" morph="none" start_char="8621" end_char="8622">de</TOKEN>
<TOKEN id="token-105-30" pos="word" morph="none" start_char="8624" end_char="8629">vacuna</TOKEN>
<TOKEN id="token-105-31" pos="word" morph="none" start_char="8631" end_char="8639">potencial</TOKEN>
<TOKEN id="token-105-32" pos="word" morph="none" start_char="8641" end_char="8646">contra</TOKEN>
<TOKEN id="token-105-33" pos="word" morph="none" start_char="8648" end_char="8649">el</TOKEN>
<TOKEN id="token-105-34" pos="unknown" morph="none" start_char="8651" end_char="8660">SARS-CoV-2</TOKEN>
<TOKEN id="token-105-35" pos="punct" morph="none" start_char="8661" end_char="8661">,</TOKEN>
<TOKEN id="token-105-36" pos="word" morph="none" start_char="8663" end_char="8668">usando</TOKEN>
<TOKEN id="token-105-37" pos="word" morph="none" start_char="8670" end_char="8673">como</TOKEN>
<TOKEN id="token-105-38" pos="word" morph="none" start_char="8675" end_char="8678">base</TOKEN>
<TOKEN id="token-105-39" pos="word" morph="none" start_char="8680" end_char="8681">la</TOKEN>
<TOKEN id="token-105-40" pos="word" morph="none" start_char="8683" end_char="8688">vacuna</TOKEN>
<TOKEN id="token-105-41" pos="word" morph="none" start_char="8690" end_char="8692">del</TOKEN>
<TOKEN id="token-105-42" pos="word" morph="none" start_char="8694" end_char="8702">sarampión</TOKEN>
<TOKEN id="token-105-43" pos="punct" morph="none" start_char="8703" end_char="8703">"</TOKEN>
</SEG>
<SEG id="segment-106" start_char="8706" end_char="8715">
<ORIGINAL_TEXT>, precisó.</ORIGINAL_TEXT>
<TOKEN id="token-106-0" pos="punct" morph="none" start_char="8706" end_char="8706">,</TOKEN>
<TOKEN id="token-106-1" pos="word" morph="none" start_char="8708" end_char="8714">precisó</TOKEN>
<TOKEN id="token-106-2" pos="punct" morph="none" start_char="8715" end_char="8715">.</TOKEN>
</SEG>
<SEG id="segment-107" start_char="8718" end_char="8947">
<ORIGINAL_TEXT>A 20 de marzo de 2020, el nuevo coronavirus ha contagiado ya a cerca de 250.000 personas y matado a más de 10.000, según datos oficiales recogidos por la AFP, provocando medidas de contención sin precedentes en casi todo el mundo.</ORIGINAL_TEXT>
<TOKEN id="token-107-0" pos="word" morph="none" start_char="8718" end_char="8718">A</TOKEN>
<TOKEN id="token-107-1" pos="word" morph="none" start_char="8720" end_char="8721">20</TOKEN>
<TOKEN id="token-107-2" pos="word" morph="none" start_char="8723" end_char="8724">de</TOKEN>
<TOKEN id="token-107-3" pos="word" morph="none" start_char="8726" end_char="8730">marzo</TOKEN>
<TOKEN id="token-107-4" pos="word" morph="none" start_char="8732" end_char="8733">de</TOKEN>
<TOKEN id="token-107-5" pos="word" morph="none" start_char="8735" end_char="8738">2020</TOKEN>
<TOKEN id="token-107-6" pos="punct" morph="none" start_char="8739" end_char="8739">,</TOKEN>
<TOKEN id="token-107-7" pos="word" morph="none" start_char="8741" end_char="8742">el</TOKEN>
<TOKEN id="token-107-8" pos="word" morph="none" start_char="8744" end_char="8748">nuevo</TOKEN>
<TOKEN id="token-107-9" pos="word" morph="none" start_char="8750" end_char="8760">coronavirus</TOKEN>
<TOKEN id="token-107-10" pos="word" morph="none" start_char="8762" end_char="8763">ha</TOKEN>
<TOKEN id="token-107-11" pos="word" morph="none" start_char="8765" end_char="8774">contagiado</TOKEN>
<TOKEN id="token-107-12" pos="word" morph="none" start_char="8776" end_char="8777">ya</TOKEN>
<TOKEN id="token-107-13" pos="word" morph="none" start_char="8779" end_char="8779">a</TOKEN>
<TOKEN id="token-107-14" pos="word" morph="none" start_char="8781" end_char="8785">cerca</TOKEN>
<TOKEN id="token-107-15" pos="word" morph="none" start_char="8787" end_char="8788">de</TOKEN>
<TOKEN id="token-107-16" pos="word" morph="none" start_char="8790" end_char="8796">250.000</TOKEN>
<TOKEN id="token-107-17" pos="word" morph="none" start_char="8798" end_char="8805">personas</TOKEN>
<TOKEN id="token-107-18" pos="word" morph="none" start_char="8807" end_char="8807">y</TOKEN>
<TOKEN id="token-107-19" pos="word" morph="none" start_char="8809" end_char="8814">matado</TOKEN>
<TOKEN id="token-107-20" pos="word" morph="none" start_char="8816" end_char="8816">a</TOKEN>
<TOKEN id="token-107-21" pos="word" morph="none" start_char="8818" end_char="8820">más</TOKEN>
<TOKEN id="token-107-22" pos="word" morph="none" start_char="8822" end_char="8823">de</TOKEN>
<TOKEN id="token-107-23" pos="unknown" morph="none" start_char="8825" end_char="8830">10.000</TOKEN>
<TOKEN id="token-107-24" pos="punct" morph="none" start_char="8831" end_char="8831">,</TOKEN>
<TOKEN id="token-107-25" pos="word" morph="none" start_char="8833" end_char="8837">según</TOKEN>
<TOKEN id="token-107-26" pos="word" morph="none" start_char="8839" end_char="8843">datos</TOKEN>
<TOKEN id="token-107-27" pos="word" morph="none" start_char="8845" end_char="8853">oficiales</TOKEN>
<TOKEN id="token-107-28" pos="word" morph="none" start_char="8855" end_char="8863">recogidos</TOKEN>
<TOKEN id="token-107-29" pos="word" morph="none" start_char="8865" end_char="8867">por</TOKEN>
<TOKEN id="token-107-30" pos="word" morph="none" start_char="8869" end_char="8870">la</TOKEN>
<TOKEN id="token-107-31" pos="word" morph="none" start_char="8872" end_char="8874">AFP</TOKEN>
<TOKEN id="token-107-32" pos="punct" morph="none" start_char="8875" end_char="8875">,</TOKEN>
<TOKEN id="token-107-33" pos="word" morph="none" start_char="8877" end_char="8886">provocando</TOKEN>
<TOKEN id="token-107-34" pos="word" morph="none" start_char="8888" end_char="8894">medidas</TOKEN>
<TOKEN id="token-107-35" pos="word" morph="none" start_char="8896" end_char="8897">de</TOKEN>
<TOKEN id="token-107-36" pos="word" morph="none" start_char="8899" end_char="8908">contención</TOKEN>
<TOKEN id="token-107-37" pos="word" morph="none" start_char="8910" end_char="8912">sin</TOKEN>
<TOKEN id="token-107-38" pos="word" morph="none" start_char="8914" end_char="8924">precedentes</TOKEN>
<TOKEN id="token-107-39" pos="word" morph="none" start_char="8926" end_char="8927">en</TOKEN>
<TOKEN id="token-107-40" pos="word" morph="none" start_char="8929" end_char="8932">casi</TOKEN>
<TOKEN id="token-107-41" pos="word" morph="none" start_char="8934" end_char="8937">todo</TOKEN>
<TOKEN id="token-107-42" pos="word" morph="none" start_char="8939" end_char="8940">el</TOKEN>
<TOKEN id="token-107-43" pos="word" morph="none" start_char="8942" end_char="8946">mundo</TOKEN>
<TOKEN id="token-107-44" pos="punct" morph="none" start_char="8947" end_char="8947">.</TOKEN>
</SEG>
<SEG id="segment-108" start_char="8950" end_char="9114">
<ORIGINAL_TEXT>En conclusión, el virus SARS-CoV-2, causante de la enfermedad COVID-19, es muy parecido a una patente de SARS-CoV del Instituto Pasteur de 2004, pero no es el mismo.</ORIGINAL_TEXT>
<TOKEN id="token-108-0" pos="word" morph="none" start_char="8950" end_char="8951">En</TOKEN>
<TOKEN id="token-108-1" pos="word" morph="none" start_char="8953" end_char="8962">conclusión</TOKEN>
<TOKEN id="token-108-2" pos="punct" morph="none" start_char="8963" end_char="8963">,</TOKEN>
<TOKEN id="token-108-3" pos="word" morph="none" start_char="8965" end_char="8966">el</TOKEN>
<TOKEN id="token-108-4" pos="word" morph="none" start_char="8968" end_char="8972">virus</TOKEN>
<TOKEN id="token-108-5" pos="unknown" morph="none" start_char="8974" end_char="8983">SARS-CoV-2</TOKEN>
<TOKEN id="token-108-6" pos="punct" morph="none" start_char="8984" end_char="8984">,</TOKEN>
<TOKEN id="token-108-7" pos="word" morph="none" start_char="8986" end_char="8993">causante</TOKEN>
<TOKEN id="token-108-8" pos="word" morph="none" start_char="8995" end_char="8996">de</TOKEN>
<TOKEN id="token-108-9" pos="word" morph="none" start_char="8998" end_char="8999">la</TOKEN>
<TOKEN id="token-108-10" pos="word" morph="none" start_char="9001" end_char="9010">enfermedad</TOKEN>
<TOKEN id="token-108-11" pos="unknown" morph="none" start_char="9012" end_char="9019">COVID-19</TOKEN>
<TOKEN id="token-108-12" pos="punct" morph="none" start_char="9020" end_char="9020">,</TOKEN>
<TOKEN id="token-108-13" pos="word" morph="none" start_char="9022" end_char="9023">es</TOKEN>
<TOKEN id="token-108-14" pos="word" morph="none" start_char="9025" end_char="9027">muy</TOKEN>
<TOKEN id="token-108-15" pos="word" morph="none" start_char="9029" end_char="9036">parecido</TOKEN>
<TOKEN id="token-108-16" pos="word" morph="none" start_char="9038" end_char="9038">a</TOKEN>
<TOKEN id="token-108-17" pos="word" morph="none" start_char="9040" end_char="9042">una</TOKEN>
<TOKEN id="token-108-18" pos="word" morph="none" start_char="9044" end_char="9050">patente</TOKEN>
<TOKEN id="token-108-19" pos="word" morph="none" start_char="9052" end_char="9053">de</TOKEN>
<TOKEN id="token-108-20" pos="unknown" morph="none" start_char="9055" end_char="9062">SARS-CoV</TOKEN>
<TOKEN id="token-108-21" pos="word" morph="none" start_char="9064" end_char="9066">del</TOKEN>
<TOKEN id="token-108-22" pos="word" morph="none" start_char="9068" end_char="9076">Instituto</TOKEN>
<TOKEN id="token-108-23" pos="word" morph="none" start_char="9078" end_char="9084">Pasteur</TOKEN>
<TOKEN id="token-108-24" pos="word" morph="none" start_char="9086" end_char="9087">de</TOKEN>
<TOKEN id="token-108-25" pos="word" morph="none" start_char="9089" end_char="9092">2004</TOKEN>
<TOKEN id="token-108-26" pos="punct" morph="none" start_char="9093" end_char="9093">,</TOKEN>
<TOKEN id="token-108-27" pos="word" morph="none" start_char="9095" end_char="9098">pero</TOKEN>
<TOKEN id="token-108-28" pos="word" morph="none" start_char="9100" end_char="9101">no</TOKEN>
<TOKEN id="token-108-29" pos="word" morph="none" start_char="9103" end_char="9104">es</TOKEN>
<TOKEN id="token-108-30" pos="word" morph="none" start_char="9106" end_char="9107">el</TOKEN>
<TOKEN id="token-108-31" pos="word" morph="none" start_char="9109" end_char="9113">mismo</TOKEN>
<TOKEN id="token-108-32" pos="punct" morph="none" start_char="9114" end_char="9114">.</TOKEN>
</SEG>
<SEG id="segment-109" start_char="9116" end_char="9179">
<ORIGINAL_TEXT>A su vez, la institución rechazó ser responsable de su creación.</ORIGINAL_TEXT>
<TOKEN id="token-109-0" pos="word" morph="none" start_char="9116" end_char="9116">A</TOKEN>
<TOKEN id="token-109-1" pos="word" morph="none" start_char="9118" end_char="9119">su</TOKEN>
<TOKEN id="token-109-2" pos="word" morph="none" start_char="9121" end_char="9123">vez</TOKEN>
<TOKEN id="token-109-3" pos="punct" morph="none" start_char="9124" end_char="9124">,</TOKEN>
<TOKEN id="token-109-4" pos="word" morph="none" start_char="9126" end_char="9127">la</TOKEN>
<TOKEN id="token-109-5" pos="word" morph="none" start_char="9129" end_char="9139">institución</TOKEN>
<TOKEN id="token-109-6" pos="word" morph="none" start_char="9141" end_char="9147">rechazó</TOKEN>
<TOKEN id="token-109-7" pos="word" morph="none" start_char="9149" end_char="9151">ser</TOKEN>
<TOKEN id="token-109-8" pos="word" morph="none" start_char="9153" end_char="9163">responsable</TOKEN>
<TOKEN id="token-109-9" pos="word" morph="none" start_char="9165" end_char="9166">de</TOKEN>
<TOKEN id="token-109-10" pos="word" morph="none" start_char="9168" end_char="9169">su</TOKEN>
<TOKEN id="token-109-11" pos="word" morph="none" start_char="9171" end_char="9178">creación</TOKEN>
<TOKEN id="token-109-12" pos="punct" morph="none" start_char="9179" end_char="9179">.</TOKEN>
</SEG>
<SEG id="segment-110" start_char="9181" end_char="9302">
<ORIGINAL_TEXT>Según una investigación realizada por científicos estadounidenses, el nuevo coronavirus es fruto de una evolución natural.</ORIGINAL_TEXT>
<TOKEN id="token-110-0" pos="word" morph="none" start_char="9181" end_char="9185">Según</TOKEN>
<TOKEN id="token-110-1" pos="word" morph="none" start_char="9187" end_char="9189">una</TOKEN>
<TOKEN id="token-110-2" pos="word" morph="none" start_char="9191" end_char="9203">investigación</TOKEN>
<TOKEN id="token-110-3" pos="word" morph="none" start_char="9205" end_char="9213">realizada</TOKEN>
<TOKEN id="token-110-4" pos="word" morph="none" start_char="9215" end_char="9217">por</TOKEN>
<TOKEN id="token-110-5" pos="word" morph="none" start_char="9219" end_char="9229">científicos</TOKEN>
<TOKEN id="token-110-6" pos="word" morph="none" start_char="9231" end_char="9245">estadounidenses</TOKEN>
<TOKEN id="token-110-7" pos="punct" morph="none" start_char="9246" end_char="9246">,</TOKEN>
<TOKEN id="token-110-8" pos="word" morph="none" start_char="9248" end_char="9249">el</TOKEN>
<TOKEN id="token-110-9" pos="word" morph="none" start_char="9251" end_char="9255">nuevo</TOKEN>
<TOKEN id="token-110-10" pos="word" morph="none" start_char="9257" end_char="9267">coronavirus</TOKEN>
<TOKEN id="token-110-11" pos="word" morph="none" start_char="9269" end_char="9270">es</TOKEN>
<TOKEN id="token-110-12" pos="word" morph="none" start_char="9272" end_char="9276">fruto</TOKEN>
<TOKEN id="token-110-13" pos="word" morph="none" start_char="9278" end_char="9279">de</TOKEN>
<TOKEN id="token-110-14" pos="word" morph="none" start_char="9281" end_char="9283">una</TOKEN>
<TOKEN id="token-110-15" pos="word" morph="none" start_char="9285" end_char="9293">evolución</TOKEN>
<TOKEN id="token-110-16" pos="word" morph="none" start_char="9295" end_char="9301">natural</TOKEN>
<TOKEN id="token-110-17" pos="punct" morph="none" start_char="9302" end_char="9302">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
