<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CAAY" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="3722" raw_text_md5="d68e1941753fab53c9bb288b3022f7e5">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="87">
<ORIGINAL_TEXT>Fact check: Coronavirus originated in China, not elsewhere, researchers and studies say</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="4">Fact</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="6" end_char="10">check</TOKEN>
<TOKEN id="token-0-2" pos="punct" morph="none" start_char="11" end_char="11">:</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="13" end_char="23">Coronavirus</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="25" end_char="34">originated</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="36" end_char="37">in</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="39" end_char="43">China</TOKEN>
<TOKEN id="token-0-7" pos="punct" morph="none" start_char="44" end_char="44">,</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="46" end_char="48">not</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="50" end_char="58">elsewhere</TOKEN>
<TOKEN id="token-0-10" pos="punct" morph="none" start_char="59" end_char="59">,</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="61" end_char="71">researchers</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="73" end_char="75">and</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="77" end_char="83">studies</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="85" end_char="87">say</TOKEN>
</SEG>
<SEG id="segment-1" start_char="91" end_char="99">
<ORIGINAL_TEXT>USA TODAY</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="91" end_char="93">USA</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="95" end_char="99">TODAY</TOKEN>
</SEG>
<SEG id="segment-2" start_char="103" end_char="153">
<ORIGINAL_TEXT>The claim: The coronavirus originated outside China</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="103" end_char="105">The</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="107" end_char="111">claim</TOKEN>
<TOKEN id="token-2-2" pos="punct" morph="none" start_char="112" end_char="112">:</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="114" end_char="116">The</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="118" end_char="128">coronavirus</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="130" end_char="139">originated</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="141" end_char="147">outside</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="149" end_char="153">China</TOKEN>
</SEG>
<SEG id="segment-3" start_char="157" end_char="309">
<ORIGINAL_TEXT>A piece published by the Centre for Research on Globalization and circulated on social media claims the virus known as COVID-19 originated outside China.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="157" end_char="157">A</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="159" end_char="163">piece</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="165" end_char="173">published</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="175" end_char="176">by</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="178" end_char="180">the</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="182" end_char="187">Centre</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="189" end_char="191">for</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="193" end_char="200">Research</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="202" end_char="203">on</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="205" end_char="217">Globalization</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="219" end_char="221">and</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="223" end_char="232">circulated</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="234" end_char="235">on</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="237" end_char="242">social</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="244" end_char="248">media</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="250" end_char="255">claims</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="257" end_char="259">the</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="261" end_char="265">virus</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="267" end_char="271">known</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="273" end_char="274">as</TOKEN>
<TOKEN id="token-3-20" pos="unknown" morph="none" start_char="276" end_char="283">COVID-19</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="285" end_char="294">originated</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="296" end_char="302">outside</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="304" end_char="308">China</TOKEN>
<TOKEN id="token-3-24" pos="punct" morph="none" start_char="309" end_char="309">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="312" end_char="486">
<ORIGINAL_TEXT>That March 11 posting makes references to a March 4 post on the same site by the same author that claims the virus "may have originated in the U.S." Titled "A Shocking Update.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="312" end_char="315">That</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="317" end_char="321">March</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="323" end_char="324">11</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="326" end_char="332">posting</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="334" end_char="338">makes</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="340" end_char="349">references</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="351" end_char="352">to</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="354" end_char="354">a</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="356" end_char="360">March</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="362" end_char="362">4</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="364" end_char="367">post</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="369" end_char="370">on</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="372" end_char="374">the</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="376" end_char="379">same</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="381" end_char="384">site</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="386" end_char="387">by</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="389" end_char="391">the</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="393" end_char="396">same</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="398" end_char="403">author</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="405" end_char="408">that</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="410" end_char="415">claims</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="417" end_char="419">the</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="421" end_char="425">virus</TOKEN>
<TOKEN id="token-4-23" pos="punct" morph="none" start_char="427" end_char="427">"</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="428" end_char="430">may</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="432" end_char="435">have</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="437" end_char="446">originated</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="448" end_char="449">in</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="451" end_char="453">the</TOKEN>
<TOKEN id="token-4-29" pos="unknown" morph="none" start_char="455" end_char="457">U.S</TOKEN>
<TOKEN id="token-4-30" pos="punct" morph="none" start_char="458" end_char="459">."</TOKEN>
<TOKEN id="token-4-31" pos="word" morph="none" start_char="461" end_char="466">Titled</TOKEN>
<TOKEN id="token-4-32" pos="punct" morph="none" start_char="468" end_char="468">"</TOKEN>
<TOKEN id="token-4-33" pos="word" morph="none" start_char="469" end_char="469">A</TOKEN>
<TOKEN id="token-4-34" pos="word" morph="none" start_char="471" end_char="478">Shocking</TOKEN>
<TOKEN id="token-4-35" pos="word" morph="none" start_char="480" end_char="485">Update</TOKEN>
<TOKEN id="token-4-36" pos="punct" morph="none" start_char="486" end_char="486">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="488" end_char="524">
<ORIGINAL_TEXT>Did The Virus Originate in the U.S.?"</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="488" end_char="490">Did</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="492" end_char="494">The</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="496" end_char="500">Virus</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="502" end_char="510">Originate</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="512" end_char="513">in</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="515" end_char="517">the</TOKEN>
<TOKEN id="token-5-6" pos="unknown" morph="none" start_char="519" end_char="521">U.S</TOKEN>
<TOKEN id="token-5-7" pos="punct" morph="none" start_char="522" end_char="524">.?"</TOKEN>
</SEG>
<SEG id="segment-6" start_char="526" end_char="661">
<ORIGINAL_TEXT>the earlier post makes several questionable claims about the origins of COVID-19 while misrepresenting cited research and media reports.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="526" end_char="528">the</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="530" end_char="536">earlier</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="538" end_char="541">post</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="543" end_char="547">makes</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="549" end_char="555">several</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="557" end_char="568">questionable</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="570" end_char="575">claims</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="577" end_char="581">about</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="583" end_char="585">the</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="587" end_char="593">origins</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="595" end_char="596">of</TOKEN>
<TOKEN id="token-6-11" pos="unknown" morph="none" start_char="598" end_char="605">COVID-19</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="607" end_char="611">while</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="613" end_char="627">misrepresenting</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="629" end_char="633">cited</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="635" end_char="642">research</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="644" end_char="646">and</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="648" end_char="652">media</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="654" end_char="660">reports</TOKEN>
<TOKEN id="token-6-19" pos="punct" morph="none" start_char="661" end_char="661">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="664" end_char="844">
<ORIGINAL_TEXT>The central claim of both the March 4 and 11 posts — that COVID-19 may have been brought to China by the U.S. Army — was recently echoed by a Chinese government official on Twitter.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="664" end_char="666">The</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="668" end_char="674">central</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="676" end_char="680">claim</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="682" end_char="683">of</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="685" end_char="688">both</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="690" end_char="692">the</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="694" end_char="698">March</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="700" end_char="700">4</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="702" end_char="704">and</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="706" end_char="707">11</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="709" end_char="713">posts</TOKEN>
<TOKEN id="token-7-11" pos="punct" morph="none" start_char="715" end_char="715">—</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="717" end_char="720">that</TOKEN>
<TOKEN id="token-7-13" pos="unknown" morph="none" start_char="722" end_char="729">COVID-19</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="731" end_char="733">may</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="735" end_char="738">have</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="740" end_char="743">been</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="745" end_char="751">brought</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="753" end_char="754">to</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="756" end_char="760">China</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="762" end_char="763">by</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="765" end_char="767">the</TOKEN>
<TOKEN id="token-7-22" pos="unknown" morph="none" start_char="769" end_char="771">U.S</TOKEN>
<TOKEN id="token-7-23" pos="punct" morph="none" start_char="772" end_char="772">.</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="774" end_char="777">Army</TOKEN>
<TOKEN id="token-7-25" pos="punct" morph="none" start_char="779" end_char="779">—</TOKEN>
<TOKEN id="token-7-26" pos="word" morph="none" start_char="781" end_char="783">was</TOKEN>
<TOKEN id="token-7-27" pos="word" morph="none" start_char="785" end_char="792">recently</TOKEN>
<TOKEN id="token-7-28" pos="word" morph="none" start_char="794" end_char="799">echoed</TOKEN>
<TOKEN id="token-7-29" pos="word" morph="none" start_char="801" end_char="802">by</TOKEN>
<TOKEN id="token-7-30" pos="word" morph="none" start_char="804" end_char="804">a</TOKEN>
<TOKEN id="token-7-31" pos="word" morph="none" start_char="806" end_char="812">Chinese</TOKEN>
<TOKEN id="token-7-32" pos="word" morph="none" start_char="814" end_char="823">government</TOKEN>
<TOKEN id="token-7-33" pos="word" morph="none" start_char="825" end_char="832">official</TOKEN>
<TOKEN id="token-7-34" pos="word" morph="none" start_char="834" end_char="835">on</TOKEN>
<TOKEN id="token-7-35" pos="word" morph="none" start_char="837" end_char="843">Twitter</TOKEN>
<TOKEN id="token-7-36" pos="punct" morph="none" start_char="844" end_char="844">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="846" end_char="907">
<ORIGINAL_TEXT>The Chinese official's claims were presented without evidence.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="846" end_char="848">The</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="850" end_char="856">Chinese</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="858" end_char="867">official's</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="869" end_char="874">claims</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="876" end_char="879">were</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="881" end_char="889">presented</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="891" end_char="897">without</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="899" end_char="906">evidence</TOKEN>
<TOKEN id="token-8-8" pos="punct" morph="none" start_char="907" end_char="907">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="910" end_char="1021">
<ORIGINAL_TEXT>Several of the central statements in the March 4 article misrepresent cited research or make unclear assertions.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="910" end_char="916">Several</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="918" end_char="919">of</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="921" end_char="923">the</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="925" end_char="931">central</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="933" end_char="942">statements</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="944" end_char="945">in</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="947" end_char="949">the</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="951" end_char="955">March</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="957" end_char="957">4</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="959" end_char="965">article</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="967" end_char="978">misrepresent</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="980" end_char="984">cited</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="986" end_char="993">research</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="995" end_char="996">or</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="998" end_char="1001">make</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1003" end_char="1009">unclear</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1011" end_char="1020">assertions</TOKEN>
<TOKEN id="token-9-17" pos="punct" morph="none" start_char="1021" end_char="1021">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1023" end_char="1174">
<ORIGINAL_TEXT>USA TODAY reached out to Larry Romanoff, author of both posts, for clarification on several of the claims made, but was unable to reach him for comment.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1023" end_char="1025">USA</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1027" end_char="1031">TODAY</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1033" end_char="1039">reached</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1041" end_char="1043">out</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1045" end_char="1046">to</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1048" end_char="1052">Larry</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1054" end_char="1061">Romanoff</TOKEN>
<TOKEN id="token-10-7" pos="punct" morph="none" start_char="1062" end_char="1062">,</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1064" end_char="1069">author</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1071" end_char="1072">of</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1074" end_char="1077">both</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1079" end_char="1083">posts</TOKEN>
<TOKEN id="token-10-12" pos="punct" morph="none" start_char="1084" end_char="1084">,</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1086" end_char="1088">for</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1090" end_char="1102">clarification</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1104" end_char="1105">on</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1107" end_char="1113">several</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1115" end_char="1116">of</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1118" end_char="1120">the</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1122" end_char="1127">claims</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1129" end_char="1132">made</TOKEN>
<TOKEN id="token-10-21" pos="punct" morph="none" start_char="1133" end_char="1133">,</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1135" end_char="1137">but</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1139" end_char="1141">was</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1143" end_char="1148">unable</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="1150" end_char="1151">to</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="1153" end_char="1157">reach</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="1159" end_char="1161">him</TOKEN>
<TOKEN id="token-10-28" pos="word" morph="none" start_char="1163" end_char="1165">for</TOKEN>
<TOKEN id="token-10-29" pos="word" morph="none" start_char="1167" end_char="1173">comment</TOKEN>
<TOKEN id="token-10-30" pos="punct" morph="none" start_char="1174" end_char="1174">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1177" end_char="1255">
<ORIGINAL_TEXT>More:A coronavirus pandemic is sweeping the world, but what exactly is a virus?</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="unknown" morph="none" start_char="1177" end_char="1182">More:A</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1184" end_char="1194">coronavirus</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1196" end_char="1203">pandemic</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1205" end_char="1206">is</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1208" end_char="1215">sweeping</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1217" end_char="1219">the</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1221" end_char="1225">world</TOKEN>
<TOKEN id="token-11-7" pos="punct" morph="none" start_char="1226" end_char="1226">,</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1228" end_char="1230">but</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1232" end_char="1235">what</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1237" end_char="1243">exactly</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1245" end_char="1246">is</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1248" end_char="1248">a</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1250" end_char="1254">virus</TOKEN>
<TOKEN id="token-11-14" pos="punct" morph="none" start_char="1255" end_char="1255">?</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1258" end_char="1307">
<ORIGINAL_TEXT>What researchers say: COVID-19 originated in China</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1258" end_char="1261">What</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1263" end_char="1273">researchers</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1275" end_char="1277">say</TOKEN>
<TOKEN id="token-12-3" pos="punct" morph="none" start_char="1278" end_char="1278">:</TOKEN>
<TOKEN id="token-12-4" pos="unknown" morph="none" start_char="1280" end_char="1287">COVID-19</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1289" end_char="1298">originated</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1300" end_char="1301">in</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1303" end_char="1307">China</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1311" end_char="1468">
<ORIGINAL_TEXT>The consensus among researchers studying the spread of the virus pinpoints COVID-19’s likely origin to a "wet market," or live animal market, in Wuhan, China.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1311" end_char="1313">The</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1315" end_char="1323">consensus</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1325" end_char="1329">among</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1331" end_char="1341">researchers</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1343" end_char="1350">studying</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1352" end_char="1354">the</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1356" end_char="1361">spread</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1363" end_char="1364">of</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1366" end_char="1368">the</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1370" end_char="1374">virus</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1376" end_char="1384">pinpoints</TOKEN>
<TOKEN id="token-13-11" pos="unknown" morph="none" start_char="1386" end_char="1395">COVID-19’s</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1397" end_char="1402">likely</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1404" end_char="1409">origin</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1411" end_char="1412">to</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1414" end_char="1414">a</TOKEN>
<TOKEN id="token-13-16" pos="punct" morph="none" start_char="1416" end_char="1416">"</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1417" end_char="1419">wet</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1421" end_char="1426">market</TOKEN>
<TOKEN id="token-13-19" pos="punct" morph="none" start_char="1427" end_char="1428">,"</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1430" end_char="1431">or</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="1433" end_char="1436">live</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="1438" end_char="1443">animal</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="1445" end_char="1450">market</TOKEN>
<TOKEN id="token-13-24" pos="punct" morph="none" start_char="1451" end_char="1451">,</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="1453" end_char="1454">in</TOKEN>
<TOKEN id="token-13-26" pos="word" morph="none" start_char="1456" end_char="1460">Wuhan</TOKEN>
<TOKEN id="token-13-27" pos="punct" morph="none" start_char="1461" end_char="1461">,</TOKEN>
<TOKEN id="token-13-28" pos="word" morph="none" start_char="1463" end_char="1467">China</TOKEN>
<TOKEN id="token-13-29" pos="punct" morph="none" start_char="1468" end_char="1468">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1470" end_char="1678">
<ORIGINAL_TEXT>Though experts have not ruled out the possibility that the pathogen could have been brought to the market by an already infected person, there is no evidence to suggest COVID-19 originated outside the country.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1470" end_char="1475">Though</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1477" end_char="1483">experts</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1485" end_char="1488">have</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1490" end_char="1492">not</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1494" end_char="1498">ruled</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1500" end_char="1502">out</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1504" end_char="1506">the</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1508" end_char="1518">possibility</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1520" end_char="1523">that</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1525" end_char="1527">the</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1529" end_char="1536">pathogen</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1538" end_char="1542">could</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1544" end_char="1547">have</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1549" end_char="1552">been</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="1554" end_char="1560">brought</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1562" end_char="1563">to</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1565" end_char="1567">the</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="1569" end_char="1574">market</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="1576" end_char="1577">by</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="1579" end_char="1580">an</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="1582" end_char="1588">already</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="1590" end_char="1597">infected</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="1599" end_char="1604">person</TOKEN>
<TOKEN id="token-14-23" pos="punct" morph="none" start_char="1605" end_char="1605">,</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="1607" end_char="1611">there</TOKEN>
<TOKEN id="token-14-25" pos="word" morph="none" start_char="1613" end_char="1614">is</TOKEN>
<TOKEN id="token-14-26" pos="word" morph="none" start_char="1616" end_char="1617">no</TOKEN>
<TOKEN id="token-14-27" pos="word" morph="none" start_char="1619" end_char="1626">evidence</TOKEN>
<TOKEN id="token-14-28" pos="word" morph="none" start_char="1628" end_char="1629">to</TOKEN>
<TOKEN id="token-14-29" pos="word" morph="none" start_char="1631" end_char="1637">suggest</TOKEN>
<TOKEN id="token-14-30" pos="unknown" morph="none" start_char="1639" end_char="1646">COVID-19</TOKEN>
<TOKEN id="token-14-31" pos="word" morph="none" start_char="1648" end_char="1657">originated</TOKEN>
<TOKEN id="token-14-32" pos="word" morph="none" start_char="1659" end_char="1665">outside</TOKEN>
<TOKEN id="token-14-33" pos="word" morph="none" start_char="1667" end_char="1669">the</TOKEN>
<TOKEN id="token-14-34" pos="word" morph="none" start_char="1671" end_char="1677">country</TOKEN>
<TOKEN id="token-14-35" pos="punct" morph="none" start_char="1678" end_char="1678">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1681" end_char="1822">
<ORIGINAL_TEXT>The origin theory for the virus is supplemented by preliminary research into the disease’s genome, as well as the origins of similar diseases.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1681" end_char="1683">The</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1685" end_char="1690">origin</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1692" end_char="1697">theory</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1699" end_char="1701">for</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1703" end_char="1705">the</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1707" end_char="1711">virus</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1713" end_char="1714">is</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1716" end_char="1727">supplemented</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1729" end_char="1730">by</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1732" end_char="1742">preliminary</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1744" end_char="1751">research</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1753" end_char="1756">into</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1758" end_char="1760">the</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1762" end_char="1770">disease’s</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1772" end_char="1777">genome</TOKEN>
<TOKEN id="token-15-15" pos="punct" morph="none" start_char="1778" end_char="1778">,</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="1780" end_char="1781">as</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="1783" end_char="1786">well</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="1788" end_char="1789">as</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="1791" end_char="1793">the</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="1795" end_char="1801">origins</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="1803" end_char="1804">of</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="1806" end_char="1812">similar</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="1814" end_char="1821">diseases</TOKEN>
<TOKEN id="token-15-24" pos="punct" morph="none" start_char="1822" end_char="1822">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1824" end_char="1972">
<ORIGINAL_TEXT>Researchers at the Shanghai Public Health Clinical Centre published the genome of COVID-19 two weeks after cases were reported in late December 2019.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1824" end_char="1834">Researchers</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1836" end_char="1837">at</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1839" end_char="1841">the</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1843" end_char="1850">Shanghai</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1852" end_char="1857">Public</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1859" end_char="1864">Health</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1866" end_char="1873">Clinical</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1875" end_char="1880">Centre</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1882" end_char="1890">published</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="1892" end_char="1894">the</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="1896" end_char="1901">genome</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="1903" end_char="1904">of</TOKEN>
<TOKEN id="token-16-12" pos="unknown" morph="none" start_char="1906" end_char="1913">COVID-19</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="1915" end_char="1917">two</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="1919" end_char="1923">weeks</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="1925" end_char="1929">after</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="1931" end_char="1935">cases</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="1937" end_char="1940">were</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="1942" end_char="1949">reported</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="1951" end_char="1952">in</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="1954" end_char="1957">late</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="1959" end_char="1966">December</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="1968" end_char="1971">2019</TOKEN>
<TOKEN id="token-16-23" pos="punct" morph="none" start_char="1972" end_char="1972">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1974" end_char="2123">
<ORIGINAL_TEXT>Gene sequencing analysis strongly suggests the virus originated in bats and was transferred to humans through a yet-unidentified intermediary species.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1974" end_char="1977">Gene</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1979" end_char="1988">sequencing</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="1990" end_char="1997">analysis</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="1999" end_char="2006">strongly</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2008" end_char="2015">suggests</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2017" end_char="2019">the</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2021" end_char="2025">virus</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2027" end_char="2036">originated</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2038" end_char="2039">in</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2041" end_char="2044">bats</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2046" end_char="2048">and</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2050" end_char="2052">was</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2054" end_char="2064">transferred</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2066" end_char="2067">to</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2069" end_char="2074">humans</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2076" end_char="2082">through</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="2084" end_char="2084">a</TOKEN>
<TOKEN id="token-17-17" pos="unknown" morph="none" start_char="2086" end_char="2101">yet-unidentified</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="2103" end_char="2114">intermediary</TOKEN>
<TOKEN id="token-17-19" pos="word" morph="none" start_char="2116" end_char="2122">species</TOKEN>
<TOKEN id="token-17-20" pos="punct" morph="none" start_char="2123" end_char="2123">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2125" end_char="2334">
<ORIGINAL_TEXT>In early February, Chinese researchers published work suggesting the intermediary species may have been the pangolin (also called a scaly anteater), though this work has not yet undergone a peer-reviewed study.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2125" end_char="2126">In</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2128" end_char="2132">early</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2134" end_char="2141">February</TOKEN>
<TOKEN id="token-18-3" pos="punct" morph="none" start_char="2142" end_char="2142">,</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2144" end_char="2150">Chinese</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2152" end_char="2162">researchers</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2164" end_char="2172">published</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2174" end_char="2177">work</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2179" end_char="2188">suggesting</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="2190" end_char="2192">the</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="2194" end_char="2205">intermediary</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="2207" end_char="2213">species</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2215" end_char="2217">may</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="2219" end_char="2222">have</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="2224" end_char="2227">been</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="2229" end_char="2231">the</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="2233" end_char="2240">pangolin</TOKEN>
<TOKEN id="token-18-17" pos="punct" morph="none" start_char="2242" end_char="2242">(</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="2243" end_char="2246">also</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="2248" end_char="2253">called</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="2255" end_char="2255">a</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="2257" end_char="2261">scaly</TOKEN>
<TOKEN id="token-18-22" pos="word" morph="none" start_char="2263" end_char="2270">anteater</TOKEN>
<TOKEN id="token-18-23" pos="punct" morph="none" start_char="2271" end_char="2272">),</TOKEN>
<TOKEN id="token-18-24" pos="word" morph="none" start_char="2274" end_char="2279">though</TOKEN>
<TOKEN id="token-18-25" pos="word" morph="none" start_char="2281" end_char="2284">this</TOKEN>
<TOKEN id="token-18-26" pos="word" morph="none" start_char="2286" end_char="2289">work</TOKEN>
<TOKEN id="token-18-27" pos="word" morph="none" start_char="2291" end_char="2293">has</TOKEN>
<TOKEN id="token-18-28" pos="word" morph="none" start_char="2295" end_char="2297">not</TOKEN>
<TOKEN id="token-18-29" pos="word" morph="none" start_char="2299" end_char="2301">yet</TOKEN>
<TOKEN id="token-18-30" pos="word" morph="none" start_char="2303" end_char="2311">undergone</TOKEN>
<TOKEN id="token-18-31" pos="word" morph="none" start_char="2313" end_char="2313">a</TOKEN>
<TOKEN id="token-18-32" pos="unknown" morph="none" start_char="2315" end_char="2327">peer-reviewed</TOKEN>
<TOKEN id="token-18-33" pos="word" morph="none" start_char="2329" end_char="2333">study</TOKEN>
<TOKEN id="token-18-34" pos="punct" morph="none" start_char="2334" end_char="2334">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2337" end_char="2476">
<ORIGINAL_TEXT>The conditions for such interspecies pathogen transfer are ripe in wet markets, which are common in parts of Asia, Africa and Latin America.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2337" end_char="2339">The</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2341" end_char="2350">conditions</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2352" end_char="2354">for</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2356" end_char="2359">such</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2361" end_char="2372">interspecies</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2374" end_char="2381">pathogen</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2383" end_char="2390">transfer</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2392" end_char="2394">are</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2396" end_char="2399">ripe</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="2401" end_char="2402">in</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="2404" end_char="2406">wet</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="2408" end_char="2414">markets</TOKEN>
<TOKEN id="token-19-12" pos="punct" morph="none" start_char="2415" end_char="2415">,</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="2417" end_char="2421">which</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="2423" end_char="2425">are</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="2427" end_char="2432">common</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="2434" end_char="2435">in</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="2437" end_char="2441">parts</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="2443" end_char="2444">of</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="2446" end_char="2449">Asia</TOKEN>
<TOKEN id="token-19-20" pos="punct" morph="none" start_char="2450" end_char="2450">,</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="2452" end_char="2457">Africa</TOKEN>
<TOKEN id="token-19-22" pos="word" morph="none" start_char="2459" end_char="2461">and</TOKEN>
<TOKEN id="token-19-23" pos="word" morph="none" start_char="2463" end_char="2467">Latin</TOKEN>
<TOKEN id="token-19-24" pos="word" morph="none" start_char="2469" end_char="2475">America</TOKEN>
<TOKEN id="token-19-25" pos="punct" morph="none" start_char="2476" end_char="2476">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2478" end_char="2596">
<ORIGINAL_TEXT>Severe acute respiratory syndrome, or SARS, resulted from a virus transferring from bats to civet cats and then humans.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2478" end_char="2483">Severe</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2485" end_char="2489">acute</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2491" end_char="2501">respiratory</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2503" end_char="2510">syndrome</TOKEN>
<TOKEN id="token-20-4" pos="punct" morph="none" start_char="2511" end_char="2511">,</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2513" end_char="2514">or</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2516" end_char="2519">SARS</TOKEN>
<TOKEN id="token-20-7" pos="punct" morph="none" start_char="2520" end_char="2520">,</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="2522" end_char="2529">resulted</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2531" end_char="2534">from</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2536" end_char="2536">a</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="2538" end_char="2542">virus</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="2544" end_char="2555">transferring</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="2557" end_char="2560">from</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="2562" end_char="2565">bats</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="2567" end_char="2568">to</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="2570" end_char="2574">civet</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="2576" end_char="2579">cats</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="2581" end_char="2583">and</TOKEN>
<TOKEN id="token-20-19" pos="word" morph="none" start_char="2585" end_char="2588">then</TOKEN>
<TOKEN id="token-20-20" pos="word" morph="none" start_char="2590" end_char="2595">humans</TOKEN>
<TOKEN id="token-20-21" pos="punct" morph="none" start_char="2596" end_char="2596">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2598" end_char="2712">
<ORIGINAL_TEXT>SARS, discovered in 2003, originated at a wet market similar to the one now suspected to be the origin of COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2598" end_char="2601">SARS</TOKEN>
<TOKEN id="token-21-1" pos="punct" morph="none" start_char="2602" end_char="2602">,</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2604" end_char="2613">discovered</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2615" end_char="2616">in</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2618" end_char="2621">2003</TOKEN>
<TOKEN id="token-21-5" pos="punct" morph="none" start_char="2622" end_char="2622">,</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2624" end_char="2633">originated</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="2635" end_char="2636">at</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="2638" end_char="2638">a</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="2640" end_char="2642">wet</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="2644" end_char="2649">market</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="2651" end_char="2657">similar</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="2659" end_char="2660">to</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="2662" end_char="2664">the</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="2666" end_char="2668">one</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="2670" end_char="2672">now</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="2674" end_char="2682">suspected</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="2684" end_char="2685">to</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="2687" end_char="2688">be</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="2690" end_char="2692">the</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="2694" end_char="2699">origin</TOKEN>
<TOKEN id="token-21-21" pos="word" morph="none" start_char="2701" end_char="2702">of</TOKEN>
<TOKEN id="token-21-22" pos="unknown" morph="none" start_char="2704" end_char="2711">COVID-19</TOKEN>
<TOKEN id="token-21-23" pos="punct" morph="none" start_char="2712" end_char="2712">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2715" end_char="2946">
<ORIGINAL_TEXT>Other claims and theories about the origins of COVID-19, including that the virus was brought to by the U.S. Army during the Military World Games in October in Wuhan, are unsubstantiated and not supported by research into the virus.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2715" end_char="2719">Other</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2721" end_char="2726">claims</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2728" end_char="2730">and</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2732" end_char="2739">theories</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2741" end_char="2745">about</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2747" end_char="2749">the</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2751" end_char="2757">origins</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2759" end_char="2760">of</TOKEN>
<TOKEN id="token-22-8" pos="unknown" morph="none" start_char="2762" end_char="2769">COVID-19</TOKEN>
<TOKEN id="token-22-9" pos="punct" morph="none" start_char="2770" end_char="2770">,</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="2772" end_char="2780">including</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="2782" end_char="2785">that</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="2787" end_char="2789">the</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="2791" end_char="2795">virus</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="2797" end_char="2799">was</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="2801" end_char="2807">brought</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="2809" end_char="2810">to</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="2812" end_char="2813">by</TOKEN>
<TOKEN id="token-22-18" pos="word" morph="none" start_char="2815" end_char="2817">the</TOKEN>
<TOKEN id="token-22-19" pos="unknown" morph="none" start_char="2819" end_char="2821">U.S</TOKEN>
<TOKEN id="token-22-20" pos="punct" morph="none" start_char="2822" end_char="2822">.</TOKEN>
<TOKEN id="token-22-21" pos="word" morph="none" start_char="2824" end_char="2827">Army</TOKEN>
<TOKEN id="token-22-22" pos="word" morph="none" start_char="2829" end_char="2834">during</TOKEN>
<TOKEN id="token-22-23" pos="word" morph="none" start_char="2836" end_char="2838">the</TOKEN>
<TOKEN id="token-22-24" pos="word" morph="none" start_char="2840" end_char="2847">Military</TOKEN>
<TOKEN id="token-22-25" pos="word" morph="none" start_char="2849" end_char="2853">World</TOKEN>
<TOKEN id="token-22-26" pos="word" morph="none" start_char="2855" end_char="2859">Games</TOKEN>
<TOKEN id="token-22-27" pos="word" morph="none" start_char="2861" end_char="2862">in</TOKEN>
<TOKEN id="token-22-28" pos="word" morph="none" start_char="2864" end_char="2870">October</TOKEN>
<TOKEN id="token-22-29" pos="word" morph="none" start_char="2872" end_char="2873">in</TOKEN>
<TOKEN id="token-22-30" pos="word" morph="none" start_char="2875" end_char="2879">Wuhan</TOKEN>
<TOKEN id="token-22-31" pos="punct" morph="none" start_char="2880" end_char="2880">,</TOKEN>
<TOKEN id="token-22-32" pos="word" morph="none" start_char="2882" end_char="2884">are</TOKEN>
<TOKEN id="token-22-33" pos="word" morph="none" start_char="2886" end_char="2900">unsubstantiated</TOKEN>
<TOKEN id="token-22-34" pos="word" morph="none" start_char="2902" end_char="2904">and</TOKEN>
<TOKEN id="token-22-35" pos="word" morph="none" start_char="2906" end_char="2908">not</TOKEN>
<TOKEN id="token-22-36" pos="word" morph="none" start_char="2910" end_char="2918">supported</TOKEN>
<TOKEN id="token-22-37" pos="word" morph="none" start_char="2920" end_char="2921">by</TOKEN>
<TOKEN id="token-22-38" pos="word" morph="none" start_char="2923" end_char="2930">research</TOKEN>
<TOKEN id="token-22-39" pos="word" morph="none" start_char="2932" end_char="2935">into</TOKEN>
<TOKEN id="token-22-40" pos="word" morph="none" start_char="2937" end_char="2939">the</TOKEN>
<TOKEN id="token-22-41" pos="word" morph="none" start_char="2941" end_char="2945">virus</TOKEN>
<TOKEN id="token-22-42" pos="punct" morph="none" start_char="2946" end_char="2946">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2949" end_char="3070">
<ORIGINAL_TEXT>Researchers at ETH Zurich released a study in early March that placed the origins of COVID-19 in November at the earliest.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2949" end_char="2959">Researchers</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2961" end_char="2962">at</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2964" end_char="2966">ETH</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2968" end_char="2973">Zurich</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="2975" end_char="2982">released</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="2984" end_char="2984">a</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="2986" end_char="2990">study</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="2992" end_char="2993">in</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="2995" end_char="2999">early</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="3001" end_char="3005">March</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="3007" end_char="3010">that</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="3012" end_char="3017">placed</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="3019" end_char="3021">the</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="3023" end_char="3029">origins</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="3031" end_char="3032">of</TOKEN>
<TOKEN id="token-23-15" pos="unknown" morph="none" start_char="3034" end_char="3041">COVID-19</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="3043" end_char="3044">in</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="3046" end_char="3053">November</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="3055" end_char="3056">at</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="3058" end_char="3060">the</TOKEN>
<TOKEN id="token-23-20" pos="word" morph="none" start_char="3062" end_char="3069">earliest</TOKEN>
<TOKEN id="token-23-21" pos="punct" morph="none" start_char="3070" end_char="3070">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="3072" end_char="3284">
<ORIGINAL_TEXT>Research published by the Scripps Research Institute in February strongly implies that the virus in humans arose naturally through interspecies transfer, putting its origin in late November or early December 2019.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="3072" end_char="3079">Research</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="3081" end_char="3089">published</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="3091" end_char="3092">by</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="3094" end_char="3096">the</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="3098" end_char="3104">Scripps</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="3106" end_char="3113">Research</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="3115" end_char="3123">Institute</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="3125" end_char="3126">in</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="3128" end_char="3135">February</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="3137" end_char="3144">strongly</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="3146" end_char="3152">implies</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="3154" end_char="3157">that</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="3159" end_char="3161">the</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="3163" end_char="3167">virus</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="3169" end_char="3170">in</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="3172" end_char="3177">humans</TOKEN>
<TOKEN id="token-24-16" pos="word" morph="none" start_char="3179" end_char="3183">arose</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="3185" end_char="3193">naturally</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="3195" end_char="3201">through</TOKEN>
<TOKEN id="token-24-19" pos="word" morph="none" start_char="3203" end_char="3214">interspecies</TOKEN>
<TOKEN id="token-24-20" pos="word" morph="none" start_char="3216" end_char="3223">transfer</TOKEN>
<TOKEN id="token-24-21" pos="punct" morph="none" start_char="3224" end_char="3224">,</TOKEN>
<TOKEN id="token-24-22" pos="word" morph="none" start_char="3226" end_char="3232">putting</TOKEN>
<TOKEN id="token-24-23" pos="word" morph="none" start_char="3234" end_char="3236">its</TOKEN>
<TOKEN id="token-24-24" pos="word" morph="none" start_char="3238" end_char="3243">origin</TOKEN>
<TOKEN id="token-24-25" pos="word" morph="none" start_char="3245" end_char="3246">in</TOKEN>
<TOKEN id="token-24-26" pos="word" morph="none" start_char="3248" end_char="3251">late</TOKEN>
<TOKEN id="token-24-27" pos="word" morph="none" start_char="3253" end_char="3260">November</TOKEN>
<TOKEN id="token-24-28" pos="word" morph="none" start_char="3262" end_char="3263">or</TOKEN>
<TOKEN id="token-24-29" pos="word" morph="none" start_char="3265" end_char="3269">early</TOKEN>
<TOKEN id="token-24-30" pos="word" morph="none" start_char="3271" end_char="3278">December</TOKEN>
<TOKEN id="token-24-31" pos="word" morph="none" start_char="3280" end_char="3283">2019</TOKEN>
<TOKEN id="token-24-32" pos="punct" morph="none" start_char="3284" end_char="3284">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="3286" end_char="3351">
<ORIGINAL_TEXT>Both studies point to the virus’s origin in Hubei province, China.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="3286" end_char="3289">Both</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="3291" end_char="3297">studies</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="3299" end_char="3303">point</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="3305" end_char="3306">to</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="3308" end_char="3310">the</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="3312" end_char="3318">virus’s</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="3320" end_char="3325">origin</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="3327" end_char="3328">in</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="3330" end_char="3334">Hubei</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="3336" end_char="3343">province</TOKEN>
<TOKEN id="token-25-10" pos="punct" morph="none" start_char="3344" end_char="3344">,</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="3346" end_char="3350">China</TOKEN>
<TOKEN id="token-25-12" pos="punct" morph="none" start_char="3351" end_char="3351">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="3354" end_char="3370">
<ORIGINAL_TEXT>Our ruling: False</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="3354" end_char="3356">Our</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="3358" end_char="3363">ruling</TOKEN>
<TOKEN id="token-26-2" pos="punct" morph="none" start_char="3364" end_char="3364">:</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="3366" end_char="3370">False</TOKEN>
</SEG>
<SEG id="segment-27" start_char="3374" end_char="3455">
<ORIGINAL_TEXT>An article circulating on social media claims COVID-19 did not originate in China.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="3374" end_char="3375">An</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="3377" end_char="3383">article</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="3385" end_char="3395">circulating</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="3397" end_char="3398">on</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="3400" end_char="3405">social</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="3407" end_char="3411">media</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="3413" end_char="3418">claims</TOKEN>
<TOKEN id="token-27-7" pos="unknown" morph="none" start_char="3420" end_char="3427">COVID-19</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="3429" end_char="3431">did</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="3433" end_char="3435">not</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="3437" end_char="3445">originate</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="3447" end_char="3448">in</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="3450" end_char="3454">China</TOKEN>
<TOKEN id="token-27-13" pos="punct" morph="none" start_char="3455" end_char="3455">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3457" end_char="3521">
<ORIGINAL_TEXT>We rate this claim FALSE because it is not supported by research.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="3457" end_char="3458">We</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="3460" end_char="3463">rate</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="3465" end_char="3468">this</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="3470" end_char="3474">claim</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="3476" end_char="3480">FALSE</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="3482" end_char="3488">because</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="3490" end_char="3491">it</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="3493" end_char="3494">is</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="3496" end_char="3498">not</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="3500" end_char="3508">supported</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="3510" end_char="3511">by</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="3513" end_char="3520">research</TOKEN>
<TOKEN id="token-28-12" pos="punct" morph="none" start_char="3521" end_char="3521">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3523" end_char="3662">
<ORIGINAL_TEXT>The consensus among experts researching the virus places the beginning of its spread at the Huanan Seafood Wholesale Market in Wuhan, China.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="3523" end_char="3525">The</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="3527" end_char="3535">consensus</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="3537" end_char="3541">among</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="3543" end_char="3549">experts</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="3551" end_char="3561">researching</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="3563" end_char="3565">the</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="3567" end_char="3571">virus</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="3573" end_char="3578">places</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="3580" end_char="3582">the</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="3584" end_char="3592">beginning</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="3594" end_char="3595">of</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="3597" end_char="3599">its</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="3601" end_char="3606">spread</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="3608" end_char="3609">at</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="3611" end_char="3613">the</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="3615" end_char="3620">Huanan</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="3622" end_char="3628">Seafood</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="3630" end_char="3638">Wholesale</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="3640" end_char="3645">Market</TOKEN>
<TOKEN id="token-29-19" pos="word" morph="none" start_char="3647" end_char="3648">in</TOKEN>
<TOKEN id="token-29-20" pos="word" morph="none" start_char="3650" end_char="3654">Wuhan</TOKEN>
<TOKEN id="token-29-21" pos="punct" morph="none" start_char="3655" end_char="3655">,</TOKEN>
<TOKEN id="token-29-22" pos="word" morph="none" start_char="3657" end_char="3661">China</TOKEN>
<TOKEN id="token-29-23" pos="punct" morph="none" start_char="3662" end_char="3662">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3665" end_char="3687">
<ORIGINAL_TEXT>Our fact-check sources:</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="3665" end_char="3667">Our</TOKEN>
<TOKEN id="token-30-1" pos="unknown" morph="none" start_char="3669" end_char="3678">fact-check</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="3680" end_char="3686">sources</TOKEN>
<TOKEN id="token-30-3" pos="punct" morph="none" start_char="3687" end_char="3687">:</TOKEN>
</SEG>
<SEG id="segment-31" start_char="3690" end_char="3718">
<ORIGINAL_TEXT>Contributing: Martina Stewart</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="3690" end_char="3701">Contributing</TOKEN>
<TOKEN id="token-31-1" pos="punct" morph="none" start_char="3702" end_char="3702">:</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="3704" end_char="3710">Martina</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="3712" end_char="3718">Stewart</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
