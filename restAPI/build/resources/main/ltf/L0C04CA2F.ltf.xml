<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CA2F" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="4620" raw_text_md5="675cc1fb91f7614424ad91a0afaaf500">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="89">
<ORIGINAL_TEXT>COVID-19 test kits were not purchased in 2017 and 2018; claim is based on mislabeled data</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="unknown" morph="none" start_char="1" end_char="8">COVID-19</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="10" end_char="13">test</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="15" end_char="18">kits</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="20" end_char="23">were</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="25" end_char="27">not</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="29" end_char="37">purchased</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="39" end_char="40">in</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="42" end_char="45">2017</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="47" end_char="49">and</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="51" end_char="54">2018</TOKEN>
<TOKEN id="token-0-10" pos="punct" morph="none" start_char="55" end_char="55">;</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="57" end_char="61">claim</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="63" end_char="64">is</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="66" end_char="70">based</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="72" end_char="73">on</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="75" end_char="84">mislabeled</TOKEN>
<TOKEN id="token-0-16" pos="word" morph="none" start_char="86" end_char="89">data</TOKEN>
</SEG>
<SEG id="segment-1" start_char="94" end_char="196">
<ORIGINAL_TEXT>FULL CLAIM: "World Bank website shows COVID-19 testing kits purchased by countries in 2017 and in 2018"</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="94" end_char="97">FULL</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="99" end_char="103">CLAIM</TOKEN>
<TOKEN id="token-1-2" pos="punct" morph="none" start_char="104" end_char="104">:</TOKEN>
<TOKEN id="token-1-3" pos="punct" morph="none" start_char="106" end_char="106">"</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="107" end_char="111">World</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="113" end_char="116">Bank</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="118" end_char="124">website</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="126" end_char="130">shows</TOKEN>
<TOKEN id="token-1-8" pos="unknown" morph="none" start_char="132" end_char="139">COVID-19</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="141" end_char="147">testing</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="149" end_char="152">kits</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="154" end_char="162">purchased</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="164" end_char="165">by</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="167" end_char="175">countries</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="177" end_char="178">in</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="180" end_char="183">2017</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="185" end_char="187">and</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="189" end_char="190">in</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="192" end_char="195">2018</TOKEN>
<TOKEN id="token-1-19" pos="punct" morph="none" start_char="196" end_char="196">"</TOKEN>
</SEG>
<SEG id="segment-2" start_char="200" end_char="488">
<ORIGINAL_TEXT>Claims that the coronavirus pandemic was planned has been fanned by online posts showing data tables from the World Integrated Trade Solutions (WITS) website, developed by the World Bank and other organizations, which "allows users to access and retrieve information on trade and tariffs."</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="200" end_char="205">Claims</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="207" end_char="210">that</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="212" end_char="214">the</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="216" end_char="226">coronavirus</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="228" end_char="235">pandemic</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="237" end_char="239">was</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="241" end_char="247">planned</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="249" end_char="251">has</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="253" end_char="256">been</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="258" end_char="263">fanned</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="265" end_char="266">by</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="268" end_char="273">online</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="275" end_char="279">posts</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="281" end_char="287">showing</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="289" end_char="292">data</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="294" end_char="299">tables</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="301" end_char="304">from</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="306" end_char="308">the</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="310" end_char="314">World</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="316" end_char="325">Integrated</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="327" end_char="331">Trade</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="333" end_char="341">Solutions</TOKEN>
<TOKEN id="token-2-22" pos="punct" morph="none" start_char="343" end_char="343">(</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="344" end_char="347">WITS</TOKEN>
<TOKEN id="token-2-24" pos="punct" morph="none" start_char="348" end_char="348">)</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="350" end_char="356">website</TOKEN>
<TOKEN id="token-2-26" pos="punct" morph="none" start_char="357" end_char="357">,</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="359" end_char="367">developed</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="369" end_char="370">by</TOKEN>
<TOKEN id="token-2-29" pos="word" morph="none" start_char="372" end_char="374">the</TOKEN>
<TOKEN id="token-2-30" pos="word" morph="none" start_char="376" end_char="380">World</TOKEN>
<TOKEN id="token-2-31" pos="word" morph="none" start_char="382" end_char="385">Bank</TOKEN>
<TOKEN id="token-2-32" pos="word" morph="none" start_char="387" end_char="389">and</TOKEN>
<TOKEN id="token-2-33" pos="word" morph="none" start_char="391" end_char="395">other</TOKEN>
<TOKEN id="token-2-34" pos="word" morph="none" start_char="397" end_char="409">organizations</TOKEN>
<TOKEN id="token-2-35" pos="punct" morph="none" start_char="410" end_char="410">,</TOKEN>
<TOKEN id="token-2-36" pos="word" morph="none" start_char="412" end_char="416">which</TOKEN>
<TOKEN id="token-2-37" pos="punct" morph="none" start_char="418" end_char="418">"</TOKEN>
<TOKEN id="token-2-38" pos="word" morph="none" start_char="419" end_char="424">allows</TOKEN>
<TOKEN id="token-2-39" pos="word" morph="none" start_char="426" end_char="430">users</TOKEN>
<TOKEN id="token-2-40" pos="word" morph="none" start_char="432" end_char="433">to</TOKEN>
<TOKEN id="token-2-41" pos="word" morph="none" start_char="435" end_char="440">access</TOKEN>
<TOKEN id="token-2-42" pos="word" morph="none" start_char="442" end_char="444">and</TOKEN>
<TOKEN id="token-2-43" pos="word" morph="none" start_char="446" end_char="453">retrieve</TOKEN>
<TOKEN id="token-2-44" pos="word" morph="none" start_char="455" end_char="465">information</TOKEN>
<TOKEN id="token-2-45" pos="word" morph="none" start_char="467" end_char="468">on</TOKEN>
<TOKEN id="token-2-46" pos="word" morph="none" start_char="470" end_char="474">trade</TOKEN>
<TOKEN id="token-2-47" pos="word" morph="none" start_char="476" end_char="478">and</TOKEN>
<TOKEN id="token-2-48" pos="word" morph="none" start_char="480" end_char="486">tariffs</TOKEN>
<TOKEN id="token-2-49" pos="punct" morph="none" start_char="487" end_char="488">."</TOKEN>
</SEG>
<SEG id="segment-3" start_char="490" end_char="702">
<ORIGINAL_TEXT>These tables appear to report that COVID-19 test kits were already being sold in 2017 and 2018 (archived here and here, respectively), which contradicts our present understanding that the pandemic started in 2019.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="490" end_char="494">These</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="496" end_char="501">tables</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="503" end_char="508">appear</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="510" end_char="511">to</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="513" end_char="518">report</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="520" end_char="523">that</TOKEN>
<TOKEN id="token-3-6" pos="unknown" morph="none" start_char="525" end_char="532">COVID-19</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="534" end_char="537">test</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="539" end_char="542">kits</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="544" end_char="547">were</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="549" end_char="555">already</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="557" end_char="561">being</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="563" end_char="566">sold</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="568" end_char="569">in</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="571" end_char="574">2017</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="576" end_char="578">and</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="580" end_char="583">2018</TOKEN>
<TOKEN id="token-3-17" pos="punct" morph="none" start_char="585" end_char="585">(</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="586" end_char="593">archived</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="595" end_char="598">here</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="600" end_char="602">and</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="604" end_char="607">here</TOKEN>
<TOKEN id="token-3-22" pos="punct" morph="none" start_char="608" end_char="608">,</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="610" end_char="621">respectively</TOKEN>
<TOKEN id="token-3-24" pos="punct" morph="none" start_char="622" end_char="623">),</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="625" end_char="629">which</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="631" end_char="641">contradicts</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="643" end_char="645">our</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="647" end_char="653">present</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="655" end_char="667">understanding</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="669" end_char="672">that</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="674" end_char="676">the</TOKEN>
<TOKEN id="token-3-32" pos="word" morph="none" start_char="678" end_char="685">pandemic</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="687" end_char="693">started</TOKEN>
<TOKEN id="token-3-34" pos="word" morph="none" start_char="695" end_char="696">in</TOKEN>
<TOKEN id="token-3-35" pos="word" morph="none" start_char="698" end_char="701">2019</TOKEN>
<TOKEN id="token-3-36" pos="punct" morph="none" start_char="702" end_char="702">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="704" end_char="813">
<ORIGINAL_TEXT>The claim was posted on the imageboard 4chan on 5 September 2020 and was also shared by Ben Swann on Facebook.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="704" end_char="706">The</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="708" end_char="712">claim</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="714" end_char="716">was</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="718" end_char="723">posted</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="725" end_char="726">on</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="728" end_char="730">the</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="732" end_char="741">imageboard</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="743" end_char="747">4chan</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="749" end_char="750">on</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="752" end_char="752">5</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="754" end_char="762">September</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="764" end_char="767">2020</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="769" end_char="771">and</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="773" end_char="775">was</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="777" end_char="780">also</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="782" end_char="787">shared</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="789" end_char="790">by</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="792" end_char="794">Ben</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="796" end_char="800">Swann</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="802" end_char="803">on</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="805" end_char="812">Facebook</TOKEN>
<TOKEN id="token-4-21" pos="punct" morph="none" start_char="813" end_char="813">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="816" end_char="981">
<ORIGINAL_TEXT>However, as we explain below, this claim is based on a misunderstanding of how the system used to track exports and imports, called the Harmonized System (HS), works.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="816" end_char="822">However</TOKEN>
<TOKEN id="token-5-1" pos="punct" morph="none" start_char="823" end_char="823">,</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="825" end_char="826">as</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="828" end_char="829">we</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="831" end_char="837">explain</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="839" end_char="843">below</TOKEN>
<TOKEN id="token-5-6" pos="punct" morph="none" start_char="844" end_char="844">,</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="846" end_char="849">this</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="851" end_char="855">claim</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="857" end_char="858">is</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="860" end_char="864">based</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="866" end_char="867">on</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="869" end_char="869">a</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="871" end_char="886">misunderstanding</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="888" end_char="889">of</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="891" end_char="893">how</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="895" end_char="897">the</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="899" end_char="904">system</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="906" end_char="909">used</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="911" end_char="912">to</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="914" end_char="918">track</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="920" end_char="926">exports</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="928" end_char="930">and</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="932" end_char="938">imports</TOKEN>
<TOKEN id="token-5-24" pos="punct" morph="none" start_char="939" end_char="939">,</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="941" end_char="946">called</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="948" end_char="950">the</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="952" end_char="961">Harmonized</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="963" end_char="968">System</TOKEN>
<TOKEN id="token-5-29" pos="punct" morph="none" start_char="970" end_char="970">(</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="971" end_char="972">HS</TOKEN>
<TOKEN id="token-5-31" pos="punct" morph="none" start_char="973" end_char="974">),</TOKEN>
<TOKEN id="token-5-32" pos="word" morph="none" start_char="976" end_char="980">works</TOKEN>
<TOKEN id="token-5-33" pos="punct" morph="none" start_char="981" end_char="981">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="983" end_char="1076">
<ORIGINAL_TEXT>And it is likely little more than the result of an error in data labeling on the WITS website.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="983" end_char="985">And</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="987" end_char="988">it</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="990" end_char="991">is</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="993" end_char="998">likely</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="1000" end_char="1005">little</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="1007" end_char="1010">more</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="1012" end_char="1015">than</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="1017" end_char="1019">the</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="1021" end_char="1026">result</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="1028" end_char="1029">of</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="1031" end_char="1032">an</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="1034" end_char="1038">error</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="1040" end_char="1041">in</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="1043" end_char="1046">data</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="1048" end_char="1055">labeling</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="1057" end_char="1058">on</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="1060" end_char="1062">the</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="1064" end_char="1067">WITS</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="1069" end_char="1075">website</TOKEN>
<TOKEN id="token-6-19" pos="punct" morph="none" start_char="1076" end_char="1076">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="1078" end_char="1122">
<ORIGINAL_TEXT>According to the U.S. Department of Commerce:</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="1078" end_char="1086">According</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="1088" end_char="1089">to</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="1091" end_char="1093">the</TOKEN>
<TOKEN id="token-7-3" pos="unknown" morph="none" start_char="1095" end_char="1097">U.S</TOKEN>
<TOKEN id="token-7-4" pos="punct" morph="none" start_char="1098" end_char="1098">.</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="1100" end_char="1109">Department</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="1111" end_char="1112">of</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="1114" end_char="1121">Commerce</TOKEN>
<TOKEN id="token-7-8" pos="punct" morph="none" start_char="1122" end_char="1122">:</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1125" end_char="1125">
<ORIGINAL_TEXT>"</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="punct" morph="none" start_char="1125" end_char="1125">"</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1128" end_char="1253">
<ORIGINAL_TEXT>Among industry classification systems, Harmonized System (HS) Codes are commonly used throughout the export process for goods.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1128" end_char="1132">Among</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1134" end_char="1141">industry</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1143" end_char="1156">classification</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1158" end_char="1164">systems</TOKEN>
<TOKEN id="token-9-4" pos="punct" morph="none" start_char="1165" end_char="1165">,</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1167" end_char="1176">Harmonized</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1178" end_char="1183">System</TOKEN>
<TOKEN id="token-9-7" pos="punct" morph="none" start_char="1185" end_char="1185">(</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1186" end_char="1187">HS</TOKEN>
<TOKEN id="token-9-9" pos="punct" morph="none" start_char="1188" end_char="1188">)</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1190" end_char="1194">Codes</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1196" end_char="1198">are</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1200" end_char="1207">commonly</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1209" end_char="1212">used</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1214" end_char="1223">throughout</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1225" end_char="1227">the</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1229" end_char="1234">export</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1236" end_char="1242">process</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1244" end_char="1246">for</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1248" end_char="1252">goods</TOKEN>
<TOKEN id="token-9-20" pos="punct" morph="none" start_char="1253" end_char="1253">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1255" end_char="1342">
<ORIGINAL_TEXT>The Harmonized System is a standardized numerical method of classifying traded products.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1255" end_char="1257">The</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1259" end_char="1268">Harmonized</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1270" end_char="1275">System</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1277" end_char="1278">is</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1280" end_char="1280">a</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1282" end_char="1293">standardized</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1295" end_char="1303">numerical</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1305" end_char="1310">method</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1312" end_char="1313">of</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1315" end_char="1325">classifying</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1327" end_char="1332">traded</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1334" end_char="1341">products</TOKEN>
<TOKEN id="token-10-12" pos="punct" morph="none" start_char="1342" end_char="1342">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1344" end_char="1476">
<ORIGINAL_TEXT>It is used by customs authorities around the world to identify products when assessing duties and taxes and for gathering statistics.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1344" end_char="1345">It</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1347" end_char="1348">is</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1350" end_char="1353">used</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1355" end_char="1356">by</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1358" end_char="1364">customs</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1366" end_char="1376">authorities</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1378" end_char="1383">around</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1385" end_char="1387">the</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1389" end_char="1393">world</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1395" end_char="1396">to</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1398" end_char="1405">identify</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1407" end_char="1414">products</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1416" end_char="1419">when</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1421" end_char="1429">assessing</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1431" end_char="1436">duties</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1438" end_char="1440">and</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1442" end_char="1446">taxes</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1448" end_char="1450">and</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1452" end_char="1454">for</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="1456" end_char="1464">gathering</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1466" end_char="1475">statistics</TOKEN>
<TOKEN id="token-11-21" pos="punct" morph="none" start_char="1476" end_char="1476">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1480" end_char="1575">
<ORIGINAL_TEXT>The HS is administrated by the World Customs Organization (WCO) and is updated every five years.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1480" end_char="1482">The</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1484" end_char="1485">HS</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1487" end_char="1488">is</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1490" end_char="1502">administrated</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1504" end_char="1505">by</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1507" end_char="1509">the</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1511" end_char="1515">World</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1517" end_char="1523">Customs</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1525" end_char="1536">Organization</TOKEN>
<TOKEN id="token-12-9" pos="punct" morph="none" start_char="1538" end_char="1538">(</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1539" end_char="1541">WCO</TOKEN>
<TOKEN id="token-12-11" pos="punct" morph="none" start_char="1542" end_char="1542">)</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1544" end_char="1546">and</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1548" end_char="1549">is</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1551" end_char="1557">updated</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1559" end_char="1563">every</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1565" end_char="1568">five</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1570" end_char="1574">years</TOKEN>
<TOKEN id="token-12-18" pos="punct" morph="none" start_char="1575" end_char="1575">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1577" end_char="1708">
<ORIGINAL_TEXT>It serves as the foundation for the import and export classification systems used in the United States and by many trading partners.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1577" end_char="1578">It</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1580" end_char="1585">serves</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1587" end_char="1588">as</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1590" end_char="1592">the</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1594" end_char="1603">foundation</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1605" end_char="1607">for</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1609" end_char="1611">the</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1613" end_char="1618">import</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1620" end_char="1622">and</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1624" end_char="1629">export</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1631" end_char="1644">classification</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1646" end_char="1652">systems</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1654" end_char="1657">used</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1659" end_char="1660">in</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1662" end_char="1664">the</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1666" end_char="1671">United</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1673" end_char="1678">States</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1680" end_char="1682">and</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1684" end_char="1685">by</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1687" end_char="1690">many</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1692" end_char="1698">trading</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="1700" end_char="1707">partners</TOKEN>
<TOKEN id="token-13-22" pos="punct" morph="none" start_char="1708" end_char="1708">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1711" end_char="1711">
<ORIGINAL_TEXT>"</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="punct" morph="none" start_char="1711" end_char="1711">"</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1715" end_char="1804">
<ORIGINAL_TEXT>Swann’s Facebook post shows that the HS code associated with COVID-19 test kits is 382200.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1715" end_char="1721">Swann’s</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1723" end_char="1730">Facebook</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1732" end_char="1735">post</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1737" end_char="1741">shows</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1743" end_char="1746">that</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1748" end_char="1750">the</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1752" end_char="1753">HS</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1755" end_char="1758">code</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1760" end_char="1769">associated</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1771" end_char="1774">with</TOKEN>
<TOKEN id="token-15-10" pos="unknown" morph="none" start_char="1776" end_char="1783">COVID-19</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1785" end_char="1788">test</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1790" end_char="1793">kits</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1795" end_char="1796">is</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1798" end_char="1803">382200</TOKEN>
<TOKEN id="token-15-15" pos="punct" morph="none" start_char="1804" end_char="1804">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1806" end_char="2013">
<ORIGINAL_TEXT>The assignment of this code to COVID-19 test kits was established in the HS classification reference for COVID-19 medical supplies, jointly issued on 9 April 2020 by the WCO and the World Health Organization.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1806" end_char="1808">The</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1810" end_char="1819">assignment</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1821" end_char="1822">of</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1824" end_char="1827">this</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1829" end_char="1832">code</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1834" end_char="1835">to</TOKEN>
<TOKEN id="token-16-6" pos="unknown" morph="none" start_char="1837" end_char="1844">COVID-19</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1846" end_char="1849">test</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1851" end_char="1854">kits</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="1856" end_char="1858">was</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="1860" end_char="1870">established</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="1872" end_char="1873">in</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="1875" end_char="1877">the</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="1879" end_char="1880">HS</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="1882" end_char="1895">classification</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="1897" end_char="1905">reference</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="1907" end_char="1909">for</TOKEN>
<TOKEN id="token-16-17" pos="unknown" morph="none" start_char="1911" end_char="1918">COVID-19</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="1920" end_char="1926">medical</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="1928" end_char="1935">supplies</TOKEN>
<TOKEN id="token-16-20" pos="punct" morph="none" start_char="1936" end_char="1936">,</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="1938" end_char="1944">jointly</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="1946" end_char="1951">issued</TOKEN>
<TOKEN id="token-16-23" pos="word" morph="none" start_char="1953" end_char="1954">on</TOKEN>
<TOKEN id="token-16-24" pos="word" morph="none" start_char="1956" end_char="1956">9</TOKEN>
<TOKEN id="token-16-25" pos="word" morph="none" start_char="1958" end_char="1962">April</TOKEN>
<TOKEN id="token-16-26" pos="word" morph="none" start_char="1964" end_char="1967">2020</TOKEN>
<TOKEN id="token-16-27" pos="word" morph="none" start_char="1969" end_char="1970">by</TOKEN>
<TOKEN id="token-16-28" pos="word" morph="none" start_char="1972" end_char="1974">the</TOKEN>
<TOKEN id="token-16-29" pos="word" morph="none" start_char="1976" end_char="1978">WCO</TOKEN>
<TOKEN id="token-16-30" pos="word" morph="none" start_char="1980" end_char="1982">and</TOKEN>
<TOKEN id="token-16-31" pos="word" morph="none" start_char="1984" end_char="1986">the</TOKEN>
<TOKEN id="token-16-32" pos="word" morph="none" start_char="1988" end_char="1992">World</TOKEN>
<TOKEN id="token-16-33" pos="word" morph="none" start_char="1994" end_char="1999">Health</TOKEN>
<TOKEN id="token-16-34" pos="word" morph="none" start_char="2001" end_char="2012">Organization</TOKEN>
<TOKEN id="token-16-35" pos="punct" morph="none" start_char="2013" end_char="2013">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2015" end_char="2123">
<ORIGINAL_TEXT>The reference also explains that this code is based on a pre-existing HS classification from 2017 (Figure 1).</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2015" end_char="2017">The</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2019" end_char="2027">reference</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2029" end_char="2032">also</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2034" end_char="2041">explains</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2043" end_char="2046">that</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2048" end_char="2051">this</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2053" end_char="2056">code</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2058" end_char="2059">is</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2061" end_char="2065">based</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2067" end_char="2068">on</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2070" end_char="2070">a</TOKEN>
<TOKEN id="token-17-11" pos="unknown" morph="none" start_char="2072" end_char="2083">pre-existing</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2085" end_char="2086">HS</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2088" end_char="2101">classification</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2103" end_char="2106">from</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2108" end_char="2111">2017</TOKEN>
<TOKEN id="token-17-16" pos="punct" morph="none" start_char="2113" end_char="2113">(</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="2114" end_char="2119">Figure</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="2121" end_char="2121">1</TOKEN>
<TOKEN id="token-17-19" pos="punct" morph="none" start_char="2122" end_char="2123">).</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2125" end_char="2203">
<ORIGINAL_TEXT>Therefore, the HS code 382200 was already in use two years before the pandemic.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2125" end_char="2133">Therefore</TOKEN>
<TOKEN id="token-18-1" pos="punct" morph="none" start_char="2134" end_char="2134">,</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2136" end_char="2138">the</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2140" end_char="2141">HS</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2143" end_char="2146">code</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2148" end_char="2153">382200</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2155" end_char="2157">was</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2159" end_char="2165">already</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2167" end_char="2168">in</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="2170" end_char="2172">use</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="2174" end_char="2176">two</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="2178" end_char="2182">years</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2184" end_char="2189">before</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="2191" end_char="2193">the</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="2195" end_char="2202">pandemic</TOKEN>
<TOKEN id="token-18-15" pos="punct" morph="none" start_char="2203" end_char="2203">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2206" end_char="2214">
<ORIGINAL_TEXT>Figure 1.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2206" end_char="2211">Figure</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2213" end_char="2213">1</TOKEN>
<TOKEN id="token-19-2" pos="punct" morph="none" start_char="2214" end_char="2214">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2216" end_char="2302">
<ORIGINAL_TEXT>Screenshot of a table in the HS classification reference for COVID-19 medical supplies.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2216" end_char="2225">Screenshot</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2227" end_char="2228">of</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2230" end_char="2230">a</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2232" end_char="2236">table</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2238" end_char="2239">in</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2241" end_char="2243">the</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2245" end_char="2246">HS</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2248" end_char="2261">classification</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="2263" end_char="2271">reference</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2273" end_char="2275">for</TOKEN>
<TOKEN id="token-20-10" pos="unknown" morph="none" start_char="2277" end_char="2284">COVID-19</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="2286" end_char="2292">medical</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="2294" end_char="2301">supplies</TOKEN>
<TOKEN id="token-20-13" pos="punct" morph="none" start_char="2302" end_char="2302">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2304" end_char="2387">
<ORIGINAL_TEXT>Note that COVID-19 test kits come under a pre-existing HS code set in 2017 (in red).</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2304" end_char="2307">Note</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2309" end_char="2312">that</TOKEN>
<TOKEN id="token-21-2" pos="unknown" morph="none" start_char="2314" end_char="2321">COVID-19</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2323" end_char="2326">test</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2328" end_char="2331">kits</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="2333" end_char="2336">come</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2338" end_char="2342">under</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="2344" end_char="2344">a</TOKEN>
<TOKEN id="token-21-8" pos="unknown" morph="none" start_char="2346" end_char="2357">pre-existing</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="2359" end_char="2360">HS</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="2362" end_char="2365">code</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="2367" end_char="2369">set</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="2371" end_char="2372">in</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="2374" end_char="2377">2017</TOKEN>
<TOKEN id="token-21-14" pos="punct" morph="none" start_char="2379" end_char="2379">(</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="2380" end_char="2381">in</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="2383" end_char="2385">red</TOKEN>
<TOKEN id="token-21-17" pos="punct" morph="none" start_char="2386" end_char="2387">).</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2391" end_char="2494">
<ORIGINAL_TEXT>The code is associated with medical test kits in general and is not specific to COVID-19 test kits only.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2391" end_char="2393">The</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2395" end_char="2398">code</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2400" end_char="2401">is</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2403" end_char="2412">associated</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2414" end_char="2417">with</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2419" end_char="2425">medical</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2427" end_char="2430">test</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2432" end_char="2435">kits</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="2437" end_char="2438">in</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="2440" end_char="2446">general</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="2448" end_char="2450">and</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="2452" end_char="2453">is</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="2455" end_char="2457">not</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="2459" end_char="2466">specific</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="2468" end_char="2469">to</TOKEN>
<TOKEN id="token-22-15" pos="unknown" morph="none" start_char="2471" end_char="2478">COVID-19</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="2480" end_char="2483">test</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="2485" end_char="2488">kits</TOKEN>
<TOKEN id="token-22-18" pos="word" morph="none" start_char="2490" end_char="2493">only</TOKEN>
<TOKEN id="token-22-19" pos="punct" morph="none" start_char="2494" end_char="2494">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2496" end_char="2741">
<ORIGINAL_TEXT>This is demonstrated by the WITS pages which display all imports by country under the code 388200 (2017 and 2018), showing that the data displayed pertains to "Reagents; composite diagnostic or laboratory reagents, other than those of heading no.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2496" end_char="2499">This</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2501" end_char="2502">is</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2504" end_char="2515">demonstrated</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2517" end_char="2518">by</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="2520" end_char="2522">the</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="2524" end_char="2527">WITS</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="2529" end_char="2533">pages</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="2535" end_char="2539">which</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="2541" end_char="2547">display</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="2549" end_char="2551">all</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="2553" end_char="2559">imports</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="2561" end_char="2562">by</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="2564" end_char="2570">country</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="2572" end_char="2576">under</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="2578" end_char="2580">the</TOKEN>
<TOKEN id="token-23-15" pos="word" morph="none" start_char="2582" end_char="2585">code</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="2587" end_char="2592">388200</TOKEN>
<TOKEN id="token-23-17" pos="punct" morph="none" start_char="2594" end_char="2594">(</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="2595" end_char="2598">2017</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="2600" end_char="2602">and</TOKEN>
<TOKEN id="token-23-20" pos="word" morph="none" start_char="2604" end_char="2607">2018</TOKEN>
<TOKEN id="token-23-21" pos="punct" morph="none" start_char="2608" end_char="2609">),</TOKEN>
<TOKEN id="token-23-22" pos="word" morph="none" start_char="2611" end_char="2617">showing</TOKEN>
<TOKEN id="token-23-23" pos="word" morph="none" start_char="2619" end_char="2622">that</TOKEN>
<TOKEN id="token-23-24" pos="word" morph="none" start_char="2624" end_char="2626">the</TOKEN>
<TOKEN id="token-23-25" pos="word" morph="none" start_char="2628" end_char="2631">data</TOKEN>
<TOKEN id="token-23-26" pos="word" morph="none" start_char="2633" end_char="2641">displayed</TOKEN>
<TOKEN id="token-23-27" pos="word" morph="none" start_char="2643" end_char="2650">pertains</TOKEN>
<TOKEN id="token-23-28" pos="word" morph="none" start_char="2652" end_char="2653">to</TOKEN>
<TOKEN id="token-23-29" pos="punct" morph="none" start_char="2655" end_char="2655">"</TOKEN>
<TOKEN id="token-23-30" pos="word" morph="none" start_char="2656" end_char="2663">Reagents</TOKEN>
<TOKEN id="token-23-31" pos="punct" morph="none" start_char="2664" end_char="2664">;</TOKEN>
<TOKEN id="token-23-32" pos="word" morph="none" start_char="2666" end_char="2674">composite</TOKEN>
<TOKEN id="token-23-33" pos="word" morph="none" start_char="2676" end_char="2685">diagnostic</TOKEN>
<TOKEN id="token-23-34" pos="word" morph="none" start_char="2687" end_char="2688">or</TOKEN>
<TOKEN id="token-23-35" pos="word" morph="none" start_char="2690" end_char="2699">laboratory</TOKEN>
<TOKEN id="token-23-36" pos="word" morph="none" start_char="2701" end_char="2708">reagents</TOKEN>
<TOKEN id="token-23-37" pos="punct" morph="none" start_char="2709" end_char="2709">,</TOKEN>
<TOKEN id="token-23-38" pos="word" morph="none" start_char="2711" end_char="2715">other</TOKEN>
<TOKEN id="token-23-39" pos="word" morph="none" start_char="2717" end_char="2720">than</TOKEN>
<TOKEN id="token-23-40" pos="word" morph="none" start_char="2722" end_char="2726">those</TOKEN>
<TOKEN id="token-23-41" pos="word" morph="none" start_char="2728" end_char="2729">of</TOKEN>
<TOKEN id="token-23-42" pos="word" morph="none" start_char="2731" end_char="2737">heading</TOKEN>
<TOKEN id="token-23-43" pos="word" morph="none" start_char="2739" end_char="2740">no</TOKEN>
<TOKEN id="token-23-44" pos="punct" morph="none" start_char="2741" end_char="2741">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2743" end_char="2767">
<ORIGINAL_TEXT>3002 or 3006" (Figure 2).</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="2743" end_char="2746">3002</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="2748" end_char="2749">or</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="2751" end_char="2754">3006</TOKEN>
<TOKEN id="token-24-3" pos="punct" morph="none" start_char="2755" end_char="2755">"</TOKEN>
<TOKEN id="token-24-4" pos="punct" morph="none" start_char="2757" end_char="2757">(</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="2758" end_char="2763">Figure</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="2765" end_char="2765">2</TOKEN>
<TOKEN id="token-24-7" pos="punct" morph="none" start_char="2766" end_char="2767">).</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2769" end_char="2835">
<ORIGINAL_TEXT>In short, this broad description can apply to any medical test kit.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="2769" end_char="2770">In</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="2772" end_char="2776">short</TOKEN>
<TOKEN id="token-25-2" pos="punct" morph="none" start_char="2777" end_char="2777">,</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="2779" end_char="2782">this</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="2784" end_char="2788">broad</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="2790" end_char="2800">description</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="2802" end_char="2804">can</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="2806" end_char="2810">apply</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="2812" end_char="2813">to</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="2815" end_char="2817">any</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="2819" end_char="2825">medical</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="2827" end_char="2830">test</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="2832" end_char="2834">kit</TOKEN>
<TOKEN id="token-25-13" pos="punct" morph="none" start_char="2835" end_char="2835">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="2838" end_char="2846">
<ORIGINAL_TEXT>Figure 2.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="2838" end_char="2843">Figure</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="2845" end_char="2845">2</TOKEN>
<TOKEN id="token-26-2" pos="punct" morph="none" start_char="2846" end_char="2846">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="2848" end_char="2940">
<ORIGINAL_TEXT>Screenshot of the WITS page which displays all 2017 imports by country under the code 388200.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="2848" end_char="2857">Screenshot</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="2859" end_char="2860">of</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="2862" end_char="2864">the</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="2866" end_char="2869">WITS</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="2871" end_char="2874">page</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="2876" end_char="2880">which</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="2882" end_char="2889">displays</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="2891" end_char="2893">all</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="2895" end_char="2898">2017</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="2900" end_char="2906">imports</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="2908" end_char="2909">by</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="2911" end_char="2917">country</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="2919" end_char="2923">under</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="2925" end_char="2927">the</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="2929" end_char="2932">code</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="2934" end_char="2939">388200</TOKEN>
<TOKEN id="token-27-16" pos="punct" morph="none" start_char="2940" end_char="2940">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="2944" end_char="3216">
<ORIGINAL_TEXT>The code’s association with medical kits in general is corroborated by the Italian news organization Open, which reported in their fact-check of the same claim that the code 382200 can also be found in descriptions of a kit that processes semen and a test kit for detecting</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="2944" end_char="2946">The</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="2948" end_char="2953">code’s</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="2955" end_char="2965">association</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="2967" end_char="2970">with</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="2972" end_char="2978">medical</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="2980" end_char="2983">kits</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="2985" end_char="2986">in</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="2988" end_char="2994">general</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="2996" end_char="2997">is</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="2999" end_char="3010">corroborated</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="3012" end_char="3013">by</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="3015" end_char="3017">the</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="3019" end_char="3025">Italian</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="3027" end_char="3030">news</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="3032" end_char="3043">organization</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="3045" end_char="3048">Open</TOKEN>
<TOKEN id="token-28-16" pos="punct" morph="none" start_char="3049" end_char="3049">,</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="3051" end_char="3055">which</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="3057" end_char="3064">reported</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="3066" end_char="3067">in</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="3069" end_char="3073">their</TOKEN>
<TOKEN id="token-28-21" pos="unknown" morph="none" start_char="3075" end_char="3084">fact-check</TOKEN>
<TOKEN id="token-28-22" pos="word" morph="none" start_char="3086" end_char="3087">of</TOKEN>
<TOKEN id="token-28-23" pos="word" morph="none" start_char="3089" end_char="3091">the</TOKEN>
<TOKEN id="token-28-24" pos="word" morph="none" start_char="3093" end_char="3096">same</TOKEN>
<TOKEN id="token-28-25" pos="word" morph="none" start_char="3098" end_char="3102">claim</TOKEN>
<TOKEN id="token-28-26" pos="word" morph="none" start_char="3104" end_char="3107">that</TOKEN>
<TOKEN id="token-28-27" pos="word" morph="none" start_char="3109" end_char="3111">the</TOKEN>
<TOKEN id="token-28-28" pos="word" morph="none" start_char="3113" end_char="3116">code</TOKEN>
<TOKEN id="token-28-29" pos="word" morph="none" start_char="3118" end_char="3123">382200</TOKEN>
<TOKEN id="token-28-30" pos="word" morph="none" start_char="3125" end_char="3127">can</TOKEN>
<TOKEN id="token-28-31" pos="word" morph="none" start_char="3129" end_char="3132">also</TOKEN>
<TOKEN id="token-28-32" pos="word" morph="none" start_char="3134" end_char="3135">be</TOKEN>
<TOKEN id="token-28-33" pos="word" morph="none" start_char="3137" end_char="3141">found</TOKEN>
<TOKEN id="token-28-34" pos="word" morph="none" start_char="3143" end_char="3144">in</TOKEN>
<TOKEN id="token-28-35" pos="word" morph="none" start_char="3146" end_char="3157">descriptions</TOKEN>
<TOKEN id="token-28-36" pos="word" morph="none" start_char="3159" end_char="3160">of</TOKEN>
<TOKEN id="token-28-37" pos="word" morph="none" start_char="3162" end_char="3162">a</TOKEN>
<TOKEN id="token-28-38" pos="word" morph="none" start_char="3164" end_char="3166">kit</TOKEN>
<TOKEN id="token-28-39" pos="word" morph="none" start_char="3168" end_char="3171">that</TOKEN>
<TOKEN id="token-28-40" pos="word" morph="none" start_char="3173" end_char="3181">processes</TOKEN>
<TOKEN id="token-28-41" pos="word" morph="none" start_char="3183" end_char="3187">semen</TOKEN>
<TOKEN id="token-28-42" pos="word" morph="none" start_char="3189" end_char="3191">and</TOKEN>
<TOKEN id="token-28-43" pos="word" morph="none" start_char="3193" end_char="3193">a</TOKEN>
<TOKEN id="token-28-44" pos="word" morph="none" start_char="3195" end_char="3198">test</TOKEN>
<TOKEN id="token-28-45" pos="word" morph="none" start_char="3200" end_char="3202">kit</TOKEN>
<TOKEN id="token-28-46" pos="word" morph="none" start_char="3204" end_char="3206">for</TOKEN>
<TOKEN id="token-28-47" pos="word" morph="none" start_char="3208" end_char="3216">detecting</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3219" end_char="3230">
<ORIGINAL_TEXT>Cryptococcus</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="3219" end_char="3230">Cryptococcus</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3233" end_char="3259">
<ORIGINAL_TEXT>, a disease-causing fungus.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="punct" morph="none" start_char="3233" end_char="3233">,</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="3235" end_char="3235">a</TOKEN>
<TOKEN id="token-30-2" pos="unknown" morph="none" start_char="3237" end_char="3251">disease-causing</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="3253" end_char="3258">fungus</TOKEN>
<TOKEN id="token-30-4" pos="punct" morph="none" start_char="3259" end_char="3259">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="3261" end_char="3494">
<ORIGINAL_TEXT>All of this information together indicates that the data tables for 2017 and 2018, which supposedly apply to COVID-19 test kits, are actually displaying information about previously existing medical test kits from before the pandemic.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="3261" end_char="3263">All</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="3265" end_char="3266">of</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="3268" end_char="3271">this</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="3273" end_char="3283">information</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="3285" end_char="3292">together</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="3294" end_char="3302">indicates</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="3304" end_char="3307">that</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="3309" end_char="3311">the</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="3313" end_char="3316">data</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="3318" end_char="3323">tables</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="3325" end_char="3327">for</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="3329" end_char="3332">2017</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="3334" end_char="3336">and</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="3338" end_char="3341">2018</TOKEN>
<TOKEN id="token-31-14" pos="punct" morph="none" start_char="3342" end_char="3342">,</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="3344" end_char="3348">which</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="3350" end_char="3359">supposedly</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="3361" end_char="3365">apply</TOKEN>
<TOKEN id="token-31-18" pos="word" morph="none" start_char="3367" end_char="3368">to</TOKEN>
<TOKEN id="token-31-19" pos="unknown" morph="none" start_char="3370" end_char="3377">COVID-19</TOKEN>
<TOKEN id="token-31-20" pos="word" morph="none" start_char="3379" end_char="3382">test</TOKEN>
<TOKEN id="token-31-21" pos="word" morph="none" start_char="3384" end_char="3387">kits</TOKEN>
<TOKEN id="token-31-22" pos="punct" morph="none" start_char="3388" end_char="3388">,</TOKEN>
<TOKEN id="token-31-23" pos="word" morph="none" start_char="3390" end_char="3392">are</TOKEN>
<TOKEN id="token-31-24" pos="word" morph="none" start_char="3394" end_char="3401">actually</TOKEN>
<TOKEN id="token-31-25" pos="word" morph="none" start_char="3403" end_char="3412">displaying</TOKEN>
<TOKEN id="token-31-26" pos="word" morph="none" start_char="3414" end_char="3424">information</TOKEN>
<TOKEN id="token-31-27" pos="word" morph="none" start_char="3426" end_char="3430">about</TOKEN>
<TOKEN id="token-31-28" pos="word" morph="none" start_char="3432" end_char="3441">previously</TOKEN>
<TOKEN id="token-31-29" pos="word" morph="none" start_char="3443" end_char="3450">existing</TOKEN>
<TOKEN id="token-31-30" pos="word" morph="none" start_char="3452" end_char="3458">medical</TOKEN>
<TOKEN id="token-31-31" pos="word" morph="none" start_char="3460" end_char="3463">test</TOKEN>
<TOKEN id="token-31-32" pos="word" morph="none" start_char="3465" end_char="3468">kits</TOKEN>
<TOKEN id="token-31-33" pos="word" morph="none" start_char="3470" end_char="3473">from</TOKEN>
<TOKEN id="token-31-34" pos="word" morph="none" start_char="3475" end_char="3480">before</TOKEN>
<TOKEN id="token-31-35" pos="word" morph="none" start_char="3482" end_char="3484">the</TOKEN>
<TOKEN id="token-31-36" pos="word" morph="none" start_char="3486" end_char="3493">pandemic</TOKEN>
<TOKEN id="token-31-37" pos="punct" morph="none" start_char="3494" end_char="3494">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="3497" end_char="3637">
<ORIGINAL_TEXT>The WITS website has since corrected the tables (2017 and 2018) to display "Medical test kits" in the title rather than "COVID-19 test kits".</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="3497" end_char="3499">The</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="3501" end_char="3504">WITS</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="3506" end_char="3512">website</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="3514" end_char="3516">has</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="3518" end_char="3522">since</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="3524" end_char="3532">corrected</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="3534" end_char="3536">the</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="3538" end_char="3543">tables</TOKEN>
<TOKEN id="token-32-8" pos="punct" morph="none" start_char="3545" end_char="3545">(</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="3546" end_char="3549">2017</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="3551" end_char="3553">and</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="3555" end_char="3558">2018</TOKEN>
<TOKEN id="token-32-12" pos="punct" morph="none" start_char="3559" end_char="3559">)</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="3561" end_char="3562">to</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="3564" end_char="3570">display</TOKEN>
<TOKEN id="token-32-15" pos="punct" morph="none" start_char="3572" end_char="3572">"</TOKEN>
<TOKEN id="token-32-16" pos="word" morph="none" start_char="3573" end_char="3579">Medical</TOKEN>
<TOKEN id="token-32-17" pos="word" morph="none" start_char="3581" end_char="3584">test</TOKEN>
<TOKEN id="token-32-18" pos="word" morph="none" start_char="3586" end_char="3589">kits</TOKEN>
<TOKEN id="token-32-19" pos="punct" morph="none" start_char="3590" end_char="3590">"</TOKEN>
<TOKEN id="token-32-20" pos="word" morph="none" start_char="3592" end_char="3593">in</TOKEN>
<TOKEN id="token-32-21" pos="word" morph="none" start_char="3595" end_char="3597">the</TOKEN>
<TOKEN id="token-32-22" pos="word" morph="none" start_char="3599" end_char="3603">title</TOKEN>
<TOKEN id="token-32-23" pos="word" morph="none" start_char="3605" end_char="3610">rather</TOKEN>
<TOKEN id="token-32-24" pos="word" morph="none" start_char="3612" end_char="3615">than</TOKEN>
<TOKEN id="token-32-25" pos="punct" morph="none" start_char="3617" end_char="3617">"</TOKEN>
<TOKEN id="token-32-26" pos="unknown" morph="none" start_char="3618" end_char="3625">COVID-19</TOKEN>
<TOKEN id="token-32-27" pos="word" morph="none" start_char="3627" end_char="3630">test</TOKEN>
<TOKEN id="token-32-28" pos="word" morph="none" start_char="3632" end_char="3635">kits</TOKEN>
<TOKEN id="token-32-29" pos="punct" morph="none" start_char="3636" end_char="3637">".</TOKEN>
</SEG>
<SEG id="segment-33" start_char="3639" end_char="3855">
<ORIGINAL_TEXT>It has also been updated to include an explanatory note: "The data here track previously existing medical devices that are now classified by the World Customs Organization as critical to tackling COVID-19" (Figure 3).</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="3639" end_char="3640">It</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="3642" end_char="3644">has</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="3646" end_char="3649">also</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="3651" end_char="3654">been</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="3656" end_char="3662">updated</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="3664" end_char="3665">to</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="3667" end_char="3673">include</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="3675" end_char="3676">an</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="3678" end_char="3688">explanatory</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="3690" end_char="3693">note</TOKEN>
<TOKEN id="token-33-10" pos="punct" morph="none" start_char="3694" end_char="3694">:</TOKEN>
<TOKEN id="token-33-11" pos="punct" morph="none" start_char="3696" end_char="3696">"</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="3697" end_char="3699">The</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="3701" end_char="3704">data</TOKEN>
<TOKEN id="token-33-14" pos="word" morph="none" start_char="3706" end_char="3709">here</TOKEN>
<TOKEN id="token-33-15" pos="word" morph="none" start_char="3711" end_char="3715">track</TOKEN>
<TOKEN id="token-33-16" pos="word" morph="none" start_char="3717" end_char="3726">previously</TOKEN>
<TOKEN id="token-33-17" pos="word" morph="none" start_char="3728" end_char="3735">existing</TOKEN>
<TOKEN id="token-33-18" pos="word" morph="none" start_char="3737" end_char="3743">medical</TOKEN>
<TOKEN id="token-33-19" pos="word" morph="none" start_char="3745" end_char="3751">devices</TOKEN>
<TOKEN id="token-33-20" pos="word" morph="none" start_char="3753" end_char="3756">that</TOKEN>
<TOKEN id="token-33-21" pos="word" morph="none" start_char="3758" end_char="3760">are</TOKEN>
<TOKEN id="token-33-22" pos="word" morph="none" start_char="3762" end_char="3764">now</TOKEN>
<TOKEN id="token-33-23" pos="word" morph="none" start_char="3766" end_char="3775">classified</TOKEN>
<TOKEN id="token-33-24" pos="word" morph="none" start_char="3777" end_char="3778">by</TOKEN>
<TOKEN id="token-33-25" pos="word" morph="none" start_char="3780" end_char="3782">the</TOKEN>
<TOKEN id="token-33-26" pos="word" morph="none" start_char="3784" end_char="3788">World</TOKEN>
<TOKEN id="token-33-27" pos="word" morph="none" start_char="3790" end_char="3796">Customs</TOKEN>
<TOKEN id="token-33-28" pos="word" morph="none" start_char="3798" end_char="3809">Organization</TOKEN>
<TOKEN id="token-33-29" pos="word" morph="none" start_char="3811" end_char="3812">as</TOKEN>
<TOKEN id="token-33-30" pos="word" morph="none" start_char="3814" end_char="3821">critical</TOKEN>
<TOKEN id="token-33-31" pos="word" morph="none" start_char="3823" end_char="3824">to</TOKEN>
<TOKEN id="token-33-32" pos="word" morph="none" start_char="3826" end_char="3833">tackling</TOKEN>
<TOKEN id="token-33-33" pos="unknown" morph="none" start_char="3835" end_char="3842">COVID-19</TOKEN>
<TOKEN id="token-33-34" pos="punct" morph="none" start_char="3843" end_char="3843">"</TOKEN>
<TOKEN id="token-33-35" pos="punct" morph="none" start_char="3845" end_char="3845">(</TOKEN>
<TOKEN id="token-33-36" pos="word" morph="none" start_char="3846" end_char="3851">Figure</TOKEN>
<TOKEN id="token-33-37" pos="word" morph="none" start_char="3853" end_char="3853">3</TOKEN>
<TOKEN id="token-33-38" pos="punct" morph="none" start_char="3854" end_char="3855">).</TOKEN>
</SEG>
<SEG id="segment-34" start_char="3858" end_char="3866">
<ORIGINAL_TEXT>Figure 3.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="3858" end_char="3863">Figure</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="3865" end_char="3865">3</TOKEN>
<TOKEN id="token-34-2" pos="punct" morph="none" start_char="3866" end_char="3866">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="3868" end_char="3968">
<ORIGINAL_TEXT>A comparison of the webpage displayed at this URL address before (top) and after (bottom) the update.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="3868" end_char="3868">A</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="3870" end_char="3879">comparison</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="3881" end_char="3882">of</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="3884" end_char="3886">the</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="3888" end_char="3894">webpage</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="3896" end_char="3904">displayed</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="3906" end_char="3907">at</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="3909" end_char="3912">this</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="3914" end_char="3916">URL</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="3918" end_char="3924">address</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="3926" end_char="3931">before</TOKEN>
<TOKEN id="token-35-11" pos="punct" morph="none" start_char="3933" end_char="3933">(</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="3934" end_char="3936">top</TOKEN>
<TOKEN id="token-35-13" pos="punct" morph="none" start_char="3937" end_char="3937">)</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="3939" end_char="3941">and</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="3943" end_char="3947">after</TOKEN>
<TOKEN id="token-35-16" pos="punct" morph="none" start_char="3949" end_char="3949">(</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="3950" end_char="3955">bottom</TOKEN>
<TOKEN id="token-35-18" pos="punct" morph="none" start_char="3956" end_char="3956">)</TOKEN>
<TOKEN id="token-35-19" pos="word" morph="none" start_char="3958" end_char="3960">the</TOKEN>
<TOKEN id="token-35-20" pos="word" morph="none" start_char="3962" end_char="3967">update</TOKEN>
<TOKEN id="token-35-21" pos="punct" morph="none" start_char="3968" end_char="3968">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="3970" end_char="4021">
<ORIGINAL_TEXT>An archive of the original webpage can be seen here.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="3970" end_char="3971">An</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="3973" end_char="3979">archive</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="3981" end_char="3982">of</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="3984" end_char="3986">the</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="3988" end_char="3995">original</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="3997" end_char="4003">webpage</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="4005" end_char="4007">can</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="4009" end_char="4010">be</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="4012" end_char="4015">seen</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="4017" end_char="4020">here</TOKEN>
<TOKEN id="token-36-10" pos="punct" morph="none" start_char="4021" end_char="4021">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="4025" end_char="4138">
<ORIGINAL_TEXT>Numerous conspiracy theories regarding the origins of the coronavirus began almost as soon as the pandemic itself.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="4025" end_char="4032">Numerous</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="4034" end_char="4043">conspiracy</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="4045" end_char="4052">theories</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="4054" end_char="4062">regarding</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="4064" end_char="4066">the</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="4068" end_char="4074">origins</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="4076" end_char="4077">of</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="4079" end_char="4081">the</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="4083" end_char="4093">coronavirus</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="4095" end_char="4099">began</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="4101" end_char="4106">almost</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="4108" end_char="4109">as</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="4111" end_char="4114">soon</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="4116" end_char="4117">as</TOKEN>
<TOKEN id="token-37-14" pos="word" morph="none" start_char="4119" end_char="4121">the</TOKEN>
<TOKEN id="token-37-15" pos="word" morph="none" start_char="4123" end_char="4130">pandemic</TOKEN>
<TOKEN id="token-37-16" pos="word" morph="none" start_char="4132" end_char="4137">itself</TOKEN>
<TOKEN id="token-37-17" pos="punct" morph="none" start_char="4138" end_char="4138">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="4140" end_char="4275">
<ORIGINAL_TEXT>The persistent claim that the pandemic is a manmade event is based on faulty premises and has been repeatedly debunked by fact-checkers.</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="4140" end_char="4142">The</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="4144" end_char="4153">persistent</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="4155" end_char="4159">claim</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="4161" end_char="4164">that</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="4166" end_char="4168">the</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="4170" end_char="4177">pandemic</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="4179" end_char="4180">is</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="4182" end_char="4182">a</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="4184" end_char="4190">manmade</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="4192" end_char="4196">event</TOKEN>
<TOKEN id="token-38-10" pos="word" morph="none" start_char="4198" end_char="4199">is</TOKEN>
<TOKEN id="token-38-11" pos="word" morph="none" start_char="4201" end_char="4205">based</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="4207" end_char="4208">on</TOKEN>
<TOKEN id="token-38-13" pos="word" morph="none" start_char="4210" end_char="4215">faulty</TOKEN>
<TOKEN id="token-38-14" pos="word" morph="none" start_char="4217" end_char="4224">premises</TOKEN>
<TOKEN id="token-38-15" pos="word" morph="none" start_char="4226" end_char="4228">and</TOKEN>
<TOKEN id="token-38-16" pos="word" morph="none" start_char="4230" end_char="4232">has</TOKEN>
<TOKEN id="token-38-17" pos="word" morph="none" start_char="4234" end_char="4237">been</TOKEN>
<TOKEN id="token-38-18" pos="word" morph="none" start_char="4239" end_char="4248">repeatedly</TOKEN>
<TOKEN id="token-38-19" pos="word" morph="none" start_char="4250" end_char="4257">debunked</TOKEN>
<TOKEN id="token-38-20" pos="word" morph="none" start_char="4259" end_char="4260">by</TOKEN>
<TOKEN id="token-38-21" pos="unknown" morph="none" start_char="4262" end_char="4274">fact-checkers</TOKEN>
<TOKEN id="token-38-22" pos="punct" morph="none" start_char="4275" end_char="4275">.</TOKEN>
</SEG>
<SEG id="segment-39" start_char="4277" end_char="4475">
<ORIGINAL_TEXT>This claim is no different, as these online posts which supposedly provide evidence of a conspiracy are likely founded on an error that led to mislabeled data, which has since been corrected by WITS.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="4277" end_char="4280">This</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="4282" end_char="4286">claim</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="4288" end_char="4289">is</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="4291" end_char="4292">no</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="4294" end_char="4302">different</TOKEN>
<TOKEN id="token-39-5" pos="punct" morph="none" start_char="4303" end_char="4303">,</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="4305" end_char="4306">as</TOKEN>
<TOKEN id="token-39-7" pos="word" morph="none" start_char="4308" end_char="4312">these</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="4314" end_char="4319">online</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="4321" end_char="4325">posts</TOKEN>
<TOKEN id="token-39-10" pos="word" morph="none" start_char="4327" end_char="4331">which</TOKEN>
<TOKEN id="token-39-11" pos="word" morph="none" start_char="4333" end_char="4342">supposedly</TOKEN>
<TOKEN id="token-39-12" pos="word" morph="none" start_char="4344" end_char="4350">provide</TOKEN>
<TOKEN id="token-39-13" pos="word" morph="none" start_char="4352" end_char="4359">evidence</TOKEN>
<TOKEN id="token-39-14" pos="word" morph="none" start_char="4361" end_char="4362">of</TOKEN>
<TOKEN id="token-39-15" pos="word" morph="none" start_char="4364" end_char="4364">a</TOKEN>
<TOKEN id="token-39-16" pos="word" morph="none" start_char="4366" end_char="4375">conspiracy</TOKEN>
<TOKEN id="token-39-17" pos="word" morph="none" start_char="4377" end_char="4379">are</TOKEN>
<TOKEN id="token-39-18" pos="word" morph="none" start_char="4381" end_char="4386">likely</TOKEN>
<TOKEN id="token-39-19" pos="word" morph="none" start_char="4388" end_char="4394">founded</TOKEN>
<TOKEN id="token-39-20" pos="word" morph="none" start_char="4396" end_char="4397">on</TOKEN>
<TOKEN id="token-39-21" pos="word" morph="none" start_char="4399" end_char="4400">an</TOKEN>
<TOKEN id="token-39-22" pos="word" morph="none" start_char="4402" end_char="4406">error</TOKEN>
<TOKEN id="token-39-23" pos="word" morph="none" start_char="4408" end_char="4411">that</TOKEN>
<TOKEN id="token-39-24" pos="word" morph="none" start_char="4413" end_char="4415">led</TOKEN>
<TOKEN id="token-39-25" pos="word" morph="none" start_char="4417" end_char="4418">to</TOKEN>
<TOKEN id="token-39-26" pos="word" morph="none" start_char="4420" end_char="4429">mislabeled</TOKEN>
<TOKEN id="token-39-27" pos="word" morph="none" start_char="4431" end_char="4434">data</TOKEN>
<TOKEN id="token-39-28" pos="punct" morph="none" start_char="4435" end_char="4435">,</TOKEN>
<TOKEN id="token-39-29" pos="word" morph="none" start_char="4437" end_char="4441">which</TOKEN>
<TOKEN id="token-39-30" pos="word" morph="none" start_char="4443" end_char="4445">has</TOKEN>
<TOKEN id="token-39-31" pos="word" morph="none" start_char="4447" end_char="4451">since</TOKEN>
<TOKEN id="token-39-32" pos="word" morph="none" start_char="4453" end_char="4456">been</TOKEN>
<TOKEN id="token-39-33" pos="word" morph="none" start_char="4458" end_char="4466">corrected</TOKEN>
<TOKEN id="token-39-34" pos="word" morph="none" start_char="4468" end_char="4469">by</TOKEN>
<TOKEN id="token-39-35" pos="word" morph="none" start_char="4471" end_char="4474">WITS</TOKEN>
<TOKEN id="token-39-36" pos="punct" morph="none" start_char="4475" end_char="4475">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="4477" end_char="4616">
<ORIGINAL_TEXT>Given that scientists only discovered the virus in early 2020, it is impossible for COVID-19 test kits to have been available two years ago.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="4477" end_char="4481">Given</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="4483" end_char="4486">that</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="4488" end_char="4497">scientists</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="4499" end_char="4502">only</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="4504" end_char="4513">discovered</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="4515" end_char="4517">the</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="4519" end_char="4523">virus</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="4525" end_char="4526">in</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="4528" end_char="4532">early</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="4534" end_char="4537">2020</TOKEN>
<TOKEN id="token-40-10" pos="punct" morph="none" start_char="4538" end_char="4538">,</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="4540" end_char="4541">it</TOKEN>
<TOKEN id="token-40-12" pos="word" morph="none" start_char="4543" end_char="4544">is</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="4546" end_char="4555">impossible</TOKEN>
<TOKEN id="token-40-14" pos="word" morph="none" start_char="4557" end_char="4559">for</TOKEN>
<TOKEN id="token-40-15" pos="unknown" morph="none" start_char="4561" end_char="4568">COVID-19</TOKEN>
<TOKEN id="token-40-16" pos="word" morph="none" start_char="4570" end_char="4573">test</TOKEN>
<TOKEN id="token-40-17" pos="word" morph="none" start_char="4575" end_char="4578">kits</TOKEN>
<TOKEN id="token-40-18" pos="word" morph="none" start_char="4580" end_char="4581">to</TOKEN>
<TOKEN id="token-40-19" pos="word" morph="none" start_char="4583" end_char="4586">have</TOKEN>
<TOKEN id="token-40-20" pos="word" morph="none" start_char="4588" end_char="4591">been</TOKEN>
<TOKEN id="token-40-21" pos="word" morph="none" start_char="4593" end_char="4601">available</TOKEN>
<TOKEN id="token-40-22" pos="word" morph="none" start_char="4603" end_char="4605">two</TOKEN>
<TOKEN id="token-40-23" pos="word" morph="none" start_char="4607" end_char="4611">years</TOKEN>
<TOKEN id="token-40-24" pos="word" morph="none" start_char="4613" end_char="4615">ago</TOKEN>
<TOKEN id="token-40-25" pos="punct" morph="none" start_char="4616" end_char="4616">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
