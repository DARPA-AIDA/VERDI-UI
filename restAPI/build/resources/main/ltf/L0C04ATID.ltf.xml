<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATID" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="2525" raw_text_md5="d70f13a7e983fe3280ef0407507ba438">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="96">
<ORIGINAL_TEXT>¿Es cierto, que existe una variedad de yuca venenosa, que puede ser letal para los seres humano?</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="punct" morph="none" start_char="1" end_char="1">¿</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="2" end_char="3">Es</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="5" end_char="10">cierto</TOKEN>
<TOKEN id="token-0-3" pos="punct" morph="none" start_char="11" end_char="11">,</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="13" end_char="15">que</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="17" end_char="22">existe</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="24" end_char="26">una</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="28" end_char="35">variedad</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="37" end_char="38">de</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="40" end_char="43">yuca</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="45" end_char="52">venenosa</TOKEN>
<TOKEN id="token-0-11" pos="punct" morph="none" start_char="53" end_char="53">,</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="55" end_char="57">que</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="59" end_char="63">puede</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="65" end_char="67">ser</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="69" end_char="73">letal</TOKEN>
<TOKEN id="token-0-16" pos="word" morph="none" start_char="75" end_char="78">para</TOKEN>
<TOKEN id="token-0-17" pos="word" morph="none" start_char="80" end_char="82">los</TOKEN>
<TOKEN id="token-0-18" pos="word" morph="none" start_char="84" end_char="88">seres</TOKEN>
<TOKEN id="token-0-19" pos="word" morph="none" start_char="90" end_char="95">humano</TOKEN>
<TOKEN id="token-0-20" pos="punct" morph="none" start_char="96" end_char="96">?</TOKEN>
</SEG>
<SEG id="segment-1" start_char="98" end_char="165">
<ORIGINAL_TEXT>¿Hay manera de diferenciarla de la yuca buena, que se come a diario?</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="punct" morph="none" start_char="98" end_char="98">¿</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="99" end_char="101">Hay</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="103" end_char="108">manera</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="110" end_char="111">de</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="113" end_char="125">diferenciarla</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="127" end_char="128">de</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="130" end_char="131">la</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="133" end_char="136">yuca</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="138" end_char="142">buena</TOKEN>
<TOKEN id="token-1-9" pos="punct" morph="none" start_char="143" end_char="143">,</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="145" end_char="147">que</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="149" end_char="150">se</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="152" end_char="155">come</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="157" end_char="157">a</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="159" end_char="164">diario</TOKEN>
<TOKEN id="token-1-15" pos="punct" morph="none" start_char="165" end_char="165">?</TOKEN>
</SEG>
<SEG id="segment-2" start_char="169" end_char="225">
<ORIGINAL_TEXT>Pero no en el sentido que la pregunta probablemente tuvo.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="169" end_char="172">Pero</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="174" end_char="175">no</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="177" end_char="178">en</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="180" end_char="181">el</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="183" end_char="189">sentido</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="191" end_char="193">que</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="195" end_char="196">la</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="198" end_char="205">pregunta</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="207" end_char="219">probablemente</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="221" end_char="224">tuvo</TOKEN>
<TOKEN id="token-2-10" pos="punct" morph="none" start_char="225" end_char="225">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="228" end_char="300">
<ORIGINAL_TEXT>Durante muchisimo tiempo, los animales salvajes portaron virus como este.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="228" end_char="234">Durante</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="236" end_char="244">muchisimo</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="246" end_char="251">tiempo</TOKEN>
<TOKEN id="token-3-3" pos="punct" morph="none" start_char="252" end_char="252">,</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="254" end_char="256">los</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="258" end_char="265">animales</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="267" end_char="274">salvajes</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="276" end_char="283">portaron</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="285" end_char="289">virus</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="291" end_char="294">como</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="296" end_char="299">este</TOKEN>
<TOKEN id="token-3-11" pos="punct" morph="none" start_char="300" end_char="300">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="302" end_char="408">
<ORIGINAL_TEXT>Algunos se enferman y mueren, otros se enferman pero sanan y siguen viviendo, y otros son portadores sanos.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="302" end_char="308">Algunos</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="310" end_char="311">se</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="313" end_char="320">enferman</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="322" end_char="322">y</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="324" end_char="329">mueren</TOKEN>
<TOKEN id="token-4-5" pos="punct" morph="none" start_char="330" end_char="330">,</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="332" end_char="336">otros</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="338" end_char="339">se</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="341" end_char="348">enferman</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="350" end_char="353">pero</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="355" end_char="359">sanan</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="361" end_char="361">y</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="363" end_char="368">siguen</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="370" end_char="377">viviendo</TOKEN>
<TOKEN id="token-4-14" pos="punct" morph="none" start_char="378" end_char="378">,</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="380" end_char="380">y</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="382" end_char="386">otros</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="388" end_char="390">son</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="392" end_char="401">portadores</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="403" end_char="407">sanos</TOKEN>
<TOKEN id="token-4-20" pos="punct" morph="none" start_char="408" end_char="408">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="410" end_char="582">
<ORIGINAL_TEXT>Sus depredadores son aquellos que o desarrollaron algun tipo de inmunidad a esos virus, o el beneficio que obtiene la especie de comerlos excede a los que mueren infectados.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="410" end_char="412">Sus</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="414" end_char="425">depredadores</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="427" end_char="429">son</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="431" end_char="438">aquellos</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="440" end_char="442">que</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="444" end_char="444">o</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="446" end_char="458">desarrollaron</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="460" end_char="464">algun</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="466" end_char="469">tipo</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="471" end_char="472">de</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="474" end_char="482">inmunidad</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="484" end_char="484">a</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="486" end_char="489">esos</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="491" end_char="495">virus</TOKEN>
<TOKEN id="token-5-14" pos="punct" morph="none" start_char="496" end_char="496">,</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="498" end_char="498">o</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="500" end_char="501">el</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="503" end_char="511">beneficio</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="513" end_char="515">que</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="517" end_char="523">obtiene</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="525" end_char="526">la</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="528" end_char="534">especie</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="536" end_char="537">de</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="539" end_char="546">comerlos</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="548" end_char="553">excede</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="555" end_char="555">a</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="557" end_char="559">los</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="561" end_char="563">que</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="565" end_char="570">mueren</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="572" end_char="581">infectados</TOKEN>
<TOKEN id="token-5-30" pos="punct" morph="none" start_char="582" end_char="582">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="584" end_char="745">
<ORIGINAL_TEXT>Pero en todos los casos, estas "transacciones" se desarrollaban en la naturaleza, lejos de los humanos, y dentro de un equilibrio dinamico (al fin y al cabo todos</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="584" end_char="587">Pero</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="589" end_char="590">en</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="592" end_char="596">todos</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="598" end_char="600">los</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="602" end_char="606">casos</TOKEN>
<TOKEN id="token-6-5" pos="punct" morph="none" start_char="607" end_char="607">,</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="609" end_char="613">estas</TOKEN>
<TOKEN id="token-6-7" pos="punct" morph="none" start_char="615" end_char="615">"</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="616" end_char="628">transacciones</TOKEN>
<TOKEN id="token-6-9" pos="punct" morph="none" start_char="629" end_char="629">"</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="631" end_char="632">se</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="634" end_char="646">desarrollaban</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="648" end_char="649">en</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="651" end_char="652">la</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="654" end_char="663">naturaleza</TOKEN>
<TOKEN id="token-6-15" pos="punct" morph="none" start_char="664" end_char="664">,</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="666" end_char="670">lejos</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="672" end_char="673">de</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="675" end_char="677">los</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="679" end_char="685">humanos</TOKEN>
<TOKEN id="token-6-20" pos="punct" morph="none" start_char="686" end_char="686">,</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="688" end_char="688">y</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="690" end_char="695">dentro</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="697" end_char="698">de</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="700" end_char="701">un</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="703" end_char="712">equilibrio</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="714" end_char="721">dinamico</TOKEN>
<TOKEN id="token-6-27" pos="punct" morph="none" start_char="723" end_char="723">(</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="724" end_char="725">al</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="727" end_char="729">fin</TOKEN>
<TOKEN id="token-6-30" pos="word" morph="none" start_char="731" end_char="731">y</TOKEN>
<TOKEN id="token-6-31" pos="word" morph="none" start_char="733" end_char="734">al</TOKEN>
<TOKEN id="token-6-32" pos="word" morph="none" start_char="736" end_char="739">cabo</TOKEN>
<TOKEN id="token-6-33" pos="word" morph="none" start_char="741" end_char="745">todos</TOKEN>
</SEG>
<SEG id="segment-7" start_char="748" end_char="837">
<ORIGINAL_TEXT>La posibilidad es baja y parece que es una ventana que se cierra cada vez más rápidamente.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="748" end_char="749">La</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="751" end_char="761">posibilidad</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="763" end_char="764">es</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="766" end_char="769">baja</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="771" end_char="771">y</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="773" end_char="778">parece</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="780" end_char="782">que</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="784" end_char="785">es</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="787" end_char="789">una</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="791" end_char="797">ventana</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="799" end_char="801">que</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="803" end_char="804">se</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="806" end_char="811">cierra</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="813" end_char="816">cada</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="818" end_char="820">vez</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="822" end_char="824">más</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="826" end_char="836">rápidamente</TOKEN>
<TOKEN id="token-7-17" pos="punct" morph="none" start_char="837" end_char="837">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="840" end_char="930">
<ORIGINAL_TEXT>Hay que tener en cuenta que es un virus nuevo y aún no se sabe muchas cosas acerca de éste.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="840" end_char="842">Hay</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="844" end_char="846">que</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="848" end_char="852">tener</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="854" end_char="855">en</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="857" end_char="862">cuenta</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="864" end_char="866">que</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="868" end_char="869">es</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="871" end_char="872">un</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="874" end_char="878">virus</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="880" end_char="884">nuevo</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="886" end_char="886">y</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="888" end_char="890">aún</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="892" end_char="893">no</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="895" end_char="896">se</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="898" end_char="901">sabe</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="903" end_char="908">muchas</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="910" end_char="914">cosas</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="916" end_char="921">acerca</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="923" end_char="924">de</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="926" end_char="929">éste</TOKEN>
<TOKEN id="token-8-20" pos="punct" morph="none" start_char="930" end_char="930">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="932" end_char="1068">
<ORIGINAL_TEXT>También, que la ciencia siempre busca ofrecer la mejor explicación temporal, de conformidad con la mejor evidencia disponible al momento.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="932" end_char="938">También</TOKEN>
<TOKEN id="token-9-1" pos="punct" morph="none" start_char="939" end_char="939">,</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="941" end_char="943">que</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="945" end_char="946">la</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="948" end_char="954">ciencia</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="956" end_char="962">siempre</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="964" end_char="968">busca</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="970" end_char="976">ofrecer</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="978" end_char="979">la</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="981" end_char="985">mejor</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="987" end_char="997">explicación</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="999" end_char="1006">temporal</TOKEN>
<TOKEN id="token-9-12" pos="punct" morph="none" start_char="1007" end_char="1007">,</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1009" end_char="1010">de</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1012" end_char="1022">conformidad</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1024" end_char="1026">con</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1028" end_char="1029">la</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1031" end_char="1035">mejor</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1037" end_char="1045">evidencia</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1047" end_char="1056">disponible</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1058" end_char="1059">al</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1061" end_char="1067">momento</TOKEN>
<TOKEN id="token-9-22" pos="punct" morph="none" start_char="1068" end_char="1068">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1070" end_char="1180">
<ORIGINAL_TEXT>La ciencia no ofrece respuestas absolutamente definitivas, por lo que muchas cosas pueden cambiar en el futuro.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1070" end_char="1071">La</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1073" end_char="1079">ciencia</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1081" end_char="1082">no</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1084" end_char="1089">ofrece</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1091" end_char="1100">respuestas</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1102" end_char="1114">absolutamente</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1116" end_char="1126">definitivas</TOKEN>
<TOKEN id="token-10-7" pos="punct" morph="none" start_char="1127" end_char="1127">,</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1129" end_char="1131">por</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1133" end_char="1134">lo</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1136" end_char="1138">que</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1140" end_char="1145">muchas</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1147" end_char="1151">cosas</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1153" end_char="1158">pueden</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1160" end_char="1166">cambiar</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1168" end_char="1169">en</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1171" end_char="1172">el</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1174" end_char="1179">futuro</TOKEN>
<TOKEN id="token-10-18" pos="punct" morph="none" start_char="1180" end_char="1180">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1182" end_char="1213">
<ORIGINAL_TEXT>Dicho esto, entremos en materia.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1182" end_char="1186">Dicho</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1188" end_char="1191">esto</TOKEN>
<TOKEN id="token-11-2" pos="punct" morph="none" start_char="1192" end_char="1192">,</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1194" end_char="1201">entremos</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1203" end_char="1204">en</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1206" end_char="1212">materia</TOKEN>
<TOKEN id="token-11-6" pos="punct" morph="none" start_char="1213" end_char="1213">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1216" end_char="1291">
<ORIGINAL_TEXT>Un estudio muy reciente (17 de marzo de 2020) abordó este tema directamente.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1216" end_char="1217">Un</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1219" end_char="1225">estudio</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1227" end_char="1229">muy</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1231" end_char="1238">reciente</TOKEN>
<TOKEN id="token-12-4" pos="punct" morph="none" start_char="1240" end_char="1240">(</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1241" end_char="1242">17</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1244" end_char="1245">de</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1247" end_char="1251">marzo</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1253" end_char="1254">de</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1256" end_char="1259">2020</TOKEN>
<TOKEN id="token-12-10" pos="punct" morph="none" start_char="1260" end_char="1260">)</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1262" end_char="1267">abordó</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1269" end_char="1272">este</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1274" end_char="1277">tema</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1279" end_char="1290">directamente</TOKEN>
<TOKEN id="token-12-15" pos="punct" morph="none" start_char="1291" end_char="1291">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1293" end_char="1354">
<ORIGINAL_TEXT>[1] Y, en resumen, los autores concluyeron que el virus SARS-C</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="punct" morph="none" start_char="1293" end_char="1293">[</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1294" end_char="1294">1</TOKEN>
<TOKEN id="token-13-2" pos="punct" morph="none" start_char="1295" end_char="1295">]</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1297" end_char="1297">Y</TOKEN>
<TOKEN id="token-13-4" pos="punct" morph="none" start_char="1298" end_char="1298">,</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1300" end_char="1301">en</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1303" end_char="1309">resumen</TOKEN>
<TOKEN id="token-13-7" pos="punct" morph="none" start_char="1310" end_char="1310">,</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1312" end_char="1314">los</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1316" end_char="1322">autores</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1324" end_char="1334">concluyeron</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1336" end_char="1338">que</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1340" end_char="1341">el</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1343" end_char="1347">virus</TOKEN>
<TOKEN id="token-13-14" pos="unknown" morph="none" start_char="1349" end_char="1354">SARS-C</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1357" end_char="1519">
<ORIGINAL_TEXT>1- Todos los que pueden infectarse se infectan (ver Peste negra en la Europa medieval, Viruela en la era de la exploración de América, Gripe española en 1918–1920)</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1357" end_char="1357">1</TOKEN>
<TOKEN id="token-14-1" pos="punct" morph="none" start_char="1358" end_char="1358">-</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1360" end_char="1364">Todos</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1366" end_char="1368">los</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1370" end_char="1372">que</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1374" end_char="1379">pueden</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1381" end_char="1390">infectarse</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1392" end_char="1393">se</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1395" end_char="1402">infectan</TOKEN>
<TOKEN id="token-14-9" pos="punct" morph="none" start_char="1404" end_char="1404">(</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1405" end_char="1407">ver</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1409" end_char="1413">Peste</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1415" end_char="1419">negra</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1421" end_char="1422">en</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="1424" end_char="1425">la</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1427" end_char="1432">Europa</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1434" end_char="1441">medieval</TOKEN>
<TOKEN id="token-14-17" pos="punct" morph="none" start_char="1442" end_char="1442">,</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="1444" end_char="1450">Viruela</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="1452" end_char="1453">en</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="1455" end_char="1456">la</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="1458" end_char="1460">era</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="1462" end_char="1463">de</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="1465" end_char="1466">la</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="1468" end_char="1478">exploración</TOKEN>
<TOKEN id="token-14-25" pos="word" morph="none" start_char="1480" end_char="1481">de</TOKEN>
<TOKEN id="token-14-26" pos="word" morph="none" start_char="1483" end_char="1489">América</TOKEN>
<TOKEN id="token-14-27" pos="punct" morph="none" start_char="1490" end_char="1490">,</TOKEN>
<TOKEN id="token-14-28" pos="word" morph="none" start_char="1492" end_char="1496">Gripe</TOKEN>
<TOKEN id="token-14-29" pos="word" morph="none" start_char="1498" end_char="1505">española</TOKEN>
<TOKEN id="token-14-30" pos="word" morph="none" start_char="1507" end_char="1508">en</TOKEN>
<TOKEN id="token-14-31" pos="unknown" morph="none" start_char="1510" end_char="1518">1918–1920</TOKEN>
<TOKEN id="token-14-32" pos="punct" morph="none" start_char="1519" end_char="1519">)</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1522" end_char="1722">
<ORIGINAL_TEXT>2- La acción del gobierno encuentra a todos los que están enfermos, los pone en cuarentena y evita una mayor propagación (ver Wuhan China, 2020, SARS en China en 2002, Ébola en África occidental, 2018)</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1522" end_char="1522">2</TOKEN>
<TOKEN id="token-15-1" pos="punct" morph="none" start_char="1523" end_char="1523">-</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1525" end_char="1526">La</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1528" end_char="1533">acción</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1535" end_char="1537">del</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1539" end_char="1546">gobierno</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1548" end_char="1556">encuentra</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1558" end_char="1558">a</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1560" end_char="1564">todos</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1566" end_char="1568">los</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1570" end_char="1572">que</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1574" end_char="1578">están</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1580" end_char="1587">enfermos</TOKEN>
<TOKEN id="token-15-13" pos="punct" morph="none" start_char="1588" end_char="1588">,</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1590" end_char="1592">los</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="1594" end_char="1597">pone</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="1599" end_char="1600">en</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="1602" end_char="1611">cuarentena</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="1613" end_char="1613">y</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="1615" end_char="1619">evita</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="1621" end_char="1623">una</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="1625" end_char="1629">mayor</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="1631" end_char="1641">propagación</TOKEN>
<TOKEN id="token-15-23" pos="punct" morph="none" start_char="1643" end_char="1643">(</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="1644" end_char="1646">ver</TOKEN>
<TOKEN id="token-15-25" pos="word" morph="none" start_char="1648" end_char="1652">Wuhan</TOKEN>
<TOKEN id="token-15-26" pos="word" morph="none" start_char="1654" end_char="1658">China</TOKEN>
<TOKEN id="token-15-27" pos="punct" morph="none" start_char="1659" end_char="1659">,</TOKEN>
<TOKEN id="token-15-28" pos="word" morph="none" start_char="1661" end_char="1664">2020</TOKEN>
<TOKEN id="token-15-29" pos="punct" morph="none" start_char="1665" end_char="1665">,</TOKEN>
<TOKEN id="token-15-30" pos="word" morph="none" start_char="1667" end_char="1670">SARS</TOKEN>
<TOKEN id="token-15-31" pos="word" morph="none" start_char="1672" end_char="1673">en</TOKEN>
<TOKEN id="token-15-32" pos="word" morph="none" start_char="1675" end_char="1679">China</TOKEN>
<TOKEN id="token-15-33" pos="word" morph="none" start_char="1681" end_char="1682">en</TOKEN>
<TOKEN id="token-15-34" pos="word" morph="none" start_char="1684" end_char="1687">2002</TOKEN>
<TOKEN id="token-15-35" pos="punct" morph="none" start_char="1688" end_char="1688">,</TOKEN>
<TOKEN id="token-15-36" pos="word" morph="none" start_char="1690" end_char="1694">Ébola</TOKEN>
<TOKEN id="token-15-37" pos="word" morph="none" start_char="1696" end_char="1697">en</TOKEN>
<TOKEN id="token-15-38" pos="word" morph="none" start_char="1699" end_char="1704">África</TOKEN>
<TOKEN id="token-15-39" pos="word" morph="none" start_char="1706" end_char="1715">occidental</TOKEN>
<TOKEN id="token-15-40" pos="punct" morph="none" start_char="1716" end_char="1716">,</TOKEN>
<TOKEN id="token-15-41" pos="word" morph="none" start_char="1718" end_char="1721">2018</TOKEN>
<TOKEN id="token-15-42" pos="punct" morph="none" start_char="1722" end_char="1722">)</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1725" end_char="1812">
<ORIGINAL_TEXT>3- La transmisión se ralentiza en climas cálidos / secos (ver influenza, todos los años)</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1725" end_char="1725">3</TOKEN>
<TOKEN id="token-16-1" pos="punct" morph="none" start_char="1726" end_char="1726">-</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1728" end_char="1729">La</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1731" end_char="1741">transmisión</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1743" end_char="1744">se</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1746" end_char="1754">ralentiza</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1756" end_char="1757">en</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1759" end_char="1764">climas</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1766" end_char="1772">cálidos</TOKEN>
<TOKEN id="token-16-9" pos="punct" morph="none" start_char="1774" end_char="1774">/</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="1776" end_char="1780">secos</TOKEN>
<TOKEN id="token-16-11" pos="punct" morph="none" start_char="1782" end_char="1782">(</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="1783" end_char="1785">ver</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="1787" end_char="1795">influenza</TOKEN>
<TOKEN id="token-16-14" pos="punct" morph="none" start_char="1796" end_char="1796">,</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="1798" end_char="1802">todos</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="1804" end_char="1806">los</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="1808" end_char="1811">años</TOKEN>
<TOKEN id="token-16-18" pos="punct" morph="none" start_char="1812" end_char="1812">)</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1815" end_char="1917">
<ORIGINAL_TEXT>Todavía no sabemos si Covid-19 disminuirá la velocidad cuando el hemisferio norte se convierta en prima</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1815" end_char="1821">Todavía</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1823" end_char="1824">no</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="1826" end_char="1832">sabemos</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="1834" end_char="1835">si</TOKEN>
<TOKEN id="token-17-4" pos="unknown" morph="none" start_char="1837" end_char="1844">Covid-19</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="1846" end_char="1855">disminuirá</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="1857" end_char="1858">la</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="1860" end_char="1868">velocidad</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="1870" end_char="1875">cuando</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="1877" end_char="1878">el</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="1880" end_char="1889">hemisferio</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="1891" end_char="1895">norte</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="1897" end_char="1898">se</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="1900" end_char="1908">convierta</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="1910" end_char="1911">en</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="1913" end_char="1917">prima</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1920" end_char="2266">
<ORIGINAL_TEXT>Vamos a contestar como si la pregunta fuera de recibo (que no lo es; y no lo es porque el concepto de raza aplicado a los humanos es aberrante: una sola región centroafricana contiene más diversidad genética que toooooda la humanidad del resto del planeta, a pesar de que un paleto racista los adscribiría a todos ellos a una supuesta raza negra).</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="1920" end_char="1924">Vamos</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="1926" end_char="1926">a</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="1928" end_char="1936">contestar</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="1938" end_char="1941">como</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="1943" end_char="1944">si</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="1946" end_char="1947">la</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="1949" end_char="1956">pregunta</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="1958" end_char="1962">fuera</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="1964" end_char="1965">de</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="1967" end_char="1972">recibo</TOKEN>
<TOKEN id="token-18-10" pos="punct" morph="none" start_char="1974" end_char="1974">(</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="1975" end_char="1977">que</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="1979" end_char="1980">no</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="1982" end_char="1983">lo</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="1985" end_char="1986">es</TOKEN>
<TOKEN id="token-18-15" pos="punct" morph="none" start_char="1987" end_char="1987">;</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="1989" end_char="1989">y</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="1991" end_char="1992">no</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="1994" end_char="1995">lo</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="1997" end_char="1998">es</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="2000" end_char="2005">porque</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="2007" end_char="2008">el</TOKEN>
<TOKEN id="token-18-22" pos="word" morph="none" start_char="2010" end_char="2017">concepto</TOKEN>
<TOKEN id="token-18-23" pos="word" morph="none" start_char="2019" end_char="2020">de</TOKEN>
<TOKEN id="token-18-24" pos="word" morph="none" start_char="2022" end_char="2025">raza</TOKEN>
<TOKEN id="token-18-25" pos="word" morph="none" start_char="2027" end_char="2034">aplicado</TOKEN>
<TOKEN id="token-18-26" pos="word" morph="none" start_char="2036" end_char="2036">a</TOKEN>
<TOKEN id="token-18-27" pos="word" morph="none" start_char="2038" end_char="2040">los</TOKEN>
<TOKEN id="token-18-28" pos="word" morph="none" start_char="2042" end_char="2048">humanos</TOKEN>
<TOKEN id="token-18-29" pos="word" morph="none" start_char="2050" end_char="2051">es</TOKEN>
<TOKEN id="token-18-30" pos="word" morph="none" start_char="2053" end_char="2061">aberrante</TOKEN>
<TOKEN id="token-18-31" pos="punct" morph="none" start_char="2062" end_char="2062">:</TOKEN>
<TOKEN id="token-18-32" pos="word" morph="none" start_char="2064" end_char="2066">una</TOKEN>
<TOKEN id="token-18-33" pos="word" morph="none" start_char="2068" end_char="2071">sola</TOKEN>
<TOKEN id="token-18-34" pos="word" morph="none" start_char="2073" end_char="2078">región</TOKEN>
<TOKEN id="token-18-35" pos="word" morph="none" start_char="2080" end_char="2093">centroafricana</TOKEN>
<TOKEN id="token-18-36" pos="word" morph="none" start_char="2095" end_char="2102">contiene</TOKEN>
<TOKEN id="token-18-37" pos="word" morph="none" start_char="2104" end_char="2106">más</TOKEN>
<TOKEN id="token-18-38" pos="word" morph="none" start_char="2108" end_char="2117">diversidad</TOKEN>
<TOKEN id="token-18-39" pos="word" morph="none" start_char="2119" end_char="2126">genética</TOKEN>
<TOKEN id="token-18-40" pos="word" morph="none" start_char="2128" end_char="2130">que</TOKEN>
<TOKEN id="token-18-41" pos="word" morph="none" start_char="2132" end_char="2139">toooooda</TOKEN>
<TOKEN id="token-18-42" pos="word" morph="none" start_char="2141" end_char="2142">la</TOKEN>
<TOKEN id="token-18-43" pos="word" morph="none" start_char="2144" end_char="2152">humanidad</TOKEN>
<TOKEN id="token-18-44" pos="word" morph="none" start_char="2154" end_char="2156">del</TOKEN>
<TOKEN id="token-18-45" pos="word" morph="none" start_char="2158" end_char="2162">resto</TOKEN>
<TOKEN id="token-18-46" pos="word" morph="none" start_char="2164" end_char="2166">del</TOKEN>
<TOKEN id="token-18-47" pos="word" morph="none" start_char="2168" end_char="2174">planeta</TOKEN>
<TOKEN id="token-18-48" pos="punct" morph="none" start_char="2175" end_char="2175">,</TOKEN>
<TOKEN id="token-18-49" pos="word" morph="none" start_char="2177" end_char="2177">a</TOKEN>
<TOKEN id="token-18-50" pos="word" morph="none" start_char="2179" end_char="2183">pesar</TOKEN>
<TOKEN id="token-18-51" pos="word" morph="none" start_char="2185" end_char="2186">de</TOKEN>
<TOKEN id="token-18-52" pos="word" morph="none" start_char="2188" end_char="2190">que</TOKEN>
<TOKEN id="token-18-53" pos="word" morph="none" start_char="2192" end_char="2193">un</TOKEN>
<TOKEN id="token-18-54" pos="word" morph="none" start_char="2195" end_char="2200">paleto</TOKEN>
<TOKEN id="token-18-55" pos="word" morph="none" start_char="2202" end_char="2208">racista</TOKEN>
<TOKEN id="token-18-56" pos="word" morph="none" start_char="2210" end_char="2212">los</TOKEN>
<TOKEN id="token-18-57" pos="word" morph="none" start_char="2214" end_char="2224">adscribiría</TOKEN>
<TOKEN id="token-18-58" pos="word" morph="none" start_char="2226" end_char="2226">a</TOKEN>
<TOKEN id="token-18-59" pos="word" morph="none" start_char="2228" end_char="2232">todos</TOKEN>
<TOKEN id="token-18-60" pos="word" morph="none" start_char="2234" end_char="2238">ellos</TOKEN>
<TOKEN id="token-18-61" pos="word" morph="none" start_char="2240" end_char="2240">a</TOKEN>
<TOKEN id="token-18-62" pos="word" morph="none" start_char="2242" end_char="2244">una</TOKEN>
<TOKEN id="token-18-63" pos="word" morph="none" start_char="2246" end_char="2253">supuesta</TOKEN>
<TOKEN id="token-18-64" pos="word" morph="none" start_char="2255" end_char="2258">raza</TOKEN>
<TOKEN id="token-18-65" pos="word" morph="none" start_char="2260" end_char="2264">negra</TOKEN>
<TOKEN id="token-18-66" pos="punct" morph="none" start_char="2265" end_char="2266">).</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2268" end_char="2282">
<ORIGINAL_TEXT>Vayamos a ello:</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2268" end_char="2274">Vayamos</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2276" end_char="2276">a</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2278" end_char="2281">ello</TOKEN>
<TOKEN id="token-19-3" pos="punct" morph="none" start_char="2282" end_char="2282">:</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2285" end_char="2316">
<ORIGINAL_TEXT>Sin duda la de los sentineleses.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2285" end_char="2287">Sin</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2289" end_char="2292">duda</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2294" end_char="2295">la</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2297" end_char="2298">de</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2300" end_char="2302">los</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2304" end_char="2315">sentineleses</TOKEN>
<TOKEN id="token-20-6" pos="punct" morph="none" start_char="2316" end_char="2316">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2318" end_char="2356">
<ORIGINAL_TEXT>Llevan milenios sin cruzarse con nadie.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2318" end_char="2323">Llevan</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2325" end_char="2332">milenios</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2334" end_char="2336">sin</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2338" end_char="2345">cruzarse</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2347" end_char="2349">con</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="2351" end_char="2355">nadie</TOKEN>
<TOKEN id="token-21-6" pos="punct" morph="none" start_char="2356" end_char="2356">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2358" end_char="2496">
<ORIGINAL_TEXT>Si estabas pensando en alguna etnia (que no raza) europea, vas jodido: los europeos somos bastardos que tenemos incluso sangre neanderthal.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2358" end_char="2359">Si</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2361" end_char="2367">estabas</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2369" end_char="2376">pensando</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2378" end_char="2379">en</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2381" end_char="2386">alguna</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2388" end_char="2392">etnia</TOKEN>
<TOKEN id="token-22-6" pos="punct" morph="none" start_char="2394" end_char="2394">(</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2395" end_char="2397">que</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="2399" end_char="2400">no</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="2402" end_char="2405">raza</TOKEN>
<TOKEN id="token-22-10" pos="punct" morph="none" start_char="2406" end_char="2406">)</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="2408" end_char="2414">europea</TOKEN>
<TOKEN id="token-22-12" pos="punct" morph="none" start_char="2415" end_char="2415">,</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="2417" end_char="2419">vas</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="2421" end_char="2426">jodido</TOKEN>
<TOKEN id="token-22-15" pos="punct" morph="none" start_char="2427" end_char="2427">:</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="2429" end_char="2431">los</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="2433" end_char="2440">europeos</TOKEN>
<TOKEN id="token-22-18" pos="word" morph="none" start_char="2442" end_char="2446">somos</TOKEN>
<TOKEN id="token-22-19" pos="word" morph="none" start_char="2448" end_char="2456">bastardos</TOKEN>
<TOKEN id="token-22-20" pos="word" morph="none" start_char="2458" end_char="2460">que</TOKEN>
<TOKEN id="token-22-21" pos="word" morph="none" start_char="2462" end_char="2468">tenemos</TOKEN>
<TOKEN id="token-22-22" pos="word" morph="none" start_char="2470" end_char="2476">incluso</TOKEN>
<TOKEN id="token-22-23" pos="word" morph="none" start_char="2478" end_char="2483">sangre</TOKEN>
<TOKEN id="token-22-24" pos="word" morph="none" start_char="2485" end_char="2495">neanderthal</TOKEN>
<TOKEN id="token-22-25" pos="punct" morph="none" start_char="2496" end_char="2496">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2498" end_char="2521">
<ORIGINAL_TEXT>Además, somos negros sól</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2498" end_char="2503">Además</TOKEN>
<TOKEN id="token-23-1" pos="punct" morph="none" start_char="2504" end_char="2504">,</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2506" end_char="2510">somos</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2512" end_char="2517">negros</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="2519" end_char="2521">sól</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
