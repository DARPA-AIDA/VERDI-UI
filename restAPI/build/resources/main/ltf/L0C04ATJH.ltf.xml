<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATJH" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="6901" raw_text_md5="c90f28d2b914c1d46d344017d5337bef">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="38">
<ORIGINAL_TEXT>Should pets be tested for coronavirus?</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="6">Should</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="8" end_char="11">pets</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="13" end_char="14">be</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="16" end_char="21">tested</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="23" end_char="25">for</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="27" end_char="37">coronavirus</TOKEN>
<TOKEN id="token-0-6" pos="punct" morph="none" start_char="38" end_char="38">?</TOKEN>
</SEG>
<SEG id="segment-1" start_char="43" end_char="74">
<ORIGINAL_TEXT>A dog wearing a mask in Shanghai</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="43" end_char="43">A</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="45" end_char="47">dog</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="49" end_char="55">wearing</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="57" end_char="57">a</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="59" end_char="62">mask</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="64" end_char="65">in</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="67" end_char="74">Shanghai</TOKEN>
</SEG>
<SEG id="segment-2" start_char="78" end_char="142">
<ORIGINAL_TEXT>Science’s COVID-19 reporting is supported by the Pulitzer Center.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="78" end_char="86">Science’s</TOKEN>
<TOKEN id="token-2-1" pos="unknown" morph="none" start_char="88" end_char="95">COVID-19</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="97" end_char="105">reporting</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="107" end_char="108">is</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="110" end_char="118">supported</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="120" end_char="121">by</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="123" end_char="125">the</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="127" end_char="134">Pulitzer</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="136" end_char="141">Center</TOKEN>
<TOKEN id="token-2-9" pos="punct" morph="none" start_char="142" end_char="142">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="145" end_char="213">
<ORIGINAL_TEXT>Last Thursday, the first cat tested positive for the new coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="145" end_char="148">Last</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="150" end_char="157">Thursday</TOKEN>
<TOKEN id="token-3-2" pos="punct" morph="none" start_char="158" end_char="158">,</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="160" end_char="162">the</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="164" end_char="168">first</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="170" end_char="172">cat</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="174" end_char="179">tested</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="181" end_char="188">positive</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="190" end_char="192">for</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="194" end_char="196">the</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="198" end_char="200">new</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="202" end_char="212">coronavirus</TOKEN>
<TOKEN id="token-3-12" pos="punct" morph="none" start_char="213" end_char="213">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="215" end_char="379">
<ORIGINAL_TEXT>The feline had diarrhea, vomiting, and difficulty breathing, and it had come down with COVID-19 about 1 week after its owner did, Belgian health officials announced.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="215" end_char="217">The</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="219" end_char="224">feline</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="226" end_char="228">had</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="230" end_char="237">diarrhea</TOKEN>
<TOKEN id="token-4-4" pos="punct" morph="none" start_char="238" end_char="238">,</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="240" end_char="247">vomiting</TOKEN>
<TOKEN id="token-4-6" pos="punct" morph="none" start_char="248" end_char="248">,</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="250" end_char="252">and</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="254" end_char="263">difficulty</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="265" end_char="273">breathing</TOKEN>
<TOKEN id="token-4-10" pos="punct" morph="none" start_char="274" end_char="274">,</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="276" end_char="278">and</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="280" end_char="281">it</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="283" end_char="285">had</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="287" end_char="290">come</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="292" end_char="295">down</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="297" end_char="300">with</TOKEN>
<TOKEN id="token-4-17" pos="unknown" morph="none" start_char="302" end_char="309">COVID-19</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="311" end_char="315">about</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="317" end_char="317">1</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="319" end_char="322">week</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="324" end_char="328">after</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="330" end_char="332">its</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="334" end_char="338">owner</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="340" end_char="342">did</TOKEN>
<TOKEN id="token-4-25" pos="punct" morph="none" start_char="343" end_char="343">,</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="345" end_char="351">Belgian</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="353" end_char="358">health</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="360" end_char="368">officials</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="370" end_char="378">announced</TOKEN>
<TOKEN id="token-4-30" pos="punct" morph="none" start_char="379" end_char="379">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="382" end_char="631">
<ORIGINAL_TEXT>The same day, Hong Kong’s Agriculture, Fisheries and Conservation Department reported that a 17-year-old Pomeranian—which had initially tested "weak positive" for SARS-CoV-2—had indeed been infected by the virus, likely by its owner or another human.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="382" end_char="384">The</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="386" end_char="389">same</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="391" end_char="393">day</TOKEN>
<TOKEN id="token-5-3" pos="punct" morph="none" start_char="394" end_char="394">,</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="396" end_char="399">Hong</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="401" end_char="406">Kong’s</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="408" end_char="418">Agriculture</TOKEN>
<TOKEN id="token-5-7" pos="punct" morph="none" start_char="419" end_char="419">,</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="421" end_char="429">Fisheries</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="431" end_char="433">and</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="435" end_char="446">Conservation</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="448" end_char="457">Department</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="459" end_char="466">reported</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="468" end_char="471">that</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="473" end_char="473">a</TOKEN>
<TOKEN id="token-5-15" pos="unknown" morph="none" start_char="475" end_char="485">17-year-old</TOKEN>
<TOKEN id="token-5-16" pos="unknown" morph="none" start_char="487" end_char="502">Pomeranian—which</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="504" end_char="506">had</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="508" end_char="516">initially</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="518" end_char="523">tested</TOKEN>
<TOKEN id="token-5-20" pos="punct" morph="none" start_char="525" end_char="525">"</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="526" end_char="529">weak</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="531" end_char="538">positive</TOKEN>
<TOKEN id="token-5-23" pos="punct" morph="none" start_char="539" end_char="539">"</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="541" end_char="543">for</TOKEN>
<TOKEN id="token-5-25" pos="unknown" morph="none" start_char="545" end_char="558">SARS-CoV-2—had</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="560" end_char="565">indeed</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="567" end_char="570">been</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="572" end_char="579">infected</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="581" end_char="582">by</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="584" end_char="586">the</TOKEN>
<TOKEN id="token-5-31" pos="word" morph="none" start_char="588" end_char="592">virus</TOKEN>
<TOKEN id="token-5-32" pos="punct" morph="none" start_char="593" end_char="593">,</TOKEN>
<TOKEN id="token-5-33" pos="word" morph="none" start_char="595" end_char="600">likely</TOKEN>
<TOKEN id="token-5-34" pos="word" morph="none" start_char="602" end_char="603">by</TOKEN>
<TOKEN id="token-5-35" pos="word" morph="none" start_char="605" end_char="607">its</TOKEN>
<TOKEN id="token-5-36" pos="word" morph="none" start_char="609" end_char="613">owner</TOKEN>
<TOKEN id="token-5-37" pos="word" morph="none" start_char="615" end_char="616">or</TOKEN>
<TOKEN id="token-5-38" pos="word" morph="none" start_char="618" end_char="624">another</TOKEN>
<TOKEN id="token-5-39" pos="word" morph="none" start_char="626" end_char="630">human</TOKEN>
<TOKEN id="token-5-40" pos="punct" morph="none" start_char="631" end_char="631">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="634" end_char="865">
<ORIGINAL_TEXT>Yet despite these cases—and a third dog that tested positive for coronavirus in Hong Kong earlier this month—the number of pets diagnosed with COVID-19 pales in comparison with the human total, now estimated to be more than 800,000.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="634" end_char="636">Yet</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="638" end_char="644">despite</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="646" end_char="650">these</TOKEN>
<TOKEN id="token-6-3" pos="unknown" morph="none" start_char="652" end_char="660">cases—and</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="662" end_char="662">a</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="664" end_char="668">third</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="670" end_char="672">dog</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="674" end_char="677">that</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="679" end_char="684">tested</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="686" end_char="693">positive</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="695" end_char="697">for</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="699" end_char="709">coronavirus</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="711" end_char="712">in</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="714" end_char="717">Hong</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="719" end_char="722">Kong</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="724" end_char="730">earlier</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="732" end_char="735">this</TOKEN>
<TOKEN id="token-6-17" pos="unknown" morph="none" start_char="737" end_char="745">month—the</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="747" end_char="752">number</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="754" end_char="755">of</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="757" end_char="760">pets</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="762" end_char="770">diagnosed</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="772" end_char="775">with</TOKEN>
<TOKEN id="token-6-23" pos="unknown" morph="none" start_char="777" end_char="784">COVID-19</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="786" end_char="790">pales</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="792" end_char="793">in</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="795" end_char="804">comparison</TOKEN>
<TOKEN id="token-6-27" pos="word" morph="none" start_char="806" end_char="809">with</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="811" end_char="813">the</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="815" end_char="819">human</TOKEN>
<TOKEN id="token-6-30" pos="word" morph="none" start_char="821" end_char="825">total</TOKEN>
<TOKEN id="token-6-31" pos="punct" morph="none" start_char="826" end_char="826">,</TOKEN>
<TOKEN id="token-6-32" pos="word" morph="none" start_char="828" end_char="830">now</TOKEN>
<TOKEN id="token-6-33" pos="word" morph="none" start_char="832" end_char="840">estimated</TOKEN>
<TOKEN id="token-6-34" pos="word" morph="none" start_char="842" end_char="843">to</TOKEN>
<TOKEN id="token-6-35" pos="word" morph="none" start_char="845" end_char="846">be</TOKEN>
<TOKEN id="token-6-36" pos="word" morph="none" start_char="848" end_char="851">more</TOKEN>
<TOKEN id="token-6-37" pos="word" morph="none" start_char="853" end_char="856">than</TOKEN>
<TOKEN id="token-6-38" pos="unknown" morph="none" start_char="858" end_char="864">800,000</TOKEN>
<TOKEN id="token-6-39" pos="punct" morph="none" start_char="865" end_char="865">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="867" end_char="1025">
<ORIGINAL_TEXT>And experts, including those at the U.S. Centers for Disease Control and Prevention (CDC), continue to emphasize that dogs and cats pose little risk to people.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="867" end_char="869">And</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="871" end_char="877">experts</TOKEN>
<TOKEN id="token-7-2" pos="punct" morph="none" start_char="878" end_char="878">,</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="880" end_char="888">including</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="890" end_char="894">those</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="896" end_char="897">at</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="899" end_char="901">the</TOKEN>
<TOKEN id="token-7-7" pos="unknown" morph="none" start_char="903" end_char="905">U.S</TOKEN>
<TOKEN id="token-7-8" pos="punct" morph="none" start_char="906" end_char="906">.</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="908" end_char="914">Centers</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="916" end_char="918">for</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="920" end_char="926">Disease</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="928" end_char="934">Control</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="936" end_char="938">and</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="940" end_char="949">Prevention</TOKEN>
<TOKEN id="token-7-15" pos="punct" morph="none" start_char="951" end_char="951">(</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="952" end_char="954">CDC</TOKEN>
<TOKEN id="token-7-17" pos="punct" morph="none" start_char="955" end_char="956">),</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="958" end_char="965">continue</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="967" end_char="968">to</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="970" end_char="978">emphasize</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="980" end_char="983">that</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="985" end_char="988">dogs</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="990" end_char="992">and</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="994" end_char="997">cats</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="999" end_char="1002">pose</TOKEN>
<TOKEN id="token-7-26" pos="word" morph="none" start_char="1004" end_char="1009">little</TOKEN>
<TOKEN id="token-7-27" pos="word" morph="none" start_char="1011" end_char="1014">risk</TOKEN>
<TOKEN id="token-7-28" pos="word" morph="none" start_char="1016" end_char="1017">to</TOKEN>
<TOKEN id="token-7-29" pos="word" morph="none" start_char="1019" end_char="1024">people</TOKEN>
<TOKEN id="token-7-30" pos="punct" morph="none" start_char="1025" end_char="1025">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1027" end_char="1351">
<ORIGINAL_TEXT>"CDC does not have evidence that pets can spread COVID-19, and there’s no reason to think pets might be a source of infection based on the information we have at this time," Casey Barton Behravesh, director of the agency’s One Health Office in the National Center for Emerging and Zoonotic Infectious Diseases, tells Science.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="punct" morph="none" start_char="1027" end_char="1027">"</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1028" end_char="1030">CDC</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1032" end_char="1035">does</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1037" end_char="1039">not</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1041" end_char="1044">have</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1046" end_char="1053">evidence</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1055" end_char="1058">that</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1060" end_char="1063">pets</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1065" end_char="1067">can</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1069" end_char="1074">spread</TOKEN>
<TOKEN id="token-8-10" pos="unknown" morph="none" start_char="1076" end_char="1083">COVID-19</TOKEN>
<TOKEN id="token-8-11" pos="punct" morph="none" start_char="1084" end_char="1084">,</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1086" end_char="1088">and</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1090" end_char="1096">there’s</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1098" end_char="1099">no</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1101" end_char="1106">reason</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1108" end_char="1109">to</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1111" end_char="1115">think</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1117" end_char="1120">pets</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1122" end_char="1126">might</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="1128" end_char="1129">be</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="1131" end_char="1131">a</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="1133" end_char="1138">source</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="1140" end_char="1141">of</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="1143" end_char="1151">infection</TOKEN>
<TOKEN id="token-8-25" pos="word" morph="none" start_char="1153" end_char="1157">based</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="1159" end_char="1160">on</TOKEN>
<TOKEN id="token-8-27" pos="word" morph="none" start_char="1162" end_char="1164">the</TOKEN>
<TOKEN id="token-8-28" pos="word" morph="none" start_char="1166" end_char="1176">information</TOKEN>
<TOKEN id="token-8-29" pos="word" morph="none" start_char="1178" end_char="1179">we</TOKEN>
<TOKEN id="token-8-30" pos="word" morph="none" start_char="1181" end_char="1184">have</TOKEN>
<TOKEN id="token-8-31" pos="word" morph="none" start_char="1186" end_char="1187">at</TOKEN>
<TOKEN id="token-8-32" pos="word" morph="none" start_char="1189" end_char="1192">this</TOKEN>
<TOKEN id="token-8-33" pos="word" morph="none" start_char="1194" end_char="1197">time</TOKEN>
<TOKEN id="token-8-34" pos="punct" morph="none" start_char="1198" end_char="1199">,"</TOKEN>
<TOKEN id="token-8-35" pos="word" morph="none" start_char="1201" end_char="1205">Casey</TOKEN>
<TOKEN id="token-8-36" pos="word" morph="none" start_char="1207" end_char="1212">Barton</TOKEN>
<TOKEN id="token-8-37" pos="word" morph="none" start_char="1214" end_char="1222">Behravesh</TOKEN>
<TOKEN id="token-8-38" pos="punct" morph="none" start_char="1223" end_char="1223">,</TOKEN>
<TOKEN id="token-8-39" pos="word" morph="none" start_char="1225" end_char="1232">director</TOKEN>
<TOKEN id="token-8-40" pos="word" morph="none" start_char="1234" end_char="1235">of</TOKEN>
<TOKEN id="token-8-41" pos="word" morph="none" start_char="1237" end_char="1239">the</TOKEN>
<TOKEN id="token-8-42" pos="word" morph="none" start_char="1241" end_char="1248">agency’s</TOKEN>
<TOKEN id="token-8-43" pos="word" morph="none" start_char="1250" end_char="1252">One</TOKEN>
<TOKEN id="token-8-44" pos="word" morph="none" start_char="1254" end_char="1259">Health</TOKEN>
<TOKEN id="token-8-45" pos="word" morph="none" start_char="1261" end_char="1266">Office</TOKEN>
<TOKEN id="token-8-46" pos="word" morph="none" start_char="1268" end_char="1269">in</TOKEN>
<TOKEN id="token-8-47" pos="word" morph="none" start_char="1271" end_char="1273">the</TOKEN>
<TOKEN id="token-8-48" pos="word" morph="none" start_char="1275" end_char="1282">National</TOKEN>
<TOKEN id="token-8-49" pos="word" morph="none" start_char="1284" end_char="1289">Center</TOKEN>
<TOKEN id="token-8-50" pos="word" morph="none" start_char="1291" end_char="1293">for</TOKEN>
<TOKEN id="token-8-51" pos="word" morph="none" start_char="1295" end_char="1302">Emerging</TOKEN>
<TOKEN id="token-8-52" pos="word" morph="none" start_char="1304" end_char="1306">and</TOKEN>
<TOKEN id="token-8-53" pos="word" morph="none" start_char="1308" end_char="1315">Zoonotic</TOKEN>
<TOKEN id="token-8-54" pos="word" morph="none" start_char="1317" end_char="1326">Infectious</TOKEN>
<TOKEN id="token-8-55" pos="word" morph="none" start_char="1328" end_char="1335">Diseases</TOKEN>
<TOKEN id="token-8-56" pos="punct" morph="none" start_char="1336" end_char="1336">,</TOKEN>
<TOKEN id="token-8-57" pos="word" morph="none" start_char="1338" end_char="1342">tells</TOKEN>
<TOKEN id="token-8-58" pos="word" morph="none" start_char="1344" end_char="1350">Science</TOKEN>
<TOKEN id="token-8-59" pos="punct" morph="none" start_char="1351" end_char="1351">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1354" end_char="1396">
<ORIGINAL_TEXT>Still, veterinarians want more information.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1354" end_char="1358">Still</TOKEN>
<TOKEN id="token-9-1" pos="punct" morph="none" start_char="1359" end_char="1359">,</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1361" end_char="1373">veterinarians</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1375" end_char="1378">want</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1380" end_char="1383">more</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1385" end_char="1395">information</TOKEN>
<TOKEN id="token-9-6" pos="punct" morph="none" start_char="1396" end_char="1396">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1398" end_char="1520">
<ORIGINAL_TEXT>Though human tests might work on animals, they are in short supply—and veterinarians prefer species-specific tests, anyway.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1398" end_char="1403">Though</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1405" end_char="1409">human</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1411" end_char="1415">tests</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1417" end_char="1421">might</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1423" end_char="1426">work</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1428" end_char="1429">on</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1431" end_char="1437">animals</TOKEN>
<TOKEN id="token-10-7" pos="punct" morph="none" start_char="1438" end_char="1438">,</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1440" end_char="1443">they</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1445" end_char="1447">are</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1449" end_char="1450">in</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1452" end_char="1456">short</TOKEN>
<TOKEN id="token-10-12" pos="unknown" morph="none" start_char="1458" end_char="1467">supply—and</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1469" end_char="1481">veterinarians</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1483" end_char="1488">prefer</TOKEN>
<TOKEN id="token-10-15" pos="unknown" morph="none" start_char="1490" end_char="1505">species-specific</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1507" end_char="1511">tests</TOKEN>
<TOKEN id="token-10-17" pos="punct" morph="none" start_char="1512" end_char="1512">,</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1514" end_char="1519">anyway</TOKEN>
<TOKEN id="token-10-19" pos="punct" morph="none" start_char="1520" end_char="1520">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1522" end_char="1621">
<ORIGINAL_TEXT>Several labs have developed a SARS-CoV-2 test for pets, but none has begun to broadly administer it.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1522" end_char="1528">Several</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1530" end_char="1533">labs</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1535" end_char="1538">have</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1540" end_char="1548">developed</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1550" end_char="1550">a</TOKEN>
<TOKEN id="token-11-5" pos="unknown" morph="none" start_char="1552" end_char="1561">SARS-CoV-2</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1563" end_char="1566">test</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1568" end_char="1570">for</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1572" end_char="1575">pets</TOKEN>
<TOKEN id="token-11-9" pos="punct" morph="none" start_char="1576" end_char="1576">,</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1578" end_char="1580">but</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1582" end_char="1585">none</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1587" end_char="1589">has</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1591" end_char="1595">begun</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1597" end_char="1598">to</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1600" end_char="1606">broadly</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1608" end_char="1617">administer</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1619" end_char="1620">it</TOKEN>
<TOKEN id="token-11-18" pos="punct" morph="none" start_char="1621" end_char="1621">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1623" end_char="1826">
<ORIGINAL_TEXT>The U.S. Department of Agriculture (USDA) has advised against it, and many experts are concerned about spreading unwarranted fear—especially amid reports that some owners have begun to abandon their pets.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1623" end_char="1625">The</TOKEN>
<TOKEN id="token-12-1" pos="unknown" morph="none" start_char="1627" end_char="1629">U.S</TOKEN>
<TOKEN id="token-12-2" pos="punct" morph="none" start_char="1630" end_char="1630">.</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1632" end_char="1641">Department</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1643" end_char="1644">of</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1646" end_char="1656">Agriculture</TOKEN>
<TOKEN id="token-12-6" pos="punct" morph="none" start_char="1658" end_char="1658">(</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1659" end_char="1662">USDA</TOKEN>
<TOKEN id="token-12-8" pos="punct" morph="none" start_char="1663" end_char="1663">)</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1665" end_char="1667">has</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1669" end_char="1675">advised</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1677" end_char="1683">against</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1685" end_char="1686">it</TOKEN>
<TOKEN id="token-12-13" pos="punct" morph="none" start_char="1687" end_char="1687">,</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1689" end_char="1691">and</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1693" end_char="1696">many</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1698" end_char="1704">experts</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1706" end_char="1708">are</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1710" end_char="1718">concerned</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1720" end_char="1724">about</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1726" end_char="1734">spreading</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1736" end_char="1746">unwarranted</TOKEN>
<TOKEN id="token-12-22" pos="unknown" morph="none" start_char="1748" end_char="1762">fear—especially</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="1764" end_char="1767">amid</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="1769" end_char="1775">reports</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="1777" end_char="1780">that</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="1782" end_char="1785">some</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="1787" end_char="1792">owners</TOKEN>
<TOKEN id="token-12-28" pos="word" morph="none" start_char="1794" end_char="1797">have</TOKEN>
<TOKEN id="token-12-29" pos="word" morph="none" start_char="1799" end_char="1803">begun</TOKEN>
<TOKEN id="token-12-30" pos="word" morph="none" start_char="1805" end_char="1806">to</TOKEN>
<TOKEN id="token-12-31" pos="word" morph="none" start_char="1808" end_char="1814">abandon</TOKEN>
<TOKEN id="token-12-32" pos="word" morph="none" start_char="1816" end_char="1820">their</TOKEN>
<TOKEN id="token-12-33" pos="word" morph="none" start_char="1822" end_char="1825">pets</TOKEN>
<TOKEN id="token-12-34" pos="punct" morph="none" start_char="1826" end_char="1826">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1828" end_char="2133">
<ORIGINAL_TEXT>"Even though we have no evidence that pets can transmit the virus, we desperately need [more] evidence one way or the other," says Timothy Baszler, executive director of the Washington Animal Disease Diagnostic Laboratory (WADDL), which announced 2 weeks ago that it had developed a COVID-19 test for pets.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="punct" morph="none" start_char="1828" end_char="1828">"</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1829" end_char="1832">Even</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1834" end_char="1839">though</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1841" end_char="1842">we</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1844" end_char="1847">have</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1849" end_char="1850">no</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1852" end_char="1859">evidence</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1861" end_char="1864">that</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1866" end_char="1869">pets</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1871" end_char="1873">can</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1875" end_char="1882">transmit</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1884" end_char="1886">the</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1888" end_char="1892">virus</TOKEN>
<TOKEN id="token-13-13" pos="punct" morph="none" start_char="1893" end_char="1893">,</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1895" end_char="1896">we</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1898" end_char="1908">desperately</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1910" end_char="1913">need</TOKEN>
<TOKEN id="token-13-17" pos="punct" morph="none" start_char="1915" end_char="1915">[</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1916" end_char="1919">more</TOKEN>
<TOKEN id="token-13-19" pos="punct" morph="none" start_char="1920" end_char="1920">]</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1922" end_char="1929">evidence</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="1931" end_char="1933">one</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="1935" end_char="1937">way</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="1939" end_char="1940">or</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="1942" end_char="1944">the</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="1946" end_char="1950">other</TOKEN>
<TOKEN id="token-13-26" pos="punct" morph="none" start_char="1951" end_char="1952">,"</TOKEN>
<TOKEN id="token-13-27" pos="word" morph="none" start_char="1954" end_char="1957">says</TOKEN>
<TOKEN id="token-13-28" pos="word" morph="none" start_char="1959" end_char="1965">Timothy</TOKEN>
<TOKEN id="token-13-29" pos="word" morph="none" start_char="1967" end_char="1973">Baszler</TOKEN>
<TOKEN id="token-13-30" pos="punct" morph="none" start_char="1974" end_char="1974">,</TOKEN>
<TOKEN id="token-13-31" pos="word" morph="none" start_char="1976" end_char="1984">executive</TOKEN>
<TOKEN id="token-13-32" pos="word" morph="none" start_char="1986" end_char="1993">director</TOKEN>
<TOKEN id="token-13-33" pos="word" morph="none" start_char="1995" end_char="1996">of</TOKEN>
<TOKEN id="token-13-34" pos="word" morph="none" start_char="1998" end_char="2000">the</TOKEN>
<TOKEN id="token-13-35" pos="word" morph="none" start_char="2002" end_char="2011">Washington</TOKEN>
<TOKEN id="token-13-36" pos="word" morph="none" start_char="2013" end_char="2018">Animal</TOKEN>
<TOKEN id="token-13-37" pos="word" morph="none" start_char="2020" end_char="2026">Disease</TOKEN>
<TOKEN id="token-13-38" pos="word" morph="none" start_char="2028" end_char="2037">Diagnostic</TOKEN>
<TOKEN id="token-13-39" pos="word" morph="none" start_char="2039" end_char="2048">Laboratory</TOKEN>
<TOKEN id="token-13-40" pos="punct" morph="none" start_char="2050" end_char="2050">(</TOKEN>
<TOKEN id="token-13-41" pos="word" morph="none" start_char="2051" end_char="2055">WADDL</TOKEN>
<TOKEN id="token-13-42" pos="punct" morph="none" start_char="2056" end_char="2057">),</TOKEN>
<TOKEN id="token-13-43" pos="word" morph="none" start_char="2059" end_char="2063">which</TOKEN>
<TOKEN id="token-13-44" pos="word" morph="none" start_char="2065" end_char="2073">announced</TOKEN>
<TOKEN id="token-13-45" pos="word" morph="none" start_char="2075" end_char="2075">2</TOKEN>
<TOKEN id="token-13-46" pos="word" morph="none" start_char="2077" end_char="2081">weeks</TOKEN>
<TOKEN id="token-13-47" pos="word" morph="none" start_char="2083" end_char="2085">ago</TOKEN>
<TOKEN id="token-13-48" pos="word" morph="none" start_char="2087" end_char="2090">that</TOKEN>
<TOKEN id="token-13-49" pos="word" morph="none" start_char="2092" end_char="2093">it</TOKEN>
<TOKEN id="token-13-50" pos="word" morph="none" start_char="2095" end_char="2097">had</TOKEN>
<TOKEN id="token-13-51" pos="word" morph="none" start_char="2099" end_char="2107">developed</TOKEN>
<TOKEN id="token-13-52" pos="word" morph="none" start_char="2109" end_char="2109">a</TOKEN>
<TOKEN id="token-13-53" pos="unknown" morph="none" start_char="2111" end_char="2118">COVID-19</TOKEN>
<TOKEN id="token-13-54" pos="word" morph="none" start_char="2120" end_char="2123">test</TOKEN>
<TOKEN id="token-13-55" pos="word" morph="none" start_char="2125" end_char="2127">for</TOKEN>
<TOKEN id="token-13-56" pos="word" morph="none" start_char="2129" end_char="2132">pets</TOKEN>
<TOKEN id="token-13-57" pos="punct" morph="none" start_char="2133" end_char="2133">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="2136" end_char="2217">
<ORIGINAL_TEXT>WADDL created its test at the request of local and federal animal health agencies.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="2136" end_char="2140">WADDL</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="2142" end_char="2148">created</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="2150" end_char="2152">its</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="2154" end_char="2157">test</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="2159" end_char="2160">at</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="2162" end_char="2164">the</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="2166" end_char="2172">request</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="2174" end_char="2175">of</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="2177" end_char="2181">local</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="2183" end_char="2185">and</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="2187" end_char="2193">federal</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="2195" end_char="2200">animal</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="2202" end_char="2207">health</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="2209" end_char="2216">agencies</TOKEN>
<TOKEN id="token-14-14" pos="punct" morph="none" start_char="2217" end_char="2217">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="2219" end_char="2410">
<ORIGINAL_TEXT>Officials were concerned because a nursing home in Kirkland, Washington—site of one of the first U.S. cluster outbreaks of COVID-19 in early March—was also home to a number of residents’ cats.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="2219" end_char="2227">Officials</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="2229" end_char="2232">were</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="2234" end_char="2242">concerned</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="2244" end_char="2250">because</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="2252" end_char="2252">a</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="2254" end_char="2260">nursing</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="2262" end_char="2265">home</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="2267" end_char="2268">in</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="2270" end_char="2277">Kirkland</TOKEN>
<TOKEN id="token-15-9" pos="punct" morph="none" start_char="2278" end_char="2278">,</TOKEN>
<TOKEN id="token-15-10" pos="unknown" morph="none" start_char="2280" end_char="2294">Washington—site</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="2296" end_char="2297">of</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="2299" end_char="2301">one</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="2303" end_char="2304">of</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="2306" end_char="2308">the</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="2310" end_char="2314">first</TOKEN>
<TOKEN id="token-15-16" pos="unknown" morph="none" start_char="2316" end_char="2318">U.S</TOKEN>
<TOKEN id="token-15-17" pos="punct" morph="none" start_char="2319" end_char="2319">.</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="2321" end_char="2327">cluster</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="2329" end_char="2337">outbreaks</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="2339" end_char="2340">of</TOKEN>
<TOKEN id="token-15-21" pos="unknown" morph="none" start_char="2342" end_char="2349">COVID-19</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="2351" end_char="2352">in</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="2354" end_char="2358">early</TOKEN>
<TOKEN id="token-15-24" pos="unknown" morph="none" start_char="2360" end_char="2368">March—was</TOKEN>
<TOKEN id="token-15-25" pos="word" morph="none" start_char="2370" end_char="2373">also</TOKEN>
<TOKEN id="token-15-26" pos="word" morph="none" start_char="2375" end_char="2378">home</TOKEN>
<TOKEN id="token-15-27" pos="word" morph="none" start_char="2380" end_char="2381">to</TOKEN>
<TOKEN id="token-15-28" pos="word" morph="none" start_char="2383" end_char="2383">a</TOKEN>
<TOKEN id="token-15-29" pos="word" morph="none" start_char="2385" end_char="2390">number</TOKEN>
<TOKEN id="token-15-30" pos="word" morph="none" start_char="2392" end_char="2393">of</TOKEN>
<TOKEN id="token-15-31" pos="word" morph="none" start_char="2395" end_char="2403">residents</TOKEN>
<TOKEN id="token-15-32" pos="punct" morph="none" start_char="2404" end_char="2404">’</TOKEN>
<TOKEN id="token-15-33" pos="word" morph="none" start_char="2406" end_char="2409">cats</TOKEN>
<TOKEN id="token-15-34" pos="punct" morph="none" start_char="2410" end_char="2410">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="2412" end_char="2700">
<ORIGINAL_TEXT>Dogs and cats share many of the same cell receptors we do—which viruses can bind to—and during the 2003 outbreak of severe acute respiratory syndrome (a coronavirus relative of SARS-CoV-2), scientists reported that cats could become infected with the virus and pass it on to other felines.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="2412" end_char="2415">Dogs</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="2417" end_char="2419">and</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="2421" end_char="2424">cats</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="2426" end_char="2430">share</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="2432" end_char="2435">many</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="2437" end_char="2438">of</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="2440" end_char="2442">the</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="2444" end_char="2447">same</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="2449" end_char="2452">cell</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="2454" end_char="2462">receptors</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="2464" end_char="2465">we</TOKEN>
<TOKEN id="token-16-11" pos="unknown" morph="none" start_char="2467" end_char="2474">do—which</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="2476" end_char="2482">viruses</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="2484" end_char="2486">can</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="2488" end_char="2491">bind</TOKEN>
<TOKEN id="token-16-15" pos="unknown" morph="none" start_char="2493" end_char="2498">to—and</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="2500" end_char="2505">during</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="2507" end_char="2509">the</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="2511" end_char="2514">2003</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="2516" end_char="2523">outbreak</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="2525" end_char="2526">of</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="2528" end_char="2533">severe</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="2535" end_char="2539">acute</TOKEN>
<TOKEN id="token-16-23" pos="word" morph="none" start_char="2541" end_char="2551">respiratory</TOKEN>
<TOKEN id="token-16-24" pos="word" morph="none" start_char="2553" end_char="2560">syndrome</TOKEN>
<TOKEN id="token-16-25" pos="punct" morph="none" start_char="2562" end_char="2562">(</TOKEN>
<TOKEN id="token-16-26" pos="word" morph="none" start_char="2563" end_char="2563">a</TOKEN>
<TOKEN id="token-16-27" pos="word" morph="none" start_char="2565" end_char="2575">coronavirus</TOKEN>
<TOKEN id="token-16-28" pos="word" morph="none" start_char="2577" end_char="2584">relative</TOKEN>
<TOKEN id="token-16-29" pos="word" morph="none" start_char="2586" end_char="2587">of</TOKEN>
<TOKEN id="token-16-30" pos="unknown" morph="none" start_char="2589" end_char="2598">SARS-CoV-2</TOKEN>
<TOKEN id="token-16-31" pos="punct" morph="none" start_char="2599" end_char="2600">),</TOKEN>
<TOKEN id="token-16-32" pos="word" morph="none" start_char="2602" end_char="2611">scientists</TOKEN>
<TOKEN id="token-16-33" pos="word" morph="none" start_char="2613" end_char="2620">reported</TOKEN>
<TOKEN id="token-16-34" pos="word" morph="none" start_char="2622" end_char="2625">that</TOKEN>
<TOKEN id="token-16-35" pos="word" morph="none" start_char="2627" end_char="2630">cats</TOKEN>
<TOKEN id="token-16-36" pos="word" morph="none" start_char="2632" end_char="2636">could</TOKEN>
<TOKEN id="token-16-37" pos="word" morph="none" start_char="2638" end_char="2643">become</TOKEN>
<TOKEN id="token-16-38" pos="word" morph="none" start_char="2645" end_char="2652">infected</TOKEN>
<TOKEN id="token-16-39" pos="word" morph="none" start_char="2654" end_char="2657">with</TOKEN>
<TOKEN id="token-16-40" pos="word" morph="none" start_char="2659" end_char="2661">the</TOKEN>
<TOKEN id="token-16-41" pos="word" morph="none" start_char="2663" end_char="2667">virus</TOKEN>
<TOKEN id="token-16-42" pos="word" morph="none" start_char="2669" end_char="2671">and</TOKEN>
<TOKEN id="token-16-43" pos="word" morph="none" start_char="2673" end_char="2676">pass</TOKEN>
<TOKEN id="token-16-44" pos="word" morph="none" start_char="2678" end_char="2679">it</TOKEN>
<TOKEN id="token-16-45" pos="word" morph="none" start_char="2681" end_char="2682">on</TOKEN>
<TOKEN id="token-16-46" pos="word" morph="none" start_char="2684" end_char="2685">to</TOKEN>
<TOKEN id="token-16-47" pos="word" morph="none" start_char="2687" end_char="2691">other</TOKEN>
<TOKEN id="token-16-48" pos="word" morph="none" start_char="2693" end_char="2699">felines</TOKEN>
<TOKEN id="token-16-49" pos="punct" morph="none" start_char="2700" end_char="2700">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2703" end_char="2834">
<ORIGINAL_TEXT>WADDL’s SARS-CoV-2 pet test is similar to the human test: It uses the polymerase chain reaction (PCR) to amplify RNA from the virus.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2703" end_char="2709">WADDL’s</TOKEN>
<TOKEN id="token-17-1" pos="unknown" morph="none" start_char="2711" end_char="2720">SARS-CoV-2</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2722" end_char="2724">pet</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2726" end_char="2729">test</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2731" end_char="2732">is</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2734" end_char="2740">similar</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2742" end_char="2743">to</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2745" end_char="2747">the</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2749" end_char="2753">human</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2755" end_char="2758">test</TOKEN>
<TOKEN id="token-17-10" pos="punct" morph="none" start_char="2759" end_char="2759">:</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2761" end_char="2762">It</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2764" end_char="2767">uses</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2769" end_char="2771">the</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2773" end_char="2782">polymerase</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2784" end_char="2788">chain</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="2790" end_char="2797">reaction</TOKEN>
<TOKEN id="token-17-17" pos="punct" morph="none" start_char="2799" end_char="2799">(</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="2800" end_char="2802">PCR</TOKEN>
<TOKEN id="token-17-19" pos="punct" morph="none" start_char="2803" end_char="2803">)</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="2805" end_char="2806">to</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="2808" end_char="2814">amplify</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="2816" end_char="2818">RNA</TOKEN>
<TOKEN id="token-17-23" pos="word" morph="none" start_char="2820" end_char="2823">from</TOKEN>
<TOKEN id="token-17-24" pos="word" morph="none" start_char="2825" end_char="2827">the</TOKEN>
<TOKEN id="token-17-25" pos="word" morph="none" start_char="2829" end_char="2833">virus</TOKEN>
<TOKEN id="token-17-26" pos="punct" morph="none" start_char="2834" end_char="2834">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2836" end_char="3031">
<ORIGINAL_TEXT>Baszler says his team developed it with dozens of archived samples of nasal and throat swabs from cats and dogs collected from the western United States, some of which were seeded with SARS-CoV-2.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2836" end_char="2842">Baszler</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2844" end_char="2847">says</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2849" end_char="2851">his</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2853" end_char="2856">team</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2858" end_char="2866">developed</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2868" end_char="2869">it</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2871" end_char="2874">with</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2876" end_char="2881">dozens</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2883" end_char="2884">of</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="2886" end_char="2893">archived</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="2895" end_char="2901">samples</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="2903" end_char="2904">of</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2906" end_char="2910">nasal</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="2912" end_char="2914">and</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="2916" end_char="2921">throat</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="2923" end_char="2927">swabs</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="2929" end_char="2932">from</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="2934" end_char="2937">cats</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="2939" end_char="2941">and</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="2943" end_char="2946">dogs</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="2948" end_char="2956">collected</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="2958" end_char="2961">from</TOKEN>
<TOKEN id="token-18-22" pos="word" morph="none" start_char="2963" end_char="2965">the</TOKEN>
<TOKEN id="token-18-23" pos="word" morph="none" start_char="2967" end_char="2973">western</TOKEN>
<TOKEN id="token-18-24" pos="word" morph="none" start_char="2975" end_char="2980">United</TOKEN>
<TOKEN id="token-18-25" pos="word" morph="none" start_char="2982" end_char="2987">States</TOKEN>
<TOKEN id="token-18-26" pos="punct" morph="none" start_char="2988" end_char="2988">,</TOKEN>
<TOKEN id="token-18-27" pos="word" morph="none" start_char="2990" end_char="2993">some</TOKEN>
<TOKEN id="token-18-28" pos="word" morph="none" start_char="2995" end_char="2996">of</TOKEN>
<TOKEN id="token-18-29" pos="word" morph="none" start_char="2998" end_char="3002">which</TOKEN>
<TOKEN id="token-18-30" pos="word" morph="none" start_char="3004" end_char="3007">were</TOKEN>
<TOKEN id="token-18-31" pos="word" morph="none" start_char="3009" end_char="3014">seeded</TOKEN>
<TOKEN id="token-18-32" pos="word" morph="none" start_char="3016" end_char="3019">with</TOKEN>
<TOKEN id="token-18-33" pos="unknown" morph="none" start_char="3021" end_char="3030">SARS-CoV-2</TOKEN>
<TOKEN id="token-18-34" pos="punct" morph="none" start_char="3031" end_char="3031">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="3033" end_char="3197">
<ORIGINAL_TEXT>Though none of these animals had COVID-19, the test was able to pick up the virus in the seeded samples, while not reporting false positives for other coronaviruses.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="3033" end_char="3038">Though</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="3040" end_char="3043">none</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="3045" end_char="3046">of</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="3048" end_char="3052">these</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="3054" end_char="3060">animals</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="3062" end_char="3064">had</TOKEN>
<TOKEN id="token-19-6" pos="unknown" morph="none" start_char="3066" end_char="3073">COVID-19</TOKEN>
<TOKEN id="token-19-7" pos="punct" morph="none" start_char="3074" end_char="3074">,</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="3076" end_char="3078">the</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="3080" end_char="3083">test</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="3085" end_char="3087">was</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="3089" end_char="3092">able</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="3094" end_char="3095">to</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="3097" end_char="3100">pick</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="3102" end_char="3103">up</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="3105" end_char="3107">the</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="3109" end_char="3113">virus</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="3115" end_char="3116">in</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="3118" end_char="3120">the</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="3122" end_char="3127">seeded</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="3129" end_char="3135">samples</TOKEN>
<TOKEN id="token-19-21" pos="punct" morph="none" start_char="3136" end_char="3136">,</TOKEN>
<TOKEN id="token-19-22" pos="word" morph="none" start_char="3138" end_char="3142">while</TOKEN>
<TOKEN id="token-19-23" pos="word" morph="none" start_char="3144" end_char="3146">not</TOKEN>
<TOKEN id="token-19-24" pos="word" morph="none" start_char="3148" end_char="3156">reporting</TOKEN>
<TOKEN id="token-19-25" pos="word" morph="none" start_char="3158" end_char="3162">false</TOKEN>
<TOKEN id="token-19-26" pos="word" morph="none" start_char="3164" end_char="3172">positives</TOKEN>
<TOKEN id="token-19-27" pos="word" morph="none" start_char="3174" end_char="3176">for</TOKEN>
<TOKEN id="token-19-28" pos="word" morph="none" start_char="3178" end_char="3182">other</TOKEN>
<TOKEN id="token-19-29" pos="word" morph="none" start_char="3184" end_char="3196">coronaviruses</TOKEN>
<TOKEN id="token-19-30" pos="punct" morph="none" start_char="3197" end_char="3197">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="3199" end_char="3338">
<ORIGINAL_TEXT>Baszler says the World Health Organization has approved the diagnostic and that WADDL could start to test up to 100 pets per day, if needed.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="3199" end_char="3205">Baszler</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="3207" end_char="3210">says</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="3212" end_char="3214">the</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="3216" end_char="3220">World</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="3222" end_char="3227">Health</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="3229" end_char="3240">Organization</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="3242" end_char="3244">has</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="3246" end_char="3253">approved</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="3255" end_char="3257">the</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="3259" end_char="3268">diagnostic</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="3270" end_char="3272">and</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="3274" end_char="3277">that</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="3279" end_char="3283">WADDL</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="3285" end_char="3289">could</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="3291" end_char="3295">start</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="3297" end_char="3298">to</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="3300" end_char="3303">test</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="3305" end_char="3306">up</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="3308" end_char="3309">to</TOKEN>
<TOKEN id="token-20-19" pos="word" morph="none" start_char="3311" end_char="3313">100</TOKEN>
<TOKEN id="token-20-20" pos="word" morph="none" start_char="3315" end_char="3318">pets</TOKEN>
<TOKEN id="token-20-21" pos="word" morph="none" start_char="3320" end_char="3322">per</TOKEN>
<TOKEN id="token-20-22" pos="word" morph="none" start_char="3324" end_char="3326">day</TOKEN>
<TOKEN id="token-20-23" pos="punct" morph="none" start_char="3327" end_char="3327">,</TOKEN>
<TOKEN id="token-20-24" pos="word" morph="none" start_char="3329" end_char="3330">if</TOKEN>
<TOKEN id="token-20-25" pos="word" morph="none" start_char="3332" end_char="3337">needed</TOKEN>
<TOKEN id="token-20-26" pos="punct" morph="none" start_char="3338" end_char="3338">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="3341" end_char="3468">
<ORIGINAL_TEXT>IDEXX Laboratories, a global network of more than 80 diagnostic labs, also announced a SARS-CoV-2 test for animals in mid-March.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="3341" end_char="3345">IDEXX</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="3347" end_char="3358">Laboratories</TOKEN>
<TOKEN id="token-21-2" pos="punct" morph="none" start_char="3359" end_char="3359">,</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="3361" end_char="3361">a</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="3363" end_char="3368">global</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="3370" end_char="3376">network</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="3378" end_char="3379">of</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="3381" end_char="3384">more</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="3386" end_char="3389">than</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="3391" end_char="3392">80</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="3394" end_char="3403">diagnostic</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="3405" end_char="3408">labs</TOKEN>
<TOKEN id="token-21-12" pos="punct" morph="none" start_char="3409" end_char="3409">,</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="3411" end_char="3414">also</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="3416" end_char="3424">announced</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="3426" end_char="3426">a</TOKEN>
<TOKEN id="token-21-16" pos="unknown" morph="none" start_char="3428" end_char="3437">SARS-CoV-2</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="3439" end_char="3442">test</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="3444" end_char="3446">for</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="3448" end_char="3454">animals</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="3456" end_char="3457">in</TOKEN>
<TOKEN id="token-21-21" pos="unknown" morph="none" start_char="3459" end_char="3467">mid-March</TOKEN>
<TOKEN id="token-21-22" pos="punct" morph="none" start_char="3468" end_char="3468">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="3470" end_char="3559">
<ORIGINAL_TEXT>Like the WADDL test, it’s based on PCR and was developed using samples from cats and dogs.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="3470" end_char="3473">Like</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="3475" end_char="3477">the</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="3479" end_char="3483">WADDL</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="3485" end_char="3488">test</TOKEN>
<TOKEN id="token-22-4" pos="punct" morph="none" start_char="3489" end_char="3489">,</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="3491" end_char="3494">it’s</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="3496" end_char="3500">based</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="3502" end_char="3503">on</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="3505" end_char="3507">PCR</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="3509" end_char="3511">and</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="3513" end_char="3515">was</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="3517" end_char="3525">developed</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="3527" end_char="3531">using</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="3533" end_char="3539">samples</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="3541" end_char="3544">from</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="3546" end_char="3549">cats</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="3551" end_char="3553">and</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="3555" end_char="3558">dogs</TOKEN>
<TOKEN id="token-22-18" pos="punct" morph="none" start_char="3559" end_char="3559">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="3561" end_char="3620">
<ORIGINAL_TEXT>(In IDEXX’s case, test development used horse samples, too.)</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="punct" morph="none" start_char="3561" end_char="3561">(</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="3562" end_char="3563">In</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="3565" end_char="3571">IDEXX’s</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="3573" end_char="3576">case</TOKEN>
<TOKEN id="token-23-4" pos="punct" morph="none" start_char="3577" end_char="3577">,</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="3579" end_char="3582">test</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="3584" end_char="3594">development</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="3596" end_char="3599">used</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="3601" end_char="3605">horse</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="3607" end_char="3613">samples</TOKEN>
<TOKEN id="token-23-10" pos="punct" morph="none" start_char="3614" end_char="3614">,</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="3616" end_char="3618">too</TOKEN>
<TOKEN id="token-23-12" pos="punct" morph="none" start_char="3619" end_char="3620">.)</TOKEN>
</SEG>
<SEG id="segment-24" start_char="3622" end_char="3730">
<ORIGINAL_TEXT>The company has analyzed more than 4000 samples, including specimens from animals with respiratory disorders.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="3622" end_char="3624">The</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="3626" end_char="3632">company</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="3634" end_char="3636">has</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="3638" end_char="3645">analyzed</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="3647" end_char="3650">more</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="3652" end_char="3655">than</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="3657" end_char="3660">4000</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="3662" end_char="3668">samples</TOKEN>
<TOKEN id="token-24-8" pos="punct" morph="none" start_char="3669" end_char="3669">,</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="3671" end_char="3679">including</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="3681" end_char="3689">specimens</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="3691" end_char="3694">from</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="3696" end_char="3702">animals</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="3704" end_char="3707">with</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="3709" end_char="3719">respiratory</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="3721" end_char="3729">disorders</TOKEN>
<TOKEN id="token-24-16" pos="punct" morph="none" start_char="3730" end_char="3730">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="3732" end_char="3809">
<ORIGINAL_TEXT>"All have come back negative," says Jim Blacka, the company’s senior director.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="punct" morph="none" start_char="3732" end_char="3732">"</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="3733" end_char="3735">All</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="3737" end_char="3740">have</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="3742" end_char="3745">come</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="3747" end_char="3750">back</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="3752" end_char="3759">negative</TOKEN>
<TOKEN id="token-25-6" pos="punct" morph="none" start_char="3760" end_char="3761">,"</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="3763" end_char="3766">says</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="3768" end_char="3770">Jim</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="3772" end_char="3777">Blacka</TOKEN>
<TOKEN id="token-25-10" pos="punct" morph="none" start_char="3778" end_char="3778">,</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="3780" end_char="3782">the</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="3784" end_char="3792">company’s</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="3794" end_char="3799">senior</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="3801" end_char="3808">director</TOKEN>
<TOKEN id="token-25-15" pos="punct" morph="none" start_char="3809" end_char="3809">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="3811" end_char="3915">
<ORIGINAL_TEXT>"If there is a need to start testing pets, we’re ready to commercialize it and make it widely available."</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="punct" morph="none" start_char="3811" end_char="3811">"</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="3812" end_char="3813">If</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="3815" end_char="3819">there</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="3821" end_char="3822">is</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="3824" end_char="3824">a</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="3826" end_char="3829">need</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="3831" end_char="3832">to</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="3834" end_char="3838">start</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="3840" end_char="3846">testing</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="3848" end_char="3851">pets</TOKEN>
<TOKEN id="token-26-10" pos="punct" morph="none" start_char="3852" end_char="3852">,</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="3854" end_char="3858">we’re</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="3860" end_char="3864">ready</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="3866" end_char="3867">to</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="3869" end_char="3881">commercialize</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="3883" end_char="3884">it</TOKEN>
<TOKEN id="token-26-16" pos="word" morph="none" start_char="3886" end_char="3888">and</TOKEN>
<TOKEN id="token-26-17" pos="word" morph="none" start_char="3890" end_char="3893">make</TOKEN>
<TOKEN id="token-26-18" pos="word" morph="none" start_char="3895" end_char="3896">it</TOKEN>
<TOKEN id="token-26-19" pos="word" morph="none" start_char="3898" end_char="3903">widely</TOKEN>
<TOKEN id="token-26-20" pos="word" morph="none" start_char="3905" end_char="3913">available</TOKEN>
<TOKEN id="token-26-21" pos="punct" morph="none" start_char="3914" end_char="3915">."</TOKEN>
</SEG>
<SEG id="segment-27" start_char="3918" end_char="3970">
<ORIGINAL_TEXT>But there are roadblocks to implementing either test.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="3918" end_char="3920">But</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="3922" end_char="3926">there</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="3928" end_char="3930">are</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="3932" end_char="3941">roadblocks</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="3943" end_char="3944">to</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="3946" end_char="3957">implementing</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="3959" end_char="3964">either</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="3966" end_char="3969">test</TOKEN>
<TOKEN id="token-27-8" pos="punct" morph="none" start_char="3970" end_char="3970">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3972" end_char="4008">
<ORIGINAL_TEXT>The first issue is a lack of urgency.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="3972" end_char="3974">The</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="3976" end_char="3980">first</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="3982" end_char="3986">issue</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="3988" end_char="3989">is</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="3991" end_char="3991">a</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="3993" end_char="3996">lack</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="3998" end_char="3999">of</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="4001" end_char="4007">urgency</TOKEN>
<TOKEN id="token-28-8" pos="punct" morph="none" start_char="4008" end_char="4008">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="4010" end_char="4274">
<ORIGINAL_TEXT>Given that there are about 150 million dogs and cats in the United States alone, if pets could readily catch COVID-19, we would be seeing tons of cases of by now, says Shelley Rankin, a microbiologist at the University of Pennsylvania School of Veterinary Medicine.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="4010" end_char="4014">Given</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="4016" end_char="4019">that</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="4021" end_char="4025">there</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="4027" end_char="4029">are</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="4031" end_char="4035">about</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="4037" end_char="4039">150</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="4041" end_char="4047">million</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="4049" end_char="4052">dogs</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="4054" end_char="4056">and</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="4058" end_char="4061">cats</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="4063" end_char="4064">in</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="4066" end_char="4068">the</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="4070" end_char="4075">United</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="4077" end_char="4082">States</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="4084" end_char="4088">alone</TOKEN>
<TOKEN id="token-29-15" pos="punct" morph="none" start_char="4089" end_char="4089">,</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="4091" end_char="4092">if</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="4094" end_char="4097">pets</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="4099" end_char="4103">could</TOKEN>
<TOKEN id="token-29-19" pos="word" morph="none" start_char="4105" end_char="4111">readily</TOKEN>
<TOKEN id="token-29-20" pos="word" morph="none" start_char="4113" end_char="4117">catch</TOKEN>
<TOKEN id="token-29-21" pos="unknown" morph="none" start_char="4119" end_char="4126">COVID-19</TOKEN>
<TOKEN id="token-29-22" pos="punct" morph="none" start_char="4127" end_char="4127">,</TOKEN>
<TOKEN id="token-29-23" pos="word" morph="none" start_char="4129" end_char="4130">we</TOKEN>
<TOKEN id="token-29-24" pos="word" morph="none" start_char="4132" end_char="4136">would</TOKEN>
<TOKEN id="token-29-25" pos="word" morph="none" start_char="4138" end_char="4139">be</TOKEN>
<TOKEN id="token-29-26" pos="word" morph="none" start_char="4141" end_char="4146">seeing</TOKEN>
<TOKEN id="token-29-27" pos="word" morph="none" start_char="4148" end_char="4151">tons</TOKEN>
<TOKEN id="token-29-28" pos="word" morph="none" start_char="4153" end_char="4154">of</TOKEN>
<TOKEN id="token-29-29" pos="word" morph="none" start_char="4156" end_char="4160">cases</TOKEN>
<TOKEN id="token-29-30" pos="word" morph="none" start_char="4162" end_char="4163">of</TOKEN>
<TOKEN id="token-29-31" pos="word" morph="none" start_char="4165" end_char="4166">by</TOKEN>
<TOKEN id="token-29-32" pos="word" morph="none" start_char="4168" end_char="4170">now</TOKEN>
<TOKEN id="token-29-33" pos="punct" morph="none" start_char="4171" end_char="4171">,</TOKEN>
<TOKEN id="token-29-34" pos="word" morph="none" start_char="4173" end_char="4176">says</TOKEN>
<TOKEN id="token-29-35" pos="word" morph="none" start_char="4178" end_char="4184">Shelley</TOKEN>
<TOKEN id="token-29-36" pos="word" morph="none" start_char="4186" end_char="4191">Rankin</TOKEN>
<TOKEN id="token-29-37" pos="punct" morph="none" start_char="4192" end_char="4192">,</TOKEN>
<TOKEN id="token-29-38" pos="word" morph="none" start_char="4194" end_char="4194">a</TOKEN>
<TOKEN id="token-29-39" pos="word" morph="none" start_char="4196" end_char="4209">microbiologist</TOKEN>
<TOKEN id="token-29-40" pos="word" morph="none" start_char="4211" end_char="4212">at</TOKEN>
<TOKEN id="token-29-41" pos="word" morph="none" start_char="4214" end_char="4216">the</TOKEN>
<TOKEN id="token-29-42" pos="word" morph="none" start_char="4218" end_char="4227">University</TOKEN>
<TOKEN id="token-29-43" pos="word" morph="none" start_char="4229" end_char="4230">of</TOKEN>
<TOKEN id="token-29-44" pos="word" morph="none" start_char="4232" end_char="4243">Pennsylvania</TOKEN>
<TOKEN id="token-29-45" pos="word" morph="none" start_char="4245" end_char="4250">School</TOKEN>
<TOKEN id="token-29-46" pos="word" morph="none" start_char="4252" end_char="4253">of</TOKEN>
<TOKEN id="token-29-47" pos="word" morph="none" start_char="4255" end_char="4264">Veterinary</TOKEN>
<TOKEN id="token-29-48" pos="word" morph="none" start_char="4266" end_char="4273">Medicine</TOKEN>
<TOKEN id="token-29-49" pos="punct" morph="none" start_char="4274" end_char="4274">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="4276" end_char="4352">
<ORIGINAL_TEXT>"Yet nobody is reporting a spike" in respiratory infections in cats and dogs.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="punct" morph="none" start_char="4276" end_char="4276">"</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="4277" end_char="4279">Yet</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="4281" end_char="4286">nobody</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="4288" end_char="4289">is</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="4291" end_char="4299">reporting</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="4301" end_char="4301">a</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="4303" end_char="4307">spike</TOKEN>
<TOKEN id="token-30-7" pos="punct" morph="none" start_char="4308" end_char="4308">"</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="4310" end_char="4311">in</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="4313" end_char="4323">respiratory</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="4325" end_char="4334">infections</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="4336" end_char="4337">in</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="4339" end_char="4342">cats</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="4344" end_char="4346">and</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="4348" end_char="4351">dogs</TOKEN>
<TOKEN id="token-30-15" pos="punct" morph="none" start_char="4352" end_char="4352">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="4355" end_char="4583">
<ORIGINAL_TEXT>Even the three pets that have tested positive for the virus shouldn’t sound an alarm, says Jonathan Epstein, vice president for science and outreach at the EcoHealth Alliance, a nonprofit that tracks emerging diseases in animals.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="4355" end_char="4358">Even</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="4360" end_char="4362">the</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="4364" end_char="4368">three</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="4370" end_char="4373">pets</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="4375" end_char="4378">that</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="4380" end_char="4383">have</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="4385" end_char="4390">tested</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="4392" end_char="4399">positive</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="4401" end_char="4403">for</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="4405" end_char="4407">the</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="4409" end_char="4413">virus</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="4415" end_char="4423">shouldn’t</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="4425" end_char="4429">sound</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="4431" end_char="4432">an</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="4434" end_char="4438">alarm</TOKEN>
<TOKEN id="token-31-15" pos="punct" morph="none" start_char="4439" end_char="4439">,</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="4441" end_char="4444">says</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="4446" end_char="4453">Jonathan</TOKEN>
<TOKEN id="token-31-18" pos="word" morph="none" start_char="4455" end_char="4461">Epstein</TOKEN>
<TOKEN id="token-31-19" pos="punct" morph="none" start_char="4462" end_char="4462">,</TOKEN>
<TOKEN id="token-31-20" pos="word" morph="none" start_char="4464" end_char="4467">vice</TOKEN>
<TOKEN id="token-31-21" pos="word" morph="none" start_char="4469" end_char="4477">president</TOKEN>
<TOKEN id="token-31-22" pos="word" morph="none" start_char="4479" end_char="4481">for</TOKEN>
<TOKEN id="token-31-23" pos="word" morph="none" start_char="4483" end_char="4489">science</TOKEN>
<TOKEN id="token-31-24" pos="word" morph="none" start_char="4491" end_char="4493">and</TOKEN>
<TOKEN id="token-31-25" pos="word" morph="none" start_char="4495" end_char="4502">outreach</TOKEN>
<TOKEN id="token-31-26" pos="word" morph="none" start_char="4504" end_char="4505">at</TOKEN>
<TOKEN id="token-31-27" pos="word" morph="none" start_char="4507" end_char="4509">the</TOKEN>
<TOKEN id="token-31-28" pos="word" morph="none" start_char="4511" end_char="4519">EcoHealth</TOKEN>
<TOKEN id="token-31-29" pos="word" morph="none" start_char="4521" end_char="4528">Alliance</TOKEN>
<TOKEN id="token-31-30" pos="punct" morph="none" start_char="4529" end_char="4529">,</TOKEN>
<TOKEN id="token-31-31" pos="word" morph="none" start_char="4531" end_char="4531">a</TOKEN>
<TOKEN id="token-31-32" pos="word" morph="none" start_char="4533" end_char="4541">nonprofit</TOKEN>
<TOKEN id="token-31-33" pos="word" morph="none" start_char="4543" end_char="4546">that</TOKEN>
<TOKEN id="token-31-34" pos="word" morph="none" start_char="4548" end_char="4553">tracks</TOKEN>
<TOKEN id="token-31-35" pos="word" morph="none" start_char="4555" end_char="4562">emerging</TOKEN>
<TOKEN id="token-31-36" pos="word" morph="none" start_char="4564" end_char="4571">diseases</TOKEN>
<TOKEN id="token-31-37" pos="word" morph="none" start_char="4573" end_char="4574">in</TOKEN>
<TOKEN id="token-31-38" pos="word" morph="none" start_char="4576" end_char="4582">animals</TOKEN>
<TOKEN id="token-31-39" pos="punct" morph="none" start_char="4583" end_char="4583">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="4585" end_char="4663">
<ORIGINAL_TEXT>"Detecting RNA is different from [animals] shedding infectious virus," he says.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="punct" morph="none" start_char="4585" end_char="4585">"</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="4586" end_char="4594">Detecting</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="4596" end_char="4598">RNA</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="4600" end_char="4601">is</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="4603" end_char="4611">different</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="4613" end_char="4616">from</TOKEN>
<TOKEN id="token-32-6" pos="punct" morph="none" start_char="4618" end_char="4618">[</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="4619" end_char="4625">animals</TOKEN>
<TOKEN id="token-32-8" pos="punct" morph="none" start_char="4626" end_char="4626">]</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="4628" end_char="4635">shedding</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="4637" end_char="4646">infectious</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="4648" end_char="4652">virus</TOKEN>
<TOKEN id="token-32-12" pos="punct" morph="none" start_char="4653" end_char="4654">,"</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="4656" end_char="4657">he</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="4659" end_char="4662">says</TOKEN>
<TOKEN id="token-32-15" pos="punct" morph="none" start_char="4663" end_char="4663">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="4665" end_char="4765">
<ORIGINAL_TEXT>"Our focus now should be on human-to-human transmission, because that’s what’s driving the epidemic."</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="punct" morph="none" start_char="4665" end_char="4665">"</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="4666" end_char="4668">Our</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="4670" end_char="4674">focus</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="4676" end_char="4678">now</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="4680" end_char="4685">should</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="4687" end_char="4688">be</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="4690" end_char="4691">on</TOKEN>
<TOKEN id="token-33-7" pos="unknown" morph="none" start_char="4693" end_char="4706">human-to-human</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="4708" end_char="4719">transmission</TOKEN>
<TOKEN id="token-33-9" pos="punct" morph="none" start_char="4720" end_char="4720">,</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="4722" end_char="4728">because</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="4730" end_char="4735">that’s</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="4737" end_char="4742">what’s</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="4744" end_char="4750">driving</TOKEN>
<TOKEN id="token-33-14" pos="word" morph="none" start_char="4752" end_char="4754">the</TOKEN>
<TOKEN id="token-33-15" pos="word" morph="none" start_char="4756" end_char="4763">epidemic</TOKEN>
<TOKEN id="token-33-16" pos="punct" morph="none" start_char="4764" end_char="4765">."</TOKEN>
</SEG>
<SEG id="segment-34" start_char="4768" end_char="4833">
<ORIGINAL_TEXT>USDA released an FAQ last week that cautioned against pet testing.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="4768" end_char="4771">USDA</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="4773" end_char="4780">released</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="4782" end_char="4783">an</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="4785" end_char="4787">FAQ</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="4789" end_char="4792">last</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="4794" end_char="4797">week</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="4799" end_char="4802">that</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="4804" end_char="4812">cautioned</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="4814" end_char="4820">against</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="4822" end_char="4824">pet</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="4826" end_char="4832">testing</TOKEN>
<TOKEN id="token-34-11" pos="punct" morph="none" start_char="4833" end_char="4833">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="4835" end_char="5021">
<ORIGINAL_TEXT>"At this time, testing for companion animals will only be done if animal and public health officials agree testing should occur due to a link to a known human case of COVID-19," it reads.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="punct" morph="none" start_char="4835" end_char="4835">"</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="4836" end_char="4837">At</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="4839" end_char="4842">this</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="4844" end_char="4847">time</TOKEN>
<TOKEN id="token-35-4" pos="punct" morph="none" start_char="4848" end_char="4848">,</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="4850" end_char="4856">testing</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="4858" end_char="4860">for</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="4862" end_char="4870">companion</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="4872" end_char="4878">animals</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="4880" end_char="4883">will</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="4885" end_char="4888">only</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="4890" end_char="4891">be</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="4893" end_char="4896">done</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="4898" end_char="4899">if</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="4901" end_char="4906">animal</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="4908" end_char="4910">and</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="4912" end_char="4917">public</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="4919" end_char="4924">health</TOKEN>
<TOKEN id="token-35-18" pos="word" morph="none" start_char="4926" end_char="4934">officials</TOKEN>
<TOKEN id="token-35-19" pos="word" morph="none" start_char="4936" end_char="4940">agree</TOKEN>
<TOKEN id="token-35-20" pos="word" morph="none" start_char="4942" end_char="4948">testing</TOKEN>
<TOKEN id="token-35-21" pos="word" morph="none" start_char="4950" end_char="4955">should</TOKEN>
<TOKEN id="token-35-22" pos="word" morph="none" start_char="4957" end_char="4961">occur</TOKEN>
<TOKEN id="token-35-23" pos="word" morph="none" start_char="4963" end_char="4965">due</TOKEN>
<TOKEN id="token-35-24" pos="word" morph="none" start_char="4967" end_char="4968">to</TOKEN>
<TOKEN id="token-35-25" pos="word" morph="none" start_char="4970" end_char="4970">a</TOKEN>
<TOKEN id="token-35-26" pos="word" morph="none" start_char="4972" end_char="4975">link</TOKEN>
<TOKEN id="token-35-27" pos="word" morph="none" start_char="4977" end_char="4978">to</TOKEN>
<TOKEN id="token-35-28" pos="word" morph="none" start_char="4980" end_char="4980">a</TOKEN>
<TOKEN id="token-35-29" pos="word" morph="none" start_char="4982" end_char="4986">known</TOKEN>
<TOKEN id="token-35-30" pos="word" morph="none" start_char="4988" end_char="4992">human</TOKEN>
<TOKEN id="token-35-31" pos="word" morph="none" start_char="4994" end_char="4997">case</TOKEN>
<TOKEN id="token-35-32" pos="word" morph="none" start_char="4999" end_char="5000">of</TOKEN>
<TOKEN id="token-35-33" pos="unknown" morph="none" start_char="5002" end_char="5009">COVID-19</TOKEN>
<TOKEN id="token-35-34" pos="punct" morph="none" start_char="5010" end_char="5011">,"</TOKEN>
<TOKEN id="token-35-35" pos="word" morph="none" start_char="5013" end_char="5014">it</TOKEN>
<TOKEN id="token-35-36" pos="word" morph="none" start_char="5016" end_char="5020">reads</TOKEN>
<TOKEN id="token-35-37" pos="punct" morph="none" start_char="5021" end_char="5021">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="5023" end_char="5087">
<ORIGINAL_TEXT>"We will not be testing the general companion animal population."</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="punct" morph="none" start_char="5023" end_char="5023">"</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="5024" end_char="5025">We</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="5027" end_char="5030">will</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="5032" end_char="5034">not</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="5036" end_char="5037">be</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="5039" end_char="5045">testing</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="5047" end_char="5049">the</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="5051" end_char="5057">general</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="5059" end_char="5067">companion</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="5069" end_char="5074">animal</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="5076" end_char="5085">population</TOKEN>
<TOKEN id="token-36-11" pos="punct" morph="none" start_char="5086" end_char="5087">."</TOKEN>
</SEG>
<SEG id="segment-37" start_char="5090" end_char="5220">
<ORIGINAL_TEXT>The document, Rankin argues, effectively prevents labs from broadly testing companion animals for SARS-CoV-2 without USDA approval.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="5090" end_char="5092">The</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="5094" end_char="5101">document</TOKEN>
<TOKEN id="token-37-2" pos="punct" morph="none" start_char="5102" end_char="5102">,</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="5104" end_char="5109">Rankin</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="5111" end_char="5116">argues</TOKEN>
<TOKEN id="token-37-5" pos="punct" morph="none" start_char="5117" end_char="5117">,</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="5119" end_char="5129">effectively</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="5131" end_char="5138">prevents</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="5140" end_char="5143">labs</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="5145" end_char="5148">from</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="5150" end_char="5156">broadly</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="5158" end_char="5164">testing</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="5166" end_char="5174">companion</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="5176" end_char="5182">animals</TOKEN>
<TOKEN id="token-37-14" pos="word" morph="none" start_char="5184" end_char="5186">for</TOKEN>
<TOKEN id="token-37-15" pos="unknown" morph="none" start_char="5188" end_char="5197">SARS-CoV-2</TOKEN>
<TOKEN id="token-37-16" pos="word" morph="none" start_char="5199" end_char="5205">without</TOKEN>
<TOKEN id="token-37-17" pos="word" morph="none" start_char="5207" end_char="5210">USDA</TOKEN>
<TOKEN id="token-37-18" pos="word" morph="none" start_char="5212" end_char="5219">approval</TOKEN>
<TOKEN id="token-37-19" pos="punct" morph="none" start_char="5220" end_char="5220">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="5222" end_char="5337">
<ORIGINAL_TEXT>Baszler says the recommendations are helpful, because it’s unclear what to do if a pet tests positive for the virus.</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="5222" end_char="5228">Baszler</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="5230" end_char="5233">says</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="5235" end_char="5237">the</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="5239" end_char="5253">recommendations</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="5255" end_char="5257">are</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="5259" end_char="5265">helpful</TOKEN>
<TOKEN id="token-38-6" pos="punct" morph="none" start_char="5266" end_char="5266">,</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="5268" end_char="5274">because</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="5276" end_char="5279">it’s</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="5281" end_char="5287">unclear</TOKEN>
<TOKEN id="token-38-10" pos="word" morph="none" start_char="5289" end_char="5292">what</TOKEN>
<TOKEN id="token-38-11" pos="word" morph="none" start_char="5294" end_char="5295">to</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="5297" end_char="5298">do</TOKEN>
<TOKEN id="token-38-13" pos="word" morph="none" start_char="5300" end_char="5301">if</TOKEN>
<TOKEN id="token-38-14" pos="word" morph="none" start_char="5303" end_char="5303">a</TOKEN>
<TOKEN id="token-38-15" pos="word" morph="none" start_char="5305" end_char="5307">pet</TOKEN>
<TOKEN id="token-38-16" pos="word" morph="none" start_char="5309" end_char="5313">tests</TOKEN>
<TOKEN id="token-38-17" pos="word" morph="none" start_char="5315" end_char="5322">positive</TOKEN>
<TOKEN id="token-38-18" pos="word" morph="none" start_char="5324" end_char="5326">for</TOKEN>
<TOKEN id="token-38-19" pos="word" morph="none" start_char="5328" end_char="5330">the</TOKEN>
<TOKEN id="token-38-20" pos="word" morph="none" start_char="5332" end_char="5336">virus</TOKEN>
<TOKEN id="token-38-21" pos="punct" morph="none" start_char="5337" end_char="5337">.</TOKEN>
</SEG>
<SEG id="segment-39" start_char="5339" end_char="5435">
<ORIGINAL_TEXT>"If you get a positive dog in a home where no one else is sick, what do you do with that animal?"</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="punct" morph="none" start_char="5339" end_char="5339">"</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="5340" end_char="5341">If</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="5343" end_char="5345">you</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="5347" end_char="5349">get</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="5351" end_char="5351">a</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="5353" end_char="5360">positive</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="5362" end_char="5364">dog</TOKEN>
<TOKEN id="token-39-7" pos="word" morph="none" start_char="5366" end_char="5367">in</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="5369" end_char="5369">a</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="5371" end_char="5374">home</TOKEN>
<TOKEN id="token-39-10" pos="word" morph="none" start_char="5376" end_char="5380">where</TOKEN>
<TOKEN id="token-39-11" pos="word" morph="none" start_char="5382" end_char="5383">no</TOKEN>
<TOKEN id="token-39-12" pos="word" morph="none" start_char="5385" end_char="5387">one</TOKEN>
<TOKEN id="token-39-13" pos="word" morph="none" start_char="5389" end_char="5392">else</TOKEN>
<TOKEN id="token-39-14" pos="word" morph="none" start_char="5394" end_char="5395">is</TOKEN>
<TOKEN id="token-39-15" pos="word" morph="none" start_char="5397" end_char="5400">sick</TOKEN>
<TOKEN id="token-39-16" pos="punct" morph="none" start_char="5401" end_char="5401">,</TOKEN>
<TOKEN id="token-39-17" pos="word" morph="none" start_char="5403" end_char="5406">what</TOKEN>
<TOKEN id="token-39-18" pos="word" morph="none" start_char="5408" end_char="5409">do</TOKEN>
<TOKEN id="token-39-19" pos="word" morph="none" start_char="5411" end_char="5413">you</TOKEN>
<TOKEN id="token-39-20" pos="word" morph="none" start_char="5415" end_char="5416">do</TOKEN>
<TOKEN id="token-39-21" pos="word" morph="none" start_char="5418" end_char="5421">with</TOKEN>
<TOKEN id="token-39-22" pos="word" morph="none" start_char="5423" end_char="5426">that</TOKEN>
<TOKEN id="token-39-23" pos="word" morph="none" start_char="5428" end_char="5433">animal</TOKEN>
<TOKEN id="token-39-24" pos="punct" morph="none" start_char="5434" end_char="5435">?"</TOKEN>
</SEG>
<SEG id="segment-40" start_char="5437" end_char="5444">
<ORIGINAL_TEXT>he asks.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="5437" end_char="5438">he</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="5440" end_char="5443">asks</TOKEN>
<TOKEN id="token-40-2" pos="punct" morph="none" start_char="5444" end_char="5444">.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="5446" end_char="5467">
<ORIGINAL_TEXT>"Do you quarantine it?</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="punct" morph="none" start_char="5446" end_char="5446">"</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="5447" end_char="5448">Do</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="5450" end_char="5452">you</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="5454" end_char="5463">quarantine</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="5465" end_char="5466">it</TOKEN>
<TOKEN id="token-41-5" pos="punct" morph="none" start_char="5467" end_char="5467">?</TOKEN>
</SEG>
<SEG id="segment-42" start_char="5469" end_char="5474">
<ORIGINAL_TEXT>Where?</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="5469" end_char="5473">Where</TOKEN>
<TOKEN id="token-42-1" pos="punct" morph="none" start_char="5474" end_char="5474">?</TOKEN>
</SEG>
<SEG id="segment-43" start_char="5476" end_char="5525">
<ORIGINAL_TEXT>And who decides when that quarantine gets lifted?"</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="5476" end_char="5478">And</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="5480" end_char="5482">who</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="5484" end_char="5490">decides</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="5492" end_char="5495">when</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="5497" end_char="5500">that</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="5502" end_char="5511">quarantine</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="5513" end_char="5516">gets</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="5518" end_char="5523">lifted</TOKEN>
<TOKEN id="token-43-8" pos="punct" morph="none" start_char="5524" end_char="5525">?"</TOKEN>
</SEG>
<SEG id="segment-44" start_char="5527" end_char="5606">
<ORIGINAL_TEXT>Rushing into testing without a road map, he says, "just creates angst and fear."</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="5527" end_char="5533">Rushing</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="5535" end_char="5538">into</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="5540" end_char="5546">testing</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="5548" end_char="5554">without</TOKEN>
<TOKEN id="token-44-4" pos="word" morph="none" start_char="5556" end_char="5556">a</TOKEN>
<TOKEN id="token-44-5" pos="word" morph="none" start_char="5558" end_char="5561">road</TOKEN>
<TOKEN id="token-44-6" pos="word" morph="none" start_char="5563" end_char="5565">map</TOKEN>
<TOKEN id="token-44-7" pos="punct" morph="none" start_char="5566" end_char="5566">,</TOKEN>
<TOKEN id="token-44-8" pos="word" morph="none" start_char="5568" end_char="5569">he</TOKEN>
<TOKEN id="token-44-9" pos="word" morph="none" start_char="5571" end_char="5574">says</TOKEN>
<TOKEN id="token-44-10" pos="punct" morph="none" start_char="5575" end_char="5575">,</TOKEN>
<TOKEN id="token-44-11" pos="punct" morph="none" start_char="5577" end_char="5577">"</TOKEN>
<TOKEN id="token-44-12" pos="word" morph="none" start_char="5578" end_char="5581">just</TOKEN>
<TOKEN id="token-44-13" pos="word" morph="none" start_char="5583" end_char="5589">creates</TOKEN>
<TOKEN id="token-44-14" pos="word" morph="none" start_char="5591" end_char="5595">angst</TOKEN>
<TOKEN id="token-44-15" pos="word" morph="none" start_char="5597" end_char="5599">and</TOKEN>
<TOKEN id="token-44-16" pos="word" morph="none" start_char="5601" end_char="5604">fear</TOKEN>
<TOKEN id="token-44-17" pos="punct" morph="none" start_char="5605" end_char="5606">."</TOKEN>
</SEG>
<SEG id="segment-45" start_char="5609" end_char="5706">
<ORIGINAL_TEXT>Baszler says he is working with state veterinary officials to develop such a plan for pet testing.</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="5609" end_char="5615">Baszler</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="5617" end_char="5620">says</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="5622" end_char="5623">he</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="5625" end_char="5626">is</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="5628" end_char="5634">working</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="5636" end_char="5639">with</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="5641" end_char="5645">state</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="5647" end_char="5656">veterinary</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="5658" end_char="5666">officials</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="5668" end_char="5669">to</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="5671" end_char="5677">develop</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="5679" end_char="5682">such</TOKEN>
<TOKEN id="token-45-12" pos="word" morph="none" start_char="5684" end_char="5684">a</TOKEN>
<TOKEN id="token-45-13" pos="word" morph="none" start_char="5686" end_char="5689">plan</TOKEN>
<TOKEN id="token-45-14" pos="word" morph="none" start_char="5691" end_char="5693">for</TOKEN>
<TOKEN id="token-45-15" pos="word" morph="none" start_char="5695" end_char="5697">pet</TOKEN>
<TOKEN id="token-45-16" pos="word" morph="none" start_char="5699" end_char="5705">testing</TOKEN>
<TOKEN id="token-45-17" pos="punct" morph="none" start_char="5706" end_char="5706">.</TOKEN>
</SEG>
<SEG id="segment-46" start_char="5708" end_char="5831">
<ORIGINAL_TEXT>He says if the efforts do begin, the first focus should be on animals in homes in which humans have already tested positive.</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="5708" end_char="5709">He</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="5711" end_char="5714">says</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="5716" end_char="5717">if</TOKEN>
<TOKEN id="token-46-3" pos="word" morph="none" start_char="5719" end_char="5721">the</TOKEN>
<TOKEN id="token-46-4" pos="word" morph="none" start_char="5723" end_char="5729">efforts</TOKEN>
<TOKEN id="token-46-5" pos="word" morph="none" start_char="5731" end_char="5732">do</TOKEN>
<TOKEN id="token-46-6" pos="word" morph="none" start_char="5734" end_char="5738">begin</TOKEN>
<TOKEN id="token-46-7" pos="punct" morph="none" start_char="5739" end_char="5739">,</TOKEN>
<TOKEN id="token-46-8" pos="word" morph="none" start_char="5741" end_char="5743">the</TOKEN>
<TOKEN id="token-46-9" pos="word" morph="none" start_char="5745" end_char="5749">first</TOKEN>
<TOKEN id="token-46-10" pos="word" morph="none" start_char="5751" end_char="5755">focus</TOKEN>
<TOKEN id="token-46-11" pos="word" morph="none" start_char="5757" end_char="5762">should</TOKEN>
<TOKEN id="token-46-12" pos="word" morph="none" start_char="5764" end_char="5765">be</TOKEN>
<TOKEN id="token-46-13" pos="word" morph="none" start_char="5767" end_char="5768">on</TOKEN>
<TOKEN id="token-46-14" pos="word" morph="none" start_char="5770" end_char="5776">animals</TOKEN>
<TOKEN id="token-46-15" pos="word" morph="none" start_char="5778" end_char="5779">in</TOKEN>
<TOKEN id="token-46-16" pos="word" morph="none" start_char="5781" end_char="5785">homes</TOKEN>
<TOKEN id="token-46-17" pos="word" morph="none" start_char="5787" end_char="5788">in</TOKEN>
<TOKEN id="token-46-18" pos="word" morph="none" start_char="5790" end_char="5794">which</TOKEN>
<TOKEN id="token-46-19" pos="word" morph="none" start_char="5796" end_char="5801">humans</TOKEN>
<TOKEN id="token-46-20" pos="word" morph="none" start_char="5803" end_char="5806">have</TOKEN>
<TOKEN id="token-46-21" pos="word" morph="none" start_char="5808" end_char="5814">already</TOKEN>
<TOKEN id="token-46-22" pos="word" morph="none" start_char="5816" end_char="5821">tested</TOKEN>
<TOKEN id="token-46-23" pos="word" morph="none" start_char="5823" end_char="5830">positive</TOKEN>
<TOKEN id="token-46-24" pos="punct" morph="none" start_char="5831" end_char="5831">.</TOKEN>
</SEG>
<SEG id="segment-47" start_char="5833" end_char="5956">
<ORIGINAL_TEXT>If those animals were positive, too, veterinarians could study them to learn more about how the virus affects cats and dogs.</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="5833" end_char="5834">If</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="5836" end_char="5840">those</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="5842" end_char="5848">animals</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="5850" end_char="5853">were</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="5855" end_char="5862">positive</TOKEN>
<TOKEN id="token-47-5" pos="punct" morph="none" start_char="5863" end_char="5863">,</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="5865" end_char="5867">too</TOKEN>
<TOKEN id="token-47-7" pos="punct" morph="none" start_char="5868" end_char="5868">,</TOKEN>
<TOKEN id="token-47-8" pos="word" morph="none" start_char="5870" end_char="5882">veterinarians</TOKEN>
<TOKEN id="token-47-9" pos="word" morph="none" start_char="5884" end_char="5888">could</TOKEN>
<TOKEN id="token-47-10" pos="word" morph="none" start_char="5890" end_char="5894">study</TOKEN>
<TOKEN id="token-47-11" pos="word" morph="none" start_char="5896" end_char="5899">them</TOKEN>
<TOKEN id="token-47-12" pos="word" morph="none" start_char="5901" end_char="5902">to</TOKEN>
<TOKEN id="token-47-13" pos="word" morph="none" start_char="5904" end_char="5908">learn</TOKEN>
<TOKEN id="token-47-14" pos="word" morph="none" start_char="5910" end_char="5913">more</TOKEN>
<TOKEN id="token-47-15" pos="word" morph="none" start_char="5915" end_char="5919">about</TOKEN>
<TOKEN id="token-47-16" pos="word" morph="none" start_char="5921" end_char="5923">how</TOKEN>
<TOKEN id="token-47-17" pos="word" morph="none" start_char="5925" end_char="5927">the</TOKEN>
<TOKEN id="token-47-18" pos="word" morph="none" start_char="5929" end_char="5933">virus</TOKEN>
<TOKEN id="token-47-19" pos="word" morph="none" start_char="5935" end_char="5941">affects</TOKEN>
<TOKEN id="token-47-20" pos="word" morph="none" start_char="5943" end_char="5946">cats</TOKEN>
<TOKEN id="token-47-21" pos="word" morph="none" start_char="5948" end_char="5950">and</TOKEN>
<TOKEN id="token-47-22" pos="word" morph="none" start_char="5952" end_char="5955">dogs</TOKEN>
<TOKEN id="token-47-23" pos="punct" morph="none" start_char="5956" end_char="5956">.</TOKEN>
</SEG>
<SEG id="segment-48" start_char="5959" end_char="6076">
<ORIGINAL_TEXT>Epstein says that even if COVID-19 becomes a mere seasonal disease, knowing pets’ role in viral spread will be useful.</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="5959" end_char="5965">Epstein</TOKEN>
<TOKEN id="token-48-1" pos="word" morph="none" start_char="5967" end_char="5970">says</TOKEN>
<TOKEN id="token-48-2" pos="word" morph="none" start_char="5972" end_char="5975">that</TOKEN>
<TOKEN id="token-48-3" pos="word" morph="none" start_char="5977" end_char="5980">even</TOKEN>
<TOKEN id="token-48-4" pos="word" morph="none" start_char="5982" end_char="5983">if</TOKEN>
<TOKEN id="token-48-5" pos="unknown" morph="none" start_char="5985" end_char="5992">COVID-19</TOKEN>
<TOKEN id="token-48-6" pos="word" morph="none" start_char="5994" end_char="6000">becomes</TOKEN>
<TOKEN id="token-48-7" pos="word" morph="none" start_char="6002" end_char="6002">a</TOKEN>
<TOKEN id="token-48-8" pos="word" morph="none" start_char="6004" end_char="6007">mere</TOKEN>
<TOKEN id="token-48-9" pos="word" morph="none" start_char="6009" end_char="6016">seasonal</TOKEN>
<TOKEN id="token-48-10" pos="word" morph="none" start_char="6018" end_char="6024">disease</TOKEN>
<TOKEN id="token-48-11" pos="punct" morph="none" start_char="6025" end_char="6025">,</TOKEN>
<TOKEN id="token-48-12" pos="word" morph="none" start_char="6027" end_char="6033">knowing</TOKEN>
<TOKEN id="token-48-13" pos="word" morph="none" start_char="6035" end_char="6038">pets</TOKEN>
<TOKEN id="token-48-14" pos="punct" morph="none" start_char="6039" end_char="6039">’</TOKEN>
<TOKEN id="token-48-15" pos="word" morph="none" start_char="6041" end_char="6044">role</TOKEN>
<TOKEN id="token-48-16" pos="word" morph="none" start_char="6046" end_char="6047">in</TOKEN>
<TOKEN id="token-48-17" pos="word" morph="none" start_char="6049" end_char="6053">viral</TOKEN>
<TOKEN id="token-48-18" pos="word" morph="none" start_char="6055" end_char="6060">spread</TOKEN>
<TOKEN id="token-48-19" pos="word" morph="none" start_char="6062" end_char="6065">will</TOKEN>
<TOKEN id="token-48-20" pos="word" morph="none" start_char="6067" end_char="6068">be</TOKEN>
<TOKEN id="token-48-21" pos="word" morph="none" start_char="6070" end_char="6075">useful</TOKEN>
<TOKEN id="token-48-22" pos="punct" morph="none" start_char="6076" end_char="6076">.</TOKEN>
</SEG>
<SEG id="segment-49" start_char="6078" end_char="6270">
<ORIGINAL_TEXT>If animals do spread the virus, he says, "You’d want to take extra precautions if you have elderly relatives visiting, or if you’re bringing dogs to nursing homes as emotional support animals."</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="6078" end_char="6079">If</TOKEN>
<TOKEN id="token-49-1" pos="word" morph="none" start_char="6081" end_char="6087">animals</TOKEN>
<TOKEN id="token-49-2" pos="word" morph="none" start_char="6089" end_char="6090">do</TOKEN>
<TOKEN id="token-49-3" pos="word" morph="none" start_char="6092" end_char="6097">spread</TOKEN>
<TOKEN id="token-49-4" pos="word" morph="none" start_char="6099" end_char="6101">the</TOKEN>
<TOKEN id="token-49-5" pos="word" morph="none" start_char="6103" end_char="6107">virus</TOKEN>
<TOKEN id="token-49-6" pos="punct" morph="none" start_char="6108" end_char="6108">,</TOKEN>
<TOKEN id="token-49-7" pos="word" morph="none" start_char="6110" end_char="6111">he</TOKEN>
<TOKEN id="token-49-8" pos="word" morph="none" start_char="6113" end_char="6116">says</TOKEN>
<TOKEN id="token-49-9" pos="punct" morph="none" start_char="6117" end_char="6117">,</TOKEN>
<TOKEN id="token-49-10" pos="punct" morph="none" start_char="6119" end_char="6119">"</TOKEN>
<TOKEN id="token-49-11" pos="word" morph="none" start_char="6120" end_char="6124">You’d</TOKEN>
<TOKEN id="token-49-12" pos="word" morph="none" start_char="6126" end_char="6129">want</TOKEN>
<TOKEN id="token-49-13" pos="word" morph="none" start_char="6131" end_char="6132">to</TOKEN>
<TOKEN id="token-49-14" pos="word" morph="none" start_char="6134" end_char="6137">take</TOKEN>
<TOKEN id="token-49-15" pos="word" morph="none" start_char="6139" end_char="6143">extra</TOKEN>
<TOKEN id="token-49-16" pos="word" morph="none" start_char="6145" end_char="6155">precautions</TOKEN>
<TOKEN id="token-49-17" pos="word" morph="none" start_char="6157" end_char="6158">if</TOKEN>
<TOKEN id="token-49-18" pos="word" morph="none" start_char="6160" end_char="6162">you</TOKEN>
<TOKEN id="token-49-19" pos="word" morph="none" start_char="6164" end_char="6167">have</TOKEN>
<TOKEN id="token-49-20" pos="word" morph="none" start_char="6169" end_char="6175">elderly</TOKEN>
<TOKEN id="token-49-21" pos="word" morph="none" start_char="6177" end_char="6185">relatives</TOKEN>
<TOKEN id="token-49-22" pos="word" morph="none" start_char="6187" end_char="6194">visiting</TOKEN>
<TOKEN id="token-49-23" pos="punct" morph="none" start_char="6195" end_char="6195">,</TOKEN>
<TOKEN id="token-49-24" pos="word" morph="none" start_char="6197" end_char="6198">or</TOKEN>
<TOKEN id="token-49-25" pos="word" morph="none" start_char="6200" end_char="6201">if</TOKEN>
<TOKEN id="token-49-26" pos="word" morph="none" start_char="6203" end_char="6208">you’re</TOKEN>
<TOKEN id="token-49-27" pos="word" morph="none" start_char="6210" end_char="6217">bringing</TOKEN>
<TOKEN id="token-49-28" pos="word" morph="none" start_char="6219" end_char="6222">dogs</TOKEN>
<TOKEN id="token-49-29" pos="word" morph="none" start_char="6224" end_char="6225">to</TOKEN>
<TOKEN id="token-49-30" pos="word" morph="none" start_char="6227" end_char="6233">nursing</TOKEN>
<TOKEN id="token-49-31" pos="word" morph="none" start_char="6235" end_char="6239">homes</TOKEN>
<TOKEN id="token-49-32" pos="word" morph="none" start_char="6241" end_char="6242">as</TOKEN>
<TOKEN id="token-49-33" pos="word" morph="none" start_char="6244" end_char="6252">emotional</TOKEN>
<TOKEN id="token-49-34" pos="word" morph="none" start_char="6254" end_char="6260">support</TOKEN>
<TOKEN id="token-49-35" pos="word" morph="none" start_char="6262" end_char="6268">animals</TOKEN>
<TOKEN id="token-49-36" pos="punct" morph="none" start_char="6269" end_char="6270">."</TOKEN>
</SEG>
<SEG id="segment-50" start_char="6273" end_char="6348">
<ORIGINAL_TEXT>For now, Behravesh recommends treating our pets like we now treat ourselves.</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="6273" end_char="6275">For</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="6277" end_char="6279">now</TOKEN>
<TOKEN id="token-50-2" pos="punct" morph="none" start_char="6280" end_char="6280">,</TOKEN>
<TOKEN id="token-50-3" pos="word" morph="none" start_char="6282" end_char="6290">Behravesh</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="6292" end_char="6301">recommends</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="6303" end_char="6310">treating</TOKEN>
<TOKEN id="token-50-6" pos="word" morph="none" start_char="6312" end_char="6314">our</TOKEN>
<TOKEN id="token-50-7" pos="word" morph="none" start_char="6316" end_char="6319">pets</TOKEN>
<TOKEN id="token-50-8" pos="word" morph="none" start_char="6321" end_char="6324">like</TOKEN>
<TOKEN id="token-50-9" pos="word" morph="none" start_char="6326" end_char="6327">we</TOKEN>
<TOKEN id="token-50-10" pos="word" morph="none" start_char="6329" end_char="6331">now</TOKEN>
<TOKEN id="token-50-11" pos="word" morph="none" start_char="6333" end_char="6337">treat</TOKEN>
<TOKEN id="token-50-12" pos="word" morph="none" start_char="6339" end_char="6347">ourselves</TOKEN>
<TOKEN id="token-50-13" pos="punct" morph="none" start_char="6348" end_char="6348">.</TOKEN>
</SEG>
<SEG id="segment-51" start_char="6350" end_char="6429">
<ORIGINAL_TEXT>"If you’re sick, restrict your access to your pet as much as you can," she says.</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="punct" morph="none" start_char="6350" end_char="6350">"</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="6351" end_char="6352">If</TOKEN>
<TOKEN id="token-51-2" pos="word" morph="none" start_char="6354" end_char="6359">you’re</TOKEN>
<TOKEN id="token-51-3" pos="word" morph="none" start_char="6361" end_char="6364">sick</TOKEN>
<TOKEN id="token-51-4" pos="punct" morph="none" start_char="6365" end_char="6365">,</TOKEN>
<TOKEN id="token-51-5" pos="word" morph="none" start_char="6367" end_char="6374">restrict</TOKEN>
<TOKEN id="token-51-6" pos="word" morph="none" start_char="6376" end_char="6379">your</TOKEN>
<TOKEN id="token-51-7" pos="word" morph="none" start_char="6381" end_char="6386">access</TOKEN>
<TOKEN id="token-51-8" pos="word" morph="none" start_char="6388" end_char="6389">to</TOKEN>
<TOKEN id="token-51-9" pos="word" morph="none" start_char="6391" end_char="6394">your</TOKEN>
<TOKEN id="token-51-10" pos="word" morph="none" start_char="6396" end_char="6398">pet</TOKEN>
<TOKEN id="token-51-11" pos="word" morph="none" start_char="6400" end_char="6401">as</TOKEN>
<TOKEN id="token-51-12" pos="word" morph="none" start_char="6403" end_char="6406">much</TOKEN>
<TOKEN id="token-51-13" pos="word" morph="none" start_char="6408" end_char="6409">as</TOKEN>
<TOKEN id="token-51-14" pos="word" morph="none" start_char="6411" end_char="6413">you</TOKEN>
<TOKEN id="token-51-15" pos="word" morph="none" start_char="6415" end_char="6417">can</TOKEN>
<TOKEN id="token-51-16" pos="punct" morph="none" start_char="6418" end_char="6419">,"</TOKEN>
<TOKEN id="token-51-17" pos="word" morph="none" start_char="6421" end_char="6423">she</TOKEN>
<TOKEN id="token-51-18" pos="word" morph="none" start_char="6425" end_char="6428">says</TOKEN>
<TOKEN id="token-51-19" pos="punct" morph="none" start_char="6429" end_char="6429">.</TOKEN>
</SEG>
<SEG id="segment-52" start_char="6431" end_char="6491">
<ORIGINAL_TEXT>"When you walk your dog, stay 6 feet away from other animals.</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="punct" morph="none" start_char="6431" end_char="6431">"</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="6432" end_char="6435">When</TOKEN>
<TOKEN id="token-52-2" pos="word" morph="none" start_char="6437" end_char="6439">you</TOKEN>
<TOKEN id="token-52-3" pos="word" morph="none" start_char="6441" end_char="6444">walk</TOKEN>
<TOKEN id="token-52-4" pos="word" morph="none" start_char="6446" end_char="6449">your</TOKEN>
<TOKEN id="token-52-5" pos="word" morph="none" start_char="6451" end_char="6453">dog</TOKEN>
<TOKEN id="token-52-6" pos="punct" morph="none" start_char="6454" end_char="6454">,</TOKEN>
<TOKEN id="token-52-7" pos="word" morph="none" start_char="6456" end_char="6459">stay</TOKEN>
<TOKEN id="token-52-8" pos="word" morph="none" start_char="6461" end_char="6461">6</TOKEN>
<TOKEN id="token-52-9" pos="word" morph="none" start_char="6463" end_char="6466">feet</TOKEN>
<TOKEN id="token-52-10" pos="word" morph="none" start_char="6468" end_char="6471">away</TOKEN>
<TOKEN id="token-52-11" pos="word" morph="none" start_char="6473" end_char="6476">from</TOKEN>
<TOKEN id="token-52-12" pos="word" morph="none" start_char="6478" end_char="6482">other</TOKEN>
<TOKEN id="token-52-13" pos="word" morph="none" start_char="6484" end_char="6490">animals</TOKEN>
<TOKEN id="token-52-14" pos="punct" morph="none" start_char="6491" end_char="6491">.</TOKEN>
</SEG>
<SEG id="segment-53" start_char="6493" end_char="6522">
<ORIGINAL_TEXT>Don’t pet other people’s dogs.</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="word" morph="none" start_char="6493" end_char="6497">Don’t</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="6499" end_char="6501">pet</TOKEN>
<TOKEN id="token-53-2" pos="word" morph="none" start_char="6503" end_char="6507">other</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="6509" end_char="6516">people’s</TOKEN>
<TOKEN id="token-53-4" pos="word" morph="none" start_char="6518" end_char="6521">dogs</TOKEN>
<TOKEN id="token-53-5" pos="punct" morph="none" start_char="6522" end_char="6522">.</TOKEN>
</SEG>
<SEG id="segment-54" start_char="6524" end_char="6557">
<ORIGINAL_TEXT>Always wash your hands," she says.</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="word" morph="none" start_char="6524" end_char="6529">Always</TOKEN>
<TOKEN id="token-54-1" pos="word" morph="none" start_char="6531" end_char="6534">wash</TOKEN>
<TOKEN id="token-54-2" pos="word" morph="none" start_char="6536" end_char="6539">your</TOKEN>
<TOKEN id="token-54-3" pos="word" morph="none" start_char="6541" end_char="6545">hands</TOKEN>
<TOKEN id="token-54-4" pos="punct" morph="none" start_char="6546" end_char="6547">,"</TOKEN>
<TOKEN id="token-54-5" pos="word" morph="none" start_char="6549" end_char="6551">she</TOKEN>
<TOKEN id="token-54-6" pos="word" morph="none" start_char="6553" end_char="6556">says</TOKEN>
<TOKEN id="token-54-7" pos="punct" morph="none" start_char="6557" end_char="6557">.</TOKEN>
</SEG>
<SEG id="segment-55" start_char="6559" end_char="6606">
<ORIGINAL_TEXT>"It’s really important that people don’t panic."</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="punct" morph="none" start_char="6559" end_char="6559">"</TOKEN>
<TOKEN id="token-55-1" pos="word" morph="none" start_char="6560" end_char="6563">It’s</TOKEN>
<TOKEN id="token-55-2" pos="word" morph="none" start_char="6565" end_char="6570">really</TOKEN>
<TOKEN id="token-55-3" pos="word" morph="none" start_char="6572" end_char="6580">important</TOKEN>
<TOKEN id="token-55-4" pos="word" morph="none" start_char="6582" end_char="6585">that</TOKEN>
<TOKEN id="token-55-5" pos="word" morph="none" start_char="6587" end_char="6592">people</TOKEN>
<TOKEN id="token-55-6" pos="word" morph="none" start_char="6594" end_char="6598">don’t</TOKEN>
<TOKEN id="token-55-7" pos="word" morph="none" start_char="6600" end_char="6604">panic</TOKEN>
<TOKEN id="token-55-8" pos="punct" morph="none" start_char="6605" end_char="6606">."</TOKEN>
</SEG>
<SEG id="segment-56" start_char="6609" end_char="6623">
<ORIGINAL_TEXT>Epstein agrees.</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="6609" end_char="6615">Epstein</TOKEN>
<TOKEN id="token-56-1" pos="word" morph="none" start_char="6617" end_char="6622">agrees</TOKEN>
<TOKEN id="token-56-2" pos="punct" morph="none" start_char="6623" end_char="6623">.</TOKEN>
</SEG>
<SEG id="segment-57" start_char="6625" end_char="6782">
<ORIGINAL_TEXT>"I don’t want to create unnecessary concern about pets," he says, arguing that our emotional connection with cats and dogs may be more critical now than ever.</ORIGINAL_TEXT>
<TOKEN id="token-57-0" pos="punct" morph="none" start_char="6625" end_char="6625">"</TOKEN>
<TOKEN id="token-57-1" pos="word" morph="none" start_char="6626" end_char="6626">I</TOKEN>
<TOKEN id="token-57-2" pos="word" morph="none" start_char="6628" end_char="6632">don’t</TOKEN>
<TOKEN id="token-57-3" pos="word" morph="none" start_char="6634" end_char="6637">want</TOKEN>
<TOKEN id="token-57-4" pos="word" morph="none" start_char="6639" end_char="6640">to</TOKEN>
<TOKEN id="token-57-5" pos="word" morph="none" start_char="6642" end_char="6647">create</TOKEN>
<TOKEN id="token-57-6" pos="word" morph="none" start_char="6649" end_char="6659">unnecessary</TOKEN>
<TOKEN id="token-57-7" pos="word" morph="none" start_char="6661" end_char="6667">concern</TOKEN>
<TOKEN id="token-57-8" pos="word" morph="none" start_char="6669" end_char="6673">about</TOKEN>
<TOKEN id="token-57-9" pos="word" morph="none" start_char="6675" end_char="6678">pets</TOKEN>
<TOKEN id="token-57-10" pos="punct" morph="none" start_char="6679" end_char="6680">,"</TOKEN>
<TOKEN id="token-57-11" pos="word" morph="none" start_char="6682" end_char="6683">he</TOKEN>
<TOKEN id="token-57-12" pos="word" morph="none" start_char="6685" end_char="6688">says</TOKEN>
<TOKEN id="token-57-13" pos="punct" morph="none" start_char="6689" end_char="6689">,</TOKEN>
<TOKEN id="token-57-14" pos="word" morph="none" start_char="6691" end_char="6697">arguing</TOKEN>
<TOKEN id="token-57-15" pos="word" morph="none" start_char="6699" end_char="6702">that</TOKEN>
<TOKEN id="token-57-16" pos="word" morph="none" start_char="6704" end_char="6706">our</TOKEN>
<TOKEN id="token-57-17" pos="word" morph="none" start_char="6708" end_char="6716">emotional</TOKEN>
<TOKEN id="token-57-18" pos="word" morph="none" start_char="6718" end_char="6727">connection</TOKEN>
<TOKEN id="token-57-19" pos="word" morph="none" start_char="6729" end_char="6732">with</TOKEN>
<TOKEN id="token-57-20" pos="word" morph="none" start_char="6734" end_char="6737">cats</TOKEN>
<TOKEN id="token-57-21" pos="word" morph="none" start_char="6739" end_char="6741">and</TOKEN>
<TOKEN id="token-57-22" pos="word" morph="none" start_char="6743" end_char="6746">dogs</TOKEN>
<TOKEN id="token-57-23" pos="word" morph="none" start_char="6748" end_char="6750">may</TOKEN>
<TOKEN id="token-57-24" pos="word" morph="none" start_char="6752" end_char="6753">be</TOKEN>
<TOKEN id="token-57-25" pos="word" morph="none" start_char="6755" end_char="6758">more</TOKEN>
<TOKEN id="token-57-26" pos="word" morph="none" start_char="6760" end_char="6767">critical</TOKEN>
<TOKEN id="token-57-27" pos="word" morph="none" start_char="6769" end_char="6771">now</TOKEN>
<TOKEN id="token-57-28" pos="word" morph="none" start_char="6773" end_char="6776">than</TOKEN>
<TOKEN id="token-57-29" pos="word" morph="none" start_char="6778" end_char="6781">ever</TOKEN>
<TOKEN id="token-57-30" pos="punct" morph="none" start_char="6782" end_char="6782">.</TOKEN>
</SEG>
<SEG id="segment-58" start_char="6784" end_char="6897">
<ORIGINAL_TEXT>"In these difficult, isolating times," he says, "there is an importance to having companion animals in your life."</ORIGINAL_TEXT>
<TOKEN id="token-58-0" pos="punct" morph="none" start_char="6784" end_char="6784">"</TOKEN>
<TOKEN id="token-58-1" pos="word" morph="none" start_char="6785" end_char="6786">In</TOKEN>
<TOKEN id="token-58-2" pos="word" morph="none" start_char="6788" end_char="6792">these</TOKEN>
<TOKEN id="token-58-3" pos="word" morph="none" start_char="6794" end_char="6802">difficult</TOKEN>
<TOKEN id="token-58-4" pos="punct" morph="none" start_char="6803" end_char="6803">,</TOKEN>
<TOKEN id="token-58-5" pos="word" morph="none" start_char="6805" end_char="6813">isolating</TOKEN>
<TOKEN id="token-58-6" pos="word" morph="none" start_char="6815" end_char="6819">times</TOKEN>
<TOKEN id="token-58-7" pos="punct" morph="none" start_char="6820" end_char="6821">,"</TOKEN>
<TOKEN id="token-58-8" pos="word" morph="none" start_char="6823" end_char="6824">he</TOKEN>
<TOKEN id="token-58-9" pos="word" morph="none" start_char="6826" end_char="6829">says</TOKEN>
<TOKEN id="token-58-10" pos="punct" morph="none" start_char="6830" end_char="6830">,</TOKEN>
<TOKEN id="token-58-11" pos="punct" morph="none" start_char="6832" end_char="6832">"</TOKEN>
<TOKEN id="token-58-12" pos="word" morph="none" start_char="6833" end_char="6837">there</TOKEN>
<TOKEN id="token-58-13" pos="word" morph="none" start_char="6839" end_char="6840">is</TOKEN>
<TOKEN id="token-58-14" pos="word" morph="none" start_char="6842" end_char="6843">an</TOKEN>
<TOKEN id="token-58-15" pos="word" morph="none" start_char="6845" end_char="6854">importance</TOKEN>
<TOKEN id="token-58-16" pos="word" morph="none" start_char="6856" end_char="6857">to</TOKEN>
<TOKEN id="token-58-17" pos="word" morph="none" start_char="6859" end_char="6864">having</TOKEN>
<TOKEN id="token-58-18" pos="word" morph="none" start_char="6866" end_char="6874">companion</TOKEN>
<TOKEN id="token-58-19" pos="word" morph="none" start_char="6876" end_char="6882">animals</TOKEN>
<TOKEN id="token-58-20" pos="word" morph="none" start_char="6884" end_char="6885">in</TOKEN>
<TOKEN id="token-58-21" pos="word" morph="none" start_char="6887" end_char="6890">your</TOKEN>
<TOKEN id="token-58-22" pos="word" morph="none" start_char="6892" end_char="6895">life</TOKEN>
<TOKEN id="token-58-23" pos="punct" morph="none" start_char="6896" end_char="6897">."</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
