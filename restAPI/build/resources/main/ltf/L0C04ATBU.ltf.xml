<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATBU" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="1856" raw_text_md5="f00e0b2c6991f76eabb849ea387eaf9a">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="35">
<ORIGINAL_TEXT>¿Se dice el COVID-19 ó la COVID-19?</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="punct" morph="none" start_char="1" end_char="1">¿</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="2" end_char="3">Se</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="5" end_char="8">dice</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="10" end_char="11">el</TOKEN>
<TOKEN id="token-0-4" pos="unknown" morph="none" start_char="13" end_char="20">COVID-19</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="22" end_char="22">ó</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="24" end_char="25">la</TOKEN>
<TOKEN id="token-0-7" pos="unknown" morph="none" start_char="27" end_char="34">COVID-19</TOKEN>
<TOKEN id="token-0-8" pos="punct" morph="none" start_char="35" end_char="35">?</TOKEN>
</SEG>
<SEG id="segment-1" start_char="39" end_char="73">
<ORIGINAL_TEXT>Empecemos por cuatro cosas básicas:</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="39" end_char="47">Empecemos</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="49" end_char="51">por</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="53" end_char="58">cuatro</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="60" end_char="64">cosas</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="66" end_char="72">básicas</TOKEN>
<TOKEN id="token-1-5" pos="punct" morph="none" start_char="73" end_char="73">:</TOKEN>
</SEG>
<SEG id="segment-2" start_char="76" end_char="109">
<ORIGINAL_TEXT>1 - Todos los virus mutan y mucho.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="76" end_char="76">1</TOKEN>
<TOKEN id="token-2-1" pos="punct" morph="none" start_char="78" end_char="78">-</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="80" end_char="84">Todos</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="86" end_char="88">los</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="90" end_char="94">virus</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="96" end_char="100">mutan</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="102" end_char="102">y</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="104" end_char="108">mucho</TOKEN>
<TOKEN id="token-2-8" pos="punct" morph="none" start_char="109" end_char="109">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="111" end_char="168">
<ORIGINAL_TEXT>No hace falta una mente maligna para crear un virus letal.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="111" end_char="112">No</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="114" end_char="117">hace</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="119" end_char="123">falta</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="125" end_char="127">una</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="129" end_char="133">mente</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="135" end_char="141">maligna</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="143" end_char="146">para</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="148" end_char="152">crear</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="154" end_char="155">un</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="157" end_char="161">virus</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="163" end_char="167">letal</TOKEN>
<TOKEN id="token-3-11" pos="punct" morph="none" start_char="168" end_char="168">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="170" end_char="241">
<ORIGINAL_TEXT>Se crean ellos solitos y lo vienen haciendo desde hace millones de años.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="170" end_char="171">Se</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="173" end_char="177">crean</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="179" end_char="183">ellos</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="185" end_char="191">solitos</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="193" end_char="193">y</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="195" end_char="196">lo</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="198" end_char="203">vienen</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="205" end_char="212">haciendo</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="214" end_char="218">desde</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="220" end_char="223">hace</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="225" end_char="232">millones</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="234" end_char="235">de</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="237" end_char="240">años</TOKEN>
<TOKEN id="token-4-13" pos="punct" morph="none" start_char="241" end_char="241">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="243" end_char="416">
<ORIGINAL_TEXT>La gripe española fue muchísimo más letal, por ejemplo, y hasta el ADN de las bacterias contiene rastros que indican que los virus llevan infectado a los seres vivos siempre.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="243" end_char="244">La</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="246" end_char="250">gripe</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="252" end_char="259">española</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="261" end_char="263">fue</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="265" end_char="273">muchísimo</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="275" end_char="277">más</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="279" end_char="283">letal</TOKEN>
<TOKEN id="token-5-7" pos="punct" morph="none" start_char="284" end_char="284">,</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="286" end_char="288">por</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="290" end_char="296">ejemplo</TOKEN>
<TOKEN id="token-5-10" pos="punct" morph="none" start_char="297" end_char="297">,</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="299" end_char="299">y</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="301" end_char="305">hasta</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="307" end_char="308">el</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="310" end_char="312">ADN</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="314" end_char="315">de</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="317" end_char="319">las</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="321" end_char="329">bacterias</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="331" end_char="338">contiene</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="340" end_char="346">rastros</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="348" end_char="350">que</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="352" end_char="358">indican</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="360" end_char="362">que</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="364" end_char="366">los</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="368" end_char="372">virus</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="374" end_char="379">llevan</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="381" end_char="389">infectado</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="391" end_char="391">a</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="393" end_char="395">los</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="397" end_char="401">seres</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="403" end_char="407">vivos</TOKEN>
<TOKEN id="token-5-31" pos="word" morph="none" start_char="409" end_char="415">siempre</TOKEN>
<TOKEN id="token-5-32" pos="punct" morph="none" start_char="416" end_char="416">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="419" end_char="455">
<ORIGINAL_TEXT>2 - El mundo está muy interconectado.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="419" end_char="419">2</TOKEN>
<TOKEN id="token-6-1" pos="punct" morph="none" start_char="421" end_char="421">-</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="423" end_char="424">El</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="426" end_char="430">mundo</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="432" end_char="435">está</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="437" end_char="439">muy</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="441" end_char="454">interconectado</TOKEN>
<TOKEN id="token-6-7" pos="punct" morph="none" start_char="455" end_char="455">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="457" end_char="499">
<ORIGINAL_TEXT>Millones de personas viajan todos los días.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="457" end_char="464">Millones</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="466" end_char="467">de</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="469" end_char="476">personas</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="478" end_char="483">viajan</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="485" end_char="489">todos</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="491" end_char="493">los</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="495" end_char="498">días</TOKEN>
<TOKEN id="token-7-7" pos="punct" morph="none" start_char="499" end_char="499">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="501" end_char="642">
<ORIGINAL_TEXT>Países como España o Italia reciben alrededor de 80 millones de visitantes cada año, así que tampoco hace falta una mente maligna para extende</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="501" end_char="506">Países</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="508" end_char="511">como</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="513" end_char="518">España</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="520" end_char="520">o</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="522" end_char="527">Italia</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="529" end_char="535">reciben</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="537" end_char="545">alrededor</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="547" end_char="548">de</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="550" end_char="551">80</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="553" end_char="560">millones</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="562" end_char="563">de</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="565" end_char="574">visitantes</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="576" end_char="579">cada</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="581" end_char="583">año</TOKEN>
<TOKEN id="token-8-14" pos="punct" morph="none" start_char="584" end_char="584">,</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="586" end_char="588">así</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="590" end_char="592">que</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="594" end_char="600">tampoco</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="602" end_char="605">hace</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="607" end_char="611">falta</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="613" end_char="615">una</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="617" end_char="621">mente</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="623" end_char="629">maligna</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="631" end_char="634">para</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="636" end_char="642">extende</TOKEN>
</SEG>
<SEG id="segment-9" start_char="646" end_char="708">
<ORIGINAL_TEXT>Creo que las respuestas hablan del virus y no de la enfermedad.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="646" end_char="649">Creo</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="651" end_char="653">que</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="655" end_char="657">las</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="659" end_char="668">respuestas</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="670" end_char="675">hablan</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="677" end_char="679">del</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="681" end_char="685">virus</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="687" end_char="687">y</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="689" end_char="690">no</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="692" end_char="693">de</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="695" end_char="696">la</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="698" end_char="707">enfermedad</TOKEN>
<TOKEN id="token-9-12" pos="punct" morph="none" start_char="708" end_char="708">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="710" end_char="793">
<ORIGINAL_TEXT>COVID-19 significa CoronaVirus Disease de 2019 o enfermedad del Coronavirus de 2019.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="unknown" morph="none" start_char="710" end_char="717">COVID-19</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="719" end_char="727">significa</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="729" end_char="739">CoronaVirus</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="741" end_char="747">Disease</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="749" end_char="750">de</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="752" end_char="755">2019</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="757" end_char="757">o</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="759" end_char="768">enfermedad</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="770" end_char="772">del</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="774" end_char="784">Coronavirus</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="786" end_char="787">de</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="789" end_char="792">2019</TOKEN>
<TOKEN id="token-10-12" pos="punct" morph="none" start_char="793" end_char="793">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="795" end_char="869">
<ORIGINAL_TEXT>Así que COVID-19 es la enfermedad que produce el virus y no el virus en si.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="795" end_char="797">Así</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="799" end_char="801">que</TOKEN>
<TOKEN id="token-11-2" pos="unknown" morph="none" start_char="803" end_char="810">COVID-19</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="812" end_char="813">es</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="815" end_char="816">la</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="818" end_char="827">enfermedad</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="829" end_char="831">que</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="833" end_char="839">produce</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="841" end_char="842">el</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="844" end_char="848">virus</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="850" end_char="850">y</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="852" end_char="853">no</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="855" end_char="856">el</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="858" end_char="862">virus</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="864" end_char="865">en</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="867" end_char="868">si</TOKEN>
<TOKEN id="token-11-16" pos="punct" morph="none" start_char="869" end_char="869">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="871" end_char="1072">
<ORIGINAL_TEXT>El origen de la enfermedad es el Virus catalogado ahora como Sars-CoV-2 por su similitud con el Virus que produce el Sars o Síndrome Respiratorio Agudo Severo (SARS es por sus siglas en inglés)del 2002.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="871" end_char="872">El</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="874" end_char="879">origen</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="881" end_char="882">de</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="884" end_char="885">la</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="887" end_char="896">enfermedad</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="898" end_char="899">es</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="901" end_char="902">el</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="904" end_char="908">Virus</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="910" end_char="919">catalogado</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="921" end_char="925">ahora</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="927" end_char="930">como</TOKEN>
<TOKEN id="token-12-11" pos="unknown" morph="none" start_char="932" end_char="941">Sars-CoV-2</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="943" end_char="945">por</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="947" end_char="948">su</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="950" end_char="958">similitud</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="960" end_char="962">con</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="964" end_char="965">el</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="967" end_char="971">Virus</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="973" end_char="975">que</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="977" end_char="983">produce</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="985" end_char="986">el</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="988" end_char="991">Sars</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="993" end_char="993">o</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="995" end_char="1002">Síndrome</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="1004" end_char="1015">Respiratorio</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="1017" end_char="1021">Agudo</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="1023" end_char="1028">Severo</TOKEN>
<TOKEN id="token-12-27" pos="punct" morph="none" start_char="1030" end_char="1030">(</TOKEN>
<TOKEN id="token-12-28" pos="word" morph="none" start_char="1031" end_char="1034">SARS</TOKEN>
<TOKEN id="token-12-29" pos="word" morph="none" start_char="1036" end_char="1037">es</TOKEN>
<TOKEN id="token-12-30" pos="word" morph="none" start_char="1039" end_char="1041">por</TOKEN>
<TOKEN id="token-12-31" pos="word" morph="none" start_char="1043" end_char="1045">sus</TOKEN>
<TOKEN id="token-12-32" pos="word" morph="none" start_char="1047" end_char="1052">siglas</TOKEN>
<TOKEN id="token-12-33" pos="word" morph="none" start_char="1054" end_char="1055">en</TOKEN>
<TOKEN id="token-12-34" pos="unknown" morph="none" start_char="1057" end_char="1066">inglés)del</TOKEN>
<TOKEN id="token-12-35" pos="word" morph="none" start_char="1068" end_char="1071">2002</TOKEN>
<TOKEN id="token-12-36" pos="punct" morph="none" start_char="1072" end_char="1072">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1074" end_char="1245">
<ORIGINAL_TEXT>El genoma de esta nueva cepa SARS CoV-2 coincide en un 94.6% con este coronavirus SARS COV-1 que produce la enfermedad SARS en el 2002 y un 96.2% con el coronavirus BAT Cov</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1074" end_char="1075">El</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1077" end_char="1082">genoma</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1084" end_char="1085">de</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1087" end_char="1090">esta</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1092" end_char="1096">nueva</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1098" end_char="1101">cepa</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1103" end_char="1106">SARS</TOKEN>
<TOKEN id="token-13-7" pos="unknown" morph="none" start_char="1108" end_char="1112">CoV-2</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1114" end_char="1121">coincide</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1123" end_char="1124">en</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1126" end_char="1127">un</TOKEN>
<TOKEN id="token-13-11" pos="unknown" morph="none" start_char="1129" end_char="1132">94.6</TOKEN>
<TOKEN id="token-13-12" pos="punct" morph="none" start_char="1133" end_char="1133">%</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1135" end_char="1137">con</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1139" end_char="1142">este</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1144" end_char="1154">coronavirus</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1156" end_char="1159">SARS</TOKEN>
<TOKEN id="token-13-17" pos="unknown" morph="none" start_char="1161" end_char="1165">COV-1</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1167" end_char="1169">que</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1171" end_char="1177">produce</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1179" end_char="1180">la</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="1182" end_char="1191">enfermedad</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="1193" end_char="1196">SARS</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="1198" end_char="1199">en</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="1201" end_char="1202">el</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="1204" end_char="1207">2002</TOKEN>
<TOKEN id="token-13-26" pos="word" morph="none" start_char="1209" end_char="1209">y</TOKEN>
<TOKEN id="token-13-27" pos="word" morph="none" start_char="1211" end_char="1212">un</TOKEN>
<TOKEN id="token-13-28" pos="unknown" morph="none" start_char="1214" end_char="1217">96.2</TOKEN>
<TOKEN id="token-13-29" pos="punct" morph="none" start_char="1218" end_char="1218">%</TOKEN>
<TOKEN id="token-13-30" pos="word" morph="none" start_char="1220" end_char="1222">con</TOKEN>
<TOKEN id="token-13-31" pos="word" morph="none" start_char="1224" end_char="1225">el</TOKEN>
<TOKEN id="token-13-32" pos="word" morph="none" start_char="1227" end_char="1237">coronavirus</TOKEN>
<TOKEN id="token-13-33" pos="word" morph="none" start_char="1239" end_char="1241">BAT</TOKEN>
<TOKEN id="token-13-34" pos="word" morph="none" start_char="1243" end_char="1245">Cov</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1249" end_char="1422">
<ORIGINAL_TEXT>El origen bien puede ser meramente consecuencia de las condiciones de promiscuidad (no sexual) en las que tradicionalmente se convive con los animales en gran parte de China.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1249" end_char="1250">El</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1252" end_char="1257">origen</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1259" end_char="1262">bien</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1264" end_char="1268">puede</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1270" end_char="1272">ser</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1274" end_char="1282">meramente</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1284" end_char="1295">consecuencia</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1297" end_char="1298">de</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1300" end_char="1302">las</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1304" end_char="1314">condiciones</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1316" end_char="1317">de</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1319" end_char="1330">promiscuidad</TOKEN>
<TOKEN id="token-14-12" pos="punct" morph="none" start_char="1332" end_char="1332">(</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1333" end_char="1334">no</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="1336" end_char="1341">sexual</TOKEN>
<TOKEN id="token-14-15" pos="punct" morph="none" start_char="1342" end_char="1342">)</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1344" end_char="1345">en</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="1347" end_char="1349">las</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="1351" end_char="1353">que</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="1355" end_char="1370">tradicionalmente</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="1372" end_char="1373">se</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="1375" end_char="1381">convive</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="1383" end_char="1385">con</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="1387" end_char="1389">los</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="1391" end_char="1398">animales</TOKEN>
<TOKEN id="token-14-25" pos="word" morph="none" start_char="1400" end_char="1401">en</TOKEN>
<TOKEN id="token-14-26" pos="word" morph="none" start_char="1403" end_char="1406">gran</TOKEN>
<TOKEN id="token-14-27" pos="word" morph="none" start_char="1408" end_char="1412">parte</TOKEN>
<TOKEN id="token-14-28" pos="word" morph="none" start_char="1414" end_char="1415">de</TOKEN>
<TOKEN id="token-14-29" pos="word" morph="none" start_char="1417" end_char="1421">China</TOKEN>
<TOKEN id="token-14-30" pos="punct" morph="none" start_char="1422" end_char="1422">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1425" end_char="1535">
<ORIGINAL_TEXT>Antes de explorar conspiraciones, recordemos que lo escrito arriba es cierto y está extensivamente documentado.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1425" end_char="1429">Antes</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1431" end_char="1432">de</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1434" end_char="1441">explorar</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1443" end_char="1456">conspiraciones</TOKEN>
<TOKEN id="token-15-4" pos="punct" morph="none" start_char="1457" end_char="1457">,</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1459" end_char="1468">recordemos</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1470" end_char="1472">que</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1474" end_char="1475">lo</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1477" end_char="1483">escrito</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1485" end_char="1490">arriba</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1492" end_char="1493">es</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1495" end_char="1500">cierto</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1502" end_char="1502">y</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1504" end_char="1507">está</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1509" end_char="1522">extensivamente</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="1524" end_char="1534">documentado</TOKEN>
<TOKEN id="token-15-16" pos="punct" morph="none" start_char="1535" end_char="1535">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1537" end_char="1720">
<ORIGINAL_TEXT>El nombre del fenómeno que ocurre cuando un patógeno hace el salto de una especie a otra se llama Zoonosis, y se han dado varios ejemplos a lo largo de la historia, y no sólo en China.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1537" end_char="1538">El</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1540" end_char="1545">nombre</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1547" end_char="1549">del</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1551" end_char="1558">fenómeno</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1560" end_char="1562">que</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1564" end_char="1569">ocurre</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1571" end_char="1576">cuando</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1578" end_char="1579">un</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1581" end_char="1588">patógeno</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="1590" end_char="1593">hace</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="1595" end_char="1596">el</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="1598" end_char="1602">salto</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="1604" end_char="1605">de</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="1607" end_char="1609">una</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="1611" end_char="1617">especie</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="1619" end_char="1619">a</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="1621" end_char="1624">otra</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="1626" end_char="1627">se</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="1629" end_char="1633">llama</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="1635" end_char="1642">Zoonosis</TOKEN>
<TOKEN id="token-16-20" pos="punct" morph="none" start_char="1643" end_char="1643">,</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="1645" end_char="1645">y</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="1647" end_char="1648">se</TOKEN>
<TOKEN id="token-16-23" pos="word" morph="none" start_char="1650" end_char="1652">han</TOKEN>
<TOKEN id="token-16-24" pos="word" morph="none" start_char="1654" end_char="1657">dado</TOKEN>
<TOKEN id="token-16-25" pos="word" morph="none" start_char="1659" end_char="1664">varios</TOKEN>
<TOKEN id="token-16-26" pos="word" morph="none" start_char="1666" end_char="1673">ejemplos</TOKEN>
<TOKEN id="token-16-27" pos="word" morph="none" start_char="1675" end_char="1675">a</TOKEN>
<TOKEN id="token-16-28" pos="word" morph="none" start_char="1677" end_char="1678">lo</TOKEN>
<TOKEN id="token-16-29" pos="word" morph="none" start_char="1680" end_char="1684">largo</TOKEN>
<TOKEN id="token-16-30" pos="word" morph="none" start_char="1686" end_char="1687">de</TOKEN>
<TOKEN id="token-16-31" pos="word" morph="none" start_char="1689" end_char="1690">la</TOKEN>
<TOKEN id="token-16-32" pos="word" morph="none" start_char="1692" end_char="1699">historia</TOKEN>
<TOKEN id="token-16-33" pos="punct" morph="none" start_char="1700" end_char="1700">,</TOKEN>
<TOKEN id="token-16-34" pos="word" morph="none" start_char="1702" end_char="1702">y</TOKEN>
<TOKEN id="token-16-35" pos="word" morph="none" start_char="1704" end_char="1705">no</TOKEN>
<TOKEN id="token-16-36" pos="word" morph="none" start_char="1707" end_char="1710">sólo</TOKEN>
<TOKEN id="token-16-37" pos="word" morph="none" start_char="1712" end_char="1713">en</TOKEN>
<TOKEN id="token-16-38" pos="word" morph="none" start_char="1715" end_char="1719">China</TOKEN>
<TOKEN id="token-16-39" pos="punct" morph="none" start_char="1720" end_char="1720">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1723" end_char="1833">
<ORIGINAL_TEXT>Enseguida, como otro Quorano respondió acertadamente a una pregunta similar; recordemos el principio de Hanlon.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1723" end_char="1731">Enseguida</TOKEN>
<TOKEN id="token-17-1" pos="punct" morph="none" start_char="1732" end_char="1732">,</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="1734" end_char="1737">como</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="1739" end_char="1742">otro</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="1744" end_char="1750">Quorano</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="1752" end_char="1760">respondió</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="1762" end_char="1774">acertadamente</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="1776" end_char="1776">a</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="1778" end_char="1780">una</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="1782" end_char="1789">pregunta</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="1791" end_char="1797">similar</TOKEN>
<TOKEN id="token-17-11" pos="punct" morph="none" start_char="1798" end_char="1798">;</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="1800" end_char="1809">recordemos</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="1811" end_char="1812">el</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="1814" end_char="1822">principio</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="1824" end_char="1825">de</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="1827" end_char="1832">Hanlon</TOKEN>
<TOKEN id="token-17-17" pos="punct" morph="none" start_char="1833" end_char="1833">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1835" end_char="1852">
<ORIGINAL_TEXT>El cual, básicamen</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="1835" end_char="1836">El</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="1838" end_char="1841">cual</TOKEN>
<TOKEN id="token-18-2" pos="punct" morph="none" start_char="1842" end_char="1842">,</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="1844" end_char="1852">básicamen</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
