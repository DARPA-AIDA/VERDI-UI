<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CA9X" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="2384" raw_text_md5="b032fd2f636e7c9fb8abebbec38f2fd6">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="64">
<ORIGINAL_TEXT>Chinese researchers claim COVID-19 originated in Greece or India</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="7">Chinese</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="9" end_char="19">researchers</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="21" end_char="25">claim</TOKEN>
<TOKEN id="token-0-3" pos="unknown" morph="none" start_char="27" end_char="34">COVID-19</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="36" end_char="45">originated</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="47" end_char="48">in</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="50" end_char="55">Greece</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="57" end_char="58">or</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="60" end_char="64">India</TOKEN>
</SEG>
<SEG id="segment-1" start_char="68" end_char="133">
<ORIGINAL_TEXT>Chinese researchers claim COVID-19 originated in Greece or India 1</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="68" end_char="74">Chinese</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="76" end_char="86">researchers</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="88" end_char="92">claim</TOKEN>
<TOKEN id="token-1-3" pos="unknown" morph="none" start_char="94" end_char="101">COVID-19</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="103" end_char="112">originated</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="114" end_char="115">in</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="117" end_char="122">Greece</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="124" end_char="125">or</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="127" end_char="131">India</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="133" end_char="133">1</TOKEN>
</SEG>
<SEG id="segment-2" start_char="137" end_char="251">
<ORIGINAL_TEXT>Chinese researchers claim that COVID-19 originates from India , but perhaps also other countries, including Greece.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="137" end_char="143">Chinese</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="145" end_char="155">researchers</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="157" end_char="161">claim</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="163" end_char="166">that</TOKEN>
<TOKEN id="token-2-4" pos="unknown" morph="none" start_char="168" end_char="175">COVID-19</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="177" end_char="186">originates</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="188" end_char="191">from</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="193" end_char="197">India</TOKEN>
<TOKEN id="token-2-8" pos="punct" morph="none" start_char="199" end_char="199">,</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="201" end_char="203">but</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="205" end_char="211">perhaps</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="213" end_char="216">also</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="218" end_char="222">other</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="224" end_char="232">countries</TOKEN>
<TOKEN id="token-2-14" pos="punct" morph="none" start_char="233" end_char="233">,</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="235" end_char="243">including</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="245" end_char="250">Greece</TOKEN>
<TOKEN id="token-2-17" pos="punct" morph="none" start_char="251" end_char="251">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="254" end_char="493">
<ORIGINAL_TEXT>A team from the Chinese Academy of Sciences claims that the virus probably started in India in the summer of 2019 and was transmitted from animals to humans through contaminated water, before traveling to Wuhan, where it was first detected.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="254" end_char="254">A</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="256" end_char="259">team</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="261" end_char="264">from</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="266" end_char="268">the</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="270" end_char="276">Chinese</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="278" end_char="284">Academy</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="286" end_char="287">of</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="289" end_char="296">Sciences</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="298" end_char="303">claims</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="305" end_char="308">that</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="310" end_char="312">the</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="314" end_char="318">virus</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="320" end_char="327">probably</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="329" end_char="335">started</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="337" end_char="338">in</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="340" end_char="344">India</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="346" end_char="347">in</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="349" end_char="351">the</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="353" end_char="358">summer</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="360" end_char="361">of</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="363" end_char="366">2019</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="368" end_char="370">and</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="372" end_char="374">was</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="376" end_char="386">transmitted</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="388" end_char="391">from</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="393" end_char="399">animals</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="401" end_char="402">to</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="404" end_char="409">humans</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="411" end_char="417">through</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="419" end_char="430">contaminated</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="432" end_char="436">water</TOKEN>
<TOKEN id="token-3-31" pos="punct" morph="none" start_char="437" end_char="437">,</TOKEN>
<TOKEN id="token-3-32" pos="word" morph="none" start_char="439" end_char="444">before</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="446" end_char="454">traveling</TOKEN>
<TOKEN id="token-3-34" pos="word" morph="none" start_char="456" end_char="457">to</TOKEN>
<TOKEN id="token-3-35" pos="word" morph="none" start_char="459" end_char="463">Wuhan</TOKEN>
<TOKEN id="token-3-36" pos="punct" morph="none" start_char="464" end_char="464">,</TOKEN>
<TOKEN id="token-3-37" pos="word" morph="none" start_char="466" end_char="470">where</TOKEN>
<TOKEN id="token-3-38" pos="word" morph="none" start_char="472" end_char="473">it</TOKEN>
<TOKEN id="token-3-39" pos="word" morph="none" start_char="475" end_char="477">was</TOKEN>
<TOKEN id="token-3-40" pos="word" morph="none" start_char="479" end_char="483">first</TOKEN>
<TOKEN id="token-3-41" pos="word" morph="none" start_char="485" end_char="492">detected</TOKEN>
<TOKEN id="token-3-42" pos="punct" morph="none" start_char="493" end_char="493">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="496" end_char="549">
<ORIGINAL_TEXT>The phylogenetic analysis submitted for publication in</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="496" end_char="498">The</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="500" end_char="511">phylogenetic</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="513" end_char="520">analysis</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="522" end_char="530">submitted</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="532" end_char="534">for</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="536" end_char="546">publication</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="548" end_char="549">in</TOKEN>
</SEG>
<SEG id="segment-5" start_char="552" end_char="561">
<ORIGINAL_TEXT>The Lancet</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="552" end_char="554">The</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="556" end_char="561">Lancet</TOKEN>
</SEG>
<SEG id="segment-6" start_char="564" end_char="652">
<ORIGINAL_TEXT>indicates that the source of COVID-19 was another country, possibly India or even Greece.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="564" end_char="572">indicates</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="574" end_char="577">that</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="579" end_char="581">the</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="583" end_char="588">source</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="590" end_char="591">of</TOKEN>
<TOKEN id="token-6-5" pos="unknown" morph="none" start_char="593" end_char="600">COVID-19</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="602" end_char="604">was</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="606" end_char="612">another</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="614" end_char="620">country</TOKEN>
<TOKEN id="token-6-9" pos="punct" morph="none" start_char="621" end_char="621">,</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="623" end_char="630">possibly</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="632" end_char="636">India</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="638" end_char="639">or</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="641" end_char="644">even</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="646" end_char="651">Greece</TOKEN>
<TOKEN id="token-6-15" pos="punct" morph="none" start_char="652" end_char="652">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="655" end_char="828">
<ORIGINAL_TEXT>The research team claims that COVID-19 may have been transmitted to humans for the first time in the summer of 2019 when India and Pakistan were hit by a prolonged heat wave.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="655" end_char="657">The</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="659" end_char="666">research</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="668" end_char="671">team</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="673" end_char="678">claims</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="680" end_char="683">that</TOKEN>
<TOKEN id="token-7-5" pos="unknown" morph="none" start_char="685" end_char="692">COVID-19</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="694" end_char="696">may</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="698" end_char="701">have</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="703" end_char="706">been</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="708" end_char="718">transmitted</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="720" end_char="721">to</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="723" end_char="728">humans</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="730" end_char="732">for</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="734" end_char="736">the</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="738" end_char="742">first</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="744" end_char="747">time</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="749" end_char="750">in</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="752" end_char="754">the</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="756" end_char="761">summer</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="763" end_char="764">of</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="766" end_char="769">2019</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="771" end_char="774">when</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="776" end_char="780">India</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="782" end_char="784">and</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="786" end_char="793">Pakistan</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="795" end_char="798">were</TOKEN>
<TOKEN id="token-7-26" pos="word" morph="none" start_char="800" end_char="802">hit</TOKEN>
<TOKEN id="token-7-27" pos="word" morph="none" start_char="804" end_char="805">by</TOKEN>
<TOKEN id="token-7-28" pos="word" morph="none" start_char="807" end_char="807">a</TOKEN>
<TOKEN id="token-7-29" pos="word" morph="none" start_char="809" end_char="817">prolonged</TOKEN>
<TOKEN id="token-7-30" pos="word" morph="none" start_char="819" end_char="822">heat</TOKEN>
<TOKEN id="token-7-31" pos="word" morph="none" start_char="824" end_char="827">wave</TOKEN>
<TOKEN id="token-7-32" pos="punct" morph="none" start_char="828" end_char="828">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="831" end_char="909">
<ORIGINAL_TEXT>The May-June India-Pakistan heatwave saw temperatures reach as high as 50.8 °C.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="831" end_char="833">The</TOKEN>
<TOKEN id="token-8-1" pos="unknown" morph="none" start_char="835" end_char="842">May-June</TOKEN>
<TOKEN id="token-8-2" pos="unknown" morph="none" start_char="844" end_char="857">India-Pakistan</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="859" end_char="866">heatwave</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="868" end_char="870">saw</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="872" end_char="883">temperatures</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="885" end_char="889">reach</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="891" end_char="892">as</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="894" end_char="897">high</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="899" end_char="900">as</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="902" end_char="905">50.8</TOKEN>
<TOKEN id="token-8-11" pos="unknown" morph="none" start_char="907" end_char="909">°C.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="913" end_char="1218">
<ORIGINAL_TEXT>"The water shortage made wild animals such as monkeys engage in the deadly fight over water among each other and would have surely increased the chance of human-wild animal interactions," wrote researchers at the Chinese Academy of Sciences, Fudan University in Shanghai and University of Texas at Houston.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="punct" morph="none" start_char="913" end_char="913">"</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="914" end_char="916">The</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="918" end_char="922">water</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="924" end_char="931">shortage</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="933" end_char="936">made</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="938" end_char="941">wild</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="943" end_char="949">animals</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="951" end_char="954">such</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="956" end_char="957">as</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="959" end_char="965">monkeys</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="967" end_char="972">engage</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="974" end_char="975">in</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="977" end_char="979">the</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="981" end_char="986">deadly</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="988" end_char="992">fight</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="994" end_char="997">over</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="999" end_char="1003">water</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1005" end_char="1009">among</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1011" end_char="1014">each</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1016" end_char="1020">other</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1022" end_char="1024">and</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1026" end_char="1030">would</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1032" end_char="1035">have</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1037" end_char="1042">surely</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1044" end_char="1052">increased</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1054" end_char="1056">the</TOKEN>
<TOKEN id="token-9-26" pos="word" morph="none" start_char="1058" end_char="1063">chance</TOKEN>
<TOKEN id="token-9-27" pos="word" morph="none" start_char="1065" end_char="1066">of</TOKEN>
<TOKEN id="token-9-28" pos="unknown" morph="none" start_char="1068" end_char="1077">human-wild</TOKEN>
<TOKEN id="token-9-29" pos="word" morph="none" start_char="1079" end_char="1084">animal</TOKEN>
<TOKEN id="token-9-30" pos="word" morph="none" start_char="1086" end_char="1097">interactions</TOKEN>
<TOKEN id="token-9-31" pos="punct" morph="none" start_char="1098" end_char="1099">,"</TOKEN>
<TOKEN id="token-9-32" pos="word" morph="none" start_char="1101" end_char="1105">wrote</TOKEN>
<TOKEN id="token-9-33" pos="word" morph="none" start_char="1107" end_char="1117">researchers</TOKEN>
<TOKEN id="token-9-34" pos="word" morph="none" start_char="1119" end_char="1120">at</TOKEN>
<TOKEN id="token-9-35" pos="word" morph="none" start_char="1122" end_char="1124">the</TOKEN>
<TOKEN id="token-9-36" pos="word" morph="none" start_char="1126" end_char="1132">Chinese</TOKEN>
<TOKEN id="token-9-37" pos="word" morph="none" start_char="1134" end_char="1140">Academy</TOKEN>
<TOKEN id="token-9-38" pos="word" morph="none" start_char="1142" end_char="1143">of</TOKEN>
<TOKEN id="token-9-39" pos="word" morph="none" start_char="1145" end_char="1152">Sciences</TOKEN>
<TOKEN id="token-9-40" pos="punct" morph="none" start_char="1153" end_char="1153">,</TOKEN>
<TOKEN id="token-9-41" pos="word" morph="none" start_char="1155" end_char="1159">Fudan</TOKEN>
<TOKEN id="token-9-42" pos="word" morph="none" start_char="1161" end_char="1170">University</TOKEN>
<TOKEN id="token-9-43" pos="word" morph="none" start_char="1172" end_char="1173">in</TOKEN>
<TOKEN id="token-9-44" pos="word" morph="none" start_char="1175" end_char="1182">Shanghai</TOKEN>
<TOKEN id="token-9-45" pos="word" morph="none" start_char="1184" end_char="1186">and</TOKEN>
<TOKEN id="token-9-46" pos="word" morph="none" start_char="1188" end_char="1197">University</TOKEN>
<TOKEN id="token-9-47" pos="word" morph="none" start_char="1199" end_char="1200">of</TOKEN>
<TOKEN id="token-9-48" pos="word" morph="none" start_char="1202" end_char="1206">Texas</TOKEN>
<TOKEN id="token-9-49" pos="word" morph="none" start_char="1208" end_char="1209">at</TOKEN>
<TOKEN id="token-9-50" pos="word" morph="none" start_char="1211" end_char="1217">Houston</TOKEN>
<TOKEN id="token-9-51" pos="punct" morph="none" start_char="1218" end_char="1218">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1221" end_char="1336">
<ORIGINAL_TEXT>"We speculated that the zoonotic transmission of SARS-CoV-2 might be associated with this unusual heat wave as well.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="punct" morph="none" start_char="1221" end_char="1221">"</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1222" end_char="1223">We</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1225" end_char="1234">speculated</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1236" end_char="1239">that</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1241" end_char="1243">the</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1245" end_char="1252">zoonotic</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1254" end_char="1265">transmission</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1267" end_char="1268">of</TOKEN>
<TOKEN id="token-10-8" pos="unknown" morph="none" start_char="1270" end_char="1279">SARS-CoV-2</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1281" end_char="1285">might</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1287" end_char="1288">be</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1290" end_char="1299">associated</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1301" end_char="1304">with</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1306" end_char="1309">this</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1311" end_char="1317">unusual</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1319" end_char="1322">heat</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1324" end_char="1327">wave</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1329" end_char="1330">as</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1332" end_char="1335">well</TOKEN>
<TOKEN id="token-10-19" pos="punct" morph="none" start_char="1336" end_char="1336">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1338" end_char="1540">
<ORIGINAL_TEXT>If it was the case, the heat wave would explain why SARS-CoV-2 is able to rapidly spread in the summer of 2020 while SARS-CoV and MERS-CoV usually slow down their spread in high temperatures," they said.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1338" end_char="1339">If</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1341" end_char="1342">it</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1344" end_char="1346">was</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1348" end_char="1350">the</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1352" end_char="1355">case</TOKEN>
<TOKEN id="token-11-5" pos="punct" morph="none" start_char="1356" end_char="1356">,</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1358" end_char="1360">the</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1362" end_char="1365">heat</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1367" end_char="1370">wave</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1372" end_char="1376">would</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1378" end_char="1384">explain</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1386" end_char="1388">why</TOKEN>
<TOKEN id="token-11-12" pos="unknown" morph="none" start_char="1390" end_char="1399">SARS-CoV-2</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1401" end_char="1402">is</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1404" end_char="1407">able</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1409" end_char="1410">to</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1412" end_char="1418">rapidly</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1420" end_char="1425">spread</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1427" end_char="1428">in</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="1430" end_char="1432">the</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1434" end_char="1439">summer</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="1441" end_char="1442">of</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="1444" end_char="1447">2020</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="1449" end_char="1453">while</TOKEN>
<TOKEN id="token-11-24" pos="unknown" morph="none" start_char="1455" end_char="1462">SARS-CoV</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="1464" end_char="1466">and</TOKEN>
<TOKEN id="token-11-26" pos="unknown" morph="none" start_char="1468" end_char="1475">MERS-CoV</TOKEN>
<TOKEN id="token-11-27" pos="word" morph="none" start_char="1477" end_char="1483">usually</TOKEN>
<TOKEN id="token-11-28" pos="word" morph="none" start_char="1485" end_char="1488">slow</TOKEN>
<TOKEN id="token-11-29" pos="word" morph="none" start_char="1490" end_char="1493">down</TOKEN>
<TOKEN id="token-11-30" pos="word" morph="none" start_char="1495" end_char="1499">their</TOKEN>
<TOKEN id="token-11-31" pos="word" morph="none" start_char="1501" end_char="1506">spread</TOKEN>
<TOKEN id="token-11-32" pos="word" morph="none" start_char="1508" end_char="1509">in</TOKEN>
<TOKEN id="token-11-33" pos="word" morph="none" start_char="1511" end_char="1514">high</TOKEN>
<TOKEN id="token-11-34" pos="word" morph="none" start_char="1516" end_char="1527">temperatures</TOKEN>
<TOKEN id="token-11-35" pos="punct" morph="none" start_char="1528" end_char="1529">,"</TOKEN>
<TOKEN id="token-11-36" pos="word" morph="none" start_char="1531" end_char="1534">they</TOKEN>
<TOKEN id="token-11-37" pos="word" morph="none" start_char="1536" end_char="1539">said</TOKEN>
<TOKEN id="token-11-38" pos="punct" morph="none" start_char="1540" end_char="1540">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1543" end_char="1812">
<ORIGINAL_TEXT>The Chinese researchers say the analysis disproves the theory that the virus first appeared in Wuhan, and suggests eight other countries as the source of the pandemic: Bangladesh, India, Italy, the United States, Greece, Australia, the Czech Republic, Russia and Serbia.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1543" end_char="1545">The</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1547" end_char="1553">Chinese</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1555" end_char="1565">researchers</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1567" end_char="1569">say</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1571" end_char="1573">the</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1575" end_char="1582">analysis</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1584" end_char="1592">disproves</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1594" end_char="1596">the</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1598" end_char="1603">theory</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1605" end_char="1608">that</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1610" end_char="1612">the</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1614" end_char="1618">virus</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1620" end_char="1624">first</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1626" end_char="1633">appeared</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1635" end_char="1636">in</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1638" end_char="1642">Wuhan</TOKEN>
<TOKEN id="token-12-16" pos="punct" morph="none" start_char="1643" end_char="1643">,</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1645" end_char="1647">and</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1649" end_char="1656">suggests</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1658" end_char="1662">eight</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1664" end_char="1668">other</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1670" end_char="1678">countries</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1680" end_char="1681">as</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="1683" end_char="1685">the</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="1687" end_char="1692">source</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="1694" end_char="1695">of</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="1697" end_char="1699">the</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="1701" end_char="1708">pandemic</TOKEN>
<TOKEN id="token-12-28" pos="punct" morph="none" start_char="1709" end_char="1709">:</TOKEN>
<TOKEN id="token-12-29" pos="word" morph="none" start_char="1711" end_char="1720">Bangladesh</TOKEN>
<TOKEN id="token-12-30" pos="punct" morph="none" start_char="1721" end_char="1721">,</TOKEN>
<TOKEN id="token-12-31" pos="word" morph="none" start_char="1723" end_char="1727">India</TOKEN>
<TOKEN id="token-12-32" pos="punct" morph="none" start_char="1728" end_char="1728">,</TOKEN>
<TOKEN id="token-12-33" pos="word" morph="none" start_char="1730" end_char="1734">Italy</TOKEN>
<TOKEN id="token-12-34" pos="punct" morph="none" start_char="1735" end_char="1735">,</TOKEN>
<TOKEN id="token-12-35" pos="word" morph="none" start_char="1737" end_char="1739">the</TOKEN>
<TOKEN id="token-12-36" pos="word" morph="none" start_char="1741" end_char="1746">United</TOKEN>
<TOKEN id="token-12-37" pos="word" morph="none" start_char="1748" end_char="1753">States</TOKEN>
<TOKEN id="token-12-38" pos="punct" morph="none" start_char="1754" end_char="1754">,</TOKEN>
<TOKEN id="token-12-39" pos="word" morph="none" start_char="1756" end_char="1761">Greece</TOKEN>
<TOKEN id="token-12-40" pos="punct" morph="none" start_char="1762" end_char="1762">,</TOKEN>
<TOKEN id="token-12-41" pos="word" morph="none" start_char="1764" end_char="1772">Australia</TOKEN>
<TOKEN id="token-12-42" pos="punct" morph="none" start_char="1773" end_char="1773">,</TOKEN>
<TOKEN id="token-12-43" pos="word" morph="none" start_char="1775" end_char="1777">the</TOKEN>
<TOKEN id="token-12-44" pos="word" morph="none" start_char="1779" end_char="1783">Czech</TOKEN>
<TOKEN id="token-12-45" pos="word" morph="none" start_char="1785" end_char="1792">Republic</TOKEN>
<TOKEN id="token-12-46" pos="punct" morph="none" start_char="1793" end_char="1793">,</TOKEN>
<TOKEN id="token-12-47" pos="word" morph="none" start_char="1795" end_char="1800">Russia</TOKEN>
<TOKEN id="token-12-48" pos="word" morph="none" start_char="1802" end_char="1804">and</TOKEN>
<TOKEN id="token-12-49" pos="word" morph="none" start_char="1806" end_char="1811">Serbia</TOKEN>
<TOKEN id="token-12-50" pos="punct" morph="none" start_char="1812" end_char="1812">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1815" end_char="1888">
<ORIGINAL_TEXT>Of these countries, India and Bangladesh emerge as the leading candidates.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1815" end_char="1816">Of</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1818" end_char="1822">these</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1824" end_char="1832">countries</TOKEN>
<TOKEN id="token-13-3" pos="punct" morph="none" start_char="1833" end_char="1833">,</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1835" end_char="1839">India</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1841" end_char="1843">and</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1845" end_char="1854">Bangladesh</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1856" end_char="1861">emerge</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1863" end_char="1864">as</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1866" end_char="1868">the</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1870" end_char="1876">leading</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1878" end_char="1887">candidates</TOKEN>
<TOKEN id="token-13-12" pos="punct" morph="none" start_char="1888" end_char="1888">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1890" end_char="2040">
<ORIGINAL_TEXT>The fact that the two Asian countries have inadequate health systems may have allowed COVID-19 to spread silently and reach China, possibly via Europe.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1890" end_char="1892">The</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1894" end_char="1897">fact</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1899" end_char="1902">that</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1904" end_char="1906">the</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1908" end_char="1910">two</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1912" end_char="1916">Asian</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1918" end_char="1926">countries</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1928" end_char="1931">have</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1933" end_char="1942">inadequate</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1944" end_char="1949">health</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1951" end_char="1957">systems</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1959" end_char="1961">may</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1963" end_char="1966">have</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1968" end_char="1974">allowed</TOKEN>
<TOKEN id="token-14-14" pos="unknown" morph="none" start_char="1976" end_char="1983">COVID-19</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1985" end_char="1986">to</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1988" end_char="1993">spread</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="1995" end_char="2002">silently</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="2004" end_char="2006">and</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="2008" end_char="2012">reach</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="2014" end_char="2018">China</TOKEN>
<TOKEN id="token-14-21" pos="punct" morph="none" start_char="2019" end_char="2019">,</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="2021" end_char="2028">possibly</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="2030" end_char="2032">via</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="2034" end_char="2039">Europe</TOKEN>
<TOKEN id="token-14-25" pos="punct" morph="none" start_char="2040" end_char="2040">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="2043" end_char="2148">
<ORIGINAL_TEXT>"Our result shows that Wuhan is not the place where human-to-human SARS-CoV-2 transmission first happened.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="punct" morph="none" start_char="2043" end_char="2043">"</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="2044" end_char="2046">Our</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="2048" end_char="2053">result</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="2055" end_char="2059">shows</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="2061" end_char="2064">that</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="2066" end_char="2070">Wuhan</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="2072" end_char="2073">is</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="2075" end_char="2077">not</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="2079" end_char="2081">the</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="2083" end_char="2087">place</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="2089" end_char="2093">where</TOKEN>
<TOKEN id="token-15-11" pos="unknown" morph="none" start_char="2095" end_char="2108">human-to-human</TOKEN>
<TOKEN id="token-15-12" pos="unknown" morph="none" start_char="2110" end_char="2119">SARS-CoV-2</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="2121" end_char="2132">transmission</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="2134" end_char="2138">first</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="2140" end_char="2147">happened</TOKEN>
<TOKEN id="token-15-16" pos="punct" morph="none" start_char="2148" end_char="2148">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="2150" end_char="2299">
<ORIGINAL_TEXT>Before it spread to Wuhan, SARS-CoV-2 has already experienced adaptive evolution during its human-to-human transmission," the three researchers wrote.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="2150" end_char="2155">Before</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="2157" end_char="2158">it</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="2160" end_char="2165">spread</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="2167" end_char="2168">to</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="2170" end_char="2174">Wuhan</TOKEN>
<TOKEN id="token-16-5" pos="punct" morph="none" start_char="2175" end_char="2175">,</TOKEN>
<TOKEN id="token-16-6" pos="unknown" morph="none" start_char="2177" end_char="2186">SARS-CoV-2</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="2188" end_char="2190">has</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="2192" end_char="2198">already</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="2200" end_char="2210">experienced</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="2212" end_char="2219">adaptive</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="2221" end_char="2229">evolution</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="2231" end_char="2236">during</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="2238" end_char="2240">its</TOKEN>
<TOKEN id="token-16-14" pos="unknown" morph="none" start_char="2242" end_char="2255">human-to-human</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="2257" end_char="2268">transmission</TOKEN>
<TOKEN id="token-16-16" pos="punct" morph="none" start_char="2269" end_char="2270">,"</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="2272" end_char="2274">the</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="2276" end_char="2280">three</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="2282" end_char="2292">researchers</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="2294" end_char="2298">wrote</TOKEN>
<TOKEN id="token-16-21" pos="punct" morph="none" start_char="2299" end_char="2299">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2302" end_char="2380">
<ORIGINAL_TEXT>The study has been submitted to The Lancet, but has not yet been peer reviewed.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2302" end_char="2304">The</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2306" end_char="2310">study</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2312" end_char="2314">has</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2316" end_char="2319">been</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2321" end_char="2329">submitted</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2331" end_char="2332">to</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2334" end_char="2336">The</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2338" end_char="2343">Lancet</TOKEN>
<TOKEN id="token-17-8" pos="punct" morph="none" start_char="2344" end_char="2344">,</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2346" end_char="2348">but</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2350" end_char="2352">has</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2354" end_char="2356">not</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2358" end_char="2360">yet</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2362" end_char="2365">been</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2367" end_char="2370">peer</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2372" end_char="2379">reviewed</TOKEN>
<TOKEN id="token-17-16" pos="punct" morph="none" start_char="2380" end_char="2380">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
