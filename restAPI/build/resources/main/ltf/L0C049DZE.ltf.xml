<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="eng">
<DOC id="L0C049DZE" lang="eng" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="8316" raw_text_md5="141d7fe72cdc23c497bc7b7c3a28d906">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="62">
<ORIGINAL_TEXT>Fact-check: Did Dr. Fauci fund research that created COVID-19?</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="unknown" morph="none" start_char="1" end_char="10">Fact-check</TOKEN>
<TOKEN id="token-0-1" pos="punct" morph="none" start_char="11" end_char="11">:</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="13" end_char="15">Did</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="17" end_char="18">Dr</TOKEN>
<TOKEN id="token-0-4" pos="punct" morph="none" start_char="19" end_char="19">.</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="21" end_char="25">Fauci</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="27" end_char="30">fund</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="32" end_char="39">research</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="41" end_char="44">that</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="46" end_char="52">created</TOKEN>
<TOKEN id="token-0-10" pos="unknown" morph="none" start_char="54" end_char="61">COVID-19</TOKEN>
<TOKEN id="token-0-11" pos="punct" morph="none" start_char="62" end_char="62">?</TOKEN>
</SEG>
<SEG id="segment-1" start_char="67" end_char="146">
<ORIGINAL_TEXT>WorldNetDaily: "New evidence ties COVID-19 creation to research funded by Fauci"</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="67" end_char="79">WorldNetDaily</TOKEN>
<TOKEN id="token-1-1" pos="punct" morph="none" start_char="80" end_char="80">:</TOKEN>
<TOKEN id="token-1-2" pos="punct" morph="none" start_char="82" end_char="82">"</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="83" end_char="85">New</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="87" end_char="94">evidence</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="96" end_char="99">ties</TOKEN>
<TOKEN id="token-1-6" pos="unknown" morph="none" start_char="101" end_char="108">COVID-19</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="110" end_char="117">creation</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="119" end_char="120">to</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="122" end_char="129">research</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="131" end_char="136">funded</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="138" end_char="139">by</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="141" end_char="145">Fauci</TOKEN>
<TOKEN id="token-1-13" pos="punct" morph="none" start_char="146" end_char="146">"</TOKEN>
</SEG>
<SEG id="segment-2" start_char="149" end_char="174">
<ORIGINAL_TEXT>PolitiFact's ruling: False</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="149" end_char="160">PolitiFact's</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="162" end_char="167">ruling</TOKEN>
<TOKEN id="token-2-2" pos="punct" morph="none" start_char="168" end_char="168">:</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="170" end_char="174">False</TOKEN>
</SEG>
<SEG id="segment-3" start_char="177" end_char="421">
<ORIGINAL_TEXT>Here's why: More than a year after the coronavirus first arrived in the U.S., conspiracy theories continue to spread about a virology lab in Wuhan, China, which has drawn scrutiny throughout the pandemic for research it conducted on bat viruses.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="177" end_char="182">Here's</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="184" end_char="186">why</TOKEN>
<TOKEN id="token-3-2" pos="punct" morph="none" start_char="187" end_char="187">:</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="189" end_char="192">More</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="194" end_char="197">than</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="199" end_char="199">a</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="201" end_char="204">year</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="206" end_char="210">after</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="212" end_char="214">the</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="216" end_char="226">coronavirus</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="228" end_char="232">first</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="234" end_char="240">arrived</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="242" end_char="243">in</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="245" end_char="247">the</TOKEN>
<TOKEN id="token-3-14" pos="unknown" morph="none" start_char="249" end_char="251">U.S</TOKEN>
<TOKEN id="token-3-15" pos="punct" morph="none" start_char="252" end_char="253">.,</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="255" end_char="264">conspiracy</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="266" end_char="273">theories</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="275" end_char="282">continue</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="284" end_char="285">to</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="287" end_char="292">spread</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="294" end_char="298">about</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="300" end_char="300">a</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="302" end_char="309">virology</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="311" end_char="313">lab</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="315" end_char="316">in</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="318" end_char="322">Wuhan</TOKEN>
<TOKEN id="token-3-27" pos="punct" morph="none" start_char="323" end_char="323">,</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="325" end_char="329">China</TOKEN>
<TOKEN id="token-3-29" pos="punct" morph="none" start_char="330" end_char="330">,</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="332" end_char="336">which</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="338" end_char="340">has</TOKEN>
<TOKEN id="token-3-32" pos="word" morph="none" start_char="342" end_char="346">drawn</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="348" end_char="355">scrutiny</TOKEN>
<TOKEN id="token-3-34" pos="word" morph="none" start_char="357" end_char="366">throughout</TOKEN>
<TOKEN id="token-3-35" pos="word" morph="none" start_char="368" end_char="370">the</TOKEN>
<TOKEN id="token-3-36" pos="word" morph="none" start_char="372" end_char="379">pandemic</TOKEN>
<TOKEN id="token-3-37" pos="word" morph="none" start_char="381" end_char="383">for</TOKEN>
<TOKEN id="token-3-38" pos="word" morph="none" start_char="385" end_char="392">research</TOKEN>
<TOKEN id="token-3-39" pos="word" morph="none" start_char="394" end_char="395">it</TOKEN>
<TOKEN id="token-3-40" pos="word" morph="none" start_char="397" end_char="405">conducted</TOKEN>
<TOKEN id="token-3-41" pos="word" morph="none" start_char="407" end_char="408">on</TOKEN>
<TOKEN id="token-3-42" pos="word" morph="none" start_char="410" end_char="412">bat</TOKEN>
<TOKEN id="token-3-43" pos="word" morph="none" start_char="414" end_char="420">viruses</TOKEN>
<TOKEN id="token-3-44" pos="punct" morph="none" start_char="421" end_char="421">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="424" end_char="526">
<ORIGINAL_TEXT>One new claim about the lab comes from conservative news site WorldNetDaily, which tried to connect Dr.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="424" end_char="426">One</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="428" end_char="430">new</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="432" end_char="436">claim</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="438" end_char="442">about</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="444" end_char="446">the</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="448" end_char="450">lab</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="452" end_char="456">comes</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="458" end_char="461">from</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="463" end_char="474">conservative</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="476" end_char="479">news</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="481" end_char="484">site</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="486" end_char="498">WorldNetDaily</TOKEN>
<TOKEN id="token-4-12" pos="punct" morph="none" start_char="499" end_char="499">,</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="501" end_char="505">which</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="507" end_char="511">tried</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="513" end_char="514">to</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="516" end_char="522">connect</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="524" end_char="525">Dr</TOKEN>
<TOKEN id="token-4-18" pos="punct" morph="none" start_char="526" end_char="526">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="528" end_char="662">
<ORIGINAL_TEXT>Anthony Fauci, head of infectious diseases at the National Institutes of Health, to the origin of the coronavirus that causes COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="528" end_char="534">Anthony</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="536" end_char="540">Fauci</TOKEN>
<TOKEN id="token-5-2" pos="punct" morph="none" start_char="541" end_char="541">,</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="543" end_char="546">head</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="548" end_char="549">of</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="551" end_char="560">infectious</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="562" end_char="569">diseases</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="571" end_char="572">at</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="574" end_char="576">the</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="578" end_char="585">National</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="587" end_char="596">Institutes</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="598" end_char="599">of</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="601" end_char="606">Health</TOKEN>
<TOKEN id="token-5-13" pos="punct" morph="none" start_char="607" end_char="607">,</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="609" end_char="610">to</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="612" end_char="614">the</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="616" end_char="621">origin</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="623" end_char="624">of</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="626" end_char="628">the</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="630" end_char="640">coronavirus</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="642" end_char="645">that</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="647" end_char="652">causes</TOKEN>
<TOKEN id="token-5-22" pos="unknown" morph="none" start_char="654" end_char="661">COVID-19</TOKEN>
<TOKEN id="token-5-23" pos="punct" morph="none" start_char="662" end_char="662">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="665" end_char="750">
<ORIGINAL_TEXT>"New evidence ties COVID-19 creation to research funded by Fauci," reads the headline.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="punct" morph="none" start_char="665" end_char="665">"</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="666" end_char="668">New</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="670" end_char="677">evidence</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="679" end_char="682">ties</TOKEN>
<TOKEN id="token-6-4" pos="unknown" morph="none" start_char="684" end_char="691">COVID-19</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="693" end_char="700">creation</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="702" end_char="703">to</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="705" end_char="712">research</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="714" end_char="719">funded</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="721" end_char="722">by</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="724" end_char="728">Fauci</TOKEN>
<TOKEN id="token-6-11" pos="punct" morph="none" start_char="729" end_char="730">,"</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="732" end_char="736">reads</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="738" end_char="740">the</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="742" end_char="749">headline</TOKEN>
<TOKEN id="token-6-15" pos="punct" morph="none" start_char="750" end_char="750">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="753" end_char="933">
<ORIGINAL_TEXT>As evidence of its claim, the article cited an investigation by Fox News commentator Steve Hilton, who claims that the coronavirus was created at the Wuhan lab with NIH grant money.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="753" end_char="754">As</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="756" end_char="763">evidence</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="765" end_char="766">of</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="768" end_char="770">its</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="772" end_char="776">claim</TOKEN>
<TOKEN id="token-7-5" pos="punct" morph="none" start_char="777" end_char="777">,</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="779" end_char="781">the</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="783" end_char="789">article</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="791" end_char="795">cited</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="797" end_char="798">an</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="800" end_char="812">investigation</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="814" end_char="815">by</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="817" end_char="819">Fox</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="821" end_char="824">News</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="826" end_char="836">commentator</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="838" end_char="842">Steve</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="844" end_char="849">Hilton</TOKEN>
<TOKEN id="token-7-17" pos="punct" morph="none" start_char="850" end_char="850">,</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="852" end_char="854">who</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="856" end_char="861">claims</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="863" end_char="866">that</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="868" end_char="870">the</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="872" end_char="882">coronavirus</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="884" end_char="886">was</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="888" end_char="894">created</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="896" end_char="897">at</TOKEN>
<TOKEN id="token-7-26" pos="word" morph="none" start_char="899" end_char="901">the</TOKEN>
<TOKEN id="token-7-27" pos="word" morph="none" start_char="903" end_char="907">Wuhan</TOKEN>
<TOKEN id="token-7-28" pos="word" morph="none" start_char="909" end_char="911">lab</TOKEN>
<TOKEN id="token-7-29" pos="word" morph="none" start_char="913" end_char="916">with</TOKEN>
<TOKEN id="token-7-30" pos="word" morph="none" start_char="918" end_char="920">NIH</TOKEN>
<TOKEN id="token-7-31" pos="word" morph="none" start_char="922" end_char="926">grant</TOKEN>
<TOKEN id="token-7-32" pos="word" morph="none" start_char="928" end_char="932">money</TOKEN>
<TOKEN id="token-7-33" pos="punct" morph="none" start_char="933" end_char="933">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="936" end_char="1045">
<ORIGINAL_TEXT>Although the NIH did fund a project at the Wuhan lab, there’s no proof that the coronavirus was bioengineered.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="936" end_char="943">Although</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="945" end_char="947">the</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="949" end_char="951">NIH</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="953" end_char="955">did</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="957" end_char="960">fund</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="962" end_char="962">a</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="964" end_char="970">project</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="972" end_char="973">at</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="975" end_char="977">the</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="979" end_char="983">Wuhan</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="985" end_char="987">lab</TOKEN>
<TOKEN id="token-8-11" pos="punct" morph="none" start_char="988" end_char="988">,</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="990" end_char="996">there’s</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="998" end_char="999">no</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1001" end_char="1005">proof</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1007" end_char="1010">that</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1012" end_char="1014">the</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1016" end_char="1026">coronavirus</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1028" end_char="1030">was</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1032" end_char="1044">bioengineered</TOKEN>
<TOKEN id="token-8-20" pos="punct" morph="none" start_char="1045" end_char="1045">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1047" end_char="1211">
<ORIGINAL_TEXT>Both the WorldNetDaily article and Hilton’s segment rely on a series of unsubstantiated allegations to spin a conspiracy theory about the virus being a lab creation.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1047" end_char="1050">Both</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1052" end_char="1054">the</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1056" end_char="1068">WorldNetDaily</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1070" end_char="1076">article</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1078" end_char="1080">and</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1082" end_char="1089">Hilton’s</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1091" end_char="1097">segment</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1099" end_char="1102">rely</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1104" end_char="1105">on</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1107" end_char="1107">a</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1109" end_char="1114">series</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1116" end_char="1117">of</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1119" end_char="1133">unsubstantiated</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1135" end_char="1145">allegations</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1147" end_char="1148">to</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1150" end_char="1153">spin</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1155" end_char="1155">a</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1157" end_char="1166">conspiracy</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1168" end_char="1173">theory</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1175" end_char="1179">about</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1181" end_char="1183">the</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1185" end_char="1189">virus</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1191" end_char="1195">being</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1197" end_char="1197">a</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1199" end_char="1201">lab</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1203" end_char="1210">creation</TOKEN>
<TOKEN id="token-9-26" pos="punct" morph="none" start_char="1211" end_char="1211">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1214" end_char="1392">
<ORIGINAL_TEXT>WorldNetDaily has since dialed back on many of its claims, issuing three separate corrections, all of which cite scientists pushing back on the notion that SARS-CoV-2 was manmade.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1214" end_char="1226">WorldNetDaily</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1228" end_char="1230">has</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1232" end_char="1236">since</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1238" end_char="1243">dialed</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1245" end_char="1248">back</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1250" end_char="1251">on</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1253" end_char="1256">many</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1258" end_char="1259">of</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1261" end_char="1263">its</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1265" end_char="1270">claims</TOKEN>
<TOKEN id="token-10-10" pos="punct" morph="none" start_char="1271" end_char="1271">,</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1273" end_char="1279">issuing</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1281" end_char="1285">three</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1287" end_char="1294">separate</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1296" end_char="1306">corrections</TOKEN>
<TOKEN id="token-10-15" pos="punct" morph="none" start_char="1307" end_char="1307">,</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1309" end_char="1311">all</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1313" end_char="1314">of</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1316" end_char="1320">which</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1322" end_char="1325">cite</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1327" end_char="1336">scientists</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1338" end_char="1344">pushing</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1346" end_char="1349">back</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1351" end_char="1352">on</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1354" end_char="1356">the</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="1358" end_char="1363">notion</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="1365" end_char="1368">that</TOKEN>
<TOKEN id="token-10-27" pos="unknown" morph="none" start_char="1370" end_char="1379">SARS-CoV-2</TOKEN>
<TOKEN id="token-10-28" pos="word" morph="none" start_char="1381" end_char="1383">was</TOKEN>
<TOKEN id="token-10-29" pos="word" morph="none" start_char="1385" end_char="1391">manmade</TOKEN>
<TOKEN id="token-10-30" pos="punct" morph="none" start_char="1392" end_char="1392">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1394" end_char="1464">
<ORIGINAL_TEXT>It has also placed a question mark at the end of the original headline.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1394" end_char="1395">It</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1397" end_char="1399">has</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1401" end_char="1404">also</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1406" end_char="1411">placed</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1413" end_char="1413">a</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1415" end_char="1422">question</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1424" end_char="1427">mark</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1429" end_char="1430">at</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1432" end_char="1434">the</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1436" end_char="1438">end</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1440" end_char="1441">of</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1443" end_char="1445">the</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1447" end_char="1454">original</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1456" end_char="1463">headline</TOKEN>
<TOKEN id="token-11-14" pos="punct" morph="none" start_char="1464" end_char="1464">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1466" end_char="1524">
<ORIGINAL_TEXT>However, the bulk of the article text has not been updated.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1466" end_char="1472">However</TOKEN>
<TOKEN id="token-12-1" pos="punct" morph="none" start_char="1473" end_char="1473">,</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1475" end_char="1477">the</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1479" end_char="1482">bulk</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1484" end_char="1485">of</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1487" end_char="1489">the</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1491" end_char="1497">article</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1499" end_char="1502">text</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1504" end_char="1506">has</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1508" end_char="1510">not</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1512" end_char="1515">been</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1517" end_char="1523">updated</TOKEN>
<TOKEN id="token-12-12" pos="punct" morph="none" start_char="1524" end_char="1524">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1527" end_char="1561">
<ORIGINAL_TEXT>The NIH grant to EcoHealth Alliance</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1527" end_char="1529">The</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1531" end_char="1533">NIH</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1535" end_char="1539">grant</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1541" end_char="1542">to</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1544" end_char="1552">EcoHealth</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1554" end_char="1561">Alliance</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1565" end_char="1820">
<ORIGINAL_TEXT>In 2014, the U.S. National Institute of Allergy and Infectious Disease, the part of the NIH headed by Fauci, awarded a $3.4 million grant to the New York-based EcoHealth Alliance, which aims to protect people from viruses that jump from species to species.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1565" end_char="1566">In</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1568" end_char="1571">2014</TOKEN>
<TOKEN id="token-14-2" pos="punct" morph="none" start_char="1572" end_char="1572">,</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1574" end_char="1576">the</TOKEN>
<TOKEN id="token-14-4" pos="unknown" morph="none" start_char="1578" end_char="1580">U.S</TOKEN>
<TOKEN id="token-14-5" pos="punct" morph="none" start_char="1581" end_char="1581">.</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1583" end_char="1590">National</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1592" end_char="1600">Institute</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1602" end_char="1603">of</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1605" end_char="1611">Allergy</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1613" end_char="1615">and</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1617" end_char="1626">Infectious</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1628" end_char="1634">Disease</TOKEN>
<TOKEN id="token-14-13" pos="punct" morph="none" start_char="1635" end_char="1635">,</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="1637" end_char="1639">the</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1641" end_char="1644">part</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1646" end_char="1647">of</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="1649" end_char="1651">the</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="1653" end_char="1655">NIH</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="1657" end_char="1662">headed</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="1664" end_char="1665">by</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="1667" end_char="1671">Fauci</TOKEN>
<TOKEN id="token-14-22" pos="punct" morph="none" start_char="1672" end_char="1672">,</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="1674" end_char="1680">awarded</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="1682" end_char="1682">a</TOKEN>
<TOKEN id="token-14-25" pos="unknown" morph="none" start_char="1684" end_char="1687">$3.4</TOKEN>
<TOKEN id="token-14-26" pos="word" morph="none" start_char="1689" end_char="1695">million</TOKEN>
<TOKEN id="token-14-27" pos="word" morph="none" start_char="1697" end_char="1701">grant</TOKEN>
<TOKEN id="token-14-28" pos="word" morph="none" start_char="1703" end_char="1704">to</TOKEN>
<TOKEN id="token-14-29" pos="word" morph="none" start_char="1706" end_char="1708">the</TOKEN>
<TOKEN id="token-14-30" pos="word" morph="none" start_char="1710" end_char="1712">New</TOKEN>
<TOKEN id="token-14-31" pos="unknown" morph="none" start_char="1714" end_char="1723">York-based</TOKEN>
<TOKEN id="token-14-32" pos="word" morph="none" start_char="1725" end_char="1733">EcoHealth</TOKEN>
<TOKEN id="token-14-33" pos="word" morph="none" start_char="1735" end_char="1742">Alliance</TOKEN>
<TOKEN id="token-14-34" pos="punct" morph="none" start_char="1743" end_char="1743">,</TOKEN>
<TOKEN id="token-14-35" pos="word" morph="none" start_char="1745" end_char="1749">which</TOKEN>
<TOKEN id="token-14-36" pos="word" morph="none" start_char="1751" end_char="1754">aims</TOKEN>
<TOKEN id="token-14-37" pos="word" morph="none" start_char="1756" end_char="1757">to</TOKEN>
<TOKEN id="token-14-38" pos="word" morph="none" start_char="1759" end_char="1765">protect</TOKEN>
<TOKEN id="token-14-39" pos="word" morph="none" start_char="1767" end_char="1772">people</TOKEN>
<TOKEN id="token-14-40" pos="word" morph="none" start_char="1774" end_char="1777">from</TOKEN>
<TOKEN id="token-14-41" pos="word" morph="none" start_char="1779" end_char="1785">viruses</TOKEN>
<TOKEN id="token-14-42" pos="word" morph="none" start_char="1787" end_char="1790">that</TOKEN>
<TOKEN id="token-14-43" pos="word" morph="none" start_char="1792" end_char="1795">jump</TOKEN>
<TOKEN id="token-14-44" pos="word" morph="none" start_char="1797" end_char="1800">from</TOKEN>
<TOKEN id="token-14-45" pos="word" morph="none" start_char="1802" end_char="1808">species</TOKEN>
<TOKEN id="token-14-46" pos="word" morph="none" start_char="1810" end_char="1811">to</TOKEN>
<TOKEN id="token-14-47" pos="word" morph="none" start_char="1813" end_char="1819">species</TOKEN>
<TOKEN id="token-14-48" pos="punct" morph="none" start_char="1820" end_char="1820">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1823" end_char="1978">
<ORIGINAL_TEXT>The group hired the virology lab in Wuhan to conduct genetic analyses of bat coronaviruses collected in Yunnan province, about 800 miles southwest of Wuhan.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1823" end_char="1825">The</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1827" end_char="1831">group</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1833" end_char="1837">hired</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1839" end_char="1841">the</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1843" end_char="1850">virology</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1852" end_char="1854">lab</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1856" end_char="1857">in</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1859" end_char="1863">Wuhan</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1865" end_char="1866">to</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1868" end_char="1874">conduct</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1876" end_char="1882">genetic</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1884" end_char="1891">analyses</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1893" end_char="1894">of</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1896" end_char="1898">bat</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1900" end_char="1912">coronaviruses</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="1914" end_char="1922">collected</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="1924" end_char="1925">in</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="1927" end_char="1932">Yunnan</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="1934" end_char="1941">province</TOKEN>
<TOKEN id="token-15-19" pos="punct" morph="none" start_char="1942" end_char="1942">,</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="1944" end_char="1948">about</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="1950" end_char="1952">800</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="1954" end_char="1958">miles</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="1960" end_char="1968">southwest</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="1970" end_char="1971">of</TOKEN>
<TOKEN id="token-15-25" pos="word" morph="none" start_char="1973" end_char="1977">Wuhan</TOKEN>
<TOKEN id="token-15-26" pos="punct" morph="none" start_char="1978" end_char="1978">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1980" end_char="2036">
<ORIGINAL_TEXT>EcoHealth Alliance paid the lab $598,500 over five years.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1980" end_char="1988">EcoHealth</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1990" end_char="1997">Alliance</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1999" end_char="2002">paid</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="2004" end_char="2006">the</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="2008" end_char="2010">lab</TOKEN>
<TOKEN id="token-16-5" pos="unknown" morph="none" start_char="2012" end_char="2019">$598,500</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="2021" end_char="2024">over</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="2026" end_char="2029">five</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="2031" end_char="2035">years</TOKEN>
<TOKEN id="token-16-9" pos="punct" morph="none" start_char="2036" end_char="2036">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2038" end_char="2114">
<ORIGINAL_TEXT>The lab had secured approval from both the U.S. State Department and the NIH.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2038" end_char="2040">The</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2042" end_char="2044">lab</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2046" end_char="2048">had</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2050" end_char="2056">secured</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2058" end_char="2065">approval</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2067" end_char="2070">from</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2072" end_char="2075">both</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2077" end_char="2079">the</TOKEN>
<TOKEN id="token-17-8" pos="unknown" morph="none" start_char="2081" end_char="2083">U.S</TOKEN>
<TOKEN id="token-17-9" pos="punct" morph="none" start_char="2084" end_char="2084">.</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2086" end_char="2090">State</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2092" end_char="2101">Department</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2103" end_char="2105">and</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2107" end_char="2109">the</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2111" end_char="2113">NIH</TOKEN>
<TOKEN id="token-17-15" pos="punct" morph="none" start_char="2114" end_char="2114">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2117" end_char="2169">
<ORIGINAL_TEXT>That the NIAID funded the project is not in question.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2117" end_char="2120">That</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2122" end_char="2124">the</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2126" end_char="2130">NIAID</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2132" end_char="2137">funded</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2139" end_char="2141">the</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2143" end_char="2149">project</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2151" end_char="2152">is</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2154" end_char="2156">not</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2158" end_char="2159">in</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="2161" end_char="2168">question</TOKEN>
<TOKEN id="token-18-10" pos="punct" morph="none" start_char="2169" end_char="2169">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2171" end_char="2338">
<ORIGINAL_TEXT>However, the WorldNetDaily article goes further than that, claiming that the grant covered "gain of function" research on a bat coronavirus, which "created" SARS-CoV-2.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2171" end_char="2177">However</TOKEN>
<TOKEN id="token-19-1" pos="punct" morph="none" start_char="2178" end_char="2178">,</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2180" end_char="2182">the</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2184" end_char="2196">WorldNetDaily</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2198" end_char="2204">article</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2206" end_char="2209">goes</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2211" end_char="2217">further</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2219" end_char="2222">than</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2224" end_char="2227">that</TOKEN>
<TOKEN id="token-19-9" pos="punct" morph="none" start_char="2228" end_char="2228">,</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="2230" end_char="2237">claiming</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="2239" end_char="2242">that</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="2244" end_char="2246">the</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="2248" end_char="2252">grant</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="2254" end_char="2260">covered</TOKEN>
<TOKEN id="token-19-15" pos="punct" morph="none" start_char="2262" end_char="2262">"</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="2263" end_char="2266">gain</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="2268" end_char="2269">of</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="2271" end_char="2278">function</TOKEN>
<TOKEN id="token-19-19" pos="punct" morph="none" start_char="2279" end_char="2279">"</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="2281" end_char="2288">research</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="2290" end_char="2291">on</TOKEN>
<TOKEN id="token-19-22" pos="word" morph="none" start_char="2293" end_char="2293">a</TOKEN>
<TOKEN id="token-19-23" pos="word" morph="none" start_char="2295" end_char="2297">bat</TOKEN>
<TOKEN id="token-19-24" pos="word" morph="none" start_char="2299" end_char="2309">coronavirus</TOKEN>
<TOKEN id="token-19-25" pos="punct" morph="none" start_char="2310" end_char="2310">,</TOKEN>
<TOKEN id="token-19-26" pos="word" morph="none" start_char="2312" end_char="2316">which</TOKEN>
<TOKEN id="token-19-27" pos="punct" morph="none" start_char="2318" end_char="2318">"</TOKEN>
<TOKEN id="token-19-28" pos="word" morph="none" start_char="2319" end_char="2325">created</TOKEN>
<TOKEN id="token-19-29" pos="punct" morph="none" start_char="2326" end_char="2326">"</TOKEN>
<TOKEN id="token-19-30" pos="unknown" morph="none" start_char="2328" end_char="2337">SARS-CoV-2</TOKEN>
<TOKEN id="token-19-31" pos="punct" morph="none" start_char="2338" end_char="2338">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2341" end_char="2466">
<ORIGINAL_TEXT>Gain-of-function research is a controversial form of study that involves boosting the infectivity and lethality of a pathogen.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="unknown" morph="none" start_char="2341" end_char="2356">Gain-of-function</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2358" end_char="2365">research</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2367" end_char="2368">is</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2370" end_char="2370">a</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2372" end_char="2384">controversial</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2386" end_char="2389">form</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2391" end_char="2392">of</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2394" end_char="2398">study</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="2400" end_char="2403">that</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2405" end_char="2412">involves</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2414" end_char="2421">boosting</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="2423" end_char="2425">the</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="2427" end_char="2437">infectivity</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="2439" end_char="2441">and</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="2443" end_char="2451">lethality</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="2453" end_char="2454">of</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="2456" end_char="2456">a</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="2458" end_char="2465">pathogen</TOKEN>
<TOKEN id="token-20-18" pos="punct" morph="none" start_char="2466" end_char="2466">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2468" end_char="2619">
<ORIGINAL_TEXT>Proponents of gain-of-function say it helps researchers spot potential threats to human health and allows them to figure out ways to tackle a new virus.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2468" end_char="2477">Proponents</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2479" end_char="2480">of</TOKEN>
<TOKEN id="token-21-2" pos="unknown" morph="none" start_char="2482" end_char="2497">gain-of-function</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2499" end_char="2501">say</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2503" end_char="2504">it</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="2506" end_char="2510">helps</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2512" end_char="2522">researchers</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="2524" end_char="2527">spot</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="2529" end_char="2537">potential</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="2539" end_char="2545">threats</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="2547" end_char="2548">to</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="2550" end_char="2554">human</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="2556" end_char="2561">health</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="2563" end_char="2565">and</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="2567" end_char="2572">allows</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="2574" end_char="2577">them</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="2579" end_char="2580">to</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="2582" end_char="2587">figure</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="2589" end_char="2591">out</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="2593" end_char="2596">ways</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="2598" end_char="2599">to</TOKEN>
<TOKEN id="token-21-21" pos="word" morph="none" start_char="2601" end_char="2606">tackle</TOKEN>
<TOKEN id="token-21-22" pos="word" morph="none" start_char="2608" end_char="2608">a</TOKEN>
<TOKEN id="token-21-23" pos="word" morph="none" start_char="2610" end_char="2612">new</TOKEN>
<TOKEN id="token-21-24" pos="word" morph="none" start_char="2614" end_char="2618">virus</TOKEN>
<TOKEN id="token-21-25" pos="punct" morph="none" start_char="2619" end_char="2619">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2621" end_char="2682">
<ORIGINAL_TEXT>Fauci has advocated for gain-of-function research in the past.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2621" end_char="2625">Fauci</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2627" end_char="2629">has</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2631" end_char="2639">advocated</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2641" end_char="2643">for</TOKEN>
<TOKEN id="token-22-4" pos="unknown" morph="none" start_char="2645" end_char="2660">gain-of-function</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2662" end_char="2669">research</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2671" end_char="2672">in</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2674" end_char="2676">the</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="2678" end_char="2681">past</TOKEN>
<TOKEN id="token-22-9" pos="punct" morph="none" start_char="2682" end_char="2682">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2684" end_char="2791">
<ORIGINAL_TEXT>In a 2011 article he co-wrote for the Washington Post, he promoted it as a means to study influenza viruses.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2684" end_char="2685">In</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2687" end_char="2687">a</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2689" end_char="2692">2011</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2694" end_char="2700">article</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="2702" end_char="2703">he</TOKEN>
<TOKEN id="token-23-5" pos="unknown" morph="none" start_char="2705" end_char="2712">co-wrote</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="2714" end_char="2716">for</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="2718" end_char="2720">the</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="2722" end_char="2731">Washington</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="2733" end_char="2736">Post</TOKEN>
<TOKEN id="token-23-10" pos="punct" morph="none" start_char="2737" end_char="2737">,</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="2739" end_char="2740">he</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="2742" end_char="2749">promoted</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="2751" end_char="2752">it</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="2754" end_char="2755">as</TOKEN>
<TOKEN id="token-23-15" pos="word" morph="none" start_char="2757" end_char="2757">a</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="2759" end_char="2763">means</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="2765" end_char="2766">to</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="2768" end_char="2772">study</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="2774" end_char="2782">influenza</TOKEN>
<TOKEN id="token-23-20" pos="word" morph="none" start_char="2784" end_char="2790">viruses</TOKEN>
<TOKEN id="token-23-21" pos="punct" morph="none" start_char="2791" end_char="2791">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2794" end_char="2888">
<ORIGINAL_TEXT>However, there’s no hard proof to support the article’s claims about gain-of-function research.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="2794" end_char="2800">However</TOKEN>
<TOKEN id="token-24-1" pos="punct" morph="none" start_char="2801" end_char="2801">,</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="2803" end_char="2809">there’s</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="2811" end_char="2812">no</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="2814" end_char="2817">hard</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="2819" end_char="2823">proof</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="2825" end_char="2826">to</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="2828" end_char="2834">support</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="2836" end_char="2838">the</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="2840" end_char="2848">article’s</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="2850" end_char="2855">claims</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="2857" end_char="2861">about</TOKEN>
<TOKEN id="token-24-12" pos="unknown" morph="none" start_char="2863" end_char="2878">gain-of-function</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="2880" end_char="2887">research</TOKEN>
<TOKEN id="token-24-14" pos="punct" morph="none" start_char="2888" end_char="2888">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2890" end_char="3007">
<ORIGINAL_TEXT>The overwhelming consensus among public health experts is that the coronavirus that causes COVID-19 evolved naturally.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="2890" end_char="2892">The</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="2894" end_char="2905">overwhelming</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="2907" end_char="2915">consensus</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="2917" end_char="2921">among</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="2923" end_char="2928">public</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="2930" end_char="2935">health</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="2937" end_char="2943">experts</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="2945" end_char="2946">is</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="2948" end_char="2951">that</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="2953" end_char="2955">the</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="2957" end_char="2967">coronavirus</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="2969" end_char="2972">that</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="2974" end_char="2979">causes</TOKEN>
<TOKEN id="token-25-13" pos="unknown" morph="none" start_char="2981" end_char="2988">COVID-19</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="2990" end_char="2996">evolved</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="2998" end_char="3006">naturally</TOKEN>
<TOKEN id="token-25-16" pos="punct" morph="none" start_char="3007" end_char="3007">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="3010" end_char="3133">
<ORIGINAL_TEXT>All parties involved in the grant to the Wuhan Institute of Virology have denied that it involved gain-of-function research.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="3010" end_char="3012">All</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="3014" end_char="3020">parties</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="3022" end_char="3029">involved</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="3031" end_char="3032">in</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="3034" end_char="3036">the</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="3038" end_char="3042">grant</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="3044" end_char="3045">to</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="3047" end_char="3049">the</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="3051" end_char="3055">Wuhan</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="3057" end_char="3065">Institute</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="3067" end_char="3068">of</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="3070" end_char="3077">Virology</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="3079" end_char="3082">have</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="3084" end_char="3089">denied</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="3091" end_char="3094">that</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="3096" end_char="3097">it</TOKEN>
<TOKEN id="token-26-16" pos="word" morph="none" start_char="3099" end_char="3106">involved</TOKEN>
<TOKEN id="token-26-17" pos="unknown" morph="none" start_char="3108" end_char="3123">gain-of-function</TOKEN>
<TOKEN id="token-26-18" pos="word" morph="none" start_char="3125" end_char="3132">research</TOKEN>
<TOKEN id="token-26-19" pos="punct" morph="none" start_char="3133" end_char="3133">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="3136" end_char="3218">
<ORIGINAL_TEXT>The NIH told us: "The research supported under the grant to EcoHealth Alliance Inc.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="3136" end_char="3138">The</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="3140" end_char="3142">NIH</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="3144" end_char="3147">told</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="3149" end_char="3150">us</TOKEN>
<TOKEN id="token-27-4" pos="punct" morph="none" start_char="3151" end_char="3151">:</TOKEN>
<TOKEN id="token-27-5" pos="punct" morph="none" start_char="3153" end_char="3153">"</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="3154" end_char="3156">The</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="3158" end_char="3165">research</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="3167" end_char="3175">supported</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="3177" end_char="3181">under</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="3183" end_char="3185">the</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="3187" end_char="3191">grant</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="3193" end_char="3194">to</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="3196" end_char="3204">EcoHealth</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="3206" end_char="3213">Alliance</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="3215" end_char="3217">Inc</TOKEN>
<TOKEN id="token-27-16" pos="punct" morph="none" start_char="3218" end_char="3218">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3220" end_char="3420">
<ORIGINAL_TEXT>characterized the function of newly discovered bat spike proteins and naturally occurring pathogens and did not involve the enhancement of the pathogenicity or transmissibility of the viruses studied."</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="3220" end_char="3232">characterized</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="3234" end_char="3236">the</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="3238" end_char="3245">function</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="3247" end_char="3248">of</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="3250" end_char="3254">newly</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="3256" end_char="3265">discovered</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="3267" end_char="3269">bat</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="3271" end_char="3275">spike</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="3277" end_char="3284">proteins</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="3286" end_char="3288">and</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="3290" end_char="3298">naturally</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="3300" end_char="3308">occurring</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="3310" end_char="3318">pathogens</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="3320" end_char="3322">and</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="3324" end_char="3326">did</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="3328" end_char="3330">not</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="3332" end_char="3338">involve</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="3340" end_char="3342">the</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="3344" end_char="3354">enhancement</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="3356" end_char="3357">of</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="3359" end_char="3361">the</TOKEN>
<TOKEN id="token-28-21" pos="word" morph="none" start_char="3363" end_char="3375">pathogenicity</TOKEN>
<TOKEN id="token-28-22" pos="word" morph="none" start_char="3377" end_char="3378">or</TOKEN>
<TOKEN id="token-28-23" pos="word" morph="none" start_char="3380" end_char="3395">transmissibility</TOKEN>
<TOKEN id="token-28-24" pos="word" morph="none" start_char="3397" end_char="3398">of</TOKEN>
<TOKEN id="token-28-25" pos="word" morph="none" start_char="3400" end_char="3402">the</TOKEN>
<TOKEN id="token-28-26" pos="word" morph="none" start_char="3404" end_char="3410">viruses</TOKEN>
<TOKEN id="token-28-27" pos="word" morph="none" start_char="3412" end_char="3418">studied</TOKEN>
<TOKEN id="token-28-28" pos="punct" morph="none" start_char="3419" end_char="3420">."</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3423" end_char="3457">
<ORIGINAL_TEXT>The grant was approved in May 2014.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="3423" end_char="3425">The</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="3427" end_char="3431">grant</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="3433" end_char="3435">was</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="3437" end_char="3444">approved</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="3446" end_char="3447">in</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="3449" end_char="3451">May</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="3453" end_char="3456">2014</TOKEN>
<TOKEN id="token-29-7" pos="punct" morph="none" start_char="3457" end_char="3457">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3459" end_char="3484">
<ORIGINAL_TEXT>Five months later, on Oct.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="3459" end_char="3462">Five</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="3464" end_char="3469">months</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="3471" end_char="3475">later</TOKEN>
<TOKEN id="token-30-3" pos="punct" morph="none" start_char="3476" end_char="3476">,</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="3478" end_char="3479">on</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="3481" end_char="3483">Oct</TOKEN>
<TOKEN id="token-30-6" pos="punct" morph="none" start_char="3484" end_char="3484">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="3486" end_char="3629">
<ORIGINAL_TEXT>17, the Obama administration announced it would not fund new projects that involved gain-of-function research, citing safety and security risks.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="3486" end_char="3487">17</TOKEN>
<TOKEN id="token-31-1" pos="punct" morph="none" start_char="3488" end_char="3488">,</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="3490" end_char="3492">the</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="3494" end_char="3498">Obama</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="3500" end_char="3513">administration</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="3515" end_char="3523">announced</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="3525" end_char="3526">it</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="3528" end_char="3532">would</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="3534" end_char="3536">not</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="3538" end_char="3541">fund</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="3543" end_char="3545">new</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="3547" end_char="3554">projects</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="3556" end_char="3559">that</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="3561" end_char="3568">involved</TOKEN>
<TOKEN id="token-31-14" pos="unknown" morph="none" start_char="3570" end_char="3585">gain-of-function</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="3587" end_char="3594">research</TOKEN>
<TOKEN id="token-31-16" pos="punct" morph="none" start_char="3595" end_char="3595">,</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="3597" end_char="3602">citing</TOKEN>
<TOKEN id="token-31-18" pos="word" morph="none" start_char="3604" end_char="3609">safety</TOKEN>
<TOKEN id="token-31-19" pos="word" morph="none" start_char="3611" end_char="3613">and</TOKEN>
<TOKEN id="token-31-20" pos="word" morph="none" start_char="3615" end_char="3622">security</TOKEN>
<TOKEN id="token-31-21" pos="word" morph="none" start_char="3624" end_char="3628">risks</TOKEN>
<TOKEN id="token-31-22" pos="punct" morph="none" start_char="3629" end_char="3629">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="3632" end_char="3784">
<ORIGINAL_TEXT>The NIH told us that it reviewed the EcoHealth Alliance project after the funding pause and determined that it did not involve gain-of-function research.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="3632" end_char="3634">The</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="3636" end_char="3638">NIH</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="3640" end_char="3643">told</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="3645" end_char="3646">us</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="3648" end_char="3651">that</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="3653" end_char="3654">it</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="3656" end_char="3663">reviewed</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="3665" end_char="3667">the</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="3669" end_char="3677">EcoHealth</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="3679" end_char="3686">Alliance</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="3688" end_char="3694">project</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="3696" end_char="3700">after</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="3702" end_char="3704">the</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="3706" end_char="3712">funding</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="3714" end_char="3718">pause</TOKEN>
<TOKEN id="token-32-15" pos="word" morph="none" start_char="3720" end_char="3722">and</TOKEN>
<TOKEN id="token-32-16" pos="word" morph="none" start_char="3724" end_char="3733">determined</TOKEN>
<TOKEN id="token-32-17" pos="word" morph="none" start_char="3735" end_char="3738">that</TOKEN>
<TOKEN id="token-32-18" pos="word" morph="none" start_char="3740" end_char="3741">it</TOKEN>
<TOKEN id="token-32-19" pos="word" morph="none" start_char="3743" end_char="3745">did</TOKEN>
<TOKEN id="token-32-20" pos="word" morph="none" start_char="3747" end_char="3749">not</TOKEN>
<TOKEN id="token-32-21" pos="word" morph="none" start_char="3751" end_char="3757">involve</TOKEN>
<TOKEN id="token-32-22" pos="unknown" morph="none" start_char="3759" end_char="3774">gain-of-function</TOKEN>
<TOKEN id="token-32-23" pos="word" morph="none" start_char="3776" end_char="3783">research</TOKEN>
<TOKEN id="token-32-24" pos="punct" morph="none" start_char="3784" end_char="3784">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="3786" end_char="3850">
<ORIGINAL_TEXT>As a result, it was not affected by the White House’s new policy.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="3786" end_char="3787">As</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="3789" end_char="3789">a</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="3791" end_char="3796">result</TOKEN>
<TOKEN id="token-33-3" pos="punct" morph="none" start_char="3797" end_char="3797">,</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="3799" end_char="3800">it</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="3802" end_char="3804">was</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="3806" end_char="3808">not</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="3810" end_char="3817">affected</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="3819" end_char="3820">by</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="3822" end_char="3824">the</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="3826" end_char="3830">White</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="3832" end_char="3838">House’s</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="3840" end_char="3842">new</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="3844" end_char="3849">policy</TOKEN>
<TOKEN id="token-33-14" pos="punct" morph="none" start_char="3850" end_char="3850">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="3853" end_char="3950">
<ORIGINAL_TEXT>Hilton and WorldNetDaily do not provide evidence that the grant covered gain-of-function research.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="3853" end_char="3858">Hilton</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="3860" end_char="3862">and</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="3864" end_char="3876">WorldNetDaily</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="3878" end_char="3879">do</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="3881" end_char="3883">not</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="3885" end_char="3891">provide</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="3893" end_char="3900">evidence</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="3902" end_char="3905">that</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="3907" end_char="3909">the</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="3911" end_char="3915">grant</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="3917" end_char="3923">covered</TOKEN>
<TOKEN id="token-34-11" pos="unknown" morph="none" start_char="3925" end_char="3940">gain-of-function</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="3942" end_char="3949">research</TOKEN>
<TOKEN id="token-34-13" pos="punct" morph="none" start_char="3950" end_char="3950">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="3952" end_char="4048">
<ORIGINAL_TEXT>When we reached out to Fox News, a spokesperson pointed us to the transcript of Hilton’s segment.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="3952" end_char="3955">When</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="3957" end_char="3958">we</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="3960" end_char="3966">reached</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="3968" end_char="3970">out</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="3972" end_char="3973">to</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="3975" end_char="3977">Fox</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="3979" end_char="3982">News</TOKEN>
<TOKEN id="token-35-7" pos="punct" morph="none" start_char="3983" end_char="3983">,</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="3985" end_char="3985">a</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="3987" end_char="3998">spokesperson</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="4000" end_char="4006">pointed</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="4008" end_char="4009">us</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="4011" end_char="4012">to</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="4014" end_char="4016">the</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="4018" end_char="4027">transcript</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="4029" end_char="4030">of</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="4032" end_char="4039">Hilton’s</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="4041" end_char="4047">segment</TOKEN>
<TOKEN id="token-35-18" pos="punct" morph="none" start_char="4048" end_char="4048">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="4051" end_char="4171">
<ORIGINAL_TEXT>MIT biologist Kevin Esvelt reviewed a paper that appears to have been published with financial assistance from the grant.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="4051" end_char="4053">MIT</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="4055" end_char="4063">biologist</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="4065" end_char="4069">Kevin</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="4071" end_char="4076">Esvelt</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="4078" end_char="4085">reviewed</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="4087" end_char="4087">a</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="4089" end_char="4093">paper</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="4095" end_char="4098">that</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="4100" end_char="4106">appears</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="4108" end_char="4109">to</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="4111" end_char="4114">have</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="4116" end_char="4119">been</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="4121" end_char="4129">published</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="4131" end_char="4134">with</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="4136" end_char="4144">financial</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="4146" end_char="4155">assistance</TOKEN>
<TOKEN id="token-36-16" pos="word" morph="none" start_char="4157" end_char="4160">from</TOKEN>
<TOKEN id="token-36-17" pos="word" morph="none" start_char="4162" end_char="4164">the</TOKEN>
<TOKEN id="token-36-18" pos="word" morph="none" start_char="4166" end_char="4170">grant</TOKEN>
<TOKEN id="token-36-19" pos="punct" morph="none" start_char="4171" end_char="4171">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="4173" end_char="4297">
<ORIGINAL_TEXT>According to Esvelt, certain techniques that the researchers used seemed to meet the definition of gain-of-function research.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="4173" end_char="4181">According</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="4183" end_char="4184">to</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="4186" end_char="4191">Esvelt</TOKEN>
<TOKEN id="token-37-3" pos="punct" morph="none" start_char="4192" end_char="4192">,</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="4194" end_char="4200">certain</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="4202" end_char="4211">techniques</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="4213" end_char="4216">that</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="4218" end_char="4220">the</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="4222" end_char="4232">researchers</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="4234" end_char="4237">used</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="4239" end_char="4244">seemed</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="4246" end_char="4247">to</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="4249" end_char="4252">meet</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="4254" end_char="4256">the</TOKEN>
<TOKEN id="token-37-14" pos="word" morph="none" start_char="4258" end_char="4267">definition</TOKEN>
<TOKEN id="token-37-15" pos="word" morph="none" start_char="4269" end_char="4270">of</TOKEN>
<TOKEN id="token-37-16" pos="unknown" morph="none" start_char="4272" end_char="4287">gain-of-function</TOKEN>
<TOKEN id="token-37-17" pos="word" morph="none" start_char="4289" end_char="4296">research</TOKEN>
<TOKEN id="token-37-18" pos="punct" morph="none" start_char="4297" end_char="4297">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="4299" end_char="4527">
<ORIGINAL_TEXT>But he told PolitiFact that "the work reported in this specific paper definitely did NOT lead to the creation of SARS-CoV-2" because the genetic sequences of the virus studied in the paper differ from that of the new coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="4299" end_char="4301">But</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="4303" end_char="4304">he</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="4306" end_char="4309">told</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="4311" end_char="4320">PolitiFact</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="4322" end_char="4325">that</TOKEN>
<TOKEN id="token-38-5" pos="punct" morph="none" start_char="4327" end_char="4327">"</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="4328" end_char="4330">the</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="4332" end_char="4335">work</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="4337" end_char="4344">reported</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="4346" end_char="4347">in</TOKEN>
<TOKEN id="token-38-10" pos="word" morph="none" start_char="4349" end_char="4352">this</TOKEN>
<TOKEN id="token-38-11" pos="word" morph="none" start_char="4354" end_char="4361">specific</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="4363" end_char="4367">paper</TOKEN>
<TOKEN id="token-38-13" pos="word" morph="none" start_char="4369" end_char="4378">definitely</TOKEN>
<TOKEN id="token-38-14" pos="word" morph="none" start_char="4380" end_char="4382">did</TOKEN>
<TOKEN id="token-38-15" pos="word" morph="none" start_char="4384" end_char="4386">NOT</TOKEN>
<TOKEN id="token-38-16" pos="word" morph="none" start_char="4388" end_char="4391">lead</TOKEN>
<TOKEN id="token-38-17" pos="word" morph="none" start_char="4393" end_char="4394">to</TOKEN>
<TOKEN id="token-38-18" pos="word" morph="none" start_char="4396" end_char="4398">the</TOKEN>
<TOKEN id="token-38-19" pos="word" morph="none" start_char="4400" end_char="4407">creation</TOKEN>
<TOKEN id="token-38-20" pos="word" morph="none" start_char="4409" end_char="4410">of</TOKEN>
<TOKEN id="token-38-21" pos="unknown" morph="none" start_char="4412" end_char="4421">SARS-CoV-2</TOKEN>
<TOKEN id="token-38-22" pos="punct" morph="none" start_char="4422" end_char="4422">"</TOKEN>
<TOKEN id="token-38-23" pos="word" morph="none" start_char="4424" end_char="4430">because</TOKEN>
<TOKEN id="token-38-24" pos="word" morph="none" start_char="4432" end_char="4434">the</TOKEN>
<TOKEN id="token-38-25" pos="word" morph="none" start_char="4436" end_char="4442">genetic</TOKEN>
<TOKEN id="token-38-26" pos="word" morph="none" start_char="4444" end_char="4452">sequences</TOKEN>
<TOKEN id="token-38-27" pos="word" morph="none" start_char="4454" end_char="4455">of</TOKEN>
<TOKEN id="token-38-28" pos="word" morph="none" start_char="4457" end_char="4459">the</TOKEN>
<TOKEN id="token-38-29" pos="word" morph="none" start_char="4461" end_char="4465">virus</TOKEN>
<TOKEN id="token-38-30" pos="word" morph="none" start_char="4467" end_char="4473">studied</TOKEN>
<TOKEN id="token-38-31" pos="word" morph="none" start_char="4475" end_char="4476">in</TOKEN>
<TOKEN id="token-38-32" pos="word" morph="none" start_char="4478" end_char="4480">the</TOKEN>
<TOKEN id="token-38-33" pos="word" morph="none" start_char="4482" end_char="4486">paper</TOKEN>
<TOKEN id="token-38-34" pos="word" morph="none" start_char="4488" end_char="4493">differ</TOKEN>
<TOKEN id="token-38-35" pos="word" morph="none" start_char="4495" end_char="4498">from</TOKEN>
<TOKEN id="token-38-36" pos="word" morph="none" start_char="4500" end_char="4503">that</TOKEN>
<TOKEN id="token-38-37" pos="word" morph="none" start_char="4505" end_char="4506">of</TOKEN>
<TOKEN id="token-38-38" pos="word" morph="none" start_char="4508" end_char="4510">the</TOKEN>
<TOKEN id="token-38-39" pos="word" morph="none" start_char="4512" end_char="4514">new</TOKEN>
<TOKEN id="token-38-40" pos="word" morph="none" start_char="4516" end_char="4526">coronavirus</TOKEN>
<TOKEN id="token-38-41" pos="punct" morph="none" start_char="4527" end_char="4527">.</TOKEN>
</SEG>
<SEG id="segment-39" start_char="4530" end_char="4610">
<ORIGINAL_TEXT>Fact-check:Will Biden’s drilling ban on federal leases 'kill' 120,000 Texas jobs?</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="unknown" morph="none" start_char="4530" end_char="4544">Fact-check:Will</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="4546" end_char="4552">Biden’s</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="4554" end_char="4561">drilling</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="4563" end_char="4565">ban</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="4567" end_char="4568">on</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="4570" end_char="4576">federal</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="4578" end_char="4583">leases</TOKEN>
<TOKEN id="token-39-7" pos="punct" morph="none" start_char="4585" end_char="4585">'</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="4586" end_char="4589">kill</TOKEN>
<TOKEN id="token-39-9" pos="punct" morph="none" start_char="4590" end_char="4590">'</TOKEN>
<TOKEN id="token-39-10" pos="unknown" morph="none" start_char="4592" end_char="4598">120,000</TOKEN>
<TOKEN id="token-39-11" pos="word" morph="none" start_char="4600" end_char="4604">Texas</TOKEN>
<TOKEN id="token-39-12" pos="word" morph="none" start_char="4606" end_char="4609">jobs</TOKEN>
<TOKEN id="token-39-13" pos="punct" morph="none" start_char="4610" end_char="4610">?</TOKEN>
</SEG>
<SEG id="segment-40" start_char="4613" end_char="4656">
<ORIGINAL_TEXT>No evidence that the coronavirus was manmade</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="4613" end_char="4614">No</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="4616" end_char="4623">evidence</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="4625" end_char="4628">that</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="4630" end_char="4632">the</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="4634" end_char="4644">coronavirus</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="4646" end_char="4648">was</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="4650" end_char="4656">manmade</TOKEN>
</SEG>
<SEG id="segment-41" start_char="4660" end_char="4806">
<ORIGINAL_TEXT>The Centers for Disease Control and Prevention, the World Health Organization, and the NIH have all said that the virus was not derived from a lab.</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="4660" end_char="4662">The</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="4664" end_char="4670">Centers</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="4672" end_char="4674">for</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="4676" end_char="4682">Disease</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="4684" end_char="4690">Control</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="4692" end_char="4694">and</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="4696" end_char="4705">Prevention</TOKEN>
<TOKEN id="token-41-7" pos="punct" morph="none" start_char="4706" end_char="4706">,</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="4708" end_char="4710">the</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="4712" end_char="4716">World</TOKEN>
<TOKEN id="token-41-10" pos="word" morph="none" start_char="4718" end_char="4723">Health</TOKEN>
<TOKEN id="token-41-11" pos="word" morph="none" start_char="4725" end_char="4736">Organization</TOKEN>
<TOKEN id="token-41-12" pos="punct" morph="none" start_char="4737" end_char="4737">,</TOKEN>
<TOKEN id="token-41-13" pos="word" morph="none" start_char="4739" end_char="4741">and</TOKEN>
<TOKEN id="token-41-14" pos="word" morph="none" start_char="4743" end_char="4745">the</TOKEN>
<TOKEN id="token-41-15" pos="word" morph="none" start_char="4747" end_char="4749">NIH</TOKEN>
<TOKEN id="token-41-16" pos="word" morph="none" start_char="4751" end_char="4754">have</TOKEN>
<TOKEN id="token-41-17" pos="word" morph="none" start_char="4756" end_char="4758">all</TOKEN>
<TOKEN id="token-41-18" pos="word" morph="none" start_char="4760" end_char="4763">said</TOKEN>
<TOKEN id="token-41-19" pos="word" morph="none" start_char="4765" end_char="4768">that</TOKEN>
<TOKEN id="token-41-20" pos="word" morph="none" start_char="4770" end_char="4772">the</TOKEN>
<TOKEN id="token-41-21" pos="word" morph="none" start_char="4774" end_char="4778">virus</TOKEN>
<TOKEN id="token-41-22" pos="word" morph="none" start_char="4780" end_char="4782">was</TOKEN>
<TOKEN id="token-41-23" pos="word" morph="none" start_char="4784" end_char="4786">not</TOKEN>
<TOKEN id="token-41-24" pos="word" morph="none" start_char="4788" end_char="4794">derived</TOKEN>
<TOKEN id="token-41-25" pos="word" morph="none" start_char="4796" end_char="4799">from</TOKEN>
<TOKEN id="token-41-26" pos="word" morph="none" start_char="4801" end_char="4801">a</TOKEN>
<TOKEN id="token-41-27" pos="word" morph="none" start_char="4803" end_char="4805">lab</TOKEN>
<TOKEN id="token-41-28" pos="punct" morph="none" start_char="4806" end_char="4806">.</TOKEN>
</SEG>
<SEG id="segment-42" start_char="4809" end_char="4895">
<ORIGINAL_TEXT>If the virus had been altered in a lab, its genomic data would show signs of tampering.</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="4809" end_char="4810">If</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="4812" end_char="4814">the</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="4816" end_char="4820">virus</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="4822" end_char="4824">had</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="4826" end_char="4829">been</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="4831" end_char="4837">altered</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="4839" end_char="4840">in</TOKEN>
<TOKEN id="token-42-7" pos="word" morph="none" start_char="4842" end_char="4842">a</TOKEN>
<TOKEN id="token-42-8" pos="word" morph="none" start_char="4844" end_char="4846">lab</TOKEN>
<TOKEN id="token-42-9" pos="punct" morph="none" start_char="4847" end_char="4847">,</TOKEN>
<TOKEN id="token-42-10" pos="word" morph="none" start_char="4849" end_char="4851">its</TOKEN>
<TOKEN id="token-42-11" pos="word" morph="none" start_char="4853" end_char="4859">genomic</TOKEN>
<TOKEN id="token-42-12" pos="word" morph="none" start_char="4861" end_char="4864">data</TOKEN>
<TOKEN id="token-42-13" pos="word" morph="none" start_char="4866" end_char="4870">would</TOKEN>
<TOKEN id="token-42-14" pos="word" morph="none" start_char="4872" end_char="4875">show</TOKEN>
<TOKEN id="token-42-15" pos="word" morph="none" start_char="4877" end_char="4881">signs</TOKEN>
<TOKEN id="token-42-16" pos="word" morph="none" start_char="4883" end_char="4884">of</TOKEN>
<TOKEN id="token-42-17" pos="word" morph="none" start_char="4886" end_char="4894">tampering</TOKEN>
<TOKEN id="token-42-18" pos="punct" morph="none" start_char="4895" end_char="4895">.</TOKEN>
</SEG>
<SEG id="segment-43" start_char="4897" end_char="5064">
<ORIGINAL_TEXT>Although scientists from around the world have publicly shared the virus’ genetic makeup thousands of times, there’s still no evidence that the virus was bioengineered.</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="4897" end_char="4904">Although</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="4906" end_char="4915">scientists</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="4917" end_char="4920">from</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="4922" end_char="4927">around</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="4929" end_char="4931">the</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="4933" end_char="4937">world</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="4939" end_char="4942">have</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="4944" end_char="4951">publicly</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="4953" end_char="4958">shared</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="4960" end_char="4962">the</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="4964" end_char="4968">virus</TOKEN>
<TOKEN id="token-43-11" pos="punct" morph="none" start_char="4969" end_char="4969">’</TOKEN>
<TOKEN id="token-43-12" pos="word" morph="none" start_char="4971" end_char="4977">genetic</TOKEN>
<TOKEN id="token-43-13" pos="word" morph="none" start_char="4979" end_char="4984">makeup</TOKEN>
<TOKEN id="token-43-14" pos="word" morph="none" start_char="4986" end_char="4994">thousands</TOKEN>
<TOKEN id="token-43-15" pos="word" morph="none" start_char="4996" end_char="4997">of</TOKEN>
<TOKEN id="token-43-16" pos="word" morph="none" start_char="4999" end_char="5003">times</TOKEN>
<TOKEN id="token-43-17" pos="punct" morph="none" start_char="5004" end_char="5004">,</TOKEN>
<TOKEN id="token-43-18" pos="word" morph="none" start_char="5006" end_char="5012">there’s</TOKEN>
<TOKEN id="token-43-19" pos="word" morph="none" start_char="5014" end_char="5018">still</TOKEN>
<TOKEN id="token-43-20" pos="word" morph="none" start_char="5020" end_char="5021">no</TOKEN>
<TOKEN id="token-43-21" pos="word" morph="none" start_char="5023" end_char="5030">evidence</TOKEN>
<TOKEN id="token-43-22" pos="word" morph="none" start_char="5032" end_char="5035">that</TOKEN>
<TOKEN id="token-43-23" pos="word" morph="none" start_char="5037" end_char="5039">the</TOKEN>
<TOKEN id="token-43-24" pos="word" morph="none" start_char="5041" end_char="5045">virus</TOKEN>
<TOKEN id="token-43-25" pos="word" morph="none" start_char="5047" end_char="5049">was</TOKEN>
<TOKEN id="token-43-26" pos="word" morph="none" start_char="5051" end_char="5063">bioengineered</TOKEN>
<TOKEN id="token-43-27" pos="punct" morph="none" start_char="5064" end_char="5064">.</TOKEN>
</SEG>
<SEG id="segment-44" start_char="5067" end_char="5073">
<ORIGINAL_TEXT>On Feb.</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="5067" end_char="5068">On</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="5070" end_char="5072">Feb</TOKEN>
<TOKEN id="token-44-2" pos="punct" morph="none" start_char="5073" end_char="5073">.</TOKEN>
</SEG>
<SEG id="segment-45" start_char="5075" end_char="5230">
<ORIGINAL_TEXT>19, 2020, public health experts signed a public statement to "strongly condemn conspiracy theories suggesting that COVID-19 does not have a natural origin."</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="5075" end_char="5076">19</TOKEN>
<TOKEN id="token-45-1" pos="punct" morph="none" start_char="5077" end_char="5077">,</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="5079" end_char="5082">2020</TOKEN>
<TOKEN id="token-45-3" pos="punct" morph="none" start_char="5083" end_char="5083">,</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="5085" end_char="5090">public</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="5092" end_char="5097">health</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="5099" end_char="5105">experts</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="5107" end_char="5112">signed</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="5114" end_char="5114">a</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="5116" end_char="5121">public</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="5123" end_char="5131">statement</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="5133" end_char="5134">to</TOKEN>
<TOKEN id="token-45-12" pos="punct" morph="none" start_char="5136" end_char="5136">"</TOKEN>
<TOKEN id="token-45-13" pos="word" morph="none" start_char="5137" end_char="5144">strongly</TOKEN>
<TOKEN id="token-45-14" pos="word" morph="none" start_char="5146" end_char="5152">condemn</TOKEN>
<TOKEN id="token-45-15" pos="word" morph="none" start_char="5154" end_char="5163">conspiracy</TOKEN>
<TOKEN id="token-45-16" pos="word" morph="none" start_char="5165" end_char="5172">theories</TOKEN>
<TOKEN id="token-45-17" pos="word" morph="none" start_char="5174" end_char="5183">suggesting</TOKEN>
<TOKEN id="token-45-18" pos="word" morph="none" start_char="5185" end_char="5188">that</TOKEN>
<TOKEN id="token-45-19" pos="unknown" morph="none" start_char="5190" end_char="5197">COVID-19</TOKEN>
<TOKEN id="token-45-20" pos="word" morph="none" start_char="5199" end_char="5202">does</TOKEN>
<TOKEN id="token-45-21" pos="word" morph="none" start_char="5204" end_char="5206">not</TOKEN>
<TOKEN id="token-45-22" pos="word" morph="none" start_char="5208" end_char="5211">have</TOKEN>
<TOKEN id="token-45-23" pos="word" morph="none" start_char="5213" end_char="5213">a</TOKEN>
<TOKEN id="token-45-24" pos="word" morph="none" start_char="5215" end_char="5221">natural</TOKEN>
<TOKEN id="token-45-25" pos="word" morph="none" start_char="5223" end_char="5228">origin</TOKEN>
<TOKEN id="token-45-26" pos="punct" morph="none" start_char="5229" end_char="5230">."</TOKEN>
</SEG>
<SEG id="segment-46" start_char="5233" end_char="5452">
<ORIGINAL_TEXT>"Scientists from multiple countries have published and analysed genomes" of SARS-CoV-2 "and they overwhelmingly conclude that this coronavirus originated in wildlife," the statement reads, citing nine scientific studies.</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="punct" morph="none" start_char="5233" end_char="5233">"</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="5234" end_char="5243">Scientists</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="5245" end_char="5248">from</TOKEN>
<TOKEN id="token-46-3" pos="word" morph="none" start_char="5250" end_char="5257">multiple</TOKEN>
<TOKEN id="token-46-4" pos="word" morph="none" start_char="5259" end_char="5267">countries</TOKEN>
<TOKEN id="token-46-5" pos="word" morph="none" start_char="5269" end_char="5272">have</TOKEN>
<TOKEN id="token-46-6" pos="word" morph="none" start_char="5274" end_char="5282">published</TOKEN>
<TOKEN id="token-46-7" pos="word" morph="none" start_char="5284" end_char="5286">and</TOKEN>
<TOKEN id="token-46-8" pos="word" morph="none" start_char="5288" end_char="5295">analysed</TOKEN>
<TOKEN id="token-46-9" pos="word" morph="none" start_char="5297" end_char="5303">genomes</TOKEN>
<TOKEN id="token-46-10" pos="punct" morph="none" start_char="5304" end_char="5304">"</TOKEN>
<TOKEN id="token-46-11" pos="word" morph="none" start_char="5306" end_char="5307">of</TOKEN>
<TOKEN id="token-46-12" pos="unknown" morph="none" start_char="5309" end_char="5318">SARS-CoV-2</TOKEN>
<TOKEN id="token-46-13" pos="punct" morph="none" start_char="5320" end_char="5320">"</TOKEN>
<TOKEN id="token-46-14" pos="word" morph="none" start_char="5321" end_char="5323">and</TOKEN>
<TOKEN id="token-46-15" pos="word" morph="none" start_char="5325" end_char="5328">they</TOKEN>
<TOKEN id="token-46-16" pos="word" morph="none" start_char="5330" end_char="5343">overwhelmingly</TOKEN>
<TOKEN id="token-46-17" pos="word" morph="none" start_char="5345" end_char="5352">conclude</TOKEN>
<TOKEN id="token-46-18" pos="word" morph="none" start_char="5354" end_char="5357">that</TOKEN>
<TOKEN id="token-46-19" pos="word" morph="none" start_char="5359" end_char="5362">this</TOKEN>
<TOKEN id="token-46-20" pos="word" morph="none" start_char="5364" end_char="5374">coronavirus</TOKEN>
<TOKEN id="token-46-21" pos="word" morph="none" start_char="5376" end_char="5385">originated</TOKEN>
<TOKEN id="token-46-22" pos="word" morph="none" start_char="5387" end_char="5388">in</TOKEN>
<TOKEN id="token-46-23" pos="word" morph="none" start_char="5390" end_char="5397">wildlife</TOKEN>
<TOKEN id="token-46-24" pos="punct" morph="none" start_char="5398" end_char="5399">,"</TOKEN>
<TOKEN id="token-46-25" pos="word" morph="none" start_char="5401" end_char="5403">the</TOKEN>
<TOKEN id="token-46-26" pos="word" morph="none" start_char="5405" end_char="5413">statement</TOKEN>
<TOKEN id="token-46-27" pos="word" morph="none" start_char="5415" end_char="5419">reads</TOKEN>
<TOKEN id="token-46-28" pos="punct" morph="none" start_char="5420" end_char="5420">,</TOKEN>
<TOKEN id="token-46-29" pos="word" morph="none" start_char="5422" end_char="5427">citing</TOKEN>
<TOKEN id="token-46-30" pos="word" morph="none" start_char="5429" end_char="5432">nine</TOKEN>
<TOKEN id="token-46-31" pos="word" morph="none" start_char="5434" end_char="5443">scientific</TOKEN>
<TOKEN id="token-46-32" pos="word" morph="none" start_char="5445" end_char="5451">studies</TOKEN>
<TOKEN id="token-46-33" pos="punct" morph="none" start_char="5452" end_char="5452">.</TOKEN>
</SEG>
<SEG id="segment-47" start_char="5455" end_char="5606">
<ORIGINAL_TEXT>A detailed computational analysis of the coronavirus conducted by five researchers in March found that its genetic makeup showed no signs of alteration.</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="5455" end_char="5455">A</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="5457" end_char="5464">detailed</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="5466" end_char="5478">computational</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="5480" end_char="5487">analysis</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="5489" end_char="5490">of</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="5492" end_char="5494">the</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="5496" end_char="5506">coronavirus</TOKEN>
<TOKEN id="token-47-7" pos="word" morph="none" start_char="5508" end_char="5516">conducted</TOKEN>
<TOKEN id="token-47-8" pos="word" morph="none" start_char="5518" end_char="5519">by</TOKEN>
<TOKEN id="token-47-9" pos="word" morph="none" start_char="5521" end_char="5524">five</TOKEN>
<TOKEN id="token-47-10" pos="word" morph="none" start_char="5526" end_char="5536">researchers</TOKEN>
<TOKEN id="token-47-11" pos="word" morph="none" start_char="5538" end_char="5539">in</TOKEN>
<TOKEN id="token-47-12" pos="word" morph="none" start_char="5541" end_char="5545">March</TOKEN>
<TOKEN id="token-47-13" pos="word" morph="none" start_char="5547" end_char="5551">found</TOKEN>
<TOKEN id="token-47-14" pos="word" morph="none" start_char="5553" end_char="5556">that</TOKEN>
<TOKEN id="token-47-15" pos="word" morph="none" start_char="5558" end_char="5560">its</TOKEN>
<TOKEN id="token-47-16" pos="word" morph="none" start_char="5562" end_char="5568">genetic</TOKEN>
<TOKEN id="token-47-17" pos="word" morph="none" start_char="5570" end_char="5575">makeup</TOKEN>
<TOKEN id="token-47-18" pos="word" morph="none" start_char="5577" end_char="5582">showed</TOKEN>
<TOKEN id="token-47-19" pos="word" morph="none" start_char="5584" end_char="5585">no</TOKEN>
<TOKEN id="token-47-20" pos="word" morph="none" start_char="5587" end_char="5591">signs</TOKEN>
<TOKEN id="token-47-21" pos="word" morph="none" start_char="5593" end_char="5594">of</TOKEN>
<TOKEN id="token-47-22" pos="word" morph="none" start_char="5596" end_char="5605">alteration</TOKEN>
<TOKEN id="token-47-23" pos="punct" morph="none" start_char="5606" end_char="5606">.</TOKEN>
</SEG>
<SEG id="segment-48" start_char="5608" end_char="5769">
<ORIGINAL_TEXT>The ability of the virus to bind to human cells is most likely the result of natural selection in an animal host or in humans after the virus jumped from animals.</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="5608" end_char="5610">The</TOKEN>
<TOKEN id="token-48-1" pos="word" morph="none" start_char="5612" end_char="5618">ability</TOKEN>
<TOKEN id="token-48-2" pos="word" morph="none" start_char="5620" end_char="5621">of</TOKEN>
<TOKEN id="token-48-3" pos="word" morph="none" start_char="5623" end_char="5625">the</TOKEN>
<TOKEN id="token-48-4" pos="word" morph="none" start_char="5627" end_char="5631">virus</TOKEN>
<TOKEN id="token-48-5" pos="word" morph="none" start_char="5633" end_char="5634">to</TOKEN>
<TOKEN id="token-48-6" pos="word" morph="none" start_char="5636" end_char="5639">bind</TOKEN>
<TOKEN id="token-48-7" pos="word" morph="none" start_char="5641" end_char="5642">to</TOKEN>
<TOKEN id="token-48-8" pos="word" morph="none" start_char="5644" end_char="5648">human</TOKEN>
<TOKEN id="token-48-9" pos="word" morph="none" start_char="5650" end_char="5654">cells</TOKEN>
<TOKEN id="token-48-10" pos="word" morph="none" start_char="5656" end_char="5657">is</TOKEN>
<TOKEN id="token-48-11" pos="word" morph="none" start_char="5659" end_char="5662">most</TOKEN>
<TOKEN id="token-48-12" pos="word" morph="none" start_char="5664" end_char="5669">likely</TOKEN>
<TOKEN id="token-48-13" pos="word" morph="none" start_char="5671" end_char="5673">the</TOKEN>
<TOKEN id="token-48-14" pos="word" morph="none" start_char="5675" end_char="5680">result</TOKEN>
<TOKEN id="token-48-15" pos="word" morph="none" start_char="5682" end_char="5683">of</TOKEN>
<TOKEN id="token-48-16" pos="word" morph="none" start_char="5685" end_char="5691">natural</TOKEN>
<TOKEN id="token-48-17" pos="word" morph="none" start_char="5693" end_char="5701">selection</TOKEN>
<TOKEN id="token-48-18" pos="word" morph="none" start_char="5703" end_char="5704">in</TOKEN>
<TOKEN id="token-48-19" pos="word" morph="none" start_char="5706" end_char="5707">an</TOKEN>
<TOKEN id="token-48-20" pos="word" morph="none" start_char="5709" end_char="5714">animal</TOKEN>
<TOKEN id="token-48-21" pos="word" morph="none" start_char="5716" end_char="5719">host</TOKEN>
<TOKEN id="token-48-22" pos="word" morph="none" start_char="5721" end_char="5722">or</TOKEN>
<TOKEN id="token-48-23" pos="word" morph="none" start_char="5724" end_char="5725">in</TOKEN>
<TOKEN id="token-48-24" pos="word" morph="none" start_char="5727" end_char="5732">humans</TOKEN>
<TOKEN id="token-48-25" pos="word" morph="none" start_char="5734" end_char="5738">after</TOKEN>
<TOKEN id="token-48-26" pos="word" morph="none" start_char="5740" end_char="5742">the</TOKEN>
<TOKEN id="token-48-27" pos="word" morph="none" start_char="5744" end_char="5748">virus</TOKEN>
<TOKEN id="token-48-28" pos="word" morph="none" start_char="5750" end_char="5755">jumped</TOKEN>
<TOKEN id="token-48-29" pos="word" morph="none" start_char="5757" end_char="5760">from</TOKEN>
<TOKEN id="token-48-30" pos="word" morph="none" start_char="5762" end_char="5768">animals</TOKEN>
<TOKEN id="token-48-31" pos="punct" morph="none" start_char="5769" end_char="5769">.</TOKEN>
</SEG>
<SEG id="segment-49" start_char="5772" end_char="5781">
<ORIGINAL_TEXT>Our ruling</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="5772" end_char="5774">Our</TOKEN>
<TOKEN id="token-49-1" pos="word" morph="none" start_char="5776" end_char="5781">ruling</TOKEN>
</SEG>
<SEG id="segment-50" start_char="5785" end_char="5875">
<ORIGINAL_TEXT>WorldNetDaily wrote that "New evidence ties COVID-19 creation to research funded by Fauci."</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="5785" end_char="5797">WorldNetDaily</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="5799" end_char="5803">wrote</TOKEN>
<TOKEN id="token-50-2" pos="word" morph="none" start_char="5805" end_char="5808">that</TOKEN>
<TOKEN id="token-50-3" pos="punct" morph="none" start_char="5810" end_char="5810">"</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="5811" end_char="5813">New</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="5815" end_char="5822">evidence</TOKEN>
<TOKEN id="token-50-6" pos="word" morph="none" start_char="5824" end_char="5827">ties</TOKEN>
<TOKEN id="token-50-7" pos="unknown" morph="none" start_char="5829" end_char="5836">COVID-19</TOKEN>
<TOKEN id="token-50-8" pos="word" morph="none" start_char="5838" end_char="5845">creation</TOKEN>
<TOKEN id="token-50-9" pos="word" morph="none" start_char="5847" end_char="5848">to</TOKEN>
<TOKEN id="token-50-10" pos="word" morph="none" start_char="5850" end_char="5857">research</TOKEN>
<TOKEN id="token-50-11" pos="word" morph="none" start_char="5859" end_char="5864">funded</TOKEN>
<TOKEN id="token-50-12" pos="word" morph="none" start_char="5866" end_char="5867">by</TOKEN>
<TOKEN id="token-50-13" pos="word" morph="none" start_char="5869" end_char="5873">Fauci</TOKEN>
<TOKEN id="token-50-14" pos="punct" morph="none" start_char="5874" end_char="5875">."</TOKEN>
</SEG>
<SEG id="segment-51" start_char="5878" end_char="6129">
<ORIGINAL_TEXT>Both the NIH and EcoHealth Alliance have denied that a grant to the Wuhan lab funded gain-of-function research, though a scientist told us that one paper published with assistance from the grant seems to describe techniques similar to gain-of-function.</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="word" morph="none" start_char="5878" end_char="5881">Both</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="5883" end_char="5885">the</TOKEN>
<TOKEN id="token-51-2" pos="word" morph="none" start_char="5887" end_char="5889">NIH</TOKEN>
<TOKEN id="token-51-3" pos="word" morph="none" start_char="5891" end_char="5893">and</TOKEN>
<TOKEN id="token-51-4" pos="word" morph="none" start_char="5895" end_char="5903">EcoHealth</TOKEN>
<TOKEN id="token-51-5" pos="word" morph="none" start_char="5905" end_char="5912">Alliance</TOKEN>
<TOKEN id="token-51-6" pos="word" morph="none" start_char="5914" end_char="5917">have</TOKEN>
<TOKEN id="token-51-7" pos="word" morph="none" start_char="5919" end_char="5924">denied</TOKEN>
<TOKEN id="token-51-8" pos="word" morph="none" start_char="5926" end_char="5929">that</TOKEN>
<TOKEN id="token-51-9" pos="word" morph="none" start_char="5931" end_char="5931">a</TOKEN>
<TOKEN id="token-51-10" pos="word" morph="none" start_char="5933" end_char="5937">grant</TOKEN>
<TOKEN id="token-51-11" pos="word" morph="none" start_char="5939" end_char="5940">to</TOKEN>
<TOKEN id="token-51-12" pos="word" morph="none" start_char="5942" end_char="5944">the</TOKEN>
<TOKEN id="token-51-13" pos="word" morph="none" start_char="5946" end_char="5950">Wuhan</TOKEN>
<TOKEN id="token-51-14" pos="word" morph="none" start_char="5952" end_char="5954">lab</TOKEN>
<TOKEN id="token-51-15" pos="word" morph="none" start_char="5956" end_char="5961">funded</TOKEN>
<TOKEN id="token-51-16" pos="unknown" morph="none" start_char="5963" end_char="5978">gain-of-function</TOKEN>
<TOKEN id="token-51-17" pos="word" morph="none" start_char="5980" end_char="5987">research</TOKEN>
<TOKEN id="token-51-18" pos="punct" morph="none" start_char="5988" end_char="5988">,</TOKEN>
<TOKEN id="token-51-19" pos="word" morph="none" start_char="5990" end_char="5995">though</TOKEN>
<TOKEN id="token-51-20" pos="word" morph="none" start_char="5997" end_char="5997">a</TOKEN>
<TOKEN id="token-51-21" pos="word" morph="none" start_char="5999" end_char="6007">scientist</TOKEN>
<TOKEN id="token-51-22" pos="word" morph="none" start_char="6009" end_char="6012">told</TOKEN>
<TOKEN id="token-51-23" pos="word" morph="none" start_char="6014" end_char="6015">us</TOKEN>
<TOKEN id="token-51-24" pos="word" morph="none" start_char="6017" end_char="6020">that</TOKEN>
<TOKEN id="token-51-25" pos="word" morph="none" start_char="6022" end_char="6024">one</TOKEN>
<TOKEN id="token-51-26" pos="word" morph="none" start_char="6026" end_char="6030">paper</TOKEN>
<TOKEN id="token-51-27" pos="word" morph="none" start_char="6032" end_char="6040">published</TOKEN>
<TOKEN id="token-51-28" pos="word" morph="none" start_char="6042" end_char="6045">with</TOKEN>
<TOKEN id="token-51-29" pos="word" morph="none" start_char="6047" end_char="6056">assistance</TOKEN>
<TOKEN id="token-51-30" pos="word" morph="none" start_char="6058" end_char="6061">from</TOKEN>
<TOKEN id="token-51-31" pos="word" morph="none" start_char="6063" end_char="6065">the</TOKEN>
<TOKEN id="token-51-32" pos="word" morph="none" start_char="6067" end_char="6071">grant</TOKEN>
<TOKEN id="token-51-33" pos="word" morph="none" start_char="6073" end_char="6077">seems</TOKEN>
<TOKEN id="token-51-34" pos="word" morph="none" start_char="6079" end_char="6080">to</TOKEN>
<TOKEN id="token-51-35" pos="word" morph="none" start_char="6082" end_char="6089">describe</TOKEN>
<TOKEN id="token-51-36" pos="word" morph="none" start_char="6091" end_char="6100">techniques</TOKEN>
<TOKEN id="token-51-37" pos="word" morph="none" start_char="6102" end_char="6108">similar</TOKEN>
<TOKEN id="token-51-38" pos="word" morph="none" start_char="6110" end_char="6111">to</TOKEN>
<TOKEN id="token-51-39" pos="unknown" morph="none" start_char="6113" end_char="6128">gain-of-function</TOKEN>
<TOKEN id="token-51-40" pos="punct" morph="none" start_char="6129" end_char="6129">.</TOKEN>
</SEG>
<SEG id="segment-52" start_char="6132" end_char="6229">
<ORIGINAL_TEXT>The CDC, the WHO, and the NIH have all said that the virus that causes COVID-19 evolved naturally.</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="6132" end_char="6134">The</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="6136" end_char="6138">CDC</TOKEN>
<TOKEN id="token-52-2" pos="punct" morph="none" start_char="6139" end_char="6139">,</TOKEN>
<TOKEN id="token-52-3" pos="word" morph="none" start_char="6141" end_char="6143">the</TOKEN>
<TOKEN id="token-52-4" pos="word" morph="none" start_char="6145" end_char="6147">WHO</TOKEN>
<TOKEN id="token-52-5" pos="punct" morph="none" start_char="6148" end_char="6148">,</TOKEN>
<TOKEN id="token-52-6" pos="word" morph="none" start_char="6150" end_char="6152">and</TOKEN>
<TOKEN id="token-52-7" pos="word" morph="none" start_char="6154" end_char="6156">the</TOKEN>
<TOKEN id="token-52-8" pos="word" morph="none" start_char="6158" end_char="6160">NIH</TOKEN>
<TOKEN id="token-52-9" pos="word" morph="none" start_char="6162" end_char="6165">have</TOKEN>
<TOKEN id="token-52-10" pos="word" morph="none" start_char="6167" end_char="6169">all</TOKEN>
<TOKEN id="token-52-11" pos="word" morph="none" start_char="6171" end_char="6174">said</TOKEN>
<TOKEN id="token-52-12" pos="word" morph="none" start_char="6176" end_char="6179">that</TOKEN>
<TOKEN id="token-52-13" pos="word" morph="none" start_char="6181" end_char="6183">the</TOKEN>
<TOKEN id="token-52-14" pos="word" morph="none" start_char="6185" end_char="6189">virus</TOKEN>
<TOKEN id="token-52-15" pos="word" morph="none" start_char="6191" end_char="6194">that</TOKEN>
<TOKEN id="token-52-16" pos="word" morph="none" start_char="6196" end_char="6201">causes</TOKEN>
<TOKEN id="token-52-17" pos="unknown" morph="none" start_char="6203" end_char="6210">COVID-19</TOKEN>
<TOKEN id="token-52-18" pos="word" morph="none" start_char="6212" end_char="6218">evolved</TOKEN>
<TOKEN id="token-52-19" pos="word" morph="none" start_char="6220" end_char="6228">naturally</TOKEN>
<TOKEN id="token-52-20" pos="punct" morph="none" start_char="6229" end_char="6229">.</TOKEN>
</SEG>
<SEG id="segment-53" start_char="6231" end_char="6308">
<ORIGINAL_TEXT>There is no evidence to support that claim that it was created by researchers.</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="word" morph="none" start_char="6231" end_char="6235">There</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="6237" end_char="6238">is</TOKEN>
<TOKEN id="token-53-2" pos="word" morph="none" start_char="6240" end_char="6241">no</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="6243" end_char="6250">evidence</TOKEN>
<TOKEN id="token-53-4" pos="word" morph="none" start_char="6252" end_char="6253">to</TOKEN>
<TOKEN id="token-53-5" pos="word" morph="none" start_char="6255" end_char="6261">support</TOKEN>
<TOKEN id="token-53-6" pos="word" morph="none" start_char="6263" end_char="6266">that</TOKEN>
<TOKEN id="token-53-7" pos="word" morph="none" start_char="6268" end_char="6272">claim</TOKEN>
<TOKEN id="token-53-8" pos="word" morph="none" start_char="6274" end_char="6277">that</TOKEN>
<TOKEN id="token-53-9" pos="word" morph="none" start_char="6279" end_char="6280">it</TOKEN>
<TOKEN id="token-53-10" pos="word" morph="none" start_char="6282" end_char="6284">was</TOKEN>
<TOKEN id="token-53-11" pos="word" morph="none" start_char="6286" end_char="6292">created</TOKEN>
<TOKEN id="token-53-12" pos="word" morph="none" start_char="6294" end_char="6295">by</TOKEN>
<TOKEN id="token-53-13" pos="word" morph="none" start_char="6297" end_char="6307">researchers</TOKEN>
<TOKEN id="token-53-14" pos="punct" morph="none" start_char="6308" end_char="6308">.</TOKEN>
</SEG>
<SEG id="segment-54" start_char="6311" end_char="6330">
<ORIGINAL_TEXT>This claim is False.</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="word" morph="none" start_char="6311" end_char="6314">This</TOKEN>
<TOKEN id="token-54-1" pos="word" morph="none" start_char="6316" end_char="6320">claim</TOKEN>
<TOKEN id="token-54-2" pos="word" morph="none" start_char="6322" end_char="6323">is</TOKEN>
<TOKEN id="token-54-3" pos="word" morph="none" start_char="6325" end_char="6329">False</TOKEN>
<TOKEN id="token-54-4" pos="punct" morph="none" start_char="6330" end_char="6330">.</TOKEN>
</SEG>
<SEG id="segment-55" start_char="6333" end_char="6339">
<ORIGINAL_TEXT>Sources</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="word" morph="none" start_char="6333" end_char="6339">Sources</TOKEN>
</SEG>
<SEG id="segment-56" start_char="6343" end_char="6426">
<ORIGINAL_TEXT>WorldNetDaily, New evidence ties COVID-19 creation to research funded by Fauci, Feb.</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="6343" end_char="6355">WorldNetDaily</TOKEN>
<TOKEN id="token-56-1" pos="punct" morph="none" start_char="6356" end_char="6356">,</TOKEN>
<TOKEN id="token-56-2" pos="word" morph="none" start_char="6358" end_char="6360">New</TOKEN>
<TOKEN id="token-56-3" pos="word" morph="none" start_char="6362" end_char="6369">evidence</TOKEN>
<TOKEN id="token-56-4" pos="word" morph="none" start_char="6371" end_char="6374">ties</TOKEN>
<TOKEN id="token-56-5" pos="unknown" morph="none" start_char="6376" end_char="6383">COVID-19</TOKEN>
<TOKEN id="token-56-6" pos="word" morph="none" start_char="6385" end_char="6392">creation</TOKEN>
<TOKEN id="token-56-7" pos="word" morph="none" start_char="6394" end_char="6395">to</TOKEN>
<TOKEN id="token-56-8" pos="word" morph="none" start_char="6397" end_char="6404">research</TOKEN>
<TOKEN id="token-56-9" pos="word" morph="none" start_char="6406" end_char="6411">funded</TOKEN>
<TOKEN id="token-56-10" pos="word" morph="none" start_char="6413" end_char="6414">by</TOKEN>
<TOKEN id="token-56-11" pos="word" morph="none" start_char="6416" end_char="6420">Fauci</TOKEN>
<TOKEN id="token-56-12" pos="punct" morph="none" start_char="6421" end_char="6421">,</TOKEN>
<TOKEN id="token-56-13" pos="word" morph="none" start_char="6423" end_char="6425">Feb</TOKEN>
<TOKEN id="token-56-14" pos="punct" morph="none" start_char="6426" end_char="6426">.</TOKEN>
</SEG>
<SEG id="segment-57" start_char="6428" end_char="6434">
<ORIGINAL_TEXT>1, 2021</ORIGINAL_TEXT>
<TOKEN id="token-57-0" pos="word" morph="none" start_char="6428" end_char="6428">1</TOKEN>
<TOKEN id="token-57-1" pos="punct" morph="none" start_char="6429" end_char="6429">,</TOKEN>
<TOKEN id="token-57-2" pos="word" morph="none" start_char="6431" end_char="6434">2021</TOKEN>
</SEG>
<SEG id="segment-58" start_char="6437" end_char="6532">
<ORIGINAL_TEXT>The Next Revolution with Steve Hilton, Coronavirus origins: Special investigation - update, Jan.</ORIGINAL_TEXT>
<TOKEN id="token-58-0" pos="word" morph="none" start_char="6437" end_char="6439">The</TOKEN>
<TOKEN id="token-58-1" pos="word" morph="none" start_char="6441" end_char="6444">Next</TOKEN>
<TOKEN id="token-58-2" pos="word" morph="none" start_char="6446" end_char="6455">Revolution</TOKEN>
<TOKEN id="token-58-3" pos="word" morph="none" start_char="6457" end_char="6460">with</TOKEN>
<TOKEN id="token-58-4" pos="word" morph="none" start_char="6462" end_char="6466">Steve</TOKEN>
<TOKEN id="token-58-5" pos="word" morph="none" start_char="6468" end_char="6473">Hilton</TOKEN>
<TOKEN id="token-58-6" pos="punct" morph="none" start_char="6474" end_char="6474">,</TOKEN>
<TOKEN id="token-58-7" pos="word" morph="none" start_char="6476" end_char="6486">Coronavirus</TOKEN>
<TOKEN id="token-58-8" pos="word" morph="none" start_char="6488" end_char="6494">origins</TOKEN>
<TOKEN id="token-58-9" pos="punct" morph="none" start_char="6495" end_char="6495">:</TOKEN>
<TOKEN id="token-58-10" pos="word" morph="none" start_char="6497" end_char="6503">Special</TOKEN>
<TOKEN id="token-58-11" pos="word" morph="none" start_char="6505" end_char="6517">investigation</TOKEN>
<TOKEN id="token-58-12" pos="punct" morph="none" start_char="6519" end_char="6519">-</TOKEN>
<TOKEN id="token-58-13" pos="word" morph="none" start_char="6521" end_char="6526">update</TOKEN>
<TOKEN id="token-58-14" pos="punct" morph="none" start_char="6527" end_char="6527">,</TOKEN>
<TOKEN id="token-58-15" pos="word" morph="none" start_char="6529" end_char="6531">Jan</TOKEN>
<TOKEN id="token-58-16" pos="punct" morph="none" start_char="6532" end_char="6532">.</TOKEN>
</SEG>
<SEG id="segment-59" start_char="6534" end_char="6541">
<ORIGINAL_TEXT>31, 2021</ORIGINAL_TEXT>
<TOKEN id="token-59-0" pos="word" morph="none" start_char="6534" end_char="6535">31</TOKEN>
<TOKEN id="token-59-1" pos="punct" morph="none" start_char="6536" end_char="6536">,</TOKEN>
<TOKEN id="token-59-2" pos="word" morph="none" start_char="6538" end_char="6541">2021</TOKEN>
</SEG>
<SEG id="segment-60" start_char="6544" end_char="6624">
<ORIGINAL_TEXT>Email interview with Kevin Esvelt, assistant professor of the MIT Media Lab, Feb.</ORIGINAL_TEXT>
<TOKEN id="token-60-0" pos="word" morph="none" start_char="6544" end_char="6548">Email</TOKEN>
<TOKEN id="token-60-1" pos="word" morph="none" start_char="6550" end_char="6558">interview</TOKEN>
<TOKEN id="token-60-2" pos="word" morph="none" start_char="6560" end_char="6563">with</TOKEN>
<TOKEN id="token-60-3" pos="word" morph="none" start_char="6565" end_char="6569">Kevin</TOKEN>
<TOKEN id="token-60-4" pos="word" morph="none" start_char="6571" end_char="6576">Esvelt</TOKEN>
<TOKEN id="token-60-5" pos="punct" morph="none" start_char="6577" end_char="6577">,</TOKEN>
<TOKEN id="token-60-6" pos="word" morph="none" start_char="6579" end_char="6587">assistant</TOKEN>
<TOKEN id="token-60-7" pos="word" morph="none" start_char="6589" end_char="6597">professor</TOKEN>
<TOKEN id="token-60-8" pos="word" morph="none" start_char="6599" end_char="6600">of</TOKEN>
<TOKEN id="token-60-9" pos="word" morph="none" start_char="6602" end_char="6604">the</TOKEN>
<TOKEN id="token-60-10" pos="word" morph="none" start_char="6606" end_char="6608">MIT</TOKEN>
<TOKEN id="token-60-11" pos="word" morph="none" start_char="6610" end_char="6614">Media</TOKEN>
<TOKEN id="token-60-12" pos="word" morph="none" start_char="6616" end_char="6618">Lab</TOKEN>
<TOKEN id="token-60-13" pos="punct" morph="none" start_char="6619" end_char="6619">,</TOKEN>
<TOKEN id="token-60-14" pos="word" morph="none" start_char="6621" end_char="6623">Feb</TOKEN>
<TOKEN id="token-60-15" pos="punct" morph="none" start_char="6624" end_char="6624">.</TOKEN>
</SEG>
<SEG id="segment-61" start_char="6626" end_char="6632">
<ORIGINAL_TEXT>4, 2021</ORIGINAL_TEXT>
<TOKEN id="token-61-0" pos="word" morph="none" start_char="6626" end_char="6626">4</TOKEN>
<TOKEN id="token-61-1" pos="punct" morph="none" start_char="6627" end_char="6627">,</TOKEN>
<TOKEN id="token-61-2" pos="word" morph="none" start_char="6629" end_char="6632">2021</TOKEN>
</SEG>
<SEG id="segment-62" start_char="6635" end_char="6715">
<ORIGINAL_TEXT>Email interview with Marc Lipsitch, professor of epidemiology at the Harvard T.H.</ORIGINAL_TEXT>
<TOKEN id="token-62-0" pos="word" morph="none" start_char="6635" end_char="6639">Email</TOKEN>
<TOKEN id="token-62-1" pos="word" morph="none" start_char="6641" end_char="6649">interview</TOKEN>
<TOKEN id="token-62-2" pos="word" morph="none" start_char="6651" end_char="6654">with</TOKEN>
<TOKEN id="token-62-3" pos="word" morph="none" start_char="6656" end_char="6659">Marc</TOKEN>
<TOKEN id="token-62-4" pos="word" morph="none" start_char="6661" end_char="6668">Lipsitch</TOKEN>
<TOKEN id="token-62-5" pos="punct" morph="none" start_char="6669" end_char="6669">,</TOKEN>
<TOKEN id="token-62-6" pos="word" morph="none" start_char="6671" end_char="6679">professor</TOKEN>
<TOKEN id="token-62-7" pos="word" morph="none" start_char="6681" end_char="6682">of</TOKEN>
<TOKEN id="token-62-8" pos="word" morph="none" start_char="6684" end_char="6695">epidemiology</TOKEN>
<TOKEN id="token-62-9" pos="word" morph="none" start_char="6697" end_char="6698">at</TOKEN>
<TOKEN id="token-62-10" pos="word" morph="none" start_char="6700" end_char="6702">the</TOKEN>
<TOKEN id="token-62-11" pos="word" morph="none" start_char="6704" end_char="6710">Harvard</TOKEN>
<TOKEN id="token-62-12" pos="unknown" morph="none" start_char="6712" end_char="6714">T.H</TOKEN>
<TOKEN id="token-62-13" pos="punct" morph="none" start_char="6715" end_char="6715">.</TOKEN>
</SEG>
<SEG id="segment-63" start_char="6717" end_char="6750">
<ORIGINAL_TEXT>Chan School of Public Health, Feb.</ORIGINAL_TEXT>
<TOKEN id="token-63-0" pos="word" morph="none" start_char="6717" end_char="6720">Chan</TOKEN>
<TOKEN id="token-63-1" pos="word" morph="none" start_char="6722" end_char="6727">School</TOKEN>
<TOKEN id="token-63-2" pos="word" morph="none" start_char="6729" end_char="6730">of</TOKEN>
<TOKEN id="token-63-3" pos="word" morph="none" start_char="6732" end_char="6737">Public</TOKEN>
<TOKEN id="token-63-4" pos="word" morph="none" start_char="6739" end_char="6744">Health</TOKEN>
<TOKEN id="token-63-5" pos="punct" morph="none" start_char="6745" end_char="6745">,</TOKEN>
<TOKEN id="token-63-6" pos="word" morph="none" start_char="6747" end_char="6749">Feb</TOKEN>
<TOKEN id="token-63-7" pos="punct" morph="none" start_char="6750" end_char="6750">.</TOKEN>
</SEG>
<SEG id="segment-64" start_char="6752" end_char="6758">
<ORIGINAL_TEXT>4, 2021</ORIGINAL_TEXT>
<TOKEN id="token-64-0" pos="word" morph="none" start_char="6752" end_char="6752">4</TOKEN>
<TOKEN id="token-64-1" pos="punct" morph="none" start_char="6753" end_char="6753">,</TOKEN>
<TOKEN id="token-64-2" pos="word" morph="none" start_char="6755" end_char="6758">2021</TOKEN>
</SEG>
<SEG id="segment-65" start_char="6761" end_char="6865">
<ORIGINAL_TEXT>PolitiFact, Tucker Carlson guest airs debunked conspiracy theory that COVID-19 was created in a lab, Sep.</ORIGINAL_TEXT>
<TOKEN id="token-65-0" pos="word" morph="none" start_char="6761" end_char="6770">PolitiFact</TOKEN>
<TOKEN id="token-65-1" pos="punct" morph="none" start_char="6771" end_char="6771">,</TOKEN>
<TOKEN id="token-65-2" pos="word" morph="none" start_char="6773" end_char="6778">Tucker</TOKEN>
<TOKEN id="token-65-3" pos="word" morph="none" start_char="6780" end_char="6786">Carlson</TOKEN>
<TOKEN id="token-65-4" pos="word" morph="none" start_char="6788" end_char="6792">guest</TOKEN>
<TOKEN id="token-65-5" pos="word" morph="none" start_char="6794" end_char="6797">airs</TOKEN>
<TOKEN id="token-65-6" pos="word" morph="none" start_char="6799" end_char="6806">debunked</TOKEN>
<TOKEN id="token-65-7" pos="word" morph="none" start_char="6808" end_char="6817">conspiracy</TOKEN>
<TOKEN id="token-65-8" pos="word" morph="none" start_char="6819" end_char="6824">theory</TOKEN>
<TOKEN id="token-65-9" pos="word" morph="none" start_char="6826" end_char="6829">that</TOKEN>
<TOKEN id="token-65-10" pos="unknown" morph="none" start_char="6831" end_char="6838">COVID-19</TOKEN>
<TOKEN id="token-65-11" pos="word" morph="none" start_char="6840" end_char="6842">was</TOKEN>
<TOKEN id="token-65-12" pos="word" morph="none" start_char="6844" end_char="6850">created</TOKEN>
<TOKEN id="token-65-13" pos="word" morph="none" start_char="6852" end_char="6853">in</TOKEN>
<TOKEN id="token-65-14" pos="word" morph="none" start_char="6855" end_char="6855">a</TOKEN>
<TOKEN id="token-65-15" pos="word" morph="none" start_char="6857" end_char="6859">lab</TOKEN>
<TOKEN id="token-65-16" pos="punct" morph="none" start_char="6860" end_char="6860">,</TOKEN>
<TOKEN id="token-65-17" pos="word" morph="none" start_char="6862" end_char="6864">Sep</TOKEN>
<TOKEN id="token-65-18" pos="punct" morph="none" start_char="6865" end_char="6865">.</TOKEN>
</SEG>
<SEG id="segment-66" start_char="6867" end_char="6874">
<ORIGINAL_TEXT>16, 2020</ORIGINAL_TEXT>
<TOKEN id="token-66-0" pos="word" morph="none" start_char="6867" end_char="6868">16</TOKEN>
<TOKEN id="token-66-1" pos="punct" morph="none" start_char="6869" end_char="6869">,</TOKEN>
<TOKEN id="token-66-2" pos="word" morph="none" start_char="6871" end_char="6874">2020</TOKEN>
</SEG>
<SEG id="segment-67" start_char="6877" end_char="6969">
<ORIGINAL_TEXT>PolitiFact, Rudy Giuliani wrong about US policy, grant amount to Wuhan virus lab, May 1, 2020</ORIGINAL_TEXT>
<TOKEN id="token-67-0" pos="word" morph="none" start_char="6877" end_char="6886">PolitiFact</TOKEN>
<TOKEN id="token-67-1" pos="punct" morph="none" start_char="6887" end_char="6887">,</TOKEN>
<TOKEN id="token-67-2" pos="word" morph="none" start_char="6889" end_char="6892">Rudy</TOKEN>
<TOKEN id="token-67-3" pos="word" morph="none" start_char="6894" end_char="6901">Giuliani</TOKEN>
<TOKEN id="token-67-4" pos="word" morph="none" start_char="6903" end_char="6907">wrong</TOKEN>
<TOKEN id="token-67-5" pos="word" morph="none" start_char="6909" end_char="6913">about</TOKEN>
<TOKEN id="token-67-6" pos="word" morph="none" start_char="6915" end_char="6916">US</TOKEN>
<TOKEN id="token-67-7" pos="word" morph="none" start_char="6918" end_char="6923">policy</TOKEN>
<TOKEN id="token-67-8" pos="punct" morph="none" start_char="6924" end_char="6924">,</TOKEN>
<TOKEN id="token-67-9" pos="word" morph="none" start_char="6926" end_char="6930">grant</TOKEN>
<TOKEN id="token-67-10" pos="word" morph="none" start_char="6932" end_char="6937">amount</TOKEN>
<TOKEN id="token-67-11" pos="word" morph="none" start_char="6939" end_char="6940">to</TOKEN>
<TOKEN id="token-67-12" pos="word" morph="none" start_char="6942" end_char="6946">Wuhan</TOKEN>
<TOKEN id="token-67-13" pos="word" morph="none" start_char="6948" end_char="6952">virus</TOKEN>
<TOKEN id="token-67-14" pos="word" morph="none" start_char="6954" end_char="6956">lab</TOKEN>
<TOKEN id="token-67-15" pos="punct" morph="none" start_char="6957" end_char="6957">,</TOKEN>
<TOKEN id="token-67-16" pos="word" morph="none" start_char="6959" end_char="6961">May</TOKEN>
<TOKEN id="token-67-17" pos="word" morph="none" start_char="6963" end_char="6963">1</TOKEN>
<TOKEN id="token-67-18" pos="punct" morph="none" start_char="6964" end_char="6964">,</TOKEN>
<TOKEN id="token-67-19" pos="word" morph="none" start_char="6966" end_char="6969">2020</TOKEN>
</SEG>
<SEG id="segment-68" start_char="6972" end_char="7053">
<ORIGINAL_TEXT>PolitiFact, Health misinformation site promotes conspiracy about coronavirus, Feb.</ORIGINAL_TEXT>
<TOKEN id="token-68-0" pos="word" morph="none" start_char="6972" end_char="6981">PolitiFact</TOKEN>
<TOKEN id="token-68-1" pos="punct" morph="none" start_char="6982" end_char="6982">,</TOKEN>
<TOKEN id="token-68-2" pos="word" morph="none" start_char="6984" end_char="6989">Health</TOKEN>
<TOKEN id="token-68-3" pos="word" morph="none" start_char="6991" end_char="7004">misinformation</TOKEN>
<TOKEN id="token-68-4" pos="word" morph="none" start_char="7006" end_char="7009">site</TOKEN>
<TOKEN id="token-68-5" pos="word" morph="none" start_char="7011" end_char="7018">promotes</TOKEN>
<TOKEN id="token-68-6" pos="word" morph="none" start_char="7020" end_char="7029">conspiracy</TOKEN>
<TOKEN id="token-68-7" pos="word" morph="none" start_char="7031" end_char="7035">about</TOKEN>
<TOKEN id="token-68-8" pos="word" morph="none" start_char="7037" end_char="7047">coronavirus</TOKEN>
<TOKEN id="token-68-9" pos="punct" morph="none" start_char="7048" end_char="7048">,</TOKEN>
<TOKEN id="token-68-10" pos="word" morph="none" start_char="7050" end_char="7052">Feb</TOKEN>
<TOKEN id="token-68-11" pos="punct" morph="none" start_char="7053" end_char="7053">.</TOKEN>
</SEG>
<SEG id="segment-69" start_char="7055" end_char="7062">
<ORIGINAL_TEXT>10, 2020</ORIGINAL_TEXT>
<TOKEN id="token-69-0" pos="word" morph="none" start_char="7055" end_char="7056">10</TOKEN>
<TOKEN id="token-69-1" pos="punct" morph="none" start_char="7057" end_char="7057">,</TOKEN>
<TOKEN id="token-69-2" pos="word" morph="none" start_char="7059" end_char="7062">2020</TOKEN>
</SEG>
<SEG id="segment-70" start_char="7065" end_char="7151">
<ORIGINAL_TEXT>PolitiFact, "What we know about the source of the coronavirus pandemic," April 17, 2020</ORIGINAL_TEXT>
<TOKEN id="token-70-0" pos="word" morph="none" start_char="7065" end_char="7074">PolitiFact</TOKEN>
<TOKEN id="token-70-1" pos="punct" morph="none" start_char="7075" end_char="7075">,</TOKEN>
<TOKEN id="token-70-2" pos="punct" morph="none" start_char="7077" end_char="7077">"</TOKEN>
<TOKEN id="token-70-3" pos="word" morph="none" start_char="7078" end_char="7081">What</TOKEN>
<TOKEN id="token-70-4" pos="word" morph="none" start_char="7083" end_char="7084">we</TOKEN>
<TOKEN id="token-70-5" pos="word" morph="none" start_char="7086" end_char="7089">know</TOKEN>
<TOKEN id="token-70-6" pos="word" morph="none" start_char="7091" end_char="7095">about</TOKEN>
<TOKEN id="token-70-7" pos="word" morph="none" start_char="7097" end_char="7099">the</TOKEN>
<TOKEN id="token-70-8" pos="word" morph="none" start_char="7101" end_char="7106">source</TOKEN>
<TOKEN id="token-70-9" pos="word" morph="none" start_char="7108" end_char="7109">of</TOKEN>
<TOKEN id="token-70-10" pos="word" morph="none" start_char="7111" end_char="7113">the</TOKEN>
<TOKEN id="token-70-11" pos="word" morph="none" start_char="7115" end_char="7125">coronavirus</TOKEN>
<TOKEN id="token-70-12" pos="word" morph="none" start_char="7127" end_char="7134">pandemic</TOKEN>
<TOKEN id="token-70-13" pos="punct" morph="none" start_char="7135" end_char="7136">,"</TOKEN>
<TOKEN id="token-70-14" pos="word" morph="none" start_char="7138" end_char="7142">April</TOKEN>
<TOKEN id="token-70-15" pos="word" morph="none" start_char="7144" end_char="7145">17</TOKEN>
<TOKEN id="token-70-16" pos="punct" morph="none" start_char="7146" end_char="7146">,</TOKEN>
<TOKEN id="token-70-17" pos="word" morph="none" start_char="7148" end_char="7151">2020</TOKEN>
</SEG>
<SEG id="segment-71" start_char="7154" end_char="7254">
<ORIGINAL_TEXT>Reuters, "Coronavirus very likely of animal origin, no sign of lab manipulation: WHO," April 21, 2020</ORIGINAL_TEXT>
<TOKEN id="token-71-0" pos="word" morph="none" start_char="7154" end_char="7160">Reuters</TOKEN>
<TOKEN id="token-71-1" pos="punct" morph="none" start_char="7161" end_char="7161">,</TOKEN>
<TOKEN id="token-71-2" pos="punct" morph="none" start_char="7163" end_char="7163">"</TOKEN>
<TOKEN id="token-71-3" pos="word" morph="none" start_char="7164" end_char="7174">Coronavirus</TOKEN>
<TOKEN id="token-71-4" pos="word" morph="none" start_char="7176" end_char="7179">very</TOKEN>
<TOKEN id="token-71-5" pos="word" morph="none" start_char="7181" end_char="7186">likely</TOKEN>
<TOKEN id="token-71-6" pos="word" morph="none" start_char="7188" end_char="7189">of</TOKEN>
<TOKEN id="token-71-7" pos="word" morph="none" start_char="7191" end_char="7196">animal</TOKEN>
<TOKEN id="token-71-8" pos="word" morph="none" start_char="7198" end_char="7203">origin</TOKEN>
<TOKEN id="token-71-9" pos="punct" morph="none" start_char="7204" end_char="7204">,</TOKEN>
<TOKEN id="token-71-10" pos="word" morph="none" start_char="7206" end_char="7207">no</TOKEN>
<TOKEN id="token-71-11" pos="word" morph="none" start_char="7209" end_char="7212">sign</TOKEN>
<TOKEN id="token-71-12" pos="word" morph="none" start_char="7214" end_char="7215">of</TOKEN>
<TOKEN id="token-71-13" pos="word" morph="none" start_char="7217" end_char="7219">lab</TOKEN>
<TOKEN id="token-71-14" pos="word" morph="none" start_char="7221" end_char="7232">manipulation</TOKEN>
<TOKEN id="token-71-15" pos="punct" morph="none" start_char="7233" end_char="7233">:</TOKEN>
<TOKEN id="token-71-16" pos="word" morph="none" start_char="7235" end_char="7237">WHO</TOKEN>
<TOKEN id="token-71-17" pos="punct" morph="none" start_char="7238" end_char="7239">,"</TOKEN>
<TOKEN id="token-71-18" pos="word" morph="none" start_char="7241" end_char="7245">April</TOKEN>
<TOKEN id="token-71-19" pos="word" morph="none" start_char="7247" end_char="7248">21</TOKEN>
<TOKEN id="token-71-20" pos="punct" morph="none" start_char="7249" end_char="7249">,</TOKEN>
<TOKEN id="token-71-21" pos="word" morph="none" start_char="7251" end_char="7254">2020</TOKEN>
</SEG>
<SEG id="segment-72" start_char="7257" end_char="7347">
<ORIGINAL_TEXT>Science Alert, "Here's How Scientists Know Coronavirus Wasn't Made in a Lab," July 17, 2020</ORIGINAL_TEXT>
<TOKEN id="token-72-0" pos="word" morph="none" start_char="7257" end_char="7263">Science</TOKEN>
<TOKEN id="token-72-1" pos="word" morph="none" start_char="7265" end_char="7269">Alert</TOKEN>
<TOKEN id="token-72-2" pos="punct" morph="none" start_char="7270" end_char="7270">,</TOKEN>
<TOKEN id="token-72-3" pos="punct" morph="none" start_char="7272" end_char="7272">"</TOKEN>
<TOKEN id="token-72-4" pos="word" morph="none" start_char="7273" end_char="7278">Here's</TOKEN>
<TOKEN id="token-72-5" pos="word" morph="none" start_char="7280" end_char="7282">How</TOKEN>
<TOKEN id="token-72-6" pos="word" morph="none" start_char="7284" end_char="7293">Scientists</TOKEN>
<TOKEN id="token-72-7" pos="word" morph="none" start_char="7295" end_char="7298">Know</TOKEN>
<TOKEN id="token-72-8" pos="word" morph="none" start_char="7300" end_char="7310">Coronavirus</TOKEN>
<TOKEN id="token-72-9" pos="word" morph="none" start_char="7312" end_char="7317">Wasn't</TOKEN>
<TOKEN id="token-72-10" pos="word" morph="none" start_char="7319" end_char="7322">Made</TOKEN>
<TOKEN id="token-72-11" pos="word" morph="none" start_char="7324" end_char="7325">in</TOKEN>
<TOKEN id="token-72-12" pos="word" morph="none" start_char="7327" end_char="7327">a</TOKEN>
<TOKEN id="token-72-13" pos="word" morph="none" start_char="7329" end_char="7331">Lab</TOKEN>
<TOKEN id="token-72-14" pos="punct" morph="none" start_char="7332" end_char="7333">,"</TOKEN>
<TOKEN id="token-72-15" pos="word" morph="none" start_char="7335" end_char="7338">July</TOKEN>
<TOKEN id="token-72-16" pos="word" morph="none" start_char="7340" end_char="7341">17</TOKEN>
<TOKEN id="token-72-17" pos="punct" morph="none" start_char="7342" end_char="7342">,</TOKEN>
<TOKEN id="token-72-18" pos="word" morph="none" start_char="7344" end_char="7347">2020</TOKEN>
</SEG>
<SEG id="segment-73" start_char="7350" end_char="7414">
<ORIGINAL_TEXT>Centers for Disease Control and Prevention, About COVID-19, Sept.</ORIGINAL_TEXT>
<TOKEN id="token-73-0" pos="word" morph="none" start_char="7350" end_char="7356">Centers</TOKEN>
<TOKEN id="token-73-1" pos="word" morph="none" start_char="7358" end_char="7360">for</TOKEN>
<TOKEN id="token-73-2" pos="word" morph="none" start_char="7362" end_char="7368">Disease</TOKEN>
<TOKEN id="token-73-3" pos="word" morph="none" start_char="7370" end_char="7376">Control</TOKEN>
<TOKEN id="token-73-4" pos="word" morph="none" start_char="7378" end_char="7380">and</TOKEN>
<TOKEN id="token-73-5" pos="word" morph="none" start_char="7382" end_char="7391">Prevention</TOKEN>
<TOKEN id="token-73-6" pos="punct" morph="none" start_char="7392" end_char="7392">,</TOKEN>
<TOKEN id="token-73-7" pos="word" morph="none" start_char="7394" end_char="7398">About</TOKEN>
<TOKEN id="token-73-8" pos="unknown" morph="none" start_char="7400" end_char="7407">COVID-19</TOKEN>
<TOKEN id="token-73-9" pos="punct" morph="none" start_char="7408" end_char="7408">,</TOKEN>
<TOKEN id="token-73-10" pos="word" morph="none" start_char="7410" end_char="7413">Sept</TOKEN>
<TOKEN id="token-73-11" pos="punct" morph="none" start_char="7414" end_char="7414">.</TOKEN>
</SEG>
<SEG id="segment-74" start_char="7416" end_char="7422">
<ORIGINAL_TEXT>1, 2020</ORIGINAL_TEXT>
<TOKEN id="token-74-0" pos="word" morph="none" start_char="7416" end_char="7416">1</TOKEN>
<TOKEN id="token-74-1" pos="punct" morph="none" start_char="7417" end_char="7417">,</TOKEN>
<TOKEN id="token-74-2" pos="word" morph="none" start_char="7419" end_char="7422">2020</TOKEN>
</SEG>
<SEG id="segment-75" start_char="7425" end_char="7531">
<ORIGINAL_TEXT>National Geographic, "Fauci: No scientific evidence the coronavirus was made in a Chinese lab," May 4, 2020</ORIGINAL_TEXT>
<TOKEN id="token-75-0" pos="word" morph="none" start_char="7425" end_char="7432">National</TOKEN>
<TOKEN id="token-75-1" pos="word" morph="none" start_char="7434" end_char="7443">Geographic</TOKEN>
<TOKEN id="token-75-2" pos="punct" morph="none" start_char="7444" end_char="7444">,</TOKEN>
<TOKEN id="token-75-3" pos="punct" morph="none" start_char="7446" end_char="7446">"</TOKEN>
<TOKEN id="token-75-4" pos="word" morph="none" start_char="7447" end_char="7451">Fauci</TOKEN>
<TOKEN id="token-75-5" pos="punct" morph="none" start_char="7452" end_char="7452">:</TOKEN>
<TOKEN id="token-75-6" pos="word" morph="none" start_char="7454" end_char="7455">No</TOKEN>
<TOKEN id="token-75-7" pos="word" morph="none" start_char="7457" end_char="7466">scientific</TOKEN>
<TOKEN id="token-75-8" pos="word" morph="none" start_char="7468" end_char="7475">evidence</TOKEN>
<TOKEN id="token-75-9" pos="word" morph="none" start_char="7477" end_char="7479">the</TOKEN>
<TOKEN id="token-75-10" pos="word" morph="none" start_char="7481" end_char="7491">coronavirus</TOKEN>
<TOKEN id="token-75-11" pos="word" morph="none" start_char="7493" end_char="7495">was</TOKEN>
<TOKEN id="token-75-12" pos="word" morph="none" start_char="7497" end_char="7500">made</TOKEN>
<TOKEN id="token-75-13" pos="word" morph="none" start_char="7502" end_char="7503">in</TOKEN>
<TOKEN id="token-75-14" pos="word" morph="none" start_char="7505" end_char="7505">a</TOKEN>
<TOKEN id="token-75-15" pos="word" morph="none" start_char="7507" end_char="7513">Chinese</TOKEN>
<TOKEN id="token-75-16" pos="word" morph="none" start_char="7515" end_char="7517">lab</TOKEN>
<TOKEN id="token-75-17" pos="punct" morph="none" start_char="7518" end_char="7519">,"</TOKEN>
<TOKEN id="token-75-18" pos="word" morph="none" start_char="7521" end_char="7523">May</TOKEN>
<TOKEN id="token-75-19" pos="word" morph="none" start_char="7525" end_char="7525">4</TOKEN>
<TOKEN id="token-75-20" pos="punct" morph="none" start_char="7526" end_char="7526">,</TOKEN>
<TOKEN id="token-75-21" pos="word" morph="none" start_char="7528" end_char="7531">2020</TOKEN>
</SEG>
<SEG id="segment-76" start_char="7534" end_char="7623">
<ORIGINAL_TEXT>Vox, Why some labs work on making viruses deadlier — and why they should stop, May 1, 2020</ORIGINAL_TEXT>
<TOKEN id="token-76-0" pos="word" morph="none" start_char="7534" end_char="7536">Vox</TOKEN>
<TOKEN id="token-76-1" pos="punct" morph="none" start_char="7537" end_char="7537">,</TOKEN>
<TOKEN id="token-76-2" pos="word" morph="none" start_char="7539" end_char="7541">Why</TOKEN>
<TOKEN id="token-76-3" pos="word" morph="none" start_char="7543" end_char="7546">some</TOKEN>
<TOKEN id="token-76-4" pos="word" morph="none" start_char="7548" end_char="7551">labs</TOKEN>
<TOKEN id="token-76-5" pos="word" morph="none" start_char="7553" end_char="7556">work</TOKEN>
<TOKEN id="token-76-6" pos="word" morph="none" start_char="7558" end_char="7559">on</TOKEN>
<TOKEN id="token-76-7" pos="word" morph="none" start_char="7561" end_char="7566">making</TOKEN>
<TOKEN id="token-76-8" pos="word" morph="none" start_char="7568" end_char="7574">viruses</TOKEN>
<TOKEN id="token-76-9" pos="word" morph="none" start_char="7576" end_char="7583">deadlier</TOKEN>
<TOKEN id="token-76-10" pos="punct" morph="none" start_char="7585" end_char="7585">—</TOKEN>
<TOKEN id="token-76-11" pos="word" morph="none" start_char="7587" end_char="7589">and</TOKEN>
<TOKEN id="token-76-12" pos="word" morph="none" start_char="7591" end_char="7593">why</TOKEN>
<TOKEN id="token-76-13" pos="word" morph="none" start_char="7595" end_char="7598">they</TOKEN>
<TOKEN id="token-76-14" pos="word" morph="none" start_char="7600" end_char="7605">should</TOKEN>
<TOKEN id="token-76-15" pos="word" morph="none" start_char="7607" end_char="7610">stop</TOKEN>
<TOKEN id="token-76-16" pos="punct" morph="none" start_char="7611" end_char="7611">,</TOKEN>
<TOKEN id="token-76-17" pos="word" morph="none" start_char="7613" end_char="7615">May</TOKEN>
<TOKEN id="token-76-18" pos="word" morph="none" start_char="7617" end_char="7617">1</TOKEN>
<TOKEN id="token-76-19" pos="punct" morph="none" start_char="7618" end_char="7618">,</TOKEN>
<TOKEN id="token-76-20" pos="word" morph="none" start_char="7620" end_char="7623">2020</TOKEN>
</SEG>
<SEG id="segment-77" start_char="7626" end_char="7677">
<ORIGINAL_TEXT>Washington Post, A flu virus risk worth taking, Dec.</ORIGINAL_TEXT>
<TOKEN id="token-77-0" pos="word" morph="none" start_char="7626" end_char="7635">Washington</TOKEN>
<TOKEN id="token-77-1" pos="word" morph="none" start_char="7637" end_char="7640">Post</TOKEN>
<TOKEN id="token-77-2" pos="punct" morph="none" start_char="7641" end_char="7641">,</TOKEN>
<TOKEN id="token-77-3" pos="word" morph="none" start_char="7643" end_char="7643">A</TOKEN>
<TOKEN id="token-77-4" pos="word" morph="none" start_char="7645" end_char="7647">flu</TOKEN>
<TOKEN id="token-77-5" pos="word" morph="none" start_char="7649" end_char="7653">virus</TOKEN>
<TOKEN id="token-77-6" pos="word" morph="none" start_char="7655" end_char="7658">risk</TOKEN>
<TOKEN id="token-77-7" pos="word" morph="none" start_char="7660" end_char="7664">worth</TOKEN>
<TOKEN id="token-77-8" pos="word" morph="none" start_char="7666" end_char="7671">taking</TOKEN>
<TOKEN id="token-77-9" pos="punct" morph="none" start_char="7672" end_char="7672">,</TOKEN>
<TOKEN id="token-77-10" pos="word" morph="none" start_char="7674" end_char="7676">Dec</TOKEN>
<TOKEN id="token-77-11" pos="punct" morph="none" start_char="7677" end_char="7677">.</TOKEN>
</SEG>
<SEG id="segment-78" start_char="7679" end_char="7686">
<ORIGINAL_TEXT>30, 2011</ORIGINAL_TEXT>
<TOKEN id="token-78-0" pos="word" morph="none" start_char="7679" end_char="7680">30</TOKEN>
<TOKEN id="token-78-1" pos="punct" morph="none" start_char="7681" end_char="7681">,</TOKEN>
<TOKEN id="token-78-2" pos="word" morph="none" start_char="7683" end_char="7686">2011</TOKEN>
</SEG>
<SEG id="segment-79" start_char="7689" end_char="7856">
<ORIGINAL_TEXT>U.S. government gain-of-function deliberative process and research funding pause on selected gain-of-function research involving influenza, MERS, and SARS viruses, Oct.</ORIGINAL_TEXT>
<TOKEN id="token-79-0" pos="unknown" morph="none" start_char="7689" end_char="7691">U.S</TOKEN>
<TOKEN id="token-79-1" pos="punct" morph="none" start_char="7692" end_char="7692">.</TOKEN>
<TOKEN id="token-79-2" pos="word" morph="none" start_char="7694" end_char="7703">government</TOKEN>
<TOKEN id="token-79-3" pos="unknown" morph="none" start_char="7705" end_char="7720">gain-of-function</TOKEN>
<TOKEN id="token-79-4" pos="word" morph="none" start_char="7722" end_char="7733">deliberative</TOKEN>
<TOKEN id="token-79-5" pos="word" morph="none" start_char="7735" end_char="7741">process</TOKEN>
<TOKEN id="token-79-6" pos="word" morph="none" start_char="7743" end_char="7745">and</TOKEN>
<TOKEN id="token-79-7" pos="word" morph="none" start_char="7747" end_char="7754">research</TOKEN>
<TOKEN id="token-79-8" pos="word" morph="none" start_char="7756" end_char="7762">funding</TOKEN>
<TOKEN id="token-79-9" pos="word" morph="none" start_char="7764" end_char="7768">pause</TOKEN>
<TOKEN id="token-79-10" pos="word" morph="none" start_char="7770" end_char="7771">on</TOKEN>
<TOKEN id="token-79-11" pos="word" morph="none" start_char="7773" end_char="7780">selected</TOKEN>
<TOKEN id="token-79-12" pos="unknown" morph="none" start_char="7782" end_char="7797">gain-of-function</TOKEN>
<TOKEN id="token-79-13" pos="word" morph="none" start_char="7799" end_char="7806">research</TOKEN>
<TOKEN id="token-79-14" pos="word" morph="none" start_char="7808" end_char="7816">involving</TOKEN>
<TOKEN id="token-79-15" pos="word" morph="none" start_char="7818" end_char="7826">influenza</TOKEN>
<TOKEN id="token-79-16" pos="punct" morph="none" start_char="7827" end_char="7827">,</TOKEN>
<TOKEN id="token-79-17" pos="word" morph="none" start_char="7829" end_char="7832">MERS</TOKEN>
<TOKEN id="token-79-18" pos="punct" morph="none" start_char="7833" end_char="7833">,</TOKEN>
<TOKEN id="token-79-19" pos="word" morph="none" start_char="7835" end_char="7837">and</TOKEN>
<TOKEN id="token-79-20" pos="word" morph="none" start_char="7839" end_char="7842">SARS</TOKEN>
<TOKEN id="token-79-21" pos="word" morph="none" start_char="7844" end_char="7850">viruses</TOKEN>
<TOKEN id="token-79-22" pos="punct" morph="none" start_char="7851" end_char="7851">,</TOKEN>
<TOKEN id="token-79-23" pos="word" morph="none" start_char="7853" end_char="7855">Oct</TOKEN>
<TOKEN id="token-79-24" pos="punct" morph="none" start_char="7856" end_char="7856">.</TOKEN>
</SEG>
<SEG id="segment-80" start_char="7858" end_char="7865">
<ORIGINAL_TEXT>17, 2014</ORIGINAL_TEXT>
<TOKEN id="token-80-0" pos="word" morph="none" start_char="7858" end_char="7859">17</TOKEN>
<TOKEN id="token-80-1" pos="punct" morph="none" start_char="7860" end_char="7860">,</TOKEN>
<TOKEN id="token-80-2" pos="word" morph="none" start_char="7862" end_char="7865">2014</TOKEN>
</SEG>
<SEG id="segment-81" start_char="7868" end_char="8010">
<ORIGINAL_TEXT>Plos Pathogens, Discovery of a rich gene pool of bat SARS-related coronaviruses provides new insights into the origin of SARS coronavirus, Nov.</ORIGINAL_TEXT>
<TOKEN id="token-81-0" pos="word" morph="none" start_char="7868" end_char="7871">Plos</TOKEN>
<TOKEN id="token-81-1" pos="word" morph="none" start_char="7873" end_char="7881">Pathogens</TOKEN>
<TOKEN id="token-81-2" pos="punct" morph="none" start_char="7882" end_char="7882">,</TOKEN>
<TOKEN id="token-81-3" pos="word" morph="none" start_char="7884" end_char="7892">Discovery</TOKEN>
<TOKEN id="token-81-4" pos="word" morph="none" start_char="7894" end_char="7895">of</TOKEN>
<TOKEN id="token-81-5" pos="word" morph="none" start_char="7897" end_char="7897">a</TOKEN>
<TOKEN id="token-81-6" pos="word" morph="none" start_char="7899" end_char="7902">rich</TOKEN>
<TOKEN id="token-81-7" pos="word" morph="none" start_char="7904" end_char="7907">gene</TOKEN>
<TOKEN id="token-81-8" pos="word" morph="none" start_char="7909" end_char="7912">pool</TOKEN>
<TOKEN id="token-81-9" pos="word" morph="none" start_char="7914" end_char="7915">of</TOKEN>
<TOKEN id="token-81-10" pos="word" morph="none" start_char="7917" end_char="7919">bat</TOKEN>
<TOKEN id="token-81-11" pos="unknown" morph="none" start_char="7921" end_char="7932">SARS-related</TOKEN>
<TOKEN id="token-81-12" pos="word" morph="none" start_char="7934" end_char="7946">coronaviruses</TOKEN>
<TOKEN id="token-81-13" pos="word" morph="none" start_char="7948" end_char="7955">provides</TOKEN>
<TOKEN id="token-81-14" pos="word" morph="none" start_char="7957" end_char="7959">new</TOKEN>
<TOKEN id="token-81-15" pos="word" morph="none" start_char="7961" end_char="7968">insights</TOKEN>
<TOKEN id="token-81-16" pos="word" morph="none" start_char="7970" end_char="7973">into</TOKEN>
<TOKEN id="token-81-17" pos="word" morph="none" start_char="7975" end_char="7977">the</TOKEN>
<TOKEN id="token-81-18" pos="word" morph="none" start_char="7979" end_char="7984">origin</TOKEN>
<TOKEN id="token-81-19" pos="word" morph="none" start_char="7986" end_char="7987">of</TOKEN>
<TOKEN id="token-81-20" pos="word" morph="none" start_char="7989" end_char="7992">SARS</TOKEN>
<TOKEN id="token-81-21" pos="word" morph="none" start_char="7994" end_char="8004">coronavirus</TOKEN>
<TOKEN id="token-81-22" pos="punct" morph="none" start_char="8005" end_char="8005">,</TOKEN>
<TOKEN id="token-81-23" pos="word" morph="none" start_char="8007" end_char="8009">Nov</TOKEN>
<TOKEN id="token-81-24" pos="punct" morph="none" start_char="8010" end_char="8010">.</TOKEN>
</SEG>
<SEG id="segment-82" start_char="8012" end_char="8019">
<ORIGINAL_TEXT>30, 2017</ORIGINAL_TEXT>
<TOKEN id="token-82-0" pos="word" morph="none" start_char="8012" end_char="8013">30</TOKEN>
<TOKEN id="token-82-1" pos="punct" morph="none" start_char="8014" end_char="8014">,</TOKEN>
<TOKEN id="token-82-2" pos="word" morph="none" start_char="8016" end_char="8019">2017</TOKEN>
</SEG>
<SEG id="segment-83" start_char="8022" end_char="8091">
<ORIGINAL_TEXT>National Library of Medicine, NCBI SARS-CoV-2 Resources, accessed Feb.</ORIGINAL_TEXT>
<TOKEN id="token-83-0" pos="word" morph="none" start_char="8022" end_char="8029">National</TOKEN>
<TOKEN id="token-83-1" pos="word" morph="none" start_char="8031" end_char="8037">Library</TOKEN>
<TOKEN id="token-83-2" pos="word" morph="none" start_char="8039" end_char="8040">of</TOKEN>
<TOKEN id="token-83-3" pos="word" morph="none" start_char="8042" end_char="8049">Medicine</TOKEN>
<TOKEN id="token-83-4" pos="punct" morph="none" start_char="8050" end_char="8050">,</TOKEN>
<TOKEN id="token-83-5" pos="word" morph="none" start_char="8052" end_char="8055">NCBI</TOKEN>
<TOKEN id="token-83-6" pos="unknown" morph="none" start_char="8057" end_char="8066">SARS-CoV-2</TOKEN>
<TOKEN id="token-83-7" pos="word" morph="none" start_char="8068" end_char="8076">Resources</TOKEN>
<TOKEN id="token-83-8" pos="punct" morph="none" start_char="8077" end_char="8077">,</TOKEN>
<TOKEN id="token-83-9" pos="word" morph="none" start_char="8079" end_char="8086">accessed</TOKEN>
<TOKEN id="token-83-10" pos="word" morph="none" start_char="8088" end_char="8090">Feb</TOKEN>
<TOKEN id="token-83-11" pos="punct" morph="none" start_char="8091" end_char="8091">.</TOKEN>
</SEG>
<SEG id="segment-84" start_char="8093" end_char="8099">
<ORIGINAL_TEXT>4, 2021</ORIGINAL_TEXT>
<TOKEN id="token-84-0" pos="word" morph="none" start_char="8093" end_char="8093">4</TOKEN>
<TOKEN id="token-84-1" pos="punct" morph="none" start_char="8094" end_char="8094">,</TOKEN>
<TOKEN id="token-84-2" pos="word" morph="none" start_char="8096" end_char="8099">2021</TOKEN>
</SEG>
<SEG id="segment-85" start_char="8102" end_char="8242">
<ORIGINAL_TEXT>The Lancet, Statement in support of the scientists, public health professionals, and medical professionals of China combatting COVID-19, Feb.</ORIGINAL_TEXT>
<TOKEN id="token-85-0" pos="word" morph="none" start_char="8102" end_char="8104">The</TOKEN>
<TOKEN id="token-85-1" pos="word" morph="none" start_char="8106" end_char="8111">Lancet</TOKEN>
<TOKEN id="token-85-2" pos="punct" morph="none" start_char="8112" end_char="8112">,</TOKEN>
<TOKEN id="token-85-3" pos="word" morph="none" start_char="8114" end_char="8122">Statement</TOKEN>
<TOKEN id="token-85-4" pos="word" morph="none" start_char="8124" end_char="8125">in</TOKEN>
<TOKEN id="token-85-5" pos="word" morph="none" start_char="8127" end_char="8133">support</TOKEN>
<TOKEN id="token-85-6" pos="word" morph="none" start_char="8135" end_char="8136">of</TOKEN>
<TOKEN id="token-85-7" pos="word" morph="none" start_char="8138" end_char="8140">the</TOKEN>
<TOKEN id="token-85-8" pos="word" morph="none" start_char="8142" end_char="8151">scientists</TOKEN>
<TOKEN id="token-85-9" pos="punct" morph="none" start_char="8152" end_char="8152">,</TOKEN>
<TOKEN id="token-85-10" pos="word" morph="none" start_char="8154" end_char="8159">public</TOKEN>
<TOKEN id="token-85-11" pos="word" morph="none" start_char="8161" end_char="8166">health</TOKEN>
<TOKEN id="token-85-12" pos="word" morph="none" start_char="8168" end_char="8180">professionals</TOKEN>
<TOKEN id="token-85-13" pos="punct" morph="none" start_char="8181" end_char="8181">,</TOKEN>
<TOKEN id="token-85-14" pos="word" morph="none" start_char="8183" end_char="8185">and</TOKEN>
<TOKEN id="token-85-15" pos="word" morph="none" start_char="8187" end_char="8193">medical</TOKEN>
<TOKEN id="token-85-16" pos="word" morph="none" start_char="8195" end_char="8207">professionals</TOKEN>
<TOKEN id="token-85-17" pos="word" morph="none" start_char="8209" end_char="8210">of</TOKEN>
<TOKEN id="token-85-18" pos="word" morph="none" start_char="8212" end_char="8216">China</TOKEN>
<TOKEN id="token-85-19" pos="word" morph="none" start_char="8218" end_char="8227">combatting</TOKEN>
<TOKEN id="token-85-20" pos="unknown" morph="none" start_char="8229" end_char="8236">COVID-19</TOKEN>
<TOKEN id="token-85-21" pos="punct" morph="none" start_char="8237" end_char="8237">,</TOKEN>
<TOKEN id="token-85-22" pos="word" morph="none" start_char="8239" end_char="8241">Feb</TOKEN>
<TOKEN id="token-85-23" pos="punct" morph="none" start_char="8242" end_char="8242">.</TOKEN>
</SEG>
<SEG id="segment-86" start_char="8244" end_char="8251">
<ORIGINAL_TEXT>19, 2020</ORIGINAL_TEXT>
<TOKEN id="token-86-0" pos="word" morph="none" start_char="8244" end_char="8245">19</TOKEN>
<TOKEN id="token-86-1" pos="punct" morph="none" start_char="8246" end_char="8246">,</TOKEN>
<TOKEN id="token-86-2" pos="word" morph="none" start_char="8248" end_char="8251">2020</TOKEN>
</SEG>
<SEG id="segment-87" start_char="8254" end_char="8312">
<ORIGINAL_TEXT>Nature, "The proximal origin of SARS-CoV-2," March 17, 2020</ORIGINAL_TEXT>
<TOKEN id="token-87-0" pos="word" morph="none" start_char="8254" end_char="8259">Nature</TOKEN>
<TOKEN id="token-87-1" pos="punct" morph="none" start_char="8260" end_char="8260">,</TOKEN>
<TOKEN id="token-87-2" pos="punct" morph="none" start_char="8262" end_char="8262">"</TOKEN>
<TOKEN id="token-87-3" pos="word" morph="none" start_char="8263" end_char="8265">The</TOKEN>
<TOKEN id="token-87-4" pos="word" morph="none" start_char="8267" end_char="8274">proximal</TOKEN>
<TOKEN id="token-87-5" pos="word" morph="none" start_char="8276" end_char="8281">origin</TOKEN>
<TOKEN id="token-87-6" pos="word" morph="none" start_char="8283" end_char="8284">of</TOKEN>
<TOKEN id="token-87-7" pos="unknown" morph="none" start_char="8286" end_char="8295">SARS-CoV-2</TOKEN>
<TOKEN id="token-87-8" pos="punct" morph="none" start_char="8296" end_char="8297">,"</TOKEN>
<TOKEN id="token-87-9" pos="word" morph="none" start_char="8299" end_char="8303">March</TOKEN>
<TOKEN id="token-87-10" pos="word" morph="none" start_char="8305" end_char="8306">17</TOKEN>
<TOKEN id="token-87-11" pos="punct" morph="none" start_char="8307" end_char="8307">,</TOKEN>
<TOKEN id="token-87-12" pos="word" morph="none" start_char="8309" end_char="8312">2020</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
