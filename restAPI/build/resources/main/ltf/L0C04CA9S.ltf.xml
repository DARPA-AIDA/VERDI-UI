<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CA9S" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="7079" raw_text_md5="b1623e5e83f3f273480e12ba3ce35bd0">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="60">
<ORIGINAL_TEXT>Chinese State Media Echoes Claims COVID-19 Originated Abroad</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="7">Chinese</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="9" end_char="13">State</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="15" end_char="19">Media</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="21" end_char="26">Echoes</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="28" end_char="33">Claims</TOKEN>
<TOKEN id="token-0-5" pos="unknown" morph="none" start_char="35" end_char="42">COVID-19</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="44" end_char="53">Originated</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="55" end_char="60">Abroad</TOKEN>
</SEG>
<SEG id="segment-1" start_char="64" end_char="267">
<ORIGINAL_TEXT>In recent days Chinese state media has returned to the claim that coronavirus did not emerge in Wuhan, the latest attempt to shape the public narrative and global memory of China’s coronavirus experience.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="64" end_char="65">In</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="67" end_char="72">recent</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="74" end_char="77">days</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="79" end_char="85">Chinese</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="87" end_char="91">state</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="93" end_char="97">media</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="99" end_char="101">has</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="103" end_char="110">returned</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="112" end_char="113">to</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="115" end_char="117">the</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="119" end_char="123">claim</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="125" end_char="128">that</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="130" end_char="140">coronavirus</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="142" end_char="144">did</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="146" end_char="148">not</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="150" end_char="155">emerge</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="157" end_char="158">in</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="160" end_char="164">Wuhan</TOKEN>
<TOKEN id="token-1-18" pos="punct" morph="none" start_char="165" end_char="165">,</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="167" end_char="169">the</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="171" end_char="176">latest</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="178" end_char="184">attempt</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="186" end_char="187">to</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="189" end_char="193">shape</TOKEN>
<TOKEN id="token-1-24" pos="word" morph="none" start_char="195" end_char="197">the</TOKEN>
<TOKEN id="token-1-25" pos="word" morph="none" start_char="199" end_char="204">public</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="206" end_char="214">narrative</TOKEN>
<TOKEN id="token-1-27" pos="word" morph="none" start_char="216" end_char="218">and</TOKEN>
<TOKEN id="token-1-28" pos="word" morph="none" start_char="220" end_char="225">global</TOKEN>
<TOKEN id="token-1-29" pos="word" morph="none" start_char="227" end_char="232">memory</TOKEN>
<TOKEN id="token-1-30" pos="word" morph="none" start_char="234" end_char="235">of</TOKEN>
<TOKEN id="token-1-31" pos="word" morph="none" start_char="237" end_char="243">China’s</TOKEN>
<TOKEN id="token-1-32" pos="word" morph="none" start_char="245" end_char="255">coronavirus</TOKEN>
<TOKEN id="token-1-33" pos="word" morph="none" start_char="257" end_char="266">experience</TOKEN>
<TOKEN id="token-1-34" pos="punct" morph="none" start_char="267" end_char="267">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="269" end_char="469">
<ORIGINAL_TEXT>In English-language posts on Facebook (a platform long blocked in China), Party mouthpiece People’s Daily quoted two top Chinese scientists who both claimed the coronavirus was imported from elsewhere:</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="269" end_char="270">In</TOKEN>
<TOKEN id="token-2-1" pos="unknown" morph="none" start_char="272" end_char="287">English-language</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="289" end_char="293">posts</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="295" end_char="296">on</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="298" end_char="305">Facebook</TOKEN>
<TOKEN id="token-2-5" pos="punct" morph="none" start_char="307" end_char="307">(</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="308" end_char="308">a</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="310" end_char="317">platform</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="319" end_char="322">long</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="324" end_char="330">blocked</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="332" end_char="333">in</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="335" end_char="339">China</TOKEN>
<TOKEN id="token-2-12" pos="punct" morph="none" start_char="340" end_char="341">),</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="343" end_char="347">Party</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="349" end_char="358">mouthpiece</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="360" end_char="367">People’s</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="369" end_char="373">Daily</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="375" end_char="380">quoted</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="382" end_char="384">two</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="386" end_char="388">top</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="390" end_char="396">Chinese</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="398" end_char="407">scientists</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="409" end_char="411">who</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="413" end_char="416">both</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="418" end_char="424">claimed</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="426" end_char="428">the</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="430" end_char="440">coronavirus</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="442" end_char="444">was</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="446" end_char="453">imported</TOKEN>
<TOKEN id="token-2-29" pos="word" morph="none" start_char="455" end_char="458">from</TOKEN>
<TOKEN id="token-2-30" pos="word" morph="none" start_char="460" end_char="468">elsewhere</TOKEN>
<TOKEN id="token-2-31" pos="punct" morph="none" start_char="469" end_char="469">:</TOKEN>
</SEG>
<SEG id="segment-3" start_char="472" end_char="762">
<ORIGINAL_TEXT>#COVID19 did not start in central China’s Wuhan but may come through imported frozen food and packaging: experts All available evidence suggests that the coronavirus, which has infected more than 59 million people in 190 countries, did not start in central China’s Wuhan, experts reiterated.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="tag" morph="none" start_char="472" end_char="479">#COVID19</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="481" end_char="483">did</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="485" end_char="487">not</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="489" end_char="493">start</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="495" end_char="496">in</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="498" end_char="504">central</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="506" end_char="512">China’s</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="514" end_char="518">Wuhan</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="520" end_char="522">but</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="524" end_char="526">may</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="528" end_char="531">come</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="533" end_char="539">through</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="541" end_char="548">imported</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="550" end_char="555">frozen</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="557" end_char="560">food</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="562" end_char="564">and</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="566" end_char="574">packaging</TOKEN>
<TOKEN id="token-3-17" pos="punct" morph="none" start_char="575" end_char="575">:</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="577" end_char="583">experts</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="585" end_char="587">All</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="589" end_char="597">available</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="599" end_char="606">evidence</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="608" end_char="615">suggests</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="617" end_char="620">that</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="622" end_char="624">the</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="626" end_char="636">coronavirus</TOKEN>
<TOKEN id="token-3-26" pos="punct" morph="none" start_char="637" end_char="637">,</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="639" end_char="643">which</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="645" end_char="647">has</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="649" end_char="656">infected</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="658" end_char="661">more</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="663" end_char="666">than</TOKEN>
<TOKEN id="token-3-32" pos="word" morph="none" start_char="668" end_char="669">59</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="671" end_char="677">million</TOKEN>
<TOKEN id="token-3-34" pos="word" morph="none" start_char="679" end_char="684">people</TOKEN>
<TOKEN id="token-3-35" pos="word" morph="none" start_char="686" end_char="687">in</TOKEN>
<TOKEN id="token-3-36" pos="word" morph="none" start_char="689" end_char="691">190</TOKEN>
<TOKEN id="token-3-37" pos="word" morph="none" start_char="693" end_char="701">countries</TOKEN>
<TOKEN id="token-3-38" pos="punct" morph="none" start_char="702" end_char="702">,</TOKEN>
<TOKEN id="token-3-39" pos="word" morph="none" start_char="704" end_char="706">did</TOKEN>
<TOKEN id="token-3-40" pos="word" morph="none" start_char="708" end_char="710">not</TOKEN>
<TOKEN id="token-3-41" pos="word" morph="none" start_char="712" end_char="716">start</TOKEN>
<TOKEN id="token-3-42" pos="word" morph="none" start_char="718" end_char="719">in</TOKEN>
<TOKEN id="token-3-43" pos="word" morph="none" start_char="721" end_char="727">central</TOKEN>
<TOKEN id="token-3-44" pos="word" morph="none" start_char="729" end_char="735">China’s</TOKEN>
<TOKEN id="token-3-45" pos="word" morph="none" start_char="737" end_char="741">Wuhan</TOKEN>
<TOKEN id="token-3-46" pos="punct" morph="none" start_char="742" end_char="742">,</TOKEN>
<TOKEN id="token-3-47" pos="word" morph="none" start_char="744" end_char="750">experts</TOKEN>
<TOKEN id="token-3-48" pos="word" morph="none" start_char="752" end_char="761">reiterated</TOKEN>
<TOKEN id="token-3-49" pos="punct" morph="none" start_char="762" end_char="762">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="764" end_char="1001">
<ORIGINAL_TEXT>"Wuhan was where the coronavirus was first detected but it was not where it originated," Zeng Guang, former chief epidemiologist of the Chinese Centre for Disease Control and Prevention (CDC), told an online academic conference on Nov 19.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="punct" morph="none" start_char="764" end_char="764">"</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="765" end_char="769">Wuhan</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="771" end_char="773">was</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="775" end_char="779">where</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="781" end_char="783">the</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="785" end_char="795">coronavirus</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="797" end_char="799">was</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="801" end_char="805">first</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="807" end_char="814">detected</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="816" end_char="818">but</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="820" end_char="821">it</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="823" end_char="825">was</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="827" end_char="829">not</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="831" end_char="835">where</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="837" end_char="838">it</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="840" end_char="849">originated</TOKEN>
<TOKEN id="token-4-16" pos="punct" morph="none" start_char="850" end_char="851">,"</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="853" end_char="856">Zeng</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="858" end_char="862">Guang</TOKEN>
<TOKEN id="token-4-19" pos="punct" morph="none" start_char="863" end_char="863">,</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="865" end_char="870">former</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="872" end_char="876">chief</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="878" end_char="891">epidemiologist</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="893" end_char="894">of</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="896" end_char="898">the</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="900" end_char="906">Chinese</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="908" end_char="913">Centre</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="915" end_char="917">for</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="919" end_char="925">Disease</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="927" end_char="933">Control</TOKEN>
<TOKEN id="token-4-30" pos="word" morph="none" start_char="935" end_char="937">and</TOKEN>
<TOKEN id="token-4-31" pos="word" morph="none" start_char="939" end_char="948">Prevention</TOKEN>
<TOKEN id="token-4-32" pos="punct" morph="none" start_char="950" end_char="950">(</TOKEN>
<TOKEN id="token-4-33" pos="word" morph="none" start_char="951" end_char="953">CDC</TOKEN>
<TOKEN id="token-4-34" pos="punct" morph="none" start_char="954" end_char="955">),</TOKEN>
<TOKEN id="token-4-35" pos="word" morph="none" start_char="957" end_char="960">told</TOKEN>
<TOKEN id="token-4-36" pos="word" morph="none" start_char="962" end_char="963">an</TOKEN>
<TOKEN id="token-4-37" pos="word" morph="none" start_char="965" end_char="970">online</TOKEN>
<TOKEN id="token-4-38" pos="word" morph="none" start_char="972" end_char="979">academic</TOKEN>
<TOKEN id="token-4-39" pos="word" morph="none" start_char="981" end_char="990">conference</TOKEN>
<TOKEN id="token-4-40" pos="word" morph="none" start_char="992" end_char="993">on</TOKEN>
<TOKEN id="token-4-41" pos="word" morph="none" start_char="995" end_char="997">Nov</TOKEN>
<TOKEN id="token-4-42" pos="word" morph="none" start_char="999" end_char="1000">19</TOKEN>
<TOKEN id="token-4-43" pos="punct" morph="none" start_char="1001" end_char="1001">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="1003" end_char="1247">
<ORIGINAL_TEXT>Wu Zunyou, the CDC’s present chief epidemiologist, also gave a similar judgment recently, saying the pathogen could have come into China through imported frozen seafood or meat products and their packaging, reported the South China Morning Post.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="1003" end_char="1004">Wu</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="1006" end_char="1011">Zunyou</TOKEN>
<TOKEN id="token-5-2" pos="punct" morph="none" start_char="1012" end_char="1012">,</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="1014" end_char="1016">the</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="1018" end_char="1022">CDC’s</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="1024" end_char="1030">present</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="1032" end_char="1036">chief</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="1038" end_char="1051">epidemiologist</TOKEN>
<TOKEN id="token-5-8" pos="punct" morph="none" start_char="1052" end_char="1052">,</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="1054" end_char="1057">also</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="1059" end_char="1062">gave</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="1064" end_char="1064">a</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="1066" end_char="1072">similar</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="1074" end_char="1081">judgment</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="1083" end_char="1090">recently</TOKEN>
<TOKEN id="token-5-15" pos="punct" morph="none" start_char="1091" end_char="1091">,</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="1093" end_char="1098">saying</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="1100" end_char="1102">the</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="1104" end_char="1111">pathogen</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="1113" end_char="1117">could</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="1119" end_char="1122">have</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="1124" end_char="1127">come</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="1129" end_char="1132">into</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="1134" end_char="1138">China</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="1140" end_char="1146">through</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="1148" end_char="1155">imported</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="1157" end_char="1162">frozen</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="1164" end_char="1170">seafood</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="1172" end_char="1173">or</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="1175" end_char="1178">meat</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="1180" end_char="1187">products</TOKEN>
<TOKEN id="token-5-31" pos="word" morph="none" start_char="1189" end_char="1191">and</TOKEN>
<TOKEN id="token-5-32" pos="word" morph="none" start_char="1193" end_char="1197">their</TOKEN>
<TOKEN id="token-5-33" pos="word" morph="none" start_char="1199" end_char="1207">packaging</TOKEN>
<TOKEN id="token-5-34" pos="punct" morph="none" start_char="1208" end_char="1208">,</TOKEN>
<TOKEN id="token-5-35" pos="word" morph="none" start_char="1210" end_char="1217">reported</TOKEN>
<TOKEN id="token-5-36" pos="word" morph="none" start_char="1219" end_char="1221">the</TOKEN>
<TOKEN id="token-5-37" pos="word" morph="none" start_char="1223" end_char="1227">South</TOKEN>
<TOKEN id="token-5-38" pos="word" morph="none" start_char="1229" end_char="1233">China</TOKEN>
<TOKEN id="token-5-39" pos="word" morph="none" start_char="1235" end_char="1241">Morning</TOKEN>
<TOKEN id="token-5-40" pos="word" morph="none" start_char="1243" end_char="1246">Post</TOKEN>
<TOKEN id="token-5-41" pos="punct" morph="none" start_char="1247" end_char="1247">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="1249" end_char="1256">
<ORIGINAL_TEXT>[Source]</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="punct" morph="none" start_char="1249" end_char="1249">[</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="1250" end_char="1255">Source</TOKEN>
<TOKEN id="token-6-2" pos="punct" morph="none" start_char="1256" end_char="1256">]</TOKEN>
</SEG>
<SEG id="segment-7" start_char="1261" end_char="1540">
<ORIGINAL_TEXT>All available evidence suggests that #COVID19 did not start in central China’s Wuhan, but may come into China through imported frozen food products and their packaging: experts https://t.co/PPakQ6vJzW pic.twitter.com/540HQNrrr1 — People's Daily, China (@PDChina) November 25, 2020</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="1261" end_char="1263">All</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="1265" end_char="1273">available</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="1275" end_char="1282">evidence</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="1284" end_char="1291">suggests</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="1293" end_char="1296">that</TOKEN>
<TOKEN id="token-7-5" pos="tag" morph="none" start_char="1298" end_char="1305">#COVID19</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="1307" end_char="1309">did</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="1311" end_char="1313">not</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="1315" end_char="1319">start</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="1321" end_char="1322">in</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="1324" end_char="1330">central</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="1332" end_char="1338">China’s</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="1340" end_char="1344">Wuhan</TOKEN>
<TOKEN id="token-7-13" pos="punct" morph="none" start_char="1345" end_char="1345">,</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="1347" end_char="1349">but</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="1351" end_char="1353">may</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="1355" end_char="1358">come</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="1360" end_char="1363">into</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="1365" end_char="1369">China</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="1371" end_char="1377">through</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="1379" end_char="1386">imported</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="1388" end_char="1393">frozen</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="1395" end_char="1398">food</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="1400" end_char="1407">products</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="1409" end_char="1411">and</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="1413" end_char="1417">their</TOKEN>
<TOKEN id="token-7-26" pos="word" morph="none" start_char="1419" end_char="1427">packaging</TOKEN>
<TOKEN id="token-7-27" pos="punct" morph="none" start_char="1428" end_char="1428">:</TOKEN>
<TOKEN id="token-7-28" pos="word" morph="none" start_char="1430" end_char="1436">experts</TOKEN>
<TOKEN id="token-7-29" pos="url" morph="none" start_char="1438" end_char="1460">https://t.co/PPakQ6vJzW</TOKEN>
<TOKEN id="token-7-30" pos="unknown" morph="none" start_char="1462" end_char="1487">pic.twitter.com/540HQNrrr1</TOKEN>
<TOKEN id="token-7-31" pos="punct" morph="none" start_char="1489" end_char="1489">—</TOKEN>
<TOKEN id="token-7-32" pos="word" morph="none" start_char="1491" end_char="1498">People's</TOKEN>
<TOKEN id="token-7-33" pos="word" morph="none" start_char="1500" end_char="1504">Daily</TOKEN>
<TOKEN id="token-7-34" pos="punct" morph="none" start_char="1505" end_char="1505">,</TOKEN>
<TOKEN id="token-7-35" pos="word" morph="none" start_char="1507" end_char="1511">China</TOKEN>
<TOKEN id="token-7-36" pos="punct" morph="none" start_char="1513" end_char="1514">(@</TOKEN>
<TOKEN id="token-7-37" pos="word" morph="none" start_char="1515" end_char="1521">PDChina</TOKEN>
<TOKEN id="token-7-38" pos="punct" morph="none" start_char="1522" end_char="1522">)</TOKEN>
<TOKEN id="token-7-39" pos="word" morph="none" start_char="1524" end_char="1531">November</TOKEN>
<TOKEN id="token-7-40" pos="word" morph="none" start_char="1533" end_char="1534">25</TOKEN>
<TOKEN id="token-7-41" pos="punct" morph="none" start_char="1535" end_char="1535">,</TOKEN>
<TOKEN id="token-7-42" pos="word" morph="none" start_char="1537" end_char="1540">2020</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1545" end_char="1625">
<ORIGINAL_TEXT>— Michael "In A Move Likely To Anger China" Mazza (@mike_mazza) November 25, 2020</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="punct" morph="none" start_char="1545" end_char="1545">—</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1547" end_char="1553">Michael</TOKEN>
<TOKEN id="token-8-2" pos="punct" morph="none" start_char="1555" end_char="1555">"</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1556" end_char="1557">In</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1559" end_char="1559">A</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1561" end_char="1564">Move</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1566" end_char="1571">Likely</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1573" end_char="1574">To</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1576" end_char="1580">Anger</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1582" end_char="1586">China</TOKEN>
<TOKEN id="token-8-10" pos="punct" morph="none" start_char="1587" end_char="1587">"</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1589" end_char="1593">Mazza</TOKEN>
<TOKEN id="token-8-12" pos="punct" morph="none" start_char="1595" end_char="1596">(@</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1597" end_char="1606">mike_mazza</TOKEN>
<TOKEN id="token-8-14" pos="punct" morph="none" start_char="1607" end_char="1607">)</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1609" end_char="1616">November</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1618" end_char="1619">25</TOKEN>
<TOKEN id="token-8-17" pos="punct" morph="none" start_char="1620" end_char="1620">,</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1622" end_char="1625">2020</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1630" end_char="1761">
<ORIGINAL_TEXT>They’ve been preparing the way for several weeks already with state media reports of coronavirus found on imported food / packaging.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1630" end_char="1636">They’ve</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1638" end_char="1641">been</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1643" end_char="1651">preparing</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1653" end_char="1655">the</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1657" end_char="1659">way</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1661" end_char="1663">for</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1665" end_char="1671">several</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1673" end_char="1677">weeks</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1679" end_char="1685">already</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1687" end_char="1690">with</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1692" end_char="1696">state</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1698" end_char="1702">media</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1704" end_char="1710">reports</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1712" end_char="1713">of</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1715" end_char="1725">coronavirus</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1727" end_char="1731">found</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1733" end_char="1734">on</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1736" end_char="1743">imported</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1745" end_char="1748">food</TOKEN>
<TOKEN id="token-9-19" pos="punct" morph="none" start_char="1750" end_char="1750">/</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1752" end_char="1760">packaging</TOKEN>
<TOKEN id="token-9-21" pos="punct" morph="none" start_char="1761" end_char="1761">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1763" end_char="1833">
<ORIGINAL_TEXT>https://t.co/3Splcix1Lf — Jeremy Goldkorn (@goldkorn) November 25, 2020</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="url" morph="none" start_char="1763" end_char="1785">https://t.co/3Splcix1Lf</TOKEN>
<TOKEN id="token-10-1" pos="punct" morph="none" start_char="1787" end_char="1787">—</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1789" end_char="1794">Jeremy</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1796" end_char="1803">Goldkorn</TOKEN>
<TOKEN id="token-10-4" pos="punct" morph="none" start_char="1805" end_char="1806">(@</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1807" end_char="1814">goldkorn</TOKEN>
<TOKEN id="token-10-6" pos="punct" morph="none" start_char="1815" end_char="1815">)</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1817" end_char="1824">November</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1826" end_char="1827">25</TOKEN>
<TOKEN id="token-10-9" pos="punct" morph="none" start_char="1828" end_char="1828">,</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1830" end_char="1833">2020</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1838" end_char="1961">
<ORIGINAL_TEXT>State media has yet to explain how, if Covid started in another place, the first exponential-growth outbreak began in Wuhan.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1838" end_char="1842">State</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1844" end_char="1848">media</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1850" end_char="1852">has</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1854" end_char="1856">yet</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1858" end_char="1859">to</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1861" end_char="1867">explain</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1869" end_char="1871">how</TOKEN>
<TOKEN id="token-11-7" pos="punct" morph="none" start_char="1872" end_char="1872">,</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1874" end_char="1875">if</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1877" end_char="1881">Covid</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1883" end_char="1889">started</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1891" end_char="1892">in</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1894" end_char="1900">another</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1902" end_char="1906">place</TOKEN>
<TOKEN id="token-11-14" pos="punct" morph="none" start_char="1907" end_char="1907">,</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1909" end_char="1911">the</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1913" end_char="1917">first</TOKEN>
<TOKEN id="token-11-17" pos="unknown" morph="none" start_char="1919" end_char="1936">exponential-growth</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1938" end_char="1945">outbreak</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="1947" end_char="1951">began</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1953" end_char="1954">in</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="1956" end_char="1960">Wuhan</TOKEN>
<TOKEN id="token-11-22" pos="punct" morph="none" start_char="1961" end_char="1961">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1963" end_char="2026">
<ORIGINAL_TEXT>Why weren’t there big outbreaks in other countries before Wuhan?</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1963" end_char="1965">Why</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1967" end_char="1973">weren’t</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1975" end_char="1979">there</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1981" end_char="1983">big</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1985" end_char="1993">outbreaks</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1995" end_char="1996">in</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1998" end_char="2002">other</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="2004" end_char="2012">countries</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="2014" end_char="2019">before</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="2021" end_char="2025">Wuhan</TOKEN>
<TOKEN id="token-12-10" pos="punct" morph="none" start_char="2026" end_char="2026">?</TOKEN>
</SEG>
<SEG id="segment-13" start_char="2028" end_char="2190">
<ORIGINAL_TEXT>Depressingly, this cold-chain theory is widely believed here in China, which is the point https://t.co/WKT3B1FnuP — David Rennie 任大伟 (@DSORennie) November 25, 2020</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="2028" end_char="2039">Depressingly</TOKEN>
<TOKEN id="token-13-1" pos="punct" morph="none" start_char="2040" end_char="2040">,</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="2042" end_char="2045">this</TOKEN>
<TOKEN id="token-13-3" pos="unknown" morph="none" start_char="2047" end_char="2056">cold-chain</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="2058" end_char="2063">theory</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="2065" end_char="2066">is</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="2068" end_char="2073">widely</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="2075" end_char="2082">believed</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="2084" end_char="2087">here</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="2089" end_char="2090">in</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="2092" end_char="2096">China</TOKEN>
<TOKEN id="token-13-11" pos="punct" morph="none" start_char="2097" end_char="2097">,</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="2099" end_char="2103">which</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="2105" end_char="2106">is</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="2108" end_char="2110">the</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="2112" end_char="2116">point</TOKEN>
<TOKEN id="token-13-16" pos="url" morph="none" start_char="2118" end_char="2140">https://t.co/WKT3B1FnuP</TOKEN>
<TOKEN id="token-13-17" pos="punct" morph="none" start_char="2142" end_char="2142">—</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="2144" end_char="2148">David</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="2150" end_char="2155">Rennie</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="2157" end_char="2159">任大伟</TOKEN>
<TOKEN id="token-13-21" pos="punct" morph="none" start_char="2161" end_char="2162">(@</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="2163" end_char="2171">DSORennie</TOKEN>
<TOKEN id="token-13-23" pos="punct" morph="none" start_char="2172" end_char="2172">)</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="2174" end_char="2181">November</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="2183" end_char="2184">25</TOKEN>
<TOKEN id="token-13-26" pos="punct" morph="none" start_char="2185" end_char="2185">,</TOKEN>
<TOKEN id="token-13-27" pos="word" morph="none" start_char="2187" end_char="2190">2020</TOKEN>
</SEG>
<SEG id="segment-14" start_char="2194" end_char="2421">
<ORIGINAL_TEXT>While making the claim that would be echoed by state media, Beijing’s former top epidemiologist Zeng Guang cited a recent Italian study that claimed coronavirus was spreading asymptomatically in Italy as early as September 2019.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="2194" end_char="2198">While</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="2200" end_char="2205">making</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="2207" end_char="2209">the</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="2211" end_char="2215">claim</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="2217" end_char="2220">that</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="2222" end_char="2226">would</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="2228" end_char="2229">be</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="2231" end_char="2236">echoed</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="2238" end_char="2239">by</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="2241" end_char="2245">state</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="2247" end_char="2251">media</TOKEN>
<TOKEN id="token-14-11" pos="punct" morph="none" start_char="2252" end_char="2252">,</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="2254" end_char="2262">Beijing’s</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="2264" end_char="2269">former</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="2271" end_char="2273">top</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="2275" end_char="2288">epidemiologist</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="2290" end_char="2293">Zeng</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="2295" end_char="2299">Guang</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="2301" end_char="2305">cited</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="2307" end_char="2307">a</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="2309" end_char="2314">recent</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="2316" end_char="2322">Italian</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="2324" end_char="2328">study</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="2330" end_char="2333">that</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="2335" end_char="2341">claimed</TOKEN>
<TOKEN id="token-14-25" pos="word" morph="none" start_char="2343" end_char="2353">coronavirus</TOKEN>
<TOKEN id="token-14-26" pos="word" morph="none" start_char="2355" end_char="2357">was</TOKEN>
<TOKEN id="token-14-27" pos="word" morph="none" start_char="2359" end_char="2367">spreading</TOKEN>
<TOKEN id="token-14-28" pos="word" morph="none" start_char="2369" end_char="2384">asymptomatically</TOKEN>
<TOKEN id="token-14-29" pos="word" morph="none" start_char="2386" end_char="2387">in</TOKEN>
<TOKEN id="token-14-30" pos="word" morph="none" start_char="2389" end_char="2393">Italy</TOKEN>
<TOKEN id="token-14-31" pos="word" morph="none" start_char="2395" end_char="2396">as</TOKEN>
<TOKEN id="token-14-32" pos="word" morph="none" start_char="2398" end_char="2402">early</TOKEN>
<TOKEN id="token-14-33" pos="word" morph="none" start_char="2404" end_char="2405">as</TOKEN>
<TOKEN id="token-14-34" pos="word" morph="none" start_char="2407" end_char="2415">September</TOKEN>
<TOKEN id="token-14-35" pos="word" morph="none" start_char="2417" end_char="2420">2019</TOKEN>
<TOKEN id="token-14-36" pos="punct" morph="none" start_char="2421" end_char="2421">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="2423" end_char="2593">
<ORIGINAL_TEXT>But the researchers behind the study contend that it "simply [documented] that the epidemic in China was not detected in time," not that Italy was the origin of the virus.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="2423" end_char="2425">But</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="2427" end_char="2429">the</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="2431" end_char="2441">researchers</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="2443" end_char="2448">behind</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="2450" end_char="2452">the</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="2454" end_char="2458">study</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="2460" end_char="2466">contend</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="2468" end_char="2471">that</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="2473" end_char="2474">it</TOKEN>
<TOKEN id="token-15-9" pos="punct" morph="none" start_char="2476" end_char="2476">"</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="2477" end_char="2482">simply</TOKEN>
<TOKEN id="token-15-11" pos="punct" morph="none" start_char="2484" end_char="2484">[</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="2485" end_char="2494">documented</TOKEN>
<TOKEN id="token-15-13" pos="punct" morph="none" start_char="2495" end_char="2495">]</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="2497" end_char="2500">that</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="2502" end_char="2504">the</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="2506" end_char="2513">epidemic</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="2515" end_char="2516">in</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="2518" end_char="2522">China</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="2524" end_char="2526">was</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="2528" end_char="2530">not</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="2532" end_char="2539">detected</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="2541" end_char="2542">in</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="2544" end_char="2547">time</TOKEN>
<TOKEN id="token-15-24" pos="punct" morph="none" start_char="2548" end_char="2549">,"</TOKEN>
<TOKEN id="token-15-25" pos="word" morph="none" start_char="2551" end_char="2553">not</TOKEN>
<TOKEN id="token-15-26" pos="word" morph="none" start_char="2555" end_char="2558">that</TOKEN>
<TOKEN id="token-15-27" pos="word" morph="none" start_char="2560" end_char="2564">Italy</TOKEN>
<TOKEN id="token-15-28" pos="word" morph="none" start_char="2566" end_char="2568">was</TOKEN>
<TOKEN id="token-15-29" pos="word" morph="none" start_char="2570" end_char="2572">the</TOKEN>
<TOKEN id="token-15-30" pos="word" morph="none" start_char="2574" end_char="2579">origin</TOKEN>
<TOKEN id="token-15-31" pos="word" morph="none" start_char="2581" end_char="2582">of</TOKEN>
<TOKEN id="token-15-32" pos="word" morph="none" start_char="2584" end_char="2586">the</TOKEN>
<TOKEN id="token-15-33" pos="word" morph="none" start_char="2588" end_char="2592">virus</TOKEN>
<TOKEN id="token-15-34" pos="punct" morph="none" start_char="2593" end_char="2593">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="2595" end_char="2794">
<ORIGINAL_TEXT>Current top epidemiologist Wu Zunyou claimed earlier in the month that "[g]rowing evidence [shows]frozen seafood or meat may have introduced the virus from the epidemic-affected countries into China."</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="2595" end_char="2601">Current</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="2603" end_char="2605">top</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="2607" end_char="2620">epidemiologist</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="2622" end_char="2623">Wu</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="2625" end_char="2630">Zunyou</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="2632" end_char="2638">claimed</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="2640" end_char="2646">earlier</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="2648" end_char="2649">in</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="2651" end_char="2653">the</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="2655" end_char="2659">month</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="2661" end_char="2664">that</TOKEN>
<TOKEN id="token-16-11" pos="punct" morph="none" start_char="2666" end_char="2667">"[</TOKEN>
<TOKEN id="token-16-12" pos="unknown" morph="none" start_char="2668" end_char="2675">g]rowing</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="2677" end_char="2684">evidence</TOKEN>
<TOKEN id="token-16-14" pos="punct" morph="none" start_char="2686" end_char="2686">[</TOKEN>
<TOKEN id="token-16-15" pos="unknown" morph="none" start_char="2687" end_char="2698">shows]frozen</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="2700" end_char="2706">seafood</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="2708" end_char="2709">or</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="2711" end_char="2714">meat</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="2716" end_char="2718">may</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="2720" end_char="2723">have</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="2725" end_char="2734">introduced</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="2736" end_char="2738">the</TOKEN>
<TOKEN id="token-16-23" pos="word" morph="none" start_char="2740" end_char="2744">virus</TOKEN>
<TOKEN id="token-16-24" pos="word" morph="none" start_char="2746" end_char="2749">from</TOKEN>
<TOKEN id="token-16-25" pos="word" morph="none" start_char="2751" end_char="2753">the</TOKEN>
<TOKEN id="token-16-26" pos="unknown" morph="none" start_char="2755" end_char="2771">epidemic-affected</TOKEN>
<TOKEN id="token-16-27" pos="word" morph="none" start_char="2773" end_char="2781">countries</TOKEN>
<TOKEN id="token-16-28" pos="word" morph="none" start_char="2783" end_char="2786">into</TOKEN>
<TOKEN id="token-16-29" pos="word" morph="none" start_char="2788" end_char="2792">China</TOKEN>
<TOKEN id="token-16-30" pos="punct" morph="none" start_char="2793" end_char="2794">."</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2797" end_char="2877">
<ORIGINAL_TEXT>Authorities have tied recent outbreaks in Tianjin and Shanghai to imported goods.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2797" end_char="2807">Authorities</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2809" end_char="2812">have</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2814" end_char="2817">tied</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2819" end_char="2824">recent</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2826" end_char="2834">outbreaks</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2836" end_char="2837">in</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2839" end_char="2845">Tianjin</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2847" end_char="2849">and</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2851" end_char="2858">Shanghai</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2860" end_char="2861">to</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2863" end_char="2870">imported</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2872" end_char="2876">goods</TOKEN>
<TOKEN id="token-17-12" pos="punct" morph="none" start_char="2877" end_char="2877">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2879" end_char="3005">
<ORIGINAL_TEXT>Videos of panicked workers fleeing the Shanghai airport after a snap decision to rapid-test 17,000 workers went viral recently.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2879" end_char="2884">Videos</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2886" end_char="2887">of</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2889" end_char="2896">panicked</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2898" end_char="2904">workers</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2906" end_char="2912">fleeing</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2914" end_char="2916">the</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2918" end_char="2925">Shanghai</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2927" end_char="2933">airport</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2935" end_char="2939">after</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="2941" end_char="2941">a</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="2943" end_char="2946">snap</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="2948" end_char="2955">decision</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2957" end_char="2958">to</TOKEN>
<TOKEN id="token-18-13" pos="unknown" morph="none" start_char="2960" end_char="2969">rapid-test</TOKEN>
<TOKEN id="token-18-14" pos="unknown" morph="none" start_char="2971" end_char="2976">17,000</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="2978" end_char="2984">workers</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="2986" end_char="2989">went</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="2991" end_char="2995">viral</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="2997" end_char="3004">recently</TOKEN>
<TOKEN id="token-18-19" pos="punct" morph="none" start_char="3005" end_char="3005">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="3007" end_char="3251">
<ORIGINAL_TEXT>While the scenes in Shanghai and Tianjin have been used to bolster claims of a foreign origin for the virus, the South China Morning Post’s Linda Lew and Nadia Lam detailed the global scientific community’s skepticism about Zeng and Wu’s claims:</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="3007" end_char="3011">While</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="3013" end_char="3015">the</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="3017" end_char="3022">scenes</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="3024" end_char="3025">in</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="3027" end_char="3034">Shanghai</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="3036" end_char="3038">and</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="3040" end_char="3046">Tianjin</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="3048" end_char="3051">have</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="3053" end_char="3056">been</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="3058" end_char="3061">used</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="3063" end_char="3064">to</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="3066" end_char="3072">bolster</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="3074" end_char="3079">claims</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="3081" end_char="3082">of</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="3084" end_char="3084">a</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="3086" end_char="3092">foreign</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="3094" end_char="3099">origin</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="3101" end_char="3103">for</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="3105" end_char="3107">the</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="3109" end_char="3113">virus</TOKEN>
<TOKEN id="token-19-20" pos="punct" morph="none" start_char="3114" end_char="3114">,</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="3116" end_char="3118">the</TOKEN>
<TOKEN id="token-19-22" pos="word" morph="none" start_char="3120" end_char="3124">South</TOKEN>
<TOKEN id="token-19-23" pos="word" morph="none" start_char="3126" end_char="3130">China</TOKEN>
<TOKEN id="token-19-24" pos="word" morph="none" start_char="3132" end_char="3138">Morning</TOKEN>
<TOKEN id="token-19-25" pos="word" morph="none" start_char="3140" end_char="3145">Post’s</TOKEN>
<TOKEN id="token-19-26" pos="word" morph="none" start_char="3147" end_char="3151">Linda</TOKEN>
<TOKEN id="token-19-27" pos="word" morph="none" start_char="3153" end_char="3155">Lew</TOKEN>
<TOKEN id="token-19-28" pos="word" morph="none" start_char="3157" end_char="3159">and</TOKEN>
<TOKEN id="token-19-29" pos="word" morph="none" start_char="3161" end_char="3165">Nadia</TOKEN>
<TOKEN id="token-19-30" pos="word" morph="none" start_char="3167" end_char="3169">Lam</TOKEN>
<TOKEN id="token-19-31" pos="word" morph="none" start_char="3171" end_char="3178">detailed</TOKEN>
<TOKEN id="token-19-32" pos="word" morph="none" start_char="3180" end_char="3182">the</TOKEN>
<TOKEN id="token-19-33" pos="word" morph="none" start_char="3184" end_char="3189">global</TOKEN>
<TOKEN id="token-19-34" pos="word" morph="none" start_char="3191" end_char="3200">scientific</TOKEN>
<TOKEN id="token-19-35" pos="word" morph="none" start_char="3202" end_char="3212">community’s</TOKEN>
<TOKEN id="token-19-36" pos="word" morph="none" start_char="3214" end_char="3223">skepticism</TOKEN>
<TOKEN id="token-19-37" pos="word" morph="none" start_char="3225" end_char="3229">about</TOKEN>
<TOKEN id="token-19-38" pos="word" morph="none" start_char="3231" end_char="3234">Zeng</TOKEN>
<TOKEN id="token-19-39" pos="word" morph="none" start_char="3236" end_char="3238">and</TOKEN>
<TOKEN id="token-19-40" pos="word" morph="none" start_char="3240" end_char="3243">Wu’s</TOKEN>
<TOKEN id="token-19-41" pos="word" morph="none" start_char="3245" end_char="3250">claims</TOKEN>
<TOKEN id="token-19-42" pos="punct" morph="none" start_char="3251" end_char="3251">:</TOKEN>
</SEG>
<SEG id="segment-20" start_char="3254" end_char="3478">
<ORIGINAL_TEXT>Wuhan University virology professor Yang Zhanqiu said suggestions the virus entered the country on imported frozen food were just guesses "that do not have supporting evidence ", according to nationalist tabloid Global Times.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="3254" end_char="3258">Wuhan</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="3260" end_char="3269">University</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="3271" end_char="3278">virology</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="3280" end_char="3288">professor</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="3290" end_char="3293">Yang</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="3295" end_char="3301">Zhanqiu</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="3303" end_char="3306">said</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="3308" end_char="3318">suggestions</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="3320" end_char="3322">the</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="3324" end_char="3328">virus</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="3330" end_char="3336">entered</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="3338" end_char="3340">the</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="3342" end_char="3348">country</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="3350" end_char="3351">on</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="3353" end_char="3360">imported</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="3362" end_char="3367">frozen</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="3369" end_char="3372">food</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="3374" end_char="3377">were</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="3379" end_char="3382">just</TOKEN>
<TOKEN id="token-20-19" pos="word" morph="none" start_char="3384" end_char="3390">guesses</TOKEN>
<TOKEN id="token-20-20" pos="punct" morph="none" start_char="3392" end_char="3392">"</TOKEN>
<TOKEN id="token-20-21" pos="word" morph="none" start_char="3393" end_char="3396">that</TOKEN>
<TOKEN id="token-20-22" pos="word" morph="none" start_char="3398" end_char="3399">do</TOKEN>
<TOKEN id="token-20-23" pos="word" morph="none" start_char="3401" end_char="3403">not</TOKEN>
<TOKEN id="token-20-24" pos="word" morph="none" start_char="3405" end_char="3408">have</TOKEN>
<TOKEN id="token-20-25" pos="word" morph="none" start_char="3410" end_char="3419">supporting</TOKEN>
<TOKEN id="token-20-26" pos="word" morph="none" start_char="3421" end_char="3428">evidence</TOKEN>
<TOKEN id="token-20-27" pos="punct" morph="none" start_char="3430" end_char="3431">",</TOKEN>
<TOKEN id="token-20-28" pos="word" morph="none" start_char="3433" end_char="3441">according</TOKEN>
<TOKEN id="token-20-29" pos="word" morph="none" start_char="3443" end_char="3444">to</TOKEN>
<TOKEN id="token-20-30" pos="word" morph="none" start_char="3446" end_char="3456">nationalist</TOKEN>
<TOKEN id="token-20-31" pos="word" morph="none" start_char="3458" end_char="3464">tabloid</TOKEN>
<TOKEN id="token-20-32" pos="word" morph="none" start_char="3466" end_char="3471">Global</TOKEN>
<TOKEN id="token-20-33" pos="word" morph="none" start_char="3473" end_char="3477">Times</TOKEN>
<TOKEN id="token-20-34" pos="punct" morph="none" start_char="3478" end_char="3478">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="3480" end_char="3695">
<ORIGINAL_TEXT>[…] Yuen Kwok-yung, chairman of infectious diseases at the University of Hong Kong’s department of microbiology, said there were questions about the Italian study and it could be a case of a "false positive" reading.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="punct" morph="none" start_char="3480" end_char="3482">[…]</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="3484" end_char="3487">Yuen</TOKEN>
<TOKEN id="token-21-2" pos="unknown" morph="none" start_char="3489" end_char="3497">Kwok-yung</TOKEN>
<TOKEN id="token-21-3" pos="punct" morph="none" start_char="3498" end_char="3498">,</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="3500" end_char="3507">chairman</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="3509" end_char="3510">of</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="3512" end_char="3521">infectious</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="3523" end_char="3530">diseases</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="3532" end_char="3533">at</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="3535" end_char="3537">the</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="3539" end_char="3548">University</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="3550" end_char="3551">of</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="3553" end_char="3556">Hong</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="3558" end_char="3563">Kong’s</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="3565" end_char="3574">department</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="3576" end_char="3577">of</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="3579" end_char="3590">microbiology</TOKEN>
<TOKEN id="token-21-17" pos="punct" morph="none" start_char="3591" end_char="3591">,</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="3593" end_char="3596">said</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="3598" end_char="3602">there</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="3604" end_char="3607">were</TOKEN>
<TOKEN id="token-21-21" pos="word" morph="none" start_char="3609" end_char="3617">questions</TOKEN>
<TOKEN id="token-21-22" pos="word" morph="none" start_char="3619" end_char="3623">about</TOKEN>
<TOKEN id="token-21-23" pos="word" morph="none" start_char="3625" end_char="3627">the</TOKEN>
<TOKEN id="token-21-24" pos="word" morph="none" start_char="3629" end_char="3635">Italian</TOKEN>
<TOKEN id="token-21-25" pos="word" morph="none" start_char="3637" end_char="3641">study</TOKEN>
<TOKEN id="token-21-26" pos="word" morph="none" start_char="3643" end_char="3645">and</TOKEN>
<TOKEN id="token-21-27" pos="word" morph="none" start_char="3647" end_char="3648">it</TOKEN>
<TOKEN id="token-21-28" pos="word" morph="none" start_char="3650" end_char="3654">could</TOKEN>
<TOKEN id="token-21-29" pos="word" morph="none" start_char="3656" end_char="3657">be</TOKEN>
<TOKEN id="token-21-30" pos="word" morph="none" start_char="3659" end_char="3659">a</TOKEN>
<TOKEN id="token-21-31" pos="word" morph="none" start_char="3661" end_char="3664">case</TOKEN>
<TOKEN id="token-21-32" pos="word" morph="none" start_char="3666" end_char="3667">of</TOKEN>
<TOKEN id="token-21-33" pos="word" morph="none" start_char="3669" end_char="3669">a</TOKEN>
<TOKEN id="token-21-34" pos="punct" morph="none" start_char="3671" end_char="3671">"</TOKEN>
<TOKEN id="token-21-35" pos="word" morph="none" start_char="3672" end_char="3676">false</TOKEN>
<TOKEN id="token-21-36" pos="word" morph="none" start_char="3678" end_char="3685">positive</TOKEN>
<TOKEN id="token-21-37" pos="punct" morph="none" start_char="3686" end_char="3686">"</TOKEN>
<TOKEN id="token-21-38" pos="word" morph="none" start_char="3688" end_char="3694">reading</TOKEN>
<TOKEN id="token-21-39" pos="punct" morph="none" start_char="3695" end_char="3695">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="3697" end_char="3893">
<ORIGINAL_TEXT>The specific antibodies found in the Italian study were insufficient to prove that the patient had Covid-19, he said at a forum organised by Hong Kong media platform Master Insight Media on Friday.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="3697" end_char="3699">The</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="3701" end_char="3708">specific</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="3710" end_char="3719">antibodies</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="3721" end_char="3725">found</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="3727" end_char="3728">in</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="3730" end_char="3732">the</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="3734" end_char="3740">Italian</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="3742" end_char="3746">study</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="3748" end_char="3751">were</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="3753" end_char="3764">insufficient</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="3766" end_char="3767">to</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="3769" end_char="3773">prove</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="3775" end_char="3778">that</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="3780" end_char="3782">the</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="3784" end_char="3790">patient</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="3792" end_char="3794">had</TOKEN>
<TOKEN id="token-22-16" pos="unknown" morph="none" start_char="3796" end_char="3803">Covid-19</TOKEN>
<TOKEN id="token-22-17" pos="punct" morph="none" start_char="3804" end_char="3804">,</TOKEN>
<TOKEN id="token-22-18" pos="word" morph="none" start_char="3806" end_char="3807">he</TOKEN>
<TOKEN id="token-22-19" pos="word" morph="none" start_char="3809" end_char="3812">said</TOKEN>
<TOKEN id="token-22-20" pos="word" morph="none" start_char="3814" end_char="3815">at</TOKEN>
<TOKEN id="token-22-21" pos="word" morph="none" start_char="3817" end_char="3817">a</TOKEN>
<TOKEN id="token-22-22" pos="word" morph="none" start_char="3819" end_char="3823">forum</TOKEN>
<TOKEN id="token-22-23" pos="word" morph="none" start_char="3825" end_char="3833">organised</TOKEN>
<TOKEN id="token-22-24" pos="word" morph="none" start_char="3835" end_char="3836">by</TOKEN>
<TOKEN id="token-22-25" pos="word" morph="none" start_char="3838" end_char="3841">Hong</TOKEN>
<TOKEN id="token-22-26" pos="word" morph="none" start_char="3843" end_char="3846">Kong</TOKEN>
<TOKEN id="token-22-27" pos="word" morph="none" start_char="3848" end_char="3852">media</TOKEN>
<TOKEN id="token-22-28" pos="word" morph="none" start_char="3854" end_char="3861">platform</TOKEN>
<TOKEN id="token-22-29" pos="word" morph="none" start_char="3863" end_char="3868">Master</TOKEN>
<TOKEN id="token-22-30" pos="word" morph="none" start_char="3870" end_char="3876">Insight</TOKEN>
<TOKEN id="token-22-31" pos="word" morph="none" start_char="3878" end_char="3882">Media</TOKEN>
<TOKEN id="token-22-32" pos="word" morph="none" start_char="3884" end_char="3885">on</TOKEN>
<TOKEN id="token-22-33" pos="word" morph="none" start_char="3887" end_char="3892">Friday</TOKEN>
<TOKEN id="token-22-34" pos="punct" morph="none" start_char="3893" end_char="3893">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="3895" end_char="3902">
<ORIGINAL_TEXT>[Source]</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="punct" morph="none" start_char="3895" end_char="3895">[</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="3896" end_char="3901">Source</TOKEN>
<TOKEN id="token-23-2" pos="punct" morph="none" start_char="3902" end_char="3902">]</TOKEN>
</SEG>
<SEG id="segment-24" start_char="3906" end_char="3975">
<ORIGINAL_TEXT>Government-endorsed conspiracies about the virus’ origins are not new.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="unknown" morph="none" start_char="3906" end_char="3924">Government-endorsed</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="3926" end_char="3937">conspiracies</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="3939" end_char="3943">about</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="3945" end_char="3947">the</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="3949" end_char="3953">virus</TOKEN>
<TOKEN id="token-24-5" pos="punct" morph="none" start_char="3954" end_char="3954">’</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="3956" end_char="3962">origins</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="3964" end_char="3966">are</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="3968" end_char="3970">not</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="3972" end_char="3974">new</TOKEN>
<TOKEN id="token-24-10" pos="punct" morph="none" start_char="3975" end_char="3975">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="3977" end_char="4205">
<ORIGINAL_TEXT>In March, Ministry of Foreign Affairs Spokesperson Zhao Lijian promoted a false theory that COVID-19 started in Fort Detrick, Maryland, and may have been brought to Wuhan by American participants in the 2019 Military World Games.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="3977" end_char="3978">In</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="3980" end_char="3984">March</TOKEN>
<TOKEN id="token-25-2" pos="punct" morph="none" start_char="3985" end_char="3985">,</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="3987" end_char="3994">Ministry</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="3996" end_char="3997">of</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="3999" end_char="4005">Foreign</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="4007" end_char="4013">Affairs</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="4015" end_char="4026">Spokesperson</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="4028" end_char="4031">Zhao</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="4033" end_char="4038">Lijian</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="4040" end_char="4047">promoted</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="4049" end_char="4049">a</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="4051" end_char="4055">false</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="4057" end_char="4062">theory</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="4064" end_char="4067">that</TOKEN>
<TOKEN id="token-25-15" pos="unknown" morph="none" start_char="4069" end_char="4076">COVID-19</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="4078" end_char="4084">started</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="4086" end_char="4087">in</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="4089" end_char="4092">Fort</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="4094" end_char="4100">Detrick</TOKEN>
<TOKEN id="token-25-20" pos="punct" morph="none" start_char="4101" end_char="4101">,</TOKEN>
<TOKEN id="token-25-21" pos="word" morph="none" start_char="4103" end_char="4110">Maryland</TOKEN>
<TOKEN id="token-25-22" pos="punct" morph="none" start_char="4111" end_char="4111">,</TOKEN>
<TOKEN id="token-25-23" pos="word" morph="none" start_char="4113" end_char="4115">and</TOKEN>
<TOKEN id="token-25-24" pos="word" morph="none" start_char="4117" end_char="4119">may</TOKEN>
<TOKEN id="token-25-25" pos="word" morph="none" start_char="4121" end_char="4124">have</TOKEN>
<TOKEN id="token-25-26" pos="word" morph="none" start_char="4126" end_char="4129">been</TOKEN>
<TOKEN id="token-25-27" pos="word" morph="none" start_char="4131" end_char="4137">brought</TOKEN>
<TOKEN id="token-25-28" pos="word" morph="none" start_char="4139" end_char="4140">to</TOKEN>
<TOKEN id="token-25-29" pos="word" morph="none" start_char="4142" end_char="4146">Wuhan</TOKEN>
<TOKEN id="token-25-30" pos="word" morph="none" start_char="4148" end_char="4149">by</TOKEN>
<TOKEN id="token-25-31" pos="word" morph="none" start_char="4151" end_char="4158">American</TOKEN>
<TOKEN id="token-25-32" pos="word" morph="none" start_char="4160" end_char="4171">participants</TOKEN>
<TOKEN id="token-25-33" pos="word" morph="none" start_char="4173" end_char="4174">in</TOKEN>
<TOKEN id="token-25-34" pos="word" morph="none" start_char="4176" end_char="4178">the</TOKEN>
<TOKEN id="token-25-35" pos="word" morph="none" start_char="4180" end_char="4183">2019</TOKEN>
<TOKEN id="token-25-36" pos="word" morph="none" start_char="4185" end_char="4192">Military</TOKEN>
<TOKEN id="token-25-37" pos="word" morph="none" start_char="4194" end_char="4198">World</TOKEN>
<TOKEN id="token-25-38" pos="word" morph="none" start_char="4200" end_char="4204">Games</TOKEN>
<TOKEN id="token-25-39" pos="punct" morph="none" start_char="4205" end_char="4205">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="4207" end_char="4319">
<ORIGINAL_TEXT>Hundreds of Chinese state-connected accounts including, diplomatic outposts and media outlets, echoed his claims.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="4207" end_char="4214">Hundreds</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="4216" end_char="4217">of</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="4219" end_char="4225">Chinese</TOKEN>
<TOKEN id="token-26-3" pos="unknown" morph="none" start_char="4227" end_char="4241">state-connected</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="4243" end_char="4250">accounts</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="4252" end_char="4260">including</TOKEN>
<TOKEN id="token-26-6" pos="punct" morph="none" start_char="4261" end_char="4261">,</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="4263" end_char="4272">diplomatic</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="4274" end_char="4281">outposts</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="4283" end_char="4285">and</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="4287" end_char="4291">media</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="4293" end_char="4299">outlets</TOKEN>
<TOKEN id="token-26-12" pos="punct" morph="none" start_char="4300" end_char="4300">,</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="4302" end_char="4307">echoed</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="4309" end_char="4311">his</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="4313" end_char="4318">claims</TOKEN>
<TOKEN id="token-26-16" pos="punct" morph="none" start_char="4319" end_char="4319">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="4321" end_char="4327">
<ORIGINAL_TEXT>Dali L.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="4321" end_char="4324">Dali</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="4326" end_char="4326">L</TOKEN>
<TOKEN id="token-27-2" pos="punct" morph="none" start_char="4327" end_char="4327">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="4329" end_char="4618">
<ORIGINAL_TEXT>Yang, an eminent sinologist at The University of Chicago, wrote that Zhao’s amplification of conspiracies served to make "such ‘theories’ appear more credible to ordinary Chinese and further helped them to spread virally on Chinese social media," thus relieving internal political pressure.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="4329" end_char="4332">Yang</TOKEN>
<TOKEN id="token-28-1" pos="punct" morph="none" start_char="4333" end_char="4333">,</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="4335" end_char="4336">an</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="4338" end_char="4344">eminent</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="4346" end_char="4355">sinologist</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="4357" end_char="4358">at</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="4360" end_char="4362">The</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="4364" end_char="4373">University</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="4375" end_char="4376">of</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="4378" end_char="4384">Chicago</TOKEN>
<TOKEN id="token-28-10" pos="punct" morph="none" start_char="4385" end_char="4385">,</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="4387" end_char="4391">wrote</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="4393" end_char="4396">that</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="4398" end_char="4403">Zhao’s</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="4405" end_char="4417">amplification</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="4419" end_char="4420">of</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="4422" end_char="4433">conspiracies</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="4435" end_char="4440">served</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="4442" end_char="4443">to</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="4445" end_char="4448">make</TOKEN>
<TOKEN id="token-28-20" pos="punct" morph="none" start_char="4450" end_char="4450">"</TOKEN>
<TOKEN id="token-28-21" pos="word" morph="none" start_char="4451" end_char="4454">such</TOKEN>
<TOKEN id="token-28-22" pos="punct" morph="none" start_char="4456" end_char="4456">‘</TOKEN>
<TOKEN id="token-28-23" pos="word" morph="none" start_char="4457" end_char="4464">theories</TOKEN>
<TOKEN id="token-28-24" pos="punct" morph="none" start_char="4465" end_char="4465">’</TOKEN>
<TOKEN id="token-28-25" pos="word" morph="none" start_char="4467" end_char="4472">appear</TOKEN>
<TOKEN id="token-28-26" pos="word" morph="none" start_char="4474" end_char="4477">more</TOKEN>
<TOKEN id="token-28-27" pos="word" morph="none" start_char="4479" end_char="4486">credible</TOKEN>
<TOKEN id="token-28-28" pos="word" morph="none" start_char="4488" end_char="4489">to</TOKEN>
<TOKEN id="token-28-29" pos="word" morph="none" start_char="4491" end_char="4498">ordinary</TOKEN>
<TOKEN id="token-28-30" pos="word" morph="none" start_char="4500" end_char="4506">Chinese</TOKEN>
<TOKEN id="token-28-31" pos="word" morph="none" start_char="4508" end_char="4510">and</TOKEN>
<TOKEN id="token-28-32" pos="word" morph="none" start_char="4512" end_char="4518">further</TOKEN>
<TOKEN id="token-28-33" pos="word" morph="none" start_char="4520" end_char="4525">helped</TOKEN>
<TOKEN id="token-28-34" pos="word" morph="none" start_char="4527" end_char="4530">them</TOKEN>
<TOKEN id="token-28-35" pos="word" morph="none" start_char="4532" end_char="4533">to</TOKEN>
<TOKEN id="token-28-36" pos="word" morph="none" start_char="4535" end_char="4540">spread</TOKEN>
<TOKEN id="token-28-37" pos="word" morph="none" start_char="4542" end_char="4548">virally</TOKEN>
<TOKEN id="token-28-38" pos="word" morph="none" start_char="4550" end_char="4551">on</TOKEN>
<TOKEN id="token-28-39" pos="word" morph="none" start_char="4553" end_char="4559">Chinese</TOKEN>
<TOKEN id="token-28-40" pos="word" morph="none" start_char="4561" end_char="4566">social</TOKEN>
<TOKEN id="token-28-41" pos="word" morph="none" start_char="4568" end_char="4572">media</TOKEN>
<TOKEN id="token-28-42" pos="punct" morph="none" start_char="4573" end_char="4574">,"</TOKEN>
<TOKEN id="token-28-43" pos="word" morph="none" start_char="4576" end_char="4579">thus</TOKEN>
<TOKEN id="token-28-44" pos="word" morph="none" start_char="4581" end_char="4589">relieving</TOKEN>
<TOKEN id="token-28-45" pos="word" morph="none" start_char="4591" end_char="4598">internal</TOKEN>
<TOKEN id="token-28-46" pos="word" morph="none" start_char="4600" end_char="4608">political</TOKEN>
<TOKEN id="token-28-47" pos="word" morph="none" start_char="4610" end_char="4617">pressure</TOKEN>
<TOKEN id="token-28-48" pos="punct" morph="none" start_char="4618" end_char="4618">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="4621" end_char="4773">
<ORIGINAL_TEXT>Beijing has resisted international investigations into the coronavirus’ origins, stymieing World Health Organization investigators access to the country.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="4621" end_char="4627">Beijing</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="4629" end_char="4631">has</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="4633" end_char="4640">resisted</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="4642" end_char="4654">international</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="4656" end_char="4669">investigations</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="4671" end_char="4674">into</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="4676" end_char="4678">the</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="4680" end_char="4690">coronavirus</TOKEN>
<TOKEN id="token-29-8" pos="punct" morph="none" start_char="4691" end_char="4691">’</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="4693" end_char="4699">origins</TOKEN>
<TOKEN id="token-29-10" pos="punct" morph="none" start_char="4700" end_char="4700">,</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="4702" end_char="4710">stymieing</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="4712" end_char="4716">World</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="4718" end_char="4723">Health</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="4725" end_char="4736">Organization</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="4738" end_char="4750">investigators</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="4752" end_char="4757">access</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="4759" end_char="4760">to</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="4762" end_char="4764">the</TOKEN>
<TOKEN id="token-29-19" pos="word" morph="none" start_char="4766" end_char="4772">country</TOKEN>
<TOKEN id="token-29-20" pos="punct" morph="none" start_char="4773" end_char="4773">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="4775" end_char="4915">
<ORIGINAL_TEXT>On Wednesday, the WHO announced the long-delayed assembly of a 10-person coronavirus investigation team, selected in consultation with China.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="4775" end_char="4776">On</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="4778" end_char="4786">Wednesday</TOKEN>
<TOKEN id="token-30-2" pos="punct" morph="none" start_char="4787" end_char="4787">,</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="4789" end_char="4791">the</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="4793" end_char="4795">WHO</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="4797" end_char="4805">announced</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="4807" end_char="4809">the</TOKEN>
<TOKEN id="token-30-7" pos="unknown" morph="none" start_char="4811" end_char="4822">long-delayed</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="4824" end_char="4831">assembly</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="4833" end_char="4834">of</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="4836" end_char="4836">a</TOKEN>
<TOKEN id="token-30-11" pos="unknown" morph="none" start_char="4838" end_char="4846">10-person</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="4848" end_char="4858">coronavirus</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="4860" end_char="4872">investigation</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="4874" end_char="4877">team</TOKEN>
<TOKEN id="token-30-15" pos="punct" morph="none" start_char="4878" end_char="4878">,</TOKEN>
<TOKEN id="token-30-16" pos="word" morph="none" start_char="4880" end_char="4887">selected</TOKEN>
<TOKEN id="token-30-17" pos="word" morph="none" start_char="4889" end_char="4890">in</TOKEN>
<TOKEN id="token-30-18" pos="word" morph="none" start_char="4892" end_char="4903">consultation</TOKEN>
<TOKEN id="token-30-19" pos="word" morph="none" start_char="4905" end_char="4908">with</TOKEN>
<TOKEN id="token-30-20" pos="word" morph="none" start_char="4910" end_char="4914">China</TOKEN>
<TOKEN id="token-30-21" pos="punct" morph="none" start_char="4915" end_char="4915">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="4917" end_char="5064">
<ORIGINAL_TEXT>At the South China Morning Post, Simone McCarthy reported on the team’s research goals, and concerns that they might be denied full access to Wuhan:</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="4917" end_char="4918">At</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="4920" end_char="4922">the</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="4924" end_char="4928">South</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="4930" end_char="4934">China</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="4936" end_char="4942">Morning</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="4944" end_char="4947">Post</TOKEN>
<TOKEN id="token-31-6" pos="punct" morph="none" start_char="4948" end_char="4948">,</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="4950" end_char="4955">Simone</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="4957" end_char="4964">McCarthy</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="4966" end_char="4973">reported</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="4975" end_char="4976">on</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="4978" end_char="4980">the</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="4982" end_char="4987">team’s</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="4989" end_char="4996">research</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="4998" end_char="5002">goals</TOKEN>
<TOKEN id="token-31-15" pos="punct" morph="none" start_char="5003" end_char="5003">,</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="5005" end_char="5007">and</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="5009" end_char="5016">concerns</TOKEN>
<TOKEN id="token-31-18" pos="word" morph="none" start_char="5018" end_char="5021">that</TOKEN>
<TOKEN id="token-31-19" pos="word" morph="none" start_char="5023" end_char="5026">they</TOKEN>
<TOKEN id="token-31-20" pos="word" morph="none" start_char="5028" end_char="5032">might</TOKEN>
<TOKEN id="token-31-21" pos="word" morph="none" start_char="5034" end_char="5035">be</TOKEN>
<TOKEN id="token-31-22" pos="word" morph="none" start_char="5037" end_char="5042">denied</TOKEN>
<TOKEN id="token-31-23" pos="word" morph="none" start_char="5044" end_char="5047">full</TOKEN>
<TOKEN id="token-31-24" pos="word" morph="none" start_char="5049" end_char="5054">access</TOKEN>
<TOKEN id="token-31-25" pos="word" morph="none" start_char="5056" end_char="5057">to</TOKEN>
<TOKEN id="token-31-26" pos="word" morph="none" start_char="5059" end_char="5063">Wuhan</TOKEN>
<TOKEN id="token-31-27" pos="punct" morph="none" start_char="5064" end_char="5064">:</TOKEN>
</SEG>
<SEG id="segment-32" start_char="5067" end_char="5295">
<ORIGINAL_TEXT>One hanging question is when the international team will join field studies on the ground in China, considered a critical part of the mission, which was called for by over 130 nations at a May meeting of the WHO’s governing body.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="5067" end_char="5069">One</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="5071" end_char="5077">hanging</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="5079" end_char="5086">question</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="5088" end_char="5089">is</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="5091" end_char="5094">when</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="5096" end_char="5098">the</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="5100" end_char="5112">international</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="5114" end_char="5117">team</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="5119" end_char="5122">will</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="5124" end_char="5127">join</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="5129" end_char="5133">field</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="5135" end_char="5141">studies</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="5143" end_char="5144">on</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="5146" end_char="5148">the</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="5150" end_char="5155">ground</TOKEN>
<TOKEN id="token-32-15" pos="word" morph="none" start_char="5157" end_char="5158">in</TOKEN>
<TOKEN id="token-32-16" pos="word" morph="none" start_char="5160" end_char="5164">China</TOKEN>
<TOKEN id="token-32-17" pos="punct" morph="none" start_char="5165" end_char="5165">,</TOKEN>
<TOKEN id="token-32-18" pos="word" morph="none" start_char="5167" end_char="5176">considered</TOKEN>
<TOKEN id="token-32-19" pos="word" morph="none" start_char="5178" end_char="5178">a</TOKEN>
<TOKEN id="token-32-20" pos="word" morph="none" start_char="5180" end_char="5187">critical</TOKEN>
<TOKEN id="token-32-21" pos="word" morph="none" start_char="5189" end_char="5192">part</TOKEN>
<TOKEN id="token-32-22" pos="word" morph="none" start_char="5194" end_char="5195">of</TOKEN>
<TOKEN id="token-32-23" pos="word" morph="none" start_char="5197" end_char="5199">the</TOKEN>
<TOKEN id="token-32-24" pos="word" morph="none" start_char="5201" end_char="5207">mission</TOKEN>
<TOKEN id="token-32-25" pos="punct" morph="none" start_char="5208" end_char="5208">,</TOKEN>
<TOKEN id="token-32-26" pos="word" morph="none" start_char="5210" end_char="5214">which</TOKEN>
<TOKEN id="token-32-27" pos="word" morph="none" start_char="5216" end_char="5218">was</TOKEN>
<TOKEN id="token-32-28" pos="word" morph="none" start_char="5220" end_char="5225">called</TOKEN>
<TOKEN id="token-32-29" pos="word" morph="none" start_char="5227" end_char="5229">for</TOKEN>
<TOKEN id="token-32-30" pos="word" morph="none" start_char="5231" end_char="5232">by</TOKEN>
<TOKEN id="token-32-31" pos="word" morph="none" start_char="5234" end_char="5237">over</TOKEN>
<TOKEN id="token-32-32" pos="word" morph="none" start_char="5239" end_char="5241">130</TOKEN>
<TOKEN id="token-32-33" pos="word" morph="none" start_char="5243" end_char="5249">nations</TOKEN>
<TOKEN id="token-32-34" pos="word" morph="none" start_char="5251" end_char="5252">at</TOKEN>
<TOKEN id="token-32-35" pos="word" morph="none" start_char="5254" end_char="5254">a</TOKEN>
<TOKEN id="token-32-36" pos="word" morph="none" start_char="5256" end_char="5258">May</TOKEN>
<TOKEN id="token-32-37" pos="word" morph="none" start_char="5260" end_char="5266">meeting</TOKEN>
<TOKEN id="token-32-38" pos="word" morph="none" start_char="5268" end_char="5269">of</TOKEN>
<TOKEN id="token-32-39" pos="word" morph="none" start_char="5271" end_char="5273">the</TOKEN>
<TOKEN id="token-32-40" pos="word" morph="none" start_char="5275" end_char="5279">WHO’s</TOKEN>
<TOKEN id="token-32-41" pos="word" morph="none" start_char="5281" end_char="5289">governing</TOKEN>
<TOKEN id="token-32-42" pos="word" morph="none" start_char="5291" end_char="5294">body</TOKEN>
<TOKEN id="token-32-43" pos="punct" morph="none" start_char="5295" end_char="5295">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="5297" end_char="5443">
<ORIGINAL_TEXT>[…] Groundwork for the mission was originally done in July and the WHO at the time said the international team would arrive "in a matter of weeks".</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="punct" morph="none" start_char="5297" end_char="5299">[…]</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="5301" end_char="5310">Groundwork</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="5312" end_char="5314">for</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="5316" end_char="5318">the</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="5320" end_char="5326">mission</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="5328" end_char="5330">was</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="5332" end_char="5341">originally</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="5343" end_char="5346">done</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="5348" end_char="5349">in</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="5351" end_char="5354">July</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="5356" end_char="5358">and</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="5360" end_char="5362">the</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="5364" end_char="5366">WHO</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="5368" end_char="5369">at</TOKEN>
<TOKEN id="token-33-14" pos="word" morph="none" start_char="5371" end_char="5373">the</TOKEN>
<TOKEN id="token-33-15" pos="word" morph="none" start_char="5375" end_char="5378">time</TOKEN>
<TOKEN id="token-33-16" pos="word" morph="none" start_char="5380" end_char="5383">said</TOKEN>
<TOKEN id="token-33-17" pos="word" morph="none" start_char="5385" end_char="5387">the</TOKEN>
<TOKEN id="token-33-18" pos="word" morph="none" start_char="5389" end_char="5401">international</TOKEN>
<TOKEN id="token-33-19" pos="word" morph="none" start_char="5403" end_char="5406">team</TOKEN>
<TOKEN id="token-33-20" pos="word" morph="none" start_char="5408" end_char="5412">would</TOKEN>
<TOKEN id="token-33-21" pos="word" morph="none" start_char="5414" end_char="5419">arrive</TOKEN>
<TOKEN id="token-33-22" pos="punct" morph="none" start_char="5421" end_char="5421">"</TOKEN>
<TOKEN id="token-33-23" pos="word" morph="none" start_char="5422" end_char="5423">in</TOKEN>
<TOKEN id="token-33-24" pos="word" morph="none" start_char="5425" end_char="5425">a</TOKEN>
<TOKEN id="token-33-25" pos="word" morph="none" start_char="5427" end_char="5432">matter</TOKEN>
<TOKEN id="token-33-26" pos="word" morph="none" start_char="5434" end_char="5435">of</TOKEN>
<TOKEN id="token-33-27" pos="word" morph="none" start_char="5437" end_char="5441">weeks</TOKEN>
<TOKEN id="token-33-28" pos="punct" morph="none" start_char="5442" end_char="5443">".</TOKEN>
</SEG>
<SEG id="segment-34" start_char="5445" end_char="5609">
<ORIGINAL_TEXT>The United States and the European Union have called for more transparency around the mission in recent meetings of the WHO’s executive board and its governing body.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="5445" end_char="5447">The</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="5449" end_char="5454">United</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="5456" end_char="5461">States</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="5463" end_char="5465">and</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="5467" end_char="5469">the</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="5471" end_char="5478">European</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="5480" end_char="5484">Union</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="5486" end_char="5489">have</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="5491" end_char="5496">called</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="5498" end_char="5500">for</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="5502" end_char="5505">more</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="5507" end_char="5518">transparency</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="5520" end_char="5525">around</TOKEN>
<TOKEN id="token-34-13" pos="word" morph="none" start_char="5527" end_char="5529">the</TOKEN>
<TOKEN id="token-34-14" pos="word" morph="none" start_char="5531" end_char="5537">mission</TOKEN>
<TOKEN id="token-34-15" pos="word" morph="none" start_char="5539" end_char="5540">in</TOKEN>
<TOKEN id="token-34-16" pos="word" morph="none" start_char="5542" end_char="5547">recent</TOKEN>
<TOKEN id="token-34-17" pos="word" morph="none" start_char="5549" end_char="5556">meetings</TOKEN>
<TOKEN id="token-34-18" pos="word" morph="none" start_char="5558" end_char="5559">of</TOKEN>
<TOKEN id="token-34-19" pos="word" morph="none" start_char="5561" end_char="5563">the</TOKEN>
<TOKEN id="token-34-20" pos="word" morph="none" start_char="5565" end_char="5569">WHO’s</TOKEN>
<TOKEN id="token-34-21" pos="word" morph="none" start_char="5571" end_char="5579">executive</TOKEN>
<TOKEN id="token-34-22" pos="word" morph="none" start_char="5581" end_char="5585">board</TOKEN>
<TOKEN id="token-34-23" pos="word" morph="none" start_char="5587" end_char="5589">and</TOKEN>
<TOKEN id="token-34-24" pos="word" morph="none" start_char="5591" end_char="5593">its</TOKEN>
<TOKEN id="token-34-25" pos="word" morph="none" start_char="5595" end_char="5603">governing</TOKEN>
<TOKEN id="token-34-26" pos="word" morph="none" start_char="5605" end_char="5608">body</TOKEN>
<TOKEN id="token-34-27" pos="punct" morph="none" start_char="5609" end_char="5609">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="5611" end_char="5733">
<ORIGINAL_TEXT>[…] The scientific mission’s phase one work centres around Wuhan, the city where the first cluster of cases was identified.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="punct" morph="none" start_char="5611" end_char="5613">[…]</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="5615" end_char="5617">The</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="5619" end_char="5628">scientific</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="5630" end_char="5638">mission’s</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="5640" end_char="5644">phase</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="5646" end_char="5648">one</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="5650" end_char="5653">work</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="5655" end_char="5661">centres</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="5663" end_char="5668">around</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="5670" end_char="5674">Wuhan</TOKEN>
<TOKEN id="token-35-10" pos="punct" morph="none" start_char="5675" end_char="5675">,</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="5677" end_char="5679">the</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="5681" end_char="5684">city</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="5686" end_char="5690">where</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="5692" end_char="5694">the</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="5696" end_char="5700">first</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="5702" end_char="5708">cluster</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="5710" end_char="5711">of</TOKEN>
<TOKEN id="token-35-18" pos="word" morph="none" start_char="5713" end_char="5717">cases</TOKEN>
<TOKEN id="token-35-19" pos="word" morph="none" start_char="5719" end_char="5721">was</TOKEN>
<TOKEN id="token-35-20" pos="word" morph="none" start_char="5723" end_char="5732">identified</TOKEN>
<TOKEN id="token-35-21" pos="punct" morph="none" start_char="5733" end_char="5733">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="5735" end_char="5954">
<ORIGINAL_TEXT>Though a number of these early cases were linked to a wet market in the city, the role of the market remains unclear due to a lack of "analytical epidemiological study", according to the WHO mission’s terms of reference.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="5735" end_char="5740">Though</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="5742" end_char="5742">a</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="5744" end_char="5749">number</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="5751" end_char="5752">of</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="5754" end_char="5758">these</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="5760" end_char="5764">early</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="5766" end_char="5770">cases</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="5772" end_char="5775">were</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="5777" end_char="5782">linked</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="5784" end_char="5785">to</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="5787" end_char="5787">a</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="5789" end_char="5791">wet</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="5793" end_char="5798">market</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="5800" end_char="5801">in</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="5803" end_char="5805">the</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="5807" end_char="5810">city</TOKEN>
<TOKEN id="token-36-16" pos="punct" morph="none" start_char="5811" end_char="5811">,</TOKEN>
<TOKEN id="token-36-17" pos="word" morph="none" start_char="5813" end_char="5815">the</TOKEN>
<TOKEN id="token-36-18" pos="word" morph="none" start_char="5817" end_char="5820">role</TOKEN>
<TOKEN id="token-36-19" pos="word" morph="none" start_char="5822" end_char="5823">of</TOKEN>
<TOKEN id="token-36-20" pos="word" morph="none" start_char="5825" end_char="5827">the</TOKEN>
<TOKEN id="token-36-21" pos="word" morph="none" start_char="5829" end_char="5834">market</TOKEN>
<TOKEN id="token-36-22" pos="word" morph="none" start_char="5836" end_char="5842">remains</TOKEN>
<TOKEN id="token-36-23" pos="word" morph="none" start_char="5844" end_char="5850">unclear</TOKEN>
<TOKEN id="token-36-24" pos="word" morph="none" start_char="5852" end_char="5854">due</TOKEN>
<TOKEN id="token-36-25" pos="word" morph="none" start_char="5856" end_char="5857">to</TOKEN>
<TOKEN id="token-36-26" pos="word" morph="none" start_char="5859" end_char="5859">a</TOKEN>
<TOKEN id="token-36-27" pos="word" morph="none" start_char="5861" end_char="5864">lack</TOKEN>
<TOKEN id="token-36-28" pos="word" morph="none" start_char="5866" end_char="5867">of</TOKEN>
<TOKEN id="token-36-29" pos="punct" morph="none" start_char="5869" end_char="5869">"</TOKEN>
<TOKEN id="token-36-30" pos="word" morph="none" start_char="5870" end_char="5879">analytical</TOKEN>
<TOKEN id="token-36-31" pos="word" morph="none" start_char="5881" end_char="5895">epidemiological</TOKEN>
<TOKEN id="token-36-32" pos="word" morph="none" start_char="5897" end_char="5901">study</TOKEN>
<TOKEN id="token-36-33" pos="punct" morph="none" start_char="5902" end_char="5903">",</TOKEN>
<TOKEN id="token-36-34" pos="word" morph="none" start_char="5905" end_char="5913">according</TOKEN>
<TOKEN id="token-36-35" pos="word" morph="none" start_char="5915" end_char="5916">to</TOKEN>
<TOKEN id="token-36-36" pos="word" morph="none" start_char="5918" end_char="5920">the</TOKEN>
<TOKEN id="token-36-37" pos="word" morph="none" start_char="5922" end_char="5924">WHO</TOKEN>
<TOKEN id="token-36-38" pos="word" morph="none" start_char="5926" end_char="5934">mission’s</TOKEN>
<TOKEN id="token-36-39" pos="word" morph="none" start_char="5936" end_char="5940">terms</TOKEN>
<TOKEN id="token-36-40" pos="word" morph="none" start_char="5942" end_char="5943">of</TOKEN>
<TOKEN id="token-36-41" pos="word" morph="none" start_char="5945" end_char="5953">reference</TOKEN>
<TOKEN id="token-36-42" pos="punct" morph="none" start_char="5954" end_char="5954">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="5956" end_char="5963">
<ORIGINAL_TEXT>[Source]</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="punct" morph="none" start_char="5956" end_char="5956">[</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="5957" end_char="5962">Source</TOKEN>
<TOKEN id="token-37-2" pos="punct" morph="none" start_char="5963" end_char="5963">]</TOKEN>
</SEG>
<SEG id="segment-38" start_char="5967" end_char="6089">
<ORIGINAL_TEXT>Contentions over the virus’ origin are part of the Chinese state’s ongoing battle to control the narrative on the pandemic.</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="5967" end_char="5977">Contentions</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="5979" end_char="5982">over</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="5984" end_char="5986">the</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="5988" end_char="5992">virus</TOKEN>
<TOKEN id="token-38-4" pos="punct" morph="none" start_char="5993" end_char="5993">’</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="5995" end_char="6000">origin</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="6002" end_char="6004">are</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="6006" end_char="6009">part</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="6011" end_char="6012">of</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="6014" end_char="6016">the</TOKEN>
<TOKEN id="token-38-10" pos="word" morph="none" start_char="6018" end_char="6024">Chinese</TOKEN>
<TOKEN id="token-38-11" pos="word" morph="none" start_char="6026" end_char="6032">state’s</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="6034" end_char="6040">ongoing</TOKEN>
<TOKEN id="token-38-13" pos="word" morph="none" start_char="6042" end_char="6047">battle</TOKEN>
<TOKEN id="token-38-14" pos="word" morph="none" start_char="6049" end_char="6050">to</TOKEN>
<TOKEN id="token-38-15" pos="word" morph="none" start_char="6052" end_char="6058">control</TOKEN>
<TOKEN id="token-38-16" pos="word" morph="none" start_char="6060" end_char="6062">the</TOKEN>
<TOKEN id="token-38-17" pos="word" morph="none" start_char="6064" end_char="6072">narrative</TOKEN>
<TOKEN id="token-38-18" pos="word" morph="none" start_char="6074" end_char="6075">on</TOKEN>
<TOKEN id="token-38-19" pos="word" morph="none" start_char="6077" end_char="6079">the</TOKEN>
<TOKEN id="token-38-20" pos="word" morph="none" start_char="6081" end_char="6088">pandemic</TOKEN>
<TOKEN id="token-38-21" pos="punct" morph="none" start_char="6089" end_char="6089">.</TOKEN>
</SEG>
<SEG id="segment-39" start_char="6091" end_char="6258">
<ORIGINAL_TEXT>Just last week citizen journalist Zhang Zhan, who covered the Wuhan outbreak on her vlog, was indicted on charges that allow authorities to imprison her for five years.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="6091" end_char="6094">Just</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="6096" end_char="6099">last</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="6101" end_char="6104">week</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="6106" end_char="6112">citizen</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="6114" end_char="6123">journalist</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="6125" end_char="6129">Zhang</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="6131" end_char="6134">Zhan</TOKEN>
<TOKEN id="token-39-7" pos="punct" morph="none" start_char="6135" end_char="6135">,</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="6137" end_char="6139">who</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="6141" end_char="6147">covered</TOKEN>
<TOKEN id="token-39-10" pos="word" morph="none" start_char="6149" end_char="6151">the</TOKEN>
<TOKEN id="token-39-11" pos="word" morph="none" start_char="6153" end_char="6157">Wuhan</TOKEN>
<TOKEN id="token-39-12" pos="word" morph="none" start_char="6159" end_char="6166">outbreak</TOKEN>
<TOKEN id="token-39-13" pos="word" morph="none" start_char="6168" end_char="6169">on</TOKEN>
<TOKEN id="token-39-14" pos="word" morph="none" start_char="6171" end_char="6173">her</TOKEN>
<TOKEN id="token-39-15" pos="word" morph="none" start_char="6175" end_char="6178">vlog</TOKEN>
<TOKEN id="token-39-16" pos="punct" morph="none" start_char="6179" end_char="6179">,</TOKEN>
<TOKEN id="token-39-17" pos="word" morph="none" start_char="6181" end_char="6183">was</TOKEN>
<TOKEN id="token-39-18" pos="word" morph="none" start_char="6185" end_char="6192">indicted</TOKEN>
<TOKEN id="token-39-19" pos="word" morph="none" start_char="6194" end_char="6195">on</TOKEN>
<TOKEN id="token-39-20" pos="word" morph="none" start_char="6197" end_char="6203">charges</TOKEN>
<TOKEN id="token-39-21" pos="word" morph="none" start_char="6205" end_char="6208">that</TOKEN>
<TOKEN id="token-39-22" pos="word" morph="none" start_char="6210" end_char="6214">allow</TOKEN>
<TOKEN id="token-39-23" pos="word" morph="none" start_char="6216" end_char="6226">authorities</TOKEN>
<TOKEN id="token-39-24" pos="word" morph="none" start_char="6228" end_char="6229">to</TOKEN>
<TOKEN id="token-39-25" pos="word" morph="none" start_char="6231" end_char="6238">imprison</TOKEN>
<TOKEN id="token-39-26" pos="word" morph="none" start_char="6240" end_char="6242">her</TOKEN>
<TOKEN id="token-39-27" pos="word" morph="none" start_char="6244" end_char="6246">for</TOKEN>
<TOKEN id="token-39-28" pos="word" morph="none" start_char="6248" end_char="6251">five</TOKEN>
<TOKEN id="token-39-29" pos="word" morph="none" start_char="6253" end_char="6257">years</TOKEN>
<TOKEN id="token-39-30" pos="punct" morph="none" start_char="6258" end_char="6258">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="6260" end_char="6369">
<ORIGINAL_TEXT>Fellow citizen journalists Chen Qiushi, Li Zehua, and Fang Bin were also detained for their coverage of Wuhan.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="6260" end_char="6265">Fellow</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="6267" end_char="6273">citizen</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="6275" end_char="6285">journalists</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="6287" end_char="6290">Chen</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="6292" end_char="6297">Qiushi</TOKEN>
<TOKEN id="token-40-5" pos="punct" morph="none" start_char="6298" end_char="6298">,</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="6300" end_char="6301">Li</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="6303" end_char="6307">Zehua</TOKEN>
<TOKEN id="token-40-8" pos="punct" morph="none" start_char="6308" end_char="6308">,</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="6310" end_char="6312">and</TOKEN>
<TOKEN id="token-40-10" pos="word" morph="none" start_char="6314" end_char="6317">Fang</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="6319" end_char="6321">Bin</TOKEN>
<TOKEN id="token-40-12" pos="word" morph="none" start_char="6323" end_char="6326">were</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="6328" end_char="6331">also</TOKEN>
<TOKEN id="token-40-14" pos="word" morph="none" start_char="6333" end_char="6340">detained</TOKEN>
<TOKEN id="token-40-15" pos="word" morph="none" start_char="6342" end_char="6344">for</TOKEN>
<TOKEN id="token-40-16" pos="word" morph="none" start_char="6346" end_char="6350">their</TOKEN>
<TOKEN id="token-40-17" pos="word" morph="none" start_char="6352" end_char="6359">coverage</TOKEN>
<TOKEN id="token-40-18" pos="word" morph="none" start_char="6361" end_char="6362">of</TOKEN>
<TOKEN id="token-40-19" pos="word" morph="none" start_char="6364" end_char="6368">Wuhan</TOKEN>
<TOKEN id="token-40-20" pos="punct" morph="none" start_char="6369" end_char="6369">.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="6371" end_char="6443">
<ORIGINAL_TEXT>Meanwhile, Chinese authorities allowed other narratives to spread freely.</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="6371" end_char="6379">Meanwhile</TOKEN>
<TOKEN id="token-41-1" pos="punct" morph="none" start_char="6380" end_char="6380">,</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="6382" end_char="6388">Chinese</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="6390" end_char="6400">authorities</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="6402" end_char="6408">allowed</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="6410" end_char="6414">other</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="6416" end_char="6425">narratives</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="6427" end_char="6428">to</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="6430" end_char="6435">spread</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="6437" end_char="6442">freely</TOKEN>
<TOKEN id="token-41-10" pos="punct" morph="none" start_char="6443" end_char="6443">.</TOKEN>
</SEG>
<SEG id="segment-42" start_char="6445" end_char="6586">
<ORIGINAL_TEXT>At The Financial Times, Christian Shepherd covered a provocative speech that tied nationalism to revisionist histories of the crisis in Wuhan:</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="6445" end_char="6446">At</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="6448" end_char="6450">The</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="6452" end_char="6460">Financial</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="6462" end_char="6466">Times</TOKEN>
<TOKEN id="token-42-4" pos="punct" morph="none" start_char="6467" end_char="6467">,</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="6469" end_char="6477">Christian</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="6479" end_char="6486">Shepherd</TOKEN>
<TOKEN id="token-42-7" pos="word" morph="none" start_char="6488" end_char="6494">covered</TOKEN>
<TOKEN id="token-42-8" pos="word" morph="none" start_char="6496" end_char="6496">a</TOKEN>
<TOKEN id="token-42-9" pos="word" morph="none" start_char="6498" end_char="6508">provocative</TOKEN>
<TOKEN id="token-42-10" pos="word" morph="none" start_char="6510" end_char="6515">speech</TOKEN>
<TOKEN id="token-42-11" pos="word" morph="none" start_char="6517" end_char="6520">that</TOKEN>
<TOKEN id="token-42-12" pos="word" morph="none" start_char="6522" end_char="6525">tied</TOKEN>
<TOKEN id="token-42-13" pos="word" morph="none" start_char="6527" end_char="6537">nationalism</TOKEN>
<TOKEN id="token-42-14" pos="word" morph="none" start_char="6539" end_char="6540">to</TOKEN>
<TOKEN id="token-42-15" pos="word" morph="none" start_char="6542" end_char="6552">revisionist</TOKEN>
<TOKEN id="token-42-16" pos="word" morph="none" start_char="6554" end_char="6562">histories</TOKEN>
<TOKEN id="token-42-17" pos="word" morph="none" start_char="6564" end_char="6565">of</TOKEN>
<TOKEN id="token-42-18" pos="word" morph="none" start_char="6567" end_char="6569">the</TOKEN>
<TOKEN id="token-42-19" pos="word" morph="none" start_char="6571" end_char="6576">crisis</TOKEN>
<TOKEN id="token-42-20" pos="word" morph="none" start_char="6578" end_char="6579">in</TOKEN>
<TOKEN id="token-42-21" pos="word" morph="none" start_char="6581" end_char="6585">Wuhan</TOKEN>
<TOKEN id="token-42-22" pos="punct" morph="none" start_char="6586" end_char="6586">:</TOKEN>
</SEG>
<SEG id="segment-43" start_char="6589" end_char="6783">
<ORIGINAL_TEXT>Li Yi, a nationalist commentator, told a conference in Shenzhen that, compared with the number of people who had died in the US, thousands of people dying in China was "the same as no one dying".</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="6589" end_char="6590">Li</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="6592" end_char="6593">Yi</TOKEN>
<TOKEN id="token-43-2" pos="punct" morph="none" start_char="6594" end_char="6594">,</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="6596" end_char="6596">a</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="6598" end_char="6608">nationalist</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="6610" end_char="6620">commentator</TOKEN>
<TOKEN id="token-43-6" pos="punct" morph="none" start_char="6621" end_char="6621">,</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="6623" end_char="6626">told</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="6628" end_char="6628">a</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="6630" end_char="6639">conference</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="6641" end_char="6642">in</TOKEN>
<TOKEN id="token-43-11" pos="word" morph="none" start_char="6644" end_char="6651">Shenzhen</TOKEN>
<TOKEN id="token-43-12" pos="word" morph="none" start_char="6653" end_char="6656">that</TOKEN>
<TOKEN id="token-43-13" pos="punct" morph="none" start_char="6657" end_char="6657">,</TOKEN>
<TOKEN id="token-43-14" pos="word" morph="none" start_char="6659" end_char="6666">compared</TOKEN>
<TOKEN id="token-43-15" pos="word" morph="none" start_char="6668" end_char="6671">with</TOKEN>
<TOKEN id="token-43-16" pos="word" morph="none" start_char="6673" end_char="6675">the</TOKEN>
<TOKEN id="token-43-17" pos="word" morph="none" start_char="6677" end_char="6682">number</TOKEN>
<TOKEN id="token-43-18" pos="word" morph="none" start_char="6684" end_char="6685">of</TOKEN>
<TOKEN id="token-43-19" pos="word" morph="none" start_char="6687" end_char="6692">people</TOKEN>
<TOKEN id="token-43-20" pos="word" morph="none" start_char="6694" end_char="6696">who</TOKEN>
<TOKEN id="token-43-21" pos="word" morph="none" start_char="6698" end_char="6700">had</TOKEN>
<TOKEN id="token-43-22" pos="word" morph="none" start_char="6702" end_char="6705">died</TOKEN>
<TOKEN id="token-43-23" pos="word" morph="none" start_char="6707" end_char="6708">in</TOKEN>
<TOKEN id="token-43-24" pos="word" morph="none" start_char="6710" end_char="6712">the</TOKEN>
<TOKEN id="token-43-25" pos="word" morph="none" start_char="6714" end_char="6715">US</TOKEN>
<TOKEN id="token-43-26" pos="punct" morph="none" start_char="6716" end_char="6716">,</TOKEN>
<TOKEN id="token-43-27" pos="word" morph="none" start_char="6718" end_char="6726">thousands</TOKEN>
<TOKEN id="token-43-28" pos="word" morph="none" start_char="6728" end_char="6729">of</TOKEN>
<TOKEN id="token-43-29" pos="word" morph="none" start_char="6731" end_char="6736">people</TOKEN>
<TOKEN id="token-43-30" pos="word" morph="none" start_char="6738" end_char="6742">dying</TOKEN>
<TOKEN id="token-43-31" pos="word" morph="none" start_char="6744" end_char="6745">in</TOKEN>
<TOKEN id="token-43-32" pos="word" morph="none" start_char="6747" end_char="6751">China</TOKEN>
<TOKEN id="token-43-33" pos="word" morph="none" start_char="6753" end_char="6755">was</TOKEN>
<TOKEN id="token-43-34" pos="punct" morph="none" start_char="6757" end_char="6757">"</TOKEN>
<TOKEN id="token-43-35" pos="word" morph="none" start_char="6758" end_char="6760">the</TOKEN>
<TOKEN id="token-43-36" pos="word" morph="none" start_char="6762" end_char="6765">same</TOKEN>
<TOKEN id="token-43-37" pos="word" morph="none" start_char="6767" end_char="6768">as</TOKEN>
<TOKEN id="token-43-38" pos="word" morph="none" start_char="6770" end_char="6771">no</TOKEN>
<TOKEN id="token-43-39" pos="word" morph="none" start_char="6773" end_char="6775">one</TOKEN>
<TOKEN id="token-43-40" pos="word" morph="none" start_char="6777" end_char="6781">dying</TOKEN>
<TOKEN id="token-43-41" pos="punct" morph="none" start_char="6782" end_char="6783">".</TOKEN>
</SEG>
<SEG id="segment-44" start_char="6785" end_char="7029">
<ORIGINAL_TEXT>Mr Li later defended himself against critics, writing on Weibo that the thrust of his speech was "patriotic" and had been "to extol the splendid success of China’s struggle against the epidemic, and to criticise the major failures of America’s".</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="6785" end_char="6786">Mr</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="6788" end_char="6789">Li</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="6791" end_char="6795">later</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="6797" end_char="6804">defended</TOKEN>
<TOKEN id="token-44-4" pos="word" morph="none" start_char="6806" end_char="6812">himself</TOKEN>
<TOKEN id="token-44-5" pos="word" morph="none" start_char="6814" end_char="6820">against</TOKEN>
<TOKEN id="token-44-6" pos="word" morph="none" start_char="6822" end_char="6828">critics</TOKEN>
<TOKEN id="token-44-7" pos="punct" morph="none" start_char="6829" end_char="6829">,</TOKEN>
<TOKEN id="token-44-8" pos="word" morph="none" start_char="6831" end_char="6837">writing</TOKEN>
<TOKEN id="token-44-9" pos="word" morph="none" start_char="6839" end_char="6840">on</TOKEN>
<TOKEN id="token-44-10" pos="word" morph="none" start_char="6842" end_char="6846">Weibo</TOKEN>
<TOKEN id="token-44-11" pos="word" morph="none" start_char="6848" end_char="6851">that</TOKEN>
<TOKEN id="token-44-12" pos="word" morph="none" start_char="6853" end_char="6855">the</TOKEN>
<TOKEN id="token-44-13" pos="word" morph="none" start_char="6857" end_char="6862">thrust</TOKEN>
<TOKEN id="token-44-14" pos="word" morph="none" start_char="6864" end_char="6865">of</TOKEN>
<TOKEN id="token-44-15" pos="word" morph="none" start_char="6867" end_char="6869">his</TOKEN>
<TOKEN id="token-44-16" pos="word" morph="none" start_char="6871" end_char="6876">speech</TOKEN>
<TOKEN id="token-44-17" pos="word" morph="none" start_char="6878" end_char="6880">was</TOKEN>
<TOKEN id="token-44-18" pos="punct" morph="none" start_char="6882" end_char="6882">"</TOKEN>
<TOKEN id="token-44-19" pos="word" morph="none" start_char="6883" end_char="6891">patriotic</TOKEN>
<TOKEN id="token-44-20" pos="punct" morph="none" start_char="6892" end_char="6892">"</TOKEN>
<TOKEN id="token-44-21" pos="word" morph="none" start_char="6894" end_char="6896">and</TOKEN>
<TOKEN id="token-44-22" pos="word" morph="none" start_char="6898" end_char="6900">had</TOKEN>
<TOKEN id="token-44-23" pos="word" morph="none" start_char="6902" end_char="6905">been</TOKEN>
<TOKEN id="token-44-24" pos="punct" morph="none" start_char="6907" end_char="6907">"</TOKEN>
<TOKEN id="token-44-25" pos="word" morph="none" start_char="6908" end_char="6909">to</TOKEN>
<TOKEN id="token-44-26" pos="word" morph="none" start_char="6911" end_char="6915">extol</TOKEN>
<TOKEN id="token-44-27" pos="word" morph="none" start_char="6917" end_char="6919">the</TOKEN>
<TOKEN id="token-44-28" pos="word" morph="none" start_char="6921" end_char="6928">splendid</TOKEN>
<TOKEN id="token-44-29" pos="word" morph="none" start_char="6930" end_char="6936">success</TOKEN>
<TOKEN id="token-44-30" pos="word" morph="none" start_char="6938" end_char="6939">of</TOKEN>
<TOKEN id="token-44-31" pos="word" morph="none" start_char="6941" end_char="6947">China’s</TOKEN>
<TOKEN id="token-44-32" pos="word" morph="none" start_char="6949" end_char="6956">struggle</TOKEN>
<TOKEN id="token-44-33" pos="word" morph="none" start_char="6958" end_char="6964">against</TOKEN>
<TOKEN id="token-44-34" pos="word" morph="none" start_char="6966" end_char="6968">the</TOKEN>
<TOKEN id="token-44-35" pos="word" morph="none" start_char="6970" end_char="6977">epidemic</TOKEN>
<TOKEN id="token-44-36" pos="punct" morph="none" start_char="6978" end_char="6978">,</TOKEN>
<TOKEN id="token-44-37" pos="word" morph="none" start_char="6980" end_char="6982">and</TOKEN>
<TOKEN id="token-44-38" pos="word" morph="none" start_char="6984" end_char="6985">to</TOKEN>
<TOKEN id="token-44-39" pos="word" morph="none" start_char="6987" end_char="6995">criticise</TOKEN>
<TOKEN id="token-44-40" pos="word" morph="none" start_char="6997" end_char="6999">the</TOKEN>
<TOKEN id="token-44-41" pos="word" morph="none" start_char="7001" end_char="7005">major</TOKEN>
<TOKEN id="token-44-42" pos="word" morph="none" start_char="7007" end_char="7014">failures</TOKEN>
<TOKEN id="token-44-43" pos="word" morph="none" start_char="7016" end_char="7017">of</TOKEN>
<TOKEN id="token-44-44" pos="word" morph="none" start_char="7019" end_char="7027">America’s</TOKEN>
<TOKEN id="token-44-45" pos="punct" morph="none" start_char="7028" end_char="7029">".</TOKEN>
</SEG>
<SEG id="segment-45" start_char="7031" end_char="7066">
<ORIGINAL_TEXT>His comments have not been censored.</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="7031" end_char="7033">His</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="7035" end_char="7042">comments</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="7044" end_char="7047">have</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="7049" end_char="7051">not</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="7053" end_char="7056">been</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="7058" end_char="7065">censored</TOKEN>
<TOKEN id="token-45-6" pos="punct" morph="none" start_char="7066" end_char="7066">.</TOKEN>
</SEG>
<SEG id="segment-46" start_char="7068" end_char="7075">
<ORIGINAL_TEXT>[Source]</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="punct" morph="none" start_char="7068" end_char="7068">[</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="7069" end_char="7074">Source</TOKEN>
<TOKEN id="token-46-2" pos="punct" morph="none" start_char="7075" end_char="7075">]</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
