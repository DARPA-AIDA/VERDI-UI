<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATS3" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="3769" raw_text_md5="6dba063146a80974ce06b51150d23337">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="81">
<ORIGINAL_TEXT>No, un vídeo de la RAI no prueba que el coronavirus fuese creado en China en 2015</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="2">No</TOKEN>
<TOKEN id="token-0-1" pos="punct" morph="none" start_char="3" end_char="3">,</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="5" end_char="6">un</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="8" end_char="12">vídeo</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="14" end_char="15">de</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="17" end_char="18">la</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="20" end_char="22">RAI</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="24" end_char="25">no</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="27" end_char="32">prueba</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="34" end_char="36">que</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="38" end_char="39">el</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="41" end_char="51">coronavirus</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="53" end_char="57">fuese</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="59" end_char="64">creado</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="66" end_char="67">en</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="69" end_char="73">China</TOKEN>
<TOKEN id="token-0-16" pos="word" morph="none" start_char="75" end_char="76">en</TOKEN>
<TOKEN id="token-0-17" pos="word" morph="none" start_char="78" end_char="81">2015</TOKEN>
</SEG>
<SEG id="segment-1" start_char="85" end_char="147">
<ORIGINAL_TEXT>Vídeo del programa de la RAI que se ha viralizado por WhatsApp.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="85" end_char="89">Vídeo</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="91" end_char="93">del</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="95" end_char="102">programa</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="104" end_char="105">de</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="107" end_char="108">la</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="110" end_char="112">RAI</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="114" end_char="116">que</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="118" end_char="119">se</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="121" end_char="122">ha</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="124" end_char="133">viralizado</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="135" end_char="137">por</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="139" end_char="146">WhatsApp</TOKEN>
<TOKEN id="token-1-12" pos="punct" morph="none" start_char="147" end_char="147">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="149" end_char="158">
<ORIGINAL_TEXT>Foto: EiTB</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="149" end_char="152">Foto</TOKEN>
<TOKEN id="token-2-1" pos="punct" morph="none" start_char="153" end_char="153">:</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="155" end_char="158">EiTB</TOKEN>
</SEG>
<SEG id="segment-3" start_char="162" end_char="423">
<ORIGINAL_TEXT>En los últimos días se ha viralizado por WhatsApp un vídeo extraído de un programa emitido en noviembre de 2015 por la RAI, la televisión pública italiana, en el que se habla de un coronavirus creado en un laboratorio de China y que podría afectar a los humanos.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="162" end_char="163">En</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="165" end_char="167">los</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="169" end_char="175">últimos</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="177" end_char="180">días</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="182" end_char="183">se</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="185" end_char="186">ha</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="188" end_char="197">viralizado</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="199" end_char="201">por</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="203" end_char="210">WhatsApp</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="212" end_char="213">un</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="215" end_char="219">vídeo</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="221" end_char="228">extraído</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="230" end_char="231">de</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="233" end_char="234">un</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="236" end_char="243">programa</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="245" end_char="251">emitido</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="253" end_char="254">en</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="256" end_char="264">noviembre</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="266" end_char="267">de</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="269" end_char="272">2015</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="274" end_char="276">por</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="278" end_char="279">la</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="281" end_char="283">RAI</TOKEN>
<TOKEN id="token-3-23" pos="punct" morph="none" start_char="284" end_char="284">,</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="286" end_char="287">la</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="289" end_char="298">televisión</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="300" end_char="306">pública</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="308" end_char="315">italiana</TOKEN>
<TOKEN id="token-3-28" pos="punct" morph="none" start_char="316" end_char="316">,</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="318" end_char="319">en</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="321" end_char="322">el</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="324" end_char="326">que</TOKEN>
<TOKEN id="token-3-32" pos="word" morph="none" start_char="328" end_char="329">se</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="331" end_char="335">habla</TOKEN>
<TOKEN id="token-3-34" pos="word" morph="none" start_char="337" end_char="338">de</TOKEN>
<TOKEN id="token-3-35" pos="word" morph="none" start_char="340" end_char="341">un</TOKEN>
<TOKEN id="token-3-36" pos="word" morph="none" start_char="343" end_char="353">coronavirus</TOKEN>
<TOKEN id="token-3-37" pos="word" morph="none" start_char="355" end_char="360">creado</TOKEN>
<TOKEN id="token-3-38" pos="word" morph="none" start_char="362" end_char="363">en</TOKEN>
<TOKEN id="token-3-39" pos="word" morph="none" start_char="365" end_char="366">un</TOKEN>
<TOKEN id="token-3-40" pos="word" morph="none" start_char="368" end_char="378">laboratorio</TOKEN>
<TOKEN id="token-3-41" pos="word" morph="none" start_char="380" end_char="381">de</TOKEN>
<TOKEN id="token-3-42" pos="word" morph="none" start_char="383" end_char="387">China</TOKEN>
<TOKEN id="token-3-43" pos="word" morph="none" start_char="389" end_char="389">y</TOKEN>
<TOKEN id="token-3-44" pos="word" morph="none" start_char="391" end_char="393">que</TOKEN>
<TOKEN id="token-3-45" pos="word" morph="none" start_char="395" end_char="400">podría</TOKEN>
<TOKEN id="token-3-46" pos="word" morph="none" start_char="402" end_char="408">afectar</TOKEN>
<TOKEN id="token-3-47" pos="word" morph="none" start_char="410" end_char="410">a</TOKEN>
<TOKEN id="token-3-48" pos="word" morph="none" start_char="412" end_char="414">los</TOKEN>
<TOKEN id="token-3-49" pos="word" morph="none" start_char="416" end_char="422">humanos</TOKEN>
<TOKEN id="token-3-50" pos="punct" morph="none" start_char="423" end_char="423">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="425" end_char="594">
<ORIGINAL_TEXT>El vídeo ha tenido gran repercusión en las redes sociales por las supuestas similitudes que se dan con el virus SARS-CoV-2, causante de la actual pandemia de la COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="425" end_char="426">El</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="428" end_char="432">vídeo</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="434" end_char="435">ha</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="437" end_char="442">tenido</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="444" end_char="447">gran</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="449" end_char="459">repercusión</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="461" end_char="462">en</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="464" end_char="466">las</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="468" end_char="472">redes</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="474" end_char="481">sociales</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="483" end_char="485">por</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="487" end_char="489">las</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="491" end_char="499">supuestas</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="501" end_char="511">similitudes</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="513" end_char="515">que</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="517" end_char="518">se</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="520" end_char="522">dan</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="524" end_char="526">con</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="528" end_char="529">el</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="531" end_char="535">virus</TOKEN>
<TOKEN id="token-4-20" pos="unknown" morph="none" start_char="537" end_char="546">SARS-CoV-2</TOKEN>
<TOKEN id="token-4-21" pos="punct" morph="none" start_char="547" end_char="547">,</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="549" end_char="556">causante</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="558" end_char="559">de</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="561" end_char="562">la</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="564" end_char="569">actual</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="571" end_char="578">pandemia</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="580" end_char="581">de</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="583" end_char="584">la</TOKEN>
<TOKEN id="token-4-29" pos="unknown" morph="none" start_char="586" end_char="593">COVID-19</TOKEN>
<TOKEN id="token-4-30" pos="punct" morph="none" start_char="594" end_char="594">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="597" end_char="791">
<ORIGINAL_TEXT>Han sido muchos los usuarios que se han puesto en contacto con el 600 900 454, el WhatsApp de la iniciativa de EiTB para frenar los #Coronabulos advirtiendo de la existencia del citado contenido.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="597" end_char="599">Han</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="601" end_char="604">sido</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="606" end_char="611">muchos</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="613" end_char="615">los</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="617" end_char="624">usuarios</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="626" end_char="628">que</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="630" end_char="631">se</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="633" end_char="635">han</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="637" end_char="642">puesto</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="644" end_char="645">en</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="647" end_char="654">contacto</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="656" end_char="658">con</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="660" end_char="661">el</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="663" end_char="665">600</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="667" end_char="669">900</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="671" end_char="673">454</TOKEN>
<TOKEN id="token-5-16" pos="punct" morph="none" start_char="674" end_char="674">,</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="676" end_char="677">el</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="679" end_char="686">WhatsApp</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="688" end_char="689">de</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="691" end_char="692">la</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="694" end_char="703">iniciativa</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="705" end_char="706">de</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="708" end_char="711">EiTB</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="713" end_char="716">para</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="718" end_char="723">frenar</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="725" end_char="727">los</TOKEN>
<TOKEN id="token-5-27" pos="tag" morph="none" start_char="729" end_char="740">#Coronabulos</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="742" end_char="752">advirtiendo</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="754" end_char="755">de</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="757" end_char="758">la</TOKEN>
<TOKEN id="token-5-31" pos="word" morph="none" start_char="760" end_char="769">existencia</TOKEN>
<TOKEN id="token-5-32" pos="word" morph="none" start_char="771" end_char="773">del</TOKEN>
<TOKEN id="token-5-33" pos="word" morph="none" start_char="775" end_char="780">citado</TOKEN>
<TOKEN id="token-5-34" pos="word" morph="none" start_char="782" end_char="790">contenido</TOKEN>
<TOKEN id="token-5-35" pos="punct" morph="none" start_char="791" end_char="791">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="794" end_char="954">
<ORIGINAL_TEXT>La página web Maldita.es (a través de su sección Maldito Bulo), con quien Euskal Irrati Telebista está en contacto estos días para colaborar en poner freno a las</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="794" end_char="795">La</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="797" end_char="802">página</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="804" end_char="806">web</TOKEN>
<TOKEN id="token-6-3" pos="unknown" morph="none" start_char="808" end_char="817">Maldita.es</TOKEN>
<TOKEN id="token-6-4" pos="punct" morph="none" start_char="819" end_char="819">(</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="820" end_char="820">a</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="822" end_char="827">través</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="829" end_char="830">de</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="832" end_char="833">su</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="835" end_char="841">sección</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="843" end_char="849">Maldito</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="851" end_char="854">Bulo</TOKEN>
<TOKEN id="token-6-12" pos="punct" morph="none" start_char="855" end_char="856">),</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="858" end_char="860">con</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="862" end_char="866">quien</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="868" end_char="873">Euskal</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="875" end_char="880">Irrati</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="882" end_char="890">Telebista</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="892" end_char="895">está</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="897" end_char="898">en</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="900" end_char="907">contacto</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="909" end_char="913">estos</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="915" end_char="918">días</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="920" end_char="923">para</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="925" end_char="933">colaborar</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="935" end_char="936">en</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="938" end_char="942">poner</TOKEN>
<TOKEN id="token-6-27" pos="word" morph="none" start_char="944" end_char="948">freno</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="950" end_char="950">a</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="952" end_char="954">las</TOKEN>
</SEG>
<SEG id="segment-7" start_char="957" end_char="965">
<ORIGINAL_TEXT>fake news</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="957" end_char="960">fake</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="962" end_char="965">news</TOKEN>
</SEG>
<SEG id="segment-8" start_char="968" end_char="1174">
<ORIGINAL_TEXT>sobre el coronavirus, ya ha tratado este tema, y considera que nos encontramos ante un bulo puesto que "no hay ninguna evidencia científica" que haga suponer que el coronavirus haya sido obra del ser humano.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="968" end_char="972">sobre</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="974" end_char="975">el</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="977" end_char="987">coronavirus</TOKEN>
<TOKEN id="token-8-3" pos="punct" morph="none" start_char="988" end_char="988">,</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="990" end_char="991">ya</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="993" end_char="994">ha</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="996" end_char="1002">tratado</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1004" end_char="1007">este</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1009" end_char="1012">tema</TOKEN>
<TOKEN id="token-8-9" pos="punct" morph="none" start_char="1013" end_char="1013">,</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1015" end_char="1015">y</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1017" end_char="1025">considera</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1027" end_char="1029">que</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1031" end_char="1033">nos</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1035" end_char="1045">encontramos</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1047" end_char="1050">ante</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1052" end_char="1053">un</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1055" end_char="1058">bulo</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1060" end_char="1065">puesto</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1067" end_char="1069">que</TOKEN>
<TOKEN id="token-8-20" pos="punct" morph="none" start_char="1071" end_char="1071">"</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="1072" end_char="1073">no</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="1075" end_char="1077">hay</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="1079" end_char="1085">ninguna</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="1087" end_char="1095">evidencia</TOKEN>
<TOKEN id="token-8-25" pos="word" morph="none" start_char="1097" end_char="1106">científica</TOKEN>
<TOKEN id="token-8-26" pos="punct" morph="none" start_char="1107" end_char="1107">"</TOKEN>
<TOKEN id="token-8-27" pos="word" morph="none" start_char="1109" end_char="1111">que</TOKEN>
<TOKEN id="token-8-28" pos="word" morph="none" start_char="1113" end_char="1116">haga</TOKEN>
<TOKEN id="token-8-29" pos="word" morph="none" start_char="1118" end_char="1124">suponer</TOKEN>
<TOKEN id="token-8-30" pos="word" morph="none" start_char="1126" end_char="1128">que</TOKEN>
<TOKEN id="token-8-31" pos="word" morph="none" start_char="1130" end_char="1131">el</TOKEN>
<TOKEN id="token-8-32" pos="word" morph="none" start_char="1133" end_char="1143">coronavirus</TOKEN>
<TOKEN id="token-8-33" pos="word" morph="none" start_char="1145" end_char="1148">haya</TOKEN>
<TOKEN id="token-8-34" pos="word" morph="none" start_char="1150" end_char="1153">sido</TOKEN>
<TOKEN id="token-8-35" pos="word" morph="none" start_char="1155" end_char="1158">obra</TOKEN>
<TOKEN id="token-8-36" pos="word" morph="none" start_char="1160" end_char="1162">del</TOKEN>
<TOKEN id="token-8-37" pos="word" morph="none" start_char="1164" end_char="1166">ser</TOKEN>
<TOKEN id="token-8-38" pos="word" morph="none" start_char="1168" end_char="1173">humano</TOKEN>
<TOKEN id="token-8-39" pos="punct" morph="none" start_char="1174" end_char="1174">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1177" end_char="1248">
<ORIGINAL_TEXT>Estos son los datos recogidos y contrastados por el equipo de Maldita.es</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1177" end_char="1181">Estos</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1183" end_char="1185">son</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1187" end_char="1189">los</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1191" end_char="1195">datos</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1197" end_char="1205">recogidos</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1207" end_char="1207">y</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1209" end_char="1220">contrastados</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1222" end_char="1224">por</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1226" end_char="1227">el</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1229" end_char="1234">equipo</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1236" end_char="1237">de</TOKEN>
<TOKEN id="token-9-11" pos="unknown" morph="none" start_char="1239" end_char="1248">Maldita.es</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1251" end_char="1251">
<ORIGINAL_TEXT>:</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="punct" morph="none" start_char="1251" end_char="1251">:</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1254" end_char="1302">
<ORIGINAL_TEXT>El 12 de noviembre de 2015, la revista científica</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1254" end_char="1255">El</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1257" end_char="1258">12</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1260" end_char="1261">de</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1263" end_char="1271">noviembre</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1273" end_char="1274">de</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1276" end_char="1279">2015</TOKEN>
<TOKEN id="token-11-6" pos="punct" morph="none" start_char="1280" end_char="1280">,</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1282" end_char="1283">la</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1285" end_char="1291">revista</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1293" end_char="1302">científica</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1305" end_char="1310">
<ORIGINAL_TEXT>Nature</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1305" end_char="1310">Nature</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1313" end_char="1549">
<ORIGINAL_TEXT>publicó un artículo sobre los hallazgos de un grupo de investigación que había sido capaz de "infectar con coronavirus de murciélago directamente a los humanos (en lugar de necesitar evolucionar primero en un huésped animal intermedio)".</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1313" end_char="1319">publicó</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1321" end_char="1322">un</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1324" end_char="1331">artículo</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1333" end_char="1337">sobre</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1339" end_char="1341">los</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1343" end_char="1351">hallazgos</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1353" end_char="1354">de</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1356" end_char="1357">un</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1359" end_char="1363">grupo</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1365" end_char="1366">de</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1368" end_char="1380">investigación</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1382" end_char="1384">que</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1386" end_char="1390">había</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1392" end_char="1395">sido</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1397" end_char="1401">capaz</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1403" end_char="1404">de</TOKEN>
<TOKEN id="token-13-16" pos="punct" morph="none" start_char="1406" end_char="1406">"</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1407" end_char="1414">infectar</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1416" end_char="1418">con</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1420" end_char="1430">coronavirus</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1432" end_char="1433">de</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="1435" end_char="1444">murciélago</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="1446" end_char="1457">directamente</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="1459" end_char="1459">a</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="1461" end_char="1463">los</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="1465" end_char="1471">humanos</TOKEN>
<TOKEN id="token-13-26" pos="punct" morph="none" start_char="1473" end_char="1473">(</TOKEN>
<TOKEN id="token-13-27" pos="word" morph="none" start_char="1474" end_char="1475">en</TOKEN>
<TOKEN id="token-13-28" pos="word" morph="none" start_char="1477" end_char="1481">lugar</TOKEN>
<TOKEN id="token-13-29" pos="word" morph="none" start_char="1483" end_char="1484">de</TOKEN>
<TOKEN id="token-13-30" pos="word" morph="none" start_char="1486" end_char="1494">necesitar</TOKEN>
<TOKEN id="token-13-31" pos="word" morph="none" start_char="1496" end_char="1506">evolucionar</TOKEN>
<TOKEN id="token-13-32" pos="word" morph="none" start_char="1508" end_char="1514">primero</TOKEN>
<TOKEN id="token-13-33" pos="word" morph="none" start_char="1516" end_char="1517">en</TOKEN>
<TOKEN id="token-13-34" pos="word" morph="none" start_char="1519" end_char="1520">un</TOKEN>
<TOKEN id="token-13-35" pos="word" morph="none" start_char="1522" end_char="1528">huésped</TOKEN>
<TOKEN id="token-13-36" pos="word" morph="none" start_char="1530" end_char="1535">animal</TOKEN>
<TOKEN id="token-13-37" pos="word" morph="none" start_char="1537" end_char="1546">intermedio</TOKEN>
<TOKEN id="token-13-38" pos="punct" morph="none" start_char="1547" end_char="1549">)".</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1552" end_char="1678">
<ORIGINAL_TEXT>Cuatro días más tarde, el 16 de noviembre de 2015, la RAI emitió, dentro de su programa especializado en información científica</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1552" end_char="1557">Cuatro</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1559" end_char="1562">días</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1564" end_char="1566">más</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1568" end_char="1572">tarde</TOKEN>
<TOKEN id="token-14-4" pos="punct" morph="none" start_char="1573" end_char="1573">,</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1575" end_char="1576">el</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1578" end_char="1579">16</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1581" end_char="1582">de</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1584" end_char="1592">noviembre</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1594" end_char="1595">de</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1597" end_char="1600">2015</TOKEN>
<TOKEN id="token-14-11" pos="punct" morph="none" start_char="1601" end_char="1601">,</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1603" end_char="1604">la</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1606" end_char="1608">RAI</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="1610" end_char="1615">emitió</TOKEN>
<TOKEN id="token-14-15" pos="punct" morph="none" start_char="1616" end_char="1616">,</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1618" end_char="1623">dentro</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="1625" end_char="1626">de</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="1628" end_char="1629">su</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="1631" end_char="1638">programa</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="1640" end_char="1652">especializado</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="1654" end_char="1655">en</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="1657" end_char="1667">información</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="1669" end_char="1678">científica</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1681" end_char="1692">
<ORIGINAL_TEXT>TGR Leonardo</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1681" end_char="1683">TGR</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1685" end_char="1692">Leonardo</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1695" end_char="1986">
<ORIGINAL_TEXT>, un reportaje sobre un estudio desarrollado por un grupo de investigadores chinos que habrían creado artificialmente un "supervirus" que causa SARS (Síndrome Respiratorio Agudo Grave) capaz de "traspasarse a los humanos directamente desde un murciélago sin pasar por una especie intermedia".</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="punct" morph="none" start_char="1695" end_char="1695">,</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1697" end_char="1698">un</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1700" end_char="1708">reportaje</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1710" end_char="1714">sobre</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1716" end_char="1717">un</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1719" end_char="1725">estudio</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1727" end_char="1738">desarrollado</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1740" end_char="1742">por</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1744" end_char="1745">un</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="1747" end_char="1751">grupo</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="1753" end_char="1754">de</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="1756" end_char="1769">investigadores</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="1771" end_char="1776">chinos</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="1778" end_char="1780">que</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="1782" end_char="1788">habrían</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="1790" end_char="1795">creado</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="1797" end_char="1811">artificialmente</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="1813" end_char="1814">un</TOKEN>
<TOKEN id="token-16-18" pos="punct" morph="none" start_char="1816" end_char="1816">"</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="1817" end_char="1826">supervirus</TOKEN>
<TOKEN id="token-16-20" pos="punct" morph="none" start_char="1827" end_char="1827">"</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="1829" end_char="1831">que</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="1833" end_char="1837">causa</TOKEN>
<TOKEN id="token-16-23" pos="word" morph="none" start_char="1839" end_char="1842">SARS</TOKEN>
<TOKEN id="token-16-24" pos="punct" morph="none" start_char="1844" end_char="1844">(</TOKEN>
<TOKEN id="token-16-25" pos="word" morph="none" start_char="1845" end_char="1852">Síndrome</TOKEN>
<TOKEN id="token-16-26" pos="word" morph="none" start_char="1854" end_char="1865">Respiratorio</TOKEN>
<TOKEN id="token-16-27" pos="word" morph="none" start_char="1867" end_char="1871">Agudo</TOKEN>
<TOKEN id="token-16-28" pos="word" morph="none" start_char="1873" end_char="1877">Grave</TOKEN>
<TOKEN id="token-16-29" pos="punct" morph="none" start_char="1878" end_char="1878">)</TOKEN>
<TOKEN id="token-16-30" pos="word" morph="none" start_char="1880" end_char="1884">capaz</TOKEN>
<TOKEN id="token-16-31" pos="word" morph="none" start_char="1886" end_char="1887">de</TOKEN>
<TOKEN id="token-16-32" pos="punct" morph="none" start_char="1889" end_char="1889">"</TOKEN>
<TOKEN id="token-16-33" pos="word" morph="none" start_char="1890" end_char="1900">traspasarse</TOKEN>
<TOKEN id="token-16-34" pos="word" morph="none" start_char="1902" end_char="1902">a</TOKEN>
<TOKEN id="token-16-35" pos="word" morph="none" start_char="1904" end_char="1906">los</TOKEN>
<TOKEN id="token-16-36" pos="word" morph="none" start_char="1908" end_char="1914">humanos</TOKEN>
<TOKEN id="token-16-37" pos="word" morph="none" start_char="1916" end_char="1927">directamente</TOKEN>
<TOKEN id="token-16-38" pos="word" morph="none" start_char="1929" end_char="1933">desde</TOKEN>
<TOKEN id="token-16-39" pos="word" morph="none" start_char="1935" end_char="1936">un</TOKEN>
<TOKEN id="token-16-40" pos="word" morph="none" start_char="1938" end_char="1947">murciélago</TOKEN>
<TOKEN id="token-16-41" pos="word" morph="none" start_char="1949" end_char="1951">sin</TOKEN>
<TOKEN id="token-16-42" pos="word" morph="none" start_char="1953" end_char="1957">pasar</TOKEN>
<TOKEN id="token-16-43" pos="word" morph="none" start_char="1959" end_char="1961">por</TOKEN>
<TOKEN id="token-16-44" pos="word" morph="none" start_char="1963" end_char="1965">una</TOKEN>
<TOKEN id="token-16-45" pos="word" morph="none" start_char="1967" end_char="1973">especie</TOKEN>
<TOKEN id="token-16-46" pos="word" morph="none" start_char="1975" end_char="1984">intermedia</TOKEN>
<TOKEN id="token-16-47" pos="punct" morph="none" start_char="1985" end_char="1986">".</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1988" end_char="2089">
<ORIGINAL_TEXT>El citado reportaje sigue actualmente accesible en la página web de la RAI (a partir del minuto 4:55).</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1988" end_char="1989">El</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1991" end_char="1996">citado</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="1998" end_char="2006">reportaje</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2008" end_char="2012">sigue</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2014" end_char="2024">actualmente</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2026" end_char="2034">accesible</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2036" end_char="2037">en</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2039" end_char="2040">la</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2042" end_char="2047">página</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2049" end_char="2051">web</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2053" end_char="2054">de</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2056" end_char="2057">la</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2059" end_char="2061">RAI</TOKEN>
<TOKEN id="token-17-13" pos="punct" morph="none" start_char="2063" end_char="2063">(</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2064" end_char="2064">a</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2066" end_char="2071">partir</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="2073" end_char="2075">del</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="2077" end_char="2082">minuto</TOKEN>
<TOKEN id="token-17-18" pos="unknown" morph="none" start_char="2084" end_char="2087">4:55</TOKEN>
<TOKEN id="token-17-19" pos="punct" morph="none" start_char="2088" end_char="2089">).</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2092" end_char="2104">
<ORIGINAL_TEXT>Aclaración de</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2092" end_char="2101">Aclaración</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2103" end_char="2104">de</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2107" end_char="2112">
<ORIGINAL_TEXT>Nature</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2107" end_char="2112">Nature</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2116" end_char="2183">
<ORIGINAL_TEXT>Ante los acontecimientos ocurridos en las últimas fechas, la revista</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2116" end_char="2119">Ante</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2121" end_char="2123">los</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2125" end_char="2139">acontecimientos</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2141" end_char="2149">ocurridos</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2151" end_char="2152">en</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2154" end_char="2156">las</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2158" end_char="2164">últimas</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2166" end_char="2171">fechas</TOKEN>
<TOKEN id="token-20-8" pos="punct" morph="none" start_char="2172" end_char="2172">,</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2174" end_char="2175">la</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2177" end_char="2183">revista</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2186" end_char="2191">
<ORIGINAL_TEXT>Nature</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2186" end_char="2191">Nature</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2194" end_char="2371">
<ORIGINAL_TEXT>añadió recientemente una nota aclaratoria en la parte superior del artículo en la que se indica que el coronavirus del que hablan en el mismo no se corresponde con el SARS-CoV-2.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2194" end_char="2199">añadió</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2201" end_char="2213">recientemente</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2215" end_char="2217">una</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2219" end_char="2222">nota</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2224" end_char="2234">aclaratoria</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2236" end_char="2237">en</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2239" end_char="2240">la</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2242" end_char="2246">parte</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="2248" end_char="2255">superior</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="2257" end_char="2259">del</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="2261" end_char="2268">artículo</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="2270" end_char="2271">en</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="2273" end_char="2274">la</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="2276" end_char="2278">que</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="2280" end_char="2281">se</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="2283" end_char="2288">indica</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="2290" end_char="2292">que</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="2294" end_char="2295">el</TOKEN>
<TOKEN id="token-22-18" pos="word" morph="none" start_char="2297" end_char="2307">coronavirus</TOKEN>
<TOKEN id="token-22-19" pos="word" morph="none" start_char="2309" end_char="2311">del</TOKEN>
<TOKEN id="token-22-20" pos="word" morph="none" start_char="2313" end_char="2315">que</TOKEN>
<TOKEN id="token-22-21" pos="word" morph="none" start_char="2317" end_char="2322">hablan</TOKEN>
<TOKEN id="token-22-22" pos="word" morph="none" start_char="2324" end_char="2325">en</TOKEN>
<TOKEN id="token-22-23" pos="word" morph="none" start_char="2327" end_char="2328">el</TOKEN>
<TOKEN id="token-22-24" pos="word" morph="none" start_char="2330" end_char="2334">mismo</TOKEN>
<TOKEN id="token-22-25" pos="word" morph="none" start_char="2336" end_char="2337">no</TOKEN>
<TOKEN id="token-22-26" pos="word" morph="none" start_char="2339" end_char="2340">se</TOKEN>
<TOKEN id="token-22-27" pos="word" morph="none" start_char="2342" end_char="2352">corresponde</TOKEN>
<TOKEN id="token-22-28" pos="word" morph="none" start_char="2354" end_char="2356">con</TOKEN>
<TOKEN id="token-22-29" pos="word" morph="none" start_char="2358" end_char="2359">el</TOKEN>
<TOKEN id="token-22-30" pos="unknown" morph="none" start_char="2361" end_char="2370">SARS-CoV-2</TOKEN>
<TOKEN id="token-22-31" pos="punct" morph="none" start_char="2371" end_char="2371">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2374" end_char="2567">
<ORIGINAL_TEXT>La nota dice así: "Somos conscientes de que esta cuestión se está utilizando como base para teorías no verificadas de que el nuevo coronavirus que causa la COVID-19 fue diseñado artificialmente.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2374" end_char="2375">La</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2377" end_char="2380">nota</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2382" end_char="2385">dice</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2387" end_char="2389">así</TOKEN>
<TOKEN id="token-23-4" pos="punct" morph="none" start_char="2390" end_char="2390">:</TOKEN>
<TOKEN id="token-23-5" pos="punct" morph="none" start_char="2392" end_char="2392">"</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="2393" end_char="2397">Somos</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="2399" end_char="2409">conscientes</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="2411" end_char="2412">de</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="2414" end_char="2416">que</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="2418" end_char="2421">esta</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="2423" end_char="2430">cuestión</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="2432" end_char="2433">se</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="2435" end_char="2438">está</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="2440" end_char="2449">utilizando</TOKEN>
<TOKEN id="token-23-15" pos="word" morph="none" start_char="2451" end_char="2454">como</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="2456" end_char="2459">base</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="2461" end_char="2464">para</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="2466" end_char="2472">teorías</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="2474" end_char="2475">no</TOKEN>
<TOKEN id="token-23-20" pos="word" morph="none" start_char="2477" end_char="2487">verificadas</TOKEN>
<TOKEN id="token-23-21" pos="word" morph="none" start_char="2489" end_char="2490">de</TOKEN>
<TOKEN id="token-23-22" pos="word" morph="none" start_char="2492" end_char="2494">que</TOKEN>
<TOKEN id="token-23-23" pos="word" morph="none" start_char="2496" end_char="2497">el</TOKEN>
<TOKEN id="token-23-24" pos="word" morph="none" start_char="2499" end_char="2503">nuevo</TOKEN>
<TOKEN id="token-23-25" pos="word" morph="none" start_char="2505" end_char="2515">coronavirus</TOKEN>
<TOKEN id="token-23-26" pos="word" morph="none" start_char="2517" end_char="2519">que</TOKEN>
<TOKEN id="token-23-27" pos="word" morph="none" start_char="2521" end_char="2525">causa</TOKEN>
<TOKEN id="token-23-28" pos="word" morph="none" start_char="2527" end_char="2528">la</TOKEN>
<TOKEN id="token-23-29" pos="unknown" morph="none" start_char="2530" end_char="2537">COVID-19</TOKEN>
<TOKEN id="token-23-30" pos="word" morph="none" start_char="2539" end_char="2541">fue</TOKEN>
<TOKEN id="token-23-31" pos="word" morph="none" start_char="2543" end_char="2550">diseñado</TOKEN>
<TOKEN id="token-23-32" pos="word" morph="none" start_char="2552" end_char="2566">artificialmente</TOKEN>
<TOKEN id="token-23-33" pos="punct" morph="none" start_char="2567" end_char="2567">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2569" end_char="2607">
<ORIGINAL_TEXT>No hay evidencia de que eso sea cierto.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="2569" end_char="2570">No</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="2572" end_char="2574">hay</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="2576" end_char="2584">evidencia</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="2586" end_char="2587">de</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="2589" end_char="2591">que</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="2593" end_char="2595">eso</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="2597" end_char="2599">sea</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="2601" end_char="2606">cierto</TOKEN>
<TOKEN id="token-24-8" pos="punct" morph="none" start_char="2607" end_char="2607">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2609" end_char="2687">
<ORIGINAL_TEXT>Los científicos creen que un animal es la fuente más probable del coronavirus".</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="2609" end_char="2611">Los</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="2613" end_char="2623">científicos</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="2625" end_char="2629">creen</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="2631" end_char="2633">que</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="2635" end_char="2636">un</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="2638" end_char="2643">animal</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="2645" end_char="2646">es</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="2648" end_char="2649">la</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="2651" end_char="2656">fuente</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="2658" end_char="2660">más</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="2662" end_char="2669">probable</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="2671" end_char="2673">del</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="2675" end_char="2685">coronavirus</TOKEN>
<TOKEN id="token-25-13" pos="punct" morph="none" start_char="2686" end_char="2687">".</TOKEN>
</SEG>
<SEG id="segment-26" start_char="2690" end_char="2734">
<ORIGINAL_TEXT>Descartan el origen artificial del SARS-CoV-2</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="2690" end_char="2698">Descartan</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="2700" end_char="2701">el</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="2703" end_char="2708">origen</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="2710" end_char="2719">artificial</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="2721" end_char="2723">del</TOKEN>
<TOKEN id="token-26-5" pos="unknown" morph="none" start_char="2725" end_char="2734">SARS-CoV-2</TOKEN>
</SEG>
<SEG id="segment-27" start_char="2738" end_char="2889">
<ORIGINAL_TEXT>Así, han sido múltiples las publicaciones científicas que se han posicionado en contra de las teorías que defienden el origen artificial del SARS-CoV-2.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="2738" end_char="2740">Así</TOKEN>
<TOKEN id="token-27-1" pos="punct" morph="none" start_char="2741" end_char="2741">,</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="2743" end_char="2745">han</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="2747" end_char="2750">sido</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="2752" end_char="2760">múltiples</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="2762" end_char="2764">las</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="2766" end_char="2778">publicaciones</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="2780" end_char="2790">científicas</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="2792" end_char="2794">que</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="2796" end_char="2797">se</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="2799" end_char="2801">han</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="2803" end_char="2813">posicionado</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="2815" end_char="2816">en</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="2818" end_char="2823">contra</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="2825" end_char="2826">de</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="2828" end_char="2830">las</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="2832" end_char="2838">teorías</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="2840" end_char="2842">que</TOKEN>
<TOKEN id="token-27-18" pos="word" morph="none" start_char="2844" end_char="2852">defienden</TOKEN>
<TOKEN id="token-27-19" pos="word" morph="none" start_char="2854" end_char="2855">el</TOKEN>
<TOKEN id="token-27-20" pos="word" morph="none" start_char="2857" end_char="2862">origen</TOKEN>
<TOKEN id="token-27-21" pos="word" morph="none" start_char="2864" end_char="2873">artificial</TOKEN>
<TOKEN id="token-27-22" pos="word" morph="none" start_char="2875" end_char="2877">del</TOKEN>
<TOKEN id="token-27-23" pos="unknown" morph="none" start_char="2879" end_char="2888">SARS-CoV-2</TOKEN>
<TOKEN id="token-27-24" pos="punct" morph="none" start_char="2889" end_char="2889">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="2892" end_char="3035">
<ORIGINAL_TEXT>De esta manera, científicos especializados en salud pública que han seguido de cerca la crisis del nuevo coronavirus publicaron un comunicado en</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="2892" end_char="2893">De</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="2895" end_char="2898">esta</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="2900" end_char="2905">manera</TOKEN>
<TOKEN id="token-28-3" pos="punct" morph="none" start_char="2906" end_char="2906">,</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="2908" end_char="2918">científicos</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="2920" end_char="2933">especializados</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="2935" end_char="2936">en</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="2938" end_char="2942">salud</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="2944" end_char="2950">pública</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="2952" end_char="2954">que</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="2956" end_char="2958">han</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="2960" end_char="2966">seguido</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="2968" end_char="2969">de</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="2971" end_char="2975">cerca</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="2977" end_char="2978">la</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="2980" end_char="2985">crisis</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="2987" end_char="2989">del</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="2991" end_char="2995">nuevo</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="2997" end_char="3007">coronavirus</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="3009" end_char="3018">publicaron</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="3020" end_char="3021">un</TOKEN>
<TOKEN id="token-28-21" pos="word" morph="none" start_char="3023" end_char="3032">comunicado</TOKEN>
<TOKEN id="token-28-22" pos="word" morph="none" start_char="3034" end_char="3035">en</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3038" end_char="3047">
<ORIGINAL_TEXT>The Lancet</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="3038" end_char="3040">The</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="3042" end_char="3047">Lancet</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3050" end_char="3115">
<ORIGINAL_TEXT>para señalar que "este coronavirus se originó en la vida salvaje".</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="3050" end_char="3053">para</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="3055" end_char="3061">señalar</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="3063" end_char="3065">que</TOKEN>
<TOKEN id="token-30-3" pos="punct" morph="none" start_char="3067" end_char="3067">"</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="3068" end_char="3071">este</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="3073" end_char="3083">coronavirus</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="3085" end_char="3086">se</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="3088" end_char="3094">originó</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="3096" end_char="3097">en</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="3099" end_char="3100">la</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="3102" end_char="3105">vida</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="3107" end_char="3113">salvaje</TOKEN>
<TOKEN id="token-30-12" pos="punct" morph="none" start_char="3114" end_char="3115">".</TOKEN>
</SEG>
<SEG id="segment-31" start_char="3118" end_char="3162">
<ORIGINAL_TEXT>Otro artículo aparecido en el foro científico</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="3118" end_char="3121">Otro</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="3123" end_char="3130">artículo</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="3132" end_char="3140">aparecido</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="3142" end_char="3143">en</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="3145" end_char="3146">el</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="3148" end_char="3151">foro</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="3153" end_char="3162">científico</TOKEN>
</SEG>
<SEG id="segment-32" start_char="3165" end_char="3175">
<ORIGINAL_TEXT>Virological</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="3165" end_char="3175">Virological</TOKEN>
</SEG>
<SEG id="segment-33" start_char="3178" end_char="3288">
<ORIGINAL_TEXT>se posiciona también contraria a la posibilidad de que el nuevo coronavirus haya sido creado en un laboratorio.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="3178" end_char="3179">se</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="3181" end_char="3189">posiciona</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="3191" end_char="3197">también</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="3199" end_char="3207">contraria</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="3209" end_char="3209">a</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="3211" end_char="3212">la</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="3214" end_char="3224">posibilidad</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="3226" end_char="3227">de</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="3229" end_char="3231">que</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="3233" end_char="3234">el</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="3236" end_char="3240">nuevo</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="3242" end_char="3252">coronavirus</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="3254" end_char="3257">haya</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="3259" end_char="3262">sido</TOKEN>
<TOKEN id="token-33-14" pos="word" morph="none" start_char="3264" end_char="3269">creado</TOKEN>
<TOKEN id="token-33-15" pos="word" morph="none" start_char="3271" end_char="3272">en</TOKEN>
<TOKEN id="token-33-16" pos="word" morph="none" start_char="3274" end_char="3275">un</TOKEN>
<TOKEN id="token-33-17" pos="word" morph="none" start_char="3277" end_char="3287">laboratorio</TOKEN>
<TOKEN id="token-33-18" pos="punct" morph="none" start_char="3288" end_char="3288">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="3291" end_char="3328">
<ORIGINAL_TEXT>En la misma línea, en otro artículo de</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="3291" end_char="3292">En</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="3294" end_char="3295">la</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="3297" end_char="3301">misma</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="3303" end_char="3307">línea</TOKEN>
<TOKEN id="token-34-4" pos="punct" morph="none" start_char="3308" end_char="3308">,</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="3310" end_char="3311">en</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="3313" end_char="3316">otro</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="3318" end_char="3325">artículo</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="3327" end_char="3328">de</TOKEN>
</SEG>
<SEG id="segment-35" start_char="3331" end_char="3345">
<ORIGINAL_TEXT>Nature Medicine</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="3331" end_char="3336">Nature</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="3338" end_char="3345">Medicine</TOKEN>
</SEG>
<SEG id="segment-36" start_char="3348" end_char="3530">
<ORIGINAL_TEXT>varios científicos internacionales afirman con rotundidad que sus análisis "muestran claramente que el SARS-CoV-2 no es una creación de laboratorio o un virus manipulado a propósito".</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="3348" end_char="3353">varios</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="3355" end_char="3365">científicos</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="3367" end_char="3381">internacionales</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="3383" end_char="3389">afirman</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="3391" end_char="3393">con</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="3395" end_char="3404">rotundidad</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="3406" end_char="3408">que</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="3410" end_char="3412">sus</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="3414" end_char="3421">análisis</TOKEN>
<TOKEN id="token-36-9" pos="punct" morph="none" start_char="3423" end_char="3423">"</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="3424" end_char="3431">muestran</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="3433" end_char="3442">claramente</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="3444" end_char="3446">que</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="3448" end_char="3449">el</TOKEN>
<TOKEN id="token-36-14" pos="unknown" morph="none" start_char="3451" end_char="3460">SARS-CoV-2</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="3462" end_char="3463">no</TOKEN>
<TOKEN id="token-36-16" pos="word" morph="none" start_char="3465" end_char="3466">es</TOKEN>
<TOKEN id="token-36-17" pos="word" morph="none" start_char="3468" end_char="3470">una</TOKEN>
<TOKEN id="token-36-18" pos="word" morph="none" start_char="3472" end_char="3479">creación</TOKEN>
<TOKEN id="token-36-19" pos="word" morph="none" start_char="3481" end_char="3482">de</TOKEN>
<TOKEN id="token-36-20" pos="word" morph="none" start_char="3484" end_char="3494">laboratorio</TOKEN>
<TOKEN id="token-36-21" pos="word" morph="none" start_char="3496" end_char="3496">o</TOKEN>
<TOKEN id="token-36-22" pos="word" morph="none" start_char="3498" end_char="3499">un</TOKEN>
<TOKEN id="token-36-23" pos="word" morph="none" start_char="3501" end_char="3505">virus</TOKEN>
<TOKEN id="token-36-24" pos="word" morph="none" start_char="3507" end_char="3516">manipulado</TOKEN>
<TOKEN id="token-36-25" pos="word" morph="none" start_char="3518" end_char="3518">a</TOKEN>
<TOKEN id="token-36-26" pos="word" morph="none" start_char="3520" end_char="3528">propósito</TOKEN>
<TOKEN id="token-36-27" pos="punct" morph="none" start_char="3529" end_char="3530">".</TOKEN>
</SEG>
<SEG id="segment-37" start_char="3533" end_char="3696">
<ORIGINAL_TEXT>Además de con Maldita.es, EiTB también colabora estos días con VOST Euskadi y la comunidad científica del programa de divulgación de Eva Caballero en Radio Euskadi,</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="3533" end_char="3538">Además</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="3540" end_char="3541">de</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="3543" end_char="3545">con</TOKEN>
<TOKEN id="token-37-3" pos="unknown" morph="none" start_char="3547" end_char="3556">Maldita.es</TOKEN>
<TOKEN id="token-37-4" pos="punct" morph="none" start_char="3557" end_char="3557">,</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="3559" end_char="3562">EiTB</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="3564" end_char="3570">también</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="3572" end_char="3579">colabora</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="3581" end_char="3585">estos</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="3587" end_char="3590">días</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="3592" end_char="3594">con</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="3596" end_char="3599">VOST</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="3601" end_char="3607">Euskadi</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="3609" end_char="3609">y</TOKEN>
<TOKEN id="token-37-14" pos="word" morph="none" start_char="3611" end_char="3612">la</TOKEN>
<TOKEN id="token-37-15" pos="word" morph="none" start_char="3614" end_char="3622">comunidad</TOKEN>
<TOKEN id="token-37-16" pos="word" morph="none" start_char="3624" end_char="3633">científica</TOKEN>
<TOKEN id="token-37-17" pos="word" morph="none" start_char="3635" end_char="3637">del</TOKEN>
<TOKEN id="token-37-18" pos="word" morph="none" start_char="3639" end_char="3646">programa</TOKEN>
<TOKEN id="token-37-19" pos="word" morph="none" start_char="3648" end_char="3649">de</TOKEN>
<TOKEN id="token-37-20" pos="word" morph="none" start_char="3651" end_char="3661">divulgación</TOKEN>
<TOKEN id="token-37-21" pos="word" morph="none" start_char="3663" end_char="3664">de</TOKEN>
<TOKEN id="token-37-22" pos="word" morph="none" start_char="3666" end_char="3668">Eva</TOKEN>
<TOKEN id="token-37-23" pos="word" morph="none" start_char="3670" end_char="3678">Caballero</TOKEN>
<TOKEN id="token-37-24" pos="word" morph="none" start_char="3680" end_char="3681">en</TOKEN>
<TOKEN id="token-37-25" pos="word" morph="none" start_char="3683" end_char="3687">Radio</TOKEN>
<TOKEN id="token-37-26" pos="word" morph="none" start_char="3689" end_char="3695">Euskadi</TOKEN>
<TOKEN id="token-37-27" pos="punct" morph="none" start_char="3696" end_char="3696">,</TOKEN>
</SEG>
<SEG id="segment-38" start_char="3699" end_char="3721">
<ORIGINAL_TEXT>La Mecánica del Caracol</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="3699" end_char="3700">La</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="3702" end_char="3709">Mecánica</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="3711" end_char="3713">del</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="3715" end_char="3721">Caracol</TOKEN>
</SEG>
<SEG id="segment-39" start_char="3724" end_char="3765">
<ORIGINAL_TEXT>en la lucha para hacer frente a los bulos.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="3724" end_char="3725">en</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="3727" end_char="3728">la</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="3730" end_char="3734">lucha</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="3736" end_char="3739">para</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="3741" end_char="3745">hacer</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="3747" end_char="3752">frente</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="3754" end_char="3754">a</TOKEN>
<TOKEN id="token-39-7" pos="word" morph="none" start_char="3756" end_char="3758">los</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="3760" end_char="3764">bulos</TOKEN>
<TOKEN id="token-39-9" pos="punct" morph="none" start_char="3765" end_char="3765">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
