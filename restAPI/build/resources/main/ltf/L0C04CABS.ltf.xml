<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CABS" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="6398" raw_text_md5="80d0dc26652d43c1ef9b6e77599402ca">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="131">
<ORIGINAL_TEXT>The coronavirus probably started spreading in Wuhan far earlier than Chinese authorities reported — here's the more likely timeline</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="3">The</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="5" end_char="15">coronavirus</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="17" end_char="24">probably</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="26" end_char="32">started</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="34" end_char="42">spreading</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="44" end_char="45">in</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="47" end_char="51">Wuhan</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="53" end_char="55">far</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="57" end_char="63">earlier</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="65" end_char="68">than</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="70" end_char="76">Chinese</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="78" end_char="88">authorities</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="90" end_char="97">reported</TOKEN>
<TOKEN id="token-0-13" pos="punct" morph="none" start_char="99" end_char="99">—</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="101" end_char="106">here's</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="108" end_char="110">the</TOKEN>
<TOKEN id="token-0-16" pos="word" morph="none" start_char="112" end_char="115">more</TOKEN>
<TOKEN id="token-0-17" pos="word" morph="none" start_char="117" end_char="122">likely</TOKEN>
<TOKEN id="token-0-18" pos="word" morph="none" start_char="124" end_char="131">timeline</TOKEN>
</SEG>
<SEG id="segment-1" start_char="136" end_char="249">
<ORIGINAL_TEXT>People in Beijing pay tribute to China's coronavirus victims during a national moment of silence on April 4, 2020.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="136" end_char="141">People</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="143" end_char="144">in</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="146" end_char="152">Beijing</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="154" end_char="156">pay</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="158" end_char="164">tribute</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="166" end_char="167">to</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="169" end_char="175">China's</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="177" end_char="187">coronavirus</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="189" end_char="195">victims</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="197" end_char="202">during</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="204" end_char="204">a</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="206" end_char="213">national</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="215" end_char="220">moment</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="222" end_char="223">of</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="225" end_char="231">silence</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="233" end_char="234">on</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="236" end_char="240">April</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="242" end_char="242">4</TOKEN>
<TOKEN id="token-1-18" pos="punct" morph="none" start_char="243" end_char="243">,</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="245" end_char="248">2020</TOKEN>
<TOKEN id="token-1-20" pos="punct" morph="none" start_char="249" end_char="249">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="252" end_char="271">
<ORIGINAL_TEXT>Thomas Peter/Reuters</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="252" end_char="257">Thomas</TOKEN>
<TOKEN id="token-2-1" pos="unknown" morph="none" start_char="259" end_char="271">Peter/Reuters</TOKEN>
</SEG>
<SEG id="segment-3" start_char="275" end_char="421">
<ORIGINAL_TEXT>Authorities in Wuhan, China, reported 41 cases of an mysterious, pneumonialike respiratory illness to the World Health Organization on December 31.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="275" end_char="285">Authorities</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="287" end_char="288">in</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="290" end_char="294">Wuhan</TOKEN>
<TOKEN id="token-3-3" pos="punct" morph="none" start_char="295" end_char="295">,</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="297" end_char="301">China</TOKEN>
<TOKEN id="token-3-5" pos="punct" morph="none" start_char="302" end_char="302">,</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="304" end_char="311">reported</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="313" end_char="314">41</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="316" end_char="320">cases</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="322" end_char="323">of</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="325" end_char="326">an</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="328" end_char="337">mysterious</TOKEN>
<TOKEN id="token-3-12" pos="punct" morph="none" start_char="338" end_char="338">,</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="340" end_char="352">pneumonialike</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="354" end_char="364">respiratory</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="366" end_char="372">illness</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="374" end_char="375">to</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="377" end_char="379">the</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="381" end_char="385">World</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="387" end_char="392">Health</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="394" end_char="405">Organization</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="407" end_char="408">on</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="410" end_char="417">December</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="419" end_char="420">31</TOKEN>
<TOKEN id="token-3-24" pos="punct" morph="none" start_char="421" end_char="421">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="423" end_char="461">
<ORIGINAL_TEXT>Most were linked to a local wet market.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="423" end_char="426">Most</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="428" end_char="431">were</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="433" end_char="438">linked</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="440" end_char="441">to</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="443" end_char="443">a</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="445" end_char="449">local</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="451" end_char="453">wet</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="455" end_char="460">market</TOKEN>
<TOKEN id="token-4-8" pos="punct" morph="none" start_char="461" end_char="461">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="464" end_char="574">
<ORIGINAL_TEXT>Three months later, that illness — now known as COVID-19 — has infected more than 1.4 million people worldwide.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="464" end_char="468">Three</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="470" end_char="475">months</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="477" end_char="481">later</TOKEN>
<TOKEN id="token-5-3" pos="punct" morph="none" start_char="482" end_char="482">,</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="484" end_char="487">that</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="489" end_char="495">illness</TOKEN>
<TOKEN id="token-5-6" pos="punct" morph="none" start_char="497" end_char="497">—</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="499" end_char="501">now</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="503" end_char="507">known</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="509" end_char="510">as</TOKEN>
<TOKEN id="token-5-10" pos="unknown" morph="none" start_char="512" end_char="519">COVID-19</TOKEN>
<TOKEN id="token-5-11" pos="punct" morph="none" start_char="521" end_char="521">—</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="523" end_char="525">has</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="527" end_char="534">infected</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="536" end_char="539">more</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="541" end_char="544">than</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="546" end_char="548">1.4</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="550" end_char="556">million</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="558" end_char="563">people</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="565" end_char="573">worldwide</TOKEN>
<TOKEN id="token-5-20" pos="punct" morph="none" start_char="574" end_char="574">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="577" end_char="671">
<ORIGINAL_TEXT>But a growing body of research suggests those early reported cases were not the first in China.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="577" end_char="579">But</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="581" end_char="581">a</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="583" end_char="589">growing</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="591" end_char="594">body</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="596" end_char="597">of</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="599" end_char="606">research</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="608" end_char="615">suggests</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="617" end_char="621">those</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="623" end_char="627">early</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="629" end_char="636">reported</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="638" end_char="642">cases</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="644" end_char="647">were</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="649" end_char="651">not</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="653" end_char="655">the</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="657" end_char="661">first</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="663" end_char="664">in</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="666" end_char="670">China</TOKEN>
<TOKEN id="token-6-17" pos="punct" morph="none" start_char="671" end_char="671">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="674" end_char="809">
<ORIGINAL_TEXT>A new study suggests that community transmission of the coronavirus in Wuhan was going on in early January, unrelated to the wet market.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="674" end_char="674">A</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="676" end_char="678">new</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="680" end_char="684">study</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="686" end_char="693">suggests</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="695" end_char="698">that</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="700" end_char="708">community</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="710" end_char="721">transmission</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="723" end_char="724">of</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="726" end_char="728">the</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="730" end_char="740">coronavirus</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="742" end_char="743">in</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="745" end_char="749">Wuhan</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="751" end_char="753">was</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="755" end_char="759">going</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="761" end_char="762">on</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="764" end_char="765">in</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="767" end_char="771">early</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="773" end_char="779">January</TOKEN>
<TOKEN id="token-7-18" pos="punct" morph="none" start_char="780" end_char="780">,</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="782" end_char="790">unrelated</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="792" end_char="793">to</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="795" end_char="797">the</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="799" end_char="801">wet</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="803" end_char="808">market</TOKEN>
<TOKEN id="token-7-24" pos="punct" morph="none" start_char="809" end_char="809">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="812" end_char="862">
<ORIGINAL_TEXT>Visit Business Insider's homepage for more stories.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="812" end_char="816">Visit</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="818" end_char="825">Business</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="827" end_char="835">Insider's</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="837" end_char="844">homepage</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="846" end_char="848">for</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="850" end_char="853">more</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="855" end_char="861">stories</TOKEN>
<TOKEN id="token-8-7" pos="punct" morph="none" start_char="862" end_char="862">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="866" end_char="994">
<ORIGINAL_TEXT>Authorities in Wuhan, China, first informed the World Health Organization about an unknown, pneumonialike illness on December 31.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="866" end_char="876">Authorities</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="878" end_char="879">in</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="881" end_char="885">Wuhan</TOKEN>
<TOKEN id="token-9-3" pos="punct" morph="none" start_char="886" end_char="886">,</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="888" end_char="892">China</TOKEN>
<TOKEN id="token-9-5" pos="punct" morph="none" start_char="893" end_char="893">,</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="895" end_char="899">first</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="901" end_char="908">informed</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="910" end_char="912">the</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="914" end_char="918">World</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="920" end_char="925">Health</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="927" end_char="938">Organization</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="940" end_char="944">about</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="946" end_char="947">an</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="949" end_char="955">unknown</TOKEN>
<TOKEN id="token-9-15" pos="punct" morph="none" start_char="956" end_char="956">,</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="958" end_char="970">pneumonialike</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="972" end_char="978">illness</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="980" end_char="981">on</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="983" end_char="990">December</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="992" end_char="993">31</TOKEN>
<TOKEN id="token-9-21" pos="punct" morph="none" start_char="994" end_char="994">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="997" end_char="1098">
<ORIGINAL_TEXT>A majority of the initial 41 cases were linked to a local wet market, which was shutdown on January 1.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="997" end_char="997">A</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="999" end_char="1006">majority</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1008" end_char="1009">of</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1011" end_char="1013">the</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1015" end_char="1021">initial</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1023" end_char="1024">41</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1026" end_char="1030">cases</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1032" end_char="1035">were</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1037" end_char="1042">linked</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1044" end_char="1045">to</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1047" end_char="1047">a</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1049" end_char="1053">local</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1055" end_char="1057">wet</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1059" end_char="1064">market</TOKEN>
<TOKEN id="token-10-14" pos="punct" morph="none" start_char="1065" end_char="1065">,</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1067" end_char="1071">which</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1073" end_char="1075">was</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1077" end_char="1084">shutdown</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1086" end_char="1087">on</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1089" end_char="1095">January</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1097" end_char="1097">1</TOKEN>
<TOKEN id="token-10-21" pos="punct" morph="none" start_char="1098" end_char="1098">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1100" end_char="1204">
<ORIGINAL_TEXT>A week later, experts identified it as a new coronavirus; the disease it caused was later named COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1100" end_char="1100">A</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1102" end_char="1105">week</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1107" end_char="1111">later</TOKEN>
<TOKEN id="token-11-3" pos="punct" morph="none" start_char="1112" end_char="1112">,</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1114" end_char="1120">experts</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1122" end_char="1131">identified</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1133" end_char="1134">it</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1136" end_char="1137">as</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1139" end_char="1139">a</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1141" end_char="1143">new</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1145" end_char="1155">coronavirus</TOKEN>
<TOKEN id="token-11-11" pos="punct" morph="none" start_char="1156" end_char="1156">;</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1158" end_char="1160">the</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1162" end_char="1168">disease</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1170" end_char="1171">it</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1173" end_char="1178">caused</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1180" end_char="1182">was</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1184" end_char="1188">later</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1190" end_char="1194">named</TOKEN>
<TOKEN id="token-11-19" pos="unknown" morph="none" start_char="1196" end_char="1203">COVID-19</TOKEN>
<TOKEN id="token-11-20" pos="punct" morph="none" start_char="1204" end_char="1204">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1207" end_char="1289">
<ORIGINAL_TEXT>But recent research suggests these late-December cases were not the first in Wuhan.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1207" end_char="1209">But</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1211" end_char="1216">recent</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1218" end_char="1225">research</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1227" end_char="1234">suggests</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1236" end_char="1240">these</TOKEN>
<TOKEN id="token-12-5" pos="unknown" morph="none" start_char="1242" end_char="1254">late-December</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1256" end_char="1260">cases</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1262" end_char="1265">were</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1267" end_char="1269">not</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1271" end_char="1273">the</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1275" end_char="1279">first</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1281" end_char="1282">in</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1284" end_char="1288">Wuhan</TOKEN>
<TOKEN id="token-12-13" pos="punct" morph="none" start_char="1289" end_char="1289">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1291" end_char="1472">
<ORIGINAL_TEXT>A study published Tuesday in the journal Nature Microbiology suggests that the coronavirus had already established itself and begun spreading in the Wuhan community by early January.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1291" end_char="1291">A</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1293" end_char="1297">study</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1299" end_char="1307">published</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1309" end_char="1315">Tuesday</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1317" end_char="1318">in</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1320" end_char="1322">the</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1324" end_char="1330">journal</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1332" end_char="1337">Nature</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1339" end_char="1350">Microbiology</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1352" end_char="1359">suggests</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1361" end_char="1364">that</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1366" end_char="1368">the</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1370" end_char="1380">coronavirus</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1382" end_char="1384">had</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1386" end_char="1392">already</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1394" end_char="1404">established</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1406" end_char="1411">itself</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1413" end_char="1415">and</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1417" end_char="1421">begun</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1423" end_char="1431">spreading</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1433" end_char="1434">in</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="1436" end_char="1438">the</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="1440" end_char="1444">Wuhan</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="1446" end_char="1454">community</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="1456" end_char="1457">by</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="1459" end_char="1463">early</TOKEN>
<TOKEN id="token-13-26" pos="word" morph="none" start_char="1465" end_char="1471">January</TOKEN>
<TOKEN id="token-13-27" pos="punct" morph="none" start_char="1472" end_char="1472">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1475" end_char="1717">
<ORIGINAL_TEXT>On Wednesday, ABC News reported that even US intelligence officials were aware of the coronavirus outbreak in China as early as November, according to sources familiar with a report from the military's National Center for Medical Intelligence.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1475" end_char="1476">On</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1478" end_char="1486">Wednesday</TOKEN>
<TOKEN id="token-14-2" pos="punct" morph="none" start_char="1487" end_char="1487">,</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1489" end_char="1491">ABC</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1493" end_char="1496">News</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1498" end_char="1505">reported</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1507" end_char="1510">that</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1512" end_char="1515">even</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1517" end_char="1518">US</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1520" end_char="1531">intelligence</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1533" end_char="1541">officials</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1543" end_char="1546">were</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1548" end_char="1552">aware</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1554" end_char="1555">of</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="1557" end_char="1559">the</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1561" end_char="1571">coronavirus</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1573" end_char="1580">outbreak</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="1582" end_char="1583">in</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="1585" end_char="1589">China</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="1591" end_char="1592">as</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="1594" end_char="1598">early</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="1600" end_char="1601">as</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="1603" end_char="1610">November</TOKEN>
<TOKEN id="token-14-23" pos="punct" morph="none" start_char="1611" end_char="1611">,</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="1613" end_char="1621">according</TOKEN>
<TOKEN id="token-14-25" pos="word" morph="none" start_char="1623" end_char="1624">to</TOKEN>
<TOKEN id="token-14-26" pos="word" morph="none" start_char="1626" end_char="1632">sources</TOKEN>
<TOKEN id="token-14-27" pos="word" morph="none" start_char="1634" end_char="1641">familiar</TOKEN>
<TOKEN id="token-14-28" pos="word" morph="none" start_char="1643" end_char="1646">with</TOKEN>
<TOKEN id="token-14-29" pos="word" morph="none" start_char="1648" end_char="1648">a</TOKEN>
<TOKEN id="token-14-30" pos="word" morph="none" start_char="1650" end_char="1655">report</TOKEN>
<TOKEN id="token-14-31" pos="word" morph="none" start_char="1657" end_char="1660">from</TOKEN>
<TOKEN id="token-14-32" pos="word" morph="none" start_char="1662" end_char="1664">the</TOKEN>
<TOKEN id="token-14-33" pos="word" morph="none" start_char="1666" end_char="1675">military's</TOKEN>
<TOKEN id="token-14-34" pos="word" morph="none" start_char="1677" end_char="1684">National</TOKEN>
<TOKEN id="token-14-35" pos="word" morph="none" start_char="1686" end_char="1691">Center</TOKEN>
<TOKEN id="token-14-36" pos="word" morph="none" start_char="1693" end_char="1695">for</TOKEN>
<TOKEN id="token-14-37" pos="word" morph="none" start_char="1697" end_char="1703">Medical</TOKEN>
<TOKEN id="token-14-38" pos="word" morph="none" start_char="1705" end_char="1716">Intelligence</TOKEN>
<TOKEN id="token-14-39" pos="punct" morph="none" start_char="1717" end_char="1717">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1720" end_char="1884">
<ORIGINAL_TEXT>"Analysts concluded it could be a cataclysmic event," one person told ABC of the report, which included intercepted wire and computer messages, and satellite images.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="punct" morph="none" start_char="1720" end_char="1720">"</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1721" end_char="1728">Analysts</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1730" end_char="1738">concluded</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1740" end_char="1741">it</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1743" end_char="1747">could</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1749" end_char="1750">be</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1752" end_char="1752">a</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1754" end_char="1764">cataclysmic</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1766" end_char="1770">event</TOKEN>
<TOKEN id="token-15-9" pos="punct" morph="none" start_char="1771" end_char="1772">,"</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1774" end_char="1776">one</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1778" end_char="1783">person</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1785" end_char="1788">told</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1790" end_char="1792">ABC</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1794" end_char="1795">of</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="1797" end_char="1799">the</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="1801" end_char="1806">report</TOKEN>
<TOKEN id="token-15-17" pos="punct" morph="none" start_char="1807" end_char="1807">,</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="1809" end_char="1813">which</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="1815" end_char="1822">included</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="1824" end_char="1834">intercepted</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="1836" end_char="1839">wire</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="1841" end_char="1843">and</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="1845" end_char="1852">computer</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="1854" end_char="1861">messages</TOKEN>
<TOKEN id="token-15-25" pos="punct" morph="none" start_char="1862" end_char="1862">,</TOKEN>
<TOKEN id="token-15-26" pos="word" morph="none" start_char="1864" end_char="1866">and</TOKEN>
<TOKEN id="token-15-27" pos="word" morph="none" start_char="1868" end_char="1876">satellite</TOKEN>
<TOKEN id="token-15-28" pos="word" morph="none" start_char="1878" end_char="1883">images</TOKEN>
<TOKEN id="token-15-29" pos="punct" morph="none" start_char="1884" end_char="1884">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1887" end_char="2020">
<ORIGINAL_TEXT>Both of these revelations contradict China and the WHO's official narrative, which says the virus was first reported in late December.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1887" end_char="1890">Both</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1892" end_char="1893">of</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1895" end_char="1899">these</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1901" end_char="1911">revelations</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1913" end_char="1922">contradict</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1924" end_char="1928">China</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1930" end_char="1932">and</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1934" end_char="1936">the</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1938" end_char="1942">WHO's</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="1944" end_char="1951">official</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="1953" end_char="1961">narrative</TOKEN>
<TOKEN id="token-16-11" pos="punct" morph="none" start_char="1962" end_char="1962">,</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="1964" end_char="1968">which</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="1970" end_char="1973">says</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="1975" end_char="1977">the</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="1979" end_char="1983">virus</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="1985" end_char="1987">was</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="1989" end_char="1993">first</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="1995" end_char="2002">reported</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="2004" end_char="2005">in</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="2007" end_char="2010">late</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="2012" end_char="2019">December</TOKEN>
<TOKEN id="token-16-22" pos="punct" morph="none" start_char="2020" end_char="2020">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2022" end_char="2141">
<ORIGINAL_TEXT>The earlier timeline may also explain how the outbreak was able to spread so quickly in China and the rest of the world.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2022" end_char="2024">The</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2026" end_char="2032">earlier</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2034" end_char="2041">timeline</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2043" end_char="2045">may</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2047" end_char="2050">also</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2052" end_char="2058">explain</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2060" end_char="2062">how</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2064" end_char="2066">the</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2068" end_char="2075">outbreak</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2077" end_char="2079">was</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2081" end_char="2084">able</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2086" end_char="2087">to</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2089" end_char="2094">spread</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2096" end_char="2097">so</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2099" end_char="2105">quickly</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2107" end_char="2108">in</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="2110" end_char="2114">China</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="2116" end_char="2118">and</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="2120" end_char="2122">the</TOKEN>
<TOKEN id="token-17-19" pos="word" morph="none" start_char="2124" end_char="2127">rest</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="2129" end_char="2130">of</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="2132" end_char="2134">the</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="2136" end_char="2140">world</TOKEN>
<TOKEN id="token-17-23" pos="punct" morph="none" start_char="2141" end_char="2141">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2144" end_char="2207">
<ORIGINAL_TEXT>Community transmission was already happening in Wuhan by January</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2144" end_char="2152">Community</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2154" end_char="2165">transmission</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2167" end_char="2169">was</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2171" end_char="2177">already</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2179" end_char="2187">happening</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2189" end_char="2190">in</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2192" end_char="2196">Wuhan</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2198" end_char="2199">by</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2201" end_char="2207">January</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2212" end_char="2389">
<ORIGINAL_TEXT>A woman walks in front of the closed Huanan Wholesale Seafood Market, where health authorities said the first coronavirus cases in the city of Wuhan originated, January 12, 2020.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2212" end_char="2212">A</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2214" end_char="2218">woman</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2220" end_char="2224">walks</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2226" end_char="2227">in</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2229" end_char="2233">front</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2235" end_char="2236">of</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2238" end_char="2240">the</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2242" end_char="2247">closed</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2249" end_char="2254">Huanan</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="2256" end_char="2264">Wholesale</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="2266" end_char="2272">Seafood</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="2274" end_char="2279">Market</TOKEN>
<TOKEN id="token-19-12" pos="punct" morph="none" start_char="2280" end_char="2280">,</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="2282" end_char="2286">where</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="2288" end_char="2293">health</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="2295" end_char="2305">authorities</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="2307" end_char="2310">said</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="2312" end_char="2314">the</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="2316" end_char="2320">first</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="2322" end_char="2332">coronavirus</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="2334" end_char="2338">cases</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="2340" end_char="2341">in</TOKEN>
<TOKEN id="token-19-22" pos="word" morph="none" start_char="2343" end_char="2345">the</TOKEN>
<TOKEN id="token-19-23" pos="word" morph="none" start_char="2347" end_char="2350">city</TOKEN>
<TOKEN id="token-19-24" pos="word" morph="none" start_char="2352" end_char="2353">of</TOKEN>
<TOKEN id="token-19-25" pos="word" morph="none" start_char="2355" end_char="2359">Wuhan</TOKEN>
<TOKEN id="token-19-26" pos="word" morph="none" start_char="2361" end_char="2370">originated</TOKEN>
<TOKEN id="token-19-27" pos="punct" morph="none" start_char="2371" end_char="2371">,</TOKEN>
<TOKEN id="token-19-28" pos="word" morph="none" start_char="2373" end_char="2379">January</TOKEN>
<TOKEN id="token-19-29" pos="word" morph="none" start_char="2381" end_char="2382">12</TOKEN>
<TOKEN id="token-19-30" pos="punct" morph="none" start_char="2383" end_char="2383">,</TOKEN>
<TOKEN id="token-19-31" pos="word" morph="none" start_char="2385" end_char="2388">2020</TOKEN>
<TOKEN id="token-19-32" pos="punct" morph="none" start_char="2389" end_char="2389">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2392" end_char="2422">
<ORIGINAL_TEXT>NOEL CELIS/AFP via Getty Images</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2392" end_char="2395">NOEL</TOKEN>
<TOKEN id="token-20-1" pos="unknown" morph="none" start_char="2397" end_char="2405">CELIS/AFP</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2407" end_char="2409">via</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2411" end_char="2415">Getty</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2417" end_char="2422">Images</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2426" end_char="2600">
<ORIGINAL_TEXT>The authors of the new Nature study analyzed 640 throat swabs collected from patients in Wuhan who went to the doctor with flu-like illnesses between October 6 and January 21.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2426" end_char="2428">The</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2430" end_char="2436">authors</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2438" end_char="2439">of</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2441" end_char="2443">the</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2445" end_char="2447">new</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="2449" end_char="2454">Nature</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2456" end_char="2460">study</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="2462" end_char="2469">analyzed</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="2471" end_char="2473">640</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="2475" end_char="2480">throat</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="2482" end_char="2486">swabs</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="2488" end_char="2496">collected</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="2498" end_char="2501">from</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="2503" end_char="2510">patients</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="2512" end_char="2513">in</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="2515" end_char="2519">Wuhan</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="2521" end_char="2523">who</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="2525" end_char="2528">went</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="2530" end_char="2531">to</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="2533" end_char="2535">the</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="2537" end_char="2542">doctor</TOKEN>
<TOKEN id="token-21-21" pos="word" morph="none" start_char="2544" end_char="2547">with</TOKEN>
<TOKEN id="token-21-22" pos="unknown" morph="none" start_char="2549" end_char="2556">flu-like</TOKEN>
<TOKEN id="token-21-23" pos="word" morph="none" start_char="2558" end_char="2566">illnesses</TOKEN>
<TOKEN id="token-21-24" pos="word" morph="none" start_char="2568" end_char="2574">between</TOKEN>
<TOKEN id="token-21-25" pos="word" morph="none" start_char="2576" end_char="2582">October</TOKEN>
<TOKEN id="token-21-26" pos="word" morph="none" start_char="2584" end_char="2584">6</TOKEN>
<TOKEN id="token-21-27" pos="word" morph="none" start_char="2586" end_char="2588">and</TOKEN>
<TOKEN id="token-21-28" pos="word" morph="none" start_char="2590" end_char="2596">January</TOKEN>
<TOKEN id="token-21-29" pos="word" morph="none" start_char="2598" end_char="2599">21</TOKEN>
<TOKEN id="token-21-30" pos="punct" morph="none" start_char="2600" end_char="2600">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2603" end_char="2721">
<ORIGINAL_TEXT>Nine of those swabs, which were collected in the first three weeks of January, tested positive for the new coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2603" end_char="2606">Nine</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2608" end_char="2609">of</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2611" end_char="2615">those</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2617" end_char="2621">swabs</TOKEN>
<TOKEN id="token-22-4" pos="punct" morph="none" start_char="2622" end_char="2622">,</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2624" end_char="2628">which</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2630" end_char="2633">were</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2635" end_char="2643">collected</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="2645" end_char="2646">in</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="2648" end_char="2650">the</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="2652" end_char="2656">first</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="2658" end_char="2662">three</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="2664" end_char="2668">weeks</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="2670" end_char="2671">of</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="2673" end_char="2679">January</TOKEN>
<TOKEN id="token-22-15" pos="punct" morph="none" start_char="2680" end_char="2680">,</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="2682" end_char="2687">tested</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="2689" end_char="2696">positive</TOKEN>
<TOKEN id="token-22-18" pos="word" morph="none" start_char="2698" end_char="2700">for</TOKEN>
<TOKEN id="token-22-19" pos="word" morph="none" start_char="2702" end_char="2704">the</TOKEN>
<TOKEN id="token-22-20" pos="word" morph="none" start_char="2706" end_char="2708">new</TOKEN>
<TOKEN id="token-22-21" pos="word" morph="none" start_char="2710" end_char="2720">coronavirus</TOKEN>
<TOKEN id="token-22-22" pos="punct" morph="none" start_char="2721" end_char="2721">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2723" end_char="2850">
<ORIGINAL_TEXT>The people those swabs belonged to came from six different districts of the Wuhan metropolitan area and its surrounding regions.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2723" end_char="2725">The</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2727" end_char="2732">people</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2734" end_char="2738">those</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2740" end_char="2744">swabs</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="2746" end_char="2753">belonged</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="2755" end_char="2756">to</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="2758" end_char="2761">came</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="2763" end_char="2766">from</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="2768" end_char="2770">six</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="2772" end_char="2780">different</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="2782" end_char="2790">districts</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="2792" end_char="2793">of</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="2795" end_char="2797">the</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="2799" end_char="2803">Wuhan</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="2805" end_char="2816">metropolitan</TOKEN>
<TOKEN id="token-23-15" pos="word" morph="none" start_char="2818" end_char="2821">area</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="2823" end_char="2825">and</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="2827" end_char="2829">its</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="2831" end_char="2841">surrounding</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="2843" end_char="2849">regions</TOKEN>
<TOKEN id="token-23-20" pos="punct" morph="none" start_char="2850" end_char="2850">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2853" end_char="3142">
<ORIGINAL_TEXT>The researchers said these findings, along with the rapid spread of the coronavirus in Wuhan — the number of reported cases jumped from 41 to more than 46,000 between December 31 and February 23 — suggest the virus had begun to spread through the community no later than the end of January.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="2853" end_char="2855">The</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="2857" end_char="2867">researchers</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="2869" end_char="2872">said</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="2874" end_char="2878">these</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="2880" end_char="2887">findings</TOKEN>
<TOKEN id="token-24-5" pos="punct" morph="none" start_char="2888" end_char="2888">,</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="2890" end_char="2894">along</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="2896" end_char="2899">with</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="2901" end_char="2903">the</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="2905" end_char="2909">rapid</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="2911" end_char="2916">spread</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="2918" end_char="2919">of</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="2921" end_char="2923">the</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="2925" end_char="2935">coronavirus</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="2937" end_char="2938">in</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="2940" end_char="2944">Wuhan</TOKEN>
<TOKEN id="token-24-16" pos="punct" morph="none" start_char="2946" end_char="2946">—</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="2948" end_char="2950">the</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="2952" end_char="2957">number</TOKEN>
<TOKEN id="token-24-19" pos="word" morph="none" start_char="2959" end_char="2960">of</TOKEN>
<TOKEN id="token-24-20" pos="word" morph="none" start_char="2962" end_char="2969">reported</TOKEN>
<TOKEN id="token-24-21" pos="word" morph="none" start_char="2971" end_char="2975">cases</TOKEN>
<TOKEN id="token-24-22" pos="word" morph="none" start_char="2977" end_char="2982">jumped</TOKEN>
<TOKEN id="token-24-23" pos="word" morph="none" start_char="2984" end_char="2987">from</TOKEN>
<TOKEN id="token-24-24" pos="word" morph="none" start_char="2989" end_char="2990">41</TOKEN>
<TOKEN id="token-24-25" pos="word" morph="none" start_char="2992" end_char="2993">to</TOKEN>
<TOKEN id="token-24-26" pos="word" morph="none" start_char="2995" end_char="2998">more</TOKEN>
<TOKEN id="token-24-27" pos="word" morph="none" start_char="3000" end_char="3003">than</TOKEN>
<TOKEN id="token-24-28" pos="unknown" morph="none" start_char="3005" end_char="3010">46,000</TOKEN>
<TOKEN id="token-24-29" pos="word" morph="none" start_char="3012" end_char="3018">between</TOKEN>
<TOKEN id="token-24-30" pos="word" morph="none" start_char="3020" end_char="3027">December</TOKEN>
<TOKEN id="token-24-31" pos="word" morph="none" start_char="3029" end_char="3030">31</TOKEN>
<TOKEN id="token-24-32" pos="word" morph="none" start_char="3032" end_char="3034">and</TOKEN>
<TOKEN id="token-24-33" pos="word" morph="none" start_char="3036" end_char="3043">February</TOKEN>
<TOKEN id="token-24-34" pos="word" morph="none" start_char="3045" end_char="3046">23</TOKEN>
<TOKEN id="token-24-35" pos="punct" morph="none" start_char="3048" end_char="3048">—</TOKEN>
<TOKEN id="token-24-36" pos="word" morph="none" start_char="3050" end_char="3056">suggest</TOKEN>
<TOKEN id="token-24-37" pos="word" morph="none" start_char="3058" end_char="3060">the</TOKEN>
<TOKEN id="token-24-38" pos="word" morph="none" start_char="3062" end_char="3066">virus</TOKEN>
<TOKEN id="token-24-39" pos="word" morph="none" start_char="3068" end_char="3070">had</TOKEN>
<TOKEN id="token-24-40" pos="word" morph="none" start_char="3072" end_char="3076">begun</TOKEN>
<TOKEN id="token-24-41" pos="word" morph="none" start_char="3078" end_char="3079">to</TOKEN>
<TOKEN id="token-24-42" pos="word" morph="none" start_char="3081" end_char="3086">spread</TOKEN>
<TOKEN id="token-24-43" pos="word" morph="none" start_char="3088" end_char="3094">through</TOKEN>
<TOKEN id="token-24-44" pos="word" morph="none" start_char="3096" end_char="3098">the</TOKEN>
<TOKEN id="token-24-45" pos="word" morph="none" start_char="3100" end_char="3108">community</TOKEN>
<TOKEN id="token-24-46" pos="word" morph="none" start_char="3110" end_char="3111">no</TOKEN>
<TOKEN id="token-24-47" pos="word" morph="none" start_char="3113" end_char="3117">later</TOKEN>
<TOKEN id="token-24-48" pos="word" morph="none" start_char="3119" end_char="3122">than</TOKEN>
<TOKEN id="token-24-49" pos="word" morph="none" start_char="3124" end_char="3126">the</TOKEN>
<TOKEN id="token-24-50" pos="word" morph="none" start_char="3128" end_char="3130">end</TOKEN>
<TOKEN id="token-24-51" pos="word" morph="none" start_char="3132" end_char="3133">of</TOKEN>
<TOKEN id="token-24-52" pos="word" morph="none" start_char="3135" end_char="3141">January</TOKEN>
<TOKEN id="token-24-53" pos="punct" morph="none" start_char="3142" end_char="3142">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="3145" end_char="3283">
<ORIGINAL_TEXT>Community transmission is the term for spread in which the source of an illness is unknown and not traceable to an infected person or area.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="3145" end_char="3153">Community</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="3155" end_char="3166">transmission</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="3168" end_char="3169">is</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="3171" end_char="3173">the</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="3175" end_char="3178">term</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="3180" end_char="3182">for</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="3184" end_char="3189">spread</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="3191" end_char="3192">in</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="3194" end_char="3198">which</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="3200" end_char="3202">the</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="3204" end_char="3209">source</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="3211" end_char="3212">of</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="3214" end_char="3215">an</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="3217" end_char="3223">illness</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="3225" end_char="3226">is</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="3228" end_char="3234">unknown</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="3236" end_char="3238">and</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="3240" end_char="3242">not</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="3244" end_char="3252">traceable</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="3254" end_char="3255">to</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="3257" end_char="3258">an</TOKEN>
<TOKEN id="token-25-21" pos="word" morph="none" start_char="3260" end_char="3267">infected</TOKEN>
<TOKEN id="token-25-22" pos="word" morph="none" start_char="3269" end_char="3274">person</TOKEN>
<TOKEN id="token-25-23" pos="word" morph="none" start_char="3276" end_char="3277">or</TOKEN>
<TOKEN id="token-25-24" pos="word" morph="none" start_char="3279" end_char="3282">area</TOKEN>
<TOKEN id="token-25-25" pos="punct" morph="none" start_char="3283" end_char="3283">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="3287" end_char="3404">
<ORIGINAL_TEXT>Residents bid farewell from their homes to a medical team from Guizhou province that is leaving Wuhan, March 25, 2020.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="3287" end_char="3295">Residents</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="3297" end_char="3299">bid</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="3301" end_char="3308">farewell</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="3310" end_char="3313">from</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="3315" end_char="3319">their</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="3321" end_char="3325">homes</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="3327" end_char="3328">to</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="3330" end_char="3330">a</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="3332" end_char="3338">medical</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="3340" end_char="3343">team</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="3345" end_char="3348">from</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="3350" end_char="3356">Guizhou</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="3358" end_char="3365">province</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="3367" end_char="3370">that</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="3372" end_char="3373">is</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="3375" end_char="3381">leaving</TOKEN>
<TOKEN id="token-26-16" pos="word" morph="none" start_char="3383" end_char="3387">Wuhan</TOKEN>
<TOKEN id="token-26-17" pos="punct" morph="none" start_char="3388" end_char="3388">,</TOKEN>
<TOKEN id="token-26-18" pos="word" morph="none" start_char="3390" end_char="3394">March</TOKEN>
<TOKEN id="token-26-19" pos="word" morph="none" start_char="3396" end_char="3397">25</TOKEN>
<TOKEN id="token-26-20" pos="punct" morph="none" start_char="3398" end_char="3398">,</TOKEN>
<TOKEN id="token-26-21" pos="word" morph="none" start_char="3400" end_char="3403">2020</TOKEN>
<TOKEN id="token-26-22" pos="punct" morph="none" start_char="3404" end_char="3404">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="3407" end_char="3429">
<ORIGINAL_TEXT>China Daily via Reuters</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="3407" end_char="3411">China</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="3413" end_char="3417">Daily</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="3419" end_char="3421">via</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="3423" end_char="3429">Reuters</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3433" end_char="3480">
<ORIGINAL_TEXT>Other research also suggests an earlier timeline</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="3433" end_char="3437">Other</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="3439" end_char="3446">research</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="3448" end_char="3451">also</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="3453" end_char="3460">suggests</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="3462" end_char="3463">an</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="3465" end_char="3471">earlier</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="3473" end_char="3480">timeline</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3484" end_char="3567">
<ORIGINAL_TEXT>Several other studies also suggest an earlier timeline of the virus' initial spread.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="3484" end_char="3490">Several</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="3492" end_char="3496">other</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="3498" end_char="3504">studies</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="3506" end_char="3509">also</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="3511" end_char="3517">suggest</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="3519" end_char="3520">an</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="3522" end_char="3528">earlier</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="3530" end_char="3537">timeline</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="3539" end_char="3540">of</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="3542" end_char="3544">the</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="3546" end_char="3550">virus</TOKEN>
<TOKEN id="token-29-11" pos="punct" morph="none" start_char="3551" end_char="3551">'</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="3553" end_char="3559">initial</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="3561" end_char="3566">spread</TOKEN>
<TOKEN id="token-29-14" pos="punct" morph="none" start_char="3567" end_char="3567">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3570" end_char="3754">
<ORIGINAL_TEXT>Research published in The Lancet in January showed that the first person to test positive for the coronavirus was likely exposed to it on December 1, then showed symptoms on December 8.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="3570" end_char="3577">Research</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="3579" end_char="3587">published</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="3589" end_char="3590">in</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="3592" end_char="3594">The</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="3596" end_char="3601">Lancet</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="3603" end_char="3604">in</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="3606" end_char="3612">January</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="3614" end_char="3619">showed</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="3621" end_char="3624">that</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="3626" end_char="3628">the</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="3630" end_char="3634">first</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="3636" end_char="3641">person</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="3643" end_char="3644">to</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="3646" end_char="3649">test</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="3651" end_char="3658">positive</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="3660" end_char="3662">for</TOKEN>
<TOKEN id="token-30-16" pos="word" morph="none" start_char="3664" end_char="3666">the</TOKEN>
<TOKEN id="token-30-17" pos="word" morph="none" start_char="3668" end_char="3678">coronavirus</TOKEN>
<TOKEN id="token-30-18" pos="word" morph="none" start_char="3680" end_char="3682">was</TOKEN>
<TOKEN id="token-30-19" pos="word" morph="none" start_char="3684" end_char="3689">likely</TOKEN>
<TOKEN id="token-30-20" pos="word" morph="none" start_char="3691" end_char="3697">exposed</TOKEN>
<TOKEN id="token-30-21" pos="word" morph="none" start_char="3699" end_char="3700">to</TOKEN>
<TOKEN id="token-30-22" pos="word" morph="none" start_char="3702" end_char="3703">it</TOKEN>
<TOKEN id="token-30-23" pos="word" morph="none" start_char="3705" end_char="3706">on</TOKEN>
<TOKEN id="token-30-24" pos="word" morph="none" start_char="3708" end_char="3715">December</TOKEN>
<TOKEN id="token-30-25" pos="word" morph="none" start_char="3717" end_char="3717">1</TOKEN>
<TOKEN id="token-30-26" pos="punct" morph="none" start_char="3718" end_char="3718">,</TOKEN>
<TOKEN id="token-30-27" pos="word" morph="none" start_char="3720" end_char="3723">then</TOKEN>
<TOKEN id="token-30-28" pos="word" morph="none" start_char="3725" end_char="3730">showed</TOKEN>
<TOKEN id="token-30-29" pos="word" morph="none" start_char="3732" end_char="3739">symptoms</TOKEN>
<TOKEN id="token-30-30" pos="word" morph="none" start_char="3741" end_char="3742">on</TOKEN>
<TOKEN id="token-30-31" pos="word" morph="none" start_char="3744" end_char="3751">December</TOKEN>
<TOKEN id="token-30-32" pos="word" morph="none" start_char="3753" end_char="3753">8</TOKEN>
<TOKEN id="token-30-33" pos="punct" morph="none" start_char="3754" end_char="3754">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="3756" end_char="3909">
<ORIGINAL_TEXT>The researchers behind the study also found that 13 of the 41 original cases showed no link to the wet market, called the Huanan Seafood Wholesale Market.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="3756" end_char="3758">The</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="3760" end_char="3770">researchers</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="3772" end_char="3777">behind</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="3779" end_char="3781">the</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="3783" end_char="3787">study</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="3789" end_char="3792">also</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="3794" end_char="3798">found</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="3800" end_char="3803">that</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="3805" end_char="3806">13</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="3808" end_char="3809">of</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="3811" end_char="3813">the</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="3815" end_char="3816">41</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="3818" end_char="3825">original</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="3827" end_char="3831">cases</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="3833" end_char="3838">showed</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="3840" end_char="3841">no</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="3843" end_char="3846">link</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="3848" end_char="3849">to</TOKEN>
<TOKEN id="token-31-18" pos="word" morph="none" start_char="3851" end_char="3853">the</TOKEN>
<TOKEN id="token-31-19" pos="word" morph="none" start_char="3855" end_char="3857">wet</TOKEN>
<TOKEN id="token-31-20" pos="word" morph="none" start_char="3859" end_char="3864">market</TOKEN>
<TOKEN id="token-31-21" pos="punct" morph="none" start_char="3865" end_char="3865">,</TOKEN>
<TOKEN id="token-31-22" pos="word" morph="none" start_char="3867" end_char="3872">called</TOKEN>
<TOKEN id="token-31-23" pos="word" morph="none" start_char="3874" end_char="3876">the</TOKEN>
<TOKEN id="token-31-24" pos="word" morph="none" start_char="3878" end_char="3883">Huanan</TOKEN>
<TOKEN id="token-31-25" pos="word" morph="none" start_char="3885" end_char="3891">Seafood</TOKEN>
<TOKEN id="token-31-26" pos="word" morph="none" start_char="3893" end_char="3901">Wholesale</TOKEN>
<TOKEN id="token-31-27" pos="word" morph="none" start_char="3903" end_char="3908">Market</TOKEN>
<TOKEN id="token-31-28" pos="punct" morph="none" start_char="3909" end_char="3909">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="3911" end_char="4008">
<ORIGINAL_TEXT>That finding supports the idea that community transmission was already happening in early January.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="3911" end_char="3914">That</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="3916" end_char="3922">finding</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="3924" end_char="3931">supports</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="3933" end_char="3935">the</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="3937" end_char="3940">idea</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="3942" end_char="3945">that</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="3947" end_char="3955">community</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="3957" end_char="3968">transmission</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="3970" end_char="3972">was</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="3974" end_char="3980">already</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="3982" end_char="3990">happening</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="3992" end_char="3993">in</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="3995" end_char="3999">early</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="4001" end_char="4007">January</TOKEN>
<TOKEN id="token-32-14" pos="punct" morph="none" start_char="4008" end_char="4008">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="4011" end_char="4225">
<ORIGINAL_TEXT>A team of infectious-disease researchers in China reported in February that they'd found surges in the use of terms related to the coronavirus on WeChat more than two weeks before officials confirmed the first case.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="4011" end_char="4011">A</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="4013" end_char="4016">team</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="4018" end_char="4019">of</TOKEN>
<TOKEN id="token-33-3" pos="unknown" morph="none" start_char="4021" end_char="4038">infectious-disease</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="4040" end_char="4050">researchers</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="4052" end_char="4053">in</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="4055" end_char="4059">China</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="4061" end_char="4068">reported</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="4070" end_char="4071">in</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="4073" end_char="4080">February</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="4082" end_char="4085">that</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="4087" end_char="4092">they'd</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="4094" end_char="4098">found</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="4100" end_char="4105">surges</TOKEN>
<TOKEN id="token-33-14" pos="word" morph="none" start_char="4107" end_char="4108">in</TOKEN>
<TOKEN id="token-33-15" pos="word" morph="none" start_char="4110" end_char="4112">the</TOKEN>
<TOKEN id="token-33-16" pos="word" morph="none" start_char="4114" end_char="4116">use</TOKEN>
<TOKEN id="token-33-17" pos="word" morph="none" start_char="4118" end_char="4119">of</TOKEN>
<TOKEN id="token-33-18" pos="word" morph="none" start_char="4121" end_char="4125">terms</TOKEN>
<TOKEN id="token-33-19" pos="word" morph="none" start_char="4127" end_char="4133">related</TOKEN>
<TOKEN id="token-33-20" pos="word" morph="none" start_char="4135" end_char="4136">to</TOKEN>
<TOKEN id="token-33-21" pos="word" morph="none" start_char="4138" end_char="4140">the</TOKEN>
<TOKEN id="token-33-22" pos="word" morph="none" start_char="4142" end_char="4152">coronavirus</TOKEN>
<TOKEN id="token-33-23" pos="word" morph="none" start_char="4154" end_char="4155">on</TOKEN>
<TOKEN id="token-33-24" pos="word" morph="none" start_char="4157" end_char="4162">WeChat</TOKEN>
<TOKEN id="token-33-25" pos="word" morph="none" start_char="4164" end_char="4167">more</TOKEN>
<TOKEN id="token-33-26" pos="word" morph="none" start_char="4169" end_char="4172">than</TOKEN>
<TOKEN id="token-33-27" pos="word" morph="none" start_char="4174" end_char="4176">two</TOKEN>
<TOKEN id="token-33-28" pos="word" morph="none" start_char="4178" end_char="4182">weeks</TOKEN>
<TOKEN id="token-33-29" pos="word" morph="none" start_char="4184" end_char="4189">before</TOKEN>
<TOKEN id="token-33-30" pos="word" morph="none" start_char="4191" end_char="4199">officials</TOKEN>
<TOKEN id="token-33-31" pos="word" morph="none" start_char="4201" end_char="4209">confirmed</TOKEN>
<TOKEN id="token-33-32" pos="word" morph="none" start_char="4211" end_char="4213">the</TOKEN>
<TOKEN id="token-33-33" pos="word" morph="none" start_char="4215" end_char="4219">first</TOKEN>
<TOKEN id="token-33-34" pos="word" morph="none" start_char="4221" end_char="4224">case</TOKEN>
<TOKEN id="token-33-35" pos="punct" morph="none" start_char="4225" end_char="4225">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="4228" end_char="4369">
<ORIGINAL_TEXT>What's more, a March study published in the New England Journal of Medicine examined 425 cases of COVID-19 reported in Wuhan as of January 22.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="4228" end_char="4233">What's</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="4235" end_char="4238">more</TOKEN>
<TOKEN id="token-34-2" pos="punct" morph="none" start_char="4239" end_char="4239">,</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="4241" end_char="4241">a</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="4243" end_char="4247">March</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="4249" end_char="4253">study</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="4255" end_char="4263">published</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="4265" end_char="4266">in</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="4268" end_char="4270">the</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="4272" end_char="4274">New</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="4276" end_char="4282">England</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="4284" end_char="4290">Journal</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="4292" end_char="4293">of</TOKEN>
<TOKEN id="token-34-13" pos="word" morph="none" start_char="4295" end_char="4302">Medicine</TOKEN>
<TOKEN id="token-34-14" pos="word" morph="none" start_char="4304" end_char="4311">examined</TOKEN>
<TOKEN id="token-34-15" pos="word" morph="none" start_char="4313" end_char="4315">425</TOKEN>
<TOKEN id="token-34-16" pos="word" morph="none" start_char="4317" end_char="4321">cases</TOKEN>
<TOKEN id="token-34-17" pos="word" morph="none" start_char="4323" end_char="4324">of</TOKEN>
<TOKEN id="token-34-18" pos="unknown" morph="none" start_char="4326" end_char="4333">COVID-19</TOKEN>
<TOKEN id="token-34-19" pos="word" morph="none" start_char="4335" end_char="4342">reported</TOKEN>
<TOKEN id="token-34-20" pos="word" morph="none" start_char="4344" end_char="4345">in</TOKEN>
<TOKEN id="token-34-21" pos="word" morph="none" start_char="4347" end_char="4351">Wuhan</TOKEN>
<TOKEN id="token-34-22" pos="word" morph="none" start_char="4353" end_char="4354">as</TOKEN>
<TOKEN id="token-34-23" pos="word" morph="none" start_char="4356" end_char="4357">of</TOKEN>
<TOKEN id="token-34-24" pos="word" morph="none" start_char="4359" end_char="4365">January</TOKEN>
<TOKEN id="token-34-25" pos="word" morph="none" start_char="4367" end_char="4368">22</TOKEN>
<TOKEN id="token-34-26" pos="punct" morph="none" start_char="4369" end_char="4369">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="4371" end_char="4511">
<ORIGINAL_TEXT>The authors found that 55% of infections that occurred before January 1 were linked to the wet market but only 8.6% of subsequent cases were.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="4371" end_char="4373">The</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="4375" end_char="4381">authors</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="4383" end_char="4387">found</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="4389" end_char="4392">that</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="4394" end_char="4395">55</TOKEN>
<TOKEN id="token-35-5" pos="punct" morph="none" start_char="4396" end_char="4396">%</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="4398" end_char="4399">of</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="4401" end_char="4410">infections</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="4412" end_char="4415">that</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="4417" end_char="4424">occurred</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="4426" end_char="4431">before</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="4433" end_char="4439">January</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="4441" end_char="4441">1</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="4443" end_char="4446">were</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="4448" end_char="4453">linked</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="4455" end_char="4456">to</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="4458" end_char="4460">the</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="4462" end_char="4464">wet</TOKEN>
<TOKEN id="token-35-18" pos="word" morph="none" start_char="4466" end_char="4471">market</TOKEN>
<TOKEN id="token-35-19" pos="word" morph="none" start_char="4473" end_char="4475">but</TOKEN>
<TOKEN id="token-35-20" pos="word" morph="none" start_char="4477" end_char="4480">only</TOKEN>
<TOKEN id="token-35-21" pos="unknown" morph="none" start_char="4482" end_char="4484">8.6</TOKEN>
<TOKEN id="token-35-22" pos="punct" morph="none" start_char="4485" end_char="4485">%</TOKEN>
<TOKEN id="token-35-23" pos="word" morph="none" start_char="4487" end_char="4488">of</TOKEN>
<TOKEN id="token-35-24" pos="word" morph="none" start_char="4490" end_char="4499">subsequent</TOKEN>
<TOKEN id="token-35-25" pos="word" morph="none" start_char="4501" end_char="4505">cases</TOKEN>
<TOKEN id="token-35-26" pos="word" morph="none" start_char="4507" end_char="4510">were</TOKEN>
<TOKEN id="token-35-27" pos="punct" morph="none" start_char="4511" end_char="4511">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="4515" end_char="4676">
<ORIGINAL_TEXT>A medical staff member waves to patients infected with the coronavirus at a temporary hospital converted from the Wuhan Sports Center in Wuhan, February 12, 2020.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="4515" end_char="4515">A</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="4517" end_char="4523">medical</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="4525" end_char="4529">staff</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="4531" end_char="4536">member</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="4538" end_char="4542">waves</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="4544" end_char="4545">to</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="4547" end_char="4554">patients</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="4556" end_char="4563">infected</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="4565" end_char="4568">with</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="4570" end_char="4572">the</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="4574" end_char="4584">coronavirus</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="4586" end_char="4587">at</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="4589" end_char="4589">a</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="4591" end_char="4599">temporary</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="4601" end_char="4608">hospital</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="4610" end_char="4618">converted</TOKEN>
<TOKEN id="token-36-16" pos="word" morph="none" start_char="4620" end_char="4623">from</TOKEN>
<TOKEN id="token-36-17" pos="word" morph="none" start_char="4625" end_char="4627">the</TOKEN>
<TOKEN id="token-36-18" pos="word" morph="none" start_char="4629" end_char="4633">Wuhan</TOKEN>
<TOKEN id="token-36-19" pos="word" morph="none" start_char="4635" end_char="4640">Sports</TOKEN>
<TOKEN id="token-36-20" pos="word" morph="none" start_char="4642" end_char="4647">Center</TOKEN>
<TOKEN id="token-36-21" pos="word" morph="none" start_char="4649" end_char="4650">in</TOKEN>
<TOKEN id="token-36-22" pos="word" morph="none" start_char="4652" end_char="4656">Wuhan</TOKEN>
<TOKEN id="token-36-23" pos="punct" morph="none" start_char="4657" end_char="4657">,</TOKEN>
<TOKEN id="token-36-24" pos="word" morph="none" start_char="4659" end_char="4666">February</TOKEN>
<TOKEN id="token-36-25" pos="word" morph="none" start_char="4668" end_char="4669">12</TOKEN>
<TOKEN id="token-36-26" pos="punct" morph="none" start_char="4670" end_char="4670">,</TOKEN>
<TOKEN id="token-36-27" pos="word" morph="none" start_char="4672" end_char="4675">2020</TOKEN>
<TOKEN id="token-36-28" pos="punct" morph="none" start_char="4676" end_char="4676">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="4679" end_char="4705">
<ORIGINAL_TEXT>Xiao Yijiu/Xinhua via Getty</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="4679" end_char="4682">Xiao</TOKEN>
<TOKEN id="token-37-1" pos="unknown" morph="none" start_char="4684" end_char="4695">Yijiu/Xinhua</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="4697" end_char="4699">via</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="4701" end_char="4705">Getty</TOKEN>
</SEG>
<SEG id="segment-38" start_char="4709" end_char="4885">
<ORIGINAL_TEXT>By analyzing when these early coronavirus patients were exposed and how their illnesses progressed, the researchers were able to estimate how quickly the outbreak grew in Wuhan.</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="4709" end_char="4710">By</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="4712" end_char="4720">analyzing</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="4722" end_char="4725">when</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="4727" end_char="4731">these</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="4733" end_char="4737">early</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="4739" end_char="4749">coronavirus</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="4751" end_char="4758">patients</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="4760" end_char="4763">were</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="4765" end_char="4771">exposed</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="4773" end_char="4775">and</TOKEN>
<TOKEN id="token-38-10" pos="word" morph="none" start_char="4777" end_char="4779">how</TOKEN>
<TOKEN id="token-38-11" pos="word" morph="none" start_char="4781" end_char="4785">their</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="4787" end_char="4795">illnesses</TOKEN>
<TOKEN id="token-38-13" pos="word" morph="none" start_char="4797" end_char="4806">progressed</TOKEN>
<TOKEN id="token-38-14" pos="punct" morph="none" start_char="4807" end_char="4807">,</TOKEN>
<TOKEN id="token-38-15" pos="word" morph="none" start_char="4809" end_char="4811">the</TOKEN>
<TOKEN id="token-38-16" pos="word" morph="none" start_char="4813" end_char="4823">researchers</TOKEN>
<TOKEN id="token-38-17" pos="word" morph="none" start_char="4825" end_char="4828">were</TOKEN>
<TOKEN id="token-38-18" pos="word" morph="none" start_char="4830" end_char="4833">able</TOKEN>
<TOKEN id="token-38-19" pos="word" morph="none" start_char="4835" end_char="4836">to</TOKEN>
<TOKEN id="token-38-20" pos="word" morph="none" start_char="4838" end_char="4845">estimate</TOKEN>
<TOKEN id="token-38-21" pos="word" morph="none" start_char="4847" end_char="4849">how</TOKEN>
<TOKEN id="token-38-22" pos="word" morph="none" start_char="4851" end_char="4857">quickly</TOKEN>
<TOKEN id="token-38-23" pos="word" morph="none" start_char="4859" end_char="4861">the</TOKEN>
<TOKEN id="token-38-24" pos="word" morph="none" start_char="4863" end_char="4870">outbreak</TOKEN>
<TOKEN id="token-38-25" pos="word" morph="none" start_char="4872" end_char="4875">grew</TOKEN>
<TOKEN id="token-38-26" pos="word" morph="none" start_char="4877" end_char="4878">in</TOKEN>
<TOKEN id="token-38-27" pos="word" morph="none" start_char="4880" end_char="4884">Wuhan</TOKEN>
<TOKEN id="token-38-28" pos="punct" morph="none" start_char="4885" end_char="4885">.</TOKEN>
</SEG>
<SEG id="segment-39" start_char="4888" end_char="5020">
<ORIGINAL_TEXT>"There is evidence that human-to-human transmission has occurred among close contacts since the middle of December 2019," they wrote.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="punct" morph="none" start_char="4888" end_char="4888">"</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="4889" end_char="4893">There</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="4895" end_char="4896">is</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="4898" end_char="4905">evidence</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="4907" end_char="4910">that</TOKEN>
<TOKEN id="token-39-5" pos="unknown" morph="none" start_char="4912" end_char="4925">human-to-human</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="4927" end_char="4938">transmission</TOKEN>
<TOKEN id="token-39-7" pos="word" morph="none" start_char="4940" end_char="4942">has</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="4944" end_char="4951">occurred</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="4953" end_char="4957">among</TOKEN>
<TOKEN id="token-39-10" pos="word" morph="none" start_char="4959" end_char="4963">close</TOKEN>
<TOKEN id="token-39-11" pos="word" morph="none" start_char="4965" end_char="4972">contacts</TOKEN>
<TOKEN id="token-39-12" pos="word" morph="none" start_char="4974" end_char="4978">since</TOKEN>
<TOKEN id="token-39-13" pos="word" morph="none" start_char="4980" end_char="4982">the</TOKEN>
<TOKEN id="token-39-14" pos="word" morph="none" start_char="4984" end_char="4989">middle</TOKEN>
<TOKEN id="token-39-15" pos="word" morph="none" start_char="4991" end_char="4992">of</TOKEN>
<TOKEN id="token-39-16" pos="word" morph="none" start_char="4994" end_char="5001">December</TOKEN>
<TOKEN id="token-39-17" pos="word" morph="none" start_char="5003" end_char="5006">2019</TOKEN>
<TOKEN id="token-39-18" pos="punct" morph="none" start_char="5007" end_char="5008">,"</TOKEN>
<TOKEN id="token-39-19" pos="word" morph="none" start_char="5010" end_char="5013">they</TOKEN>
<TOKEN id="token-39-20" pos="word" morph="none" start_char="5015" end_char="5019">wrote</TOKEN>
<TOKEN id="token-39-21" pos="punct" morph="none" start_char="5020" end_char="5020">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="5023" end_char="5140">
<ORIGINAL_TEXT>If authorities had been able to identify the virus earlier, the course of the pandemic might have been very different.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="5023" end_char="5024">If</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="5026" end_char="5036">authorities</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="5038" end_char="5040">had</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="5042" end_char="5045">been</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="5047" end_char="5050">able</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="5052" end_char="5053">to</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="5055" end_char="5062">identify</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="5064" end_char="5066">the</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="5068" end_char="5072">virus</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="5074" end_char="5080">earlier</TOKEN>
<TOKEN id="token-40-10" pos="punct" morph="none" start_char="5081" end_char="5081">,</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="5083" end_char="5085">the</TOKEN>
<TOKEN id="token-40-12" pos="word" morph="none" start_char="5087" end_char="5092">course</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="5094" end_char="5095">of</TOKEN>
<TOKEN id="token-40-14" pos="word" morph="none" start_char="5097" end_char="5099">the</TOKEN>
<TOKEN id="token-40-15" pos="word" morph="none" start_char="5101" end_char="5108">pandemic</TOKEN>
<TOKEN id="token-40-16" pos="word" morph="none" start_char="5110" end_char="5114">might</TOKEN>
<TOKEN id="token-40-17" pos="word" morph="none" start_char="5116" end_char="5119">have</TOKEN>
<TOKEN id="token-40-18" pos="word" morph="none" start_char="5121" end_char="5124">been</TOKEN>
<TOKEN id="token-40-19" pos="word" morph="none" start_char="5126" end_char="5129">very</TOKEN>
<TOKEN id="token-40-20" pos="word" morph="none" start_char="5131" end_char="5139">different</TOKEN>
<TOKEN id="token-40-21" pos="punct" morph="none" start_char="5140" end_char="5140">.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="5142" end_char="5381">
<ORIGINAL_TEXT>A March study showed that if Chinese authorities had acted three weeks earlier to institute travel restrictions, social distancing, and the identification and isolation of patients, coronavirus cases in China would have been reduced by 95%.</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="5142" end_char="5142">A</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="5144" end_char="5148">March</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="5150" end_char="5154">study</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="5156" end_char="5161">showed</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="5163" end_char="5166">that</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="5168" end_char="5169">if</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="5171" end_char="5177">Chinese</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="5179" end_char="5189">authorities</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="5191" end_char="5193">had</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="5195" end_char="5199">acted</TOKEN>
<TOKEN id="token-41-10" pos="word" morph="none" start_char="5201" end_char="5205">three</TOKEN>
<TOKEN id="token-41-11" pos="word" morph="none" start_char="5207" end_char="5211">weeks</TOKEN>
<TOKEN id="token-41-12" pos="word" morph="none" start_char="5213" end_char="5219">earlier</TOKEN>
<TOKEN id="token-41-13" pos="word" morph="none" start_char="5221" end_char="5222">to</TOKEN>
<TOKEN id="token-41-14" pos="word" morph="none" start_char="5224" end_char="5232">institute</TOKEN>
<TOKEN id="token-41-15" pos="word" morph="none" start_char="5234" end_char="5239">travel</TOKEN>
<TOKEN id="token-41-16" pos="word" morph="none" start_char="5241" end_char="5252">restrictions</TOKEN>
<TOKEN id="token-41-17" pos="punct" morph="none" start_char="5253" end_char="5253">,</TOKEN>
<TOKEN id="token-41-18" pos="word" morph="none" start_char="5255" end_char="5260">social</TOKEN>
<TOKEN id="token-41-19" pos="word" morph="none" start_char="5262" end_char="5271">distancing</TOKEN>
<TOKEN id="token-41-20" pos="punct" morph="none" start_char="5272" end_char="5272">,</TOKEN>
<TOKEN id="token-41-21" pos="word" morph="none" start_char="5274" end_char="5276">and</TOKEN>
<TOKEN id="token-41-22" pos="word" morph="none" start_char="5278" end_char="5280">the</TOKEN>
<TOKEN id="token-41-23" pos="word" morph="none" start_char="5282" end_char="5295">identification</TOKEN>
<TOKEN id="token-41-24" pos="word" morph="none" start_char="5297" end_char="5299">and</TOKEN>
<TOKEN id="token-41-25" pos="word" morph="none" start_char="5301" end_char="5309">isolation</TOKEN>
<TOKEN id="token-41-26" pos="word" morph="none" start_char="5311" end_char="5312">of</TOKEN>
<TOKEN id="token-41-27" pos="word" morph="none" start_char="5314" end_char="5321">patients</TOKEN>
<TOKEN id="token-41-28" pos="punct" morph="none" start_char="5322" end_char="5322">,</TOKEN>
<TOKEN id="token-41-29" pos="word" morph="none" start_char="5324" end_char="5334">coronavirus</TOKEN>
<TOKEN id="token-41-30" pos="word" morph="none" start_char="5336" end_char="5340">cases</TOKEN>
<TOKEN id="token-41-31" pos="word" morph="none" start_char="5342" end_char="5343">in</TOKEN>
<TOKEN id="token-41-32" pos="word" morph="none" start_char="5345" end_char="5349">China</TOKEN>
<TOKEN id="token-41-33" pos="word" morph="none" start_char="5351" end_char="5355">would</TOKEN>
<TOKEN id="token-41-34" pos="word" morph="none" start_char="5357" end_char="5360">have</TOKEN>
<TOKEN id="token-41-35" pos="word" morph="none" start_char="5362" end_char="5365">been</TOKEN>
<TOKEN id="token-41-36" pos="word" morph="none" start_char="5367" end_char="5373">reduced</TOKEN>
<TOKEN id="token-41-37" pos="word" morph="none" start_char="5375" end_char="5376">by</TOKEN>
<TOKEN id="token-41-38" pos="word" morph="none" start_char="5378" end_char="5379">95</TOKEN>
<TOKEN id="token-41-39" pos="punct" morph="none" start_char="5380" end_char="5381">%.</TOKEN>
</SEG>
<SEG id="segment-42" start_char="5384" end_char="5419">
<ORIGINAL_TEXT>Why early cases may have been missed</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="5384" end_char="5386">Why</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="5388" end_char="5392">early</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="5394" end_char="5398">cases</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="5400" end_char="5402">may</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="5404" end_char="5407">have</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="5409" end_char="5412">been</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="5414" end_char="5419">missed</TOKEN>
</SEG>
<SEG id="segment-43" start_char="5423" end_char="5668">
<ORIGINAL_TEXT>The identity of "patient zero" still hasn't been confirmed, but it may have been a 55-year-old man from China's Hubei province who was infected on November 17, according to the South China Morning Post (SCMP), which reviewed government documents.</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="5423" end_char="5425">The</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="5427" end_char="5434">identity</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="5436" end_char="5437">of</TOKEN>
<TOKEN id="token-43-3" pos="punct" morph="none" start_char="5439" end_char="5439">"</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="5440" end_char="5446">patient</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="5448" end_char="5451">zero</TOKEN>
<TOKEN id="token-43-6" pos="punct" morph="none" start_char="5452" end_char="5452">"</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="5454" end_char="5458">still</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="5460" end_char="5465">hasn't</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="5467" end_char="5470">been</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="5472" end_char="5480">confirmed</TOKEN>
<TOKEN id="token-43-11" pos="punct" morph="none" start_char="5481" end_char="5481">,</TOKEN>
<TOKEN id="token-43-12" pos="word" morph="none" start_char="5483" end_char="5485">but</TOKEN>
<TOKEN id="token-43-13" pos="word" morph="none" start_char="5487" end_char="5488">it</TOKEN>
<TOKEN id="token-43-14" pos="word" morph="none" start_char="5490" end_char="5492">may</TOKEN>
<TOKEN id="token-43-15" pos="word" morph="none" start_char="5494" end_char="5497">have</TOKEN>
<TOKEN id="token-43-16" pos="word" morph="none" start_char="5499" end_char="5502">been</TOKEN>
<TOKEN id="token-43-17" pos="word" morph="none" start_char="5504" end_char="5504">a</TOKEN>
<TOKEN id="token-43-18" pos="unknown" morph="none" start_char="5506" end_char="5516">55-year-old</TOKEN>
<TOKEN id="token-43-19" pos="word" morph="none" start_char="5518" end_char="5520">man</TOKEN>
<TOKEN id="token-43-20" pos="word" morph="none" start_char="5522" end_char="5525">from</TOKEN>
<TOKEN id="token-43-21" pos="word" morph="none" start_char="5527" end_char="5533">China's</TOKEN>
<TOKEN id="token-43-22" pos="word" morph="none" start_char="5535" end_char="5539">Hubei</TOKEN>
<TOKEN id="token-43-23" pos="word" morph="none" start_char="5541" end_char="5548">province</TOKEN>
<TOKEN id="token-43-24" pos="word" morph="none" start_char="5550" end_char="5552">who</TOKEN>
<TOKEN id="token-43-25" pos="word" morph="none" start_char="5554" end_char="5556">was</TOKEN>
<TOKEN id="token-43-26" pos="word" morph="none" start_char="5558" end_char="5565">infected</TOKEN>
<TOKEN id="token-43-27" pos="word" morph="none" start_char="5567" end_char="5568">on</TOKEN>
<TOKEN id="token-43-28" pos="word" morph="none" start_char="5570" end_char="5577">November</TOKEN>
<TOKEN id="token-43-29" pos="word" morph="none" start_char="5579" end_char="5580">17</TOKEN>
<TOKEN id="token-43-30" pos="punct" morph="none" start_char="5581" end_char="5581">,</TOKEN>
<TOKEN id="token-43-31" pos="word" morph="none" start_char="5583" end_char="5591">according</TOKEN>
<TOKEN id="token-43-32" pos="word" morph="none" start_char="5593" end_char="5594">to</TOKEN>
<TOKEN id="token-43-33" pos="word" morph="none" start_char="5596" end_char="5598">the</TOKEN>
<TOKEN id="token-43-34" pos="word" morph="none" start_char="5600" end_char="5604">South</TOKEN>
<TOKEN id="token-43-35" pos="word" morph="none" start_char="5606" end_char="5610">China</TOKEN>
<TOKEN id="token-43-36" pos="word" morph="none" start_char="5612" end_char="5618">Morning</TOKEN>
<TOKEN id="token-43-37" pos="word" morph="none" start_char="5620" end_char="5623">Post</TOKEN>
<TOKEN id="token-43-38" pos="punct" morph="none" start_char="5625" end_char="5625">(</TOKEN>
<TOKEN id="token-43-39" pos="word" morph="none" start_char="5626" end_char="5629">SCMP</TOKEN>
<TOKEN id="token-43-40" pos="punct" morph="none" start_char="5630" end_char="5631">),</TOKEN>
<TOKEN id="token-43-41" pos="word" morph="none" start_char="5633" end_char="5637">which</TOKEN>
<TOKEN id="token-43-42" pos="word" morph="none" start_char="5639" end_char="5646">reviewed</TOKEN>
<TOKEN id="token-43-43" pos="word" morph="none" start_char="5648" end_char="5657">government</TOKEN>
<TOKEN id="token-43-44" pos="word" morph="none" start_char="5659" end_char="5667">documents</TOKEN>
<TOKEN id="token-43-45" pos="punct" morph="none" start_char="5668" end_char="5668">.</TOKEN>
</SEG>
<SEG id="segment-44" start_char="5671" end_char="5766">
<ORIGINAL_TEXT>The Chinese government has not officially offered or commented on any amended timeline, however.</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="5671" end_char="5673">The</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="5675" end_char="5681">Chinese</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="5683" end_char="5692">government</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="5694" end_char="5696">has</TOKEN>
<TOKEN id="token-44-4" pos="word" morph="none" start_char="5698" end_char="5700">not</TOKEN>
<TOKEN id="token-44-5" pos="word" morph="none" start_char="5702" end_char="5711">officially</TOKEN>
<TOKEN id="token-44-6" pos="word" morph="none" start_char="5713" end_char="5719">offered</TOKEN>
<TOKEN id="token-44-7" pos="word" morph="none" start_char="5721" end_char="5722">or</TOKEN>
<TOKEN id="token-44-8" pos="word" morph="none" start_char="5724" end_char="5732">commented</TOKEN>
<TOKEN id="token-44-9" pos="word" morph="none" start_char="5734" end_char="5735">on</TOKEN>
<TOKEN id="token-44-10" pos="word" morph="none" start_char="5737" end_char="5739">any</TOKEN>
<TOKEN id="token-44-11" pos="word" morph="none" start_char="5741" end_char="5747">amended</TOKEN>
<TOKEN id="token-44-12" pos="word" morph="none" start_char="5749" end_char="5756">timeline</TOKEN>
<TOKEN id="token-44-13" pos="punct" morph="none" start_char="5757" end_char="5757">,</TOKEN>
<TOKEN id="token-44-14" pos="word" morph="none" start_char="5759" end_char="5765">however</TOKEN>
<TOKEN id="token-44-15" pos="punct" morph="none" start_char="5766" end_char="5766">.</TOKEN>
</SEG>
<SEG id="segment-45" start_char="5770" end_char="5867">
<ORIGINAL_TEXT>A man has his temperature checked as he leaves the Hankou railway station in Wuhan, April 7, 2020.</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="5770" end_char="5770">A</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="5772" end_char="5774">man</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="5776" end_char="5778">has</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="5780" end_char="5782">his</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="5784" end_char="5794">temperature</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="5796" end_char="5802">checked</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="5804" end_char="5805">as</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="5807" end_char="5808">he</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="5810" end_char="5815">leaves</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="5817" end_char="5819">the</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="5821" end_char="5826">Hankou</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="5828" end_char="5834">railway</TOKEN>
<TOKEN id="token-45-12" pos="word" morph="none" start_char="5836" end_char="5842">station</TOKEN>
<TOKEN id="token-45-13" pos="word" morph="none" start_char="5844" end_char="5845">in</TOKEN>
<TOKEN id="token-45-14" pos="word" morph="none" start_char="5847" end_char="5851">Wuhan</TOKEN>
<TOKEN id="token-45-15" pos="punct" morph="none" start_char="5852" end_char="5852">,</TOKEN>
<TOKEN id="token-45-16" pos="word" morph="none" start_char="5854" end_char="5858">April</TOKEN>
<TOKEN id="token-45-17" pos="word" morph="none" start_char="5860" end_char="5860">7</TOKEN>
<TOKEN id="token-45-18" pos="punct" morph="none" start_char="5861" end_char="5861">,</TOKEN>
<TOKEN id="token-45-19" pos="word" morph="none" start_char="5863" end_char="5866">2020</TOKEN>
<TOKEN id="token-45-20" pos="punct" morph="none" start_char="5867" end_char="5867">.</TOKEN>
</SEG>
<SEG id="segment-46" start_char="5870" end_char="5904">
<ORIGINAL_TEXT>HECTOR RETAMAL/AFP via Getty Images</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="5870" end_char="5875">HECTOR</TOKEN>
<TOKEN id="token-46-1" pos="unknown" morph="none" start_char="5877" end_char="5887">RETAMAL/AFP</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="5889" end_char="5891">via</TOKEN>
<TOKEN id="token-46-3" pos="word" morph="none" start_char="5893" end_char="5897">Getty</TOKEN>
<TOKEN id="token-46-4" pos="word" morph="none" start_char="5899" end_char="5904">Images</TOKEN>
</SEG>
<SEG id="segment-47" start_char="5908" end_char="6101">
<ORIGINAL_TEXT>It's not surprising, however, that the illness evaded detection for weeks, since experts think up to 50% of people who get infected may not symptoms but can still transmit the illness to others.</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="5908" end_char="5911">It's</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="5913" end_char="5915">not</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="5917" end_char="5926">surprising</TOKEN>
<TOKEN id="token-47-3" pos="punct" morph="none" start_char="5927" end_char="5927">,</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="5929" end_char="5935">however</TOKEN>
<TOKEN id="token-47-5" pos="punct" morph="none" start_char="5936" end_char="5936">,</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="5938" end_char="5941">that</TOKEN>
<TOKEN id="token-47-7" pos="word" morph="none" start_char="5943" end_char="5945">the</TOKEN>
<TOKEN id="token-47-8" pos="word" morph="none" start_char="5947" end_char="5953">illness</TOKEN>
<TOKEN id="token-47-9" pos="word" morph="none" start_char="5955" end_char="5960">evaded</TOKEN>
<TOKEN id="token-47-10" pos="word" morph="none" start_char="5962" end_char="5970">detection</TOKEN>
<TOKEN id="token-47-11" pos="word" morph="none" start_char="5972" end_char="5974">for</TOKEN>
<TOKEN id="token-47-12" pos="word" morph="none" start_char="5976" end_char="5980">weeks</TOKEN>
<TOKEN id="token-47-13" pos="punct" morph="none" start_char="5981" end_char="5981">,</TOKEN>
<TOKEN id="token-47-14" pos="word" morph="none" start_char="5983" end_char="5987">since</TOKEN>
<TOKEN id="token-47-15" pos="word" morph="none" start_char="5989" end_char="5995">experts</TOKEN>
<TOKEN id="token-47-16" pos="word" morph="none" start_char="5997" end_char="6001">think</TOKEN>
<TOKEN id="token-47-17" pos="word" morph="none" start_char="6003" end_char="6004">up</TOKEN>
<TOKEN id="token-47-18" pos="word" morph="none" start_char="6006" end_char="6007">to</TOKEN>
<TOKEN id="token-47-19" pos="word" morph="none" start_char="6009" end_char="6010">50</TOKEN>
<TOKEN id="token-47-20" pos="punct" morph="none" start_char="6011" end_char="6011">%</TOKEN>
<TOKEN id="token-47-21" pos="word" morph="none" start_char="6013" end_char="6014">of</TOKEN>
<TOKEN id="token-47-22" pos="word" morph="none" start_char="6016" end_char="6021">people</TOKEN>
<TOKEN id="token-47-23" pos="word" morph="none" start_char="6023" end_char="6025">who</TOKEN>
<TOKEN id="token-47-24" pos="word" morph="none" start_char="6027" end_char="6029">get</TOKEN>
<TOKEN id="token-47-25" pos="word" morph="none" start_char="6031" end_char="6038">infected</TOKEN>
<TOKEN id="token-47-26" pos="word" morph="none" start_char="6040" end_char="6042">may</TOKEN>
<TOKEN id="token-47-27" pos="word" morph="none" start_char="6044" end_char="6046">not</TOKEN>
<TOKEN id="token-47-28" pos="word" morph="none" start_char="6048" end_char="6055">symptoms</TOKEN>
<TOKEN id="token-47-29" pos="word" morph="none" start_char="6057" end_char="6059">but</TOKEN>
<TOKEN id="token-47-30" pos="word" morph="none" start_char="6061" end_char="6063">can</TOKEN>
<TOKEN id="token-47-31" pos="word" morph="none" start_char="6065" end_char="6069">still</TOKEN>
<TOKEN id="token-47-32" pos="word" morph="none" start_char="6071" end_char="6078">transmit</TOKEN>
<TOKEN id="token-47-33" pos="word" morph="none" start_char="6080" end_char="6082">the</TOKEN>
<TOKEN id="token-47-34" pos="word" morph="none" start_char="6084" end_char="6090">illness</TOKEN>
<TOKEN id="token-47-35" pos="word" morph="none" start_char="6092" end_char="6093">to</TOKEN>
<TOKEN id="token-47-36" pos="word" morph="none" start_char="6095" end_char="6100">others</TOKEN>
<TOKEN id="token-47-37" pos="punct" morph="none" start_char="6101" end_char="6101">.</TOKEN>
</SEG>
<SEG id="segment-48" start_char="6104" end_char="6263">
<ORIGINAL_TEXT>The authors of the new Nature study also noted that diagnostic testing didn't become widely available in Wuhan until January 23, after the city was locked down.</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="6104" end_char="6106">The</TOKEN>
<TOKEN id="token-48-1" pos="word" morph="none" start_char="6108" end_char="6114">authors</TOKEN>
<TOKEN id="token-48-2" pos="word" morph="none" start_char="6116" end_char="6117">of</TOKEN>
<TOKEN id="token-48-3" pos="word" morph="none" start_char="6119" end_char="6121">the</TOKEN>
<TOKEN id="token-48-4" pos="word" morph="none" start_char="6123" end_char="6125">new</TOKEN>
<TOKEN id="token-48-5" pos="word" morph="none" start_char="6127" end_char="6132">Nature</TOKEN>
<TOKEN id="token-48-6" pos="word" morph="none" start_char="6134" end_char="6138">study</TOKEN>
<TOKEN id="token-48-7" pos="word" morph="none" start_char="6140" end_char="6143">also</TOKEN>
<TOKEN id="token-48-8" pos="word" morph="none" start_char="6145" end_char="6149">noted</TOKEN>
<TOKEN id="token-48-9" pos="word" morph="none" start_char="6151" end_char="6154">that</TOKEN>
<TOKEN id="token-48-10" pos="word" morph="none" start_char="6156" end_char="6165">diagnostic</TOKEN>
<TOKEN id="token-48-11" pos="word" morph="none" start_char="6167" end_char="6173">testing</TOKEN>
<TOKEN id="token-48-12" pos="word" morph="none" start_char="6175" end_char="6180">didn't</TOKEN>
<TOKEN id="token-48-13" pos="word" morph="none" start_char="6182" end_char="6187">become</TOKEN>
<TOKEN id="token-48-14" pos="word" morph="none" start_char="6189" end_char="6194">widely</TOKEN>
<TOKEN id="token-48-15" pos="word" morph="none" start_char="6196" end_char="6204">available</TOKEN>
<TOKEN id="token-48-16" pos="word" morph="none" start_char="6206" end_char="6207">in</TOKEN>
<TOKEN id="token-48-17" pos="word" morph="none" start_char="6209" end_char="6213">Wuhan</TOKEN>
<TOKEN id="token-48-18" pos="word" morph="none" start_char="6215" end_char="6219">until</TOKEN>
<TOKEN id="token-48-19" pos="word" morph="none" start_char="6221" end_char="6227">January</TOKEN>
<TOKEN id="token-48-20" pos="word" morph="none" start_char="6229" end_char="6230">23</TOKEN>
<TOKEN id="token-48-21" pos="punct" morph="none" start_char="6231" end_char="6231">,</TOKEN>
<TOKEN id="token-48-22" pos="word" morph="none" start_char="6233" end_char="6237">after</TOKEN>
<TOKEN id="token-48-23" pos="word" morph="none" start_char="6239" end_char="6241">the</TOKEN>
<TOKEN id="token-48-24" pos="word" morph="none" start_char="6243" end_char="6246">city</TOKEN>
<TOKEN id="token-48-25" pos="word" morph="none" start_char="6248" end_char="6250">was</TOKEN>
<TOKEN id="token-48-26" pos="word" morph="none" start_char="6252" end_char="6257">locked</TOKEN>
<TOKEN id="token-48-27" pos="word" morph="none" start_char="6259" end_char="6262">down</TOKEN>
<TOKEN id="token-48-28" pos="punct" morph="none" start_char="6263" end_char="6263">.</TOKEN>
</SEG>
<SEG id="segment-49" start_char="6266" end_char="6286">
<ORIGINAL_TEXT>Something is loading.</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="6266" end_char="6274">Something</TOKEN>
<TOKEN id="token-49-1" pos="word" morph="none" start_char="6276" end_char="6277">is</TOKEN>
<TOKEN id="token-49-2" pos="word" morph="none" start_char="6279" end_char="6285">loading</TOKEN>
<TOKEN id="token-49-3" pos="punct" morph="none" start_char="6286" end_char="6286">.</TOKEN>
</SEG>
<SEG id="segment-50" start_char="6289" end_char="6323">
<ORIGINAL_TEXT>Two crossed lines that form an 'X'.</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="6289" end_char="6291">Two</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="6293" end_char="6299">crossed</TOKEN>
<TOKEN id="token-50-2" pos="word" morph="none" start_char="6301" end_char="6305">lines</TOKEN>
<TOKEN id="token-50-3" pos="word" morph="none" start_char="6307" end_char="6310">that</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="6312" end_char="6315">form</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="6317" end_char="6318">an</TOKEN>
<TOKEN id="token-50-6" pos="punct" morph="none" start_char="6320" end_char="6320">'</TOKEN>
<TOKEN id="token-50-7" pos="word" morph="none" start_char="6321" end_char="6321">X</TOKEN>
<TOKEN id="token-50-8" pos="punct" morph="none" start_char="6322" end_char="6323">'.</TOKEN>
</SEG>
<SEG id="segment-51" start_char="6325" end_char="6394">
<ORIGINAL_TEXT>It indicates a way to close an interaction, or dismiss a notification.</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="word" morph="none" start_char="6325" end_char="6326">It</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="6328" end_char="6336">indicates</TOKEN>
<TOKEN id="token-51-2" pos="word" morph="none" start_char="6338" end_char="6338">a</TOKEN>
<TOKEN id="token-51-3" pos="word" morph="none" start_char="6340" end_char="6342">way</TOKEN>
<TOKEN id="token-51-4" pos="word" morph="none" start_char="6344" end_char="6345">to</TOKEN>
<TOKEN id="token-51-5" pos="word" morph="none" start_char="6347" end_char="6351">close</TOKEN>
<TOKEN id="token-51-6" pos="word" morph="none" start_char="6353" end_char="6354">an</TOKEN>
<TOKEN id="token-51-7" pos="word" morph="none" start_char="6356" end_char="6366">interaction</TOKEN>
<TOKEN id="token-51-8" pos="punct" morph="none" start_char="6367" end_char="6367">,</TOKEN>
<TOKEN id="token-51-9" pos="word" morph="none" start_char="6369" end_char="6370">or</TOKEN>
<TOKEN id="token-51-10" pos="word" morph="none" start_char="6372" end_char="6378">dismiss</TOKEN>
<TOKEN id="token-51-11" pos="word" morph="none" start_char="6380" end_char="6380">a</TOKEN>
<TOKEN id="token-51-12" pos="word" morph="none" start_char="6382" end_char="6393">notification</TOKEN>
<TOKEN id="token-51-13" pos="punct" morph="none" start_char="6394" end_char="6394">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
