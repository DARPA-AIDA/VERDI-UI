<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CVMC" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="9024" raw_text_md5="f4b2c3db6027a6f29346f0dc54667384">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="94">
<ORIGINAL_TEXT>Covid-19: la extraña empresa detrás del cambio de opinión de la OMS sobre la Hidroxicloroquina</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="unknown" morph="none" start_char="1" end_char="8">Covid-19</TOKEN>
<TOKEN id="token-0-1" pos="punct" morph="none" start_char="9" end_char="9">:</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="11" end_char="12">la</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="14" end_char="20">extraña</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="22" end_char="28">empresa</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="30" end_char="35">detrás</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="37" end_char="39">del</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="41" end_char="46">cambio</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="48" end_char="49">de</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="51" end_char="57">opinión</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="59" end_char="60">de</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="62" end_char="63">la</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="65" end_char="67">OMS</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="69" end_char="73">sobre</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="75" end_char="76">la</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="78" end_char="94">Hidroxicloroquina</TOKEN>
</SEG>
<SEG id="segment-1" start_char="98" end_char="213">
<ORIGINAL_TEXT>Este ha sido uno de los giros de 180 grados más rápidos en la historia de la Organización Mundial de la Salud (OMS).</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="98" end_char="101">Este</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="103" end_char="104">ha</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="106" end_char="109">sido</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="111" end_char="113">uno</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="115" end_char="116">de</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="118" end_char="120">los</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="122" end_char="126">giros</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="128" end_char="129">de</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="131" end_char="133">180</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="135" end_char="140">grados</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="142" end_char="144">más</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="146" end_char="152">rápidos</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="154" end_char="155">en</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="157" end_char="158">la</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="160" end_char="167">historia</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="169" end_char="170">de</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="172" end_char="173">la</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="175" end_char="186">Organización</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="188" end_char="194">Mundial</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="196" end_char="197">de</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="199" end_char="200">la</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="202" end_char="206">Salud</TOKEN>
<TOKEN id="token-1-22" pos="punct" morph="none" start_char="208" end_char="208">(</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="209" end_char="211">OMS</TOKEN>
<TOKEN id="token-1-24" pos="punct" morph="none" start_char="212" end_char="213">).</TOKEN>
</SEG>
<SEG id="segment-2" start_char="215" end_char="451">
<ORIGINAL_TEXT>Esta última anunció el miércoles 3 de junio su intención de retomar las pruebas clínicas sobre el uso de la Hidroxicloroquina para tratar a los pacientes afectados por el Covid-19… tan solo diez días después de haber detenido el proceso.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="215" end_char="218">Esta</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="220" end_char="225">última</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="227" end_char="233">anunció</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="235" end_char="236">el</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="238" end_char="246">miércoles</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="248" end_char="248">3</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="250" end_char="251">de</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="253" end_char="257">junio</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="259" end_char="260">su</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="262" end_char="270">intención</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="272" end_char="273">de</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="275" end_char="281">retomar</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="283" end_char="285">las</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="287" end_char="293">pruebas</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="295" end_char="302">clínicas</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="304" end_char="308">sobre</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="310" end_char="311">el</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="313" end_char="315">uso</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="317" end_char="318">de</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="320" end_char="321">la</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="323" end_char="339">Hidroxicloroquina</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="341" end_char="344">para</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="346" end_char="351">tratar</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="353" end_char="353">a</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="355" end_char="357">los</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="359" end_char="367">pacientes</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="369" end_char="377">afectados</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="379" end_char="381">por</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="383" end_char="384">el</TOKEN>
<TOKEN id="token-2-29" pos="unknown" morph="none" start_char="386" end_char="393">Covid-19</TOKEN>
<TOKEN id="token-2-30" pos="punct" morph="none" start_char="394" end_char="394">…</TOKEN>
<TOKEN id="token-2-31" pos="word" morph="none" start_char="396" end_char="398">tan</TOKEN>
<TOKEN id="token-2-32" pos="word" morph="none" start_char="400" end_char="403">solo</TOKEN>
<TOKEN id="token-2-33" pos="word" morph="none" start_char="405" end_char="408">diez</TOKEN>
<TOKEN id="token-2-34" pos="word" morph="none" start_char="410" end_char="413">días</TOKEN>
<TOKEN id="token-2-35" pos="word" morph="none" start_char="415" end_char="421">después</TOKEN>
<TOKEN id="token-2-36" pos="word" morph="none" start_char="423" end_char="424">de</TOKEN>
<TOKEN id="token-2-37" pos="word" morph="none" start_char="426" end_char="430">haber</TOKEN>
<TOKEN id="token-2-38" pos="word" morph="none" start_char="432" end_char="439">detenido</TOKEN>
<TOKEN id="token-2-39" pos="word" morph="none" start_char="441" end_char="442">el</TOKEN>
<TOKEN id="token-2-40" pos="word" morph="none" start_char="444" end_char="450">proceso</TOKEN>
<TOKEN id="token-2-41" pos="punct" morph="none" start_char="451" end_char="451">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="454" end_char="647">
<ORIGINAL_TEXT>Se abre un nuevo capítulo en la ya turbulenta historia de este medicamento contra el paludismo que el presidente estadounidense Donald Trump asegura haber tomado para protegerse del coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="454" end_char="455">Se</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="457" end_char="460">abre</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="462" end_char="463">un</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="465" end_char="469">nuevo</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="471" end_char="478">capítulo</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="480" end_char="481">en</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="483" end_char="484">la</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="486" end_char="487">ya</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="489" end_char="498">turbulenta</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="500" end_char="507">historia</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="509" end_char="510">de</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="512" end_char="515">este</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="517" end_char="527">medicamento</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="529" end_char="534">contra</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="536" end_char="537">el</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="539" end_char="547">paludismo</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="549" end_char="551">que</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="553" end_char="554">el</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="556" end_char="565">presidente</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="567" end_char="580">estadounidense</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="582" end_char="587">Donald</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="589" end_char="593">Trump</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="595" end_char="601">asegura</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="603" end_char="607">haber</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="609" end_char="614">tomado</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="616" end_char="619">para</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="621" end_char="630">protegerse</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="632" end_char="634">del</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="636" end_char="646">coronavirus</TOKEN>
<TOKEN id="token-3-29" pos="punct" morph="none" start_char="647" end_char="647">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="649" end_char="753">
<ORIGINAL_TEXT>Un cambio que también mancha la reputación de la muy respetada revista científica británica 'The Lancet'.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="649" end_char="650">Un</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="652" end_char="657">cambio</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="659" end_char="661">que</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="663" end_char="669">también</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="671" end_char="676">mancha</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="678" end_char="679">la</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="681" end_char="690">reputación</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="692" end_char="693">de</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="695" end_char="696">la</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="698" end_char="700">muy</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="702" end_char="710">respetada</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="712" end_char="718">revista</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="720" end_char="729">científica</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="731" end_char="739">británica</TOKEN>
<TOKEN id="token-4-14" pos="punct" morph="none" start_char="741" end_char="741">'</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="742" end_char="744">The</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="746" end_char="751">Lancet</TOKEN>
<TOKEN id="token-4-17" pos="punct" morph="none" start_char="752" end_char="753">'.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="756" end_char="1032">
<ORIGINAL_TEXT>En efecto, la OMS había decidido detener las pruebas sobre la eficacia de la Hidroxicloroquina tras la publicación de un artículo en esta revista donde se "demostraba" que ese tratamiento aumentaba el riesgo de complicaciones cardíacas entre los pacientes enfermos de Covid-19.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="756" end_char="757">En</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="759" end_char="764">efecto</TOKEN>
<TOKEN id="token-5-2" pos="punct" morph="none" start_char="765" end_char="765">,</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="767" end_char="768">la</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="770" end_char="772">OMS</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="774" end_char="778">había</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="780" end_char="787">decidido</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="789" end_char="795">detener</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="797" end_char="799">las</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="801" end_char="807">pruebas</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="809" end_char="813">sobre</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="815" end_char="816">la</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="818" end_char="825">eficacia</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="827" end_char="828">de</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="830" end_char="831">la</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="833" end_char="849">Hidroxicloroquina</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="851" end_char="854">tras</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="856" end_char="857">la</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="859" end_char="869">publicación</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="871" end_char="872">de</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="874" end_char="875">un</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="877" end_char="884">artículo</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="886" end_char="887">en</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="889" end_char="892">esta</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="894" end_char="900">revista</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="902" end_char="906">donde</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="908" end_char="909">se</TOKEN>
<TOKEN id="token-5-27" pos="punct" morph="none" start_char="911" end_char="911">"</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="912" end_char="921">demostraba</TOKEN>
<TOKEN id="token-5-29" pos="punct" morph="none" start_char="922" end_char="922">"</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="924" end_char="926">que</TOKEN>
<TOKEN id="token-5-31" pos="word" morph="none" start_char="928" end_char="930">ese</TOKEN>
<TOKEN id="token-5-32" pos="word" morph="none" start_char="932" end_char="942">tratamiento</TOKEN>
<TOKEN id="token-5-33" pos="word" morph="none" start_char="944" end_char="952">aumentaba</TOKEN>
<TOKEN id="token-5-34" pos="word" morph="none" start_char="954" end_char="955">el</TOKEN>
<TOKEN id="token-5-35" pos="word" morph="none" start_char="957" end_char="962">riesgo</TOKEN>
<TOKEN id="token-5-36" pos="word" morph="none" start_char="964" end_char="965">de</TOKEN>
<TOKEN id="token-5-37" pos="word" morph="none" start_char="967" end_char="980">complicaciones</TOKEN>
<TOKEN id="token-5-38" pos="word" morph="none" start_char="982" end_char="990">cardíacas</TOKEN>
<TOKEN id="token-5-39" pos="word" morph="none" start_char="992" end_char="996">entre</TOKEN>
<TOKEN id="token-5-40" pos="word" morph="none" start_char="998" end_char="1000">los</TOKEN>
<TOKEN id="token-5-41" pos="word" morph="none" start_char="1002" end_char="1010">pacientes</TOKEN>
<TOKEN id="token-5-42" pos="word" morph="none" start_char="1012" end_char="1019">enfermos</TOKEN>
<TOKEN id="token-5-43" pos="word" morph="none" start_char="1021" end_char="1022">de</TOKEN>
<TOKEN id="token-5-44" pos="unknown" morph="none" start_char="1024" end_char="1031">Covid-19</TOKEN>
<TOKEN id="token-5-45" pos="punct" morph="none" start_char="1032" end_char="1032">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="1034" end_char="1093">
<ORIGINAL_TEXT>Otros centros de investigación siguieron este mismo ejemplo.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="1034" end_char="1038">Otros</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="1040" end_char="1046">centros</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="1048" end_char="1049">de</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="1051" end_char="1063">investigación</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="1065" end_char="1073">siguieron</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="1075" end_char="1078">este</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="1080" end_char="1084">mismo</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="1086" end_char="1092">ejemplo</TOKEN>
<TOKEN id="token-6-8" pos="punct" morph="none" start_char="1093" end_char="1093">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="1095" end_char="1229">
<ORIGINAL_TEXT>Decisiones con importantes consecuencias en plena pandemia, mientras la carrera por encontrar una solución eficaz está en pleno apogeo.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="1095" end_char="1104">Decisiones</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="1106" end_char="1108">con</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="1110" end_char="1120">importantes</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="1122" end_char="1134">consecuencias</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="1136" end_char="1137">en</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="1139" end_char="1143">plena</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="1145" end_char="1152">pandemia</TOKEN>
<TOKEN id="token-7-7" pos="punct" morph="none" start_char="1153" end_char="1153">,</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="1155" end_char="1162">mientras</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="1164" end_char="1165">la</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="1167" end_char="1173">carrera</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="1175" end_char="1177">por</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="1179" end_char="1187">encontrar</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="1189" end_char="1191">una</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="1193" end_char="1200">solución</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="1202" end_char="1207">eficaz</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="1209" end_char="1212">está</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="1214" end_char="1215">en</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="1217" end_char="1221">pleno</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="1223" end_char="1228">apogeo</TOKEN>
<TOKEN id="token-7-20" pos="punct" morph="none" start_char="1229" end_char="1229">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1232" end_char="1264">
<ORIGINAL_TEXT>Surgisphere y sus cinco empleados</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1232" end_char="1242">Surgisphere</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1244" end_char="1244">y</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1246" end_char="1248">sus</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1250" end_char="1254">cinco</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1256" end_char="1264">empleados</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1267" end_char="1425">
<ORIGINAL_TEXT>Cabe resaltar que 'The Lancet' publicó el 3 de junio una "advertencia" relacionada con el famoso artículo, sugiriendo que tal vez podía haber 'gato encerrado'.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1267" end_char="1270">Cabe</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1272" end_char="1279">resaltar</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1281" end_char="1283">que</TOKEN>
<TOKEN id="token-9-3" pos="punct" morph="none" start_char="1285" end_char="1285">'</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1286" end_char="1288">The</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1290" end_char="1295">Lancet</TOKEN>
<TOKEN id="token-9-6" pos="punct" morph="none" start_char="1296" end_char="1296">'</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1298" end_char="1304">publicó</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1306" end_char="1307">el</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1309" end_char="1309">3</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1311" end_char="1312">de</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1314" end_char="1318">junio</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1320" end_char="1322">una</TOKEN>
<TOKEN id="token-9-13" pos="punct" morph="none" start_char="1324" end_char="1324">"</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1325" end_char="1335">advertencia</TOKEN>
<TOKEN id="token-9-15" pos="punct" morph="none" start_char="1336" end_char="1336">"</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1338" end_char="1348">relacionada</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1350" end_char="1352">con</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1354" end_char="1355">el</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1357" end_char="1362">famoso</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1364" end_char="1371">artículo</TOKEN>
<TOKEN id="token-9-21" pos="punct" morph="none" start_char="1372" end_char="1372">,</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1374" end_char="1383">sugiriendo</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1385" end_char="1387">que</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1389" end_char="1391">tal</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1393" end_char="1395">vez</TOKEN>
<TOKEN id="token-9-26" pos="word" morph="none" start_char="1397" end_char="1401">podía</TOKEN>
<TOKEN id="token-9-27" pos="word" morph="none" start_char="1403" end_char="1407">haber</TOKEN>
<TOKEN id="token-9-28" pos="punct" morph="none" start_char="1409" end_char="1409">'</TOKEN>
<TOKEN id="token-9-29" pos="word" morph="none" start_char="1410" end_char="1413">gato</TOKEN>
<TOKEN id="token-9-30" pos="word" morph="none" start_char="1415" end_char="1423">encerrado</TOKEN>
<TOKEN id="token-9-31" pos="punct" morph="none" start_char="1424" end_char="1425">'.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1427" end_char="1620">
<ORIGINAL_TEXT>Era hora: una parte de la comunidad científica arremetió contra este estudio, cuyas conclusiones fueron consideradas discutibles por los más educados y completamente falsas por los más extremos.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1427" end_char="1429">Era</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1431" end_char="1434">hora</TOKEN>
<TOKEN id="token-10-2" pos="punct" morph="none" start_char="1435" end_char="1435">:</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1437" end_char="1439">una</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1441" end_char="1445">parte</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1447" end_char="1448">de</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1450" end_char="1451">la</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1453" end_char="1461">comunidad</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1463" end_char="1472">científica</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1474" end_char="1482">arremetió</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1484" end_char="1489">contra</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1491" end_char="1494">este</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1496" end_char="1502">estudio</TOKEN>
<TOKEN id="token-10-13" pos="punct" morph="none" start_char="1503" end_char="1503">,</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1505" end_char="1509">cuyas</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1511" end_char="1522">conclusiones</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1524" end_char="1529">fueron</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1531" end_char="1542">consideradas</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1544" end_char="1554">discutibles</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1556" end_char="1558">por</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1560" end_char="1562">los</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1564" end_char="1566">más</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1568" end_char="1575">educados</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1577" end_char="1577">y</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1579" end_char="1591">completamente</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="1593" end_char="1598">falsas</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="1600" end_char="1602">por</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="1604" end_char="1606">los</TOKEN>
<TOKEN id="token-10-28" pos="word" morph="none" start_char="1608" end_char="1610">más</TOKEN>
<TOKEN id="token-10-29" pos="word" morph="none" start_char="1612" end_char="1619">extremos</TOKEN>
<TOKEN id="token-10-30" pos="punct" morph="none" start_char="1620" end_char="1620">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1623" end_char="1882">
<ORIGINAL_TEXT>La furia de los investigadores, resumida en una carta abierta firmada por más de 100 científicos, se concentró particularmente contra Surgisphere, una pequeña empresa estadounidense de biotecnología dirigida por uno de los co-autores del controvertido estudio.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1623" end_char="1624">La</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1626" end_char="1630">furia</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1632" end_char="1633">de</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1635" end_char="1637">los</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1639" end_char="1652">investigadores</TOKEN>
<TOKEN id="token-11-5" pos="punct" morph="none" start_char="1653" end_char="1653">,</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1655" end_char="1662">resumida</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1664" end_char="1665">en</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1667" end_char="1669">una</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1671" end_char="1675">carta</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1677" end_char="1683">abierta</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1685" end_char="1691">firmada</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1693" end_char="1695">por</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1697" end_char="1699">más</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1701" end_char="1702">de</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1704" end_char="1706">100</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1708" end_char="1718">científicos</TOKEN>
<TOKEN id="token-11-17" pos="punct" morph="none" start_char="1719" end_char="1719">,</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1721" end_char="1722">se</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="1724" end_char="1732">concentró</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1734" end_char="1748">particularmente</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="1750" end_char="1755">contra</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="1757" end_char="1767">Surgisphere</TOKEN>
<TOKEN id="token-11-23" pos="punct" morph="none" start_char="1768" end_char="1768">,</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="1770" end_char="1772">una</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="1774" end_char="1780">pequeña</TOKEN>
<TOKEN id="token-11-26" pos="word" morph="none" start_char="1782" end_char="1788">empresa</TOKEN>
<TOKEN id="token-11-27" pos="word" morph="none" start_char="1790" end_char="1803">estadounidense</TOKEN>
<TOKEN id="token-11-28" pos="word" morph="none" start_char="1805" end_char="1806">de</TOKEN>
<TOKEN id="token-11-29" pos="word" morph="none" start_char="1808" end_char="1820">biotecnología</TOKEN>
<TOKEN id="token-11-30" pos="word" morph="none" start_char="1822" end_char="1829">dirigida</TOKEN>
<TOKEN id="token-11-31" pos="word" morph="none" start_char="1831" end_char="1833">por</TOKEN>
<TOKEN id="token-11-32" pos="word" morph="none" start_char="1835" end_char="1837">uno</TOKEN>
<TOKEN id="token-11-33" pos="word" morph="none" start_char="1839" end_char="1840">de</TOKEN>
<TOKEN id="token-11-34" pos="word" morph="none" start_char="1842" end_char="1844">los</TOKEN>
<TOKEN id="token-11-35" pos="unknown" morph="none" start_char="1846" end_char="1855">co-autores</TOKEN>
<TOKEN id="token-11-36" pos="word" morph="none" start_char="1857" end_char="1859">del</TOKEN>
<TOKEN id="token-11-37" pos="word" morph="none" start_char="1861" end_char="1873">controvertido</TOKEN>
<TOKEN id="token-11-38" pos="word" morph="none" start_char="1875" end_char="1881">estudio</TOKEN>
<TOKEN id="token-11-39" pos="punct" morph="none" start_char="1882" end_char="1882">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1885" end_char="2003">
<ORIGINAL_TEXT>Fue esta empresa la que proporcionó todos los datos médicos que permitieron evaluar el impacto de la Hidroxicloroquina.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1885" end_char="1887">Fue</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1889" end_char="1892">esta</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1894" end_char="1900">empresa</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1902" end_char="1903">la</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1905" end_char="1907">que</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1909" end_char="1919">proporcionó</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1921" end_char="1925">todos</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1927" end_char="1929">los</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1931" end_char="1935">datos</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1937" end_char="1943">médicos</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1945" end_char="1947">que</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1949" end_char="1959">permitieron</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1961" end_char="1967">evaluar</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1969" end_char="1970">el</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1972" end_char="1978">impacto</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1980" end_char="1981">de</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1983" end_char="1984">la</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1986" end_char="2002">Hidroxicloroquina</TOKEN>
<TOKEN id="token-12-18" pos="punct" morph="none" start_char="2003" end_char="2003">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="2005" end_char="2242">
<ORIGINAL_TEXT>De manera general, los autores del estudio afirman que gracias a Surgisphere tuvieron acceso a las informaciones de salud de más de 96.032 pacientes contaminados con coronavirus y hospitalizados en 671 hospitales, en los seis continentes.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="2005" end_char="2006">De</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="2008" end_char="2013">manera</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="2015" end_char="2021">general</TOKEN>
<TOKEN id="token-13-3" pos="punct" morph="none" start_char="2022" end_char="2022">,</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="2024" end_char="2026">los</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="2028" end_char="2034">autores</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="2036" end_char="2038">del</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="2040" end_char="2046">estudio</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="2048" end_char="2054">afirman</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="2056" end_char="2058">que</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="2060" end_char="2066">gracias</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="2068" end_char="2068">a</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="2070" end_char="2080">Surgisphere</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="2082" end_char="2089">tuvieron</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="2091" end_char="2096">acceso</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="2098" end_char="2098">a</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="2100" end_char="2102">las</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="2104" end_char="2116">informaciones</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="2118" end_char="2119">de</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="2121" end_char="2125">salud</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="2127" end_char="2128">de</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="2130" end_char="2132">más</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="2134" end_char="2135">de</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="2137" end_char="2142">96.032</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="2144" end_char="2152">pacientes</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="2154" end_char="2165">contaminados</TOKEN>
<TOKEN id="token-13-26" pos="word" morph="none" start_char="2167" end_char="2169">con</TOKEN>
<TOKEN id="token-13-27" pos="word" morph="none" start_char="2171" end_char="2181">coronavirus</TOKEN>
<TOKEN id="token-13-28" pos="word" morph="none" start_char="2183" end_char="2183">y</TOKEN>
<TOKEN id="token-13-29" pos="word" morph="none" start_char="2185" end_char="2198">hospitalizados</TOKEN>
<TOKEN id="token-13-30" pos="word" morph="none" start_char="2200" end_char="2201">en</TOKEN>
<TOKEN id="token-13-31" pos="word" morph="none" start_char="2203" end_char="2205">671</TOKEN>
<TOKEN id="token-13-32" pos="word" morph="none" start_char="2207" end_char="2216">hospitales</TOKEN>
<TOKEN id="token-13-33" pos="punct" morph="none" start_char="2217" end_char="2217">,</TOKEN>
<TOKEN id="token-13-34" pos="word" morph="none" start_char="2219" end_char="2220">en</TOKEN>
<TOKEN id="token-13-35" pos="word" morph="none" start_char="2222" end_char="2224">los</TOKEN>
<TOKEN id="token-13-36" pos="word" morph="none" start_char="2226" end_char="2229">seis</TOKEN>
<TOKEN id="token-13-37" pos="word" morph="none" start_char="2231" end_char="2241">continentes</TOKEN>
<TOKEN id="token-13-38" pos="punct" morph="none" start_char="2242" end_char="2242">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="2245" end_char="2336">
<ORIGINAL_TEXT>Una inmensa base de datos… de la cual nadie o casi nadie había oído hablar hasta el momento.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="2245" end_char="2247">Una</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="2249" end_char="2255">inmensa</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="2257" end_char="2260">base</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="2262" end_char="2263">de</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="2265" end_char="2269">datos</TOKEN>
<TOKEN id="token-14-5" pos="punct" morph="none" start_char="2270" end_char="2270">…</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="2272" end_char="2273">de</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="2275" end_char="2276">la</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="2278" end_char="2281">cual</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="2283" end_char="2287">nadie</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="2289" end_char="2289">o</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="2291" end_char="2294">casi</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="2296" end_char="2300">nadie</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="2302" end_char="2306">había</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="2308" end_char="2311">oído</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="2313" end_char="2318">hablar</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="2320" end_char="2324">hasta</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="2326" end_char="2327">el</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="2329" end_char="2335">momento</TOKEN>
<TOKEN id="token-14-19" pos="punct" morph="none" start_char="2336" end_char="2336">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="2338" end_char="2469">
<ORIGINAL_TEXT>Por una simple razón: la empresa de Illinois que administra dicha información parece haber salido de la nada en tan solo unos meses.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="2338" end_char="2340">Por</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="2342" end_char="2344">una</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="2346" end_char="2351">simple</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="2353" end_char="2357">razón</TOKEN>
<TOKEN id="token-15-4" pos="punct" morph="none" start_char="2358" end_char="2358">:</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="2360" end_char="2361">la</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="2363" end_char="2369">empresa</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="2371" end_char="2372">de</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="2374" end_char="2381">Illinois</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="2383" end_char="2385">que</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="2387" end_char="2396">administra</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="2398" end_char="2402">dicha</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="2404" end_char="2414">información</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="2416" end_char="2421">parece</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="2423" end_char="2427">haber</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="2429" end_char="2434">salido</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="2436" end_char="2437">de</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="2439" end_char="2440">la</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="2442" end_char="2445">nada</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="2447" end_char="2448">en</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="2450" end_char="2452">tan</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="2454" end_char="2457">solo</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="2459" end_char="2462">unos</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="2464" end_char="2468">meses</TOKEN>
<TOKEN id="token-15-24" pos="punct" morph="none" start_char="2469" end_char="2469">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="2471" end_char="2654">
<ORIGINAL_TEXT>Sapan Desai, director general de Surgisphere y antiguo cirujano, asegura que fue fundada en 2009 y que trabaja desde hace años recolectando estas informaciones médicas ultra-sensibles.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="2471" end_char="2475">Sapan</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="2477" end_char="2481">Desai</TOKEN>
<TOKEN id="token-16-2" pos="punct" morph="none" start_char="2482" end_char="2482">,</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="2484" end_char="2491">director</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="2493" end_char="2499">general</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="2501" end_char="2502">de</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="2504" end_char="2514">Surgisphere</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="2516" end_char="2516">y</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="2518" end_char="2524">antiguo</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="2526" end_char="2533">cirujano</TOKEN>
<TOKEN id="token-16-10" pos="punct" morph="none" start_char="2534" end_char="2534">,</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="2536" end_char="2542">asegura</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="2544" end_char="2546">que</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="2548" end_char="2550">fue</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="2552" end_char="2558">fundada</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="2560" end_char="2561">en</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="2563" end_char="2566">2009</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="2568" end_char="2568">y</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="2570" end_char="2572">que</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="2574" end_char="2580">trabaja</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="2582" end_char="2586">desde</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="2588" end_char="2591">hace</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="2593" end_char="2596">años</TOKEN>
<TOKEN id="token-16-23" pos="word" morph="none" start_char="2598" end_char="2609">recolectando</TOKEN>
<TOKEN id="token-16-24" pos="word" morph="none" start_char="2611" end_char="2615">estas</TOKEN>
<TOKEN id="token-16-25" pos="word" morph="none" start_char="2617" end_char="2629">informaciones</TOKEN>
<TOKEN id="token-16-26" pos="word" morph="none" start_char="2631" end_char="2637">médicas</TOKEN>
<TOKEN id="token-16-27" pos="unknown" morph="none" start_char="2639" end_char="2653">ultra-sensibles</TOKEN>
<TOKEN id="token-16-28" pos="punct" morph="none" start_char="2654" end_char="2654">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2658" end_char="2810">
<ORIGINAL_TEXT>Sin embargo, en LinkedIn, en el perfil de la empresa solo aparecen cinco empleados quienes, a excepción de Sapan Desai, se unieron a la compañía en 2020.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2658" end_char="2660">Sin</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2662" end_char="2668">embargo</TOKEN>
<TOKEN id="token-17-2" pos="punct" morph="none" start_char="2669" end_char="2669">,</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2671" end_char="2672">en</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2674" end_char="2681">LinkedIn</TOKEN>
<TOKEN id="token-17-5" pos="punct" morph="none" start_char="2682" end_char="2682">,</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2684" end_char="2685">en</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2687" end_char="2688">el</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2690" end_char="2695">perfil</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2697" end_char="2698">de</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2700" end_char="2701">la</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2703" end_char="2709">empresa</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2711" end_char="2714">solo</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2716" end_char="2723">aparecen</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2725" end_char="2729">cinco</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2731" end_char="2739">empleados</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="2741" end_char="2747">quienes</TOKEN>
<TOKEN id="token-17-17" pos="punct" morph="none" start_char="2748" end_char="2748">,</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="2750" end_char="2750">a</TOKEN>
<TOKEN id="token-17-19" pos="word" morph="none" start_char="2752" end_char="2760">excepción</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="2762" end_char="2763">de</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="2765" end_char="2769">Sapan</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="2771" end_char="2775">Desai</TOKEN>
<TOKEN id="token-17-23" pos="punct" morph="none" start_char="2776" end_char="2776">,</TOKEN>
<TOKEN id="token-17-24" pos="word" morph="none" start_char="2778" end_char="2779">se</TOKEN>
<TOKEN id="token-17-25" pos="word" morph="none" start_char="2781" end_char="2787">unieron</TOKEN>
<TOKEN id="token-17-26" pos="word" morph="none" start_char="2789" end_char="2789">a</TOKEN>
<TOKEN id="token-17-27" pos="word" morph="none" start_char="2791" end_char="2792">la</TOKEN>
<TOKEN id="token-17-28" pos="word" morph="none" start_char="2794" end_char="2801">compañía</TOKEN>
<TOKEN id="token-17-29" pos="word" morph="none" start_char="2803" end_char="2804">en</TOKEN>
<TOKEN id="token-17-30" pos="word" morph="none" start_char="2806" end_char="2809">2020</TOKEN>
<TOKEN id="token-17-31" pos="punct" morph="none" start_char="2810" end_char="2810">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2812" end_char="3051">
<ORIGINAL_TEXT>El perfil de los colaboradores de Surgisphere no da la impresión de ser un equipo a la vanguardia en cuanto a innovación tecnológica en el ámbito de la salud, resalta el periódico 'The Guardian', que realizó una investigación por su cuenta.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2812" end_char="2813">El</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2815" end_char="2820">perfil</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2822" end_char="2823">de</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2825" end_char="2827">los</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2829" end_char="2841">colaboradores</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2843" end_char="2844">de</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2846" end_char="2856">Surgisphere</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2858" end_char="2859">no</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2861" end_char="2862">da</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="2864" end_char="2865">la</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="2867" end_char="2875">impresión</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="2877" end_char="2878">de</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2880" end_char="2882">ser</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="2884" end_char="2885">un</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="2887" end_char="2892">equipo</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="2894" end_char="2894">a</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="2896" end_char="2897">la</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="2899" end_char="2908">vanguardia</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="2910" end_char="2911">en</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="2913" end_char="2918">cuanto</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="2920" end_char="2920">a</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="2922" end_char="2931">innovación</TOKEN>
<TOKEN id="token-18-22" pos="word" morph="none" start_char="2933" end_char="2943">tecnológica</TOKEN>
<TOKEN id="token-18-23" pos="word" morph="none" start_char="2945" end_char="2946">en</TOKEN>
<TOKEN id="token-18-24" pos="word" morph="none" start_char="2948" end_char="2949">el</TOKEN>
<TOKEN id="token-18-25" pos="word" morph="none" start_char="2951" end_char="2956">ámbito</TOKEN>
<TOKEN id="token-18-26" pos="word" morph="none" start_char="2958" end_char="2959">de</TOKEN>
<TOKEN id="token-18-27" pos="word" morph="none" start_char="2961" end_char="2962">la</TOKEN>
<TOKEN id="token-18-28" pos="word" morph="none" start_char="2964" end_char="2968">salud</TOKEN>
<TOKEN id="token-18-29" pos="punct" morph="none" start_char="2969" end_char="2969">,</TOKEN>
<TOKEN id="token-18-30" pos="word" morph="none" start_char="2971" end_char="2977">resalta</TOKEN>
<TOKEN id="token-18-31" pos="word" morph="none" start_char="2979" end_char="2980">el</TOKEN>
<TOKEN id="token-18-32" pos="word" morph="none" start_char="2982" end_char="2990">periódico</TOKEN>
<TOKEN id="token-18-33" pos="punct" morph="none" start_char="2992" end_char="2992">'</TOKEN>
<TOKEN id="token-18-34" pos="word" morph="none" start_char="2993" end_char="2995">The</TOKEN>
<TOKEN id="token-18-35" pos="word" morph="none" start_char="2997" end_char="3004">Guardian</TOKEN>
<TOKEN id="token-18-36" pos="punct" morph="none" start_char="3005" end_char="3006">',</TOKEN>
<TOKEN id="token-18-37" pos="word" morph="none" start_char="3008" end_char="3010">que</TOKEN>
<TOKEN id="token-18-38" pos="word" morph="none" start_char="3012" end_char="3018">realizó</TOKEN>
<TOKEN id="token-18-39" pos="word" morph="none" start_char="3020" end_char="3022">una</TOKEN>
<TOKEN id="token-18-40" pos="word" morph="none" start_char="3024" end_char="3036">investigación</TOKEN>
<TOKEN id="token-18-41" pos="word" morph="none" start_char="3038" end_char="3040">por</TOKEN>
<TOKEN id="token-18-42" pos="word" morph="none" start_char="3042" end_char="3043">su</TOKEN>
<TOKEN id="token-18-43" pos="word" morph="none" start_char="3045" end_char="3050">cuenta</TOKEN>
<TOKEN id="token-18-44" pos="punct" morph="none" start_char="3051" end_char="3051">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="3053" end_char="3182">
<ORIGINAL_TEXT>"Uno de ellos escribía antes novelas de ciencia ficción mientras que otra era modelo y recepcionista", resume el diario británico.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="punct" morph="none" start_char="3053" end_char="3053">"</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="3054" end_char="3056">Uno</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="3058" end_char="3059">de</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="3061" end_char="3065">ellos</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="3067" end_char="3074">escribía</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="3076" end_char="3080">antes</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="3082" end_char="3088">novelas</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="3090" end_char="3091">de</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="3093" end_char="3099">ciencia</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="3101" end_char="3107">ficción</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="3109" end_char="3116">mientras</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="3118" end_char="3120">que</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="3122" end_char="3125">otra</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="3127" end_char="3129">era</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="3131" end_char="3136">modelo</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="3138" end_char="3138">y</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="3140" end_char="3152">recepcionista</TOKEN>
<TOKEN id="token-19-17" pos="punct" morph="none" start_char="3153" end_char="3154">",</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="3156" end_char="3161">resume</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="3163" end_char="3164">el</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="3166" end_char="3171">diario</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="3173" end_char="3181">británico</TOKEN>
<TOKEN id="token-19-22" pos="punct" morph="none" start_char="3182" end_char="3182">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="3185" end_char="3198">
<ORIGINAL_TEXT>¿Datos falsos?</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="punct" morph="none" start_char="3185" end_char="3185">¿</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="3186" end_char="3190">Datos</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="3192" end_char="3197">falsos</TOKEN>
<TOKEN id="token-20-3" pos="punct" morph="none" start_char="3198" end_char="3198">?</TOKEN>
</SEG>
<SEG id="segment-21" start_char="3201" end_char="3323">
<ORIGINAL_TEXT>¿Cómo un equipo tan pequeño pudo obtener entre tantos hospitales los datos médicos de una cantidad tan grande de pacientes?</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="punct" morph="none" start_char="3201" end_char="3201">¿</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="3202" end_char="3205">Cómo</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="3207" end_char="3208">un</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="3210" end_char="3215">equipo</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="3217" end_char="3219">tan</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="3221" end_char="3227">pequeño</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="3229" end_char="3232">pudo</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="3234" end_char="3240">obtener</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="3242" end_char="3246">entre</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="3248" end_char="3253">tantos</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="3255" end_char="3264">hospitales</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="3266" end_char="3268">los</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="3270" end_char="3274">datos</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="3276" end_char="3282">médicos</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="3284" end_char="3285">de</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="3287" end_char="3289">una</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="3291" end_char="3298">cantidad</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="3300" end_char="3302">tan</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="3304" end_char="3309">grande</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="3311" end_char="3312">de</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="3314" end_char="3322">pacientes</TOKEN>
<TOKEN id="token-21-21" pos="punct" morph="none" start_char="3323" end_char="3323">?</TOKEN>
</SEG>
<SEG id="segment-22" start_char="3325" end_char="3519">
<ORIGINAL_TEXT>Esa es la pregunta del millón para Peter Ellis, un estadístico australiano que también centró su atención sobre el particular caso de la pequeña empresa de Illinois, en una larga entrada de blog.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="3325" end_char="3327">Esa</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="3329" end_char="3330">es</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="3332" end_char="3333">la</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="3335" end_char="3342">pregunta</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="3344" end_char="3346">del</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="3348" end_char="3353">millón</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="3355" end_char="3358">para</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="3360" end_char="3364">Peter</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="3366" end_char="3370">Ellis</TOKEN>
<TOKEN id="token-22-9" pos="punct" morph="none" start_char="3371" end_char="3371">,</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="3373" end_char="3374">un</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="3376" end_char="3386">estadístico</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="3388" end_char="3398">australiano</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="3400" end_char="3402">que</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="3404" end_char="3410">también</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="3412" end_char="3417">centró</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="3419" end_char="3420">su</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="3422" end_char="3429">atención</TOKEN>
<TOKEN id="token-22-18" pos="word" morph="none" start_char="3431" end_char="3435">sobre</TOKEN>
<TOKEN id="token-22-19" pos="word" morph="none" start_char="3437" end_char="3438">el</TOKEN>
<TOKEN id="token-22-20" pos="word" morph="none" start_char="3440" end_char="3449">particular</TOKEN>
<TOKEN id="token-22-21" pos="word" morph="none" start_char="3451" end_char="3454">caso</TOKEN>
<TOKEN id="token-22-22" pos="word" morph="none" start_char="3456" end_char="3457">de</TOKEN>
<TOKEN id="token-22-23" pos="word" morph="none" start_char="3459" end_char="3460">la</TOKEN>
<TOKEN id="token-22-24" pos="word" morph="none" start_char="3462" end_char="3468">pequeña</TOKEN>
<TOKEN id="token-22-25" pos="word" morph="none" start_char="3470" end_char="3476">empresa</TOKEN>
<TOKEN id="token-22-26" pos="word" morph="none" start_char="3478" end_char="3479">de</TOKEN>
<TOKEN id="token-22-27" pos="word" morph="none" start_char="3481" end_char="3488">Illinois</TOKEN>
<TOKEN id="token-22-28" pos="punct" morph="none" start_char="3489" end_char="3489">,</TOKEN>
<TOKEN id="token-22-29" pos="word" morph="none" start_char="3491" end_char="3492">en</TOKEN>
<TOKEN id="token-22-30" pos="word" morph="none" start_char="3494" end_char="3496">una</TOKEN>
<TOKEN id="token-22-31" pos="word" morph="none" start_char="3498" end_char="3502">larga</TOKEN>
<TOKEN id="token-22-32" pos="word" morph="none" start_char="3504" end_char="3510">entrada</TOKEN>
<TOKEN id="token-22-33" pos="word" morph="none" start_char="3512" end_char="3513">de</TOKEN>
<TOKEN id="token-22-34" pos="word" morph="none" start_char="3515" end_char="3518">blog</TOKEN>
<TOKEN id="token-22-35" pos="punct" morph="none" start_char="3519" end_char="3519">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="3522" end_char="3765">
<ORIGINAL_TEXT>Oficialmente, Surgisphere ofrece una plataforma tecnológica equipada con "inteligencia artificial y big data" a más de 1.000 hospitales y clínicas para ayudarlos a tratar de manera más eficaz todas las informaciones médicas sobre sus pacientes.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="3522" end_char="3533">Oficialmente</TOKEN>
<TOKEN id="token-23-1" pos="punct" morph="none" start_char="3534" end_char="3534">,</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="3536" end_char="3546">Surgisphere</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="3548" end_char="3553">ofrece</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="3555" end_char="3557">una</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="3559" end_char="3568">plataforma</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="3570" end_char="3580">tecnológica</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="3582" end_char="3589">equipada</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="3591" end_char="3593">con</TOKEN>
<TOKEN id="token-23-9" pos="punct" morph="none" start_char="3595" end_char="3595">"</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="3596" end_char="3607">inteligencia</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="3609" end_char="3618">artificial</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="3620" end_char="3620">y</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="3622" end_char="3624">big</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="3626" end_char="3629">data</TOKEN>
<TOKEN id="token-23-15" pos="punct" morph="none" start_char="3630" end_char="3630">"</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="3632" end_char="3632">a</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="3634" end_char="3636">más</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="3638" end_char="3639">de</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="3641" end_char="3645">1.000</TOKEN>
<TOKEN id="token-23-20" pos="word" morph="none" start_char="3647" end_char="3656">hospitales</TOKEN>
<TOKEN id="token-23-21" pos="word" morph="none" start_char="3658" end_char="3658">y</TOKEN>
<TOKEN id="token-23-22" pos="word" morph="none" start_char="3660" end_char="3667">clínicas</TOKEN>
<TOKEN id="token-23-23" pos="word" morph="none" start_char="3669" end_char="3672">para</TOKEN>
<TOKEN id="token-23-24" pos="word" morph="none" start_char="3674" end_char="3682">ayudarlos</TOKEN>
<TOKEN id="token-23-25" pos="word" morph="none" start_char="3684" end_char="3684">a</TOKEN>
<TOKEN id="token-23-26" pos="word" morph="none" start_char="3686" end_char="3691">tratar</TOKEN>
<TOKEN id="token-23-27" pos="word" morph="none" start_char="3693" end_char="3694">de</TOKEN>
<TOKEN id="token-23-28" pos="word" morph="none" start_char="3696" end_char="3701">manera</TOKEN>
<TOKEN id="token-23-29" pos="word" morph="none" start_char="3703" end_char="3705">más</TOKEN>
<TOKEN id="token-23-30" pos="word" morph="none" start_char="3707" end_char="3712">eficaz</TOKEN>
<TOKEN id="token-23-31" pos="word" morph="none" start_char="3714" end_char="3718">todas</TOKEN>
<TOKEN id="token-23-32" pos="word" morph="none" start_char="3720" end_char="3722">las</TOKEN>
<TOKEN id="token-23-33" pos="word" morph="none" start_char="3724" end_char="3736">informaciones</TOKEN>
<TOKEN id="token-23-34" pos="word" morph="none" start_char="3738" end_char="3744">médicas</TOKEN>
<TOKEN id="token-23-35" pos="word" morph="none" start_char="3746" end_char="3750">sobre</TOKEN>
<TOKEN id="token-23-36" pos="word" morph="none" start_char="3752" end_char="3754">sus</TOKEN>
<TOKEN id="token-23-37" pos="word" morph="none" start_char="3756" end_char="3764">pacientes</TOKEN>
<TOKEN id="token-23-38" pos="punct" morph="none" start_char="3765" end_char="3765">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="3767" end_char="3938">
<ORIGINAL_TEXT>A cambio de este servicio, Surgisphere puede tener acceso a todos estos datos, que son "anonimizados", con el objetivo de ponerlos a disposición de la comunidad científica.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="3767" end_char="3767">A</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="3769" end_char="3774">cambio</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="3776" end_char="3777">de</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="3779" end_char="3782">este</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="3784" end_char="3791">servicio</TOKEN>
<TOKEN id="token-24-5" pos="punct" morph="none" start_char="3792" end_char="3792">,</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="3794" end_char="3804">Surgisphere</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="3806" end_char="3810">puede</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="3812" end_char="3816">tener</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="3818" end_char="3823">acceso</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="3825" end_char="3825">a</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="3827" end_char="3831">todos</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="3833" end_char="3837">estos</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="3839" end_char="3843">datos</TOKEN>
<TOKEN id="token-24-14" pos="punct" morph="none" start_char="3844" end_char="3844">,</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="3846" end_char="3848">que</TOKEN>
<TOKEN id="token-24-16" pos="word" morph="none" start_char="3850" end_char="3852">son</TOKEN>
<TOKEN id="token-24-17" pos="punct" morph="none" start_char="3854" end_char="3854">"</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="3855" end_char="3866">anonimizados</TOKEN>
<TOKEN id="token-24-19" pos="punct" morph="none" start_char="3867" end_char="3868">",</TOKEN>
<TOKEN id="token-24-20" pos="word" morph="none" start_char="3870" end_char="3872">con</TOKEN>
<TOKEN id="token-24-21" pos="word" morph="none" start_char="3874" end_char="3875">el</TOKEN>
<TOKEN id="token-24-22" pos="word" morph="none" start_char="3877" end_char="3884">objetivo</TOKEN>
<TOKEN id="token-24-23" pos="word" morph="none" start_char="3886" end_char="3887">de</TOKEN>
<TOKEN id="token-24-24" pos="word" morph="none" start_char="3889" end_char="3896">ponerlos</TOKEN>
<TOKEN id="token-24-25" pos="word" morph="none" start_char="3898" end_char="3898">a</TOKEN>
<TOKEN id="token-24-26" pos="word" morph="none" start_char="3900" end_char="3910">disposición</TOKEN>
<TOKEN id="token-24-27" pos="word" morph="none" start_char="3912" end_char="3913">de</TOKEN>
<TOKEN id="token-24-28" pos="word" morph="none" start_char="3915" end_char="3916">la</TOKEN>
<TOKEN id="token-24-29" pos="word" morph="none" start_char="3918" end_char="3926">comunidad</TOKEN>
<TOKEN id="token-24-30" pos="word" morph="none" start_char="3928" end_char="3937">científica</TOKEN>
<TOKEN id="token-24-31" pos="punct" morph="none" start_char="3938" end_char="3938">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="3941" end_char="4126">
<ORIGINAL_TEXT>Pero construir semejante red de aliados toma mucho tiempo, asegura Peter Ellis, quien trabajó en múltiples ocasiones con el Gobierno australiano administrando importantes bases de datos.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="3941" end_char="3944">Pero</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="3946" end_char="3954">construir</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="3956" end_char="3964">semejante</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="3966" end_char="3968">red</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="3970" end_char="3971">de</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="3973" end_char="3979">aliados</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="3981" end_char="3984">toma</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="3986" end_char="3990">mucho</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="3992" end_char="3997">tiempo</TOKEN>
<TOKEN id="token-25-9" pos="punct" morph="none" start_char="3998" end_char="3998">,</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="4000" end_char="4006">asegura</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="4008" end_char="4012">Peter</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="4014" end_char="4018">Ellis</TOKEN>
<TOKEN id="token-25-13" pos="punct" morph="none" start_char="4019" end_char="4019">,</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="4021" end_char="4025">quien</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="4027" end_char="4033">trabajó</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="4035" end_char="4036">en</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="4038" end_char="4046">múltiples</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="4048" end_char="4056">ocasiones</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="4058" end_char="4060">con</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="4062" end_char="4063">el</TOKEN>
<TOKEN id="token-25-21" pos="word" morph="none" start_char="4065" end_char="4072">Gobierno</TOKEN>
<TOKEN id="token-25-22" pos="word" morph="none" start_char="4074" end_char="4084">australiano</TOKEN>
<TOKEN id="token-25-23" pos="word" morph="none" start_char="4086" end_char="4098">administrando</TOKEN>
<TOKEN id="token-25-24" pos="word" morph="none" start_char="4100" end_char="4110">importantes</TOKEN>
<TOKEN id="token-25-25" pos="word" morph="none" start_char="4112" end_char="4116">bases</TOKEN>
<TOKEN id="token-25-26" pos="word" morph="none" start_char="4118" end_char="4119">de</TOKEN>
<TOKEN id="token-25-27" pos="word" morph="none" start_char="4121" end_char="4125">datos</TOKEN>
<TOKEN id="token-25-28" pos="punct" morph="none" start_char="4126" end_char="4126">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="4129" end_char="4319">
<ORIGINAL_TEXT>Es necesario convencer a todos los integrantes de un hospital, desde los equipos administrativos y médicos hasta los responsables de la seguridad informática, de la seriedad de la iniciativa.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="4129" end_char="4130">Es</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="4132" end_char="4140">necesario</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="4142" end_char="4150">convencer</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="4152" end_char="4152">a</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="4154" end_char="4158">todos</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="4160" end_char="4162">los</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="4164" end_char="4174">integrantes</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="4176" end_char="4177">de</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="4179" end_char="4180">un</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="4182" end_char="4189">hospital</TOKEN>
<TOKEN id="token-26-10" pos="punct" morph="none" start_char="4190" end_char="4190">,</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="4192" end_char="4196">desde</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="4198" end_char="4200">los</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="4202" end_char="4208">equipos</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="4210" end_char="4224">administrativos</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="4226" end_char="4226">y</TOKEN>
<TOKEN id="token-26-16" pos="word" morph="none" start_char="4228" end_char="4234">médicos</TOKEN>
<TOKEN id="token-26-17" pos="word" morph="none" start_char="4236" end_char="4240">hasta</TOKEN>
<TOKEN id="token-26-18" pos="word" morph="none" start_char="4242" end_char="4244">los</TOKEN>
<TOKEN id="token-26-19" pos="word" morph="none" start_char="4246" end_char="4257">responsables</TOKEN>
<TOKEN id="token-26-20" pos="word" morph="none" start_char="4259" end_char="4260">de</TOKEN>
<TOKEN id="token-26-21" pos="word" morph="none" start_char="4262" end_char="4263">la</TOKEN>
<TOKEN id="token-26-22" pos="word" morph="none" start_char="4265" end_char="4273">seguridad</TOKEN>
<TOKEN id="token-26-23" pos="word" morph="none" start_char="4275" end_char="4285">informática</TOKEN>
<TOKEN id="token-26-24" pos="punct" morph="none" start_char="4286" end_char="4286">,</TOKEN>
<TOKEN id="token-26-25" pos="word" morph="none" start_char="4288" end_char="4289">de</TOKEN>
<TOKEN id="token-26-26" pos="word" morph="none" start_char="4291" end_char="4292">la</TOKEN>
<TOKEN id="token-26-27" pos="word" morph="none" start_char="4294" end_char="4301">seriedad</TOKEN>
<TOKEN id="token-26-28" pos="word" morph="none" start_char="4303" end_char="4304">de</TOKEN>
<TOKEN id="token-26-29" pos="word" morph="none" start_char="4306" end_char="4307">la</TOKEN>
<TOKEN id="token-26-30" pos="word" morph="none" start_char="4309" end_char="4318">iniciativa</TOKEN>
<TOKEN id="token-26-31" pos="punct" morph="none" start_char="4319" end_char="4319">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="4321" end_char="4522">
<ORIGINAL_TEXT>A fin de cuentas, se trata del tratamiento de las informaciones personales más sensibles que existen (historia clínica completa, resultados de radiografías, datos sobre los medicamentos utilizados, etc.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="4321" end_char="4321">A</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="4323" end_char="4325">fin</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="4327" end_char="4328">de</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="4330" end_char="4336">cuentas</TOKEN>
<TOKEN id="token-27-4" pos="punct" morph="none" start_char="4337" end_char="4337">,</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="4339" end_char="4340">se</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="4342" end_char="4346">trata</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="4348" end_char="4350">del</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="4352" end_char="4362">tratamiento</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="4364" end_char="4365">de</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="4367" end_char="4369">las</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="4371" end_char="4383">informaciones</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="4385" end_char="4394">personales</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="4396" end_char="4398">más</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="4400" end_char="4408">sensibles</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="4410" end_char="4412">que</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="4414" end_char="4420">existen</TOKEN>
<TOKEN id="token-27-17" pos="punct" morph="none" start_char="4422" end_char="4422">(</TOKEN>
<TOKEN id="token-27-18" pos="word" morph="none" start_char="4423" end_char="4430">historia</TOKEN>
<TOKEN id="token-27-19" pos="word" morph="none" start_char="4432" end_char="4438">clínica</TOKEN>
<TOKEN id="token-27-20" pos="word" morph="none" start_char="4440" end_char="4447">completa</TOKEN>
<TOKEN id="token-27-21" pos="punct" morph="none" start_char="4448" end_char="4448">,</TOKEN>
<TOKEN id="token-27-22" pos="word" morph="none" start_char="4450" end_char="4459">resultados</TOKEN>
<TOKEN id="token-27-23" pos="word" morph="none" start_char="4461" end_char="4462">de</TOKEN>
<TOKEN id="token-27-24" pos="word" morph="none" start_char="4464" end_char="4475">radiografías</TOKEN>
<TOKEN id="token-27-25" pos="punct" morph="none" start_char="4476" end_char="4476">,</TOKEN>
<TOKEN id="token-27-26" pos="word" morph="none" start_char="4478" end_char="4482">datos</TOKEN>
<TOKEN id="token-27-27" pos="word" morph="none" start_char="4484" end_char="4488">sobre</TOKEN>
<TOKEN id="token-27-28" pos="word" morph="none" start_char="4490" end_char="4492">los</TOKEN>
<TOKEN id="token-27-29" pos="word" morph="none" start_char="4494" end_char="4505">medicamentos</TOKEN>
<TOKEN id="token-27-30" pos="word" morph="none" start_char="4507" end_char="4516">utilizados</TOKEN>
<TOKEN id="token-27-31" pos="punct" morph="none" start_char="4517" end_char="4517">,</TOKEN>
<TOKEN id="token-27-32" pos="word" morph="none" start_char="4519" end_char="4521">etc</TOKEN>
<TOKEN id="token-27-33" pos="punct" morph="none" start_char="4522" end_char="4522">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="4524" end_char="4525">
<ORIGINAL_TEXT>).</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="punct" morph="none" start_char="4524" end_char="4525">).</TOKEN>
</SEG>
<SEG id="segment-29" start_char="4528" end_char="4661">
<ORIGINAL_TEXT>La pantalla de un ordenador muestra Hidroxicloroquina a la venta en una página web brasileña, el 20 de mayo de 2020 en Rio de Janeiro.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="4528" end_char="4529">La</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="4531" end_char="4538">pantalla</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="4540" end_char="4541">de</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="4543" end_char="4544">un</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="4546" end_char="4554">ordenador</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="4556" end_char="4562">muestra</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="4564" end_char="4580">Hidroxicloroquina</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="4582" end_char="4582">a</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="4584" end_char="4585">la</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="4587" end_char="4591">venta</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="4593" end_char="4594">en</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="4596" end_char="4598">una</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="4600" end_char="4605">página</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="4607" end_char="4609">web</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="4611" end_char="4619">brasileña</TOKEN>
<TOKEN id="token-29-15" pos="punct" morph="none" start_char="4620" end_char="4620">,</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="4622" end_char="4623">el</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="4625" end_char="4626">20</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="4628" end_char="4629">de</TOKEN>
<TOKEN id="token-29-19" pos="word" morph="none" start_char="4631" end_char="4634">mayo</TOKEN>
<TOKEN id="token-29-20" pos="word" morph="none" start_char="4636" end_char="4637">de</TOKEN>
<TOKEN id="token-29-21" pos="word" morph="none" start_char="4639" end_char="4642">2020</TOKEN>
<TOKEN id="token-29-22" pos="word" morph="none" start_char="4644" end_char="4645">en</TOKEN>
<TOKEN id="token-29-23" pos="word" morph="none" start_char="4647" end_char="4649">Rio</TOKEN>
<TOKEN id="token-29-24" pos="word" morph="none" start_char="4651" end_char="4652">de</TOKEN>
<TOKEN id="token-29-25" pos="word" morph="none" start_char="4654" end_char="4660">Janeiro</TOKEN>
<TOKEN id="token-29-26" pos="punct" morph="none" start_char="4661" end_char="4661">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="4663" end_char="4680">
<ORIGINAL_TEXT>Mauro Pimentel AFP</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="4663" end_char="4667">Mauro</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="4669" end_char="4676">Pimentel</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="4678" end_char="4680">AFP</TOKEN>
</SEG>
<SEG id="segment-31" start_char="4684" end_char="4906">
<ORIGINAL_TEXT>Que una pequeña empresa privada casi desconocida tenga acceso a semejante tesoro es potencialmente "un escándalo mucho más grande que el de los datos de Facebook recolectados por Cambridge Analytica", considera Peter Ellis.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="4684" end_char="4686">Que</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="4688" end_char="4690">una</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="4692" end_char="4698">pequeña</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="4700" end_char="4706">empresa</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="4708" end_char="4714">privada</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="4716" end_char="4719">casi</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="4721" end_char="4731">desconocida</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="4733" end_char="4737">tenga</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="4739" end_char="4744">acceso</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="4746" end_char="4746">a</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="4748" end_char="4756">semejante</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="4758" end_char="4763">tesoro</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="4765" end_char="4766">es</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="4768" end_char="4781">potencialmente</TOKEN>
<TOKEN id="token-31-14" pos="punct" morph="none" start_char="4783" end_char="4783">"</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="4784" end_char="4785">un</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="4787" end_char="4795">escándalo</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="4797" end_char="4801">mucho</TOKEN>
<TOKEN id="token-31-18" pos="word" morph="none" start_char="4803" end_char="4805">más</TOKEN>
<TOKEN id="token-31-19" pos="word" morph="none" start_char="4807" end_char="4812">grande</TOKEN>
<TOKEN id="token-31-20" pos="word" morph="none" start_char="4814" end_char="4816">que</TOKEN>
<TOKEN id="token-31-21" pos="word" morph="none" start_char="4818" end_char="4819">el</TOKEN>
<TOKEN id="token-31-22" pos="word" morph="none" start_char="4821" end_char="4822">de</TOKEN>
<TOKEN id="token-31-23" pos="word" morph="none" start_char="4824" end_char="4826">los</TOKEN>
<TOKEN id="token-31-24" pos="word" morph="none" start_char="4828" end_char="4832">datos</TOKEN>
<TOKEN id="token-31-25" pos="word" morph="none" start_char="4834" end_char="4835">de</TOKEN>
<TOKEN id="token-31-26" pos="word" morph="none" start_char="4837" end_char="4844">Facebook</TOKEN>
<TOKEN id="token-31-27" pos="word" morph="none" start_char="4846" end_char="4857">recolectados</TOKEN>
<TOKEN id="token-31-28" pos="word" morph="none" start_char="4859" end_char="4861">por</TOKEN>
<TOKEN id="token-31-29" pos="word" morph="none" start_char="4863" end_char="4871">Cambridge</TOKEN>
<TOKEN id="token-31-30" pos="word" morph="none" start_char="4873" end_char="4881">Analytica</TOKEN>
<TOKEN id="token-31-31" pos="punct" morph="none" start_char="4882" end_char="4883">",</TOKEN>
<TOKEN id="token-31-32" pos="word" morph="none" start_char="4885" end_char="4893">considera</TOKEN>
<TOKEN id="token-31-33" pos="word" morph="none" start_char="4895" end_char="4899">Peter</TOKEN>
<TOKEN id="token-31-34" pos="word" morph="none" start_char="4901" end_char="4905">Ellis</TOKEN>
<TOKEN id="token-31-35" pos="punct" morph="none" start_char="4906" end_char="4906">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="4909" end_char="4957">
<ORIGINAL_TEXT>Desarrollar semejante sistema es también costoso.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="4909" end_char="4919">Desarrollar</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="4921" end_char="4929">semejante</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="4931" end_char="4937">sistema</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="4939" end_char="4940">es</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="4942" end_char="4948">también</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="4950" end_char="4956">costoso</TOKEN>
<TOKEN id="token-32-6" pos="punct" morph="none" start_char="4957" end_char="4957">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="4959" end_char="5130">
<ORIGINAL_TEXT>El estadístico australiano evalúa el costo de semejante plataforma en 300.000 dólares por hospital y no le "sorprendería que cada instalación costara un millón de dólares".</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="4959" end_char="4960">El</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="4962" end_char="4972">estadístico</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="4974" end_char="4984">australiano</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="4986" end_char="4991">evalúa</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="4993" end_char="4994">el</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="4996" end_char="5000">costo</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="5002" end_char="5003">de</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="5005" end_char="5013">semejante</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="5015" end_char="5024">plataforma</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="5026" end_char="5027">en</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="5029" end_char="5035">300.000</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="5037" end_char="5043">dólares</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="5045" end_char="5047">por</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="5049" end_char="5056">hospital</TOKEN>
<TOKEN id="token-33-14" pos="word" morph="none" start_char="5058" end_char="5058">y</TOKEN>
<TOKEN id="token-33-15" pos="word" morph="none" start_char="5060" end_char="5061">no</TOKEN>
<TOKEN id="token-33-16" pos="word" morph="none" start_char="5063" end_char="5064">le</TOKEN>
<TOKEN id="token-33-17" pos="punct" morph="none" start_char="5066" end_char="5066">"</TOKEN>
<TOKEN id="token-33-18" pos="word" morph="none" start_char="5067" end_char="5078">sorprendería</TOKEN>
<TOKEN id="token-33-19" pos="word" morph="none" start_char="5080" end_char="5082">que</TOKEN>
<TOKEN id="token-33-20" pos="word" morph="none" start_char="5084" end_char="5087">cada</TOKEN>
<TOKEN id="token-33-21" pos="word" morph="none" start_char="5089" end_char="5099">instalación</TOKEN>
<TOKEN id="token-33-22" pos="word" morph="none" start_char="5101" end_char="5107">costara</TOKEN>
<TOKEN id="token-33-23" pos="word" morph="none" start_char="5109" end_char="5110">un</TOKEN>
<TOKEN id="token-33-24" pos="word" morph="none" start_char="5112" end_char="5117">millón</TOKEN>
<TOKEN id="token-33-25" pos="word" morph="none" start_char="5119" end_char="5120">de</TOKEN>
<TOKEN id="token-33-26" pos="word" morph="none" start_char="5122" end_char="5128">dólares</TOKEN>
<TOKEN id="token-33-27" pos="punct" morph="none" start_char="5129" end_char="5130">".</TOKEN>
</SEG>
<SEG id="segment-34" start_char="5132" end_char="5190">
<ORIGINAL_TEXT>Surgisphere debería entonces disponer de fondos semejantes.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="5132" end_char="5142">Surgisphere</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="5144" end_char="5150">debería</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="5152" end_char="5159">entonces</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="5161" end_char="5168">disponer</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="5170" end_char="5171">de</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="5173" end_char="5178">fondos</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="5180" end_char="5189">semejantes</TOKEN>
<TOKEN id="token-34-7" pos="punct" morph="none" start_char="5190" end_char="5190">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="5192" end_char="5422">
<ORIGINAL_TEXT>No hay ninguna información pública sobre el presupuesto de esta joven empresa, pero Dun Badstreet, una empresa que reúne datos financieros de empresas del mundo entero, evaluó los ingresos de Surgisphere en tan solo 45.245 dólares.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="5192" end_char="5193">No</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="5195" end_char="5197">hay</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="5199" end_char="5205">ninguna</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="5207" end_char="5217">información</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="5219" end_char="5225">pública</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="5227" end_char="5231">sobre</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="5233" end_char="5234">el</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="5236" end_char="5246">presupuesto</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="5248" end_char="5249">de</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="5251" end_char="5254">esta</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="5256" end_char="5260">joven</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="5262" end_char="5268">empresa</TOKEN>
<TOKEN id="token-35-12" pos="punct" morph="none" start_char="5269" end_char="5269">,</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="5271" end_char="5274">pero</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="5276" end_char="5278">Dun</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="5280" end_char="5288">Badstreet</TOKEN>
<TOKEN id="token-35-16" pos="punct" morph="none" start_char="5289" end_char="5289">,</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="5291" end_char="5293">una</TOKEN>
<TOKEN id="token-35-18" pos="word" morph="none" start_char="5295" end_char="5301">empresa</TOKEN>
<TOKEN id="token-35-19" pos="word" morph="none" start_char="5303" end_char="5305">que</TOKEN>
<TOKEN id="token-35-20" pos="word" morph="none" start_char="5307" end_char="5311">reúne</TOKEN>
<TOKEN id="token-35-21" pos="word" morph="none" start_char="5313" end_char="5317">datos</TOKEN>
<TOKEN id="token-35-22" pos="word" morph="none" start_char="5319" end_char="5329">financieros</TOKEN>
<TOKEN id="token-35-23" pos="word" morph="none" start_char="5331" end_char="5332">de</TOKEN>
<TOKEN id="token-35-24" pos="word" morph="none" start_char="5334" end_char="5341">empresas</TOKEN>
<TOKEN id="token-35-25" pos="word" morph="none" start_char="5343" end_char="5345">del</TOKEN>
<TOKEN id="token-35-26" pos="word" morph="none" start_char="5347" end_char="5351">mundo</TOKEN>
<TOKEN id="token-35-27" pos="word" morph="none" start_char="5353" end_char="5358">entero</TOKEN>
<TOKEN id="token-35-28" pos="punct" morph="none" start_char="5359" end_char="5359">,</TOKEN>
<TOKEN id="token-35-29" pos="word" morph="none" start_char="5361" end_char="5366">evaluó</TOKEN>
<TOKEN id="token-35-30" pos="word" morph="none" start_char="5368" end_char="5370">los</TOKEN>
<TOKEN id="token-35-31" pos="word" morph="none" start_char="5372" end_char="5379">ingresos</TOKEN>
<TOKEN id="token-35-32" pos="word" morph="none" start_char="5381" end_char="5382">de</TOKEN>
<TOKEN id="token-35-33" pos="word" morph="none" start_char="5384" end_char="5394">Surgisphere</TOKEN>
<TOKEN id="token-35-34" pos="word" morph="none" start_char="5396" end_char="5397">en</TOKEN>
<TOKEN id="token-35-35" pos="word" morph="none" start_char="5399" end_char="5401">tan</TOKEN>
<TOKEN id="token-35-36" pos="word" morph="none" start_char="5403" end_char="5406">solo</TOKEN>
<TOKEN id="token-35-37" pos="word" morph="none" start_char="5408" end_char="5413">45.245</TOKEN>
<TOKEN id="token-35-38" pos="word" morph="none" start_char="5415" end_char="5421">dólares</TOKEN>
<TOKEN id="token-35-39" pos="punct" morph="none" start_char="5422" end_char="5422">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="5424" end_char="5572">
<ORIGINAL_TEXT>Todos estos elementos llevan a Peter Ellis a afirmar que "los datos proporcionados para el artículo de 'Lancet' fueron quizás totalmente fabricados".</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="5424" end_char="5428">Todos</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="5430" end_char="5434">estos</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="5436" end_char="5444">elementos</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="5446" end_char="5451">llevan</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="5453" end_char="5453">a</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="5455" end_char="5459">Peter</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="5461" end_char="5465">Ellis</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="5467" end_char="5467">a</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="5469" end_char="5475">afirmar</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="5477" end_char="5479">que</TOKEN>
<TOKEN id="token-36-10" pos="punct" morph="none" start_char="5481" end_char="5481">"</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="5482" end_char="5484">los</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="5486" end_char="5490">datos</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="5492" end_char="5505">proporcionados</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="5507" end_char="5510">para</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="5512" end_char="5513">el</TOKEN>
<TOKEN id="token-36-16" pos="word" morph="none" start_char="5515" end_char="5522">artículo</TOKEN>
<TOKEN id="token-36-17" pos="word" morph="none" start_char="5524" end_char="5525">de</TOKEN>
<TOKEN id="token-36-18" pos="punct" morph="none" start_char="5527" end_char="5527">'</TOKEN>
<TOKEN id="token-36-19" pos="word" morph="none" start_char="5528" end_char="5533">Lancet</TOKEN>
<TOKEN id="token-36-20" pos="punct" morph="none" start_char="5534" end_char="5534">'</TOKEN>
<TOKEN id="token-36-21" pos="word" morph="none" start_char="5536" end_char="5541">fueron</TOKEN>
<TOKEN id="token-36-22" pos="word" morph="none" start_char="5543" end_char="5548">quizás</TOKEN>
<TOKEN id="token-36-23" pos="word" morph="none" start_char="5550" end_char="5559">totalmente</TOKEN>
<TOKEN id="token-36-24" pos="word" morph="none" start_char="5561" end_char="5570">fabricados</TOKEN>
<TOKEN id="token-36-25" pos="punct" morph="none" start_char="5571" end_char="5572">".</TOKEN>
</SEG>
<SEG id="segment-37" start_char="5575" end_char="5695">
<ORIGINAL_TEXT>Otros científicos, que firmaron la carta abierta, también se inclinan por compartir esta opinión… pero por otras razones.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="5575" end_char="5579">Otros</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="5581" end_char="5591">científicos</TOKEN>
<TOKEN id="token-37-2" pos="punct" morph="none" start_char="5592" end_char="5592">,</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="5594" end_char="5596">que</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="5598" end_char="5605">firmaron</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="5607" end_char="5608">la</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="5610" end_char="5614">carta</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="5616" end_char="5622">abierta</TOKEN>
<TOKEN id="token-37-8" pos="punct" morph="none" start_char="5623" end_char="5623">,</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="5625" end_char="5631">también</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="5633" end_char="5634">se</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="5636" end_char="5643">inclinan</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="5645" end_char="5647">por</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="5649" end_char="5657">compartir</TOKEN>
<TOKEN id="token-37-14" pos="word" morph="none" start_char="5659" end_char="5662">esta</TOKEN>
<TOKEN id="token-37-15" pos="word" morph="none" start_char="5664" end_char="5670">opinión</TOKEN>
<TOKEN id="token-37-16" pos="punct" morph="none" start_char="5671" end_char="5671">…</TOKEN>
<TOKEN id="token-37-17" pos="word" morph="none" start_char="5673" end_char="5676">pero</TOKEN>
<TOKEN id="token-37-18" pos="word" morph="none" start_char="5678" end_char="5680">por</TOKEN>
<TOKEN id="token-37-19" pos="word" morph="none" start_char="5682" end_char="5686">otras</TOKEN>
<TOKEN id="token-37-20" pos="word" morph="none" start_char="5688" end_char="5694">razones</TOKEN>
<TOKEN id="token-37-21" pos="punct" morph="none" start_char="5695" end_char="5695">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="5697" end_char="5776">
<ORIGINAL_TEXT>Consideran que las cifras del estudio no corresponden a la realidad del terreno.</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="5697" end_char="5706">Consideran</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="5708" end_char="5710">que</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="5712" end_char="5714">las</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="5716" end_char="5721">cifras</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="5723" end_char="5725">del</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="5727" end_char="5733">estudio</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="5735" end_char="5736">no</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="5738" end_char="5749">corresponden</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="5751" end_char="5751">a</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="5753" end_char="5754">la</TOKEN>
<TOKEN id="token-38-10" pos="word" morph="none" start_char="5756" end_char="5763">realidad</TOKEN>
<TOKEN id="token-38-11" pos="word" morph="none" start_char="5765" end_char="5767">del</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="5769" end_char="5775">terreno</TOKEN>
<TOKEN id="token-38-13" pos="punct" morph="none" start_char="5776" end_char="5776">.</TOKEN>
</SEG>
<SEG id="segment-39" start_char="5778" end_char="5980">
<ORIGINAL_TEXT>Los autores del informe afirman, por ejemplo, haber accedido a los datos de 600 australianos contaminados por Covid-19 hasta el 21 de abril, de los cuales solo 73 habrían muerto a causa de la enfermedad.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="5778" end_char="5780">Los</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="5782" end_char="5788">autores</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="5790" end_char="5792">del</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="5794" end_char="5800">informe</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="5802" end_char="5808">afirman</TOKEN>
<TOKEN id="token-39-5" pos="punct" morph="none" start_char="5809" end_char="5809">,</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="5811" end_char="5813">por</TOKEN>
<TOKEN id="token-39-7" pos="word" morph="none" start_char="5815" end_char="5821">ejemplo</TOKEN>
<TOKEN id="token-39-8" pos="punct" morph="none" start_char="5822" end_char="5822">,</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="5824" end_char="5828">haber</TOKEN>
<TOKEN id="token-39-10" pos="word" morph="none" start_char="5830" end_char="5837">accedido</TOKEN>
<TOKEN id="token-39-11" pos="word" morph="none" start_char="5839" end_char="5839">a</TOKEN>
<TOKEN id="token-39-12" pos="word" morph="none" start_char="5841" end_char="5843">los</TOKEN>
<TOKEN id="token-39-13" pos="word" morph="none" start_char="5845" end_char="5849">datos</TOKEN>
<TOKEN id="token-39-14" pos="word" morph="none" start_char="5851" end_char="5852">de</TOKEN>
<TOKEN id="token-39-15" pos="word" morph="none" start_char="5854" end_char="5856">600</TOKEN>
<TOKEN id="token-39-16" pos="word" morph="none" start_char="5858" end_char="5869">australianos</TOKEN>
<TOKEN id="token-39-17" pos="word" morph="none" start_char="5871" end_char="5882">contaminados</TOKEN>
<TOKEN id="token-39-18" pos="word" morph="none" start_char="5884" end_char="5886">por</TOKEN>
<TOKEN id="token-39-19" pos="unknown" morph="none" start_char="5888" end_char="5895">Covid-19</TOKEN>
<TOKEN id="token-39-20" pos="word" morph="none" start_char="5897" end_char="5901">hasta</TOKEN>
<TOKEN id="token-39-21" pos="word" morph="none" start_char="5903" end_char="5904">el</TOKEN>
<TOKEN id="token-39-22" pos="word" morph="none" start_char="5906" end_char="5907">21</TOKEN>
<TOKEN id="token-39-23" pos="word" morph="none" start_char="5909" end_char="5910">de</TOKEN>
<TOKEN id="token-39-24" pos="word" morph="none" start_char="5912" end_char="5916">abril</TOKEN>
<TOKEN id="token-39-25" pos="punct" morph="none" start_char="5917" end_char="5917">,</TOKEN>
<TOKEN id="token-39-26" pos="word" morph="none" start_char="5919" end_char="5920">de</TOKEN>
<TOKEN id="token-39-27" pos="word" morph="none" start_char="5922" end_char="5924">los</TOKEN>
<TOKEN id="token-39-28" pos="word" morph="none" start_char="5926" end_char="5931">cuales</TOKEN>
<TOKEN id="token-39-29" pos="word" morph="none" start_char="5933" end_char="5936">solo</TOKEN>
<TOKEN id="token-39-30" pos="word" morph="none" start_char="5938" end_char="5939">73</TOKEN>
<TOKEN id="token-39-31" pos="word" morph="none" start_char="5941" end_char="5947">habrían</TOKEN>
<TOKEN id="token-39-32" pos="word" morph="none" start_char="5949" end_char="5954">muerto</TOKEN>
<TOKEN id="token-39-33" pos="word" morph="none" start_char="5956" end_char="5956">a</TOKEN>
<TOKEN id="token-39-34" pos="word" morph="none" start_char="5958" end_char="5962">causa</TOKEN>
<TOKEN id="token-39-35" pos="word" morph="none" start_char="5964" end_char="5965">de</TOKEN>
<TOKEN id="token-39-36" pos="word" morph="none" start_char="5967" end_char="5968">la</TOKEN>
<TOKEN id="token-39-37" pos="word" morph="none" start_char="5970" end_char="5979">enfermedad</TOKEN>
<TOKEN id="token-39-38" pos="punct" morph="none" start_char="5980" end_char="5980">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="5982" end_char="6135">
<ORIGINAL_TEXT>El problema es que oficialmente había solo 67 fallecimientos relacionados con coronavirus hasta esa fecha en Australia, tal como lo reveló 'The Guardian'.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="5982" end_char="5983">El</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="5985" end_char="5992">problema</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="5994" end_char="5995">es</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="5997" end_char="5999">que</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="6001" end_char="6012">oficialmente</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="6014" end_char="6018">había</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="6020" end_char="6023">solo</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="6025" end_char="6026">67</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="6028" end_char="6041">fallecimientos</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="6043" end_char="6054">relacionados</TOKEN>
<TOKEN id="token-40-10" pos="word" morph="none" start_char="6056" end_char="6058">con</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="6060" end_char="6070">coronavirus</TOKEN>
<TOKEN id="token-40-12" pos="word" morph="none" start_char="6072" end_char="6076">hasta</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="6078" end_char="6080">esa</TOKEN>
<TOKEN id="token-40-14" pos="word" morph="none" start_char="6082" end_char="6086">fecha</TOKEN>
<TOKEN id="token-40-15" pos="word" morph="none" start_char="6088" end_char="6089">en</TOKEN>
<TOKEN id="token-40-16" pos="word" morph="none" start_char="6091" end_char="6099">Australia</TOKEN>
<TOKEN id="token-40-17" pos="punct" morph="none" start_char="6100" end_char="6100">,</TOKEN>
<TOKEN id="token-40-18" pos="word" morph="none" start_char="6102" end_char="6104">tal</TOKEN>
<TOKEN id="token-40-19" pos="word" morph="none" start_char="6106" end_char="6109">como</TOKEN>
<TOKEN id="token-40-20" pos="word" morph="none" start_char="6111" end_char="6112">lo</TOKEN>
<TOKEN id="token-40-21" pos="word" morph="none" start_char="6114" end_char="6119">reveló</TOKEN>
<TOKEN id="token-40-22" pos="punct" morph="none" start_char="6121" end_char="6121">'</TOKEN>
<TOKEN id="token-40-23" pos="word" morph="none" start_char="6122" end_char="6124">The</TOKEN>
<TOKEN id="token-40-24" pos="word" morph="none" start_char="6126" end_char="6133">Guardian</TOKEN>
<TOKEN id="token-40-25" pos="punct" morph="none" start_char="6134" end_char="6135">'.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="6137" end_char="6328">
<ORIGINAL_TEXT>Sapan Desai reconoció el error, explicando que había sido a causa de un hospital que por equivocación se clasificó como australiano mientras que en realidad "dependía del continente asiático".</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="6137" end_char="6141">Sapan</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="6143" end_char="6147">Desai</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="6149" end_char="6157">reconoció</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="6159" end_char="6160">el</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="6162" end_char="6166">error</TOKEN>
<TOKEN id="token-41-5" pos="punct" morph="none" start_char="6167" end_char="6167">,</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="6169" end_char="6178">explicando</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="6180" end_char="6182">que</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="6184" end_char="6188">había</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="6190" end_char="6193">sido</TOKEN>
<TOKEN id="token-41-10" pos="word" morph="none" start_char="6195" end_char="6195">a</TOKEN>
<TOKEN id="token-41-11" pos="word" morph="none" start_char="6197" end_char="6201">causa</TOKEN>
<TOKEN id="token-41-12" pos="word" morph="none" start_char="6203" end_char="6204">de</TOKEN>
<TOKEN id="token-41-13" pos="word" morph="none" start_char="6206" end_char="6207">un</TOKEN>
<TOKEN id="token-41-14" pos="word" morph="none" start_char="6209" end_char="6216">hospital</TOKEN>
<TOKEN id="token-41-15" pos="word" morph="none" start_char="6218" end_char="6220">que</TOKEN>
<TOKEN id="token-41-16" pos="word" morph="none" start_char="6222" end_char="6224">por</TOKEN>
<TOKEN id="token-41-17" pos="word" morph="none" start_char="6226" end_char="6237">equivocación</TOKEN>
<TOKEN id="token-41-18" pos="word" morph="none" start_char="6239" end_char="6240">se</TOKEN>
<TOKEN id="token-41-19" pos="word" morph="none" start_char="6242" end_char="6250">clasificó</TOKEN>
<TOKEN id="token-41-20" pos="word" morph="none" start_char="6252" end_char="6255">como</TOKEN>
<TOKEN id="token-41-21" pos="word" morph="none" start_char="6257" end_char="6267">australiano</TOKEN>
<TOKEN id="token-41-22" pos="word" morph="none" start_char="6269" end_char="6276">mientras</TOKEN>
<TOKEN id="token-41-23" pos="word" morph="none" start_char="6278" end_char="6280">que</TOKEN>
<TOKEN id="token-41-24" pos="word" morph="none" start_char="6282" end_char="6283">en</TOKEN>
<TOKEN id="token-41-25" pos="word" morph="none" start_char="6285" end_char="6292">realidad</TOKEN>
<TOKEN id="token-41-26" pos="punct" morph="none" start_char="6294" end_char="6294">"</TOKEN>
<TOKEN id="token-41-27" pos="word" morph="none" start_char="6295" end_char="6302">dependía</TOKEN>
<TOKEN id="token-41-28" pos="word" morph="none" start_char="6304" end_char="6306">del</TOKEN>
<TOKEN id="token-41-29" pos="word" morph="none" start_char="6308" end_char="6317">continente</TOKEN>
<TOKEN id="token-41-30" pos="word" morph="none" start_char="6319" end_char="6326">asiático</TOKEN>
<TOKEN id="token-41-31" pos="punct" morph="none" start_char="6327" end_char="6328">".</TOKEN>
</SEG>
<SEG id="segment-42" start_char="6331" end_char="6394">
<ORIGINAL_TEXT>La precisión de los datos para África también levantó sospechas.</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="6331" end_char="6332">La</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="6334" end_char="6342">precisión</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="6344" end_char="6345">de</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="6347" end_char="6349">los</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="6351" end_char="6355">datos</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="6357" end_char="6360">para</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="6362" end_char="6367">África</TOKEN>
<TOKEN id="token-42-7" pos="word" morph="none" start_char="6369" end_char="6375">también</TOKEN>
<TOKEN id="token-42-8" pos="word" morph="none" start_char="6377" end_char="6383">levantó</TOKEN>
<TOKEN id="token-42-9" pos="word" morph="none" start_char="6385" end_char="6393">sospechas</TOKEN>
<TOKEN id="token-42-10" pos="punct" morph="none" start_char="6394" end_char="6394">.</TOKEN>
</SEG>
<SEG id="segment-43" start_char="6397" end_char="6723">
<ORIGINAL_TEXT>Parece imposible que Surgisphere haya podido obtener en tan poco tiempo informaciones médicas detalladas sobre más del 25% del conjunto de los pacientes contaminados por Covid-19 en el continente africano hasta el 21 de abril, afirma James Watson, investigador británico que reside en Tailandia y que co-firmó la carta abierta.</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="6397" end_char="6402">Parece</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="6404" end_char="6412">imposible</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="6414" end_char="6416">que</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="6418" end_char="6428">Surgisphere</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="6430" end_char="6433">haya</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="6435" end_char="6440">podido</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="6442" end_char="6448">obtener</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="6450" end_char="6451">en</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="6453" end_char="6455">tan</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="6457" end_char="6460">poco</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="6462" end_char="6467">tiempo</TOKEN>
<TOKEN id="token-43-11" pos="word" morph="none" start_char="6469" end_char="6481">informaciones</TOKEN>
<TOKEN id="token-43-12" pos="word" morph="none" start_char="6483" end_char="6489">médicas</TOKEN>
<TOKEN id="token-43-13" pos="word" morph="none" start_char="6491" end_char="6500">detalladas</TOKEN>
<TOKEN id="token-43-14" pos="word" morph="none" start_char="6502" end_char="6506">sobre</TOKEN>
<TOKEN id="token-43-15" pos="word" morph="none" start_char="6508" end_char="6510">más</TOKEN>
<TOKEN id="token-43-16" pos="word" morph="none" start_char="6512" end_char="6514">del</TOKEN>
<TOKEN id="token-43-17" pos="word" morph="none" start_char="6516" end_char="6517">25</TOKEN>
<TOKEN id="token-43-18" pos="punct" morph="none" start_char="6518" end_char="6518">%</TOKEN>
<TOKEN id="token-43-19" pos="word" morph="none" start_char="6520" end_char="6522">del</TOKEN>
<TOKEN id="token-43-20" pos="word" morph="none" start_char="6524" end_char="6531">conjunto</TOKEN>
<TOKEN id="token-43-21" pos="word" morph="none" start_char="6533" end_char="6534">de</TOKEN>
<TOKEN id="token-43-22" pos="word" morph="none" start_char="6536" end_char="6538">los</TOKEN>
<TOKEN id="token-43-23" pos="word" morph="none" start_char="6540" end_char="6548">pacientes</TOKEN>
<TOKEN id="token-43-24" pos="word" morph="none" start_char="6550" end_char="6561">contaminados</TOKEN>
<TOKEN id="token-43-25" pos="word" morph="none" start_char="6563" end_char="6565">por</TOKEN>
<TOKEN id="token-43-26" pos="unknown" morph="none" start_char="6567" end_char="6574">Covid-19</TOKEN>
<TOKEN id="token-43-27" pos="word" morph="none" start_char="6576" end_char="6577">en</TOKEN>
<TOKEN id="token-43-28" pos="word" morph="none" start_char="6579" end_char="6580">el</TOKEN>
<TOKEN id="token-43-29" pos="word" morph="none" start_char="6582" end_char="6591">continente</TOKEN>
<TOKEN id="token-43-30" pos="word" morph="none" start_char="6593" end_char="6600">africano</TOKEN>
<TOKEN id="token-43-31" pos="word" morph="none" start_char="6602" end_char="6606">hasta</TOKEN>
<TOKEN id="token-43-32" pos="word" morph="none" start_char="6608" end_char="6609">el</TOKEN>
<TOKEN id="token-43-33" pos="word" morph="none" start_char="6611" end_char="6612">21</TOKEN>
<TOKEN id="token-43-34" pos="word" morph="none" start_char="6614" end_char="6615">de</TOKEN>
<TOKEN id="token-43-35" pos="word" morph="none" start_char="6617" end_char="6621">abril</TOKEN>
<TOKEN id="token-43-36" pos="punct" morph="none" start_char="6622" end_char="6622">,</TOKEN>
<TOKEN id="token-43-37" pos="word" morph="none" start_char="6624" end_char="6629">afirma</TOKEN>
<TOKEN id="token-43-38" pos="word" morph="none" start_char="6631" end_char="6635">James</TOKEN>
<TOKEN id="token-43-39" pos="word" morph="none" start_char="6637" end_char="6642">Watson</TOKEN>
<TOKEN id="token-43-40" pos="punct" morph="none" start_char="6643" end_char="6643">,</TOKEN>
<TOKEN id="token-43-41" pos="word" morph="none" start_char="6645" end_char="6656">investigador</TOKEN>
<TOKEN id="token-43-42" pos="word" morph="none" start_char="6658" end_char="6666">británico</TOKEN>
<TOKEN id="token-43-43" pos="word" morph="none" start_char="6668" end_char="6670">que</TOKEN>
<TOKEN id="token-43-44" pos="word" morph="none" start_char="6672" end_char="6677">reside</TOKEN>
<TOKEN id="token-43-45" pos="word" morph="none" start_char="6679" end_char="6680">en</TOKEN>
<TOKEN id="token-43-46" pos="word" morph="none" start_char="6682" end_char="6690">Tailandia</TOKEN>
<TOKEN id="token-43-47" pos="word" morph="none" start_char="6692" end_char="6692">y</TOKEN>
<TOKEN id="token-43-48" pos="word" morph="none" start_char="6694" end_char="6696">que</TOKEN>
<TOKEN id="token-43-49" pos="unknown" morph="none" start_char="6698" end_char="6705">co-firmó</TOKEN>
<TOKEN id="token-43-50" pos="word" morph="none" start_char="6707" end_char="6708">la</TOKEN>
<TOKEN id="token-43-51" pos="word" morph="none" start_char="6710" end_char="6714">carta</TOKEN>
<TOKEN id="token-43-52" pos="word" morph="none" start_char="6716" end_char="6722">abierta</TOKEN>
<TOKEN id="token-43-53" pos="punct" morph="none" start_char="6723" end_char="6723">.</TOKEN>
</SEG>
<SEG id="segment-44" start_char="6725" end_char="6974">
<ORIGINAL_TEXT>Incluso los hospitales privados mejor equipados raramente cuentan con un sistema informático perfectamente actualizado con todos los datos sobre sus pacientes, añade Anthony Etyang, un epidemiólogo de Kenia entrevistado por la página 'The Scientist'.</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="6725" end_char="6731">Incluso</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="6733" end_char="6735">los</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="6737" end_char="6746">hospitales</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="6748" end_char="6755">privados</TOKEN>
<TOKEN id="token-44-4" pos="word" morph="none" start_char="6757" end_char="6761">mejor</TOKEN>
<TOKEN id="token-44-5" pos="word" morph="none" start_char="6763" end_char="6771">equipados</TOKEN>
<TOKEN id="token-44-6" pos="word" morph="none" start_char="6773" end_char="6781">raramente</TOKEN>
<TOKEN id="token-44-7" pos="word" morph="none" start_char="6783" end_char="6789">cuentan</TOKEN>
<TOKEN id="token-44-8" pos="word" morph="none" start_char="6791" end_char="6793">con</TOKEN>
<TOKEN id="token-44-9" pos="word" morph="none" start_char="6795" end_char="6796">un</TOKEN>
<TOKEN id="token-44-10" pos="word" morph="none" start_char="6798" end_char="6804">sistema</TOKEN>
<TOKEN id="token-44-11" pos="word" morph="none" start_char="6806" end_char="6816">informático</TOKEN>
<TOKEN id="token-44-12" pos="word" morph="none" start_char="6818" end_char="6830">perfectamente</TOKEN>
<TOKEN id="token-44-13" pos="word" morph="none" start_char="6832" end_char="6842">actualizado</TOKEN>
<TOKEN id="token-44-14" pos="word" morph="none" start_char="6844" end_char="6846">con</TOKEN>
<TOKEN id="token-44-15" pos="word" morph="none" start_char="6848" end_char="6852">todos</TOKEN>
<TOKEN id="token-44-16" pos="word" morph="none" start_char="6854" end_char="6856">los</TOKEN>
<TOKEN id="token-44-17" pos="word" morph="none" start_char="6858" end_char="6862">datos</TOKEN>
<TOKEN id="token-44-18" pos="word" morph="none" start_char="6864" end_char="6868">sobre</TOKEN>
<TOKEN id="token-44-19" pos="word" morph="none" start_char="6870" end_char="6872">sus</TOKEN>
<TOKEN id="token-44-20" pos="word" morph="none" start_char="6874" end_char="6882">pacientes</TOKEN>
<TOKEN id="token-44-21" pos="punct" morph="none" start_char="6883" end_char="6883">,</TOKEN>
<TOKEN id="token-44-22" pos="word" morph="none" start_char="6885" end_char="6889">añade</TOKEN>
<TOKEN id="token-44-23" pos="word" morph="none" start_char="6891" end_char="6897">Anthony</TOKEN>
<TOKEN id="token-44-24" pos="word" morph="none" start_char="6899" end_char="6904">Etyang</TOKEN>
<TOKEN id="token-44-25" pos="punct" morph="none" start_char="6905" end_char="6905">,</TOKEN>
<TOKEN id="token-44-26" pos="word" morph="none" start_char="6907" end_char="6908">un</TOKEN>
<TOKEN id="token-44-27" pos="word" morph="none" start_char="6910" end_char="6921">epidemiólogo</TOKEN>
<TOKEN id="token-44-28" pos="word" morph="none" start_char="6923" end_char="6924">de</TOKEN>
<TOKEN id="token-44-29" pos="word" morph="none" start_char="6926" end_char="6930">Kenia</TOKEN>
<TOKEN id="token-44-30" pos="word" morph="none" start_char="6932" end_char="6943">entrevistado</TOKEN>
<TOKEN id="token-44-31" pos="word" morph="none" start_char="6945" end_char="6947">por</TOKEN>
<TOKEN id="token-44-32" pos="word" morph="none" start_char="6949" end_char="6950">la</TOKEN>
<TOKEN id="token-44-33" pos="word" morph="none" start_char="6952" end_char="6957">página</TOKEN>
<TOKEN id="token-44-34" pos="punct" morph="none" start_char="6959" end_char="6959">'</TOKEN>
<TOKEN id="token-44-35" pos="word" morph="none" start_char="6960" end_char="6962">The</TOKEN>
<TOKEN id="token-44-36" pos="word" morph="none" start_char="6964" end_char="6972">Scientist</TOKEN>
<TOKEN id="token-44-37" pos="punct" morph="none" start_char="6973" end_char="6974">'.</TOKEN>
</SEG>
<SEG id="segment-45" start_char="6977" end_char="7023">
<ORIGINAL_TEXT>Surgisphere anuncia una auditoría independiente</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="6977" end_char="6987">Surgisphere</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="6989" end_char="6995">anuncia</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="6997" end_char="6999">una</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="7001" end_char="7009">auditoría</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="7011" end_char="7023">independiente</TOKEN>
</SEG>
<SEG id="segment-46" start_char="7026" end_char="7163">
<ORIGINAL_TEXT>Pero el estudio de 'Lancet' no es el único en haber utilizado la base de datos de Surgisphere, apunta la revista estadounidense 'Science'.</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="7026" end_char="7029">Pero</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="7031" end_char="7032">el</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="7034" end_char="7040">estudio</TOKEN>
<TOKEN id="token-46-3" pos="word" morph="none" start_char="7042" end_char="7043">de</TOKEN>
<TOKEN id="token-46-4" pos="punct" morph="none" start_char="7045" end_char="7045">'</TOKEN>
<TOKEN id="token-46-5" pos="word" morph="none" start_char="7046" end_char="7051">Lancet</TOKEN>
<TOKEN id="token-46-6" pos="punct" morph="none" start_char="7052" end_char="7052">'</TOKEN>
<TOKEN id="token-46-7" pos="word" morph="none" start_char="7054" end_char="7055">no</TOKEN>
<TOKEN id="token-46-8" pos="word" morph="none" start_char="7057" end_char="7058">es</TOKEN>
<TOKEN id="token-46-9" pos="word" morph="none" start_char="7060" end_char="7061">el</TOKEN>
<TOKEN id="token-46-10" pos="word" morph="none" start_char="7063" end_char="7067">único</TOKEN>
<TOKEN id="token-46-11" pos="word" morph="none" start_char="7069" end_char="7070">en</TOKEN>
<TOKEN id="token-46-12" pos="word" morph="none" start_char="7072" end_char="7076">haber</TOKEN>
<TOKEN id="token-46-13" pos="word" morph="none" start_char="7078" end_char="7086">utilizado</TOKEN>
<TOKEN id="token-46-14" pos="word" morph="none" start_char="7088" end_char="7089">la</TOKEN>
<TOKEN id="token-46-15" pos="word" morph="none" start_char="7091" end_char="7094">base</TOKEN>
<TOKEN id="token-46-16" pos="word" morph="none" start_char="7096" end_char="7097">de</TOKEN>
<TOKEN id="token-46-17" pos="word" morph="none" start_char="7099" end_char="7103">datos</TOKEN>
<TOKEN id="token-46-18" pos="word" morph="none" start_char="7105" end_char="7106">de</TOKEN>
<TOKEN id="token-46-19" pos="word" morph="none" start_char="7108" end_char="7118">Surgisphere</TOKEN>
<TOKEN id="token-46-20" pos="punct" morph="none" start_char="7119" end_char="7119">,</TOKEN>
<TOKEN id="token-46-21" pos="word" morph="none" start_char="7121" end_char="7126">apunta</TOKEN>
<TOKEN id="token-46-22" pos="word" morph="none" start_char="7128" end_char="7129">la</TOKEN>
<TOKEN id="token-46-23" pos="word" morph="none" start_char="7131" end_char="7137">revista</TOKEN>
<TOKEN id="token-46-24" pos="word" morph="none" start_char="7139" end_char="7152">estadounidense</TOKEN>
<TOKEN id="token-46-25" pos="punct" morph="none" start_char="7154" end_char="7154">'</TOKEN>
<TOKEN id="token-46-26" pos="word" morph="none" start_char="7155" end_char="7161">Science</TOKEN>
<TOKEN id="token-46-27" pos="punct" morph="none" start_char="7162" end_char="7163">'.</TOKEN>
</SEG>
<SEG id="segment-47" start_char="7165" end_char="7263">
<ORIGINAL_TEXT>No son muchos más pero sí tuvieron un impacto real sobre las políticas de lucha contra el Covid-19.</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="7165" end_char="7166">No</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="7168" end_char="7170">son</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="7172" end_char="7177">muchos</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="7179" end_char="7181">más</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="7183" end_char="7186">pero</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="7188" end_char="7189">sí</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="7191" end_char="7198">tuvieron</TOKEN>
<TOKEN id="token-47-7" pos="word" morph="none" start_char="7200" end_char="7201">un</TOKEN>
<TOKEN id="token-47-8" pos="word" morph="none" start_char="7203" end_char="7209">impacto</TOKEN>
<TOKEN id="token-47-9" pos="word" morph="none" start_char="7211" end_char="7214">real</TOKEN>
<TOKEN id="token-47-10" pos="word" morph="none" start_char="7216" end_char="7220">sobre</TOKEN>
<TOKEN id="token-47-11" pos="word" morph="none" start_char="7222" end_char="7224">las</TOKEN>
<TOKEN id="token-47-12" pos="word" morph="none" start_char="7226" end_char="7234">políticas</TOKEN>
<TOKEN id="token-47-13" pos="word" morph="none" start_char="7236" end_char="7237">de</TOKEN>
<TOKEN id="token-47-14" pos="word" morph="none" start_char="7239" end_char="7243">lucha</TOKEN>
<TOKEN id="token-47-15" pos="word" morph="none" start_char="7245" end_char="7250">contra</TOKEN>
<TOKEN id="token-47-16" pos="word" morph="none" start_char="7252" end_char="7253">el</TOKEN>
<TOKEN id="token-47-17" pos="unknown" morph="none" start_char="7255" end_char="7262">Covid-19</TOKEN>
<TOKEN id="token-47-18" pos="punct" morph="none" start_char="7263" end_char="7263">.</TOKEN>
</SEG>
<SEG id="segment-48" start_char="7265" end_char="7457">
<ORIGINAL_TEXT>Uno de ellos demostraba que la Ivermectina, un medicamento utilizado para tratar diversas enfermedades como la sarna, reducía la tasa de mortalidad de las personas contaminadas con coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="7265" end_char="7267">Uno</TOKEN>
<TOKEN id="token-48-1" pos="word" morph="none" start_char="7269" end_char="7270">de</TOKEN>
<TOKEN id="token-48-2" pos="word" morph="none" start_char="7272" end_char="7276">ellos</TOKEN>
<TOKEN id="token-48-3" pos="word" morph="none" start_char="7278" end_char="7287">demostraba</TOKEN>
<TOKEN id="token-48-4" pos="word" morph="none" start_char="7289" end_char="7291">que</TOKEN>
<TOKEN id="token-48-5" pos="word" morph="none" start_char="7293" end_char="7294">la</TOKEN>
<TOKEN id="token-48-6" pos="word" morph="none" start_char="7296" end_char="7306">Ivermectina</TOKEN>
<TOKEN id="token-48-7" pos="punct" morph="none" start_char="7307" end_char="7307">,</TOKEN>
<TOKEN id="token-48-8" pos="word" morph="none" start_char="7309" end_char="7310">un</TOKEN>
<TOKEN id="token-48-9" pos="word" morph="none" start_char="7312" end_char="7322">medicamento</TOKEN>
<TOKEN id="token-48-10" pos="word" morph="none" start_char="7324" end_char="7332">utilizado</TOKEN>
<TOKEN id="token-48-11" pos="word" morph="none" start_char="7334" end_char="7337">para</TOKEN>
<TOKEN id="token-48-12" pos="word" morph="none" start_char="7339" end_char="7344">tratar</TOKEN>
<TOKEN id="token-48-13" pos="word" morph="none" start_char="7346" end_char="7353">diversas</TOKEN>
<TOKEN id="token-48-14" pos="word" morph="none" start_char="7355" end_char="7366">enfermedades</TOKEN>
<TOKEN id="token-48-15" pos="word" morph="none" start_char="7368" end_char="7371">como</TOKEN>
<TOKEN id="token-48-16" pos="word" morph="none" start_char="7373" end_char="7374">la</TOKEN>
<TOKEN id="token-48-17" pos="word" morph="none" start_char="7376" end_char="7380">sarna</TOKEN>
<TOKEN id="token-48-18" pos="punct" morph="none" start_char="7381" end_char="7381">,</TOKEN>
<TOKEN id="token-48-19" pos="word" morph="none" start_char="7383" end_char="7389">reducía</TOKEN>
<TOKEN id="token-48-20" pos="word" morph="none" start_char="7391" end_char="7392">la</TOKEN>
<TOKEN id="token-48-21" pos="word" morph="none" start_char="7394" end_char="7397">tasa</TOKEN>
<TOKEN id="token-48-22" pos="word" morph="none" start_char="7399" end_char="7400">de</TOKEN>
<TOKEN id="token-48-23" pos="word" morph="none" start_char="7402" end_char="7411">mortalidad</TOKEN>
<TOKEN id="token-48-24" pos="word" morph="none" start_char="7413" end_char="7414">de</TOKEN>
<TOKEN id="token-48-25" pos="word" morph="none" start_char="7416" end_char="7418">las</TOKEN>
<TOKEN id="token-48-26" pos="word" morph="none" start_char="7420" end_char="7427">personas</TOKEN>
<TOKEN id="token-48-27" pos="word" morph="none" start_char="7429" end_char="7440">contaminadas</TOKEN>
<TOKEN id="token-48-28" pos="word" morph="none" start_char="7442" end_char="7444">con</TOKEN>
<TOKEN id="token-48-29" pos="word" morph="none" start_char="7446" end_char="7456">coronavirus</TOKEN>
<TOKEN id="token-48-30" pos="punct" morph="none" start_char="7457" end_char="7457">.</TOKEN>
</SEG>
<SEG id="segment-49" start_char="7459" end_char="7584">
<ORIGINAL_TEXT>Este resultado llevó al gobierno peruano a añadir este medicamento a la lista de tratamientos recomendados contra el Covid-19.</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="7459" end_char="7462">Este</TOKEN>
<TOKEN id="token-49-1" pos="word" morph="none" start_char="7464" end_char="7472">resultado</TOKEN>
<TOKEN id="token-49-2" pos="word" morph="none" start_char="7474" end_char="7478">llevó</TOKEN>
<TOKEN id="token-49-3" pos="word" morph="none" start_char="7480" end_char="7481">al</TOKEN>
<TOKEN id="token-49-4" pos="word" morph="none" start_char="7483" end_char="7490">gobierno</TOKEN>
<TOKEN id="token-49-5" pos="word" morph="none" start_char="7492" end_char="7498">peruano</TOKEN>
<TOKEN id="token-49-6" pos="word" morph="none" start_char="7500" end_char="7500">a</TOKEN>
<TOKEN id="token-49-7" pos="word" morph="none" start_char="7502" end_char="7507">añadir</TOKEN>
<TOKEN id="token-49-8" pos="word" morph="none" start_char="7509" end_char="7512">este</TOKEN>
<TOKEN id="token-49-9" pos="word" morph="none" start_char="7514" end_char="7524">medicamento</TOKEN>
<TOKEN id="token-49-10" pos="word" morph="none" start_char="7526" end_char="7526">a</TOKEN>
<TOKEN id="token-49-11" pos="word" morph="none" start_char="7528" end_char="7529">la</TOKEN>
<TOKEN id="token-49-12" pos="word" morph="none" start_char="7531" end_char="7535">lista</TOKEN>
<TOKEN id="token-49-13" pos="word" morph="none" start_char="7537" end_char="7538">de</TOKEN>
<TOKEN id="token-49-14" pos="word" morph="none" start_char="7540" end_char="7551">tratamientos</TOKEN>
<TOKEN id="token-49-15" pos="word" morph="none" start_char="7553" end_char="7564">recomendados</TOKEN>
<TOKEN id="token-49-16" pos="word" morph="none" start_char="7566" end_char="7571">contra</TOKEN>
<TOKEN id="token-49-17" pos="word" morph="none" start_char="7573" end_char="7574">el</TOKEN>
<TOKEN id="token-49-18" pos="unknown" morph="none" start_char="7576" end_char="7583">Covid-19</TOKEN>
<TOKEN id="token-49-19" pos="punct" morph="none" start_char="7584" end_char="7584">.</TOKEN>
</SEG>
<SEG id="segment-50" start_char="7587" end_char="7804">
<ORIGINAL_TEXT>Otro estudio, publicado por el 'New England Journal of Medicine', concluía que ciertos tratamientos comunes para los problemas cardíacos no aumentaban el riesgo de complicación en caso de contaminación por coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="7587" end_char="7590">Otro</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="7592" end_char="7598">estudio</TOKEN>
<TOKEN id="token-50-2" pos="punct" morph="none" start_char="7599" end_char="7599">,</TOKEN>
<TOKEN id="token-50-3" pos="word" morph="none" start_char="7601" end_char="7609">publicado</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="7611" end_char="7613">por</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="7615" end_char="7616">el</TOKEN>
<TOKEN id="token-50-6" pos="punct" morph="none" start_char="7618" end_char="7618">'</TOKEN>
<TOKEN id="token-50-7" pos="word" morph="none" start_char="7619" end_char="7621">New</TOKEN>
<TOKEN id="token-50-8" pos="word" morph="none" start_char="7623" end_char="7629">England</TOKEN>
<TOKEN id="token-50-9" pos="word" morph="none" start_char="7631" end_char="7637">Journal</TOKEN>
<TOKEN id="token-50-10" pos="word" morph="none" start_char="7639" end_char="7640">of</TOKEN>
<TOKEN id="token-50-11" pos="word" morph="none" start_char="7642" end_char="7649">Medicine</TOKEN>
<TOKEN id="token-50-12" pos="punct" morph="none" start_char="7650" end_char="7651">',</TOKEN>
<TOKEN id="token-50-13" pos="word" morph="none" start_char="7653" end_char="7660">concluía</TOKEN>
<TOKEN id="token-50-14" pos="word" morph="none" start_char="7662" end_char="7664">que</TOKEN>
<TOKEN id="token-50-15" pos="word" morph="none" start_char="7666" end_char="7672">ciertos</TOKEN>
<TOKEN id="token-50-16" pos="word" morph="none" start_char="7674" end_char="7685">tratamientos</TOKEN>
<TOKEN id="token-50-17" pos="word" morph="none" start_char="7687" end_char="7693">comunes</TOKEN>
<TOKEN id="token-50-18" pos="word" morph="none" start_char="7695" end_char="7698">para</TOKEN>
<TOKEN id="token-50-19" pos="word" morph="none" start_char="7700" end_char="7702">los</TOKEN>
<TOKEN id="token-50-20" pos="word" morph="none" start_char="7704" end_char="7712">problemas</TOKEN>
<TOKEN id="token-50-21" pos="word" morph="none" start_char="7714" end_char="7722">cardíacos</TOKEN>
<TOKEN id="token-50-22" pos="word" morph="none" start_char="7724" end_char="7725">no</TOKEN>
<TOKEN id="token-50-23" pos="word" morph="none" start_char="7727" end_char="7736">aumentaban</TOKEN>
<TOKEN id="token-50-24" pos="word" morph="none" start_char="7738" end_char="7739">el</TOKEN>
<TOKEN id="token-50-25" pos="word" morph="none" start_char="7741" end_char="7746">riesgo</TOKEN>
<TOKEN id="token-50-26" pos="word" morph="none" start_char="7748" end_char="7749">de</TOKEN>
<TOKEN id="token-50-27" pos="word" morph="none" start_char="7751" end_char="7762">complicación</TOKEN>
<TOKEN id="token-50-28" pos="word" morph="none" start_char="7764" end_char="7765">en</TOKEN>
<TOKEN id="token-50-29" pos="word" morph="none" start_char="7767" end_char="7770">caso</TOKEN>
<TOKEN id="token-50-30" pos="word" morph="none" start_char="7772" end_char="7773">de</TOKEN>
<TOKEN id="token-50-31" pos="word" morph="none" start_char="7775" end_char="7787">contaminación</TOKEN>
<TOKEN id="token-50-32" pos="word" morph="none" start_char="7789" end_char="7791">por</TOKEN>
<TOKEN id="token-50-33" pos="word" morph="none" start_char="7793" end_char="7803">coronavirus</TOKEN>
<TOKEN id="token-50-34" pos="punct" morph="none" start_char="7804" end_char="7804">.</TOKEN>
</SEG>
<SEG id="segment-51" start_char="7806" end_char="7938">
<ORIGINAL_TEXT>Al igual que 'The Lancet', el 'New England Journal of Medicine' decidió publicar una advertencia sobre la fiabilidad de este estudio.</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="word" morph="none" start_char="7806" end_char="7807">Al</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="7809" end_char="7813">igual</TOKEN>
<TOKEN id="token-51-2" pos="word" morph="none" start_char="7815" end_char="7817">que</TOKEN>
<TOKEN id="token-51-3" pos="punct" morph="none" start_char="7819" end_char="7819">'</TOKEN>
<TOKEN id="token-51-4" pos="word" morph="none" start_char="7820" end_char="7822">The</TOKEN>
<TOKEN id="token-51-5" pos="word" morph="none" start_char="7824" end_char="7829">Lancet</TOKEN>
<TOKEN id="token-51-6" pos="punct" morph="none" start_char="7830" end_char="7831">',</TOKEN>
<TOKEN id="token-51-7" pos="word" morph="none" start_char="7833" end_char="7834">el</TOKEN>
<TOKEN id="token-51-8" pos="punct" morph="none" start_char="7836" end_char="7836">'</TOKEN>
<TOKEN id="token-51-9" pos="word" morph="none" start_char="7837" end_char="7839">New</TOKEN>
<TOKEN id="token-51-10" pos="word" morph="none" start_char="7841" end_char="7847">England</TOKEN>
<TOKEN id="token-51-11" pos="word" morph="none" start_char="7849" end_char="7855">Journal</TOKEN>
<TOKEN id="token-51-12" pos="word" morph="none" start_char="7857" end_char="7858">of</TOKEN>
<TOKEN id="token-51-13" pos="word" morph="none" start_char="7860" end_char="7867">Medicine</TOKEN>
<TOKEN id="token-51-14" pos="punct" morph="none" start_char="7868" end_char="7868">'</TOKEN>
<TOKEN id="token-51-15" pos="word" morph="none" start_char="7870" end_char="7876">decidió</TOKEN>
<TOKEN id="token-51-16" pos="word" morph="none" start_char="7878" end_char="7885">publicar</TOKEN>
<TOKEN id="token-51-17" pos="word" morph="none" start_char="7887" end_char="7889">una</TOKEN>
<TOKEN id="token-51-18" pos="word" morph="none" start_char="7891" end_char="7901">advertencia</TOKEN>
<TOKEN id="token-51-19" pos="word" morph="none" start_char="7903" end_char="7907">sobre</TOKEN>
<TOKEN id="token-51-20" pos="word" morph="none" start_char="7909" end_char="7910">la</TOKEN>
<TOKEN id="token-51-21" pos="word" morph="none" start_char="7912" end_char="7921">fiabilidad</TOKEN>
<TOKEN id="token-51-22" pos="word" morph="none" start_char="7923" end_char="7924">de</TOKEN>
<TOKEN id="token-51-23" pos="word" morph="none" start_char="7926" end_char="7929">este</TOKEN>
<TOKEN id="token-51-24" pos="word" morph="none" start_char="7931" end_char="7937">estudio</TOKEN>
<TOKEN id="token-51-25" pos="punct" morph="none" start_char="7938" end_char="7938">.</TOKEN>
</SEG>
<SEG id="segment-52" start_char="7941" end_char="8071">
<ORIGINAL_TEXT>Ante las críticas, Surgisphere anunció que una auditoría independiente evaluaría lo más pronto posible su base de datos científica.</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="7941" end_char="7944">Ante</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="7946" end_char="7948">las</TOKEN>
<TOKEN id="token-52-2" pos="word" morph="none" start_char="7950" end_char="7957">críticas</TOKEN>
<TOKEN id="token-52-3" pos="punct" morph="none" start_char="7958" end_char="7958">,</TOKEN>
<TOKEN id="token-52-4" pos="word" morph="none" start_char="7960" end_char="7970">Surgisphere</TOKEN>
<TOKEN id="token-52-5" pos="word" morph="none" start_char="7972" end_char="7978">anunció</TOKEN>
<TOKEN id="token-52-6" pos="word" morph="none" start_char="7980" end_char="7982">que</TOKEN>
<TOKEN id="token-52-7" pos="word" morph="none" start_char="7984" end_char="7986">una</TOKEN>
<TOKEN id="token-52-8" pos="word" morph="none" start_char="7988" end_char="7996">auditoría</TOKEN>
<TOKEN id="token-52-9" pos="word" morph="none" start_char="7998" end_char="8010">independiente</TOKEN>
<TOKEN id="token-52-10" pos="word" morph="none" start_char="8012" end_char="8020">evaluaría</TOKEN>
<TOKEN id="token-52-11" pos="word" morph="none" start_char="8022" end_char="8023">lo</TOKEN>
<TOKEN id="token-52-12" pos="word" morph="none" start_char="8025" end_char="8027">más</TOKEN>
<TOKEN id="token-52-13" pos="word" morph="none" start_char="8029" end_char="8034">pronto</TOKEN>
<TOKEN id="token-52-14" pos="word" morph="none" start_char="8036" end_char="8042">posible</TOKEN>
<TOKEN id="token-52-15" pos="word" morph="none" start_char="8044" end_char="8045">su</TOKEN>
<TOKEN id="token-52-16" pos="word" morph="none" start_char="8047" end_char="8050">base</TOKEN>
<TOKEN id="token-52-17" pos="word" morph="none" start_char="8052" end_char="8053">de</TOKEN>
<TOKEN id="token-52-18" pos="word" morph="none" start_char="8055" end_char="8059">datos</TOKEN>
<TOKEN id="token-52-19" pos="word" morph="none" start_char="8061" end_char="8070">científica</TOKEN>
<TOKEN id="token-52-20" pos="punct" morph="none" start_char="8071" end_char="8071">.</TOKEN>
</SEG>
<SEG id="segment-53" start_char="8074" end_char="8326">
<ORIGINAL_TEXT>Entrevistado por 'The Guardian', Sapan Desai sigue defendiendo las conclusiones de los distintos estudios en los que participó, afirmando que hay "una incomprensión fundamental sobre lo que estamos haciendo y sobre el funcionamiento de nuestro sistema".</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="word" morph="none" start_char="8074" end_char="8085">Entrevistado</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="8087" end_char="8089">por</TOKEN>
<TOKEN id="token-53-2" pos="punct" morph="none" start_char="8091" end_char="8091">'</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="8092" end_char="8094">The</TOKEN>
<TOKEN id="token-53-4" pos="word" morph="none" start_char="8096" end_char="8103">Guardian</TOKEN>
<TOKEN id="token-53-5" pos="punct" morph="none" start_char="8104" end_char="8105">',</TOKEN>
<TOKEN id="token-53-6" pos="word" morph="none" start_char="8107" end_char="8111">Sapan</TOKEN>
<TOKEN id="token-53-7" pos="word" morph="none" start_char="8113" end_char="8117">Desai</TOKEN>
<TOKEN id="token-53-8" pos="word" morph="none" start_char="8119" end_char="8123">sigue</TOKEN>
<TOKEN id="token-53-9" pos="word" morph="none" start_char="8125" end_char="8135">defendiendo</TOKEN>
<TOKEN id="token-53-10" pos="word" morph="none" start_char="8137" end_char="8139">las</TOKEN>
<TOKEN id="token-53-11" pos="word" morph="none" start_char="8141" end_char="8152">conclusiones</TOKEN>
<TOKEN id="token-53-12" pos="word" morph="none" start_char="8154" end_char="8155">de</TOKEN>
<TOKEN id="token-53-13" pos="word" morph="none" start_char="8157" end_char="8159">los</TOKEN>
<TOKEN id="token-53-14" pos="word" morph="none" start_char="8161" end_char="8169">distintos</TOKEN>
<TOKEN id="token-53-15" pos="word" morph="none" start_char="8171" end_char="8178">estudios</TOKEN>
<TOKEN id="token-53-16" pos="word" morph="none" start_char="8180" end_char="8181">en</TOKEN>
<TOKEN id="token-53-17" pos="word" morph="none" start_char="8183" end_char="8185">los</TOKEN>
<TOKEN id="token-53-18" pos="word" morph="none" start_char="8187" end_char="8189">que</TOKEN>
<TOKEN id="token-53-19" pos="word" morph="none" start_char="8191" end_char="8199">participó</TOKEN>
<TOKEN id="token-53-20" pos="punct" morph="none" start_char="8200" end_char="8200">,</TOKEN>
<TOKEN id="token-53-21" pos="word" morph="none" start_char="8202" end_char="8210">afirmando</TOKEN>
<TOKEN id="token-53-22" pos="word" morph="none" start_char="8212" end_char="8214">que</TOKEN>
<TOKEN id="token-53-23" pos="word" morph="none" start_char="8216" end_char="8218">hay</TOKEN>
<TOKEN id="token-53-24" pos="punct" morph="none" start_char="8220" end_char="8220">"</TOKEN>
<TOKEN id="token-53-25" pos="word" morph="none" start_char="8221" end_char="8223">una</TOKEN>
<TOKEN id="token-53-26" pos="word" morph="none" start_char="8225" end_char="8237">incomprensión</TOKEN>
<TOKEN id="token-53-27" pos="word" morph="none" start_char="8239" end_char="8249">fundamental</TOKEN>
<TOKEN id="token-53-28" pos="word" morph="none" start_char="8251" end_char="8255">sobre</TOKEN>
<TOKEN id="token-53-29" pos="word" morph="none" start_char="8257" end_char="8258">lo</TOKEN>
<TOKEN id="token-53-30" pos="word" morph="none" start_char="8260" end_char="8262">que</TOKEN>
<TOKEN id="token-53-31" pos="word" morph="none" start_char="8264" end_char="8270">estamos</TOKEN>
<TOKEN id="token-53-32" pos="word" morph="none" start_char="8272" end_char="8279">haciendo</TOKEN>
<TOKEN id="token-53-33" pos="word" morph="none" start_char="8281" end_char="8281">y</TOKEN>
<TOKEN id="token-53-34" pos="word" morph="none" start_char="8283" end_char="8287">sobre</TOKEN>
<TOKEN id="token-53-35" pos="word" morph="none" start_char="8289" end_char="8290">el</TOKEN>
<TOKEN id="token-53-36" pos="word" morph="none" start_char="8292" end_char="8305">funcionamiento</TOKEN>
<TOKEN id="token-53-37" pos="word" morph="none" start_char="8307" end_char="8308">de</TOKEN>
<TOKEN id="token-53-38" pos="word" morph="none" start_char="8310" end_char="8316">nuestro</TOKEN>
<TOKEN id="token-53-39" pos="word" morph="none" start_char="8318" end_char="8324">sistema</TOKEN>
<TOKEN id="token-53-40" pos="punct" morph="none" start_char="8325" end_char="8326">".</TOKEN>
</SEG>
<SEG id="segment-54" start_char="8328" end_char="8507">
<ORIGINAL_TEXT>Sin embargo, no quiso explicarle más al diario británico sobre su plataforma tecnológica y se sigue negando a revelar la lista de los hospitales con los cuales Surgisphere trabaja.</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="word" morph="none" start_char="8328" end_char="8330">Sin</TOKEN>
<TOKEN id="token-54-1" pos="word" morph="none" start_char="8332" end_char="8338">embargo</TOKEN>
<TOKEN id="token-54-2" pos="punct" morph="none" start_char="8339" end_char="8339">,</TOKEN>
<TOKEN id="token-54-3" pos="word" morph="none" start_char="8341" end_char="8342">no</TOKEN>
<TOKEN id="token-54-4" pos="word" morph="none" start_char="8344" end_char="8348">quiso</TOKEN>
<TOKEN id="token-54-5" pos="word" morph="none" start_char="8350" end_char="8359">explicarle</TOKEN>
<TOKEN id="token-54-6" pos="word" morph="none" start_char="8361" end_char="8363">más</TOKEN>
<TOKEN id="token-54-7" pos="word" morph="none" start_char="8365" end_char="8366">al</TOKEN>
<TOKEN id="token-54-8" pos="word" morph="none" start_char="8368" end_char="8373">diario</TOKEN>
<TOKEN id="token-54-9" pos="word" morph="none" start_char="8375" end_char="8383">británico</TOKEN>
<TOKEN id="token-54-10" pos="word" morph="none" start_char="8385" end_char="8389">sobre</TOKEN>
<TOKEN id="token-54-11" pos="word" morph="none" start_char="8391" end_char="8392">su</TOKEN>
<TOKEN id="token-54-12" pos="word" morph="none" start_char="8394" end_char="8403">plataforma</TOKEN>
<TOKEN id="token-54-13" pos="word" morph="none" start_char="8405" end_char="8415">tecnológica</TOKEN>
<TOKEN id="token-54-14" pos="word" morph="none" start_char="8417" end_char="8417">y</TOKEN>
<TOKEN id="token-54-15" pos="word" morph="none" start_char="8419" end_char="8420">se</TOKEN>
<TOKEN id="token-54-16" pos="word" morph="none" start_char="8422" end_char="8426">sigue</TOKEN>
<TOKEN id="token-54-17" pos="word" morph="none" start_char="8428" end_char="8434">negando</TOKEN>
<TOKEN id="token-54-18" pos="word" morph="none" start_char="8436" end_char="8436">a</TOKEN>
<TOKEN id="token-54-19" pos="word" morph="none" start_char="8438" end_char="8444">revelar</TOKEN>
<TOKEN id="token-54-20" pos="word" morph="none" start_char="8446" end_char="8447">la</TOKEN>
<TOKEN id="token-54-21" pos="word" morph="none" start_char="8449" end_char="8453">lista</TOKEN>
<TOKEN id="token-54-22" pos="word" morph="none" start_char="8455" end_char="8456">de</TOKEN>
<TOKEN id="token-54-23" pos="word" morph="none" start_char="8458" end_char="8460">los</TOKEN>
<TOKEN id="token-54-24" pos="word" morph="none" start_char="8462" end_char="8471">hospitales</TOKEN>
<TOKEN id="token-54-25" pos="word" morph="none" start_char="8473" end_char="8475">con</TOKEN>
<TOKEN id="token-54-26" pos="word" morph="none" start_char="8477" end_char="8479">los</TOKEN>
<TOKEN id="token-54-27" pos="word" morph="none" start_char="8481" end_char="8486">cuales</TOKEN>
<TOKEN id="token-54-28" pos="word" morph="none" start_char="8488" end_char="8498">Surgisphere</TOKEN>
<TOKEN id="token-54-29" pos="word" morph="none" start_char="8500" end_char="8506">trabaja</TOKEN>
<TOKEN id="token-54-30" pos="punct" morph="none" start_char="8507" end_char="8507">.</TOKEN>
</SEG>
<SEG id="segment-55" start_char="8509" end_char="8574">
<ORIGINAL_TEXT>Se trata de un tema de "confidencialidad de datos", asegura Desai.</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="word" morph="none" start_char="8509" end_char="8510">Se</TOKEN>
<TOKEN id="token-55-1" pos="word" morph="none" start_char="8512" end_char="8516">trata</TOKEN>
<TOKEN id="token-55-2" pos="word" morph="none" start_char="8518" end_char="8519">de</TOKEN>
<TOKEN id="token-55-3" pos="word" morph="none" start_char="8521" end_char="8522">un</TOKEN>
<TOKEN id="token-55-4" pos="word" morph="none" start_char="8524" end_char="8527">tema</TOKEN>
<TOKEN id="token-55-5" pos="word" morph="none" start_char="8529" end_char="8530">de</TOKEN>
<TOKEN id="token-55-6" pos="punct" morph="none" start_char="8532" end_char="8532">"</TOKEN>
<TOKEN id="token-55-7" pos="word" morph="none" start_char="8533" end_char="8548">confidencialidad</TOKEN>
<TOKEN id="token-55-8" pos="word" morph="none" start_char="8550" end_char="8551">de</TOKEN>
<TOKEN id="token-55-9" pos="word" morph="none" start_char="8553" end_char="8557">datos</TOKEN>
<TOKEN id="token-55-10" pos="punct" morph="none" start_char="8558" end_char="8559">",</TOKEN>
<TOKEN id="token-55-11" pos="word" morph="none" start_char="8561" end_char="8567">asegura</TOKEN>
<TOKEN id="token-55-12" pos="word" morph="none" start_char="8569" end_char="8573">Desai</TOKEN>
<TOKEN id="token-55-13" pos="punct" morph="none" start_char="8574" end_char="8574">.</TOKEN>
</SEG>
<SEG id="segment-56" start_char="8577" end_char="8646">
<ORIGINAL_TEXT>En todo caso, la Hidroxicloroquina no necesitaba este nuevo escándalo.</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="8577" end_char="8578">En</TOKEN>
<TOKEN id="token-56-1" pos="word" morph="none" start_char="8580" end_char="8583">todo</TOKEN>
<TOKEN id="token-56-2" pos="word" morph="none" start_char="8585" end_char="8588">caso</TOKEN>
<TOKEN id="token-56-3" pos="punct" morph="none" start_char="8589" end_char="8589">,</TOKEN>
<TOKEN id="token-56-4" pos="word" morph="none" start_char="8591" end_char="8592">la</TOKEN>
<TOKEN id="token-56-5" pos="word" morph="none" start_char="8594" end_char="8610">Hidroxicloroquina</TOKEN>
<TOKEN id="token-56-6" pos="word" morph="none" start_char="8612" end_char="8613">no</TOKEN>
<TOKEN id="token-56-7" pos="word" morph="none" start_char="8615" end_char="8624">necesitaba</TOKEN>
<TOKEN id="token-56-8" pos="word" morph="none" start_char="8626" end_char="8629">este</TOKEN>
<TOKEN id="token-56-9" pos="word" morph="none" start_char="8631" end_char="8635">nuevo</TOKEN>
<TOKEN id="token-56-10" pos="word" morph="none" start_char="8637" end_char="8645">escándalo</TOKEN>
<TOKEN id="token-56-11" pos="punct" morph="none" start_char="8646" end_char="8646">.</TOKEN>
</SEG>
<SEG id="segment-57" start_char="8648" end_char="8966">
<ORIGINAL_TEXT>Las controversias relacionadas con los trabajos del profesor Didier Raoult, las mordaces afirmaciones de Donald Trump sobre "el remedio milagroso", el cambio de opinión de la OMS y las revelaciones sobre Surgisphere, terminaron haciendo de este medicamento contra la malaria el mal capítulo científico de esta pandemia.</ORIGINAL_TEXT>
<TOKEN id="token-57-0" pos="word" morph="none" start_char="8648" end_char="8650">Las</TOKEN>
<TOKEN id="token-57-1" pos="word" morph="none" start_char="8652" end_char="8664">controversias</TOKEN>
<TOKEN id="token-57-2" pos="word" morph="none" start_char="8666" end_char="8677">relacionadas</TOKEN>
<TOKEN id="token-57-3" pos="word" morph="none" start_char="8679" end_char="8681">con</TOKEN>
<TOKEN id="token-57-4" pos="word" morph="none" start_char="8683" end_char="8685">los</TOKEN>
<TOKEN id="token-57-5" pos="word" morph="none" start_char="8687" end_char="8694">trabajos</TOKEN>
<TOKEN id="token-57-6" pos="word" morph="none" start_char="8696" end_char="8698">del</TOKEN>
<TOKEN id="token-57-7" pos="word" morph="none" start_char="8700" end_char="8707">profesor</TOKEN>
<TOKEN id="token-57-8" pos="word" morph="none" start_char="8709" end_char="8714">Didier</TOKEN>
<TOKEN id="token-57-9" pos="word" morph="none" start_char="8716" end_char="8721">Raoult</TOKEN>
<TOKEN id="token-57-10" pos="punct" morph="none" start_char="8722" end_char="8722">,</TOKEN>
<TOKEN id="token-57-11" pos="word" morph="none" start_char="8724" end_char="8726">las</TOKEN>
<TOKEN id="token-57-12" pos="word" morph="none" start_char="8728" end_char="8735">mordaces</TOKEN>
<TOKEN id="token-57-13" pos="word" morph="none" start_char="8737" end_char="8748">afirmaciones</TOKEN>
<TOKEN id="token-57-14" pos="word" morph="none" start_char="8750" end_char="8751">de</TOKEN>
<TOKEN id="token-57-15" pos="word" morph="none" start_char="8753" end_char="8758">Donald</TOKEN>
<TOKEN id="token-57-16" pos="word" morph="none" start_char="8760" end_char="8764">Trump</TOKEN>
<TOKEN id="token-57-17" pos="word" morph="none" start_char="8766" end_char="8770">sobre</TOKEN>
<TOKEN id="token-57-18" pos="punct" morph="none" start_char="8772" end_char="8772">"</TOKEN>
<TOKEN id="token-57-19" pos="word" morph="none" start_char="8773" end_char="8774">el</TOKEN>
<TOKEN id="token-57-20" pos="word" morph="none" start_char="8776" end_char="8782">remedio</TOKEN>
<TOKEN id="token-57-21" pos="word" morph="none" start_char="8784" end_char="8792">milagroso</TOKEN>
<TOKEN id="token-57-22" pos="punct" morph="none" start_char="8793" end_char="8794">",</TOKEN>
<TOKEN id="token-57-23" pos="word" morph="none" start_char="8796" end_char="8797">el</TOKEN>
<TOKEN id="token-57-24" pos="word" morph="none" start_char="8799" end_char="8804">cambio</TOKEN>
<TOKEN id="token-57-25" pos="word" morph="none" start_char="8806" end_char="8807">de</TOKEN>
<TOKEN id="token-57-26" pos="word" morph="none" start_char="8809" end_char="8815">opinión</TOKEN>
<TOKEN id="token-57-27" pos="word" morph="none" start_char="8817" end_char="8818">de</TOKEN>
<TOKEN id="token-57-28" pos="word" morph="none" start_char="8820" end_char="8821">la</TOKEN>
<TOKEN id="token-57-29" pos="word" morph="none" start_char="8823" end_char="8825">OMS</TOKEN>
<TOKEN id="token-57-30" pos="word" morph="none" start_char="8827" end_char="8827">y</TOKEN>
<TOKEN id="token-57-31" pos="word" morph="none" start_char="8829" end_char="8831">las</TOKEN>
<TOKEN id="token-57-32" pos="word" morph="none" start_char="8833" end_char="8844">revelaciones</TOKEN>
<TOKEN id="token-57-33" pos="word" morph="none" start_char="8846" end_char="8850">sobre</TOKEN>
<TOKEN id="token-57-34" pos="word" morph="none" start_char="8852" end_char="8862">Surgisphere</TOKEN>
<TOKEN id="token-57-35" pos="punct" morph="none" start_char="8863" end_char="8863">,</TOKEN>
<TOKEN id="token-57-36" pos="word" morph="none" start_char="8865" end_char="8874">terminaron</TOKEN>
<TOKEN id="token-57-37" pos="word" morph="none" start_char="8876" end_char="8883">haciendo</TOKEN>
<TOKEN id="token-57-38" pos="word" morph="none" start_char="8885" end_char="8886">de</TOKEN>
<TOKEN id="token-57-39" pos="word" morph="none" start_char="8888" end_char="8891">este</TOKEN>
<TOKEN id="token-57-40" pos="word" morph="none" start_char="8893" end_char="8903">medicamento</TOKEN>
<TOKEN id="token-57-41" pos="word" morph="none" start_char="8905" end_char="8910">contra</TOKEN>
<TOKEN id="token-57-42" pos="word" morph="none" start_char="8912" end_char="8913">la</TOKEN>
<TOKEN id="token-57-43" pos="word" morph="none" start_char="8915" end_char="8921">malaria</TOKEN>
<TOKEN id="token-57-44" pos="word" morph="none" start_char="8923" end_char="8924">el</TOKEN>
<TOKEN id="token-57-45" pos="word" morph="none" start_char="8926" end_char="8928">mal</TOKEN>
<TOKEN id="token-57-46" pos="word" morph="none" start_char="8930" end_char="8937">capítulo</TOKEN>
<TOKEN id="token-57-47" pos="word" morph="none" start_char="8939" end_char="8948">científico</TOKEN>
<TOKEN id="token-57-48" pos="word" morph="none" start_char="8950" end_char="8951">de</TOKEN>
<TOKEN id="token-57-49" pos="word" morph="none" start_char="8953" end_char="8956">esta</TOKEN>
<TOKEN id="token-57-50" pos="word" morph="none" start_char="8958" end_char="8965">pandemia</TOKEN>
<TOKEN id="token-57-51" pos="punct" morph="none" start_char="8966" end_char="8966">.</TOKEN>
</SEG>
<SEG id="segment-58" start_char="8969" end_char="9020">
<ORIGINAL_TEXT>Este artículo fue adaptado de su original en francés</ORIGINAL_TEXT>
<TOKEN id="token-58-0" pos="word" morph="none" start_char="8969" end_char="8972">Este</TOKEN>
<TOKEN id="token-58-1" pos="word" morph="none" start_char="8974" end_char="8981">artículo</TOKEN>
<TOKEN id="token-58-2" pos="word" morph="none" start_char="8983" end_char="8985">fue</TOKEN>
<TOKEN id="token-58-3" pos="word" morph="none" start_char="8987" end_char="8994">adaptado</TOKEN>
<TOKEN id="token-58-4" pos="word" morph="none" start_char="8996" end_char="8997">de</TOKEN>
<TOKEN id="token-58-5" pos="word" morph="none" start_char="8999" end_char="9000">su</TOKEN>
<TOKEN id="token-58-6" pos="word" morph="none" start_char="9002" end_char="9009">original</TOKEN>
<TOKEN id="token-58-7" pos="word" morph="none" start_char="9011" end_char="9012">en</TOKEN>
<TOKEN id="token-58-8" pos="word" morph="none" start_char="9014" end_char="9020">francés</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
