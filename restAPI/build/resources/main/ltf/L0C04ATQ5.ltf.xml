<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATQ5" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="2136" raw_text_md5="12e5423ad2902f5608838af114d40f58">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="65">
<ORIGINAL_TEXT>El coronavirus podría haber estado circulando por China en agosto</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="2">El</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="4" end_char="14">coronavirus</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="16" end_char="21">podría</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="23" end_char="27">haber</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="29" end_char="34">estado</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="36" end_char="45">circulando</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="47" end_char="49">por</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="51" end_char="55">China</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="57" end_char="58">en</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="60" end_char="65">agosto</TOKEN>
</SEG>
<SEG id="segment-1" start_char="71" end_char="150">
<ORIGINAL_TEXT>A woman wearing a protective face mask seen in Sydney, Wednesday, March 4, 2020.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="71" end_char="71">A</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="73" end_char="77">woman</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="79" end_char="85">wearing</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="87" end_char="87">a</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="89" end_char="98">protective</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="100" end_char="103">face</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="105" end_char="108">mask</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="110" end_char="113">seen</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="115" end_char="116">in</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="118" end_char="123">Sydney</TOKEN>
<TOKEN id="token-1-10" pos="punct" morph="none" start_char="124" end_char="124">,</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="126" end_char="134">Wednesday</TOKEN>
<TOKEN id="token-1-12" pos="punct" morph="none" start_char="135" end_char="135">,</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="137" end_char="141">March</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="143" end_char="143">4</TOKEN>
<TOKEN id="token-1-15" pos="punct" morph="none" start_char="144" end_char="144">,</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="146" end_char="149">2020</TOKEN>
<TOKEN id="token-1-17" pos="punct" morph="none" start_char="150" end_char="150">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="152" end_char="216">
<ORIGINAL_TEXT>(AAP Image/James Gourley) NO ARCHIVING - AAPIMAGE / DPA - Archivo</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="punct" morph="none" start_char="152" end_char="152">(</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="153" end_char="155">AAP</TOKEN>
<TOKEN id="token-2-2" pos="unknown" morph="none" start_char="157" end_char="167">Image/James</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="169" end_char="175">Gourley</TOKEN>
<TOKEN id="token-2-4" pos="punct" morph="none" start_char="176" end_char="176">)</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="178" end_char="179">NO</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="181" end_char="189">ARCHIVING</TOKEN>
<TOKEN id="token-2-7" pos="punct" morph="none" start_char="191" end_char="191">-</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="193" end_char="200">AAPIMAGE</TOKEN>
<TOKEN id="token-2-9" pos="punct" morph="none" start_char="202" end_char="202">/</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="204" end_char="206">DPA</TOKEN>
<TOKEN id="token-2-11" pos="punct" morph="none" start_char="208" end_char="208">-</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="210" end_char="216">Archivo</TOKEN>
</SEG>
<SEG id="segment-3" start_char="219" end_char="232">
<ORIGINAL_TEXT>MADRID, 9 Jun.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="219" end_char="224">MADRID</TOKEN>
<TOKEN id="token-3-1" pos="punct" morph="none" start_char="225" end_char="225">,</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="227" end_char="227">9</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="229" end_char="231">Jun</TOKEN>
<TOKEN id="token-3-4" pos="punct" morph="none" start_char="232" end_char="232">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="234" end_char="249">
<ORIGINAL_TEXT>(EUROPA PRESS) -</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="punct" morph="none" start_char="234" end_char="234">(</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="235" end_char="240">EUROPA</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="242" end_char="246">PRESS</TOKEN>
<TOKEN id="token-4-3" pos="punct" morph="none" start_char="247" end_char="247">)</TOKEN>
<TOKEN id="token-4-4" pos="punct" morph="none" start_char="249" end_char="249">-</TOKEN>
</SEG>
<SEG id="segment-5" start_char="252" end_char="520">
<ORIGINAL_TEXT>Un estudio llevado a cabo por investigadores del Harvard Medical School de Boston (Estados Unidos) ha puesto de manifiesto que el nuevo coronavirus, cuya enfermedad se conoce como Covid-19, podría haber estado circulando por Wuhan (China) desde el pasado mes de agosto.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="252" end_char="253">Un</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="255" end_char="261">estudio</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="263" end_char="269">llevado</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="271" end_char="271">a</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="273" end_char="276">cabo</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="278" end_char="280">por</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="282" end_char="295">investigadores</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="297" end_char="299">del</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="301" end_char="307">Harvard</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="309" end_char="315">Medical</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="317" end_char="322">School</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="324" end_char="325">de</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="327" end_char="332">Boston</TOKEN>
<TOKEN id="token-5-13" pos="punct" morph="none" start_char="334" end_char="334">(</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="335" end_char="341">Estados</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="343" end_char="348">Unidos</TOKEN>
<TOKEN id="token-5-16" pos="punct" morph="none" start_char="349" end_char="349">)</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="351" end_char="352">ha</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="354" end_char="359">puesto</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="361" end_char="362">de</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="364" end_char="373">manifiesto</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="375" end_char="377">que</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="379" end_char="380">el</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="382" end_char="386">nuevo</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="388" end_char="398">coronavirus</TOKEN>
<TOKEN id="token-5-25" pos="punct" morph="none" start_char="399" end_char="399">,</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="401" end_char="404">cuya</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="406" end_char="415">enfermedad</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="417" end_char="418">se</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="420" end_char="425">conoce</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="427" end_char="430">como</TOKEN>
<TOKEN id="token-5-31" pos="unknown" morph="none" start_char="432" end_char="439">Covid-19</TOKEN>
<TOKEN id="token-5-32" pos="punct" morph="none" start_char="440" end_char="440">,</TOKEN>
<TOKEN id="token-5-33" pos="word" morph="none" start_char="442" end_char="447">podría</TOKEN>
<TOKEN id="token-5-34" pos="word" morph="none" start_char="449" end_char="453">haber</TOKEN>
<TOKEN id="token-5-35" pos="word" morph="none" start_char="455" end_char="460">estado</TOKEN>
<TOKEN id="token-5-36" pos="word" morph="none" start_char="462" end_char="471">circulando</TOKEN>
<TOKEN id="token-5-37" pos="word" morph="none" start_char="473" end_char="475">por</TOKEN>
<TOKEN id="token-5-38" pos="word" morph="none" start_char="477" end_char="481">Wuhan</TOKEN>
<TOKEN id="token-5-39" pos="punct" morph="none" start_char="483" end_char="483">(</TOKEN>
<TOKEN id="token-5-40" pos="word" morph="none" start_char="484" end_char="488">China</TOKEN>
<TOKEN id="token-5-41" pos="punct" morph="none" start_char="489" end_char="489">)</TOKEN>
<TOKEN id="token-5-42" pos="word" morph="none" start_char="491" end_char="495">desde</TOKEN>
<TOKEN id="token-5-43" pos="word" morph="none" start_char="497" end_char="498">el</TOKEN>
<TOKEN id="token-5-44" pos="word" morph="none" start_char="500" end_char="505">pasado</TOKEN>
<TOKEN id="token-5-45" pos="word" morph="none" start_char="507" end_char="509">mes</TOKEN>
<TOKEN id="token-5-46" pos="word" morph="none" start_char="511" end_char="512">de</TOKEN>
<TOKEN id="token-5-47" pos="word" morph="none" start_char="514" end_char="519">agosto</TOKEN>
<TOKEN id="token-5-48" pos="punct" morph="none" start_char="520" end_char="520">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="523" end_char="756">
<ORIGINAL_TEXT>A esta conclusión han llegado tras analizar imágenes satélites de los aparcamientos en los hospitales de la ciudad china así como las búsquedas en Internet sobre términos relacionados con síntomas característico del nuevo coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="523" end_char="523">A</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="525" end_char="528">esta</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="530" end_char="539">conclusión</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="541" end_char="543">han</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="545" end_char="551">llegado</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="553" end_char="556">tras</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="558" end_char="565">analizar</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="567" end_char="574">imágenes</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="576" end_char="584">satélites</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="586" end_char="587">de</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="589" end_char="591">los</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="593" end_char="605">aparcamientos</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="607" end_char="608">en</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="610" end_char="612">los</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="614" end_char="623">hospitales</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="625" end_char="626">de</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="628" end_char="629">la</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="631" end_char="636">ciudad</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="638" end_char="642">china</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="644" end_char="646">así</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="648" end_char="651">como</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="653" end_char="655">las</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="657" end_char="665">búsquedas</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="667" end_char="668">en</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="670" end_char="677">Internet</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="679" end_char="683">sobre</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="685" end_char="692">términos</TOKEN>
<TOKEN id="token-6-27" pos="word" morph="none" start_char="694" end_char="705">relacionados</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="707" end_char="709">con</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="711" end_char="718">síntomas</TOKEN>
<TOKEN id="token-6-30" pos="word" morph="none" start_char="720" end_char="733">característico</TOKEN>
<TOKEN id="token-6-31" pos="word" morph="none" start_char="735" end_char="737">del</TOKEN>
<TOKEN id="token-6-32" pos="word" morph="none" start_char="739" end_char="743">nuevo</TOKEN>
<TOKEN id="token-6-33" pos="word" morph="none" start_char="745" end_char="755">coronavirus</TOKEN>
<TOKEN id="token-6-34" pos="punct" morph="none" start_char="756" end_char="756">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="759" end_char="1058">
<ORIGINAL_TEXT>De hecho, según los análisis realizados por los expertos, el virus ha podido estar circulando antes de detectarse en el mercado de Wuhan, lugar en el que hasta ahora se ha pensado que comenzó la propagación de la enfermedad y que ha afectado a la mayor parte de los países del mundo, incluido España.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="759" end_char="760">De</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="762" end_char="766">hecho</TOKEN>
<TOKEN id="token-7-2" pos="punct" morph="none" start_char="767" end_char="767">,</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="769" end_char="773">según</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="775" end_char="777">los</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="779" end_char="786">análisis</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="788" end_char="797">realizados</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="799" end_char="801">por</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="803" end_char="805">los</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="807" end_char="814">expertos</TOKEN>
<TOKEN id="token-7-10" pos="punct" morph="none" start_char="815" end_char="815">,</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="817" end_char="818">el</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="820" end_char="824">virus</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="826" end_char="827">ha</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="829" end_char="834">podido</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="836" end_char="840">estar</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="842" end_char="851">circulando</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="853" end_char="857">antes</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="859" end_char="860">de</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="862" end_char="871">detectarse</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="873" end_char="874">en</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="876" end_char="877">el</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="879" end_char="885">mercado</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="887" end_char="888">de</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="890" end_char="894">Wuhan</TOKEN>
<TOKEN id="token-7-25" pos="punct" morph="none" start_char="895" end_char="895">,</TOKEN>
<TOKEN id="token-7-26" pos="word" morph="none" start_char="897" end_char="901">lugar</TOKEN>
<TOKEN id="token-7-27" pos="word" morph="none" start_char="903" end_char="904">en</TOKEN>
<TOKEN id="token-7-28" pos="word" morph="none" start_char="906" end_char="907">el</TOKEN>
<TOKEN id="token-7-29" pos="word" morph="none" start_char="909" end_char="911">que</TOKEN>
<TOKEN id="token-7-30" pos="word" morph="none" start_char="913" end_char="917">hasta</TOKEN>
<TOKEN id="token-7-31" pos="word" morph="none" start_char="919" end_char="923">ahora</TOKEN>
<TOKEN id="token-7-32" pos="word" morph="none" start_char="925" end_char="926">se</TOKEN>
<TOKEN id="token-7-33" pos="word" morph="none" start_char="928" end_char="929">ha</TOKEN>
<TOKEN id="token-7-34" pos="word" morph="none" start_char="931" end_char="937">pensado</TOKEN>
<TOKEN id="token-7-35" pos="word" morph="none" start_char="939" end_char="941">que</TOKEN>
<TOKEN id="token-7-36" pos="word" morph="none" start_char="943" end_char="949">comenzó</TOKEN>
<TOKEN id="token-7-37" pos="word" morph="none" start_char="951" end_char="952">la</TOKEN>
<TOKEN id="token-7-38" pos="word" morph="none" start_char="954" end_char="964">propagación</TOKEN>
<TOKEN id="token-7-39" pos="word" morph="none" start_char="966" end_char="967">de</TOKEN>
<TOKEN id="token-7-40" pos="word" morph="none" start_char="969" end_char="970">la</TOKEN>
<TOKEN id="token-7-41" pos="word" morph="none" start_char="972" end_char="981">enfermedad</TOKEN>
<TOKEN id="token-7-42" pos="word" morph="none" start_char="983" end_char="983">y</TOKEN>
<TOKEN id="token-7-43" pos="word" morph="none" start_char="985" end_char="987">que</TOKEN>
<TOKEN id="token-7-44" pos="word" morph="none" start_char="989" end_char="990">ha</TOKEN>
<TOKEN id="token-7-45" pos="word" morph="none" start_char="992" end_char="999">afectado</TOKEN>
<TOKEN id="token-7-46" pos="word" morph="none" start_char="1001" end_char="1001">a</TOKEN>
<TOKEN id="token-7-47" pos="word" morph="none" start_char="1003" end_char="1004">la</TOKEN>
<TOKEN id="token-7-48" pos="word" morph="none" start_char="1006" end_char="1010">mayor</TOKEN>
<TOKEN id="token-7-49" pos="word" morph="none" start_char="1012" end_char="1016">parte</TOKEN>
<TOKEN id="token-7-50" pos="word" morph="none" start_char="1018" end_char="1019">de</TOKEN>
<TOKEN id="token-7-51" pos="word" morph="none" start_char="1021" end_char="1023">los</TOKEN>
<TOKEN id="token-7-52" pos="word" morph="none" start_char="1025" end_char="1030">países</TOKEN>
<TOKEN id="token-7-53" pos="word" morph="none" start_char="1032" end_char="1034">del</TOKEN>
<TOKEN id="token-7-54" pos="word" morph="none" start_char="1036" end_char="1040">mundo</TOKEN>
<TOKEN id="token-7-55" pos="punct" morph="none" start_char="1041" end_char="1041">,</TOKEN>
<TOKEN id="token-7-56" pos="word" morph="none" start_char="1043" end_char="1050">incluido</TOKEN>
<TOKEN id="token-7-57" pos="word" morph="none" start_char="1052" end_char="1057">España</TOKEN>
<TOKEN id="token-7-58" pos="punct" morph="none" start_char="1058" end_char="1058">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1061" end_char="1200">
<ORIGINAL_TEXT>En concreto, los expertos analizaron más de 100 imágenes satélites de Wuhan desde el 9 de enero de 2018 hasta el 30 de abril de 2020, lo que</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1061" end_char="1062">En</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1064" end_char="1071">concreto</TOKEN>
<TOKEN id="token-8-2" pos="punct" morph="none" start_char="1072" end_char="1072">,</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1074" end_char="1076">los</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1078" end_char="1085">expertos</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1087" end_char="1096">analizaron</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1098" end_char="1100">más</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1102" end_char="1103">de</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1105" end_char="1107">100</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1109" end_char="1116">imágenes</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1118" end_char="1126">satélites</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1128" end_char="1129">de</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1131" end_char="1135">Wuhan</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1137" end_char="1141">desde</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1143" end_char="1144">el</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1146" end_char="1146">9</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1148" end_char="1149">de</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1151" end_char="1155">enero</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1157" end_char="1158">de</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1160" end_char="1163">2018</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="1165" end_char="1169">hasta</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="1171" end_char="1172">el</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="1174" end_char="1175">30</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="1177" end_char="1178">de</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="1180" end_char="1184">abril</TOKEN>
<TOKEN id="token-8-25" pos="word" morph="none" start_char="1186" end_char="1187">de</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="1189" end_char="1192">2020</TOKEN>
<TOKEN id="token-8-27" pos="punct" morph="none" start_char="1193" end_char="1193">,</TOKEN>
<TOKEN id="token-8-28" pos="word" morph="none" start_char="1195" end_char="1196">lo</TOKEN>
<TOKEN id="token-8-29" pos="word" morph="none" start_char="1198" end_char="1200">que</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1203" end_char="1308">
<ORIGINAL_TEXT>resultó en más de 200 fotografías de aparcamientos y zonas hospitalarias de hospitales de la ciudad china.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1203" end_char="1209">resultó</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1211" end_char="1212">en</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1214" end_char="1216">más</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1218" end_char="1219">de</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1221" end_char="1223">200</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1225" end_char="1235">fotografías</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1237" end_char="1238">de</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1240" end_char="1252">aparcamientos</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1254" end_char="1254">y</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1256" end_char="1260">zonas</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1262" end_char="1274">hospitalarias</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1276" end_char="1277">de</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1279" end_char="1288">hospitales</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1290" end_char="1291">de</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1293" end_char="1294">la</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1296" end_char="1301">ciudad</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1303" end_char="1307">china</TOKEN>
<TOKEN id="token-9-17" pos="punct" morph="none" start_char="1308" end_char="1308">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1311" end_char="1513">
<ORIGINAL_TEXT>Así, pudieron comprobar que a partir de agosto se produjo un incremento de vistas a los centros hospitalarios, especialmente entre septiembre y octubre y culminando el pico máximo en el mes de diciembre.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1311" end_char="1313">Así</TOKEN>
<TOKEN id="token-10-1" pos="punct" morph="none" start_char="1314" end_char="1314">,</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1316" end_char="1323">pudieron</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1325" end_char="1333">comprobar</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1335" end_char="1337">que</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1339" end_char="1339">a</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1341" end_char="1346">partir</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1348" end_char="1349">de</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1351" end_char="1356">agosto</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1358" end_char="1359">se</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1361" end_char="1367">produjo</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1369" end_char="1370">un</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1372" end_char="1381">incremento</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1383" end_char="1384">de</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1386" end_char="1391">vistas</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1393" end_char="1393">a</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1395" end_char="1397">los</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1399" end_char="1405">centros</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1407" end_char="1419">hospitalarios</TOKEN>
<TOKEN id="token-10-19" pos="punct" morph="none" start_char="1420" end_char="1420">,</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1422" end_char="1434">especialmente</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1436" end_char="1440">entre</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1442" end_char="1451">septiembre</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1453" end_char="1453">y</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1455" end_char="1461">octubre</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="1463" end_char="1463">y</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="1465" end_char="1474">culminando</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="1476" end_char="1477">el</TOKEN>
<TOKEN id="token-10-28" pos="word" morph="none" start_char="1479" end_char="1482">pico</TOKEN>
<TOKEN id="token-10-29" pos="word" morph="none" start_char="1484" end_char="1489">máximo</TOKEN>
<TOKEN id="token-10-30" pos="word" morph="none" start_char="1491" end_char="1492">en</TOKEN>
<TOKEN id="token-10-31" pos="word" morph="none" start_char="1494" end_char="1495">el</TOKEN>
<TOKEN id="token-10-32" pos="word" morph="none" start_char="1497" end_char="1499">mes</TOKEN>
<TOKEN id="token-10-33" pos="word" morph="none" start_char="1501" end_char="1502">de</TOKEN>
<TOKEN id="token-10-34" pos="word" morph="none" start_char="1504" end_char="1512">diciembre</TOKEN>
<TOKEN id="token-10-35" pos="punct" morph="none" start_char="1513" end_char="1513">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1515" end_char="1613">
<ORIGINAL_TEXT>Además, en ese mismo periodo se produjo un incremento de consultas en Internet sobre tos y diarrea.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1515" end_char="1520">Además</TOKEN>
<TOKEN id="token-11-1" pos="punct" morph="none" start_char="1521" end_char="1521">,</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1523" end_char="1524">en</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1526" end_char="1528">ese</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1530" end_char="1534">mismo</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1536" end_char="1542">periodo</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1544" end_char="1545">se</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1547" end_char="1553">produjo</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1555" end_char="1556">un</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1558" end_char="1567">incremento</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1569" end_char="1570">de</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1572" end_char="1580">consultas</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1582" end_char="1583">en</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1585" end_char="1592">Internet</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1594" end_char="1598">sobre</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1600" end_char="1602">tos</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1604" end_char="1604">y</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1606" end_char="1612">diarrea</TOKEN>
<TOKEN id="token-11-18" pos="punct" morph="none" start_char="1613" end_char="1613">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1616" end_char="1946">
<ORIGINAL_TEXT>Finalmente, y aunque los autores del trabajo reconocen que estos incrementos de las visitas a los hospitales y las búsquedas en Internet no se pueden relacionar directamente con el coronavirus, sí aseguran que respaldan otros trabajos en los que se señala que el coronavirus surgió antes de que se detectara en el mercado de Wuhan.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1616" end_char="1625">Finalmente</TOKEN>
<TOKEN id="token-12-1" pos="punct" morph="none" start_char="1626" end_char="1626">,</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1628" end_char="1628">y</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1630" end_char="1635">aunque</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1637" end_char="1639">los</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1641" end_char="1647">autores</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1649" end_char="1651">del</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1653" end_char="1659">trabajo</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1661" end_char="1669">reconocen</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1671" end_char="1673">que</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1675" end_char="1679">estos</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1681" end_char="1691">incrementos</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1693" end_char="1694">de</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1696" end_char="1698">las</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1700" end_char="1706">visitas</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1708" end_char="1708">a</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1710" end_char="1712">los</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1714" end_char="1723">hospitales</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1725" end_char="1725">y</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1727" end_char="1729">las</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1731" end_char="1739">búsquedas</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1741" end_char="1742">en</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1744" end_char="1751">Internet</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="1753" end_char="1754">no</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="1756" end_char="1757">se</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="1759" end_char="1764">pueden</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="1766" end_char="1775">relacionar</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="1777" end_char="1788">directamente</TOKEN>
<TOKEN id="token-12-28" pos="word" morph="none" start_char="1790" end_char="1792">con</TOKEN>
<TOKEN id="token-12-29" pos="word" morph="none" start_char="1794" end_char="1795">el</TOKEN>
<TOKEN id="token-12-30" pos="word" morph="none" start_char="1797" end_char="1807">coronavirus</TOKEN>
<TOKEN id="token-12-31" pos="punct" morph="none" start_char="1808" end_char="1808">,</TOKEN>
<TOKEN id="token-12-32" pos="word" morph="none" start_char="1810" end_char="1811">sí</TOKEN>
<TOKEN id="token-12-33" pos="word" morph="none" start_char="1813" end_char="1820">aseguran</TOKEN>
<TOKEN id="token-12-34" pos="word" morph="none" start_char="1822" end_char="1824">que</TOKEN>
<TOKEN id="token-12-35" pos="word" morph="none" start_char="1826" end_char="1834">respaldan</TOKEN>
<TOKEN id="token-12-36" pos="word" morph="none" start_char="1836" end_char="1840">otros</TOKEN>
<TOKEN id="token-12-37" pos="word" morph="none" start_char="1842" end_char="1849">trabajos</TOKEN>
<TOKEN id="token-12-38" pos="word" morph="none" start_char="1851" end_char="1852">en</TOKEN>
<TOKEN id="token-12-39" pos="word" morph="none" start_char="1854" end_char="1856">los</TOKEN>
<TOKEN id="token-12-40" pos="word" morph="none" start_char="1858" end_char="1860">que</TOKEN>
<TOKEN id="token-12-41" pos="word" morph="none" start_char="1862" end_char="1863">se</TOKEN>
<TOKEN id="token-12-42" pos="word" morph="none" start_char="1865" end_char="1870">señala</TOKEN>
<TOKEN id="token-12-43" pos="word" morph="none" start_char="1872" end_char="1874">que</TOKEN>
<TOKEN id="token-12-44" pos="word" morph="none" start_char="1876" end_char="1877">el</TOKEN>
<TOKEN id="token-12-45" pos="word" morph="none" start_char="1879" end_char="1889">coronavirus</TOKEN>
<TOKEN id="token-12-46" pos="word" morph="none" start_char="1891" end_char="1896">surgió</TOKEN>
<TOKEN id="token-12-47" pos="word" morph="none" start_char="1898" end_char="1902">antes</TOKEN>
<TOKEN id="token-12-48" pos="word" morph="none" start_char="1904" end_char="1905">de</TOKEN>
<TOKEN id="token-12-49" pos="word" morph="none" start_char="1907" end_char="1909">que</TOKEN>
<TOKEN id="token-12-50" pos="word" morph="none" start_char="1911" end_char="1912">se</TOKEN>
<TOKEN id="token-12-51" pos="word" morph="none" start_char="1914" end_char="1922">detectara</TOKEN>
<TOKEN id="token-12-52" pos="word" morph="none" start_char="1924" end_char="1925">en</TOKEN>
<TOKEN id="token-12-53" pos="word" morph="none" start_char="1927" end_char="1928">el</TOKEN>
<TOKEN id="token-12-54" pos="word" morph="none" start_char="1930" end_char="1936">mercado</TOKEN>
<TOKEN id="token-12-55" pos="word" morph="none" start_char="1938" end_char="1939">de</TOKEN>
<TOKEN id="token-12-56" pos="word" morph="none" start_char="1941" end_char="1945">Wuhan</TOKEN>
<TOKEN id="token-12-57" pos="punct" morph="none" start_char="1946" end_char="1946">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1949" end_char="2132">
<ORIGINAL_TEXT>Al mismo tiempo, explican que en el mes de agosto hubo muchas personas que buscaron el síntoma de la diarrea en Internet, el cual es uno de los signos más característicos del Covid-19.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1949" end_char="1950">Al</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1952" end_char="1956">mismo</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1958" end_char="1963">tiempo</TOKEN>
<TOKEN id="token-13-3" pos="punct" morph="none" start_char="1964" end_char="1964">,</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1966" end_char="1973">explican</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1975" end_char="1977">que</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1979" end_char="1980">en</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1982" end_char="1983">el</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1985" end_char="1987">mes</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1989" end_char="1990">de</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1992" end_char="1997">agosto</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1999" end_char="2002">hubo</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="2004" end_char="2009">muchas</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="2011" end_char="2018">personas</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="2020" end_char="2022">que</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="2024" end_char="2031">buscaron</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="2033" end_char="2034">el</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="2036" end_char="2042">síntoma</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="2044" end_char="2045">de</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="2047" end_char="2048">la</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="2050" end_char="2056">diarrea</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="2058" end_char="2059">en</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="2061" end_char="2068">Internet</TOKEN>
<TOKEN id="token-13-23" pos="punct" morph="none" start_char="2069" end_char="2069">,</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="2071" end_char="2072">el</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="2074" end_char="2077">cual</TOKEN>
<TOKEN id="token-13-26" pos="word" morph="none" start_char="2079" end_char="2080">es</TOKEN>
<TOKEN id="token-13-27" pos="word" morph="none" start_char="2082" end_char="2084">uno</TOKEN>
<TOKEN id="token-13-28" pos="word" morph="none" start_char="2086" end_char="2087">de</TOKEN>
<TOKEN id="token-13-29" pos="word" morph="none" start_char="2089" end_char="2091">los</TOKEN>
<TOKEN id="token-13-30" pos="word" morph="none" start_char="2093" end_char="2098">signos</TOKEN>
<TOKEN id="token-13-31" pos="word" morph="none" start_char="2100" end_char="2102">más</TOKEN>
<TOKEN id="token-13-32" pos="word" morph="none" start_char="2104" end_char="2118">característicos</TOKEN>
<TOKEN id="token-13-33" pos="word" morph="none" start_char="2120" end_char="2122">del</TOKEN>
<TOKEN id="token-13-34" pos="unknown" morph="none" start_char="2124" end_char="2131">Covid-19</TOKEN>
<TOKEN id="token-13-35" pos="punct" morph="none" start_char="2132" end_char="2132">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
