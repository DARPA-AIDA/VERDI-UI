<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CAB0" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="1521" raw_text_md5="654907567cd2a581df261f11803d905e">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="59">
<ORIGINAL_TEXT>China says covid-19 might have originated in Northern Italy</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="5">China</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="7" end_char="10">says</TOKEN>
<TOKEN id="token-0-2" pos="unknown" morph="none" start_char="12" end_char="19">covid-19</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="21" end_char="25">might</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="27" end_char="30">have</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="32" end_char="41">originated</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="43" end_char="44">in</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="46" end_char="53">Northern</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="55" end_char="59">Italy</TOKEN>
</SEG>
<SEG id="segment-1" start_char="67" end_char="140">
<ORIGINAL_TEXT>China thinks that covid-19 originally developed in Italy and not in Wuhan.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="67" end_char="71">China</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="73" end_char="78">thinks</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="80" end_char="83">that</TOKEN>
<TOKEN id="token-1-3" pos="unknown" morph="none" start_char="85" end_char="92">covid-19</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="94" end_char="103">originally</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="105" end_char="113">developed</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="115" end_char="116">in</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="118" end_char="122">Italy</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="124" end_char="126">and</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="128" end_char="130">not</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="132" end_char="133">in</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="135" end_char="139">Wuhan</TOKEN>
<TOKEN id="token-1-12" pos="punct" morph="none" start_char="140" end_char="140">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="142" end_char="191">
<ORIGINAL_TEXT>The news has been relaunched by the New York Post.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="142" end_char="144">The</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="146" end_char="149">news</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="151" end_char="153">has</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="155" end_char="158">been</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="160" end_char="169">relaunched</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="171" end_char="172">by</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="174" end_char="176">the</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="178" end_char="180">New</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="182" end_char="185">York</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="187" end_char="190">Post</TOKEN>
<TOKEN id="token-2-10" pos="punct" morph="none" start_char="191" end_char="191">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="193" end_char="332">
<ORIGINAL_TEXT>The Government in Beijing is giving great importance to an Italian study that highlights how covid-19 was circulating in Italy in late 2019.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="193" end_char="195">The</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="197" end_char="206">Government</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="208" end_char="209">in</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="211" end_char="217">Beijing</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="219" end_char="220">is</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="222" end_char="227">giving</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="229" end_char="233">great</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="235" end_char="244">importance</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="246" end_char="247">to</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="249" end_char="250">an</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="252" end_char="258">Italian</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="260" end_char="264">study</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="266" end_char="269">that</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="271" end_char="280">highlights</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="282" end_char="284">how</TOKEN>
<TOKEN id="token-3-15" pos="unknown" morph="none" start_char="286" end_char="293">covid-19</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="295" end_char="297">was</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="299" end_char="309">circulating</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="311" end_char="312">in</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="314" end_char="318">Italy</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="320" end_char="321">in</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="323" end_char="326">late</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="328" end_char="331">2019</TOKEN>
<TOKEN id="token-3-23" pos="punct" morph="none" start_char="332" end_char="332">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="335" end_char="609">
<ORIGINAL_TEXT>The spokesman of the Chinese Foreign Ministry, Zhao Lijiain, told the UK Times how this study demonstrates even more that tracing the origin of the virus is a complex scientific issue "that should be left to scientists, it is a fluid process that can involve many countries".</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="335" end_char="337">The</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="339" end_char="347">spokesman</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="349" end_char="350">of</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="352" end_char="354">the</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="356" end_char="362">Chinese</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="364" end_char="370">Foreign</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="372" end_char="379">Ministry</TOKEN>
<TOKEN id="token-4-7" pos="punct" morph="none" start_char="380" end_char="380">,</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="382" end_char="385">Zhao</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="387" end_char="393">Lijiain</TOKEN>
<TOKEN id="token-4-10" pos="punct" morph="none" start_char="394" end_char="394">,</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="396" end_char="399">told</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="401" end_char="403">the</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="405" end_char="406">UK</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="408" end_char="412">Times</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="414" end_char="416">how</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="418" end_char="421">this</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="423" end_char="427">study</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="429" end_char="440">demonstrates</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="442" end_char="445">even</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="447" end_char="450">more</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="452" end_char="455">that</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="457" end_char="463">tracing</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="465" end_char="467">the</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="469" end_char="474">origin</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="476" end_char="477">of</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="479" end_char="481">the</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="483" end_char="487">virus</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="489" end_char="490">is</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="492" end_char="492">a</TOKEN>
<TOKEN id="token-4-30" pos="word" morph="none" start_char="494" end_char="500">complex</TOKEN>
<TOKEN id="token-4-31" pos="word" morph="none" start_char="502" end_char="511">scientific</TOKEN>
<TOKEN id="token-4-32" pos="word" morph="none" start_char="513" end_char="517">issue</TOKEN>
<TOKEN id="token-4-33" pos="punct" morph="none" start_char="519" end_char="519">"</TOKEN>
<TOKEN id="token-4-34" pos="word" morph="none" start_char="520" end_char="523">that</TOKEN>
<TOKEN id="token-4-35" pos="word" morph="none" start_char="525" end_char="530">should</TOKEN>
<TOKEN id="token-4-36" pos="word" morph="none" start_char="532" end_char="533">be</TOKEN>
<TOKEN id="token-4-37" pos="word" morph="none" start_char="535" end_char="538">left</TOKEN>
<TOKEN id="token-4-38" pos="word" morph="none" start_char="540" end_char="541">to</TOKEN>
<TOKEN id="token-4-39" pos="word" morph="none" start_char="543" end_char="552">scientists</TOKEN>
<TOKEN id="token-4-40" pos="punct" morph="none" start_char="553" end_char="553">,</TOKEN>
<TOKEN id="token-4-41" pos="word" morph="none" start_char="555" end_char="556">it</TOKEN>
<TOKEN id="token-4-42" pos="word" morph="none" start_char="558" end_char="559">is</TOKEN>
<TOKEN id="token-4-43" pos="word" morph="none" start_char="561" end_char="561">a</TOKEN>
<TOKEN id="token-4-44" pos="word" morph="none" start_char="563" end_char="567">fluid</TOKEN>
<TOKEN id="token-4-45" pos="word" morph="none" start_char="569" end_char="575">process</TOKEN>
<TOKEN id="token-4-46" pos="word" morph="none" start_char="577" end_char="580">that</TOKEN>
<TOKEN id="token-4-47" pos="word" morph="none" start_char="582" end_char="584">can</TOKEN>
<TOKEN id="token-4-48" pos="word" morph="none" start_char="586" end_char="592">involve</TOKEN>
<TOKEN id="token-4-49" pos="word" morph="none" start_char="594" end_char="597">many</TOKEN>
<TOKEN id="token-4-50" pos="word" morph="none" start_char="599" end_char="607">countries</TOKEN>
<TOKEN id="token-4-51" pos="punct" morph="none" start_char="608" end_char="609">".</TOKEN>
</SEG>
<SEG id="segment-5" start_char="612" end_char="722">
<ORIGINAL_TEXT>It is not the first time that China tries to remove all its responsibility for the development of the pandemic.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="612" end_char="613">It</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="615" end_char="616">is</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="618" end_char="620">not</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="622" end_char="624">the</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="626" end_char="630">first</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="632" end_char="635">time</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="637" end_char="640">that</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="642" end_char="646">China</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="648" end_char="652">tries</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="654" end_char="655">to</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="657" end_char="662">remove</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="664" end_char="666">all</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="668" end_char="670">its</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="672" end_char="685">responsibility</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="687" end_char="689">for</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="691" end_char="693">the</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="695" end_char="705">development</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="707" end_char="708">of</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="710" end_char="712">the</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="714" end_char="721">pandemic</TOKEN>
<TOKEN id="token-5-20" pos="punct" morph="none" start_char="722" end_char="722">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="724" end_char="948">
<ORIGINAL_TEXT>In the past it turned the spotlight on a possible responsibility of Spain, as well as on the United States that could be responsible for bringing the virus to Wuhan in October 2019 on the occasion of the World Military Games.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="724" end_char="725">In</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="727" end_char="729">the</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="731" end_char="734">past</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="736" end_char="737">it</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="739" end_char="744">turned</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="746" end_char="748">the</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="750" end_char="758">spotlight</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="760" end_char="761">on</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="763" end_char="763">a</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="765" end_char="772">possible</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="774" end_char="787">responsibility</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="789" end_char="790">of</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="792" end_char="796">Spain</TOKEN>
<TOKEN id="token-6-13" pos="punct" morph="none" start_char="797" end_char="797">,</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="799" end_char="800">as</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="802" end_char="805">well</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="807" end_char="808">as</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="810" end_char="811">on</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="813" end_char="815">the</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="817" end_char="822">United</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="824" end_char="829">States</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="831" end_char="834">that</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="836" end_char="840">could</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="842" end_char="843">be</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="845" end_char="855">responsible</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="857" end_char="859">for</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="861" end_char="868">bringing</TOKEN>
<TOKEN id="token-6-27" pos="word" morph="none" start_char="870" end_char="872">the</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="874" end_char="878">virus</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="880" end_char="881">to</TOKEN>
<TOKEN id="token-6-30" pos="word" morph="none" start_char="883" end_char="887">Wuhan</TOKEN>
<TOKEN id="token-6-31" pos="word" morph="none" start_char="889" end_char="890">in</TOKEN>
<TOKEN id="token-6-32" pos="word" morph="none" start_char="892" end_char="898">October</TOKEN>
<TOKEN id="token-6-33" pos="word" morph="none" start_char="900" end_char="903">2019</TOKEN>
<TOKEN id="token-6-34" pos="word" morph="none" start_char="905" end_char="906">on</TOKEN>
<TOKEN id="token-6-35" pos="word" morph="none" start_char="908" end_char="910">the</TOKEN>
<TOKEN id="token-6-36" pos="word" morph="none" start_char="912" end_char="919">occasion</TOKEN>
<TOKEN id="token-6-37" pos="word" morph="none" start_char="921" end_char="922">of</TOKEN>
<TOKEN id="token-6-38" pos="word" morph="none" start_char="924" end_char="926">the</TOKEN>
<TOKEN id="token-6-39" pos="word" morph="none" start_char="928" end_char="932">World</TOKEN>
<TOKEN id="token-6-40" pos="word" morph="none" start_char="934" end_char="941">Military</TOKEN>
<TOKEN id="token-6-41" pos="word" morph="none" start_char="943" end_char="947">Games</TOKEN>
<TOKEN id="token-6-42" pos="punct" morph="none" start_char="948" end_char="948">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="951" end_char="1123">
<ORIGINAL_TEXT>In addition to this, the WHO has previously stated that the virus may not have originated in China, but it could have circulated in other countries, albeit asymptomatically.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="951" end_char="952">In</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="954" end_char="961">addition</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="963" end_char="964">to</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="966" end_char="969">this</TOKEN>
<TOKEN id="token-7-4" pos="punct" morph="none" start_char="970" end_char="970">,</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="972" end_char="974">the</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="976" end_char="978">WHO</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="980" end_char="982">has</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="984" end_char="993">previously</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="995" end_char="1000">stated</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="1002" end_char="1005">that</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="1007" end_char="1009">the</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="1011" end_char="1015">virus</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="1017" end_char="1019">may</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="1021" end_char="1023">not</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="1025" end_char="1028">have</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="1030" end_char="1039">originated</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="1041" end_char="1042">in</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="1044" end_char="1048">China</TOKEN>
<TOKEN id="token-7-19" pos="punct" morph="none" start_char="1049" end_char="1049">,</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="1051" end_char="1053">but</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="1055" end_char="1056">it</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="1058" end_char="1062">could</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="1064" end_char="1067">have</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="1069" end_char="1078">circulated</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="1080" end_char="1081">in</TOKEN>
<TOKEN id="token-7-26" pos="word" morph="none" start_char="1083" end_char="1087">other</TOKEN>
<TOKEN id="token-7-27" pos="word" morph="none" start_char="1089" end_char="1097">countries</TOKEN>
<TOKEN id="token-7-28" pos="punct" morph="none" start_char="1098" end_char="1098">,</TOKEN>
<TOKEN id="token-7-29" pos="word" morph="none" start_char="1100" end_char="1105">albeit</TOKEN>
<TOKEN id="token-7-30" pos="word" morph="none" start_char="1107" end_char="1122">asymptomatically</TOKEN>
<TOKEN id="token-7-31" pos="punct" morph="none" start_char="1123" end_char="1123">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1126" end_char="1275">
<ORIGINAL_TEXT>However, many scientists are skeptical of the Italian study’s findings along with the fact that it doesn't rule out the covid-19 originating in China.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1126" end_char="1132">However</TOKEN>
<TOKEN id="token-8-1" pos="punct" morph="none" start_char="1133" end_char="1133">,</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1135" end_char="1138">many</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1140" end_char="1149">scientists</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1151" end_char="1153">are</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1155" end_char="1163">skeptical</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1165" end_char="1166">of</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1168" end_char="1170">the</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1172" end_char="1178">Italian</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1180" end_char="1186">study’s</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1188" end_char="1195">findings</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1197" end_char="1201">along</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1203" end_char="1206">with</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1208" end_char="1210">the</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1212" end_char="1215">fact</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1217" end_char="1220">that</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1222" end_char="1223">it</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1225" end_char="1231">doesn't</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1233" end_char="1236">rule</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1238" end_char="1240">out</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="1242" end_char="1244">the</TOKEN>
<TOKEN id="token-8-21" pos="unknown" morph="none" start_char="1246" end_char="1253">covid-19</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="1255" end_char="1265">originating</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="1267" end_char="1268">in</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="1270" end_char="1274">China</TOKEN>
<TOKEN id="token-8-25" pos="punct" morph="none" start_char="1275" end_char="1275">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1278" end_char="1517">
<ORIGINAL_TEXT>"We know that China delayed announcing its outbreak so there is no telling when it started there, and China has very strong commercial links with northern Italy," said Giovanni Apolone of Milan’s National Cancer Institute told the UK Times.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="punct" morph="none" start_char="1278" end_char="1278">"</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1279" end_char="1280">We</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1282" end_char="1285">know</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1287" end_char="1290">that</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1292" end_char="1296">China</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1298" end_char="1304">delayed</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1306" end_char="1315">announcing</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1317" end_char="1319">its</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1321" end_char="1328">outbreak</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1330" end_char="1331">so</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1333" end_char="1337">there</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1339" end_char="1340">is</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1342" end_char="1343">no</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1345" end_char="1351">telling</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1353" end_char="1356">when</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1358" end_char="1359">it</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1361" end_char="1367">started</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1369" end_char="1373">there</TOKEN>
<TOKEN id="token-9-18" pos="punct" morph="none" start_char="1374" end_char="1374">,</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1376" end_char="1378">and</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1380" end_char="1384">China</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1386" end_char="1388">has</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1390" end_char="1393">very</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1395" end_char="1400">strong</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1402" end_char="1411">commercial</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1413" end_char="1417">links</TOKEN>
<TOKEN id="token-9-26" pos="word" morph="none" start_char="1419" end_char="1422">with</TOKEN>
<TOKEN id="token-9-27" pos="word" morph="none" start_char="1424" end_char="1431">northern</TOKEN>
<TOKEN id="token-9-28" pos="word" morph="none" start_char="1433" end_char="1437">Italy</TOKEN>
<TOKEN id="token-9-29" pos="punct" morph="none" start_char="1438" end_char="1439">,"</TOKEN>
<TOKEN id="token-9-30" pos="word" morph="none" start_char="1441" end_char="1444">said</TOKEN>
<TOKEN id="token-9-31" pos="word" morph="none" start_char="1446" end_char="1453">Giovanni</TOKEN>
<TOKEN id="token-9-32" pos="word" morph="none" start_char="1455" end_char="1461">Apolone</TOKEN>
<TOKEN id="token-9-33" pos="word" morph="none" start_char="1463" end_char="1464">of</TOKEN>
<TOKEN id="token-9-34" pos="word" morph="none" start_char="1466" end_char="1472">Milan’s</TOKEN>
<TOKEN id="token-9-35" pos="word" morph="none" start_char="1474" end_char="1481">National</TOKEN>
<TOKEN id="token-9-36" pos="word" morph="none" start_char="1483" end_char="1488">Cancer</TOKEN>
<TOKEN id="token-9-37" pos="word" morph="none" start_char="1490" end_char="1498">Institute</TOKEN>
<TOKEN id="token-9-38" pos="word" morph="none" start_char="1500" end_char="1503">told</TOKEN>
<TOKEN id="token-9-39" pos="word" morph="none" start_char="1505" end_char="1507">the</TOKEN>
<TOKEN id="token-9-40" pos="word" morph="none" start_char="1509" end_char="1510">UK</TOKEN>
<TOKEN id="token-9-41" pos="word" morph="none" start_char="1512" end_char="1516">Times</TOKEN>
<TOKEN id="token-9-42" pos="punct" morph="none" start_char="1517" end_char="1517">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
