<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CV9H" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="7529" raw_text_md5="303126968af7ed0b30f3ce222ac37ce3">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="99">
<ORIGINAL_TEXT>Estudio del CDS (versión mejorada del MMS, dióxido de cloro) en 104 humanos infectados por COVID-19</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="7">Estudio</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="9" end_char="11">del</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="13" end_char="15">CDS</TOKEN>
<TOKEN id="token-0-3" pos="punct" morph="none" start_char="17" end_char="17">(</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="18" end_char="24">versión</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="26" end_char="33">mejorada</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="35" end_char="37">del</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="39" end_char="41">MMS</TOKEN>
<TOKEN id="token-0-8" pos="punct" morph="none" start_char="42" end_char="42">,</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="44" end_char="50">dióxido</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="52" end_char="53">de</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="55" end_char="59">cloro</TOKEN>
<TOKEN id="token-0-12" pos="punct" morph="none" start_char="60" end_char="60">)</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="62" end_char="63">en</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="65" end_char="67">104</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="69" end_char="75">humanos</TOKEN>
<TOKEN id="token-0-16" pos="word" morph="none" start_char="77" end_char="86">infectados</TOKEN>
<TOKEN id="token-0-17" pos="word" morph="none" start_char="88" end_char="90">por</TOKEN>
<TOKEN id="token-0-18" pos="unknown" morph="none" start_char="92" end_char="99">COVID-19</TOKEN>
</SEG>
<SEG id="segment-1" start_char="103" end_char="203">
<ORIGINAL_TEXT>Supongo que automáticamente este post será reducido a la nada o enviado al subforo de conspiraciones.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="103" end_char="109">Supongo</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="111" end_char="113">que</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="115" end_char="129">automáticamente</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="131" end_char="134">este</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="136" end_char="139">post</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="141" end_char="144">será</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="146" end_char="153">reducido</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="155" end_char="155">a</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="157" end_char="158">la</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="160" end_char="163">nada</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="165" end_char="165">o</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="167" end_char="173">enviado</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="175" end_char="176">al</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="178" end_char="184">subforo</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="186" end_char="187">de</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="189" end_char="202">conspiraciones</TOKEN>
<TOKEN id="token-1-16" pos="punct" morph="none" start_char="203" end_char="203">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="205" end_char="258">
<ORIGINAL_TEXT>Pero lo que aqui les mostrare no es magia, es ciencia.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="205" end_char="208">Pero</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="210" end_char="211">lo</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="213" end_char="215">que</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="217" end_char="220">aqui</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="222" end_char="224">les</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="226" end_char="233">mostrare</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="235" end_char="236">no</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="238" end_char="239">es</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="241" end_char="245">magia</TOKEN>
<TOKEN id="token-2-9" pos="punct" morph="none" start_char="246" end_char="246">,</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="248" end_char="249">es</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="251" end_char="257">ciencia</TOKEN>
<TOKEN id="token-2-12" pos="punct" morph="none" start_char="258" end_char="258">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="260" end_char="401">
<ORIGINAL_TEXT>Se trata del primer estudio bien documentado de tratamiento del virus SarsCoV2 mediante el uso de dióxido de cloro vía oral y vía intravenosa.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="260" end_char="261">Se</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="263" end_char="267">trata</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="269" end_char="271">del</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="273" end_char="278">primer</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="280" end_char="286">estudio</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="288" end_char="291">bien</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="293" end_char="303">documentado</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="305" end_char="306">de</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="308" end_char="318">tratamiento</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="320" end_char="322">del</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="324" end_char="328">virus</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="330" end_char="337">SarsCoV2</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="339" end_char="346">mediante</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="348" end_char="349">el</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="351" end_char="353">uso</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="355" end_char="356">de</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="358" end_char="364">dióxido</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="366" end_char="367">de</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="369" end_char="373">cloro</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="375" end_char="377">vía</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="379" end_char="382">oral</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="384" end_char="384">y</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="386" end_char="388">vía</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="390" end_char="400">intravenosa</TOKEN>
<TOKEN id="token-3-24" pos="punct" morph="none" start_char="401" end_char="401">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="404" end_char="503">
<ORIGINAL_TEXT>Estudio del CDS (versión mejorada del MMS, dióxido de cloro) en 104 humanos infectados por COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="404" end_char="410">Estudio</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="412" end_char="414">del</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="416" end_char="418">CDS</TOKEN>
<TOKEN id="token-4-3" pos="punct" morph="none" start_char="420" end_char="420">(</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="421" end_char="427">versión</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="429" end_char="436">mejorada</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="438" end_char="440">del</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="442" end_char="444">MMS</TOKEN>
<TOKEN id="token-4-8" pos="punct" morph="none" start_char="445" end_char="445">,</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="447" end_char="453">dióxido</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="455" end_char="456">de</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="458" end_char="462">cloro</TOKEN>
<TOKEN id="token-4-12" pos="punct" morph="none" start_char="463" end_char="463">)</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="465" end_char="466">en</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="468" end_char="470">104</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="472" end_char="478">humanos</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="480" end_char="489">infectados</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="491" end_char="493">por</TOKEN>
<TOKEN id="token-4-18" pos="unknown" morph="none" start_char="495" end_char="502">COVID-19</TOKEN>
<TOKEN id="token-4-19" pos="punct" morph="none" start_char="503" end_char="503">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="506" end_char="829">
<ORIGINAL_TEXT>Aquí tenéis el documento oficial de ensayo clínico preliminar en Ecuador de CDS Oral e intravenoso de la asociación médica de AEMEMI con acta notarial firmada y datos fidedignos que demuestran la eficacia del Dióxido de cloro tanto Oral como Parenteral como sustancia eficaz contra el coronavirus con una eficacia de un 97%.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="506" end_char="509">Aquí</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="511" end_char="516">tenéis</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="518" end_char="519">el</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="521" end_char="529">documento</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="531" end_char="537">oficial</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="539" end_char="540">de</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="542" end_char="547">ensayo</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="549" end_char="555">clínico</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="557" end_char="566">preliminar</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="568" end_char="569">en</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="571" end_char="577">Ecuador</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="579" end_char="580">de</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="582" end_char="584">CDS</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="586" end_char="589">Oral</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="591" end_char="591">e</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="593" end_char="603">intravenoso</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="605" end_char="606">de</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="608" end_char="609">la</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="611" end_char="620">asociación</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="622" end_char="627">médica</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="629" end_char="630">de</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="632" end_char="637">AEMEMI</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="639" end_char="641">con</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="643" end_char="646">acta</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="648" end_char="655">notarial</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="657" end_char="663">firmada</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="665" end_char="665">y</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="667" end_char="671">datos</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="673" end_char="682">fidedignos</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="684" end_char="686">que</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="688" end_char="697">demuestran</TOKEN>
<TOKEN id="token-5-31" pos="word" morph="none" start_char="699" end_char="700">la</TOKEN>
<TOKEN id="token-5-32" pos="word" morph="none" start_char="702" end_char="709">eficacia</TOKEN>
<TOKEN id="token-5-33" pos="word" morph="none" start_char="711" end_char="713">del</TOKEN>
<TOKEN id="token-5-34" pos="word" morph="none" start_char="715" end_char="721">Dióxido</TOKEN>
<TOKEN id="token-5-35" pos="word" morph="none" start_char="723" end_char="724">de</TOKEN>
<TOKEN id="token-5-36" pos="word" morph="none" start_char="726" end_char="730">cloro</TOKEN>
<TOKEN id="token-5-37" pos="word" morph="none" start_char="732" end_char="736">tanto</TOKEN>
<TOKEN id="token-5-38" pos="word" morph="none" start_char="738" end_char="741">Oral</TOKEN>
<TOKEN id="token-5-39" pos="word" morph="none" start_char="743" end_char="746">como</TOKEN>
<TOKEN id="token-5-40" pos="word" morph="none" start_char="748" end_char="757">Parenteral</TOKEN>
<TOKEN id="token-5-41" pos="word" morph="none" start_char="759" end_char="762">como</TOKEN>
<TOKEN id="token-5-42" pos="word" morph="none" start_char="764" end_char="772">sustancia</TOKEN>
<TOKEN id="token-5-43" pos="word" morph="none" start_char="774" end_char="779">eficaz</TOKEN>
<TOKEN id="token-5-44" pos="word" morph="none" start_char="781" end_char="786">contra</TOKEN>
<TOKEN id="token-5-45" pos="word" morph="none" start_char="788" end_char="789">el</TOKEN>
<TOKEN id="token-5-46" pos="word" morph="none" start_char="791" end_char="801">coronavirus</TOKEN>
<TOKEN id="token-5-47" pos="word" morph="none" start_char="803" end_char="805">con</TOKEN>
<TOKEN id="token-5-48" pos="word" morph="none" start_char="807" end_char="809">una</TOKEN>
<TOKEN id="token-5-49" pos="word" morph="none" start_char="811" end_char="818">eficacia</TOKEN>
<TOKEN id="token-5-50" pos="word" morph="none" start_char="820" end_char="821">de</TOKEN>
<TOKEN id="token-5-51" pos="word" morph="none" start_char="823" end_char="824">un</TOKEN>
<TOKEN id="token-5-52" pos="word" morph="none" start_char="826" end_char="827">97</TOKEN>
<TOKEN id="token-5-53" pos="punct" morph="none" start_char="828" end_char="829">%.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="832" end_char="985">
<ORIGINAL_TEXT>¿Cuánto tardarán los medios convencionales en hablar de esta solución barata, inocua y no patentable a la supuesta pandemia actual, entre otras dolencias?</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="punct" morph="none" start_char="832" end_char="832">¿</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="833" end_char="838">Cuánto</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="840" end_char="847">tardarán</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="849" end_char="851">los</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="853" end_char="858">medios</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="860" end_char="873">convencionales</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="875" end_char="876">en</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="878" end_char="883">hablar</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="885" end_char="886">de</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="888" end_char="891">esta</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="893" end_char="900">solución</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="902" end_char="907">barata</TOKEN>
<TOKEN id="token-6-12" pos="punct" morph="none" start_char="908" end_char="908">,</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="910" end_char="915">inocua</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="917" end_char="917">y</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="919" end_char="920">no</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="922" end_char="931">patentable</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="933" end_char="933">a</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="935" end_char="936">la</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="938" end_char="945">supuesta</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="947" end_char="954">pandemia</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="956" end_char="961">actual</TOKEN>
<TOKEN id="token-6-22" pos="punct" morph="none" start_char="962" end_char="962">,</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="964" end_char="968">entre</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="970" end_char="974">otras</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="976" end_char="984">dolencias</TOKEN>
<TOKEN id="token-6-26" pos="punct" morph="none" start_char="985" end_char="985">?</TOKEN>
</SEG>
<SEG id="segment-7" start_char="988" end_char="1119">
<ORIGINAL_TEXT>El ensayo fue hecho en Guayaquil Ecuador y es de dominio público para ser distribuido libremente mientras no se altere el contenido.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="988" end_char="989">El</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="991" end_char="996">ensayo</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="998" end_char="1000">fue</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="1002" end_char="1006">hecho</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="1008" end_char="1009">en</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="1011" end_char="1019">Guayaquil</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="1021" end_char="1027">Ecuador</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="1029" end_char="1029">y</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="1031" end_char="1032">es</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="1034" end_char="1035">de</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="1037" end_char="1043">dominio</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="1045" end_char="1051">público</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="1053" end_char="1056">para</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="1058" end_char="1060">ser</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="1062" end_char="1072">distribuido</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="1074" end_char="1083">libremente</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="1085" end_char="1092">mientras</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="1094" end_char="1095">no</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="1097" end_char="1098">se</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="1100" end_char="1105">altere</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="1107" end_char="1108">el</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="1110" end_char="1118">contenido</TOKEN>
<TOKEN id="token-7-22" pos="punct" morph="none" start_char="1119" end_char="1119">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1122" end_char="1156">
<ORIGINAL_TEXT>Se facilita en el siguiente enlace:</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1122" end_char="1123">Se</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1125" end_char="1132">facilita</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1134" end_char="1135">en</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1137" end_char="1138">el</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1140" end_char="1148">siguiente</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1150" end_char="1155">enlace</TOKEN>
<TOKEN id="token-8-6" pos="punct" morph="none" start_char="1156" end_char="1156">:</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1159" end_char="1241">
<ORIGINAL_TEXT>https://cdn.lbryplayer.xyz/content/...af59ac186a8c3645280de725dc5/stream?download=1</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="url" morph="none" start_char="1159" end_char="1241">https://cdn.lbryplayer.xyz/content/...af59ac186a8c3645280de725dc5/stream?download=1</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1244" end_char="1296">
<ORIGINAL_TEXT>Hablamos de un estudio elaborado y firmado 7 médicos.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1244" end_char="1251">Hablamos</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1253" end_char="1254">de</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1256" end_char="1257">un</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1259" end_char="1265">estudio</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1267" end_char="1275">elaborado</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1277" end_char="1277">y</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1279" end_char="1285">firmado</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1287" end_char="1287">7</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1289" end_char="1295">médicos</TOKEN>
<TOKEN id="token-10-9" pos="punct" morph="none" start_char="1296" end_char="1296">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1298" end_char="1359">
<ORIGINAL_TEXT>Por favor tenganlo en cuenta antes de directamente censurarlo.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1298" end_char="1300">Por</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1302" end_char="1306">favor</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1308" end_char="1315">tenganlo</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1317" end_char="1318">en</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1320" end_char="1325">cuenta</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1327" end_char="1331">antes</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1333" end_char="1334">de</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1336" end_char="1347">directamente</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1349" end_char="1358">censurarlo</TOKEN>
<TOKEN id="token-11-9" pos="punct" morph="none" start_char="1359" end_char="1359">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1371" end_char="1429">
<ORIGINAL_TEXT>Opinión de Andreas Kalcker sobre este estudio de Guayaquil.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1371" end_char="1377">Opinión</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1379" end_char="1380">de</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1382" end_char="1388">Andreas</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1390" end_char="1396">Kalcker</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1398" end_char="1402">sobre</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1404" end_char="1407">este</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1409" end_char="1415">estudio</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1417" end_char="1418">de</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1420" end_char="1428">Guayaquil</TOKEN>
<TOKEN id="token-12-9" pos="punct" morph="none" start_char="1429" end_char="1429">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1433" end_char="1470">
<ORIGINAL_TEXT>Resume es demasiada información diaria</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1433" end_char="1438">Resume</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1440" end_char="1441">es</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1443" end_char="1451">demasiada</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1453" end_char="1463">información</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1465" end_char="1470">diaria</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1474" end_char="1544">
<ORIGINAL_TEXT>Por favor, como dije se trata de un estudio realizado en 104 pacientes.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1474" end_char="1476">Por</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1478" end_char="1482">favor</TOKEN>
<TOKEN id="token-14-2" pos="punct" morph="none" start_char="1483" end_char="1483">,</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1485" end_char="1488">como</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1490" end_char="1493">dije</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1495" end_char="1496">se</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1498" end_char="1502">trata</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1504" end_char="1505">de</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1507" end_char="1508">un</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1510" end_char="1516">estudio</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1518" end_char="1526">realizado</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1528" end_char="1529">en</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1531" end_char="1533">104</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1535" end_char="1543">pacientes</TOKEN>
<TOKEN id="token-14-14" pos="punct" morph="none" start_char="1544" end_char="1544">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1546" end_char="1636">
<ORIGINAL_TEXT>Tienen los consentimientos informados, diversas pruebas PCR y otras dentro del PDF anexado.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1546" end_char="1551">Tienen</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1553" end_char="1555">los</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1557" end_char="1571">consentimientos</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1573" end_char="1582">informados</TOKEN>
<TOKEN id="token-15-4" pos="punct" morph="none" start_char="1583" end_char="1583">,</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1585" end_char="1592">diversas</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1594" end_char="1600">pruebas</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1602" end_char="1604">PCR</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1606" end_char="1606">y</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1608" end_char="1612">otras</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1614" end_char="1619">dentro</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1621" end_char="1623">del</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1625" end_char="1627">PDF</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1629" end_char="1635">anexado</TOKEN>
<TOKEN id="token-15-14" pos="punct" morph="none" start_char="1636" end_char="1636">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1639" end_char="1745">
<ORIGINAL_TEXT>No deberiamos cerrarnos ante nuevos problemas...ya que los nuevos problemas necesitan de nuevas soluciones.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1639" end_char="1640">No</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1642" end_char="1651">deberiamos</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1653" end_char="1661">cerrarnos</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1663" end_char="1666">ante</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1668" end_char="1673">nuevos</TOKEN>
<TOKEN id="token-16-5" pos="unknown" morph="none" start_char="1675" end_char="1688">problemas...ya</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1690" end_char="1692">que</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1694" end_char="1696">los</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1698" end_char="1703">nuevos</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="1705" end_char="1713">problemas</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="1715" end_char="1723">necesitan</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="1725" end_char="1726">de</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="1728" end_char="1733">nuevas</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="1735" end_char="1744">soluciones</TOKEN>
<TOKEN id="token-16-14" pos="punct" morph="none" start_char="1745" end_char="1745">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1749" end_char="1858">
<ORIGINAL_TEXT>Mientras aqui no se buscan soluciones, el viceministro de salud de Ecuador ha estado presente en este estudio.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1749" end_char="1756">Mientras</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1758" end_char="1761">aqui</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="1763" end_char="1764">no</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="1766" end_char="1767">se</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="1769" end_char="1774">buscan</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="1776" end_char="1785">soluciones</TOKEN>
<TOKEN id="token-17-6" pos="punct" morph="none" start_char="1786" end_char="1786">,</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="1788" end_char="1789">el</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="1791" end_char="1802">viceministro</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="1804" end_char="1805">de</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="1807" end_char="1811">salud</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="1813" end_char="1814">de</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="1816" end_char="1822">Ecuador</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="1824" end_char="1825">ha</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="1827" end_char="1832">estado</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="1834" end_char="1841">presente</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="1843" end_char="1844">en</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="1846" end_char="1849">este</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="1851" end_char="1857">estudio</TOKEN>
<TOKEN id="token-17-19" pos="punct" morph="none" start_char="1858" end_char="1858">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1862" end_char="1917">
<ORIGINAL_TEXT>manutartufo dijo: Resume es demasiada información diaria</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="1862" end_char="1872">manutartufo</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="1874" end_char="1877">dijo</TOKEN>
<TOKEN id="token-18-2" pos="punct" morph="none" start_char="1878" end_char="1878">:</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="1880" end_char="1885">Resume</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="1887" end_char="1888">es</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="1890" end_char="1898">demasiada</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="1900" end_char="1910">información</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="1912" end_char="1917">diaria</TOKEN>
</SEG>
<SEG id="segment-19" start_char="1921" end_char="1951">
<ORIGINAL_TEXT>La ultima imagen es el resumen.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="1921" end_char="1922">La</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="1924" end_char="1929">ultima</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="1931" end_char="1936">imagen</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="1938" end_char="1939">es</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="1941" end_char="1942">el</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="1944" end_char="1950">resumen</TOKEN>
<TOKEN id="token-19-6" pos="punct" morph="none" start_char="1951" end_char="1951">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="1955" end_char="2131">
<ORIGINAL_TEXT>Tranquilo AUNQUE YA SABEMOS QUE FUNCIONA contra el COVID, AQUI LOS FENOMENOS te van a pedir Estudios DOBLE CIEGO esos que NO TIENEN las VACUNA DE FAUCI y KILL GATES jojojojojojo</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="1955" end_char="1963">Tranquilo</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="1965" end_char="1970">AUNQUE</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="1972" end_char="1973">YA</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="1975" end_char="1981">SABEMOS</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="1983" end_char="1985">QUE</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="1987" end_char="1994">FUNCIONA</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="1996" end_char="2001">contra</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2003" end_char="2004">el</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="2006" end_char="2010">COVID</TOKEN>
<TOKEN id="token-20-9" pos="punct" morph="none" start_char="2011" end_char="2011">,</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2013" end_char="2016">AQUI</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="2018" end_char="2020">LOS</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="2022" end_char="2030">FENOMENOS</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="2032" end_char="2033">te</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="2035" end_char="2037">van</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="2039" end_char="2039">a</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="2041" end_char="2045">pedir</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="2047" end_char="2054">Estudios</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="2056" end_char="2060">DOBLE</TOKEN>
<TOKEN id="token-20-19" pos="word" morph="none" start_char="2062" end_char="2066">CIEGO</TOKEN>
<TOKEN id="token-20-20" pos="word" morph="none" start_char="2068" end_char="2071">esos</TOKEN>
<TOKEN id="token-20-21" pos="word" morph="none" start_char="2073" end_char="2075">que</TOKEN>
<TOKEN id="token-20-22" pos="word" morph="none" start_char="2077" end_char="2078">NO</TOKEN>
<TOKEN id="token-20-23" pos="word" morph="none" start_char="2080" end_char="2085">TIENEN</TOKEN>
<TOKEN id="token-20-24" pos="word" morph="none" start_char="2087" end_char="2089">las</TOKEN>
<TOKEN id="token-20-25" pos="word" morph="none" start_char="2091" end_char="2096">VACUNA</TOKEN>
<TOKEN id="token-20-26" pos="word" morph="none" start_char="2098" end_char="2099">DE</TOKEN>
<TOKEN id="token-20-27" pos="word" morph="none" start_char="2101" end_char="2105">FAUCI</TOKEN>
<TOKEN id="token-20-28" pos="word" morph="none" start_char="2107" end_char="2107">y</TOKEN>
<TOKEN id="token-20-29" pos="word" morph="none" start_char="2109" end_char="2112">KILL</TOKEN>
<TOKEN id="token-20-30" pos="word" morph="none" start_char="2114" end_char="2118">GATES</TOKEN>
<TOKEN id="token-20-31" pos="word" morph="none" start_char="2120" end_char="2131">jojojojojojo</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2134" end_char="2150">
<ORIGINAL_TEXT>Y NINGUNA VACUNA.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2134" end_char="2134">Y</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2136" end_char="2142">NINGUNA</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2144" end_char="2149">VACUNA</TOKEN>
<TOKEN id="token-21-3" pos="punct" morph="none" start_char="2150" end_char="2150">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2154" end_char="2209">
<ORIGINAL_TEXT>manutartufo dijo: Resume es demasiada información diaria</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2154" end_char="2164">manutartufo</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2166" end_char="2169">dijo</TOKEN>
<TOKEN id="token-22-2" pos="punct" morph="none" start_char="2170" end_char="2170">:</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2172" end_char="2177">Resume</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2179" end_char="2180">es</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2182" end_char="2190">demasiada</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2192" end_char="2202">información</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2204" end_char="2209">diaria</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2213" end_char="2255">
<ORIGINAL_TEXT>¿Demasiada información, 15 líneas de texto?</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="punct" morph="none" start_char="2213" end_char="2213">¿</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2214" end_char="2222">Demasiada</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2224" end_char="2234">información</TOKEN>
<TOKEN id="token-23-3" pos="punct" morph="none" start_char="2235" end_char="2235">,</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="2237" end_char="2238">15</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="2240" end_char="2245">líneas</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="2247" end_char="2248">de</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="2250" end_char="2254">texto</TOKEN>
<TOKEN id="token-23-8" pos="punct" morph="none" start_char="2255" end_char="2255">?</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2259" end_char="2301">
<ORIGINAL_TEXT>Muchas gracias por la información, Técnico.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="2259" end_char="2264">Muchas</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="2266" end_char="2272">gracias</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="2274" end_char="2276">por</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="2278" end_char="2279">la</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="2281" end_char="2291">información</TOKEN>
<TOKEN id="token-24-5" pos="punct" morph="none" start_char="2292" end_char="2292">,</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="2294" end_char="2300">Técnico</TOKEN>
<TOKEN id="token-24-7" pos="punct" morph="none" start_char="2301" end_char="2301">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2303" end_char="2350">
<ORIGINAL_TEXT>Espero que con el informe que adjuntas los Sres.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="2303" end_char="2308">Espero</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="2310" end_char="2312">que</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="2314" end_char="2316">con</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="2318" end_char="2319">el</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="2321" end_char="2327">informe</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="2329" end_char="2331">que</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="2333" end_char="2340">adjuntas</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="2342" end_char="2344">los</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="2346" end_char="2349">Sres</TOKEN>
<TOKEN id="token-25-9" pos="punct" morph="none" start_char="2350" end_char="2350">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="2352" end_char="2423">
<ORIGINAL_TEXT>Inquisidores del foro se den por satisfechos y dejen el hilo donde está.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="2352" end_char="2363">Inquisidores</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="2365" end_char="2367">del</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="2369" end_char="2372">foro</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="2374" end_char="2375">se</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="2377" end_char="2379">den</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="2381" end_char="2383">por</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="2385" end_char="2395">satisfechos</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="2397" end_char="2397">y</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="2399" end_char="2403">dejen</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="2405" end_char="2406">el</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="2408" end_char="2411">hilo</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="2413" end_char="2417">donde</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="2419" end_char="2422">está</TOKEN>
<TOKEN id="token-26-13" pos="punct" morph="none" start_char="2423" end_char="2423">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="2427" end_char="2506">
<ORIGINAL_TEXT>Estamos hablando de un estudio médico de 84 páginas...autentificado por notario.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="2427" end_char="2433">Estamos</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="2435" end_char="2442">hablando</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="2444" end_char="2445">de</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="2447" end_char="2448">un</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="2450" end_char="2456">estudio</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="2458" end_char="2463">médico</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="2465" end_char="2466">de</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="2468" end_char="2469">84</TOKEN>
<TOKEN id="token-27-8" pos="unknown" morph="none" start_char="2471" end_char="2493">páginas...autentificado</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="2495" end_char="2497">por</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="2499" end_char="2505">notario</TOKEN>
<TOKEN id="token-27-11" pos="punct" morph="none" start_char="2506" end_char="2506">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="2508" end_char="2752">
<ORIGINAL_TEXT>Con los DNIs del médico investigador principal y los datos de los otros 6, con los consentimientos informados de los pacientes sometidos al estudio, con datos histiológicos, con analiticas, con la aportación de los positivos por prueba PCR, etc.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="2508" end_char="2510">Con</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="2512" end_char="2514">los</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="2516" end_char="2519">DNIs</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="2521" end_char="2523">del</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="2525" end_char="2530">médico</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="2532" end_char="2543">investigador</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="2545" end_char="2553">principal</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="2555" end_char="2555">y</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="2557" end_char="2559">los</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="2561" end_char="2565">datos</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="2567" end_char="2568">de</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="2570" end_char="2572">los</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="2574" end_char="2578">otros</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="2580" end_char="2580">6</TOKEN>
<TOKEN id="token-28-14" pos="punct" morph="none" start_char="2581" end_char="2581">,</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="2583" end_char="2585">con</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="2587" end_char="2589">los</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="2591" end_char="2605">consentimientos</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="2607" end_char="2616">informados</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="2618" end_char="2619">de</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="2621" end_char="2623">los</TOKEN>
<TOKEN id="token-28-21" pos="word" morph="none" start_char="2625" end_char="2633">pacientes</TOKEN>
<TOKEN id="token-28-22" pos="word" morph="none" start_char="2635" end_char="2643">sometidos</TOKEN>
<TOKEN id="token-28-23" pos="word" morph="none" start_char="2645" end_char="2646">al</TOKEN>
<TOKEN id="token-28-24" pos="word" morph="none" start_char="2648" end_char="2654">estudio</TOKEN>
<TOKEN id="token-28-25" pos="punct" morph="none" start_char="2655" end_char="2655">,</TOKEN>
<TOKEN id="token-28-26" pos="word" morph="none" start_char="2657" end_char="2659">con</TOKEN>
<TOKEN id="token-28-27" pos="word" morph="none" start_char="2661" end_char="2665">datos</TOKEN>
<TOKEN id="token-28-28" pos="word" morph="none" start_char="2667" end_char="2679">histiológicos</TOKEN>
<TOKEN id="token-28-29" pos="punct" morph="none" start_char="2680" end_char="2680">,</TOKEN>
<TOKEN id="token-28-30" pos="word" morph="none" start_char="2682" end_char="2684">con</TOKEN>
<TOKEN id="token-28-31" pos="word" morph="none" start_char="2686" end_char="2695">analiticas</TOKEN>
<TOKEN id="token-28-32" pos="punct" morph="none" start_char="2696" end_char="2696">,</TOKEN>
<TOKEN id="token-28-33" pos="word" morph="none" start_char="2698" end_char="2700">con</TOKEN>
<TOKEN id="token-28-34" pos="word" morph="none" start_char="2702" end_char="2703">la</TOKEN>
<TOKEN id="token-28-35" pos="word" morph="none" start_char="2705" end_char="2714">aportación</TOKEN>
<TOKEN id="token-28-36" pos="word" morph="none" start_char="2716" end_char="2717">de</TOKEN>
<TOKEN id="token-28-37" pos="word" morph="none" start_char="2719" end_char="2721">los</TOKEN>
<TOKEN id="token-28-38" pos="word" morph="none" start_char="2723" end_char="2731">positivos</TOKEN>
<TOKEN id="token-28-39" pos="word" morph="none" start_char="2733" end_char="2735">por</TOKEN>
<TOKEN id="token-28-40" pos="word" morph="none" start_char="2737" end_char="2742">prueba</TOKEN>
<TOKEN id="token-28-41" pos="word" morph="none" start_char="2744" end_char="2746">PCR</TOKEN>
<TOKEN id="token-28-42" pos="punct" morph="none" start_char="2747" end_char="2747">,</TOKEN>
<TOKEN id="token-28-43" pos="word" morph="none" start_char="2749" end_char="2751">etc</TOKEN>
<TOKEN id="token-28-44" pos="punct" morph="none" start_char="2752" end_char="2752">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="2756" end_char="2778">
<ORIGINAL_TEXT>¿Y el grupo de control?</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="punct" morph="none" start_char="2756" end_char="2756">¿</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="2757" end_char="2757">Y</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="2759" end_char="2760">el</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="2762" end_char="2766">grupo</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="2768" end_char="2769">de</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="2771" end_char="2777">control</TOKEN>
<TOKEN id="token-29-6" pos="punct" morph="none" start_char="2778" end_char="2778">?</TOKEN>
</SEG>
<SEG id="segment-30" start_char="2780" end_char="2925">
<ORIGINAL_TEXT>¿A qué grupo equivalente no le dieron MMS estos discípulos del charlatán Kalcker para comprobar que sea el MMS lo que causa algún efecto positivo?</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="punct" morph="none" start_char="2780" end_char="2780">¿</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="2781" end_char="2781">A</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="2783" end_char="2785">qué</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="2787" end_char="2791">grupo</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="2793" end_char="2803">equivalente</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="2805" end_char="2806">no</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="2808" end_char="2809">le</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="2811" end_char="2816">dieron</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="2818" end_char="2820">MMS</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="2822" end_char="2826">estos</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="2828" end_char="2837">discípulos</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="2839" end_char="2841">del</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="2843" end_char="2851">charlatán</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="2853" end_char="2859">Kalcker</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="2861" end_char="2864">para</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="2866" end_char="2874">comprobar</TOKEN>
<TOKEN id="token-30-16" pos="word" morph="none" start_char="2876" end_char="2878">que</TOKEN>
<TOKEN id="token-30-17" pos="word" morph="none" start_char="2880" end_char="2882">sea</TOKEN>
<TOKEN id="token-30-18" pos="word" morph="none" start_char="2884" end_char="2885">el</TOKEN>
<TOKEN id="token-30-19" pos="word" morph="none" start_char="2887" end_char="2889">MMS</TOKEN>
<TOKEN id="token-30-20" pos="word" morph="none" start_char="2891" end_char="2892">lo</TOKEN>
<TOKEN id="token-30-21" pos="word" morph="none" start_char="2894" end_char="2896">que</TOKEN>
<TOKEN id="token-30-22" pos="word" morph="none" start_char="2898" end_char="2902">causa</TOKEN>
<TOKEN id="token-30-23" pos="word" morph="none" start_char="2904" end_char="2908">algún</TOKEN>
<TOKEN id="token-30-24" pos="word" morph="none" start_char="2910" end_char="2915">efecto</TOKEN>
<TOKEN id="token-30-25" pos="word" morph="none" start_char="2917" end_char="2924">positivo</TOKEN>
<TOKEN id="token-30-26" pos="punct" morph="none" start_char="2925" end_char="2925">?</TOKEN>
</SEG>
<SEG id="segment-31" start_char="2928" end_char="3188">
<ORIGINAL_TEXT>Obviamente, si les das cualquier cosa suficientemente inocua como para no matarles directamente a un grupo de personas entre 30 y 50 años con un virus que en la gran mayoría de casos no mata en ese grupo de edad, no es ningún misterio que se acaben recuperando.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="2928" end_char="2937">Obviamente</TOKEN>
<TOKEN id="token-31-1" pos="punct" morph="none" start_char="2938" end_char="2938">,</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="2940" end_char="2941">si</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="2943" end_char="2945">les</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="2947" end_char="2949">das</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="2951" end_char="2959">cualquier</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="2961" end_char="2964">cosa</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="2966" end_char="2980">suficientemente</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="2982" end_char="2987">inocua</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="2989" end_char="2992">como</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="2994" end_char="2997">para</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="2999" end_char="3000">no</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="3002" end_char="3009">matarles</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="3011" end_char="3022">directamente</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="3024" end_char="3024">a</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="3026" end_char="3027">un</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="3029" end_char="3033">grupo</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="3035" end_char="3036">de</TOKEN>
<TOKEN id="token-31-18" pos="word" morph="none" start_char="3038" end_char="3045">personas</TOKEN>
<TOKEN id="token-31-19" pos="word" morph="none" start_char="3047" end_char="3051">entre</TOKEN>
<TOKEN id="token-31-20" pos="word" morph="none" start_char="3053" end_char="3054">30</TOKEN>
<TOKEN id="token-31-21" pos="word" morph="none" start_char="3056" end_char="3056">y</TOKEN>
<TOKEN id="token-31-22" pos="word" morph="none" start_char="3058" end_char="3059">50</TOKEN>
<TOKEN id="token-31-23" pos="word" morph="none" start_char="3061" end_char="3064">años</TOKEN>
<TOKEN id="token-31-24" pos="word" morph="none" start_char="3066" end_char="3068">con</TOKEN>
<TOKEN id="token-31-25" pos="word" morph="none" start_char="3070" end_char="3071">un</TOKEN>
<TOKEN id="token-31-26" pos="word" morph="none" start_char="3073" end_char="3077">virus</TOKEN>
<TOKEN id="token-31-27" pos="word" morph="none" start_char="3079" end_char="3081">que</TOKEN>
<TOKEN id="token-31-28" pos="word" morph="none" start_char="3083" end_char="3084">en</TOKEN>
<TOKEN id="token-31-29" pos="word" morph="none" start_char="3086" end_char="3087">la</TOKEN>
<TOKEN id="token-31-30" pos="word" morph="none" start_char="3089" end_char="3092">gran</TOKEN>
<TOKEN id="token-31-31" pos="word" morph="none" start_char="3094" end_char="3100">mayoría</TOKEN>
<TOKEN id="token-31-32" pos="word" morph="none" start_char="3102" end_char="3103">de</TOKEN>
<TOKEN id="token-31-33" pos="word" morph="none" start_char="3105" end_char="3109">casos</TOKEN>
<TOKEN id="token-31-34" pos="word" morph="none" start_char="3111" end_char="3112">no</TOKEN>
<TOKEN id="token-31-35" pos="word" morph="none" start_char="3114" end_char="3117">mata</TOKEN>
<TOKEN id="token-31-36" pos="word" morph="none" start_char="3119" end_char="3120">en</TOKEN>
<TOKEN id="token-31-37" pos="word" morph="none" start_char="3122" end_char="3124">ese</TOKEN>
<TOKEN id="token-31-38" pos="word" morph="none" start_char="3126" end_char="3130">grupo</TOKEN>
<TOKEN id="token-31-39" pos="word" morph="none" start_char="3132" end_char="3133">de</TOKEN>
<TOKEN id="token-31-40" pos="word" morph="none" start_char="3135" end_char="3138">edad</TOKEN>
<TOKEN id="token-31-41" pos="punct" morph="none" start_char="3139" end_char="3139">,</TOKEN>
<TOKEN id="token-31-42" pos="word" morph="none" start_char="3141" end_char="3142">no</TOKEN>
<TOKEN id="token-31-43" pos="word" morph="none" start_char="3144" end_char="3145">es</TOKEN>
<TOKEN id="token-31-44" pos="word" morph="none" start_char="3147" end_char="3152">ningún</TOKEN>
<TOKEN id="token-31-45" pos="word" morph="none" start_char="3154" end_char="3161">misterio</TOKEN>
<TOKEN id="token-31-46" pos="word" morph="none" start_char="3163" end_char="3165">que</TOKEN>
<TOKEN id="token-31-47" pos="word" morph="none" start_char="3167" end_char="3168">se</TOKEN>
<TOKEN id="token-31-48" pos="word" morph="none" start_char="3170" end_char="3175">acaben</TOKEN>
<TOKEN id="token-31-49" pos="word" morph="none" start_char="3177" end_char="3187">recuperando</TOKEN>
<TOKEN id="token-31-50" pos="punct" morph="none" start_char="3188" end_char="3188">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="3191" end_char="3330">
<ORIGINAL_TEXT>Yo podría hacer un estudio exactamente igual diciendo que el agua cura el Coronavirus, porque seguro que además de MMS también tomaron agua.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="3191" end_char="3192">Yo</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="3194" end_char="3199">podría</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="3201" end_char="3205">hacer</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="3207" end_char="3208">un</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="3210" end_char="3216">estudio</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="3218" end_char="3228">exactamente</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="3230" end_char="3234">igual</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="3236" end_char="3243">diciendo</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="3245" end_char="3247">que</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="3249" end_char="3250">el</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="3252" end_char="3255">agua</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="3257" end_char="3260">cura</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="3262" end_char="3263">el</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="3265" end_char="3275">Coronavirus</TOKEN>
<TOKEN id="token-32-14" pos="punct" morph="none" start_char="3276" end_char="3276">,</TOKEN>
<TOKEN id="token-32-15" pos="word" morph="none" start_char="3278" end_char="3283">porque</TOKEN>
<TOKEN id="token-32-16" pos="word" morph="none" start_char="3285" end_char="3290">seguro</TOKEN>
<TOKEN id="token-32-17" pos="word" morph="none" start_char="3292" end_char="3294">que</TOKEN>
<TOKEN id="token-32-18" pos="word" morph="none" start_char="3296" end_char="3301">además</TOKEN>
<TOKEN id="token-32-19" pos="word" morph="none" start_char="3303" end_char="3304">de</TOKEN>
<TOKEN id="token-32-20" pos="word" morph="none" start_char="3306" end_char="3308">MMS</TOKEN>
<TOKEN id="token-32-21" pos="word" morph="none" start_char="3310" end_char="3316">también</TOKEN>
<TOKEN id="token-32-22" pos="word" morph="none" start_char="3318" end_char="3324">tomaron</TOKEN>
<TOKEN id="token-32-23" pos="word" morph="none" start_char="3326" end_char="3329">agua</TOKEN>
<TOKEN id="token-32-24" pos="punct" morph="none" start_char="3330" end_char="3330">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="3333" end_char="3408">
<ORIGINAL_TEXT>¿En qué publicación científica seria dices que van a intentar publicar esto?</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="punct" morph="none" start_char="3333" end_char="3333">¿</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="3334" end_char="3335">En</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="3337" end_char="3339">qué</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="3341" end_char="3351">publicación</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="3353" end_char="3362">científica</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="3364" end_char="3368">seria</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="3370" end_char="3374">dices</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="3376" end_char="3378">que</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="3380" end_char="3382">van</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="3384" end_char="3384">a</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="3386" end_char="3393">intentar</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="3395" end_char="3402">publicar</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="3404" end_char="3407">esto</TOKEN>
<TOKEN id="token-33-13" pos="punct" morph="none" start_char="3408" end_char="3408">?</TOKEN>
</SEG>
<SEG id="segment-34" start_char="3412" end_char="3589">
<ORIGINAL_TEXT>Gracias @un tecnico preocupado me he mirado el informe por encima y en general los síntomas se reducen en un 82% al cuarto día si he leído bien, sin necesidad de hospitalización.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="3412" end_char="3418">Gracias</TOKEN>
<TOKEN id="token-34-1" pos="tag" morph="none" start_char="3420" end_char="3422">@un</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="3424" end_char="3430">tecnico</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="3432" end_char="3441">preocupado</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="3443" end_char="3444">me</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="3446" end_char="3447">he</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="3449" end_char="3454">mirado</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="3456" end_char="3457">el</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="3459" end_char="3465">informe</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="3467" end_char="3469">por</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="3471" end_char="3476">encima</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="3478" end_char="3478">y</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="3480" end_char="3481">en</TOKEN>
<TOKEN id="token-34-13" pos="word" morph="none" start_char="3483" end_char="3489">general</TOKEN>
<TOKEN id="token-34-14" pos="word" morph="none" start_char="3491" end_char="3493">los</TOKEN>
<TOKEN id="token-34-15" pos="word" morph="none" start_char="3495" end_char="3502">síntomas</TOKEN>
<TOKEN id="token-34-16" pos="word" morph="none" start_char="3504" end_char="3505">se</TOKEN>
<TOKEN id="token-34-17" pos="word" morph="none" start_char="3507" end_char="3513">reducen</TOKEN>
<TOKEN id="token-34-18" pos="word" morph="none" start_char="3515" end_char="3516">en</TOKEN>
<TOKEN id="token-34-19" pos="word" morph="none" start_char="3518" end_char="3519">un</TOKEN>
<TOKEN id="token-34-20" pos="word" morph="none" start_char="3521" end_char="3522">82</TOKEN>
<TOKEN id="token-34-21" pos="punct" morph="none" start_char="3523" end_char="3523">%</TOKEN>
<TOKEN id="token-34-22" pos="word" morph="none" start_char="3525" end_char="3526">al</TOKEN>
<TOKEN id="token-34-23" pos="word" morph="none" start_char="3528" end_char="3533">cuarto</TOKEN>
<TOKEN id="token-34-24" pos="word" morph="none" start_char="3535" end_char="3537">día</TOKEN>
<TOKEN id="token-34-25" pos="word" morph="none" start_char="3539" end_char="3540">si</TOKEN>
<TOKEN id="token-34-26" pos="word" morph="none" start_char="3542" end_char="3543">he</TOKEN>
<TOKEN id="token-34-27" pos="word" morph="none" start_char="3545" end_char="3549">leído</TOKEN>
<TOKEN id="token-34-28" pos="word" morph="none" start_char="3551" end_char="3554">bien</TOKEN>
<TOKEN id="token-34-29" pos="punct" morph="none" start_char="3555" end_char="3555">,</TOKEN>
<TOKEN id="token-34-30" pos="word" morph="none" start_char="3557" end_char="3559">sin</TOKEN>
<TOKEN id="token-34-31" pos="word" morph="none" start_char="3561" end_char="3569">necesidad</TOKEN>
<TOKEN id="token-34-32" pos="word" morph="none" start_char="3571" end_char="3572">de</TOKEN>
<TOKEN id="token-34-33" pos="word" morph="none" start_char="3574" end_char="3588">hospitalización</TOKEN>
<TOKEN id="token-34-34" pos="punct" morph="none" start_char="3589" end_char="3589">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="3591" end_char="3717">
<ORIGINAL_TEXT>Si no hace falta decir nada más, lo primero que muere en las guerras es la verdad, viendo lo que censuran se deduce lo que hay.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="3591" end_char="3592">Si</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="3594" end_char="3595">no</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="3597" end_char="3600">hace</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="3602" end_char="3606">falta</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="3608" end_char="3612">decir</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="3614" end_char="3617">nada</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="3619" end_char="3621">más</TOKEN>
<TOKEN id="token-35-7" pos="punct" morph="none" start_char="3622" end_char="3622">,</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="3624" end_char="3625">lo</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="3627" end_char="3633">primero</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="3635" end_char="3637">que</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="3639" end_char="3643">muere</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="3645" end_char="3646">en</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="3648" end_char="3650">las</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="3652" end_char="3658">guerras</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="3660" end_char="3661">es</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="3663" end_char="3664">la</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="3666" end_char="3671">verdad</TOKEN>
<TOKEN id="token-35-18" pos="punct" morph="none" start_char="3672" end_char="3672">,</TOKEN>
<TOKEN id="token-35-19" pos="word" morph="none" start_char="3674" end_char="3679">viendo</TOKEN>
<TOKEN id="token-35-20" pos="word" morph="none" start_char="3681" end_char="3682">lo</TOKEN>
<TOKEN id="token-35-21" pos="word" morph="none" start_char="3684" end_char="3686">que</TOKEN>
<TOKEN id="token-35-22" pos="word" morph="none" start_char="3688" end_char="3695">censuran</TOKEN>
<TOKEN id="token-35-23" pos="word" morph="none" start_char="3697" end_char="3698">se</TOKEN>
<TOKEN id="token-35-24" pos="word" morph="none" start_char="3700" end_char="3705">deduce</TOKEN>
<TOKEN id="token-35-25" pos="word" morph="none" start_char="3707" end_char="3708">lo</TOKEN>
<TOKEN id="token-35-26" pos="word" morph="none" start_char="3710" end_char="3712">que</TOKEN>
<TOKEN id="token-35-27" pos="word" morph="none" start_char="3714" end_char="3716">hay</TOKEN>
<TOKEN id="token-35-28" pos="punct" morph="none" start_char="3717" end_char="3717">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="3723" end_char="3823">
<ORIGINAL_TEXT>Bueno, al final Youtube me ha censurado el único vídeo que tenía en mi canal de Youtube sobre el MMS.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="3723" end_char="3727">Bueno</TOKEN>
<TOKEN id="token-36-1" pos="punct" morph="none" start_char="3728" end_char="3728">,</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="3730" end_char="3731">al</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="3733" end_char="3737">final</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="3739" end_char="3745">Youtube</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="3747" end_char="3748">me</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="3750" end_char="3751">ha</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="3753" end_char="3761">censurado</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="3763" end_char="3764">el</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="3766" end_char="3770">único</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="3772" end_char="3776">vídeo</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="3778" end_char="3780">que</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="3782" end_char="3786">tenía</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="3788" end_char="3789">en</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="3791" end_char="3792">mi</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="3794" end_char="3798">canal</TOKEN>
<TOKEN id="token-36-16" pos="word" morph="none" start_char="3800" end_char="3801">de</TOKEN>
<TOKEN id="token-36-17" pos="word" morph="none" start_char="3803" end_char="3809">Youtube</TOKEN>
<TOKEN id="token-36-18" pos="word" morph="none" start_char="3811" end_char="3815">sobre</TOKEN>
<TOKEN id="token-36-19" pos="word" morph="none" start_char="3817" end_char="3818">el</TOKEN>
<TOKEN id="token-36-20" pos="word" morph="none" start_char="3820" end_char="3822">MMS</TOKEN>
<TOKEN id="token-36-21" pos="punct" morph="none" start_char="3823" end_char="3823">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="3826" end_char="3900">
<ORIGINAL_TEXT>Curiosamente se trataba de un corte de 6 minutos del canal uno de Colombia.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="3826" end_char="3837">Curiosamente</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="3839" end_char="3840">se</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="3842" end_char="3848">trataba</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="3850" end_char="3851">de</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="3853" end_char="3854">un</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="3856" end_char="3860">corte</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="3862" end_char="3863">de</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="3865" end_char="3865">6</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="3867" end_char="3873">minutos</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="3875" end_char="3877">del</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="3879" end_char="3883">canal</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="3885" end_char="3887">uno</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="3889" end_char="3890">de</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="3892" end_char="3899">Colombia</TOKEN>
<TOKEN id="token-37-14" pos="punct" morph="none" start_char="3900" end_char="3900">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="3902" end_char="4000">
<ORIGINAL_TEXT>O sea, era algo oficial que aún estará en Youtube...pero mis 6 minutos sin ninguna modificación no.</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="3902" end_char="3902">O</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="3904" end_char="3906">sea</TOKEN>
<TOKEN id="token-38-2" pos="punct" morph="none" start_char="3907" end_char="3907">,</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="3909" end_char="3911">era</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="3913" end_char="3916">algo</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="3918" end_char="3924">oficial</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="3926" end_char="3928">que</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="3930" end_char="3932">aún</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="3934" end_char="3939">estará</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="3941" end_char="3942">en</TOKEN>
<TOKEN id="token-38-10" pos="unknown" morph="none" start_char="3944" end_char="3957">Youtube...pero</TOKEN>
<TOKEN id="token-38-11" pos="word" morph="none" start_char="3959" end_char="3961">mis</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="3963" end_char="3963">6</TOKEN>
<TOKEN id="token-38-13" pos="word" morph="none" start_char="3965" end_char="3971">minutos</TOKEN>
<TOKEN id="token-38-14" pos="word" morph="none" start_char="3973" end_char="3975">sin</TOKEN>
<TOKEN id="token-38-15" pos="word" morph="none" start_char="3977" end_char="3983">ninguna</TOKEN>
<TOKEN id="token-38-16" pos="word" morph="none" start_char="3985" end_char="3996">modificación</TOKEN>
<TOKEN id="token-38-17" pos="word" morph="none" start_char="3998" end_char="3999">no</TOKEN>
<TOKEN id="token-38-18" pos="punct" morph="none" start_char="4000" end_char="4000">.</TOKEN>
</SEG>
<SEG id="segment-39" start_char="4004" end_char="4063">
<ORIGINAL_TEXT>Afortunadamente hice una copia y la guarde en este servidor.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="4004" end_char="4018">Afortunadamente</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="4020" end_char="4023">hice</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="4025" end_char="4027">una</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="4029" end_char="4033">copia</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="4035" end_char="4035">y</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="4037" end_char="4038">la</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="4040" end_char="4045">guarde</TOKEN>
<TOKEN id="token-39-7" pos="word" morph="none" start_char="4047" end_char="4048">en</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="4050" end_char="4053">este</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="4055" end_char="4062">servidor</TOKEN>
<TOKEN id="token-39-10" pos="punct" morph="none" start_char="4063" end_char="4063">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="4066" end_char="4139">
<ORIGINAL_TEXT>Noticias Uno-Colombia-2-5-2020 dióxido de cloro tratamiento COVID1902.mp4</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="4066" end_char="4073">Noticias</TOKEN>
<TOKEN id="token-40-1" pos="unknown" morph="none" start_char="4075" end_char="4095">Uno-Colombia-2-5-2020</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="4097" end_char="4104">dióxido</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="4106" end_char="4107">de</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="4109" end_char="4113">cloro</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="4115" end_char="4125">tratamiento</TOKEN>
<TOKEN id="token-40-6" pos="unknown" morph="none" start_char="4127" end_char="4139">COVID1902.mp4</TOKEN>
</SEG>
<SEG id="segment-41" start_char="4142" end_char="4353">
<ORIGINAL_TEXT>En el vídeo podréis ver el patético intento de esta cadena de televisión por ridiculizar el proyecto de investigación de un posible tratamiento del COVID19 con dióxido de cloro efectuado por un médico colombiano.</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="4142" end_char="4143">En</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="4145" end_char="4146">el</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="4148" end_char="4152">vídeo</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="4154" end_char="4160">podréis</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="4162" end_char="4164">ver</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="4166" end_char="4167">el</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="4169" end_char="4176">patético</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="4178" end_char="4184">intento</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="4186" end_char="4187">de</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="4189" end_char="4192">esta</TOKEN>
<TOKEN id="token-41-10" pos="word" morph="none" start_char="4194" end_char="4199">cadena</TOKEN>
<TOKEN id="token-41-11" pos="word" morph="none" start_char="4201" end_char="4202">de</TOKEN>
<TOKEN id="token-41-12" pos="word" morph="none" start_char="4204" end_char="4213">televisión</TOKEN>
<TOKEN id="token-41-13" pos="word" morph="none" start_char="4215" end_char="4217">por</TOKEN>
<TOKEN id="token-41-14" pos="word" morph="none" start_char="4219" end_char="4229">ridiculizar</TOKEN>
<TOKEN id="token-41-15" pos="word" morph="none" start_char="4231" end_char="4232">el</TOKEN>
<TOKEN id="token-41-16" pos="word" morph="none" start_char="4234" end_char="4241">proyecto</TOKEN>
<TOKEN id="token-41-17" pos="word" morph="none" start_char="4243" end_char="4244">de</TOKEN>
<TOKEN id="token-41-18" pos="word" morph="none" start_char="4246" end_char="4258">investigación</TOKEN>
<TOKEN id="token-41-19" pos="word" morph="none" start_char="4260" end_char="4261">de</TOKEN>
<TOKEN id="token-41-20" pos="word" morph="none" start_char="4263" end_char="4264">un</TOKEN>
<TOKEN id="token-41-21" pos="word" morph="none" start_char="4266" end_char="4272">posible</TOKEN>
<TOKEN id="token-41-22" pos="word" morph="none" start_char="4274" end_char="4284">tratamiento</TOKEN>
<TOKEN id="token-41-23" pos="word" morph="none" start_char="4286" end_char="4288">del</TOKEN>
<TOKEN id="token-41-24" pos="word" morph="none" start_char="4290" end_char="4296">COVID19</TOKEN>
<TOKEN id="token-41-25" pos="word" morph="none" start_char="4298" end_char="4300">con</TOKEN>
<TOKEN id="token-41-26" pos="word" morph="none" start_char="4302" end_char="4308">dióxido</TOKEN>
<TOKEN id="token-41-27" pos="word" morph="none" start_char="4310" end_char="4311">de</TOKEN>
<TOKEN id="token-41-28" pos="word" morph="none" start_char="4313" end_char="4317">cloro</TOKEN>
<TOKEN id="token-41-29" pos="word" morph="none" start_char="4319" end_char="4327">efectuado</TOKEN>
<TOKEN id="token-41-30" pos="word" morph="none" start_char="4329" end_char="4331">por</TOKEN>
<TOKEN id="token-41-31" pos="word" morph="none" start_char="4333" end_char="4334">un</TOKEN>
<TOKEN id="token-41-32" pos="word" morph="none" start_char="4336" end_char="4341">médico</TOKEN>
<TOKEN id="token-41-33" pos="word" morph="none" start_char="4343" end_char="4352">colombiano</TOKEN>
<TOKEN id="token-41-34" pos="punct" morph="none" start_char="4353" end_char="4353">.</TOKEN>
</SEG>
<SEG id="segment-42" start_char="4356" end_char="4445">
<ORIGINAL_TEXT>Ya me diréis que tiene de malo mostrar 6 minutos de un reportaje que se ha emitido por TV.</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="4356" end_char="4357">Ya</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="4359" end_char="4360">me</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="4362" end_char="4367">diréis</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="4369" end_char="4371">que</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="4373" end_char="4377">tiene</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="4379" end_char="4380">de</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="4382" end_char="4385">malo</TOKEN>
<TOKEN id="token-42-7" pos="word" morph="none" start_char="4387" end_char="4393">mostrar</TOKEN>
<TOKEN id="token-42-8" pos="word" morph="none" start_char="4395" end_char="4395">6</TOKEN>
<TOKEN id="token-42-9" pos="word" morph="none" start_char="4397" end_char="4403">minutos</TOKEN>
<TOKEN id="token-42-10" pos="word" morph="none" start_char="4405" end_char="4406">de</TOKEN>
<TOKEN id="token-42-11" pos="word" morph="none" start_char="4408" end_char="4409">un</TOKEN>
<TOKEN id="token-42-12" pos="word" morph="none" start_char="4411" end_char="4419">reportaje</TOKEN>
<TOKEN id="token-42-13" pos="word" morph="none" start_char="4421" end_char="4423">que</TOKEN>
<TOKEN id="token-42-14" pos="word" morph="none" start_char="4425" end_char="4426">se</TOKEN>
<TOKEN id="token-42-15" pos="word" morph="none" start_char="4428" end_char="4429">ha</TOKEN>
<TOKEN id="token-42-16" pos="word" morph="none" start_char="4431" end_char="4437">emitido</TOKEN>
<TOKEN id="token-42-17" pos="word" morph="none" start_char="4439" end_char="4441">por</TOKEN>
<TOKEN id="token-42-18" pos="word" morph="none" start_char="4443" end_char="4444">TV</TOKEN>
<TOKEN id="token-42-19" pos="punct" morph="none" start_char="4445" end_char="4445">.</TOKEN>
</SEG>
<SEG id="segment-43" start_char="4448" end_char="4547">
<ORIGINAL_TEXT>Este tipo de censura es una especie de miguitas de pan que nos muestra que vamos por el buen camino.</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="4448" end_char="4451">Este</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="4453" end_char="4456">tipo</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="4458" end_char="4459">de</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="4461" end_char="4467">censura</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="4469" end_char="4470">es</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="4472" end_char="4474">una</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="4476" end_char="4482">especie</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="4484" end_char="4485">de</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="4487" end_char="4494">miguitas</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="4496" end_char="4497">de</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="4499" end_char="4501">pan</TOKEN>
<TOKEN id="token-43-11" pos="word" morph="none" start_char="4503" end_char="4505">que</TOKEN>
<TOKEN id="token-43-12" pos="word" morph="none" start_char="4507" end_char="4509">nos</TOKEN>
<TOKEN id="token-43-13" pos="word" morph="none" start_char="4511" end_char="4517">muestra</TOKEN>
<TOKEN id="token-43-14" pos="word" morph="none" start_char="4519" end_char="4521">que</TOKEN>
<TOKEN id="token-43-15" pos="word" morph="none" start_char="4523" end_char="4527">vamos</TOKEN>
<TOKEN id="token-43-16" pos="word" morph="none" start_char="4529" end_char="4531">por</TOKEN>
<TOKEN id="token-43-17" pos="word" morph="none" start_char="4533" end_char="4534">el</TOKEN>
<TOKEN id="token-43-18" pos="word" morph="none" start_char="4536" end_char="4539">buen</TOKEN>
<TOKEN id="token-43-19" pos="word" morph="none" start_char="4541" end_char="4546">camino</TOKEN>
<TOKEN id="token-43-20" pos="punct" morph="none" start_char="4547" end_char="4547">.</TOKEN>
</SEG>
<SEG id="segment-44" start_char="4551" end_char="4658">
<ORIGINAL_TEXT>un tecnico preocupado dijo: Estamos hablando de un estudio médico de 84 páginas...autentificado por notario.</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="4551" end_char="4552">un</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="4554" end_char="4560">tecnico</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="4562" end_char="4571">preocupado</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="4573" end_char="4576">dijo</TOKEN>
<TOKEN id="token-44-4" pos="punct" morph="none" start_char="4577" end_char="4577">:</TOKEN>
<TOKEN id="token-44-5" pos="word" morph="none" start_char="4579" end_char="4585">Estamos</TOKEN>
<TOKEN id="token-44-6" pos="word" morph="none" start_char="4587" end_char="4594">hablando</TOKEN>
<TOKEN id="token-44-7" pos="word" morph="none" start_char="4596" end_char="4597">de</TOKEN>
<TOKEN id="token-44-8" pos="word" morph="none" start_char="4599" end_char="4600">un</TOKEN>
<TOKEN id="token-44-9" pos="word" morph="none" start_char="4602" end_char="4608">estudio</TOKEN>
<TOKEN id="token-44-10" pos="word" morph="none" start_char="4610" end_char="4615">médico</TOKEN>
<TOKEN id="token-44-11" pos="word" morph="none" start_char="4617" end_char="4618">de</TOKEN>
<TOKEN id="token-44-12" pos="word" morph="none" start_char="4620" end_char="4621">84</TOKEN>
<TOKEN id="token-44-13" pos="unknown" morph="none" start_char="4623" end_char="4645">páginas...autentificado</TOKEN>
<TOKEN id="token-44-14" pos="word" morph="none" start_char="4647" end_char="4649">por</TOKEN>
<TOKEN id="token-44-15" pos="word" morph="none" start_char="4651" end_char="4657">notario</TOKEN>
<TOKEN id="token-44-16" pos="punct" morph="none" start_char="4658" end_char="4658">.</TOKEN>
</SEG>
<SEG id="segment-45" start_char="4660" end_char="4904">
<ORIGINAL_TEXT>Con los DNIs del médico investigador principal y los datos de los otros 6, con los consentimientos informados de los pacientes sometidos al estudio, con datos histiológicos, con analiticas, con la aportación de los positivos por prueba PCR, etc.</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="4660" end_char="4662">Con</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="4664" end_char="4666">los</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="4668" end_char="4671">DNIs</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="4673" end_char="4675">del</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="4677" end_char="4682">médico</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="4684" end_char="4695">investigador</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="4697" end_char="4705">principal</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="4707" end_char="4707">y</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="4709" end_char="4711">los</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="4713" end_char="4717">datos</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="4719" end_char="4720">de</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="4722" end_char="4724">los</TOKEN>
<TOKEN id="token-45-12" pos="word" morph="none" start_char="4726" end_char="4730">otros</TOKEN>
<TOKEN id="token-45-13" pos="word" morph="none" start_char="4732" end_char="4732">6</TOKEN>
<TOKEN id="token-45-14" pos="punct" morph="none" start_char="4733" end_char="4733">,</TOKEN>
<TOKEN id="token-45-15" pos="word" morph="none" start_char="4735" end_char="4737">con</TOKEN>
<TOKEN id="token-45-16" pos="word" morph="none" start_char="4739" end_char="4741">los</TOKEN>
<TOKEN id="token-45-17" pos="word" morph="none" start_char="4743" end_char="4757">consentimientos</TOKEN>
<TOKEN id="token-45-18" pos="word" morph="none" start_char="4759" end_char="4768">informados</TOKEN>
<TOKEN id="token-45-19" pos="word" morph="none" start_char="4770" end_char="4771">de</TOKEN>
<TOKEN id="token-45-20" pos="word" morph="none" start_char="4773" end_char="4775">los</TOKEN>
<TOKEN id="token-45-21" pos="word" morph="none" start_char="4777" end_char="4785">pacientes</TOKEN>
<TOKEN id="token-45-22" pos="word" morph="none" start_char="4787" end_char="4795">sometidos</TOKEN>
<TOKEN id="token-45-23" pos="word" morph="none" start_char="4797" end_char="4798">al</TOKEN>
<TOKEN id="token-45-24" pos="word" morph="none" start_char="4800" end_char="4806">estudio</TOKEN>
<TOKEN id="token-45-25" pos="punct" morph="none" start_char="4807" end_char="4807">,</TOKEN>
<TOKEN id="token-45-26" pos="word" morph="none" start_char="4809" end_char="4811">con</TOKEN>
<TOKEN id="token-45-27" pos="word" morph="none" start_char="4813" end_char="4817">datos</TOKEN>
<TOKEN id="token-45-28" pos="word" morph="none" start_char="4819" end_char="4831">histiológicos</TOKEN>
<TOKEN id="token-45-29" pos="punct" morph="none" start_char="4832" end_char="4832">,</TOKEN>
<TOKEN id="token-45-30" pos="word" morph="none" start_char="4834" end_char="4836">con</TOKEN>
<TOKEN id="token-45-31" pos="word" morph="none" start_char="4838" end_char="4847">analiticas</TOKEN>
<TOKEN id="token-45-32" pos="punct" morph="none" start_char="4848" end_char="4848">,</TOKEN>
<TOKEN id="token-45-33" pos="word" morph="none" start_char="4850" end_char="4852">con</TOKEN>
<TOKEN id="token-45-34" pos="word" morph="none" start_char="4854" end_char="4855">la</TOKEN>
<TOKEN id="token-45-35" pos="word" morph="none" start_char="4857" end_char="4866">aportación</TOKEN>
<TOKEN id="token-45-36" pos="word" morph="none" start_char="4868" end_char="4869">de</TOKEN>
<TOKEN id="token-45-37" pos="word" morph="none" start_char="4871" end_char="4873">los</TOKEN>
<TOKEN id="token-45-38" pos="word" morph="none" start_char="4875" end_char="4883">positivos</TOKEN>
<TOKEN id="token-45-39" pos="word" morph="none" start_char="4885" end_char="4887">por</TOKEN>
<TOKEN id="token-45-40" pos="word" morph="none" start_char="4889" end_char="4894">prueba</TOKEN>
<TOKEN id="token-45-41" pos="word" morph="none" start_char="4896" end_char="4898">PCR</TOKEN>
<TOKEN id="token-45-42" pos="punct" morph="none" start_char="4899" end_char="4899">,</TOKEN>
<TOKEN id="token-45-43" pos="word" morph="none" start_char="4901" end_char="4903">etc</TOKEN>
<TOKEN id="token-45-44" pos="punct" morph="none" start_char="4904" end_char="4904">.</TOKEN>
</SEG>
<SEG id="segment-46" start_char="4908" end_char="5265">
<ORIGINAL_TEXT>No hace falta saber mucho sobre medicina o estudios científicos para darse cuenta de que un estudio en el que coges a un grupo de personas en una franja de edad en la que la gran mayoría de la gente supera el virus, les das cualquier cosa que no les mate, y luego te asombras de que la mayoría efectivamente se curen, es un estudio que vale para muy poquito.</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="4908" end_char="4909">No</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="4911" end_char="4914">hace</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="4916" end_char="4920">falta</TOKEN>
<TOKEN id="token-46-3" pos="word" morph="none" start_char="4922" end_char="4926">saber</TOKEN>
<TOKEN id="token-46-4" pos="word" morph="none" start_char="4928" end_char="4932">mucho</TOKEN>
<TOKEN id="token-46-5" pos="word" morph="none" start_char="4934" end_char="4938">sobre</TOKEN>
<TOKEN id="token-46-6" pos="word" morph="none" start_char="4940" end_char="4947">medicina</TOKEN>
<TOKEN id="token-46-7" pos="word" morph="none" start_char="4949" end_char="4949">o</TOKEN>
<TOKEN id="token-46-8" pos="word" morph="none" start_char="4951" end_char="4958">estudios</TOKEN>
<TOKEN id="token-46-9" pos="word" morph="none" start_char="4960" end_char="4970">científicos</TOKEN>
<TOKEN id="token-46-10" pos="word" morph="none" start_char="4972" end_char="4975">para</TOKEN>
<TOKEN id="token-46-11" pos="word" morph="none" start_char="4977" end_char="4981">darse</TOKEN>
<TOKEN id="token-46-12" pos="word" morph="none" start_char="4983" end_char="4988">cuenta</TOKEN>
<TOKEN id="token-46-13" pos="word" morph="none" start_char="4990" end_char="4991">de</TOKEN>
<TOKEN id="token-46-14" pos="word" morph="none" start_char="4993" end_char="4995">que</TOKEN>
<TOKEN id="token-46-15" pos="word" morph="none" start_char="4997" end_char="4998">un</TOKEN>
<TOKEN id="token-46-16" pos="word" morph="none" start_char="5000" end_char="5006">estudio</TOKEN>
<TOKEN id="token-46-17" pos="word" morph="none" start_char="5008" end_char="5009">en</TOKEN>
<TOKEN id="token-46-18" pos="word" morph="none" start_char="5011" end_char="5012">el</TOKEN>
<TOKEN id="token-46-19" pos="word" morph="none" start_char="5014" end_char="5016">que</TOKEN>
<TOKEN id="token-46-20" pos="word" morph="none" start_char="5018" end_char="5022">coges</TOKEN>
<TOKEN id="token-46-21" pos="word" morph="none" start_char="5024" end_char="5024">a</TOKEN>
<TOKEN id="token-46-22" pos="word" morph="none" start_char="5026" end_char="5027">un</TOKEN>
<TOKEN id="token-46-23" pos="word" morph="none" start_char="5029" end_char="5033">grupo</TOKEN>
<TOKEN id="token-46-24" pos="word" morph="none" start_char="5035" end_char="5036">de</TOKEN>
<TOKEN id="token-46-25" pos="word" morph="none" start_char="5038" end_char="5045">personas</TOKEN>
<TOKEN id="token-46-26" pos="word" morph="none" start_char="5047" end_char="5048">en</TOKEN>
<TOKEN id="token-46-27" pos="word" morph="none" start_char="5050" end_char="5052">una</TOKEN>
<TOKEN id="token-46-28" pos="word" morph="none" start_char="5054" end_char="5059">franja</TOKEN>
<TOKEN id="token-46-29" pos="word" morph="none" start_char="5061" end_char="5062">de</TOKEN>
<TOKEN id="token-46-30" pos="word" morph="none" start_char="5064" end_char="5067">edad</TOKEN>
<TOKEN id="token-46-31" pos="word" morph="none" start_char="5069" end_char="5070">en</TOKEN>
<TOKEN id="token-46-32" pos="word" morph="none" start_char="5072" end_char="5073">la</TOKEN>
<TOKEN id="token-46-33" pos="word" morph="none" start_char="5075" end_char="5077">que</TOKEN>
<TOKEN id="token-46-34" pos="word" morph="none" start_char="5079" end_char="5080">la</TOKEN>
<TOKEN id="token-46-35" pos="word" morph="none" start_char="5082" end_char="5085">gran</TOKEN>
<TOKEN id="token-46-36" pos="word" morph="none" start_char="5087" end_char="5093">mayoría</TOKEN>
<TOKEN id="token-46-37" pos="word" morph="none" start_char="5095" end_char="5096">de</TOKEN>
<TOKEN id="token-46-38" pos="word" morph="none" start_char="5098" end_char="5099">la</TOKEN>
<TOKEN id="token-46-39" pos="word" morph="none" start_char="5101" end_char="5105">gente</TOKEN>
<TOKEN id="token-46-40" pos="word" morph="none" start_char="5107" end_char="5112">supera</TOKEN>
<TOKEN id="token-46-41" pos="word" morph="none" start_char="5114" end_char="5115">el</TOKEN>
<TOKEN id="token-46-42" pos="word" morph="none" start_char="5117" end_char="5121">virus</TOKEN>
<TOKEN id="token-46-43" pos="punct" morph="none" start_char="5122" end_char="5122">,</TOKEN>
<TOKEN id="token-46-44" pos="word" morph="none" start_char="5124" end_char="5126">les</TOKEN>
<TOKEN id="token-46-45" pos="word" morph="none" start_char="5128" end_char="5130">das</TOKEN>
<TOKEN id="token-46-46" pos="word" morph="none" start_char="5132" end_char="5140">cualquier</TOKEN>
<TOKEN id="token-46-47" pos="word" morph="none" start_char="5142" end_char="5145">cosa</TOKEN>
<TOKEN id="token-46-48" pos="word" morph="none" start_char="5147" end_char="5149">que</TOKEN>
<TOKEN id="token-46-49" pos="word" morph="none" start_char="5151" end_char="5152">no</TOKEN>
<TOKEN id="token-46-50" pos="word" morph="none" start_char="5154" end_char="5156">les</TOKEN>
<TOKEN id="token-46-51" pos="word" morph="none" start_char="5158" end_char="5161">mate</TOKEN>
<TOKEN id="token-46-52" pos="punct" morph="none" start_char="5162" end_char="5162">,</TOKEN>
<TOKEN id="token-46-53" pos="word" morph="none" start_char="5164" end_char="5164">y</TOKEN>
<TOKEN id="token-46-54" pos="word" morph="none" start_char="5166" end_char="5170">luego</TOKEN>
<TOKEN id="token-46-55" pos="word" morph="none" start_char="5172" end_char="5173">te</TOKEN>
<TOKEN id="token-46-56" pos="word" morph="none" start_char="5175" end_char="5182">asombras</TOKEN>
<TOKEN id="token-46-57" pos="word" morph="none" start_char="5184" end_char="5185">de</TOKEN>
<TOKEN id="token-46-58" pos="word" morph="none" start_char="5187" end_char="5189">que</TOKEN>
<TOKEN id="token-46-59" pos="word" morph="none" start_char="5191" end_char="5192">la</TOKEN>
<TOKEN id="token-46-60" pos="word" morph="none" start_char="5194" end_char="5200">mayoría</TOKEN>
<TOKEN id="token-46-61" pos="word" morph="none" start_char="5202" end_char="5214">efectivamente</TOKEN>
<TOKEN id="token-46-62" pos="word" morph="none" start_char="5216" end_char="5217">se</TOKEN>
<TOKEN id="token-46-63" pos="word" morph="none" start_char="5219" end_char="5223">curen</TOKEN>
<TOKEN id="token-46-64" pos="punct" morph="none" start_char="5224" end_char="5224">,</TOKEN>
<TOKEN id="token-46-65" pos="word" morph="none" start_char="5226" end_char="5227">es</TOKEN>
<TOKEN id="token-46-66" pos="word" morph="none" start_char="5229" end_char="5230">un</TOKEN>
<TOKEN id="token-46-67" pos="word" morph="none" start_char="5232" end_char="5238">estudio</TOKEN>
<TOKEN id="token-46-68" pos="word" morph="none" start_char="5240" end_char="5242">que</TOKEN>
<TOKEN id="token-46-69" pos="word" morph="none" start_char="5244" end_char="5247">vale</TOKEN>
<TOKEN id="token-46-70" pos="word" morph="none" start_char="5249" end_char="5252">para</TOKEN>
<TOKEN id="token-46-71" pos="word" morph="none" start_char="5254" end_char="5256">muy</TOKEN>
<TOKEN id="token-46-72" pos="word" morph="none" start_char="5258" end_char="5264">poquito</TOKEN>
<TOKEN id="token-46-73" pos="punct" morph="none" start_char="5265" end_char="5265">.</TOKEN>
</SEG>
<SEG id="segment-47" start_char="5268" end_char="5297">
<ORIGINAL_TEXT>¿Cuál era el grupo de control?</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="punct" morph="none" start_char="5268" end_char="5268">¿</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="5269" end_char="5272">Cuál</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="5274" end_char="5276">era</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="5278" end_char="5279">el</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="5281" end_char="5285">grupo</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="5287" end_char="5288">de</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="5290" end_char="5296">control</TOKEN>
<TOKEN id="token-47-7" pos="punct" morph="none" start_char="5297" end_char="5297">?</TOKEN>
</SEG>
<SEG id="segment-48" start_char="5300" end_char="5419">
<ORIGINAL_TEXT>Y por cierto, la bondad de un estudios científico no la valida un notario Has escuchado hablar de la revisión por pares?</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="5300" end_char="5300">Y</TOKEN>
<TOKEN id="token-48-1" pos="word" morph="none" start_char="5302" end_char="5304">por</TOKEN>
<TOKEN id="token-48-2" pos="word" morph="none" start_char="5306" end_char="5311">cierto</TOKEN>
<TOKEN id="token-48-3" pos="punct" morph="none" start_char="5312" end_char="5312">,</TOKEN>
<TOKEN id="token-48-4" pos="word" morph="none" start_char="5314" end_char="5315">la</TOKEN>
<TOKEN id="token-48-5" pos="word" morph="none" start_char="5317" end_char="5322">bondad</TOKEN>
<TOKEN id="token-48-6" pos="word" morph="none" start_char="5324" end_char="5325">de</TOKEN>
<TOKEN id="token-48-7" pos="word" morph="none" start_char="5327" end_char="5328">un</TOKEN>
<TOKEN id="token-48-8" pos="word" morph="none" start_char="5330" end_char="5337">estudios</TOKEN>
<TOKEN id="token-48-9" pos="word" morph="none" start_char="5339" end_char="5348">científico</TOKEN>
<TOKEN id="token-48-10" pos="word" morph="none" start_char="5350" end_char="5351">no</TOKEN>
<TOKEN id="token-48-11" pos="word" morph="none" start_char="5353" end_char="5354">la</TOKEN>
<TOKEN id="token-48-12" pos="word" morph="none" start_char="5356" end_char="5361">valida</TOKEN>
<TOKEN id="token-48-13" pos="word" morph="none" start_char="5363" end_char="5364">un</TOKEN>
<TOKEN id="token-48-14" pos="word" morph="none" start_char="5366" end_char="5372">notario</TOKEN>
<TOKEN id="token-48-15" pos="word" morph="none" start_char="5374" end_char="5376">Has</TOKEN>
<TOKEN id="token-48-16" pos="word" morph="none" start_char="5378" end_char="5386">escuchado</TOKEN>
<TOKEN id="token-48-17" pos="word" morph="none" start_char="5388" end_char="5393">hablar</TOKEN>
<TOKEN id="token-48-18" pos="word" morph="none" start_char="5395" end_char="5396">de</TOKEN>
<TOKEN id="token-48-19" pos="word" morph="none" start_char="5398" end_char="5399">la</TOKEN>
<TOKEN id="token-48-20" pos="word" morph="none" start_char="5401" end_char="5408">revisión</TOKEN>
<TOKEN id="token-48-21" pos="word" morph="none" start_char="5410" end_char="5412">por</TOKEN>
<TOKEN id="token-48-22" pos="word" morph="none" start_char="5414" end_char="5418">pares</TOKEN>
<TOKEN id="token-48-23" pos="punct" morph="none" start_char="5419" end_char="5419">?</TOKEN>
</SEG>
<SEG id="segment-49" start_char="5424" end_char="5552">
<ORIGINAL_TEXT>un tecnico preocupado dijo: Supongo que automáticamente este post será reducido a la nada o enviado al subforo de conspiraciones.</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="5424" end_char="5425">un</TOKEN>
<TOKEN id="token-49-1" pos="word" morph="none" start_char="5427" end_char="5433">tecnico</TOKEN>
<TOKEN id="token-49-2" pos="word" morph="none" start_char="5435" end_char="5444">preocupado</TOKEN>
<TOKEN id="token-49-3" pos="word" morph="none" start_char="5446" end_char="5449">dijo</TOKEN>
<TOKEN id="token-49-4" pos="punct" morph="none" start_char="5450" end_char="5450">:</TOKEN>
<TOKEN id="token-49-5" pos="word" morph="none" start_char="5452" end_char="5458">Supongo</TOKEN>
<TOKEN id="token-49-6" pos="word" morph="none" start_char="5460" end_char="5462">que</TOKEN>
<TOKEN id="token-49-7" pos="word" morph="none" start_char="5464" end_char="5478">automáticamente</TOKEN>
<TOKEN id="token-49-8" pos="word" morph="none" start_char="5480" end_char="5483">este</TOKEN>
<TOKEN id="token-49-9" pos="word" morph="none" start_char="5485" end_char="5488">post</TOKEN>
<TOKEN id="token-49-10" pos="word" morph="none" start_char="5490" end_char="5493">será</TOKEN>
<TOKEN id="token-49-11" pos="word" morph="none" start_char="5495" end_char="5502">reducido</TOKEN>
<TOKEN id="token-49-12" pos="word" morph="none" start_char="5504" end_char="5504">a</TOKEN>
<TOKEN id="token-49-13" pos="word" morph="none" start_char="5506" end_char="5507">la</TOKEN>
<TOKEN id="token-49-14" pos="word" morph="none" start_char="5509" end_char="5512">nada</TOKEN>
<TOKEN id="token-49-15" pos="word" morph="none" start_char="5514" end_char="5514">o</TOKEN>
<TOKEN id="token-49-16" pos="word" morph="none" start_char="5516" end_char="5522">enviado</TOKEN>
<TOKEN id="token-49-17" pos="word" morph="none" start_char="5524" end_char="5525">al</TOKEN>
<TOKEN id="token-49-18" pos="word" morph="none" start_char="5527" end_char="5533">subforo</TOKEN>
<TOKEN id="token-49-19" pos="word" morph="none" start_char="5535" end_char="5536">de</TOKEN>
<TOKEN id="token-49-20" pos="word" morph="none" start_char="5538" end_char="5551">conspiraciones</TOKEN>
<TOKEN id="token-49-21" pos="punct" morph="none" start_char="5552" end_char="5552">.</TOKEN>
</SEG>
<SEG id="segment-50" start_char="5554" end_char="5607">
<ORIGINAL_TEXT>Pero lo que aqui les mostrare no es magia, es ciencia.</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="5554" end_char="5557">Pero</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="5559" end_char="5560">lo</TOKEN>
<TOKEN id="token-50-2" pos="word" morph="none" start_char="5562" end_char="5564">que</TOKEN>
<TOKEN id="token-50-3" pos="word" morph="none" start_char="5566" end_char="5569">aqui</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="5571" end_char="5573">les</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="5575" end_char="5582">mostrare</TOKEN>
<TOKEN id="token-50-6" pos="word" morph="none" start_char="5584" end_char="5585">no</TOKEN>
<TOKEN id="token-50-7" pos="word" morph="none" start_char="5587" end_char="5588">es</TOKEN>
<TOKEN id="token-50-8" pos="word" morph="none" start_char="5590" end_char="5594">magia</TOKEN>
<TOKEN id="token-50-9" pos="punct" morph="none" start_char="5595" end_char="5595">,</TOKEN>
<TOKEN id="token-50-10" pos="word" morph="none" start_char="5597" end_char="5598">es</TOKEN>
<TOKEN id="token-50-11" pos="word" morph="none" start_char="5600" end_char="5606">ciencia</TOKEN>
<TOKEN id="token-50-12" pos="punct" morph="none" start_char="5607" end_char="5607">.</TOKEN>
</SEG>
<SEG id="segment-51" start_char="5609" end_char="5750">
<ORIGINAL_TEXT>Se trata del primer estudio bien documentado de tratamiento del virus SarsCoV2 mediante el uso de dióxido de cloro vía oral y vía intravenosa.</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="word" morph="none" start_char="5609" end_char="5610">Se</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="5612" end_char="5616">trata</TOKEN>
<TOKEN id="token-51-2" pos="word" morph="none" start_char="5618" end_char="5620">del</TOKEN>
<TOKEN id="token-51-3" pos="word" morph="none" start_char="5622" end_char="5627">primer</TOKEN>
<TOKEN id="token-51-4" pos="word" morph="none" start_char="5629" end_char="5635">estudio</TOKEN>
<TOKEN id="token-51-5" pos="word" morph="none" start_char="5637" end_char="5640">bien</TOKEN>
<TOKEN id="token-51-6" pos="word" morph="none" start_char="5642" end_char="5652">documentado</TOKEN>
<TOKEN id="token-51-7" pos="word" morph="none" start_char="5654" end_char="5655">de</TOKEN>
<TOKEN id="token-51-8" pos="word" morph="none" start_char="5657" end_char="5667">tratamiento</TOKEN>
<TOKEN id="token-51-9" pos="word" morph="none" start_char="5669" end_char="5671">del</TOKEN>
<TOKEN id="token-51-10" pos="word" morph="none" start_char="5673" end_char="5677">virus</TOKEN>
<TOKEN id="token-51-11" pos="word" morph="none" start_char="5679" end_char="5686">SarsCoV2</TOKEN>
<TOKEN id="token-51-12" pos="word" morph="none" start_char="5688" end_char="5695">mediante</TOKEN>
<TOKEN id="token-51-13" pos="word" morph="none" start_char="5697" end_char="5698">el</TOKEN>
<TOKEN id="token-51-14" pos="word" morph="none" start_char="5700" end_char="5702">uso</TOKEN>
<TOKEN id="token-51-15" pos="word" morph="none" start_char="5704" end_char="5705">de</TOKEN>
<TOKEN id="token-51-16" pos="word" morph="none" start_char="5707" end_char="5713">dióxido</TOKEN>
<TOKEN id="token-51-17" pos="word" morph="none" start_char="5715" end_char="5716">de</TOKEN>
<TOKEN id="token-51-18" pos="word" morph="none" start_char="5718" end_char="5722">cloro</TOKEN>
<TOKEN id="token-51-19" pos="word" morph="none" start_char="5724" end_char="5726">vía</TOKEN>
<TOKEN id="token-51-20" pos="word" morph="none" start_char="5728" end_char="5731">oral</TOKEN>
<TOKEN id="token-51-21" pos="word" morph="none" start_char="5733" end_char="5733">y</TOKEN>
<TOKEN id="token-51-22" pos="word" morph="none" start_char="5735" end_char="5737">vía</TOKEN>
<TOKEN id="token-51-23" pos="word" morph="none" start_char="5739" end_char="5749">intravenosa</TOKEN>
<TOKEN id="token-51-24" pos="punct" morph="none" start_char="5750" end_char="5750">.</TOKEN>
</SEG>
<SEG id="segment-52" start_char="5752" end_char="5851">
<ORIGINAL_TEXT>Estudio del CDS (versión mejorada del MMS, dióxido de cloro) en 104 humanos infectados por COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="5752" end_char="5758">Estudio</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="5760" end_char="5762">del</TOKEN>
<TOKEN id="token-52-2" pos="word" morph="none" start_char="5764" end_char="5766">CDS</TOKEN>
<TOKEN id="token-52-3" pos="punct" morph="none" start_char="5768" end_char="5768">(</TOKEN>
<TOKEN id="token-52-4" pos="word" morph="none" start_char="5769" end_char="5775">versión</TOKEN>
<TOKEN id="token-52-5" pos="word" morph="none" start_char="5777" end_char="5784">mejorada</TOKEN>
<TOKEN id="token-52-6" pos="word" morph="none" start_char="5786" end_char="5788">del</TOKEN>
<TOKEN id="token-52-7" pos="word" morph="none" start_char="5790" end_char="5792">MMS</TOKEN>
<TOKEN id="token-52-8" pos="punct" morph="none" start_char="5793" end_char="5793">,</TOKEN>
<TOKEN id="token-52-9" pos="word" morph="none" start_char="5795" end_char="5801">dióxido</TOKEN>
<TOKEN id="token-52-10" pos="word" morph="none" start_char="5803" end_char="5804">de</TOKEN>
<TOKEN id="token-52-11" pos="word" morph="none" start_char="5806" end_char="5810">cloro</TOKEN>
<TOKEN id="token-52-12" pos="punct" morph="none" start_char="5811" end_char="5811">)</TOKEN>
<TOKEN id="token-52-13" pos="word" morph="none" start_char="5813" end_char="5814">en</TOKEN>
<TOKEN id="token-52-14" pos="word" morph="none" start_char="5816" end_char="5818">104</TOKEN>
<TOKEN id="token-52-15" pos="word" morph="none" start_char="5820" end_char="5826">humanos</TOKEN>
<TOKEN id="token-52-16" pos="word" morph="none" start_char="5828" end_char="5837">infectados</TOKEN>
<TOKEN id="token-52-17" pos="word" morph="none" start_char="5839" end_char="5841">por</TOKEN>
<TOKEN id="token-52-18" pos="unknown" morph="none" start_char="5843" end_char="5850">COVID-19</TOKEN>
<TOKEN id="token-52-19" pos="punct" morph="none" start_char="5851" end_char="5851">.</TOKEN>
</SEG>
<SEG id="segment-53" start_char="5853" end_char="6176">
<ORIGINAL_TEXT>Aquí tenéis el documento oficial de ensayo clínico preliminar en Ecuador de CDS Oral e intravenoso de la asociación médica de AEMEMI con acta notarial firmada y datos fidedignos que demuestran la eficacia del Dióxido de cloro tanto Oral como Parenteral como sustancia eficaz contra el coronavirus con una eficacia de un 97%.</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="word" morph="none" start_char="5853" end_char="5856">Aquí</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="5858" end_char="5863">tenéis</TOKEN>
<TOKEN id="token-53-2" pos="word" morph="none" start_char="5865" end_char="5866">el</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="5868" end_char="5876">documento</TOKEN>
<TOKEN id="token-53-4" pos="word" morph="none" start_char="5878" end_char="5884">oficial</TOKEN>
<TOKEN id="token-53-5" pos="word" morph="none" start_char="5886" end_char="5887">de</TOKEN>
<TOKEN id="token-53-6" pos="word" morph="none" start_char="5889" end_char="5894">ensayo</TOKEN>
<TOKEN id="token-53-7" pos="word" morph="none" start_char="5896" end_char="5902">clínico</TOKEN>
<TOKEN id="token-53-8" pos="word" morph="none" start_char="5904" end_char="5913">preliminar</TOKEN>
<TOKEN id="token-53-9" pos="word" morph="none" start_char="5915" end_char="5916">en</TOKEN>
<TOKEN id="token-53-10" pos="word" morph="none" start_char="5918" end_char="5924">Ecuador</TOKEN>
<TOKEN id="token-53-11" pos="word" morph="none" start_char="5926" end_char="5927">de</TOKEN>
<TOKEN id="token-53-12" pos="word" morph="none" start_char="5929" end_char="5931">CDS</TOKEN>
<TOKEN id="token-53-13" pos="word" morph="none" start_char="5933" end_char="5936">Oral</TOKEN>
<TOKEN id="token-53-14" pos="word" morph="none" start_char="5938" end_char="5938">e</TOKEN>
<TOKEN id="token-53-15" pos="word" morph="none" start_char="5940" end_char="5950">intravenoso</TOKEN>
<TOKEN id="token-53-16" pos="word" morph="none" start_char="5952" end_char="5953">de</TOKEN>
<TOKEN id="token-53-17" pos="word" morph="none" start_char="5955" end_char="5956">la</TOKEN>
<TOKEN id="token-53-18" pos="word" morph="none" start_char="5958" end_char="5967">asociación</TOKEN>
<TOKEN id="token-53-19" pos="word" morph="none" start_char="5969" end_char="5974">médica</TOKEN>
<TOKEN id="token-53-20" pos="word" morph="none" start_char="5976" end_char="5977">de</TOKEN>
<TOKEN id="token-53-21" pos="word" morph="none" start_char="5979" end_char="5984">AEMEMI</TOKEN>
<TOKEN id="token-53-22" pos="word" morph="none" start_char="5986" end_char="5988">con</TOKEN>
<TOKEN id="token-53-23" pos="word" morph="none" start_char="5990" end_char="5993">acta</TOKEN>
<TOKEN id="token-53-24" pos="word" morph="none" start_char="5995" end_char="6002">notarial</TOKEN>
<TOKEN id="token-53-25" pos="word" morph="none" start_char="6004" end_char="6010">firmada</TOKEN>
<TOKEN id="token-53-26" pos="word" morph="none" start_char="6012" end_char="6012">y</TOKEN>
<TOKEN id="token-53-27" pos="word" morph="none" start_char="6014" end_char="6018">datos</TOKEN>
<TOKEN id="token-53-28" pos="word" morph="none" start_char="6020" end_char="6029">fidedignos</TOKEN>
<TOKEN id="token-53-29" pos="word" morph="none" start_char="6031" end_char="6033">que</TOKEN>
<TOKEN id="token-53-30" pos="word" morph="none" start_char="6035" end_char="6044">demuestran</TOKEN>
<TOKEN id="token-53-31" pos="word" morph="none" start_char="6046" end_char="6047">la</TOKEN>
<TOKEN id="token-53-32" pos="word" morph="none" start_char="6049" end_char="6056">eficacia</TOKEN>
<TOKEN id="token-53-33" pos="word" morph="none" start_char="6058" end_char="6060">del</TOKEN>
<TOKEN id="token-53-34" pos="word" morph="none" start_char="6062" end_char="6068">Dióxido</TOKEN>
<TOKEN id="token-53-35" pos="word" morph="none" start_char="6070" end_char="6071">de</TOKEN>
<TOKEN id="token-53-36" pos="word" morph="none" start_char="6073" end_char="6077">cloro</TOKEN>
<TOKEN id="token-53-37" pos="word" morph="none" start_char="6079" end_char="6083">tanto</TOKEN>
<TOKEN id="token-53-38" pos="word" morph="none" start_char="6085" end_char="6088">Oral</TOKEN>
<TOKEN id="token-53-39" pos="word" morph="none" start_char="6090" end_char="6093">como</TOKEN>
<TOKEN id="token-53-40" pos="word" morph="none" start_char="6095" end_char="6104">Parenteral</TOKEN>
<TOKEN id="token-53-41" pos="word" morph="none" start_char="6106" end_char="6109">como</TOKEN>
<TOKEN id="token-53-42" pos="word" morph="none" start_char="6111" end_char="6119">sustancia</TOKEN>
<TOKEN id="token-53-43" pos="word" morph="none" start_char="6121" end_char="6126">eficaz</TOKEN>
<TOKEN id="token-53-44" pos="word" morph="none" start_char="6128" end_char="6133">contra</TOKEN>
<TOKEN id="token-53-45" pos="word" morph="none" start_char="6135" end_char="6136">el</TOKEN>
<TOKEN id="token-53-46" pos="word" morph="none" start_char="6138" end_char="6148">coronavirus</TOKEN>
<TOKEN id="token-53-47" pos="word" morph="none" start_char="6150" end_char="6152">con</TOKEN>
<TOKEN id="token-53-48" pos="word" morph="none" start_char="6154" end_char="6156">una</TOKEN>
<TOKEN id="token-53-49" pos="word" morph="none" start_char="6158" end_char="6165">eficacia</TOKEN>
<TOKEN id="token-53-50" pos="word" morph="none" start_char="6167" end_char="6168">de</TOKEN>
<TOKEN id="token-53-51" pos="word" morph="none" start_char="6170" end_char="6171">un</TOKEN>
<TOKEN id="token-53-52" pos="word" morph="none" start_char="6173" end_char="6174">97</TOKEN>
<TOKEN id="token-53-53" pos="punct" morph="none" start_char="6175" end_char="6176">%.</TOKEN>
</SEG>
<SEG id="segment-54" start_char="6178" end_char="6331">
<ORIGINAL_TEXT>¿Cuánto tardarán los medios convencionales en hablar de esta solución barata, inocua y no patentable a la supuesta pandemia actual, entre otras dolencias?</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="punct" morph="none" start_char="6178" end_char="6178">¿</TOKEN>
<TOKEN id="token-54-1" pos="word" morph="none" start_char="6179" end_char="6184">Cuánto</TOKEN>
<TOKEN id="token-54-2" pos="word" morph="none" start_char="6186" end_char="6193">tardarán</TOKEN>
<TOKEN id="token-54-3" pos="word" morph="none" start_char="6195" end_char="6197">los</TOKEN>
<TOKEN id="token-54-4" pos="word" morph="none" start_char="6199" end_char="6204">medios</TOKEN>
<TOKEN id="token-54-5" pos="word" morph="none" start_char="6206" end_char="6219">convencionales</TOKEN>
<TOKEN id="token-54-6" pos="word" morph="none" start_char="6221" end_char="6222">en</TOKEN>
<TOKEN id="token-54-7" pos="word" morph="none" start_char="6224" end_char="6229">hablar</TOKEN>
<TOKEN id="token-54-8" pos="word" morph="none" start_char="6231" end_char="6232">de</TOKEN>
<TOKEN id="token-54-9" pos="word" morph="none" start_char="6234" end_char="6237">esta</TOKEN>
<TOKEN id="token-54-10" pos="word" morph="none" start_char="6239" end_char="6246">solución</TOKEN>
<TOKEN id="token-54-11" pos="word" morph="none" start_char="6248" end_char="6253">barata</TOKEN>
<TOKEN id="token-54-12" pos="punct" morph="none" start_char="6254" end_char="6254">,</TOKEN>
<TOKEN id="token-54-13" pos="word" morph="none" start_char="6256" end_char="6261">inocua</TOKEN>
<TOKEN id="token-54-14" pos="word" morph="none" start_char="6263" end_char="6263">y</TOKEN>
<TOKEN id="token-54-15" pos="word" morph="none" start_char="6265" end_char="6266">no</TOKEN>
<TOKEN id="token-54-16" pos="word" morph="none" start_char="6268" end_char="6277">patentable</TOKEN>
<TOKEN id="token-54-17" pos="word" morph="none" start_char="6279" end_char="6279">a</TOKEN>
<TOKEN id="token-54-18" pos="word" morph="none" start_char="6281" end_char="6282">la</TOKEN>
<TOKEN id="token-54-19" pos="word" morph="none" start_char="6284" end_char="6291">supuesta</TOKEN>
<TOKEN id="token-54-20" pos="word" morph="none" start_char="6293" end_char="6300">pandemia</TOKEN>
<TOKEN id="token-54-21" pos="word" morph="none" start_char="6302" end_char="6307">actual</TOKEN>
<TOKEN id="token-54-22" pos="punct" morph="none" start_char="6308" end_char="6308">,</TOKEN>
<TOKEN id="token-54-23" pos="word" morph="none" start_char="6310" end_char="6314">entre</TOKEN>
<TOKEN id="token-54-24" pos="word" morph="none" start_char="6316" end_char="6320">otras</TOKEN>
<TOKEN id="token-54-25" pos="word" morph="none" start_char="6322" end_char="6330">dolencias</TOKEN>
<TOKEN id="token-54-26" pos="punct" morph="none" start_char="6331" end_char="6331">?</TOKEN>
</SEG>
<SEG id="segment-55" start_char="6333" end_char="6464">
<ORIGINAL_TEXT>El ensayo fue hecho en Guayaquil Ecuador y es de dominio público para ser distribuido libremente mientras no se altere el contenido.</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="word" morph="none" start_char="6333" end_char="6334">El</TOKEN>
<TOKEN id="token-55-1" pos="word" morph="none" start_char="6336" end_char="6341">ensayo</TOKEN>
<TOKEN id="token-55-2" pos="word" morph="none" start_char="6343" end_char="6345">fue</TOKEN>
<TOKEN id="token-55-3" pos="word" morph="none" start_char="6347" end_char="6351">hecho</TOKEN>
<TOKEN id="token-55-4" pos="word" morph="none" start_char="6353" end_char="6354">en</TOKEN>
<TOKEN id="token-55-5" pos="word" morph="none" start_char="6356" end_char="6364">Guayaquil</TOKEN>
<TOKEN id="token-55-6" pos="word" morph="none" start_char="6366" end_char="6372">Ecuador</TOKEN>
<TOKEN id="token-55-7" pos="word" morph="none" start_char="6374" end_char="6374">y</TOKEN>
<TOKEN id="token-55-8" pos="word" morph="none" start_char="6376" end_char="6377">es</TOKEN>
<TOKEN id="token-55-9" pos="word" morph="none" start_char="6379" end_char="6380">de</TOKEN>
<TOKEN id="token-55-10" pos="word" morph="none" start_char="6382" end_char="6388">dominio</TOKEN>
<TOKEN id="token-55-11" pos="word" morph="none" start_char="6390" end_char="6396">público</TOKEN>
<TOKEN id="token-55-12" pos="word" morph="none" start_char="6398" end_char="6401">para</TOKEN>
<TOKEN id="token-55-13" pos="word" morph="none" start_char="6403" end_char="6405">ser</TOKEN>
<TOKEN id="token-55-14" pos="word" morph="none" start_char="6407" end_char="6417">distribuido</TOKEN>
<TOKEN id="token-55-15" pos="word" morph="none" start_char="6419" end_char="6428">libremente</TOKEN>
<TOKEN id="token-55-16" pos="word" morph="none" start_char="6430" end_char="6437">mientras</TOKEN>
<TOKEN id="token-55-17" pos="word" morph="none" start_char="6439" end_char="6440">no</TOKEN>
<TOKEN id="token-55-18" pos="word" morph="none" start_char="6442" end_char="6443">se</TOKEN>
<TOKEN id="token-55-19" pos="word" morph="none" start_char="6445" end_char="6450">altere</TOKEN>
<TOKEN id="token-55-20" pos="word" morph="none" start_char="6452" end_char="6453">el</TOKEN>
<TOKEN id="token-55-21" pos="word" morph="none" start_char="6455" end_char="6463">contenido</TOKEN>
<TOKEN id="token-55-22" pos="punct" morph="none" start_char="6464" end_char="6464">.</TOKEN>
</SEG>
<SEG id="segment-56" start_char="6466" end_char="6638">
<ORIGINAL_TEXT>Se facilita en el siguiente enlace: https://cdn.lbryplayer.xyz/content/...af59ac186a8c3645280de725dc5/stream?download=1 Hablamos de un estudio elaborado y firmado 7 médicos.</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="6466" end_char="6467">Se</TOKEN>
<TOKEN id="token-56-1" pos="word" morph="none" start_char="6469" end_char="6476">facilita</TOKEN>
<TOKEN id="token-56-2" pos="word" morph="none" start_char="6478" end_char="6479">en</TOKEN>
<TOKEN id="token-56-3" pos="word" morph="none" start_char="6481" end_char="6482">el</TOKEN>
<TOKEN id="token-56-4" pos="word" morph="none" start_char="6484" end_char="6492">siguiente</TOKEN>
<TOKEN id="token-56-5" pos="word" morph="none" start_char="6494" end_char="6499">enlace</TOKEN>
<TOKEN id="token-56-6" pos="punct" morph="none" start_char="6500" end_char="6500">:</TOKEN>
<TOKEN id="token-56-7" pos="url" morph="none" start_char="6502" end_char="6584">https://cdn.lbryplayer.xyz/content/...af59ac186a8c3645280de725dc5/stream?download=1</TOKEN>
<TOKEN id="token-56-8" pos="word" morph="none" start_char="6586" end_char="6593">Hablamos</TOKEN>
<TOKEN id="token-56-9" pos="word" morph="none" start_char="6595" end_char="6596">de</TOKEN>
<TOKEN id="token-56-10" pos="word" morph="none" start_char="6598" end_char="6599">un</TOKEN>
<TOKEN id="token-56-11" pos="word" morph="none" start_char="6601" end_char="6607">estudio</TOKEN>
<TOKEN id="token-56-12" pos="word" morph="none" start_char="6609" end_char="6617">elaborado</TOKEN>
<TOKEN id="token-56-13" pos="word" morph="none" start_char="6619" end_char="6619">y</TOKEN>
<TOKEN id="token-56-14" pos="word" morph="none" start_char="6621" end_char="6627">firmado</TOKEN>
<TOKEN id="token-56-15" pos="word" morph="none" start_char="6629" end_char="6629">7</TOKEN>
<TOKEN id="token-56-16" pos="word" morph="none" start_char="6631" end_char="6637">médicos</TOKEN>
<TOKEN id="token-56-17" pos="punct" morph="none" start_char="6638" end_char="6638">.</TOKEN>
</SEG>
<SEG id="segment-57" start_char="6640" end_char="6701">
<ORIGINAL_TEXT>Por favor tenganlo en cuenta antes de directamente censurarlo.</ORIGINAL_TEXT>
<TOKEN id="token-57-0" pos="word" morph="none" start_char="6640" end_char="6642">Por</TOKEN>
<TOKEN id="token-57-1" pos="word" morph="none" start_char="6644" end_char="6648">favor</TOKEN>
<TOKEN id="token-57-2" pos="word" morph="none" start_char="6650" end_char="6657">tenganlo</TOKEN>
<TOKEN id="token-57-3" pos="word" morph="none" start_char="6659" end_char="6660">en</TOKEN>
<TOKEN id="token-57-4" pos="word" morph="none" start_char="6662" end_char="6667">cuenta</TOKEN>
<TOKEN id="token-57-5" pos="word" morph="none" start_char="6669" end_char="6673">antes</TOKEN>
<TOKEN id="token-57-6" pos="word" morph="none" start_char="6675" end_char="6676">de</TOKEN>
<TOKEN id="token-57-7" pos="word" morph="none" start_char="6678" end_char="6689">directamente</TOKEN>
<TOKEN id="token-57-8" pos="word" morph="none" start_char="6691" end_char="6700">censurarlo</TOKEN>
<TOKEN id="token-57-9" pos="punct" morph="none" start_char="6701" end_char="6701">.</TOKEN>
</SEG>
<SEG id="segment-58" start_char="6703" end_char="6972">
<ORIGINAL_TEXT>Ver archivo adjunto 321837 Ver archivo adjunto 321838 Ver archivo adjunto 321839 Ver archivo adjunto 321841 Ver archivo adjunto 321842 Ver archivo adjunto 321843 Ver archivo adjunto 321845 Ver archivo adjunto 321846 Ver archivo adjunto 321848 Hacer clic para expandir...</ORIGINAL_TEXT>
<TOKEN id="token-58-0" pos="word" morph="none" start_char="6703" end_char="6705">Ver</TOKEN>
<TOKEN id="token-58-1" pos="word" morph="none" start_char="6707" end_char="6713">archivo</TOKEN>
<TOKEN id="token-58-2" pos="word" morph="none" start_char="6715" end_char="6721">adjunto</TOKEN>
<TOKEN id="token-58-3" pos="word" morph="none" start_char="6723" end_char="6728">321837</TOKEN>
<TOKEN id="token-58-4" pos="word" morph="none" start_char="6730" end_char="6732">Ver</TOKEN>
<TOKEN id="token-58-5" pos="word" morph="none" start_char="6734" end_char="6740">archivo</TOKEN>
<TOKEN id="token-58-6" pos="word" morph="none" start_char="6742" end_char="6748">adjunto</TOKEN>
<TOKEN id="token-58-7" pos="word" morph="none" start_char="6750" end_char="6755">321838</TOKEN>
<TOKEN id="token-58-8" pos="word" morph="none" start_char="6757" end_char="6759">Ver</TOKEN>
<TOKEN id="token-58-9" pos="word" morph="none" start_char="6761" end_char="6767">archivo</TOKEN>
<TOKEN id="token-58-10" pos="word" morph="none" start_char="6769" end_char="6775">adjunto</TOKEN>
<TOKEN id="token-58-11" pos="word" morph="none" start_char="6777" end_char="6782">321839</TOKEN>
<TOKEN id="token-58-12" pos="word" morph="none" start_char="6784" end_char="6786">Ver</TOKEN>
<TOKEN id="token-58-13" pos="word" morph="none" start_char="6788" end_char="6794">archivo</TOKEN>
<TOKEN id="token-58-14" pos="word" morph="none" start_char="6796" end_char="6802">adjunto</TOKEN>
<TOKEN id="token-58-15" pos="word" morph="none" start_char="6804" end_char="6809">321841</TOKEN>
<TOKEN id="token-58-16" pos="word" morph="none" start_char="6811" end_char="6813">Ver</TOKEN>
<TOKEN id="token-58-17" pos="word" morph="none" start_char="6815" end_char="6821">archivo</TOKEN>
<TOKEN id="token-58-18" pos="word" morph="none" start_char="6823" end_char="6829">adjunto</TOKEN>
<TOKEN id="token-58-19" pos="word" morph="none" start_char="6831" end_char="6836">321842</TOKEN>
<TOKEN id="token-58-20" pos="word" morph="none" start_char="6838" end_char="6840">Ver</TOKEN>
<TOKEN id="token-58-21" pos="word" morph="none" start_char="6842" end_char="6848">archivo</TOKEN>
<TOKEN id="token-58-22" pos="word" morph="none" start_char="6850" end_char="6856">adjunto</TOKEN>
<TOKEN id="token-58-23" pos="word" morph="none" start_char="6858" end_char="6863">321843</TOKEN>
<TOKEN id="token-58-24" pos="word" morph="none" start_char="6865" end_char="6867">Ver</TOKEN>
<TOKEN id="token-58-25" pos="word" morph="none" start_char="6869" end_char="6875">archivo</TOKEN>
<TOKEN id="token-58-26" pos="word" morph="none" start_char="6877" end_char="6883">adjunto</TOKEN>
<TOKEN id="token-58-27" pos="word" morph="none" start_char="6885" end_char="6890">321845</TOKEN>
<TOKEN id="token-58-28" pos="word" morph="none" start_char="6892" end_char="6894">Ver</TOKEN>
<TOKEN id="token-58-29" pos="word" morph="none" start_char="6896" end_char="6902">archivo</TOKEN>
<TOKEN id="token-58-30" pos="word" morph="none" start_char="6904" end_char="6910">adjunto</TOKEN>
<TOKEN id="token-58-31" pos="word" morph="none" start_char="6912" end_char="6917">321846</TOKEN>
<TOKEN id="token-58-32" pos="word" morph="none" start_char="6919" end_char="6921">Ver</TOKEN>
<TOKEN id="token-58-33" pos="word" morph="none" start_char="6923" end_char="6929">archivo</TOKEN>
<TOKEN id="token-58-34" pos="word" morph="none" start_char="6931" end_char="6937">adjunto</TOKEN>
<TOKEN id="token-58-35" pos="word" morph="none" start_char="6939" end_char="6944">321848</TOKEN>
<TOKEN id="token-58-36" pos="word" morph="none" start_char="6946" end_char="6950">Hacer</TOKEN>
<TOKEN id="token-58-37" pos="word" morph="none" start_char="6952" end_char="6955">clic</TOKEN>
<TOKEN id="token-58-38" pos="word" morph="none" start_char="6957" end_char="6960">para</TOKEN>
<TOKEN id="token-58-39" pos="word" morph="none" start_char="6962" end_char="6969">expandir</TOKEN>
<TOKEN id="token-58-40" pos="punct" morph="none" start_char="6970" end_char="6972">...</TOKEN>
</SEG>
<SEG id="segment-59" start_char="6975" end_char="6998">
<ORIGINAL_TEXT>Todo un éxito sin dudas.</ORIGINAL_TEXT>
<TOKEN id="token-59-0" pos="word" morph="none" start_char="6975" end_char="6978">Todo</TOKEN>
<TOKEN id="token-59-1" pos="word" morph="none" start_char="6980" end_char="6981">un</TOKEN>
<TOKEN id="token-59-2" pos="word" morph="none" start_char="6983" end_char="6987">éxito</TOKEN>
<TOKEN id="token-59-3" pos="word" morph="none" start_char="6989" end_char="6991">sin</TOKEN>
<TOKEN id="token-59-4" pos="word" morph="none" start_char="6993" end_char="6997">dudas</TOKEN>
<TOKEN id="token-59-5" pos="punct" morph="none" start_char="6998" end_char="6998">.</TOKEN>
</SEG>
<SEG id="segment-60" start_char="7000" end_char="7128">
<ORIGINAL_TEXT>Una muestra de 104 pacientes con alteraciones de la formula leucocitaria y ferritina, vamos lo que se ve en el supuesto Covid 19.</ORIGINAL_TEXT>
<TOKEN id="token-60-0" pos="word" morph="none" start_char="7000" end_char="7002">Una</TOKEN>
<TOKEN id="token-60-1" pos="word" morph="none" start_char="7004" end_char="7010">muestra</TOKEN>
<TOKEN id="token-60-2" pos="word" morph="none" start_char="7012" end_char="7013">de</TOKEN>
<TOKEN id="token-60-3" pos="word" morph="none" start_char="7015" end_char="7017">104</TOKEN>
<TOKEN id="token-60-4" pos="word" morph="none" start_char="7019" end_char="7027">pacientes</TOKEN>
<TOKEN id="token-60-5" pos="word" morph="none" start_char="7029" end_char="7031">con</TOKEN>
<TOKEN id="token-60-6" pos="word" morph="none" start_char="7033" end_char="7044">alteraciones</TOKEN>
<TOKEN id="token-60-7" pos="word" morph="none" start_char="7046" end_char="7047">de</TOKEN>
<TOKEN id="token-60-8" pos="word" morph="none" start_char="7049" end_char="7050">la</TOKEN>
<TOKEN id="token-60-9" pos="word" morph="none" start_char="7052" end_char="7058">formula</TOKEN>
<TOKEN id="token-60-10" pos="word" morph="none" start_char="7060" end_char="7071">leucocitaria</TOKEN>
<TOKEN id="token-60-11" pos="word" morph="none" start_char="7073" end_char="7073">y</TOKEN>
<TOKEN id="token-60-12" pos="word" morph="none" start_char="7075" end_char="7083">ferritina</TOKEN>
<TOKEN id="token-60-13" pos="punct" morph="none" start_char="7084" end_char="7084">,</TOKEN>
<TOKEN id="token-60-14" pos="word" morph="none" start_char="7086" end_char="7090">vamos</TOKEN>
<TOKEN id="token-60-15" pos="word" morph="none" start_char="7092" end_char="7093">lo</TOKEN>
<TOKEN id="token-60-16" pos="word" morph="none" start_char="7095" end_char="7097">que</TOKEN>
<TOKEN id="token-60-17" pos="word" morph="none" start_char="7099" end_char="7100">se</TOKEN>
<TOKEN id="token-60-18" pos="word" morph="none" start_char="7102" end_char="7103">ve</TOKEN>
<TOKEN id="token-60-19" pos="word" morph="none" start_char="7105" end_char="7106">en</TOKEN>
<TOKEN id="token-60-20" pos="word" morph="none" start_char="7108" end_char="7109">el</TOKEN>
<TOKEN id="token-60-21" pos="word" morph="none" start_char="7111" end_char="7118">supuesto</TOKEN>
<TOKEN id="token-60-22" pos="word" morph="none" start_char="7120" end_char="7124">Covid</TOKEN>
<TOKEN id="token-60-23" pos="word" morph="none" start_char="7126" end_char="7127">19</TOKEN>
<TOKEN id="token-60-24" pos="punct" morph="none" start_char="7128" end_char="7128">.</TOKEN>
</SEG>
<SEG id="segment-61" start_char="7131" end_char="7179">
<ORIGINAL_TEXT>A los 4 días remisión de síntomas, ni una muerte.</ORIGINAL_TEXT>
<TOKEN id="token-61-0" pos="word" morph="none" start_char="7131" end_char="7131">A</TOKEN>
<TOKEN id="token-61-1" pos="word" morph="none" start_char="7133" end_char="7135">los</TOKEN>
<TOKEN id="token-61-2" pos="word" morph="none" start_char="7137" end_char="7137">4</TOKEN>
<TOKEN id="token-61-3" pos="word" morph="none" start_char="7139" end_char="7142">días</TOKEN>
<TOKEN id="token-61-4" pos="word" morph="none" start_char="7144" end_char="7151">remisión</TOKEN>
<TOKEN id="token-61-5" pos="word" morph="none" start_char="7153" end_char="7154">de</TOKEN>
<TOKEN id="token-61-6" pos="word" morph="none" start_char="7156" end_char="7163">síntomas</TOKEN>
<TOKEN id="token-61-7" pos="punct" morph="none" start_char="7164" end_char="7164">,</TOKEN>
<TOKEN id="token-61-8" pos="word" morph="none" start_char="7166" end_char="7167">ni</TOKEN>
<TOKEN id="token-61-9" pos="word" morph="none" start_char="7169" end_char="7171">una</TOKEN>
<TOKEN id="token-61-10" pos="word" morph="none" start_char="7173" end_char="7178">muerte</TOKEN>
<TOKEN id="token-61-11" pos="punct" morph="none" start_char="7179" end_char="7179">.</TOKEN>
</SEG>
<SEG id="segment-62" start_char="7181" end_char="7238">
<ORIGINAL_TEXT>La toxicidad queda clara que no tiene discusión, no tiene.</ORIGINAL_TEXT>
<TOKEN id="token-62-0" pos="word" morph="none" start_char="7181" end_char="7182">La</TOKEN>
<TOKEN id="token-62-1" pos="word" morph="none" start_char="7184" end_char="7192">toxicidad</TOKEN>
<TOKEN id="token-62-2" pos="word" morph="none" start_char="7194" end_char="7198">queda</TOKEN>
<TOKEN id="token-62-3" pos="word" morph="none" start_char="7200" end_char="7204">clara</TOKEN>
<TOKEN id="token-62-4" pos="word" morph="none" start_char="7206" end_char="7208">que</TOKEN>
<TOKEN id="token-62-5" pos="word" morph="none" start_char="7210" end_char="7211">no</TOKEN>
<TOKEN id="token-62-6" pos="word" morph="none" start_char="7213" end_char="7217">tiene</TOKEN>
<TOKEN id="token-62-7" pos="word" morph="none" start_char="7219" end_char="7227">discusión</TOKEN>
<TOKEN id="token-62-8" pos="punct" morph="none" start_char="7228" end_char="7228">,</TOKEN>
<TOKEN id="token-62-9" pos="word" morph="none" start_char="7230" end_char="7231">no</TOKEN>
<TOKEN id="token-62-10" pos="word" morph="none" start_char="7233" end_char="7237">tiene</TOKEN>
<TOKEN id="token-62-11" pos="punct" morph="none" start_char="7238" end_char="7238">.</TOKEN>
</SEG>
<SEG id="segment-63" start_char="7241" end_char="7290">
<ORIGINAL_TEXT>Muy buenas noticias con este estudio sin dudas.!!!</ORIGINAL_TEXT>
<TOKEN id="token-63-0" pos="word" morph="none" start_char="7241" end_char="7243">Muy</TOKEN>
<TOKEN id="token-63-1" pos="word" morph="none" start_char="7245" end_char="7250">buenas</TOKEN>
<TOKEN id="token-63-2" pos="word" morph="none" start_char="7252" end_char="7259">noticias</TOKEN>
<TOKEN id="token-63-3" pos="word" morph="none" start_char="7261" end_char="7263">con</TOKEN>
<TOKEN id="token-63-4" pos="word" morph="none" start_char="7265" end_char="7268">este</TOKEN>
<TOKEN id="token-63-5" pos="word" morph="none" start_char="7270" end_char="7276">estudio</TOKEN>
<TOKEN id="token-63-6" pos="word" morph="none" start_char="7278" end_char="7280">sin</TOKEN>
<TOKEN id="token-63-7" pos="word" morph="none" start_char="7282" end_char="7286">dudas</TOKEN>
<TOKEN id="token-63-8" pos="punct" morph="none" start_char="7287" end_char="7290">.!!!</TOKEN>
</SEG>
<SEG id="segment-64" start_char="7293" end_char="7325">
<ORIGINAL_TEXT>Felicidades a los investigadores.</ORIGINAL_TEXT>
<TOKEN id="token-64-0" pos="word" morph="none" start_char="7293" end_char="7303">Felicidades</TOKEN>
<TOKEN id="token-64-1" pos="word" morph="none" start_char="7305" end_char="7305">a</TOKEN>
<TOKEN id="token-64-2" pos="word" morph="none" start_char="7307" end_char="7309">los</TOKEN>
<TOKEN id="token-64-3" pos="word" morph="none" start_char="7311" end_char="7324">investigadores</TOKEN>
<TOKEN id="token-64-4" pos="punct" morph="none" start_char="7325" end_char="7325">.</TOKEN>
</SEG>
<SEG id="segment-65" start_char="7330" end_char="7409">
<ORIGINAL_TEXT>Esta claro que a la farmaindustria no le interesa curar si no que hacer negocio.</ORIGINAL_TEXT>
<TOKEN id="token-65-0" pos="word" morph="none" start_char="7330" end_char="7333">Esta</TOKEN>
<TOKEN id="token-65-1" pos="word" morph="none" start_char="7335" end_char="7339">claro</TOKEN>
<TOKEN id="token-65-2" pos="word" morph="none" start_char="7341" end_char="7343">que</TOKEN>
<TOKEN id="token-65-3" pos="word" morph="none" start_char="7345" end_char="7345">a</TOKEN>
<TOKEN id="token-65-4" pos="word" morph="none" start_char="7347" end_char="7348">la</TOKEN>
<TOKEN id="token-65-5" pos="word" morph="none" start_char="7350" end_char="7363">farmaindustria</TOKEN>
<TOKEN id="token-65-6" pos="word" morph="none" start_char="7365" end_char="7366">no</TOKEN>
<TOKEN id="token-65-7" pos="word" morph="none" start_char="7368" end_char="7369">le</TOKEN>
<TOKEN id="token-65-8" pos="word" morph="none" start_char="7371" end_char="7378">interesa</TOKEN>
<TOKEN id="token-65-9" pos="word" morph="none" start_char="7380" end_char="7384">curar</TOKEN>
<TOKEN id="token-65-10" pos="word" morph="none" start_char="7386" end_char="7387">si</TOKEN>
<TOKEN id="token-65-11" pos="word" morph="none" start_char="7389" end_char="7390">no</TOKEN>
<TOKEN id="token-65-12" pos="word" morph="none" start_char="7392" end_char="7394">que</TOKEN>
<TOKEN id="token-65-13" pos="word" morph="none" start_char="7396" end_char="7400">hacer</TOKEN>
<TOKEN id="token-65-14" pos="word" morph="none" start_char="7402" end_char="7408">negocio</TOKEN>
<TOKEN id="token-65-15" pos="punct" morph="none" start_char="7409" end_char="7409">.</TOKEN>
</SEG>
<SEG id="segment-66" start_char="7411" end_char="7482">
<ORIGINAL_TEXT>De ahí vienen todos los ataques a esta solución buena barata y efectiva.</ORIGINAL_TEXT>
<TOKEN id="token-66-0" pos="word" morph="none" start_char="7411" end_char="7412">De</TOKEN>
<TOKEN id="token-66-1" pos="word" morph="none" start_char="7414" end_char="7416">ahí</TOKEN>
<TOKEN id="token-66-2" pos="word" morph="none" start_char="7418" end_char="7423">vienen</TOKEN>
<TOKEN id="token-66-3" pos="word" morph="none" start_char="7425" end_char="7429">todos</TOKEN>
<TOKEN id="token-66-4" pos="word" morph="none" start_char="7431" end_char="7433">los</TOKEN>
<TOKEN id="token-66-5" pos="word" morph="none" start_char="7435" end_char="7441">ataques</TOKEN>
<TOKEN id="token-66-6" pos="word" morph="none" start_char="7443" end_char="7443">a</TOKEN>
<TOKEN id="token-66-7" pos="word" morph="none" start_char="7445" end_char="7448">esta</TOKEN>
<TOKEN id="token-66-8" pos="word" morph="none" start_char="7450" end_char="7457">solución</TOKEN>
<TOKEN id="token-66-9" pos="word" morph="none" start_char="7459" end_char="7463">buena</TOKEN>
<TOKEN id="token-66-10" pos="word" morph="none" start_char="7465" end_char="7470">barata</TOKEN>
<TOKEN id="token-66-11" pos="word" morph="none" start_char="7472" end_char="7472">y</TOKEN>
<TOKEN id="token-66-12" pos="word" morph="none" start_char="7474" end_char="7481">efectiva</TOKEN>
<TOKEN id="token-66-13" pos="punct" morph="none" start_char="7482" end_char="7482">.</TOKEN>
</SEG>
<SEG id="segment-67" start_char="7486" end_char="7525">
<ORIGINAL_TEXT>Gracias por esta noticia, importantísima</ORIGINAL_TEXT>
<TOKEN id="token-67-0" pos="word" morph="none" start_char="7486" end_char="7492">Gracias</TOKEN>
<TOKEN id="token-67-1" pos="word" morph="none" start_char="7494" end_char="7496">por</TOKEN>
<TOKEN id="token-67-2" pos="word" morph="none" start_char="7498" end_char="7501">esta</TOKEN>
<TOKEN id="token-67-3" pos="word" morph="none" start_char="7503" end_char="7509">noticia</TOKEN>
<TOKEN id="token-67-4" pos="punct" morph="none" start_char="7510" end_char="7510">,</TOKEN>
<TOKEN id="token-67-5" pos="word" morph="none" start_char="7512" end_char="7525">importantísima</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
