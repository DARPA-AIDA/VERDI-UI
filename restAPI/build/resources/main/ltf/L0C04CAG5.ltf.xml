<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CAG5" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="1051" raw_text_md5="00dc773b75fa9daad5e46ec63726b15c">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="64">
<ORIGINAL_TEXT>BASTANTE GRAVE: Canal5 acusa al gobierno de ASESINAR a ancianos.</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="8">BASTANTE</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="10" end_char="14">GRAVE</TOKEN>
<TOKEN id="token-0-2" pos="punct" morph="none" start_char="15" end_char="15">:</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="17" end_char="22">Canal5</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="24" end_char="28">acusa</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="30" end_char="31">al</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="33" end_char="40">gobierno</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="42" end_char="43">de</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="45" end_char="52">ASESINAR</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="54" end_char="54">a</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="56" end_char="63">ancianos</TOKEN>
<TOKEN id="token-0-11" pos="punct" morph="none" start_char="64" end_char="64">.</TOKEN>
</SEG>
<SEG id="segment-1" start_char="66" end_char="93">
<ORIGINAL_TEXT>Eutanasia encubierta (video)</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="66" end_char="74">Eutanasia</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="76" end_char="85">encubierta</TOKEN>
<TOKEN id="token-1-2" pos="punct" morph="none" start_char="87" end_char="87">(</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="88" end_char="92">video</TOKEN>
<TOKEN id="token-1-4" pos="punct" morph="none" start_char="93" end_char="93">)</TOKEN>
</SEG>
<SEG id="segment-2" start_char="98" end_char="127">
<ORIGINAL_TEXT>Dice lo mismo que Cesar Vidal.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="98" end_char="101">Dice</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="103" end_char="104">lo</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="106" end_char="110">mismo</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="112" end_char="114">que</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="116" end_char="120">Cesar</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="122" end_char="126">Vidal</TOKEN>
<TOKEN id="token-2-6" pos="punct" morph="none" start_char="127" end_char="127">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="129" end_char="160">
<ORIGINAL_TEXT>Torr치 hace lo mismo que Sanchez.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="129" end_char="133">Torr치</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="135" end_char="138">hace</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="140" end_char="141">lo</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="143" end_char="147">mismo</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="149" end_char="151">que</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="153" end_char="159">Sanchez</TOKEN>
<TOKEN id="token-3-6" pos="punct" morph="none" start_char="160" end_char="160">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="163" end_char="247">
<ORIGINAL_TEXT>Se ha ordenado a las autoridades sanitarias desde hace 2 semanas, hacer lo siguiente:</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="163" end_char="164">Se</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="166" end_char="167">ha</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="169" end_char="176">ordenado</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="178" end_char="178">a</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="180" end_char="182">las</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="184" end_char="194">autoridades</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="196" end_char="205">sanitarias</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="207" end_char="211">desde</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="213" end_char="216">hace</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="218" end_char="218">2</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="220" end_char="226">semanas</TOKEN>
<TOKEN id="token-4-11" pos="punct" morph="none" start_char="227" end_char="227">,</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="229" end_char="233">hacer</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="235" end_char="236">lo</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="238" end_char="246">siguiente</TOKEN>
<TOKEN id="token-4-15" pos="punct" morph="none" start_char="247" end_char="247">:</TOKEN>
</SEG>
<SEG id="segment-5" start_char="250" end_char="290">
<ORIGINAL_TEXT>-15 minutos de respirador a cada anciano.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="250" end_char="252">-15</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="254" end_char="260">minutos</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="262" end_char="263">de</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="265" end_char="274">respirador</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="276" end_char="276">a</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="278" end_char="281">cada</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="283" end_char="289">anciano</TOKEN>
<TOKEN id="token-5-7" pos="punct" morph="none" start_char="290" end_char="290">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="292" end_char="337">
<ORIGINAL_TEXT>Se lo quitan y luego se lo dan a otro anciano.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="292" end_char="293">Se</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="295" end_char="296">lo</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="298" end_char="303">quitan</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="305" end_char="305">y</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="307" end_char="311">luego</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="313" end_char="314">se</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="316" end_char="317">lo</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="319" end_char="321">dan</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="323" end_char="323">a</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="325" end_char="328">otro</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="330" end_char="336">anciano</TOKEN>
<TOKEN id="token-6-11" pos="punct" morph="none" start_char="337" end_char="337">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="339" end_char="454">
<ORIGINAL_TEXT>Y administran sedaci칩n, lo cual equivale a la muerte del paciente, al tener problemas respiratorios por Coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="339" end_char="339">Y</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="341" end_char="351">administran</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="353" end_char="360">sedaci칩n</TOKEN>
<TOKEN id="token-7-3" pos="punct" morph="none" start_char="361" end_char="361">,</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="363" end_char="364">lo</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="366" end_char="369">cual</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="371" end_char="378">equivale</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="380" end_char="380">a</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="382" end_char="383">la</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="385" end_char="390">muerte</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="392" end_char="394">del</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="396" end_char="403">paciente</TOKEN>
<TOKEN id="token-7-12" pos="punct" morph="none" start_char="404" end_char="404">,</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="406" end_char="407">al</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="409" end_char="413">tener</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="415" end_char="423">problemas</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="425" end_char="437">respiratorios</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="439" end_char="441">por</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="443" end_char="453">Coronavirus</TOKEN>
<TOKEN id="token-7-19" pos="punct" morph="none" start_char="454" end_char="454">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="457" end_char="481">
<ORIGINAL_TEXT>-Sin test, sin autopsias.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="punct" morph="none" start_char="457" end_char="457">-</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="458" end_char="460">Sin</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="462" end_char="465">test</TOKEN>
<TOKEN id="token-8-3" pos="punct" morph="none" start_char="466" end_char="466">,</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="468" end_char="470">sin</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="472" end_char="480">autopsias</TOKEN>
<TOKEN id="token-8-6" pos="punct" morph="none" start_char="481" end_char="481">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="483" end_char="544">
<ORIGINAL_TEXT>Retrasarlos y evitarlos para que no se sepa de qu칠 han muerto.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="483" end_char="493">Retrasarlos</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="495" end_char="495">y</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="497" end_char="505">evitarlos</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="507" end_char="510">para</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="512" end_char="514">que</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="516" end_char="517">no</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="519" end_char="520">se</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="522" end_char="525">sepa</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="527" end_char="528">de</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="530" end_char="532">qu칠</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="534" end_char="536">han</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="538" end_char="543">muerto</TOKEN>
<TOKEN id="token-9-12" pos="punct" morph="none" start_char="544" end_char="544">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="547" end_char="652">
<ORIGINAL_TEXT>Un proyecto genocida de eutanasia para as칤 no pagar pensiones y quitarse de encima a los que no les votan.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="547" end_char="548">Un</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="550" end_char="557">proyecto</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="559" end_char="566">genocida</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="568" end_char="569">de</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="571" end_char="579">eutanasia</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="581" end_char="584">para</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="586" end_char="588">as칤</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="590" end_char="591">no</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="593" end_char="597">pagar</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="599" end_char="607">pensiones</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="609" end_char="609">y</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="611" end_char="618">quitarse</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="620" end_char="621">de</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="623" end_char="628">encima</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="630" end_char="630">a</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="632" end_char="634">los</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="636" end_char="638">que</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="640" end_char="641">no</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="643" end_char="645">les</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="647" end_char="651">votan</TOKEN>
<TOKEN id="token-10-20" pos="punct" morph="none" start_char="652" end_char="652">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="654" end_char="750">
<ORIGINAL_TEXT>Ya sabemos por qu칠 hay 11000 muertos de momento, una cifra exagerada con respecto a otros pa칤ses.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="654" end_char="655">Ya</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="657" end_char="663">sabemos</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="665" end_char="667">por</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="669" end_char="671">qu칠</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="673" end_char="675">hay</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="677" end_char="681">11000</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="683" end_char="689">muertos</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="691" end_char="692">de</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="694" end_char="700">momento</TOKEN>
<TOKEN id="token-11-9" pos="punct" morph="none" start_char="701" end_char="701">,</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="703" end_char="705">una</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="707" end_char="711">cifra</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="713" end_char="721">exagerada</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="723" end_char="725">con</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="727" end_char="734">respecto</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="736" end_char="736">a</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="738" end_char="742">otros</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="744" end_char="749">pa칤ses</TOKEN>
<TOKEN id="token-11-18" pos="punct" morph="none" start_char="750" end_char="750">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="752" end_char="781">
<ORIGINAL_TEXT>No es triaje, es lo siguiente.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="752" end_char="753">No</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="755" end_char="756">es</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="758" end_char="763">triaje</TOKEN>
<TOKEN id="token-12-3" pos="punct" morph="none" start_char="764" end_char="764">,</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="766" end_char="767">es</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="769" end_char="770">lo</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="772" end_char="780">siguiente</TOKEN>
<TOKEN id="token-12-7" pos="punct" morph="none" start_char="781" end_char="781">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="784" end_char="903">
<ORIGINAL_TEXT>Si es verdad 칠sto, todo m칠dico o enfermera que est칠 colaborando con esta soluci칩n final, es IGUAL de criminal que ellos.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="784" end_char="785">Si</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="787" end_char="788">es</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="790" end_char="795">verdad</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="797" end_char="800">칠sto</TOKEN>
<TOKEN id="token-13-4" pos="punct" morph="none" start_char="801" end_char="801">,</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="803" end_char="806">todo</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="808" end_char="813">m칠dico</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="815" end_char="815">o</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="817" end_char="825">enfermera</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="827" end_char="829">que</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="831" end_char="834">est칠</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="836" end_char="846">colaborando</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="848" end_char="850">con</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="852" end_char="855">esta</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="857" end_char="864">soluci칩n</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="866" end_char="870">final</TOKEN>
<TOKEN id="token-13-16" pos="punct" morph="none" start_char="871" end_char="871">,</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="873" end_char="874">es</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="876" end_char="880">IGUAL</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="882" end_char="883">de</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="885" end_char="892">criminal</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="894" end_char="896">que</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="898" end_char="902">ellos</TOKEN>
<TOKEN id="token-13-23" pos="punct" morph="none" start_char="903" end_char="903">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="905" end_char="927">
<ORIGINAL_TEXT>Esto debe investigarse.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="905" end_char="908">Esto</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="910" end_char="913">debe</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="915" end_char="926">investigarse</TOKEN>
<TOKEN id="token-14-3" pos="punct" morph="none" start_char="927" end_char="927">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="930" end_char="1012">
<ORIGINAL_TEXT>Y mientras tanto, las TVs controladas para enga침ar a la gente, y ense침ar payasadas.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="930" end_char="930">Y</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="932" end_char="939">mientras</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="941" end_char="945">tanto</TOKEN>
<TOKEN id="token-15-3" pos="punct" morph="none" start_char="946" end_char="946">,</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="948" end_char="950">las</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="952" end_char="954">TVs</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="956" end_char="966">controladas</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="968" end_char="971">para</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="973" end_char="979">enga침ar</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="981" end_char="981">a</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="983" end_char="984">la</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="986" end_char="990">gente</TOKEN>
<TOKEN id="token-15-12" pos="punct" morph="none" start_char="991" end_char="991">,</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="993" end_char="993">y</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="995" end_char="1001">ense침ar</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="1003" end_char="1011">payasadas</TOKEN>
<TOKEN id="token-15-16" pos="punct" morph="none" start_char="1012" end_char="1012">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1016" end_char="1047">
<ORIGINAL_TEXT>resubido, esto no se puede tapar</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1016" end_char="1023">resubido</TOKEN>
<TOKEN id="token-16-1" pos="punct" morph="none" start_char="1024" end_char="1024">,</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1026" end_char="1029">esto</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1031" end_char="1032">no</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1034" end_char="1035">se</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1037" end_char="1041">puede</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1043" end_char="1047">tapar</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
