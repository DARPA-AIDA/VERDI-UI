<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATFD" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="2373" raw_text_md5="7eb1b84f39a3a2373c908a958d072a23">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="63">
<ORIGINAL_TEXT>Naturally acquired immunity to Covid lasts at least five months</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="9">Naturally</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="11" end_char="18">acquired</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="20" end_char="27">immunity</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="29" end_char="30">to</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="32" end_char="36">Covid</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="38" end_char="42">lasts</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="44" end_char="45">at</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="47" end_char="51">least</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="53" end_char="56">five</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="58" end_char="63">months</TOKEN>
</SEG>
<SEG id="segment-1" start_char="68" end_char="228">
<ORIGINAL_TEXT>People infected with Covid-19 in the past are likely to be protected against reinfection for at least five months, a Public Health England (PHE) study has found.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="68" end_char="73">People</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="75" end_char="82">infected</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="84" end_char="87">with</TOKEN>
<TOKEN id="token-1-3" pos="unknown" morph="none" start_char="89" end_char="96">Covid-19</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="98" end_char="99">in</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="101" end_char="103">the</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="105" end_char="108">past</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="110" end_char="112">are</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="114" end_char="119">likely</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="121" end_char="122">to</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="124" end_char="125">be</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="127" end_char="135">protected</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="137" end_char="143">against</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="145" end_char="155">reinfection</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="157" end_char="159">for</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="161" end_char="162">at</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="164" end_char="168">least</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="170" end_char="173">five</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="175" end_char="180">months</TOKEN>
<TOKEN id="token-1-19" pos="punct" morph="none" start_char="181" end_char="181">,</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="183" end_char="183">a</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="185" end_char="190">Public</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="192" end_char="197">Health</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="199" end_char="205">England</TOKEN>
<TOKEN id="token-1-24" pos="punct" morph="none" start_char="207" end_char="207">(</TOKEN>
<TOKEN id="token-1-25" pos="word" morph="none" start_char="208" end_char="210">PHE</TOKEN>
<TOKEN id="token-1-26" pos="punct" morph="none" start_char="211" end_char="211">)</TOKEN>
<TOKEN id="token-1-27" pos="word" morph="none" start_char="213" end_char="217">study</TOKEN>
<TOKEN id="token-1-28" pos="word" morph="none" start_char="219" end_char="221">has</TOKEN>
<TOKEN id="token-1-29" pos="word" morph="none" start_char="223" end_char="227">found</TOKEN>
<TOKEN id="token-1-30" pos="punct" morph="none" start_char="228" end_char="228">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="231" end_char="432">
<ORIGINAL_TEXT>Analysis of figures from the SIREN study also shows that naturally acquired immunity provides at least 83 per cent protection against reinfection, compared to people who have not had the disease before.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="231" end_char="238">Analysis</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="240" end_char="241">of</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="243" end_char="249">figures</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="251" end_char="254">from</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="256" end_char="258">the</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="260" end_char="264">SIREN</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="266" end_char="270">study</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="272" end_char="275">also</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="277" end_char="281">shows</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="283" end_char="286">that</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="288" end_char="296">naturally</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="298" end_char="305">acquired</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="307" end_char="314">immunity</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="316" end_char="323">provides</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="325" end_char="326">at</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="328" end_char="332">least</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="334" end_char="335">83</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="337" end_char="339">per</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="341" end_char="344">cent</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="346" end_char="355">protection</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="357" end_char="363">against</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="365" end_char="375">reinfection</TOKEN>
<TOKEN id="token-2-22" pos="punct" morph="none" start_char="376" end_char="376">,</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="378" end_char="385">compared</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="387" end_char="388">to</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="390" end_char="395">people</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="397" end_char="399">who</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="401" end_char="404">have</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="406" end_char="408">not</TOKEN>
<TOKEN id="token-2-29" pos="word" morph="none" start_char="410" end_char="412">had</TOKEN>
<TOKEN id="token-2-30" pos="word" morph="none" start_char="414" end_char="416">the</TOKEN>
<TOKEN id="token-2-31" pos="word" morph="none" start_char="418" end_char="424">disease</TOKEN>
<TOKEN id="token-2-32" pos="word" morph="none" start_char="426" end_char="431">before</TOKEN>
<TOKEN id="token-2-33" pos="punct" morph="none" start_char="432" end_char="432">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="435" end_char="632">
<ORIGINAL_TEXT>The study will continue to assess whether protection may last for longer than five months, and whether people who contracted the disease in the first wave may now be vulnerable to catching it again.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="435" end_char="437">The</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="439" end_char="443">study</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="445" end_char="448">will</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="450" end_char="457">continue</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="459" end_char="460">to</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="462" end_char="467">assess</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="469" end_char="475">whether</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="477" end_char="486">protection</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="488" end_char="490">may</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="492" end_char="495">last</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="497" end_char="499">for</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="501" end_char="506">longer</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="508" end_char="511">than</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="513" end_char="516">five</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="518" end_char="523">months</TOKEN>
<TOKEN id="token-3-15" pos="punct" morph="none" start_char="524" end_char="524">,</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="526" end_char="528">and</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="530" end_char="536">whether</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="538" end_char="543">people</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="545" end_char="547">who</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="549" end_char="558">contracted</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="560" end_char="562">the</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="564" end_char="570">disease</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="572" end_char="573">in</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="575" end_char="577">the</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="579" end_char="583">first</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="585" end_char="588">wave</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="590" end_char="592">may</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="594" end_char="596">now</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="598" end_char="599">be</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="601" end_char="610">vulnerable</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="612" end_char="613">to</TOKEN>
<TOKEN id="token-3-32" pos="word" morph="none" start_char="615" end_char="622">catching</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="624" end_char="625">it</TOKEN>
<TOKEN id="token-3-34" pos="word" morph="none" start_char="627" end_char="631">again</TOKEN>
<TOKEN id="token-3-35" pos="punct" morph="none" start_char="632" end_char="632">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="635" end_char="795">
<ORIGINAL_TEXT>However, PHE cautions that those with immunity may still be able carry the virus in their nose and throat and therefore have a risk of transmitting it to others.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="635" end_char="641">However</TOKEN>
<TOKEN id="token-4-1" pos="punct" morph="none" start_char="642" end_char="642">,</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="644" end_char="646">PHE</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="648" end_char="655">cautions</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="657" end_char="660">that</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="662" end_char="666">those</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="668" end_char="671">with</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="673" end_char="680">immunity</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="682" end_char="684">may</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="686" end_char="690">still</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="692" end_char="693">be</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="695" end_char="698">able</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="700" end_char="704">carry</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="706" end_char="708">the</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="710" end_char="714">virus</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="716" end_char="717">in</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="719" end_char="723">their</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="725" end_char="728">nose</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="730" end_char="732">and</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="734" end_char="739">throat</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="741" end_char="743">and</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="745" end_char="753">therefore</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="755" end_char="758">have</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="760" end_char="760">a</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="762" end_char="765">risk</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="767" end_char="768">of</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="770" end_char="781">transmitting</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="783" end_char="784">it</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="786" end_char="787">to</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="789" end_char="794">others</TOKEN>
<TOKEN id="token-4-30" pos="punct" morph="none" start_char="795" end_char="795">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="798" end_char="1012">
<ORIGINAL_TEXT>The SIREN study has performed regular antibody and PCR testing on 20,787 healthcare workers, including frontline clinical staff and those in non-clinical roles, from 102 NHS trusts since the study commenced in June.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="798" end_char="800">The</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="802" end_char="806">SIREN</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="808" end_char="812">study</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="814" end_char="816">has</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="818" end_char="826">performed</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="828" end_char="834">regular</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="836" end_char="843">antibody</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="845" end_char="847">and</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="849" end_char="851">PCR</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="853" end_char="859">testing</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="861" end_char="862">on</TOKEN>
<TOKEN id="token-5-11" pos="unknown" morph="none" start_char="864" end_char="869">20,787</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="871" end_char="880">healthcare</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="882" end_char="888">workers</TOKEN>
<TOKEN id="token-5-14" pos="punct" morph="none" start_char="889" end_char="889">,</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="891" end_char="899">including</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="901" end_char="909">frontline</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="911" end_char="918">clinical</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="920" end_char="924">staff</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="926" end_char="928">and</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="930" end_char="934">those</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="936" end_char="937">in</TOKEN>
<TOKEN id="token-5-22" pos="unknown" morph="none" start_char="939" end_char="950">non-clinical</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="952" end_char="956">roles</TOKEN>
<TOKEN id="token-5-24" pos="punct" morph="none" start_char="957" end_char="957">,</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="959" end_char="962">from</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="964" end_char="966">102</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="968" end_char="970">NHS</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="972" end_char="977">trusts</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="979" end_char="983">since</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="985" end_char="987">the</TOKEN>
<TOKEN id="token-5-31" pos="word" morph="none" start_char="989" end_char="993">study</TOKEN>
<TOKEN id="token-5-32" pos="word" morph="none" start_char="995" end_char="1003">commenced</TOKEN>
<TOKEN id="token-5-33" pos="word" morph="none" start_char="1005" end_char="1006">in</TOKEN>
<TOKEN id="token-5-34" pos="word" morph="none" start_char="1008" end_char="1011">June</TOKEN>
<TOKEN id="token-5-35" pos="punct" morph="none" start_char="1012" end_char="1012">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="1014" end_char="1102">
<ORIGINAL_TEXT>Just over 6,600 of participants tested positive for Covid-19 antibodies upon recruitment.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="1014" end_char="1017">Just</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="1019" end_char="1022">over</TOKEN>
<TOKEN id="token-6-2" pos="unknown" morph="none" start_char="1024" end_char="1028">6,600</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="1030" end_char="1031">of</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="1033" end_char="1044">participants</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="1046" end_char="1051">tested</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="1053" end_char="1060">positive</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="1062" end_char="1064">for</TOKEN>
<TOKEN id="token-6-8" pos="unknown" morph="none" start_char="1066" end_char="1073">Covid-19</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="1075" end_char="1084">antibodies</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="1086" end_char="1089">upon</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="1091" end_char="1101">recruitment</TOKEN>
<TOKEN id="token-6-12" pos="punct" morph="none" start_char="1102" end_char="1102">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="1105" end_char="1267">
<ORIGINAL_TEXT>Of the 44 potential reinfections identified by the study, two were designated ‘probable’ and 42 ‘possible’, based on the amount of confirmatory evidence available.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="1105" end_char="1106">Of</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="1108" end_char="1110">the</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="1112" end_char="1113">44</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="1115" end_char="1123">potential</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="1125" end_char="1136">reinfections</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="1138" end_char="1147">identified</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="1149" end_char="1150">by</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="1152" end_char="1154">the</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="1156" end_char="1160">study</TOKEN>
<TOKEN id="token-7-9" pos="punct" morph="none" start_char="1161" end_char="1161">,</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="1163" end_char="1165">two</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="1167" end_char="1170">were</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="1172" end_char="1181">designated</TOKEN>
<TOKEN id="token-7-13" pos="punct" morph="none" start_char="1183" end_char="1183">‘</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="1184" end_char="1191">probable</TOKEN>
<TOKEN id="token-7-15" pos="punct" morph="none" start_char="1192" end_char="1192">’</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="1194" end_char="1196">and</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="1198" end_char="1199">42</TOKEN>
<TOKEN id="token-7-18" pos="punct" morph="none" start_char="1201" end_char="1201">‘</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="1202" end_char="1209">possible</TOKEN>
<TOKEN id="token-7-20" pos="punct" morph="none" start_char="1210" end_char="1211">’,</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="1213" end_char="1217">based</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="1219" end_char="1220">on</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="1222" end_char="1224">the</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="1226" end_char="1231">amount</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="1233" end_char="1234">of</TOKEN>
<TOKEN id="token-7-26" pos="word" morph="none" start_char="1236" end_char="1247">confirmatory</TOKEN>
<TOKEN id="token-7-27" pos="word" morph="none" start_char="1249" end_char="1256">evidence</TOKEN>
<TOKEN id="token-7-28" pos="word" morph="none" start_char="1258" end_char="1266">available</TOKEN>
<TOKEN id="token-7-29" pos="punct" morph="none" start_char="1267" end_char="1267">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1270" end_char="1417">
<ORIGINAL_TEXT>Both of the two ‘probable’ reinfections reported experiencing Covid symptoms during the first wave of the pandemic, but were not tested at the time.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1270" end_char="1273">Both</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1275" end_char="1276">of</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1278" end_char="1280">the</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1282" end_char="1284">two</TOKEN>
<TOKEN id="token-8-4" pos="punct" morph="none" start_char="1286" end_char="1286">‘</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1287" end_char="1294">probable</TOKEN>
<TOKEN id="token-8-6" pos="punct" morph="none" start_char="1295" end_char="1295">’</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1297" end_char="1308">reinfections</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1310" end_char="1317">reported</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1319" end_char="1330">experiencing</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1332" end_char="1336">Covid</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1338" end_char="1345">symptoms</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1347" end_char="1352">during</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1354" end_char="1356">the</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1358" end_char="1362">first</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1364" end_char="1367">wave</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1369" end_char="1370">of</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1372" end_char="1374">the</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1376" end_char="1383">pandemic</TOKEN>
<TOKEN id="token-8-19" pos="punct" morph="none" start_char="1384" end_char="1384">,</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="1386" end_char="1388">but</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="1390" end_char="1393">were</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="1395" end_char="1397">not</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="1399" end_char="1404">tested</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="1406" end_char="1407">at</TOKEN>
<TOKEN id="token-8-25" pos="word" morph="none" start_char="1409" end_char="1411">the</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="1413" end_char="1416">time</TOKEN>
<TOKEN id="token-8-27" pos="punct" morph="none" start_char="1417" end_char="1417">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1419" end_char="1494">
<ORIGINAL_TEXT>Both patients reported that their symptoms were less severe the second time.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1419" end_char="1422">Both</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1424" end_char="1431">patients</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1433" end_char="1440">reported</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1442" end_char="1445">that</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1447" end_char="1451">their</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1453" end_char="1460">symptoms</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1462" end_char="1465">were</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1467" end_char="1470">less</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1472" end_char="1477">severe</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1479" end_char="1481">the</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1483" end_char="1488">second</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1490" end_char="1493">time</TOKEN>
<TOKEN id="token-9-12" pos="punct" morph="none" start_char="1494" end_char="1494">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1497" end_char="1667">
<ORIGINAL_TEXT>None of the 44 potential reinfection cases were PCR tested during the first wave, but all tested positive for Covid-19 antibodies at the point of recruitment to the study.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1497" end_char="1500">None</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1502" end_char="1503">of</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1505" end_char="1507">the</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1509" end_char="1510">44</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1512" end_char="1520">potential</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1522" end_char="1532">reinfection</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1534" end_char="1538">cases</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1540" end_char="1543">were</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1545" end_char="1547">PCR</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1549" end_char="1554">tested</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1556" end_char="1561">during</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1563" end_char="1565">the</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1567" end_char="1571">first</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1573" end_char="1576">wave</TOKEN>
<TOKEN id="token-10-14" pos="punct" morph="none" start_char="1577" end_char="1577">,</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1579" end_char="1581">but</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1583" end_char="1585">all</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1587" end_char="1592">tested</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1594" end_char="1601">positive</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1603" end_char="1605">for</TOKEN>
<TOKEN id="token-10-20" pos="unknown" morph="none" start_char="1607" end_char="1614">Covid-19</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1616" end_char="1625">antibodies</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1627" end_char="1628">at</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1630" end_char="1632">the</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1634" end_char="1638">point</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="1640" end_char="1641">of</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="1643" end_char="1653">recruitment</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="1655" end_char="1656">to</TOKEN>
<TOKEN id="token-10-28" pos="word" morph="none" start_char="1658" end_char="1660">the</TOKEN>
<TOKEN id="token-10-29" pos="word" morph="none" start_char="1662" end_char="1666">study</TOKEN>
<TOKEN id="token-10-30" pos="punct" morph="none" start_char="1667" end_char="1667">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1670" end_char="1862">
<ORIGINAL_TEXT>If all 44 cases were confirmed, it would represent an 83 per cent rate of protection from reinfection, while if only the 2 ‘probable’ reinfections were confirmed, the rate would be 99 per cent.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1670" end_char="1671">If</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1673" end_char="1675">all</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1677" end_char="1678">44</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1680" end_char="1684">cases</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1686" end_char="1689">were</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1691" end_char="1699">confirmed</TOKEN>
<TOKEN id="token-11-6" pos="punct" morph="none" start_char="1700" end_char="1700">,</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1702" end_char="1703">it</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1705" end_char="1709">would</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1711" end_char="1719">represent</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1721" end_char="1722">an</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1724" end_char="1725">83</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1727" end_char="1729">per</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1731" end_char="1734">cent</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1736" end_char="1739">rate</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1741" end_char="1742">of</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1744" end_char="1753">protection</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1755" end_char="1758">from</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1760" end_char="1770">reinfection</TOKEN>
<TOKEN id="token-11-19" pos="punct" morph="none" start_char="1771" end_char="1771">,</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1773" end_char="1777">while</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="1779" end_char="1780">if</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="1782" end_char="1785">only</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="1787" end_char="1789">the</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="1791" end_char="1791">2</TOKEN>
<TOKEN id="token-11-25" pos="punct" morph="none" start_char="1793" end_char="1793">‘</TOKEN>
<TOKEN id="token-11-26" pos="word" morph="none" start_char="1794" end_char="1801">probable</TOKEN>
<TOKEN id="token-11-27" pos="punct" morph="none" start_char="1802" end_char="1802">’</TOKEN>
<TOKEN id="token-11-28" pos="word" morph="none" start_char="1804" end_char="1815">reinfections</TOKEN>
<TOKEN id="token-11-29" pos="word" morph="none" start_char="1817" end_char="1820">were</TOKEN>
<TOKEN id="token-11-30" pos="word" morph="none" start_char="1822" end_char="1830">confirmed</TOKEN>
<TOKEN id="token-11-31" pos="punct" morph="none" start_char="1831" end_char="1831">,</TOKEN>
<TOKEN id="token-11-32" pos="word" morph="none" start_char="1833" end_char="1835">the</TOKEN>
<TOKEN id="token-11-33" pos="word" morph="none" start_char="1837" end_char="1840">rate</TOKEN>
<TOKEN id="token-11-34" pos="word" morph="none" start_char="1842" end_char="1846">would</TOKEN>
<TOKEN id="token-11-35" pos="word" morph="none" start_char="1848" end_char="1849">be</TOKEN>
<TOKEN id="token-11-36" pos="word" morph="none" start_char="1851" end_char="1852">99</TOKEN>
<TOKEN id="token-11-37" pos="word" morph="none" start_char="1854" end_char="1856">per</TOKEN>
<TOKEN id="token-11-38" pos="word" morph="none" start_char="1858" end_char="1861">cent</TOKEN>
<TOKEN id="token-11-39" pos="punct" morph="none" start_char="1862" end_char="1862">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1864" end_char="1923">
<ORIGINAL_TEXT>Further research is ongoing to clarify this range, says PHE.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1864" end_char="1870">Further</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1872" end_char="1879">research</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1881" end_char="1882">is</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1884" end_char="1890">ongoing</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1892" end_char="1893">to</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1895" end_char="1901">clarify</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1903" end_char="1906">this</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1908" end_char="1912">range</TOKEN>
<TOKEN id="token-12-8" pos="punct" morph="none" start_char="1913" end_char="1913">,</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1915" end_char="1918">says</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1920" end_char="1922">PHE</TOKEN>
<TOKEN id="token-12-11" pos="punct" morph="none" start_char="1923" end_char="1923">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1926" end_char="2152">
<ORIGINAL_TEXT>PHE cautions that this analysis occurred prior to the appearance of the new variant VOC202012/01, and says further work is underway to understand whether and to what extent antibodies provide protection against the new variant.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1926" end_char="1928">PHE</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1930" end_char="1937">cautions</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1939" end_char="1942">that</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1944" end_char="1947">this</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1949" end_char="1956">analysis</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1958" end_char="1965">occurred</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1967" end_char="1971">prior</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1973" end_char="1974">to</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1976" end_char="1978">the</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1980" end_char="1989">appearance</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1991" end_char="1992">of</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1994" end_char="1996">the</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1998" end_char="2000">new</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="2002" end_char="2008">variant</TOKEN>
<TOKEN id="token-13-14" pos="unknown" morph="none" start_char="2010" end_char="2021">VOC202012/01</TOKEN>
<TOKEN id="token-13-15" pos="punct" morph="none" start_char="2022" end_char="2022">,</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="2024" end_char="2026">and</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="2028" end_char="2031">says</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="2033" end_char="2039">further</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="2041" end_char="2044">work</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="2046" end_char="2047">is</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="2049" end_char="2056">underway</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="2058" end_char="2059">to</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="2061" end_char="2070">understand</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="2072" end_char="2078">whether</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="2080" end_char="2082">and</TOKEN>
<TOKEN id="token-13-26" pos="word" morph="none" start_char="2084" end_char="2085">to</TOKEN>
<TOKEN id="token-13-27" pos="word" morph="none" start_char="2087" end_char="2090">what</TOKEN>
<TOKEN id="token-13-28" pos="word" morph="none" start_char="2092" end_char="2097">extent</TOKEN>
<TOKEN id="token-13-29" pos="word" morph="none" start_char="2099" end_char="2108">antibodies</TOKEN>
<TOKEN id="token-13-30" pos="word" morph="none" start_char="2110" end_char="2116">provide</TOKEN>
<TOKEN id="token-13-31" pos="word" morph="none" start_char="2118" end_char="2127">protection</TOKEN>
<TOKEN id="token-13-32" pos="word" morph="none" start_char="2129" end_char="2135">against</TOKEN>
<TOKEN id="token-13-33" pos="word" morph="none" start_char="2137" end_char="2139">the</TOKEN>
<TOKEN id="token-13-34" pos="word" morph="none" start_char="2141" end_char="2143">new</TOKEN>
<TOKEN id="token-13-35" pos="word" morph="none" start_char="2145" end_char="2151">variant</TOKEN>
<TOKEN id="token-13-36" pos="punct" morph="none" start_char="2152" end_char="2152">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="2155" end_char="2369">
<ORIGINAL_TEXT>The study will continue to follow participants for 12 months to explore how long any immunity may last, the effectiveness of vaccines and to what extent people with immunity are able to carry and transmit the virus.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="2155" end_char="2157">The</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="2159" end_char="2163">study</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="2165" end_char="2168">will</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="2170" end_char="2177">continue</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="2179" end_char="2180">to</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="2182" end_char="2187">follow</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="2189" end_char="2200">participants</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="2202" end_char="2204">for</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="2206" end_char="2207">12</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="2209" end_char="2214">months</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="2216" end_char="2217">to</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="2219" end_char="2225">explore</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="2227" end_char="2229">how</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="2231" end_char="2234">long</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="2236" end_char="2238">any</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="2240" end_char="2247">immunity</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="2249" end_char="2251">may</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="2253" end_char="2256">last</TOKEN>
<TOKEN id="token-14-18" pos="punct" morph="none" start_char="2257" end_char="2257">,</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="2259" end_char="2261">the</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="2263" end_char="2275">effectiveness</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="2277" end_char="2278">of</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="2280" end_char="2287">vaccines</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="2289" end_char="2291">and</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="2293" end_char="2294">to</TOKEN>
<TOKEN id="token-14-25" pos="word" morph="none" start_char="2296" end_char="2299">what</TOKEN>
<TOKEN id="token-14-26" pos="word" morph="none" start_char="2301" end_char="2306">extent</TOKEN>
<TOKEN id="token-14-27" pos="word" morph="none" start_char="2308" end_char="2313">people</TOKEN>
<TOKEN id="token-14-28" pos="word" morph="none" start_char="2315" end_char="2318">with</TOKEN>
<TOKEN id="token-14-29" pos="word" morph="none" start_char="2320" end_char="2327">immunity</TOKEN>
<TOKEN id="token-14-30" pos="word" morph="none" start_char="2329" end_char="2331">are</TOKEN>
<TOKEN id="token-14-31" pos="word" morph="none" start_char="2333" end_char="2336">able</TOKEN>
<TOKEN id="token-14-32" pos="word" morph="none" start_char="2338" end_char="2339">to</TOKEN>
<TOKEN id="token-14-33" pos="word" morph="none" start_char="2341" end_char="2345">carry</TOKEN>
<TOKEN id="token-14-34" pos="word" morph="none" start_char="2347" end_char="2349">and</TOKEN>
<TOKEN id="token-14-35" pos="word" morph="none" start_char="2351" end_char="2358">transmit</TOKEN>
<TOKEN id="token-14-36" pos="word" morph="none" start_char="2360" end_char="2362">the</TOKEN>
<TOKEN id="token-14-37" pos="word" morph="none" start_char="2364" end_char="2368">virus</TOKEN>
<TOKEN id="token-14-38" pos="punct" morph="none" start_char="2369" end_char="2369">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
