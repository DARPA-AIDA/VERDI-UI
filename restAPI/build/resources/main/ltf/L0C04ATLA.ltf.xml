<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATLA" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="2351" raw_text_md5="a2df7c54eb0dc8bd88f68b9a6be970e0">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="45">
<ORIGINAL_TEXT>Is using UV light to kill Covid-19 effective?</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="2">Is</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="4" end_char="8">using</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="10" end_char="11">UV</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="13" end_char="17">light</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="19" end_char="20">to</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="22" end_char="25">kill</TOKEN>
<TOKEN id="token-0-6" pos="unknown" morph="none" start_char="27" end_char="34">Covid-19</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="36" end_char="44">effective</TOKEN>
<TOKEN id="token-0-8" pos="punct" morph="none" start_char="45" end_char="45">?</TOKEN>
</SEG>
<SEG id="segment-1" start_char="49" end_char="57">
<ORIGINAL_TEXT>Dear all,</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="49" end_char="52">Dear</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="54" end_char="56">all</TOKEN>
<TOKEN id="token-1-2" pos="punct" morph="none" start_char="57" end_char="57">,</TOKEN>
</SEG>
<SEG id="segment-2" start_char="60" end_char="173">
<ORIGINAL_TEXT>My company is planning to keep new equipment in a closed room under UV light for 24hrs in order to kill any covid.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="60" end_char="61">My</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="63" end_char="69">company</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="71" end_char="72">is</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="74" end_char="81">planning</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="83" end_char="84">to</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="86" end_char="89">keep</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="91" end_char="93">new</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="95" end_char="103">equipment</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="105" end_char="106">in</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="108" end_char="108">a</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="110" end_char="115">closed</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="117" end_char="120">room</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="122" end_char="126">under</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="128" end_char="129">UV</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="131" end_char="135">light</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="137" end_char="139">for</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="141" end_char="145">24hrs</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="147" end_char="148">in</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="150" end_char="154">order</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="156" end_char="157">to</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="159" end_char="162">kill</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="164" end_char="166">any</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="168" end_char="172">covid</TOKEN>
<TOKEN id="token-2-23" pos="punct" morph="none" start_char="173" end_char="173">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="175" end_char="205">
<ORIGINAL_TEXT>is such method effective THANKS</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="175" end_char="176">is</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="178" end_char="181">such</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="183" end_char="188">method</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="190" end_char="198">effective</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="200" end_char="205">THANKS</TOKEN>
</SEG>
<SEG id="segment-4" start_char="209" end_char="297">
<ORIGINAL_TEXT>It seems there could be potential - article extract below - , for equipment use at least.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="209" end_char="210">It</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="212" end_char="216">seems</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="218" end_char="222">there</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="224" end_char="228">could</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="230" end_char="231">be</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="233" end_char="241">potential</TOKEN>
<TOKEN id="token-4-6" pos="punct" morph="none" start_char="243" end_char="243">-</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="245" end_char="251">article</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="253" end_char="259">extract</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="261" end_char="265">below</TOKEN>
<TOKEN id="token-4-10" pos="punct" morph="none" start_char="267" end_char="267">-</TOKEN>
<TOKEN id="token-4-11" pos="punct" morph="none" start_char="269" end_char="269">,</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="271" end_char="273">for</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="275" end_char="283">equipment</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="285" end_char="287">use</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="289" end_char="290">at</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="292" end_char="296">least</TOKEN>
<TOKEN id="token-4-17" pos="punct" morph="none" start_char="297" end_char="297">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="299" end_char="481">
<ORIGINAL_TEXT>Personally I'd research thoroughly to establish the effectivity and method and then risk assess to weigh up the cost/benefit against risks especially given the severity of UVC misuse.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="299" end_char="308">Personally</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="310" end_char="312">I'd</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="314" end_char="321">research</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="323" end_char="332">thoroughly</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="334" end_char="335">to</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="337" end_char="345">establish</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="347" end_char="349">the</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="351" end_char="361">effectivity</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="363" end_char="365">and</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="367" end_char="372">method</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="374" end_char="376">and</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="378" end_char="381">then</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="383" end_char="386">risk</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="388" end_char="393">assess</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="395" end_char="396">to</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="398" end_char="402">weigh</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="404" end_char="405">up</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="407" end_char="409">the</TOKEN>
<TOKEN id="token-5-18" pos="unknown" morph="none" start_char="411" end_char="422">cost/benefit</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="424" end_char="430">against</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="432" end_char="436">risks</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="438" end_char="447">especially</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="449" end_char="453">given</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="455" end_char="457">the</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="459" end_char="466">severity</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="468" end_char="469">of</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="471" end_char="473">UVC</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="475" end_char="480">misuse</TOKEN>
<TOKEN id="token-5-28" pos="punct" morph="none" start_char="481" end_char="481">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="483" end_char="650">
<ORIGINAL_TEXT>I.e if it is the case that the likliness of transmission of Covid-19 on equipment is low whereas the cost of the operation including H is high it may not be worthwhile.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="unknown" morph="none" start_char="483" end_char="485">I.e</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="487" end_char="488">if</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="490" end_char="491">it</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="493" end_char="494">is</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="496" end_char="498">the</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="500" end_char="503">case</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="505" end_char="508">that</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="510" end_char="512">the</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="514" end_char="522">likliness</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="524" end_char="525">of</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="527" end_char="538">transmission</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="540" end_char="541">of</TOKEN>
<TOKEN id="token-6-12" pos="unknown" morph="none" start_char="543" end_char="550">Covid-19</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="552" end_char="553">on</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="555" end_char="563">equipment</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="565" end_char="566">is</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="568" end_char="570">low</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="572" end_char="578">whereas</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="580" end_char="582">the</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="584" end_char="587">cost</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="589" end_char="590">of</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="592" end_char="594">the</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="596" end_char="604">operation</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="606" end_char="614">including</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="616" end_char="616">H</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="618" end_char="619">is</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="621" end_char="624">high</TOKEN>
<TOKEN id="token-6-27" pos="word" morph="none" start_char="626" end_char="627">it</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="629" end_char="631">may</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="633" end_char="635">not</TOKEN>
<TOKEN id="token-6-30" pos="word" morph="none" start_char="637" end_char="638">be</TOKEN>
<TOKEN id="token-6-31" pos="word" morph="none" start_char="640" end_char="649">worthwhile</TOKEN>
<TOKEN id="token-6-32" pos="punct" morph="none" start_char="650" end_char="650">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="653" end_char="684">
<ORIGINAL_TEXT>There is also a third type: UVC.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="653" end_char="657">There</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="659" end_char="660">is</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="662" end_char="665">also</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="667" end_char="667">a</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="669" end_char="673">third</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="675" end_char="678">type</TOKEN>
<TOKEN id="token-7-6" pos="punct" morph="none" start_char="679" end_char="679">:</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="681" end_char="683">UVC</TOKEN>
<TOKEN id="token-7-8" pos="punct" morph="none" start_char="684" end_char="684">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="686" end_char="788">
<ORIGINAL_TEXT>This relatively obscure part of the spectrum consists of a shorter, more energetic wavelength of light.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="686" end_char="689">This</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="691" end_char="700">relatively</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="702" end_char="708">obscure</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="710" end_char="713">part</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="715" end_char="716">of</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="718" end_char="720">the</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="722" end_char="729">spectrum</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="731" end_char="738">consists</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="740" end_char="741">of</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="743" end_char="743">a</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="745" end_char="751">shorter</TOKEN>
<TOKEN id="token-8-11" pos="punct" morph="none" start_char="752" end_char="752">,</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="754" end_char="757">more</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="759" end_char="767">energetic</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="769" end_char="778">wavelength</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="780" end_char="781">of</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="783" end_char="787">light</TOKEN>
<TOKEN id="token-8-17" pos="punct" morph="none" start_char="788" end_char="788">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="790" end_char="883">
<ORIGINAL_TEXT>It is particularly good at destroying genetic material – whether in humans or viral particles.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="790" end_char="791">It</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="793" end_char="794">is</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="796" end_char="807">particularly</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="809" end_char="812">good</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="814" end_char="815">at</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="817" end_char="826">destroying</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="828" end_char="834">genetic</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="836" end_char="843">material</TOKEN>
<TOKEN id="token-9-8" pos="punct" morph="none" start_char="845" end_char="845">–</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="847" end_char="853">whether</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="855" end_char="856">in</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="858" end_char="863">humans</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="865" end_char="866">or</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="868" end_char="872">viral</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="874" end_char="882">particles</TOKEN>
<TOKEN id="token-9-15" pos="punct" morph="none" start_char="883" end_char="883">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="885" end_char="946">
<ORIGINAL_TEXT>Luckily, most of us are unlikely to have ever encountered any.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="885" end_char="891">Luckily</TOKEN>
<TOKEN id="token-10-1" pos="punct" morph="none" start_char="892" end_char="892">,</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="894" end_char="897">most</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="899" end_char="900">of</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="902" end_char="903">us</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="905" end_char="907">are</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="909" end_char="916">unlikely</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="918" end_char="919">to</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="921" end_char="924">have</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="926" end_char="929">ever</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="931" end_char="941">encountered</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="943" end_char="945">any</TOKEN>
<TOKEN id="token-10-12" pos="punct" morph="none" start_char="946" end_char="946">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="948" end_char="1047">
<ORIGINAL_TEXT>That’s because it’s filtered out by ozone in the atmosphere long before it reaches our fragile skin.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="948" end_char="953">That’s</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="955" end_char="961">because</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="963" end_char="966">it’s</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="968" end_char="975">filtered</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="977" end_char="979">out</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="981" end_char="982">by</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="984" end_char="988">ozone</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="990" end_char="991">in</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="993" end_char="995">the</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="997" end_char="1006">atmosphere</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1008" end_char="1011">long</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1013" end_char="1018">before</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1020" end_char="1021">it</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1023" end_char="1029">reaches</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1031" end_char="1033">our</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1035" end_char="1041">fragile</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1043" end_char="1046">skin</TOKEN>
<TOKEN id="token-11-17" pos="punct" morph="none" start_char="1047" end_char="1047">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1050" end_char="1160">
<ORIGINAL_TEXT>Or that was the case, at least, until scientists discovered that they could harness UVC to kill microorganisms.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1050" end_char="1051">Or</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1053" end_char="1056">that</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1058" end_char="1060">was</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1062" end_char="1064">the</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1066" end_char="1069">case</TOKEN>
<TOKEN id="token-12-5" pos="punct" morph="none" start_char="1070" end_char="1070">,</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1072" end_char="1073">at</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1075" end_char="1079">least</TOKEN>
<TOKEN id="token-12-8" pos="punct" morph="none" start_char="1080" end_char="1080">,</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1082" end_char="1086">until</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1088" end_char="1097">scientists</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1099" end_char="1108">discovered</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1110" end_char="1113">that</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1115" end_char="1118">they</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1120" end_char="1124">could</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1126" end_char="1132">harness</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1134" end_char="1136">UVC</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1138" end_char="1139">to</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1141" end_char="1144">kill</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1146" end_char="1159">microorganisms</TOKEN>
<TOKEN id="token-12-20" pos="punct" morph="none" start_char="1160" end_char="1160">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1162" end_char="1327">
<ORIGINAL_TEXT>Since the finding in 1878, artificially produced UVC has become a staple method of sterilisation – one used in hospitals, airplanes, offices, and factories every day.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1162" end_char="1166">Since</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1168" end_char="1170">the</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1172" end_char="1178">finding</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1180" end_char="1181">in</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1183" end_char="1186">1878</TOKEN>
<TOKEN id="token-13-5" pos="punct" morph="none" start_char="1187" end_char="1187">,</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1189" end_char="1200">artificially</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1202" end_char="1209">produced</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1211" end_char="1213">UVC</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1215" end_char="1217">has</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1219" end_char="1224">become</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1226" end_char="1226">a</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1228" end_char="1233">staple</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1235" end_char="1240">method</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1242" end_char="1243">of</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1245" end_char="1257">sterilisation</TOKEN>
<TOKEN id="token-13-16" pos="punct" morph="none" start_char="1259" end_char="1259">–</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1261" end_char="1263">one</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1265" end_char="1268">used</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1270" end_char="1271">in</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1273" end_char="1281">hospitals</TOKEN>
<TOKEN id="token-13-21" pos="punct" morph="none" start_char="1282" end_char="1282">,</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="1284" end_char="1292">airplanes</TOKEN>
<TOKEN id="token-13-23" pos="punct" morph="none" start_char="1293" end_char="1293">,</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="1295" end_char="1301">offices</TOKEN>
<TOKEN id="token-13-25" pos="punct" morph="none" start_char="1302" end_char="1302">,</TOKEN>
<TOKEN id="token-13-26" pos="word" morph="none" start_char="1304" end_char="1306">and</TOKEN>
<TOKEN id="token-13-27" pos="word" morph="none" start_char="1308" end_char="1316">factories</TOKEN>
<TOKEN id="token-13-28" pos="word" morph="none" start_char="1318" end_char="1322">every</TOKEN>
<TOKEN id="token-13-29" pos="word" morph="none" start_char="1324" end_char="1326">day</TOKEN>
<TOKEN id="token-13-30" pos="punct" morph="none" start_char="1327" end_char="1327">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1329" end_char="1505">
<ORIGINAL_TEXT>Crucially, it’s also fundamental to the process of sanitising drinking water; some parasites are resistant to chemical disinfectants such as chlorine, so it provides a failsafe.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1329" end_char="1337">Crucially</TOKEN>
<TOKEN id="token-14-1" pos="punct" morph="none" start_char="1338" end_char="1338">,</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1340" end_char="1343">it’s</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1345" end_char="1348">also</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1350" end_char="1360">fundamental</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1362" end_char="1363">to</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1365" end_char="1367">the</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1369" end_char="1375">process</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1377" end_char="1378">of</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1380" end_char="1389">sanitising</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1391" end_char="1398">drinking</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1400" end_char="1404">water</TOKEN>
<TOKEN id="token-14-12" pos="punct" morph="none" start_char="1405" end_char="1405">;</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1407" end_char="1410">some</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="1412" end_char="1420">parasites</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1422" end_char="1424">are</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1426" end_char="1434">resistant</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="1436" end_char="1437">to</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="1439" end_char="1446">chemical</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="1448" end_char="1460">disinfectants</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="1462" end_char="1465">such</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="1467" end_char="1468">as</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="1470" end_char="1477">chlorine</TOKEN>
<TOKEN id="token-14-23" pos="punct" morph="none" start_char="1478" end_char="1478">,</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="1480" end_char="1481">so</TOKEN>
<TOKEN id="token-14-25" pos="word" morph="none" start_char="1483" end_char="1484">it</TOKEN>
<TOKEN id="token-14-26" pos="word" morph="none" start_char="1486" end_char="1493">provides</TOKEN>
<TOKEN id="token-14-27" pos="word" morph="none" start_char="1495" end_char="1495">a</TOKEN>
<TOKEN id="token-14-28" pos="word" morph="none" start_char="1497" end_char="1504">failsafe</TOKEN>
<TOKEN id="token-14-29" pos="punct" morph="none" start_char="1505" end_char="1505">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1508" end_char="1676">
<ORIGINAL_TEXT>Though there hasn’t been any research looking at how UVC affects Covid-19 specifically, studies have shown that it can be used against other coronaviruses, such as Sars.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1508" end_char="1513">Though</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1515" end_char="1519">there</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1521" end_char="1526">hasn’t</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1528" end_char="1531">been</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1533" end_char="1535">any</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1537" end_char="1544">research</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1546" end_char="1552">looking</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1554" end_char="1555">at</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1557" end_char="1559">how</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1561" end_char="1563">UVC</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1565" end_char="1571">affects</TOKEN>
<TOKEN id="token-15-11" pos="unknown" morph="none" start_char="1573" end_char="1580">Covid-19</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1582" end_char="1593">specifically</TOKEN>
<TOKEN id="token-15-13" pos="punct" morph="none" start_char="1594" end_char="1594">,</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1596" end_char="1602">studies</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="1604" end_char="1607">have</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="1609" end_char="1613">shown</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="1615" end_char="1618">that</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="1620" end_char="1621">it</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="1623" end_char="1625">can</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="1627" end_char="1628">be</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="1630" end_char="1633">used</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="1635" end_char="1641">against</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="1643" end_char="1647">other</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="1649" end_char="1661">coronaviruses</TOKEN>
<TOKEN id="token-15-25" pos="punct" morph="none" start_char="1662" end_char="1662">,</TOKEN>
<TOKEN id="token-15-26" pos="word" morph="none" start_char="1664" end_char="1667">such</TOKEN>
<TOKEN id="token-15-27" pos="word" morph="none" start_char="1669" end_char="1670">as</TOKEN>
<TOKEN id="token-15-28" pos="word" morph="none" start_char="1672" end_char="1675">Sars</TOKEN>
<TOKEN id="token-15-29" pos="punct" morph="none" start_char="1676" end_char="1676">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1678" end_char="1808">
<ORIGINAL_TEXT>The radiation warps the structure of their genetic material and prevents the viral particles from making more copies of themselves.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1678" end_char="1680">The</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1682" end_char="1690">radiation</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1692" end_char="1696">warps</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1698" end_char="1700">the</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1702" end_char="1710">structure</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1712" end_char="1713">of</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1715" end_char="1719">their</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1721" end_char="1727">genetic</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1729" end_char="1736">material</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="1738" end_char="1740">and</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="1742" end_char="1749">prevents</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="1751" end_char="1753">the</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="1755" end_char="1759">viral</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="1761" end_char="1769">particles</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="1771" end_char="1774">from</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="1776" end_char="1781">making</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="1783" end_char="1786">more</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="1788" end_char="1793">copies</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="1795" end_char="1796">of</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="1798" end_char="1807">themselves</TOKEN>
<TOKEN id="token-16-20" pos="punct" morph="none" start_char="1808" end_char="1808">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1811" end_char="1905">
<ORIGINAL_TEXT>As a result, a concentrated form of UVC is now on the front line in the fight against Covid-19.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1811" end_char="1812">As</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1814" end_char="1814">a</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="1816" end_char="1821">result</TOKEN>
<TOKEN id="token-17-3" pos="punct" morph="none" start_char="1822" end_char="1822">,</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="1824" end_char="1824">a</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="1826" end_char="1837">concentrated</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="1839" end_char="1842">form</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="1844" end_char="1845">of</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="1847" end_char="1849">UVC</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="1851" end_char="1852">is</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="1854" end_char="1856">now</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="1858" end_char="1859">on</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="1861" end_char="1863">the</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="1865" end_char="1869">front</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="1871" end_char="1874">line</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="1876" end_char="1877">in</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="1879" end_char="1881">the</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="1883" end_char="1887">fight</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="1889" end_char="1895">against</TOKEN>
<TOKEN id="token-17-19" pos="unknown" morph="none" start_char="1897" end_char="1904">Covid-19</TOKEN>
<TOKEN id="token-17-20" pos="punct" morph="none" start_char="1905" end_char="1905">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1907" end_char="2055">
<ORIGINAL_TEXT>In China, whole buses are being lit up by the ghostly blue light each night, while squat, UVC-emitting robots have been cleaning floors in hospitals.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="1907" end_char="1908">In</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="1910" end_char="1914">China</TOKEN>
<TOKEN id="token-18-2" pos="punct" morph="none" start_char="1915" end_char="1915">,</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="1917" end_char="1921">whole</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="1923" end_char="1927">buses</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="1929" end_char="1931">are</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="1933" end_char="1937">being</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="1939" end_char="1941">lit</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="1943" end_char="1944">up</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="1946" end_char="1947">by</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="1949" end_char="1951">the</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="1953" end_char="1959">ghostly</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="1961" end_char="1964">blue</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="1966" end_char="1970">light</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="1972" end_char="1975">each</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="1977" end_char="1981">night</TOKEN>
<TOKEN id="token-18-16" pos="punct" morph="none" start_char="1982" end_char="1982">,</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="1984" end_char="1988">while</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="1990" end_char="1994">squat</TOKEN>
<TOKEN id="token-18-19" pos="punct" morph="none" start_char="1995" end_char="1995">,</TOKEN>
<TOKEN id="token-18-20" pos="unknown" morph="none" start_char="1997" end_char="2008">UVC-emitting</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="2010" end_char="2015">robots</TOKEN>
<TOKEN id="token-18-22" pos="word" morph="none" start_char="2017" end_char="2020">have</TOKEN>
<TOKEN id="token-18-23" pos="word" morph="none" start_char="2022" end_char="2025">been</TOKEN>
<TOKEN id="token-18-24" pos="word" morph="none" start_char="2027" end_char="2034">cleaning</TOKEN>
<TOKEN id="token-18-25" pos="word" morph="none" start_char="2036" end_char="2041">floors</TOKEN>
<TOKEN id="token-18-26" pos="word" morph="none" start_char="2043" end_char="2044">in</TOKEN>
<TOKEN id="token-18-27" pos="word" morph="none" start_char="2046" end_char="2054">hospitals</TOKEN>
<TOKEN id="token-18-28" pos="punct" morph="none" start_char="2055" end_char="2055">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2057" end_char="2118">
<ORIGINAL_TEXT>Banks have even been using the light to disinfect their money.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2057" end_char="2061">Banks</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2063" end_char="2066">have</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2068" end_char="2071">even</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2073" end_char="2076">been</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2078" end_char="2082">using</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2084" end_char="2086">the</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2088" end_char="2092">light</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2094" end_char="2095">to</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2097" end_char="2105">disinfect</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="2107" end_char="2111">their</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="2113" end_char="2117">money</TOKEN>
<TOKEN id="token-19-11" pos="punct" morph="none" start_char="2118" end_char="2118">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2122" end_char="2159">
<ORIGINAL_TEXT>https://www.bbc.com/...s-with-uv-light</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="url" morph="none" start_char="2122" end_char="2159">https://www.bbc.com/...s-with-uv-light</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2162" end_char="2206">
<ORIGINAL_TEXT>Edited by zanorias, 13 April 2020 - 07:55 AM.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2162" end_char="2167">Edited</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2169" end_char="2170">by</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2172" end_char="2179">zanorias</TOKEN>
<TOKEN id="token-21-3" pos="punct" morph="none" start_char="2180" end_char="2180">,</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2182" end_char="2183">13</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="2185" end_char="2189">April</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2191" end_char="2194">2020</TOKEN>
<TOKEN id="token-21-7" pos="punct" morph="none" start_char="2196" end_char="2196">-</TOKEN>
<TOKEN id="token-21-8" pos="unknown" morph="none" start_char="2198" end_char="2202">07:55</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="2204" end_char="2205">AM</TOKEN>
<TOKEN id="token-21-10" pos="punct" morph="none" start_char="2206" end_char="2206">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2210" end_char="2222">
<ORIGINAL_TEXT>Many thanks:)</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2210" end_char="2213">Many</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2215" end_char="2220">thanks</TOKEN>
<TOKEN id="token-22-2" pos="punct" morph="none" start_char="2221" end_char="2222">:)</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2226" end_char="2243">
<ORIGINAL_TEXT>We're using Ozone.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2226" end_char="2230">We're</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2232" end_char="2236">using</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2238" end_char="2242">Ozone</TOKEN>
<TOKEN id="token-23-3" pos="punct" morph="none" start_char="2243" end_char="2243">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2246" end_char="2283">
<ORIGINAL_TEXT>https://www.aeroqual...avirus-covid-19</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="url" morph="none" start_char="2246" end_char="2283">https://www.aeroqual...avirus-covid-19</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2287" end_char="2296">
<ORIGINAL_TEXT>thanks all</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="2287" end_char="2292">thanks</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="2294" end_char="2296">all</TOKEN>
</SEG>
<SEG id="segment-26" start_char="2299" end_char="2347">
<ORIGINAL_TEXT>can we put carton boxes and plastic bags under UV</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="2299" end_char="2301">can</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="2303" end_char="2304">we</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="2306" end_char="2308">put</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="2310" end_char="2315">carton</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="2317" end_char="2321">boxes</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="2323" end_char="2325">and</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="2327" end_char="2333">plastic</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="2335" end_char="2338">bags</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="2340" end_char="2344">under</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="2346" end_char="2347">UV</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
