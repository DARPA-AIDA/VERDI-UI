<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="eng">
<DOC id="L0C049DZL" lang="eng" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="3832" raw_text_md5="d7d62a4baa4c9d70342f01bb7820371d">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="47">
<ORIGINAL_TEXT>Chinese Officials Blame US Army for Coronavirus</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="7">Chinese</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="9" end_char="17">Officials</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="19" end_char="23">Blame</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="25" end_char="26">US</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="28" end_char="31">Army</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="33" end_char="35">for</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="37" end_char="47">Coronavirus</TOKEN>
</SEG>
<SEG id="segment-1" start_char="51" end_char="278">
<ORIGINAL_TEXT>A Chinese official who has a history of attacking the United States online has lent a voice to a conspiracy theory that blames American soldiers for bringing COVID-19 to China, though the science does not support that narrative.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="51" end_char="51">A</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="53" end_char="59">Chinese</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="61" end_char="68">official</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="70" end_char="72">who</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="74" end_char="76">has</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="78" end_char="78">a</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="80" end_char="86">history</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="88" end_char="89">of</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="91" end_char="99">attacking</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="101" end_char="103">the</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="105" end_char="110">United</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="112" end_char="117">States</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="119" end_char="124">online</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="126" end_char="128">has</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="130" end_char="133">lent</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="135" end_char="135">a</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="137" end_char="141">voice</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="143" end_char="144">to</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="146" end_char="146">a</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="148" end_char="157">conspiracy</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="159" end_char="164">theory</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="166" end_char="169">that</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="171" end_char="176">blames</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="178" end_char="185">American</TOKEN>
<TOKEN id="token-1-24" pos="word" morph="none" start_char="187" end_char="194">soldiers</TOKEN>
<TOKEN id="token-1-25" pos="word" morph="none" start_char="196" end_char="198">for</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="200" end_char="207">bringing</TOKEN>
<TOKEN id="token-1-27" pos="unknown" morph="none" start_char="209" end_char="216">COVID-19</TOKEN>
<TOKEN id="token-1-28" pos="word" morph="none" start_char="218" end_char="219">to</TOKEN>
<TOKEN id="token-1-29" pos="word" morph="none" start_char="221" end_char="225">China</TOKEN>
<TOKEN id="token-1-30" pos="punct" morph="none" start_char="226" end_char="226">,</TOKEN>
<TOKEN id="token-1-31" pos="word" morph="none" start_char="228" end_char="233">though</TOKEN>
<TOKEN id="token-1-32" pos="word" morph="none" start_char="235" end_char="237">the</TOKEN>
<TOKEN id="token-1-33" pos="word" morph="none" start_char="239" end_char="245">science</TOKEN>
<TOKEN id="token-1-34" pos="word" morph="none" start_char="247" end_char="250">does</TOKEN>
<TOKEN id="token-1-35" pos="word" morph="none" start_char="252" end_char="254">not</TOKEN>
<TOKEN id="token-1-36" pos="word" morph="none" start_char="256" end_char="262">support</TOKEN>
<TOKEN id="token-1-37" pos="word" morph="none" start_char="264" end_char="267">that</TOKEN>
<TOKEN id="token-1-38" pos="word" morph="none" start_char="269" end_char="277">narrative</TOKEN>
<TOKEN id="token-1-39" pos="punct" morph="none" start_char="278" end_char="278">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="281" end_char="604">
<ORIGINAL_TEXT>According to the unfounded accusation, which reports say has been widely shared on the popular Chinese social media platform Weibo, the novel coronavirus SARS-CoV-2 was introduced to China when 300 US military members arrived in the Wuhan region for the Military World Games in mid-October and infected the local population.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="281" end_char="289">According</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="291" end_char="292">to</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="294" end_char="296">the</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="298" end_char="306">unfounded</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="308" end_char="317">accusation</TOKEN>
<TOKEN id="token-2-5" pos="punct" morph="none" start_char="318" end_char="318">,</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="320" end_char="324">which</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="326" end_char="332">reports</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="334" end_char="336">say</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="338" end_char="340">has</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="342" end_char="345">been</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="347" end_char="352">widely</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="354" end_char="359">shared</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="361" end_char="362">on</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="364" end_char="366">the</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="368" end_char="374">popular</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="376" end_char="382">Chinese</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="384" end_char="389">social</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="391" end_char="395">media</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="397" end_char="404">platform</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="406" end_char="410">Weibo</TOKEN>
<TOKEN id="token-2-21" pos="punct" morph="none" start_char="411" end_char="411">,</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="413" end_char="415">the</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="417" end_char="421">novel</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="423" end_char="433">coronavirus</TOKEN>
<TOKEN id="token-2-25" pos="unknown" morph="none" start_char="435" end_char="444">SARS-CoV-2</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="446" end_char="448">was</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="450" end_char="459">introduced</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="461" end_char="462">to</TOKEN>
<TOKEN id="token-2-29" pos="word" morph="none" start_char="464" end_char="468">China</TOKEN>
<TOKEN id="token-2-30" pos="word" morph="none" start_char="470" end_char="473">when</TOKEN>
<TOKEN id="token-2-31" pos="word" morph="none" start_char="475" end_char="477">300</TOKEN>
<TOKEN id="token-2-32" pos="word" morph="none" start_char="479" end_char="480">US</TOKEN>
<TOKEN id="token-2-33" pos="word" morph="none" start_char="482" end_char="489">military</TOKEN>
<TOKEN id="token-2-34" pos="word" morph="none" start_char="491" end_char="497">members</TOKEN>
<TOKEN id="token-2-35" pos="word" morph="none" start_char="499" end_char="505">arrived</TOKEN>
<TOKEN id="token-2-36" pos="word" morph="none" start_char="507" end_char="508">in</TOKEN>
<TOKEN id="token-2-37" pos="word" morph="none" start_char="510" end_char="512">the</TOKEN>
<TOKEN id="token-2-38" pos="word" morph="none" start_char="514" end_char="518">Wuhan</TOKEN>
<TOKEN id="token-2-39" pos="word" morph="none" start_char="520" end_char="525">region</TOKEN>
<TOKEN id="token-2-40" pos="word" morph="none" start_char="527" end_char="529">for</TOKEN>
<TOKEN id="token-2-41" pos="word" morph="none" start_char="531" end_char="533">the</TOKEN>
<TOKEN id="token-2-42" pos="word" morph="none" start_char="535" end_char="542">Military</TOKEN>
<TOKEN id="token-2-43" pos="word" morph="none" start_char="544" end_char="548">World</TOKEN>
<TOKEN id="token-2-44" pos="word" morph="none" start_char="550" end_char="554">Games</TOKEN>
<TOKEN id="token-2-45" pos="word" morph="none" start_char="556" end_char="557">in</TOKEN>
<TOKEN id="token-2-46" pos="unknown" morph="none" start_char="559" end_char="569">mid-October</TOKEN>
<TOKEN id="token-2-47" pos="word" morph="none" start_char="571" end_char="573">and</TOKEN>
<TOKEN id="token-2-48" pos="word" morph="none" start_char="575" end_char="582">infected</TOKEN>
<TOKEN id="token-2-49" pos="word" morph="none" start_char="584" end_char="586">the</TOKEN>
<TOKEN id="token-2-50" pos="word" morph="none" start_char="588" end_char="592">local</TOKEN>
<TOKEN id="token-2-51" pos="word" morph="none" start_char="594" end_char="603">population</TOKEN>
<TOKEN id="token-2-52" pos="punct" morph="none" start_char="604" end_char="604">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="606" end_char="685">
<ORIGINAL_TEXT>None of the servicemembers who made the trip have tested positive for the virus.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="606" end_char="609">None</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="611" end_char="612">of</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="614" end_char="616">the</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="618" end_char="631">servicemembers</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="633" end_char="635">who</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="637" end_char="640">made</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="642" end_char="644">the</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="646" end_char="649">trip</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="651" end_char="654">have</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="656" end_char="661">tested</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="663" end_char="670">positive</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="672" end_char="674">for</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="676" end_char="678">the</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="680" end_char="684">virus</TOKEN>
<TOKEN id="token-3-14" pos="punct" morph="none" start_char="685" end_char="685">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="688" end_char="936">
<ORIGINAL_TEXT>The rumors seemed to begin when Chinese respiratory specialist Zhong Nanshan stated at a February press conference that "though the COVID-19 was first discovered in China, it does not mean that it originated from China," planting the seeds of doubt.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="688" end_char="690">The</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="692" end_char="697">rumors</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="699" end_char="704">seemed</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="706" end_char="707">to</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="709" end_char="713">begin</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="715" end_char="718">when</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="720" end_char="726">Chinese</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="728" end_char="738">respiratory</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="740" end_char="749">specialist</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="751" end_char="755">Zhong</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="757" end_char="763">Nanshan</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="765" end_char="770">stated</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="772" end_char="773">at</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="775" end_char="775">a</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="777" end_char="784">February</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="786" end_char="790">press</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="792" end_char="801">conference</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="803" end_char="806">that</TOKEN>
<TOKEN id="token-4-18" pos="punct" morph="none" start_char="808" end_char="808">"</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="809" end_char="814">though</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="816" end_char="818">the</TOKEN>
<TOKEN id="token-4-21" pos="unknown" morph="none" start_char="820" end_char="827">COVID-19</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="829" end_char="831">was</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="833" end_char="837">first</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="839" end_char="848">discovered</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="850" end_char="851">in</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="853" end_char="857">China</TOKEN>
<TOKEN id="token-4-27" pos="punct" morph="none" start_char="858" end_char="858">,</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="860" end_char="861">it</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="863" end_char="866">does</TOKEN>
<TOKEN id="token-4-30" pos="word" morph="none" start_char="868" end_char="870">not</TOKEN>
<TOKEN id="token-4-31" pos="word" morph="none" start_char="872" end_char="875">mean</TOKEN>
<TOKEN id="token-4-32" pos="word" morph="none" start_char="877" end_char="880">that</TOKEN>
<TOKEN id="token-4-33" pos="word" morph="none" start_char="882" end_char="883">it</TOKEN>
<TOKEN id="token-4-34" pos="word" morph="none" start_char="885" end_char="894">originated</TOKEN>
<TOKEN id="token-4-35" pos="word" morph="none" start_char="896" end_char="899">from</TOKEN>
<TOKEN id="token-4-36" pos="word" morph="none" start_char="901" end_char="905">China</TOKEN>
<TOKEN id="token-4-37" pos="punct" morph="none" start_char="906" end_char="907">,"</TOKEN>
<TOKEN id="token-4-38" pos="word" morph="none" start_char="909" end_char="916">planting</TOKEN>
<TOKEN id="token-4-39" pos="word" morph="none" start_char="918" end_char="920">the</TOKEN>
<TOKEN id="token-4-40" pos="word" morph="none" start_char="922" end_char="926">seeds</TOKEN>
<TOKEN id="token-4-41" pos="word" morph="none" start_char="928" end_char="929">of</TOKEN>
<TOKEN id="token-4-42" pos="word" morph="none" start_char="931" end_char="935">doubt</TOKEN>
<TOKEN id="token-4-43" pos="punct" morph="none" start_char="936" end_char="936">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="939" end_char="1127">
<ORIGINAL_TEXT>On Thursday (March 12), Zhao Lijian, the spokesperson of China’s Ministry of Foreign Affairs, took to Twitter, a social platform banned in China, to ask, "When did patient zero begin in US?</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="939" end_char="940">On</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="942" end_char="949">Thursday</TOKEN>
<TOKEN id="token-5-2" pos="punct" morph="none" start_char="951" end_char="951">(</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="952" end_char="956">March</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="958" end_char="959">12</TOKEN>
<TOKEN id="token-5-5" pos="punct" morph="none" start_char="960" end_char="961">),</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="963" end_char="966">Zhao</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="968" end_char="973">Lijian</TOKEN>
<TOKEN id="token-5-8" pos="punct" morph="none" start_char="974" end_char="974">,</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="976" end_char="978">the</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="980" end_char="991">spokesperson</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="993" end_char="994">of</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="996" end_char="1002">China’s</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="1004" end_char="1011">Ministry</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="1013" end_char="1014">of</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="1016" end_char="1022">Foreign</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="1024" end_char="1030">Affairs</TOKEN>
<TOKEN id="token-5-17" pos="punct" morph="none" start_char="1031" end_char="1031">,</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="1033" end_char="1036">took</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="1038" end_char="1039">to</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="1041" end_char="1047">Twitter</TOKEN>
<TOKEN id="token-5-21" pos="punct" morph="none" start_char="1048" end_char="1048">,</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="1050" end_char="1050">a</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="1052" end_char="1057">social</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="1059" end_char="1066">platform</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="1068" end_char="1073">banned</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="1075" end_char="1076">in</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="1078" end_char="1082">China</TOKEN>
<TOKEN id="token-5-28" pos="punct" morph="none" start_char="1083" end_char="1083">,</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="1085" end_char="1086">to</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="1088" end_char="1090">ask</TOKEN>
<TOKEN id="token-5-31" pos="punct" morph="none" start_char="1091" end_char="1091">,</TOKEN>
<TOKEN id="token-5-32" pos="punct" morph="none" start_char="1093" end_char="1093">"</TOKEN>
<TOKEN id="token-5-33" pos="word" morph="none" start_char="1094" end_char="1097">When</TOKEN>
<TOKEN id="token-5-34" pos="word" morph="none" start_char="1099" end_char="1101">did</TOKEN>
<TOKEN id="token-5-35" pos="word" morph="none" start_char="1103" end_char="1109">patient</TOKEN>
<TOKEN id="token-5-36" pos="word" morph="none" start_char="1111" end_char="1114">zero</TOKEN>
<TOKEN id="token-5-37" pos="word" morph="none" start_char="1116" end_char="1120">begin</TOKEN>
<TOKEN id="token-5-38" pos="word" morph="none" start_char="1122" end_char="1123">in</TOKEN>
<TOKEN id="token-5-39" pos="word" morph="none" start_char="1125" end_char="1126">US</TOKEN>
<TOKEN id="token-5-40" pos="punct" morph="none" start_char="1127" end_char="1127">?</TOKEN>
</SEG>
<SEG id="segment-6" start_char="1129" end_char="1157">
<ORIGINAL_TEXT>How many people are infected?</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="1129" end_char="1131">How</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="1133" end_char="1136">many</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="1138" end_char="1143">people</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="1145" end_char="1147">are</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="1149" end_char="1156">infected</TOKEN>
<TOKEN id="token-6-5" pos="punct" morph="none" start_char="1157" end_char="1157">?</TOKEN>
</SEG>
<SEG id="segment-7" start_char="1159" end_char="1194">
<ORIGINAL_TEXT>What are the names of the hospitals?</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="1159" end_char="1162">What</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="1164" end_char="1166">are</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="1168" end_char="1170">the</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="1172" end_char="1176">names</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="1178" end_char="1179">of</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="1181" end_char="1183">the</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="1185" end_char="1193">hospitals</TOKEN>
<TOKEN id="token-7-7" pos="punct" morph="none" start_char="1194" end_char="1194">?</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1196" end_char="1249">
<ORIGINAL_TEXT>It might be US army who brought the epidemic to Wuhan.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1196" end_char="1197">It</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1199" end_char="1203">might</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1205" end_char="1206">be</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1208" end_char="1209">US</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1211" end_char="1214">army</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1216" end_char="1218">who</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1220" end_char="1226">brought</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1228" end_char="1230">the</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1232" end_char="1239">epidemic</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1241" end_char="1242">to</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1244" end_char="1248">Wuhan</TOKEN>
<TOKEN id="token-8-11" pos="punct" morph="none" start_char="1249" end_char="1249">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1251" end_char="1265">
<ORIGINAL_TEXT>Be transparent!</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1251" end_char="1252">Be</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1254" end_char="1264">transparent</TOKEN>
<TOKEN id="token-9-2" pos="punct" morph="none" start_char="1265" end_char="1265">!</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1267" end_char="1288">
<ORIGINAL_TEXT>Make public your data!</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1267" end_char="1270">Make</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1272" end_char="1277">public</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1279" end_char="1282">your</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1284" end_char="1287">data</TOKEN>
<TOKEN id="token-10-4" pos="punct" morph="none" start_char="1288" end_char="1288">!</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1290" end_char="1315">
<ORIGINAL_TEXT>US owe us an explanation!"</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1290" end_char="1291">US</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1293" end_char="1295">owe</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1297" end_char="1298">us</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1300" end_char="1301">an</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1303" end_char="1313">explanation</TOKEN>
<TOKEN id="token-11-5" pos="punct" morph="none" start_char="1314" end_char="1315">!"</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1318" end_char="1587">
<ORIGINAL_TEXT>The text of the tweet was accompanied by a video of US Centers for Disease Control and Prevention Director Robert Redfield saying that some deaths assumed to have been caused by the flu were actually COVID-19, though the video does not reference specific cases or dates.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1318" end_char="1320">The</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1322" end_char="1325">text</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1327" end_char="1328">of</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1330" end_char="1332">the</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1334" end_char="1338">tweet</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1340" end_char="1342">was</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1344" end_char="1354">accompanied</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1356" end_char="1357">by</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1359" end_char="1359">a</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1361" end_char="1365">video</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1367" end_char="1368">of</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1370" end_char="1371">US</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1373" end_char="1379">Centers</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1381" end_char="1383">for</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1385" end_char="1391">Disease</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1393" end_char="1399">Control</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1401" end_char="1403">and</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1405" end_char="1414">Prevention</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1416" end_char="1423">Director</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1425" end_char="1430">Robert</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1432" end_char="1439">Redfield</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1441" end_char="1446">saying</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1448" end_char="1451">that</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="1453" end_char="1456">some</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="1458" end_char="1463">deaths</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="1465" end_char="1471">assumed</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="1473" end_char="1474">to</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="1476" end_char="1479">have</TOKEN>
<TOKEN id="token-12-28" pos="word" morph="none" start_char="1481" end_char="1484">been</TOKEN>
<TOKEN id="token-12-29" pos="word" morph="none" start_char="1486" end_char="1491">caused</TOKEN>
<TOKEN id="token-12-30" pos="word" morph="none" start_char="1493" end_char="1494">by</TOKEN>
<TOKEN id="token-12-31" pos="word" morph="none" start_char="1496" end_char="1498">the</TOKEN>
<TOKEN id="token-12-32" pos="word" morph="none" start_char="1500" end_char="1502">flu</TOKEN>
<TOKEN id="token-12-33" pos="word" morph="none" start_char="1504" end_char="1507">were</TOKEN>
<TOKEN id="token-12-34" pos="word" morph="none" start_char="1509" end_char="1516">actually</TOKEN>
<TOKEN id="token-12-35" pos="unknown" morph="none" start_char="1518" end_char="1525">COVID-19</TOKEN>
<TOKEN id="token-12-36" pos="punct" morph="none" start_char="1526" end_char="1526">,</TOKEN>
<TOKEN id="token-12-37" pos="word" morph="none" start_char="1528" end_char="1533">though</TOKEN>
<TOKEN id="token-12-38" pos="word" morph="none" start_char="1535" end_char="1537">the</TOKEN>
<TOKEN id="token-12-39" pos="word" morph="none" start_char="1539" end_char="1543">video</TOKEN>
<TOKEN id="token-12-40" pos="word" morph="none" start_char="1545" end_char="1548">does</TOKEN>
<TOKEN id="token-12-41" pos="word" morph="none" start_char="1550" end_char="1552">not</TOKEN>
<TOKEN id="token-12-42" pos="word" morph="none" start_char="1554" end_char="1562">reference</TOKEN>
<TOKEN id="token-12-43" pos="word" morph="none" start_char="1564" end_char="1571">specific</TOKEN>
<TOKEN id="token-12-44" pos="word" morph="none" start_char="1573" end_char="1577">cases</TOKEN>
<TOKEN id="token-12-45" pos="word" morph="none" start_char="1579" end_char="1580">or</TOKEN>
<TOKEN id="token-12-46" pos="word" morph="none" start_char="1582" end_char="1586">dates</TOKEN>
<TOKEN id="token-12-47" pos="punct" morph="none" start_char="1587" end_char="1587">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1590" end_char="1762">
<ORIGINAL_TEXT>Lijian has also retweeted a link to a known conspiracy site that claims the virus may have originated at the US Army Medical Research Institute of Infectious Diseases at Ft.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1590" end_char="1595">Lijian</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1597" end_char="1599">has</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1601" end_char="1604">also</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1606" end_char="1614">retweeted</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1616" end_char="1616">a</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1618" end_char="1621">link</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1623" end_char="1624">to</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1626" end_char="1626">a</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1628" end_char="1632">known</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1634" end_char="1643">conspiracy</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1645" end_char="1648">site</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1650" end_char="1653">that</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1655" end_char="1660">claims</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1662" end_char="1664">the</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1666" end_char="1670">virus</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1672" end_char="1674">may</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1676" end_char="1679">have</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1681" end_char="1690">originated</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1692" end_char="1693">at</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1695" end_char="1697">the</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1699" end_char="1700">US</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="1702" end_char="1705">Army</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="1707" end_char="1713">Medical</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="1715" end_char="1722">Research</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="1724" end_char="1732">Institute</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="1734" end_char="1735">of</TOKEN>
<TOKEN id="token-13-26" pos="word" morph="none" start_char="1737" end_char="1746">Infectious</TOKEN>
<TOKEN id="token-13-27" pos="word" morph="none" start_char="1748" end_char="1755">Diseases</TOKEN>
<TOKEN id="token-13-28" pos="word" morph="none" start_char="1757" end_char="1758">at</TOKEN>
<TOKEN id="token-13-29" pos="word" morph="none" start_char="1760" end_char="1761">Ft</TOKEN>
<TOKEN id="token-13-30" pos="punct" morph="none" start_char="1762" end_char="1762">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1764" end_char="1864">
<ORIGINAL_TEXT>Detrick in Maryland, which was shut down in August after biosafety lapses with a number of pathogens.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1764" end_char="1770">Detrick</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1772" end_char="1773">in</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1775" end_char="1782">Maryland</TOKEN>
<TOKEN id="token-14-3" pos="punct" morph="none" start_char="1783" end_char="1783">,</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1785" end_char="1789">which</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1791" end_char="1793">was</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1795" end_char="1798">shut</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1800" end_char="1803">down</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1805" end_char="1806">in</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1808" end_char="1813">August</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1815" end_char="1819">after</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1821" end_char="1829">biosafety</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1831" end_char="1836">lapses</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1838" end_char="1841">with</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="1843" end_char="1843">a</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1845" end_char="1850">number</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1852" end_char="1853">of</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="1855" end_char="1863">pathogens</TOKEN>
<TOKEN id="token-14-18" pos="punct" morph="none" start_char="1864" end_char="1864">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1866" end_char="1926">
<ORIGINAL_TEXT>The website goes on to speculate that the virus went from Ft.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1866" end_char="1868">The</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1870" end_char="1876">website</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1878" end_char="1881">goes</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1883" end_char="1884">on</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1886" end_char="1887">to</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1889" end_char="1897">speculate</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1899" end_char="1902">that</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1904" end_char="1906">the</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1908" end_char="1912">virus</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1914" end_char="1917">went</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1919" end_char="1922">from</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1924" end_char="1925">Ft</TOKEN>
<TOKEN id="token-15-12" pos="punct" morph="none" start_char="1926" end_char="1926">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1928" end_char="1970">
<ORIGINAL_TEXT>Detrick to e-cigarettes to Hawaii to Wuhan.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1928" end_char="1934">Detrick</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1936" end_char="1937">to</TOKEN>
<TOKEN id="token-16-2" pos="unknown" morph="none" start_char="1939" end_char="1950">e-cigarettes</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1952" end_char="1953">to</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1955" end_char="1960">Hawaii</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1962" end_char="1963">to</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1965" end_char="1969">Wuhan</TOKEN>
<TOKEN id="token-16-7" pos="punct" morph="none" start_char="1970" end_char="1970">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1972" end_char="2109">
<ORIGINAL_TEXT>There is no evidence the pathogens in Maryland ever left the lab and there’s an equal lack of evidence supporting any of the other claims.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1972" end_char="1976">There</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1978" end_char="1979">is</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="1981" end_char="1982">no</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="1984" end_char="1991">evidence</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="1993" end_char="1995">the</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="1997" end_char="2005">pathogens</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2007" end_char="2008">in</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2010" end_char="2017">Maryland</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2019" end_char="2022">ever</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2024" end_char="2027">left</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2029" end_char="2031">the</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2033" end_char="2035">lab</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2037" end_char="2039">and</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2041" end_char="2047">there’s</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2049" end_char="2050">an</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2052" end_char="2056">equal</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="2058" end_char="2061">lack</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="2063" end_char="2064">of</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="2066" end_char="2073">evidence</TOKEN>
<TOKEN id="token-17-19" pos="word" morph="none" start_char="2075" end_char="2084">supporting</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="2086" end_char="2088">any</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="2090" end_char="2091">of</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="2093" end_char="2095">the</TOKEN>
<TOKEN id="token-17-23" pos="word" morph="none" start_char="2097" end_char="2101">other</TOKEN>
<TOKEN id="token-17-24" pos="word" morph="none" start_char="2103" end_char="2108">claims</TOKEN>
<TOKEN id="token-17-25" pos="punct" morph="none" start_char="2109" end_char="2109">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2112" end_char="2252">
<ORIGINAL_TEXT>An analysis of the virus’s genome indicates that the outbreak wasn’t caused by a strain from a lab and likely came from wild animals instead.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2112" end_char="2113">An</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2115" end_char="2122">analysis</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2124" end_char="2125">of</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2127" end_char="2129">the</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2131" end_char="2137">virus’s</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2139" end_char="2144">genome</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2146" end_char="2154">indicates</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2156" end_char="2159">that</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2161" end_char="2163">the</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="2165" end_char="2172">outbreak</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="2174" end_char="2179">wasn’t</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="2181" end_char="2186">caused</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2188" end_char="2189">by</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="2191" end_char="2191">a</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="2193" end_char="2198">strain</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="2200" end_char="2203">from</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="2205" end_char="2205">a</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="2207" end_char="2209">lab</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="2211" end_char="2213">and</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="2215" end_char="2220">likely</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="2222" end_char="2225">came</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="2227" end_char="2230">from</TOKEN>
<TOKEN id="token-18-22" pos="word" morph="none" start_char="2232" end_char="2235">wild</TOKEN>
<TOKEN id="token-18-23" pos="word" morph="none" start_char="2237" end_char="2243">animals</TOKEN>
<TOKEN id="token-18-24" pos="word" morph="none" start_char="2245" end_char="2251">instead</TOKEN>
<TOKEN id="token-18-25" pos="punct" morph="none" start_char="2252" end_char="2252">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2255" end_char="2479">
<ORIGINAL_TEXT>Despite the lack of evidence, the fact that a government official is making these claims seemingly unchecked could have larger consequences, says Victor Shih, an associate professor at the University of California, San Diego.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2255" end_char="2261">Despite</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2263" end_char="2265">the</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2267" end_char="2270">lack</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2272" end_char="2273">of</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2275" end_char="2282">evidence</TOKEN>
<TOKEN id="token-19-5" pos="punct" morph="none" start_char="2283" end_char="2283">,</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2285" end_char="2287">the</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2289" end_char="2292">fact</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2294" end_char="2297">that</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="2299" end_char="2299">a</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="2301" end_char="2310">government</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="2312" end_char="2319">official</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="2321" end_char="2322">is</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="2324" end_char="2329">making</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="2331" end_char="2335">these</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="2337" end_char="2342">claims</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="2344" end_char="2352">seemingly</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="2354" end_char="2362">unchecked</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="2364" end_char="2368">could</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="2370" end_char="2373">have</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="2375" end_char="2380">larger</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="2382" end_char="2393">consequences</TOKEN>
<TOKEN id="token-19-22" pos="punct" morph="none" start_char="2394" end_char="2394">,</TOKEN>
<TOKEN id="token-19-23" pos="word" morph="none" start_char="2396" end_char="2399">says</TOKEN>
<TOKEN id="token-19-24" pos="word" morph="none" start_char="2401" end_char="2406">Victor</TOKEN>
<TOKEN id="token-19-25" pos="word" morph="none" start_char="2408" end_char="2411">Shih</TOKEN>
<TOKEN id="token-19-26" pos="punct" morph="none" start_char="2412" end_char="2412">,</TOKEN>
<TOKEN id="token-19-27" pos="word" morph="none" start_char="2414" end_char="2415">an</TOKEN>
<TOKEN id="token-19-28" pos="word" morph="none" start_char="2417" end_char="2425">associate</TOKEN>
<TOKEN id="token-19-29" pos="word" morph="none" start_char="2427" end_char="2435">professor</TOKEN>
<TOKEN id="token-19-30" pos="word" morph="none" start_char="2437" end_char="2438">at</TOKEN>
<TOKEN id="token-19-31" pos="word" morph="none" start_char="2440" end_char="2442">the</TOKEN>
<TOKEN id="token-19-32" pos="word" morph="none" start_char="2444" end_char="2453">University</TOKEN>
<TOKEN id="token-19-33" pos="word" morph="none" start_char="2455" end_char="2456">of</TOKEN>
<TOKEN id="token-19-34" pos="word" morph="none" start_char="2458" end_char="2467">California</TOKEN>
<TOKEN id="token-19-35" pos="punct" morph="none" start_char="2468" end_char="2468">,</TOKEN>
<TOKEN id="token-19-36" pos="word" morph="none" start_char="2470" end_char="2472">San</TOKEN>
<TOKEN id="token-19-37" pos="word" morph="none" start_char="2474" end_char="2478">Diego</TOKEN>
<TOKEN id="token-19-38" pos="punct" morph="none" start_char="2479" end_char="2479">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2482" end_char="2580">
<ORIGINAL_TEXT>"If the [Chinese] leadership really believes in the culpability of the U.S. government," Shih tells</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="punct" morph="none" start_char="2482" end_char="2482">"</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2483" end_char="2484">If</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2486" end_char="2488">the</TOKEN>
<TOKEN id="token-20-3" pos="punct" morph="none" start_char="2490" end_char="2490">[</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2491" end_char="2497">Chinese</TOKEN>
<TOKEN id="token-20-5" pos="punct" morph="none" start_char="2498" end_char="2498">]</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2500" end_char="2509">leadership</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2511" end_char="2516">really</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="2518" end_char="2525">believes</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2527" end_char="2528">in</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2530" end_char="2532">the</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="2534" end_char="2544">culpability</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="2546" end_char="2547">of</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="2549" end_char="2551">the</TOKEN>
<TOKEN id="token-20-14" pos="unknown" morph="none" start_char="2553" end_char="2555">U.S</TOKEN>
<TOKEN id="token-20-15" pos="punct" morph="none" start_char="2556" end_char="2556">.</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="2558" end_char="2567">government</TOKEN>
<TOKEN id="token-20-17" pos="punct" morph="none" start_char="2568" end_char="2569">,"</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="2571" end_char="2574">Shih</TOKEN>
<TOKEN id="token-20-19" pos="word" morph="none" start_char="2576" end_char="2580">tells</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2583" end_char="2600">
<ORIGINAL_TEXT>The New York Times</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2583" end_char="2585">The</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2587" end_char="2589">New</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2591" end_char="2594">York</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2596" end_char="2600">Times</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2603" end_char="2682">
<ORIGINAL_TEXT>, "it may behave in a way that dramatically worsens the bilateral relationship."</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="punct" morph="none" start_char="2603" end_char="2603">,</TOKEN>
<TOKEN id="token-22-1" pos="punct" morph="none" start_char="2605" end_char="2605">"</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2606" end_char="2607">it</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2609" end_char="2611">may</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2613" end_char="2618">behave</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2620" end_char="2621">in</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2623" end_char="2623">a</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2625" end_char="2627">way</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="2629" end_char="2632">that</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="2634" end_char="2645">dramatically</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="2647" end_char="2653">worsens</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="2655" end_char="2657">the</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="2659" end_char="2667">bilateral</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="2669" end_char="2680">relationship</TOKEN>
<TOKEN id="token-22-14" pos="punct" morph="none" start_char="2681" end_char="2682">."</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2685" end_char="2786">
<ORIGINAL_TEXT>The statements might simply be a distraction from criticisms about how China has handled the outbreak.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2685" end_char="2687">The</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2689" end_char="2698">statements</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2700" end_char="2704">might</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2706" end_char="2711">simply</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="2713" end_char="2714">be</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="2716" end_char="2716">a</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="2718" end_char="2728">distraction</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="2730" end_char="2733">from</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="2735" end_char="2744">criticisms</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="2746" end_char="2750">about</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="2752" end_char="2754">how</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="2756" end_char="2760">China</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="2762" end_char="2764">has</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="2766" end_char="2772">handled</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="2774" end_char="2776">the</TOKEN>
<TOKEN id="token-23-15" pos="word" morph="none" start_char="2778" end_char="2785">outbreak</TOKEN>
<TOKEN id="token-23-16" pos="punct" morph="none" start_char="2786" end_char="2786">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2788" end_char="2973">
<ORIGINAL_TEXT>Li Wenliang, a Chinese doctor who had tried to raise awareness about the virus in the early stages, was punished by the government and forced to say his concerns were an "illegal rumor."</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="2788" end_char="2789">Li</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="2791" end_char="2798">Wenliang</TOKEN>
<TOKEN id="token-24-2" pos="punct" morph="none" start_char="2799" end_char="2799">,</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="2801" end_char="2801">a</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="2803" end_char="2809">Chinese</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="2811" end_char="2816">doctor</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="2818" end_char="2820">who</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="2822" end_char="2824">had</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="2826" end_char="2830">tried</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="2832" end_char="2833">to</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="2835" end_char="2839">raise</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="2841" end_char="2849">awareness</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="2851" end_char="2855">about</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="2857" end_char="2859">the</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="2861" end_char="2865">virus</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="2867" end_char="2868">in</TOKEN>
<TOKEN id="token-24-16" pos="word" morph="none" start_char="2870" end_char="2872">the</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="2874" end_char="2878">early</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="2880" end_char="2885">stages</TOKEN>
<TOKEN id="token-24-19" pos="punct" morph="none" start_char="2886" end_char="2886">,</TOKEN>
<TOKEN id="token-24-20" pos="word" morph="none" start_char="2888" end_char="2890">was</TOKEN>
<TOKEN id="token-24-21" pos="word" morph="none" start_char="2892" end_char="2899">punished</TOKEN>
<TOKEN id="token-24-22" pos="word" morph="none" start_char="2901" end_char="2902">by</TOKEN>
<TOKEN id="token-24-23" pos="word" morph="none" start_char="2904" end_char="2906">the</TOKEN>
<TOKEN id="token-24-24" pos="word" morph="none" start_char="2908" end_char="2917">government</TOKEN>
<TOKEN id="token-24-25" pos="word" morph="none" start_char="2919" end_char="2921">and</TOKEN>
<TOKEN id="token-24-26" pos="word" morph="none" start_char="2923" end_char="2928">forced</TOKEN>
<TOKEN id="token-24-27" pos="word" morph="none" start_char="2930" end_char="2931">to</TOKEN>
<TOKEN id="token-24-28" pos="word" morph="none" start_char="2933" end_char="2935">say</TOKEN>
<TOKEN id="token-24-29" pos="word" morph="none" start_char="2937" end_char="2939">his</TOKEN>
<TOKEN id="token-24-30" pos="word" morph="none" start_char="2941" end_char="2948">concerns</TOKEN>
<TOKEN id="token-24-31" pos="word" morph="none" start_char="2950" end_char="2953">were</TOKEN>
<TOKEN id="token-24-32" pos="word" morph="none" start_char="2955" end_char="2956">an</TOKEN>
<TOKEN id="token-24-33" pos="punct" morph="none" start_char="2958" end_char="2958">"</TOKEN>
<TOKEN id="token-24-34" pos="word" morph="none" start_char="2959" end_char="2965">illegal</TOKEN>
<TOKEN id="token-24-35" pos="word" morph="none" start_char="2967" end_char="2971">rumor</TOKEN>
<TOKEN id="token-24-36" pos="punct" morph="none" start_char="2972" end_char="2973">."</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2975" end_char="3065">
<ORIGINAL_TEXT>Li contracted the virus himself while treating a patient in January and died on February 7.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="2975" end_char="2976">Li</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="2978" end_char="2987">contracted</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="2989" end_char="2991">the</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="2993" end_char="2997">virus</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="2999" end_char="3005">himself</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="3007" end_char="3011">while</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="3013" end_char="3020">treating</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="3022" end_char="3022">a</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="3024" end_char="3030">patient</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="3032" end_char="3033">in</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="3035" end_char="3041">January</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="3043" end_char="3045">and</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="3047" end_char="3050">died</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="3052" end_char="3053">on</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="3055" end_char="3062">February</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="3064" end_char="3064">7</TOKEN>
<TOKEN id="token-25-16" pos="punct" morph="none" start_char="3065" end_char="3065">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="3067" end_char="3188">
<ORIGINAL_TEXT>Critics claim that had these concerns been taken seriously at the time, it could have curbed the severity of the outbreak.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="3067" end_char="3073">Critics</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="3075" end_char="3079">claim</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="3081" end_char="3084">that</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="3086" end_char="3088">had</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="3090" end_char="3094">these</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="3096" end_char="3103">concerns</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="3105" end_char="3108">been</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="3110" end_char="3114">taken</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="3116" end_char="3124">seriously</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="3126" end_char="3127">at</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="3129" end_char="3131">the</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="3133" end_char="3136">time</TOKEN>
<TOKEN id="token-26-12" pos="punct" morph="none" start_char="3137" end_char="3137">,</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="3139" end_char="3140">it</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="3142" end_char="3146">could</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="3148" end_char="3151">have</TOKEN>
<TOKEN id="token-26-16" pos="word" morph="none" start_char="3153" end_char="3158">curbed</TOKEN>
<TOKEN id="token-26-17" pos="word" morph="none" start_char="3160" end_char="3162">the</TOKEN>
<TOKEN id="token-26-18" pos="word" morph="none" start_char="3164" end_char="3171">severity</TOKEN>
<TOKEN id="token-26-19" pos="word" morph="none" start_char="3173" end_char="3174">of</TOKEN>
<TOKEN id="token-26-20" pos="word" morph="none" start_char="3176" end_char="3178">the</TOKEN>
<TOKEN id="token-26-21" pos="word" morph="none" start_char="3180" end_char="3187">outbreak</TOKEN>
<TOKEN id="token-26-22" pos="punct" morph="none" start_char="3188" end_char="3188">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="3191" end_char="3339">
<ORIGINAL_TEXT>The unfounded claims could also be a response to US officials who have referred to SARS-CoV-2 as the "China virus" or "Wuhan virus," according to the</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="3191" end_char="3193">The</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="3195" end_char="3203">unfounded</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="3205" end_char="3210">claims</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="3212" end_char="3216">could</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="3218" end_char="3221">also</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="3223" end_char="3224">be</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="3226" end_char="3226">a</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="3228" end_char="3235">response</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="3237" end_char="3238">to</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="3240" end_char="3241">US</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="3243" end_char="3251">officials</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="3253" end_char="3255">who</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="3257" end_char="3260">have</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="3262" end_char="3269">referred</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="3271" end_char="3272">to</TOKEN>
<TOKEN id="token-27-15" pos="unknown" morph="none" start_char="3274" end_char="3283">SARS-CoV-2</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="3285" end_char="3286">as</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="3288" end_char="3290">the</TOKEN>
<TOKEN id="token-27-18" pos="punct" morph="none" start_char="3292" end_char="3292">"</TOKEN>
<TOKEN id="token-27-19" pos="word" morph="none" start_char="3293" end_char="3297">China</TOKEN>
<TOKEN id="token-27-20" pos="word" morph="none" start_char="3299" end_char="3303">virus</TOKEN>
<TOKEN id="token-27-21" pos="punct" morph="none" start_char="3304" end_char="3304">"</TOKEN>
<TOKEN id="token-27-22" pos="word" morph="none" start_char="3306" end_char="3307">or</TOKEN>
<TOKEN id="token-27-23" pos="punct" morph="none" start_char="3309" end_char="3309">"</TOKEN>
<TOKEN id="token-27-24" pos="word" morph="none" start_char="3310" end_char="3314">Wuhan</TOKEN>
<TOKEN id="token-27-25" pos="word" morph="none" start_char="3316" end_char="3320">virus</TOKEN>
<TOKEN id="token-27-26" pos="punct" morph="none" start_char="3321" end_char="3322">,"</TOKEN>
<TOKEN id="token-27-27" pos="word" morph="none" start_char="3324" end_char="3332">according</TOKEN>
<TOKEN id="token-27-28" pos="word" morph="none" start_char="3334" end_char="3335">to</TOKEN>
<TOKEN id="token-27-29" pos="word" morph="none" start_char="3337" end_char="3339">the</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3342" end_char="3346">
<ORIGINAL_TEXT>Times</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="3342" end_char="3346">Times</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3349" end_char="3434">
<ORIGINAL_TEXT>, terms that Lijian denounced as "highly irresponsible" at a March 4 press conference.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="punct" morph="none" start_char="3349" end_char="3349">,</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="3351" end_char="3355">terms</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="3357" end_char="3360">that</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="3362" end_char="3367">Lijian</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="3369" end_char="3377">denounced</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="3379" end_char="3380">as</TOKEN>
<TOKEN id="token-29-6" pos="punct" morph="none" start_char="3382" end_char="3382">"</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="3383" end_char="3388">highly</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="3390" end_char="3402">irresponsible</TOKEN>
<TOKEN id="token-29-9" pos="punct" morph="none" start_char="3403" end_char="3403">"</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="3405" end_char="3406">at</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="3408" end_char="3408">a</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="3410" end_char="3414">March</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="3416" end_char="3416">4</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="3418" end_char="3422">press</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="3424" end_char="3433">conference</TOKEN>
<TOKEN id="token-29-16" pos="punct" morph="none" start_char="3434" end_char="3434">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3437" end_char="3686">
<ORIGINAL_TEXT>"The conspiracy theories are a new, low front in what they clearly perceive as a global competition over the narrative of this crisis," Julian Gewirtz, an Academy Scholar at Harvard University's Weatherhead Center for International Affairs, tells the</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="punct" morph="none" start_char="3437" end_char="3437">"</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="3438" end_char="3440">The</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="3442" end_char="3451">conspiracy</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="3453" end_char="3460">theories</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="3462" end_char="3464">are</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="3466" end_char="3466">a</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="3468" end_char="3470">new</TOKEN>
<TOKEN id="token-30-7" pos="punct" morph="none" start_char="3471" end_char="3471">,</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="3473" end_char="3475">low</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="3477" end_char="3481">front</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="3483" end_char="3484">in</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="3486" end_char="3489">what</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="3491" end_char="3494">they</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="3496" end_char="3502">clearly</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="3504" end_char="3511">perceive</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="3513" end_char="3514">as</TOKEN>
<TOKEN id="token-30-16" pos="word" morph="none" start_char="3516" end_char="3516">a</TOKEN>
<TOKEN id="token-30-17" pos="word" morph="none" start_char="3518" end_char="3523">global</TOKEN>
<TOKEN id="token-30-18" pos="word" morph="none" start_char="3525" end_char="3535">competition</TOKEN>
<TOKEN id="token-30-19" pos="word" morph="none" start_char="3537" end_char="3540">over</TOKEN>
<TOKEN id="token-30-20" pos="word" morph="none" start_char="3542" end_char="3544">the</TOKEN>
<TOKEN id="token-30-21" pos="word" morph="none" start_char="3546" end_char="3554">narrative</TOKEN>
<TOKEN id="token-30-22" pos="word" morph="none" start_char="3556" end_char="3557">of</TOKEN>
<TOKEN id="token-30-23" pos="word" morph="none" start_char="3559" end_char="3562">this</TOKEN>
<TOKEN id="token-30-24" pos="word" morph="none" start_char="3564" end_char="3569">crisis</TOKEN>
<TOKEN id="token-30-25" pos="punct" morph="none" start_char="3570" end_char="3571">,"</TOKEN>
<TOKEN id="token-30-26" pos="word" morph="none" start_char="3573" end_char="3578">Julian</TOKEN>
<TOKEN id="token-30-27" pos="word" morph="none" start_char="3580" end_char="3586">Gewirtz</TOKEN>
<TOKEN id="token-30-28" pos="punct" morph="none" start_char="3587" end_char="3587">,</TOKEN>
<TOKEN id="token-30-29" pos="word" morph="none" start_char="3589" end_char="3590">an</TOKEN>
<TOKEN id="token-30-30" pos="word" morph="none" start_char="3592" end_char="3598">Academy</TOKEN>
<TOKEN id="token-30-31" pos="word" morph="none" start_char="3600" end_char="3606">Scholar</TOKEN>
<TOKEN id="token-30-32" pos="word" morph="none" start_char="3608" end_char="3609">at</TOKEN>
<TOKEN id="token-30-33" pos="word" morph="none" start_char="3611" end_char="3617">Harvard</TOKEN>
<TOKEN id="token-30-34" pos="word" morph="none" start_char="3619" end_char="3630">University's</TOKEN>
<TOKEN id="token-30-35" pos="word" morph="none" start_char="3632" end_char="3642">Weatherhead</TOKEN>
<TOKEN id="token-30-36" pos="word" morph="none" start_char="3644" end_char="3649">Center</TOKEN>
<TOKEN id="token-30-37" pos="word" morph="none" start_char="3651" end_char="3653">for</TOKEN>
<TOKEN id="token-30-38" pos="word" morph="none" start_char="3655" end_char="3667">International</TOKEN>
<TOKEN id="token-30-39" pos="word" morph="none" start_char="3669" end_char="3675">Affairs</TOKEN>
<TOKEN id="token-30-40" pos="punct" morph="none" start_char="3676" end_char="3676">,</TOKEN>
<TOKEN id="token-30-41" pos="word" morph="none" start_char="3678" end_char="3682">tells</TOKEN>
<TOKEN id="token-30-42" pos="word" morph="none" start_char="3684" end_char="3686">the</TOKEN>
</SEG>
<SEG id="segment-31" start_char="3689" end_char="3693">
<ORIGINAL_TEXT>Times</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="3689" end_char="3693">Times</TOKEN>
</SEG>
<SEG id="segment-32" start_char="3696" end_char="3696">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="punct" morph="none" start_char="3696" end_char="3696">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="3699" end_char="3740">
<ORIGINAL_TEXT>Lisa Winter is the social media editor for</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="3699" end_char="3702">Lisa</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="3704" end_char="3709">Winter</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="3711" end_char="3712">is</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="3714" end_char="3716">the</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="3718" end_char="3723">social</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="3725" end_char="3729">media</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="3731" end_char="3736">editor</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="3738" end_char="3740">for</TOKEN>
</SEG>
<SEG id="segment-34" start_char="3743" end_char="3756">
<ORIGINAL_TEXT>The Scientist.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="3743" end_char="3745">The</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="3747" end_char="3755">Scientist</TOKEN>
<TOKEN id="token-34-2" pos="punct" morph="none" start_char="3756" end_char="3756">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="3759" end_char="3828">
<ORIGINAL_TEXT>Email her at lwinter@the-scientist.com or connect on Twitter @Lisa831.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="3759" end_char="3763">Email</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="3765" end_char="3767">her</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="3769" end_char="3770">at</TOKEN>
<TOKEN id="token-35-3" pos="unknown" morph="none" start_char="3772" end_char="3796">lwinter@the-scientist.com</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="3798" end_char="3799">or</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="3801" end_char="3807">connect</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="3809" end_char="3810">on</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="3812" end_char="3818">Twitter</TOKEN>
<TOKEN id="token-35-8" pos="tag" morph="none" start_char="3820" end_char="3828">@Lisa831.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
