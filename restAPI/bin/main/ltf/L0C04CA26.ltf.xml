<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CA26" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="4498" raw_text_md5="5bd49d403ca7fc41b84540ed179021b2">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="95">
<ORIGINAL_TEXT>Evidence that the COVID-19 virus existed in March 2019 would be ‘highly surprising’ says expert</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="8">Evidence</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="10" end_char="13">that</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="15" end_char="17">the</TOKEN>
<TOKEN id="token-0-3" pos="unknown" morph="none" start_char="19" end_char="26">COVID-19</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="28" end_char="32">virus</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="34" end_char="40">existed</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="42" end_char="43">in</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="45" end_char="49">March</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="51" end_char="54">2019</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="56" end_char="60">would</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="62" end_char="63">be</TOKEN>
<TOKEN id="token-0-11" pos="punct" morph="none" start_char="65" end_char="65">‘</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="66" end_char="71">highly</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="73" end_char="82">surprising</TOKEN>
<TOKEN id="token-0-14" pos="punct" morph="none" start_char="83" end_char="83">’</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="85" end_char="88">says</TOKEN>
<TOKEN id="token-0-16" pos="word" morph="none" start_char="90" end_char="95">expert</TOKEN>
</SEG>
<SEG id="segment-1" start_char="99" end_char="211">
<ORIGINAL_TEXT>Earlier this month, an Oxford University professor claimed that the coronavirus may not have originated in China.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="99" end_char="105">Earlier</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="107" end_char="110">this</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="112" end_char="116">month</TOKEN>
<TOKEN id="token-1-3" pos="punct" morph="none" start_char="117" end_char="117">,</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="119" end_char="120">an</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="122" end_char="127">Oxford</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="129" end_char="138">University</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="140" end_char="148">professor</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="150" end_char="156">claimed</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="158" end_char="161">that</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="163" end_char="165">the</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="167" end_char="177">coronavirus</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="179" end_char="181">may</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="183" end_char="185">not</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="187" end_char="190">have</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="192" end_char="201">originated</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="203" end_char="204">in</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="206" end_char="210">China</TOKEN>
<TOKEN id="token-1-18" pos="punct" morph="none" start_char="211" end_char="211">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="213" end_char="368">
<ORIGINAL_TEXT>Instead, Dr Tom Jefferson suggested that SARS-CoV-2 could have been lying dormant across the world until emerging under favourable environmental conditions.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="213" end_char="219">Instead</TOKEN>
<TOKEN id="token-2-1" pos="punct" morph="none" start_char="220" end_char="220">,</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="222" end_char="223">Dr</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="225" end_char="227">Tom</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="229" end_char="237">Jefferson</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="239" end_char="247">suggested</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="249" end_char="252">that</TOKEN>
<TOKEN id="token-2-7" pos="unknown" morph="none" start_char="254" end_char="263">SARS-CoV-2</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="265" end_char="269">could</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="271" end_char="274">have</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="276" end_char="279">been</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="281" end_char="285">lying</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="287" end_char="293">dormant</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="295" end_char="300">across</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="302" end_char="304">the</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="306" end_char="310">world</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="312" end_char="316">until</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="318" end_char="325">emerging</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="327" end_char="331">under</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="333" end_char="342">favourable</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="344" end_char="356">environmental</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="358" end_char="367">conditions</TOKEN>
<TOKEN id="token-2-22" pos="punct" morph="none" start_char="368" end_char="368">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="371" end_char="546">
<ORIGINAL_TEXT>In a recent interview Dr Jefferson pointed to studies that found traces of COVID-19 in sewage samples from Spain, Italy and Brazil all of which pre-date its discovery in China.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="371" end_char="372">In</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="374" end_char="374">a</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="376" end_char="381">recent</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="383" end_char="391">interview</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="393" end_char="394">Dr</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="396" end_char="404">Jefferson</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="406" end_char="412">pointed</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="414" end_char="415">to</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="417" end_char="423">studies</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="425" end_char="428">that</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="430" end_char="434">found</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="436" end_char="441">traces</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="443" end_char="444">of</TOKEN>
<TOKEN id="token-3-13" pos="unknown" morph="none" start_char="446" end_char="453">COVID-19</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="455" end_char="456">in</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="458" end_char="463">sewage</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="465" end_char="471">samples</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="473" end_char="476">from</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="478" end_char="482">Spain</TOKEN>
<TOKEN id="token-3-19" pos="punct" morph="none" start_char="483" end_char="483">,</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="485" end_char="489">Italy</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="491" end_char="493">and</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="495" end_char="500">Brazil</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="502" end_char="504">all</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="506" end_char="507">of</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="509" end_char="513">which</TOKEN>
<TOKEN id="token-3-26" pos="unknown" morph="none" start_char="515" end_char="522">pre-date</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="524" end_char="526">its</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="528" end_char="536">discovery</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="538" end_char="539">in</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="541" end_char="545">China</TOKEN>
<TOKEN id="token-3-31" pos="punct" morph="none" start_char="546" end_char="546">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="548" end_char="724">
<ORIGINAL_TEXT>This included one preprint study, which has not been peer reviewed, that claims to have found the presence of SARS-CoV-2 genomes in a Barcelona sewage sample from 12 March 2019.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="548" end_char="551">This</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="553" end_char="560">included</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="562" end_char="564">one</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="566" end_char="573">preprint</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="575" end_char="579">study</TOKEN>
<TOKEN id="token-4-5" pos="punct" morph="none" start_char="580" end_char="580">,</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="582" end_char="586">which</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="588" end_char="590">has</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="592" end_char="594">not</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="596" end_char="599">been</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="601" end_char="604">peer</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="606" end_char="613">reviewed</TOKEN>
<TOKEN id="token-4-12" pos="punct" morph="none" start_char="614" end_char="614">,</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="616" end_char="619">that</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="621" end_char="626">claims</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="628" end_char="629">to</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="631" end_char="634">have</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="636" end_char="640">found</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="642" end_char="644">the</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="646" end_char="653">presence</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="655" end_char="656">of</TOKEN>
<TOKEN id="token-4-21" pos="unknown" morph="none" start_char="658" end_char="667">SARS-CoV-2</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="669" end_char="675">genomes</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="677" end_char="678">in</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="680" end_char="680">a</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="682" end_char="690">Barcelona</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="692" end_char="697">sewage</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="699" end_char="704">sample</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="706" end_char="709">from</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="711" end_char="712">12</TOKEN>
<TOKEN id="token-4-30" pos="word" morph="none" start_char="714" end_char="718">March</TOKEN>
<TOKEN id="token-4-31" pos="word" morph="none" start_char="720" end_char="723">2019</TOKEN>
<TOKEN id="token-4-32" pos="punct" morph="none" start_char="724" end_char="724">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="727" end_char="750">
<ORIGINAL_TEXT>Can viruses lie dormant?</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="727" end_char="729">Can</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="731" end_char="737">viruses</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="739" end_char="741">lie</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="743" end_char="749">dormant</TOKEN>
<TOKEN id="token-5-4" pos="punct" morph="none" start_char="750" end_char="750">?</TOKEN>
</SEG>
<SEG id="segment-6" start_char="754" end_char="965">
<ORIGINAL_TEXT>"There are some viruses (such as herpes viruses) that can infect cells, establish a latent infection and then be reactivated at a later date," explains Dr Jeremy Rossman, a virologist from the University of Kent.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="punct" morph="none" start_char="754" end_char="754">"</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="755" end_char="759">There</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="761" end_char="763">are</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="765" end_char="768">some</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="770" end_char="776">viruses</TOKEN>
<TOKEN id="token-6-5" pos="punct" morph="none" start_char="778" end_char="778">(</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="779" end_char="782">such</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="784" end_char="785">as</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="787" end_char="792">herpes</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="794" end_char="800">viruses</TOKEN>
<TOKEN id="token-6-10" pos="punct" morph="none" start_char="801" end_char="801">)</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="803" end_char="806">that</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="808" end_char="810">can</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="812" end_char="817">infect</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="819" end_char="823">cells</TOKEN>
<TOKEN id="token-6-15" pos="punct" morph="none" start_char="824" end_char="824">,</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="826" end_char="834">establish</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="836" end_char="836">a</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="838" end_char="843">latent</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="845" end_char="853">infection</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="855" end_char="857">and</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="859" end_char="862">then</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="864" end_char="865">be</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="867" end_char="877">reactivated</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="879" end_char="880">at</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="882" end_char="882">a</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="884" end_char="888">later</TOKEN>
<TOKEN id="token-6-27" pos="word" morph="none" start_char="890" end_char="893">date</TOKEN>
<TOKEN id="token-6-28" pos="punct" morph="none" start_char="894" end_char="895">,"</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="897" end_char="904">explains</TOKEN>
<TOKEN id="token-6-30" pos="word" morph="none" start_char="906" end_char="907">Dr</TOKEN>
<TOKEN id="token-6-31" pos="word" morph="none" start_char="909" end_char="914">Jeremy</TOKEN>
<TOKEN id="token-6-32" pos="word" morph="none" start_char="916" end_char="922">Rossman</TOKEN>
<TOKEN id="token-6-33" pos="punct" morph="none" start_char="923" end_char="923">,</TOKEN>
<TOKEN id="token-6-34" pos="word" morph="none" start_char="925" end_char="925">a</TOKEN>
<TOKEN id="token-6-35" pos="word" morph="none" start_char="927" end_char="936">virologist</TOKEN>
<TOKEN id="token-6-36" pos="word" morph="none" start_char="938" end_char="941">from</TOKEN>
<TOKEN id="token-6-37" pos="word" morph="none" start_char="943" end_char="945">the</TOKEN>
<TOKEN id="token-6-38" pos="word" morph="none" start_char="947" end_char="956">University</TOKEN>
<TOKEN id="token-6-39" pos="word" morph="none" start_char="958" end_char="959">of</TOKEN>
<TOKEN id="token-6-40" pos="word" morph="none" start_char="961" end_char="964">Kent</TOKEN>
<TOKEN id="token-6-41" pos="punct" morph="none" start_char="965" end_char="965">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="967" end_char="1044">
<ORIGINAL_TEXT>"However, it is unlikely that coronaviruses establish any latency or dormancy.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="punct" morph="none" start_char="967" end_char="967">"</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="968" end_char="974">However</TOKEN>
<TOKEN id="token-7-2" pos="punct" morph="none" start_char="975" end_char="975">,</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="977" end_char="978">it</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="980" end_char="981">is</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="983" end_char="990">unlikely</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="992" end_char="995">that</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="997" end_char="1009">coronaviruses</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="1011" end_char="1019">establish</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="1021" end_char="1023">any</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="1025" end_char="1031">latency</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="1033" end_char="1034">or</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="1036" end_char="1043">dormancy</TOKEN>
<TOKEN id="token-7-13" pos="punct" morph="none" start_char="1044" end_char="1044">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1047" end_char="1145">
<ORIGINAL_TEXT>"There is no evidence that SARS-CoV-2 can lie dormant or be activated by environmental conditions."</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="punct" morph="none" start_char="1047" end_char="1047">"</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1048" end_char="1052">There</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1054" end_char="1055">is</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1057" end_char="1058">no</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1060" end_char="1067">evidence</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1069" end_char="1072">that</TOKEN>
<TOKEN id="token-8-6" pos="unknown" morph="none" start_char="1074" end_char="1083">SARS-CoV-2</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1085" end_char="1087">can</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1089" end_char="1091">lie</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1093" end_char="1099">dormant</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1101" end_char="1102">or</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1104" end_char="1105">be</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1107" end_char="1115">activated</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1117" end_char="1118">by</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1120" end_char="1132">environmental</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1134" end_char="1143">conditions</TOKEN>
<TOKEN id="token-8-16" pos="punct" morph="none" start_char="1144" end_char="1145">."</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1148" end_char="1167">
<ORIGINAL_TEXT>In an interview with</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1148" end_char="1149">In</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1151" end_char="1152">an</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1154" end_char="1162">interview</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1164" end_char="1167">with</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1170" end_char="1188">
<ORIGINAL_TEXT>The Daily Telegraph</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1170" end_char="1172">The</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1174" end_char="1178">Daily</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1180" end_char="1188">Telegraph</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1191" end_char="1330">
<ORIGINAL_TEXT>, Dr Jefferson said of the studies finding SARS-CoV-2 in sewage, "the explanation could only be that these agents don’t come or go anywhere.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="punct" morph="none" start_char="1191" end_char="1191">,</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1193" end_char="1194">Dr</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1196" end_char="1204">Jefferson</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1206" end_char="1209">said</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1211" end_char="1212">of</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1214" end_char="1216">the</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1218" end_char="1224">studies</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1226" end_char="1232">finding</TOKEN>
<TOKEN id="token-11-8" pos="unknown" morph="none" start_char="1234" end_char="1243">SARS-CoV-2</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1245" end_char="1246">in</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1248" end_char="1253">sewage</TOKEN>
<TOKEN id="token-11-11" pos="punct" morph="none" start_char="1254" end_char="1254">,</TOKEN>
<TOKEN id="token-11-12" pos="punct" morph="none" start_char="1256" end_char="1256">"</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1257" end_char="1259">the</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1261" end_char="1271">explanation</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1273" end_char="1277">could</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1279" end_char="1282">only</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1284" end_char="1285">be</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1287" end_char="1290">that</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="1292" end_char="1296">these</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1298" end_char="1303">agents</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="1305" end_char="1309">don’t</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="1311" end_char="1314">come</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="1316" end_char="1317">or</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="1319" end_char="1320">go</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="1322" end_char="1329">anywhere</TOKEN>
<TOKEN id="token-11-26" pos="punct" morph="none" start_char="1330" end_char="1330">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1332" end_char="1380">
<ORIGINAL_TEXT>They are always here and something ignites them."</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1332" end_char="1335">They</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1337" end_char="1339">are</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1341" end_char="1346">always</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1348" end_char="1351">here</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1353" end_char="1355">and</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1357" end_char="1365">something</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1367" end_char="1373">ignites</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1375" end_char="1378">them</TOKEN>
<TOKEN id="token-12-8" pos="punct" morph="none" start_char="1379" end_char="1380">."</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1382" end_char="1395">
<ORIGINAL_TEXT>© Getty Images</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="unknown" morph="none" start_char="1382" end_char="1382">©</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1384" end_char="1388">Getty</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1390" end_char="1395">Images</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1398" end_char="1606">
<ORIGINAL_TEXT>Dr Rossman adds that "we know the SARS-CoV-2 virus rapidly degrades in the environment (such as on contaminated surfaces) and so it is very unlikely that the virus would be able to persist in the environment."</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1398" end_char="1399">Dr</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1401" end_char="1407">Rossman</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1409" end_char="1412">adds</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1414" end_char="1417">that</TOKEN>
<TOKEN id="token-14-4" pos="punct" morph="none" start_char="1419" end_char="1419">"</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1420" end_char="1421">we</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1423" end_char="1426">know</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1428" end_char="1430">the</TOKEN>
<TOKEN id="token-14-8" pos="unknown" morph="none" start_char="1432" end_char="1441">SARS-CoV-2</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1443" end_char="1447">virus</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1449" end_char="1455">rapidly</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1457" end_char="1464">degrades</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1466" end_char="1467">in</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1469" end_char="1471">the</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="1473" end_char="1483">environment</TOKEN>
<TOKEN id="token-14-15" pos="punct" morph="none" start_char="1485" end_char="1485">(</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1486" end_char="1489">such</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="1491" end_char="1492">as</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="1494" end_char="1495">on</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="1497" end_char="1508">contaminated</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="1510" end_char="1517">surfaces</TOKEN>
<TOKEN id="token-14-21" pos="punct" morph="none" start_char="1518" end_char="1518">)</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="1520" end_char="1522">and</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="1524" end_char="1525">so</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="1527" end_char="1528">it</TOKEN>
<TOKEN id="token-14-25" pos="word" morph="none" start_char="1530" end_char="1531">is</TOKEN>
<TOKEN id="token-14-26" pos="word" morph="none" start_char="1533" end_char="1536">very</TOKEN>
<TOKEN id="token-14-27" pos="word" morph="none" start_char="1538" end_char="1545">unlikely</TOKEN>
<TOKEN id="token-14-28" pos="word" morph="none" start_char="1547" end_char="1550">that</TOKEN>
<TOKEN id="token-14-29" pos="word" morph="none" start_char="1552" end_char="1554">the</TOKEN>
<TOKEN id="token-14-30" pos="word" morph="none" start_char="1556" end_char="1560">virus</TOKEN>
<TOKEN id="token-14-31" pos="word" morph="none" start_char="1562" end_char="1566">would</TOKEN>
<TOKEN id="token-14-32" pos="word" morph="none" start_char="1568" end_char="1569">be</TOKEN>
<TOKEN id="token-14-33" pos="word" morph="none" start_char="1571" end_char="1574">able</TOKEN>
<TOKEN id="token-14-34" pos="word" morph="none" start_char="1576" end_char="1577">to</TOKEN>
<TOKEN id="token-14-35" pos="word" morph="none" start_char="1579" end_char="1585">persist</TOKEN>
<TOKEN id="token-14-36" pos="word" morph="none" start_char="1587" end_char="1588">in</TOKEN>
<TOKEN id="token-14-37" pos="word" morph="none" start_char="1590" end_char="1592">the</TOKEN>
<TOKEN id="token-14-38" pos="word" morph="none" start_char="1594" end_char="1604">environment</TOKEN>
<TOKEN id="token-14-39" pos="punct" morph="none" start_char="1605" end_char="1606">."</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1609" end_char="1656">
<ORIGINAL_TEXT>What about the virus genomes found in Barcelona?</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1609" end_char="1612">What</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1614" end_char="1618">about</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1620" end_char="1622">the</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1624" end_char="1628">virus</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1630" end_char="1636">genomes</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1638" end_char="1642">found</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1644" end_char="1645">in</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1647" end_char="1655">Barcelona</TOKEN>
<TOKEN id="token-15-8" pos="punct" morph="none" start_char="1656" end_char="1656">?</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1660" end_char="1789">
<ORIGINAL_TEXT>The only suggested evidence for very early presence of the virus comes from a pre-print study that has not yet been peer reviewed.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1660" end_char="1662">The</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1664" end_char="1667">only</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1669" end_char="1677">suggested</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1679" end_char="1686">evidence</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1688" end_char="1690">for</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1692" end_char="1695">very</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1697" end_char="1701">early</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1703" end_char="1710">presence</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1712" end_char="1713">of</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="1715" end_char="1717">the</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="1719" end_char="1723">virus</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="1725" end_char="1729">comes</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="1731" end_char="1734">from</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="1736" end_char="1736">a</TOKEN>
<TOKEN id="token-16-14" pos="unknown" morph="none" start_char="1738" end_char="1746">pre-print</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="1748" end_char="1752">study</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="1754" end_char="1757">that</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="1759" end_char="1761">has</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="1763" end_char="1765">not</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="1767" end_char="1769">yet</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="1771" end_char="1774">been</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="1776" end_char="1779">peer</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="1781" end_char="1788">reviewed</TOKEN>
<TOKEN id="token-16-23" pos="punct" morph="none" start_char="1789" end_char="1789">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1792" end_char="1939">
<ORIGINAL_TEXT>"Without full peer review of the study it is premature to make any conclusions, as other factors may have influenced the results," warns Dr Rossman.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="punct" morph="none" start_char="1792" end_char="1792">"</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1793" end_char="1799">Without</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="1801" end_char="1804">full</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="1806" end_char="1809">peer</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="1811" end_char="1816">review</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="1818" end_char="1819">of</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="1821" end_char="1823">the</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="1825" end_char="1829">study</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="1831" end_char="1832">it</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="1834" end_char="1835">is</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="1837" end_char="1845">premature</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="1847" end_char="1848">to</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="1850" end_char="1853">make</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="1855" end_char="1857">any</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="1859" end_char="1869">conclusions</TOKEN>
<TOKEN id="token-17-15" pos="punct" morph="none" start_char="1870" end_char="1870">,</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="1872" end_char="1873">as</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="1875" end_char="1879">other</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="1881" end_char="1887">factors</TOKEN>
<TOKEN id="token-17-19" pos="word" morph="none" start_char="1889" end_char="1891">may</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="1893" end_char="1896">have</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="1898" end_char="1907">influenced</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="1909" end_char="1911">the</TOKEN>
<TOKEN id="token-17-23" pos="word" morph="none" start_char="1913" end_char="1919">results</TOKEN>
<TOKEN id="token-17-24" pos="punct" morph="none" start_char="1920" end_char="1921">,"</TOKEN>
<TOKEN id="token-17-25" pos="word" morph="none" start_char="1923" end_char="1927">warns</TOKEN>
<TOKEN id="token-17-26" pos="word" morph="none" start_char="1929" end_char="1930">Dr</TOKEN>
<TOKEN id="token-17-27" pos="word" morph="none" start_char="1932" end_char="1938">Rossman</TOKEN>
<TOKEN id="token-17-28" pos="punct" morph="none" start_char="1939" end_char="1939">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1942" end_char="1973">
<ORIGINAL_TEXT>Read more about the coronavirus:</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="1942" end_char="1945">Read</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="1947" end_char="1950">more</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="1952" end_char="1956">about</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="1958" end_char="1960">the</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="1962" end_char="1972">coronavirus</TOKEN>
<TOKEN id="token-18-5" pos="punct" morph="none" start_char="1973" end_char="1973">:</TOKEN>
</SEG>
<SEG id="segment-19" start_char="1976" end_char="2119">
<ORIGINAL_TEXT>"Of note, in the single early sample deemed positive, the virus genome was only detected in 2 out of 5 [tests] and at very low detection levels.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="punct" morph="none" start_char="1976" end_char="1976">"</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="1977" end_char="1978">Of</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="1980" end_char="1983">note</TOKEN>
<TOKEN id="token-19-3" pos="punct" morph="none" start_char="1984" end_char="1984">,</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="1986" end_char="1987">in</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="1989" end_char="1991">the</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="1993" end_char="1998">single</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2000" end_char="2004">early</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2006" end_char="2011">sample</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="2013" end_char="2018">deemed</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="2020" end_char="2027">positive</TOKEN>
<TOKEN id="token-19-11" pos="punct" morph="none" start_char="2028" end_char="2028">,</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="2030" end_char="2032">the</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="2034" end_char="2038">virus</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="2040" end_char="2045">genome</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="2047" end_char="2049">was</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="2051" end_char="2054">only</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="2056" end_char="2063">detected</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="2065" end_char="2066">in</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="2068" end_char="2068">2</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="2070" end_char="2072">out</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="2074" end_char="2075">of</TOKEN>
<TOKEN id="token-19-22" pos="word" morph="none" start_char="2077" end_char="2077">5</TOKEN>
<TOKEN id="token-19-23" pos="punct" morph="none" start_char="2079" end_char="2079">[</TOKEN>
<TOKEN id="token-19-24" pos="word" morph="none" start_char="2080" end_char="2084">tests</TOKEN>
<TOKEN id="token-19-25" pos="punct" morph="none" start_char="2085" end_char="2085">]</TOKEN>
<TOKEN id="token-19-26" pos="word" morph="none" start_char="2087" end_char="2089">and</TOKEN>
<TOKEN id="token-19-27" pos="word" morph="none" start_char="2091" end_char="2092">at</TOKEN>
<TOKEN id="token-19-28" pos="word" morph="none" start_char="2094" end_char="2097">very</TOKEN>
<TOKEN id="token-19-29" pos="word" morph="none" start_char="2099" end_char="2101">low</TOKEN>
<TOKEN id="token-19-30" pos="word" morph="none" start_char="2103" end_char="2111">detection</TOKEN>
<TOKEN id="token-19-31" pos="word" morph="none" start_char="2113" end_char="2118">levels</TOKEN>
<TOKEN id="token-19-32" pos="punct" morph="none" start_char="2119" end_char="2119">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2122" end_char="2260">
<ORIGINAL_TEXT>"This raises the possibility that it was not SARS-CoV-2 that was detected, but could be cross-reactivity with another virus or contaminant.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="punct" morph="none" start_char="2122" end_char="2122">"</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2123" end_char="2126">This</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2128" end_char="2133">raises</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2135" end_char="2137">the</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2139" end_char="2149">possibility</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2151" end_char="2154">that</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2156" end_char="2157">it</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2159" end_char="2161">was</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="2163" end_char="2165">not</TOKEN>
<TOKEN id="token-20-9" pos="unknown" morph="none" start_char="2167" end_char="2176">SARS-CoV-2</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2178" end_char="2181">that</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="2183" end_char="2185">was</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="2187" end_char="2194">detected</TOKEN>
<TOKEN id="token-20-13" pos="punct" morph="none" start_char="2195" end_char="2195">,</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="2197" end_char="2199">but</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="2201" end_char="2205">could</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="2207" end_char="2208">be</TOKEN>
<TOKEN id="token-20-17" pos="unknown" morph="none" start_char="2210" end_char="2225">cross-reactivity</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="2227" end_char="2230">with</TOKEN>
<TOKEN id="token-20-19" pos="word" morph="none" start_char="2232" end_char="2238">another</TOKEN>
<TOKEN id="token-20-20" pos="word" morph="none" start_char="2240" end_char="2244">virus</TOKEN>
<TOKEN id="token-20-21" pos="word" morph="none" start_char="2246" end_char="2247">or</TOKEN>
<TOKEN id="token-20-22" pos="word" morph="none" start_char="2249" end_char="2259">contaminant</TOKEN>
<TOKEN id="token-20-23" pos="punct" morph="none" start_char="2260" end_char="2260">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2262" end_char="2457">
<ORIGINAL_TEXT>For example, perhaps a local outbreak of another, related coronavirus occurred during that time period and some of the [tests] could not fully distinguish between that coronavirus and SARS-CoV-2."</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2262" end_char="2264">For</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2266" end_char="2272">example</TOKEN>
<TOKEN id="token-21-2" pos="punct" morph="none" start_char="2273" end_char="2273">,</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2275" end_char="2281">perhaps</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2283" end_char="2283">a</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="2285" end_char="2289">local</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2291" end_char="2298">outbreak</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="2300" end_char="2301">of</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="2303" end_char="2309">another</TOKEN>
<TOKEN id="token-21-9" pos="punct" morph="none" start_char="2310" end_char="2310">,</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="2312" end_char="2318">related</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="2320" end_char="2330">coronavirus</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="2332" end_char="2339">occurred</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="2341" end_char="2346">during</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="2348" end_char="2351">that</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="2353" end_char="2356">time</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="2358" end_char="2363">period</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="2365" end_char="2367">and</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="2369" end_char="2372">some</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="2374" end_char="2375">of</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="2377" end_char="2379">the</TOKEN>
<TOKEN id="token-21-21" pos="punct" morph="none" start_char="2381" end_char="2381">[</TOKEN>
<TOKEN id="token-21-22" pos="word" morph="none" start_char="2382" end_char="2386">tests</TOKEN>
<TOKEN id="token-21-23" pos="punct" morph="none" start_char="2387" end_char="2387">]</TOKEN>
<TOKEN id="token-21-24" pos="word" morph="none" start_char="2389" end_char="2393">could</TOKEN>
<TOKEN id="token-21-25" pos="word" morph="none" start_char="2395" end_char="2397">not</TOKEN>
<TOKEN id="token-21-26" pos="word" morph="none" start_char="2399" end_char="2403">fully</TOKEN>
<TOKEN id="token-21-27" pos="word" morph="none" start_char="2405" end_char="2415">distinguish</TOKEN>
<TOKEN id="token-21-28" pos="word" morph="none" start_char="2417" end_char="2423">between</TOKEN>
<TOKEN id="token-21-29" pos="word" morph="none" start_char="2425" end_char="2428">that</TOKEN>
<TOKEN id="token-21-30" pos="word" morph="none" start_char="2430" end_char="2440">coronavirus</TOKEN>
<TOKEN id="token-21-31" pos="word" morph="none" start_char="2442" end_char="2444">and</TOKEN>
<TOKEN id="token-21-32" pos="unknown" morph="none" start_char="2446" end_char="2455">SARS-CoV-2</TOKEN>
<TOKEN id="token-21-33" pos="punct" morph="none" start_char="2456" end_char="2457">."</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2460" end_char="2517">
<ORIGINAL_TEXT>What evidence is there that the virus originated in China?</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2460" end_char="2463">What</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2465" end_char="2472">evidence</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2474" end_char="2475">is</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2477" end_char="2481">there</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2483" end_char="2486">that</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2488" end_char="2490">the</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2492" end_char="2496">virus</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2498" end_char="2507">originated</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="2509" end_char="2510">in</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="2512" end_char="2516">China</TOKEN>
<TOKEN id="token-22-10" pos="punct" morph="none" start_char="2517" end_char="2517">?</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2521" end_char="2851">
<ORIGINAL_TEXT>Dr Rossman says that currently, the best evidence for the location and date of SARS-CoV-2 emergence into the human population comes from the early detection of positive cases in China and from the determination of cases presumed to be caused by SARS-Cov-2 through the symptoms exhibited (the study of which is called symptomology).</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2521" end_char="2522">Dr</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2524" end_char="2530">Rossman</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2532" end_char="2535">says</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2537" end_char="2540">that</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="2542" end_char="2550">currently</TOKEN>
<TOKEN id="token-23-5" pos="punct" morph="none" start_char="2551" end_char="2551">,</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="2553" end_char="2555">the</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="2557" end_char="2560">best</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="2562" end_char="2569">evidence</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="2571" end_char="2573">for</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="2575" end_char="2577">the</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="2579" end_char="2586">location</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="2588" end_char="2590">and</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="2592" end_char="2595">date</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="2597" end_char="2598">of</TOKEN>
<TOKEN id="token-23-15" pos="unknown" morph="none" start_char="2600" end_char="2609">SARS-CoV-2</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="2611" end_char="2619">emergence</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="2621" end_char="2624">into</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="2626" end_char="2628">the</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="2630" end_char="2634">human</TOKEN>
<TOKEN id="token-23-20" pos="word" morph="none" start_char="2636" end_char="2645">population</TOKEN>
<TOKEN id="token-23-21" pos="word" morph="none" start_char="2647" end_char="2651">comes</TOKEN>
<TOKEN id="token-23-22" pos="word" morph="none" start_char="2653" end_char="2656">from</TOKEN>
<TOKEN id="token-23-23" pos="word" morph="none" start_char="2658" end_char="2660">the</TOKEN>
<TOKEN id="token-23-24" pos="word" morph="none" start_char="2662" end_char="2666">early</TOKEN>
<TOKEN id="token-23-25" pos="word" morph="none" start_char="2668" end_char="2676">detection</TOKEN>
<TOKEN id="token-23-26" pos="word" morph="none" start_char="2678" end_char="2679">of</TOKEN>
<TOKEN id="token-23-27" pos="word" morph="none" start_char="2681" end_char="2688">positive</TOKEN>
<TOKEN id="token-23-28" pos="word" morph="none" start_char="2690" end_char="2694">cases</TOKEN>
<TOKEN id="token-23-29" pos="word" morph="none" start_char="2696" end_char="2697">in</TOKEN>
<TOKEN id="token-23-30" pos="word" morph="none" start_char="2699" end_char="2703">China</TOKEN>
<TOKEN id="token-23-31" pos="word" morph="none" start_char="2705" end_char="2707">and</TOKEN>
<TOKEN id="token-23-32" pos="word" morph="none" start_char="2709" end_char="2712">from</TOKEN>
<TOKEN id="token-23-33" pos="word" morph="none" start_char="2714" end_char="2716">the</TOKEN>
<TOKEN id="token-23-34" pos="word" morph="none" start_char="2718" end_char="2730">determination</TOKEN>
<TOKEN id="token-23-35" pos="word" morph="none" start_char="2732" end_char="2733">of</TOKEN>
<TOKEN id="token-23-36" pos="word" morph="none" start_char="2735" end_char="2739">cases</TOKEN>
<TOKEN id="token-23-37" pos="word" morph="none" start_char="2741" end_char="2748">presumed</TOKEN>
<TOKEN id="token-23-38" pos="word" morph="none" start_char="2750" end_char="2751">to</TOKEN>
<TOKEN id="token-23-39" pos="word" morph="none" start_char="2753" end_char="2754">be</TOKEN>
<TOKEN id="token-23-40" pos="word" morph="none" start_char="2756" end_char="2761">caused</TOKEN>
<TOKEN id="token-23-41" pos="word" morph="none" start_char="2763" end_char="2764">by</TOKEN>
<TOKEN id="token-23-42" pos="unknown" morph="none" start_char="2766" end_char="2775">SARS-Cov-2</TOKEN>
<TOKEN id="token-23-43" pos="word" morph="none" start_char="2777" end_char="2783">through</TOKEN>
<TOKEN id="token-23-44" pos="word" morph="none" start_char="2785" end_char="2787">the</TOKEN>
<TOKEN id="token-23-45" pos="word" morph="none" start_char="2789" end_char="2796">symptoms</TOKEN>
<TOKEN id="token-23-46" pos="word" morph="none" start_char="2798" end_char="2806">exhibited</TOKEN>
<TOKEN id="token-23-47" pos="punct" morph="none" start_char="2808" end_char="2808">(</TOKEN>
<TOKEN id="token-23-48" pos="word" morph="none" start_char="2809" end_char="2811">the</TOKEN>
<TOKEN id="token-23-49" pos="word" morph="none" start_char="2813" end_char="2817">study</TOKEN>
<TOKEN id="token-23-50" pos="word" morph="none" start_char="2819" end_char="2820">of</TOKEN>
<TOKEN id="token-23-51" pos="word" morph="none" start_char="2822" end_char="2826">which</TOKEN>
<TOKEN id="token-23-52" pos="word" morph="none" start_char="2828" end_char="2829">is</TOKEN>
<TOKEN id="token-23-53" pos="word" morph="none" start_char="2831" end_char="2836">called</TOKEN>
<TOKEN id="token-23-54" pos="word" morph="none" start_char="2838" end_char="2849">symptomology</TOKEN>
<TOKEN id="token-23-55" pos="punct" morph="none" start_char="2850" end_char="2851">).</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2853" end_char="3020">
<ORIGINAL_TEXT>It’s also possible to use molecular dating when forming a timeline for viral emergence, using human samples and analysing the different mutations of the virus’s genome.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="2853" end_char="2856">It’s</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="2858" end_char="2861">also</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="2863" end_char="2870">possible</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="2872" end_char="2873">to</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="2875" end_char="2877">use</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="2879" end_char="2887">molecular</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="2889" end_char="2894">dating</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="2896" end_char="2899">when</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="2901" end_char="2907">forming</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="2909" end_char="2909">a</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="2911" end_char="2918">timeline</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="2920" end_char="2922">for</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="2924" end_char="2928">viral</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="2930" end_char="2938">emergence</TOKEN>
<TOKEN id="token-24-14" pos="punct" morph="none" start_char="2939" end_char="2939">,</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="2941" end_char="2945">using</TOKEN>
<TOKEN id="token-24-16" pos="word" morph="none" start_char="2947" end_char="2951">human</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="2953" end_char="2959">samples</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="2961" end_char="2963">and</TOKEN>
<TOKEN id="token-24-19" pos="word" morph="none" start_char="2965" end_char="2973">analysing</TOKEN>
<TOKEN id="token-24-20" pos="word" morph="none" start_char="2975" end_char="2977">the</TOKEN>
<TOKEN id="token-24-21" pos="word" morph="none" start_char="2979" end_char="2987">different</TOKEN>
<TOKEN id="token-24-22" pos="word" morph="none" start_char="2989" end_char="2997">mutations</TOKEN>
<TOKEN id="token-24-23" pos="word" morph="none" start_char="2999" end_char="3000">of</TOKEN>
<TOKEN id="token-24-24" pos="word" morph="none" start_char="3002" end_char="3004">the</TOKEN>
<TOKEN id="token-24-25" pos="word" morph="none" start_char="3006" end_char="3012">virus’s</TOKEN>
<TOKEN id="token-24-26" pos="word" morph="none" start_char="3014" end_char="3019">genome</TOKEN>
<TOKEN id="token-24-27" pos="punct" morph="none" start_char="3020" end_char="3020">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="3023" end_char="3157">
<ORIGINAL_TEXT>In Scotland, sewage is being tested for traces of COVID-19 in a trial aimed at helping monitor the spread of coronavirus © Getty Images</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="3023" end_char="3024">In</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="3026" end_char="3033">Scotland</TOKEN>
<TOKEN id="token-25-2" pos="punct" morph="none" start_char="3034" end_char="3034">,</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="3036" end_char="3041">sewage</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="3043" end_char="3044">is</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="3046" end_char="3050">being</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="3052" end_char="3057">tested</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="3059" end_char="3061">for</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="3063" end_char="3068">traces</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="3070" end_char="3071">of</TOKEN>
<TOKEN id="token-25-10" pos="unknown" morph="none" start_char="3073" end_char="3080">COVID-19</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="3082" end_char="3083">in</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="3085" end_char="3085">a</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="3087" end_char="3091">trial</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="3093" end_char="3097">aimed</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="3099" end_char="3100">at</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="3102" end_char="3108">helping</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="3110" end_char="3116">monitor</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="3118" end_char="3120">the</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="3122" end_char="3127">spread</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="3129" end_char="3130">of</TOKEN>
<TOKEN id="token-25-21" pos="word" morph="none" start_char="3132" end_char="3142">coronavirus</TOKEN>
<TOKEN id="token-25-22" pos="unknown" morph="none" start_char="3144" end_char="3144">©</TOKEN>
<TOKEN id="token-25-23" pos="word" morph="none" start_char="3146" end_char="3150">Getty</TOKEN>
<TOKEN id="token-25-24" pos="word" morph="none" start_char="3152" end_char="3157">Images</TOKEN>
</SEG>
<SEG id="segment-26" start_char="3160" end_char="3252">
<ORIGINAL_TEXT>"This combination of data puts viral emergence in China between October and December of 2019.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="punct" morph="none" start_char="3160" end_char="3160">"</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="3161" end_char="3164">This</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="3166" end_char="3176">combination</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="3178" end_char="3179">of</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="3181" end_char="3184">data</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="3186" end_char="3189">puts</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="3191" end_char="3195">viral</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="3197" end_char="3205">emergence</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="3207" end_char="3208">in</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="3210" end_char="3214">China</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="3216" end_char="3222">between</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="3224" end_char="3230">October</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="3232" end_char="3234">and</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="3236" end_char="3243">December</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="3245" end_char="3246">of</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="3248" end_char="3251">2019</TOKEN>
<TOKEN id="token-26-16" pos="punct" morph="none" start_char="3252" end_char="3252">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="3255" end_char="3527">
<ORIGINAL_TEXT>"Our current data does not specifically pinpoint the geographical area where the virus emerged, so we cannot specifically confirm emergence in Wuhan; however, the number of early case reports and diagnostic testing is highly convincing for emergence in China in late 2019."</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="punct" morph="none" start_char="3255" end_char="3255">"</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="3256" end_char="3258">Our</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="3260" end_char="3266">current</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="3268" end_char="3271">data</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="3273" end_char="3276">does</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="3278" end_char="3280">not</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="3282" end_char="3293">specifically</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="3295" end_char="3302">pinpoint</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="3304" end_char="3306">the</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="3308" end_char="3319">geographical</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="3321" end_char="3324">area</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="3326" end_char="3330">where</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="3332" end_char="3334">the</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="3336" end_char="3340">virus</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="3342" end_char="3348">emerged</TOKEN>
<TOKEN id="token-27-15" pos="punct" morph="none" start_char="3349" end_char="3349">,</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="3351" end_char="3352">so</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="3354" end_char="3355">we</TOKEN>
<TOKEN id="token-27-18" pos="word" morph="none" start_char="3357" end_char="3362">cannot</TOKEN>
<TOKEN id="token-27-19" pos="word" morph="none" start_char="3364" end_char="3375">specifically</TOKEN>
<TOKEN id="token-27-20" pos="word" morph="none" start_char="3377" end_char="3383">confirm</TOKEN>
<TOKEN id="token-27-21" pos="word" morph="none" start_char="3385" end_char="3393">emergence</TOKEN>
<TOKEN id="token-27-22" pos="word" morph="none" start_char="3395" end_char="3396">in</TOKEN>
<TOKEN id="token-27-23" pos="word" morph="none" start_char="3398" end_char="3402">Wuhan</TOKEN>
<TOKEN id="token-27-24" pos="punct" morph="none" start_char="3403" end_char="3403">;</TOKEN>
<TOKEN id="token-27-25" pos="word" morph="none" start_char="3405" end_char="3411">however</TOKEN>
<TOKEN id="token-27-26" pos="punct" morph="none" start_char="3412" end_char="3412">,</TOKEN>
<TOKEN id="token-27-27" pos="word" morph="none" start_char="3414" end_char="3416">the</TOKEN>
<TOKEN id="token-27-28" pos="word" morph="none" start_char="3418" end_char="3423">number</TOKEN>
<TOKEN id="token-27-29" pos="word" morph="none" start_char="3425" end_char="3426">of</TOKEN>
<TOKEN id="token-27-30" pos="word" morph="none" start_char="3428" end_char="3432">early</TOKEN>
<TOKEN id="token-27-31" pos="word" morph="none" start_char="3434" end_char="3437">case</TOKEN>
<TOKEN id="token-27-32" pos="word" morph="none" start_char="3439" end_char="3445">reports</TOKEN>
<TOKEN id="token-27-33" pos="word" morph="none" start_char="3447" end_char="3449">and</TOKEN>
<TOKEN id="token-27-34" pos="word" morph="none" start_char="3451" end_char="3460">diagnostic</TOKEN>
<TOKEN id="token-27-35" pos="word" morph="none" start_char="3462" end_char="3468">testing</TOKEN>
<TOKEN id="token-27-36" pos="word" morph="none" start_char="3470" end_char="3471">is</TOKEN>
<TOKEN id="token-27-37" pos="word" morph="none" start_char="3473" end_char="3478">highly</TOKEN>
<TOKEN id="token-27-38" pos="word" morph="none" start_char="3480" end_char="3489">convincing</TOKEN>
<TOKEN id="token-27-39" pos="word" morph="none" start_char="3491" end_char="3493">for</TOKEN>
<TOKEN id="token-27-40" pos="word" morph="none" start_char="3495" end_char="3503">emergence</TOKEN>
<TOKEN id="token-27-41" pos="word" morph="none" start_char="3505" end_char="3506">in</TOKEN>
<TOKEN id="token-27-42" pos="word" morph="none" start_char="3508" end_char="3512">China</TOKEN>
<TOKEN id="token-27-43" pos="word" morph="none" start_char="3514" end_char="3515">in</TOKEN>
<TOKEN id="token-27-44" pos="word" morph="none" start_char="3517" end_char="3520">late</TOKEN>
<TOKEN id="token-27-45" pos="word" morph="none" start_char="3522" end_char="3525">2019</TOKEN>
<TOKEN id="token-27-46" pos="punct" morph="none" start_char="3526" end_char="3527">."</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3530" end_char="3663">
<ORIGINAL_TEXT>"Finding evidence of the virus in humans (or human samples such as sewage) in March 2019 would be highly surprising," says Dr Rossman.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="punct" morph="none" start_char="3530" end_char="3530">"</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="3531" end_char="3537">Finding</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="3539" end_char="3546">evidence</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="3548" end_char="3549">of</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="3551" end_char="3553">the</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="3555" end_char="3559">virus</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="3561" end_char="3562">in</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="3564" end_char="3569">humans</TOKEN>
<TOKEN id="token-28-8" pos="punct" morph="none" start_char="3571" end_char="3571">(</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="3572" end_char="3573">or</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="3575" end_char="3579">human</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="3581" end_char="3587">samples</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="3589" end_char="3592">such</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="3594" end_char="3595">as</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="3597" end_char="3602">sewage</TOKEN>
<TOKEN id="token-28-15" pos="punct" morph="none" start_char="3603" end_char="3603">)</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="3605" end_char="3606">in</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="3608" end_char="3612">March</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="3614" end_char="3617">2019</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="3619" end_char="3623">would</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="3625" end_char="3626">be</TOKEN>
<TOKEN id="token-28-21" pos="word" morph="none" start_char="3628" end_char="3633">highly</TOKEN>
<TOKEN id="token-28-22" pos="word" morph="none" start_char="3635" end_char="3644">surprising</TOKEN>
<TOKEN id="token-28-23" pos="punct" morph="none" start_char="3645" end_char="3646">,"</TOKEN>
<TOKEN id="token-28-24" pos="word" morph="none" start_char="3648" end_char="3651">says</TOKEN>
<TOKEN id="token-28-25" pos="word" morph="none" start_char="3653" end_char="3654">Dr</TOKEN>
<TOKEN id="token-28-26" pos="word" morph="none" start_char="3656" end_char="3662">Rossman</TOKEN>
<TOKEN id="token-28-27" pos="punct" morph="none" start_char="3663" end_char="3663">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3666" end_char="3715">
<ORIGINAL_TEXT>Reader Q How long can a virus live outside a body?</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="3666" end_char="3671">Reader</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="3673" end_char="3673">Q</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="3675" end_char="3677">How</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="3679" end_char="3682">long</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="3684" end_char="3686">can</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="3688" end_char="3688">a</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="3690" end_char="3694">virus</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="3696" end_char="3699">live</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="3701" end_char="3707">outside</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="3709" end_char="3709">a</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="3711" end_char="3714">body</TOKEN>
<TOKEN id="token-29-11" pos="punct" morph="none" start_char="3715" end_char="3715">?</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3719" end_char="3750">
<ORIGINAL_TEXT>Asked by: Chaudhary Nikul, India</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="3719" end_char="3723">Asked</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="3725" end_char="3726">by</TOKEN>
<TOKEN id="token-30-2" pos="punct" morph="none" start_char="3727" end_char="3727">:</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="3729" end_char="3737">Chaudhary</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="3739" end_char="3743">Nikul</TOKEN>
<TOKEN id="token-30-5" pos="punct" morph="none" start_char="3744" end_char="3744">,</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="3746" end_char="3750">India</TOKEN>
</SEG>
<SEG id="segment-31" start_char="3753" end_char="3874">
<ORIGINAL_TEXT>Viruses can live for a surprisingly long time outside of a body, depending on conditions such as moisture and temperature.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="3753" end_char="3759">Viruses</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="3761" end_char="3763">can</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="3765" end_char="3768">live</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="3770" end_char="3772">for</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="3774" end_char="3774">a</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="3776" end_char="3787">surprisingly</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="3789" end_char="3792">long</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="3794" end_char="3797">time</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="3799" end_char="3805">outside</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="3807" end_char="3808">of</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="3810" end_char="3810">a</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="3812" end_char="3815">body</TOKEN>
<TOKEN id="token-31-12" pos="punct" morph="none" start_char="3816" end_char="3816">,</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="3818" end_char="3826">depending</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="3828" end_char="3829">on</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="3831" end_char="3840">conditions</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="3842" end_char="3845">such</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="3847" end_char="3848">as</TOKEN>
<TOKEN id="token-31-18" pos="word" morph="none" start_char="3850" end_char="3857">moisture</TOKEN>
<TOKEN id="token-31-19" pos="word" morph="none" start_char="3859" end_char="3861">and</TOKEN>
<TOKEN id="token-31-20" pos="word" morph="none" start_char="3863" end_char="3873">temperature</TOKEN>
<TOKEN id="token-31-21" pos="punct" morph="none" start_char="3874" end_char="3874">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="3876" end_char="3966">
<ORIGINAL_TEXT>They tend to live longer on water-resistant surfaces, such as stainless steel and plastics.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="3876" end_char="3879">They</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="3881" end_char="3884">tend</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="3886" end_char="3887">to</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="3889" end_char="3892">live</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="3894" end_char="3899">longer</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="3901" end_char="3902">on</TOKEN>
<TOKEN id="token-32-6" pos="unknown" morph="none" start_char="3904" end_char="3918">water-resistant</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="3920" end_char="3927">surfaces</TOKEN>
<TOKEN id="token-32-8" pos="punct" morph="none" start_char="3928" end_char="3928">,</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="3930" end_char="3933">such</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="3935" end_char="3936">as</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="3938" end_char="3946">stainless</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="3948" end_char="3952">steel</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="3954" end_char="3956">and</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="3958" end_char="3965">plastics</TOKEN>
<TOKEN id="token-32-15" pos="punct" morph="none" start_char="3966" end_char="3966">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="3969" end_char="4109">
<ORIGINAL_TEXT>A cold virus can sometimes survive on indoor surfaces for several days, although its ability to cause infection drops dramatically over time.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="3969" end_char="3969">A</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="3971" end_char="3974">cold</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="3976" end_char="3980">virus</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="3982" end_char="3984">can</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="3986" end_char="3994">sometimes</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="3996" end_char="4002">survive</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="4004" end_char="4005">on</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="4007" end_char="4012">indoor</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="4014" end_char="4021">surfaces</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="4023" end_char="4025">for</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="4027" end_char="4033">several</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="4035" end_char="4038">days</TOKEN>
<TOKEN id="token-33-12" pos="punct" morph="none" start_char="4039" end_char="4039">,</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="4041" end_char="4048">although</TOKEN>
<TOKEN id="token-33-14" pos="word" morph="none" start_char="4050" end_char="4052">its</TOKEN>
<TOKEN id="token-33-15" pos="word" morph="none" start_char="4054" end_char="4060">ability</TOKEN>
<TOKEN id="token-33-16" pos="word" morph="none" start_char="4062" end_char="4063">to</TOKEN>
<TOKEN id="token-33-17" pos="word" morph="none" start_char="4065" end_char="4069">cause</TOKEN>
<TOKEN id="token-33-18" pos="word" morph="none" start_char="4071" end_char="4079">infection</TOKEN>
<TOKEN id="token-33-19" pos="word" morph="none" start_char="4081" end_char="4085">drops</TOKEN>
<TOKEN id="token-33-20" pos="word" morph="none" start_char="4087" end_char="4098">dramatically</TOKEN>
<TOKEN id="token-33-21" pos="word" morph="none" start_char="4100" end_char="4103">over</TOKEN>
<TOKEN id="token-33-22" pos="word" morph="none" start_char="4105" end_char="4108">time</TOKEN>
<TOKEN id="token-33-23" pos="punct" morph="none" start_char="4109" end_char="4109">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="4112" end_char="4272">
<ORIGINAL_TEXT>Flu viruses can survive in the air for several hours, especially at lower temperatures, and on hard surfaces they can survive and remain infectious for 24 hours.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="4112" end_char="4114">Flu</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="4116" end_char="4122">viruses</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="4124" end_char="4126">can</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="4128" end_char="4134">survive</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="4136" end_char="4137">in</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="4139" end_char="4141">the</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="4143" end_char="4145">air</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="4147" end_char="4149">for</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="4151" end_char="4157">several</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="4159" end_char="4163">hours</TOKEN>
<TOKEN id="token-34-10" pos="punct" morph="none" start_char="4164" end_char="4164">,</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="4166" end_char="4175">especially</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="4177" end_char="4178">at</TOKEN>
<TOKEN id="token-34-13" pos="word" morph="none" start_char="4180" end_char="4184">lower</TOKEN>
<TOKEN id="token-34-14" pos="word" morph="none" start_char="4186" end_char="4197">temperatures</TOKEN>
<TOKEN id="token-34-15" pos="punct" morph="none" start_char="4198" end_char="4198">,</TOKEN>
<TOKEN id="token-34-16" pos="word" morph="none" start_char="4200" end_char="4202">and</TOKEN>
<TOKEN id="token-34-17" pos="word" morph="none" start_char="4204" end_char="4205">on</TOKEN>
<TOKEN id="token-34-18" pos="word" morph="none" start_char="4207" end_char="4210">hard</TOKEN>
<TOKEN id="token-34-19" pos="word" morph="none" start_char="4212" end_char="4219">surfaces</TOKEN>
<TOKEN id="token-34-20" pos="word" morph="none" start_char="4221" end_char="4224">they</TOKEN>
<TOKEN id="token-34-21" pos="word" morph="none" start_char="4226" end_char="4228">can</TOKEN>
<TOKEN id="token-34-22" pos="word" morph="none" start_char="4230" end_char="4236">survive</TOKEN>
<TOKEN id="token-34-23" pos="word" morph="none" start_char="4238" end_char="4240">and</TOKEN>
<TOKEN id="token-34-24" pos="word" morph="none" start_char="4242" end_char="4247">remain</TOKEN>
<TOKEN id="token-34-25" pos="word" morph="none" start_char="4249" end_char="4258">infectious</TOKEN>
<TOKEN id="token-34-26" pos="word" morph="none" start_char="4260" end_char="4262">for</TOKEN>
<TOKEN id="token-34-27" pos="word" morph="none" start_char="4264" end_char="4265">24</TOKEN>
<TOKEN id="token-34-28" pos="word" morph="none" start_char="4267" end_char="4271">hours</TOKEN>
<TOKEN id="token-34-29" pos="punct" morph="none" start_char="4272" end_char="4272">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="4275" end_char="4388">
<ORIGINAL_TEXT>Enteric viruses, such as norovirus and hepatitis A, can survive for weeks on a surface if conditions are suitable.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="4275" end_char="4281">Enteric</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="4283" end_char="4289">viruses</TOKEN>
<TOKEN id="token-35-2" pos="punct" morph="none" start_char="4290" end_char="4290">,</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="4292" end_char="4295">such</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="4297" end_char="4298">as</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="4300" end_char="4308">norovirus</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="4310" end_char="4312">and</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="4314" end_char="4322">hepatitis</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="4324" end_char="4324">A</TOKEN>
<TOKEN id="token-35-9" pos="punct" morph="none" start_char="4325" end_char="4325">,</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="4327" end_char="4329">can</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="4331" end_char="4337">survive</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="4339" end_char="4341">for</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="4343" end_char="4347">weeks</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="4349" end_char="4350">on</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="4352" end_char="4352">a</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="4354" end_char="4360">surface</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="4362" end_char="4363">if</TOKEN>
<TOKEN id="token-35-18" pos="word" morph="none" start_char="4365" end_char="4374">conditions</TOKEN>
<TOKEN id="token-35-19" pos="word" morph="none" start_char="4376" end_char="4378">are</TOKEN>
<TOKEN id="token-35-20" pos="word" morph="none" start_char="4380" end_char="4387">suitable</TOKEN>
<TOKEN id="token-35-21" pos="punct" morph="none" start_char="4388" end_char="4388">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="4390" end_char="4482">
<ORIGINAL_TEXT>The norovirus is known for causing sickness outbreaks in schools, cruise ships and hospitals.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="4390" end_char="4392">The</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="4394" end_char="4402">norovirus</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="4404" end_char="4405">is</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="4407" end_char="4411">known</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="4413" end_char="4415">for</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="4417" end_char="4423">causing</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="4425" end_char="4432">sickness</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="4434" end_char="4442">outbreaks</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="4444" end_char="4445">in</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="4447" end_char="4453">schools</TOKEN>
<TOKEN id="token-36-10" pos="punct" morph="none" start_char="4454" end_char="4454">,</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="4456" end_char="4461">cruise</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="4463" end_char="4467">ships</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="4469" end_char="4471">and</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="4473" end_char="4481">hospitals</TOKEN>
<TOKEN id="token-36-15" pos="punct" morph="none" start_char="4482" end_char="4482">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="4485" end_char="4494">
<ORIGINAL_TEXT>Read more:</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="4485" end_char="4488">Read</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="4490" end_char="4493">more</TOKEN>
<TOKEN id="token-37-2" pos="punct" morph="none" start_char="4494" end_char="4494">:</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
