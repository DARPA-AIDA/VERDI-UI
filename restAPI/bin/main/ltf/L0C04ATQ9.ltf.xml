<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATQ9" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="4236" raw_text_md5="b27336146430fd6c4e0ea4d7ce0baa0d">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="18">
<ORIGINAL_TEXT>¿Y si llegó antes?</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="punct" morph="none" start_char="1" end_char="1">¿</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="2" end_char="2">Y</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="4" end_char="5">si</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="7" end_char="11">llegó</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="13" end_char="17">antes</TOKEN>
<TOKEN id="token-0-5" pos="punct" morph="none" start_char="18" end_char="18">?</TOKEN>
</SEG>
<SEG id="segment-1" start_char="20" end_char="81">
<ORIGINAL_TEXT>El coronavirus circuló de forma latente en China desde octubre</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="20" end_char="21">El</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="23" end_char="33">coronavirus</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="35" end_char="41">circuló</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="43" end_char="44">de</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="46" end_char="50">forma</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="52" end_char="58">latente</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="60" end_char="61">en</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="63" end_char="67">China</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="69" end_char="73">desde</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="75" end_char="81">octubre</TOKEN>
</SEG>
<SEG id="segment-2" start_char="86" end_char="102">
<ORIGINAL_TEXT>Coronavirus China</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="86" end_char="96">Coronavirus</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="98" end_char="102">China</TOKEN>
</SEG>
<SEG id="segment-3" start_char="105" end_char="137">
<ORIGINAL_TEXT>¿Ya estaba en octubre circulando?</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="punct" morph="none" start_char="105" end_char="105">¿</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="106" end_char="107">Ya</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="109" end_char="114">estaba</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="116" end_char="117">en</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="119" end_char="125">octubre</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="127" end_char="136">circulando</TOKEN>
<TOKEN id="token-3-6" pos="punct" morph="none" start_char="137" end_char="137">?</TOKEN>
</SEG>
<SEG id="segment-4" start_char="139" end_char="175">
<ORIGINAL_TEXT>Algunos estudios ya apuntan a que sí.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="139" end_char="145">Algunos</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="147" end_char="154">estudios</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="156" end_char="157">ya</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="159" end_char="165">apuntan</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="167" end_char="167">a</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="169" end_char="171">que</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="173" end_char="174">sí</TOKEN>
<TOKEN id="token-4-7" pos="punct" morph="none" start_char="175" end_char="175">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="177" end_char="504">
<ORIGINAL_TEXT>El coronavirus SARS-CoV-2, causante de la pandemia de coronavirus, ya circulaba de forma latente y silenciosa en Wuhan en el mes de octubre y se propagó "de manera estocástica y sin mostrar signos epidémicos", según las conclusiones de un estudio en el que han participado biólogos de la Universidad de Barcelona que recoge Efe.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="177" end_char="178">El</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="180" end_char="190">coronavirus</TOKEN>
<TOKEN id="token-5-2" pos="unknown" morph="none" start_char="192" end_char="201">SARS-CoV-2</TOKEN>
<TOKEN id="token-5-3" pos="punct" morph="none" start_char="202" end_char="202">,</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="204" end_char="211">causante</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="213" end_char="214">de</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="216" end_char="217">la</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="219" end_char="226">pandemia</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="228" end_char="229">de</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="231" end_char="241">coronavirus</TOKEN>
<TOKEN id="token-5-10" pos="punct" morph="none" start_char="242" end_char="242">,</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="244" end_char="245">ya</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="247" end_char="255">circulaba</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="257" end_char="258">de</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="260" end_char="264">forma</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="266" end_char="272">latente</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="274" end_char="274">y</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="276" end_char="285">silenciosa</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="287" end_char="288">en</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="290" end_char="294">Wuhan</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="296" end_char="297">en</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="299" end_char="300">el</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="302" end_char="304">mes</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="306" end_char="307">de</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="309" end_char="315">octubre</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="317" end_char="317">y</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="319" end_char="320">se</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="322" end_char="328">propagó</TOKEN>
<TOKEN id="token-5-28" pos="punct" morph="none" start_char="330" end_char="330">"</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="331" end_char="332">de</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="334" end_char="339">manera</TOKEN>
<TOKEN id="token-5-31" pos="word" morph="none" start_char="341" end_char="351">estocástica</TOKEN>
<TOKEN id="token-5-32" pos="word" morph="none" start_char="353" end_char="353">y</TOKEN>
<TOKEN id="token-5-33" pos="word" morph="none" start_char="355" end_char="357">sin</TOKEN>
<TOKEN id="token-5-34" pos="word" morph="none" start_char="359" end_char="365">mostrar</TOKEN>
<TOKEN id="token-5-35" pos="word" morph="none" start_char="367" end_char="372">signos</TOKEN>
<TOKEN id="token-5-36" pos="word" morph="none" start_char="374" end_char="383">epidémicos</TOKEN>
<TOKEN id="token-5-37" pos="punct" morph="none" start_char="384" end_char="385">",</TOKEN>
<TOKEN id="token-5-38" pos="word" morph="none" start_char="387" end_char="391">según</TOKEN>
<TOKEN id="token-5-39" pos="word" morph="none" start_char="393" end_char="395">las</TOKEN>
<TOKEN id="token-5-40" pos="word" morph="none" start_char="397" end_char="408">conclusiones</TOKEN>
<TOKEN id="token-5-41" pos="word" morph="none" start_char="410" end_char="411">de</TOKEN>
<TOKEN id="token-5-42" pos="word" morph="none" start_char="413" end_char="414">un</TOKEN>
<TOKEN id="token-5-43" pos="word" morph="none" start_char="416" end_char="422">estudio</TOKEN>
<TOKEN id="token-5-44" pos="word" morph="none" start_char="424" end_char="425">en</TOKEN>
<TOKEN id="token-5-45" pos="word" morph="none" start_char="427" end_char="428">el</TOKEN>
<TOKEN id="token-5-46" pos="word" morph="none" start_char="430" end_char="432">que</TOKEN>
<TOKEN id="token-5-47" pos="word" morph="none" start_char="434" end_char="436">han</TOKEN>
<TOKEN id="token-5-48" pos="word" morph="none" start_char="438" end_char="448">participado</TOKEN>
<TOKEN id="token-5-49" pos="word" morph="none" start_char="450" end_char="457">biólogos</TOKEN>
<TOKEN id="token-5-50" pos="word" morph="none" start_char="459" end_char="460">de</TOKEN>
<TOKEN id="token-5-51" pos="word" morph="none" start_char="462" end_char="463">la</TOKEN>
<TOKEN id="token-5-52" pos="word" morph="none" start_char="465" end_char="475">Universidad</TOKEN>
<TOKEN id="token-5-53" pos="word" morph="none" start_char="477" end_char="478">de</TOKEN>
<TOKEN id="token-5-54" pos="word" morph="none" start_char="480" end_char="488">Barcelona</TOKEN>
<TOKEN id="token-5-55" pos="word" morph="none" start_char="490" end_char="492">que</TOKEN>
<TOKEN id="token-5-56" pos="word" morph="none" start_char="494" end_char="499">recoge</TOKEN>
<TOKEN id="token-5-57" pos="word" morph="none" start_char="501" end_char="503">Efe</TOKEN>
<TOKEN id="token-5-58" pos="punct" morph="none" start_char="504" end_char="504">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="507" end_char="886">
<ORIGINAL_TEXT>El trabajo, que publica la revista 'Frontiers in Medicine', defiende que, aunque oficialmente el brote de SARS-CoV-2 se presentó de manera imprevisible en el mercado popular de animales salvajes de Wuhan (China) en diciembre de 2019, los estudios filogenéticos indican que el coronavirus circulaba en fase de latencia ya desde octubre en esa ciudad de la provincia china de Hubei.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="507" end_char="508">El</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="510" end_char="516">trabajo</TOKEN>
<TOKEN id="token-6-2" pos="punct" morph="none" start_char="517" end_char="517">,</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="519" end_char="521">que</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="523" end_char="529">publica</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="531" end_char="532">la</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="534" end_char="540">revista</TOKEN>
<TOKEN id="token-6-7" pos="punct" morph="none" start_char="542" end_char="542">'</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="543" end_char="551">Frontiers</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="553" end_char="554">in</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="556" end_char="563">Medicine</TOKEN>
<TOKEN id="token-6-11" pos="punct" morph="none" start_char="564" end_char="565">',</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="567" end_char="574">defiende</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="576" end_char="578">que</TOKEN>
<TOKEN id="token-6-14" pos="punct" morph="none" start_char="579" end_char="579">,</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="581" end_char="586">aunque</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="588" end_char="599">oficialmente</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="601" end_char="602">el</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="604" end_char="608">brote</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="610" end_char="611">de</TOKEN>
<TOKEN id="token-6-20" pos="unknown" morph="none" start_char="613" end_char="622">SARS-CoV-2</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="624" end_char="625">se</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="627" end_char="634">presentó</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="636" end_char="637">de</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="639" end_char="644">manera</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="646" end_char="657">imprevisible</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="659" end_char="660">en</TOKEN>
<TOKEN id="token-6-27" pos="word" morph="none" start_char="662" end_char="663">el</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="665" end_char="671">mercado</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="673" end_char="679">popular</TOKEN>
<TOKEN id="token-6-30" pos="word" morph="none" start_char="681" end_char="682">de</TOKEN>
<TOKEN id="token-6-31" pos="word" morph="none" start_char="684" end_char="691">animales</TOKEN>
<TOKEN id="token-6-32" pos="word" morph="none" start_char="693" end_char="700">salvajes</TOKEN>
<TOKEN id="token-6-33" pos="word" morph="none" start_char="702" end_char="703">de</TOKEN>
<TOKEN id="token-6-34" pos="word" morph="none" start_char="705" end_char="709">Wuhan</TOKEN>
<TOKEN id="token-6-35" pos="punct" morph="none" start_char="711" end_char="711">(</TOKEN>
<TOKEN id="token-6-36" pos="word" morph="none" start_char="712" end_char="716">China</TOKEN>
<TOKEN id="token-6-37" pos="punct" morph="none" start_char="717" end_char="717">)</TOKEN>
<TOKEN id="token-6-38" pos="word" morph="none" start_char="719" end_char="720">en</TOKEN>
<TOKEN id="token-6-39" pos="word" morph="none" start_char="722" end_char="730">diciembre</TOKEN>
<TOKEN id="token-6-40" pos="word" morph="none" start_char="732" end_char="733">de</TOKEN>
<TOKEN id="token-6-41" pos="word" morph="none" start_char="735" end_char="738">2019</TOKEN>
<TOKEN id="token-6-42" pos="punct" morph="none" start_char="739" end_char="739">,</TOKEN>
<TOKEN id="token-6-43" pos="word" morph="none" start_char="741" end_char="743">los</TOKEN>
<TOKEN id="token-6-44" pos="word" morph="none" start_char="745" end_char="752">estudios</TOKEN>
<TOKEN id="token-6-45" pos="word" morph="none" start_char="754" end_char="766">filogenéticos</TOKEN>
<TOKEN id="token-6-46" pos="word" morph="none" start_char="768" end_char="774">indican</TOKEN>
<TOKEN id="token-6-47" pos="word" morph="none" start_char="776" end_char="778">que</TOKEN>
<TOKEN id="token-6-48" pos="word" morph="none" start_char="780" end_char="781">el</TOKEN>
<TOKEN id="token-6-49" pos="word" morph="none" start_char="783" end_char="793">coronavirus</TOKEN>
<TOKEN id="token-6-50" pos="word" morph="none" start_char="795" end_char="803">circulaba</TOKEN>
<TOKEN id="token-6-51" pos="word" morph="none" start_char="805" end_char="806">en</TOKEN>
<TOKEN id="token-6-52" pos="word" morph="none" start_char="808" end_char="811">fase</TOKEN>
<TOKEN id="token-6-53" pos="word" morph="none" start_char="813" end_char="814">de</TOKEN>
<TOKEN id="token-6-54" pos="word" morph="none" start_char="816" end_char="823">latencia</TOKEN>
<TOKEN id="token-6-55" pos="word" morph="none" start_char="825" end_char="826">ya</TOKEN>
<TOKEN id="token-6-56" pos="word" morph="none" start_char="828" end_char="832">desde</TOKEN>
<TOKEN id="token-6-57" pos="word" morph="none" start_char="834" end_char="840">octubre</TOKEN>
<TOKEN id="token-6-58" pos="word" morph="none" start_char="842" end_char="843">en</TOKEN>
<TOKEN id="token-6-59" pos="word" morph="none" start_char="845" end_char="847">esa</TOKEN>
<TOKEN id="token-6-60" pos="word" morph="none" start_char="849" end_char="854">ciudad</TOKEN>
<TOKEN id="token-6-61" pos="word" morph="none" start_char="856" end_char="857">de</TOKEN>
<TOKEN id="token-6-62" pos="word" morph="none" start_char="859" end_char="860">la</TOKEN>
<TOKEN id="token-6-63" pos="word" morph="none" start_char="862" end_char="870">provincia</TOKEN>
<TOKEN id="token-6-64" pos="word" morph="none" start_char="872" end_char="876">china</TOKEN>
<TOKEN id="token-6-65" pos="word" morph="none" start_char="878" end_char="879">de</TOKEN>
<TOKEN id="token-6-66" pos="word" morph="none" start_char="881" end_char="885">Hubei</TOKEN>
<TOKEN id="token-6-67" pos="punct" morph="none" start_char="886" end_char="886">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="889" end_char="1335">
<ORIGINAL_TEXT>"En esta fase de latencia, la infección siguió su curso silencioso", según el equipo de investigadores, formado por Jordi Serra-Cobo y Marc López, de la Facultad de Biología y del Instituto de Investigación de la Biodiversidad (IRBio) de la UB; Roger Frutos, del Centro de Cooperación Internacional en Investigación Agronómica para el Desarrollo (CIRAD, Francia); y Christian A. Devaux, del Centro Nacional para la Investigación Científica (CNRS).</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="punct" morph="none" start_char="889" end_char="889">"</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="890" end_char="891">En</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="893" end_char="896">esta</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="898" end_char="901">fase</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="903" end_char="904">de</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="906" end_char="913">latencia</TOKEN>
<TOKEN id="token-7-6" pos="punct" morph="none" start_char="914" end_char="914">,</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="916" end_char="917">la</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="919" end_char="927">infección</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="929" end_char="934">siguió</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="936" end_char="937">su</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="939" end_char="943">curso</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="945" end_char="954">silencioso</TOKEN>
<TOKEN id="token-7-13" pos="punct" morph="none" start_char="955" end_char="956">",</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="958" end_char="962">según</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="964" end_char="965">el</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="967" end_char="972">equipo</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="974" end_char="975">de</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="977" end_char="990">investigadores</TOKEN>
<TOKEN id="token-7-19" pos="punct" morph="none" start_char="991" end_char="991">,</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="993" end_char="999">formado</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="1001" end_char="1003">por</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="1005" end_char="1009">Jordi</TOKEN>
<TOKEN id="token-7-23" pos="unknown" morph="none" start_char="1011" end_char="1020">Serra-Cobo</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="1022" end_char="1022">y</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="1024" end_char="1027">Marc</TOKEN>
<TOKEN id="token-7-26" pos="word" morph="none" start_char="1029" end_char="1033">López</TOKEN>
<TOKEN id="token-7-27" pos="punct" morph="none" start_char="1034" end_char="1034">,</TOKEN>
<TOKEN id="token-7-28" pos="word" morph="none" start_char="1036" end_char="1037">de</TOKEN>
<TOKEN id="token-7-29" pos="word" morph="none" start_char="1039" end_char="1040">la</TOKEN>
<TOKEN id="token-7-30" pos="word" morph="none" start_char="1042" end_char="1049">Facultad</TOKEN>
<TOKEN id="token-7-31" pos="word" morph="none" start_char="1051" end_char="1052">de</TOKEN>
<TOKEN id="token-7-32" pos="word" morph="none" start_char="1054" end_char="1061">Biología</TOKEN>
<TOKEN id="token-7-33" pos="word" morph="none" start_char="1063" end_char="1063">y</TOKEN>
<TOKEN id="token-7-34" pos="word" morph="none" start_char="1065" end_char="1067">del</TOKEN>
<TOKEN id="token-7-35" pos="word" morph="none" start_char="1069" end_char="1077">Instituto</TOKEN>
<TOKEN id="token-7-36" pos="word" morph="none" start_char="1079" end_char="1080">de</TOKEN>
<TOKEN id="token-7-37" pos="word" morph="none" start_char="1082" end_char="1094">Investigación</TOKEN>
<TOKEN id="token-7-38" pos="word" morph="none" start_char="1096" end_char="1097">de</TOKEN>
<TOKEN id="token-7-39" pos="word" morph="none" start_char="1099" end_char="1100">la</TOKEN>
<TOKEN id="token-7-40" pos="word" morph="none" start_char="1102" end_char="1114">Biodiversidad</TOKEN>
<TOKEN id="token-7-41" pos="punct" morph="none" start_char="1116" end_char="1116">(</TOKEN>
<TOKEN id="token-7-42" pos="word" morph="none" start_char="1117" end_char="1121">IRBio</TOKEN>
<TOKEN id="token-7-43" pos="punct" morph="none" start_char="1122" end_char="1122">)</TOKEN>
<TOKEN id="token-7-44" pos="word" morph="none" start_char="1124" end_char="1125">de</TOKEN>
<TOKEN id="token-7-45" pos="word" morph="none" start_char="1127" end_char="1128">la</TOKEN>
<TOKEN id="token-7-46" pos="word" morph="none" start_char="1130" end_char="1131">UB</TOKEN>
<TOKEN id="token-7-47" pos="punct" morph="none" start_char="1132" end_char="1132">;</TOKEN>
<TOKEN id="token-7-48" pos="word" morph="none" start_char="1134" end_char="1138">Roger</TOKEN>
<TOKEN id="token-7-49" pos="word" morph="none" start_char="1140" end_char="1145">Frutos</TOKEN>
<TOKEN id="token-7-50" pos="punct" morph="none" start_char="1146" end_char="1146">,</TOKEN>
<TOKEN id="token-7-51" pos="word" morph="none" start_char="1148" end_char="1150">del</TOKEN>
<TOKEN id="token-7-52" pos="word" morph="none" start_char="1152" end_char="1157">Centro</TOKEN>
<TOKEN id="token-7-53" pos="word" morph="none" start_char="1159" end_char="1160">de</TOKEN>
<TOKEN id="token-7-54" pos="word" morph="none" start_char="1162" end_char="1172">Cooperación</TOKEN>
<TOKEN id="token-7-55" pos="word" morph="none" start_char="1174" end_char="1186">Internacional</TOKEN>
<TOKEN id="token-7-56" pos="word" morph="none" start_char="1188" end_char="1189">en</TOKEN>
<TOKEN id="token-7-57" pos="word" morph="none" start_char="1191" end_char="1203">Investigación</TOKEN>
<TOKEN id="token-7-58" pos="word" morph="none" start_char="1205" end_char="1214">Agronómica</TOKEN>
<TOKEN id="token-7-59" pos="word" morph="none" start_char="1216" end_char="1219">para</TOKEN>
<TOKEN id="token-7-60" pos="word" morph="none" start_char="1221" end_char="1222">el</TOKEN>
<TOKEN id="token-7-61" pos="word" morph="none" start_char="1224" end_char="1233">Desarrollo</TOKEN>
<TOKEN id="token-7-62" pos="punct" morph="none" start_char="1235" end_char="1235">(</TOKEN>
<TOKEN id="token-7-63" pos="word" morph="none" start_char="1236" end_char="1240">CIRAD</TOKEN>
<TOKEN id="token-7-64" pos="punct" morph="none" start_char="1241" end_char="1241">,</TOKEN>
<TOKEN id="token-7-65" pos="word" morph="none" start_char="1243" end_char="1249">Francia</TOKEN>
<TOKEN id="token-7-66" pos="punct" morph="none" start_char="1250" end_char="1251">);</TOKEN>
<TOKEN id="token-7-67" pos="word" morph="none" start_char="1253" end_char="1253">y</TOKEN>
<TOKEN id="token-7-68" pos="word" morph="none" start_char="1255" end_char="1263">Christian</TOKEN>
<TOKEN id="token-7-69" pos="word" morph="none" start_char="1265" end_char="1265">A</TOKEN>
<TOKEN id="token-7-70" pos="punct" morph="none" start_char="1266" end_char="1266">.</TOKEN>
<TOKEN id="token-7-71" pos="word" morph="none" start_char="1268" end_char="1273">Devaux</TOKEN>
<TOKEN id="token-7-72" pos="punct" morph="none" start_char="1274" end_char="1274">,</TOKEN>
<TOKEN id="token-7-73" pos="word" morph="none" start_char="1276" end_char="1278">del</TOKEN>
<TOKEN id="token-7-74" pos="word" morph="none" start_char="1280" end_char="1285">Centro</TOKEN>
<TOKEN id="token-7-75" pos="word" morph="none" start_char="1287" end_char="1294">Nacional</TOKEN>
<TOKEN id="token-7-76" pos="word" morph="none" start_char="1296" end_char="1299">para</TOKEN>
<TOKEN id="token-7-77" pos="word" morph="none" start_char="1301" end_char="1302">la</TOKEN>
<TOKEN id="token-7-78" pos="word" morph="none" start_char="1304" end_char="1316">Investigación</TOKEN>
<TOKEN id="token-7-79" pos="word" morph="none" start_char="1318" end_char="1327">Científica</TOKEN>
<TOKEN id="token-7-80" pos="punct" morph="none" start_char="1329" end_char="1329">(</TOKEN>
<TOKEN id="token-7-81" pos="word" morph="none" start_char="1330" end_char="1333">CNRS</TOKEN>
<TOKEN id="token-7-82" pos="punct" morph="none" start_char="1334" end_char="1335">).</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1338" end_char="1569">
<ORIGINAL_TEXT>El estudio revisa la conjunción única de eventos que permitieron la expansión global de este nuevo coronavirus, que muestra un largo período de incubación, un elevado número de casos asintomáticos y una alta movilidad internacional.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1338" end_char="1339">El</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1341" end_char="1347">estudio</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1349" end_char="1354">revisa</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1356" end_char="1357">la</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1359" end_char="1368">conjunción</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1370" end_char="1374">única</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1376" end_char="1377">de</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1379" end_char="1385">eventos</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1387" end_char="1389">que</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1391" end_char="1401">permitieron</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1403" end_char="1404">la</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1406" end_char="1414">expansión</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1416" end_char="1421">global</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1423" end_char="1424">de</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1426" end_char="1429">este</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1431" end_char="1435">nuevo</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1437" end_char="1447">coronavirus</TOKEN>
<TOKEN id="token-8-17" pos="punct" morph="none" start_char="1448" end_char="1448">,</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1450" end_char="1452">que</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1454" end_char="1460">muestra</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="1462" end_char="1463">un</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="1465" end_char="1469">largo</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="1471" end_char="1477">período</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="1479" end_char="1480">de</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="1482" end_char="1491">incubación</TOKEN>
<TOKEN id="token-8-25" pos="punct" morph="none" start_char="1492" end_char="1492">,</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="1494" end_char="1495">un</TOKEN>
<TOKEN id="token-8-27" pos="word" morph="none" start_char="1497" end_char="1503">elevado</TOKEN>
<TOKEN id="token-8-28" pos="word" morph="none" start_char="1505" end_char="1510">número</TOKEN>
<TOKEN id="token-8-29" pos="word" morph="none" start_char="1512" end_char="1513">de</TOKEN>
<TOKEN id="token-8-30" pos="word" morph="none" start_char="1515" end_char="1519">casos</TOKEN>
<TOKEN id="token-8-31" pos="word" morph="none" start_char="1521" end_char="1533">asintomáticos</TOKEN>
<TOKEN id="token-8-32" pos="word" morph="none" start_char="1535" end_char="1535">y</TOKEN>
<TOKEN id="token-8-33" pos="word" morph="none" start_char="1537" end_char="1539">una</TOKEN>
<TOKEN id="token-8-34" pos="word" morph="none" start_char="1541" end_char="1544">alta</TOKEN>
<TOKEN id="token-8-35" pos="word" morph="none" start_char="1546" end_char="1554">movilidad</TOKEN>
<TOKEN id="token-8-36" pos="word" morph="none" start_char="1556" end_char="1568">internacional</TOKEN>
<TOKEN id="token-8-37" pos="punct" morph="none" start_char="1569" end_char="1569">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1571" end_char="1873">
<ORIGINAL_TEXT>Según Serra-Cobo, para que una enfermedad infecciosa se disperse, deben cumplirse tres condiciones: el patógeno debe ser capaz de infectar y reproducirse en humanos, debe poder entrar en contacto con personas a través de un reservorio natural, y debe ser propagado a través de un amplio circuito social.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1571" end_char="1575">Según</TOKEN>
<TOKEN id="token-9-1" pos="unknown" morph="none" start_char="1577" end_char="1586">Serra-Cobo</TOKEN>
<TOKEN id="token-9-2" pos="punct" morph="none" start_char="1587" end_char="1587">,</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1589" end_char="1592">para</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1594" end_char="1596">que</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1598" end_char="1600">una</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1602" end_char="1611">enfermedad</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1613" end_char="1622">infecciosa</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1624" end_char="1625">se</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1627" end_char="1634">disperse</TOKEN>
<TOKEN id="token-9-10" pos="punct" morph="none" start_char="1635" end_char="1635">,</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1637" end_char="1641">deben</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1643" end_char="1651">cumplirse</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1653" end_char="1656">tres</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1658" end_char="1668">condiciones</TOKEN>
<TOKEN id="token-9-15" pos="punct" morph="none" start_char="1669" end_char="1669">:</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1671" end_char="1672">el</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1674" end_char="1681">patógeno</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1683" end_char="1686">debe</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1688" end_char="1690">ser</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1692" end_char="1696">capaz</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1698" end_char="1699">de</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1701" end_char="1708">infectar</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1710" end_char="1710">y</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1712" end_char="1723">reproducirse</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1725" end_char="1726">en</TOKEN>
<TOKEN id="token-9-26" pos="word" morph="none" start_char="1728" end_char="1734">humanos</TOKEN>
<TOKEN id="token-9-27" pos="punct" morph="none" start_char="1735" end_char="1735">,</TOKEN>
<TOKEN id="token-9-28" pos="word" morph="none" start_char="1737" end_char="1740">debe</TOKEN>
<TOKEN id="token-9-29" pos="word" morph="none" start_char="1742" end_char="1746">poder</TOKEN>
<TOKEN id="token-9-30" pos="word" morph="none" start_char="1748" end_char="1753">entrar</TOKEN>
<TOKEN id="token-9-31" pos="word" morph="none" start_char="1755" end_char="1756">en</TOKEN>
<TOKEN id="token-9-32" pos="word" morph="none" start_char="1758" end_char="1765">contacto</TOKEN>
<TOKEN id="token-9-33" pos="word" morph="none" start_char="1767" end_char="1769">con</TOKEN>
<TOKEN id="token-9-34" pos="word" morph="none" start_char="1771" end_char="1778">personas</TOKEN>
<TOKEN id="token-9-35" pos="word" morph="none" start_char="1780" end_char="1780">a</TOKEN>
<TOKEN id="token-9-36" pos="word" morph="none" start_char="1782" end_char="1787">través</TOKEN>
<TOKEN id="token-9-37" pos="word" morph="none" start_char="1789" end_char="1790">de</TOKEN>
<TOKEN id="token-9-38" pos="word" morph="none" start_char="1792" end_char="1793">un</TOKEN>
<TOKEN id="token-9-39" pos="word" morph="none" start_char="1795" end_char="1804">reservorio</TOKEN>
<TOKEN id="token-9-40" pos="word" morph="none" start_char="1806" end_char="1812">natural</TOKEN>
<TOKEN id="token-9-41" pos="punct" morph="none" start_char="1813" end_char="1813">,</TOKEN>
<TOKEN id="token-9-42" pos="word" morph="none" start_char="1815" end_char="1815">y</TOKEN>
<TOKEN id="token-9-43" pos="word" morph="none" start_char="1817" end_char="1820">debe</TOKEN>
<TOKEN id="token-9-44" pos="word" morph="none" start_char="1822" end_char="1824">ser</TOKEN>
<TOKEN id="token-9-45" pos="word" morph="none" start_char="1826" end_char="1834">propagado</TOKEN>
<TOKEN id="token-9-46" pos="word" morph="none" start_char="1836" end_char="1836">a</TOKEN>
<TOKEN id="token-9-47" pos="word" morph="none" start_char="1838" end_char="1843">través</TOKEN>
<TOKEN id="token-9-48" pos="word" morph="none" start_char="1845" end_char="1846">de</TOKEN>
<TOKEN id="token-9-49" pos="word" morph="none" start_char="1848" end_char="1849">un</TOKEN>
<TOKEN id="token-9-50" pos="word" morph="none" start_char="1851" end_char="1856">amplio</TOKEN>
<TOKEN id="token-9-51" pos="word" morph="none" start_char="1858" end_char="1865">circuito</TOKEN>
<TOKEN id="token-9-52" pos="word" morph="none" start_char="1867" end_char="1872">social</TOKEN>
<TOKEN id="token-9-53" pos="punct" morph="none" start_char="1873" end_char="1873">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1876" end_char="1973">
<ORIGINAL_TEXT>En el caso de la Covid-19, todas las condiciones exigidas coincidieron en Wuhan a finales de 2019.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1876" end_char="1877">En</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1879" end_char="1880">el</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1882" end_char="1885">caso</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1887" end_char="1888">de</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1890" end_char="1891">la</TOKEN>
<TOKEN id="token-10-5" pos="unknown" morph="none" start_char="1893" end_char="1900">Covid-19</TOKEN>
<TOKEN id="token-10-6" pos="punct" morph="none" start_char="1901" end_char="1901">,</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1903" end_char="1907">todas</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1909" end_char="1911">las</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1913" end_char="1923">condiciones</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1925" end_char="1932">exigidas</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1934" end_char="1945">coincidieron</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1947" end_char="1948">en</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1950" end_char="1954">Wuhan</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1956" end_char="1956">a</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1958" end_char="1964">finales</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1966" end_char="1967">de</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1969" end_char="1972">2019</TOKEN>
<TOKEN id="token-10-18" pos="punct" morph="none" start_char="1973" end_char="1973">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1975" end_char="2217">
<ORIGINAL_TEXT>Según los autores, la aparición del coronavirus es el resultado de una excepcional "alineación planetaria", es decir, una coincidencia específica de factores biológicos y sociales que permitieron que surgiera y se expandiera por todo el mundo.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1975" end_char="1979">Según</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1981" end_char="1983">los</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1985" end_char="1991">autores</TOKEN>
<TOKEN id="token-11-3" pos="punct" morph="none" start_char="1992" end_char="1992">,</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1994" end_char="1995">la</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1997" end_char="2005">aparición</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="2007" end_char="2009">del</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="2011" end_char="2021">coronavirus</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="2023" end_char="2024">es</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="2026" end_char="2027">el</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="2029" end_char="2037">resultado</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="2039" end_char="2040">de</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="2042" end_char="2044">una</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="2046" end_char="2056">excepcional</TOKEN>
<TOKEN id="token-11-14" pos="punct" morph="none" start_char="2058" end_char="2058">"</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="2059" end_char="2068">alineación</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="2070" end_char="2079">planetaria</TOKEN>
<TOKEN id="token-11-17" pos="punct" morph="none" start_char="2080" end_char="2081">",</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="2083" end_char="2084">es</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="2086" end_char="2090">decir</TOKEN>
<TOKEN id="token-11-20" pos="punct" morph="none" start_char="2091" end_char="2091">,</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="2093" end_char="2095">una</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="2097" end_char="2108">coincidencia</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="2110" end_char="2119">específica</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="2121" end_char="2122">de</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="2124" end_char="2131">factores</TOKEN>
<TOKEN id="token-11-26" pos="word" morph="none" start_char="2133" end_char="2142">biológicos</TOKEN>
<TOKEN id="token-11-27" pos="word" morph="none" start_char="2144" end_char="2144">y</TOKEN>
<TOKEN id="token-11-28" pos="word" morph="none" start_char="2146" end_char="2153">sociales</TOKEN>
<TOKEN id="token-11-29" pos="word" morph="none" start_char="2155" end_char="2157">que</TOKEN>
<TOKEN id="token-11-30" pos="word" morph="none" start_char="2159" end_char="2169">permitieron</TOKEN>
<TOKEN id="token-11-31" pos="word" morph="none" start_char="2171" end_char="2173">que</TOKEN>
<TOKEN id="token-11-32" pos="word" morph="none" start_char="2175" end_char="2182">surgiera</TOKEN>
<TOKEN id="token-11-33" pos="word" morph="none" start_char="2184" end_char="2184">y</TOKEN>
<TOKEN id="token-11-34" pos="word" morph="none" start_char="2186" end_char="2187">se</TOKEN>
<TOKEN id="token-11-35" pos="word" morph="none" start_char="2189" end_char="2198">expandiera</TOKEN>
<TOKEN id="token-11-36" pos="word" morph="none" start_char="2200" end_char="2202">por</TOKEN>
<TOKEN id="token-11-37" pos="word" morph="none" start_char="2204" end_char="2207">todo</TOKEN>
<TOKEN id="token-11-38" pos="word" morph="none" start_char="2209" end_char="2210">el</TOKEN>
<TOKEN id="token-11-39" pos="word" morph="none" start_char="2212" end_char="2216">mundo</TOKEN>
<TOKEN id="token-11-40" pos="punct" morph="none" start_char="2217" end_char="2217">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="2220" end_char="2586">
<ORIGINAL_TEXT>"Lo que desencadenó la epidemia es la aparición simultánea de dos celebraciones importantes en el mismo lugar -la gran fiesta de la familia y el año nuevo chino-, que pusieron en contacto a muchas personas con otros inicialmente infectadas, lo que proporcionó la fase de amplificación necesaria", según los autores, que indican que "otro paso clave fue la movilidad".</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="punct" morph="none" start_char="2220" end_char="2220">"</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="2221" end_char="2222">Lo</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="2224" end_char="2226">que</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="2228" end_char="2238">desencadenó</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="2240" end_char="2241">la</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="2243" end_char="2250">epidemia</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="2252" end_char="2253">es</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="2255" end_char="2256">la</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="2258" end_char="2266">aparición</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="2268" end_char="2277">simultánea</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="2279" end_char="2280">de</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="2282" end_char="2284">dos</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="2286" end_char="2298">celebraciones</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="2300" end_char="2310">importantes</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="2312" end_char="2313">en</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="2315" end_char="2316">el</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="2318" end_char="2322">mismo</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="2324" end_char="2328">lugar</TOKEN>
<TOKEN id="token-12-18" pos="punct" morph="none" start_char="2330" end_char="2330">-</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="2331" end_char="2332">la</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="2334" end_char="2337">gran</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="2339" end_char="2344">fiesta</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="2346" end_char="2347">de</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="2349" end_char="2350">la</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="2352" end_char="2358">familia</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="2360" end_char="2360">y</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="2362" end_char="2363">el</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="2365" end_char="2367">año</TOKEN>
<TOKEN id="token-12-28" pos="word" morph="none" start_char="2369" end_char="2373">nuevo</TOKEN>
<TOKEN id="token-12-29" pos="word" morph="none" start_char="2375" end_char="2379">chino</TOKEN>
<TOKEN id="token-12-30" pos="punct" morph="none" start_char="2380" end_char="2381">-,</TOKEN>
<TOKEN id="token-12-31" pos="word" morph="none" start_char="2383" end_char="2385">que</TOKEN>
<TOKEN id="token-12-32" pos="word" morph="none" start_char="2387" end_char="2394">pusieron</TOKEN>
<TOKEN id="token-12-33" pos="word" morph="none" start_char="2396" end_char="2397">en</TOKEN>
<TOKEN id="token-12-34" pos="word" morph="none" start_char="2399" end_char="2406">contacto</TOKEN>
<TOKEN id="token-12-35" pos="word" morph="none" start_char="2408" end_char="2408">a</TOKEN>
<TOKEN id="token-12-36" pos="word" morph="none" start_char="2410" end_char="2415">muchas</TOKEN>
<TOKEN id="token-12-37" pos="word" morph="none" start_char="2417" end_char="2424">personas</TOKEN>
<TOKEN id="token-12-38" pos="word" morph="none" start_char="2426" end_char="2428">con</TOKEN>
<TOKEN id="token-12-39" pos="word" morph="none" start_char="2430" end_char="2434">otros</TOKEN>
<TOKEN id="token-12-40" pos="word" morph="none" start_char="2436" end_char="2447">inicialmente</TOKEN>
<TOKEN id="token-12-41" pos="word" morph="none" start_char="2449" end_char="2458">infectadas</TOKEN>
<TOKEN id="token-12-42" pos="punct" morph="none" start_char="2459" end_char="2459">,</TOKEN>
<TOKEN id="token-12-43" pos="word" morph="none" start_char="2461" end_char="2462">lo</TOKEN>
<TOKEN id="token-12-44" pos="word" morph="none" start_char="2464" end_char="2466">que</TOKEN>
<TOKEN id="token-12-45" pos="word" morph="none" start_char="2468" end_char="2478">proporcionó</TOKEN>
<TOKEN id="token-12-46" pos="word" morph="none" start_char="2480" end_char="2481">la</TOKEN>
<TOKEN id="token-12-47" pos="word" morph="none" start_char="2483" end_char="2486">fase</TOKEN>
<TOKEN id="token-12-48" pos="word" morph="none" start_char="2488" end_char="2489">de</TOKEN>
<TOKEN id="token-12-49" pos="word" morph="none" start_char="2491" end_char="2503">amplificación</TOKEN>
<TOKEN id="token-12-50" pos="word" morph="none" start_char="2505" end_char="2513">necesaria</TOKEN>
<TOKEN id="token-12-51" pos="punct" morph="none" start_char="2514" end_char="2515">",</TOKEN>
<TOKEN id="token-12-52" pos="word" morph="none" start_char="2517" end_char="2521">según</TOKEN>
<TOKEN id="token-12-53" pos="word" morph="none" start_char="2523" end_char="2525">los</TOKEN>
<TOKEN id="token-12-54" pos="word" morph="none" start_char="2527" end_char="2533">autores</TOKEN>
<TOKEN id="token-12-55" pos="punct" morph="none" start_char="2534" end_char="2534">,</TOKEN>
<TOKEN id="token-12-56" pos="word" morph="none" start_char="2536" end_char="2538">que</TOKEN>
<TOKEN id="token-12-57" pos="word" morph="none" start_char="2540" end_char="2546">indican</TOKEN>
<TOKEN id="token-12-58" pos="word" morph="none" start_char="2548" end_char="2550">que</TOKEN>
<TOKEN id="token-12-59" pos="punct" morph="none" start_char="2552" end_char="2552">"</TOKEN>
<TOKEN id="token-12-60" pos="word" morph="none" start_char="2553" end_char="2556">otro</TOKEN>
<TOKEN id="token-12-61" pos="word" morph="none" start_char="2558" end_char="2561">paso</TOKEN>
<TOKEN id="token-12-62" pos="word" morph="none" start_char="2563" end_char="2567">clave</TOKEN>
<TOKEN id="token-12-63" pos="word" morph="none" start_char="2569" end_char="2571">fue</TOKEN>
<TOKEN id="token-12-64" pos="word" morph="none" start_char="2573" end_char="2574">la</TOKEN>
<TOKEN id="token-12-65" pos="word" morph="none" start_char="2576" end_char="2584">movilidad</TOKEN>
<TOKEN id="token-12-66" pos="punct" morph="none" start_char="2585" end_char="2586">".</TOKEN>
</SEG>
<SEG id="segment-13" start_char="2589" end_char="2729">
<ORIGINAL_TEXT>Según Serra-Cobo, "no se puede hacer nada para evitar la circulación de coronavirus en estado salvaje, es decir, durante el ciclo selvático".</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="2589" end_char="2593">Según</TOKEN>
<TOKEN id="token-13-1" pos="unknown" morph="none" start_char="2595" end_char="2604">Serra-Cobo</TOKEN>
<TOKEN id="token-13-2" pos="punct" morph="none" start_char="2605" end_char="2605">,</TOKEN>
<TOKEN id="token-13-3" pos="punct" morph="none" start_char="2607" end_char="2607">"</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="2608" end_char="2609">no</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="2611" end_char="2612">se</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="2614" end_char="2618">puede</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="2620" end_char="2624">hacer</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="2626" end_char="2629">nada</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="2631" end_char="2634">para</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="2636" end_char="2641">evitar</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="2643" end_char="2644">la</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="2646" end_char="2656">circulación</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="2658" end_char="2659">de</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="2661" end_char="2671">coronavirus</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="2673" end_char="2674">en</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="2676" end_char="2681">estado</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="2683" end_char="2689">salvaje</TOKEN>
<TOKEN id="token-13-18" pos="punct" morph="none" start_char="2690" end_char="2690">,</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="2692" end_char="2693">es</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="2695" end_char="2699">decir</TOKEN>
<TOKEN id="token-13-21" pos="punct" morph="none" start_char="2700" end_char="2700">,</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="2702" end_char="2708">durante</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="2710" end_char="2711">el</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="2713" end_char="2717">ciclo</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="2719" end_char="2727">selvático</TOKEN>
<TOKEN id="token-13-26" pos="punct" morph="none" start_char="2728" end_char="2729">".</TOKEN>
</SEG>
<SEG id="segment-14" start_char="2731" end_char="3017">
<ORIGINAL_TEXT>El biólogo ha recordado que "las alteraciones ambientales y la antropización de los sistemas naturales inciden en la pérdida de hábitats y de biodiversidad, inciden en la dinámica de las especies reservorio de patógenos e incrementan la probabilidad de que infecten a la especie humana".</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="2731" end_char="2732">El</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="2734" end_char="2740">biólogo</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="2742" end_char="2743">ha</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="2745" end_char="2753">recordado</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="2755" end_char="2757">que</TOKEN>
<TOKEN id="token-14-5" pos="punct" morph="none" start_char="2759" end_char="2759">"</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="2760" end_char="2762">las</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="2764" end_char="2775">alteraciones</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="2777" end_char="2787">ambientales</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="2789" end_char="2789">y</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="2791" end_char="2792">la</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="2794" end_char="2806">antropización</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="2808" end_char="2809">de</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="2811" end_char="2813">los</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="2815" end_char="2822">sistemas</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="2824" end_char="2832">naturales</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="2834" end_char="2840">inciden</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="2842" end_char="2843">en</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="2845" end_char="2846">la</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="2848" end_char="2854">pérdida</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="2856" end_char="2857">de</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="2859" end_char="2866">hábitats</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="2868" end_char="2868">y</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="2870" end_char="2871">de</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="2873" end_char="2885">biodiversidad</TOKEN>
<TOKEN id="token-14-25" pos="punct" morph="none" start_char="2886" end_char="2886">,</TOKEN>
<TOKEN id="token-14-26" pos="word" morph="none" start_char="2888" end_char="2894">inciden</TOKEN>
<TOKEN id="token-14-27" pos="word" morph="none" start_char="2896" end_char="2897">en</TOKEN>
<TOKEN id="token-14-28" pos="word" morph="none" start_char="2899" end_char="2900">la</TOKEN>
<TOKEN id="token-14-29" pos="word" morph="none" start_char="2902" end_char="2909">dinámica</TOKEN>
<TOKEN id="token-14-30" pos="word" morph="none" start_char="2911" end_char="2912">de</TOKEN>
<TOKEN id="token-14-31" pos="word" morph="none" start_char="2914" end_char="2916">las</TOKEN>
<TOKEN id="token-14-32" pos="word" morph="none" start_char="2918" end_char="2925">especies</TOKEN>
<TOKEN id="token-14-33" pos="word" morph="none" start_char="2927" end_char="2936">reservorio</TOKEN>
<TOKEN id="token-14-34" pos="word" morph="none" start_char="2938" end_char="2939">de</TOKEN>
<TOKEN id="token-14-35" pos="word" morph="none" start_char="2941" end_char="2949">patógenos</TOKEN>
<TOKEN id="token-14-36" pos="word" morph="none" start_char="2951" end_char="2951">e</TOKEN>
<TOKEN id="token-14-37" pos="word" morph="none" start_char="2953" end_char="2963">incrementan</TOKEN>
<TOKEN id="token-14-38" pos="word" morph="none" start_char="2965" end_char="2966">la</TOKEN>
<TOKEN id="token-14-39" pos="word" morph="none" start_char="2968" end_char="2979">probabilidad</TOKEN>
<TOKEN id="token-14-40" pos="word" morph="none" start_char="2981" end_char="2982">de</TOKEN>
<TOKEN id="token-14-41" pos="word" morph="none" start_char="2984" end_char="2986">que</TOKEN>
<TOKEN id="token-14-42" pos="word" morph="none" start_char="2988" end_char="2995">infecten</TOKEN>
<TOKEN id="token-14-43" pos="word" morph="none" start_char="2997" end_char="2997">a</TOKEN>
<TOKEN id="token-14-44" pos="word" morph="none" start_char="2999" end_char="3000">la</TOKEN>
<TOKEN id="token-14-45" pos="word" morph="none" start_char="3002" end_char="3008">especie</TOKEN>
<TOKEN id="token-14-46" pos="word" morph="none" start_char="3010" end_char="3015">humana</TOKEN>
<TOKEN id="token-14-47" pos="punct" morph="none" start_char="3016" end_char="3017">".</TOKEN>
</SEG>
<SEG id="segment-15" start_char="3020" end_char="3351">
<ORIGINAL_TEXT>"Este fenómeno es especialmente importante en el sureste asiático, lugar donde se han originado las epidemias del SARS y la Covid-19", subraya Serra-Cobo, profesor de Biología Evolutiva, Ecología y Ciencias Ambientales de la UB y miembro de un proyecto de la UE para la detección rápida del coronavirus a través de nanodispositivos.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="punct" morph="none" start_char="3020" end_char="3020">"</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="3021" end_char="3024">Este</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="3026" end_char="3033">fenómeno</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="3035" end_char="3036">es</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="3038" end_char="3050">especialmente</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="3052" end_char="3061">importante</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="3063" end_char="3064">en</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="3066" end_char="3067">el</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="3069" end_char="3075">sureste</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="3077" end_char="3084">asiático</TOKEN>
<TOKEN id="token-15-10" pos="punct" morph="none" start_char="3085" end_char="3085">,</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="3087" end_char="3091">lugar</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="3093" end_char="3097">donde</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="3099" end_char="3100">se</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="3102" end_char="3104">han</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="3106" end_char="3114">originado</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="3116" end_char="3118">las</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="3120" end_char="3128">epidemias</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="3130" end_char="3132">del</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="3134" end_char="3137">SARS</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="3139" end_char="3139">y</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="3141" end_char="3142">la</TOKEN>
<TOKEN id="token-15-22" pos="unknown" morph="none" start_char="3144" end_char="3151">Covid-19</TOKEN>
<TOKEN id="token-15-23" pos="punct" morph="none" start_char="3152" end_char="3153">",</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="3155" end_char="3161">subraya</TOKEN>
<TOKEN id="token-15-25" pos="unknown" morph="none" start_char="3163" end_char="3172">Serra-Cobo</TOKEN>
<TOKEN id="token-15-26" pos="punct" morph="none" start_char="3173" end_char="3173">,</TOKEN>
<TOKEN id="token-15-27" pos="word" morph="none" start_char="3175" end_char="3182">profesor</TOKEN>
<TOKEN id="token-15-28" pos="word" morph="none" start_char="3184" end_char="3185">de</TOKEN>
<TOKEN id="token-15-29" pos="word" morph="none" start_char="3187" end_char="3194">Biología</TOKEN>
<TOKEN id="token-15-30" pos="word" morph="none" start_char="3196" end_char="3204">Evolutiva</TOKEN>
<TOKEN id="token-15-31" pos="punct" morph="none" start_char="3205" end_char="3205">,</TOKEN>
<TOKEN id="token-15-32" pos="word" morph="none" start_char="3207" end_char="3214">Ecología</TOKEN>
<TOKEN id="token-15-33" pos="word" morph="none" start_char="3216" end_char="3216">y</TOKEN>
<TOKEN id="token-15-34" pos="word" morph="none" start_char="3218" end_char="3225">Ciencias</TOKEN>
<TOKEN id="token-15-35" pos="word" morph="none" start_char="3227" end_char="3237">Ambientales</TOKEN>
<TOKEN id="token-15-36" pos="word" morph="none" start_char="3239" end_char="3240">de</TOKEN>
<TOKEN id="token-15-37" pos="word" morph="none" start_char="3242" end_char="3243">la</TOKEN>
<TOKEN id="token-15-38" pos="word" morph="none" start_char="3245" end_char="3246">UB</TOKEN>
<TOKEN id="token-15-39" pos="word" morph="none" start_char="3248" end_char="3248">y</TOKEN>
<TOKEN id="token-15-40" pos="word" morph="none" start_char="3250" end_char="3256">miembro</TOKEN>
<TOKEN id="token-15-41" pos="word" morph="none" start_char="3258" end_char="3259">de</TOKEN>
<TOKEN id="token-15-42" pos="word" morph="none" start_char="3261" end_char="3262">un</TOKEN>
<TOKEN id="token-15-43" pos="word" morph="none" start_char="3264" end_char="3271">proyecto</TOKEN>
<TOKEN id="token-15-44" pos="word" morph="none" start_char="3273" end_char="3274">de</TOKEN>
<TOKEN id="token-15-45" pos="word" morph="none" start_char="3276" end_char="3277">la</TOKEN>
<TOKEN id="token-15-46" pos="word" morph="none" start_char="3279" end_char="3280">UE</TOKEN>
<TOKEN id="token-15-47" pos="word" morph="none" start_char="3282" end_char="3285">para</TOKEN>
<TOKEN id="token-15-48" pos="word" morph="none" start_char="3287" end_char="3288">la</TOKEN>
<TOKEN id="token-15-49" pos="word" morph="none" start_char="3290" end_char="3298">detección</TOKEN>
<TOKEN id="token-15-50" pos="word" morph="none" start_char="3300" end_char="3305">rápida</TOKEN>
<TOKEN id="token-15-51" pos="word" morph="none" start_char="3307" end_char="3309">del</TOKEN>
<TOKEN id="token-15-52" pos="word" morph="none" start_char="3311" end_char="3321">coronavirus</TOKEN>
<TOKEN id="token-15-53" pos="word" morph="none" start_char="3323" end_char="3323">a</TOKEN>
<TOKEN id="token-15-54" pos="word" morph="none" start_char="3325" end_char="3330">través</TOKEN>
<TOKEN id="token-15-55" pos="word" morph="none" start_char="3332" end_char="3333">de</TOKEN>
<TOKEN id="token-15-56" pos="word" morph="none" start_char="3335" end_char="3350">nanodispositivos</TOKEN>
<TOKEN id="token-15-57" pos="punct" morph="none" start_char="3351" end_char="3351">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="3354" end_char="3524">
<ORIGINAL_TEXT>El profesor defiende que es fundamental prohibir la tenencia y uso de especies protegidas y ofrecer alternativas para evitar el impacto del mercado negro de fauna salvaje.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="3354" end_char="3355">El</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="3357" end_char="3364">profesor</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="3366" end_char="3373">defiende</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="3375" end_char="3377">que</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="3379" end_char="3380">es</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="3382" end_char="3392">fundamental</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="3394" end_char="3401">prohibir</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="3403" end_char="3404">la</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="3406" end_char="3413">tenencia</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="3415" end_char="3415">y</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="3417" end_char="3419">uso</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="3421" end_char="3422">de</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="3424" end_char="3431">especies</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="3433" end_char="3442">protegidas</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="3444" end_char="3444">y</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="3446" end_char="3452">ofrecer</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="3454" end_char="3465">alternativas</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="3467" end_char="3470">para</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="3472" end_char="3477">evitar</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="3479" end_char="3480">el</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="3482" end_char="3488">impacto</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="3490" end_char="3492">del</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="3494" end_char="3500">mercado</TOKEN>
<TOKEN id="token-16-23" pos="word" morph="none" start_char="3502" end_char="3506">negro</TOKEN>
<TOKEN id="token-16-24" pos="word" morph="none" start_char="3508" end_char="3509">de</TOKEN>
<TOKEN id="token-16-25" pos="word" morph="none" start_char="3511" end_char="3515">fauna</TOKEN>
<TOKEN id="token-16-26" pos="word" morph="none" start_char="3517" end_char="3523">salvaje</TOKEN>
<TOKEN id="token-16-27" pos="punct" morph="none" start_char="3524" end_char="3524">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="3526" end_char="3871">
<ORIGINAL_TEXT>"Incluso si el brote de SARS-CoV-2 se originó de manera inesperada en Wuhan, se habría podido evitar", opinan los autores, que recuerdan que los inicios de esta pandemia son comparables con las de brotes anteriores de coronavirus, por ejemplo, el síndrome respiratorio de Oriente Medio o MERS, conocidas por la comunidad científica internacional.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="punct" morph="none" start_char="3526" end_char="3526">"</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="3527" end_char="3533">Incluso</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="3535" end_char="3536">si</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="3538" end_char="3539">el</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="3541" end_char="3545">brote</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="3547" end_char="3548">de</TOKEN>
<TOKEN id="token-17-6" pos="unknown" morph="none" start_char="3550" end_char="3559">SARS-CoV-2</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="3561" end_char="3562">se</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="3564" end_char="3570">originó</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="3572" end_char="3573">de</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="3575" end_char="3580">manera</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="3582" end_char="3591">inesperada</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="3593" end_char="3594">en</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="3596" end_char="3600">Wuhan</TOKEN>
<TOKEN id="token-17-14" pos="punct" morph="none" start_char="3601" end_char="3601">,</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="3603" end_char="3604">se</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="3606" end_char="3611">habría</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="3613" end_char="3618">podido</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="3620" end_char="3625">evitar</TOKEN>
<TOKEN id="token-17-19" pos="punct" morph="none" start_char="3626" end_char="3627">",</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="3629" end_char="3634">opinan</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="3636" end_char="3638">los</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="3640" end_char="3646">autores</TOKEN>
<TOKEN id="token-17-23" pos="punct" morph="none" start_char="3647" end_char="3647">,</TOKEN>
<TOKEN id="token-17-24" pos="word" morph="none" start_char="3649" end_char="3651">que</TOKEN>
<TOKEN id="token-17-25" pos="word" morph="none" start_char="3653" end_char="3661">recuerdan</TOKEN>
<TOKEN id="token-17-26" pos="word" morph="none" start_char="3663" end_char="3665">que</TOKEN>
<TOKEN id="token-17-27" pos="word" morph="none" start_char="3667" end_char="3669">los</TOKEN>
<TOKEN id="token-17-28" pos="word" morph="none" start_char="3671" end_char="3677">inicios</TOKEN>
<TOKEN id="token-17-29" pos="word" morph="none" start_char="3679" end_char="3680">de</TOKEN>
<TOKEN id="token-17-30" pos="word" morph="none" start_char="3682" end_char="3685">esta</TOKEN>
<TOKEN id="token-17-31" pos="word" morph="none" start_char="3687" end_char="3694">pandemia</TOKEN>
<TOKEN id="token-17-32" pos="word" morph="none" start_char="3696" end_char="3698">son</TOKEN>
<TOKEN id="token-17-33" pos="word" morph="none" start_char="3700" end_char="3710">comparables</TOKEN>
<TOKEN id="token-17-34" pos="word" morph="none" start_char="3712" end_char="3714">con</TOKEN>
<TOKEN id="token-17-35" pos="word" morph="none" start_char="3716" end_char="3718">las</TOKEN>
<TOKEN id="token-17-36" pos="word" morph="none" start_char="3720" end_char="3721">de</TOKEN>
<TOKEN id="token-17-37" pos="word" morph="none" start_char="3723" end_char="3728">brotes</TOKEN>
<TOKEN id="token-17-38" pos="word" morph="none" start_char="3730" end_char="3739">anteriores</TOKEN>
<TOKEN id="token-17-39" pos="word" morph="none" start_char="3741" end_char="3742">de</TOKEN>
<TOKEN id="token-17-40" pos="word" morph="none" start_char="3744" end_char="3754">coronavirus</TOKEN>
<TOKEN id="token-17-41" pos="punct" morph="none" start_char="3755" end_char="3755">,</TOKEN>
<TOKEN id="token-17-42" pos="word" morph="none" start_char="3757" end_char="3759">por</TOKEN>
<TOKEN id="token-17-43" pos="word" morph="none" start_char="3761" end_char="3767">ejemplo</TOKEN>
<TOKEN id="token-17-44" pos="punct" morph="none" start_char="3768" end_char="3768">,</TOKEN>
<TOKEN id="token-17-45" pos="word" morph="none" start_char="3770" end_char="3771">el</TOKEN>
<TOKEN id="token-17-46" pos="word" morph="none" start_char="3773" end_char="3780">síndrome</TOKEN>
<TOKEN id="token-17-47" pos="word" morph="none" start_char="3782" end_char="3793">respiratorio</TOKEN>
<TOKEN id="token-17-48" pos="word" morph="none" start_char="3795" end_char="3796">de</TOKEN>
<TOKEN id="token-17-49" pos="word" morph="none" start_char="3798" end_char="3804">Oriente</TOKEN>
<TOKEN id="token-17-50" pos="word" morph="none" start_char="3806" end_char="3810">Medio</TOKEN>
<TOKEN id="token-17-51" pos="word" morph="none" start_char="3812" end_char="3812">o</TOKEN>
<TOKEN id="token-17-52" pos="word" morph="none" start_char="3814" end_char="3817">MERS</TOKEN>
<TOKEN id="token-17-53" pos="punct" morph="none" start_char="3818" end_char="3818">,</TOKEN>
<TOKEN id="token-17-54" pos="word" morph="none" start_char="3820" end_char="3828">conocidas</TOKEN>
<TOKEN id="token-17-55" pos="word" morph="none" start_char="3830" end_char="3832">por</TOKEN>
<TOKEN id="token-17-56" pos="word" morph="none" start_char="3834" end_char="3835">la</TOKEN>
<TOKEN id="token-17-57" pos="word" morph="none" start_char="3837" end_char="3845">comunidad</TOKEN>
<TOKEN id="token-17-58" pos="word" morph="none" start_char="3847" end_char="3856">científica</TOKEN>
<TOKEN id="token-17-59" pos="word" morph="none" start_char="3858" end_char="3870">internacional</TOKEN>
<TOKEN id="token-17-60" pos="punct" morph="none" start_char="3871" end_char="3871">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="3874" end_char="3896">
<ORIGINAL_TEXT>"Habrá otras pandemias.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="punct" morph="none" start_char="3874" end_char="3874">"</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="3875" end_char="3879">Habrá</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="3881" end_char="3885">otras</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="3887" end_char="3895">pandemias</TOKEN>
<TOKEN id="token-18-4" pos="punct" morph="none" start_char="3896" end_char="3896">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="3898" end_char="3946">
<ORIGINAL_TEXT>Es solo una cuestión de probabilidad y de tiempo.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="3898" end_char="3899">Es</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="3901" end_char="3904">solo</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="3906" end_char="3908">una</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="3910" end_char="3917">cuestión</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="3919" end_char="3920">de</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="3922" end_char="3933">probabilidad</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="3935" end_char="3935">y</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="3937" end_char="3938">de</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="3940" end_char="3945">tiempo</TOKEN>
<TOKEN id="token-19-9" pos="punct" morph="none" start_char="3946" end_char="3946">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="3948" end_char="4232">
<ORIGINAL_TEXT>Actualmente, el riesgo de emergencia es mayoritariamente de coronavirus, arbovirus y virus de la gripe", alertan los autores del estudio, que recomiendan "un esfuerzo internacional y que los gobiernos puedan prever y se preparen para detener la próxima pandemia en su punto de origen".</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="3948" end_char="3958">Actualmente</TOKEN>
<TOKEN id="token-20-1" pos="punct" morph="none" start_char="3959" end_char="3959">,</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="3961" end_char="3962">el</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="3964" end_char="3969">riesgo</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="3971" end_char="3972">de</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="3974" end_char="3983">emergencia</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="3985" end_char="3986">es</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="3988" end_char="4003">mayoritariamente</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="4005" end_char="4006">de</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="4008" end_char="4018">coronavirus</TOKEN>
<TOKEN id="token-20-10" pos="punct" morph="none" start_char="4019" end_char="4019">,</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="4021" end_char="4029">arbovirus</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="4031" end_char="4031">y</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="4033" end_char="4037">virus</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="4039" end_char="4040">de</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="4042" end_char="4043">la</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="4045" end_char="4049">gripe</TOKEN>
<TOKEN id="token-20-17" pos="punct" morph="none" start_char="4050" end_char="4051">",</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="4053" end_char="4059">alertan</TOKEN>
<TOKEN id="token-20-19" pos="word" morph="none" start_char="4061" end_char="4063">los</TOKEN>
<TOKEN id="token-20-20" pos="word" morph="none" start_char="4065" end_char="4071">autores</TOKEN>
<TOKEN id="token-20-21" pos="word" morph="none" start_char="4073" end_char="4075">del</TOKEN>
<TOKEN id="token-20-22" pos="word" morph="none" start_char="4077" end_char="4083">estudio</TOKEN>
<TOKEN id="token-20-23" pos="punct" morph="none" start_char="4084" end_char="4084">,</TOKEN>
<TOKEN id="token-20-24" pos="word" morph="none" start_char="4086" end_char="4088">que</TOKEN>
<TOKEN id="token-20-25" pos="word" morph="none" start_char="4090" end_char="4100">recomiendan</TOKEN>
<TOKEN id="token-20-26" pos="punct" morph="none" start_char="4102" end_char="4102">"</TOKEN>
<TOKEN id="token-20-27" pos="word" morph="none" start_char="4103" end_char="4104">un</TOKEN>
<TOKEN id="token-20-28" pos="word" morph="none" start_char="4106" end_char="4113">esfuerzo</TOKEN>
<TOKEN id="token-20-29" pos="word" morph="none" start_char="4115" end_char="4127">internacional</TOKEN>
<TOKEN id="token-20-30" pos="word" morph="none" start_char="4129" end_char="4129">y</TOKEN>
<TOKEN id="token-20-31" pos="word" morph="none" start_char="4131" end_char="4133">que</TOKEN>
<TOKEN id="token-20-32" pos="word" morph="none" start_char="4135" end_char="4137">los</TOKEN>
<TOKEN id="token-20-33" pos="word" morph="none" start_char="4139" end_char="4147">gobiernos</TOKEN>
<TOKEN id="token-20-34" pos="word" morph="none" start_char="4149" end_char="4154">puedan</TOKEN>
<TOKEN id="token-20-35" pos="word" morph="none" start_char="4156" end_char="4161">prever</TOKEN>
<TOKEN id="token-20-36" pos="word" morph="none" start_char="4163" end_char="4163">y</TOKEN>
<TOKEN id="token-20-37" pos="word" morph="none" start_char="4165" end_char="4166">se</TOKEN>
<TOKEN id="token-20-38" pos="word" morph="none" start_char="4168" end_char="4175">preparen</TOKEN>
<TOKEN id="token-20-39" pos="word" morph="none" start_char="4177" end_char="4180">para</TOKEN>
<TOKEN id="token-20-40" pos="word" morph="none" start_char="4182" end_char="4188">detener</TOKEN>
<TOKEN id="token-20-41" pos="word" morph="none" start_char="4190" end_char="4191">la</TOKEN>
<TOKEN id="token-20-42" pos="word" morph="none" start_char="4193" end_char="4199">próxima</TOKEN>
<TOKEN id="token-20-43" pos="word" morph="none" start_char="4201" end_char="4208">pandemia</TOKEN>
<TOKEN id="token-20-44" pos="word" morph="none" start_char="4210" end_char="4211">en</TOKEN>
<TOKEN id="token-20-45" pos="word" morph="none" start_char="4213" end_char="4214">su</TOKEN>
<TOKEN id="token-20-46" pos="word" morph="none" start_char="4216" end_char="4220">punto</TOKEN>
<TOKEN id="token-20-47" pos="word" morph="none" start_char="4222" end_char="4223">de</TOKEN>
<TOKEN id="token-20-48" pos="word" morph="none" start_char="4225" end_char="4230">origen</TOKEN>
<TOKEN id="token-20-49" pos="punct" morph="none" start_char="4231" end_char="4232">".</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
