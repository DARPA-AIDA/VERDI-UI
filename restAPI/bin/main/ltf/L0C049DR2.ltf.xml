<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="eng">
<DOC id="L0C049DR2" lang="eng" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="2501" raw_text_md5="1bdf77fc1051557733852c7e2294e7b8">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="123">
<ORIGINAL_TEXT>Rudy Giuliani’s Wild Wine Lady Witness Peddles A New Bonkers Conspiracy Theory: ‘Obama Funded That Wuhan Lab To Make COVID’</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="4">Rudy</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="6" end_char="15">Giuliani’s</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="17" end_char="20">Wild</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="22" end_char="25">Wine</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="27" end_char="30">Lady</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="32" end_char="38">Witness</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="40" end_char="46">Peddles</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="48" end_char="48">A</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="50" end_char="52">New</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="54" end_char="60">Bonkers</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="62" end_char="71">Conspiracy</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="73" end_char="78">Theory</TOKEN>
<TOKEN id="token-0-12" pos="punct" morph="none" start_char="79" end_char="79">:</TOKEN>
<TOKEN id="token-0-13" pos="punct" morph="none" start_char="81" end_char="81">‘</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="82" end_char="86">Obama</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="88" end_char="93">Funded</TOKEN>
<TOKEN id="token-0-16" pos="word" morph="none" start_char="95" end_char="98">That</TOKEN>
<TOKEN id="token-0-17" pos="word" morph="none" start_char="100" end_char="104">Wuhan</TOKEN>
<TOKEN id="token-0-18" pos="word" morph="none" start_char="106" end_char="108">Lab</TOKEN>
<TOKEN id="token-0-19" pos="word" morph="none" start_char="110" end_char="111">To</TOKEN>
<TOKEN id="token-0-20" pos="word" morph="none" start_char="113" end_char="116">Make</TOKEN>
<TOKEN id="token-0-21" pos="word" morph="none" start_char="118" end_char="122">COVID</TOKEN>
<TOKEN id="token-0-22" pos="punct" morph="none" start_char="123" end_char="123">’</TOKEN>
</SEG>
<SEG id="segment-1" start_char="127" end_char="137">
<ORIGINAL_TEXT>Getty Image</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="127" end_char="131">Getty</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="133" end_char="137">Image</TOKEN>
</SEG>
<SEG id="segment-2" start_char="141" end_char="261">
<ORIGINAL_TEXT>The voter fraud hearing witness who’s come to be known as "Giuliani’s wine lady," aka Melissa Carone, has had a big week.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="141" end_char="143">The</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="145" end_char="149">voter</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="151" end_char="155">fraud</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="157" end_char="163">hearing</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="165" end_char="171">witness</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="173" end_char="177">who’s</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="179" end_char="182">come</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="184" end_char="185">to</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="187" end_char="188">be</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="190" end_char="194">known</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="196" end_char="197">as</TOKEN>
<TOKEN id="token-2-11" pos="punct" morph="none" start_char="199" end_char="199">"</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="200" end_char="209">Giuliani’s</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="211" end_char="214">wine</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="216" end_char="219">lady</TOKEN>
<TOKEN id="token-2-15" pos="punct" morph="none" start_char="220" end_char="221">,"</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="223" end_char="225">aka</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="227" end_char="233">Melissa</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="235" end_char="240">Carone</TOKEN>
<TOKEN id="token-2-19" pos="punct" morph="none" start_char="241" end_char="241">,</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="243" end_char="245">has</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="247" end_char="249">had</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="251" end_char="251">a</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="253" end_char="255">big</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="257" end_char="260">week</TOKEN>
<TOKEN id="token-2-25" pos="punct" morph="none" start_char="261" end_char="261">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="263" end_char="299">
<ORIGINAL_TEXT>And it’s been a big week for us, too.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="263" end_char="265">And</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="267" end_char="270">it’s</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="272" end_char="275">been</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="277" end_char="277">a</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="279" end_char="281">big</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="283" end_char="286">week</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="288" end_char="290">for</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="292" end_char="293">us</TOKEN>
<TOKEN id="token-3-8" pos="punct" morph="none" start_char="294" end_char="294">,</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="296" end_char="298">too</TOKEN>
<TOKEN id="token-3-10" pos="punct" morph="none" start_char="299" end_char="299">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="301" end_char="418">
<ORIGINAL_TEXT>We learned Carone, whose unhinged testimony catapulted her to social media infamy, has a bizarre history with the law.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="301" end_char="302">We</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="304" end_char="310">learned</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="312" end_char="317">Carone</TOKEN>
<TOKEN id="token-4-3" pos="punct" morph="none" start_char="318" end_char="318">,</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="320" end_char="324">whose</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="326" end_char="333">unhinged</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="335" end_char="343">testimony</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="345" end_char="354">catapulted</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="356" end_char="358">her</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="360" end_char="361">to</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="363" end_char="368">social</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="370" end_char="374">media</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="376" end_char="381">infamy</TOKEN>
<TOKEN id="token-4-13" pos="punct" morph="none" start_char="382" end_char="382">,</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="384" end_char="386">has</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="388" end_char="388">a</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="390" end_char="396">bizarre</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="398" end_char="404">history</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="406" end_char="409">with</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="411" end_char="413">the</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="415" end_char="417">law</TOKEN>
<TOKEN id="token-4-21" pos="punct" morph="none" start_char="418" end_char="418">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="420" end_char="509">
<ORIGINAL_TEXT>We learned that, according to her at least, she wasn’t allegedly drunk during the hearing.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="420" end_char="421">We</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="423" end_char="429">learned</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="431" end_char="434">that</TOKEN>
<TOKEN id="token-5-3" pos="punct" morph="none" start_char="435" end_char="435">,</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="437" end_char="445">according</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="447" end_char="448">to</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="450" end_char="452">her</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="454" end_char="455">at</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="457" end_char="461">least</TOKEN>
<TOKEN id="token-5-9" pos="punct" morph="none" start_char="462" end_char="462">,</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="464" end_char="466">she</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="468" end_char="473">wasn’t</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="475" end_char="483">allegedly</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="485" end_char="489">drunk</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="491" end_char="496">during</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="498" end_char="500">the</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="502" end_char="508">hearing</TOKEN>
<TOKEN id="token-5-17" pos="punct" morph="none" start_char="509" end_char="509">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="511" end_char="586">
<ORIGINAL_TEXT>We learned that she used to dance at a strip club actually called Bada Bing.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="511" end_char="512">We</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="514" end_char="520">learned</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="522" end_char="525">that</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="527" end_char="529">she</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="531" end_char="534">used</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="536" end_char="537">to</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="539" end_char="543">dance</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="545" end_char="546">at</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="548" end_char="548">a</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="550" end_char="554">strip</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="556" end_char="559">club</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="561" end_char="568">actually</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="570" end_char="575">called</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="577" end_char="580">Bada</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="582" end_char="585">Bing</TOKEN>
<TOKEN id="token-6-15" pos="punct" morph="none" start_char="586" end_char="586">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="588" end_char="705">
<ORIGINAL_TEXT>And now it turns out she believes one of the battier current conspiracy theories: that COVID-19 was invented in a lab.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="588" end_char="590">And</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="592" end_char="594">now</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="596" end_char="597">it</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="599" end_char="603">turns</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="605" end_char="607">out</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="609" end_char="611">she</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="613" end_char="620">believes</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="622" end_char="624">one</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="626" end_char="627">of</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="629" end_char="631">the</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="633" end_char="639">battier</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="641" end_char="647">current</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="649" end_char="658">conspiracy</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="660" end_char="667">theories</TOKEN>
<TOKEN id="token-7-14" pos="punct" morph="none" start_char="668" end_char="668">:</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="670" end_char="673">that</TOKEN>
<TOKEN id="token-7-16" pos="unknown" morph="none" start_char="675" end_char="682">COVID-19</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="684" end_char="686">was</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="688" end_char="695">invented</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="697" end_char="698">in</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="700" end_char="700">a</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="702" end_char="704">lab</TOKEN>
<TOKEN id="token-7-22" pos="punct" morph="none" start_char="705" end_char="705">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="707" end_char="728">
<ORIGINAL_TEXT>Oh, the Obamas did it.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="707" end_char="708">Oh</TOKEN>
<TOKEN id="token-8-1" pos="punct" morph="none" start_char="709" end_char="709">,</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="711" end_char="713">the</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="715" end_char="720">Obamas</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="722" end_char="724">did</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="726" end_char="727">it</TOKEN>
<TOKEN id="token-8-6" pos="punct" morph="none" start_char="728" end_char="728">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="731" end_char="736">
<ORIGINAL_TEXT>As per</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="731" end_char="732">As</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="734" end_char="736">per</TOKEN>
</SEG>
<SEG id="segment-10" start_char="739" end_char="746">
<ORIGINAL_TEXT>Newsweek</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="739" end_char="746">Newsweek</TOKEN>
</SEG>
<SEG id="segment-11" start_char="749" end_char="829">
<ORIGINAL_TEXT>, Carone sat down for an exclusive interview posted on the belong to — of course!</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="punct" morph="none" start_char="749" end_char="749">,</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="751" end_char="756">Carone</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="758" end_char="760">sat</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="762" end_char="765">down</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="767" end_char="769">for</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="771" end_char="772">an</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="774" end_char="782">exclusive</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="784" end_char="792">interview</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="794" end_char="799">posted</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="801" end_char="802">on</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="804" end_char="806">the</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="808" end_char="813">belong</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="815" end_char="816">to</TOKEN>
<TOKEN id="token-11-13" pos="punct" morph="none" start_char="818" end_char="818">—</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="820" end_char="821">of</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="823" end_char="828">course</TOKEN>
<TOKEN id="token-11-16" pos="punct" morph="none" start_char="829" end_char="829">!</TOKEN>
</SEG>
<SEG id="segment-12" start_char="831" end_char="961">
<ORIGINAL_TEXT>— Sarah Palin, the late John McCain’s notorious (and partially forgotten) former running mate, from the more simpler times of 2008.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="punct" morph="none" start_char="831" end_char="831">—</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="833" end_char="837">Sarah</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="839" end_char="843">Palin</TOKEN>
<TOKEN id="token-12-3" pos="punct" morph="none" start_char="844" end_char="844">,</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="846" end_char="848">the</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="850" end_char="853">late</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="855" end_char="858">John</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="860" end_char="867">McCain’s</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="869" end_char="877">notorious</TOKEN>
<TOKEN id="token-12-9" pos="punct" morph="none" start_char="879" end_char="879">(</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="880" end_char="882">and</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="884" end_char="892">partially</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="894" end_char="902">forgotten</TOKEN>
<TOKEN id="token-12-13" pos="punct" morph="none" start_char="903" end_char="903">)</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="905" end_char="910">former</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="912" end_char="918">running</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="920" end_char="923">mate</TOKEN>
<TOKEN id="token-12-17" pos="punct" morph="none" start_char="924" end_char="924">,</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="926" end_char="929">from</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="931" end_char="933">the</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="935" end_char="938">more</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="940" end_char="946">simpler</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="948" end_char="952">times</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="954" end_char="955">of</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="957" end_char="960">2008</TOKEN>
<TOKEN id="token-12-25" pos="punct" morph="none" start_char="961" end_char="961">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="963" end_char="1097">
<ORIGINAL_TEXT>One Kevin Scholla spoke with Carone about her being the target of derision and not a little bit scorn, to which Palin, too, can relate.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="963" end_char="965">One</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="967" end_char="971">Kevin</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="973" end_char="979">Scholla</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="981" end_char="985">spoke</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="987" end_char="990">with</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="992" end_char="997">Carone</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="999" end_char="1003">about</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1005" end_char="1007">her</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1009" end_char="1013">being</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1015" end_char="1017">the</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1019" end_char="1024">target</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1026" end_char="1027">of</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1029" end_char="1036">derision</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1038" end_char="1040">and</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1042" end_char="1044">not</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1046" end_char="1046">a</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1048" end_char="1053">little</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1055" end_char="1057">bit</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1059" end_char="1063">scorn</TOKEN>
<TOKEN id="token-13-19" pos="punct" morph="none" start_char="1064" end_char="1064">,</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1066" end_char="1067">to</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="1069" end_char="1073">which</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="1075" end_char="1079">Palin</TOKEN>
<TOKEN id="token-13-23" pos="punct" morph="none" start_char="1080" end_char="1080">,</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="1082" end_char="1084">too</TOKEN>
<TOKEN id="token-13-25" pos="punct" morph="none" start_char="1085" end_char="1085">,</TOKEN>
<TOKEN id="token-13-26" pos="word" morph="none" start_char="1087" end_char="1089">can</TOKEN>
<TOKEN id="token-13-27" pos="word" morph="none" start_char="1091" end_char="1096">relate</TOKEN>
<TOKEN id="token-13-28" pos="punct" morph="none" start_char="1097" end_char="1097">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1100" end_char="1144">
<ORIGINAL_TEXT>"This is what they do to Trump," Carone said.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="punct" morph="none" start_char="1100" end_char="1100">"</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1101" end_char="1104">This</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1106" end_char="1107">is</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1109" end_char="1112">what</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1114" end_char="1117">they</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1119" end_char="1120">do</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1122" end_char="1123">to</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1125" end_char="1129">Trump</TOKEN>
<TOKEN id="token-14-8" pos="punct" morph="none" start_char="1130" end_char="1131">,"</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1133" end_char="1138">Carone</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1140" end_char="1143">said</TOKEN>
<TOKEN id="token-14-11" pos="punct" morph="none" start_char="1144" end_char="1144">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1146" end_char="1177">
<ORIGINAL_TEXT>"It’s not going to work with me.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="punct" morph="none" start_char="1146" end_char="1146">"</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1147" end_char="1150">It’s</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1152" end_char="1154">not</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1156" end_char="1160">going</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1162" end_char="1163">to</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1165" end_char="1168">work</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1170" end_char="1173">with</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1175" end_char="1176">me</TOKEN>
<TOKEN id="token-15-8" pos="punct" morph="none" start_char="1177" end_char="1177">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1179" end_char="1259">
<ORIGINAL_TEXT>I won’t back down because I am very religious and I know God is watching over me.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1179" end_char="1179">I</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1181" end_char="1185">won’t</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1187" end_char="1190">back</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1192" end_char="1195">down</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1197" end_char="1203">because</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1205" end_char="1205">I</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1207" end_char="1208">am</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1210" end_char="1213">very</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1215" end_char="1223">religious</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="1225" end_char="1227">and</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="1229" end_char="1229">I</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="1231" end_char="1234">know</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="1236" end_char="1238">God</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="1240" end_char="1241">is</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="1243" end_char="1250">watching</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="1252" end_char="1255">over</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="1257" end_char="1258">me</TOKEN>
<TOKEN id="token-16-17" pos="punct" morph="none" start_char="1259" end_char="1259">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1261" end_char="1285">
<ORIGINAL_TEXT>This started with COVID."</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1261" end_char="1264">This</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1266" end_char="1272">started</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="1274" end_char="1277">with</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="1279" end_char="1283">COVID</TOKEN>
<TOKEN id="token-17-4" pos="punct" morph="none" start_char="1284" end_char="1285">."</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1287" end_char="1314">
<ORIGINAL_TEXT>Carone then went next level.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="1287" end_char="1292">Carone</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="1294" end_char="1297">then</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="1299" end_char="1302">went</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="1304" end_char="1307">next</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="1309" end_char="1313">level</TOKEN>
<TOKEN id="token-18-5" pos="punct" morph="none" start_char="1314" end_char="1314">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="1316" end_char="1363">
<ORIGINAL_TEXT>"The Obamas funded that Wuhan lab to make COVID.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="punct" morph="none" start_char="1316" end_char="1316">"</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="1317" end_char="1319">The</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="1321" end_char="1326">Obamas</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="1328" end_char="1333">funded</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="1335" end_char="1338">that</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="1340" end_char="1344">Wuhan</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="1346" end_char="1348">lab</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="1350" end_char="1351">to</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="1353" end_char="1356">make</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="1358" end_char="1362">COVID</TOKEN>
<TOKEN id="token-19-10" pos="punct" morph="none" start_char="1363" end_char="1363">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="1365" end_char="1394">
<ORIGINAL_TEXT>Then the impeachment process."</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="1365" end_char="1368">Then</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="1370" end_char="1372">the</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="1374" end_char="1384">impeachment</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="1386" end_char="1392">process</TOKEN>
<TOKEN id="token-20-4" pos="punct" morph="none" start_char="1393" end_char="1394">."</TOKEN>
</SEG>
<SEG id="segment-21" start_char="1397" end_char="1411">
<ORIGINAL_TEXT>She kept going.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="1397" end_char="1399">She</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="1401" end_char="1404">kept</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="1406" end_char="1410">going</TOKEN>
<TOKEN id="token-21-3" pos="punct" morph="none" start_char="1411" end_char="1411">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="1413" end_char="1488">
<ORIGINAL_TEXT>"They’ve used every avenue possible to cheat, they used Dominion," she said.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="punct" morph="none" start_char="1413" end_char="1413">"</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="1414" end_char="1420">They’ve</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="1422" end_char="1425">used</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="1427" end_char="1431">every</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="1433" end_char="1438">avenue</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="1440" end_char="1447">possible</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="1449" end_char="1450">to</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="1452" end_char="1456">cheat</TOKEN>
<TOKEN id="token-22-8" pos="punct" morph="none" start_char="1457" end_char="1457">,</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="1459" end_char="1462">they</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="1464" end_char="1467">used</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="1469" end_char="1476">Dominion</TOKEN>
<TOKEN id="token-22-12" pos="punct" morph="none" start_char="1477" end_char="1478">,"</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="1480" end_char="1482">she</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="1484" end_char="1487">said</TOKEN>
<TOKEN id="token-22-15" pos="punct" morph="none" start_char="1488" end_char="1488">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="1490" end_char="1529">
<ORIGINAL_TEXT>"Dominion software was created to cheat.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="punct" morph="none" start_char="1490" end_char="1490">"</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="1491" end_char="1498">Dominion</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="1500" end_char="1507">software</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="1509" end_char="1511">was</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="1513" end_char="1519">created</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="1521" end_char="1522">to</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="1524" end_char="1528">cheat</TOKEN>
<TOKEN id="token-23-7" pos="punct" morph="none" start_char="1529" end_char="1529">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="1531" end_char="1577">
<ORIGINAL_TEXT>I have a binder from Dominion that proves this.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="1531" end_char="1531">I</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="1533" end_char="1536">have</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="1538" end_char="1538">a</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="1540" end_char="1545">binder</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="1547" end_char="1550">from</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="1552" end_char="1559">Dominion</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="1561" end_char="1564">that</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="1566" end_char="1571">proves</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="1573" end_char="1576">this</TOKEN>
<TOKEN id="token-24-9" pos="punct" morph="none" start_char="1577" end_char="1577">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="1579" end_char="1621">
<ORIGINAL_TEXT>There’s so much more that will be exposed."</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="1579" end_char="1585">There’s</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="1587" end_char="1588">so</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="1590" end_char="1593">much</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="1595" end_char="1598">more</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="1600" end_char="1603">that</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="1605" end_char="1608">will</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="1610" end_char="1611">be</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="1613" end_char="1619">exposed</TOKEN>
<TOKEN id="token-25-8" pos="punct" morph="none" start_char="1620" end_char="1621">."</TOKEN>
</SEG>
<SEG id="segment-26" start_char="1624" end_char="1667">
<ORIGINAL_TEXT>Mind you, none of this is original nonsense.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="1624" end_char="1627">Mind</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="1629" end_char="1631">you</TOKEN>
<TOKEN id="token-26-2" pos="punct" morph="none" start_char="1632" end_char="1632">,</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="1634" end_char="1637">none</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="1639" end_char="1640">of</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="1642" end_char="1645">this</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="1647" end_char="1648">is</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="1650" end_char="1657">original</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="1659" end_char="1666">nonsense</TOKEN>
<TOKEN id="token-26-9" pos="punct" morph="none" start_char="1667" end_char="1667">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="1669" end_char="1767">
<ORIGINAL_TEXT>These are all moth-ridden Trumpist conspiracy theories, all of them easily and repeatedly debunked.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="1669" end_char="1673">These</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="1675" end_char="1677">are</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="1679" end_char="1681">all</TOKEN>
<TOKEN id="token-27-3" pos="unknown" morph="none" start_char="1683" end_char="1693">moth-ridden</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="1695" end_char="1702">Trumpist</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="1704" end_char="1713">conspiracy</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="1715" end_char="1722">theories</TOKEN>
<TOKEN id="token-27-7" pos="punct" morph="none" start_char="1723" end_char="1723">,</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="1725" end_char="1727">all</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="1729" end_char="1730">of</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="1732" end_char="1735">them</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="1737" end_char="1742">easily</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="1744" end_char="1746">and</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="1748" end_char="1757">repeatedly</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="1759" end_char="1766">debunked</TOKEN>
<TOKEN id="token-27-15" pos="punct" morph="none" start_char="1767" end_char="1767">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="1770" end_char="1846">
<ORIGINAL_TEXT>Interestingly, though, the interview mysteriously vanished from Palin’s site.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="1770" end_char="1782">Interestingly</TOKEN>
<TOKEN id="token-28-1" pos="punct" morph="none" start_char="1783" end_char="1783">,</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="1785" end_char="1790">though</TOKEN>
<TOKEN id="token-28-3" pos="punct" morph="none" start_char="1791" end_char="1791">,</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="1793" end_char="1795">the</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="1797" end_char="1805">interview</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="1807" end_char="1818">mysteriously</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="1820" end_char="1827">vanished</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="1829" end_char="1832">from</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="1834" end_char="1840">Palin’s</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="1842" end_char="1845">site</TOKEN>
<TOKEN id="token-28-11" pos="punct" morph="none" start_char="1846" end_char="1846">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="1848" end_char="2170">
<ORIGINAL_TEXT>Luckily, it was documented in full at Archive.org, though it mostly finds her again parroting far right talking points: the line about Trump being ahead early in the evening, before absentee votes were counted; that Republican governors not overturning the election are "RINOs"; that there’s more coming out, just you wait.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="1848" end_char="1854">Luckily</TOKEN>
<TOKEN id="token-29-1" pos="punct" morph="none" start_char="1855" end_char="1855">,</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="1857" end_char="1858">it</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="1860" end_char="1862">was</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="1864" end_char="1873">documented</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="1875" end_char="1876">in</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="1878" end_char="1881">full</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="1883" end_char="1884">at</TOKEN>
<TOKEN id="token-29-8" pos="unknown" morph="none" start_char="1886" end_char="1896">Archive.org</TOKEN>
<TOKEN id="token-29-9" pos="punct" morph="none" start_char="1897" end_char="1897">,</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="1899" end_char="1904">though</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="1906" end_char="1907">it</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="1909" end_char="1914">mostly</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="1916" end_char="1920">finds</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="1922" end_char="1924">her</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="1926" end_char="1930">again</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="1932" end_char="1940">parroting</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="1942" end_char="1944">far</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="1946" end_char="1950">right</TOKEN>
<TOKEN id="token-29-19" pos="word" morph="none" start_char="1952" end_char="1958">talking</TOKEN>
<TOKEN id="token-29-20" pos="word" morph="none" start_char="1960" end_char="1965">points</TOKEN>
<TOKEN id="token-29-21" pos="punct" morph="none" start_char="1966" end_char="1966">:</TOKEN>
<TOKEN id="token-29-22" pos="word" morph="none" start_char="1968" end_char="1970">the</TOKEN>
<TOKEN id="token-29-23" pos="word" morph="none" start_char="1972" end_char="1975">line</TOKEN>
<TOKEN id="token-29-24" pos="word" morph="none" start_char="1977" end_char="1981">about</TOKEN>
<TOKEN id="token-29-25" pos="word" morph="none" start_char="1983" end_char="1987">Trump</TOKEN>
<TOKEN id="token-29-26" pos="word" morph="none" start_char="1989" end_char="1993">being</TOKEN>
<TOKEN id="token-29-27" pos="word" morph="none" start_char="1995" end_char="1999">ahead</TOKEN>
<TOKEN id="token-29-28" pos="word" morph="none" start_char="2001" end_char="2005">early</TOKEN>
<TOKEN id="token-29-29" pos="word" morph="none" start_char="2007" end_char="2008">in</TOKEN>
<TOKEN id="token-29-30" pos="word" morph="none" start_char="2010" end_char="2012">the</TOKEN>
<TOKEN id="token-29-31" pos="word" morph="none" start_char="2014" end_char="2020">evening</TOKEN>
<TOKEN id="token-29-32" pos="punct" morph="none" start_char="2021" end_char="2021">,</TOKEN>
<TOKEN id="token-29-33" pos="word" morph="none" start_char="2023" end_char="2028">before</TOKEN>
<TOKEN id="token-29-34" pos="word" morph="none" start_char="2030" end_char="2037">absentee</TOKEN>
<TOKEN id="token-29-35" pos="word" morph="none" start_char="2039" end_char="2043">votes</TOKEN>
<TOKEN id="token-29-36" pos="word" morph="none" start_char="2045" end_char="2048">were</TOKEN>
<TOKEN id="token-29-37" pos="word" morph="none" start_char="2050" end_char="2056">counted</TOKEN>
<TOKEN id="token-29-38" pos="punct" morph="none" start_char="2057" end_char="2057">;</TOKEN>
<TOKEN id="token-29-39" pos="word" morph="none" start_char="2059" end_char="2062">that</TOKEN>
<TOKEN id="token-29-40" pos="word" morph="none" start_char="2064" end_char="2073">Republican</TOKEN>
<TOKEN id="token-29-41" pos="word" morph="none" start_char="2075" end_char="2083">governors</TOKEN>
<TOKEN id="token-29-42" pos="word" morph="none" start_char="2085" end_char="2087">not</TOKEN>
<TOKEN id="token-29-43" pos="word" morph="none" start_char="2089" end_char="2099">overturning</TOKEN>
<TOKEN id="token-29-44" pos="word" morph="none" start_char="2101" end_char="2103">the</TOKEN>
<TOKEN id="token-29-45" pos="word" morph="none" start_char="2105" end_char="2112">election</TOKEN>
<TOKEN id="token-29-46" pos="word" morph="none" start_char="2114" end_char="2116">are</TOKEN>
<TOKEN id="token-29-47" pos="punct" morph="none" start_char="2118" end_char="2118">"</TOKEN>
<TOKEN id="token-29-48" pos="word" morph="none" start_char="2119" end_char="2123">RINOs</TOKEN>
<TOKEN id="token-29-49" pos="punct" morph="none" start_char="2124" end_char="2125">";</TOKEN>
<TOKEN id="token-29-50" pos="word" morph="none" start_char="2127" end_char="2130">that</TOKEN>
<TOKEN id="token-29-51" pos="word" morph="none" start_char="2132" end_char="2138">there’s</TOKEN>
<TOKEN id="token-29-52" pos="word" morph="none" start_char="2140" end_char="2143">more</TOKEN>
<TOKEN id="token-29-53" pos="word" morph="none" start_char="2145" end_char="2150">coming</TOKEN>
<TOKEN id="token-29-54" pos="word" morph="none" start_char="2152" end_char="2154">out</TOKEN>
<TOKEN id="token-29-55" pos="punct" morph="none" start_char="2155" end_char="2155">,</TOKEN>
<TOKEN id="token-29-56" pos="word" morph="none" start_char="2157" end_char="2160">just</TOKEN>
<TOKEN id="token-29-57" pos="word" morph="none" start_char="2162" end_char="2164">you</TOKEN>
<TOKEN id="token-29-58" pos="word" morph="none" start_char="2166" end_char="2169">wait</TOKEN>
<TOKEN id="token-29-59" pos="punct" morph="none" start_char="2170" end_char="2170">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="2173" end_char="2309">
<ORIGINAL_TEXT>The article concludes by whipping out a term you may not have heard in the last 12 years: "Mama grizzlies everywhere have a new champion.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="2173" end_char="2175">The</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="2177" end_char="2183">article</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="2185" end_char="2193">concludes</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="2195" end_char="2196">by</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="2198" end_char="2205">whipping</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="2207" end_char="2209">out</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="2211" end_char="2211">a</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="2213" end_char="2216">term</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="2218" end_char="2220">you</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="2222" end_char="2224">may</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="2226" end_char="2228">not</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="2230" end_char="2233">have</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="2235" end_char="2239">heard</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="2241" end_char="2242">in</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="2244" end_char="2246">the</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="2248" end_char="2251">last</TOKEN>
<TOKEN id="token-30-16" pos="word" morph="none" start_char="2253" end_char="2254">12</TOKEN>
<TOKEN id="token-30-17" pos="word" morph="none" start_char="2256" end_char="2260">years</TOKEN>
<TOKEN id="token-30-18" pos="punct" morph="none" start_char="2261" end_char="2261">:</TOKEN>
<TOKEN id="token-30-19" pos="punct" morph="none" start_char="2263" end_char="2263">"</TOKEN>
<TOKEN id="token-30-20" pos="word" morph="none" start_char="2264" end_char="2267">Mama</TOKEN>
<TOKEN id="token-30-21" pos="word" morph="none" start_char="2269" end_char="2277">grizzlies</TOKEN>
<TOKEN id="token-30-22" pos="word" morph="none" start_char="2279" end_char="2288">everywhere</TOKEN>
<TOKEN id="token-30-23" pos="word" morph="none" start_char="2290" end_char="2293">have</TOKEN>
<TOKEN id="token-30-24" pos="word" morph="none" start_char="2295" end_char="2295">a</TOKEN>
<TOKEN id="token-30-25" pos="word" morph="none" start_char="2297" end_char="2299">new</TOKEN>
<TOKEN id="token-30-26" pos="word" morph="none" start_char="2301" end_char="2308">champion</TOKEN>
<TOKEN id="token-30-27" pos="punct" morph="none" start_char="2309" end_char="2309">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="2311" end_char="2358">
<ORIGINAL_TEXT>She’s the Mama Wolverine, Mellissa Carone [sic].</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="2311" end_char="2315">She’s</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="2317" end_char="2319">the</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="2321" end_char="2324">Mama</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="2326" end_char="2334">Wolverine</TOKEN>
<TOKEN id="token-31-4" pos="punct" morph="none" start_char="2335" end_char="2335">,</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="2337" end_char="2344">Mellissa</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="2346" end_char="2351">Carone</TOKEN>
<TOKEN id="token-31-7" pos="punct" morph="none" start_char="2353" end_char="2353">[</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="2354" end_char="2356">sic</TOKEN>
<TOKEN id="token-31-9" pos="punct" morph="none" start_char="2357" end_char="2358">].</TOKEN>
</SEG>
<SEG id="segment-32" start_char="2360" end_char="2385">
<ORIGINAL_TEXT>And she’s not going away."</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="2360" end_char="2362">And</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="2364" end_char="2368">she’s</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="2370" end_char="2372">not</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="2374" end_char="2378">going</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="2380" end_char="2383">away</TOKEN>
<TOKEN id="token-32-5" pos="punct" morph="none" start_char="2384" end_char="2385">."</TOKEN>
</SEG>
<SEG id="segment-33" start_char="2388" end_char="2447">
<ORIGINAL_TEXT>Ordinarily we’d say her 15 minutes of fame are about to end.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="2388" end_char="2397">Ordinarily</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="2399" end_char="2402">we’d</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="2404" end_char="2406">say</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="2408" end_char="2410">her</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="2412" end_char="2413">15</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="2415" end_char="2421">minutes</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="2423" end_char="2424">of</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="2426" end_char="2429">fame</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="2431" end_char="2433">are</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="2435" end_char="2439">about</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="2441" end_char="2442">to</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="2444" end_char="2446">end</TOKEN>
<TOKEN id="token-33-12" pos="punct" morph="none" start_char="2447" end_char="2447">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="2449" end_char="2497">
<ORIGINAL_TEXT>But the Trump era GOP always needs more like her.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="2449" end_char="2451">But</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="2453" end_char="2455">the</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="2457" end_char="2461">Trump</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="2463" end_char="2465">era</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="2467" end_char="2469">GOP</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="2471" end_char="2476">always</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="2478" end_char="2482">needs</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="2484" end_char="2487">more</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="2489" end_char="2492">like</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="2494" end_char="2496">her</TOKEN>
<TOKEN id="token-34-10" pos="punct" morph="none" start_char="2497" end_char="2497">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
