<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CA6N" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="3484" raw_text_md5="03c0477eae2bcec0aa7effec73e49f74">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="73">
<ORIGINAL_TEXT>Study linking coronavirus origin to stray dogs 'speculative', experts say</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="5">Study</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="7" end_char="13">linking</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="15" end_char="25">coronavirus</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="27" end_char="32">origin</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="34" end_char="35">to</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="37" end_char="41">stray</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="43" end_char="46">dogs</TOKEN>
<TOKEN id="token-0-7" pos="punct" morph="none" start_char="48" end_char="48">'</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="49" end_char="59">speculative</TOKEN>
<TOKEN id="token-0-9" pos="punct" morph="none" start_char="60" end_char="61">',</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="63" end_char="69">experts</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="71" end_char="73">say</TOKEN>
</SEG>
<SEG id="segment-1" start_char="77" end_char="97">
<ORIGINAL_TEXT>Representative image.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="77" end_char="90">Representative</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="92" end_char="96">image</TOKEN>
<TOKEN id="token-1-2" pos="punct" morph="none" start_char="97" end_char="97">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="99" end_char="112">
<ORIGINAL_TEXT>(iStock photo)</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="punct" morph="none" start_char="99" end_char="99">(</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="100" end_char="105">iStock</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="107" end_char="111">photo</TOKEN>
<TOKEN id="token-2-3" pos="punct" morph="none" start_char="112" end_char="112">)</TOKEN>
</SEG>
<SEG id="segment-3" start_char="116" end_char="403">
<ORIGINAL_TEXT>Scientists have expressed concerns about a study which proposed that stray dogs may have played a role in the origin of the novel coronavirus behind the COVID-19 pandemic, saying that pet owners may abandon their dogs because of these "speculative" findings which need experimental proof.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="116" end_char="125">Scientists</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="127" end_char="130">have</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="132" end_char="140">expressed</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="142" end_char="149">concerns</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="151" end_char="155">about</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="157" end_char="157">a</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="159" end_char="163">study</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="165" end_char="169">which</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="171" end_char="178">proposed</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="180" end_char="183">that</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="185" end_char="189">stray</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="191" end_char="194">dogs</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="196" end_char="198">may</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="200" end_char="203">have</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="205" end_char="210">played</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="212" end_char="212">a</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="214" end_char="217">role</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="219" end_char="220">in</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="222" end_char="224">the</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="226" end_char="231">origin</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="233" end_char="234">of</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="236" end_char="238">the</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="240" end_char="244">novel</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="246" end_char="256">coronavirus</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="258" end_char="263">behind</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="265" end_char="267">the</TOKEN>
<TOKEN id="token-3-26" pos="unknown" morph="none" start_char="269" end_char="276">COVID-19</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="278" end_char="285">pandemic</TOKEN>
<TOKEN id="token-3-28" pos="punct" morph="none" start_char="286" end_char="286">,</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="288" end_char="293">saying</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="295" end_char="298">that</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="300" end_char="302">pet</TOKEN>
<TOKEN id="token-3-32" pos="word" morph="none" start_char="304" end_char="309">owners</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="311" end_char="313">may</TOKEN>
<TOKEN id="token-3-34" pos="word" morph="none" start_char="315" end_char="321">abandon</TOKEN>
<TOKEN id="token-3-35" pos="word" morph="none" start_char="323" end_char="327">their</TOKEN>
<TOKEN id="token-3-36" pos="word" morph="none" start_char="329" end_char="332">dogs</TOKEN>
<TOKEN id="token-3-37" pos="word" morph="none" start_char="334" end_char="340">because</TOKEN>
<TOKEN id="token-3-38" pos="word" morph="none" start_char="342" end_char="343">of</TOKEN>
<TOKEN id="token-3-39" pos="word" morph="none" start_char="345" end_char="349">these</TOKEN>
<TOKEN id="token-3-40" pos="punct" morph="none" start_char="351" end_char="351">"</TOKEN>
<TOKEN id="token-3-41" pos="word" morph="none" start_char="352" end_char="362">speculative</TOKEN>
<TOKEN id="token-3-42" pos="punct" morph="none" start_char="363" end_char="363">"</TOKEN>
<TOKEN id="token-3-43" pos="word" morph="none" start_char="365" end_char="372">findings</TOKEN>
<TOKEN id="token-3-44" pos="word" morph="none" start_char="374" end_char="378">which</TOKEN>
<TOKEN id="token-3-45" pos="word" morph="none" start_char="380" end_char="383">need</TOKEN>
<TOKEN id="token-3-46" pos="word" morph="none" start_char="385" end_char="396">experimental</TOKEN>
<TOKEN id="token-3-47" pos="word" morph="none" start_char="398" end_char="402">proof</TOKEN>
<TOKEN id="token-3-48" pos="punct" morph="none" start_char="403" end_char="403">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="406" end_char="612">
<ORIGINAL_TEXT>The study, published earlier this month in the journal Molecular Biology and Evolution, proposed a possible link between stray dogs, particularly their intestines, and the evolution of the novel coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="406" end_char="408">The</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="410" end_char="414">study</TOKEN>
<TOKEN id="token-4-2" pos="punct" morph="none" start_char="415" end_char="415">,</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="417" end_char="425">published</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="427" end_char="433">earlier</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="435" end_char="438">this</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="440" end_char="444">month</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="446" end_char="447">in</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="449" end_char="451">the</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="453" end_char="459">journal</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="461" end_char="469">Molecular</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="471" end_char="477">Biology</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="479" end_char="481">and</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="483" end_char="491">Evolution</TOKEN>
<TOKEN id="token-4-14" pos="punct" morph="none" start_char="492" end_char="492">,</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="494" end_char="501">proposed</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="503" end_char="503">a</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="505" end_char="512">possible</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="514" end_char="517">link</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="519" end_char="525">between</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="527" end_char="531">stray</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="533" end_char="536">dogs</TOKEN>
<TOKEN id="token-4-22" pos="punct" morph="none" start_char="537" end_char="537">,</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="539" end_char="550">particularly</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="552" end_char="556">their</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="558" end_char="567">intestines</TOKEN>
<TOKEN id="token-4-26" pos="punct" morph="none" start_char="568" end_char="568">,</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="570" end_char="572">and</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="574" end_char="576">the</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="578" end_char="586">evolution</TOKEN>
<TOKEN id="token-4-30" pos="word" morph="none" start_char="588" end_char="589">of</TOKEN>
<TOKEN id="token-4-31" pos="word" morph="none" start_char="591" end_char="593">the</TOKEN>
<TOKEN id="token-4-32" pos="word" morph="none" start_char="595" end_char="599">novel</TOKEN>
<TOKEN id="token-4-33" pos="word" morph="none" start_char="601" end_char="611">coronavirus</TOKEN>
<TOKEN id="token-4-34" pos="punct" morph="none" start_char="612" end_char="612">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="615" end_char="648">
<ORIGINAL_TEXT>Follow live updates on coronavirus</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="615" end_char="620">Follow</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="622" end_char="625">live</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="627" end_char="633">updates</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="635" end_char="636">on</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="638" end_char="648">coronavirus</TOKEN>
</SEG>
<SEG id="segment-6" start_char="651" end_char="907">
<ORIGINAL_TEXT>According to the study author Xuhua Xia from the University of Ottawa in Canada, the intestines of stray dogs may have offered a conducive environment for coronaviruses to evolve into ones with better ability to evade certain mammalian host immune defences.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="651" end_char="659">According</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="661" end_char="662">to</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="664" end_char="666">the</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="668" end_char="672">study</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="674" end_char="679">author</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="681" end_char="685">Xuhua</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="687" end_char="689">Xia</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="691" end_char="694">from</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="696" end_char="698">the</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="700" end_char="709">University</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="711" end_char="712">of</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="714" end_char="719">Ottawa</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="721" end_char="722">in</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="724" end_char="729">Canada</TOKEN>
<TOKEN id="token-6-14" pos="punct" morph="none" start_char="730" end_char="730">,</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="732" end_char="734">the</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="736" end_char="745">intestines</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="747" end_char="748">of</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="750" end_char="754">stray</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="756" end_char="759">dogs</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="761" end_char="763">may</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="765" end_char="768">have</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="770" end_char="776">offered</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="778" end_char="778">a</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="780" end_char="788">conducive</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="790" end_char="800">environment</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="802" end_char="804">for</TOKEN>
<TOKEN id="token-6-27" pos="word" morph="none" start_char="806" end_char="818">coronaviruses</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="820" end_char="821">to</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="823" end_char="828">evolve</TOKEN>
<TOKEN id="token-6-30" pos="word" morph="none" start_char="830" end_char="833">into</TOKEN>
<TOKEN id="token-6-31" pos="word" morph="none" start_char="835" end_char="838">ones</TOKEN>
<TOKEN id="token-6-32" pos="word" morph="none" start_char="840" end_char="843">with</TOKEN>
<TOKEN id="token-6-33" pos="word" morph="none" start_char="845" end_char="850">better</TOKEN>
<TOKEN id="token-6-34" pos="word" morph="none" start_char="852" end_char="858">ability</TOKEN>
<TOKEN id="token-6-35" pos="word" morph="none" start_char="860" end_char="861">to</TOKEN>
<TOKEN id="token-6-36" pos="word" morph="none" start_char="863" end_char="867">evade</TOKEN>
<TOKEN id="token-6-37" pos="word" morph="none" start_char="869" end_char="875">certain</TOKEN>
<TOKEN id="token-6-38" pos="word" morph="none" start_char="877" end_char="885">mammalian</TOKEN>
<TOKEN id="token-6-39" pos="word" morph="none" start_char="887" end_char="890">host</TOKEN>
<TOKEN id="token-6-40" pos="word" morph="none" start_char="892" end_char="897">immune</TOKEN>
<TOKEN id="token-6-41" pos="word" morph="none" start_char="899" end_char="906">defences</TOKEN>
<TOKEN id="token-6-42" pos="punct" morph="none" start_char="907" end_char="907">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="910" end_char="1038">
<ORIGINAL_TEXT>Based on this, he suggested the "importance of monitoring SARS-like coronaviruses in feral dogs in the fight against SARS-CoV-2."</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="910" end_char="914">Based</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="916" end_char="917">on</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="919" end_char="922">this</TOKEN>
<TOKEN id="token-7-3" pos="punct" morph="none" start_char="923" end_char="923">,</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="925" end_char="926">he</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="928" end_char="936">suggested</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="938" end_char="940">the</TOKEN>
<TOKEN id="token-7-7" pos="punct" morph="none" start_char="942" end_char="942">"</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="943" end_char="952">importance</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="954" end_char="955">of</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="957" end_char="966">monitoring</TOKEN>
<TOKEN id="token-7-11" pos="unknown" morph="none" start_char="968" end_char="976">SARS-like</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="978" end_char="990">coronaviruses</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="992" end_char="993">in</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="995" end_char="999">feral</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="1001" end_char="1004">dogs</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="1006" end_char="1007">in</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="1009" end_char="1011">the</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="1013" end_char="1017">fight</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="1019" end_char="1025">against</TOKEN>
<TOKEN id="token-7-20" pos="unknown" morph="none" start_char="1027" end_char="1036">SARS-CoV-2</TOKEN>
<TOKEN id="token-7-21" pos="punct" morph="none" start_char="1037" end_char="1038">."</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1041" end_char="1137">
<ORIGINAL_TEXT>However, several scientists have raised concerns if such a conclusion can be made from the study.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1041" end_char="1047">However</TOKEN>
<TOKEN id="token-8-1" pos="punct" morph="none" start_char="1048" end_char="1048">,</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1050" end_char="1056">several</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1058" end_char="1067">scientists</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1069" end_char="1072">have</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1074" end_char="1079">raised</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1081" end_char="1088">concerns</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1090" end_char="1091">if</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1093" end_char="1096">such</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1098" end_char="1098">a</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1100" end_char="1109">conclusion</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1111" end_char="1113">can</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1115" end_char="1116">be</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1118" end_char="1121">made</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1123" end_char="1126">from</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1128" end_char="1130">the</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1132" end_char="1136">study</TOKEN>
<TOKEN id="token-8-17" pos="punct" morph="none" start_char="1137" end_char="1137">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1140" end_char="1165">
<ORIGINAL_TEXT>"The study is theoretical.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="punct" morph="none" start_char="1140" end_char="1140">"</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1141" end_char="1143">The</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1145" end_char="1149">study</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1151" end_char="1152">is</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1154" end_char="1164">theoretical</TOKEN>
<TOKEN id="token-9-5" pos="punct" morph="none" start_char="1165" end_char="1165">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1167" end_char="1464">
<ORIGINAL_TEXT>It does not provide a functional lab experiment proving that the virus would be less virulent if certain changes mentioned in the study are made," Subhajit Biswas, Senior Scientist of Infectious Diseases and Immunology from the CSIR-Indian Institute of Chemical Biology (IICB) in Kolkata, told PTI.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1167" end_char="1168">It</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1170" end_char="1173">does</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1175" end_char="1177">not</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1179" end_char="1185">provide</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1187" end_char="1187">a</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1189" end_char="1198">functional</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1200" end_char="1202">lab</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1204" end_char="1213">experiment</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1215" end_char="1221">proving</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1223" end_char="1226">that</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1228" end_char="1230">the</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1232" end_char="1236">virus</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1238" end_char="1242">would</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1244" end_char="1245">be</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1247" end_char="1250">less</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1252" end_char="1259">virulent</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1261" end_char="1262">if</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1264" end_char="1270">certain</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1272" end_char="1278">changes</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1280" end_char="1288">mentioned</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1290" end_char="1291">in</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1293" end_char="1295">the</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1297" end_char="1301">study</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1303" end_char="1305">are</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1307" end_char="1310">made</TOKEN>
<TOKEN id="token-10-25" pos="punct" morph="none" start_char="1311" end_char="1312">,"</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="1314" end_char="1321">Subhajit</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="1323" end_char="1328">Biswas</TOKEN>
<TOKEN id="token-10-28" pos="punct" morph="none" start_char="1329" end_char="1329">,</TOKEN>
<TOKEN id="token-10-29" pos="word" morph="none" start_char="1331" end_char="1336">Senior</TOKEN>
<TOKEN id="token-10-30" pos="word" morph="none" start_char="1338" end_char="1346">Scientist</TOKEN>
<TOKEN id="token-10-31" pos="word" morph="none" start_char="1348" end_char="1349">of</TOKEN>
<TOKEN id="token-10-32" pos="word" morph="none" start_char="1351" end_char="1360">Infectious</TOKEN>
<TOKEN id="token-10-33" pos="word" morph="none" start_char="1362" end_char="1369">Diseases</TOKEN>
<TOKEN id="token-10-34" pos="word" morph="none" start_char="1371" end_char="1373">and</TOKEN>
<TOKEN id="token-10-35" pos="word" morph="none" start_char="1375" end_char="1384">Immunology</TOKEN>
<TOKEN id="token-10-36" pos="word" morph="none" start_char="1386" end_char="1389">from</TOKEN>
<TOKEN id="token-10-37" pos="word" morph="none" start_char="1391" end_char="1393">the</TOKEN>
<TOKEN id="token-10-38" pos="unknown" morph="none" start_char="1395" end_char="1405">CSIR-Indian</TOKEN>
<TOKEN id="token-10-39" pos="word" morph="none" start_char="1407" end_char="1415">Institute</TOKEN>
<TOKEN id="token-10-40" pos="word" morph="none" start_char="1417" end_char="1418">of</TOKEN>
<TOKEN id="token-10-41" pos="word" morph="none" start_char="1420" end_char="1427">Chemical</TOKEN>
<TOKEN id="token-10-42" pos="word" morph="none" start_char="1429" end_char="1435">Biology</TOKEN>
<TOKEN id="token-10-43" pos="punct" morph="none" start_char="1437" end_char="1437">(</TOKEN>
<TOKEN id="token-10-44" pos="word" morph="none" start_char="1438" end_char="1441">IICB</TOKEN>
<TOKEN id="token-10-45" pos="punct" morph="none" start_char="1442" end_char="1442">)</TOKEN>
<TOKEN id="token-10-46" pos="word" morph="none" start_char="1444" end_char="1445">in</TOKEN>
<TOKEN id="token-10-47" pos="word" morph="none" start_char="1447" end_char="1453">Kolkata</TOKEN>
<TOKEN id="token-10-48" pos="punct" morph="none" start_char="1454" end_char="1454">,</TOKEN>
<TOKEN id="token-10-49" pos="word" morph="none" start_char="1456" end_char="1459">told</TOKEN>
<TOKEN id="token-10-50" pos="word" morph="none" start_char="1461" end_char="1463">PTI</TOKEN>
<TOKEN id="token-10-51" pos="punct" morph="none" start_char="1464" end_char="1464">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1467" end_char="1581">
<ORIGINAL_TEXT>"SARS-CoV-2 evolution in dog intestine is highly speculative at this point, it is just a prediction," Biswas added.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="punct" morph="none" start_char="1467" end_char="1467">"</TOKEN>
<TOKEN id="token-11-1" pos="unknown" morph="none" start_char="1468" end_char="1477">SARS-CoV-2</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1479" end_char="1487">evolution</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1489" end_char="1490">in</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1492" end_char="1494">dog</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1496" end_char="1504">intestine</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1506" end_char="1507">is</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1509" end_char="1514">highly</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1516" end_char="1526">speculative</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1528" end_char="1529">at</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1531" end_char="1534">this</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1536" end_char="1540">point</TOKEN>
<TOKEN id="token-11-12" pos="punct" morph="none" start_char="1541" end_char="1541">,</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1543" end_char="1544">it</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1546" end_char="1547">is</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1549" end_char="1552">just</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1554" end_char="1554">a</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1556" end_char="1565">prediction</TOKEN>
<TOKEN id="token-11-18" pos="punct" morph="none" start_char="1566" end_char="1567">,"</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="1569" end_char="1574">Biswas</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1576" end_char="1580">added</TOKEN>
<TOKEN id="token-11-21" pos="punct" morph="none" start_char="1581" end_char="1581">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1584" end_char="1727">
<ORIGINAL_TEXT>According to virologist Upasana Ray from CSIR-IICB, there is a "possibility" that dog intestines may have helped in the evolution of SARS-CoV-2.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1584" end_char="1592">According</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1594" end_char="1595">to</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1597" end_char="1606">virologist</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1608" end_char="1614">Upasana</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1616" end_char="1618">Ray</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1620" end_char="1623">from</TOKEN>
<TOKEN id="token-12-6" pos="unknown" morph="none" start_char="1625" end_char="1633">CSIR-IICB</TOKEN>
<TOKEN id="token-12-7" pos="punct" morph="none" start_char="1634" end_char="1634">,</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1636" end_char="1640">there</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1642" end_char="1643">is</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1645" end_char="1645">a</TOKEN>
<TOKEN id="token-12-11" pos="punct" morph="none" start_char="1647" end_char="1647">"</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1648" end_char="1658">possibility</TOKEN>
<TOKEN id="token-12-13" pos="punct" morph="none" start_char="1659" end_char="1659">"</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1661" end_char="1664">that</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1666" end_char="1668">dog</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1670" end_char="1679">intestines</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1681" end_char="1683">may</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1685" end_char="1688">have</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1690" end_char="1695">helped</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1697" end_char="1698">in</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1700" end_char="1702">the</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1704" end_char="1712">evolution</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="1714" end_char="1715">of</TOKEN>
<TOKEN id="token-12-24" pos="unknown" morph="none" start_char="1717" end_char="1726">SARS-CoV-2</TOKEN>
<TOKEN id="token-12-25" pos="punct" morph="none" start_char="1727" end_char="1727">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1730" end_char="1844">
<ORIGINAL_TEXT>However, she said "this is a hypothesis, and it is better not to nail it on dogs as we don't have direct evidence."</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1730" end_char="1736">However</TOKEN>
<TOKEN id="token-13-1" pos="punct" morph="none" start_char="1737" end_char="1737">,</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1739" end_char="1741">she</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1743" end_char="1746">said</TOKEN>
<TOKEN id="token-13-4" pos="punct" morph="none" start_char="1748" end_char="1748">"</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1749" end_char="1752">this</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1754" end_char="1755">is</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1757" end_char="1757">a</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1759" end_char="1768">hypothesis</TOKEN>
<TOKEN id="token-13-9" pos="punct" morph="none" start_char="1769" end_char="1769">,</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1771" end_char="1773">and</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1775" end_char="1776">it</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1778" end_char="1779">is</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1781" end_char="1786">better</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1788" end_char="1790">not</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1792" end_char="1793">to</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1795" end_char="1798">nail</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1800" end_char="1801">it</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1803" end_char="1804">on</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1806" end_char="1809">dogs</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1811" end_char="1812">as</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="1814" end_char="1815">we</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="1817" end_char="1821">don't</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="1823" end_char="1826">have</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="1828" end_char="1833">direct</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="1835" end_char="1842">evidence</TOKEN>
<TOKEN id="token-13-26" pos="punct" morph="none" start_char="1843" end_char="1844">."</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1847" end_char="2010">
<ORIGINAL_TEXT>The Federation of Indian Animal Protection Organisations (FIAPO) also expressed concern that people may take the study to mean that dogs are carriers of SARS-CoV-2.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1847" end_char="1849">The</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1851" end_char="1860">Federation</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1862" end_char="1863">of</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1865" end_char="1870">Indian</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1872" end_char="1877">Animal</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1879" end_char="1888">Protection</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1890" end_char="1902">Organisations</TOKEN>
<TOKEN id="token-14-7" pos="punct" morph="none" start_char="1904" end_char="1904">(</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1905" end_char="1909">FIAPO</TOKEN>
<TOKEN id="token-14-9" pos="punct" morph="none" start_char="1910" end_char="1910">)</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1912" end_char="1915">also</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1917" end_char="1925">expressed</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1927" end_char="1933">concern</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1935" end_char="1938">that</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="1940" end_char="1945">people</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1947" end_char="1949">may</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1951" end_char="1954">take</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="1956" end_char="1958">the</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="1960" end_char="1964">study</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="1966" end_char="1967">to</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="1969" end_char="1972">mean</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="1974" end_char="1977">that</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="1979" end_char="1982">dogs</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="1984" end_char="1986">are</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="1988" end_char="1995">carriers</TOKEN>
<TOKEN id="token-14-25" pos="word" morph="none" start_char="1997" end_char="1998">of</TOKEN>
<TOKEN id="token-14-26" pos="unknown" morph="none" start_char="2000" end_char="2009">SARS-CoV-2</TOKEN>
<TOKEN id="token-14-27" pos="punct" morph="none" start_char="2010" end_char="2010">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="2013" end_char="2116">
<ORIGINAL_TEXT>It also noted that people's attitudes towards their own pets may change due to the research conclusions.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="2013" end_char="2014">It</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="2016" end_char="2019">also</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="2021" end_char="2025">noted</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="2027" end_char="2030">that</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="2032" end_char="2039">people's</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="2041" end_char="2049">attitudes</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="2051" end_char="2057">towards</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="2059" end_char="2063">their</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="2065" end_char="2067">own</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="2069" end_char="2072">pets</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="2074" end_char="2076">may</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="2078" end_char="2083">change</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="2085" end_char="2087">due</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="2089" end_char="2090">to</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="2092" end_char="2094">the</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="2096" end_char="2103">research</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="2105" end_char="2115">conclusions</TOKEN>
<TOKEN id="token-15-17" pos="punct" morph="none" start_char="2116" end_char="2116">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="2119" end_char="2337">
<ORIGINAL_TEXT>"People may start abandoning their dogs, which will be doubly hard on the dogs especially during circumstances like these when the food to scavenge upon is really low due to the lockdown," FIAPO said in an email to PTI.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="punct" morph="none" start_char="2119" end_char="2119">"</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="2120" end_char="2125">People</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="2127" end_char="2129">may</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="2131" end_char="2135">start</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="2137" end_char="2146">abandoning</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="2148" end_char="2152">their</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="2154" end_char="2157">dogs</TOKEN>
<TOKEN id="token-16-7" pos="punct" morph="none" start_char="2158" end_char="2158">,</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="2160" end_char="2164">which</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="2166" end_char="2169">will</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="2171" end_char="2172">be</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="2174" end_char="2179">doubly</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="2181" end_char="2184">hard</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="2186" end_char="2187">on</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="2189" end_char="2191">the</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="2193" end_char="2196">dogs</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="2198" end_char="2207">especially</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="2209" end_char="2214">during</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="2216" end_char="2228">circumstances</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="2230" end_char="2233">like</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="2235" end_char="2239">these</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="2241" end_char="2244">when</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="2246" end_char="2248">the</TOKEN>
<TOKEN id="token-16-23" pos="word" morph="none" start_char="2250" end_char="2253">food</TOKEN>
<TOKEN id="token-16-24" pos="word" morph="none" start_char="2255" end_char="2256">to</TOKEN>
<TOKEN id="token-16-25" pos="word" morph="none" start_char="2258" end_char="2265">scavenge</TOKEN>
<TOKEN id="token-16-26" pos="word" morph="none" start_char="2267" end_char="2270">upon</TOKEN>
<TOKEN id="token-16-27" pos="word" morph="none" start_char="2272" end_char="2273">is</TOKEN>
<TOKEN id="token-16-28" pos="word" morph="none" start_char="2275" end_char="2280">really</TOKEN>
<TOKEN id="token-16-29" pos="word" morph="none" start_char="2282" end_char="2284">low</TOKEN>
<TOKEN id="token-16-30" pos="word" morph="none" start_char="2286" end_char="2288">due</TOKEN>
<TOKEN id="token-16-31" pos="word" morph="none" start_char="2290" end_char="2291">to</TOKEN>
<TOKEN id="token-16-32" pos="word" morph="none" start_char="2293" end_char="2295">the</TOKEN>
<TOKEN id="token-16-33" pos="word" morph="none" start_char="2297" end_char="2304">lockdown</TOKEN>
<TOKEN id="token-16-34" pos="punct" morph="none" start_char="2305" end_char="2306">,"</TOKEN>
<TOKEN id="token-16-35" pos="word" morph="none" start_char="2308" end_char="2312">FIAPO</TOKEN>
<TOKEN id="token-16-36" pos="word" morph="none" start_char="2314" end_char="2317">said</TOKEN>
<TOKEN id="token-16-37" pos="word" morph="none" start_char="2319" end_char="2320">in</TOKEN>
<TOKEN id="token-16-38" pos="word" morph="none" start_char="2322" end_char="2323">an</TOKEN>
<TOKEN id="token-16-39" pos="word" morph="none" start_char="2325" end_char="2329">email</TOKEN>
<TOKEN id="token-16-40" pos="word" morph="none" start_char="2331" end_char="2332">to</TOKEN>
<TOKEN id="token-16-41" pos="word" morph="none" start_char="2334" end_char="2336">PTI</TOKEN>
<TOKEN id="token-16-42" pos="punct" morph="none" start_char="2337" end_char="2337">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2340" end_char="2643">
<ORIGINAL_TEXT>Biswas explained that while the observation was "very interesting," the conclusions drawn in the paper can only be taken as speculation, unless an experimental animal model study is conducted in which the genetic motif described by the scientists is modulated in a virus to see if it changes infectivity.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2340" end_char="2345">Biswas</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2347" end_char="2355">explained</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2357" end_char="2360">that</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2362" end_char="2366">while</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2368" end_char="2370">the</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2372" end_char="2382">observation</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2384" end_char="2386">was</TOKEN>
<TOKEN id="token-17-7" pos="punct" morph="none" start_char="2388" end_char="2388">"</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2389" end_char="2392">very</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2394" end_char="2404">interesting</TOKEN>
<TOKEN id="token-17-10" pos="punct" morph="none" start_char="2405" end_char="2406">,"</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2408" end_char="2410">the</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2412" end_char="2422">conclusions</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2424" end_char="2428">drawn</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2430" end_char="2431">in</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2433" end_char="2435">the</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="2437" end_char="2441">paper</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="2443" end_char="2445">can</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="2447" end_char="2450">only</TOKEN>
<TOKEN id="token-17-19" pos="word" morph="none" start_char="2452" end_char="2453">be</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="2455" end_char="2459">taken</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="2461" end_char="2462">as</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="2464" end_char="2474">speculation</TOKEN>
<TOKEN id="token-17-23" pos="punct" morph="none" start_char="2475" end_char="2475">,</TOKEN>
<TOKEN id="token-17-24" pos="word" morph="none" start_char="2477" end_char="2482">unless</TOKEN>
<TOKEN id="token-17-25" pos="word" morph="none" start_char="2484" end_char="2485">an</TOKEN>
<TOKEN id="token-17-26" pos="word" morph="none" start_char="2487" end_char="2498">experimental</TOKEN>
<TOKEN id="token-17-27" pos="word" morph="none" start_char="2500" end_char="2505">animal</TOKEN>
<TOKEN id="token-17-28" pos="word" morph="none" start_char="2507" end_char="2511">model</TOKEN>
<TOKEN id="token-17-29" pos="word" morph="none" start_char="2513" end_char="2517">study</TOKEN>
<TOKEN id="token-17-30" pos="word" morph="none" start_char="2519" end_char="2520">is</TOKEN>
<TOKEN id="token-17-31" pos="word" morph="none" start_char="2522" end_char="2530">conducted</TOKEN>
<TOKEN id="token-17-32" pos="word" morph="none" start_char="2532" end_char="2533">in</TOKEN>
<TOKEN id="token-17-33" pos="word" morph="none" start_char="2535" end_char="2539">which</TOKEN>
<TOKEN id="token-17-34" pos="word" morph="none" start_char="2541" end_char="2543">the</TOKEN>
<TOKEN id="token-17-35" pos="word" morph="none" start_char="2545" end_char="2551">genetic</TOKEN>
<TOKEN id="token-17-36" pos="word" morph="none" start_char="2553" end_char="2557">motif</TOKEN>
<TOKEN id="token-17-37" pos="word" morph="none" start_char="2559" end_char="2567">described</TOKEN>
<TOKEN id="token-17-38" pos="word" morph="none" start_char="2569" end_char="2570">by</TOKEN>
<TOKEN id="token-17-39" pos="word" morph="none" start_char="2572" end_char="2574">the</TOKEN>
<TOKEN id="token-17-40" pos="word" morph="none" start_char="2576" end_char="2585">scientists</TOKEN>
<TOKEN id="token-17-41" pos="word" morph="none" start_char="2587" end_char="2588">is</TOKEN>
<TOKEN id="token-17-42" pos="word" morph="none" start_char="2590" end_char="2598">modulated</TOKEN>
<TOKEN id="token-17-43" pos="word" morph="none" start_char="2600" end_char="2601">in</TOKEN>
<TOKEN id="token-17-44" pos="word" morph="none" start_char="2603" end_char="2603">a</TOKEN>
<TOKEN id="token-17-45" pos="word" morph="none" start_char="2605" end_char="2609">virus</TOKEN>
<TOKEN id="token-17-46" pos="word" morph="none" start_char="2611" end_char="2612">to</TOKEN>
<TOKEN id="token-17-47" pos="word" morph="none" start_char="2614" end_char="2616">see</TOKEN>
<TOKEN id="token-17-48" pos="word" morph="none" start_char="2618" end_char="2619">if</TOKEN>
<TOKEN id="token-17-49" pos="word" morph="none" start_char="2621" end_char="2622">it</TOKEN>
<TOKEN id="token-17-50" pos="word" morph="none" start_char="2624" end_char="2630">changes</TOKEN>
<TOKEN id="token-17-51" pos="word" morph="none" start_char="2632" end_char="2642">infectivity</TOKEN>
<TOKEN id="token-17-52" pos="punct" morph="none" start_char="2643" end_char="2643">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2646" end_char="2941">
<ORIGINAL_TEXT>Another study, published in the journal Science earlier this month noted that dogs and other domestic animals, including livestock, even when exposed to the novel coronavirus in large quantities didn't get infected, or were not capable of transmitting it among other dogs kept in close proximity.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2646" end_char="2652">Another</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2654" end_char="2658">study</TOKEN>
<TOKEN id="token-18-2" pos="punct" morph="none" start_char="2659" end_char="2659">,</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2661" end_char="2669">published</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2671" end_char="2672">in</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2674" end_char="2676">the</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2678" end_char="2684">journal</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2686" end_char="2692">Science</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2694" end_char="2700">earlier</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="2702" end_char="2705">this</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="2707" end_char="2711">month</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="2713" end_char="2717">noted</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2719" end_char="2722">that</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="2724" end_char="2727">dogs</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="2729" end_char="2731">and</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="2733" end_char="2737">other</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="2739" end_char="2746">domestic</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="2748" end_char="2754">animals</TOKEN>
<TOKEN id="token-18-18" pos="punct" morph="none" start_char="2755" end_char="2755">,</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="2757" end_char="2765">including</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="2767" end_char="2775">livestock</TOKEN>
<TOKEN id="token-18-21" pos="punct" morph="none" start_char="2776" end_char="2776">,</TOKEN>
<TOKEN id="token-18-22" pos="word" morph="none" start_char="2778" end_char="2781">even</TOKEN>
<TOKEN id="token-18-23" pos="word" morph="none" start_char="2783" end_char="2786">when</TOKEN>
<TOKEN id="token-18-24" pos="word" morph="none" start_char="2788" end_char="2794">exposed</TOKEN>
<TOKEN id="token-18-25" pos="word" morph="none" start_char="2796" end_char="2797">to</TOKEN>
<TOKEN id="token-18-26" pos="word" morph="none" start_char="2799" end_char="2801">the</TOKEN>
<TOKEN id="token-18-27" pos="word" morph="none" start_char="2803" end_char="2807">novel</TOKEN>
<TOKEN id="token-18-28" pos="word" morph="none" start_char="2809" end_char="2819">coronavirus</TOKEN>
<TOKEN id="token-18-29" pos="word" morph="none" start_char="2821" end_char="2822">in</TOKEN>
<TOKEN id="token-18-30" pos="word" morph="none" start_char="2824" end_char="2828">large</TOKEN>
<TOKEN id="token-18-31" pos="word" morph="none" start_char="2830" end_char="2839">quantities</TOKEN>
<TOKEN id="token-18-32" pos="word" morph="none" start_char="2841" end_char="2846">didn't</TOKEN>
<TOKEN id="token-18-33" pos="word" morph="none" start_char="2848" end_char="2850">get</TOKEN>
<TOKEN id="token-18-34" pos="word" morph="none" start_char="2852" end_char="2859">infected</TOKEN>
<TOKEN id="token-18-35" pos="punct" morph="none" start_char="2860" end_char="2860">,</TOKEN>
<TOKEN id="token-18-36" pos="word" morph="none" start_char="2862" end_char="2863">or</TOKEN>
<TOKEN id="token-18-37" pos="word" morph="none" start_char="2865" end_char="2868">were</TOKEN>
<TOKEN id="token-18-38" pos="word" morph="none" start_char="2870" end_char="2872">not</TOKEN>
<TOKEN id="token-18-39" pos="word" morph="none" start_char="2874" end_char="2880">capable</TOKEN>
<TOKEN id="token-18-40" pos="word" morph="none" start_char="2882" end_char="2883">of</TOKEN>
<TOKEN id="token-18-41" pos="word" morph="none" start_char="2885" end_char="2896">transmitting</TOKEN>
<TOKEN id="token-18-42" pos="word" morph="none" start_char="2898" end_char="2899">it</TOKEN>
<TOKEN id="token-18-43" pos="word" morph="none" start_char="2901" end_char="2905">among</TOKEN>
<TOKEN id="token-18-44" pos="word" morph="none" start_char="2907" end_char="2911">other</TOKEN>
<TOKEN id="token-18-45" pos="word" morph="none" start_char="2913" end_char="2916">dogs</TOKEN>
<TOKEN id="token-18-46" pos="word" morph="none" start_char="2918" end_char="2921">kept</TOKEN>
<TOKEN id="token-18-47" pos="word" morph="none" start_char="2923" end_char="2924">in</TOKEN>
<TOKEN id="token-18-48" pos="word" morph="none" start_char="2926" end_char="2930">close</TOKEN>
<TOKEN id="token-18-49" pos="word" morph="none" start_char="2932" end_char="2940">proximity</TOKEN>
<TOKEN id="token-18-50" pos="punct" morph="none" start_char="2941" end_char="2941">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2944" end_char="3093">
<ORIGINAL_TEXT>They found similar results in other animals such as pigs, chickens, and ducks, while cats were susceptible and transmitted the virus among other cats.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2944" end_char="2947">They</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2949" end_char="2953">found</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2955" end_char="2961">similar</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2963" end_char="2969">results</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2971" end_char="2972">in</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2974" end_char="2978">other</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2980" end_char="2986">animals</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2988" end_char="2991">such</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2993" end_char="2994">as</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="2996" end_char="2999">pigs</TOKEN>
<TOKEN id="token-19-10" pos="punct" morph="none" start_char="3000" end_char="3000">,</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="3002" end_char="3009">chickens</TOKEN>
<TOKEN id="token-19-12" pos="punct" morph="none" start_char="3010" end_char="3010">,</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="3012" end_char="3014">and</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="3016" end_char="3020">ducks</TOKEN>
<TOKEN id="token-19-15" pos="punct" morph="none" start_char="3021" end_char="3021">,</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="3023" end_char="3027">while</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="3029" end_char="3032">cats</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="3034" end_char="3037">were</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="3039" end_char="3049">susceptible</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="3051" end_char="3053">and</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="3055" end_char="3065">transmitted</TOKEN>
<TOKEN id="token-19-22" pos="word" morph="none" start_char="3067" end_char="3069">the</TOKEN>
<TOKEN id="token-19-23" pos="word" morph="none" start_char="3071" end_char="3075">virus</TOKEN>
<TOKEN id="token-19-24" pos="word" morph="none" start_char="3077" end_char="3081">among</TOKEN>
<TOKEN id="token-19-25" pos="word" morph="none" start_char="3083" end_char="3087">other</TOKEN>
<TOKEN id="token-19-26" pos="word" morph="none" start_char="3089" end_char="3092">cats</TOKEN>
<TOKEN id="token-19-27" pos="punct" morph="none" start_char="3093" end_char="3093">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="3096" end_char="3217">
<ORIGINAL_TEXT>However, the scientists also cautioned that there is no evidence to conclude that cats could transmit the virus to humans.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="3096" end_char="3102">However</TOKEN>
<TOKEN id="token-20-1" pos="punct" morph="none" start_char="3103" end_char="3103">,</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="3105" end_char="3107">the</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="3109" end_char="3118">scientists</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="3120" end_char="3123">also</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="3125" end_char="3133">cautioned</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="3135" end_char="3138">that</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="3140" end_char="3144">there</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="3146" end_char="3147">is</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="3149" end_char="3150">no</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="3152" end_char="3159">evidence</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="3161" end_char="3162">to</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="3164" end_char="3171">conclude</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="3173" end_char="3176">that</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="3178" end_char="3181">cats</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="3183" end_char="3187">could</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="3189" end_char="3196">transmit</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="3198" end_char="3200">the</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="3202" end_char="3206">virus</TOKEN>
<TOKEN id="token-20-19" pos="word" morph="none" start_char="3208" end_char="3209">to</TOKEN>
<TOKEN id="token-20-20" pos="word" morph="none" start_char="3211" end_char="3216">humans</TOKEN>
<TOKEN id="token-20-21" pos="punct" morph="none" start_char="3217" end_char="3217">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="3220" end_char="3480">
<ORIGINAL_TEXT>"We found that SARS-CoV-2 replicates poorly in dogs, pigs, chickens, and ducks, but ferrets and cats are permissive to infection," the scientists, including those from the National Institute for Viral Disease Control and Prevention in China, wrote in the study.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="punct" morph="none" start_char="3220" end_char="3220">"</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="3221" end_char="3222">We</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="3224" end_char="3228">found</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="3230" end_char="3233">that</TOKEN>
<TOKEN id="token-21-4" pos="unknown" morph="none" start_char="3235" end_char="3244">SARS-CoV-2</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="3246" end_char="3255">replicates</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="3257" end_char="3262">poorly</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="3264" end_char="3265">in</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="3267" end_char="3270">dogs</TOKEN>
<TOKEN id="token-21-9" pos="punct" morph="none" start_char="3271" end_char="3271">,</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="3273" end_char="3276">pigs</TOKEN>
<TOKEN id="token-21-11" pos="punct" morph="none" start_char="3277" end_char="3277">,</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="3279" end_char="3286">chickens</TOKEN>
<TOKEN id="token-21-13" pos="punct" morph="none" start_char="3287" end_char="3287">,</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="3289" end_char="3291">and</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="3293" end_char="3297">ducks</TOKEN>
<TOKEN id="token-21-16" pos="punct" morph="none" start_char="3298" end_char="3298">,</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="3300" end_char="3302">but</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="3304" end_char="3310">ferrets</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="3312" end_char="3314">and</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="3316" end_char="3319">cats</TOKEN>
<TOKEN id="token-21-21" pos="word" morph="none" start_char="3321" end_char="3323">are</TOKEN>
<TOKEN id="token-21-22" pos="word" morph="none" start_char="3325" end_char="3334">permissive</TOKEN>
<TOKEN id="token-21-23" pos="word" morph="none" start_char="3336" end_char="3337">to</TOKEN>
<TOKEN id="token-21-24" pos="word" morph="none" start_char="3339" end_char="3347">infection</TOKEN>
<TOKEN id="token-21-25" pos="punct" morph="none" start_char="3348" end_char="3349">,"</TOKEN>
<TOKEN id="token-21-26" pos="word" morph="none" start_char="3351" end_char="3353">the</TOKEN>
<TOKEN id="token-21-27" pos="word" morph="none" start_char="3355" end_char="3364">scientists</TOKEN>
<TOKEN id="token-21-28" pos="punct" morph="none" start_char="3365" end_char="3365">,</TOKEN>
<TOKEN id="token-21-29" pos="word" morph="none" start_char="3367" end_char="3375">including</TOKEN>
<TOKEN id="token-21-30" pos="word" morph="none" start_char="3377" end_char="3381">those</TOKEN>
<TOKEN id="token-21-31" pos="word" morph="none" start_char="3383" end_char="3386">from</TOKEN>
<TOKEN id="token-21-32" pos="word" morph="none" start_char="3388" end_char="3390">the</TOKEN>
<TOKEN id="token-21-33" pos="word" morph="none" start_char="3392" end_char="3399">National</TOKEN>
<TOKEN id="token-21-34" pos="word" morph="none" start_char="3401" end_char="3409">Institute</TOKEN>
<TOKEN id="token-21-35" pos="word" morph="none" start_char="3411" end_char="3413">for</TOKEN>
<TOKEN id="token-21-36" pos="word" morph="none" start_char="3415" end_char="3419">Viral</TOKEN>
<TOKEN id="token-21-37" pos="word" morph="none" start_char="3421" end_char="3427">Disease</TOKEN>
<TOKEN id="token-21-38" pos="word" morph="none" start_char="3429" end_char="3435">Control</TOKEN>
<TOKEN id="token-21-39" pos="word" morph="none" start_char="3437" end_char="3439">and</TOKEN>
<TOKEN id="token-21-40" pos="word" morph="none" start_char="3441" end_char="3450">Prevention</TOKEN>
<TOKEN id="token-21-41" pos="word" morph="none" start_char="3452" end_char="3453">in</TOKEN>
<TOKEN id="token-21-42" pos="word" morph="none" start_char="3455" end_char="3459">China</TOKEN>
<TOKEN id="token-21-43" pos="punct" morph="none" start_char="3460" end_char="3460">,</TOKEN>
<TOKEN id="token-21-44" pos="word" morph="none" start_char="3462" end_char="3466">wrote</TOKEN>
<TOKEN id="token-21-45" pos="word" morph="none" start_char="3468" end_char="3469">in</TOKEN>
<TOKEN id="token-21-46" pos="word" morph="none" start_char="3471" end_char="3473">the</TOKEN>
<TOKEN id="token-21-47" pos="word" morph="none" start_char="3475" end_char="3479">study</TOKEN>
<TOKEN id="token-21-48" pos="punct" morph="none" start_char="3480" end_char="3480">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
