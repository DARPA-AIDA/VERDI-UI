<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CAAI" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="15701" raw_text_md5="5a7ac8a76107e8f9b3d202f1183ae3c7">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="146">
<ORIGINAL_TEXT>Now Chinese scientists claim coronavirus originated in INDIA in summer 2019 amid heatwave 'that forced humans and animals to drink the same water'</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="3">Now</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="5" end_char="11">Chinese</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="13" end_char="22">scientists</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="24" end_char="28">claim</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="30" end_char="40">coronavirus</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="42" end_char="51">originated</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="53" end_char="54">in</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="56" end_char="60">INDIA</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="62" end_char="63">in</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="65" end_char="70">summer</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="72" end_char="75">2019</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="77" end_char="80">amid</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="82" end_char="89">heatwave</TOKEN>
<TOKEN id="token-0-13" pos="punct" morph="none" start_char="91" end_char="91">'</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="92" end_char="95">that</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="97" end_char="102">forced</TOKEN>
<TOKEN id="token-0-16" pos="word" morph="none" start_char="104" end_char="109">humans</TOKEN>
<TOKEN id="token-0-17" pos="word" morph="none" start_char="111" end_char="113">and</TOKEN>
<TOKEN id="token-0-18" pos="word" morph="none" start_char="115" end_char="121">animals</TOKEN>
<TOKEN id="token-0-19" pos="word" morph="none" start_char="123" end_char="124">to</TOKEN>
<TOKEN id="token-0-20" pos="word" morph="none" start_char="126" end_char="130">drink</TOKEN>
<TOKEN id="token-0-21" pos="word" morph="none" start_char="132" end_char="134">the</TOKEN>
<TOKEN id="token-0-22" pos="word" morph="none" start_char="136" end_char="139">same</TOKEN>
<TOKEN id="token-0-23" pos="word" morph="none" start_char="141" end_char="145">water</TOKEN>
<TOKEN id="token-0-24" pos="punct" morph="none" start_char="146" end_char="146">'</TOKEN>
</SEG>
<SEG id="segment-1" start_char="150" end_char="307">
<ORIGINAL_TEXT>Chinese researchers have claimed that coronavirus originated in India, in the latest attempt by academics to pin blame for the pandemic outside their borders.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="150" end_char="156">Chinese</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="158" end_char="168">researchers</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="170" end_char="173">have</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="175" end_char="181">claimed</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="183" end_char="186">that</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="188" end_char="198">coronavirus</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="200" end_char="209">originated</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="211" end_char="212">in</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="214" end_char="218">India</TOKEN>
<TOKEN id="token-1-9" pos="punct" morph="none" start_char="219" end_char="219">,</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="221" end_char="222">in</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="224" end_char="226">the</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="228" end_char="233">latest</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="235" end_char="241">attempt</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="243" end_char="244">by</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="246" end_char="254">academics</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="256" end_char="257">to</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="259" end_char="261">pin</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="263" end_char="267">blame</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="269" end_char="271">for</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="273" end_char="275">the</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="277" end_char="284">pandemic</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="286" end_char="292">outside</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="294" end_char="298">their</TOKEN>
<TOKEN id="token-1-24" pos="word" morph="none" start_char="300" end_char="306">borders</TOKEN>
<TOKEN id="token-1-25" pos="punct" morph="none" start_char="307" end_char="307">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="310" end_char="536">
<ORIGINAL_TEXT>A team from the Chinese Academy of Sciences argues the virus likely originated in India in summer 2019 - jumping from animals to humans via contaminated water - before travelling unnoticed to Wuhan, where it was first detected.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="310" end_char="310">A</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="312" end_char="315">team</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="317" end_char="320">from</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="322" end_char="324">the</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="326" end_char="332">Chinese</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="334" end_char="340">Academy</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="342" end_char="343">of</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="345" end_char="352">Sciences</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="354" end_char="359">argues</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="361" end_char="363">the</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="365" end_char="369">virus</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="371" end_char="376">likely</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="378" end_char="387">originated</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="389" end_char="390">in</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="392" end_char="396">India</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="398" end_char="399">in</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="401" end_char="406">summer</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="408" end_char="411">2019</TOKEN>
<TOKEN id="token-2-18" pos="punct" morph="none" start_char="413" end_char="413">-</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="415" end_char="421">jumping</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="423" end_char="426">from</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="428" end_char="434">animals</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="436" end_char="437">to</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="439" end_char="444">humans</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="446" end_char="448">via</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="450" end_char="461">contaminated</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="463" end_char="467">water</TOKEN>
<TOKEN id="token-2-27" pos="punct" morph="none" start_char="469" end_char="469">-</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="471" end_char="476">before</TOKEN>
<TOKEN id="token-2-29" pos="word" morph="none" start_char="478" end_char="487">travelling</TOKEN>
<TOKEN id="token-2-30" pos="word" morph="none" start_char="489" end_char="497">unnoticed</TOKEN>
<TOKEN id="token-2-31" pos="word" morph="none" start_char="499" end_char="500">to</TOKEN>
<TOKEN id="token-2-32" pos="word" morph="none" start_char="502" end_char="506">Wuhan</TOKEN>
<TOKEN id="token-2-33" pos="punct" morph="none" start_char="507" end_char="507">,</TOKEN>
<TOKEN id="token-2-34" pos="word" morph="none" start_char="509" end_char="513">where</TOKEN>
<TOKEN id="token-2-35" pos="word" morph="none" start_char="515" end_char="516">it</TOKEN>
<TOKEN id="token-2-36" pos="word" morph="none" start_char="518" end_char="520">was</TOKEN>
<TOKEN id="token-2-37" pos="word" morph="none" start_char="522" end_char="526">first</TOKEN>
<TOKEN id="token-2-38" pos="word" morph="none" start_char="528" end_char="535">detected</TOKEN>
<TOKEN id="token-2-39" pos="punct" morph="none" start_char="536" end_char="536">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="539" end_char="694">
<ORIGINAL_TEXT>But David Robertson, and expert from Glasgow University, called the paper 'very flawed' and concluded 'it adds nothing to our understanding of coronavirus'.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="539" end_char="541">But</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="543" end_char="547">David</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="549" end_char="557">Robertson</TOKEN>
<TOKEN id="token-3-3" pos="punct" morph="none" start_char="558" end_char="558">,</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="560" end_char="562">and</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="564" end_char="569">expert</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="571" end_char="574">from</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="576" end_char="582">Glasgow</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="584" end_char="593">University</TOKEN>
<TOKEN id="token-3-9" pos="punct" morph="none" start_char="594" end_char="594">,</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="596" end_char="601">called</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="603" end_char="605">the</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="607" end_char="611">paper</TOKEN>
<TOKEN id="token-3-13" pos="punct" morph="none" start_char="613" end_char="613">'</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="614" end_char="617">very</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="619" end_char="624">flawed</TOKEN>
<TOKEN id="token-3-16" pos="punct" morph="none" start_char="625" end_char="625">'</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="627" end_char="629">and</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="631" end_char="639">concluded</TOKEN>
<TOKEN id="token-3-19" pos="punct" morph="none" start_char="641" end_char="641">'</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="642" end_char="643">it</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="645" end_char="648">adds</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="650" end_char="656">nothing</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="658" end_char="659">to</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="661" end_char="663">our</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="665" end_char="677">understanding</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="679" end_char="680">of</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="682" end_char="692">coronavirus</TOKEN>
<TOKEN id="token-3-28" pos="punct" morph="none" start_char="693" end_char="694">'.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="697" end_char="900">
<ORIGINAL_TEXT>It is not the first time that Chinese authorities have pointed the finger of blame elsewhere - suggesting, largely without evidence, that both Italy and the US could be the site of the original infection.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="697" end_char="698">It</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="700" end_char="701">is</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="703" end_char="705">not</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="707" end_char="709">the</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="711" end_char="715">first</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="717" end_char="720">time</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="722" end_char="725">that</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="727" end_char="733">Chinese</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="735" end_char="745">authorities</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="747" end_char="750">have</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="752" end_char="758">pointed</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="760" end_char="762">the</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="764" end_char="769">finger</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="771" end_char="772">of</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="774" end_char="778">blame</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="780" end_char="788">elsewhere</TOKEN>
<TOKEN id="token-4-16" pos="punct" morph="none" start_char="790" end_char="790">-</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="792" end_char="801">suggesting</TOKEN>
<TOKEN id="token-4-18" pos="punct" morph="none" start_char="802" end_char="802">,</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="804" end_char="810">largely</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="812" end_char="818">without</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="820" end_char="827">evidence</TOKEN>
<TOKEN id="token-4-22" pos="punct" morph="none" start_char="828" end_char="828">,</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="830" end_char="833">that</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="835" end_char="838">both</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="840" end_char="844">Italy</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="846" end_char="848">and</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="850" end_char="852">the</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="854" end_char="855">US</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="857" end_char="861">could</TOKEN>
<TOKEN id="token-4-30" pos="word" morph="none" start_char="863" end_char="864">be</TOKEN>
<TOKEN id="token-4-31" pos="word" morph="none" start_char="866" end_char="868">the</TOKEN>
<TOKEN id="token-4-32" pos="word" morph="none" start_char="870" end_char="873">site</TOKEN>
<TOKEN id="token-4-33" pos="word" morph="none" start_char="875" end_char="876">of</TOKEN>
<TOKEN id="token-4-34" pos="word" morph="none" start_char="878" end_char="880">the</TOKEN>
<TOKEN id="token-4-35" pos="word" morph="none" start_char="882" end_char="889">original</TOKEN>
<TOKEN id="token-4-36" pos="word" morph="none" start_char="891" end_char="899">infection</TOKEN>
<TOKEN id="token-4-37" pos="punct" morph="none" start_char="900" end_char="900">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="903" end_char="1048">
<ORIGINAL_TEXT>And it comes against a backdrop of increased political tensions between India and China, with troops attacking each-other along a disputed border.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="903" end_char="905">And</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="907" end_char="908">it</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="910" end_char="914">comes</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="916" end_char="922">against</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="924" end_char="924">a</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="926" end_char="933">backdrop</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="935" end_char="936">of</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="938" end_char="946">increased</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="948" end_char="956">political</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="958" end_char="965">tensions</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="967" end_char="973">between</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="975" end_char="979">India</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="981" end_char="983">and</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="985" end_char="989">China</TOKEN>
<TOKEN id="token-5-14" pos="punct" morph="none" start_char="990" end_char="990">,</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="992" end_char="995">with</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="997" end_char="1002">troops</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="1004" end_char="1012">attacking</TOKEN>
<TOKEN id="token-5-18" pos="unknown" morph="none" start_char="1014" end_char="1023">each-other</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="1025" end_char="1029">along</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="1031" end_char="1031">a</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="1033" end_char="1040">disputed</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="1042" end_char="1047">border</TOKEN>
<TOKEN id="token-5-23" pos="punct" morph="none" start_char="1048" end_char="1048">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="1053" end_char="1197">
<ORIGINAL_TEXT>The WHO is currently looking for the source of coronavirus in China, while the body of scientific evidence suggests the disease originated there.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="1053" end_char="1055">The</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="1057" end_char="1059">WHO</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="1061" end_char="1062">is</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="1064" end_char="1072">currently</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="1074" end_char="1080">looking</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="1082" end_char="1084">for</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="1086" end_char="1088">the</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="1090" end_char="1095">source</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="1097" end_char="1098">of</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="1100" end_char="1110">coronavirus</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="1112" end_char="1113">in</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="1115" end_char="1119">China</TOKEN>
<TOKEN id="token-6-12" pos="punct" morph="none" start_char="1120" end_char="1120">,</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="1122" end_char="1126">while</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="1128" end_char="1130">the</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="1132" end_char="1135">body</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="1137" end_char="1138">of</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="1140" end_char="1149">scientific</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="1151" end_char="1158">evidence</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="1160" end_char="1167">suggests</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="1169" end_char="1171">the</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="1173" end_char="1179">disease</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="1181" end_char="1190">originated</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="1192" end_char="1196">there</TOKEN>
<TOKEN id="token-6-24" pos="punct" morph="none" start_char="1197" end_char="1197">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="1200" end_char="1337">
<ORIGINAL_TEXT>In their paper, the Chinese team use phylogenetic analysis - a study of how a virus mutates - to attempt to trace the origins of Covid-19.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="1200" end_char="1201">In</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="1203" end_char="1207">their</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="1209" end_char="1213">paper</TOKEN>
<TOKEN id="token-7-3" pos="punct" morph="none" start_char="1214" end_char="1214">,</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="1216" end_char="1218">the</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="1220" end_char="1226">Chinese</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="1228" end_char="1231">team</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="1233" end_char="1235">use</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="1237" end_char="1248">phylogenetic</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="1250" end_char="1257">analysis</TOKEN>
<TOKEN id="token-7-10" pos="punct" morph="none" start_char="1259" end_char="1259">-</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="1261" end_char="1261">a</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="1263" end_char="1267">study</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="1269" end_char="1270">of</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="1272" end_char="1274">how</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="1276" end_char="1276">a</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="1278" end_char="1282">virus</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="1284" end_char="1290">mutates</TOKEN>
<TOKEN id="token-7-18" pos="punct" morph="none" start_char="1292" end_char="1292">-</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="1294" end_char="1295">to</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="1297" end_char="1303">attempt</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="1305" end_char="1306">to</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="1308" end_char="1312">trace</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="1314" end_char="1316">the</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="1318" end_char="1324">origins</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="1326" end_char="1327">of</TOKEN>
<TOKEN id="token-7-26" pos="unknown" morph="none" start_char="1329" end_char="1336">Covid-19</TOKEN>
<TOKEN id="token-7-27" pos="punct" morph="none" start_char="1337" end_char="1337">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1340" end_char="1466">
<ORIGINAL_TEXT>Viruses, like all cells, mutate as they reproduce, meaning tiny changes occur in their DNA each time they replicate themselves.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1340" end_char="1346">Viruses</TOKEN>
<TOKEN id="token-8-1" pos="punct" morph="none" start_char="1347" end_char="1347">,</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1349" end_char="1352">like</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1354" end_char="1356">all</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1358" end_char="1362">cells</TOKEN>
<TOKEN id="token-8-5" pos="punct" morph="none" start_char="1363" end_char="1363">,</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1365" end_char="1370">mutate</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1372" end_char="1373">as</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1375" end_char="1378">they</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1380" end_char="1388">reproduce</TOKEN>
<TOKEN id="token-8-10" pos="punct" morph="none" start_char="1389" end_char="1389">,</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1391" end_char="1397">meaning</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1399" end_char="1402">tiny</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1404" end_char="1410">changes</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1412" end_char="1416">occur</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1418" end_char="1419">in</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1421" end_char="1425">their</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1427" end_char="1429">DNA</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1431" end_char="1434">each</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1436" end_char="1439">time</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="1441" end_char="1444">they</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="1446" end_char="1454">replicate</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="1456" end_char="1465">themselves</TOKEN>
<TOKEN id="token-8-23" pos="punct" morph="none" start_char="1466" end_char="1466">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1469" end_char="1513">
<ORIGINAL_TEXT>China's official timeline vs The new evidence</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1469" end_char="1475">China's</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1477" end_char="1484">official</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1486" end_char="1493">timeline</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1495" end_char="1496">vs</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1498" end_char="1500">The</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1502" end_char="1504">new</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1506" end_char="1513">evidence</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1517" end_char="1533">
<ORIGINAL_TEXT>Official timeline</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1517" end_char="1524">Official</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1526" end_char="1533">timeline</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1536" end_char="1597">
<ORIGINAL_TEXT>Dec 8 - Earliest date that China has acknowledged an infection</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1536" end_char="1538">Dec</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1540" end_char="1540">8</TOKEN>
<TOKEN id="token-11-2" pos="punct" morph="none" start_char="1542" end_char="1542">-</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1544" end_char="1551">Earliest</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1553" end_char="1556">date</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1558" end_char="1561">that</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1563" end_char="1567">China</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1569" end_char="1571">has</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1573" end_char="1584">acknowledged</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1586" end_char="1587">an</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1589" end_char="1597">infection</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1600" end_char="1690">
<ORIGINAL_TEXT>Dec 31 - China first reported 'pneumonia of unknown cause' to the World Health Organisation</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1600" end_char="1602">Dec</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1604" end_char="1605">31</TOKEN>
<TOKEN id="token-12-2" pos="punct" morph="none" start_char="1607" end_char="1607">-</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1609" end_char="1613">China</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1615" end_char="1619">first</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1621" end_char="1628">reported</TOKEN>
<TOKEN id="token-12-6" pos="punct" morph="none" start_char="1630" end_char="1630">'</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1631" end_char="1639">pneumonia</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1641" end_char="1642">of</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1644" end_char="1650">unknown</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1652" end_char="1656">cause</TOKEN>
<TOKEN id="token-12-11" pos="punct" morph="none" start_char="1657" end_char="1657">'</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1659" end_char="1660">to</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1662" end_char="1664">the</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1666" end_char="1670">World</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1672" end_char="1677">Health</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1679" end_char="1690">Organisation</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1693" end_char="1744">
<ORIGINAL_TEXT>Jan 1 - Wuhan seafood market closed for disinfection</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1693" end_char="1695">Jan</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1697" end_char="1697">1</TOKEN>
<TOKEN id="token-13-2" pos="punct" morph="none" start_char="1699" end_char="1699">-</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1701" end_char="1705">Wuhan</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1707" end_char="1713">seafood</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1715" end_char="1720">market</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1722" end_char="1727">closed</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1729" end_char="1731">for</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1733" end_char="1744">disinfection</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1747" end_char="1785">
<ORIGINAL_TEXT>Jan 11 - China reported its first death</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1747" end_char="1749">Jan</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1751" end_char="1752">11</TOKEN>
<TOKEN id="token-14-2" pos="punct" morph="none" start_char="1754" end_char="1754">-</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1756" end_char="1760">China</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1762" end_char="1769">reported</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1771" end_char="1773">its</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1775" end_char="1779">first</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1781" end_char="1785">death</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1788" end_char="1813">
<ORIGINAL_TEXT>Jan 23 - Wuhan locked down</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1788" end_char="1790">Jan</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1792" end_char="1793">23</TOKEN>
<TOKEN id="token-15-2" pos="punct" morph="none" start_char="1795" end_char="1795">-</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1797" end_char="1801">Wuhan</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1803" end_char="1808">locked</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1810" end_char="1813">down</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1816" end_char="1916">
<ORIGINAL_TEXT>Jan 31 - WHO declared 'outbreak of international concern' as China admitted having thousands of cases</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1816" end_char="1818">Jan</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1820" end_char="1821">31</TOKEN>
<TOKEN id="token-16-2" pos="punct" morph="none" start_char="1823" end_char="1823">-</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1825" end_char="1827">WHO</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1829" end_char="1836">declared</TOKEN>
<TOKEN id="token-16-5" pos="punct" morph="none" start_char="1838" end_char="1838">'</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1839" end_char="1846">outbreak</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1848" end_char="1849">of</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1851" end_char="1863">international</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="1865" end_char="1871">concern</TOKEN>
<TOKEN id="token-16-10" pos="punct" morph="none" start_char="1872" end_char="1872">'</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="1874" end_char="1875">as</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="1877" end_char="1881">China</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="1883" end_char="1890">admitted</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="1892" end_char="1897">having</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="1899" end_char="1907">thousands</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="1909" end_char="1910">of</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="1912" end_char="1916">cases</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1919" end_char="2017">
<ORIGINAL_TEXT>Feb 23 - Italy reports cluster of cases in first major outbreak not linked to travellers from China</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1919" end_char="1921">Feb</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1923" end_char="1924">23</TOKEN>
<TOKEN id="token-17-2" pos="punct" morph="none" start_char="1926" end_char="1926">-</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="1928" end_char="1932">Italy</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="1934" end_char="1940">reports</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="1942" end_char="1948">cluster</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="1950" end_char="1951">of</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="1953" end_char="1957">cases</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="1959" end_char="1960">in</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="1962" end_char="1966">first</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="1968" end_char="1972">major</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="1974" end_char="1981">outbreak</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="1983" end_char="1985">not</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="1987" end_char="1992">linked</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="1994" end_char="1995">to</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="1997" end_char="2006">travellers</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="2008" end_char="2011">from</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="2013" end_char="2017">China</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2020" end_char="2031">
<ORIGINAL_TEXT>New evidence</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2020" end_char="2022">New</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2024" end_char="2031">evidence</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2034" end_char="2101">
<ORIGINAL_TEXT>Sep - Blood samples taken in Milan found to contain Covid antibodies</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2034" end_char="2036">Sep</TOKEN>
<TOKEN id="token-19-1" pos="punct" morph="none" start_char="2038" end_char="2038">-</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2040" end_char="2044">Blood</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2046" end_char="2052">samples</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2054" end_char="2058">taken</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2060" end_char="2061">in</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2063" end_char="2067">Milan</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2069" end_char="2073">found</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2075" end_char="2076">to</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="2078" end_char="2084">contain</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="2086" end_char="2090">Covid</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="2092" end_char="2101">antibodies</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2104" end_char="2210">
<ORIGINAL_TEXT>Oct-Dec - Hundreds of 'pneumonia' cases near Milan may be linked to virus, and scientists are investigating</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="unknown" morph="none" start_char="2104" end_char="2110">Oct-Dec</TOKEN>
<TOKEN id="token-20-1" pos="punct" morph="none" start_char="2112" end_char="2112">-</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2114" end_char="2121">Hundreds</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2123" end_char="2124">of</TOKEN>
<TOKEN id="token-20-4" pos="punct" morph="none" start_char="2126" end_char="2126">'</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2127" end_char="2135">pneumonia</TOKEN>
<TOKEN id="token-20-6" pos="punct" morph="none" start_char="2136" end_char="2136">'</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2138" end_char="2142">cases</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="2144" end_char="2147">near</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2149" end_char="2153">Milan</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2155" end_char="2157">may</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="2159" end_char="2160">be</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="2162" end_char="2167">linked</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="2169" end_char="2170">to</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="2172" end_char="2176">virus</TOKEN>
<TOKEN id="token-20-15" pos="punct" morph="none" start_char="2177" end_char="2177">,</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="2179" end_char="2181">and</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="2183" end_char="2192">scientists</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="2194" end_char="2196">are</TOKEN>
<TOKEN id="token-20-19" pos="word" morph="none" start_char="2198" end_char="2210">investigating</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2213" end_char="2317">
<ORIGINAL_TEXT>Nov - Sewage samples taken in Florianópolis, Brazil, suggest virus was present and are being investigated</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2213" end_char="2215">Nov</TOKEN>
<TOKEN id="token-21-1" pos="punct" morph="none" start_char="2217" end_char="2217">-</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2219" end_char="2224">Sewage</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2226" end_char="2232">samples</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2234" end_char="2238">taken</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="2240" end_char="2241">in</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2243" end_char="2255">Florianópolis</TOKEN>
<TOKEN id="token-21-7" pos="punct" morph="none" start_char="2256" end_char="2256">,</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="2258" end_char="2263">Brazil</TOKEN>
<TOKEN id="token-21-9" pos="punct" morph="none" start_char="2264" end_char="2264">,</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="2266" end_char="2272">suggest</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="2274" end_char="2278">virus</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="2280" end_char="2282">was</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="2284" end_char="2290">present</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="2292" end_char="2294">and</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="2296" end_char="2298">are</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="2300" end_char="2304">being</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="2306" end_char="2317">investigated</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2320" end_char="2388">
<ORIGINAL_TEXT>Nov 17 - Leaked documents suggest case detected in China on this date</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2320" end_char="2322">Nov</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2324" end_char="2325">17</TOKEN>
<TOKEN id="token-22-2" pos="punct" morph="none" start_char="2327" end_char="2327">-</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2329" end_char="2334">Leaked</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2336" end_char="2344">documents</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2346" end_char="2352">suggest</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2354" end_char="2357">case</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2359" end_char="2366">detected</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="2368" end_char="2369">in</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="2371" end_char="2375">China</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="2377" end_char="2378">on</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="2380" end_char="2383">this</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="2385" end_char="2388">date</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2391" end_char="2520">
<ORIGINAL_TEXT>Dec 1 - Chinese researchers report an infection on this date in a peer-reviewed study, but it has not been acknowledged by Beijing</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2391" end_char="2393">Dec</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2395" end_char="2395">1</TOKEN>
<TOKEN id="token-23-2" pos="punct" morph="none" start_char="2397" end_char="2397">-</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2399" end_char="2405">Chinese</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="2407" end_char="2417">researchers</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="2419" end_char="2424">report</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="2426" end_char="2427">an</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="2429" end_char="2437">infection</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="2439" end_char="2440">on</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="2442" end_char="2445">this</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="2447" end_char="2450">date</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="2452" end_char="2453">in</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="2455" end_char="2455">a</TOKEN>
<TOKEN id="token-23-13" pos="unknown" morph="none" start_char="2457" end_char="2469">peer-reviewed</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="2471" end_char="2475">study</TOKEN>
<TOKEN id="token-23-15" pos="punct" morph="none" start_char="2476" end_char="2476">,</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="2478" end_char="2480">but</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="2482" end_char="2483">it</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="2485" end_char="2487">has</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="2489" end_char="2491">not</TOKEN>
<TOKEN id="token-23-20" pos="word" morph="none" start_char="2493" end_char="2496">been</TOKEN>
<TOKEN id="token-23-21" pos="word" morph="none" start_char="2498" end_char="2509">acknowledged</TOKEN>
<TOKEN id="token-23-22" pos="word" morph="none" start_char="2511" end_char="2512">by</TOKEN>
<TOKEN id="token-23-23" pos="word" morph="none" start_char="2514" end_char="2520">Beijing</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2523" end_char="2614">
<ORIGINAL_TEXT>Dec 18 - Sewage samples taken in Milan and Turin suggest virus was circulating in the cities</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="2523" end_char="2525">Dec</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="2527" end_char="2528">18</TOKEN>
<TOKEN id="token-24-2" pos="punct" morph="none" start_char="2530" end_char="2530">-</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="2532" end_char="2537">Sewage</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="2539" end_char="2545">samples</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="2547" end_char="2551">taken</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="2553" end_char="2554">in</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="2556" end_char="2560">Milan</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="2562" end_char="2564">and</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="2566" end_char="2570">Turin</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="2572" end_char="2578">suggest</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="2580" end_char="2584">virus</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="2586" end_char="2588">was</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="2590" end_char="2600">circulating</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="2602" end_char="2603">in</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="2605" end_char="2607">the</TOKEN>
<TOKEN id="token-24-16" pos="word" morph="none" start_char="2609" end_char="2614">cities</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2617" end_char="2686">
<ORIGINAL_TEXT>Jan 2020 - Sewage samples from Barcelona suggest virus was in the city</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="2617" end_char="2619">Jan</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="2621" end_char="2624">2020</TOKEN>
<TOKEN id="token-25-2" pos="punct" morph="none" start_char="2626" end_char="2626">-</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="2628" end_char="2633">Sewage</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="2635" end_char="2641">samples</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="2643" end_char="2646">from</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="2648" end_char="2656">Barcelona</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="2658" end_char="2664">suggest</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="2666" end_char="2670">virus</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="2672" end_char="2674">was</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="2676" end_char="2677">in</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="2679" end_char="2681">the</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="2683" end_char="2686">city</TOKEN>
</SEG>
<SEG id="segment-26" start_char="2689" end_char="2701">
<ORIGINAL_TEXT>Advertisement</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="2689" end_char="2701">Advertisement</TOKEN>
</SEG>
<SEG id="segment-27" start_char="2704" end_char="2857">
<ORIGINAL_TEXT>The scientists argue that it should therefore be possible to track down the original version of the virus by finding the sample with the fewest mutations.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="2704" end_char="2706">The</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="2708" end_char="2717">scientists</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="2719" end_char="2723">argue</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="2725" end_char="2728">that</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="2730" end_char="2731">it</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="2733" end_char="2738">should</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="2740" end_char="2748">therefore</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="2750" end_char="2751">be</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="2753" end_char="2760">possible</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="2762" end_char="2763">to</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="2765" end_char="2769">track</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="2771" end_char="2774">down</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="2776" end_char="2778">the</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="2780" end_char="2787">original</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="2789" end_char="2795">version</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="2797" end_char="2798">of</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="2800" end_char="2802">the</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="2804" end_char="2808">virus</TOKEN>
<TOKEN id="token-27-18" pos="word" morph="none" start_char="2810" end_char="2811">by</TOKEN>
<TOKEN id="token-27-19" pos="word" morph="none" start_char="2813" end_char="2819">finding</TOKEN>
<TOKEN id="token-27-20" pos="word" morph="none" start_char="2821" end_char="2823">the</TOKEN>
<TOKEN id="token-27-21" pos="word" morph="none" start_char="2825" end_char="2830">sample</TOKEN>
<TOKEN id="token-27-22" pos="word" morph="none" start_char="2832" end_char="2835">with</TOKEN>
<TOKEN id="token-27-23" pos="word" morph="none" start_char="2837" end_char="2839">the</TOKEN>
<TOKEN id="token-27-24" pos="word" morph="none" start_char="2841" end_char="2846">fewest</TOKEN>
<TOKEN id="token-27-25" pos="word" morph="none" start_char="2848" end_char="2856">mutations</TOKEN>
<TOKEN id="token-27-26" pos="punct" morph="none" start_char="2857" end_char="2857">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="2860" end_char="3083">
<ORIGINAL_TEXT>They say that using this method rules out the virus found in Wuhan as the 'original' virus, and instead points to eight other countries: Bangladesh, the USA, Greece, Australia, India, Italy, Czech Republic, Russia or Serbia.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="2860" end_char="2863">They</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="2865" end_char="2867">say</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="2869" end_char="2872">that</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="2874" end_char="2878">using</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="2880" end_char="2883">this</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="2885" end_char="2890">method</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="2892" end_char="2896">rules</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="2898" end_char="2900">out</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="2902" end_char="2904">the</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="2906" end_char="2910">virus</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="2912" end_char="2916">found</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="2918" end_char="2919">in</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="2921" end_char="2925">Wuhan</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="2927" end_char="2928">as</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="2930" end_char="2932">the</TOKEN>
<TOKEN id="token-28-15" pos="punct" morph="none" start_char="2934" end_char="2934">'</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="2935" end_char="2942">original</TOKEN>
<TOKEN id="token-28-17" pos="punct" morph="none" start_char="2943" end_char="2943">'</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="2945" end_char="2949">virus</TOKEN>
<TOKEN id="token-28-19" pos="punct" morph="none" start_char="2950" end_char="2950">,</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="2952" end_char="2954">and</TOKEN>
<TOKEN id="token-28-21" pos="word" morph="none" start_char="2956" end_char="2962">instead</TOKEN>
<TOKEN id="token-28-22" pos="word" morph="none" start_char="2964" end_char="2969">points</TOKEN>
<TOKEN id="token-28-23" pos="word" morph="none" start_char="2971" end_char="2972">to</TOKEN>
<TOKEN id="token-28-24" pos="word" morph="none" start_char="2974" end_char="2978">eight</TOKEN>
<TOKEN id="token-28-25" pos="word" morph="none" start_char="2980" end_char="2984">other</TOKEN>
<TOKEN id="token-28-26" pos="word" morph="none" start_char="2986" end_char="2994">countries</TOKEN>
<TOKEN id="token-28-27" pos="punct" morph="none" start_char="2995" end_char="2995">:</TOKEN>
<TOKEN id="token-28-28" pos="word" morph="none" start_char="2997" end_char="3006">Bangladesh</TOKEN>
<TOKEN id="token-28-29" pos="punct" morph="none" start_char="3007" end_char="3007">,</TOKEN>
<TOKEN id="token-28-30" pos="word" morph="none" start_char="3009" end_char="3011">the</TOKEN>
<TOKEN id="token-28-31" pos="word" morph="none" start_char="3013" end_char="3015">USA</TOKEN>
<TOKEN id="token-28-32" pos="punct" morph="none" start_char="3016" end_char="3016">,</TOKEN>
<TOKEN id="token-28-33" pos="word" morph="none" start_char="3018" end_char="3023">Greece</TOKEN>
<TOKEN id="token-28-34" pos="punct" morph="none" start_char="3024" end_char="3024">,</TOKEN>
<TOKEN id="token-28-35" pos="word" morph="none" start_char="3026" end_char="3034">Australia</TOKEN>
<TOKEN id="token-28-36" pos="punct" morph="none" start_char="3035" end_char="3035">,</TOKEN>
<TOKEN id="token-28-37" pos="word" morph="none" start_char="3037" end_char="3041">India</TOKEN>
<TOKEN id="token-28-38" pos="punct" morph="none" start_char="3042" end_char="3042">,</TOKEN>
<TOKEN id="token-28-39" pos="word" morph="none" start_char="3044" end_char="3048">Italy</TOKEN>
<TOKEN id="token-28-40" pos="punct" morph="none" start_char="3049" end_char="3049">,</TOKEN>
<TOKEN id="token-28-41" pos="word" morph="none" start_char="3051" end_char="3055">Czech</TOKEN>
<TOKEN id="token-28-42" pos="word" morph="none" start_char="3057" end_char="3064">Republic</TOKEN>
<TOKEN id="token-28-43" pos="punct" morph="none" start_char="3065" end_char="3065">,</TOKEN>
<TOKEN id="token-28-44" pos="word" morph="none" start_char="3067" end_char="3072">Russia</TOKEN>
<TOKEN id="token-28-45" pos="word" morph="none" start_char="3074" end_char="3075">or</TOKEN>
<TOKEN id="token-28-46" pos="word" morph="none" start_char="3077" end_char="3082">Serbia</TOKEN>
<TOKEN id="token-28-47" pos="punct" morph="none" start_char="3083" end_char="3083">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3086" end_char="3274">
<ORIGINAL_TEXT>Researchers go on to argue that because India and Bangladesh both recorded samples with low mutations and are geographic neighbours, it is likely that the first transmission occurred there.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="3086" end_char="3096">Researchers</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="3098" end_char="3099">go</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="3101" end_char="3102">on</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="3104" end_char="3105">to</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="3107" end_char="3111">argue</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="3113" end_char="3116">that</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="3118" end_char="3124">because</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="3126" end_char="3130">India</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="3132" end_char="3134">and</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="3136" end_char="3145">Bangladesh</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="3147" end_char="3150">both</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="3152" end_char="3159">recorded</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="3161" end_char="3167">samples</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="3169" end_char="3172">with</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="3174" end_char="3176">low</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="3178" end_char="3186">mutations</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="3188" end_char="3190">and</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="3192" end_char="3194">are</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="3196" end_char="3205">geographic</TOKEN>
<TOKEN id="token-29-19" pos="word" morph="none" start_char="3207" end_char="3216">neighbours</TOKEN>
<TOKEN id="token-29-20" pos="punct" morph="none" start_char="3217" end_char="3217">,</TOKEN>
<TOKEN id="token-29-21" pos="word" morph="none" start_char="3219" end_char="3220">it</TOKEN>
<TOKEN id="token-29-22" pos="word" morph="none" start_char="3222" end_char="3223">is</TOKEN>
<TOKEN id="token-29-23" pos="word" morph="none" start_char="3225" end_char="3230">likely</TOKEN>
<TOKEN id="token-29-24" pos="word" morph="none" start_char="3232" end_char="3235">that</TOKEN>
<TOKEN id="token-29-25" pos="word" morph="none" start_char="3237" end_char="3239">the</TOKEN>
<TOKEN id="token-29-26" pos="word" morph="none" start_char="3241" end_char="3245">first</TOKEN>
<TOKEN id="token-29-27" pos="word" morph="none" start_char="3247" end_char="3258">transmission</TOKEN>
<TOKEN id="token-29-28" pos="word" morph="none" start_char="3260" end_char="3267">occurred</TOKEN>
<TOKEN id="token-29-29" pos="word" morph="none" start_char="3269" end_char="3273">there</TOKEN>
<TOKEN id="token-29-30" pos="punct" morph="none" start_char="3274" end_char="3274">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3277" end_char="3472">
<ORIGINAL_TEXT>By estimating the amount of time it takes for the virus to mutate once, and comparing that to the samples taken there, they also theorise that the virus first emerged there in July or August 2019.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="3277" end_char="3278">By</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="3280" end_char="3289">estimating</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="3291" end_char="3293">the</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="3295" end_char="3300">amount</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="3302" end_char="3303">of</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="3305" end_char="3308">time</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="3310" end_char="3311">it</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="3313" end_char="3317">takes</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="3319" end_char="3321">for</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="3323" end_char="3325">the</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="3327" end_char="3331">virus</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="3333" end_char="3334">to</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="3336" end_char="3341">mutate</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="3343" end_char="3346">once</TOKEN>
<TOKEN id="token-30-14" pos="punct" morph="none" start_char="3347" end_char="3347">,</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="3349" end_char="3351">and</TOKEN>
<TOKEN id="token-30-16" pos="word" morph="none" start_char="3353" end_char="3361">comparing</TOKEN>
<TOKEN id="token-30-17" pos="word" morph="none" start_char="3363" end_char="3366">that</TOKEN>
<TOKEN id="token-30-18" pos="word" morph="none" start_char="3368" end_char="3369">to</TOKEN>
<TOKEN id="token-30-19" pos="word" morph="none" start_char="3371" end_char="3373">the</TOKEN>
<TOKEN id="token-30-20" pos="word" morph="none" start_char="3375" end_char="3381">samples</TOKEN>
<TOKEN id="token-30-21" pos="word" morph="none" start_char="3383" end_char="3387">taken</TOKEN>
<TOKEN id="token-30-22" pos="word" morph="none" start_char="3389" end_char="3393">there</TOKEN>
<TOKEN id="token-30-23" pos="punct" morph="none" start_char="3394" end_char="3394">,</TOKEN>
<TOKEN id="token-30-24" pos="word" morph="none" start_char="3396" end_char="3399">they</TOKEN>
<TOKEN id="token-30-25" pos="word" morph="none" start_char="3401" end_char="3404">also</TOKEN>
<TOKEN id="token-30-26" pos="word" morph="none" start_char="3406" end_char="3413">theorise</TOKEN>
<TOKEN id="token-30-27" pos="word" morph="none" start_char="3415" end_char="3418">that</TOKEN>
<TOKEN id="token-30-28" pos="word" morph="none" start_char="3420" end_char="3422">the</TOKEN>
<TOKEN id="token-30-29" pos="word" morph="none" start_char="3424" end_char="3428">virus</TOKEN>
<TOKEN id="token-30-30" pos="word" morph="none" start_char="3430" end_char="3434">first</TOKEN>
<TOKEN id="token-30-31" pos="word" morph="none" start_char="3436" end_char="3442">emerged</TOKEN>
<TOKEN id="token-30-32" pos="word" morph="none" start_char="3444" end_char="3448">there</TOKEN>
<TOKEN id="token-30-33" pos="word" morph="none" start_char="3450" end_char="3451">in</TOKEN>
<TOKEN id="token-30-34" pos="word" morph="none" start_char="3453" end_char="3456">July</TOKEN>
<TOKEN id="token-30-35" pos="word" morph="none" start_char="3458" end_char="3459">or</TOKEN>
<TOKEN id="token-30-36" pos="word" morph="none" start_char="3461" end_char="3466">August</TOKEN>
<TOKEN id="token-30-37" pos="word" morph="none" start_char="3468" end_char="3471">2019</TOKEN>
<TOKEN id="token-30-38" pos="punct" morph="none" start_char="3472" end_char="3472">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="3475" end_char="3660">
<ORIGINAL_TEXT>They go on to say: 'From May to June 2019, the second longest recorded heat wave had rampaged in northern-central India and Pakistan, which created a serious water crisis in this region.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="3475" end_char="3478">They</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="3480" end_char="3481">go</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="3483" end_char="3484">on</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="3486" end_char="3487">to</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="3489" end_char="3491">say</TOKEN>
<TOKEN id="token-31-5" pos="punct" morph="none" start_char="3492" end_char="3492">:</TOKEN>
<TOKEN id="token-31-6" pos="punct" morph="none" start_char="3494" end_char="3494">'</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="3495" end_char="3498">From</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="3500" end_char="3502">May</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="3504" end_char="3505">to</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="3507" end_char="3510">June</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="3512" end_char="3515">2019</TOKEN>
<TOKEN id="token-31-12" pos="punct" morph="none" start_char="3516" end_char="3516">,</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="3518" end_char="3520">the</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="3522" end_char="3527">second</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="3529" end_char="3535">longest</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="3537" end_char="3544">recorded</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="3546" end_char="3549">heat</TOKEN>
<TOKEN id="token-31-18" pos="word" morph="none" start_char="3551" end_char="3554">wave</TOKEN>
<TOKEN id="token-31-19" pos="word" morph="none" start_char="3556" end_char="3558">had</TOKEN>
<TOKEN id="token-31-20" pos="word" morph="none" start_char="3560" end_char="3567">rampaged</TOKEN>
<TOKEN id="token-31-21" pos="word" morph="none" start_char="3569" end_char="3570">in</TOKEN>
<TOKEN id="token-31-22" pos="unknown" morph="none" start_char="3572" end_char="3587">northern-central</TOKEN>
<TOKEN id="token-31-23" pos="word" morph="none" start_char="3589" end_char="3593">India</TOKEN>
<TOKEN id="token-31-24" pos="word" morph="none" start_char="3595" end_char="3597">and</TOKEN>
<TOKEN id="token-31-25" pos="word" morph="none" start_char="3599" end_char="3606">Pakistan</TOKEN>
<TOKEN id="token-31-26" pos="punct" morph="none" start_char="3607" end_char="3607">,</TOKEN>
<TOKEN id="token-31-27" pos="word" morph="none" start_char="3609" end_char="3613">which</TOKEN>
<TOKEN id="token-31-28" pos="word" morph="none" start_char="3615" end_char="3621">created</TOKEN>
<TOKEN id="token-31-29" pos="word" morph="none" start_char="3623" end_char="3623">a</TOKEN>
<TOKEN id="token-31-30" pos="word" morph="none" start_char="3625" end_char="3631">serious</TOKEN>
<TOKEN id="token-31-31" pos="word" morph="none" start_char="3633" end_char="3637">water</TOKEN>
<TOKEN id="token-31-32" pos="word" morph="none" start_char="3639" end_char="3644">crisis</TOKEN>
<TOKEN id="token-31-33" pos="word" morph="none" start_char="3646" end_char="3647">in</TOKEN>
<TOKEN id="token-31-34" pos="word" morph="none" start_char="3649" end_char="3652">this</TOKEN>
<TOKEN id="token-31-35" pos="word" morph="none" start_char="3654" end_char="3659">region</TOKEN>
<TOKEN id="token-31-36" pos="punct" morph="none" start_char="3660" end_char="3660">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="3663" end_char="3848">
<ORIGINAL_TEXT>'The water shortage made wild animals such as monkeys engage in the deadly fight over water among each other and would have surely increased the chance of human-wild animal interactions.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="punct" morph="none" start_char="3663" end_char="3663">'</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="3664" end_char="3666">The</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="3668" end_char="3672">water</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="3674" end_char="3681">shortage</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="3683" end_char="3686">made</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="3688" end_char="3691">wild</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="3693" end_char="3699">animals</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="3701" end_char="3704">such</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="3706" end_char="3707">as</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="3709" end_char="3715">monkeys</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="3717" end_char="3722">engage</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="3724" end_char="3725">in</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="3727" end_char="3729">the</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="3731" end_char="3736">deadly</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="3738" end_char="3742">fight</TOKEN>
<TOKEN id="token-32-15" pos="word" morph="none" start_char="3744" end_char="3747">over</TOKEN>
<TOKEN id="token-32-16" pos="word" morph="none" start_char="3749" end_char="3753">water</TOKEN>
<TOKEN id="token-32-17" pos="word" morph="none" start_char="3755" end_char="3759">among</TOKEN>
<TOKEN id="token-32-18" pos="word" morph="none" start_char="3761" end_char="3764">each</TOKEN>
<TOKEN id="token-32-19" pos="word" morph="none" start_char="3766" end_char="3770">other</TOKEN>
<TOKEN id="token-32-20" pos="word" morph="none" start_char="3772" end_char="3774">and</TOKEN>
<TOKEN id="token-32-21" pos="word" morph="none" start_char="3776" end_char="3780">would</TOKEN>
<TOKEN id="token-32-22" pos="word" morph="none" start_char="3782" end_char="3785">have</TOKEN>
<TOKEN id="token-32-23" pos="word" morph="none" start_char="3787" end_char="3792">surely</TOKEN>
<TOKEN id="token-32-24" pos="word" morph="none" start_char="3794" end_char="3802">increased</TOKEN>
<TOKEN id="token-32-25" pos="word" morph="none" start_char="3804" end_char="3806">the</TOKEN>
<TOKEN id="token-32-26" pos="word" morph="none" start_char="3808" end_char="3813">chance</TOKEN>
<TOKEN id="token-32-27" pos="word" morph="none" start_char="3815" end_char="3816">of</TOKEN>
<TOKEN id="token-32-28" pos="unknown" morph="none" start_char="3818" end_char="3827">human-wild</TOKEN>
<TOKEN id="token-32-29" pos="word" morph="none" start_char="3829" end_char="3834">animal</TOKEN>
<TOKEN id="token-32-30" pos="word" morph="none" start_char="3836" end_char="3847">interactions</TOKEN>
<TOKEN id="token-32-31" pos="punct" morph="none" start_char="3848" end_char="3848">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="3851" end_char="3968">
<ORIGINAL_TEXT>'We speculated that the [animal to human] transmission of SARS-CoV-2 might be associated with this unusual heat wave.'</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="punct" morph="none" start_char="3851" end_char="3851">'</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="3852" end_char="3853">We</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="3855" end_char="3864">speculated</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="3866" end_char="3869">that</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="3871" end_char="3873">the</TOKEN>
<TOKEN id="token-33-5" pos="punct" morph="none" start_char="3875" end_char="3875">[</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="3876" end_char="3881">animal</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="3883" end_char="3884">to</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="3886" end_char="3890">human</TOKEN>
<TOKEN id="token-33-9" pos="punct" morph="none" start_char="3891" end_char="3891">]</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="3893" end_char="3904">transmission</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="3906" end_char="3907">of</TOKEN>
<TOKEN id="token-33-12" pos="unknown" morph="none" start_char="3909" end_char="3918">SARS-CoV-2</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="3920" end_char="3924">might</TOKEN>
<TOKEN id="token-33-14" pos="word" morph="none" start_char="3926" end_char="3927">be</TOKEN>
<TOKEN id="token-33-15" pos="word" morph="none" start_char="3929" end_char="3938">associated</TOKEN>
<TOKEN id="token-33-16" pos="word" morph="none" start_char="3940" end_char="3943">with</TOKEN>
<TOKEN id="token-33-17" pos="word" morph="none" start_char="3945" end_char="3948">this</TOKEN>
<TOKEN id="token-33-18" pos="word" morph="none" start_char="3950" end_char="3956">unusual</TOKEN>
<TOKEN id="token-33-19" pos="word" morph="none" start_char="3958" end_char="3961">heat</TOKEN>
<TOKEN id="token-33-20" pos="word" morph="none" start_char="3963" end_char="3966">wave</TOKEN>
<TOKEN id="token-33-21" pos="punct" morph="none" start_char="3967" end_char="3968">.'</TOKEN>
</SEG>
<SEG id="segment-34" start_char="3971" end_char="4156">
<ORIGINAL_TEXT>Researchers further argue that India's poor healthcare system and young population - who suffer less severe symptoms of Covid - allowed the virus to spread undetected for several months.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="3971" end_char="3981">Researchers</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="3983" end_char="3989">further</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="3991" end_char="3995">argue</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="3997" end_char="4000">that</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="4002" end_char="4008">India's</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="4010" end_char="4013">poor</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="4015" end_char="4024">healthcare</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="4026" end_char="4031">system</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="4033" end_char="4035">and</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="4037" end_char="4041">young</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="4043" end_char="4052">population</TOKEN>
<TOKEN id="token-34-11" pos="punct" morph="none" start_char="4054" end_char="4054">-</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="4056" end_char="4058">who</TOKEN>
<TOKEN id="token-34-13" pos="word" morph="none" start_char="4060" end_char="4065">suffer</TOKEN>
<TOKEN id="token-34-14" pos="word" morph="none" start_char="4067" end_char="4070">less</TOKEN>
<TOKEN id="token-34-15" pos="word" morph="none" start_char="4072" end_char="4077">severe</TOKEN>
<TOKEN id="token-34-16" pos="word" morph="none" start_char="4079" end_char="4086">symptoms</TOKEN>
<TOKEN id="token-34-17" pos="word" morph="none" start_char="4088" end_char="4089">of</TOKEN>
<TOKEN id="token-34-18" pos="word" morph="none" start_char="4091" end_char="4095">Covid</TOKEN>
<TOKEN id="token-34-19" pos="punct" morph="none" start_char="4097" end_char="4097">-</TOKEN>
<TOKEN id="token-34-20" pos="word" morph="none" start_char="4099" end_char="4105">allowed</TOKEN>
<TOKEN id="token-34-21" pos="word" morph="none" start_char="4107" end_char="4109">the</TOKEN>
<TOKEN id="token-34-22" pos="word" morph="none" start_char="4111" end_char="4115">virus</TOKEN>
<TOKEN id="token-34-23" pos="word" morph="none" start_char="4117" end_char="4118">to</TOKEN>
<TOKEN id="token-34-24" pos="word" morph="none" start_char="4120" end_char="4125">spread</TOKEN>
<TOKEN id="token-34-25" pos="word" morph="none" start_char="4127" end_char="4136">undetected</TOKEN>
<TOKEN id="token-34-26" pos="word" morph="none" start_char="4138" end_char="4140">for</TOKEN>
<TOKEN id="token-34-27" pos="word" morph="none" start_char="4142" end_char="4148">several</TOKEN>
<TOKEN id="token-34-28" pos="word" morph="none" start_char="4150" end_char="4155">months</TOKEN>
<TOKEN id="token-34-29" pos="punct" morph="none" start_char="4156" end_char="4156">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="4159" end_char="4287">
<ORIGINAL_TEXT>They speculate that the virus could have spread to the other countries on their list before coming to China, possibly via Europe.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="4159" end_char="4162">They</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="4164" end_char="4172">speculate</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="4174" end_char="4177">that</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="4179" end_char="4181">the</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="4183" end_char="4187">virus</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="4189" end_char="4193">could</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="4195" end_char="4198">have</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="4200" end_char="4205">spread</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="4207" end_char="4208">to</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="4210" end_char="4212">the</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="4214" end_char="4218">other</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="4220" end_char="4228">countries</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="4230" end_char="4231">on</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="4233" end_char="4237">their</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="4239" end_char="4242">list</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="4244" end_char="4249">before</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="4251" end_char="4256">coming</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="4258" end_char="4259">to</TOKEN>
<TOKEN id="token-35-18" pos="word" morph="none" start_char="4261" end_char="4265">China</TOKEN>
<TOKEN id="token-35-19" pos="punct" morph="none" start_char="4266" end_char="4266">,</TOKEN>
<TOKEN id="token-35-20" pos="word" morph="none" start_char="4268" end_char="4275">possibly</TOKEN>
<TOKEN id="token-35-21" pos="word" morph="none" start_char="4277" end_char="4279">via</TOKEN>
<TOKEN id="token-35-22" pos="word" morph="none" start_char="4281" end_char="4286">Europe</TOKEN>
<TOKEN id="token-35-23" pos="punct" morph="none" start_char="4287" end_char="4287">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="4290" end_char="4402">
<ORIGINAL_TEXT>'In this regard, the COVID-19 pandemic is inevitable and the Wuhan epidemic is only a part of it,' they conclude.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="punct" morph="none" start_char="4290" end_char="4290">'</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="4291" end_char="4292">In</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="4294" end_char="4297">this</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="4299" end_char="4304">regard</TOKEN>
<TOKEN id="token-36-4" pos="punct" morph="none" start_char="4305" end_char="4305">,</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="4307" end_char="4309">the</TOKEN>
<TOKEN id="token-36-6" pos="unknown" morph="none" start_char="4311" end_char="4318">COVID-19</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="4320" end_char="4327">pandemic</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="4329" end_char="4330">is</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="4332" end_char="4341">inevitable</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="4343" end_char="4345">and</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="4347" end_char="4349">the</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="4351" end_char="4355">Wuhan</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="4357" end_char="4364">epidemic</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="4366" end_char="4367">is</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="4369" end_char="4372">only</TOKEN>
<TOKEN id="token-36-16" pos="word" morph="none" start_char="4374" end_char="4374">a</TOKEN>
<TOKEN id="token-36-17" pos="word" morph="none" start_char="4376" end_char="4379">part</TOKEN>
<TOKEN id="token-36-18" pos="word" morph="none" start_char="4381" end_char="4382">of</TOKEN>
<TOKEN id="token-36-19" pos="word" morph="none" start_char="4384" end_char="4385">it</TOKEN>
<TOKEN id="token-36-20" pos="punct" morph="none" start_char="4386" end_char="4387">,'</TOKEN>
<TOKEN id="token-36-21" pos="word" morph="none" start_char="4389" end_char="4392">they</TOKEN>
<TOKEN id="token-36-22" pos="word" morph="none" start_char="4394" end_char="4401">conclude</TOKEN>
<TOKEN id="token-36-23" pos="punct" morph="none" start_char="4402" end_char="4402">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="4405" end_char="4468">
<ORIGINAL_TEXT>However, other researchers were not impressed with the findings.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="4405" end_char="4411">However</TOKEN>
<TOKEN id="token-37-1" pos="punct" morph="none" start_char="4412" end_char="4412">,</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="4414" end_char="4418">other</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="4420" end_char="4430">researchers</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="4432" end_char="4435">were</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="4437" end_char="4439">not</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="4441" end_char="4449">impressed</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="4451" end_char="4454">with</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="4456" end_char="4458">the</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="4460" end_char="4467">findings</TOKEN>
<TOKEN id="token-37-10" pos="punct" morph="none" start_char="4468" end_char="4468">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="4471" end_char="4625">
<ORIGINAL_TEXT>In a statement to Mail Online, Professor Robertson said: 'The author's approach of identifying the "least mutated" virus sequences is... inherently biased.</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="4471" end_char="4472">In</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="4474" end_char="4474">a</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="4476" end_char="4484">statement</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="4486" end_char="4487">to</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="4489" end_char="4492">Mail</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="4494" end_char="4499">Online</TOKEN>
<TOKEN id="token-38-6" pos="punct" morph="none" start_char="4500" end_char="4500">,</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="4502" end_char="4510">Professor</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="4512" end_char="4520">Robertson</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="4522" end_char="4525">said</TOKEN>
<TOKEN id="token-38-10" pos="punct" morph="none" start_char="4526" end_char="4526">:</TOKEN>
<TOKEN id="token-38-11" pos="punct" morph="none" start_char="4528" end_char="4528">'</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="4529" end_char="4531">The</TOKEN>
<TOKEN id="token-38-13" pos="word" morph="none" start_char="4533" end_char="4540">author's</TOKEN>
<TOKEN id="token-38-14" pos="word" morph="none" start_char="4542" end_char="4549">approach</TOKEN>
<TOKEN id="token-38-15" pos="word" morph="none" start_char="4551" end_char="4552">of</TOKEN>
<TOKEN id="token-38-16" pos="word" morph="none" start_char="4554" end_char="4564">identifying</TOKEN>
<TOKEN id="token-38-17" pos="word" morph="none" start_char="4566" end_char="4568">the</TOKEN>
<TOKEN id="token-38-18" pos="punct" morph="none" start_char="4570" end_char="4570">"</TOKEN>
<TOKEN id="token-38-19" pos="word" morph="none" start_char="4571" end_char="4575">least</TOKEN>
<TOKEN id="token-38-20" pos="word" morph="none" start_char="4577" end_char="4583">mutated</TOKEN>
<TOKEN id="token-38-21" pos="punct" morph="none" start_char="4584" end_char="4584">"</TOKEN>
<TOKEN id="token-38-22" pos="word" morph="none" start_char="4586" end_char="4590">virus</TOKEN>
<TOKEN id="token-38-23" pos="word" morph="none" start_char="4592" end_char="4600">sequences</TOKEN>
<TOKEN id="token-38-24" pos="word" morph="none" start_char="4602" end_char="4603">is</TOKEN>
<TOKEN id="token-38-25" pos="punct" morph="none" start_char="4604" end_char="4606">...</TOKEN>
<TOKEN id="token-38-26" pos="word" morph="none" start_char="4608" end_char="4617">inherently</TOKEN>
<TOKEN id="token-38-27" pos="word" morph="none" start_char="4619" end_char="4624">biased</TOKEN>
<TOKEN id="token-38-28" pos="punct" morph="none" start_char="4625" end_char="4625">.</TOKEN>
</SEG>
<SEG id="segment-39" start_char="4628" end_char="4776">
<ORIGINAL_TEXT>'The authors have also ignored the extensive epidemiological data available that shows clear emergence in China and that the virus spread from there.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="punct" morph="none" start_char="4628" end_char="4628">'</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="4629" end_char="4631">The</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="4633" end_char="4639">authors</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="4641" end_char="4644">have</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="4646" end_char="4649">also</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="4651" end_char="4657">ignored</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="4659" end_char="4661">the</TOKEN>
<TOKEN id="token-39-7" pos="word" morph="none" start_char="4663" end_char="4671">extensive</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="4673" end_char="4687">epidemiological</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="4689" end_char="4692">data</TOKEN>
<TOKEN id="token-39-10" pos="word" morph="none" start_char="4694" end_char="4702">available</TOKEN>
<TOKEN id="token-39-11" pos="word" morph="none" start_char="4704" end_char="4707">that</TOKEN>
<TOKEN id="token-39-12" pos="word" morph="none" start_char="4709" end_char="4713">shows</TOKEN>
<TOKEN id="token-39-13" pos="word" morph="none" start_char="4715" end_char="4719">clear</TOKEN>
<TOKEN id="token-39-14" pos="word" morph="none" start_char="4721" end_char="4729">emergence</TOKEN>
<TOKEN id="token-39-15" pos="word" morph="none" start_char="4731" end_char="4732">in</TOKEN>
<TOKEN id="token-39-16" pos="word" morph="none" start_char="4734" end_char="4738">China</TOKEN>
<TOKEN id="token-39-17" pos="word" morph="none" start_char="4740" end_char="4742">and</TOKEN>
<TOKEN id="token-39-18" pos="word" morph="none" start_char="4744" end_char="4747">that</TOKEN>
<TOKEN id="token-39-19" pos="word" morph="none" start_char="4749" end_char="4751">the</TOKEN>
<TOKEN id="token-39-20" pos="word" morph="none" start_char="4753" end_char="4757">virus</TOKEN>
<TOKEN id="token-39-21" pos="word" morph="none" start_char="4759" end_char="4764">spread</TOKEN>
<TOKEN id="token-39-22" pos="word" morph="none" start_char="4766" end_char="4769">from</TOKEN>
<TOKEN id="token-39-23" pos="word" morph="none" start_char="4771" end_char="4775">there</TOKEN>
<TOKEN id="token-39-24" pos="punct" morph="none" start_char="4776" end_char="4776">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="4779" end_char="4839">
<ORIGINAL_TEXT>'This paper adds nothing to our understanding of SARS-CoV-2.'</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="punct" morph="none" start_char="4779" end_char="4779">'</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="4780" end_char="4783">This</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="4785" end_char="4789">paper</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="4791" end_char="4794">adds</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="4796" end_char="4802">nothing</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="4804" end_char="4805">to</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="4807" end_char="4809">our</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="4811" end_char="4823">understanding</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="4825" end_char="4826">of</TOKEN>
<TOKEN id="token-40-9" pos="unknown" morph="none" start_char="4828" end_char="4837">SARS-CoV-2</TOKEN>
<TOKEN id="token-40-10" pos="punct" morph="none" start_char="4838" end_char="4839">.'</TOKEN>
</SEG>
<SEG id="segment-41" start_char="4842" end_char="5094">
<ORIGINAL_TEXT>Marc Suchard, an expert from the University of California, told the South China Morning Post: 'Picking the viral sequence that appears to have the least number of differences to the others in an arbitrary collection is unlikely to yield the progenitor.'</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="4842" end_char="4845">Marc</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="4847" end_char="4853">Suchard</TOKEN>
<TOKEN id="token-41-2" pos="punct" morph="none" start_char="4854" end_char="4854">,</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="4856" end_char="4857">an</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="4859" end_char="4864">expert</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="4866" end_char="4869">from</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="4871" end_char="4873">the</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="4875" end_char="4884">University</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="4886" end_char="4887">of</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="4889" end_char="4898">California</TOKEN>
<TOKEN id="token-41-10" pos="punct" morph="none" start_char="4899" end_char="4899">,</TOKEN>
<TOKEN id="token-41-11" pos="word" morph="none" start_char="4901" end_char="4904">told</TOKEN>
<TOKEN id="token-41-12" pos="word" morph="none" start_char="4906" end_char="4908">the</TOKEN>
<TOKEN id="token-41-13" pos="word" morph="none" start_char="4910" end_char="4914">South</TOKEN>
<TOKEN id="token-41-14" pos="word" morph="none" start_char="4916" end_char="4920">China</TOKEN>
<TOKEN id="token-41-15" pos="word" morph="none" start_char="4922" end_char="4928">Morning</TOKEN>
<TOKEN id="token-41-16" pos="word" morph="none" start_char="4930" end_char="4933">Post</TOKEN>
<TOKEN id="token-41-17" pos="punct" morph="none" start_char="4934" end_char="4934">:</TOKEN>
<TOKEN id="token-41-18" pos="punct" morph="none" start_char="4936" end_char="4936">'</TOKEN>
<TOKEN id="token-41-19" pos="word" morph="none" start_char="4937" end_char="4943">Picking</TOKEN>
<TOKEN id="token-41-20" pos="word" morph="none" start_char="4945" end_char="4947">the</TOKEN>
<TOKEN id="token-41-21" pos="word" morph="none" start_char="4949" end_char="4953">viral</TOKEN>
<TOKEN id="token-41-22" pos="word" morph="none" start_char="4955" end_char="4962">sequence</TOKEN>
<TOKEN id="token-41-23" pos="word" morph="none" start_char="4964" end_char="4967">that</TOKEN>
<TOKEN id="token-41-24" pos="word" morph="none" start_char="4969" end_char="4975">appears</TOKEN>
<TOKEN id="token-41-25" pos="word" morph="none" start_char="4977" end_char="4978">to</TOKEN>
<TOKEN id="token-41-26" pos="word" morph="none" start_char="4980" end_char="4983">have</TOKEN>
<TOKEN id="token-41-27" pos="word" morph="none" start_char="4985" end_char="4987">the</TOKEN>
<TOKEN id="token-41-28" pos="word" morph="none" start_char="4989" end_char="4993">least</TOKEN>
<TOKEN id="token-41-29" pos="word" morph="none" start_char="4995" end_char="5000">number</TOKEN>
<TOKEN id="token-41-30" pos="word" morph="none" start_char="5002" end_char="5003">of</TOKEN>
<TOKEN id="token-41-31" pos="word" morph="none" start_char="5005" end_char="5015">differences</TOKEN>
<TOKEN id="token-41-32" pos="word" morph="none" start_char="5017" end_char="5018">to</TOKEN>
<TOKEN id="token-41-33" pos="word" morph="none" start_char="5020" end_char="5022">the</TOKEN>
<TOKEN id="token-41-34" pos="word" morph="none" start_char="5024" end_char="5029">others</TOKEN>
<TOKEN id="token-41-35" pos="word" morph="none" start_char="5031" end_char="5032">in</TOKEN>
<TOKEN id="token-41-36" pos="word" morph="none" start_char="5034" end_char="5035">an</TOKEN>
<TOKEN id="token-41-37" pos="word" morph="none" start_char="5037" end_char="5045">arbitrary</TOKEN>
<TOKEN id="token-41-38" pos="word" morph="none" start_char="5047" end_char="5056">collection</TOKEN>
<TOKEN id="token-41-39" pos="word" morph="none" start_char="5058" end_char="5059">is</TOKEN>
<TOKEN id="token-41-40" pos="word" morph="none" start_char="5061" end_char="5068">unlikely</TOKEN>
<TOKEN id="token-41-41" pos="word" morph="none" start_char="5070" end_char="5071">to</TOKEN>
<TOKEN id="token-41-42" pos="word" morph="none" start_char="5073" end_char="5077">yield</TOKEN>
<TOKEN id="token-41-43" pos="word" morph="none" start_char="5079" end_char="5081">the</TOKEN>
<TOKEN id="token-41-44" pos="word" morph="none" start_char="5083" end_char="5092">progenitor</TOKEN>
<TOKEN id="token-41-45" pos="punct" morph="none" start_char="5093" end_char="5094">.'</TOKEN>
</SEG>
<SEG id="segment-42" start_char="5097" end_char="5221">
<ORIGINAL_TEXT>Another UK-based researcher told Mail Online that the study contains 'big claims' and that he is 'skeptical' of the findings.</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="5097" end_char="5103">Another</TOKEN>
<TOKEN id="token-42-1" pos="unknown" morph="none" start_char="5105" end_char="5112">UK-based</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="5114" end_char="5123">researcher</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="5125" end_char="5128">told</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="5130" end_char="5133">Mail</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="5135" end_char="5140">Online</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="5142" end_char="5145">that</TOKEN>
<TOKEN id="token-42-7" pos="word" morph="none" start_char="5147" end_char="5149">the</TOKEN>
<TOKEN id="token-42-8" pos="word" morph="none" start_char="5151" end_char="5155">study</TOKEN>
<TOKEN id="token-42-9" pos="word" morph="none" start_char="5157" end_char="5164">contains</TOKEN>
<TOKEN id="token-42-10" pos="punct" morph="none" start_char="5166" end_char="5166">'</TOKEN>
<TOKEN id="token-42-11" pos="word" morph="none" start_char="5167" end_char="5169">big</TOKEN>
<TOKEN id="token-42-12" pos="word" morph="none" start_char="5171" end_char="5176">claims</TOKEN>
<TOKEN id="token-42-13" pos="punct" morph="none" start_char="5177" end_char="5177">'</TOKEN>
<TOKEN id="token-42-14" pos="word" morph="none" start_char="5179" end_char="5181">and</TOKEN>
<TOKEN id="token-42-15" pos="word" morph="none" start_char="5183" end_char="5186">that</TOKEN>
<TOKEN id="token-42-16" pos="word" morph="none" start_char="5188" end_char="5189">he</TOKEN>
<TOKEN id="token-42-17" pos="word" morph="none" start_char="5191" end_char="5192">is</TOKEN>
<TOKEN id="token-42-18" pos="punct" morph="none" start_char="5194" end_char="5194">'</TOKEN>
<TOKEN id="token-42-19" pos="word" morph="none" start_char="5195" end_char="5203">skeptical</TOKEN>
<TOKEN id="token-42-20" pos="punct" morph="none" start_char="5204" end_char="5204">'</TOKEN>
<TOKEN id="token-42-21" pos="word" morph="none" start_char="5206" end_char="5207">of</TOKEN>
<TOKEN id="token-42-22" pos="word" morph="none" start_char="5209" end_char="5211">the</TOKEN>
<TOKEN id="token-42-23" pos="word" morph="none" start_char="5213" end_char="5220">findings</TOKEN>
<TOKEN id="token-42-24" pos="punct" morph="none" start_char="5221" end_char="5221">.</TOKEN>
</SEG>
<SEG id="segment-43" start_char="5225" end_char="5388">
<ORIGINAL_TEXT>India suffered a near-record heatwave in 2019 as water ran in desperately short supply, forcing the government to trasport it into cities in large trucks (pictured)</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="5225" end_char="5229">India</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="5231" end_char="5238">suffered</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="5240" end_char="5240">a</TOKEN>
<TOKEN id="token-43-3" pos="unknown" morph="none" start_char="5242" end_char="5252">near-record</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="5254" end_char="5261">heatwave</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="5263" end_char="5264">in</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="5266" end_char="5269">2019</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="5271" end_char="5272">as</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="5274" end_char="5278">water</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="5280" end_char="5282">ran</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="5284" end_char="5285">in</TOKEN>
<TOKEN id="token-43-11" pos="word" morph="none" start_char="5287" end_char="5297">desperately</TOKEN>
<TOKEN id="token-43-12" pos="word" morph="none" start_char="5299" end_char="5303">short</TOKEN>
<TOKEN id="token-43-13" pos="word" morph="none" start_char="5305" end_char="5310">supply</TOKEN>
<TOKEN id="token-43-14" pos="punct" morph="none" start_char="5311" end_char="5311">,</TOKEN>
<TOKEN id="token-43-15" pos="word" morph="none" start_char="5313" end_char="5319">forcing</TOKEN>
<TOKEN id="token-43-16" pos="word" morph="none" start_char="5321" end_char="5323">the</TOKEN>
<TOKEN id="token-43-17" pos="word" morph="none" start_char="5325" end_char="5334">government</TOKEN>
<TOKEN id="token-43-18" pos="word" morph="none" start_char="5336" end_char="5337">to</TOKEN>
<TOKEN id="token-43-19" pos="word" morph="none" start_char="5339" end_char="5346">trasport</TOKEN>
<TOKEN id="token-43-20" pos="word" morph="none" start_char="5348" end_char="5349">it</TOKEN>
<TOKEN id="token-43-21" pos="word" morph="none" start_char="5351" end_char="5354">into</TOKEN>
<TOKEN id="token-43-22" pos="word" morph="none" start_char="5356" end_char="5361">cities</TOKEN>
<TOKEN id="token-43-23" pos="word" morph="none" start_char="5363" end_char="5364">in</TOKEN>
<TOKEN id="token-43-24" pos="word" morph="none" start_char="5366" end_char="5370">large</TOKEN>
<TOKEN id="token-43-25" pos="word" morph="none" start_char="5372" end_char="5377">trucks</TOKEN>
<TOKEN id="token-43-26" pos="punct" morph="none" start_char="5379" end_char="5379">(</TOKEN>
<TOKEN id="token-43-27" pos="word" morph="none" start_char="5380" end_char="5387">pictured</TOKEN>
<TOKEN id="token-43-28" pos="punct" morph="none" start_char="5388" end_char="5388">)</TOKEN>
</SEG>
<SEG id="segment-44" start_char="5391" end_char="5537">
<ORIGINAL_TEXT>Coroanvirus first emerged in China in December 2019, linked to a cluster of cases of 'pneumonia of unknown origin' at a seafood market in the city.</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="5391" end_char="5401">Coroanvirus</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="5403" end_char="5407">first</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="5409" end_char="5415">emerged</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="5417" end_char="5418">in</TOKEN>
<TOKEN id="token-44-4" pos="word" morph="none" start_char="5420" end_char="5424">China</TOKEN>
<TOKEN id="token-44-5" pos="word" morph="none" start_char="5426" end_char="5427">in</TOKEN>
<TOKEN id="token-44-6" pos="word" morph="none" start_char="5429" end_char="5436">December</TOKEN>
<TOKEN id="token-44-7" pos="word" morph="none" start_char="5438" end_char="5441">2019</TOKEN>
<TOKEN id="token-44-8" pos="punct" morph="none" start_char="5442" end_char="5442">,</TOKEN>
<TOKEN id="token-44-9" pos="word" morph="none" start_char="5444" end_char="5449">linked</TOKEN>
<TOKEN id="token-44-10" pos="word" morph="none" start_char="5451" end_char="5452">to</TOKEN>
<TOKEN id="token-44-11" pos="word" morph="none" start_char="5454" end_char="5454">a</TOKEN>
<TOKEN id="token-44-12" pos="word" morph="none" start_char="5456" end_char="5462">cluster</TOKEN>
<TOKEN id="token-44-13" pos="word" morph="none" start_char="5464" end_char="5465">of</TOKEN>
<TOKEN id="token-44-14" pos="word" morph="none" start_char="5467" end_char="5471">cases</TOKEN>
<TOKEN id="token-44-15" pos="word" morph="none" start_char="5473" end_char="5474">of</TOKEN>
<TOKEN id="token-44-16" pos="punct" morph="none" start_char="5476" end_char="5476">'</TOKEN>
<TOKEN id="token-44-17" pos="word" morph="none" start_char="5477" end_char="5485">pneumonia</TOKEN>
<TOKEN id="token-44-18" pos="word" morph="none" start_char="5487" end_char="5488">of</TOKEN>
<TOKEN id="token-44-19" pos="word" morph="none" start_char="5490" end_char="5496">unknown</TOKEN>
<TOKEN id="token-44-20" pos="word" morph="none" start_char="5498" end_char="5503">origin</TOKEN>
<TOKEN id="token-44-21" pos="punct" morph="none" start_char="5504" end_char="5504">'</TOKEN>
<TOKEN id="token-44-22" pos="word" morph="none" start_char="5506" end_char="5507">at</TOKEN>
<TOKEN id="token-44-23" pos="word" morph="none" start_char="5509" end_char="5509">a</TOKEN>
<TOKEN id="token-44-24" pos="word" morph="none" start_char="5511" end_char="5517">seafood</TOKEN>
<TOKEN id="token-44-25" pos="word" morph="none" start_char="5519" end_char="5524">market</TOKEN>
<TOKEN id="token-44-26" pos="word" morph="none" start_char="5526" end_char="5527">in</TOKEN>
<TOKEN id="token-44-27" pos="word" morph="none" start_char="5529" end_char="5531">the</TOKEN>
<TOKEN id="token-44-28" pos="word" morph="none" start_char="5533" end_char="5536">city</TOKEN>
<TOKEN id="token-44-29" pos="punct" morph="none" start_char="5537" end_char="5537">.</TOKEN>
</SEG>
<SEG id="segment-45" start_char="5540" end_char="5676">
<ORIGINAL_TEXT>It then spread across China before making its way to other countires, mostly via toursits, where it spread rapidly and caused a pandemic.</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="5540" end_char="5541">It</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="5543" end_char="5546">then</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="5548" end_char="5553">spread</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="5555" end_char="5560">across</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="5562" end_char="5566">China</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="5568" end_char="5573">before</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="5575" end_char="5580">making</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="5582" end_char="5584">its</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="5586" end_char="5588">way</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="5590" end_char="5591">to</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="5593" end_char="5597">other</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="5599" end_char="5607">countires</TOKEN>
<TOKEN id="token-45-12" pos="punct" morph="none" start_char="5608" end_char="5608">,</TOKEN>
<TOKEN id="token-45-13" pos="word" morph="none" start_char="5610" end_char="5615">mostly</TOKEN>
<TOKEN id="token-45-14" pos="word" morph="none" start_char="5617" end_char="5619">via</TOKEN>
<TOKEN id="token-45-15" pos="word" morph="none" start_char="5621" end_char="5628">toursits</TOKEN>
<TOKEN id="token-45-16" pos="punct" morph="none" start_char="5629" end_char="5629">,</TOKEN>
<TOKEN id="token-45-17" pos="word" morph="none" start_char="5631" end_char="5635">where</TOKEN>
<TOKEN id="token-45-18" pos="word" morph="none" start_char="5637" end_char="5638">it</TOKEN>
<TOKEN id="token-45-19" pos="word" morph="none" start_char="5640" end_char="5645">spread</TOKEN>
<TOKEN id="token-45-20" pos="word" morph="none" start_char="5647" end_char="5653">rapidly</TOKEN>
<TOKEN id="token-45-21" pos="word" morph="none" start_char="5655" end_char="5657">and</TOKEN>
<TOKEN id="token-45-22" pos="word" morph="none" start_char="5659" end_char="5664">caused</TOKEN>
<TOKEN id="token-45-23" pos="word" morph="none" start_char="5666" end_char="5666">a</TOKEN>
<TOKEN id="token-45-24" pos="word" morph="none" start_char="5668" end_char="5675">pandemic</TOKEN>
<TOKEN id="token-45-25" pos="punct" morph="none" start_char="5676" end_char="5676">.</TOKEN>
</SEG>
<SEG id="segment-46" start_char="5679" end_char="5860">
<ORIGINAL_TEXT>But nobody has been able to identify 'patient zero' the first person known to have caught the disease, which means we do not known when or where exactly the first infection occurred.</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="5679" end_char="5681">But</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="5683" end_char="5688">nobody</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="5690" end_char="5692">has</TOKEN>
<TOKEN id="token-46-3" pos="word" morph="none" start_char="5694" end_char="5697">been</TOKEN>
<TOKEN id="token-46-4" pos="word" morph="none" start_char="5699" end_char="5702">able</TOKEN>
<TOKEN id="token-46-5" pos="word" morph="none" start_char="5704" end_char="5705">to</TOKEN>
<TOKEN id="token-46-6" pos="word" morph="none" start_char="5707" end_char="5714">identify</TOKEN>
<TOKEN id="token-46-7" pos="punct" morph="none" start_char="5716" end_char="5716">'</TOKEN>
<TOKEN id="token-46-8" pos="word" morph="none" start_char="5717" end_char="5723">patient</TOKEN>
<TOKEN id="token-46-9" pos="word" morph="none" start_char="5725" end_char="5728">zero</TOKEN>
<TOKEN id="token-46-10" pos="punct" morph="none" start_char="5729" end_char="5729">'</TOKEN>
<TOKEN id="token-46-11" pos="word" morph="none" start_char="5731" end_char="5733">the</TOKEN>
<TOKEN id="token-46-12" pos="word" morph="none" start_char="5735" end_char="5739">first</TOKEN>
<TOKEN id="token-46-13" pos="word" morph="none" start_char="5741" end_char="5746">person</TOKEN>
<TOKEN id="token-46-14" pos="word" morph="none" start_char="5748" end_char="5752">known</TOKEN>
<TOKEN id="token-46-15" pos="word" morph="none" start_char="5754" end_char="5755">to</TOKEN>
<TOKEN id="token-46-16" pos="word" morph="none" start_char="5757" end_char="5760">have</TOKEN>
<TOKEN id="token-46-17" pos="word" morph="none" start_char="5762" end_char="5767">caught</TOKEN>
<TOKEN id="token-46-18" pos="word" morph="none" start_char="5769" end_char="5771">the</TOKEN>
<TOKEN id="token-46-19" pos="word" morph="none" start_char="5773" end_char="5779">disease</TOKEN>
<TOKEN id="token-46-20" pos="punct" morph="none" start_char="5780" end_char="5780">,</TOKEN>
<TOKEN id="token-46-21" pos="word" morph="none" start_char="5782" end_char="5786">which</TOKEN>
<TOKEN id="token-46-22" pos="word" morph="none" start_char="5788" end_char="5792">means</TOKEN>
<TOKEN id="token-46-23" pos="word" morph="none" start_char="5794" end_char="5795">we</TOKEN>
<TOKEN id="token-46-24" pos="word" morph="none" start_char="5797" end_char="5798">do</TOKEN>
<TOKEN id="token-46-25" pos="word" morph="none" start_char="5800" end_char="5802">not</TOKEN>
<TOKEN id="token-46-26" pos="word" morph="none" start_char="5804" end_char="5808">known</TOKEN>
<TOKEN id="token-46-27" pos="word" morph="none" start_char="5810" end_char="5813">when</TOKEN>
<TOKEN id="token-46-28" pos="word" morph="none" start_char="5815" end_char="5816">or</TOKEN>
<TOKEN id="token-46-29" pos="word" morph="none" start_char="5818" end_char="5822">where</TOKEN>
<TOKEN id="token-46-30" pos="word" morph="none" start_char="5824" end_char="5830">exactly</TOKEN>
<TOKEN id="token-46-31" pos="word" morph="none" start_char="5832" end_char="5834">the</TOKEN>
<TOKEN id="token-46-32" pos="word" morph="none" start_char="5836" end_char="5840">first</TOKEN>
<TOKEN id="token-46-33" pos="word" morph="none" start_char="5842" end_char="5850">infection</TOKEN>
<TOKEN id="token-46-34" pos="word" morph="none" start_char="5852" end_char="5859">occurred</TOKEN>
<TOKEN id="token-46-35" pos="punct" morph="none" start_char="5860" end_char="5860">.</TOKEN>
</SEG>
<SEG id="segment-47" start_char="5863" end_char="5986">
<ORIGINAL_TEXT>That has led rise to intense speculation and founded many conspiracy theories, none of which have so far been substantiated.</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="5863" end_char="5866">That</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="5868" end_char="5870">has</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="5872" end_char="5874">led</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="5876" end_char="5879">rise</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="5881" end_char="5882">to</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="5884" end_char="5890">intense</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="5892" end_char="5902">speculation</TOKEN>
<TOKEN id="token-47-7" pos="word" morph="none" start_char="5904" end_char="5906">and</TOKEN>
<TOKEN id="token-47-8" pos="word" morph="none" start_char="5908" end_char="5914">founded</TOKEN>
<TOKEN id="token-47-9" pos="word" morph="none" start_char="5916" end_char="5919">many</TOKEN>
<TOKEN id="token-47-10" pos="word" morph="none" start_char="5921" end_char="5930">conspiracy</TOKEN>
<TOKEN id="token-47-11" pos="word" morph="none" start_char="5932" end_char="5939">theories</TOKEN>
<TOKEN id="token-47-12" pos="punct" morph="none" start_char="5940" end_char="5940">,</TOKEN>
<TOKEN id="token-47-13" pos="word" morph="none" start_char="5942" end_char="5945">none</TOKEN>
<TOKEN id="token-47-14" pos="word" morph="none" start_char="5947" end_char="5948">of</TOKEN>
<TOKEN id="token-47-15" pos="word" morph="none" start_char="5950" end_char="5954">which</TOKEN>
<TOKEN id="token-47-16" pos="word" morph="none" start_char="5956" end_char="5959">have</TOKEN>
<TOKEN id="token-47-17" pos="word" morph="none" start_char="5961" end_char="5962">so</TOKEN>
<TOKEN id="token-47-18" pos="word" morph="none" start_char="5964" end_char="5966">far</TOKEN>
<TOKEN id="token-47-19" pos="word" morph="none" start_char="5968" end_char="5971">been</TOKEN>
<TOKEN id="token-47-20" pos="word" morph="none" start_char="5973" end_char="5985">substantiated</TOKEN>
<TOKEN id="token-47-21" pos="punct" morph="none" start_char="5986" end_char="5986">.</TOKEN>
</SEG>
<SEG id="segment-48" start_char="5989" end_char="6129">
<ORIGINAL_TEXT>The World Health Organisation, under pressure because of its own response to the pandemic, has sent a 10-person team to China to investigate.</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="5989" end_char="5991">The</TOKEN>
<TOKEN id="token-48-1" pos="word" morph="none" start_char="5993" end_char="5997">World</TOKEN>
<TOKEN id="token-48-2" pos="word" morph="none" start_char="5999" end_char="6004">Health</TOKEN>
<TOKEN id="token-48-3" pos="word" morph="none" start_char="6006" end_char="6017">Organisation</TOKEN>
<TOKEN id="token-48-4" pos="punct" morph="none" start_char="6018" end_char="6018">,</TOKEN>
<TOKEN id="token-48-5" pos="word" morph="none" start_char="6020" end_char="6024">under</TOKEN>
<TOKEN id="token-48-6" pos="word" morph="none" start_char="6026" end_char="6033">pressure</TOKEN>
<TOKEN id="token-48-7" pos="word" morph="none" start_char="6035" end_char="6041">because</TOKEN>
<TOKEN id="token-48-8" pos="word" morph="none" start_char="6043" end_char="6044">of</TOKEN>
<TOKEN id="token-48-9" pos="word" morph="none" start_char="6046" end_char="6048">its</TOKEN>
<TOKEN id="token-48-10" pos="word" morph="none" start_char="6050" end_char="6052">own</TOKEN>
<TOKEN id="token-48-11" pos="word" morph="none" start_char="6054" end_char="6061">response</TOKEN>
<TOKEN id="token-48-12" pos="word" morph="none" start_char="6063" end_char="6064">to</TOKEN>
<TOKEN id="token-48-13" pos="word" morph="none" start_char="6066" end_char="6068">the</TOKEN>
<TOKEN id="token-48-14" pos="word" morph="none" start_char="6070" end_char="6077">pandemic</TOKEN>
<TOKEN id="token-48-15" pos="punct" morph="none" start_char="6078" end_char="6078">,</TOKEN>
<TOKEN id="token-48-16" pos="word" morph="none" start_char="6080" end_char="6082">has</TOKEN>
<TOKEN id="token-48-17" pos="word" morph="none" start_char="6084" end_char="6087">sent</TOKEN>
<TOKEN id="token-48-18" pos="word" morph="none" start_char="6089" end_char="6089">a</TOKEN>
<TOKEN id="token-48-19" pos="unknown" morph="none" start_char="6091" end_char="6099">10-person</TOKEN>
<TOKEN id="token-48-20" pos="word" morph="none" start_char="6101" end_char="6104">team</TOKEN>
<TOKEN id="token-48-21" pos="word" morph="none" start_char="6106" end_char="6107">to</TOKEN>
<TOKEN id="token-48-22" pos="word" morph="none" start_char="6109" end_char="6113">China</TOKEN>
<TOKEN id="token-48-23" pos="word" morph="none" start_char="6115" end_char="6116">to</TOKEN>
<TOKEN id="token-48-24" pos="word" morph="none" start_char="6118" end_char="6128">investigate</TOKEN>
<TOKEN id="token-48-25" pos="punct" morph="none" start_char="6129" end_char="6129">.</TOKEN>
</SEG>
<SEG id="segment-49" start_char="6132" end_char="6279">
<ORIGINAL_TEXT>While the team admit it is possible that the virus originated outside of the country, their initial searches are all focused within China's borders.</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="6132" end_char="6136">While</TOKEN>
<TOKEN id="token-49-1" pos="word" morph="none" start_char="6138" end_char="6140">the</TOKEN>
<TOKEN id="token-49-2" pos="word" morph="none" start_char="6142" end_char="6145">team</TOKEN>
<TOKEN id="token-49-3" pos="word" morph="none" start_char="6147" end_char="6151">admit</TOKEN>
<TOKEN id="token-49-4" pos="word" morph="none" start_char="6153" end_char="6154">it</TOKEN>
<TOKEN id="token-49-5" pos="word" morph="none" start_char="6156" end_char="6157">is</TOKEN>
<TOKEN id="token-49-6" pos="word" morph="none" start_char="6159" end_char="6166">possible</TOKEN>
<TOKEN id="token-49-7" pos="word" morph="none" start_char="6168" end_char="6171">that</TOKEN>
<TOKEN id="token-49-8" pos="word" morph="none" start_char="6173" end_char="6175">the</TOKEN>
<TOKEN id="token-49-9" pos="word" morph="none" start_char="6177" end_char="6181">virus</TOKEN>
<TOKEN id="token-49-10" pos="word" morph="none" start_char="6183" end_char="6192">originated</TOKEN>
<TOKEN id="token-49-11" pos="word" morph="none" start_char="6194" end_char="6200">outside</TOKEN>
<TOKEN id="token-49-12" pos="word" morph="none" start_char="6202" end_char="6203">of</TOKEN>
<TOKEN id="token-49-13" pos="word" morph="none" start_char="6205" end_char="6207">the</TOKEN>
<TOKEN id="token-49-14" pos="word" morph="none" start_char="6209" end_char="6215">country</TOKEN>
<TOKEN id="token-49-15" pos="punct" morph="none" start_char="6216" end_char="6216">,</TOKEN>
<TOKEN id="token-49-16" pos="word" morph="none" start_char="6218" end_char="6222">their</TOKEN>
<TOKEN id="token-49-17" pos="word" morph="none" start_char="6224" end_char="6230">initial</TOKEN>
<TOKEN id="token-49-18" pos="word" morph="none" start_char="6232" end_char="6239">searches</TOKEN>
<TOKEN id="token-49-19" pos="word" morph="none" start_char="6241" end_char="6243">are</TOKEN>
<TOKEN id="token-49-20" pos="word" morph="none" start_char="6245" end_char="6247">all</TOKEN>
<TOKEN id="token-49-21" pos="word" morph="none" start_char="6249" end_char="6255">focused</TOKEN>
<TOKEN id="token-49-22" pos="word" morph="none" start_char="6257" end_char="6262">within</TOKEN>
<TOKEN id="token-49-23" pos="word" morph="none" start_char="6264" end_char="6270">China's</TOKEN>
<TOKEN id="token-49-24" pos="word" morph="none" start_char="6272" end_char="6278">borders</TOKEN>
<TOKEN id="token-49-25" pos="punct" morph="none" start_char="6279" end_char="6279">.</TOKEN>
</SEG>
<SEG id="segment-50" start_char="6282" end_char="6438">
<ORIGINAL_TEXT>The UN agency has tried to temper expectations ahead of the investigation, warning that tracking any new pathogen is a 'riddle that can take years to solve'.</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="6282" end_char="6284">The</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="6286" end_char="6287">UN</TOKEN>
<TOKEN id="token-50-2" pos="word" morph="none" start_char="6289" end_char="6294">agency</TOKEN>
<TOKEN id="token-50-3" pos="word" morph="none" start_char="6296" end_char="6298">has</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="6300" end_char="6304">tried</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="6306" end_char="6307">to</TOKEN>
<TOKEN id="token-50-6" pos="word" morph="none" start_char="6309" end_char="6314">temper</TOKEN>
<TOKEN id="token-50-7" pos="word" morph="none" start_char="6316" end_char="6327">expectations</TOKEN>
<TOKEN id="token-50-8" pos="word" morph="none" start_char="6329" end_char="6333">ahead</TOKEN>
<TOKEN id="token-50-9" pos="word" morph="none" start_char="6335" end_char="6336">of</TOKEN>
<TOKEN id="token-50-10" pos="word" morph="none" start_char="6338" end_char="6340">the</TOKEN>
<TOKEN id="token-50-11" pos="word" morph="none" start_char="6342" end_char="6354">investigation</TOKEN>
<TOKEN id="token-50-12" pos="punct" morph="none" start_char="6355" end_char="6355">,</TOKEN>
<TOKEN id="token-50-13" pos="word" morph="none" start_char="6357" end_char="6363">warning</TOKEN>
<TOKEN id="token-50-14" pos="word" morph="none" start_char="6365" end_char="6368">that</TOKEN>
<TOKEN id="token-50-15" pos="word" morph="none" start_char="6370" end_char="6377">tracking</TOKEN>
<TOKEN id="token-50-16" pos="word" morph="none" start_char="6379" end_char="6381">any</TOKEN>
<TOKEN id="token-50-17" pos="word" morph="none" start_char="6383" end_char="6385">new</TOKEN>
<TOKEN id="token-50-18" pos="word" morph="none" start_char="6387" end_char="6394">pathogen</TOKEN>
<TOKEN id="token-50-19" pos="word" morph="none" start_char="6396" end_char="6397">is</TOKEN>
<TOKEN id="token-50-20" pos="word" morph="none" start_char="6399" end_char="6399">a</TOKEN>
<TOKEN id="token-50-21" pos="punct" morph="none" start_char="6401" end_char="6401">'</TOKEN>
<TOKEN id="token-50-22" pos="word" morph="none" start_char="6402" end_char="6407">riddle</TOKEN>
<TOKEN id="token-50-23" pos="word" morph="none" start_char="6409" end_char="6412">that</TOKEN>
<TOKEN id="token-50-24" pos="word" morph="none" start_char="6414" end_char="6416">can</TOKEN>
<TOKEN id="token-50-25" pos="word" morph="none" start_char="6418" end_char="6421">take</TOKEN>
<TOKEN id="token-50-26" pos="word" morph="none" start_char="6423" end_char="6427">years</TOKEN>
<TOKEN id="token-50-27" pos="word" morph="none" start_char="6429" end_char="6430">to</TOKEN>
<TOKEN id="token-50-28" pos="word" morph="none" start_char="6432" end_char="6436">solve</TOKEN>
<TOKEN id="token-50-29" pos="punct" morph="none" start_char="6437" end_char="6438">'.</TOKEN>
</SEG>
<SEG id="segment-51" start_char="6441" end_char="6638">
<ORIGINAL_TEXT>It took more than a year for scientists to prove MERS, another coronavirus, originated in camels in Saudi Arabia, and even longer to trace the original SARS back to bats in a cave in southern China.</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="word" morph="none" start_char="6441" end_char="6442">It</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="6444" end_char="6447">took</TOKEN>
<TOKEN id="token-51-2" pos="word" morph="none" start_char="6449" end_char="6452">more</TOKEN>
<TOKEN id="token-51-3" pos="word" morph="none" start_char="6454" end_char="6457">than</TOKEN>
<TOKEN id="token-51-4" pos="word" morph="none" start_char="6459" end_char="6459">a</TOKEN>
<TOKEN id="token-51-5" pos="word" morph="none" start_char="6461" end_char="6464">year</TOKEN>
<TOKEN id="token-51-6" pos="word" morph="none" start_char="6466" end_char="6468">for</TOKEN>
<TOKEN id="token-51-7" pos="word" morph="none" start_char="6470" end_char="6479">scientists</TOKEN>
<TOKEN id="token-51-8" pos="word" morph="none" start_char="6481" end_char="6482">to</TOKEN>
<TOKEN id="token-51-9" pos="word" morph="none" start_char="6484" end_char="6488">prove</TOKEN>
<TOKEN id="token-51-10" pos="word" morph="none" start_char="6490" end_char="6493">MERS</TOKEN>
<TOKEN id="token-51-11" pos="punct" morph="none" start_char="6494" end_char="6494">,</TOKEN>
<TOKEN id="token-51-12" pos="word" morph="none" start_char="6496" end_char="6502">another</TOKEN>
<TOKEN id="token-51-13" pos="word" morph="none" start_char="6504" end_char="6514">coronavirus</TOKEN>
<TOKEN id="token-51-14" pos="punct" morph="none" start_char="6515" end_char="6515">,</TOKEN>
<TOKEN id="token-51-15" pos="word" morph="none" start_char="6517" end_char="6526">originated</TOKEN>
<TOKEN id="token-51-16" pos="word" morph="none" start_char="6528" end_char="6529">in</TOKEN>
<TOKEN id="token-51-17" pos="word" morph="none" start_char="6531" end_char="6536">camels</TOKEN>
<TOKEN id="token-51-18" pos="word" morph="none" start_char="6538" end_char="6539">in</TOKEN>
<TOKEN id="token-51-19" pos="word" morph="none" start_char="6541" end_char="6545">Saudi</TOKEN>
<TOKEN id="token-51-20" pos="word" morph="none" start_char="6547" end_char="6552">Arabia</TOKEN>
<TOKEN id="token-51-21" pos="punct" morph="none" start_char="6553" end_char="6553">,</TOKEN>
<TOKEN id="token-51-22" pos="word" morph="none" start_char="6555" end_char="6557">and</TOKEN>
<TOKEN id="token-51-23" pos="word" morph="none" start_char="6559" end_char="6562">even</TOKEN>
<TOKEN id="token-51-24" pos="word" morph="none" start_char="6564" end_char="6569">longer</TOKEN>
<TOKEN id="token-51-25" pos="word" morph="none" start_char="6571" end_char="6572">to</TOKEN>
<TOKEN id="token-51-26" pos="word" morph="none" start_char="6574" end_char="6578">trace</TOKEN>
<TOKEN id="token-51-27" pos="word" morph="none" start_char="6580" end_char="6582">the</TOKEN>
<TOKEN id="token-51-28" pos="word" morph="none" start_char="6584" end_char="6591">original</TOKEN>
<TOKEN id="token-51-29" pos="word" morph="none" start_char="6593" end_char="6596">SARS</TOKEN>
<TOKEN id="token-51-30" pos="word" morph="none" start_char="6598" end_char="6601">back</TOKEN>
<TOKEN id="token-51-31" pos="word" morph="none" start_char="6603" end_char="6604">to</TOKEN>
<TOKEN id="token-51-32" pos="word" morph="none" start_char="6606" end_char="6609">bats</TOKEN>
<TOKEN id="token-51-33" pos="word" morph="none" start_char="6611" end_char="6612">in</TOKEN>
<TOKEN id="token-51-34" pos="word" morph="none" start_char="6614" end_char="6614">a</TOKEN>
<TOKEN id="token-51-35" pos="word" morph="none" start_char="6616" end_char="6619">cave</TOKEN>
<TOKEN id="token-51-36" pos="word" morph="none" start_char="6621" end_char="6622">in</TOKEN>
<TOKEN id="token-51-37" pos="word" morph="none" start_char="6624" end_char="6631">southern</TOKEN>
<TOKEN id="token-51-38" pos="word" morph="none" start_char="6633" end_char="6637">China</TOKEN>
<TOKEN id="token-51-39" pos="punct" morph="none" start_char="6638" end_char="6638">.</TOKEN>
</SEG>
<SEG id="segment-52" start_char="6641" end_char="6762">
<ORIGINAL_TEXT>The Chinese paper was also published shortly before the WHO released the details of scientists leading the probe in China.</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="6641" end_char="6643">The</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="6645" end_char="6651">Chinese</TOKEN>
<TOKEN id="token-52-2" pos="word" morph="none" start_char="6653" end_char="6657">paper</TOKEN>
<TOKEN id="token-52-3" pos="word" morph="none" start_char="6659" end_char="6661">was</TOKEN>
<TOKEN id="token-52-4" pos="word" morph="none" start_char="6663" end_char="6666">also</TOKEN>
<TOKEN id="token-52-5" pos="word" morph="none" start_char="6668" end_char="6676">published</TOKEN>
<TOKEN id="token-52-6" pos="word" morph="none" start_char="6678" end_char="6684">shortly</TOKEN>
<TOKEN id="token-52-7" pos="word" morph="none" start_char="6686" end_char="6691">before</TOKEN>
<TOKEN id="token-52-8" pos="word" morph="none" start_char="6693" end_char="6695">the</TOKEN>
<TOKEN id="token-52-9" pos="word" morph="none" start_char="6697" end_char="6699">WHO</TOKEN>
<TOKEN id="token-52-10" pos="word" morph="none" start_char="6701" end_char="6708">released</TOKEN>
<TOKEN id="token-52-11" pos="word" morph="none" start_char="6710" end_char="6712">the</TOKEN>
<TOKEN id="token-52-12" pos="word" morph="none" start_char="6714" end_char="6720">details</TOKEN>
<TOKEN id="token-52-13" pos="word" morph="none" start_char="6722" end_char="6723">of</TOKEN>
<TOKEN id="token-52-14" pos="word" morph="none" start_char="6725" end_char="6734">scientists</TOKEN>
<TOKEN id="token-52-15" pos="word" morph="none" start_char="6736" end_char="6742">leading</TOKEN>
<TOKEN id="token-52-16" pos="word" morph="none" start_char="6744" end_char="6746">the</TOKEN>
<TOKEN id="token-52-17" pos="word" morph="none" start_char="6748" end_char="6752">probe</TOKEN>
<TOKEN id="token-52-18" pos="word" morph="none" start_char="6754" end_char="6755">in</TOKEN>
<TOKEN id="token-52-19" pos="word" morph="none" start_char="6757" end_char="6761">China</TOKEN>
<TOKEN id="token-52-20" pos="punct" morph="none" start_char="6762" end_char="6762">.</TOKEN>
</SEG>
<SEG id="segment-53" start_char="6765" end_char="6883">
<ORIGINAL_TEXT>The great cover-up of China: Beijing punished Covid whistleblower and claimed it came from US - so what CAN we believe?</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="word" morph="none" start_char="6765" end_char="6767">The</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="6769" end_char="6773">great</TOKEN>
<TOKEN id="token-53-2" pos="unknown" morph="none" start_char="6775" end_char="6782">cover-up</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="6784" end_char="6785">of</TOKEN>
<TOKEN id="token-53-4" pos="word" morph="none" start_char="6787" end_char="6791">China</TOKEN>
<TOKEN id="token-53-5" pos="punct" morph="none" start_char="6792" end_char="6792">:</TOKEN>
<TOKEN id="token-53-6" pos="word" morph="none" start_char="6794" end_char="6800">Beijing</TOKEN>
<TOKEN id="token-53-7" pos="word" morph="none" start_char="6802" end_char="6809">punished</TOKEN>
<TOKEN id="token-53-8" pos="word" morph="none" start_char="6811" end_char="6815">Covid</TOKEN>
<TOKEN id="token-53-9" pos="word" morph="none" start_char="6817" end_char="6829">whistleblower</TOKEN>
<TOKEN id="token-53-10" pos="word" morph="none" start_char="6831" end_char="6833">and</TOKEN>
<TOKEN id="token-53-11" pos="word" morph="none" start_char="6835" end_char="6841">claimed</TOKEN>
<TOKEN id="token-53-12" pos="word" morph="none" start_char="6843" end_char="6844">it</TOKEN>
<TOKEN id="token-53-13" pos="word" morph="none" start_char="6846" end_char="6849">came</TOKEN>
<TOKEN id="token-53-14" pos="word" morph="none" start_char="6851" end_char="6854">from</TOKEN>
<TOKEN id="token-53-15" pos="word" morph="none" start_char="6856" end_char="6857">US</TOKEN>
<TOKEN id="token-53-16" pos="punct" morph="none" start_char="6859" end_char="6859">-</TOKEN>
<TOKEN id="token-53-17" pos="word" morph="none" start_char="6861" end_char="6862">so</TOKEN>
<TOKEN id="token-53-18" pos="word" morph="none" start_char="6864" end_char="6867">what</TOKEN>
<TOKEN id="token-53-19" pos="word" morph="none" start_char="6869" end_char="6871">CAN</TOKEN>
<TOKEN id="token-53-20" pos="word" morph="none" start_char="6873" end_char="6874">we</TOKEN>
<TOKEN id="token-53-21" pos="word" morph="none" start_char="6876" end_char="6882">believe</TOKEN>
<TOKEN id="token-53-22" pos="punct" morph="none" start_char="6883" end_char="6883">?</TOKEN>
</SEG>
<SEG id="segment-54" start_char="6886" end_char="6901">
<ORIGINAL_TEXT>Initial outbreak</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="word" morph="none" start_char="6886" end_char="6892">Initial</TOKEN>
<TOKEN id="token-54-1" pos="word" morph="none" start_char="6894" end_char="6901">outbreak</TOKEN>
</SEG>
<SEG id="segment-55" start_char="6904" end_char="7066">
<ORIGINAL_TEXT>Doctors in China, including Li Wenliang, began reporting the existence of a new type of respiratory infection that was similar to SARS in early December last year.</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="word" morph="none" start_char="6904" end_char="6910">Doctors</TOKEN>
<TOKEN id="token-55-1" pos="word" morph="none" start_char="6912" end_char="6913">in</TOKEN>
<TOKEN id="token-55-2" pos="word" morph="none" start_char="6915" end_char="6919">China</TOKEN>
<TOKEN id="token-55-3" pos="punct" morph="none" start_char="6920" end_char="6920">,</TOKEN>
<TOKEN id="token-55-4" pos="word" morph="none" start_char="6922" end_char="6930">including</TOKEN>
<TOKEN id="token-55-5" pos="word" morph="none" start_char="6932" end_char="6933">Li</TOKEN>
<TOKEN id="token-55-6" pos="word" morph="none" start_char="6935" end_char="6942">Wenliang</TOKEN>
<TOKEN id="token-55-7" pos="punct" morph="none" start_char="6943" end_char="6943">,</TOKEN>
<TOKEN id="token-55-8" pos="word" morph="none" start_char="6945" end_char="6949">began</TOKEN>
<TOKEN id="token-55-9" pos="word" morph="none" start_char="6951" end_char="6959">reporting</TOKEN>
<TOKEN id="token-55-10" pos="word" morph="none" start_char="6961" end_char="6963">the</TOKEN>
<TOKEN id="token-55-11" pos="word" morph="none" start_char="6965" end_char="6973">existence</TOKEN>
<TOKEN id="token-55-12" pos="word" morph="none" start_char="6975" end_char="6976">of</TOKEN>
<TOKEN id="token-55-13" pos="word" morph="none" start_char="6978" end_char="6978">a</TOKEN>
<TOKEN id="token-55-14" pos="word" morph="none" start_char="6980" end_char="6982">new</TOKEN>
<TOKEN id="token-55-15" pos="word" morph="none" start_char="6984" end_char="6987">type</TOKEN>
<TOKEN id="token-55-16" pos="word" morph="none" start_char="6989" end_char="6990">of</TOKEN>
<TOKEN id="token-55-17" pos="word" morph="none" start_char="6992" end_char="7002">respiratory</TOKEN>
<TOKEN id="token-55-18" pos="word" morph="none" start_char="7004" end_char="7012">infection</TOKEN>
<TOKEN id="token-55-19" pos="word" morph="none" start_char="7014" end_char="7017">that</TOKEN>
<TOKEN id="token-55-20" pos="word" morph="none" start_char="7019" end_char="7021">was</TOKEN>
<TOKEN id="token-55-21" pos="word" morph="none" start_char="7023" end_char="7029">similar</TOKEN>
<TOKEN id="token-55-22" pos="word" morph="none" start_char="7031" end_char="7032">to</TOKEN>
<TOKEN id="token-55-23" pos="word" morph="none" start_char="7034" end_char="7037">SARS</TOKEN>
<TOKEN id="token-55-24" pos="word" morph="none" start_char="7039" end_char="7040">in</TOKEN>
<TOKEN id="token-55-25" pos="word" morph="none" start_char="7042" end_char="7046">early</TOKEN>
<TOKEN id="token-55-26" pos="word" morph="none" start_char="7048" end_char="7055">December</TOKEN>
<TOKEN id="token-55-27" pos="word" morph="none" start_char="7057" end_char="7060">last</TOKEN>
<TOKEN id="token-55-28" pos="word" morph="none" start_char="7062" end_char="7065">year</TOKEN>
<TOKEN id="token-55-29" pos="punct" morph="none" start_char="7066" end_char="7066">.</TOKEN>
</SEG>
<SEG id="segment-56" start_char="7069" end_char="7249">
<ORIGINAL_TEXT>But rather than publicise the reports and warn the public, Chinese police hauled Wenliang and eight of his colleagues who had been posting about the virus online in for questioning.</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="7069" end_char="7071">But</TOKEN>
<TOKEN id="token-56-1" pos="word" morph="none" start_char="7073" end_char="7078">rather</TOKEN>
<TOKEN id="token-56-2" pos="word" morph="none" start_char="7080" end_char="7083">than</TOKEN>
<TOKEN id="token-56-3" pos="word" morph="none" start_char="7085" end_char="7093">publicise</TOKEN>
<TOKEN id="token-56-4" pos="word" morph="none" start_char="7095" end_char="7097">the</TOKEN>
<TOKEN id="token-56-5" pos="word" morph="none" start_char="7099" end_char="7105">reports</TOKEN>
<TOKEN id="token-56-6" pos="word" morph="none" start_char="7107" end_char="7109">and</TOKEN>
<TOKEN id="token-56-7" pos="word" morph="none" start_char="7111" end_char="7114">warn</TOKEN>
<TOKEN id="token-56-8" pos="word" morph="none" start_char="7116" end_char="7118">the</TOKEN>
<TOKEN id="token-56-9" pos="word" morph="none" start_char="7120" end_char="7125">public</TOKEN>
<TOKEN id="token-56-10" pos="punct" morph="none" start_char="7126" end_char="7126">,</TOKEN>
<TOKEN id="token-56-11" pos="word" morph="none" start_char="7128" end_char="7134">Chinese</TOKEN>
<TOKEN id="token-56-12" pos="word" morph="none" start_char="7136" end_char="7141">police</TOKEN>
<TOKEN id="token-56-13" pos="word" morph="none" start_char="7143" end_char="7148">hauled</TOKEN>
<TOKEN id="token-56-14" pos="word" morph="none" start_char="7150" end_char="7157">Wenliang</TOKEN>
<TOKEN id="token-56-15" pos="word" morph="none" start_char="7159" end_char="7161">and</TOKEN>
<TOKEN id="token-56-16" pos="word" morph="none" start_char="7163" end_char="7167">eight</TOKEN>
<TOKEN id="token-56-17" pos="word" morph="none" start_char="7169" end_char="7170">of</TOKEN>
<TOKEN id="token-56-18" pos="word" morph="none" start_char="7172" end_char="7174">his</TOKEN>
<TOKEN id="token-56-19" pos="word" morph="none" start_char="7176" end_char="7185">colleagues</TOKEN>
<TOKEN id="token-56-20" pos="word" morph="none" start_char="7187" end_char="7189">who</TOKEN>
<TOKEN id="token-56-21" pos="word" morph="none" start_char="7191" end_char="7193">had</TOKEN>
<TOKEN id="token-56-22" pos="word" morph="none" start_char="7195" end_char="7198">been</TOKEN>
<TOKEN id="token-56-23" pos="word" morph="none" start_char="7200" end_char="7206">posting</TOKEN>
<TOKEN id="token-56-24" pos="word" morph="none" start_char="7208" end_char="7212">about</TOKEN>
<TOKEN id="token-56-25" pos="word" morph="none" start_char="7214" end_char="7216">the</TOKEN>
<TOKEN id="token-56-26" pos="word" morph="none" start_char="7218" end_char="7222">virus</TOKEN>
<TOKEN id="token-56-27" pos="word" morph="none" start_char="7224" end_char="7229">online</TOKEN>
<TOKEN id="token-56-28" pos="word" morph="none" start_char="7231" end_char="7232">in</TOKEN>
<TOKEN id="token-56-29" pos="word" morph="none" start_char="7234" end_char="7236">for</TOKEN>
<TOKEN id="token-56-30" pos="word" morph="none" start_char="7238" end_char="7248">questioning</TOKEN>
<TOKEN id="token-56-31" pos="punct" morph="none" start_char="7249" end_char="7249">.</TOKEN>
</SEG>
<SEG id="segment-57" start_char="7252" end_char="7376">
<ORIGINAL_TEXT>Wenliang, who would later die from the virus, was forced to sign a document admitting the information he published was false.</ORIGINAL_TEXT>
<TOKEN id="token-57-0" pos="word" morph="none" start_char="7252" end_char="7259">Wenliang</TOKEN>
<TOKEN id="token-57-1" pos="punct" morph="none" start_char="7260" end_char="7260">,</TOKEN>
<TOKEN id="token-57-2" pos="word" morph="none" start_char="7262" end_char="7264">who</TOKEN>
<TOKEN id="token-57-3" pos="word" morph="none" start_char="7266" end_char="7270">would</TOKEN>
<TOKEN id="token-57-4" pos="word" morph="none" start_char="7272" end_char="7276">later</TOKEN>
<TOKEN id="token-57-5" pos="word" morph="none" start_char="7278" end_char="7280">die</TOKEN>
<TOKEN id="token-57-6" pos="word" morph="none" start_char="7282" end_char="7285">from</TOKEN>
<TOKEN id="token-57-7" pos="word" morph="none" start_char="7287" end_char="7289">the</TOKEN>
<TOKEN id="token-57-8" pos="word" morph="none" start_char="7291" end_char="7295">virus</TOKEN>
<TOKEN id="token-57-9" pos="punct" morph="none" start_char="7296" end_char="7296">,</TOKEN>
<TOKEN id="token-57-10" pos="word" morph="none" start_char="7298" end_char="7300">was</TOKEN>
<TOKEN id="token-57-11" pos="word" morph="none" start_char="7302" end_char="7307">forced</TOKEN>
<TOKEN id="token-57-12" pos="word" morph="none" start_char="7309" end_char="7310">to</TOKEN>
<TOKEN id="token-57-13" pos="word" morph="none" start_char="7312" end_char="7315">sign</TOKEN>
<TOKEN id="token-57-14" pos="word" morph="none" start_char="7317" end_char="7317">a</TOKEN>
<TOKEN id="token-57-15" pos="word" morph="none" start_char="7319" end_char="7326">document</TOKEN>
<TOKEN id="token-57-16" pos="word" morph="none" start_char="7328" end_char="7336">admitting</TOKEN>
<TOKEN id="token-57-17" pos="word" morph="none" start_char="7338" end_char="7340">the</TOKEN>
<TOKEN id="token-57-18" pos="word" morph="none" start_char="7342" end_char="7352">information</TOKEN>
<TOKEN id="token-57-19" pos="word" morph="none" start_char="7354" end_char="7355">he</TOKEN>
<TOKEN id="token-57-20" pos="word" morph="none" start_char="7357" end_char="7365">published</TOKEN>
<TOKEN id="token-57-21" pos="word" morph="none" start_char="7367" end_char="7369">was</TOKEN>
<TOKEN id="token-57-22" pos="word" morph="none" start_char="7371" end_char="7375">false</TOKEN>
<TOKEN id="token-57-23" pos="punct" morph="none" start_char="7376" end_char="7376">.</TOKEN>
</SEG>
<SEG id="segment-58" start_char="7379" end_char="7568">
<ORIGINAL_TEXT>While China has been widely-praised for a draconian lockdown that helped slow the spread of the virus, evidence suggests that the country could have acted much quicker to prevent the spread.</ORIGINAL_TEXT>
<TOKEN id="token-58-0" pos="word" morph="none" start_char="7379" end_char="7383">While</TOKEN>
<TOKEN id="token-58-1" pos="word" morph="none" start_char="7385" end_char="7389">China</TOKEN>
<TOKEN id="token-58-2" pos="word" morph="none" start_char="7391" end_char="7393">has</TOKEN>
<TOKEN id="token-58-3" pos="word" morph="none" start_char="7395" end_char="7398">been</TOKEN>
<TOKEN id="token-58-4" pos="unknown" morph="none" start_char="7400" end_char="7413">widely-praised</TOKEN>
<TOKEN id="token-58-5" pos="word" morph="none" start_char="7415" end_char="7417">for</TOKEN>
<TOKEN id="token-58-6" pos="word" morph="none" start_char="7419" end_char="7419">a</TOKEN>
<TOKEN id="token-58-7" pos="word" morph="none" start_char="7421" end_char="7429">draconian</TOKEN>
<TOKEN id="token-58-8" pos="word" morph="none" start_char="7431" end_char="7438">lockdown</TOKEN>
<TOKEN id="token-58-9" pos="word" morph="none" start_char="7440" end_char="7443">that</TOKEN>
<TOKEN id="token-58-10" pos="word" morph="none" start_char="7445" end_char="7450">helped</TOKEN>
<TOKEN id="token-58-11" pos="word" morph="none" start_char="7452" end_char="7455">slow</TOKEN>
<TOKEN id="token-58-12" pos="word" morph="none" start_char="7457" end_char="7459">the</TOKEN>
<TOKEN id="token-58-13" pos="word" morph="none" start_char="7461" end_char="7466">spread</TOKEN>
<TOKEN id="token-58-14" pos="word" morph="none" start_char="7468" end_char="7469">of</TOKEN>
<TOKEN id="token-58-15" pos="word" morph="none" start_char="7471" end_char="7473">the</TOKEN>
<TOKEN id="token-58-16" pos="word" morph="none" start_char="7475" end_char="7479">virus</TOKEN>
<TOKEN id="token-58-17" pos="punct" morph="none" start_char="7480" end_char="7480">,</TOKEN>
<TOKEN id="token-58-18" pos="word" morph="none" start_char="7482" end_char="7489">evidence</TOKEN>
<TOKEN id="token-58-19" pos="word" morph="none" start_char="7491" end_char="7498">suggests</TOKEN>
<TOKEN id="token-58-20" pos="word" morph="none" start_char="7500" end_char="7503">that</TOKEN>
<TOKEN id="token-58-21" pos="word" morph="none" start_char="7505" end_char="7507">the</TOKEN>
<TOKEN id="token-58-22" pos="word" morph="none" start_char="7509" end_char="7515">country</TOKEN>
<TOKEN id="token-58-23" pos="word" morph="none" start_char="7517" end_char="7521">could</TOKEN>
<TOKEN id="token-58-24" pos="word" morph="none" start_char="7523" end_char="7526">have</TOKEN>
<TOKEN id="token-58-25" pos="word" morph="none" start_char="7528" end_char="7532">acted</TOKEN>
<TOKEN id="token-58-26" pos="word" morph="none" start_char="7534" end_char="7537">much</TOKEN>
<TOKEN id="token-58-27" pos="word" morph="none" start_char="7539" end_char="7545">quicker</TOKEN>
<TOKEN id="token-58-28" pos="word" morph="none" start_char="7547" end_char="7548">to</TOKEN>
<TOKEN id="token-58-29" pos="word" morph="none" start_char="7550" end_char="7556">prevent</TOKEN>
<TOKEN id="token-58-30" pos="word" morph="none" start_char="7558" end_char="7560">the</TOKEN>
<TOKEN id="token-58-31" pos="word" morph="none" start_char="7562" end_char="7567">spread</TOKEN>
<TOKEN id="token-58-32" pos="punct" morph="none" start_char="7568" end_char="7568">.</TOKEN>
</SEG>
<SEG id="segment-59" start_char="7573" end_char="7724">
<ORIGINAL_TEXT>Dr Li Wenliang, one of the first Chinese medics to report the existence of the new coronavirus, was forced by police to confess to spreading false data.</ORIGINAL_TEXT>
<TOKEN id="token-59-0" pos="word" morph="none" start_char="7573" end_char="7574">Dr</TOKEN>
<TOKEN id="token-59-1" pos="word" morph="none" start_char="7576" end_char="7577">Li</TOKEN>
<TOKEN id="token-59-2" pos="word" morph="none" start_char="7579" end_char="7586">Wenliang</TOKEN>
<TOKEN id="token-59-3" pos="punct" morph="none" start_char="7587" end_char="7587">,</TOKEN>
<TOKEN id="token-59-4" pos="word" morph="none" start_char="7589" end_char="7591">one</TOKEN>
<TOKEN id="token-59-5" pos="word" morph="none" start_char="7593" end_char="7594">of</TOKEN>
<TOKEN id="token-59-6" pos="word" morph="none" start_char="7596" end_char="7598">the</TOKEN>
<TOKEN id="token-59-7" pos="word" morph="none" start_char="7600" end_char="7604">first</TOKEN>
<TOKEN id="token-59-8" pos="word" morph="none" start_char="7606" end_char="7612">Chinese</TOKEN>
<TOKEN id="token-59-9" pos="word" morph="none" start_char="7614" end_char="7619">medics</TOKEN>
<TOKEN id="token-59-10" pos="word" morph="none" start_char="7621" end_char="7622">to</TOKEN>
<TOKEN id="token-59-11" pos="word" morph="none" start_char="7624" end_char="7629">report</TOKEN>
<TOKEN id="token-59-12" pos="word" morph="none" start_char="7631" end_char="7633">the</TOKEN>
<TOKEN id="token-59-13" pos="word" morph="none" start_char="7635" end_char="7643">existence</TOKEN>
<TOKEN id="token-59-14" pos="word" morph="none" start_char="7645" end_char="7646">of</TOKEN>
<TOKEN id="token-59-15" pos="word" morph="none" start_char="7648" end_char="7650">the</TOKEN>
<TOKEN id="token-59-16" pos="word" morph="none" start_char="7652" end_char="7654">new</TOKEN>
<TOKEN id="token-59-17" pos="word" morph="none" start_char="7656" end_char="7666">coronavirus</TOKEN>
<TOKEN id="token-59-18" pos="punct" morph="none" start_char="7667" end_char="7667">,</TOKEN>
<TOKEN id="token-59-19" pos="word" morph="none" start_char="7669" end_char="7671">was</TOKEN>
<TOKEN id="token-59-20" pos="word" morph="none" start_char="7673" end_char="7678">forced</TOKEN>
<TOKEN id="token-59-21" pos="word" morph="none" start_char="7680" end_char="7681">by</TOKEN>
<TOKEN id="token-59-22" pos="word" morph="none" start_char="7683" end_char="7688">police</TOKEN>
<TOKEN id="token-59-23" pos="word" morph="none" start_char="7690" end_char="7691">to</TOKEN>
<TOKEN id="token-59-24" pos="word" morph="none" start_char="7693" end_char="7699">confess</TOKEN>
<TOKEN id="token-59-25" pos="word" morph="none" start_char="7701" end_char="7702">to</TOKEN>
<TOKEN id="token-59-26" pos="word" morph="none" start_char="7704" end_char="7712">spreading</TOKEN>
<TOKEN id="token-59-27" pos="word" morph="none" start_char="7714" end_char="7718">false</TOKEN>
<TOKEN id="token-59-28" pos="word" morph="none" start_char="7720" end_char="7723">data</TOKEN>
<TOKEN id="token-59-29" pos="punct" morph="none" start_char="7724" end_char="7724">.</TOKEN>
</SEG>
<SEG id="segment-60" start_char="7726" end_char="7753">
<ORIGINAL_TEXT>He later died from the virus</ORIGINAL_TEXT>
<TOKEN id="token-60-0" pos="word" morph="none" start_char="7726" end_char="7727">He</TOKEN>
<TOKEN id="token-60-1" pos="word" morph="none" start_char="7729" end_char="7733">later</TOKEN>
<TOKEN id="token-60-2" pos="word" morph="none" start_char="7735" end_char="7738">died</TOKEN>
<TOKEN id="token-60-3" pos="word" morph="none" start_char="7740" end_char="7743">from</TOKEN>
<TOKEN id="token-60-4" pos="word" morph="none" start_char="7745" end_char="7747">the</TOKEN>
<TOKEN id="token-60-5" pos="word" morph="none" start_char="7749" end_char="7753">virus</TOKEN>
</SEG>
<SEG id="segment-61" start_char="7756" end_char="7942">
<ORIGINAL_TEXT>Samples analysed as early as December 26 suggested a new type of SARS was circulating, the Washington Post reported, but Wuhan was not locked down until January 22 - almost a month later.</ORIGINAL_TEXT>
<TOKEN id="token-61-0" pos="word" morph="none" start_char="7756" end_char="7762">Samples</TOKEN>
<TOKEN id="token-61-1" pos="word" morph="none" start_char="7764" end_char="7771">analysed</TOKEN>
<TOKEN id="token-61-2" pos="word" morph="none" start_char="7773" end_char="7774">as</TOKEN>
<TOKEN id="token-61-3" pos="word" morph="none" start_char="7776" end_char="7780">early</TOKEN>
<TOKEN id="token-61-4" pos="word" morph="none" start_char="7782" end_char="7783">as</TOKEN>
<TOKEN id="token-61-5" pos="word" morph="none" start_char="7785" end_char="7792">December</TOKEN>
<TOKEN id="token-61-6" pos="word" morph="none" start_char="7794" end_char="7795">26</TOKEN>
<TOKEN id="token-61-7" pos="word" morph="none" start_char="7797" end_char="7805">suggested</TOKEN>
<TOKEN id="token-61-8" pos="word" morph="none" start_char="7807" end_char="7807">a</TOKEN>
<TOKEN id="token-61-9" pos="word" morph="none" start_char="7809" end_char="7811">new</TOKEN>
<TOKEN id="token-61-10" pos="word" morph="none" start_char="7813" end_char="7816">type</TOKEN>
<TOKEN id="token-61-11" pos="word" morph="none" start_char="7818" end_char="7819">of</TOKEN>
<TOKEN id="token-61-12" pos="word" morph="none" start_char="7821" end_char="7824">SARS</TOKEN>
<TOKEN id="token-61-13" pos="word" morph="none" start_char="7826" end_char="7828">was</TOKEN>
<TOKEN id="token-61-14" pos="word" morph="none" start_char="7830" end_char="7840">circulating</TOKEN>
<TOKEN id="token-61-15" pos="punct" morph="none" start_char="7841" end_char="7841">,</TOKEN>
<TOKEN id="token-61-16" pos="word" morph="none" start_char="7843" end_char="7845">the</TOKEN>
<TOKEN id="token-61-17" pos="word" morph="none" start_char="7847" end_char="7856">Washington</TOKEN>
<TOKEN id="token-61-18" pos="word" morph="none" start_char="7858" end_char="7861">Post</TOKEN>
<TOKEN id="token-61-19" pos="word" morph="none" start_char="7863" end_char="7870">reported</TOKEN>
<TOKEN id="token-61-20" pos="punct" morph="none" start_char="7871" end_char="7871">,</TOKEN>
<TOKEN id="token-61-21" pos="word" morph="none" start_char="7873" end_char="7875">but</TOKEN>
<TOKEN id="token-61-22" pos="word" morph="none" start_char="7877" end_char="7881">Wuhan</TOKEN>
<TOKEN id="token-61-23" pos="word" morph="none" start_char="7883" end_char="7885">was</TOKEN>
<TOKEN id="token-61-24" pos="word" morph="none" start_char="7887" end_char="7889">not</TOKEN>
<TOKEN id="token-61-25" pos="word" morph="none" start_char="7891" end_char="7896">locked</TOKEN>
<TOKEN id="token-61-26" pos="word" morph="none" start_char="7898" end_char="7901">down</TOKEN>
<TOKEN id="token-61-27" pos="word" morph="none" start_char="7903" end_char="7907">until</TOKEN>
<TOKEN id="token-61-28" pos="word" morph="none" start_char="7909" end_char="7915">January</TOKEN>
<TOKEN id="token-61-29" pos="word" morph="none" start_char="7917" end_char="7918">22</TOKEN>
<TOKEN id="token-61-30" pos="punct" morph="none" start_char="7920" end_char="7920">-</TOKEN>
<TOKEN id="token-61-31" pos="word" morph="none" start_char="7922" end_char="7927">almost</TOKEN>
<TOKEN id="token-61-32" pos="word" morph="none" start_char="7929" end_char="7929">a</TOKEN>
<TOKEN id="token-61-33" pos="word" morph="none" start_char="7931" end_char="7935">month</TOKEN>
<TOKEN id="token-61-34" pos="word" morph="none" start_char="7937" end_char="7941">later</TOKEN>
<TOKEN id="token-61-35" pos="punct" morph="none" start_char="7942" end_char="7942">.</TOKEN>
</SEG>
<SEG id="segment-62" start_char="7945" end_char="8142">
<ORIGINAL_TEXT>Wuhan's mayor also admitted an error that allowed 5million people to travel out of the city before the lockdown came into place without being checked for the virus, potentially helping it to spread.</ORIGINAL_TEXT>
<TOKEN id="token-62-0" pos="word" morph="none" start_char="7945" end_char="7951">Wuhan's</TOKEN>
<TOKEN id="token-62-1" pos="word" morph="none" start_char="7953" end_char="7957">mayor</TOKEN>
<TOKEN id="token-62-2" pos="word" morph="none" start_char="7959" end_char="7962">also</TOKEN>
<TOKEN id="token-62-3" pos="word" morph="none" start_char="7964" end_char="7971">admitted</TOKEN>
<TOKEN id="token-62-4" pos="word" morph="none" start_char="7973" end_char="7974">an</TOKEN>
<TOKEN id="token-62-5" pos="word" morph="none" start_char="7976" end_char="7980">error</TOKEN>
<TOKEN id="token-62-6" pos="word" morph="none" start_char="7982" end_char="7985">that</TOKEN>
<TOKEN id="token-62-7" pos="word" morph="none" start_char="7987" end_char="7993">allowed</TOKEN>
<TOKEN id="token-62-8" pos="word" morph="none" start_char="7995" end_char="8002">5million</TOKEN>
<TOKEN id="token-62-9" pos="word" morph="none" start_char="8004" end_char="8009">people</TOKEN>
<TOKEN id="token-62-10" pos="word" morph="none" start_char="8011" end_char="8012">to</TOKEN>
<TOKEN id="token-62-11" pos="word" morph="none" start_char="8014" end_char="8019">travel</TOKEN>
<TOKEN id="token-62-12" pos="word" morph="none" start_char="8021" end_char="8023">out</TOKEN>
<TOKEN id="token-62-13" pos="word" morph="none" start_char="8025" end_char="8026">of</TOKEN>
<TOKEN id="token-62-14" pos="word" morph="none" start_char="8028" end_char="8030">the</TOKEN>
<TOKEN id="token-62-15" pos="word" morph="none" start_char="8032" end_char="8035">city</TOKEN>
<TOKEN id="token-62-16" pos="word" morph="none" start_char="8037" end_char="8042">before</TOKEN>
<TOKEN id="token-62-17" pos="word" morph="none" start_char="8044" end_char="8046">the</TOKEN>
<TOKEN id="token-62-18" pos="word" morph="none" start_char="8048" end_char="8055">lockdown</TOKEN>
<TOKEN id="token-62-19" pos="word" morph="none" start_char="8057" end_char="8060">came</TOKEN>
<TOKEN id="token-62-20" pos="word" morph="none" start_char="8062" end_char="8065">into</TOKEN>
<TOKEN id="token-62-21" pos="word" morph="none" start_char="8067" end_char="8071">place</TOKEN>
<TOKEN id="token-62-22" pos="word" morph="none" start_char="8073" end_char="8079">without</TOKEN>
<TOKEN id="token-62-23" pos="word" morph="none" start_char="8081" end_char="8085">being</TOKEN>
<TOKEN id="token-62-24" pos="word" morph="none" start_char="8087" end_char="8093">checked</TOKEN>
<TOKEN id="token-62-25" pos="word" morph="none" start_char="8095" end_char="8097">for</TOKEN>
<TOKEN id="token-62-26" pos="word" morph="none" start_char="8099" end_char="8101">the</TOKEN>
<TOKEN id="token-62-27" pos="word" morph="none" start_char="8103" end_char="8107">virus</TOKEN>
<TOKEN id="token-62-28" pos="punct" morph="none" start_char="8108" end_char="8108">,</TOKEN>
<TOKEN id="token-62-29" pos="word" morph="none" start_char="8110" end_char="8120">potentially</TOKEN>
<TOKEN id="token-62-30" pos="word" morph="none" start_char="8122" end_char="8128">helping</TOKEN>
<TOKEN id="token-62-31" pos="word" morph="none" start_char="8130" end_char="8131">it</TOKEN>
<TOKEN id="token-62-32" pos="word" morph="none" start_char="8133" end_char="8134">to</TOKEN>
<TOKEN id="token-62-33" pos="word" morph="none" start_char="8136" end_char="8141">spread</TOKEN>
<TOKEN id="token-62-34" pos="punct" morph="none" start_char="8142" end_char="8142">.</TOKEN>
</SEG>
<SEG id="segment-63" start_char="8145" end_char="8302">
<ORIGINAL_TEXT>Chinese authorities have also been reluctant to had over information on the country's 'patient zero' - or the first person known to have contracted the virus.</ORIGINAL_TEXT>
<TOKEN id="token-63-0" pos="word" morph="none" start_char="8145" end_char="8151">Chinese</TOKEN>
<TOKEN id="token-63-1" pos="word" morph="none" start_char="8153" end_char="8163">authorities</TOKEN>
<TOKEN id="token-63-2" pos="word" morph="none" start_char="8165" end_char="8168">have</TOKEN>
<TOKEN id="token-63-3" pos="word" morph="none" start_char="8170" end_char="8173">also</TOKEN>
<TOKEN id="token-63-4" pos="word" morph="none" start_char="8175" end_char="8178">been</TOKEN>
<TOKEN id="token-63-5" pos="word" morph="none" start_char="8180" end_char="8188">reluctant</TOKEN>
<TOKEN id="token-63-6" pos="word" morph="none" start_char="8190" end_char="8191">to</TOKEN>
<TOKEN id="token-63-7" pos="word" morph="none" start_char="8193" end_char="8195">had</TOKEN>
<TOKEN id="token-63-8" pos="word" morph="none" start_char="8197" end_char="8200">over</TOKEN>
<TOKEN id="token-63-9" pos="word" morph="none" start_char="8202" end_char="8212">information</TOKEN>
<TOKEN id="token-63-10" pos="word" morph="none" start_char="8214" end_char="8215">on</TOKEN>
<TOKEN id="token-63-11" pos="word" morph="none" start_char="8217" end_char="8219">the</TOKEN>
<TOKEN id="token-63-12" pos="word" morph="none" start_char="8221" end_char="8229">country's</TOKEN>
<TOKEN id="token-63-13" pos="punct" morph="none" start_char="8231" end_char="8231">'</TOKEN>
<TOKEN id="token-63-14" pos="word" morph="none" start_char="8232" end_char="8238">patient</TOKEN>
<TOKEN id="token-63-15" pos="word" morph="none" start_char="8240" end_char="8243">zero</TOKEN>
<TOKEN id="token-63-16" pos="punct" morph="none" start_char="8244" end_char="8244">'</TOKEN>
<TOKEN id="token-63-17" pos="punct" morph="none" start_char="8246" end_char="8246">-</TOKEN>
<TOKEN id="token-63-18" pos="word" morph="none" start_char="8248" end_char="8249">or</TOKEN>
<TOKEN id="token-63-19" pos="word" morph="none" start_char="8251" end_char="8253">the</TOKEN>
<TOKEN id="token-63-20" pos="word" morph="none" start_char="8255" end_char="8259">first</TOKEN>
<TOKEN id="token-63-21" pos="word" morph="none" start_char="8261" end_char="8266">person</TOKEN>
<TOKEN id="token-63-22" pos="word" morph="none" start_char="8268" end_char="8272">known</TOKEN>
<TOKEN id="token-63-23" pos="word" morph="none" start_char="8274" end_char="8275">to</TOKEN>
<TOKEN id="token-63-24" pos="word" morph="none" start_char="8277" end_char="8280">have</TOKEN>
<TOKEN id="token-63-25" pos="word" morph="none" start_char="8282" end_char="8291">contracted</TOKEN>
<TOKEN id="token-63-26" pos="word" morph="none" start_char="8293" end_char="8295">the</TOKEN>
<TOKEN id="token-63-27" pos="word" morph="none" start_char="8297" end_char="8301">virus</TOKEN>
<TOKEN id="token-63-28" pos="punct" morph="none" start_char="8302" end_char="8302">.</TOKEN>
</SEG>
<SEG id="segment-64" start_char="8305" end_char="8494">
<ORIGINAL_TEXT>While Beijing claims the first infection took place on December 8, researchers have traced the virus back to at least December 1 and anecdotal evidence suggests it was spreading in November.</ORIGINAL_TEXT>
<TOKEN id="token-64-0" pos="word" morph="none" start_char="8305" end_char="8309">While</TOKEN>
<TOKEN id="token-64-1" pos="word" morph="none" start_char="8311" end_char="8317">Beijing</TOKEN>
<TOKEN id="token-64-2" pos="word" morph="none" start_char="8319" end_char="8324">claims</TOKEN>
<TOKEN id="token-64-3" pos="word" morph="none" start_char="8326" end_char="8328">the</TOKEN>
<TOKEN id="token-64-4" pos="word" morph="none" start_char="8330" end_char="8334">first</TOKEN>
<TOKEN id="token-64-5" pos="word" morph="none" start_char="8336" end_char="8344">infection</TOKEN>
<TOKEN id="token-64-6" pos="word" morph="none" start_char="8346" end_char="8349">took</TOKEN>
<TOKEN id="token-64-7" pos="word" morph="none" start_char="8351" end_char="8355">place</TOKEN>
<TOKEN id="token-64-8" pos="word" morph="none" start_char="8357" end_char="8358">on</TOKEN>
<TOKEN id="token-64-9" pos="word" morph="none" start_char="8360" end_char="8367">December</TOKEN>
<TOKEN id="token-64-10" pos="word" morph="none" start_char="8369" end_char="8369">8</TOKEN>
<TOKEN id="token-64-11" pos="punct" morph="none" start_char="8370" end_char="8370">,</TOKEN>
<TOKEN id="token-64-12" pos="word" morph="none" start_char="8372" end_char="8382">researchers</TOKEN>
<TOKEN id="token-64-13" pos="word" morph="none" start_char="8384" end_char="8387">have</TOKEN>
<TOKEN id="token-64-14" pos="word" morph="none" start_char="8389" end_char="8394">traced</TOKEN>
<TOKEN id="token-64-15" pos="word" morph="none" start_char="8396" end_char="8398">the</TOKEN>
<TOKEN id="token-64-16" pos="word" morph="none" start_char="8400" end_char="8404">virus</TOKEN>
<TOKEN id="token-64-17" pos="word" morph="none" start_char="8406" end_char="8409">back</TOKEN>
<TOKEN id="token-64-18" pos="word" morph="none" start_char="8411" end_char="8412">to</TOKEN>
<TOKEN id="token-64-19" pos="word" morph="none" start_char="8414" end_char="8415">at</TOKEN>
<TOKEN id="token-64-20" pos="word" morph="none" start_char="8417" end_char="8421">least</TOKEN>
<TOKEN id="token-64-21" pos="word" morph="none" start_char="8423" end_char="8430">December</TOKEN>
<TOKEN id="token-64-22" pos="word" morph="none" start_char="8432" end_char="8432">1</TOKEN>
<TOKEN id="token-64-23" pos="word" morph="none" start_char="8434" end_char="8436">and</TOKEN>
<TOKEN id="token-64-24" pos="word" morph="none" start_char="8438" end_char="8446">anecdotal</TOKEN>
<TOKEN id="token-64-25" pos="word" morph="none" start_char="8448" end_char="8455">evidence</TOKEN>
<TOKEN id="token-64-26" pos="word" morph="none" start_char="8457" end_char="8464">suggests</TOKEN>
<TOKEN id="token-64-27" pos="word" morph="none" start_char="8466" end_char="8467">it</TOKEN>
<TOKEN id="token-64-28" pos="word" morph="none" start_char="8469" end_char="8471">was</TOKEN>
<TOKEN id="token-64-29" pos="word" morph="none" start_char="8473" end_char="8481">spreading</TOKEN>
<TOKEN id="token-64-30" pos="word" morph="none" start_char="8483" end_char="8484">in</TOKEN>
<TOKEN id="token-64-31" pos="word" morph="none" start_char="8486" end_char="8493">November</TOKEN>
<TOKEN id="token-64-32" pos="punct" morph="none" start_char="8494" end_char="8494">.</TOKEN>
</SEG>
<SEG id="segment-65" start_char="8497" end_char="8636">
<ORIGINAL_TEXT>A lack of information about the first patient has meant scientists are still unclear how the disease made the leap from animals into humans.</ORIGINAL_TEXT>
<TOKEN id="token-65-0" pos="word" morph="none" start_char="8497" end_char="8497">A</TOKEN>
<TOKEN id="token-65-1" pos="word" morph="none" start_char="8499" end_char="8502">lack</TOKEN>
<TOKEN id="token-65-2" pos="word" morph="none" start_char="8504" end_char="8505">of</TOKEN>
<TOKEN id="token-65-3" pos="word" morph="none" start_char="8507" end_char="8517">information</TOKEN>
<TOKEN id="token-65-4" pos="word" morph="none" start_char="8519" end_char="8523">about</TOKEN>
<TOKEN id="token-65-5" pos="word" morph="none" start_char="8525" end_char="8527">the</TOKEN>
<TOKEN id="token-65-6" pos="word" morph="none" start_char="8529" end_char="8533">first</TOKEN>
<TOKEN id="token-65-7" pos="word" morph="none" start_char="8535" end_char="8541">patient</TOKEN>
<TOKEN id="token-65-8" pos="word" morph="none" start_char="8543" end_char="8545">has</TOKEN>
<TOKEN id="token-65-9" pos="word" morph="none" start_char="8547" end_char="8551">meant</TOKEN>
<TOKEN id="token-65-10" pos="word" morph="none" start_char="8553" end_char="8562">scientists</TOKEN>
<TOKEN id="token-65-11" pos="word" morph="none" start_char="8564" end_char="8566">are</TOKEN>
<TOKEN id="token-65-12" pos="word" morph="none" start_char="8568" end_char="8572">still</TOKEN>
<TOKEN id="token-65-13" pos="word" morph="none" start_char="8574" end_char="8580">unclear</TOKEN>
<TOKEN id="token-65-14" pos="word" morph="none" start_char="8582" end_char="8584">how</TOKEN>
<TOKEN id="token-65-15" pos="word" morph="none" start_char="8586" end_char="8588">the</TOKEN>
<TOKEN id="token-65-16" pos="word" morph="none" start_char="8590" end_char="8596">disease</TOKEN>
<TOKEN id="token-65-17" pos="word" morph="none" start_char="8598" end_char="8601">made</TOKEN>
<TOKEN id="token-65-18" pos="word" morph="none" start_char="8603" end_char="8605">the</TOKEN>
<TOKEN id="token-65-19" pos="word" morph="none" start_char="8607" end_char="8610">leap</TOKEN>
<TOKEN id="token-65-20" pos="word" morph="none" start_char="8612" end_char="8615">from</TOKEN>
<TOKEN id="token-65-21" pos="word" morph="none" start_char="8617" end_char="8623">animals</TOKEN>
<TOKEN id="token-65-22" pos="word" morph="none" start_char="8625" end_char="8628">into</TOKEN>
<TOKEN id="token-65-23" pos="word" morph="none" start_char="8630" end_char="8635">humans</TOKEN>
<TOKEN id="token-65-24" pos="punct" morph="none" start_char="8636" end_char="8636">.</TOKEN>
</SEG>
<SEG id="segment-66" start_char="8639" end_char="8802">
<ORIGINAL_TEXT>Theories include that it could have been carried by a bat or pangolin that was sold at a market in Wuhan and then eaten by someone, but this has not been confirmed.</ORIGINAL_TEXT>
<TOKEN id="token-66-0" pos="word" morph="none" start_char="8639" end_char="8646">Theories</TOKEN>
<TOKEN id="token-66-1" pos="word" morph="none" start_char="8648" end_char="8654">include</TOKEN>
<TOKEN id="token-66-2" pos="word" morph="none" start_char="8656" end_char="8659">that</TOKEN>
<TOKEN id="token-66-3" pos="word" morph="none" start_char="8661" end_char="8662">it</TOKEN>
<TOKEN id="token-66-4" pos="word" morph="none" start_char="8664" end_char="8668">could</TOKEN>
<TOKEN id="token-66-5" pos="word" morph="none" start_char="8670" end_char="8673">have</TOKEN>
<TOKEN id="token-66-6" pos="word" morph="none" start_char="8675" end_char="8678">been</TOKEN>
<TOKEN id="token-66-7" pos="word" morph="none" start_char="8680" end_char="8686">carried</TOKEN>
<TOKEN id="token-66-8" pos="word" morph="none" start_char="8688" end_char="8689">by</TOKEN>
<TOKEN id="token-66-9" pos="word" morph="none" start_char="8691" end_char="8691">a</TOKEN>
<TOKEN id="token-66-10" pos="word" morph="none" start_char="8693" end_char="8695">bat</TOKEN>
<TOKEN id="token-66-11" pos="word" morph="none" start_char="8697" end_char="8698">or</TOKEN>
<TOKEN id="token-66-12" pos="word" morph="none" start_char="8700" end_char="8707">pangolin</TOKEN>
<TOKEN id="token-66-13" pos="word" morph="none" start_char="8709" end_char="8712">that</TOKEN>
<TOKEN id="token-66-14" pos="word" morph="none" start_char="8714" end_char="8716">was</TOKEN>
<TOKEN id="token-66-15" pos="word" morph="none" start_char="8718" end_char="8721">sold</TOKEN>
<TOKEN id="token-66-16" pos="word" morph="none" start_char="8723" end_char="8724">at</TOKEN>
<TOKEN id="token-66-17" pos="word" morph="none" start_char="8726" end_char="8726">a</TOKEN>
<TOKEN id="token-66-18" pos="word" morph="none" start_char="8728" end_char="8733">market</TOKEN>
<TOKEN id="token-66-19" pos="word" morph="none" start_char="8735" end_char="8736">in</TOKEN>
<TOKEN id="token-66-20" pos="word" morph="none" start_char="8738" end_char="8742">Wuhan</TOKEN>
<TOKEN id="token-66-21" pos="word" morph="none" start_char="8744" end_char="8746">and</TOKEN>
<TOKEN id="token-66-22" pos="word" morph="none" start_char="8748" end_char="8751">then</TOKEN>
<TOKEN id="token-66-23" pos="word" morph="none" start_char="8753" end_char="8757">eaten</TOKEN>
<TOKEN id="token-66-24" pos="word" morph="none" start_char="8759" end_char="8760">by</TOKEN>
<TOKEN id="token-66-25" pos="word" morph="none" start_char="8762" end_char="8768">someone</TOKEN>
<TOKEN id="token-66-26" pos="punct" morph="none" start_char="8769" end_char="8769">,</TOKEN>
<TOKEN id="token-66-27" pos="word" morph="none" start_char="8771" end_char="8773">but</TOKEN>
<TOKEN id="token-66-28" pos="word" morph="none" start_char="8775" end_char="8778">this</TOKEN>
<TOKEN id="token-66-29" pos="word" morph="none" start_char="8780" end_char="8782">has</TOKEN>
<TOKEN id="token-66-30" pos="word" morph="none" start_char="8784" end_char="8786">not</TOKEN>
<TOKEN id="token-66-31" pos="word" morph="none" start_char="8788" end_char="8791">been</TOKEN>
<TOKEN id="token-66-32" pos="word" morph="none" start_char="8793" end_char="8801">confirmed</TOKEN>
<TOKEN id="token-66-33" pos="punct" morph="none" start_char="8802" end_char="8802">.</TOKEN>
</SEG>
<SEG id="segment-67" start_char="8805" end_char="8817">
<ORIGINAL_TEXT>Early reports</ORIGINAL_TEXT>
<TOKEN id="token-67-0" pos="word" morph="none" start_char="8805" end_char="8809">Early</TOKEN>
<TOKEN id="token-67-1" pos="word" morph="none" start_char="8811" end_char="8817">reports</TOKEN>
</SEG>
<SEG id="segment-68" start_char="8820" end_char="9026">
<ORIGINAL_TEXT>Chinese authorities initially reported that the virus could not spread person-to-person, despite evidence that it was spreading rapidly through the city of Wuhan including doctors being infected by patients.</ORIGINAL_TEXT>
<TOKEN id="token-68-0" pos="word" morph="none" start_char="8820" end_char="8826">Chinese</TOKEN>
<TOKEN id="token-68-1" pos="word" morph="none" start_char="8828" end_char="8838">authorities</TOKEN>
<TOKEN id="token-68-2" pos="word" morph="none" start_char="8840" end_char="8848">initially</TOKEN>
<TOKEN id="token-68-3" pos="word" morph="none" start_char="8850" end_char="8857">reported</TOKEN>
<TOKEN id="token-68-4" pos="word" morph="none" start_char="8859" end_char="8862">that</TOKEN>
<TOKEN id="token-68-5" pos="word" morph="none" start_char="8864" end_char="8866">the</TOKEN>
<TOKEN id="token-68-6" pos="word" morph="none" start_char="8868" end_char="8872">virus</TOKEN>
<TOKEN id="token-68-7" pos="word" morph="none" start_char="8874" end_char="8878">could</TOKEN>
<TOKEN id="token-68-8" pos="word" morph="none" start_char="8880" end_char="8882">not</TOKEN>
<TOKEN id="token-68-9" pos="word" morph="none" start_char="8884" end_char="8889">spread</TOKEN>
<TOKEN id="token-68-10" pos="unknown" morph="none" start_char="8891" end_char="8906">person-to-person</TOKEN>
<TOKEN id="token-68-11" pos="punct" morph="none" start_char="8907" end_char="8907">,</TOKEN>
<TOKEN id="token-68-12" pos="word" morph="none" start_char="8909" end_char="8915">despite</TOKEN>
<TOKEN id="token-68-13" pos="word" morph="none" start_char="8917" end_char="8924">evidence</TOKEN>
<TOKEN id="token-68-14" pos="word" morph="none" start_char="8926" end_char="8929">that</TOKEN>
<TOKEN id="token-68-15" pos="word" morph="none" start_char="8931" end_char="8932">it</TOKEN>
<TOKEN id="token-68-16" pos="word" morph="none" start_char="8934" end_char="8936">was</TOKEN>
<TOKEN id="token-68-17" pos="word" morph="none" start_char="8938" end_char="8946">spreading</TOKEN>
<TOKEN id="token-68-18" pos="word" morph="none" start_char="8948" end_char="8954">rapidly</TOKEN>
<TOKEN id="token-68-19" pos="word" morph="none" start_char="8956" end_char="8962">through</TOKEN>
<TOKEN id="token-68-20" pos="word" morph="none" start_char="8964" end_char="8966">the</TOKEN>
<TOKEN id="token-68-21" pos="word" morph="none" start_char="8968" end_char="8971">city</TOKEN>
<TOKEN id="token-68-22" pos="word" morph="none" start_char="8973" end_char="8974">of</TOKEN>
<TOKEN id="token-68-23" pos="word" morph="none" start_char="8976" end_char="8980">Wuhan</TOKEN>
<TOKEN id="token-68-24" pos="word" morph="none" start_char="8982" end_char="8990">including</TOKEN>
<TOKEN id="token-68-25" pos="word" morph="none" start_char="8992" end_char="8998">doctors</TOKEN>
<TOKEN id="token-68-26" pos="word" morph="none" start_char="9000" end_char="9004">being</TOKEN>
<TOKEN id="token-68-27" pos="word" morph="none" start_char="9006" end_char="9013">infected</TOKEN>
<TOKEN id="token-68-28" pos="word" morph="none" start_char="9015" end_char="9016">by</TOKEN>
<TOKEN id="token-68-29" pos="word" morph="none" start_char="9018" end_char="9025">patients</TOKEN>
<TOKEN id="token-68-30" pos="punct" morph="none" start_char="9026" end_char="9026">.</TOKEN>
</SEG>
<SEG id="segment-69" start_char="9029" end_char="9237">
<ORIGINAL_TEXT>This was used as justification for keeping the city of Wuhan operating as normal through a major CCP conference that was held between January 11 and 17, with authorities claiming zero new cases in this period.</ORIGINAL_TEXT>
<TOKEN id="token-69-0" pos="word" morph="none" start_char="9029" end_char="9032">This</TOKEN>
<TOKEN id="token-69-1" pos="word" morph="none" start_char="9034" end_char="9036">was</TOKEN>
<TOKEN id="token-69-2" pos="word" morph="none" start_char="9038" end_char="9041">used</TOKEN>
<TOKEN id="token-69-3" pos="word" morph="none" start_char="9043" end_char="9044">as</TOKEN>
<TOKEN id="token-69-4" pos="word" morph="none" start_char="9046" end_char="9058">justification</TOKEN>
<TOKEN id="token-69-5" pos="word" morph="none" start_char="9060" end_char="9062">for</TOKEN>
<TOKEN id="token-69-6" pos="word" morph="none" start_char="9064" end_char="9070">keeping</TOKEN>
<TOKEN id="token-69-7" pos="word" morph="none" start_char="9072" end_char="9074">the</TOKEN>
<TOKEN id="token-69-8" pos="word" morph="none" start_char="9076" end_char="9079">city</TOKEN>
<TOKEN id="token-69-9" pos="word" morph="none" start_char="9081" end_char="9082">of</TOKEN>
<TOKEN id="token-69-10" pos="word" morph="none" start_char="9084" end_char="9088">Wuhan</TOKEN>
<TOKEN id="token-69-11" pos="word" morph="none" start_char="9090" end_char="9098">operating</TOKEN>
<TOKEN id="token-69-12" pos="word" morph="none" start_char="9100" end_char="9101">as</TOKEN>
<TOKEN id="token-69-13" pos="word" morph="none" start_char="9103" end_char="9108">normal</TOKEN>
<TOKEN id="token-69-14" pos="word" morph="none" start_char="9110" end_char="9116">through</TOKEN>
<TOKEN id="token-69-15" pos="word" morph="none" start_char="9118" end_char="9118">a</TOKEN>
<TOKEN id="token-69-16" pos="word" morph="none" start_char="9120" end_char="9124">major</TOKEN>
<TOKEN id="token-69-17" pos="word" morph="none" start_char="9126" end_char="9128">CCP</TOKEN>
<TOKEN id="token-69-18" pos="word" morph="none" start_char="9130" end_char="9139">conference</TOKEN>
<TOKEN id="token-69-19" pos="word" morph="none" start_char="9141" end_char="9144">that</TOKEN>
<TOKEN id="token-69-20" pos="word" morph="none" start_char="9146" end_char="9148">was</TOKEN>
<TOKEN id="token-69-21" pos="word" morph="none" start_char="9150" end_char="9153">held</TOKEN>
<TOKEN id="token-69-22" pos="word" morph="none" start_char="9155" end_char="9161">between</TOKEN>
<TOKEN id="token-69-23" pos="word" morph="none" start_char="9163" end_char="9169">January</TOKEN>
<TOKEN id="token-69-24" pos="word" morph="none" start_char="9171" end_char="9172">11</TOKEN>
<TOKEN id="token-69-25" pos="word" morph="none" start_char="9174" end_char="9176">and</TOKEN>
<TOKEN id="token-69-26" pos="word" morph="none" start_char="9178" end_char="9179">17</TOKEN>
<TOKEN id="token-69-27" pos="punct" morph="none" start_char="9180" end_char="9180">,</TOKEN>
<TOKEN id="token-69-28" pos="word" morph="none" start_char="9182" end_char="9185">with</TOKEN>
<TOKEN id="token-69-29" pos="word" morph="none" start_char="9187" end_char="9197">authorities</TOKEN>
<TOKEN id="token-69-30" pos="word" morph="none" start_char="9199" end_char="9206">claiming</TOKEN>
<TOKEN id="token-69-31" pos="word" morph="none" start_char="9208" end_char="9211">zero</TOKEN>
<TOKEN id="token-69-32" pos="word" morph="none" start_char="9213" end_char="9215">new</TOKEN>
<TOKEN id="token-69-33" pos="word" morph="none" start_char="9217" end_char="9221">cases</TOKEN>
<TOKEN id="token-69-34" pos="word" morph="none" start_char="9223" end_char="9224">in</TOKEN>
<TOKEN id="token-69-35" pos="word" morph="none" start_char="9226" end_char="9229">this</TOKEN>
<TOKEN id="token-69-36" pos="word" morph="none" start_char="9231" end_char="9236">period</TOKEN>
<TOKEN id="token-69-37" pos="punct" morph="none" start_char="9237" end_char="9237">.</TOKEN>
</SEG>
<SEG id="segment-70" start_char="9240" end_char="9396">
<ORIGINAL_TEXT>China did not confirm human-to-human transmission of the virus until late January, when large parts of Hubei province including Wuhan were put into lockdown.</ORIGINAL_TEXT>
<TOKEN id="token-70-0" pos="word" morph="none" start_char="9240" end_char="9244">China</TOKEN>
<TOKEN id="token-70-1" pos="word" morph="none" start_char="9246" end_char="9248">did</TOKEN>
<TOKEN id="token-70-2" pos="word" morph="none" start_char="9250" end_char="9252">not</TOKEN>
<TOKEN id="token-70-3" pos="word" morph="none" start_char="9254" end_char="9260">confirm</TOKEN>
<TOKEN id="token-70-4" pos="unknown" morph="none" start_char="9262" end_char="9275">human-to-human</TOKEN>
<TOKEN id="token-70-5" pos="word" morph="none" start_char="9277" end_char="9288">transmission</TOKEN>
<TOKEN id="token-70-6" pos="word" morph="none" start_char="9290" end_char="9291">of</TOKEN>
<TOKEN id="token-70-7" pos="word" morph="none" start_char="9293" end_char="9295">the</TOKEN>
<TOKEN id="token-70-8" pos="word" morph="none" start_char="9297" end_char="9301">virus</TOKEN>
<TOKEN id="token-70-9" pos="word" morph="none" start_char="9303" end_char="9307">until</TOKEN>
<TOKEN id="token-70-10" pos="word" morph="none" start_char="9309" end_char="9312">late</TOKEN>
<TOKEN id="token-70-11" pos="word" morph="none" start_char="9314" end_char="9320">January</TOKEN>
<TOKEN id="token-70-12" pos="punct" morph="none" start_char="9321" end_char="9321">,</TOKEN>
<TOKEN id="token-70-13" pos="word" morph="none" start_char="9323" end_char="9326">when</TOKEN>
<TOKEN id="token-70-14" pos="word" morph="none" start_char="9328" end_char="9332">large</TOKEN>
<TOKEN id="token-70-15" pos="word" morph="none" start_char="9334" end_char="9338">parts</TOKEN>
<TOKEN id="token-70-16" pos="word" morph="none" start_char="9340" end_char="9341">of</TOKEN>
<TOKEN id="token-70-17" pos="word" morph="none" start_char="9343" end_char="9347">Hubei</TOKEN>
<TOKEN id="token-70-18" pos="word" morph="none" start_char="9349" end_char="9356">province</TOKEN>
<TOKEN id="token-70-19" pos="word" morph="none" start_char="9358" end_char="9366">including</TOKEN>
<TOKEN id="token-70-20" pos="word" morph="none" start_char="9368" end_char="9372">Wuhan</TOKEN>
<TOKEN id="token-70-21" pos="word" morph="none" start_char="9374" end_char="9377">were</TOKEN>
<TOKEN id="token-70-22" pos="word" morph="none" start_char="9379" end_char="9381">put</TOKEN>
<TOKEN id="token-70-23" pos="word" morph="none" start_char="9383" end_char="9386">into</TOKEN>
<TOKEN id="token-70-24" pos="word" morph="none" start_char="9388" end_char="9395">lockdown</TOKEN>
<TOKEN id="token-70-25" pos="punct" morph="none" start_char="9396" end_char="9396">.</TOKEN>
</SEG>
<SEG id="segment-71" start_char="9400" end_char="9600">
<ORIGINAL_TEXT>Despite reporting the existence of a 'novel type of pneumonia' to the World Health Organisation on December 31, Wuhan's largest newspaper also made no mention of the virus until the week of January 20.</ORIGINAL_TEXT>
<TOKEN id="token-71-0" pos="word" morph="none" start_char="9400" end_char="9406">Despite</TOKEN>
<TOKEN id="token-71-1" pos="word" morph="none" start_char="9408" end_char="9416">reporting</TOKEN>
<TOKEN id="token-71-2" pos="word" morph="none" start_char="9418" end_char="9420">the</TOKEN>
<TOKEN id="token-71-3" pos="word" morph="none" start_char="9422" end_char="9430">existence</TOKEN>
<TOKEN id="token-71-4" pos="word" morph="none" start_char="9432" end_char="9433">of</TOKEN>
<TOKEN id="token-71-5" pos="word" morph="none" start_char="9435" end_char="9435">a</TOKEN>
<TOKEN id="token-71-6" pos="punct" morph="none" start_char="9437" end_char="9437">'</TOKEN>
<TOKEN id="token-71-7" pos="word" morph="none" start_char="9438" end_char="9442">novel</TOKEN>
<TOKEN id="token-71-8" pos="word" morph="none" start_char="9444" end_char="9447">type</TOKEN>
<TOKEN id="token-71-9" pos="word" morph="none" start_char="9449" end_char="9450">of</TOKEN>
<TOKEN id="token-71-10" pos="word" morph="none" start_char="9452" end_char="9460">pneumonia</TOKEN>
<TOKEN id="token-71-11" pos="punct" morph="none" start_char="9461" end_char="9461">'</TOKEN>
<TOKEN id="token-71-12" pos="word" morph="none" start_char="9463" end_char="9464">to</TOKEN>
<TOKEN id="token-71-13" pos="word" morph="none" start_char="9466" end_char="9468">the</TOKEN>
<TOKEN id="token-71-14" pos="word" morph="none" start_char="9470" end_char="9474">World</TOKEN>
<TOKEN id="token-71-15" pos="word" morph="none" start_char="9476" end_char="9481">Health</TOKEN>
<TOKEN id="token-71-16" pos="word" morph="none" start_char="9483" end_char="9494">Organisation</TOKEN>
<TOKEN id="token-71-17" pos="word" morph="none" start_char="9496" end_char="9497">on</TOKEN>
<TOKEN id="token-71-18" pos="word" morph="none" start_char="9499" end_char="9506">December</TOKEN>
<TOKEN id="token-71-19" pos="word" morph="none" start_char="9508" end_char="9509">31</TOKEN>
<TOKEN id="token-71-20" pos="punct" morph="none" start_char="9510" end_char="9510">,</TOKEN>
<TOKEN id="token-71-21" pos="word" morph="none" start_char="9512" end_char="9518">Wuhan's</TOKEN>
<TOKEN id="token-71-22" pos="word" morph="none" start_char="9520" end_char="9526">largest</TOKEN>
<TOKEN id="token-71-23" pos="word" morph="none" start_char="9528" end_char="9536">newspaper</TOKEN>
<TOKEN id="token-71-24" pos="word" morph="none" start_char="9538" end_char="9541">also</TOKEN>
<TOKEN id="token-71-25" pos="word" morph="none" start_char="9543" end_char="9546">made</TOKEN>
<TOKEN id="token-71-26" pos="word" morph="none" start_char="9548" end_char="9549">no</TOKEN>
<TOKEN id="token-71-27" pos="word" morph="none" start_char="9551" end_char="9557">mention</TOKEN>
<TOKEN id="token-71-28" pos="word" morph="none" start_char="9559" end_char="9560">of</TOKEN>
<TOKEN id="token-71-29" pos="word" morph="none" start_char="9562" end_char="9564">the</TOKEN>
<TOKEN id="token-71-30" pos="word" morph="none" start_char="9566" end_char="9570">virus</TOKEN>
<TOKEN id="token-71-31" pos="word" morph="none" start_char="9572" end_char="9576">until</TOKEN>
<TOKEN id="token-71-32" pos="word" morph="none" start_char="9578" end_char="9580">the</TOKEN>
<TOKEN id="token-71-33" pos="word" morph="none" start_char="9582" end_char="9585">week</TOKEN>
<TOKEN id="token-71-34" pos="word" morph="none" start_char="9587" end_char="9588">of</TOKEN>
<TOKEN id="token-71-35" pos="word" morph="none" start_char="9590" end_char="9596">January</TOKEN>
<TOKEN id="token-71-36" pos="word" morph="none" start_char="9598" end_char="9599">20</TOKEN>
<TOKEN id="token-71-37" pos="punct" morph="none" start_char="9600" end_char="9600">.</TOKEN>
</SEG>
<SEG id="segment-72" start_char="9603" end_char="9707">
<ORIGINAL_TEXT>That meant people in the city were not taking precautions such as social distancing to stop it spreading.</ORIGINAL_TEXT>
<TOKEN id="token-72-0" pos="word" morph="none" start_char="9603" end_char="9606">That</TOKEN>
<TOKEN id="token-72-1" pos="word" morph="none" start_char="9608" end_char="9612">meant</TOKEN>
<TOKEN id="token-72-2" pos="word" morph="none" start_char="9614" end_char="9619">people</TOKEN>
<TOKEN id="token-72-3" pos="word" morph="none" start_char="9621" end_char="9622">in</TOKEN>
<TOKEN id="token-72-4" pos="word" morph="none" start_char="9624" end_char="9626">the</TOKEN>
<TOKEN id="token-72-5" pos="word" morph="none" start_char="9628" end_char="9631">city</TOKEN>
<TOKEN id="token-72-6" pos="word" morph="none" start_char="9633" end_char="9636">were</TOKEN>
<TOKEN id="token-72-7" pos="word" morph="none" start_char="9638" end_char="9640">not</TOKEN>
<TOKEN id="token-72-8" pos="word" morph="none" start_char="9642" end_char="9647">taking</TOKEN>
<TOKEN id="token-72-9" pos="word" morph="none" start_char="9649" end_char="9659">precautions</TOKEN>
<TOKEN id="token-72-10" pos="word" morph="none" start_char="9661" end_char="9664">such</TOKEN>
<TOKEN id="token-72-11" pos="word" morph="none" start_char="9666" end_char="9667">as</TOKEN>
<TOKEN id="token-72-12" pos="word" morph="none" start_char="9669" end_char="9674">social</TOKEN>
<TOKEN id="token-72-13" pos="word" morph="none" start_char="9676" end_char="9685">distancing</TOKEN>
<TOKEN id="token-72-14" pos="word" morph="none" start_char="9687" end_char="9688">to</TOKEN>
<TOKEN id="token-72-15" pos="word" morph="none" start_char="9690" end_char="9693">stop</TOKEN>
<TOKEN id="token-72-16" pos="word" morph="none" start_char="9695" end_char="9696">it</TOKEN>
<TOKEN id="token-72-17" pos="word" morph="none" start_char="9698" end_char="9706">spreading</TOKEN>
<TOKEN id="token-72-18" pos="punct" morph="none" start_char="9707" end_char="9707">.</TOKEN>
</SEG>
<SEG id="segment-73" start_char="9710" end_char="9898">
<ORIGINAL_TEXT>It also meant that people had begun travelling for the Lunar New Year holiday, which was due to start on January 24 and sees millions of people visit relatives, spreading the virus further.</ORIGINAL_TEXT>
<TOKEN id="token-73-0" pos="word" morph="none" start_char="9710" end_char="9711">It</TOKEN>
<TOKEN id="token-73-1" pos="word" morph="none" start_char="9713" end_char="9716">also</TOKEN>
<TOKEN id="token-73-2" pos="word" morph="none" start_char="9718" end_char="9722">meant</TOKEN>
<TOKEN id="token-73-3" pos="word" morph="none" start_char="9724" end_char="9727">that</TOKEN>
<TOKEN id="token-73-4" pos="word" morph="none" start_char="9729" end_char="9734">people</TOKEN>
<TOKEN id="token-73-5" pos="word" morph="none" start_char="9736" end_char="9738">had</TOKEN>
<TOKEN id="token-73-6" pos="word" morph="none" start_char="9740" end_char="9744">begun</TOKEN>
<TOKEN id="token-73-7" pos="word" morph="none" start_char="9746" end_char="9755">travelling</TOKEN>
<TOKEN id="token-73-8" pos="word" morph="none" start_char="9757" end_char="9759">for</TOKEN>
<TOKEN id="token-73-9" pos="word" morph="none" start_char="9761" end_char="9763">the</TOKEN>
<TOKEN id="token-73-10" pos="word" morph="none" start_char="9765" end_char="9769">Lunar</TOKEN>
<TOKEN id="token-73-11" pos="word" morph="none" start_char="9771" end_char="9773">New</TOKEN>
<TOKEN id="token-73-12" pos="word" morph="none" start_char="9775" end_char="9778">Year</TOKEN>
<TOKEN id="token-73-13" pos="word" morph="none" start_char="9780" end_char="9786">holiday</TOKEN>
<TOKEN id="token-73-14" pos="punct" morph="none" start_char="9787" end_char="9787">,</TOKEN>
<TOKEN id="token-73-15" pos="word" morph="none" start_char="9789" end_char="9793">which</TOKEN>
<TOKEN id="token-73-16" pos="word" morph="none" start_char="9795" end_char="9797">was</TOKEN>
<TOKEN id="token-73-17" pos="word" morph="none" start_char="9799" end_char="9801">due</TOKEN>
<TOKEN id="token-73-18" pos="word" morph="none" start_char="9803" end_char="9804">to</TOKEN>
<TOKEN id="token-73-19" pos="word" morph="none" start_char="9806" end_char="9810">start</TOKEN>
<TOKEN id="token-73-20" pos="word" morph="none" start_char="9812" end_char="9813">on</TOKEN>
<TOKEN id="token-73-21" pos="word" morph="none" start_char="9815" end_char="9821">January</TOKEN>
<TOKEN id="token-73-22" pos="word" morph="none" start_char="9823" end_char="9824">24</TOKEN>
<TOKEN id="token-73-23" pos="word" morph="none" start_char="9826" end_char="9828">and</TOKEN>
<TOKEN id="token-73-24" pos="word" morph="none" start_char="9830" end_char="9833">sees</TOKEN>
<TOKEN id="token-73-25" pos="word" morph="none" start_char="9835" end_char="9842">millions</TOKEN>
<TOKEN id="token-73-26" pos="word" morph="none" start_char="9844" end_char="9845">of</TOKEN>
<TOKEN id="token-73-27" pos="word" morph="none" start_char="9847" end_char="9852">people</TOKEN>
<TOKEN id="token-73-28" pos="word" morph="none" start_char="9854" end_char="9858">visit</TOKEN>
<TOKEN id="token-73-29" pos="word" morph="none" start_char="9860" end_char="9868">relatives</TOKEN>
<TOKEN id="token-73-30" pos="punct" morph="none" start_char="9869" end_char="9869">,</TOKEN>
<TOKEN id="token-73-31" pos="word" morph="none" start_char="9871" end_char="9879">spreading</TOKEN>
<TOKEN id="token-73-32" pos="word" morph="none" start_char="9881" end_char="9883">the</TOKEN>
<TOKEN id="token-73-33" pos="word" morph="none" start_char="9885" end_char="9889">virus</TOKEN>
<TOKEN id="token-73-34" pos="word" morph="none" start_char="9891" end_char="9897">further</TOKEN>
<TOKEN id="token-73-35" pos="punct" morph="none" start_char="9898" end_char="9898">.</TOKEN>
</SEG>
<SEG id="segment-74" start_char="9901" end_char="10128">
<ORIGINAL_TEXT>Furthermore, China delayed reports suggesting that some 14 per cent of patients who initially tested negative for the virus or who appeared to have recovered tested positive a second time, only confirming such cases in February.</ORIGINAL_TEXT>
<TOKEN id="token-74-0" pos="word" morph="none" start_char="9901" end_char="9911">Furthermore</TOKEN>
<TOKEN id="token-74-1" pos="punct" morph="none" start_char="9912" end_char="9912">,</TOKEN>
<TOKEN id="token-74-2" pos="word" morph="none" start_char="9914" end_char="9918">China</TOKEN>
<TOKEN id="token-74-3" pos="word" morph="none" start_char="9920" end_char="9926">delayed</TOKEN>
<TOKEN id="token-74-4" pos="word" morph="none" start_char="9928" end_char="9934">reports</TOKEN>
<TOKEN id="token-74-5" pos="word" morph="none" start_char="9936" end_char="9945">suggesting</TOKEN>
<TOKEN id="token-74-6" pos="word" morph="none" start_char="9947" end_char="9950">that</TOKEN>
<TOKEN id="token-74-7" pos="word" morph="none" start_char="9952" end_char="9955">some</TOKEN>
<TOKEN id="token-74-8" pos="word" morph="none" start_char="9957" end_char="9958">14</TOKEN>
<TOKEN id="token-74-9" pos="word" morph="none" start_char="9960" end_char="9962">per</TOKEN>
<TOKEN id="token-74-10" pos="word" morph="none" start_char="9964" end_char="9967">cent</TOKEN>
<TOKEN id="token-74-11" pos="word" morph="none" start_char="9969" end_char="9970">of</TOKEN>
<TOKEN id="token-74-12" pos="word" morph="none" start_char="9972" end_char="9979">patients</TOKEN>
<TOKEN id="token-74-13" pos="word" morph="none" start_char="9981" end_char="9983">who</TOKEN>
<TOKEN id="token-74-14" pos="word" morph="none" start_char="9985" end_char="9993">initially</TOKEN>
<TOKEN id="token-74-15" pos="word" morph="none" start_char="9995" end_char="10000">tested</TOKEN>
<TOKEN id="token-74-16" pos="word" morph="none" start_char="10002" end_char="10009">negative</TOKEN>
<TOKEN id="token-74-17" pos="word" morph="none" start_char="10011" end_char="10013">for</TOKEN>
<TOKEN id="token-74-18" pos="word" morph="none" start_char="10015" end_char="10017">the</TOKEN>
<TOKEN id="token-74-19" pos="word" morph="none" start_char="10019" end_char="10023">virus</TOKEN>
<TOKEN id="token-74-20" pos="word" morph="none" start_char="10025" end_char="10026">or</TOKEN>
<TOKEN id="token-74-21" pos="word" morph="none" start_char="10028" end_char="10030">who</TOKEN>
<TOKEN id="token-74-22" pos="word" morph="none" start_char="10032" end_char="10039">appeared</TOKEN>
<TOKEN id="token-74-23" pos="word" morph="none" start_char="10041" end_char="10042">to</TOKEN>
<TOKEN id="token-74-24" pos="word" morph="none" start_char="10044" end_char="10047">have</TOKEN>
<TOKEN id="token-74-25" pos="word" morph="none" start_char="10049" end_char="10057">recovered</TOKEN>
<TOKEN id="token-74-26" pos="word" morph="none" start_char="10059" end_char="10064">tested</TOKEN>
<TOKEN id="token-74-27" pos="word" morph="none" start_char="10066" end_char="10073">positive</TOKEN>
<TOKEN id="token-74-28" pos="word" morph="none" start_char="10075" end_char="10075">a</TOKEN>
<TOKEN id="token-74-29" pos="word" morph="none" start_char="10077" end_char="10082">second</TOKEN>
<TOKEN id="token-74-30" pos="word" morph="none" start_char="10084" end_char="10087">time</TOKEN>
<TOKEN id="token-74-31" pos="punct" morph="none" start_char="10088" end_char="10088">,</TOKEN>
<TOKEN id="token-74-32" pos="word" morph="none" start_char="10090" end_char="10093">only</TOKEN>
<TOKEN id="token-74-33" pos="word" morph="none" start_char="10095" end_char="10104">confirming</TOKEN>
<TOKEN id="token-74-34" pos="word" morph="none" start_char="10106" end_char="10109">such</TOKEN>
<TOKEN id="token-74-35" pos="word" morph="none" start_char="10111" end_char="10115">cases</TOKEN>
<TOKEN id="token-74-36" pos="word" morph="none" start_char="10117" end_char="10118">in</TOKEN>
<TOKEN id="token-74-37" pos="word" morph="none" start_char="10120" end_char="10127">February</TOKEN>
<TOKEN id="token-74-38" pos="punct" morph="none" start_char="10128" end_char="10128">.</TOKEN>
</SEG>
<SEG id="segment-75" start_char="10131" end_char="10348">
<ORIGINAL_TEXT>That further hampered efforts at early containment of the virus in places such as Japan, where patients who tested negative on board the Diamond Princess cruise ship were allowed to leave - only to test positive later.</ORIGINAL_TEXT>
<TOKEN id="token-75-0" pos="word" morph="none" start_char="10131" end_char="10134">That</TOKEN>
<TOKEN id="token-75-1" pos="word" morph="none" start_char="10136" end_char="10142">further</TOKEN>
<TOKEN id="token-75-2" pos="word" morph="none" start_char="10144" end_char="10151">hampered</TOKEN>
<TOKEN id="token-75-3" pos="word" morph="none" start_char="10153" end_char="10159">efforts</TOKEN>
<TOKEN id="token-75-4" pos="word" morph="none" start_char="10161" end_char="10162">at</TOKEN>
<TOKEN id="token-75-5" pos="word" morph="none" start_char="10164" end_char="10168">early</TOKEN>
<TOKEN id="token-75-6" pos="word" morph="none" start_char="10170" end_char="10180">containment</TOKEN>
<TOKEN id="token-75-7" pos="word" morph="none" start_char="10182" end_char="10183">of</TOKEN>
<TOKEN id="token-75-8" pos="word" morph="none" start_char="10185" end_char="10187">the</TOKEN>
<TOKEN id="token-75-9" pos="word" morph="none" start_char="10189" end_char="10193">virus</TOKEN>
<TOKEN id="token-75-10" pos="word" morph="none" start_char="10195" end_char="10196">in</TOKEN>
<TOKEN id="token-75-11" pos="word" morph="none" start_char="10198" end_char="10203">places</TOKEN>
<TOKEN id="token-75-12" pos="word" morph="none" start_char="10205" end_char="10208">such</TOKEN>
<TOKEN id="token-75-13" pos="word" morph="none" start_char="10210" end_char="10211">as</TOKEN>
<TOKEN id="token-75-14" pos="word" morph="none" start_char="10213" end_char="10217">Japan</TOKEN>
<TOKEN id="token-75-15" pos="punct" morph="none" start_char="10218" end_char="10218">,</TOKEN>
<TOKEN id="token-75-16" pos="word" morph="none" start_char="10220" end_char="10224">where</TOKEN>
<TOKEN id="token-75-17" pos="word" morph="none" start_char="10226" end_char="10233">patients</TOKEN>
<TOKEN id="token-75-18" pos="word" morph="none" start_char="10235" end_char="10237">who</TOKEN>
<TOKEN id="token-75-19" pos="word" morph="none" start_char="10239" end_char="10244">tested</TOKEN>
<TOKEN id="token-75-20" pos="word" morph="none" start_char="10246" end_char="10253">negative</TOKEN>
<TOKEN id="token-75-21" pos="word" morph="none" start_char="10255" end_char="10256">on</TOKEN>
<TOKEN id="token-75-22" pos="word" morph="none" start_char="10258" end_char="10262">board</TOKEN>
<TOKEN id="token-75-23" pos="word" morph="none" start_char="10264" end_char="10266">the</TOKEN>
<TOKEN id="token-75-24" pos="word" morph="none" start_char="10268" end_char="10274">Diamond</TOKEN>
<TOKEN id="token-75-25" pos="word" morph="none" start_char="10276" end_char="10283">Princess</TOKEN>
<TOKEN id="token-75-26" pos="word" morph="none" start_char="10285" end_char="10290">cruise</TOKEN>
<TOKEN id="token-75-27" pos="word" morph="none" start_char="10292" end_char="10295">ship</TOKEN>
<TOKEN id="token-75-28" pos="word" morph="none" start_char="10297" end_char="10300">were</TOKEN>
<TOKEN id="token-75-29" pos="word" morph="none" start_char="10302" end_char="10308">allowed</TOKEN>
<TOKEN id="token-75-30" pos="word" morph="none" start_char="10310" end_char="10311">to</TOKEN>
<TOKEN id="token-75-31" pos="word" morph="none" start_char="10313" end_char="10317">leave</TOKEN>
<TOKEN id="token-75-32" pos="punct" morph="none" start_char="10319" end_char="10319">-</TOKEN>
<TOKEN id="token-75-33" pos="word" morph="none" start_char="10321" end_char="10324">only</TOKEN>
<TOKEN id="token-75-34" pos="word" morph="none" start_char="10326" end_char="10327">to</TOKEN>
<TOKEN id="token-75-35" pos="word" morph="none" start_char="10329" end_char="10332">test</TOKEN>
<TOKEN id="token-75-36" pos="word" morph="none" start_char="10334" end_char="10341">positive</TOKEN>
<TOKEN id="token-75-37" pos="word" morph="none" start_char="10343" end_char="10347">later</TOKEN>
<TOKEN id="token-75-38" pos="punct" morph="none" start_char="10348" end_char="10348">.</TOKEN>
</SEG>
<SEG id="segment-76" start_char="10351" end_char="10551">
<ORIGINAL_TEXT>Authorities in Beijing were also slow to report the deaths of two doctors from the virus, including one who was killed on January 25 but whose death was not reported by state media until a month later.</ORIGINAL_TEXT>
<TOKEN id="token-76-0" pos="word" morph="none" start_char="10351" end_char="10361">Authorities</TOKEN>
<TOKEN id="token-76-1" pos="word" morph="none" start_char="10363" end_char="10364">in</TOKEN>
<TOKEN id="token-76-2" pos="word" morph="none" start_char="10366" end_char="10372">Beijing</TOKEN>
<TOKEN id="token-76-3" pos="word" morph="none" start_char="10374" end_char="10377">were</TOKEN>
<TOKEN id="token-76-4" pos="word" morph="none" start_char="10379" end_char="10382">also</TOKEN>
<TOKEN id="token-76-5" pos="word" morph="none" start_char="10384" end_char="10387">slow</TOKEN>
<TOKEN id="token-76-6" pos="word" morph="none" start_char="10389" end_char="10390">to</TOKEN>
<TOKEN id="token-76-7" pos="word" morph="none" start_char="10392" end_char="10397">report</TOKEN>
<TOKEN id="token-76-8" pos="word" morph="none" start_char="10399" end_char="10401">the</TOKEN>
<TOKEN id="token-76-9" pos="word" morph="none" start_char="10403" end_char="10408">deaths</TOKEN>
<TOKEN id="token-76-10" pos="word" morph="none" start_char="10410" end_char="10411">of</TOKEN>
<TOKEN id="token-76-11" pos="word" morph="none" start_char="10413" end_char="10415">two</TOKEN>
<TOKEN id="token-76-12" pos="word" morph="none" start_char="10417" end_char="10423">doctors</TOKEN>
<TOKEN id="token-76-13" pos="word" morph="none" start_char="10425" end_char="10428">from</TOKEN>
<TOKEN id="token-76-14" pos="word" morph="none" start_char="10430" end_char="10432">the</TOKEN>
<TOKEN id="token-76-15" pos="word" morph="none" start_char="10434" end_char="10438">virus</TOKEN>
<TOKEN id="token-76-16" pos="punct" morph="none" start_char="10439" end_char="10439">,</TOKEN>
<TOKEN id="token-76-17" pos="word" morph="none" start_char="10441" end_char="10449">including</TOKEN>
<TOKEN id="token-76-18" pos="word" morph="none" start_char="10451" end_char="10453">one</TOKEN>
<TOKEN id="token-76-19" pos="word" morph="none" start_char="10455" end_char="10457">who</TOKEN>
<TOKEN id="token-76-20" pos="word" morph="none" start_char="10459" end_char="10461">was</TOKEN>
<TOKEN id="token-76-21" pos="word" morph="none" start_char="10463" end_char="10468">killed</TOKEN>
<TOKEN id="token-76-22" pos="word" morph="none" start_char="10470" end_char="10471">on</TOKEN>
<TOKEN id="token-76-23" pos="word" morph="none" start_char="10473" end_char="10479">January</TOKEN>
<TOKEN id="token-76-24" pos="word" morph="none" start_char="10481" end_char="10482">25</TOKEN>
<TOKEN id="token-76-25" pos="word" morph="none" start_char="10484" end_char="10486">but</TOKEN>
<TOKEN id="token-76-26" pos="word" morph="none" start_char="10488" end_char="10492">whose</TOKEN>
<TOKEN id="token-76-27" pos="word" morph="none" start_char="10494" end_char="10498">death</TOKEN>
<TOKEN id="token-76-28" pos="word" morph="none" start_char="10500" end_char="10502">was</TOKEN>
<TOKEN id="token-76-29" pos="word" morph="none" start_char="10504" end_char="10506">not</TOKEN>
<TOKEN id="token-76-30" pos="word" morph="none" start_char="10508" end_char="10515">reported</TOKEN>
<TOKEN id="token-76-31" pos="word" morph="none" start_char="10517" end_char="10518">by</TOKEN>
<TOKEN id="token-76-32" pos="word" morph="none" start_char="10520" end_char="10524">state</TOKEN>
<TOKEN id="token-76-33" pos="word" morph="none" start_char="10526" end_char="10530">media</TOKEN>
<TOKEN id="token-76-34" pos="word" morph="none" start_char="10532" end_char="10536">until</TOKEN>
<TOKEN id="token-76-35" pos="word" morph="none" start_char="10538" end_char="10538">a</TOKEN>
<TOKEN id="token-76-36" pos="word" morph="none" start_char="10540" end_char="10544">month</TOKEN>
<TOKEN id="token-76-37" pos="word" morph="none" start_char="10546" end_char="10550">later</TOKEN>
<TOKEN id="token-76-38" pos="punct" morph="none" start_char="10551" end_char="10551">.</TOKEN>
</SEG>
<SEG id="segment-77" start_char="10555" end_char="10573">
<ORIGINAL_TEXT>Origin of the virus</ORIGINAL_TEXT>
<TOKEN id="token-77-0" pos="word" morph="none" start_char="10555" end_char="10560">Origin</TOKEN>
<TOKEN id="token-77-1" pos="word" morph="none" start_char="10562" end_char="10563">of</TOKEN>
<TOKEN id="token-77-2" pos="word" morph="none" start_char="10565" end_char="10567">the</TOKEN>
<TOKEN id="token-77-3" pos="word" morph="none" start_char="10569" end_char="10573">virus</TOKEN>
</SEG>
<SEG id="segment-78" start_char="10576" end_char="10777">
<ORIGINAL_TEXT>Despite early admissions that the virus began in the city of Wuhan, China later back-tracked - even going so far as to suggest American troops had brought the infection over after visiting the province.</ORIGINAL_TEXT>
<TOKEN id="token-78-0" pos="word" morph="none" start_char="10576" end_char="10582">Despite</TOKEN>
<TOKEN id="token-78-1" pos="word" morph="none" start_char="10584" end_char="10588">early</TOKEN>
<TOKEN id="token-78-2" pos="word" morph="none" start_char="10590" end_char="10599">admissions</TOKEN>
<TOKEN id="token-78-3" pos="word" morph="none" start_char="10601" end_char="10604">that</TOKEN>
<TOKEN id="token-78-4" pos="word" morph="none" start_char="10606" end_char="10608">the</TOKEN>
<TOKEN id="token-78-5" pos="word" morph="none" start_char="10610" end_char="10614">virus</TOKEN>
<TOKEN id="token-78-6" pos="word" morph="none" start_char="10616" end_char="10620">began</TOKEN>
<TOKEN id="token-78-7" pos="word" morph="none" start_char="10622" end_char="10623">in</TOKEN>
<TOKEN id="token-78-8" pos="word" morph="none" start_char="10625" end_char="10627">the</TOKEN>
<TOKEN id="token-78-9" pos="word" morph="none" start_char="10629" end_char="10632">city</TOKEN>
<TOKEN id="token-78-10" pos="word" morph="none" start_char="10634" end_char="10635">of</TOKEN>
<TOKEN id="token-78-11" pos="word" morph="none" start_char="10637" end_char="10641">Wuhan</TOKEN>
<TOKEN id="token-78-12" pos="punct" morph="none" start_char="10642" end_char="10642">,</TOKEN>
<TOKEN id="token-78-13" pos="word" morph="none" start_char="10644" end_char="10648">China</TOKEN>
<TOKEN id="token-78-14" pos="word" morph="none" start_char="10650" end_char="10654">later</TOKEN>
<TOKEN id="token-78-15" pos="unknown" morph="none" start_char="10656" end_char="10667">back-tracked</TOKEN>
<TOKEN id="token-78-16" pos="punct" morph="none" start_char="10669" end_char="10669">-</TOKEN>
<TOKEN id="token-78-17" pos="word" morph="none" start_char="10671" end_char="10674">even</TOKEN>
<TOKEN id="token-78-18" pos="word" morph="none" start_char="10676" end_char="10680">going</TOKEN>
<TOKEN id="token-78-19" pos="word" morph="none" start_char="10682" end_char="10683">so</TOKEN>
<TOKEN id="token-78-20" pos="word" morph="none" start_char="10685" end_char="10687">far</TOKEN>
<TOKEN id="token-78-21" pos="word" morph="none" start_char="10689" end_char="10690">as</TOKEN>
<TOKEN id="token-78-22" pos="word" morph="none" start_char="10692" end_char="10693">to</TOKEN>
<TOKEN id="token-78-23" pos="word" morph="none" start_char="10695" end_char="10701">suggest</TOKEN>
<TOKEN id="token-78-24" pos="word" morph="none" start_char="10703" end_char="10710">American</TOKEN>
<TOKEN id="token-78-25" pos="word" morph="none" start_char="10712" end_char="10717">troops</TOKEN>
<TOKEN id="token-78-26" pos="word" morph="none" start_char="10719" end_char="10721">had</TOKEN>
<TOKEN id="token-78-27" pos="word" morph="none" start_char="10723" end_char="10729">brought</TOKEN>
<TOKEN id="token-78-28" pos="word" morph="none" start_char="10731" end_char="10733">the</TOKEN>
<TOKEN id="token-78-29" pos="word" morph="none" start_char="10735" end_char="10743">infection</TOKEN>
<TOKEN id="token-78-30" pos="word" morph="none" start_char="10745" end_char="10748">over</TOKEN>
<TOKEN id="token-78-31" pos="word" morph="none" start_char="10750" end_char="10754">after</TOKEN>
<TOKEN id="token-78-32" pos="word" morph="none" start_char="10756" end_char="10763">visiting</TOKEN>
<TOKEN id="token-78-33" pos="word" morph="none" start_char="10765" end_char="10767">the</TOKEN>
<TOKEN id="token-78-34" pos="word" morph="none" start_char="10769" end_char="10776">province</TOKEN>
<TOKEN id="token-78-35" pos="punct" morph="none" start_char="10777" end_char="10777">.</TOKEN>
</SEG>
<SEG id="segment-79" start_char="10780" end_char="10931">
<ORIGINAL_TEXT>Lijian Zhao, a prominent official within the Chinese Foreign Ministry, tweeted out the claim on March 12 while providing no evidence to substantiate it.</ORIGINAL_TEXT>
<TOKEN id="token-79-0" pos="word" morph="none" start_char="10780" end_char="10785">Lijian</TOKEN>
<TOKEN id="token-79-1" pos="word" morph="none" start_char="10787" end_char="10790">Zhao</TOKEN>
<TOKEN id="token-79-2" pos="punct" morph="none" start_char="10791" end_char="10791">,</TOKEN>
<TOKEN id="token-79-3" pos="word" morph="none" start_char="10793" end_char="10793">a</TOKEN>
<TOKEN id="token-79-4" pos="word" morph="none" start_char="10795" end_char="10803">prominent</TOKEN>
<TOKEN id="token-79-5" pos="word" morph="none" start_char="10805" end_char="10812">official</TOKEN>
<TOKEN id="token-79-6" pos="word" morph="none" start_char="10814" end_char="10819">within</TOKEN>
<TOKEN id="token-79-7" pos="word" morph="none" start_char="10821" end_char="10823">the</TOKEN>
<TOKEN id="token-79-8" pos="word" morph="none" start_char="10825" end_char="10831">Chinese</TOKEN>
<TOKEN id="token-79-9" pos="word" morph="none" start_char="10833" end_char="10839">Foreign</TOKEN>
<TOKEN id="token-79-10" pos="word" morph="none" start_char="10841" end_char="10848">Ministry</TOKEN>
<TOKEN id="token-79-11" pos="punct" morph="none" start_char="10849" end_char="10849">,</TOKEN>
<TOKEN id="token-79-12" pos="word" morph="none" start_char="10851" end_char="10857">tweeted</TOKEN>
<TOKEN id="token-79-13" pos="word" morph="none" start_char="10859" end_char="10861">out</TOKEN>
<TOKEN id="token-79-14" pos="word" morph="none" start_char="10863" end_char="10865">the</TOKEN>
<TOKEN id="token-79-15" pos="word" morph="none" start_char="10867" end_char="10871">claim</TOKEN>
<TOKEN id="token-79-16" pos="word" morph="none" start_char="10873" end_char="10874">on</TOKEN>
<TOKEN id="token-79-17" pos="word" morph="none" start_char="10876" end_char="10880">March</TOKEN>
<TOKEN id="token-79-18" pos="word" morph="none" start_char="10882" end_char="10883">12</TOKEN>
<TOKEN id="token-79-19" pos="word" morph="none" start_char="10885" end_char="10889">while</TOKEN>
<TOKEN id="token-79-20" pos="word" morph="none" start_char="10891" end_char="10899">providing</TOKEN>
<TOKEN id="token-79-21" pos="word" morph="none" start_char="10901" end_char="10902">no</TOKEN>
<TOKEN id="token-79-22" pos="word" morph="none" start_char="10904" end_char="10911">evidence</TOKEN>
<TOKEN id="token-79-23" pos="word" morph="none" start_char="10913" end_char="10914">to</TOKEN>
<TOKEN id="token-79-24" pos="word" morph="none" start_char="10916" end_char="10927">substantiate</TOKEN>
<TOKEN id="token-79-25" pos="word" morph="none" start_char="10929" end_char="10930">it</TOKEN>
<TOKEN id="token-79-26" pos="punct" morph="none" start_char="10931" end_char="10931">.</TOKEN>
</SEG>
<SEG id="segment-80" start_char="10934" end_char="10968">
<ORIGINAL_TEXT>'When did patient zero begin in US?</ORIGINAL_TEXT>
<TOKEN id="token-80-0" pos="punct" morph="none" start_char="10934" end_char="10934">'</TOKEN>
<TOKEN id="token-80-1" pos="word" morph="none" start_char="10935" end_char="10938">When</TOKEN>
<TOKEN id="token-80-2" pos="word" morph="none" start_char="10940" end_char="10942">did</TOKEN>
<TOKEN id="token-80-3" pos="word" morph="none" start_char="10944" end_char="10950">patient</TOKEN>
<TOKEN id="token-80-4" pos="word" morph="none" start_char="10952" end_char="10955">zero</TOKEN>
<TOKEN id="token-80-5" pos="word" morph="none" start_char="10957" end_char="10961">begin</TOKEN>
<TOKEN id="token-80-6" pos="word" morph="none" start_char="10963" end_char="10964">in</TOKEN>
<TOKEN id="token-80-7" pos="word" morph="none" start_char="10966" end_char="10967">US</TOKEN>
<TOKEN id="token-80-8" pos="punct" morph="none" start_char="10968" end_char="10968">?</TOKEN>
</SEG>
<SEG id="segment-81" start_char="10970" end_char="10998">
<ORIGINAL_TEXT>How many people are infected?</ORIGINAL_TEXT>
<TOKEN id="token-81-0" pos="word" morph="none" start_char="10970" end_char="10972">How</TOKEN>
<TOKEN id="token-81-1" pos="word" morph="none" start_char="10974" end_char="10977">many</TOKEN>
<TOKEN id="token-81-2" pos="word" morph="none" start_char="10979" end_char="10984">people</TOKEN>
<TOKEN id="token-81-3" pos="word" morph="none" start_char="10986" end_char="10988">are</TOKEN>
<TOKEN id="token-81-4" pos="word" morph="none" start_char="10990" end_char="10997">infected</TOKEN>
<TOKEN id="token-81-5" pos="punct" morph="none" start_char="10998" end_char="10998">?</TOKEN>
</SEG>
<SEG id="segment-82" start_char="11000" end_char="11046">
<ORIGINAL_TEXT>What are the names of the hospitals,' he wrote.</ORIGINAL_TEXT>
<TOKEN id="token-82-0" pos="word" morph="none" start_char="11000" end_char="11003">What</TOKEN>
<TOKEN id="token-82-1" pos="word" morph="none" start_char="11005" end_char="11007">are</TOKEN>
<TOKEN id="token-82-2" pos="word" morph="none" start_char="11009" end_char="11011">the</TOKEN>
<TOKEN id="token-82-3" pos="word" morph="none" start_char="11013" end_char="11017">names</TOKEN>
<TOKEN id="token-82-4" pos="word" morph="none" start_char="11019" end_char="11020">of</TOKEN>
<TOKEN id="token-82-5" pos="word" morph="none" start_char="11022" end_char="11024">the</TOKEN>
<TOKEN id="token-82-6" pos="word" morph="none" start_char="11026" end_char="11034">hospitals</TOKEN>
<TOKEN id="token-82-7" pos="punct" morph="none" start_char="11035" end_char="11036">,'</TOKEN>
<TOKEN id="token-82-8" pos="word" morph="none" start_char="11038" end_char="11039">he</TOKEN>
<TOKEN id="token-82-9" pos="word" morph="none" start_char="11041" end_char="11045">wrote</TOKEN>
<TOKEN id="token-82-10" pos="punct" morph="none" start_char="11046" end_char="11046">.</TOKEN>
</SEG>
<SEG id="segment-83" start_char="11050" end_char="11205">
<ORIGINAL_TEXT>Referencing a military athletics tournament in Wuhan in October, which US troops attended, he wrote: 'It might be US army who brought the epidemic to Wuhan.</ORIGINAL_TEXT>
<TOKEN id="token-83-0" pos="word" morph="none" start_char="11050" end_char="11060">Referencing</TOKEN>
<TOKEN id="token-83-1" pos="word" morph="none" start_char="11062" end_char="11062">a</TOKEN>
<TOKEN id="token-83-2" pos="word" morph="none" start_char="11064" end_char="11071">military</TOKEN>
<TOKEN id="token-83-3" pos="word" morph="none" start_char="11073" end_char="11081">athletics</TOKEN>
<TOKEN id="token-83-4" pos="word" morph="none" start_char="11083" end_char="11092">tournament</TOKEN>
<TOKEN id="token-83-5" pos="word" morph="none" start_char="11094" end_char="11095">in</TOKEN>
<TOKEN id="token-83-6" pos="word" morph="none" start_char="11097" end_char="11101">Wuhan</TOKEN>
<TOKEN id="token-83-7" pos="word" morph="none" start_char="11103" end_char="11104">in</TOKEN>
<TOKEN id="token-83-8" pos="word" morph="none" start_char="11106" end_char="11112">October</TOKEN>
<TOKEN id="token-83-9" pos="punct" morph="none" start_char="11113" end_char="11113">,</TOKEN>
<TOKEN id="token-83-10" pos="word" morph="none" start_char="11115" end_char="11119">which</TOKEN>
<TOKEN id="token-83-11" pos="word" morph="none" start_char="11121" end_char="11122">US</TOKEN>
<TOKEN id="token-83-12" pos="word" morph="none" start_char="11124" end_char="11129">troops</TOKEN>
<TOKEN id="token-83-13" pos="word" morph="none" start_char="11131" end_char="11138">attended</TOKEN>
<TOKEN id="token-83-14" pos="punct" morph="none" start_char="11139" end_char="11139">,</TOKEN>
<TOKEN id="token-83-15" pos="word" morph="none" start_char="11141" end_char="11142">he</TOKEN>
<TOKEN id="token-83-16" pos="word" morph="none" start_char="11144" end_char="11148">wrote</TOKEN>
<TOKEN id="token-83-17" pos="punct" morph="none" start_char="11149" end_char="11149">:</TOKEN>
<TOKEN id="token-83-18" pos="punct" morph="none" start_char="11151" end_char="11151">'</TOKEN>
<TOKEN id="token-83-19" pos="word" morph="none" start_char="11152" end_char="11153">It</TOKEN>
<TOKEN id="token-83-20" pos="word" morph="none" start_char="11155" end_char="11159">might</TOKEN>
<TOKEN id="token-83-21" pos="word" morph="none" start_char="11161" end_char="11162">be</TOKEN>
<TOKEN id="token-83-22" pos="word" morph="none" start_char="11164" end_char="11165">US</TOKEN>
<TOKEN id="token-83-23" pos="word" morph="none" start_char="11167" end_char="11170">army</TOKEN>
<TOKEN id="token-83-24" pos="word" morph="none" start_char="11172" end_char="11174">who</TOKEN>
<TOKEN id="token-83-25" pos="word" morph="none" start_char="11176" end_char="11182">brought</TOKEN>
<TOKEN id="token-83-26" pos="word" morph="none" start_char="11184" end_char="11186">the</TOKEN>
<TOKEN id="token-83-27" pos="word" morph="none" start_char="11188" end_char="11195">epidemic</TOKEN>
<TOKEN id="token-83-28" pos="word" morph="none" start_char="11197" end_char="11198">to</TOKEN>
<TOKEN id="token-83-29" pos="word" morph="none" start_char="11200" end_char="11204">Wuhan</TOKEN>
<TOKEN id="token-83-30" pos="punct" morph="none" start_char="11205" end_char="11205">.</TOKEN>
</SEG>
<SEG id="segment-84" start_char="11208" end_char="11223">
<ORIGINAL_TEXT>'Be transparent!</ORIGINAL_TEXT>
<TOKEN id="token-84-0" pos="punct" morph="none" start_char="11208" end_char="11208">'</TOKEN>
<TOKEN id="token-84-1" pos="word" morph="none" start_char="11209" end_char="11210">Be</TOKEN>
<TOKEN id="token-84-2" pos="word" morph="none" start_char="11212" end_char="11222">transparent</TOKEN>
<TOKEN id="token-84-3" pos="punct" morph="none" start_char="11223" end_char="11223">!</TOKEN>
</SEG>
<SEG id="segment-85" start_char="11225" end_char="11246">
<ORIGINAL_TEXT>Make public your data!</ORIGINAL_TEXT>
<TOKEN id="token-85-0" pos="word" morph="none" start_char="11225" end_char="11228">Make</TOKEN>
<TOKEN id="token-85-1" pos="word" morph="none" start_char="11230" end_char="11235">public</TOKEN>
<TOKEN id="token-85-2" pos="word" morph="none" start_char="11237" end_char="11240">your</TOKEN>
<TOKEN id="token-85-3" pos="word" morph="none" start_char="11242" end_char="11245">data</TOKEN>
<TOKEN id="token-85-4" pos="punct" morph="none" start_char="11246" end_char="11246">!</TOKEN>
</SEG>
<SEG id="segment-86" start_char="11248" end_char="11273">
<ORIGINAL_TEXT>US owe us an explanation!'</ORIGINAL_TEXT>
<TOKEN id="token-86-0" pos="word" morph="none" start_char="11248" end_char="11249">US</TOKEN>
<TOKEN id="token-86-1" pos="word" morph="none" start_char="11251" end_char="11253">owe</TOKEN>
<TOKEN id="token-86-2" pos="word" morph="none" start_char="11255" end_char="11256">us</TOKEN>
<TOKEN id="token-86-3" pos="word" morph="none" start_char="11258" end_char="11259">an</TOKEN>
<TOKEN id="token-86-4" pos="word" morph="none" start_char="11261" end_char="11271">explanation</TOKEN>
<TOKEN id="token-86-5" pos="punct" morph="none" start_char="11272" end_char="11273">!'</TOKEN>
</SEG>
<SEG id="segment-87" start_char="11276" end_char="11378">
<ORIGINAL_TEXT>In fact, America's 'patient zero' was a man who travelled from China to Washington State on January 15.</ORIGINAL_TEXT>
<TOKEN id="token-87-0" pos="word" morph="none" start_char="11276" end_char="11277">In</TOKEN>
<TOKEN id="token-87-1" pos="word" morph="none" start_char="11279" end_char="11282">fact</TOKEN>
<TOKEN id="token-87-2" pos="punct" morph="none" start_char="11283" end_char="11283">,</TOKEN>
<TOKEN id="token-87-3" pos="word" morph="none" start_char="11285" end_char="11293">America's</TOKEN>
<TOKEN id="token-87-4" pos="punct" morph="none" start_char="11295" end_char="11295">'</TOKEN>
<TOKEN id="token-87-5" pos="word" morph="none" start_char="11296" end_char="11302">patient</TOKEN>
<TOKEN id="token-87-6" pos="word" morph="none" start_char="11304" end_char="11307">zero</TOKEN>
<TOKEN id="token-87-7" pos="punct" morph="none" start_char="11308" end_char="11308">'</TOKEN>
<TOKEN id="token-87-8" pos="word" morph="none" start_char="11310" end_char="11312">was</TOKEN>
<TOKEN id="token-87-9" pos="word" morph="none" start_char="11314" end_char="11314">a</TOKEN>
<TOKEN id="token-87-10" pos="word" morph="none" start_char="11316" end_char="11318">man</TOKEN>
<TOKEN id="token-87-11" pos="word" morph="none" start_char="11320" end_char="11322">who</TOKEN>
<TOKEN id="token-87-12" pos="word" morph="none" start_char="11324" end_char="11332">travelled</TOKEN>
<TOKEN id="token-87-13" pos="word" morph="none" start_char="11334" end_char="11337">from</TOKEN>
<TOKEN id="token-87-14" pos="word" morph="none" start_char="11339" end_char="11343">China</TOKEN>
<TOKEN id="token-87-15" pos="word" morph="none" start_char="11345" end_char="11346">to</TOKEN>
<TOKEN id="token-87-16" pos="word" morph="none" start_char="11348" end_char="11357">Washington</TOKEN>
<TOKEN id="token-87-17" pos="word" morph="none" start_char="11359" end_char="11363">State</TOKEN>
<TOKEN id="token-87-18" pos="word" morph="none" start_char="11365" end_char="11366">on</TOKEN>
<TOKEN id="token-87-19" pos="word" morph="none" start_char="11368" end_char="11374">January</TOKEN>
<TOKEN id="token-87-20" pos="word" morph="none" start_char="11376" end_char="11377">15</TOKEN>
<TOKEN id="token-87-21" pos="punct" morph="none" start_char="11378" end_char="11378">.</TOKEN>
</SEG>
<SEG id="segment-88" start_char="11380" end_char="11428">
<ORIGINAL_TEXT>The case was confirmed by the CDC six days later.</ORIGINAL_TEXT>
<TOKEN id="token-88-0" pos="word" morph="none" start_char="11380" end_char="11382">The</TOKEN>
<TOKEN id="token-88-1" pos="word" morph="none" start_char="11384" end_char="11387">case</TOKEN>
<TOKEN id="token-88-2" pos="word" morph="none" start_char="11389" end_char="11391">was</TOKEN>
<TOKEN id="token-88-3" pos="word" morph="none" start_char="11393" end_char="11401">confirmed</TOKEN>
<TOKEN id="token-88-4" pos="word" morph="none" start_char="11403" end_char="11404">by</TOKEN>
<TOKEN id="token-88-5" pos="word" morph="none" start_char="11406" end_char="11408">the</TOKEN>
<TOKEN id="token-88-6" pos="word" morph="none" start_char="11410" end_char="11412">CDC</TOKEN>
<TOKEN id="token-88-7" pos="word" morph="none" start_char="11414" end_char="11416">six</TOKEN>
<TOKEN id="token-88-8" pos="word" morph="none" start_char="11418" end_char="11421">days</TOKEN>
<TOKEN id="token-88-9" pos="word" morph="none" start_char="11423" end_char="11427">later</TOKEN>
<TOKEN id="token-88-10" pos="punct" morph="none" start_char="11428" end_char="11428">.</TOKEN>
</SEG>
<SEG id="segment-89" start_char="11431" end_char="11673">
<ORIGINAL_TEXT>Chinese has also tried to push the theory that the virus originated in Italy, the country with the most deaths, by distorting a quote from an Italian doctor who suggested the country's first cases could have occurred much earlier than thought.</ORIGINAL_TEXT>
<TOKEN id="token-89-0" pos="word" morph="none" start_char="11431" end_char="11437">Chinese</TOKEN>
<TOKEN id="token-89-1" pos="word" morph="none" start_char="11439" end_char="11441">has</TOKEN>
<TOKEN id="token-89-2" pos="word" morph="none" start_char="11443" end_char="11446">also</TOKEN>
<TOKEN id="token-89-3" pos="word" morph="none" start_char="11448" end_char="11452">tried</TOKEN>
<TOKEN id="token-89-4" pos="word" morph="none" start_char="11454" end_char="11455">to</TOKEN>
<TOKEN id="token-89-5" pos="word" morph="none" start_char="11457" end_char="11460">push</TOKEN>
<TOKEN id="token-89-6" pos="word" morph="none" start_char="11462" end_char="11464">the</TOKEN>
<TOKEN id="token-89-7" pos="word" morph="none" start_char="11466" end_char="11471">theory</TOKEN>
<TOKEN id="token-89-8" pos="word" morph="none" start_char="11473" end_char="11476">that</TOKEN>
<TOKEN id="token-89-9" pos="word" morph="none" start_char="11478" end_char="11480">the</TOKEN>
<TOKEN id="token-89-10" pos="word" morph="none" start_char="11482" end_char="11486">virus</TOKEN>
<TOKEN id="token-89-11" pos="word" morph="none" start_char="11488" end_char="11497">originated</TOKEN>
<TOKEN id="token-89-12" pos="word" morph="none" start_char="11499" end_char="11500">in</TOKEN>
<TOKEN id="token-89-13" pos="word" morph="none" start_char="11502" end_char="11506">Italy</TOKEN>
<TOKEN id="token-89-14" pos="punct" morph="none" start_char="11507" end_char="11507">,</TOKEN>
<TOKEN id="token-89-15" pos="word" morph="none" start_char="11509" end_char="11511">the</TOKEN>
<TOKEN id="token-89-16" pos="word" morph="none" start_char="11513" end_char="11519">country</TOKEN>
<TOKEN id="token-89-17" pos="word" morph="none" start_char="11521" end_char="11524">with</TOKEN>
<TOKEN id="token-89-18" pos="word" morph="none" start_char="11526" end_char="11528">the</TOKEN>
<TOKEN id="token-89-19" pos="word" morph="none" start_char="11530" end_char="11533">most</TOKEN>
<TOKEN id="token-89-20" pos="word" morph="none" start_char="11535" end_char="11540">deaths</TOKEN>
<TOKEN id="token-89-21" pos="punct" morph="none" start_char="11541" end_char="11541">,</TOKEN>
<TOKEN id="token-89-22" pos="word" morph="none" start_char="11543" end_char="11544">by</TOKEN>
<TOKEN id="token-89-23" pos="word" morph="none" start_char="11546" end_char="11555">distorting</TOKEN>
<TOKEN id="token-89-24" pos="word" morph="none" start_char="11557" end_char="11557">a</TOKEN>
<TOKEN id="token-89-25" pos="word" morph="none" start_char="11559" end_char="11563">quote</TOKEN>
<TOKEN id="token-89-26" pos="word" morph="none" start_char="11565" end_char="11568">from</TOKEN>
<TOKEN id="token-89-27" pos="word" morph="none" start_char="11570" end_char="11571">an</TOKEN>
<TOKEN id="token-89-28" pos="word" morph="none" start_char="11573" end_char="11579">Italian</TOKEN>
<TOKEN id="token-89-29" pos="word" morph="none" start_char="11581" end_char="11586">doctor</TOKEN>
<TOKEN id="token-89-30" pos="word" morph="none" start_char="11588" end_char="11590">who</TOKEN>
<TOKEN id="token-89-31" pos="word" morph="none" start_char="11592" end_char="11600">suggested</TOKEN>
<TOKEN id="token-89-32" pos="word" morph="none" start_char="11602" end_char="11604">the</TOKEN>
<TOKEN id="token-89-33" pos="word" morph="none" start_char="11606" end_char="11614">country's</TOKEN>
<TOKEN id="token-89-34" pos="word" morph="none" start_char="11616" end_char="11620">first</TOKEN>
<TOKEN id="token-89-35" pos="word" morph="none" start_char="11622" end_char="11626">cases</TOKEN>
<TOKEN id="token-89-36" pos="word" morph="none" start_char="11628" end_char="11632">could</TOKEN>
<TOKEN id="token-89-37" pos="word" morph="none" start_char="11634" end_char="11637">have</TOKEN>
<TOKEN id="token-89-38" pos="word" morph="none" start_char="11639" end_char="11646">occurred</TOKEN>
<TOKEN id="token-89-39" pos="word" morph="none" start_char="11648" end_char="11651">much</TOKEN>
<TOKEN id="token-89-40" pos="word" morph="none" start_char="11653" end_char="11659">earlier</TOKEN>
<TOKEN id="token-89-41" pos="word" morph="none" start_char="11661" end_char="11664">than</TOKEN>
<TOKEN id="token-89-42" pos="word" morph="none" start_char="11666" end_char="11672">thought</TOKEN>
<TOKEN id="token-89-43" pos="punct" morph="none" start_char="11673" end_char="11673">.</TOKEN>
</SEG>
<SEG id="segment-90" start_char="11677" end_char="11832">
<ORIGINAL_TEXT>Giuseppe Remuzzi said he is investigating strange cases of pneumonia as far back as December and November, months before the virus was known to have spread.</ORIGINAL_TEXT>
<TOKEN id="token-90-0" pos="word" morph="none" start_char="11677" end_char="11684">Giuseppe</TOKEN>
<TOKEN id="token-90-1" pos="word" morph="none" start_char="11686" end_char="11692">Remuzzi</TOKEN>
<TOKEN id="token-90-2" pos="word" morph="none" start_char="11694" end_char="11697">said</TOKEN>
<TOKEN id="token-90-3" pos="word" morph="none" start_char="11699" end_char="11700">he</TOKEN>
<TOKEN id="token-90-4" pos="word" morph="none" start_char="11702" end_char="11703">is</TOKEN>
<TOKEN id="token-90-5" pos="word" morph="none" start_char="11705" end_char="11717">investigating</TOKEN>
<TOKEN id="token-90-6" pos="word" morph="none" start_char="11719" end_char="11725">strange</TOKEN>
<TOKEN id="token-90-7" pos="word" morph="none" start_char="11727" end_char="11731">cases</TOKEN>
<TOKEN id="token-90-8" pos="word" morph="none" start_char="11733" end_char="11734">of</TOKEN>
<TOKEN id="token-90-9" pos="word" morph="none" start_char="11736" end_char="11744">pneumonia</TOKEN>
<TOKEN id="token-90-10" pos="word" morph="none" start_char="11746" end_char="11747">as</TOKEN>
<TOKEN id="token-90-11" pos="word" morph="none" start_char="11749" end_char="11751">far</TOKEN>
<TOKEN id="token-90-12" pos="word" morph="none" start_char="11753" end_char="11756">back</TOKEN>
<TOKEN id="token-90-13" pos="word" morph="none" start_char="11758" end_char="11759">as</TOKEN>
<TOKEN id="token-90-14" pos="word" morph="none" start_char="11761" end_char="11768">December</TOKEN>
<TOKEN id="token-90-15" pos="word" morph="none" start_char="11770" end_char="11772">and</TOKEN>
<TOKEN id="token-90-16" pos="word" morph="none" start_char="11774" end_char="11781">November</TOKEN>
<TOKEN id="token-90-17" pos="punct" morph="none" start_char="11782" end_char="11782">,</TOKEN>
<TOKEN id="token-90-18" pos="word" morph="none" start_char="11784" end_char="11789">months</TOKEN>
<TOKEN id="token-90-19" pos="word" morph="none" start_char="11791" end_char="11796">before</TOKEN>
<TOKEN id="token-90-20" pos="word" morph="none" start_char="11798" end_char="11800">the</TOKEN>
<TOKEN id="token-90-21" pos="word" morph="none" start_char="11802" end_char="11806">virus</TOKEN>
<TOKEN id="token-90-22" pos="word" morph="none" start_char="11808" end_char="11810">was</TOKEN>
<TOKEN id="token-90-23" pos="word" morph="none" start_char="11812" end_char="11816">known</TOKEN>
<TOKEN id="token-90-24" pos="word" morph="none" start_char="11818" end_char="11819">to</TOKEN>
<TOKEN id="token-90-25" pos="word" morph="none" start_char="11821" end_char="11824">have</TOKEN>
<TOKEN id="token-90-26" pos="word" morph="none" start_char="11826" end_char="11831">spread</TOKEN>
<TOKEN id="token-90-27" pos="punct" morph="none" start_char="11832" end_char="11832">.</TOKEN>
</SEG>
<SEG id="segment-91" start_char="11835" end_char="11951">
<ORIGINAL_TEXT>Chinese state media widely reported his comments while also suggesting that the virus could have originated in Italy.</ORIGINAL_TEXT>
<TOKEN id="token-91-0" pos="word" morph="none" start_char="11835" end_char="11841">Chinese</TOKEN>
<TOKEN id="token-91-1" pos="word" morph="none" start_char="11843" end_char="11847">state</TOKEN>
<TOKEN id="token-91-2" pos="word" morph="none" start_char="11849" end_char="11853">media</TOKEN>
<TOKEN id="token-91-3" pos="word" morph="none" start_char="11855" end_char="11860">widely</TOKEN>
<TOKEN id="token-91-4" pos="word" morph="none" start_char="11862" end_char="11869">reported</TOKEN>
<TOKEN id="token-91-5" pos="word" morph="none" start_char="11871" end_char="11873">his</TOKEN>
<TOKEN id="token-91-6" pos="word" morph="none" start_char="11875" end_char="11882">comments</TOKEN>
<TOKEN id="token-91-7" pos="word" morph="none" start_char="11884" end_char="11888">while</TOKEN>
<TOKEN id="token-91-8" pos="word" morph="none" start_char="11890" end_char="11893">also</TOKEN>
<TOKEN id="token-91-9" pos="word" morph="none" start_char="11895" end_char="11904">suggesting</TOKEN>
<TOKEN id="token-91-10" pos="word" morph="none" start_char="11906" end_char="11909">that</TOKEN>
<TOKEN id="token-91-11" pos="word" morph="none" start_char="11911" end_char="11913">the</TOKEN>
<TOKEN id="token-91-12" pos="word" morph="none" start_char="11915" end_char="11919">virus</TOKEN>
<TOKEN id="token-91-13" pos="word" morph="none" start_char="11921" end_char="11925">could</TOKEN>
<TOKEN id="token-91-14" pos="word" morph="none" start_char="11927" end_char="11930">have</TOKEN>
<TOKEN id="token-91-15" pos="word" morph="none" start_char="11932" end_char="11941">originated</TOKEN>
<TOKEN id="token-91-16" pos="word" morph="none" start_char="11943" end_char="11944">in</TOKEN>
<TOKEN id="token-91-17" pos="word" morph="none" start_char="11946" end_char="11950">Italy</TOKEN>
<TOKEN id="token-91-18" pos="punct" morph="none" start_char="11951" end_char="11951">.</TOKEN>
</SEG>
<SEG id="segment-92" start_char="11954" end_char="12102">
<ORIGINAL_TEXT>In fact, Remuzzi says, there can be no doubt it started in Wuhan - but may have spread out of the province and across the world earlier than thought.</ORIGINAL_TEXT>
<TOKEN id="token-92-0" pos="word" morph="none" start_char="11954" end_char="11955">In</TOKEN>
<TOKEN id="token-92-1" pos="word" morph="none" start_char="11957" end_char="11960">fact</TOKEN>
<TOKEN id="token-92-2" pos="punct" morph="none" start_char="11961" end_char="11961">,</TOKEN>
<TOKEN id="token-92-3" pos="word" morph="none" start_char="11963" end_char="11969">Remuzzi</TOKEN>
<TOKEN id="token-92-4" pos="word" morph="none" start_char="11971" end_char="11974">says</TOKEN>
<TOKEN id="token-92-5" pos="punct" morph="none" start_char="11975" end_char="11975">,</TOKEN>
<TOKEN id="token-92-6" pos="word" morph="none" start_char="11977" end_char="11981">there</TOKEN>
<TOKEN id="token-92-7" pos="word" morph="none" start_char="11983" end_char="11985">can</TOKEN>
<TOKEN id="token-92-8" pos="word" morph="none" start_char="11987" end_char="11988">be</TOKEN>
<TOKEN id="token-92-9" pos="word" morph="none" start_char="11990" end_char="11991">no</TOKEN>
<TOKEN id="token-92-10" pos="word" morph="none" start_char="11993" end_char="11997">doubt</TOKEN>
<TOKEN id="token-92-11" pos="word" morph="none" start_char="11999" end_char="12000">it</TOKEN>
<TOKEN id="token-92-12" pos="word" morph="none" start_char="12002" end_char="12008">started</TOKEN>
<TOKEN id="token-92-13" pos="word" morph="none" start_char="12010" end_char="12011">in</TOKEN>
<TOKEN id="token-92-14" pos="word" morph="none" start_char="12013" end_char="12017">Wuhan</TOKEN>
<TOKEN id="token-92-15" pos="punct" morph="none" start_char="12019" end_char="12019">-</TOKEN>
<TOKEN id="token-92-16" pos="word" morph="none" start_char="12021" end_char="12023">but</TOKEN>
<TOKEN id="token-92-17" pos="word" morph="none" start_char="12025" end_char="12027">may</TOKEN>
<TOKEN id="token-92-18" pos="word" morph="none" start_char="12029" end_char="12032">have</TOKEN>
<TOKEN id="token-92-19" pos="word" morph="none" start_char="12034" end_char="12039">spread</TOKEN>
<TOKEN id="token-92-20" pos="word" morph="none" start_char="12041" end_char="12043">out</TOKEN>
<TOKEN id="token-92-21" pos="word" morph="none" start_char="12045" end_char="12046">of</TOKEN>
<TOKEN id="token-92-22" pos="word" morph="none" start_char="12048" end_char="12050">the</TOKEN>
<TOKEN id="token-92-23" pos="word" morph="none" start_char="12052" end_char="12059">province</TOKEN>
<TOKEN id="token-92-24" pos="word" morph="none" start_char="12061" end_char="12063">and</TOKEN>
<TOKEN id="token-92-25" pos="word" morph="none" start_char="12065" end_char="12070">across</TOKEN>
<TOKEN id="token-92-26" pos="word" morph="none" start_char="12072" end_char="12074">the</TOKEN>
<TOKEN id="token-92-27" pos="word" morph="none" start_char="12076" end_char="12080">world</TOKEN>
<TOKEN id="token-92-28" pos="word" morph="none" start_char="12082" end_char="12088">earlier</TOKEN>
<TOKEN id="token-92-29" pos="word" morph="none" start_char="12090" end_char="12093">than</TOKEN>
<TOKEN id="token-92-30" pos="word" morph="none" start_char="12095" end_char="12101">thought</TOKEN>
<TOKEN id="token-92-31" pos="punct" morph="none" start_char="12102" end_char="12102">.</TOKEN>
</SEG>
<SEG id="segment-93" start_char="12105" end_char="12119">
<ORIGINAL_TEXT>Infection total</ORIGINAL_TEXT>
<TOKEN id="token-93-0" pos="word" morph="none" start_char="12105" end_char="12113">Infection</TOKEN>
<TOKEN id="token-93-1" pos="word" morph="none" start_char="12115" end_char="12119">total</TOKEN>
</SEG>
<SEG id="segment-94" start_char="12122" end_char="12332">
<ORIGINAL_TEXT>China has reported a total of some 82,000 infections from coronavirus, claiming a domestic infection rate of zero for several days in a row recently - even as it eased lockdown restrictions in placed like Hubei.</ORIGINAL_TEXT>
<TOKEN id="token-94-0" pos="word" morph="none" start_char="12122" end_char="12126">China</TOKEN>
<TOKEN id="token-94-1" pos="word" morph="none" start_char="12128" end_char="12130">has</TOKEN>
<TOKEN id="token-94-2" pos="word" morph="none" start_char="12132" end_char="12139">reported</TOKEN>
<TOKEN id="token-94-3" pos="word" morph="none" start_char="12141" end_char="12141">a</TOKEN>
<TOKEN id="token-94-4" pos="word" morph="none" start_char="12143" end_char="12147">total</TOKEN>
<TOKEN id="token-94-5" pos="word" morph="none" start_char="12149" end_char="12150">of</TOKEN>
<TOKEN id="token-94-6" pos="word" morph="none" start_char="12152" end_char="12155">some</TOKEN>
<TOKEN id="token-94-7" pos="unknown" morph="none" start_char="12157" end_char="12162">82,000</TOKEN>
<TOKEN id="token-94-8" pos="word" morph="none" start_char="12164" end_char="12173">infections</TOKEN>
<TOKEN id="token-94-9" pos="word" morph="none" start_char="12175" end_char="12178">from</TOKEN>
<TOKEN id="token-94-10" pos="word" morph="none" start_char="12180" end_char="12190">coronavirus</TOKEN>
<TOKEN id="token-94-11" pos="punct" morph="none" start_char="12191" end_char="12191">,</TOKEN>
<TOKEN id="token-94-12" pos="word" morph="none" start_char="12193" end_char="12200">claiming</TOKEN>
<TOKEN id="token-94-13" pos="word" morph="none" start_char="12202" end_char="12202">a</TOKEN>
<TOKEN id="token-94-14" pos="word" morph="none" start_char="12204" end_char="12211">domestic</TOKEN>
<TOKEN id="token-94-15" pos="word" morph="none" start_char="12213" end_char="12221">infection</TOKEN>
<TOKEN id="token-94-16" pos="word" morph="none" start_char="12223" end_char="12226">rate</TOKEN>
<TOKEN id="token-94-17" pos="word" morph="none" start_char="12228" end_char="12229">of</TOKEN>
<TOKEN id="token-94-18" pos="word" morph="none" start_char="12231" end_char="12234">zero</TOKEN>
<TOKEN id="token-94-19" pos="word" morph="none" start_char="12236" end_char="12238">for</TOKEN>
<TOKEN id="token-94-20" pos="word" morph="none" start_char="12240" end_char="12246">several</TOKEN>
<TOKEN id="token-94-21" pos="word" morph="none" start_char="12248" end_char="12251">days</TOKEN>
<TOKEN id="token-94-22" pos="word" morph="none" start_char="12253" end_char="12254">in</TOKEN>
<TOKEN id="token-94-23" pos="word" morph="none" start_char="12256" end_char="12256">a</TOKEN>
<TOKEN id="token-94-24" pos="word" morph="none" start_char="12258" end_char="12260">row</TOKEN>
<TOKEN id="token-94-25" pos="word" morph="none" start_char="12262" end_char="12269">recently</TOKEN>
<TOKEN id="token-94-26" pos="punct" morph="none" start_char="12271" end_char="12271">-</TOKEN>
<TOKEN id="token-94-27" pos="word" morph="none" start_char="12273" end_char="12276">even</TOKEN>
<TOKEN id="token-94-28" pos="word" morph="none" start_char="12278" end_char="12279">as</TOKEN>
<TOKEN id="token-94-29" pos="word" morph="none" start_char="12281" end_char="12282">it</TOKEN>
<TOKEN id="token-94-30" pos="word" morph="none" start_char="12284" end_char="12288">eased</TOKEN>
<TOKEN id="token-94-31" pos="word" morph="none" start_char="12290" end_char="12297">lockdown</TOKEN>
<TOKEN id="token-94-32" pos="word" morph="none" start_char="12299" end_char="12310">restrictions</TOKEN>
<TOKEN id="token-94-33" pos="word" morph="none" start_char="12312" end_char="12313">in</TOKEN>
<TOKEN id="token-94-34" pos="word" morph="none" start_char="12315" end_char="12320">placed</TOKEN>
<TOKEN id="token-94-35" pos="word" morph="none" start_char="12322" end_char="12325">like</TOKEN>
<TOKEN id="token-94-36" pos="word" morph="none" start_char="12327" end_char="12331">Hubei</TOKEN>
<TOKEN id="token-94-37" pos="punct" morph="none" start_char="12332" end_char="12332">.</TOKEN>
</SEG>
<SEG id="segment-95" start_char="12335" end_char="12448">
<ORIGINAL_TEXT>But, by the country's own admission, the virus is likely still spreading - via people who have few or no symptoms.</ORIGINAL_TEXT>
<TOKEN id="token-95-0" pos="word" morph="none" start_char="12335" end_char="12337">But</TOKEN>
<TOKEN id="token-95-1" pos="punct" morph="none" start_char="12338" end_char="12338">,</TOKEN>
<TOKEN id="token-95-2" pos="word" morph="none" start_char="12340" end_char="12341">by</TOKEN>
<TOKEN id="token-95-3" pos="word" morph="none" start_char="12343" end_char="12345">the</TOKEN>
<TOKEN id="token-95-4" pos="word" morph="none" start_char="12347" end_char="12355">country's</TOKEN>
<TOKEN id="token-95-5" pos="word" morph="none" start_char="12357" end_char="12359">own</TOKEN>
<TOKEN id="token-95-6" pos="word" morph="none" start_char="12361" end_char="12369">admission</TOKEN>
<TOKEN id="token-95-7" pos="punct" morph="none" start_char="12370" end_char="12370">,</TOKEN>
<TOKEN id="token-95-8" pos="word" morph="none" start_char="12372" end_char="12374">the</TOKEN>
<TOKEN id="token-95-9" pos="word" morph="none" start_char="12376" end_char="12380">virus</TOKEN>
<TOKEN id="token-95-10" pos="word" morph="none" start_char="12382" end_char="12383">is</TOKEN>
<TOKEN id="token-95-11" pos="word" morph="none" start_char="12385" end_char="12390">likely</TOKEN>
<TOKEN id="token-95-12" pos="word" morph="none" start_char="12392" end_char="12396">still</TOKEN>
<TOKEN id="token-95-13" pos="word" morph="none" start_char="12398" end_char="12406">spreading</TOKEN>
<TOKEN id="token-95-14" pos="punct" morph="none" start_char="12408" end_char="12408">-</TOKEN>
<TOKEN id="token-95-15" pos="word" morph="none" start_char="12410" end_char="12412">via</TOKEN>
<TOKEN id="token-95-16" pos="word" morph="none" start_char="12414" end_char="12419">people</TOKEN>
<TOKEN id="token-95-17" pos="word" morph="none" start_char="12421" end_char="12423">who</TOKEN>
<TOKEN id="token-95-18" pos="word" morph="none" start_char="12425" end_char="12428">have</TOKEN>
<TOKEN id="token-95-19" pos="word" morph="none" start_char="12430" end_char="12432">few</TOKEN>
<TOKEN id="token-95-20" pos="word" morph="none" start_char="12434" end_char="12435">or</TOKEN>
<TOKEN id="token-95-21" pos="word" morph="none" start_char="12437" end_char="12438">no</TOKEN>
<TOKEN id="token-95-22" pos="word" morph="none" start_char="12440" end_char="12447">symptoms</TOKEN>
<TOKEN id="token-95-23" pos="punct" morph="none" start_char="12448" end_char="12448">.</TOKEN>
</SEG>
<SEG id="segment-96" start_char="12451" end_char="12633">
<ORIGINAL_TEXT>Beijing-based outlet Caixin reported that 'a couple to over 10 cases of covert infections of the virus are being detected' in China every day, despite not showing up in official data.</ORIGINAL_TEXT>
<TOKEN id="token-96-0" pos="unknown" morph="none" start_char="12451" end_char="12463">Beijing-based</TOKEN>
<TOKEN id="token-96-1" pos="word" morph="none" start_char="12465" end_char="12470">outlet</TOKEN>
<TOKEN id="token-96-2" pos="word" morph="none" start_char="12472" end_char="12477">Caixin</TOKEN>
<TOKEN id="token-96-3" pos="word" morph="none" start_char="12479" end_char="12486">reported</TOKEN>
<TOKEN id="token-96-4" pos="word" morph="none" start_char="12488" end_char="12491">that</TOKEN>
<TOKEN id="token-96-5" pos="punct" morph="none" start_char="12493" end_char="12493">'</TOKEN>
<TOKEN id="token-96-6" pos="word" morph="none" start_char="12494" end_char="12494">a</TOKEN>
<TOKEN id="token-96-7" pos="word" morph="none" start_char="12496" end_char="12501">couple</TOKEN>
<TOKEN id="token-96-8" pos="word" morph="none" start_char="12503" end_char="12504">to</TOKEN>
<TOKEN id="token-96-9" pos="word" morph="none" start_char="12506" end_char="12509">over</TOKEN>
<TOKEN id="token-96-10" pos="word" morph="none" start_char="12511" end_char="12512">10</TOKEN>
<TOKEN id="token-96-11" pos="word" morph="none" start_char="12514" end_char="12518">cases</TOKEN>
<TOKEN id="token-96-12" pos="word" morph="none" start_char="12520" end_char="12521">of</TOKEN>
<TOKEN id="token-96-13" pos="word" morph="none" start_char="12523" end_char="12528">covert</TOKEN>
<TOKEN id="token-96-14" pos="word" morph="none" start_char="12530" end_char="12539">infections</TOKEN>
<TOKEN id="token-96-15" pos="word" morph="none" start_char="12541" end_char="12542">of</TOKEN>
<TOKEN id="token-96-16" pos="word" morph="none" start_char="12544" end_char="12546">the</TOKEN>
<TOKEN id="token-96-17" pos="word" morph="none" start_char="12548" end_char="12552">virus</TOKEN>
<TOKEN id="token-96-18" pos="word" morph="none" start_char="12554" end_char="12556">are</TOKEN>
<TOKEN id="token-96-19" pos="word" morph="none" start_char="12558" end_char="12562">being</TOKEN>
<TOKEN id="token-96-20" pos="word" morph="none" start_char="12564" end_char="12571">detected</TOKEN>
<TOKEN id="token-96-21" pos="punct" morph="none" start_char="12572" end_char="12572">'</TOKEN>
<TOKEN id="token-96-22" pos="word" morph="none" start_char="12574" end_char="12575">in</TOKEN>
<TOKEN id="token-96-23" pos="word" morph="none" start_char="12577" end_char="12581">China</TOKEN>
<TOKEN id="token-96-24" pos="word" morph="none" start_char="12583" end_char="12587">every</TOKEN>
<TOKEN id="token-96-25" pos="word" morph="none" start_char="12589" end_char="12591">day</TOKEN>
<TOKEN id="token-96-26" pos="punct" morph="none" start_char="12592" end_char="12592">,</TOKEN>
<TOKEN id="token-96-27" pos="word" morph="none" start_char="12594" end_char="12600">despite</TOKEN>
<TOKEN id="token-96-28" pos="word" morph="none" start_char="12602" end_char="12604">not</TOKEN>
<TOKEN id="token-96-29" pos="word" morph="none" start_char="12606" end_char="12612">showing</TOKEN>
<TOKEN id="token-96-30" pos="word" morph="none" start_char="12614" end_char="12615">up</TOKEN>
<TOKEN id="token-96-31" pos="word" morph="none" start_char="12617" end_char="12618">in</TOKEN>
<TOKEN id="token-96-32" pos="word" morph="none" start_char="12620" end_char="12627">official</TOKEN>
<TOKEN id="token-96-33" pos="word" morph="none" start_char="12629" end_char="12632">data</TOKEN>
<TOKEN id="token-96-34" pos="punct" morph="none" start_char="12633" end_char="12633">.</TOKEN>
</SEG>
<SEG id="segment-97" start_char="12636" end_char="12732">
<ORIGINAL_TEXT>Meanwhile foreign governments have heaped scorn on China's infection reporting cannot be trusted.</ORIGINAL_TEXT>
<TOKEN id="token-97-0" pos="word" morph="none" start_char="12636" end_char="12644">Meanwhile</TOKEN>
<TOKEN id="token-97-1" pos="word" morph="none" start_char="12646" end_char="12652">foreign</TOKEN>
<TOKEN id="token-97-2" pos="word" morph="none" start_char="12654" end_char="12664">governments</TOKEN>
<TOKEN id="token-97-3" pos="word" morph="none" start_char="12666" end_char="12669">have</TOKEN>
<TOKEN id="token-97-4" pos="word" morph="none" start_char="12671" end_char="12676">heaped</TOKEN>
<TOKEN id="token-97-5" pos="word" morph="none" start_char="12678" end_char="12682">scorn</TOKEN>
<TOKEN id="token-97-6" pos="word" morph="none" start_char="12684" end_char="12685">on</TOKEN>
<TOKEN id="token-97-7" pos="word" morph="none" start_char="12687" end_char="12693">China's</TOKEN>
<TOKEN id="token-97-8" pos="word" morph="none" start_char="12695" end_char="12703">infection</TOKEN>
<TOKEN id="token-97-9" pos="word" morph="none" start_char="12705" end_char="12713">reporting</TOKEN>
<TOKEN id="token-97-10" pos="word" morph="none" start_char="12715" end_char="12720">cannot</TOKEN>
<TOKEN id="token-97-11" pos="word" morph="none" start_char="12722" end_char="12723">be</TOKEN>
<TOKEN id="token-97-12" pos="word" morph="none" start_char="12725" end_char="12731">trusted</TOKEN>
<TOKEN id="token-97-13" pos="punct" morph="none" start_char="12732" end_char="12732">.</TOKEN>
</SEG>
<SEG id="segment-98" start_char="12735" end_char="12950">
<ORIGINAL_TEXT>Marco Rubio, a prominent Republican senator and former presidential candidate from the US, tweeted that 'we have NO IDEA how many cases China really has' after the US infection total passed Beijing's official figure.</ORIGINAL_TEXT>
<TOKEN id="token-98-0" pos="word" morph="none" start_char="12735" end_char="12739">Marco</TOKEN>
<TOKEN id="token-98-1" pos="word" morph="none" start_char="12741" end_char="12745">Rubio</TOKEN>
<TOKEN id="token-98-2" pos="punct" morph="none" start_char="12746" end_char="12746">,</TOKEN>
<TOKEN id="token-98-3" pos="word" morph="none" start_char="12748" end_char="12748">a</TOKEN>
<TOKEN id="token-98-4" pos="word" morph="none" start_char="12750" end_char="12758">prominent</TOKEN>
<TOKEN id="token-98-5" pos="word" morph="none" start_char="12760" end_char="12769">Republican</TOKEN>
<TOKEN id="token-98-6" pos="word" morph="none" start_char="12771" end_char="12777">senator</TOKEN>
<TOKEN id="token-98-7" pos="word" morph="none" start_char="12779" end_char="12781">and</TOKEN>
<TOKEN id="token-98-8" pos="word" morph="none" start_char="12783" end_char="12788">former</TOKEN>
<TOKEN id="token-98-9" pos="word" morph="none" start_char="12790" end_char="12801">presidential</TOKEN>
<TOKEN id="token-98-10" pos="word" morph="none" start_char="12803" end_char="12811">candidate</TOKEN>
<TOKEN id="token-98-11" pos="word" morph="none" start_char="12813" end_char="12816">from</TOKEN>
<TOKEN id="token-98-12" pos="word" morph="none" start_char="12818" end_char="12820">the</TOKEN>
<TOKEN id="token-98-13" pos="word" morph="none" start_char="12822" end_char="12823">US</TOKEN>
<TOKEN id="token-98-14" pos="punct" morph="none" start_char="12824" end_char="12824">,</TOKEN>
<TOKEN id="token-98-15" pos="word" morph="none" start_char="12826" end_char="12832">tweeted</TOKEN>
<TOKEN id="token-98-16" pos="word" morph="none" start_char="12834" end_char="12837">that</TOKEN>
<TOKEN id="token-98-17" pos="punct" morph="none" start_char="12839" end_char="12839">'</TOKEN>
<TOKEN id="token-98-18" pos="word" morph="none" start_char="12840" end_char="12841">we</TOKEN>
<TOKEN id="token-98-19" pos="word" morph="none" start_char="12843" end_char="12846">have</TOKEN>
<TOKEN id="token-98-20" pos="word" morph="none" start_char="12848" end_char="12849">NO</TOKEN>
<TOKEN id="token-98-21" pos="word" morph="none" start_char="12851" end_char="12854">IDEA</TOKEN>
<TOKEN id="token-98-22" pos="word" morph="none" start_char="12856" end_char="12858">how</TOKEN>
<TOKEN id="token-98-23" pos="word" morph="none" start_char="12860" end_char="12863">many</TOKEN>
<TOKEN id="token-98-24" pos="word" morph="none" start_char="12865" end_char="12869">cases</TOKEN>
<TOKEN id="token-98-25" pos="word" morph="none" start_char="12871" end_char="12875">China</TOKEN>
<TOKEN id="token-98-26" pos="word" morph="none" start_char="12877" end_char="12882">really</TOKEN>
<TOKEN id="token-98-27" pos="word" morph="none" start_char="12884" end_char="12886">has</TOKEN>
<TOKEN id="token-98-28" pos="punct" morph="none" start_char="12887" end_char="12887">'</TOKEN>
<TOKEN id="token-98-29" pos="word" morph="none" start_char="12889" end_char="12893">after</TOKEN>
<TOKEN id="token-98-30" pos="word" morph="none" start_char="12895" end_char="12897">the</TOKEN>
<TOKEN id="token-98-31" pos="word" morph="none" start_char="12899" end_char="12900">US</TOKEN>
<TOKEN id="token-98-32" pos="word" morph="none" start_char="12902" end_char="12910">infection</TOKEN>
<TOKEN id="token-98-33" pos="word" morph="none" start_char="12912" end_char="12916">total</TOKEN>
<TOKEN id="token-98-34" pos="word" morph="none" start_char="12918" end_char="12923">passed</TOKEN>
<TOKEN id="token-98-35" pos="word" morph="none" start_char="12925" end_char="12933">Beijing's</TOKEN>
<TOKEN id="token-98-36" pos="word" morph="none" start_char="12935" end_char="12942">official</TOKEN>
<TOKEN id="token-98-37" pos="word" morph="none" start_char="12944" end_char="12949">figure</TOKEN>
<TOKEN id="token-98-38" pos="punct" morph="none" start_char="12950" end_char="12950">.</TOKEN>
</SEG>
<SEG id="segment-99" start_char="12953" end_char="13030">
<ORIGINAL_TEXT>'Without any doubt it's significantly more than what they admit to,' he added.</ORIGINAL_TEXT>
<TOKEN id="token-99-0" pos="punct" morph="none" start_char="12953" end_char="12953">'</TOKEN>
<TOKEN id="token-99-1" pos="word" morph="none" start_char="12954" end_char="12960">Without</TOKEN>
<TOKEN id="token-99-2" pos="word" morph="none" start_char="12962" end_char="12964">any</TOKEN>
<TOKEN id="token-99-3" pos="word" morph="none" start_char="12966" end_char="12970">doubt</TOKEN>
<TOKEN id="token-99-4" pos="word" morph="none" start_char="12972" end_char="12975">it's</TOKEN>
<TOKEN id="token-99-5" pos="word" morph="none" start_char="12977" end_char="12989">significantly</TOKEN>
<TOKEN id="token-99-6" pos="word" morph="none" start_char="12991" end_char="12994">more</TOKEN>
<TOKEN id="token-99-7" pos="word" morph="none" start_char="12996" end_char="12999">than</TOKEN>
<TOKEN id="token-99-8" pos="word" morph="none" start_char="13001" end_char="13004">what</TOKEN>
<TOKEN id="token-99-9" pos="word" morph="none" start_char="13006" end_char="13009">they</TOKEN>
<TOKEN id="token-99-10" pos="word" morph="none" start_char="13011" end_char="13015">admit</TOKEN>
<TOKEN id="token-99-11" pos="word" morph="none" start_char="13017" end_char="13018">to</TOKEN>
<TOKEN id="token-99-12" pos="punct" morph="none" start_char="13019" end_char="13020">,'</TOKEN>
<TOKEN id="token-99-13" pos="word" morph="none" start_char="13022" end_char="13023">he</TOKEN>
<TOKEN id="token-99-14" pos="word" morph="none" start_char="13025" end_char="13029">added</TOKEN>
<TOKEN id="token-99-15" pos="punct" morph="none" start_char="13030" end_char="13030">.</TOKEN>
</SEG>
<SEG id="segment-100" start_char="13033" end_char="13231">
<ORIGINAL_TEXT>Meanwhile the UK government has also cast doubt on China's reporting, with Conservative minister and former Prime Ministerial candidate Michael Gove claiming the Communist Party could not be trusted.</ORIGINAL_TEXT>
<TOKEN id="token-100-0" pos="word" morph="none" start_char="13033" end_char="13041">Meanwhile</TOKEN>
<TOKEN id="token-100-1" pos="word" morph="none" start_char="13043" end_char="13045">the</TOKEN>
<TOKEN id="token-100-2" pos="word" morph="none" start_char="13047" end_char="13048">UK</TOKEN>
<TOKEN id="token-100-3" pos="word" morph="none" start_char="13050" end_char="13059">government</TOKEN>
<TOKEN id="token-100-4" pos="word" morph="none" start_char="13061" end_char="13063">has</TOKEN>
<TOKEN id="token-100-5" pos="word" morph="none" start_char="13065" end_char="13068">also</TOKEN>
<TOKEN id="token-100-6" pos="word" morph="none" start_char="13070" end_char="13073">cast</TOKEN>
<TOKEN id="token-100-7" pos="word" morph="none" start_char="13075" end_char="13079">doubt</TOKEN>
<TOKEN id="token-100-8" pos="word" morph="none" start_char="13081" end_char="13082">on</TOKEN>
<TOKEN id="token-100-9" pos="word" morph="none" start_char="13084" end_char="13090">China's</TOKEN>
<TOKEN id="token-100-10" pos="word" morph="none" start_char="13092" end_char="13100">reporting</TOKEN>
<TOKEN id="token-100-11" pos="punct" morph="none" start_char="13101" end_char="13101">,</TOKEN>
<TOKEN id="token-100-12" pos="word" morph="none" start_char="13103" end_char="13106">with</TOKEN>
<TOKEN id="token-100-13" pos="word" morph="none" start_char="13108" end_char="13119">Conservative</TOKEN>
<TOKEN id="token-100-14" pos="word" morph="none" start_char="13121" end_char="13128">minister</TOKEN>
<TOKEN id="token-100-15" pos="word" morph="none" start_char="13130" end_char="13132">and</TOKEN>
<TOKEN id="token-100-16" pos="word" morph="none" start_char="13134" end_char="13139">former</TOKEN>
<TOKEN id="token-100-17" pos="word" morph="none" start_char="13141" end_char="13145">Prime</TOKEN>
<TOKEN id="token-100-18" pos="word" morph="none" start_char="13147" end_char="13157">Ministerial</TOKEN>
<TOKEN id="token-100-19" pos="word" morph="none" start_char="13159" end_char="13167">candidate</TOKEN>
<TOKEN id="token-100-20" pos="word" morph="none" start_char="13169" end_char="13175">Michael</TOKEN>
<TOKEN id="token-100-21" pos="word" morph="none" start_char="13177" end_char="13180">Gove</TOKEN>
<TOKEN id="token-100-22" pos="word" morph="none" start_char="13182" end_char="13189">claiming</TOKEN>
<TOKEN id="token-100-23" pos="word" morph="none" start_char="13191" end_char="13193">the</TOKEN>
<TOKEN id="token-100-24" pos="word" morph="none" start_char="13195" end_char="13203">Communist</TOKEN>
<TOKEN id="token-100-25" pos="word" morph="none" start_char="13205" end_char="13209">Party</TOKEN>
<TOKEN id="token-100-26" pos="word" morph="none" start_char="13211" end_char="13215">could</TOKEN>
<TOKEN id="token-100-27" pos="word" morph="none" start_char="13217" end_char="13219">not</TOKEN>
<TOKEN id="token-100-28" pos="word" morph="none" start_char="13221" end_char="13222">be</TOKEN>
<TOKEN id="token-100-29" pos="word" morph="none" start_char="13224" end_char="13230">trusted</TOKEN>
<TOKEN id="token-100-30" pos="punct" morph="none" start_char="13231" end_char="13231">.</TOKEN>
</SEG>
<SEG id="segment-101" start_char="13234" end_char="13363">
<ORIGINAL_TEXT>'Some of the reporting from China was not clear about the scale, the nature, the infectiousness of this [virus],' he told the BBC.</ORIGINAL_TEXT>
<TOKEN id="token-101-0" pos="punct" morph="none" start_char="13234" end_char="13234">'</TOKEN>
<TOKEN id="token-101-1" pos="word" morph="none" start_char="13235" end_char="13238">Some</TOKEN>
<TOKEN id="token-101-2" pos="word" morph="none" start_char="13240" end_char="13241">of</TOKEN>
<TOKEN id="token-101-3" pos="word" morph="none" start_char="13243" end_char="13245">the</TOKEN>
<TOKEN id="token-101-4" pos="word" morph="none" start_char="13247" end_char="13255">reporting</TOKEN>
<TOKEN id="token-101-5" pos="word" morph="none" start_char="13257" end_char="13260">from</TOKEN>
<TOKEN id="token-101-6" pos="word" morph="none" start_char="13262" end_char="13266">China</TOKEN>
<TOKEN id="token-101-7" pos="word" morph="none" start_char="13268" end_char="13270">was</TOKEN>
<TOKEN id="token-101-8" pos="word" morph="none" start_char="13272" end_char="13274">not</TOKEN>
<TOKEN id="token-101-9" pos="word" morph="none" start_char="13276" end_char="13280">clear</TOKEN>
<TOKEN id="token-101-10" pos="word" morph="none" start_char="13282" end_char="13286">about</TOKEN>
<TOKEN id="token-101-11" pos="word" morph="none" start_char="13288" end_char="13290">the</TOKEN>
<TOKEN id="token-101-12" pos="word" morph="none" start_char="13292" end_char="13296">scale</TOKEN>
<TOKEN id="token-101-13" pos="punct" morph="none" start_char="13297" end_char="13297">,</TOKEN>
<TOKEN id="token-101-14" pos="word" morph="none" start_char="13299" end_char="13301">the</TOKEN>
<TOKEN id="token-101-15" pos="word" morph="none" start_char="13303" end_char="13308">nature</TOKEN>
<TOKEN id="token-101-16" pos="punct" morph="none" start_char="13309" end_char="13309">,</TOKEN>
<TOKEN id="token-101-17" pos="word" morph="none" start_char="13311" end_char="13313">the</TOKEN>
<TOKEN id="token-101-18" pos="word" morph="none" start_char="13315" end_char="13328">infectiousness</TOKEN>
<TOKEN id="token-101-19" pos="word" morph="none" start_char="13330" end_char="13331">of</TOKEN>
<TOKEN id="token-101-20" pos="word" morph="none" start_char="13333" end_char="13336">this</TOKEN>
<TOKEN id="token-101-21" pos="punct" morph="none" start_char="13338" end_char="13338">[</TOKEN>
<TOKEN id="token-101-22" pos="word" morph="none" start_char="13339" end_char="13343">virus</TOKEN>
<TOKEN id="token-101-23" pos="punct" morph="none" start_char="13344" end_char="13346">],'</TOKEN>
<TOKEN id="token-101-24" pos="word" morph="none" start_char="13348" end_char="13349">he</TOKEN>
<TOKEN id="token-101-25" pos="word" morph="none" start_char="13351" end_char="13354">told</TOKEN>
<TOKEN id="token-101-26" pos="word" morph="none" start_char="13356" end_char="13358">the</TOKEN>
<TOKEN id="token-101-27" pos="word" morph="none" start_char="13360" end_char="13362">BBC</TOKEN>
<TOKEN id="token-101-28" pos="punct" morph="none" start_char="13363" end_char="13363">.</TOKEN>
</SEG>
<SEG id="segment-102" start_char="13366" end_char="13497">
<ORIGINAL_TEXT>Meanwhile sources told the Mail that China's true infection total could be anything up to 40 times as high as reports had suggested.</ORIGINAL_TEXT>
<TOKEN id="token-102-0" pos="word" morph="none" start_char="13366" end_char="13374">Meanwhile</TOKEN>
<TOKEN id="token-102-1" pos="word" morph="none" start_char="13376" end_char="13382">sources</TOKEN>
<TOKEN id="token-102-2" pos="word" morph="none" start_char="13384" end_char="13387">told</TOKEN>
<TOKEN id="token-102-3" pos="word" morph="none" start_char="13389" end_char="13391">the</TOKEN>
<TOKEN id="token-102-4" pos="word" morph="none" start_char="13393" end_char="13396">Mail</TOKEN>
<TOKEN id="token-102-5" pos="word" morph="none" start_char="13398" end_char="13401">that</TOKEN>
<TOKEN id="token-102-6" pos="word" morph="none" start_char="13403" end_char="13409">China's</TOKEN>
<TOKEN id="token-102-7" pos="word" morph="none" start_char="13411" end_char="13414">true</TOKEN>
<TOKEN id="token-102-8" pos="word" morph="none" start_char="13416" end_char="13424">infection</TOKEN>
<TOKEN id="token-102-9" pos="word" morph="none" start_char="13426" end_char="13430">total</TOKEN>
<TOKEN id="token-102-10" pos="word" morph="none" start_char="13432" end_char="13436">could</TOKEN>
<TOKEN id="token-102-11" pos="word" morph="none" start_char="13438" end_char="13439">be</TOKEN>
<TOKEN id="token-102-12" pos="word" morph="none" start_char="13441" end_char="13448">anything</TOKEN>
<TOKEN id="token-102-13" pos="word" morph="none" start_char="13450" end_char="13451">up</TOKEN>
<TOKEN id="token-102-14" pos="word" morph="none" start_char="13453" end_char="13454">to</TOKEN>
<TOKEN id="token-102-15" pos="word" morph="none" start_char="13456" end_char="13457">40</TOKEN>
<TOKEN id="token-102-16" pos="word" morph="none" start_char="13459" end_char="13463">times</TOKEN>
<TOKEN id="token-102-17" pos="word" morph="none" start_char="13465" end_char="13466">as</TOKEN>
<TOKEN id="token-102-18" pos="word" morph="none" start_char="13468" end_char="13471">high</TOKEN>
<TOKEN id="token-102-19" pos="word" morph="none" start_char="13473" end_char="13474">as</TOKEN>
<TOKEN id="token-102-20" pos="word" morph="none" start_char="13476" end_char="13482">reports</TOKEN>
<TOKEN id="token-102-21" pos="word" morph="none" start_char="13484" end_char="13486">had</TOKEN>
<TOKEN id="token-102-22" pos="word" morph="none" start_char="13488" end_char="13496">suggested</TOKEN>
<TOKEN id="token-102-23" pos="punct" morph="none" start_char="13497" end_char="13497">.</TOKEN>
</SEG>
<SEG id="segment-103" start_char="13501" end_char="13632">
<ORIGINAL_TEXT>Marco Rubio, a prominent Republican senator, has said that China's figures cannot be trusted and a far higher than has been reported</ORIGINAL_TEXT>
<TOKEN id="token-103-0" pos="word" morph="none" start_char="13501" end_char="13505">Marco</TOKEN>
<TOKEN id="token-103-1" pos="word" morph="none" start_char="13507" end_char="13511">Rubio</TOKEN>
<TOKEN id="token-103-2" pos="punct" morph="none" start_char="13512" end_char="13512">,</TOKEN>
<TOKEN id="token-103-3" pos="word" morph="none" start_char="13514" end_char="13514">a</TOKEN>
<TOKEN id="token-103-4" pos="word" morph="none" start_char="13516" end_char="13524">prominent</TOKEN>
<TOKEN id="token-103-5" pos="word" morph="none" start_char="13526" end_char="13535">Republican</TOKEN>
<TOKEN id="token-103-6" pos="word" morph="none" start_char="13537" end_char="13543">senator</TOKEN>
<TOKEN id="token-103-7" pos="punct" morph="none" start_char="13544" end_char="13544">,</TOKEN>
<TOKEN id="token-103-8" pos="word" morph="none" start_char="13546" end_char="13548">has</TOKEN>
<TOKEN id="token-103-9" pos="word" morph="none" start_char="13550" end_char="13553">said</TOKEN>
<TOKEN id="token-103-10" pos="word" morph="none" start_char="13555" end_char="13558">that</TOKEN>
<TOKEN id="token-103-11" pos="word" morph="none" start_char="13560" end_char="13566">China's</TOKEN>
<TOKEN id="token-103-12" pos="word" morph="none" start_char="13568" end_char="13574">figures</TOKEN>
<TOKEN id="token-103-13" pos="word" morph="none" start_char="13576" end_char="13581">cannot</TOKEN>
<TOKEN id="token-103-14" pos="word" morph="none" start_char="13583" end_char="13584">be</TOKEN>
<TOKEN id="token-103-15" pos="word" morph="none" start_char="13586" end_char="13592">trusted</TOKEN>
<TOKEN id="token-103-16" pos="word" morph="none" start_char="13594" end_char="13596">and</TOKEN>
<TOKEN id="token-103-17" pos="word" morph="none" start_char="13598" end_char="13598">a</TOKEN>
<TOKEN id="token-103-18" pos="word" morph="none" start_char="13600" end_char="13602">far</TOKEN>
<TOKEN id="token-103-19" pos="word" morph="none" start_char="13604" end_char="13609">higher</TOKEN>
<TOKEN id="token-103-20" pos="word" morph="none" start_char="13611" end_char="13614">than</TOKEN>
<TOKEN id="token-103-21" pos="word" morph="none" start_char="13616" end_char="13618">has</TOKEN>
<TOKEN id="token-103-22" pos="word" morph="none" start_char="13620" end_char="13623">been</TOKEN>
<TOKEN id="token-103-23" pos="word" morph="none" start_char="13625" end_char="13632">reported</TOKEN>
</SEG>
<SEG id="segment-104" start_char="13635" end_char="13645">
<ORIGINAL_TEXT>Death total</ORIGINAL_TEXT>
<TOKEN id="token-104-0" pos="word" morph="none" start_char="13635" end_char="13639">Death</TOKEN>
<TOKEN id="token-104-1" pos="word" morph="none" start_char="13641" end_char="13645">total</TOKEN>
</SEG>
<SEG id="segment-105" start_char="13648" end_char="13758">
<ORIGINAL_TEXT>Doubt has also been cast on China's reported death toll from the virus, which currently stands at around 3,300.</ORIGINAL_TEXT>
<TOKEN id="token-105-0" pos="word" morph="none" start_char="13648" end_char="13652">Doubt</TOKEN>
<TOKEN id="token-105-1" pos="word" morph="none" start_char="13654" end_char="13656">has</TOKEN>
<TOKEN id="token-105-2" pos="word" morph="none" start_char="13658" end_char="13661">also</TOKEN>
<TOKEN id="token-105-3" pos="word" morph="none" start_char="13663" end_char="13666">been</TOKEN>
<TOKEN id="token-105-4" pos="word" morph="none" start_char="13668" end_char="13671">cast</TOKEN>
<TOKEN id="token-105-5" pos="word" morph="none" start_char="13673" end_char="13674">on</TOKEN>
<TOKEN id="token-105-6" pos="word" morph="none" start_char="13676" end_char="13682">China's</TOKEN>
<TOKEN id="token-105-7" pos="word" morph="none" start_char="13684" end_char="13691">reported</TOKEN>
<TOKEN id="token-105-8" pos="word" morph="none" start_char="13693" end_char="13697">death</TOKEN>
<TOKEN id="token-105-9" pos="word" morph="none" start_char="13699" end_char="13702">toll</TOKEN>
<TOKEN id="token-105-10" pos="word" morph="none" start_char="13704" end_char="13707">from</TOKEN>
<TOKEN id="token-105-11" pos="word" morph="none" start_char="13709" end_char="13711">the</TOKEN>
<TOKEN id="token-105-12" pos="word" morph="none" start_char="13713" end_char="13717">virus</TOKEN>
<TOKEN id="token-105-13" pos="punct" morph="none" start_char="13718" end_char="13718">,</TOKEN>
<TOKEN id="token-105-14" pos="word" morph="none" start_char="13720" end_char="13724">which</TOKEN>
<TOKEN id="token-105-15" pos="word" morph="none" start_char="13726" end_char="13734">currently</TOKEN>
<TOKEN id="token-105-16" pos="word" morph="none" start_char="13736" end_char="13741">stands</TOKEN>
<TOKEN id="token-105-17" pos="word" morph="none" start_char="13743" end_char="13744">at</TOKEN>
<TOKEN id="token-105-18" pos="word" morph="none" start_char="13746" end_char="13751">around</TOKEN>
<TOKEN id="token-105-19" pos="unknown" morph="none" start_char="13753" end_char="13757">3,300</TOKEN>
<TOKEN id="token-105-20" pos="punct" morph="none" start_char="13758" end_char="13758">.</TOKEN>
</SEG>
<SEG id="segment-106" start_char="13761" end_char="13953">
<ORIGINAL_TEXT>Locals in epicenter city Wuhan have been keeping an eye on funeral homes since lockdown restrictions were partly lifted, claiming they have been 'working around the clock' to dispose of bodies.</ORIGINAL_TEXT>
<TOKEN id="token-106-0" pos="word" morph="none" start_char="13761" end_char="13766">Locals</TOKEN>
<TOKEN id="token-106-1" pos="word" morph="none" start_char="13768" end_char="13769">in</TOKEN>
<TOKEN id="token-106-2" pos="word" morph="none" start_char="13771" end_char="13779">epicenter</TOKEN>
<TOKEN id="token-106-3" pos="word" morph="none" start_char="13781" end_char="13784">city</TOKEN>
<TOKEN id="token-106-4" pos="word" morph="none" start_char="13786" end_char="13790">Wuhan</TOKEN>
<TOKEN id="token-106-5" pos="word" morph="none" start_char="13792" end_char="13795">have</TOKEN>
<TOKEN id="token-106-6" pos="word" morph="none" start_char="13797" end_char="13800">been</TOKEN>
<TOKEN id="token-106-7" pos="word" morph="none" start_char="13802" end_char="13808">keeping</TOKEN>
<TOKEN id="token-106-8" pos="word" morph="none" start_char="13810" end_char="13811">an</TOKEN>
<TOKEN id="token-106-9" pos="word" morph="none" start_char="13813" end_char="13815">eye</TOKEN>
<TOKEN id="token-106-10" pos="word" morph="none" start_char="13817" end_char="13818">on</TOKEN>
<TOKEN id="token-106-11" pos="word" morph="none" start_char="13820" end_char="13826">funeral</TOKEN>
<TOKEN id="token-106-12" pos="word" morph="none" start_char="13828" end_char="13832">homes</TOKEN>
<TOKEN id="token-106-13" pos="word" morph="none" start_char="13834" end_char="13838">since</TOKEN>
<TOKEN id="token-106-14" pos="word" morph="none" start_char="13840" end_char="13847">lockdown</TOKEN>
<TOKEN id="token-106-15" pos="word" morph="none" start_char="13849" end_char="13860">restrictions</TOKEN>
<TOKEN id="token-106-16" pos="word" morph="none" start_char="13862" end_char="13865">were</TOKEN>
<TOKEN id="token-106-17" pos="word" morph="none" start_char="13867" end_char="13872">partly</TOKEN>
<TOKEN id="token-106-18" pos="word" morph="none" start_char="13874" end_char="13879">lifted</TOKEN>
<TOKEN id="token-106-19" pos="punct" morph="none" start_char="13880" end_char="13880">,</TOKEN>
<TOKEN id="token-106-20" pos="word" morph="none" start_char="13882" end_char="13889">claiming</TOKEN>
<TOKEN id="token-106-21" pos="word" morph="none" start_char="13891" end_char="13894">they</TOKEN>
<TOKEN id="token-106-22" pos="word" morph="none" start_char="13896" end_char="13899">have</TOKEN>
<TOKEN id="token-106-23" pos="word" morph="none" start_char="13901" end_char="13904">been</TOKEN>
<TOKEN id="token-106-24" pos="punct" morph="none" start_char="13906" end_char="13906">'</TOKEN>
<TOKEN id="token-106-25" pos="word" morph="none" start_char="13907" end_char="13913">working</TOKEN>
<TOKEN id="token-106-26" pos="word" morph="none" start_char="13915" end_char="13920">around</TOKEN>
<TOKEN id="token-106-27" pos="word" morph="none" start_char="13922" end_char="13924">the</TOKEN>
<TOKEN id="token-106-28" pos="word" morph="none" start_char="13926" end_char="13930">clock</TOKEN>
<TOKEN id="token-106-29" pos="punct" morph="none" start_char="13931" end_char="13931">'</TOKEN>
<TOKEN id="token-106-30" pos="word" morph="none" start_char="13933" end_char="13934">to</TOKEN>
<TOKEN id="token-106-31" pos="word" morph="none" start_char="13936" end_char="13942">dispose</TOKEN>
<TOKEN id="token-106-32" pos="word" morph="none" start_char="13944" end_char="13945">of</TOKEN>
<TOKEN id="token-106-33" pos="word" morph="none" start_char="13947" end_char="13952">bodies</TOKEN>
<TOKEN id="token-106-34" pos="punct" morph="none" start_char="13953" end_char="13953">.</TOKEN>
</SEG>
<SEG id="segment-107" start_char="13957" end_char="14133">
<ORIGINAL_TEXT>Social media posts estimate that 3,500 urns are being handed out by crematoriums each day, while Caixin reports that one funeral home in the city placed an order for 5,000 urns.</ORIGINAL_TEXT>
<TOKEN id="token-107-0" pos="word" morph="none" start_char="13957" end_char="13962">Social</TOKEN>
<TOKEN id="token-107-1" pos="word" morph="none" start_char="13964" end_char="13968">media</TOKEN>
<TOKEN id="token-107-2" pos="word" morph="none" start_char="13970" end_char="13974">posts</TOKEN>
<TOKEN id="token-107-3" pos="word" morph="none" start_char="13976" end_char="13983">estimate</TOKEN>
<TOKEN id="token-107-4" pos="word" morph="none" start_char="13985" end_char="13988">that</TOKEN>
<TOKEN id="token-107-5" pos="unknown" morph="none" start_char="13990" end_char="13994">3,500</TOKEN>
<TOKEN id="token-107-6" pos="word" morph="none" start_char="13996" end_char="13999">urns</TOKEN>
<TOKEN id="token-107-7" pos="word" morph="none" start_char="14001" end_char="14003">are</TOKEN>
<TOKEN id="token-107-8" pos="word" morph="none" start_char="14005" end_char="14009">being</TOKEN>
<TOKEN id="token-107-9" pos="word" morph="none" start_char="14011" end_char="14016">handed</TOKEN>
<TOKEN id="token-107-10" pos="word" morph="none" start_char="14018" end_char="14020">out</TOKEN>
<TOKEN id="token-107-11" pos="word" morph="none" start_char="14022" end_char="14023">by</TOKEN>
<TOKEN id="token-107-12" pos="word" morph="none" start_char="14025" end_char="14036">crematoriums</TOKEN>
<TOKEN id="token-107-13" pos="word" morph="none" start_char="14038" end_char="14041">each</TOKEN>
<TOKEN id="token-107-14" pos="word" morph="none" start_char="14043" end_char="14045">day</TOKEN>
<TOKEN id="token-107-15" pos="punct" morph="none" start_char="14046" end_char="14046">,</TOKEN>
<TOKEN id="token-107-16" pos="word" morph="none" start_char="14048" end_char="14052">while</TOKEN>
<TOKEN id="token-107-17" pos="word" morph="none" start_char="14054" end_char="14059">Caixin</TOKEN>
<TOKEN id="token-107-18" pos="word" morph="none" start_char="14061" end_char="14067">reports</TOKEN>
<TOKEN id="token-107-19" pos="word" morph="none" start_char="14069" end_char="14072">that</TOKEN>
<TOKEN id="token-107-20" pos="word" morph="none" start_char="14074" end_char="14076">one</TOKEN>
<TOKEN id="token-107-21" pos="word" morph="none" start_char="14078" end_char="14084">funeral</TOKEN>
<TOKEN id="token-107-22" pos="word" morph="none" start_char="14086" end_char="14089">home</TOKEN>
<TOKEN id="token-107-23" pos="word" morph="none" start_char="14091" end_char="14092">in</TOKEN>
<TOKEN id="token-107-24" pos="word" morph="none" start_char="14094" end_char="14096">the</TOKEN>
<TOKEN id="token-107-25" pos="word" morph="none" start_char="14098" end_char="14101">city</TOKEN>
<TOKEN id="token-107-26" pos="word" morph="none" start_char="14103" end_char="14108">placed</TOKEN>
<TOKEN id="token-107-27" pos="word" morph="none" start_char="14110" end_char="14111">an</TOKEN>
<TOKEN id="token-107-28" pos="word" morph="none" start_char="14113" end_char="14117">order</TOKEN>
<TOKEN id="token-107-29" pos="word" morph="none" start_char="14119" end_char="14121">for</TOKEN>
<TOKEN id="token-107-30" pos="unknown" morph="none" start_char="14123" end_char="14127">5,000</TOKEN>
<TOKEN id="token-107-31" pos="word" morph="none" start_char="14129" end_char="14132">urns</TOKEN>
<TOKEN id="token-107-32" pos="punct" morph="none" start_char="14133" end_char="14133">.</TOKEN>
</SEG>
<SEG id="segment-108" start_char="14136" end_char="14276">
<ORIGINAL_TEXT>Locals believe that efforts to dispose of the bodies began March 23 and city authorities have said the process will end on or around April 5.</ORIGINAL_TEXT>
<TOKEN id="token-108-0" pos="word" morph="none" start_char="14136" end_char="14141">Locals</TOKEN>
<TOKEN id="token-108-1" pos="word" morph="none" start_char="14143" end_char="14149">believe</TOKEN>
<TOKEN id="token-108-2" pos="word" morph="none" start_char="14151" end_char="14154">that</TOKEN>
<TOKEN id="token-108-3" pos="word" morph="none" start_char="14156" end_char="14162">efforts</TOKEN>
<TOKEN id="token-108-4" pos="word" morph="none" start_char="14164" end_char="14165">to</TOKEN>
<TOKEN id="token-108-5" pos="word" morph="none" start_char="14167" end_char="14173">dispose</TOKEN>
<TOKEN id="token-108-6" pos="word" morph="none" start_char="14175" end_char="14176">of</TOKEN>
<TOKEN id="token-108-7" pos="word" morph="none" start_char="14178" end_char="14180">the</TOKEN>
<TOKEN id="token-108-8" pos="word" morph="none" start_char="14182" end_char="14187">bodies</TOKEN>
<TOKEN id="token-108-9" pos="word" morph="none" start_char="14189" end_char="14193">began</TOKEN>
<TOKEN id="token-108-10" pos="word" morph="none" start_char="14195" end_char="14199">March</TOKEN>
<TOKEN id="token-108-11" pos="word" morph="none" start_char="14201" end_char="14202">23</TOKEN>
<TOKEN id="token-108-12" pos="word" morph="none" start_char="14204" end_char="14206">and</TOKEN>
<TOKEN id="token-108-13" pos="word" morph="none" start_char="14208" end_char="14211">city</TOKEN>
<TOKEN id="token-108-14" pos="word" morph="none" start_char="14213" end_char="14223">authorities</TOKEN>
<TOKEN id="token-108-15" pos="word" morph="none" start_char="14225" end_char="14228">have</TOKEN>
<TOKEN id="token-108-16" pos="word" morph="none" start_char="14230" end_char="14233">said</TOKEN>
<TOKEN id="token-108-17" pos="word" morph="none" start_char="14235" end_char="14237">the</TOKEN>
<TOKEN id="token-108-18" pos="word" morph="none" start_char="14239" end_char="14245">process</TOKEN>
<TOKEN id="token-108-19" pos="word" morph="none" start_char="14247" end_char="14250">will</TOKEN>
<TOKEN id="token-108-20" pos="word" morph="none" start_char="14252" end_char="14254">end</TOKEN>
<TOKEN id="token-108-21" pos="word" morph="none" start_char="14256" end_char="14257">on</TOKEN>
<TOKEN id="token-108-22" pos="word" morph="none" start_char="14259" end_char="14260">or</TOKEN>
<TOKEN id="token-108-23" pos="word" morph="none" start_char="14262" end_char="14267">around</TOKEN>
<TOKEN id="token-108-24" pos="word" morph="none" start_char="14269" end_char="14273">April</TOKEN>
<TOKEN id="token-108-25" pos="word" morph="none" start_char="14275" end_char="14275">5</TOKEN>
<TOKEN id="token-108-26" pos="punct" morph="none" start_char="14276" end_char="14276">.</TOKEN>
</SEG>
<SEG id="segment-109" start_char="14279" end_char="14375">
<ORIGINAL_TEXT>That would mean roughly 42,000 urns handed out in that time frame, ten times the reported figure.</ORIGINAL_TEXT>
<TOKEN id="token-109-0" pos="word" morph="none" start_char="14279" end_char="14282">That</TOKEN>
<TOKEN id="token-109-1" pos="word" morph="none" start_char="14284" end_char="14288">would</TOKEN>
<TOKEN id="token-109-2" pos="word" morph="none" start_char="14290" end_char="14293">mean</TOKEN>
<TOKEN id="token-109-3" pos="word" morph="none" start_char="14295" end_char="14301">roughly</TOKEN>
<TOKEN id="token-109-4" pos="unknown" morph="none" start_char="14303" end_char="14308">42,000</TOKEN>
<TOKEN id="token-109-5" pos="word" morph="none" start_char="14310" end_char="14313">urns</TOKEN>
<TOKEN id="token-109-6" pos="word" morph="none" start_char="14315" end_char="14320">handed</TOKEN>
<TOKEN id="token-109-7" pos="word" morph="none" start_char="14322" end_char="14324">out</TOKEN>
<TOKEN id="token-109-8" pos="word" morph="none" start_char="14326" end_char="14327">in</TOKEN>
<TOKEN id="token-109-9" pos="word" morph="none" start_char="14329" end_char="14332">that</TOKEN>
<TOKEN id="token-109-10" pos="word" morph="none" start_char="14334" end_char="14337">time</TOKEN>
<TOKEN id="token-109-11" pos="word" morph="none" start_char="14339" end_char="14343">frame</TOKEN>
<TOKEN id="token-109-12" pos="punct" morph="none" start_char="14344" end_char="14344">,</TOKEN>
<TOKEN id="token-109-13" pos="word" morph="none" start_char="14346" end_char="14348">ten</TOKEN>
<TOKEN id="token-109-14" pos="word" morph="none" start_char="14350" end_char="14354">times</TOKEN>
<TOKEN id="token-109-15" pos="word" morph="none" start_char="14356" end_char="14358">the</TOKEN>
<TOKEN id="token-109-16" pos="word" morph="none" start_char="14360" end_char="14367">reported</TOKEN>
<TOKEN id="token-109-17" pos="word" morph="none" start_char="14369" end_char="14374">figure</TOKEN>
<TOKEN id="token-109-18" pos="punct" morph="none" start_char="14375" end_char="14375">.</TOKEN>
</SEG>
<SEG id="segment-110" start_char="14378" end_char="14397">
<ORIGINAL_TEXT>Chinese aid packages</ORIGINAL_TEXT>
<TOKEN id="token-110-0" pos="word" morph="none" start_char="14378" end_char="14384">Chinese</TOKEN>
<TOKEN id="token-110-1" pos="word" morph="none" start_char="14386" end_char="14388">aid</TOKEN>
<TOKEN id="token-110-2" pos="word" morph="none" start_char="14390" end_char="14397">packages</TOKEN>
</SEG>
<SEG id="segment-111" start_char="14400" end_char="14637">
<ORIGINAL_TEXT>As it brought its own coronavirus epidemic under control and as the disease spread across the rest of the world, China attempted to paint itself as a helpful neighbour by sending aid and supplies to countries most in need - such as Italy.</ORIGINAL_TEXT>
<TOKEN id="token-111-0" pos="word" morph="none" start_char="14400" end_char="14401">As</TOKEN>
<TOKEN id="token-111-1" pos="word" morph="none" start_char="14403" end_char="14404">it</TOKEN>
<TOKEN id="token-111-2" pos="word" morph="none" start_char="14406" end_char="14412">brought</TOKEN>
<TOKEN id="token-111-3" pos="word" morph="none" start_char="14414" end_char="14416">its</TOKEN>
<TOKEN id="token-111-4" pos="word" morph="none" start_char="14418" end_char="14420">own</TOKEN>
<TOKEN id="token-111-5" pos="word" morph="none" start_char="14422" end_char="14432">coronavirus</TOKEN>
<TOKEN id="token-111-6" pos="word" morph="none" start_char="14434" end_char="14441">epidemic</TOKEN>
<TOKEN id="token-111-7" pos="word" morph="none" start_char="14443" end_char="14447">under</TOKEN>
<TOKEN id="token-111-8" pos="word" morph="none" start_char="14449" end_char="14455">control</TOKEN>
<TOKEN id="token-111-9" pos="word" morph="none" start_char="14457" end_char="14459">and</TOKEN>
<TOKEN id="token-111-10" pos="word" morph="none" start_char="14461" end_char="14462">as</TOKEN>
<TOKEN id="token-111-11" pos="word" morph="none" start_char="14464" end_char="14466">the</TOKEN>
<TOKEN id="token-111-12" pos="word" morph="none" start_char="14468" end_char="14474">disease</TOKEN>
<TOKEN id="token-111-13" pos="word" morph="none" start_char="14476" end_char="14481">spread</TOKEN>
<TOKEN id="token-111-14" pos="word" morph="none" start_char="14483" end_char="14488">across</TOKEN>
<TOKEN id="token-111-15" pos="word" morph="none" start_char="14490" end_char="14492">the</TOKEN>
<TOKEN id="token-111-16" pos="word" morph="none" start_char="14494" end_char="14497">rest</TOKEN>
<TOKEN id="token-111-17" pos="word" morph="none" start_char="14499" end_char="14500">of</TOKEN>
<TOKEN id="token-111-18" pos="word" morph="none" start_char="14502" end_char="14504">the</TOKEN>
<TOKEN id="token-111-19" pos="word" morph="none" start_char="14506" end_char="14510">world</TOKEN>
<TOKEN id="token-111-20" pos="punct" morph="none" start_char="14511" end_char="14511">,</TOKEN>
<TOKEN id="token-111-21" pos="word" morph="none" start_char="14513" end_char="14517">China</TOKEN>
<TOKEN id="token-111-22" pos="word" morph="none" start_char="14519" end_char="14527">attempted</TOKEN>
<TOKEN id="token-111-23" pos="word" morph="none" start_char="14529" end_char="14530">to</TOKEN>
<TOKEN id="token-111-24" pos="word" morph="none" start_char="14532" end_char="14536">paint</TOKEN>
<TOKEN id="token-111-25" pos="word" morph="none" start_char="14538" end_char="14543">itself</TOKEN>
<TOKEN id="token-111-26" pos="word" morph="none" start_char="14545" end_char="14546">as</TOKEN>
<TOKEN id="token-111-27" pos="word" morph="none" start_char="14548" end_char="14548">a</TOKEN>
<TOKEN id="token-111-28" pos="word" morph="none" start_char="14550" end_char="14556">helpful</TOKEN>
<TOKEN id="token-111-29" pos="word" morph="none" start_char="14558" end_char="14566">neighbour</TOKEN>
<TOKEN id="token-111-30" pos="word" morph="none" start_char="14568" end_char="14569">by</TOKEN>
<TOKEN id="token-111-31" pos="word" morph="none" start_char="14571" end_char="14577">sending</TOKEN>
<TOKEN id="token-111-32" pos="word" morph="none" start_char="14579" end_char="14581">aid</TOKEN>
<TOKEN id="token-111-33" pos="word" morph="none" start_char="14583" end_char="14585">and</TOKEN>
<TOKEN id="token-111-34" pos="word" morph="none" start_char="14587" end_char="14594">supplies</TOKEN>
<TOKEN id="token-111-35" pos="word" morph="none" start_char="14596" end_char="14597">to</TOKEN>
<TOKEN id="token-111-36" pos="word" morph="none" start_char="14599" end_char="14607">countries</TOKEN>
<TOKEN id="token-111-37" pos="word" morph="none" start_char="14609" end_char="14612">most</TOKEN>
<TOKEN id="token-111-38" pos="word" morph="none" start_char="14614" end_char="14615">in</TOKEN>
<TOKEN id="token-111-39" pos="word" morph="none" start_char="14617" end_char="14620">need</TOKEN>
<TOKEN id="token-111-40" pos="punct" morph="none" start_char="14622" end_char="14622">-</TOKEN>
<TOKEN id="token-111-41" pos="word" morph="none" start_char="14624" end_char="14627">such</TOKEN>
<TOKEN id="token-111-42" pos="word" morph="none" start_char="14629" end_char="14630">as</TOKEN>
<TOKEN id="token-111-43" pos="word" morph="none" start_char="14632" end_char="14636">Italy</TOKEN>
<TOKEN id="token-111-44" pos="punct" morph="none" start_char="14637" end_char="14637">.</TOKEN>
</SEG>
<SEG id="segment-112" start_char="14640" end_char="14779">
<ORIGINAL_TEXT>In fact, while the Chinese Red Cross supplied some free equipment to the Italians, the country purchased a large amount of what it received.</ORIGINAL_TEXT>
<TOKEN id="token-112-0" pos="word" morph="none" start_char="14640" end_char="14641">In</TOKEN>
<TOKEN id="token-112-1" pos="word" morph="none" start_char="14643" end_char="14646">fact</TOKEN>
<TOKEN id="token-112-2" pos="punct" morph="none" start_char="14647" end_char="14647">,</TOKEN>
<TOKEN id="token-112-3" pos="word" morph="none" start_char="14649" end_char="14653">while</TOKEN>
<TOKEN id="token-112-4" pos="word" morph="none" start_char="14655" end_char="14657">the</TOKEN>
<TOKEN id="token-112-5" pos="word" morph="none" start_char="14659" end_char="14665">Chinese</TOKEN>
<TOKEN id="token-112-6" pos="word" morph="none" start_char="14667" end_char="14669">Red</TOKEN>
<TOKEN id="token-112-7" pos="word" morph="none" start_char="14671" end_char="14675">Cross</TOKEN>
<TOKEN id="token-112-8" pos="word" morph="none" start_char="14677" end_char="14684">supplied</TOKEN>
<TOKEN id="token-112-9" pos="word" morph="none" start_char="14686" end_char="14689">some</TOKEN>
<TOKEN id="token-112-10" pos="word" morph="none" start_char="14691" end_char="14694">free</TOKEN>
<TOKEN id="token-112-11" pos="word" morph="none" start_char="14696" end_char="14704">equipment</TOKEN>
<TOKEN id="token-112-12" pos="word" morph="none" start_char="14706" end_char="14707">to</TOKEN>
<TOKEN id="token-112-13" pos="word" morph="none" start_char="14709" end_char="14711">the</TOKEN>
<TOKEN id="token-112-14" pos="word" morph="none" start_char="14713" end_char="14720">Italians</TOKEN>
<TOKEN id="token-112-15" pos="punct" morph="none" start_char="14721" end_char="14721">,</TOKEN>
<TOKEN id="token-112-16" pos="word" morph="none" start_char="14723" end_char="14725">the</TOKEN>
<TOKEN id="token-112-17" pos="word" morph="none" start_char="14727" end_char="14733">country</TOKEN>
<TOKEN id="token-112-18" pos="word" morph="none" start_char="14735" end_char="14743">purchased</TOKEN>
<TOKEN id="token-112-19" pos="word" morph="none" start_char="14745" end_char="14745">a</TOKEN>
<TOKEN id="token-112-20" pos="word" morph="none" start_char="14747" end_char="14751">large</TOKEN>
<TOKEN id="token-112-21" pos="word" morph="none" start_char="14753" end_char="14758">amount</TOKEN>
<TOKEN id="token-112-22" pos="word" morph="none" start_char="14760" end_char="14761">of</TOKEN>
<TOKEN id="token-112-23" pos="word" morph="none" start_char="14763" end_char="14766">what</TOKEN>
<TOKEN id="token-112-24" pos="word" morph="none" start_char="14768" end_char="14769">it</TOKEN>
<TOKEN id="token-112-25" pos="word" morph="none" start_char="14771" end_char="14778">received</TOKEN>
<TOKEN id="token-112-26" pos="punct" morph="none" start_char="14779" end_char="14779">.</TOKEN>
</SEG>
<SEG id="segment-113" start_char="14782" end_char="14951">
<ORIGINAL_TEXT>Meanwhile officials in Spain said that a batch of coronavirus testing kits bought from China had just 30 per cent reliability - unlike the 80 per cent they were promised.</ORIGINAL_TEXT>
<TOKEN id="token-113-0" pos="word" morph="none" start_char="14782" end_char="14790">Meanwhile</TOKEN>
<TOKEN id="token-113-1" pos="word" morph="none" start_char="14792" end_char="14800">officials</TOKEN>
<TOKEN id="token-113-2" pos="word" morph="none" start_char="14802" end_char="14803">in</TOKEN>
<TOKEN id="token-113-3" pos="word" morph="none" start_char="14805" end_char="14809">Spain</TOKEN>
<TOKEN id="token-113-4" pos="word" morph="none" start_char="14811" end_char="14814">said</TOKEN>
<TOKEN id="token-113-5" pos="word" morph="none" start_char="14816" end_char="14819">that</TOKEN>
<TOKEN id="token-113-6" pos="word" morph="none" start_char="14821" end_char="14821">a</TOKEN>
<TOKEN id="token-113-7" pos="word" morph="none" start_char="14823" end_char="14827">batch</TOKEN>
<TOKEN id="token-113-8" pos="word" morph="none" start_char="14829" end_char="14830">of</TOKEN>
<TOKEN id="token-113-9" pos="word" morph="none" start_char="14832" end_char="14842">coronavirus</TOKEN>
<TOKEN id="token-113-10" pos="word" morph="none" start_char="14844" end_char="14850">testing</TOKEN>
<TOKEN id="token-113-11" pos="word" morph="none" start_char="14852" end_char="14855">kits</TOKEN>
<TOKEN id="token-113-12" pos="word" morph="none" start_char="14857" end_char="14862">bought</TOKEN>
<TOKEN id="token-113-13" pos="word" morph="none" start_char="14864" end_char="14867">from</TOKEN>
<TOKEN id="token-113-14" pos="word" morph="none" start_char="14869" end_char="14873">China</TOKEN>
<TOKEN id="token-113-15" pos="word" morph="none" start_char="14875" end_char="14877">had</TOKEN>
<TOKEN id="token-113-16" pos="word" morph="none" start_char="14879" end_char="14882">just</TOKEN>
<TOKEN id="token-113-17" pos="word" morph="none" start_char="14884" end_char="14885">30</TOKEN>
<TOKEN id="token-113-18" pos="word" morph="none" start_char="14887" end_char="14889">per</TOKEN>
<TOKEN id="token-113-19" pos="word" morph="none" start_char="14891" end_char="14894">cent</TOKEN>
<TOKEN id="token-113-20" pos="word" morph="none" start_char="14896" end_char="14906">reliability</TOKEN>
<TOKEN id="token-113-21" pos="punct" morph="none" start_char="14908" end_char="14908">-</TOKEN>
<TOKEN id="token-113-22" pos="word" morph="none" start_char="14910" end_char="14915">unlike</TOKEN>
<TOKEN id="token-113-23" pos="word" morph="none" start_char="14917" end_char="14919">the</TOKEN>
<TOKEN id="token-113-24" pos="word" morph="none" start_char="14921" end_char="14922">80</TOKEN>
<TOKEN id="token-113-25" pos="word" morph="none" start_char="14924" end_char="14926">per</TOKEN>
<TOKEN id="token-113-26" pos="word" morph="none" start_char="14928" end_char="14931">cent</TOKEN>
<TOKEN id="token-113-27" pos="word" morph="none" start_char="14933" end_char="14936">they</TOKEN>
<TOKEN id="token-113-28" pos="word" morph="none" start_char="14938" end_char="14941">were</TOKEN>
<TOKEN id="token-113-29" pos="word" morph="none" start_char="14943" end_char="14950">promised</TOKEN>
<TOKEN id="token-113-30" pos="punct" morph="none" start_char="14951" end_char="14951">.</TOKEN>
</SEG>
<SEG id="segment-114" start_char="14955" end_char="15106">
<ORIGINAL_TEXT>China is also the world's largest manufacturer of disposable masks of the kind being worn to slow the spread of the virus by people while out in public.</ORIGINAL_TEXT>
<TOKEN id="token-114-0" pos="word" morph="none" start_char="14955" end_char="14959">China</TOKEN>
<TOKEN id="token-114-1" pos="word" morph="none" start_char="14961" end_char="14962">is</TOKEN>
<TOKEN id="token-114-2" pos="word" morph="none" start_char="14964" end_char="14967">also</TOKEN>
<TOKEN id="token-114-3" pos="word" morph="none" start_char="14969" end_char="14971">the</TOKEN>
<TOKEN id="token-114-4" pos="word" morph="none" start_char="14973" end_char="14979">world's</TOKEN>
<TOKEN id="token-114-5" pos="word" morph="none" start_char="14981" end_char="14987">largest</TOKEN>
<TOKEN id="token-114-6" pos="word" morph="none" start_char="14989" end_char="15000">manufacturer</TOKEN>
<TOKEN id="token-114-7" pos="word" morph="none" start_char="15002" end_char="15003">of</TOKEN>
<TOKEN id="token-114-8" pos="word" morph="none" start_char="15005" end_char="15014">disposable</TOKEN>
<TOKEN id="token-114-9" pos="word" morph="none" start_char="15016" end_char="15020">masks</TOKEN>
<TOKEN id="token-114-10" pos="word" morph="none" start_char="15022" end_char="15023">of</TOKEN>
<TOKEN id="token-114-11" pos="word" morph="none" start_char="15025" end_char="15027">the</TOKEN>
<TOKEN id="token-114-12" pos="word" morph="none" start_char="15029" end_char="15032">kind</TOKEN>
<TOKEN id="token-114-13" pos="word" morph="none" start_char="15034" end_char="15038">being</TOKEN>
<TOKEN id="token-114-14" pos="word" morph="none" start_char="15040" end_char="15043">worn</TOKEN>
<TOKEN id="token-114-15" pos="word" morph="none" start_char="15045" end_char="15046">to</TOKEN>
<TOKEN id="token-114-16" pos="word" morph="none" start_char="15048" end_char="15051">slow</TOKEN>
<TOKEN id="token-114-17" pos="word" morph="none" start_char="15053" end_char="15055">the</TOKEN>
<TOKEN id="token-114-18" pos="word" morph="none" start_char="15057" end_char="15062">spread</TOKEN>
<TOKEN id="token-114-19" pos="word" morph="none" start_char="15064" end_char="15065">of</TOKEN>
<TOKEN id="token-114-20" pos="word" morph="none" start_char="15067" end_char="15069">the</TOKEN>
<TOKEN id="token-114-21" pos="word" morph="none" start_char="15071" end_char="15075">virus</TOKEN>
<TOKEN id="token-114-22" pos="word" morph="none" start_char="15077" end_char="15078">by</TOKEN>
<TOKEN id="token-114-23" pos="word" morph="none" start_char="15080" end_char="15085">people</TOKEN>
<TOKEN id="token-114-24" pos="word" morph="none" start_char="15087" end_char="15091">while</TOKEN>
<TOKEN id="token-114-25" pos="word" morph="none" start_char="15093" end_char="15095">out</TOKEN>
<TOKEN id="token-114-26" pos="word" morph="none" start_char="15097" end_char="15098">in</TOKEN>
<TOKEN id="token-114-27" pos="word" morph="none" start_char="15100" end_char="15105">public</TOKEN>
<TOKEN id="token-114-28" pos="punct" morph="none" start_char="15106" end_char="15106">.</TOKEN>
</SEG>
<SEG id="segment-115" start_char="15109" end_char="15298">
<ORIGINAL_TEXT>But as the disease began gathering speed in the country in January, China began limiting exports of the masks while also buying up supplies from other countries, the New York Times reported.</ORIGINAL_TEXT>
<TOKEN id="token-115-0" pos="word" morph="none" start_char="15109" end_char="15111">But</TOKEN>
<TOKEN id="token-115-1" pos="word" morph="none" start_char="15113" end_char="15114">as</TOKEN>
<TOKEN id="token-115-2" pos="word" morph="none" start_char="15116" end_char="15118">the</TOKEN>
<TOKEN id="token-115-3" pos="word" morph="none" start_char="15120" end_char="15126">disease</TOKEN>
<TOKEN id="token-115-4" pos="word" morph="none" start_char="15128" end_char="15132">began</TOKEN>
<TOKEN id="token-115-5" pos="word" morph="none" start_char="15134" end_char="15142">gathering</TOKEN>
<TOKEN id="token-115-6" pos="word" morph="none" start_char="15144" end_char="15148">speed</TOKEN>
<TOKEN id="token-115-7" pos="word" morph="none" start_char="15150" end_char="15151">in</TOKEN>
<TOKEN id="token-115-8" pos="word" morph="none" start_char="15153" end_char="15155">the</TOKEN>
<TOKEN id="token-115-9" pos="word" morph="none" start_char="15157" end_char="15163">country</TOKEN>
<TOKEN id="token-115-10" pos="word" morph="none" start_char="15165" end_char="15166">in</TOKEN>
<TOKEN id="token-115-11" pos="word" morph="none" start_char="15168" end_char="15174">January</TOKEN>
<TOKEN id="token-115-12" pos="punct" morph="none" start_char="15175" end_char="15175">,</TOKEN>
<TOKEN id="token-115-13" pos="word" morph="none" start_char="15177" end_char="15181">China</TOKEN>
<TOKEN id="token-115-14" pos="word" morph="none" start_char="15183" end_char="15187">began</TOKEN>
<TOKEN id="token-115-15" pos="word" morph="none" start_char="15189" end_char="15196">limiting</TOKEN>
<TOKEN id="token-115-16" pos="word" morph="none" start_char="15198" end_char="15204">exports</TOKEN>
<TOKEN id="token-115-17" pos="word" morph="none" start_char="15206" end_char="15207">of</TOKEN>
<TOKEN id="token-115-18" pos="word" morph="none" start_char="15209" end_char="15211">the</TOKEN>
<TOKEN id="token-115-19" pos="word" morph="none" start_char="15213" end_char="15217">masks</TOKEN>
<TOKEN id="token-115-20" pos="word" morph="none" start_char="15219" end_char="15223">while</TOKEN>
<TOKEN id="token-115-21" pos="word" morph="none" start_char="15225" end_char="15228">also</TOKEN>
<TOKEN id="token-115-22" pos="word" morph="none" start_char="15230" end_char="15235">buying</TOKEN>
<TOKEN id="token-115-23" pos="word" morph="none" start_char="15237" end_char="15238">up</TOKEN>
<TOKEN id="token-115-24" pos="word" morph="none" start_char="15240" end_char="15247">supplies</TOKEN>
<TOKEN id="token-115-25" pos="word" morph="none" start_char="15249" end_char="15252">from</TOKEN>
<TOKEN id="token-115-26" pos="word" morph="none" start_char="15254" end_char="15258">other</TOKEN>
<TOKEN id="token-115-27" pos="word" morph="none" start_char="15260" end_char="15268">countries</TOKEN>
<TOKEN id="token-115-28" pos="punct" morph="none" start_char="15269" end_char="15269">,</TOKEN>
<TOKEN id="token-115-29" pos="word" morph="none" start_char="15271" end_char="15273">the</TOKEN>
<TOKEN id="token-115-30" pos="word" morph="none" start_char="15275" end_char="15277">New</TOKEN>
<TOKEN id="token-115-31" pos="word" morph="none" start_char="15279" end_char="15282">York</TOKEN>
<TOKEN id="token-115-32" pos="word" morph="none" start_char="15284" end_char="15288">Times</TOKEN>
<TOKEN id="token-115-33" pos="word" morph="none" start_char="15290" end_char="15297">reported</TOKEN>
<TOKEN id="token-115-34" pos="punct" morph="none" start_char="15298" end_char="15298">.</TOKEN>
</SEG>
<SEG id="segment-116" start_char="15301" end_char="15468">
<ORIGINAL_TEXT>As well as halting virtually all exports of masks, China also bought up some 56million masks and respirators from overseas while fears of a pandemic were still far off.</ORIGINAL_TEXT>
<TOKEN id="token-116-0" pos="word" morph="none" start_char="15301" end_char="15302">As</TOKEN>
<TOKEN id="token-116-1" pos="word" morph="none" start_char="15304" end_char="15307">well</TOKEN>
<TOKEN id="token-116-2" pos="word" morph="none" start_char="15309" end_char="15310">as</TOKEN>
<TOKEN id="token-116-3" pos="word" morph="none" start_char="15312" end_char="15318">halting</TOKEN>
<TOKEN id="token-116-4" pos="word" morph="none" start_char="15320" end_char="15328">virtually</TOKEN>
<TOKEN id="token-116-5" pos="word" morph="none" start_char="15330" end_char="15332">all</TOKEN>
<TOKEN id="token-116-6" pos="word" morph="none" start_char="15334" end_char="15340">exports</TOKEN>
<TOKEN id="token-116-7" pos="word" morph="none" start_char="15342" end_char="15343">of</TOKEN>
<TOKEN id="token-116-8" pos="word" morph="none" start_char="15345" end_char="15349">masks</TOKEN>
<TOKEN id="token-116-9" pos="punct" morph="none" start_char="15350" end_char="15350">,</TOKEN>
<TOKEN id="token-116-10" pos="word" morph="none" start_char="15352" end_char="15356">China</TOKEN>
<TOKEN id="token-116-11" pos="word" morph="none" start_char="15358" end_char="15361">also</TOKEN>
<TOKEN id="token-116-12" pos="word" morph="none" start_char="15363" end_char="15368">bought</TOKEN>
<TOKEN id="token-116-13" pos="word" morph="none" start_char="15370" end_char="15371">up</TOKEN>
<TOKEN id="token-116-14" pos="word" morph="none" start_char="15373" end_char="15376">some</TOKEN>
<TOKEN id="token-116-15" pos="word" morph="none" start_char="15378" end_char="15386">56million</TOKEN>
<TOKEN id="token-116-16" pos="word" morph="none" start_char="15388" end_char="15392">masks</TOKEN>
<TOKEN id="token-116-17" pos="word" morph="none" start_char="15394" end_char="15396">and</TOKEN>
<TOKEN id="token-116-18" pos="word" morph="none" start_char="15398" end_char="15408">respirators</TOKEN>
<TOKEN id="token-116-19" pos="word" morph="none" start_char="15410" end_char="15413">from</TOKEN>
<TOKEN id="token-116-20" pos="word" morph="none" start_char="15415" end_char="15422">overseas</TOKEN>
<TOKEN id="token-116-21" pos="word" morph="none" start_char="15424" end_char="15428">while</TOKEN>
<TOKEN id="token-116-22" pos="word" morph="none" start_char="15430" end_char="15434">fears</TOKEN>
<TOKEN id="token-116-23" pos="word" morph="none" start_char="15436" end_char="15437">of</TOKEN>
<TOKEN id="token-116-24" pos="word" morph="none" start_char="15439" end_char="15439">a</TOKEN>
<TOKEN id="token-116-25" pos="word" morph="none" start_char="15441" end_char="15448">pandemic</TOKEN>
<TOKEN id="token-116-26" pos="word" morph="none" start_char="15450" end_char="15453">were</TOKEN>
<TOKEN id="token-116-27" pos="word" morph="none" start_char="15455" end_char="15459">still</TOKEN>
<TOKEN id="token-116-28" pos="word" morph="none" start_char="15461" end_char="15463">far</TOKEN>
<TOKEN id="token-116-29" pos="word" morph="none" start_char="15465" end_char="15467">off</TOKEN>
<TOKEN id="token-116-30" pos="punct" morph="none" start_char="15468" end_char="15468">.</TOKEN>
</SEG>
<SEG id="segment-117" start_char="15471" end_char="15697">
<ORIGINAL_TEXT>Despite reports from US mask manufacturers of factories in Shanghai being effectively nationalised, China denies it has any such policy in place and has said it is 'willing to strengthen international cooperation' on the issue.</ORIGINAL_TEXT>
<TOKEN id="token-117-0" pos="word" morph="none" start_char="15471" end_char="15477">Despite</TOKEN>
<TOKEN id="token-117-1" pos="word" morph="none" start_char="15479" end_char="15485">reports</TOKEN>
<TOKEN id="token-117-2" pos="word" morph="none" start_char="15487" end_char="15490">from</TOKEN>
<TOKEN id="token-117-3" pos="word" morph="none" start_char="15492" end_char="15493">US</TOKEN>
<TOKEN id="token-117-4" pos="word" morph="none" start_char="15495" end_char="15498">mask</TOKEN>
<TOKEN id="token-117-5" pos="word" morph="none" start_char="15500" end_char="15512">manufacturers</TOKEN>
<TOKEN id="token-117-6" pos="word" morph="none" start_char="15514" end_char="15515">of</TOKEN>
<TOKEN id="token-117-7" pos="word" morph="none" start_char="15517" end_char="15525">factories</TOKEN>
<TOKEN id="token-117-8" pos="word" morph="none" start_char="15527" end_char="15528">in</TOKEN>
<TOKEN id="token-117-9" pos="word" morph="none" start_char="15530" end_char="15537">Shanghai</TOKEN>
<TOKEN id="token-117-10" pos="word" morph="none" start_char="15539" end_char="15543">being</TOKEN>
<TOKEN id="token-117-11" pos="word" morph="none" start_char="15545" end_char="15555">effectively</TOKEN>
<TOKEN id="token-117-12" pos="word" morph="none" start_char="15557" end_char="15568">nationalised</TOKEN>
<TOKEN id="token-117-13" pos="punct" morph="none" start_char="15569" end_char="15569">,</TOKEN>
<TOKEN id="token-117-14" pos="word" morph="none" start_char="15571" end_char="15575">China</TOKEN>
<TOKEN id="token-117-15" pos="word" morph="none" start_char="15577" end_char="15582">denies</TOKEN>
<TOKEN id="token-117-16" pos="word" morph="none" start_char="15584" end_char="15585">it</TOKEN>
<TOKEN id="token-117-17" pos="word" morph="none" start_char="15587" end_char="15589">has</TOKEN>
<TOKEN id="token-117-18" pos="word" morph="none" start_char="15591" end_char="15593">any</TOKEN>
<TOKEN id="token-117-19" pos="word" morph="none" start_char="15595" end_char="15598">such</TOKEN>
<TOKEN id="token-117-20" pos="word" morph="none" start_char="15600" end_char="15605">policy</TOKEN>
<TOKEN id="token-117-21" pos="word" morph="none" start_char="15607" end_char="15608">in</TOKEN>
<TOKEN id="token-117-22" pos="word" morph="none" start_char="15610" end_char="15614">place</TOKEN>
<TOKEN id="token-117-23" pos="word" morph="none" start_char="15616" end_char="15618">and</TOKEN>
<TOKEN id="token-117-24" pos="word" morph="none" start_char="15620" end_char="15622">has</TOKEN>
<TOKEN id="token-117-25" pos="word" morph="none" start_char="15624" end_char="15627">said</TOKEN>
<TOKEN id="token-117-26" pos="word" morph="none" start_char="15629" end_char="15630">it</TOKEN>
<TOKEN id="token-117-27" pos="word" morph="none" start_char="15632" end_char="15633">is</TOKEN>
<TOKEN id="token-117-28" pos="punct" morph="none" start_char="15635" end_char="15635">'</TOKEN>
<TOKEN id="token-117-29" pos="word" morph="none" start_char="15636" end_char="15642">willing</TOKEN>
<TOKEN id="token-117-30" pos="word" morph="none" start_char="15644" end_char="15645">to</TOKEN>
<TOKEN id="token-117-31" pos="word" morph="none" start_char="15647" end_char="15656">strengthen</TOKEN>
<TOKEN id="token-117-32" pos="word" morph="none" start_char="15658" end_char="15670">international</TOKEN>
<TOKEN id="token-117-33" pos="word" morph="none" start_char="15672" end_char="15682">cooperation</TOKEN>
<TOKEN id="token-117-34" pos="punct" morph="none" start_char="15683" end_char="15683">'</TOKEN>
<TOKEN id="token-117-35" pos="word" morph="none" start_char="15685" end_char="15686">on</TOKEN>
<TOKEN id="token-117-36" pos="word" morph="none" start_char="15688" end_char="15690">the</TOKEN>
<TOKEN id="token-117-37" pos="word" morph="none" start_char="15692" end_char="15696">issue</TOKEN>
<TOKEN id="token-117-38" pos="punct" morph="none" start_char="15697" end_char="15697">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
