<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATLE" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="8255" raw_text_md5="778371d9f703828c5938f37df871a9b9">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="50">
<ORIGINAL_TEXT>Wash Your Hands—but Beware the Electric Hand Dryer</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="4">Wash</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="6" end_char="9">Your</TOKEN>
<TOKEN id="token-0-2" pos="unknown" morph="none" start_char="11" end_char="19">Hands—but</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="21" end_char="26">Beware</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="28" end_char="30">the</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="32" end_char="39">Electric</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="41" end_char="44">Hand</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="46" end_char="50">Dryer</TOKEN>
</SEG>
<SEG id="segment-1" start_char="54" end_char="65">
<ORIGINAL_TEXT>Tom Bartlett</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="54" end_char="56">Tom</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="58" end_char="65">Bartlett</TOKEN>
</SEG>
<SEG id="segment-2" start_char="68" end_char="72">
<ORIGINAL_TEXT>Ideas</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="68" end_char="72">Ideas</TOKEN>
</SEG>
<SEG id="segment-3" start_char="75" end_char="93">
<ORIGINAL_TEXT>03.06.2020 01:29 PM</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="unknown" morph="none" start_char="75" end_char="84">03.06.2020</TOKEN>
<TOKEN id="token-3-1" pos="unknown" morph="none" start_char="86" end_char="90">01:29</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="92" end_char="93">PM</TOKEN>
</SEG>
<SEG id="segment-4" start_char="96" end_char="145">
<ORIGINAL_TEXT>Wash Your Hands—but Beware the Electric Hand Dryer</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="96" end_char="99">Wash</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="101" end_char="104">Your</TOKEN>
<TOKEN id="token-4-2" pos="unknown" morph="none" start_char="106" end_char="114">Hands—but</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="116" end_char="121">Beware</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="123" end_char="125">the</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="127" end_char="134">Electric</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="136" end_char="139">Hand</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="141" end_char="145">Dryer</TOKEN>
</SEG>
<SEG id="segment-5" start_char="149" end_char="224">
<ORIGINAL_TEXT>"Electric towels" were supposed to prevent the spread of contagious disease.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="punct" morph="none" start_char="149" end_char="149">"</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="150" end_char="157">Electric</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="159" end_char="164">towels</TOKEN>
<TOKEN id="token-5-3" pos="punct" morph="none" start_char="165" end_char="165">"</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="167" end_char="170">were</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="172" end_char="179">supposed</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="181" end_char="182">to</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="184" end_char="190">prevent</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="192" end_char="194">the</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="196" end_char="201">spread</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="203" end_char="204">of</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="206" end_char="215">contagious</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="217" end_char="223">disease</TOKEN>
<TOKEN id="token-5-13" pos="punct" morph="none" start_char="224" end_char="224">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="226" end_char="265">
<ORIGINAL_TEXT>What if they've been doing the opposite?</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="226" end_char="229">What</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="231" end_char="232">if</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="234" end_char="240">they've</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="242" end_char="245">been</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="247" end_char="251">doing</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="253" end_char="255">the</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="257" end_char="264">opposite</TOKEN>
<TOKEN id="token-6-7" pos="punct" morph="none" start_char="265" end_char="265">?</TOKEN>
</SEG>
<SEG id="segment-7" start_char="268" end_char="293">
<ORIGINAL_TEXT>Save this story for later.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="268" end_char="271">Save</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="273" end_char="276">this</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="278" end_char="282">story</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="284" end_char="286">for</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="288" end_char="292">later</TOKEN>
<TOKEN id="token-7-5" pos="punct" morph="none" start_char="293" end_char="293">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="297" end_char="320">
<ORIGINAL_TEXT>Photograph: Getty Images</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="297" end_char="306">Photograph</TOKEN>
<TOKEN id="token-8-1" pos="punct" morph="none" start_char="307" end_char="307">:</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="309" end_char="313">Getty</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="315" end_char="320">Images</TOKEN>
</SEG>
<SEG id="segment-9" start_char="324" end_char="519">
<ORIGINAL_TEXT>The spread of Covid-19 has turned us into a nation of hand-washing obsessives, citizens who vigorously interlace our fingers and circle-scrub our thumbs with an exacting, anxiety-fueled intensity.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="324" end_char="326">The</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="328" end_char="333">spread</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="335" end_char="336">of</TOKEN>
<TOKEN id="token-9-3" pos="unknown" morph="none" start_char="338" end_char="345">Covid-19</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="347" end_char="349">has</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="351" end_char="356">turned</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="358" end_char="359">us</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="361" end_char="364">into</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="366" end_char="366">a</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="368" end_char="373">nation</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="375" end_char="376">of</TOKEN>
<TOKEN id="token-9-11" pos="unknown" morph="none" start_char="378" end_char="389">hand-washing</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="391" end_char="400">obsessives</TOKEN>
<TOKEN id="token-9-13" pos="punct" morph="none" start_char="401" end_char="401">,</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="403" end_char="410">citizens</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="412" end_char="414">who</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="416" end_char="425">vigorously</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="427" end_char="435">interlace</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="437" end_char="439">our</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="441" end_char="447">fingers</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="449" end_char="451">and</TOKEN>
<TOKEN id="token-9-21" pos="unknown" morph="none" start_char="453" end_char="464">circle-scrub</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="466" end_char="468">our</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="470" end_char="475">thumbs</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="477" end_char="480">with</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="482" end_char="483">an</TOKEN>
<TOKEN id="token-9-26" pos="word" morph="none" start_char="485" end_char="492">exacting</TOKEN>
<TOKEN id="token-9-27" pos="punct" morph="none" start_char="493" end_char="493">,</TOKEN>
<TOKEN id="token-9-28" pos="unknown" morph="none" start_char="495" end_char="508">anxiety-fueled</TOKEN>
<TOKEN id="token-9-29" pos="word" morph="none" start_char="510" end_char="518">intensity</TOKEN>
<TOKEN id="token-9-30" pos="punct" morph="none" start_char="519" end_char="519">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="521" end_char="748">
<ORIGINAL_TEXT>But it’s not over when you flip off the faucet: Drying your hands matters too, because damp skin provides a hospitable environment for microorganisms and, as a result, might increase the likelihood that you’ll pass on pathogens.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="521" end_char="523">But</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="525" end_char="528">it’s</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="530" end_char="532">not</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="534" end_char="537">over</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="539" end_char="542">when</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="544" end_char="546">you</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="548" end_char="551">flip</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="553" end_char="555">off</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="557" end_char="559">the</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="561" end_char="566">faucet</TOKEN>
<TOKEN id="token-10-10" pos="punct" morph="none" start_char="567" end_char="567">:</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="569" end_char="574">Drying</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="576" end_char="579">your</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="581" end_char="585">hands</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="587" end_char="593">matters</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="595" end_char="597">too</TOKEN>
<TOKEN id="token-10-16" pos="punct" morph="none" start_char="598" end_char="598">,</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="600" end_char="606">because</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="608" end_char="611">damp</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="613" end_char="616">skin</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="618" end_char="625">provides</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="627" end_char="627">a</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="629" end_char="638">hospitable</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="640" end_char="650">environment</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="652" end_char="654">for</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="656" end_char="669">microorganisms</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="671" end_char="673">and</TOKEN>
<TOKEN id="token-10-27" pos="punct" morph="none" start_char="674" end_char="674">,</TOKEN>
<TOKEN id="token-10-28" pos="word" morph="none" start_char="676" end_char="677">as</TOKEN>
<TOKEN id="token-10-29" pos="word" morph="none" start_char="679" end_char="679">a</TOKEN>
<TOKEN id="token-10-30" pos="word" morph="none" start_char="681" end_char="686">result</TOKEN>
<TOKEN id="token-10-31" pos="punct" morph="none" start_char="687" end_char="687">,</TOKEN>
<TOKEN id="token-10-32" pos="word" morph="none" start_char="689" end_char="693">might</TOKEN>
<TOKEN id="token-10-33" pos="word" morph="none" start_char="695" end_char="702">increase</TOKEN>
<TOKEN id="token-10-34" pos="word" morph="none" start_char="704" end_char="706">the</TOKEN>
<TOKEN id="token-10-35" pos="word" morph="none" start_char="708" end_char="717">likelihood</TOKEN>
<TOKEN id="token-10-36" pos="word" morph="none" start_char="719" end_char="722">that</TOKEN>
<TOKEN id="token-10-37" pos="word" morph="none" start_char="724" end_char="729">you’ll</TOKEN>
<TOKEN id="token-10-38" pos="word" morph="none" start_char="731" end_char="734">pass</TOKEN>
<TOKEN id="token-10-39" pos="word" morph="none" start_char="736" end_char="737">on</TOKEN>
<TOKEN id="token-10-40" pos="word" morph="none" start_char="739" end_char="747">pathogens</TOKEN>
<TOKEN id="token-10-41" pos="punct" morph="none" start_char="748" end_char="748">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="751" end_char="925">
<ORIGINAL_TEXT>So now, as we confront what could be a society-altering disease outbreak, it seems worth taking a hard look at the widely reviled yet seemingly ubiquitous electric hand dryer.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="751" end_char="752">So</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="754" end_char="756">now</TOKEN>
<TOKEN id="token-11-2" pos="punct" morph="none" start_char="757" end_char="757">,</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="759" end_char="760">as</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="762" end_char="763">we</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="765" end_char="772">confront</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="774" end_char="777">what</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="779" end_char="783">could</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="785" end_char="786">be</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="788" end_char="788">a</TOKEN>
<TOKEN id="token-11-10" pos="unknown" morph="none" start_char="790" end_char="805">society-altering</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="807" end_char="813">disease</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="815" end_char="822">outbreak</TOKEN>
<TOKEN id="token-11-13" pos="punct" morph="none" start_char="823" end_char="823">,</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="825" end_char="826">it</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="828" end_char="832">seems</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="834" end_char="838">worth</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="840" end_char="845">taking</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="847" end_char="847">a</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="849" end_char="852">hard</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="854" end_char="857">look</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="859" end_char="860">at</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="862" end_char="864">the</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="866" end_char="871">widely</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="873" end_char="879">reviled</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="881" end_char="883">yet</TOKEN>
<TOKEN id="token-11-26" pos="word" morph="none" start_char="885" end_char="893">seemingly</TOKEN>
<TOKEN id="token-11-27" pos="word" morph="none" start_char="895" end_char="904">ubiquitous</TOKEN>
<TOKEN id="token-11-28" pos="word" morph="none" start_char="906" end_char="913">electric</TOKEN>
<TOKEN id="token-11-29" pos="word" morph="none" start_char="915" end_char="918">hand</TOKEN>
<TOKEN id="token-11-30" pos="word" morph="none" start_char="920" end_char="924">dryer</TOKEN>
<TOKEN id="token-11-31" pos="punct" morph="none" start_char="925" end_char="925">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="927" end_char="993">
<ORIGINAL_TEXT>Are they as hygienic as paper towels, as their manufacturers claim?</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="927" end_char="929">Are</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="931" end_char="934">they</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="936" end_char="937">as</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="939" end_char="946">hygienic</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="948" end_char="949">as</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="951" end_char="955">paper</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="957" end_char="962">towels</TOKEN>
<TOKEN id="token-12-7" pos="punct" morph="none" start_char="963" end_char="963">,</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="965" end_char="966">as</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="968" end_char="972">their</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="974" end_char="986">manufacturers</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="988" end_char="992">claim</TOKEN>
<TOKEN id="token-12-12" pos="punct" morph="none" start_char="993" end_char="993">?</TOKEN>
</SEG>
<SEG id="segment-13" start_char="996" end_char="1189">
<ORIGINAL_TEXT>The earliest pitches for hand dryers played up their supposed ability when it comes to "preventing the spread of contagious disease," as a 1924 newspaper ad for the Airdry Electric Towel put it.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="996" end_char="998">The</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1000" end_char="1007">earliest</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1009" end_char="1015">pitches</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1017" end_char="1019">for</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1021" end_char="1024">hand</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1026" end_char="1031">dryers</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1033" end_char="1038">played</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1040" end_char="1041">up</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1043" end_char="1047">their</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1049" end_char="1056">supposed</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1058" end_char="1064">ability</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1066" end_char="1069">when</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1071" end_char="1072">it</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1074" end_char="1078">comes</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1080" end_char="1081">to</TOKEN>
<TOKEN id="token-13-15" pos="punct" morph="none" start_char="1083" end_char="1083">"</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1084" end_char="1093">preventing</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1095" end_char="1097">the</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1099" end_char="1104">spread</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1106" end_char="1107">of</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1109" end_char="1118">contagious</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="1120" end_char="1126">disease</TOKEN>
<TOKEN id="token-13-22" pos="punct" morph="none" start_char="1127" end_char="1128">,"</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="1130" end_char="1131">as</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="1133" end_char="1133">a</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="1135" end_char="1138">1924</TOKEN>
<TOKEN id="token-13-26" pos="word" morph="none" start_char="1140" end_char="1148">newspaper</TOKEN>
<TOKEN id="token-13-27" pos="word" morph="none" start_char="1150" end_char="1151">ad</TOKEN>
<TOKEN id="token-13-28" pos="word" morph="none" start_char="1153" end_char="1155">for</TOKEN>
<TOKEN id="token-13-29" pos="word" morph="none" start_char="1157" end_char="1159">the</TOKEN>
<TOKEN id="token-13-30" pos="word" morph="none" start_char="1161" end_char="1166">Airdry</TOKEN>
<TOKEN id="token-13-31" pos="word" morph="none" start_char="1168" end_char="1175">Electric</TOKEN>
<TOKEN id="token-13-32" pos="word" morph="none" start_char="1177" end_char="1181">Towel</TOKEN>
<TOKEN id="token-13-33" pos="word" morph="none" start_char="1183" end_char="1185">put</TOKEN>
<TOKEN id="token-13-34" pos="word" morph="none" start_char="1187" end_char="1188">it</TOKEN>
<TOKEN id="token-13-35" pos="punct" morph="none" start_char="1189" end_char="1189">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1191" end_char="1485">
<ORIGINAL_TEXT>More recently, Dyson, whose Airblade hand dryer promises to "scrape water from hands like a windshield wiper," has bragged that its HEPA air filter captures particles as tiny as .3 microns in diameter, much like the N95 face masks that are now selling for AirPod Pro–equivalent prices on Amazon.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1191" end_char="1194">More</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1196" end_char="1203">recently</TOKEN>
<TOKEN id="token-14-2" pos="punct" morph="none" start_char="1204" end_char="1204">,</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1206" end_char="1210">Dyson</TOKEN>
<TOKEN id="token-14-4" pos="punct" morph="none" start_char="1211" end_char="1211">,</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1213" end_char="1217">whose</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1219" end_char="1226">Airblade</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1228" end_char="1231">hand</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1233" end_char="1237">dryer</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1239" end_char="1246">promises</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1248" end_char="1249">to</TOKEN>
<TOKEN id="token-14-11" pos="punct" morph="none" start_char="1251" end_char="1251">"</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1252" end_char="1257">scrape</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1259" end_char="1263">water</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="1265" end_char="1268">from</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1270" end_char="1274">hands</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1276" end_char="1279">like</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="1281" end_char="1281">a</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="1283" end_char="1292">windshield</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="1294" end_char="1298">wiper</TOKEN>
<TOKEN id="token-14-20" pos="punct" morph="none" start_char="1299" end_char="1300">,"</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="1302" end_char="1304">has</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="1306" end_char="1312">bragged</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="1314" end_char="1317">that</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="1319" end_char="1321">its</TOKEN>
<TOKEN id="token-14-25" pos="word" morph="none" start_char="1323" end_char="1326">HEPA</TOKEN>
<TOKEN id="token-14-26" pos="word" morph="none" start_char="1328" end_char="1330">air</TOKEN>
<TOKEN id="token-14-27" pos="word" morph="none" start_char="1332" end_char="1337">filter</TOKEN>
<TOKEN id="token-14-28" pos="word" morph="none" start_char="1339" end_char="1346">captures</TOKEN>
<TOKEN id="token-14-29" pos="word" morph="none" start_char="1348" end_char="1356">particles</TOKEN>
<TOKEN id="token-14-30" pos="word" morph="none" start_char="1358" end_char="1359">as</TOKEN>
<TOKEN id="token-14-31" pos="word" morph="none" start_char="1361" end_char="1364">tiny</TOKEN>
<TOKEN id="token-14-32" pos="word" morph="none" start_char="1366" end_char="1367">as</TOKEN>
<TOKEN id="token-14-33" pos="word" morph="none" start_char="1369" end_char="1370">.3</TOKEN>
<TOKEN id="token-14-34" pos="word" morph="none" start_char="1372" end_char="1378">microns</TOKEN>
<TOKEN id="token-14-35" pos="word" morph="none" start_char="1380" end_char="1381">in</TOKEN>
<TOKEN id="token-14-36" pos="word" morph="none" start_char="1383" end_char="1390">diameter</TOKEN>
<TOKEN id="token-14-37" pos="punct" morph="none" start_char="1391" end_char="1391">,</TOKEN>
<TOKEN id="token-14-38" pos="word" morph="none" start_char="1393" end_char="1396">much</TOKEN>
<TOKEN id="token-14-39" pos="word" morph="none" start_char="1398" end_char="1401">like</TOKEN>
<TOKEN id="token-14-40" pos="word" morph="none" start_char="1403" end_char="1405">the</TOKEN>
<TOKEN id="token-14-41" pos="word" morph="none" start_char="1407" end_char="1409">N95</TOKEN>
<TOKEN id="token-14-42" pos="word" morph="none" start_char="1411" end_char="1414">face</TOKEN>
<TOKEN id="token-14-43" pos="word" morph="none" start_char="1416" end_char="1420">masks</TOKEN>
<TOKEN id="token-14-44" pos="word" morph="none" start_char="1422" end_char="1425">that</TOKEN>
<TOKEN id="token-14-45" pos="word" morph="none" start_char="1427" end_char="1429">are</TOKEN>
<TOKEN id="token-14-46" pos="word" morph="none" start_char="1431" end_char="1433">now</TOKEN>
<TOKEN id="token-14-47" pos="word" morph="none" start_char="1435" end_char="1441">selling</TOKEN>
<TOKEN id="token-14-48" pos="word" morph="none" start_char="1443" end_char="1445">for</TOKEN>
<TOKEN id="token-14-49" pos="word" morph="none" start_char="1447" end_char="1452">AirPod</TOKEN>
<TOKEN id="token-14-50" pos="unknown" morph="none" start_char="1454" end_char="1467">Pro–equivalent</TOKEN>
<TOKEN id="token-14-51" pos="word" morph="none" start_char="1469" end_char="1474">prices</TOKEN>
<TOKEN id="token-14-52" pos="word" morph="none" start_char="1476" end_char="1477">on</TOKEN>
<TOKEN id="token-14-53" pos="word" morph="none" start_char="1479" end_char="1484">Amazon</TOKEN>
<TOKEN id="token-14-54" pos="punct" morph="none" start_char="1485" end_char="1485">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1488" end_char="1702">
<ORIGINAL_TEXT>But the quality of the intake filter doesn’t address whether blowing air at high speeds is a smart idea given that it may be sending droplets and particles from your just-washed hands flying rapidly every which way.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1488" end_char="1490">But</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1492" end_char="1494">the</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1496" end_char="1502">quality</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1504" end_char="1505">of</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1507" end_char="1509">the</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1511" end_char="1516">intake</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1518" end_char="1523">filter</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1525" end_char="1531">doesn’t</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1533" end_char="1539">address</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1541" end_char="1547">whether</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1549" end_char="1555">blowing</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1557" end_char="1559">air</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1561" end_char="1562">at</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1564" end_char="1567">high</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1569" end_char="1574">speeds</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="1576" end_char="1577">is</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="1579" end_char="1579">a</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="1581" end_char="1585">smart</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="1587" end_char="1590">idea</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="1592" end_char="1596">given</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="1598" end_char="1601">that</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="1603" end_char="1604">it</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="1606" end_char="1608">may</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="1610" end_char="1611">be</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="1613" end_char="1619">sending</TOKEN>
<TOKEN id="token-15-25" pos="word" morph="none" start_char="1621" end_char="1628">droplets</TOKEN>
<TOKEN id="token-15-26" pos="word" morph="none" start_char="1630" end_char="1632">and</TOKEN>
<TOKEN id="token-15-27" pos="word" morph="none" start_char="1634" end_char="1642">particles</TOKEN>
<TOKEN id="token-15-28" pos="word" morph="none" start_char="1644" end_char="1647">from</TOKEN>
<TOKEN id="token-15-29" pos="word" morph="none" start_char="1649" end_char="1652">your</TOKEN>
<TOKEN id="token-15-30" pos="unknown" morph="none" start_char="1654" end_char="1664">just-washed</TOKEN>
<TOKEN id="token-15-31" pos="word" morph="none" start_char="1666" end_char="1670">hands</TOKEN>
<TOKEN id="token-15-32" pos="word" morph="none" start_char="1672" end_char="1677">flying</TOKEN>
<TOKEN id="token-15-33" pos="word" morph="none" start_char="1679" end_char="1685">rapidly</TOKEN>
<TOKEN id="token-15-34" pos="word" morph="none" start_char="1687" end_char="1691">every</TOKEN>
<TOKEN id="token-15-35" pos="word" morph="none" start_char="1693" end_char="1697">which</TOKEN>
<TOKEN id="token-15-36" pos="word" morph="none" start_char="1699" end_char="1701">way</TOKEN>
<TOKEN id="token-15-37" pos="punct" morph="none" start_char="1702" end_char="1702">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1704" end_char="1791">
<ORIGINAL_TEXT>When you dig into the science on hand dryers, you’ll come across reason to be concerned.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1704" end_char="1707">When</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1709" end_char="1711">you</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1713" end_char="1715">dig</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1717" end_char="1720">into</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1722" end_char="1724">the</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1726" end_char="1732">science</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1734" end_char="1735">on</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1737" end_char="1740">hand</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1742" end_char="1747">dryers</TOKEN>
<TOKEN id="token-16-9" pos="punct" morph="none" start_char="1748" end_char="1748">,</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="1750" end_char="1755">you’ll</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="1757" end_char="1760">come</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="1762" end_char="1767">across</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="1769" end_char="1774">reason</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="1776" end_char="1777">to</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="1779" end_char="1780">be</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="1782" end_char="1790">concerned</TOKEN>
<TOKEN id="token-16-17" pos="punct" morph="none" start_char="1791" end_char="1791">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1793" end_char="1994">
<ORIGINAL_TEXT>A study published in 1989 found that gentler, old-style hand dryers blew bacteria over a three-foot radius and onto the user’s clothes, which considering the era was probably an acid-washed jean jacket.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1793" end_char="1793">A</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1795" end_char="1799">study</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="1801" end_char="1809">published</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="1811" end_char="1812">in</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="1814" end_char="1817">1989</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="1819" end_char="1823">found</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="1825" end_char="1828">that</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="1830" end_char="1836">gentler</TOKEN>
<TOKEN id="token-17-8" pos="punct" morph="none" start_char="1837" end_char="1837">,</TOKEN>
<TOKEN id="token-17-9" pos="unknown" morph="none" start_char="1839" end_char="1847">old-style</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="1849" end_char="1852">hand</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="1854" end_char="1859">dryers</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="1861" end_char="1864">blew</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="1866" end_char="1873">bacteria</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="1875" end_char="1878">over</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="1880" end_char="1880">a</TOKEN>
<TOKEN id="token-17-16" pos="unknown" morph="none" start_char="1882" end_char="1891">three-foot</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="1893" end_char="1898">radius</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="1900" end_char="1902">and</TOKEN>
<TOKEN id="token-17-19" pos="word" morph="none" start_char="1904" end_char="1907">onto</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="1909" end_char="1911">the</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="1913" end_char="1918">user’s</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="1920" end_char="1926">clothes</TOKEN>
<TOKEN id="token-17-23" pos="punct" morph="none" start_char="1927" end_char="1927">,</TOKEN>
<TOKEN id="token-17-24" pos="word" morph="none" start_char="1929" end_char="1933">which</TOKEN>
<TOKEN id="token-17-25" pos="word" morph="none" start_char="1935" end_char="1945">considering</TOKEN>
<TOKEN id="token-17-26" pos="word" morph="none" start_char="1947" end_char="1949">the</TOKEN>
<TOKEN id="token-17-27" pos="word" morph="none" start_char="1951" end_char="1953">era</TOKEN>
<TOKEN id="token-17-28" pos="word" morph="none" start_char="1955" end_char="1957">was</TOKEN>
<TOKEN id="token-17-29" pos="word" morph="none" start_char="1959" end_char="1966">probably</TOKEN>
<TOKEN id="token-17-30" pos="word" morph="none" start_char="1968" end_char="1969">an</TOKEN>
<TOKEN id="token-17-31" pos="unknown" morph="none" start_char="1971" end_char="1981">acid-washed</TOKEN>
<TOKEN id="token-17-32" pos="word" morph="none" start_char="1983" end_char="1986">jean</TOKEN>
<TOKEN id="token-17-33" pos="word" morph="none" start_char="1988" end_char="1993">jacket</TOKEN>
<TOKEN id="token-17-34" pos="punct" morph="none" start_char="1994" end_char="1994">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1997" end_char="2173">
<ORIGINAL_TEXT>A 2018 study produced even more troubling results, finding that "potential pathogens and spores" could be "dispersed throughout buildings and deposited on hands by hand dryers."</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="1997" end_char="1997">A</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="1999" end_char="2002">2018</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2004" end_char="2008">study</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2010" end_char="2017">produced</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2019" end_char="2022">even</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2024" end_char="2027">more</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2029" end_char="2037">troubling</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2039" end_char="2045">results</TOKEN>
<TOKEN id="token-18-8" pos="punct" morph="none" start_char="2046" end_char="2046">,</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="2048" end_char="2054">finding</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="2056" end_char="2059">that</TOKEN>
<TOKEN id="token-18-11" pos="punct" morph="none" start_char="2061" end_char="2061">"</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2062" end_char="2070">potential</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="2072" end_char="2080">pathogens</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="2082" end_char="2084">and</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="2086" end_char="2091">spores</TOKEN>
<TOKEN id="token-18-16" pos="punct" morph="none" start_char="2092" end_char="2092">"</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="2094" end_char="2098">could</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="2100" end_char="2101">be</TOKEN>
<TOKEN id="token-18-19" pos="punct" morph="none" start_char="2103" end_char="2103">"</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="2104" end_char="2112">dispersed</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="2114" end_char="2123">throughout</TOKEN>
<TOKEN id="token-18-22" pos="word" morph="none" start_char="2125" end_char="2133">buildings</TOKEN>
<TOKEN id="token-18-23" pos="word" morph="none" start_char="2135" end_char="2137">and</TOKEN>
<TOKEN id="token-18-24" pos="word" morph="none" start_char="2139" end_char="2147">deposited</TOKEN>
<TOKEN id="token-18-25" pos="word" morph="none" start_char="2149" end_char="2150">on</TOKEN>
<TOKEN id="token-18-26" pos="word" morph="none" start_char="2152" end_char="2156">hands</TOKEN>
<TOKEN id="token-18-27" pos="word" morph="none" start_char="2158" end_char="2159">by</TOKEN>
<TOKEN id="token-18-28" pos="word" morph="none" start_char="2161" end_char="2164">hand</TOKEN>
<TOKEN id="token-18-29" pos="word" morph="none" start_char="2166" end_char="2171">dryers</TOKEN>
<TOKEN id="token-18-30" pos="punct" morph="none" start_char="2172" end_char="2173">."</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2175" end_char="2412">
<ORIGINAL_TEXT>It tested conventional hot-air models with and without filters and determined that the filters "most likely reduce the number of potentially pathogenic bacteria with the potential to colonize hands but do not eliminate the risk entirely."</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2175" end_char="2176">It</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2178" end_char="2183">tested</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2185" end_char="2196">conventional</TOKEN>
<TOKEN id="token-19-3" pos="unknown" morph="none" start_char="2198" end_char="2204">hot-air</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2206" end_char="2211">models</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2213" end_char="2216">with</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2218" end_char="2220">and</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2222" end_char="2228">without</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2230" end_char="2236">filters</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="2238" end_char="2240">and</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="2242" end_char="2251">determined</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="2253" end_char="2256">that</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="2258" end_char="2260">the</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="2262" end_char="2268">filters</TOKEN>
<TOKEN id="token-19-14" pos="punct" morph="none" start_char="2270" end_char="2270">"</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="2271" end_char="2274">most</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="2276" end_char="2281">likely</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="2283" end_char="2288">reduce</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="2290" end_char="2292">the</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="2294" end_char="2299">number</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="2301" end_char="2302">of</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="2304" end_char="2314">potentially</TOKEN>
<TOKEN id="token-19-22" pos="word" morph="none" start_char="2316" end_char="2325">pathogenic</TOKEN>
<TOKEN id="token-19-23" pos="word" morph="none" start_char="2327" end_char="2334">bacteria</TOKEN>
<TOKEN id="token-19-24" pos="word" morph="none" start_char="2336" end_char="2339">with</TOKEN>
<TOKEN id="token-19-25" pos="word" morph="none" start_char="2341" end_char="2343">the</TOKEN>
<TOKEN id="token-19-26" pos="word" morph="none" start_char="2345" end_char="2353">potential</TOKEN>
<TOKEN id="token-19-27" pos="word" morph="none" start_char="2355" end_char="2356">to</TOKEN>
<TOKEN id="token-19-28" pos="word" morph="none" start_char="2358" end_char="2365">colonize</TOKEN>
<TOKEN id="token-19-29" pos="word" morph="none" start_char="2367" end_char="2371">hands</TOKEN>
<TOKEN id="token-19-30" pos="word" morph="none" start_char="2373" end_char="2375">but</TOKEN>
<TOKEN id="token-19-31" pos="word" morph="none" start_char="2377" end_char="2378">do</TOKEN>
<TOKEN id="token-19-32" pos="word" morph="none" start_char="2380" end_char="2382">not</TOKEN>
<TOKEN id="token-19-33" pos="word" morph="none" start_char="2384" end_char="2392">eliminate</TOKEN>
<TOKEN id="token-19-34" pos="word" morph="none" start_char="2394" end_char="2396">the</TOKEN>
<TOKEN id="token-19-35" pos="word" morph="none" start_char="2398" end_char="2401">risk</TOKEN>
<TOKEN id="token-19-36" pos="word" morph="none" start_char="2403" end_char="2410">entirely</TOKEN>
<TOKEN id="token-19-37" pos="punct" morph="none" start_char="2411" end_char="2412">."</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2414" end_char="2642">
<ORIGINAL_TEXT>A 2015 study found that super-aggro hand-dryers like the ones made by Dyson, which use higher-speed jets of air at room temperature, "produced significantly greater aerosolization of virus on the hands" than the traditional kind.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2414" end_char="2414">A</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2416" end_char="2419">2015</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2421" end_char="2425">study</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2427" end_char="2431">found</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2433" end_char="2436">that</TOKEN>
<TOKEN id="token-20-5" pos="unknown" morph="none" start_char="2438" end_char="2448">super-aggro</TOKEN>
<TOKEN id="token-20-6" pos="unknown" morph="none" start_char="2450" end_char="2460">hand-dryers</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2462" end_char="2465">like</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="2467" end_char="2469">the</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2471" end_char="2474">ones</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2476" end_char="2479">made</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="2481" end_char="2482">by</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="2484" end_char="2488">Dyson</TOKEN>
<TOKEN id="token-20-13" pos="punct" morph="none" start_char="2489" end_char="2489">,</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="2491" end_char="2495">which</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="2497" end_char="2499">use</TOKEN>
<TOKEN id="token-20-16" pos="unknown" morph="none" start_char="2501" end_char="2512">higher-speed</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="2514" end_char="2517">jets</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="2519" end_char="2520">of</TOKEN>
<TOKEN id="token-20-19" pos="word" morph="none" start_char="2522" end_char="2524">air</TOKEN>
<TOKEN id="token-20-20" pos="word" morph="none" start_char="2526" end_char="2527">at</TOKEN>
<TOKEN id="token-20-21" pos="word" morph="none" start_char="2529" end_char="2532">room</TOKEN>
<TOKEN id="token-20-22" pos="word" morph="none" start_char="2534" end_char="2544">temperature</TOKEN>
<TOKEN id="token-20-23" pos="punct" morph="none" start_char="2545" end_char="2545">,</TOKEN>
<TOKEN id="token-20-24" pos="punct" morph="none" start_char="2547" end_char="2547">"</TOKEN>
<TOKEN id="token-20-25" pos="word" morph="none" start_char="2548" end_char="2555">produced</TOKEN>
<TOKEN id="token-20-26" pos="word" morph="none" start_char="2557" end_char="2569">significantly</TOKEN>
<TOKEN id="token-20-27" pos="word" morph="none" start_char="2571" end_char="2577">greater</TOKEN>
<TOKEN id="token-20-28" pos="word" morph="none" start_char="2579" end_char="2592">aerosolization</TOKEN>
<TOKEN id="token-20-29" pos="word" morph="none" start_char="2594" end_char="2595">of</TOKEN>
<TOKEN id="token-20-30" pos="word" morph="none" start_char="2597" end_char="2601">virus</TOKEN>
<TOKEN id="token-20-31" pos="word" morph="none" start_char="2603" end_char="2604">on</TOKEN>
<TOKEN id="token-20-32" pos="word" morph="none" start_char="2606" end_char="2608">the</TOKEN>
<TOKEN id="token-20-33" pos="word" morph="none" start_char="2610" end_char="2614">hands</TOKEN>
<TOKEN id="token-20-34" pos="punct" morph="none" start_char="2615" end_char="2615">"</TOKEN>
<TOKEN id="token-20-35" pos="word" morph="none" start_char="2617" end_char="2620">than</TOKEN>
<TOKEN id="token-20-36" pos="word" morph="none" start_char="2622" end_char="2624">the</TOKEN>
<TOKEN id="token-20-37" pos="word" morph="none" start_char="2626" end_char="2636">traditional</TOKEN>
<TOKEN id="token-20-38" pos="word" morph="none" start_char="2638" end_char="2641">kind</TOKEN>
<TOKEN id="token-20-39" pos="punct" morph="none" start_char="2642" end_char="2642">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2644" end_char="2744">
<ORIGINAL_TEXT>Paper towels, meanwhile, were found to cause about the same amount of viral spread as hot-air models.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2644" end_char="2648">Paper</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2650" end_char="2655">towels</TOKEN>
<TOKEN id="token-21-2" pos="punct" morph="none" start_char="2656" end_char="2656">,</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2658" end_char="2666">meanwhile</TOKEN>
<TOKEN id="token-21-4" pos="punct" morph="none" start_char="2667" end_char="2667">,</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="2669" end_char="2672">were</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2674" end_char="2678">found</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="2680" end_char="2681">to</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="2683" end_char="2687">cause</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="2689" end_char="2693">about</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="2695" end_char="2697">the</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="2699" end_char="2702">same</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="2704" end_char="2709">amount</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="2711" end_char="2712">of</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="2714" end_char="2718">viral</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="2720" end_char="2725">spread</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="2727" end_char="2728">as</TOKEN>
<TOKEN id="token-21-17" pos="unknown" morph="none" start_char="2730" end_char="2736">hot-air</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="2738" end_char="2743">models</TOKEN>
<TOKEN id="token-21-19" pos="punct" morph="none" start_char="2744" end_char="2744">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2747" end_char="2806">
<ORIGINAL_TEXT>A 2012 analysis of 12 studies over four decades published in</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2747" end_char="2747">A</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2749" end_char="2752">2012</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2754" end_char="2761">analysis</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2763" end_char="2764">of</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2766" end_char="2767">12</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2769" end_char="2775">studies</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2777" end_char="2780">over</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2782" end_char="2785">four</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="2787" end_char="2793">decades</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="2795" end_char="2803">published</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="2805" end_char="2806">in</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2809" end_char="2831">
<ORIGINAL_TEXT>Mayo Clinic Proceedings</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2809" end_char="2812">Mayo</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2814" end_char="2819">Clinic</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2821" end_char="2831">Proceedings</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2834" end_char="3032">
<ORIGINAL_TEXT>concluded that "[f]rom a hygiene viewpoint, paper towels are superior to electric air dryers" and that they should be used in "locations in which hygiene is paramount, such as hospitals and clinics."</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="2834" end_char="2842">concluded</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="2844" end_char="2847">that</TOKEN>
<TOKEN id="token-24-2" pos="punct" morph="none" start_char="2849" end_char="2850">"[</TOKEN>
<TOKEN id="token-24-3" pos="unknown" morph="none" start_char="2851" end_char="2855">f]rom</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="2857" end_char="2857">a</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="2859" end_char="2865">hygiene</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="2867" end_char="2875">viewpoint</TOKEN>
<TOKEN id="token-24-7" pos="punct" morph="none" start_char="2876" end_char="2876">,</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="2878" end_char="2882">paper</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="2884" end_char="2889">towels</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="2891" end_char="2893">are</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="2895" end_char="2902">superior</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="2904" end_char="2905">to</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="2907" end_char="2914">electric</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="2916" end_char="2918">air</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="2920" end_char="2925">dryers</TOKEN>
<TOKEN id="token-24-16" pos="punct" morph="none" start_char="2926" end_char="2926">"</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="2928" end_char="2930">and</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="2932" end_char="2935">that</TOKEN>
<TOKEN id="token-24-19" pos="word" morph="none" start_char="2937" end_char="2940">they</TOKEN>
<TOKEN id="token-24-20" pos="word" morph="none" start_char="2942" end_char="2947">should</TOKEN>
<TOKEN id="token-24-21" pos="word" morph="none" start_char="2949" end_char="2950">be</TOKEN>
<TOKEN id="token-24-22" pos="word" morph="none" start_char="2952" end_char="2955">used</TOKEN>
<TOKEN id="token-24-23" pos="word" morph="none" start_char="2957" end_char="2958">in</TOKEN>
<TOKEN id="token-24-24" pos="punct" morph="none" start_char="2960" end_char="2960">"</TOKEN>
<TOKEN id="token-24-25" pos="word" morph="none" start_char="2961" end_char="2969">locations</TOKEN>
<TOKEN id="token-24-26" pos="word" morph="none" start_char="2971" end_char="2972">in</TOKEN>
<TOKEN id="token-24-27" pos="word" morph="none" start_char="2974" end_char="2978">which</TOKEN>
<TOKEN id="token-24-28" pos="word" morph="none" start_char="2980" end_char="2986">hygiene</TOKEN>
<TOKEN id="token-24-29" pos="word" morph="none" start_char="2988" end_char="2989">is</TOKEN>
<TOKEN id="token-24-30" pos="word" morph="none" start_char="2991" end_char="2999">paramount</TOKEN>
<TOKEN id="token-24-31" pos="punct" morph="none" start_char="3000" end_char="3000">,</TOKEN>
<TOKEN id="token-24-32" pos="word" morph="none" start_char="3002" end_char="3005">such</TOKEN>
<TOKEN id="token-24-33" pos="word" morph="none" start_char="3007" end_char="3008">as</TOKEN>
<TOKEN id="token-24-34" pos="word" morph="none" start_char="3010" end_char="3018">hospitals</TOKEN>
<TOKEN id="token-24-35" pos="word" morph="none" start_char="3020" end_char="3022">and</TOKEN>
<TOKEN id="token-24-36" pos="word" morph="none" start_char="3024" end_char="3030">clinics</TOKEN>
<TOKEN id="token-24-37" pos="punct" morph="none" start_char="3031" end_char="3032">."</TOKEN>
</SEG>
<SEG id="segment-25" start_char="3034" end_char="3153">
<ORIGINAL_TEXT>Though it could be argued that hygiene should be paramount in the restroom of, say, your neighborhood Panera Bread, too.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="3034" end_char="3039">Though</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="3041" end_char="3042">it</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="3044" end_char="3048">could</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="3050" end_char="3051">be</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="3053" end_char="3058">argued</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="3060" end_char="3063">that</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="3065" end_char="3071">hygiene</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="3073" end_char="3078">should</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="3080" end_char="3081">be</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="3083" end_char="3091">paramount</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="3093" end_char="3094">in</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="3096" end_char="3098">the</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="3100" end_char="3107">restroom</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="3109" end_char="3110">of</TOKEN>
<TOKEN id="token-25-14" pos="punct" morph="none" start_char="3111" end_char="3111">,</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="3113" end_char="3115">say</TOKEN>
<TOKEN id="token-25-16" pos="punct" morph="none" start_char="3116" end_char="3116">,</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="3118" end_char="3121">your</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="3123" end_char="3134">neighborhood</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="3136" end_char="3141">Panera</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="3143" end_char="3147">Bread</TOKEN>
<TOKEN id="token-25-21" pos="punct" morph="none" start_char="3148" end_char="3148">,</TOKEN>
<TOKEN id="token-25-22" pos="word" morph="none" start_char="3150" end_char="3152">too</TOKEN>
<TOKEN id="token-25-23" pos="punct" morph="none" start_char="3153" end_char="3153">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="3155" end_char="3259">
<ORIGINAL_TEXT>The analysis did find that dryers like Dyson’s "led to much less bacterial transfer than hot air dryers."</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="3155" end_char="3157">The</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="3159" end_char="3166">analysis</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="3168" end_char="3170">did</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="3172" end_char="3175">find</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="3177" end_char="3180">that</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="3182" end_char="3187">dryers</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="3189" end_char="3192">like</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="3194" end_char="3200">Dyson’s</TOKEN>
<TOKEN id="token-26-8" pos="punct" morph="none" start_char="3202" end_char="3202">"</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="3203" end_char="3205">led</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="3207" end_char="3208">to</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="3210" end_char="3213">much</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="3215" end_char="3218">less</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="3220" end_char="3228">bacterial</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="3230" end_char="3237">transfer</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="3239" end_char="3242">than</TOKEN>
<TOKEN id="token-26-16" pos="word" morph="none" start_char="3244" end_char="3246">hot</TOKEN>
<TOKEN id="token-26-17" pos="word" morph="none" start_char="3248" end_char="3250">air</TOKEN>
<TOKEN id="token-26-18" pos="word" morph="none" start_char="3252" end_char="3257">dryers</TOKEN>
<TOKEN id="token-26-19" pos="punct" morph="none" start_char="3258" end_char="3259">."</TOKEN>
</SEG>
<SEG id="segment-27" start_char="3262" end_char="3372">
<ORIGINAL_TEXT>So does that tell us anything about whether hand dryers could spread a virus like the one that causes Covid-19?</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="3262" end_char="3263">So</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="3265" end_char="3268">does</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="3270" end_char="3273">that</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="3275" end_char="3278">tell</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="3280" end_char="3281">us</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="3283" end_char="3290">anything</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="3292" end_char="3296">about</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="3298" end_char="3304">whether</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="3306" end_char="3309">hand</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="3311" end_char="3316">dryers</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="3318" end_char="3322">could</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="3324" end_char="3329">spread</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="3331" end_char="3331">a</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="3333" end_char="3337">virus</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="3339" end_char="3342">like</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="3344" end_char="3346">the</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="3348" end_char="3350">one</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="3352" end_char="3355">that</TOKEN>
<TOKEN id="token-27-18" pos="word" morph="none" start_char="3357" end_char="3362">causes</TOKEN>
<TOKEN id="token-27-19" pos="unknown" morph="none" start_char="3364" end_char="3371">Covid-19</TOKEN>
<TOKEN id="token-27-20" pos="punct" morph="none" start_char="3372" end_char="3372">?</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3374" end_char="3484">
<ORIGINAL_TEXT>I called Peter Setlow, a biochemist at the University of Connecticut and one of the authors of that 2018 study.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="3374" end_char="3374">I</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="3376" end_char="3381">called</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="3383" end_char="3387">Peter</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="3389" end_char="3394">Setlow</TOKEN>
<TOKEN id="token-28-4" pos="punct" morph="none" start_char="3395" end_char="3395">,</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="3397" end_char="3397">a</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="3399" end_char="3408">biochemist</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="3410" end_char="3411">at</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="3413" end_char="3415">the</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="3417" end_char="3426">University</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="3428" end_char="3429">of</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="3431" end_char="3441">Connecticut</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="3443" end_char="3445">and</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="3447" end_char="3449">one</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="3451" end_char="3452">of</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="3454" end_char="3456">the</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="3458" end_char="3464">authors</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="3466" end_char="3467">of</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="3469" end_char="3472">that</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="3474" end_char="3477">2018</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="3479" end_char="3483">study</TOKEN>
<TOKEN id="token-28-21" pos="punct" morph="none" start_char="3484" end_char="3484">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3486" end_char="3663">
<ORIGINAL_TEXT>Setlow is a "spore guy" not an infectious disease expert, but he nonetheless came away from that research with a deep and abiding distrust of hand dryers regardless of the model.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="3486" end_char="3491">Setlow</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="3493" end_char="3494">is</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="3496" end_char="3496">a</TOKEN>
<TOKEN id="token-29-3" pos="punct" morph="none" start_char="3498" end_char="3498">"</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="3499" end_char="3503">spore</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="3505" end_char="3507">guy</TOKEN>
<TOKEN id="token-29-6" pos="punct" morph="none" start_char="3508" end_char="3508">"</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="3510" end_char="3512">not</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="3514" end_char="3515">an</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="3517" end_char="3526">infectious</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="3528" end_char="3534">disease</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="3536" end_char="3541">expert</TOKEN>
<TOKEN id="token-29-12" pos="punct" morph="none" start_char="3542" end_char="3542">,</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="3544" end_char="3546">but</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="3548" end_char="3549">he</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="3551" end_char="3561">nonetheless</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="3563" end_char="3566">came</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="3568" end_char="3571">away</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="3573" end_char="3576">from</TOKEN>
<TOKEN id="token-29-19" pos="word" morph="none" start_char="3578" end_char="3581">that</TOKEN>
<TOKEN id="token-29-20" pos="word" morph="none" start_char="3583" end_char="3590">research</TOKEN>
<TOKEN id="token-29-21" pos="word" morph="none" start_char="3592" end_char="3595">with</TOKEN>
<TOKEN id="token-29-22" pos="word" morph="none" start_char="3597" end_char="3597">a</TOKEN>
<TOKEN id="token-29-23" pos="word" morph="none" start_char="3599" end_char="3602">deep</TOKEN>
<TOKEN id="token-29-24" pos="word" morph="none" start_char="3604" end_char="3606">and</TOKEN>
<TOKEN id="token-29-25" pos="word" morph="none" start_char="3608" end_char="3614">abiding</TOKEN>
<TOKEN id="token-29-26" pos="word" morph="none" start_char="3616" end_char="3623">distrust</TOKEN>
<TOKEN id="token-29-27" pos="word" morph="none" start_char="3625" end_char="3626">of</TOKEN>
<TOKEN id="token-29-28" pos="word" morph="none" start_char="3628" end_char="3631">hand</TOKEN>
<TOKEN id="token-29-29" pos="word" morph="none" start_char="3633" end_char="3638">dryers</TOKEN>
<TOKEN id="token-29-30" pos="word" morph="none" start_char="3640" end_char="3649">regardless</TOKEN>
<TOKEN id="token-29-31" pos="word" morph="none" start_char="3651" end_char="3652">of</TOKEN>
<TOKEN id="token-29-32" pos="word" morph="none" start_char="3654" end_char="3656">the</TOKEN>
<TOKEN id="token-29-33" pos="word" morph="none" start_char="3658" end_char="3662">model</TOKEN>
<TOKEN id="token-29-34" pos="punct" morph="none" start_char="3663" end_char="3663">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3665" end_char="3705">
<ORIGINAL_TEXT>"Sorry, hand-dryer industry," he told me.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="punct" morph="none" start_char="3665" end_char="3665">"</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="3666" end_char="3670">Sorry</TOKEN>
<TOKEN id="token-30-2" pos="punct" morph="none" start_char="3671" end_char="3671">,</TOKEN>
<TOKEN id="token-30-3" pos="unknown" morph="none" start_char="3673" end_char="3682">hand-dryer</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="3684" end_char="3691">industry</TOKEN>
<TOKEN id="token-30-5" pos="punct" morph="none" start_char="3692" end_char="3693">,"</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="3695" end_char="3696">he</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="3698" end_char="3701">told</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="3703" end_char="3704">me</TOKEN>
<TOKEN id="token-30-9" pos="punct" morph="none" start_char="3705" end_char="3705">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="3707" end_char="3759">
<ORIGINAL_TEXT>"My personal opinion is that they shouldn’t be used."</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="punct" morph="none" start_char="3707" end_char="3707">"</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="3708" end_char="3709">My</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="3711" end_char="3718">personal</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="3720" end_char="3726">opinion</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="3728" end_char="3729">is</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="3731" end_char="3734">that</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="3736" end_char="3739">they</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="3741" end_char="3749">shouldn’t</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="3751" end_char="3752">be</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="3754" end_char="3757">used</TOKEN>
<TOKEN id="token-31-10" pos="punct" morph="none" start_char="3758" end_char="3759">."</TOKEN>
</SEG>
<SEG id="segment-32" start_char="3762" end_char="4088">
<ORIGINAL_TEXT>There’s been understandable blowback from the hand-dryer industry, which questions the methodology of some of this research and notes that certain studies pegging hand dryers as disease vectors—including the one cited above, from 2015—were carried out by researchers who had worked as consultants for paper-towel manufacturers.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="3762" end_char="3768">There’s</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="3770" end_char="3773">been</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="3775" end_char="3788">understandable</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="3790" end_char="3797">blowback</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="3799" end_char="3802">from</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="3804" end_char="3806">the</TOKEN>
<TOKEN id="token-32-6" pos="unknown" morph="none" start_char="3808" end_char="3817">hand-dryer</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="3819" end_char="3826">industry</TOKEN>
<TOKEN id="token-32-8" pos="punct" morph="none" start_char="3827" end_char="3827">,</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="3829" end_char="3833">which</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="3835" end_char="3843">questions</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="3845" end_char="3847">the</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="3849" end_char="3859">methodology</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="3861" end_char="3862">of</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="3864" end_char="3867">some</TOKEN>
<TOKEN id="token-32-15" pos="word" morph="none" start_char="3869" end_char="3870">of</TOKEN>
<TOKEN id="token-32-16" pos="word" morph="none" start_char="3872" end_char="3875">this</TOKEN>
<TOKEN id="token-32-17" pos="word" morph="none" start_char="3877" end_char="3884">research</TOKEN>
<TOKEN id="token-32-18" pos="word" morph="none" start_char="3886" end_char="3888">and</TOKEN>
<TOKEN id="token-32-19" pos="word" morph="none" start_char="3890" end_char="3894">notes</TOKEN>
<TOKEN id="token-32-20" pos="word" morph="none" start_char="3896" end_char="3899">that</TOKEN>
<TOKEN id="token-32-21" pos="word" morph="none" start_char="3901" end_char="3907">certain</TOKEN>
<TOKEN id="token-32-22" pos="word" morph="none" start_char="3909" end_char="3915">studies</TOKEN>
<TOKEN id="token-32-23" pos="word" morph="none" start_char="3917" end_char="3923">pegging</TOKEN>
<TOKEN id="token-32-24" pos="word" morph="none" start_char="3925" end_char="3928">hand</TOKEN>
<TOKEN id="token-32-25" pos="word" morph="none" start_char="3930" end_char="3935">dryers</TOKEN>
<TOKEN id="token-32-26" pos="word" morph="none" start_char="3937" end_char="3938">as</TOKEN>
<TOKEN id="token-32-27" pos="word" morph="none" start_char="3940" end_char="3946">disease</TOKEN>
<TOKEN id="token-32-28" pos="unknown" morph="none" start_char="3948" end_char="3964">vectors—including</TOKEN>
<TOKEN id="token-32-29" pos="word" morph="none" start_char="3966" end_char="3968">the</TOKEN>
<TOKEN id="token-32-30" pos="word" morph="none" start_char="3970" end_char="3972">one</TOKEN>
<TOKEN id="token-32-31" pos="word" morph="none" start_char="3974" end_char="3978">cited</TOKEN>
<TOKEN id="token-32-32" pos="word" morph="none" start_char="3980" end_char="3984">above</TOKEN>
<TOKEN id="token-32-33" pos="punct" morph="none" start_char="3985" end_char="3985">,</TOKEN>
<TOKEN id="token-32-34" pos="word" morph="none" start_char="3987" end_char="3990">from</TOKEN>
<TOKEN id="token-32-35" pos="unknown" morph="none" start_char="3992" end_char="4000">2015—were</TOKEN>
<TOKEN id="token-32-36" pos="word" morph="none" start_char="4002" end_char="4008">carried</TOKEN>
<TOKEN id="token-32-37" pos="word" morph="none" start_char="4010" end_char="4012">out</TOKEN>
<TOKEN id="token-32-38" pos="word" morph="none" start_char="4014" end_char="4015">by</TOKEN>
<TOKEN id="token-32-39" pos="word" morph="none" start_char="4017" end_char="4027">researchers</TOKEN>
<TOKEN id="token-32-40" pos="word" morph="none" start_char="4029" end_char="4031">who</TOKEN>
<TOKEN id="token-32-41" pos="word" morph="none" start_char="4033" end_char="4035">had</TOKEN>
<TOKEN id="token-32-42" pos="word" morph="none" start_char="4037" end_char="4042">worked</TOKEN>
<TOKEN id="token-32-43" pos="word" morph="none" start_char="4044" end_char="4045">as</TOKEN>
<TOKEN id="token-32-44" pos="word" morph="none" start_char="4047" end_char="4057">consultants</TOKEN>
<TOKEN id="token-32-45" pos="word" morph="none" start_char="4059" end_char="4061">for</TOKEN>
<TOKEN id="token-32-46" pos="unknown" morph="none" start_char="4063" end_char="4073">paper-towel</TOKEN>
<TOKEN id="token-32-47" pos="word" morph="none" start_char="4075" end_char="4087">manufacturers</TOKEN>
<TOKEN id="token-32-48" pos="punct" morph="none" start_char="4088" end_char="4088">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="4090" end_char="4133">
<ORIGINAL_TEXT>This is true in some, though not all, cases.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="4090" end_char="4093">This</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="4095" end_char="4096">is</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="4098" end_char="4101">true</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="4103" end_char="4104">in</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="4106" end_char="4109">some</TOKEN>
<TOKEN id="token-33-5" pos="punct" morph="none" start_char="4110" end_char="4110">,</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="4112" end_char="4117">though</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="4119" end_char="4121">not</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="4123" end_char="4125">all</TOKEN>
<TOKEN id="token-33-9" pos="punct" morph="none" start_char="4126" end_char="4126">,</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="4128" end_char="4132">cases</TOKEN>
<TOKEN id="token-33-11" pos="punct" morph="none" start_char="4133" end_char="4133">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="4135" end_char="4221">
<ORIGINAL_TEXT>Dyson got in on the game by funding a study, published last April, that found—surprise!</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="4135" end_char="4139">Dyson</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="4141" end_char="4143">got</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="4145" end_char="4146">in</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="4148" end_char="4149">on</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="4151" end_char="4153">the</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="4155" end_char="4158">game</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="4160" end_char="4161">by</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="4163" end_char="4169">funding</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="4171" end_char="4171">a</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="4173" end_char="4177">study</TOKEN>
<TOKEN id="token-34-10" pos="punct" morph="none" start_char="4178" end_char="4178">,</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="4180" end_char="4188">published</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="4190" end_char="4193">last</TOKEN>
<TOKEN id="token-34-13" pos="word" morph="none" start_char="4195" end_char="4199">April</TOKEN>
<TOKEN id="token-34-14" pos="punct" morph="none" start_char="4200" end_char="4200">,</TOKEN>
<TOKEN id="token-34-15" pos="word" morph="none" start_char="4202" end_char="4205">that</TOKEN>
<TOKEN id="token-34-16" pos="unknown" morph="none" start_char="4207" end_char="4220">found—surprise</TOKEN>
<TOKEN id="token-34-17" pos="punct" morph="none" start_char="4221" end_char="4221">!</TOKEN>
</SEG>
<SEG id="segment-35" start_char="4223" end_char="4326">
<ORIGINAL_TEXT>—hands dried with the company’s own Airblade harbored fewer bacteria than those dried with paper towels.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="punct" morph="none" start_char="4223" end_char="4223">—</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="4224" end_char="4228">hands</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="4230" end_char="4234">dried</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="4236" end_char="4239">with</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="4241" end_char="4243">the</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="4245" end_char="4253">company’s</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="4255" end_char="4257">own</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="4259" end_char="4266">Airblade</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="4268" end_char="4275">harbored</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="4277" end_char="4281">fewer</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="4283" end_char="4290">bacteria</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="4292" end_char="4295">than</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="4297" end_char="4301">those</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="4303" end_char="4307">dried</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="4309" end_char="4312">with</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="4314" end_char="4318">paper</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="4320" end_char="4325">towels</TOKEN>
<TOKEN id="token-35-17" pos="punct" morph="none" start_char="4326" end_char="4326">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="4329" end_char="4380">
<ORIGINAL_TEXT>There’s reason to be skeptical of last year’s paper.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="4329" end_char="4335">There’s</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="4337" end_char="4342">reason</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="4344" end_char="4345">to</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="4347" end_char="4348">be</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="4350" end_char="4358">skeptical</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="4360" end_char="4361">of</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="4363" end_char="4366">last</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="4368" end_char="4373">year’s</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="4375" end_char="4379">paper</TOKEN>
<TOKEN id="token-36-9" pos="punct" morph="none" start_char="4380" end_char="4380">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="4382" end_char="4522">
<ORIGINAL_TEXT>In the study, subjects "slowly" moved their hands in and out of the machine for a full minute, something no normal human is ever going to do.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="4382" end_char="4383">In</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="4385" end_char="4387">the</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="4389" end_char="4393">study</TOKEN>
<TOKEN id="token-37-3" pos="punct" morph="none" start_char="4394" end_char="4394">,</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="4396" end_char="4403">subjects</TOKEN>
<TOKEN id="token-37-5" pos="punct" morph="none" start_char="4405" end_char="4405">"</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="4406" end_char="4411">slowly</TOKEN>
<TOKEN id="token-37-7" pos="punct" morph="none" start_char="4412" end_char="4412">"</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="4414" end_char="4418">moved</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="4420" end_char="4424">their</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="4426" end_char="4430">hands</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="4432" end_char="4433">in</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="4435" end_char="4437">and</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="4439" end_char="4441">out</TOKEN>
<TOKEN id="token-37-14" pos="word" morph="none" start_char="4443" end_char="4444">of</TOKEN>
<TOKEN id="token-37-15" pos="word" morph="none" start_char="4446" end_char="4448">the</TOKEN>
<TOKEN id="token-37-16" pos="word" morph="none" start_char="4450" end_char="4456">machine</TOKEN>
<TOKEN id="token-37-17" pos="word" morph="none" start_char="4458" end_char="4460">for</TOKEN>
<TOKEN id="token-37-18" pos="word" morph="none" start_char="4462" end_char="4462">a</TOKEN>
<TOKEN id="token-37-19" pos="word" morph="none" start_char="4464" end_char="4467">full</TOKEN>
<TOKEN id="token-37-20" pos="word" morph="none" start_char="4469" end_char="4474">minute</TOKEN>
<TOKEN id="token-37-21" pos="punct" morph="none" start_char="4475" end_char="4475">,</TOKEN>
<TOKEN id="token-37-22" pos="word" morph="none" start_char="4477" end_char="4485">something</TOKEN>
<TOKEN id="token-37-23" pos="word" morph="none" start_char="4487" end_char="4488">no</TOKEN>
<TOKEN id="token-37-24" pos="word" morph="none" start_char="4490" end_char="4495">normal</TOKEN>
<TOKEN id="token-37-25" pos="word" morph="none" start_char="4497" end_char="4501">human</TOKEN>
<TOKEN id="token-37-26" pos="word" morph="none" start_char="4503" end_char="4504">is</TOKEN>
<TOKEN id="token-37-27" pos="word" morph="none" start_char="4506" end_char="4509">ever</TOKEN>
<TOKEN id="token-37-28" pos="word" morph="none" start_char="4511" end_char="4515">going</TOKEN>
<TOKEN id="token-37-29" pos="word" morph="none" start_char="4517" end_char="4518">to</TOKEN>
<TOKEN id="token-37-30" pos="word" morph="none" start_char="4520" end_char="4521">do</TOKEN>
<TOKEN id="token-37-31" pos="punct" morph="none" start_char="4522" end_char="4522">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="4524" end_char="4632">
<ORIGINAL_TEXT>Besides, Dyson says elsewhere that the model dries hands satisfactorily in a mere 12 seconds, so which is it?</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="4524" end_char="4530">Besides</TOKEN>
<TOKEN id="token-38-1" pos="punct" morph="none" start_char="4531" end_char="4531">,</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="4533" end_char="4537">Dyson</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="4539" end_char="4542">says</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="4544" end_char="4552">elsewhere</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="4554" end_char="4557">that</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="4559" end_char="4561">the</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="4563" end_char="4567">model</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="4569" end_char="4573">dries</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="4575" end_char="4579">hands</TOKEN>
<TOKEN id="token-38-10" pos="word" morph="none" start_char="4581" end_char="4594">satisfactorily</TOKEN>
<TOKEN id="token-38-11" pos="word" morph="none" start_char="4596" end_char="4597">in</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="4599" end_char="4599">a</TOKEN>
<TOKEN id="token-38-13" pos="word" morph="none" start_char="4601" end_char="4604">mere</TOKEN>
<TOKEN id="token-38-14" pos="word" morph="none" start_char="4606" end_char="4607">12</TOKEN>
<TOKEN id="token-38-15" pos="word" morph="none" start_char="4609" end_char="4615">seconds</TOKEN>
<TOKEN id="token-38-16" pos="punct" morph="none" start_char="4616" end_char="4616">,</TOKEN>
<TOKEN id="token-38-17" pos="word" morph="none" start_char="4618" end_char="4619">so</TOKEN>
<TOKEN id="token-38-18" pos="word" morph="none" start_char="4621" end_char="4625">which</TOKEN>
<TOKEN id="token-38-19" pos="word" morph="none" start_char="4627" end_char="4628">is</TOKEN>
<TOKEN id="token-38-20" pos="word" morph="none" start_char="4630" end_char="4631">it</TOKEN>
<TOKEN id="token-38-21" pos="punct" morph="none" start_char="4632" end_char="4632">?</TOKEN>
</SEG>
<SEG id="segment-39" start_char="4634" end_char="4786">
<ORIGINAL_TEXT>More importantly, that study only looked at the bacteria left behind on hands post-drying, not whether particles might have been blown onto your clothes.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="4634" end_char="4637">More</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="4639" end_char="4649">importantly</TOKEN>
<TOKEN id="token-39-2" pos="punct" morph="none" start_char="4650" end_char="4650">,</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="4652" end_char="4655">that</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="4657" end_char="4661">study</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="4663" end_char="4666">only</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="4668" end_char="4673">looked</TOKEN>
<TOKEN id="token-39-7" pos="word" morph="none" start_char="4675" end_char="4676">at</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="4678" end_char="4680">the</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="4682" end_char="4689">bacteria</TOKEN>
<TOKEN id="token-39-10" pos="word" morph="none" start_char="4691" end_char="4694">left</TOKEN>
<TOKEN id="token-39-11" pos="word" morph="none" start_char="4696" end_char="4701">behind</TOKEN>
<TOKEN id="token-39-12" pos="word" morph="none" start_char="4703" end_char="4704">on</TOKEN>
<TOKEN id="token-39-13" pos="word" morph="none" start_char="4706" end_char="4710">hands</TOKEN>
<TOKEN id="token-39-14" pos="unknown" morph="none" start_char="4712" end_char="4722">post-drying</TOKEN>
<TOKEN id="token-39-15" pos="punct" morph="none" start_char="4723" end_char="4723">,</TOKEN>
<TOKEN id="token-39-16" pos="word" morph="none" start_char="4725" end_char="4727">not</TOKEN>
<TOKEN id="token-39-17" pos="word" morph="none" start_char="4729" end_char="4735">whether</TOKEN>
<TOKEN id="token-39-18" pos="word" morph="none" start_char="4737" end_char="4745">particles</TOKEN>
<TOKEN id="token-39-19" pos="word" morph="none" start_char="4747" end_char="4751">might</TOKEN>
<TOKEN id="token-39-20" pos="word" morph="none" start_char="4753" end_char="4756">have</TOKEN>
<TOKEN id="token-39-21" pos="word" morph="none" start_char="4758" end_char="4761">been</TOKEN>
<TOKEN id="token-39-22" pos="word" morph="none" start_char="4763" end_char="4767">blown</TOKEN>
<TOKEN id="token-39-23" pos="word" morph="none" start_char="4769" end_char="4772">onto</TOKEN>
<TOKEN id="token-39-24" pos="word" morph="none" start_char="4774" end_char="4777">your</TOKEN>
<TOKEN id="token-39-25" pos="word" morph="none" start_char="4779" end_char="4785">clothes</TOKEN>
<TOKEN id="token-39-26" pos="punct" morph="none" start_char="4786" end_char="4786">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="4789" end_char="4926">
<ORIGINAL_TEXT>It’s not just a matter of public health: There are fortunes at stake in the science war between the paper-towel and hand-dryer industries.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="4789" end_char="4792">It’s</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="4794" end_char="4796">not</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="4798" end_char="4801">just</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="4803" end_char="4803">a</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="4805" end_char="4810">matter</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="4812" end_char="4813">of</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="4815" end_char="4820">public</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="4822" end_char="4827">health</TOKEN>
<TOKEN id="token-40-8" pos="punct" morph="none" start_char="4828" end_char="4828">:</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="4830" end_char="4834">There</TOKEN>
<TOKEN id="token-40-10" pos="word" morph="none" start_char="4836" end_char="4838">are</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="4840" end_char="4847">fortunes</TOKEN>
<TOKEN id="token-40-12" pos="word" morph="none" start_char="4849" end_char="4850">at</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="4852" end_char="4856">stake</TOKEN>
<TOKEN id="token-40-14" pos="word" morph="none" start_char="4858" end_char="4859">in</TOKEN>
<TOKEN id="token-40-15" pos="word" morph="none" start_char="4861" end_char="4863">the</TOKEN>
<TOKEN id="token-40-16" pos="word" morph="none" start_char="4865" end_char="4871">science</TOKEN>
<TOKEN id="token-40-17" pos="word" morph="none" start_char="4873" end_char="4875">war</TOKEN>
<TOKEN id="token-40-18" pos="word" morph="none" start_char="4877" end_char="4883">between</TOKEN>
<TOKEN id="token-40-19" pos="word" morph="none" start_char="4885" end_char="4887">the</TOKEN>
<TOKEN id="token-40-20" pos="unknown" morph="none" start_char="4889" end_char="4899">paper-towel</TOKEN>
<TOKEN id="token-40-21" pos="word" morph="none" start_char="4901" end_char="4903">and</TOKEN>
<TOKEN id="token-40-22" pos="unknown" morph="none" start_char="4905" end_char="4914">hand-dryer</TOKEN>
<TOKEN id="token-40-23" pos="word" morph="none" start_char="4916" end_char="4925">industries</TOKEN>
<TOKEN id="token-40-24" pos="punct" morph="none" start_char="4926" end_char="4926">.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="4928" end_char="5154">
<ORIGINAL_TEXT>Multifold paper towels, the kind commonly used in bathrooms, are a several-billion-dollar-a-year behemoth, and one recent estimate of the global market for hand dryers puts the number at a shade under $800 million, and growing.</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="4928" end_char="4936">Multifold</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="4938" end_char="4942">paper</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="4944" end_char="4949">towels</TOKEN>
<TOKEN id="token-41-3" pos="punct" morph="none" start_char="4950" end_char="4950">,</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="4952" end_char="4954">the</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="4956" end_char="4959">kind</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="4961" end_char="4968">commonly</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="4970" end_char="4973">used</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="4975" end_char="4976">in</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="4978" end_char="4986">bathrooms</TOKEN>
<TOKEN id="token-41-10" pos="punct" morph="none" start_char="4987" end_char="4987">,</TOKEN>
<TOKEN id="token-41-11" pos="word" morph="none" start_char="4989" end_char="4991">are</TOKEN>
<TOKEN id="token-41-12" pos="word" morph="none" start_char="4993" end_char="4993">a</TOKEN>
<TOKEN id="token-41-13" pos="unknown" morph="none" start_char="4995" end_char="5023">several-billion-dollar-a-year</TOKEN>
<TOKEN id="token-41-14" pos="word" morph="none" start_char="5025" end_char="5032">behemoth</TOKEN>
<TOKEN id="token-41-15" pos="punct" morph="none" start_char="5033" end_char="5033">,</TOKEN>
<TOKEN id="token-41-16" pos="word" morph="none" start_char="5035" end_char="5037">and</TOKEN>
<TOKEN id="token-41-17" pos="word" morph="none" start_char="5039" end_char="5041">one</TOKEN>
<TOKEN id="token-41-18" pos="word" morph="none" start_char="5043" end_char="5048">recent</TOKEN>
<TOKEN id="token-41-19" pos="word" morph="none" start_char="5050" end_char="5057">estimate</TOKEN>
<TOKEN id="token-41-20" pos="word" morph="none" start_char="5059" end_char="5060">of</TOKEN>
<TOKEN id="token-41-21" pos="word" morph="none" start_char="5062" end_char="5064">the</TOKEN>
<TOKEN id="token-41-22" pos="word" morph="none" start_char="5066" end_char="5071">global</TOKEN>
<TOKEN id="token-41-23" pos="word" morph="none" start_char="5073" end_char="5078">market</TOKEN>
<TOKEN id="token-41-24" pos="word" morph="none" start_char="5080" end_char="5082">for</TOKEN>
<TOKEN id="token-41-25" pos="word" morph="none" start_char="5084" end_char="5087">hand</TOKEN>
<TOKEN id="token-41-26" pos="word" morph="none" start_char="5089" end_char="5094">dryers</TOKEN>
<TOKEN id="token-41-27" pos="word" morph="none" start_char="5096" end_char="5099">puts</TOKEN>
<TOKEN id="token-41-28" pos="word" morph="none" start_char="5101" end_char="5103">the</TOKEN>
<TOKEN id="token-41-29" pos="word" morph="none" start_char="5105" end_char="5110">number</TOKEN>
<TOKEN id="token-41-30" pos="word" morph="none" start_char="5112" end_char="5113">at</TOKEN>
<TOKEN id="token-41-31" pos="word" morph="none" start_char="5115" end_char="5115">a</TOKEN>
<TOKEN id="token-41-32" pos="word" morph="none" start_char="5117" end_char="5121">shade</TOKEN>
<TOKEN id="token-41-33" pos="word" morph="none" start_char="5123" end_char="5127">under</TOKEN>
<TOKEN id="token-41-34" pos="unknown" morph="none" start_char="5129" end_char="5132">$800</TOKEN>
<TOKEN id="token-41-35" pos="word" morph="none" start_char="5134" end_char="5140">million</TOKEN>
<TOKEN id="token-41-36" pos="punct" morph="none" start_char="5141" end_char="5141">,</TOKEN>
<TOKEN id="token-41-37" pos="word" morph="none" start_char="5143" end_char="5145">and</TOKEN>
<TOKEN id="token-41-38" pos="word" morph="none" start_char="5147" end_char="5153">growing</TOKEN>
<TOKEN id="token-41-39" pos="punct" morph="none" start_char="5154" end_char="5154">.</TOKEN>
</SEG>
<SEG id="segment-42" start_char="5156" end_char="5267">
<ORIGINAL_TEXT>This is big money and obviously no company wants their products to be viewed as more likely to make people sick.</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="5156" end_char="5159">This</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="5161" end_char="5162">is</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="5164" end_char="5166">big</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="5168" end_char="5172">money</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="5174" end_char="5176">and</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="5178" end_char="5186">obviously</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="5188" end_char="5189">no</TOKEN>
<TOKEN id="token-42-7" pos="word" morph="none" start_char="5191" end_char="5197">company</TOKEN>
<TOKEN id="token-42-8" pos="word" morph="none" start_char="5199" end_char="5203">wants</TOKEN>
<TOKEN id="token-42-9" pos="word" morph="none" start_char="5205" end_char="5209">their</TOKEN>
<TOKEN id="token-42-10" pos="word" morph="none" start_char="5211" end_char="5218">products</TOKEN>
<TOKEN id="token-42-11" pos="word" morph="none" start_char="5220" end_char="5221">to</TOKEN>
<TOKEN id="token-42-12" pos="word" morph="none" start_char="5223" end_char="5224">be</TOKEN>
<TOKEN id="token-42-13" pos="word" morph="none" start_char="5226" end_char="5231">viewed</TOKEN>
<TOKEN id="token-42-14" pos="word" morph="none" start_char="5233" end_char="5234">as</TOKEN>
<TOKEN id="token-42-15" pos="word" morph="none" start_char="5236" end_char="5239">more</TOKEN>
<TOKEN id="token-42-16" pos="word" morph="none" start_char="5241" end_char="5246">likely</TOKEN>
<TOKEN id="token-42-17" pos="word" morph="none" start_char="5248" end_char="5249">to</TOKEN>
<TOKEN id="token-42-18" pos="word" morph="none" start_char="5251" end_char="5254">make</TOKEN>
<TOKEN id="token-42-19" pos="word" morph="none" start_char="5256" end_char="5261">people</TOKEN>
<TOKEN id="token-42-20" pos="word" morph="none" start_char="5263" end_char="5266">sick</TOKEN>
<TOKEN id="token-42-21" pos="punct" morph="none" start_char="5267" end_char="5267">.</TOKEN>
</SEG>
<SEG id="segment-43" start_char="5269" end_char="5404">
<ORIGINAL_TEXT>Dyson has made the case that, while other brands of hand dryers might spread disease, its products are perfectly safe even in hospitals.</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="5269" end_char="5273">Dyson</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="5275" end_char="5277">has</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="5279" end_char="5282">made</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="5284" end_char="5286">the</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="5288" end_char="5291">case</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="5293" end_char="5296">that</TOKEN>
<TOKEN id="token-43-6" pos="punct" morph="none" start_char="5297" end_char="5297">,</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="5299" end_char="5303">while</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="5305" end_char="5309">other</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="5311" end_char="5316">brands</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="5318" end_char="5319">of</TOKEN>
<TOKEN id="token-43-11" pos="word" morph="none" start_char="5321" end_char="5324">hand</TOKEN>
<TOKEN id="token-43-12" pos="word" morph="none" start_char="5326" end_char="5331">dryers</TOKEN>
<TOKEN id="token-43-13" pos="word" morph="none" start_char="5333" end_char="5337">might</TOKEN>
<TOKEN id="token-43-14" pos="word" morph="none" start_char="5339" end_char="5344">spread</TOKEN>
<TOKEN id="token-43-15" pos="word" morph="none" start_char="5346" end_char="5352">disease</TOKEN>
<TOKEN id="token-43-16" pos="punct" morph="none" start_char="5353" end_char="5353">,</TOKEN>
<TOKEN id="token-43-17" pos="word" morph="none" start_char="5355" end_char="5357">its</TOKEN>
<TOKEN id="token-43-18" pos="word" morph="none" start_char="5359" end_char="5366">products</TOKEN>
<TOKEN id="token-43-19" pos="word" morph="none" start_char="5368" end_char="5370">are</TOKEN>
<TOKEN id="token-43-20" pos="word" morph="none" start_char="5372" end_char="5380">perfectly</TOKEN>
<TOKEN id="token-43-21" pos="word" morph="none" start_char="5382" end_char="5385">safe</TOKEN>
<TOKEN id="token-43-22" pos="word" morph="none" start_char="5387" end_char="5390">even</TOKEN>
<TOKEN id="token-43-23" pos="word" morph="none" start_char="5392" end_char="5393">in</TOKEN>
<TOKEN id="token-43-24" pos="word" morph="none" start_char="5395" end_char="5403">hospitals</TOKEN>
<TOKEN id="token-43-25" pos="punct" morph="none" start_char="5404" end_char="5404">.</TOKEN>
</SEG>
<SEG id="segment-44" start_char="5406" end_char="5587">
<ORIGINAL_TEXT>Karen Holeyman, lead research scientist and microbiologist at Dyson, also notes via email that "Dyson Airblade™ hand dryers are proven hygienic," and referred to its HEPA air filter.</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="5406" end_char="5410">Karen</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="5412" end_char="5419">Holeyman</TOKEN>
<TOKEN id="token-44-2" pos="punct" morph="none" start_char="5420" end_char="5420">,</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="5422" end_char="5425">lead</TOKEN>
<TOKEN id="token-44-4" pos="word" morph="none" start_char="5427" end_char="5434">research</TOKEN>
<TOKEN id="token-44-5" pos="word" morph="none" start_char="5436" end_char="5444">scientist</TOKEN>
<TOKEN id="token-44-6" pos="word" morph="none" start_char="5446" end_char="5448">and</TOKEN>
<TOKEN id="token-44-7" pos="word" morph="none" start_char="5450" end_char="5463">microbiologist</TOKEN>
<TOKEN id="token-44-8" pos="word" morph="none" start_char="5465" end_char="5466">at</TOKEN>
<TOKEN id="token-44-9" pos="word" morph="none" start_char="5468" end_char="5472">Dyson</TOKEN>
<TOKEN id="token-44-10" pos="punct" morph="none" start_char="5473" end_char="5473">,</TOKEN>
<TOKEN id="token-44-11" pos="word" morph="none" start_char="5475" end_char="5478">also</TOKEN>
<TOKEN id="token-44-12" pos="word" morph="none" start_char="5480" end_char="5484">notes</TOKEN>
<TOKEN id="token-44-13" pos="word" morph="none" start_char="5486" end_char="5488">via</TOKEN>
<TOKEN id="token-44-14" pos="word" morph="none" start_char="5490" end_char="5494">email</TOKEN>
<TOKEN id="token-44-15" pos="word" morph="none" start_char="5496" end_char="5499">that</TOKEN>
<TOKEN id="token-44-16" pos="punct" morph="none" start_char="5501" end_char="5501">"</TOKEN>
<TOKEN id="token-44-17" pos="word" morph="none" start_char="5502" end_char="5506">Dyson</TOKEN>
<TOKEN id="token-44-18" pos="unknown" morph="none" start_char="5508" end_char="5516">Airblade™</TOKEN>
<TOKEN id="token-44-19" pos="word" morph="none" start_char="5518" end_char="5521">hand</TOKEN>
<TOKEN id="token-44-20" pos="word" morph="none" start_char="5523" end_char="5528">dryers</TOKEN>
<TOKEN id="token-44-21" pos="word" morph="none" start_char="5530" end_char="5532">are</TOKEN>
<TOKEN id="token-44-22" pos="word" morph="none" start_char="5534" end_char="5539">proven</TOKEN>
<TOKEN id="token-44-23" pos="word" morph="none" start_char="5541" end_char="5548">hygienic</TOKEN>
<TOKEN id="token-44-24" pos="punct" morph="none" start_char="5549" end_char="5550">,"</TOKEN>
<TOKEN id="token-44-25" pos="word" morph="none" start_char="5552" end_char="5554">and</TOKEN>
<TOKEN id="token-44-26" pos="word" morph="none" start_char="5556" end_char="5563">referred</TOKEN>
<TOKEN id="token-44-27" pos="word" morph="none" start_char="5565" end_char="5566">to</TOKEN>
<TOKEN id="token-44-28" pos="word" morph="none" start_char="5568" end_char="5570">its</TOKEN>
<TOKEN id="token-44-29" pos="word" morph="none" start_char="5572" end_char="5575">HEPA</TOKEN>
<TOKEN id="token-44-30" pos="word" morph="none" start_char="5577" end_char="5579">air</TOKEN>
<TOKEN id="token-44-31" pos="word" morph="none" start_char="5581" end_char="5586">filter</TOKEN>
<TOKEN id="token-44-32" pos="punct" morph="none" start_char="5587" end_char="5587">.</TOKEN>
</SEG>
<SEG id="segment-45" start_char="5590" end_char="5687">
<ORIGINAL_TEXT>Yet it’s hard to read the scientific papers without concluding that, well, paper is the way to go.</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="5590" end_char="5592">Yet</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="5594" end_char="5597">it’s</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="5599" end_char="5602">hard</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="5604" end_char="5605">to</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="5607" end_char="5610">read</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="5612" end_char="5614">the</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="5616" end_char="5625">scientific</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="5627" end_char="5632">papers</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="5634" end_char="5640">without</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="5642" end_char="5651">concluding</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="5653" end_char="5656">that</TOKEN>
<TOKEN id="token-45-11" pos="punct" morph="none" start_char="5657" end_char="5657">,</TOKEN>
<TOKEN id="token-45-12" pos="word" morph="none" start_char="5659" end_char="5662">well</TOKEN>
<TOKEN id="token-45-13" pos="punct" morph="none" start_char="5663" end_char="5663">,</TOKEN>
<TOKEN id="token-45-14" pos="word" morph="none" start_char="5665" end_char="5669">paper</TOKEN>
<TOKEN id="token-45-15" pos="word" morph="none" start_char="5671" end_char="5672">is</TOKEN>
<TOKEN id="token-45-16" pos="word" morph="none" start_char="5674" end_char="5676">the</TOKEN>
<TOKEN id="token-45-17" pos="word" morph="none" start_char="5678" end_char="5680">way</TOKEN>
<TOKEN id="token-45-18" pos="word" morph="none" start_char="5682" end_char="5683">to</TOKEN>
<TOKEN id="token-45-19" pos="word" morph="none" start_char="5685" end_char="5686">go</TOKEN>
<TOKEN id="token-45-20" pos="punct" morph="none" start_char="5687" end_char="5687">.</TOKEN>
</SEG>
<SEG id="segment-46" start_char="5689" end_char="5818">
<ORIGINAL_TEXT>If the science seems to lean in that direction, though, why have electric dryers continued to claim more and more tiled territory?</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="5689" end_char="5690">If</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="5692" end_char="5694">the</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="5696" end_char="5702">science</TOKEN>
<TOKEN id="token-46-3" pos="word" morph="none" start_char="5704" end_char="5708">seems</TOKEN>
<TOKEN id="token-46-4" pos="word" morph="none" start_char="5710" end_char="5711">to</TOKEN>
<TOKEN id="token-46-5" pos="word" morph="none" start_char="5713" end_char="5716">lean</TOKEN>
<TOKEN id="token-46-6" pos="word" morph="none" start_char="5718" end_char="5719">in</TOKEN>
<TOKEN id="token-46-7" pos="word" morph="none" start_char="5721" end_char="5724">that</TOKEN>
<TOKEN id="token-46-8" pos="word" morph="none" start_char="5726" end_char="5734">direction</TOKEN>
<TOKEN id="token-46-9" pos="punct" morph="none" start_char="5735" end_char="5735">,</TOKEN>
<TOKEN id="token-46-10" pos="word" morph="none" start_char="5737" end_char="5742">though</TOKEN>
<TOKEN id="token-46-11" pos="punct" morph="none" start_char="5743" end_char="5743">,</TOKEN>
<TOKEN id="token-46-12" pos="word" morph="none" start_char="5745" end_char="5747">why</TOKEN>
<TOKEN id="token-46-13" pos="word" morph="none" start_char="5749" end_char="5752">have</TOKEN>
<TOKEN id="token-46-14" pos="word" morph="none" start_char="5754" end_char="5761">electric</TOKEN>
<TOKEN id="token-46-15" pos="word" morph="none" start_char="5763" end_char="5768">dryers</TOKEN>
<TOKEN id="token-46-16" pos="word" morph="none" start_char="5770" end_char="5778">continued</TOKEN>
<TOKEN id="token-46-17" pos="word" morph="none" start_char="5780" end_char="5781">to</TOKEN>
<TOKEN id="token-46-18" pos="word" morph="none" start_char="5783" end_char="5787">claim</TOKEN>
<TOKEN id="token-46-19" pos="word" morph="none" start_char="5789" end_char="5792">more</TOKEN>
<TOKEN id="token-46-20" pos="word" morph="none" start_char="5794" end_char="5796">and</TOKEN>
<TOKEN id="token-46-21" pos="word" morph="none" start_char="5798" end_char="5801">more</TOKEN>
<TOKEN id="token-46-22" pos="word" morph="none" start_char="5803" end_char="5807">tiled</TOKEN>
<TOKEN id="token-46-23" pos="word" morph="none" start_char="5809" end_char="5817">territory</TOKEN>
<TOKEN id="token-46-24" pos="punct" morph="none" start_char="5818" end_char="5818">?</TOKEN>
</SEG>
<SEG id="segment-47" start_char="5820" end_char="5865">
<ORIGINAL_TEXT>For starters, they do have undeniable upsides.</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="5820" end_char="5822">For</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="5824" end_char="5831">starters</TOKEN>
<TOKEN id="token-47-2" pos="punct" morph="none" start_char="5832" end_char="5832">,</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="5834" end_char="5837">they</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="5839" end_char="5840">do</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="5842" end_char="5845">have</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="5847" end_char="5856">undeniable</TOKEN>
<TOKEN id="token-47-7" pos="word" morph="none" start_char="5858" end_char="5864">upsides</TOKEN>
<TOKEN id="token-47-8" pos="punct" morph="none" start_char="5865" end_char="5865">.</TOKEN>
</SEG>
<SEG id="segment-48" start_char="5867" end_char="5960">
<ORIGINAL_TEXT>Unlike paper towels, hand dryers don’t create waste and they’re drastically cheaper over time.</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="5867" end_char="5872">Unlike</TOKEN>
<TOKEN id="token-48-1" pos="word" morph="none" start_char="5874" end_char="5878">paper</TOKEN>
<TOKEN id="token-48-2" pos="word" morph="none" start_char="5880" end_char="5885">towels</TOKEN>
<TOKEN id="token-48-3" pos="punct" morph="none" start_char="5886" end_char="5886">,</TOKEN>
<TOKEN id="token-48-4" pos="word" morph="none" start_char="5888" end_char="5891">hand</TOKEN>
<TOKEN id="token-48-5" pos="word" morph="none" start_char="5893" end_char="5898">dryers</TOKEN>
<TOKEN id="token-48-6" pos="word" morph="none" start_char="5900" end_char="5904">don’t</TOKEN>
<TOKEN id="token-48-7" pos="word" morph="none" start_char="5906" end_char="5911">create</TOKEN>
<TOKEN id="token-48-8" pos="word" morph="none" start_char="5913" end_char="5917">waste</TOKEN>
<TOKEN id="token-48-9" pos="word" morph="none" start_char="5919" end_char="5921">and</TOKEN>
<TOKEN id="token-48-10" pos="word" morph="none" start_char="5923" end_char="5929">they’re</TOKEN>
<TOKEN id="token-48-11" pos="word" morph="none" start_char="5931" end_char="5941">drastically</TOKEN>
<TOKEN id="token-48-12" pos="word" morph="none" start_char="5943" end_char="5949">cheaper</TOKEN>
<TOKEN id="token-48-13" pos="word" morph="none" start_char="5951" end_char="5954">over</TOKEN>
<TOKEN id="token-48-14" pos="word" morph="none" start_char="5956" end_char="5959">time</TOKEN>
<TOKEN id="token-48-15" pos="punct" morph="none" start_char="5960" end_char="5960">.</TOKEN>
</SEG>
<SEG id="segment-49" start_char="5962" end_char="6156">
<ORIGINAL_TEXT>The annual cost for paper towels in a public restroom can easily top a thousand dollars, while the electricity required to run a hand dryer costs about a fifth of that, according to one estimate.</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="5962" end_char="5964">The</TOKEN>
<TOKEN id="token-49-1" pos="word" morph="none" start_char="5966" end_char="5971">annual</TOKEN>
<TOKEN id="token-49-2" pos="word" morph="none" start_char="5973" end_char="5976">cost</TOKEN>
<TOKEN id="token-49-3" pos="word" morph="none" start_char="5978" end_char="5980">for</TOKEN>
<TOKEN id="token-49-4" pos="word" morph="none" start_char="5982" end_char="5986">paper</TOKEN>
<TOKEN id="token-49-5" pos="word" morph="none" start_char="5988" end_char="5993">towels</TOKEN>
<TOKEN id="token-49-6" pos="word" morph="none" start_char="5995" end_char="5996">in</TOKEN>
<TOKEN id="token-49-7" pos="word" morph="none" start_char="5998" end_char="5998">a</TOKEN>
<TOKEN id="token-49-8" pos="word" morph="none" start_char="6000" end_char="6005">public</TOKEN>
<TOKEN id="token-49-9" pos="word" morph="none" start_char="6007" end_char="6014">restroom</TOKEN>
<TOKEN id="token-49-10" pos="word" morph="none" start_char="6016" end_char="6018">can</TOKEN>
<TOKEN id="token-49-11" pos="word" morph="none" start_char="6020" end_char="6025">easily</TOKEN>
<TOKEN id="token-49-12" pos="word" morph="none" start_char="6027" end_char="6029">top</TOKEN>
<TOKEN id="token-49-13" pos="word" morph="none" start_char="6031" end_char="6031">a</TOKEN>
<TOKEN id="token-49-14" pos="word" morph="none" start_char="6033" end_char="6040">thousand</TOKEN>
<TOKEN id="token-49-15" pos="word" morph="none" start_char="6042" end_char="6048">dollars</TOKEN>
<TOKEN id="token-49-16" pos="punct" morph="none" start_char="6049" end_char="6049">,</TOKEN>
<TOKEN id="token-49-17" pos="word" morph="none" start_char="6051" end_char="6055">while</TOKEN>
<TOKEN id="token-49-18" pos="word" morph="none" start_char="6057" end_char="6059">the</TOKEN>
<TOKEN id="token-49-19" pos="word" morph="none" start_char="6061" end_char="6071">electricity</TOKEN>
<TOKEN id="token-49-20" pos="word" morph="none" start_char="6073" end_char="6080">required</TOKEN>
<TOKEN id="token-49-21" pos="word" morph="none" start_char="6082" end_char="6083">to</TOKEN>
<TOKEN id="token-49-22" pos="word" morph="none" start_char="6085" end_char="6087">run</TOKEN>
<TOKEN id="token-49-23" pos="word" morph="none" start_char="6089" end_char="6089">a</TOKEN>
<TOKEN id="token-49-24" pos="word" morph="none" start_char="6091" end_char="6094">hand</TOKEN>
<TOKEN id="token-49-25" pos="word" morph="none" start_char="6096" end_char="6100">dryer</TOKEN>
<TOKEN id="token-49-26" pos="word" morph="none" start_char="6102" end_char="6106">costs</TOKEN>
<TOKEN id="token-49-27" pos="word" morph="none" start_char="6108" end_char="6112">about</TOKEN>
<TOKEN id="token-49-28" pos="word" morph="none" start_char="6114" end_char="6114">a</TOKEN>
<TOKEN id="token-49-29" pos="word" morph="none" start_char="6116" end_char="6120">fifth</TOKEN>
<TOKEN id="token-49-30" pos="word" morph="none" start_char="6122" end_char="6123">of</TOKEN>
<TOKEN id="token-49-31" pos="word" morph="none" start_char="6125" end_char="6128">that</TOKEN>
<TOKEN id="token-49-32" pos="punct" morph="none" start_char="6129" end_char="6129">,</TOKEN>
<TOKEN id="token-49-33" pos="word" morph="none" start_char="6131" end_char="6139">according</TOKEN>
<TOKEN id="token-49-34" pos="word" morph="none" start_char="6141" end_char="6142">to</TOKEN>
<TOKEN id="token-49-35" pos="word" morph="none" start_char="6144" end_char="6146">one</TOKEN>
<TOKEN id="token-49-36" pos="word" morph="none" start_char="6148" end_char="6155">estimate</TOKEN>
<TOKEN id="token-49-37" pos="punct" morph="none" start_char="6156" end_char="6156">.</TOKEN>
</SEG>
<SEG id="segment-50" start_char="6159" end_char="6268">
<ORIGINAL_TEXT>But focusing on paper towel prices seems a little ridiculous when epidemiologists are calculating death rates.</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="6159" end_char="6161">But</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="6163" end_char="6170">focusing</TOKEN>
<TOKEN id="token-50-2" pos="word" morph="none" start_char="6172" end_char="6173">on</TOKEN>
<TOKEN id="token-50-3" pos="word" morph="none" start_char="6175" end_char="6179">paper</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="6181" end_char="6185">towel</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="6187" end_char="6192">prices</TOKEN>
<TOKEN id="token-50-6" pos="word" morph="none" start_char="6194" end_char="6198">seems</TOKEN>
<TOKEN id="token-50-7" pos="word" morph="none" start_char="6200" end_char="6200">a</TOKEN>
<TOKEN id="token-50-8" pos="word" morph="none" start_char="6202" end_char="6207">little</TOKEN>
<TOKEN id="token-50-9" pos="word" morph="none" start_char="6209" end_char="6218">ridiculous</TOKEN>
<TOKEN id="token-50-10" pos="word" morph="none" start_char="6220" end_char="6223">when</TOKEN>
<TOKEN id="token-50-11" pos="word" morph="none" start_char="6225" end_char="6239">epidemiologists</TOKEN>
<TOKEN id="token-50-12" pos="word" morph="none" start_char="6241" end_char="6243">are</TOKEN>
<TOKEN id="token-50-13" pos="word" morph="none" start_char="6245" end_char="6255">calculating</TOKEN>
<TOKEN id="token-50-14" pos="word" morph="none" start_char="6257" end_char="6261">death</TOKEN>
<TOKEN id="token-50-15" pos="word" morph="none" start_char="6263" end_char="6267">rates</TOKEN>
<TOKEN id="token-50-16" pos="punct" morph="none" start_char="6268" end_char="6268">.</TOKEN>
</SEG>
<SEG id="segment-51" start_char="6270" end_char="6334">
<ORIGINAL_TEXT>We’re at a moment when hand-washing must be taken very seriously.</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="word" morph="none" start_char="6270" end_char="6274">We’re</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="6276" end_char="6277">at</TOKEN>
<TOKEN id="token-51-2" pos="word" morph="none" start_char="6279" end_char="6279">a</TOKEN>
<TOKEN id="token-51-3" pos="word" morph="none" start_char="6281" end_char="6286">moment</TOKEN>
<TOKEN id="token-51-4" pos="word" morph="none" start_char="6288" end_char="6291">when</TOKEN>
<TOKEN id="token-51-5" pos="unknown" morph="none" start_char="6293" end_char="6304">hand-washing</TOKEN>
<TOKEN id="token-51-6" pos="word" morph="none" start_char="6306" end_char="6309">must</TOKEN>
<TOKEN id="token-51-7" pos="word" morph="none" start_char="6311" end_char="6312">be</TOKEN>
<TOKEN id="token-51-8" pos="word" morph="none" start_char="6314" end_char="6318">taken</TOKEN>
<TOKEN id="token-51-9" pos="word" morph="none" start_char="6320" end_char="6323">very</TOKEN>
<TOKEN id="token-51-10" pos="word" morph="none" start_char="6325" end_char="6333">seriously</TOKEN>
<TOKEN id="token-51-11" pos="punct" morph="none" start_char="6334" end_char="6334">.</TOKEN>
</SEG>
<SEG id="segment-52" start_char="6336" end_char="6368">
<ORIGINAL_TEXT>The same is true for hand-drying.</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="6336" end_char="6338">The</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="6340" end_char="6343">same</TOKEN>
<TOKEN id="token-52-2" pos="word" morph="none" start_char="6345" end_char="6346">is</TOKEN>
<TOKEN id="token-52-3" pos="word" morph="none" start_char="6348" end_char="6351">true</TOKEN>
<TOKEN id="token-52-4" pos="word" morph="none" start_char="6353" end_char="6355">for</TOKEN>
<TOKEN id="token-52-5" pos="unknown" morph="none" start_char="6357" end_char="6367">hand-drying</TOKEN>
<TOKEN id="token-52-6" pos="punct" morph="none" start_char="6368" end_char="6368">.</TOKEN>
</SEG>
<SEG id="segment-53" start_char="6370" end_char="6506">
<ORIGINAL_TEXT>Electric hand dryers appear to be a modern, more responsible solution to an everyday problem—but one that may not live up to its billing.</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="word" morph="none" start_char="6370" end_char="6377">Electric</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="6379" end_char="6382">hand</TOKEN>
<TOKEN id="token-53-2" pos="word" morph="none" start_char="6384" end_char="6389">dryers</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="6391" end_char="6396">appear</TOKEN>
<TOKEN id="token-53-4" pos="word" morph="none" start_char="6398" end_char="6399">to</TOKEN>
<TOKEN id="token-53-5" pos="word" morph="none" start_char="6401" end_char="6402">be</TOKEN>
<TOKEN id="token-53-6" pos="word" morph="none" start_char="6404" end_char="6404">a</TOKEN>
<TOKEN id="token-53-7" pos="word" morph="none" start_char="6406" end_char="6411">modern</TOKEN>
<TOKEN id="token-53-8" pos="punct" morph="none" start_char="6412" end_char="6412">,</TOKEN>
<TOKEN id="token-53-9" pos="word" morph="none" start_char="6414" end_char="6417">more</TOKEN>
<TOKEN id="token-53-10" pos="word" morph="none" start_char="6419" end_char="6429">responsible</TOKEN>
<TOKEN id="token-53-11" pos="word" morph="none" start_char="6431" end_char="6438">solution</TOKEN>
<TOKEN id="token-53-12" pos="word" morph="none" start_char="6440" end_char="6441">to</TOKEN>
<TOKEN id="token-53-13" pos="word" morph="none" start_char="6443" end_char="6444">an</TOKEN>
<TOKEN id="token-53-14" pos="word" morph="none" start_char="6446" end_char="6453">everyday</TOKEN>
<TOKEN id="token-53-15" pos="unknown" morph="none" start_char="6455" end_char="6465">problem—but</TOKEN>
<TOKEN id="token-53-16" pos="word" morph="none" start_char="6467" end_char="6469">one</TOKEN>
<TOKEN id="token-53-17" pos="word" morph="none" start_char="6471" end_char="6474">that</TOKEN>
<TOKEN id="token-53-18" pos="word" morph="none" start_char="6476" end_char="6478">may</TOKEN>
<TOKEN id="token-53-19" pos="word" morph="none" start_char="6480" end_char="6482">not</TOKEN>
<TOKEN id="token-53-20" pos="word" morph="none" start_char="6484" end_char="6487">live</TOKEN>
<TOKEN id="token-53-21" pos="word" morph="none" start_char="6489" end_char="6490">up</TOKEN>
<TOKEN id="token-53-22" pos="word" morph="none" start_char="6492" end_char="6493">to</TOKEN>
<TOKEN id="token-53-23" pos="word" morph="none" start_char="6495" end_char="6497">its</TOKEN>
<TOKEN id="token-53-24" pos="word" morph="none" start_char="6499" end_char="6505">billing</TOKEN>
<TOKEN id="token-53-25" pos="punct" morph="none" start_char="6506" end_char="6506">.</TOKEN>
</SEG>
<SEG id="segment-54" start_char="6510" end_char="6551">
<ORIGINAL_TEXT>Read all of our coronavirus coverage here.</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="word" morph="none" start_char="6510" end_char="6513">Read</TOKEN>
<TOKEN id="token-54-1" pos="word" morph="none" start_char="6515" end_char="6517">all</TOKEN>
<TOKEN id="token-54-2" pos="word" morph="none" start_char="6519" end_char="6520">of</TOKEN>
<TOKEN id="token-54-3" pos="word" morph="none" start_char="6522" end_char="6524">our</TOKEN>
<TOKEN id="token-54-4" pos="word" morph="none" start_char="6526" end_char="6536">coronavirus</TOKEN>
<TOKEN id="token-54-5" pos="word" morph="none" start_char="6538" end_char="6545">coverage</TOKEN>
<TOKEN id="token-54-6" pos="word" morph="none" start_char="6547" end_char="6550">here</TOKEN>
<TOKEN id="token-54-7" pos="punct" morph="none" start_char="6551" end_char="6551">.</TOKEN>
</SEG>
<SEG id="segment-55" start_char="6554" end_char="6680">
<ORIGINAL_TEXT>Updated 3/12/2020 5:25pm EST: This story has been updated to include comment from Dyson; to clarify that the 2012 analysis from</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="word" morph="none" start_char="6554" end_char="6560">Updated</TOKEN>
<TOKEN id="token-55-1" pos="unknown" morph="none" start_char="6562" end_char="6570">3/12/2020</TOKEN>
<TOKEN id="token-55-2" pos="unknown" morph="none" start_char="6572" end_char="6577">5:25pm</TOKEN>
<TOKEN id="token-55-3" pos="word" morph="none" start_char="6579" end_char="6581">EST</TOKEN>
<TOKEN id="token-55-4" pos="punct" morph="none" start_char="6582" end_char="6582">:</TOKEN>
<TOKEN id="token-55-5" pos="word" morph="none" start_char="6584" end_char="6587">This</TOKEN>
<TOKEN id="token-55-6" pos="word" morph="none" start_char="6589" end_char="6593">story</TOKEN>
<TOKEN id="token-55-7" pos="word" morph="none" start_char="6595" end_char="6597">has</TOKEN>
<TOKEN id="token-55-8" pos="word" morph="none" start_char="6599" end_char="6602">been</TOKEN>
<TOKEN id="token-55-9" pos="word" morph="none" start_char="6604" end_char="6610">updated</TOKEN>
<TOKEN id="token-55-10" pos="word" morph="none" start_char="6612" end_char="6613">to</TOKEN>
<TOKEN id="token-55-11" pos="word" morph="none" start_char="6615" end_char="6621">include</TOKEN>
<TOKEN id="token-55-12" pos="word" morph="none" start_char="6623" end_char="6629">comment</TOKEN>
<TOKEN id="token-55-13" pos="word" morph="none" start_char="6631" end_char="6634">from</TOKEN>
<TOKEN id="token-55-14" pos="word" morph="none" start_char="6636" end_char="6640">Dyson</TOKEN>
<TOKEN id="token-55-15" pos="punct" morph="none" start_char="6641" end_char="6641">;</TOKEN>
<TOKEN id="token-55-16" pos="word" morph="none" start_char="6643" end_char="6644">to</TOKEN>
<TOKEN id="token-55-17" pos="word" morph="none" start_char="6646" end_char="6652">clarify</TOKEN>
<TOKEN id="token-55-18" pos="word" morph="none" start_char="6654" end_char="6657">that</TOKEN>
<TOKEN id="token-55-19" pos="word" morph="none" start_char="6659" end_char="6661">the</TOKEN>
<TOKEN id="token-55-20" pos="word" morph="none" start_char="6663" end_char="6666">2012</TOKEN>
<TOKEN id="token-55-21" pos="word" morph="none" start_char="6668" end_char="6675">analysis</TOKEN>
<TOKEN id="token-55-22" pos="word" morph="none" start_char="6677" end_char="6680">from</TOKEN>
</SEG>
<SEG id="segment-56" start_char="6683" end_char="6705">
<ORIGINAL_TEXT>Mayo Clinic Proceedings</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="6683" end_char="6686">Mayo</TOKEN>
<TOKEN id="token-56-1" pos="word" morph="none" start_char="6688" end_char="6693">Clinic</TOKEN>
<TOKEN id="token-56-2" pos="word" morph="none" start_char="6695" end_char="6705">Proceedings</TOKEN>
</SEG>
<SEG id="segment-57" start_char="6708" end_char="6972">
<ORIGINAL_TEXT>found that high-speed air dryers "led to much less bacterial transfer than hot air dryers," and that the 2018 study referenced tested conventional hot-air dryers; and to remove any implication that drying hands on pants may be more hygienic than using a hand dryer.</ORIGINAL_TEXT>
<TOKEN id="token-57-0" pos="word" morph="none" start_char="6708" end_char="6712">found</TOKEN>
<TOKEN id="token-57-1" pos="word" morph="none" start_char="6714" end_char="6717">that</TOKEN>
<TOKEN id="token-57-2" pos="unknown" morph="none" start_char="6719" end_char="6728">high-speed</TOKEN>
<TOKEN id="token-57-3" pos="word" morph="none" start_char="6730" end_char="6732">air</TOKEN>
<TOKEN id="token-57-4" pos="word" morph="none" start_char="6734" end_char="6739">dryers</TOKEN>
<TOKEN id="token-57-5" pos="punct" morph="none" start_char="6741" end_char="6741">"</TOKEN>
<TOKEN id="token-57-6" pos="word" morph="none" start_char="6742" end_char="6744">led</TOKEN>
<TOKEN id="token-57-7" pos="word" morph="none" start_char="6746" end_char="6747">to</TOKEN>
<TOKEN id="token-57-8" pos="word" morph="none" start_char="6749" end_char="6752">much</TOKEN>
<TOKEN id="token-57-9" pos="word" morph="none" start_char="6754" end_char="6757">less</TOKEN>
<TOKEN id="token-57-10" pos="word" morph="none" start_char="6759" end_char="6767">bacterial</TOKEN>
<TOKEN id="token-57-11" pos="word" morph="none" start_char="6769" end_char="6776">transfer</TOKEN>
<TOKEN id="token-57-12" pos="word" morph="none" start_char="6778" end_char="6781">than</TOKEN>
<TOKEN id="token-57-13" pos="word" morph="none" start_char="6783" end_char="6785">hot</TOKEN>
<TOKEN id="token-57-14" pos="word" morph="none" start_char="6787" end_char="6789">air</TOKEN>
<TOKEN id="token-57-15" pos="word" morph="none" start_char="6791" end_char="6796">dryers</TOKEN>
<TOKEN id="token-57-16" pos="punct" morph="none" start_char="6797" end_char="6798">,"</TOKEN>
<TOKEN id="token-57-17" pos="word" morph="none" start_char="6800" end_char="6802">and</TOKEN>
<TOKEN id="token-57-18" pos="word" morph="none" start_char="6804" end_char="6807">that</TOKEN>
<TOKEN id="token-57-19" pos="word" morph="none" start_char="6809" end_char="6811">the</TOKEN>
<TOKEN id="token-57-20" pos="word" morph="none" start_char="6813" end_char="6816">2018</TOKEN>
<TOKEN id="token-57-21" pos="word" morph="none" start_char="6818" end_char="6822">study</TOKEN>
<TOKEN id="token-57-22" pos="word" morph="none" start_char="6824" end_char="6833">referenced</TOKEN>
<TOKEN id="token-57-23" pos="word" morph="none" start_char="6835" end_char="6840">tested</TOKEN>
<TOKEN id="token-57-24" pos="word" morph="none" start_char="6842" end_char="6853">conventional</TOKEN>
<TOKEN id="token-57-25" pos="unknown" morph="none" start_char="6855" end_char="6861">hot-air</TOKEN>
<TOKEN id="token-57-26" pos="word" morph="none" start_char="6863" end_char="6868">dryers</TOKEN>
<TOKEN id="token-57-27" pos="punct" morph="none" start_char="6869" end_char="6869">;</TOKEN>
<TOKEN id="token-57-28" pos="word" morph="none" start_char="6871" end_char="6873">and</TOKEN>
<TOKEN id="token-57-29" pos="word" morph="none" start_char="6875" end_char="6876">to</TOKEN>
<TOKEN id="token-57-30" pos="word" morph="none" start_char="6878" end_char="6883">remove</TOKEN>
<TOKEN id="token-57-31" pos="word" morph="none" start_char="6885" end_char="6887">any</TOKEN>
<TOKEN id="token-57-32" pos="word" morph="none" start_char="6889" end_char="6899">implication</TOKEN>
<TOKEN id="token-57-33" pos="word" morph="none" start_char="6901" end_char="6904">that</TOKEN>
<TOKEN id="token-57-34" pos="word" morph="none" start_char="6906" end_char="6911">drying</TOKEN>
<TOKEN id="token-57-35" pos="word" morph="none" start_char="6913" end_char="6917">hands</TOKEN>
<TOKEN id="token-57-36" pos="word" morph="none" start_char="6919" end_char="6920">on</TOKEN>
<TOKEN id="token-57-37" pos="word" morph="none" start_char="6922" end_char="6926">pants</TOKEN>
<TOKEN id="token-57-38" pos="word" morph="none" start_char="6928" end_char="6930">may</TOKEN>
<TOKEN id="token-57-39" pos="word" morph="none" start_char="6932" end_char="6933">be</TOKEN>
<TOKEN id="token-57-40" pos="word" morph="none" start_char="6935" end_char="6938">more</TOKEN>
<TOKEN id="token-57-41" pos="word" morph="none" start_char="6940" end_char="6947">hygienic</TOKEN>
<TOKEN id="token-57-42" pos="word" morph="none" start_char="6949" end_char="6952">than</TOKEN>
<TOKEN id="token-57-43" pos="word" morph="none" start_char="6954" end_char="6958">using</TOKEN>
<TOKEN id="token-57-44" pos="word" morph="none" start_char="6960" end_char="6960">a</TOKEN>
<TOKEN id="token-57-45" pos="word" morph="none" start_char="6962" end_char="6965">hand</TOKEN>
<TOKEN id="token-57-46" pos="word" morph="none" start_char="6967" end_char="6971">dryer</TOKEN>
<TOKEN id="token-57-47" pos="punct" morph="none" start_char="6972" end_char="6972">.</TOKEN>
</SEG>
<SEG id="segment-58" start_char="6974" end_char="7030">
<ORIGINAL_TEXT>The language has been sharpened and clarified throughout.</ORIGINAL_TEXT>
<TOKEN id="token-58-0" pos="word" morph="none" start_char="6974" end_char="6976">The</TOKEN>
<TOKEN id="token-58-1" pos="word" morph="none" start_char="6978" end_char="6985">language</TOKEN>
<TOKEN id="token-58-2" pos="word" morph="none" start_char="6987" end_char="6989">has</TOKEN>
<TOKEN id="token-58-3" pos="word" morph="none" start_char="6991" end_char="6994">been</TOKEN>
<TOKEN id="token-58-4" pos="word" morph="none" start_char="6996" end_char="7004">sharpened</TOKEN>
<TOKEN id="token-58-5" pos="word" morph="none" start_char="7006" end_char="7008">and</TOKEN>
<TOKEN id="token-58-6" pos="word" morph="none" start_char="7010" end_char="7018">clarified</TOKEN>
<TOKEN id="token-58-7" pos="word" morph="none" start_char="7020" end_char="7029">throughout</TOKEN>
<TOKEN id="token-58-8" pos="punct" morph="none" start_char="7030" end_char="7030">.</TOKEN>
</SEG>
<SEG id="segment-59" start_char="7033" end_char="7402">
<ORIGINAL_TEXT>Updated 3/19/2020 5:20pm EST: Since this article was published, Dyson has provided the following statement: "Karen Holeyman, lead research scientist and microbiologist at Dyson, notes via email that ‘Dyson Airblade™ hand dryers are proven hygienic, and there is no scientific basis to suggest that our hand dryers spread pathogens or are less hygienic than paper towels.</ORIGINAL_TEXT>
<TOKEN id="token-59-0" pos="word" morph="none" start_char="7033" end_char="7039">Updated</TOKEN>
<TOKEN id="token-59-1" pos="unknown" morph="none" start_char="7041" end_char="7049">3/19/2020</TOKEN>
<TOKEN id="token-59-2" pos="unknown" morph="none" start_char="7051" end_char="7056">5:20pm</TOKEN>
<TOKEN id="token-59-3" pos="word" morph="none" start_char="7058" end_char="7060">EST</TOKEN>
<TOKEN id="token-59-4" pos="punct" morph="none" start_char="7061" end_char="7061">:</TOKEN>
<TOKEN id="token-59-5" pos="word" morph="none" start_char="7063" end_char="7067">Since</TOKEN>
<TOKEN id="token-59-6" pos="word" morph="none" start_char="7069" end_char="7072">this</TOKEN>
<TOKEN id="token-59-7" pos="word" morph="none" start_char="7074" end_char="7080">article</TOKEN>
<TOKEN id="token-59-8" pos="word" morph="none" start_char="7082" end_char="7084">was</TOKEN>
<TOKEN id="token-59-9" pos="word" morph="none" start_char="7086" end_char="7094">published</TOKEN>
<TOKEN id="token-59-10" pos="punct" morph="none" start_char="7095" end_char="7095">,</TOKEN>
<TOKEN id="token-59-11" pos="word" morph="none" start_char="7097" end_char="7101">Dyson</TOKEN>
<TOKEN id="token-59-12" pos="word" morph="none" start_char="7103" end_char="7105">has</TOKEN>
<TOKEN id="token-59-13" pos="word" morph="none" start_char="7107" end_char="7114">provided</TOKEN>
<TOKEN id="token-59-14" pos="word" morph="none" start_char="7116" end_char="7118">the</TOKEN>
<TOKEN id="token-59-15" pos="word" morph="none" start_char="7120" end_char="7128">following</TOKEN>
<TOKEN id="token-59-16" pos="word" morph="none" start_char="7130" end_char="7138">statement</TOKEN>
<TOKEN id="token-59-17" pos="punct" morph="none" start_char="7139" end_char="7139">:</TOKEN>
<TOKEN id="token-59-18" pos="punct" morph="none" start_char="7141" end_char="7141">"</TOKEN>
<TOKEN id="token-59-19" pos="word" morph="none" start_char="7142" end_char="7146">Karen</TOKEN>
<TOKEN id="token-59-20" pos="word" morph="none" start_char="7148" end_char="7155">Holeyman</TOKEN>
<TOKEN id="token-59-21" pos="punct" morph="none" start_char="7156" end_char="7156">,</TOKEN>
<TOKEN id="token-59-22" pos="word" morph="none" start_char="7158" end_char="7161">lead</TOKEN>
<TOKEN id="token-59-23" pos="word" morph="none" start_char="7163" end_char="7170">research</TOKEN>
<TOKEN id="token-59-24" pos="word" morph="none" start_char="7172" end_char="7180">scientist</TOKEN>
<TOKEN id="token-59-25" pos="word" morph="none" start_char="7182" end_char="7184">and</TOKEN>
<TOKEN id="token-59-26" pos="word" morph="none" start_char="7186" end_char="7199">microbiologist</TOKEN>
<TOKEN id="token-59-27" pos="word" morph="none" start_char="7201" end_char="7202">at</TOKEN>
<TOKEN id="token-59-28" pos="word" morph="none" start_char="7204" end_char="7208">Dyson</TOKEN>
<TOKEN id="token-59-29" pos="punct" morph="none" start_char="7209" end_char="7209">,</TOKEN>
<TOKEN id="token-59-30" pos="word" morph="none" start_char="7211" end_char="7215">notes</TOKEN>
<TOKEN id="token-59-31" pos="word" morph="none" start_char="7217" end_char="7219">via</TOKEN>
<TOKEN id="token-59-32" pos="word" morph="none" start_char="7221" end_char="7225">email</TOKEN>
<TOKEN id="token-59-33" pos="word" morph="none" start_char="7227" end_char="7230">that</TOKEN>
<TOKEN id="token-59-34" pos="punct" morph="none" start_char="7232" end_char="7232">‘</TOKEN>
<TOKEN id="token-59-35" pos="word" morph="none" start_char="7233" end_char="7237">Dyson</TOKEN>
<TOKEN id="token-59-36" pos="unknown" morph="none" start_char="7239" end_char="7247">Airblade™</TOKEN>
<TOKEN id="token-59-37" pos="word" morph="none" start_char="7249" end_char="7252">hand</TOKEN>
<TOKEN id="token-59-38" pos="word" morph="none" start_char="7254" end_char="7259">dryers</TOKEN>
<TOKEN id="token-59-39" pos="word" morph="none" start_char="7261" end_char="7263">are</TOKEN>
<TOKEN id="token-59-40" pos="word" morph="none" start_char="7265" end_char="7270">proven</TOKEN>
<TOKEN id="token-59-41" pos="word" morph="none" start_char="7272" end_char="7279">hygienic</TOKEN>
<TOKEN id="token-59-42" pos="punct" morph="none" start_char="7280" end_char="7280">,</TOKEN>
<TOKEN id="token-59-43" pos="word" morph="none" start_char="7282" end_char="7284">and</TOKEN>
<TOKEN id="token-59-44" pos="word" morph="none" start_char="7286" end_char="7290">there</TOKEN>
<TOKEN id="token-59-45" pos="word" morph="none" start_char="7292" end_char="7293">is</TOKEN>
<TOKEN id="token-59-46" pos="word" morph="none" start_char="7295" end_char="7296">no</TOKEN>
<TOKEN id="token-59-47" pos="word" morph="none" start_char="7298" end_char="7307">scientific</TOKEN>
<TOKEN id="token-59-48" pos="word" morph="none" start_char="7309" end_char="7313">basis</TOKEN>
<TOKEN id="token-59-49" pos="word" morph="none" start_char="7315" end_char="7316">to</TOKEN>
<TOKEN id="token-59-50" pos="word" morph="none" start_char="7318" end_char="7324">suggest</TOKEN>
<TOKEN id="token-59-51" pos="word" morph="none" start_char="7326" end_char="7329">that</TOKEN>
<TOKEN id="token-59-52" pos="word" morph="none" start_char="7331" end_char="7333">our</TOKEN>
<TOKEN id="token-59-53" pos="word" morph="none" start_char="7335" end_char="7338">hand</TOKEN>
<TOKEN id="token-59-54" pos="word" morph="none" start_char="7340" end_char="7345">dryers</TOKEN>
<TOKEN id="token-59-55" pos="word" morph="none" start_char="7347" end_char="7352">spread</TOKEN>
<TOKEN id="token-59-56" pos="word" morph="none" start_char="7354" end_char="7362">pathogens</TOKEN>
<TOKEN id="token-59-57" pos="word" morph="none" start_char="7364" end_char="7365">or</TOKEN>
<TOKEN id="token-59-58" pos="word" morph="none" start_char="7367" end_char="7369">are</TOKEN>
<TOKEN id="token-59-59" pos="word" morph="none" start_char="7371" end_char="7374">less</TOKEN>
<TOKEN id="token-59-60" pos="word" morph="none" start_char="7376" end_char="7383">hygienic</TOKEN>
<TOKEN id="token-59-61" pos="word" morph="none" start_char="7385" end_char="7388">than</TOKEN>
<TOKEN id="token-59-62" pos="word" morph="none" start_char="7390" end_char="7394">paper</TOKEN>
<TOKEN id="token-59-63" pos="word" morph="none" start_char="7396" end_char="7401">towels</TOKEN>
<TOKEN id="token-59-64" pos="punct" morph="none" start_char="7402" end_char="7402">.</TOKEN>
</SEG>
<SEG id="segment-60" start_char="7404" end_char="7635">
<ORIGINAL_TEXT>The 2015 study referenced was funded by the paper towel industry and tellingly did not employ methodology which represents real-world use and instead used unwashed hands covered in unrealistically high levels of virus contamination.</ORIGINAL_TEXT>
<TOKEN id="token-60-0" pos="word" morph="none" start_char="7404" end_char="7406">The</TOKEN>
<TOKEN id="token-60-1" pos="word" morph="none" start_char="7408" end_char="7411">2015</TOKEN>
<TOKEN id="token-60-2" pos="word" morph="none" start_char="7413" end_char="7417">study</TOKEN>
<TOKEN id="token-60-3" pos="word" morph="none" start_char="7419" end_char="7428">referenced</TOKEN>
<TOKEN id="token-60-4" pos="word" morph="none" start_char="7430" end_char="7432">was</TOKEN>
<TOKEN id="token-60-5" pos="word" morph="none" start_char="7434" end_char="7439">funded</TOKEN>
<TOKEN id="token-60-6" pos="word" morph="none" start_char="7441" end_char="7442">by</TOKEN>
<TOKEN id="token-60-7" pos="word" morph="none" start_char="7444" end_char="7446">the</TOKEN>
<TOKEN id="token-60-8" pos="word" morph="none" start_char="7448" end_char="7452">paper</TOKEN>
<TOKEN id="token-60-9" pos="word" morph="none" start_char="7454" end_char="7458">towel</TOKEN>
<TOKEN id="token-60-10" pos="word" morph="none" start_char="7460" end_char="7467">industry</TOKEN>
<TOKEN id="token-60-11" pos="word" morph="none" start_char="7469" end_char="7471">and</TOKEN>
<TOKEN id="token-60-12" pos="word" morph="none" start_char="7473" end_char="7481">tellingly</TOKEN>
<TOKEN id="token-60-13" pos="word" morph="none" start_char="7483" end_char="7485">did</TOKEN>
<TOKEN id="token-60-14" pos="word" morph="none" start_char="7487" end_char="7489">not</TOKEN>
<TOKEN id="token-60-15" pos="word" morph="none" start_char="7491" end_char="7496">employ</TOKEN>
<TOKEN id="token-60-16" pos="word" morph="none" start_char="7498" end_char="7508">methodology</TOKEN>
<TOKEN id="token-60-17" pos="word" morph="none" start_char="7510" end_char="7514">which</TOKEN>
<TOKEN id="token-60-18" pos="word" morph="none" start_char="7516" end_char="7525">represents</TOKEN>
<TOKEN id="token-60-19" pos="unknown" morph="none" start_char="7527" end_char="7536">real-world</TOKEN>
<TOKEN id="token-60-20" pos="word" morph="none" start_char="7538" end_char="7540">use</TOKEN>
<TOKEN id="token-60-21" pos="word" morph="none" start_char="7542" end_char="7544">and</TOKEN>
<TOKEN id="token-60-22" pos="word" morph="none" start_char="7546" end_char="7552">instead</TOKEN>
<TOKEN id="token-60-23" pos="word" morph="none" start_char="7554" end_char="7557">used</TOKEN>
<TOKEN id="token-60-24" pos="word" morph="none" start_char="7559" end_char="7566">unwashed</TOKEN>
<TOKEN id="token-60-25" pos="word" morph="none" start_char="7568" end_char="7572">hands</TOKEN>
<TOKEN id="token-60-26" pos="word" morph="none" start_char="7574" end_char="7580">covered</TOKEN>
<TOKEN id="token-60-27" pos="word" morph="none" start_char="7582" end_char="7583">in</TOKEN>
<TOKEN id="token-60-28" pos="word" morph="none" start_char="7585" end_char="7599">unrealistically</TOKEN>
<TOKEN id="token-60-29" pos="word" morph="none" start_char="7601" end_char="7604">high</TOKEN>
<TOKEN id="token-60-30" pos="word" morph="none" start_char="7606" end_char="7611">levels</TOKEN>
<TOKEN id="token-60-31" pos="word" morph="none" start_char="7613" end_char="7614">of</TOKEN>
<TOKEN id="token-60-32" pos="word" morph="none" start_char="7616" end_char="7620">virus</TOKEN>
<TOKEN id="token-60-33" pos="word" morph="none" start_char="7622" end_char="7634">contamination</TOKEN>
<TOKEN id="token-60-34" pos="punct" morph="none" start_char="7635" end_char="7635">.</TOKEN>
</SEG>
<SEG id="segment-61" start_char="7637" end_char="7773">
<ORIGINAL_TEXT>In addition, Dyson Airblade™ hand dryers are the only hand dryers that have been globally certified hygienic by NSF P335 accreditation.’"</ORIGINAL_TEXT>
<TOKEN id="token-61-0" pos="word" morph="none" start_char="7637" end_char="7638">In</TOKEN>
<TOKEN id="token-61-1" pos="word" morph="none" start_char="7640" end_char="7647">addition</TOKEN>
<TOKEN id="token-61-2" pos="punct" morph="none" start_char="7648" end_char="7648">,</TOKEN>
<TOKEN id="token-61-3" pos="word" morph="none" start_char="7650" end_char="7654">Dyson</TOKEN>
<TOKEN id="token-61-4" pos="unknown" morph="none" start_char="7656" end_char="7664">Airblade™</TOKEN>
<TOKEN id="token-61-5" pos="word" morph="none" start_char="7666" end_char="7669">hand</TOKEN>
<TOKEN id="token-61-6" pos="word" morph="none" start_char="7671" end_char="7676">dryers</TOKEN>
<TOKEN id="token-61-7" pos="word" morph="none" start_char="7678" end_char="7680">are</TOKEN>
<TOKEN id="token-61-8" pos="word" morph="none" start_char="7682" end_char="7684">the</TOKEN>
<TOKEN id="token-61-9" pos="word" morph="none" start_char="7686" end_char="7689">only</TOKEN>
<TOKEN id="token-61-10" pos="word" morph="none" start_char="7691" end_char="7694">hand</TOKEN>
<TOKEN id="token-61-11" pos="word" morph="none" start_char="7696" end_char="7701">dryers</TOKEN>
<TOKEN id="token-61-12" pos="word" morph="none" start_char="7703" end_char="7706">that</TOKEN>
<TOKEN id="token-61-13" pos="word" morph="none" start_char="7708" end_char="7711">have</TOKEN>
<TOKEN id="token-61-14" pos="word" morph="none" start_char="7713" end_char="7716">been</TOKEN>
<TOKEN id="token-61-15" pos="word" morph="none" start_char="7718" end_char="7725">globally</TOKEN>
<TOKEN id="token-61-16" pos="word" morph="none" start_char="7727" end_char="7735">certified</TOKEN>
<TOKEN id="token-61-17" pos="word" morph="none" start_char="7737" end_char="7744">hygienic</TOKEN>
<TOKEN id="token-61-18" pos="word" morph="none" start_char="7746" end_char="7747">by</TOKEN>
<TOKEN id="token-61-19" pos="word" morph="none" start_char="7749" end_char="7751">NSF</TOKEN>
<TOKEN id="token-61-20" pos="word" morph="none" start_char="7753" end_char="7756">P335</TOKEN>
<TOKEN id="token-61-21" pos="word" morph="none" start_char="7758" end_char="7770">accreditation</TOKEN>
<TOKEN id="token-61-22" pos="punct" morph="none" start_char="7771" end_char="7773">.’"</TOKEN>
</SEG>
<SEG id="segment-62" start_char="7777" end_char="7800">
<ORIGINAL_TEXT>More Great WIRED Stories</ORIGINAL_TEXT>
<TOKEN id="token-62-0" pos="word" morph="none" start_char="7777" end_char="7780">More</TOKEN>
<TOKEN id="token-62-1" pos="word" morph="none" start_char="7782" end_char="7786">Great</TOKEN>
<TOKEN id="token-62-2" pos="word" morph="none" start_char="7788" end_char="7792">WIRED</TOKEN>
<TOKEN id="token-62-3" pos="word" morph="none" start_char="7794" end_char="7800">Stories</TOKEN>
</SEG>
<SEG id="segment-63" start_char="7803" end_char="7836">
<ORIGINAL_TEXT>Silicon Valley ruined work culture</ORIGINAL_TEXT>
<TOKEN id="token-63-0" pos="word" morph="none" start_char="7803" end_char="7809">Silicon</TOKEN>
<TOKEN id="token-63-1" pos="word" morph="none" start_char="7811" end_char="7816">Valley</TOKEN>
<TOKEN id="token-63-2" pos="word" morph="none" start_char="7818" end_char="7823">ruined</TOKEN>
<TOKEN id="token-63-3" pos="word" morph="none" start_char="7825" end_char="7828">work</TOKEN>
<TOKEN id="token-63-4" pos="word" morph="none" start_char="7830" end_char="7836">culture</TOKEN>
</SEG>
<SEG id="segment-64" start_char="7839" end_char="7896">
<ORIGINAL_TEXT>Going the distance (and beyond) to catch marathon cheaters</ORIGINAL_TEXT>
<TOKEN id="token-64-0" pos="word" morph="none" start_char="7839" end_char="7843">Going</TOKEN>
<TOKEN id="token-64-1" pos="word" morph="none" start_char="7845" end_char="7847">the</TOKEN>
<TOKEN id="token-64-2" pos="word" morph="none" start_char="7849" end_char="7856">distance</TOKEN>
<TOKEN id="token-64-3" pos="punct" morph="none" start_char="7858" end_char="7858">(</TOKEN>
<TOKEN id="token-64-4" pos="word" morph="none" start_char="7859" end_char="7861">and</TOKEN>
<TOKEN id="token-64-5" pos="word" morph="none" start_char="7863" end_char="7868">beyond</TOKEN>
<TOKEN id="token-64-6" pos="punct" morph="none" start_char="7869" end_char="7869">)</TOKEN>
<TOKEN id="token-64-7" pos="word" morph="none" start_char="7871" end_char="7872">to</TOKEN>
<TOKEN id="token-64-8" pos="word" morph="none" start_char="7874" end_char="7878">catch</TOKEN>
<TOKEN id="token-64-9" pos="word" morph="none" start_char="7880" end_char="7887">marathon</TOKEN>
<TOKEN id="token-64-10" pos="word" morph="none" start_char="7889" end_char="7896">cheaters</TOKEN>
</SEG>
<SEG id="segment-65" start_char="7899" end_char="7950">
<ORIGINAL_TEXT>NASA’s epic gamble to get martian dirt back to Earth</ORIGINAL_TEXT>
<TOKEN id="token-65-0" pos="word" morph="none" start_char="7899" end_char="7904">NASA’s</TOKEN>
<TOKEN id="token-65-1" pos="word" morph="none" start_char="7906" end_char="7909">epic</TOKEN>
<TOKEN id="token-65-2" pos="word" morph="none" start_char="7911" end_char="7916">gamble</TOKEN>
<TOKEN id="token-65-3" pos="word" morph="none" start_char="7918" end_char="7919">to</TOKEN>
<TOKEN id="token-65-4" pos="word" morph="none" start_char="7921" end_char="7923">get</TOKEN>
<TOKEN id="token-65-5" pos="word" morph="none" start_char="7925" end_char="7931">martian</TOKEN>
<TOKEN id="token-65-6" pos="word" morph="none" start_char="7933" end_char="7936">dirt</TOKEN>
<TOKEN id="token-65-7" pos="word" morph="none" start_char="7938" end_char="7941">back</TOKEN>
<TOKEN id="token-65-8" pos="word" morph="none" start_char="7943" end_char="7944">to</TOKEN>
<TOKEN id="token-65-9" pos="word" morph="none" start_char="7946" end_char="7950">Earth</TOKEN>
</SEG>
<SEG id="segment-66" start_char="7953" end_char="8010">
<ORIGINAL_TEXT>Plane contrails have a surprising effect on global warming</ORIGINAL_TEXT>
<TOKEN id="token-66-0" pos="word" morph="none" start_char="7953" end_char="7957">Plane</TOKEN>
<TOKEN id="token-66-1" pos="word" morph="none" start_char="7959" end_char="7967">contrails</TOKEN>
<TOKEN id="token-66-2" pos="word" morph="none" start_char="7969" end_char="7972">have</TOKEN>
<TOKEN id="token-66-3" pos="word" morph="none" start_char="7974" end_char="7974">a</TOKEN>
<TOKEN id="token-66-4" pos="word" morph="none" start_char="7976" end_char="7985">surprising</TOKEN>
<TOKEN id="token-66-5" pos="word" morph="none" start_char="7987" end_char="7992">effect</TOKEN>
<TOKEN id="token-66-6" pos="word" morph="none" start_char="7994" end_char="7995">on</TOKEN>
<TOKEN id="token-66-7" pos="word" morph="none" start_char="7997" end_char="8002">global</TOKEN>
<TOKEN id="token-66-8" pos="word" morph="none" start_char="8004" end_char="8010">warming</TOKEN>
</SEG>
<SEG id="segment-67" start_char="8013" end_char="8057">
<ORIGINAL_TEXT>Can you spot the idioms in these photographs?</ORIGINAL_TEXT>
<TOKEN id="token-67-0" pos="word" morph="none" start_char="8013" end_char="8015">Can</TOKEN>
<TOKEN id="token-67-1" pos="word" morph="none" start_char="8017" end_char="8019">you</TOKEN>
<TOKEN id="token-67-2" pos="word" morph="none" start_char="8021" end_char="8024">spot</TOKEN>
<TOKEN id="token-67-3" pos="word" morph="none" start_char="8026" end_char="8028">the</TOKEN>
<TOKEN id="token-67-4" pos="word" morph="none" start_char="8030" end_char="8035">idioms</TOKEN>
<TOKEN id="token-67-5" pos="word" morph="none" start_char="8037" end_char="8038">in</TOKEN>
<TOKEN id="token-67-6" pos="word" morph="none" start_char="8040" end_char="8044">these</TOKEN>
<TOKEN id="token-67-7" pos="word" morph="none" start_char="8046" end_char="8056">photographs</TOKEN>
<TOKEN id="token-67-8" pos="punct" morph="none" start_char="8057" end_char="8057">?</TOKEN>
</SEG>
<SEG id="segment-68" start_char="8060" end_char="8104">
<ORIGINAL_TEXT>👁 A defeated chess champ makes peace with AI.</ORIGINAL_TEXT>
<TOKEN id="token-68-0" pos="unknown" morph="none" start_char="8060" end_char="8060">👁</TOKEN>
<TOKEN id="token-68-1" pos="word" morph="none" start_char="8062" end_char="8062">A</TOKEN>
<TOKEN id="token-68-2" pos="word" morph="none" start_char="8064" end_char="8071">defeated</TOKEN>
<TOKEN id="token-68-3" pos="word" morph="none" start_char="8073" end_char="8077">chess</TOKEN>
<TOKEN id="token-68-4" pos="word" morph="none" start_char="8079" end_char="8083">champ</TOKEN>
<TOKEN id="token-68-5" pos="word" morph="none" start_char="8085" end_char="8089">makes</TOKEN>
<TOKEN id="token-68-6" pos="word" morph="none" start_char="8091" end_char="8095">peace</TOKEN>
<TOKEN id="token-68-7" pos="word" morph="none" start_char="8097" end_char="8100">with</TOKEN>
<TOKEN id="token-68-8" pos="word" morph="none" start_char="8102" end_char="8103">AI</TOKEN>
<TOKEN id="token-68-9" pos="punct" morph="none" start_char="8104" end_char="8104">.</TOKEN>
</SEG>
<SEG id="segment-69" start_char="8106" end_char="8129">
<ORIGINAL_TEXT>Plus, the latest AI news</ORIGINAL_TEXT>
<TOKEN id="token-69-0" pos="word" morph="none" start_char="8106" end_char="8109">Plus</TOKEN>
<TOKEN id="token-69-1" pos="punct" morph="none" start_char="8110" end_char="8110">,</TOKEN>
<TOKEN id="token-69-2" pos="word" morph="none" start_char="8112" end_char="8114">the</TOKEN>
<TOKEN id="token-69-3" pos="word" morph="none" start_char="8116" end_char="8121">latest</TOKEN>
<TOKEN id="token-69-4" pos="word" morph="none" start_char="8123" end_char="8124">AI</TOKEN>
<TOKEN id="token-69-5" pos="word" morph="none" start_char="8126" end_char="8129">news</TOKEN>
</SEG>
<SEG id="segment-70" start_char="8132" end_char="8251">
<ORIGINAL_TEXT>✨ Optimize your home life with our Gear team’s best picks, from robot vacuums to affordable mattresses to smart speakers</ORIGINAL_TEXT>
<TOKEN id="token-70-0" pos="unknown" morph="none" start_char="8132" end_char="8132">✨</TOKEN>
<TOKEN id="token-70-1" pos="word" morph="none" start_char="8134" end_char="8141">Optimize</TOKEN>
<TOKEN id="token-70-2" pos="word" morph="none" start_char="8143" end_char="8146">your</TOKEN>
<TOKEN id="token-70-3" pos="word" morph="none" start_char="8148" end_char="8151">home</TOKEN>
<TOKEN id="token-70-4" pos="word" morph="none" start_char="8153" end_char="8156">life</TOKEN>
<TOKEN id="token-70-5" pos="word" morph="none" start_char="8158" end_char="8161">with</TOKEN>
<TOKEN id="token-70-6" pos="word" morph="none" start_char="8163" end_char="8165">our</TOKEN>
<TOKEN id="token-70-7" pos="word" morph="none" start_char="8167" end_char="8170">Gear</TOKEN>
<TOKEN id="token-70-8" pos="word" morph="none" start_char="8172" end_char="8177">team’s</TOKEN>
<TOKEN id="token-70-9" pos="word" morph="none" start_char="8179" end_char="8182">best</TOKEN>
<TOKEN id="token-70-10" pos="word" morph="none" start_char="8184" end_char="8188">picks</TOKEN>
<TOKEN id="token-70-11" pos="punct" morph="none" start_char="8189" end_char="8189">,</TOKEN>
<TOKEN id="token-70-12" pos="word" morph="none" start_char="8191" end_char="8194">from</TOKEN>
<TOKEN id="token-70-13" pos="word" morph="none" start_char="8196" end_char="8200">robot</TOKEN>
<TOKEN id="token-70-14" pos="word" morph="none" start_char="8202" end_char="8208">vacuums</TOKEN>
<TOKEN id="token-70-15" pos="word" morph="none" start_char="8210" end_char="8211">to</TOKEN>
<TOKEN id="token-70-16" pos="word" morph="none" start_char="8213" end_char="8222">affordable</TOKEN>
<TOKEN id="token-70-17" pos="word" morph="none" start_char="8224" end_char="8233">mattresses</TOKEN>
<TOKEN id="token-70-18" pos="word" morph="none" start_char="8235" end_char="8236">to</TOKEN>
<TOKEN id="token-70-19" pos="word" morph="none" start_char="8238" end_char="8242">smart</TOKEN>
<TOKEN id="token-70-20" pos="word" morph="none" start_char="8244" end_char="8251">speakers</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
