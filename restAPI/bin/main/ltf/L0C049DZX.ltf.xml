<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="eng">
<DOC id="L0C049DZX" lang="eng" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="10202" raw_text_md5="e54865f2cb9713f274b0648a612ab368">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="64">
<ORIGINAL_TEXT>New evidence ties COVID-19 creation to research funded by Fauci?</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="3">New</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="5" end_char="12">evidence</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="14" end_char="17">ties</TOKEN>
<TOKEN id="token-0-3" pos="unknown" morph="none" start_char="19" end_char="26">COVID-19</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="28" end_char="35">creation</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="37" end_char="38">to</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="40" end_char="47">research</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="49" end_char="54">funded</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="56" end_char="57">by</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="59" end_char="63">Fauci</TOKEN>
<TOKEN id="token-0-10" pos="punct" morph="none" start_char="64" end_char="64">?</TOKEN>
</SEG>
<SEG id="segment-1" start_char="68" end_char="70">
<ORIGINAL_TEXT>Dr.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="68" end_char="69">Dr</TOKEN>
<TOKEN id="token-1-1" pos="punct" morph="none" start_char="70" end_char="70">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="72" end_char="345">
<ORIGINAL_TEXT>Anthony Fauci, Director of National Institute of Allergy and Infectious Diseases, addresses his remarks at a roundtable on donating plasma Thursday, July 30, 2020, at the American Red Cross-National Headquarters in Washington, D.C. (Official White House photo by Tia Dufour)</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="72" end_char="78">Anthony</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="80" end_char="84">Fauci</TOKEN>
<TOKEN id="token-2-2" pos="punct" morph="none" start_char="85" end_char="85">,</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="87" end_char="94">Director</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="96" end_char="97">of</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="99" end_char="106">National</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="108" end_char="116">Institute</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="118" end_char="119">of</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="121" end_char="127">Allergy</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="129" end_char="131">and</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="133" end_char="142">Infectious</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="144" end_char="151">Diseases</TOKEN>
<TOKEN id="token-2-12" pos="punct" morph="none" start_char="152" end_char="152">,</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="154" end_char="162">addresses</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="164" end_char="166">his</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="168" end_char="174">remarks</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="176" end_char="177">at</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="179" end_char="179">a</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="181" end_char="190">roundtable</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="192" end_char="193">on</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="195" end_char="202">donating</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="204" end_char="209">plasma</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="211" end_char="218">Thursday</TOKEN>
<TOKEN id="token-2-23" pos="punct" morph="none" start_char="219" end_char="219">,</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="221" end_char="224">July</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="226" end_char="227">30</TOKEN>
<TOKEN id="token-2-26" pos="punct" morph="none" start_char="228" end_char="228">,</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="230" end_char="233">2020</TOKEN>
<TOKEN id="token-2-28" pos="punct" morph="none" start_char="234" end_char="234">,</TOKEN>
<TOKEN id="token-2-29" pos="word" morph="none" start_char="236" end_char="237">at</TOKEN>
<TOKEN id="token-2-30" pos="word" morph="none" start_char="239" end_char="241">the</TOKEN>
<TOKEN id="token-2-31" pos="word" morph="none" start_char="243" end_char="250">American</TOKEN>
<TOKEN id="token-2-32" pos="word" morph="none" start_char="252" end_char="254">Red</TOKEN>
<TOKEN id="token-2-33" pos="unknown" morph="none" start_char="256" end_char="269">Cross-National</TOKEN>
<TOKEN id="token-2-34" pos="word" morph="none" start_char="271" end_char="282">Headquarters</TOKEN>
<TOKEN id="token-2-35" pos="word" morph="none" start_char="284" end_char="285">in</TOKEN>
<TOKEN id="token-2-36" pos="word" morph="none" start_char="287" end_char="296">Washington</TOKEN>
<TOKEN id="token-2-37" pos="punct" morph="none" start_char="297" end_char="297">,</TOKEN>
<TOKEN id="token-2-38" pos="unknown" morph="none" start_char="299" end_char="301">D.C</TOKEN>
<TOKEN id="token-2-39" pos="punct" morph="none" start_char="302" end_char="302">.</TOKEN>
<TOKEN id="token-2-40" pos="punct" morph="none" start_char="304" end_char="304">(</TOKEN>
<TOKEN id="token-2-41" pos="word" morph="none" start_char="305" end_char="312">Official</TOKEN>
<TOKEN id="token-2-42" pos="word" morph="none" start_char="314" end_char="318">White</TOKEN>
<TOKEN id="token-2-43" pos="word" morph="none" start_char="320" end_char="324">House</TOKEN>
<TOKEN id="token-2-44" pos="word" morph="none" start_char="326" end_char="330">photo</TOKEN>
<TOKEN id="token-2-45" pos="word" morph="none" start_char="332" end_char="333">by</TOKEN>
<TOKEN id="token-2-46" pos="word" morph="none" start_char="335" end_char="337">Tia</TOKEN>
<TOKEN id="token-2-47" pos="word" morph="none" start_char="339" end_char="344">Dufour</TOKEN>
<TOKEN id="token-2-48" pos="punct" morph="none" start_char="345" end_char="345">)</TOKEN>
</SEG>
<SEG id="segment-3" start_char="348" end_char="359">
<ORIGINAL_TEXT>UPDATED Feb.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="348" end_char="354">UPDATED</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="356" end_char="358">Feb</TOKEN>
<TOKEN id="token-3-2" pos="punct" morph="none" start_char="359" end_char="359">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="361" end_char="509">
<ORIGINAL_TEXT>8, 2021: A fact check by USA Today from March and April 2020 indicated the coronavirus is not man-made or engineered, but its origin remains unclear.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="361" end_char="361">8</TOKEN>
<TOKEN id="token-4-1" pos="punct" morph="none" start_char="362" end_char="362">,</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="364" end_char="367">2021</TOKEN>
<TOKEN id="token-4-3" pos="punct" morph="none" start_char="368" end_char="368">:</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="370" end_char="370">A</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="372" end_char="375">fact</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="377" end_char="381">check</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="383" end_char="384">by</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="386" end_char="388">USA</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="390" end_char="394">Today</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="396" end_char="399">from</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="401" end_char="405">March</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="407" end_char="409">and</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="411" end_char="415">April</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="417" end_char="420">2020</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="422" end_char="430">indicated</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="432" end_char="434">the</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="436" end_char="446">coronavirus</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="448" end_char="449">is</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="451" end_char="453">not</TOKEN>
<TOKEN id="token-4-20" pos="unknown" morph="none" start_char="455" end_char="462">man-made</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="464" end_char="465">or</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="467" end_char="476">engineered</TOKEN>
<TOKEN id="token-4-23" pos="punct" morph="none" start_char="477" end_char="477">,</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="479" end_char="481">but</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="483" end_char="485">its</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="487" end_char="492">origin</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="494" end_char="500">remains</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="502" end_char="508">unclear</TOKEN>
<TOKEN id="token-4-29" pos="punct" morph="none" start_char="509" end_char="509">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="511" end_char="605">
<ORIGINAL_TEXT>It said, "There is no evidence to suggest that the virus was created in a Chinese laboratory. "</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="511" end_char="512">It</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="514" end_char="517">said</TOKEN>
<TOKEN id="token-5-2" pos="punct" morph="none" start_char="518" end_char="518">,</TOKEN>
<TOKEN id="token-5-3" pos="punct" morph="none" start_char="520" end_char="520">"</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="521" end_char="525">There</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="527" end_char="528">is</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="530" end_char="531">no</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="533" end_char="540">evidence</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="542" end_char="543">to</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="545" end_char="551">suggest</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="553" end_char="556">that</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="558" end_char="560">the</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="562" end_char="566">virus</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="568" end_char="570">was</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="572" end_char="578">created</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="580" end_char="581">in</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="583" end_char="583">a</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="585" end_char="591">Chinese</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="593" end_char="602">laboratory</TOKEN>
<TOKEN id="token-5-19" pos="punct" morph="none" start_char="603" end_char="603">.</TOKEN>
<TOKEN id="token-5-20" pos="punct" morph="none" start_char="605" end_char="605">"</TOKEN>
</SEG>
<SEG id="segment-6" start_char="608" end_char="702">
<ORIGINAL_TEXT>It is probable, likely, that the virus is of animal origin," WHO spokeswoman Fadela Chaib said.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="608" end_char="609">It</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="611" end_char="612">is</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="614" end_char="621">probable</TOKEN>
<TOKEN id="token-6-3" pos="punct" morph="none" start_char="622" end_char="622">,</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="624" end_char="629">likely</TOKEN>
<TOKEN id="token-6-5" pos="punct" morph="none" start_char="630" end_char="630">,</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="632" end_char="635">that</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="637" end_char="639">the</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="641" end_char="645">virus</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="647" end_char="648">is</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="650" end_char="651">of</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="653" end_char="658">animal</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="660" end_char="665">origin</TOKEN>
<TOKEN id="token-6-13" pos="punct" morph="none" start_char="666" end_char="667">,"</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="669" end_char="671">WHO</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="673" end_char="683">spokeswoman</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="685" end_char="690">Fadela</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="692" end_char="696">Chaib</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="698" end_char="701">said</TOKEN>
<TOKEN id="token-6-19" pos="punct" morph="none" start_char="702" end_char="702">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="705" end_char="804">
<ORIGINAL_TEXT>The Scripps Research Institute released a study that rejects the notion that the virus was man-made.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="705" end_char="707">The</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="709" end_char="715">Scripps</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="717" end_char="724">Research</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="726" end_char="734">Institute</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="736" end_char="743">released</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="745" end_char="745">a</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="747" end_char="751">study</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="753" end_char="756">that</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="758" end_char="764">rejects</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="766" end_char="768">the</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="770" end_char="775">notion</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="777" end_char="780">that</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="782" end_char="784">the</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="786" end_char="790">virus</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="792" end_char="794">was</TOKEN>
<TOKEN id="token-7-15" pos="unknown" morph="none" start_char="796" end_char="803">man-made</TOKEN>
<TOKEN id="token-7-16" pos="punct" morph="none" start_char="804" end_char="804">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="806" end_char="963">
<ORIGINAL_TEXT>Researchers concluded that if the virus were engineered, its genome sequence would more closely resemble earlier and more serious versions of the coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="806" end_char="816">Researchers</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="818" end_char="826">concluded</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="828" end_char="831">that</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="833" end_char="834">if</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="836" end_char="838">the</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="840" end_char="844">virus</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="846" end_char="849">were</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="851" end_char="860">engineered</TOKEN>
<TOKEN id="token-8-8" pos="punct" morph="none" start_char="861" end_char="861">,</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="863" end_char="865">its</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="867" end_char="872">genome</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="874" end_char="881">sequence</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="883" end_char="887">would</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="889" end_char="892">more</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="894" end_char="900">closely</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="902" end_char="909">resemble</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="911" end_char="917">earlier</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="919" end_char="921">and</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="923" end_char="926">more</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="928" end_char="934">serious</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="936" end_char="943">versions</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="945" end_char="946">of</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="948" end_char="950">the</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="952" end_char="962">coronavirus</TOKEN>
<TOKEN id="token-8-24" pos="punct" morph="none" start_char="963" end_char="963">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="966" end_char="993">
<ORIGINAL_TEXT>FactCheck.org stated on Feb.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="unknown" morph="none" start_char="966" end_char="978">FactCheck.org</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="980" end_char="985">stated</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="987" end_char="988">on</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="990" end_char="992">Feb</TOKEN>
<TOKEN id="token-9-4" pos="punct" morph="none" start_char="993" end_char="993">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="995" end_char="1111">
<ORIGINAL_TEXT>7, 2020, "There is no evidence that the new virus was bioengineered, and every indication it came from an animal. ...</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="995" end_char="995">7</TOKEN>
<TOKEN id="token-10-1" pos="punct" morph="none" start_char="996" end_char="996">,</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="998" end_char="1001">2020</TOKEN>
<TOKEN id="token-10-3" pos="punct" morph="none" start_char="1002" end_char="1002">,</TOKEN>
<TOKEN id="token-10-4" pos="punct" morph="none" start_char="1004" end_char="1004">"</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1005" end_char="1009">There</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1011" end_char="1012">is</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1014" end_char="1015">no</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1017" end_char="1024">evidence</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1026" end_char="1029">that</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1031" end_char="1033">the</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1035" end_char="1037">new</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1039" end_char="1043">virus</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1045" end_char="1047">was</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1049" end_char="1061">bioengineered</TOKEN>
<TOKEN id="token-10-15" pos="punct" morph="none" start_char="1062" end_char="1062">,</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1064" end_char="1066">and</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1068" end_char="1072">every</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1074" end_char="1083">indication</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1085" end_char="1086">it</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1088" end_char="1091">came</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1093" end_char="1096">from</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1098" end_char="1099">an</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1101" end_char="1106">animal</TOKEN>
<TOKEN id="token-10-24" pos="punct" morph="none" start_char="1107" end_char="1107">.</TOKEN>
<TOKEN id="token-10-25" pos="punct" morph="none" start_char="1109" end_char="1111">...</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1113" end_char="1175">
<ORIGINAL_TEXT>All lines of evidence point to the virus coming from an animal.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1113" end_char="1115">All</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1117" end_char="1121">lines</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1123" end_char="1124">of</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1126" end_char="1133">evidence</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1135" end_char="1139">point</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1141" end_char="1142">to</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1144" end_char="1146">the</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1148" end_char="1152">virus</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1154" end_char="1159">coming</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1161" end_char="1164">from</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1166" end_char="1167">an</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1169" end_char="1174">animal</TOKEN>
<TOKEN id="token-11-12" pos="punct" morph="none" start_char="1175" end_char="1175">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1177" end_char="1380">
<ORIGINAL_TEXT>That's consistent with what scientists have learned about the ecology of coronaviruses in the last 20 years," according to Timothy Sheahan, a virologist at the University of North Carolina at Chapel Hill.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1177" end_char="1182">That's</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1184" end_char="1193">consistent</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1195" end_char="1198">with</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1200" end_char="1203">what</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1205" end_char="1214">scientists</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1216" end_char="1219">have</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1221" end_char="1227">learned</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1229" end_char="1233">about</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1235" end_char="1237">the</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1239" end_char="1245">ecology</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1247" end_char="1248">of</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1250" end_char="1262">coronaviruses</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1264" end_char="1265">in</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1267" end_char="1269">the</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1271" end_char="1274">last</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1276" end_char="1277">20</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1279" end_char="1283">years</TOKEN>
<TOKEN id="token-12-17" pos="punct" morph="none" start_char="1284" end_char="1285">,"</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1287" end_char="1295">according</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1297" end_char="1298">to</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1300" end_char="1306">Timothy</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1308" end_char="1314">Sheahan</TOKEN>
<TOKEN id="token-12-22" pos="punct" morph="none" start_char="1315" end_char="1315">,</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="1317" end_char="1317">a</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="1319" end_char="1328">virologist</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="1330" end_char="1331">at</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="1333" end_char="1335">the</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="1337" end_char="1346">University</TOKEN>
<TOKEN id="token-12-28" pos="word" morph="none" start_char="1348" end_char="1349">of</TOKEN>
<TOKEN id="token-12-29" pos="word" morph="none" start_char="1351" end_char="1355">North</TOKEN>
<TOKEN id="token-12-30" pos="word" morph="none" start_char="1357" end_char="1364">Carolina</TOKEN>
<TOKEN id="token-12-31" pos="word" morph="none" start_char="1366" end_char="1367">at</TOKEN>
<TOKEN id="token-12-32" pos="word" morph="none" start_char="1369" end_char="1374">Chapel</TOKEN>
<TOKEN id="token-12-33" pos="word" morph="none" start_char="1376" end_char="1379">Hill</TOKEN>
<TOKEN id="token-12-34" pos="punct" morph="none" start_char="1380" end_char="1380">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1382" end_char="1460">
<ORIGINAL_TEXT>It fits with the fact that the virus shares 96% of its genome with a bat virus.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1382" end_char="1383">It</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1385" end_char="1388">fits</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1390" end_char="1393">with</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1395" end_char="1397">the</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1399" end_char="1402">fact</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1404" end_char="1407">that</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1409" end_char="1411">the</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1413" end_char="1417">virus</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1419" end_char="1424">shares</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1426" end_char="1427">96</TOKEN>
<TOKEN id="token-13-10" pos="punct" morph="none" start_char="1428" end_char="1428">%</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1430" end_char="1431">of</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1433" end_char="1435">its</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1437" end_char="1442">genome</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1444" end_char="1447">with</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1449" end_char="1449">a</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1451" end_char="1453">bat</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1455" end_char="1459">virus</TOKEN>
<TOKEN id="token-13-18" pos="punct" morph="none" start_char="1460" end_char="1460">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1463" end_char="1557">
<ORIGINAL_TEXT>"The genetic data is pointing to this virus coming from a bat reservoir," he said, "not a lab."</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="punct" morph="none" start_char="1463" end_char="1463">"</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1464" end_char="1466">The</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1468" end_char="1474">genetic</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1476" end_char="1479">data</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1481" end_char="1482">is</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1484" end_char="1491">pointing</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1493" end_char="1494">to</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1496" end_char="1499">this</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1501" end_char="1505">virus</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1507" end_char="1512">coming</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1514" end_char="1517">from</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1519" end_char="1519">a</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1521" end_char="1523">bat</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1525" end_char="1533">reservoir</TOKEN>
<TOKEN id="token-14-14" pos="punct" morph="none" start_char="1534" end_char="1535">,"</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1537" end_char="1538">he</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1540" end_char="1543">said</TOKEN>
<TOKEN id="token-14-17" pos="punct" morph="none" start_char="1544" end_char="1544">,</TOKEN>
<TOKEN id="token-14-18" pos="punct" morph="none" start_char="1546" end_char="1546">"</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="1547" end_char="1549">not</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="1551" end_char="1551">a</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="1553" end_char="1555">lab</TOKEN>
<TOKEN id="token-14-22" pos="punct" morph="none" start_char="1556" end_char="1557">."</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1561" end_char="1575">
<ORIGINAL_TEXT>ORIGINAL STORY:</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1561" end_char="1568">ORIGINAL</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1570" end_char="1574">STORY</TOKEN>
<TOKEN id="token-15-2" pos="punct" morph="none" start_char="1575" end_char="1575">:</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1578" end_char="1866">
<ORIGINAL_TEXT>China, the World Health Organization and the U.S. National Institutes of Health have dimissed the theory that the virus causing the global pandemic that has killed more than 2 million people and devastated economies worldwide escaped from the Wuhan, China, lab funded by the United States.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1578" end_char="1582">China</TOKEN>
<TOKEN id="token-16-1" pos="punct" morph="none" start_char="1583" end_char="1583">,</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1585" end_char="1587">the</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1589" end_char="1593">World</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1595" end_char="1600">Health</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1602" end_char="1613">Organization</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1615" end_char="1617">and</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1619" end_char="1621">the</TOKEN>
<TOKEN id="token-16-8" pos="unknown" morph="none" start_char="1623" end_char="1625">U.S</TOKEN>
<TOKEN id="token-16-9" pos="punct" morph="none" start_char="1626" end_char="1626">.</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="1628" end_char="1635">National</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="1637" end_char="1646">Institutes</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="1648" end_char="1649">of</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="1651" end_char="1656">Health</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="1658" end_char="1661">have</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="1663" end_char="1670">dimissed</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="1672" end_char="1674">the</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="1676" end_char="1681">theory</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="1683" end_char="1686">that</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="1688" end_char="1690">the</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="1692" end_char="1696">virus</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="1698" end_char="1704">causing</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="1706" end_char="1708">the</TOKEN>
<TOKEN id="token-16-23" pos="word" morph="none" start_char="1710" end_char="1715">global</TOKEN>
<TOKEN id="token-16-24" pos="word" morph="none" start_char="1717" end_char="1724">pandemic</TOKEN>
<TOKEN id="token-16-25" pos="word" morph="none" start_char="1726" end_char="1729">that</TOKEN>
<TOKEN id="token-16-26" pos="word" morph="none" start_char="1731" end_char="1733">has</TOKEN>
<TOKEN id="token-16-27" pos="word" morph="none" start_char="1735" end_char="1740">killed</TOKEN>
<TOKEN id="token-16-28" pos="word" morph="none" start_char="1742" end_char="1745">more</TOKEN>
<TOKEN id="token-16-29" pos="word" morph="none" start_char="1747" end_char="1750">than</TOKEN>
<TOKEN id="token-16-30" pos="word" morph="none" start_char="1752" end_char="1752">2</TOKEN>
<TOKEN id="token-16-31" pos="word" morph="none" start_char="1754" end_char="1760">million</TOKEN>
<TOKEN id="token-16-32" pos="word" morph="none" start_char="1762" end_char="1767">people</TOKEN>
<TOKEN id="token-16-33" pos="word" morph="none" start_char="1769" end_char="1771">and</TOKEN>
<TOKEN id="token-16-34" pos="word" morph="none" start_char="1773" end_char="1782">devastated</TOKEN>
<TOKEN id="token-16-35" pos="word" morph="none" start_char="1784" end_char="1792">economies</TOKEN>
<TOKEN id="token-16-36" pos="word" morph="none" start_char="1794" end_char="1802">worldwide</TOKEN>
<TOKEN id="token-16-37" pos="word" morph="none" start_char="1804" end_char="1810">escaped</TOKEN>
<TOKEN id="token-16-38" pos="word" morph="none" start_char="1812" end_char="1815">from</TOKEN>
<TOKEN id="token-16-39" pos="word" morph="none" start_char="1817" end_char="1819">the</TOKEN>
<TOKEN id="token-16-40" pos="word" morph="none" start_char="1821" end_char="1825">Wuhan</TOKEN>
<TOKEN id="token-16-41" pos="punct" morph="none" start_char="1826" end_char="1826">,</TOKEN>
<TOKEN id="token-16-42" pos="word" morph="none" start_char="1828" end_char="1832">China</TOKEN>
<TOKEN id="token-16-43" pos="punct" morph="none" start_char="1833" end_char="1833">,</TOKEN>
<TOKEN id="token-16-44" pos="word" morph="none" start_char="1835" end_char="1837">lab</TOKEN>
<TOKEN id="token-16-45" pos="word" morph="none" start_char="1839" end_char="1844">funded</TOKEN>
<TOKEN id="token-16-46" pos="word" morph="none" start_char="1846" end_char="1847">by</TOKEN>
<TOKEN id="token-16-47" pos="word" morph="none" start_char="1849" end_char="1851">the</TOKEN>
<TOKEN id="token-16-48" pos="word" morph="none" start_char="1853" end_char="1858">United</TOKEN>
<TOKEN id="token-16-49" pos="word" morph="none" start_char="1860" end_char="1865">States</TOKEN>
<TOKEN id="token-16-50" pos="punct" morph="none" start_char="1866" end_char="1866">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1869" end_char="1961">
<ORIGINAL_TEXT>But there's no disputing the fact, as Newsweek reported in April 2020, that NIH executive Dr.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1869" end_char="1871">But</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1873" end_char="1879">there's</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="1881" end_char="1882">no</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="1884" end_char="1892">disputing</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="1894" end_char="1896">the</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="1898" end_char="1901">fact</TOKEN>
<TOKEN id="token-17-6" pos="punct" morph="none" start_char="1902" end_char="1902">,</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="1904" end_char="1905">as</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="1907" end_char="1914">Newsweek</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="1916" end_char="1923">reported</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="1925" end_char="1926">in</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="1928" end_char="1932">April</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="1934" end_char="1937">2020</TOKEN>
<TOKEN id="token-17-13" pos="punct" morph="none" start_char="1938" end_char="1938">,</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="1940" end_char="1943">that</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="1945" end_char="1947">NIH</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="1949" end_char="1957">executive</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="1959" end_char="1960">Dr</TOKEN>
<TOKEN id="token-17-18" pos="punct" morph="none" start_char="1961" end_char="1961">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1963" end_char="2111">
<ORIGINAL_TEXT>Anthony Fauci promoted a highly controversial type of research involving the manipulation of viruses to explore their potential for infecting humans.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="1963" end_char="1969">Anthony</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="1971" end_char="1975">Fauci</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="1977" end_char="1984">promoted</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="1986" end_char="1986">a</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="1988" end_char="1993">highly</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="1995" end_char="2007">controversial</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2009" end_char="2012">type</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2014" end_char="2015">of</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2017" end_char="2024">research</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="2026" end_char="2034">involving</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="2036" end_char="2038">the</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="2040" end_char="2051">manipulation</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2053" end_char="2054">of</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="2056" end_char="2062">viruses</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="2064" end_char="2065">to</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="2067" end_char="2073">explore</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="2075" end_char="2079">their</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="2081" end_char="2089">potential</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="2091" end_char="2093">for</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="2095" end_char="2103">infecting</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="2105" end_char="2110">humans</TOKEN>
<TOKEN id="token-18-21" pos="punct" morph="none" start_char="2111" end_char="2111">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2113" end_char="2346">
<ORIGINAL_TEXT>And it's known that more than 200 scientists pressured the Obama administration in 2014 to temporarily halt U.S. funding for that research because of the risk of a manipulated virus accidentally escaping a lab and igniting a pandemic.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2113" end_char="2115">And</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2117" end_char="2120">it's</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2122" end_char="2126">known</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2128" end_char="2131">that</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2133" end_char="2136">more</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2138" end_char="2141">than</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2143" end_char="2145">200</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2147" end_char="2156">scientists</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2158" end_char="2166">pressured</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="2168" end_char="2170">the</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="2172" end_char="2176">Obama</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="2178" end_char="2191">administration</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="2193" end_char="2194">in</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="2196" end_char="2199">2014</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="2201" end_char="2202">to</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="2204" end_char="2214">temporarily</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="2216" end_char="2219">halt</TOKEN>
<TOKEN id="token-19-17" pos="unknown" morph="none" start_char="2221" end_char="2223">U.S</TOKEN>
<TOKEN id="token-19-18" pos="punct" morph="none" start_char="2224" end_char="2224">.</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="2226" end_char="2232">funding</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="2234" end_char="2236">for</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="2238" end_char="2241">that</TOKEN>
<TOKEN id="token-19-22" pos="word" morph="none" start_char="2243" end_char="2250">research</TOKEN>
<TOKEN id="token-19-23" pos="word" morph="none" start_char="2252" end_char="2258">because</TOKEN>
<TOKEN id="token-19-24" pos="word" morph="none" start_char="2260" end_char="2261">of</TOKEN>
<TOKEN id="token-19-25" pos="word" morph="none" start_char="2263" end_char="2265">the</TOKEN>
<TOKEN id="token-19-26" pos="word" morph="none" start_char="2267" end_char="2270">risk</TOKEN>
<TOKEN id="token-19-27" pos="word" morph="none" start_char="2272" end_char="2273">of</TOKEN>
<TOKEN id="token-19-28" pos="word" morph="none" start_char="2275" end_char="2275">a</TOKEN>
<TOKEN id="token-19-29" pos="word" morph="none" start_char="2277" end_char="2287">manipulated</TOKEN>
<TOKEN id="token-19-30" pos="word" morph="none" start_char="2289" end_char="2293">virus</TOKEN>
<TOKEN id="token-19-31" pos="word" morph="none" start_char="2295" end_char="2306">accidentally</TOKEN>
<TOKEN id="token-19-32" pos="word" morph="none" start_char="2308" end_char="2315">escaping</TOKEN>
<TOKEN id="token-19-33" pos="word" morph="none" start_char="2317" end_char="2317">a</TOKEN>
<TOKEN id="token-19-34" pos="word" morph="none" start_char="2319" end_char="2321">lab</TOKEN>
<TOKEN id="token-19-35" pos="word" morph="none" start_char="2323" end_char="2325">and</TOKEN>
<TOKEN id="token-19-36" pos="word" morph="none" start_char="2327" end_char="2334">igniting</TOKEN>
<TOKEN id="token-19-37" pos="word" morph="none" start_char="2336" end_char="2336">a</TOKEN>
<TOKEN id="token-19-38" pos="word" morph="none" start_char="2338" end_char="2345">pandemic</TOKEN>
<TOKEN id="token-19-39" pos="punct" morph="none" start_char="2346" end_char="2346">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2348" end_char="2465">
<ORIGINAL_TEXT>Nevertheless, under Fauci's direction, the dangerous virus engineering resumed in 2017 and continued until April 2020.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2348" end_char="2359">Nevertheless</TOKEN>
<TOKEN id="token-20-1" pos="punct" morph="none" start_char="2360" end_char="2360">,</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2362" end_char="2366">under</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2368" end_char="2374">Fauci's</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2376" end_char="2384">direction</TOKEN>
<TOKEN id="token-20-5" pos="punct" morph="none" start_char="2385" end_char="2385">,</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2387" end_char="2389">the</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2391" end_char="2399">dangerous</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="2401" end_char="2405">virus</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2407" end_char="2417">engineering</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2419" end_char="2425">resumed</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="2427" end_char="2428">in</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="2430" end_char="2433">2017</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="2435" end_char="2437">and</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="2439" end_char="2447">continued</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="2449" end_char="2453">until</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="2455" end_char="2459">April</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="2461" end_char="2464">2020</TOKEN>
<TOKEN id="token-20-18" pos="punct" morph="none" start_char="2465" end_char="2465">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2468" end_char="2838">
<ORIGINAL_TEXT>Now, documentary evidence makes it a "near certainty" that the coronavirus pandemic originated in the Wuhan Institute of Virology in China, where so-called "gain-of-function" research was funded by Fauci's National Institute of Allergy and Infectious Diseases, according to Steve Hilton, who is leading a special investigation for his Fox News show "The Next Revolution."</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2468" end_char="2470">Now</TOKEN>
<TOKEN id="token-21-1" pos="punct" morph="none" start_char="2471" end_char="2471">,</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2473" end_char="2483">documentary</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2485" end_char="2492">evidence</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2494" end_char="2498">makes</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="2500" end_char="2501">it</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2503" end_char="2503">a</TOKEN>
<TOKEN id="token-21-7" pos="punct" morph="none" start_char="2505" end_char="2505">"</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="2506" end_char="2509">near</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="2511" end_char="2519">certainty</TOKEN>
<TOKEN id="token-21-10" pos="punct" morph="none" start_char="2520" end_char="2520">"</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="2522" end_char="2525">that</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="2527" end_char="2529">the</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="2531" end_char="2541">coronavirus</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="2543" end_char="2550">pandemic</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="2552" end_char="2561">originated</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="2563" end_char="2564">in</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="2566" end_char="2568">the</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="2570" end_char="2574">Wuhan</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="2576" end_char="2584">Institute</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="2586" end_char="2587">of</TOKEN>
<TOKEN id="token-21-21" pos="word" morph="none" start_char="2589" end_char="2596">Virology</TOKEN>
<TOKEN id="token-21-22" pos="word" morph="none" start_char="2598" end_char="2599">in</TOKEN>
<TOKEN id="token-21-23" pos="word" morph="none" start_char="2601" end_char="2605">China</TOKEN>
<TOKEN id="token-21-24" pos="punct" morph="none" start_char="2606" end_char="2606">,</TOKEN>
<TOKEN id="token-21-25" pos="word" morph="none" start_char="2608" end_char="2612">where</TOKEN>
<TOKEN id="token-21-26" pos="unknown" morph="none" start_char="2614" end_char="2622">so-called</TOKEN>
<TOKEN id="token-21-27" pos="punct" morph="none" start_char="2624" end_char="2624">"</TOKEN>
<TOKEN id="token-21-28" pos="unknown" morph="none" start_char="2625" end_char="2640">gain-of-function</TOKEN>
<TOKEN id="token-21-29" pos="punct" morph="none" start_char="2641" end_char="2641">"</TOKEN>
<TOKEN id="token-21-30" pos="word" morph="none" start_char="2643" end_char="2650">research</TOKEN>
<TOKEN id="token-21-31" pos="word" morph="none" start_char="2652" end_char="2654">was</TOKEN>
<TOKEN id="token-21-32" pos="word" morph="none" start_char="2656" end_char="2661">funded</TOKEN>
<TOKEN id="token-21-33" pos="word" morph="none" start_char="2663" end_char="2664">by</TOKEN>
<TOKEN id="token-21-34" pos="word" morph="none" start_char="2666" end_char="2672">Fauci's</TOKEN>
<TOKEN id="token-21-35" pos="word" morph="none" start_char="2674" end_char="2681">National</TOKEN>
<TOKEN id="token-21-36" pos="word" morph="none" start_char="2683" end_char="2691">Institute</TOKEN>
<TOKEN id="token-21-37" pos="word" morph="none" start_char="2693" end_char="2694">of</TOKEN>
<TOKEN id="token-21-38" pos="word" morph="none" start_char="2696" end_char="2702">Allergy</TOKEN>
<TOKEN id="token-21-39" pos="word" morph="none" start_char="2704" end_char="2706">and</TOKEN>
<TOKEN id="token-21-40" pos="word" morph="none" start_char="2708" end_char="2717">Infectious</TOKEN>
<TOKEN id="token-21-41" pos="word" morph="none" start_char="2719" end_char="2726">Diseases</TOKEN>
<TOKEN id="token-21-42" pos="punct" morph="none" start_char="2727" end_char="2727">,</TOKEN>
<TOKEN id="token-21-43" pos="word" morph="none" start_char="2729" end_char="2737">according</TOKEN>
<TOKEN id="token-21-44" pos="word" morph="none" start_char="2739" end_char="2740">to</TOKEN>
<TOKEN id="token-21-45" pos="word" morph="none" start_char="2742" end_char="2746">Steve</TOKEN>
<TOKEN id="token-21-46" pos="word" morph="none" start_char="2748" end_char="2753">Hilton</TOKEN>
<TOKEN id="token-21-47" pos="punct" morph="none" start_char="2754" end_char="2754">,</TOKEN>
<TOKEN id="token-21-48" pos="word" morph="none" start_char="2756" end_char="2758">who</TOKEN>
<TOKEN id="token-21-49" pos="word" morph="none" start_char="2760" end_char="2761">is</TOKEN>
<TOKEN id="token-21-50" pos="word" morph="none" start_char="2763" end_char="2769">leading</TOKEN>
<TOKEN id="token-21-51" pos="word" morph="none" start_char="2771" end_char="2771">a</TOKEN>
<TOKEN id="token-21-52" pos="word" morph="none" start_char="2773" end_char="2779">special</TOKEN>
<TOKEN id="token-21-53" pos="word" morph="none" start_char="2781" end_char="2793">investigation</TOKEN>
<TOKEN id="token-21-54" pos="word" morph="none" start_char="2795" end_char="2797">for</TOKEN>
<TOKEN id="token-21-55" pos="word" morph="none" start_char="2799" end_char="2801">his</TOKEN>
<TOKEN id="token-21-56" pos="word" morph="none" start_char="2803" end_char="2805">Fox</TOKEN>
<TOKEN id="token-21-57" pos="word" morph="none" start_char="2807" end_char="2810">News</TOKEN>
<TOKEN id="token-21-58" pos="word" morph="none" start_char="2812" end_char="2815">show</TOKEN>
<TOKEN id="token-21-59" pos="punct" morph="none" start_char="2817" end_char="2817">"</TOKEN>
<TOKEN id="token-21-60" pos="word" morph="none" start_char="2818" end_char="2820">The</TOKEN>
<TOKEN id="token-21-61" pos="word" morph="none" start_char="2822" end_char="2825">Next</TOKEN>
<TOKEN id="token-21-62" pos="word" morph="none" start_char="2827" end_char="2836">Revolution</TOKEN>
<TOKEN id="token-21-63" pos="punct" morph="none" start_char="2837" end_char="2838">."</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2841" end_char="3040">
<ORIGINAL_TEXT>Significantly, his investigation found a direct link between a bat coronavirus discovered a decade ago in a mine in Yunnan province and one that had been engineered in the Wuhan lab, 1,000 miles away.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2841" end_char="2853">Significantly</TOKEN>
<TOKEN id="token-22-1" pos="punct" morph="none" start_char="2854" end_char="2854">,</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2856" end_char="2858">his</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2860" end_char="2872">investigation</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2874" end_char="2878">found</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2880" end_char="2880">a</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2882" end_char="2887">direct</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2889" end_char="2892">link</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="2894" end_char="2900">between</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="2902" end_char="2902">a</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="2904" end_char="2906">bat</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="2908" end_char="2918">coronavirus</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="2920" end_char="2929">discovered</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="2931" end_char="2931">a</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="2933" end_char="2938">decade</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="2940" end_char="2942">ago</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="2944" end_char="2945">in</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="2947" end_char="2947">a</TOKEN>
<TOKEN id="token-22-18" pos="word" morph="none" start_char="2949" end_char="2952">mine</TOKEN>
<TOKEN id="token-22-19" pos="word" morph="none" start_char="2954" end_char="2955">in</TOKEN>
<TOKEN id="token-22-20" pos="word" morph="none" start_char="2957" end_char="2962">Yunnan</TOKEN>
<TOKEN id="token-22-21" pos="word" morph="none" start_char="2964" end_char="2971">province</TOKEN>
<TOKEN id="token-22-22" pos="word" morph="none" start_char="2973" end_char="2975">and</TOKEN>
<TOKEN id="token-22-23" pos="word" morph="none" start_char="2977" end_char="2979">one</TOKEN>
<TOKEN id="token-22-24" pos="word" morph="none" start_char="2981" end_char="2984">that</TOKEN>
<TOKEN id="token-22-25" pos="word" morph="none" start_char="2986" end_char="2988">had</TOKEN>
<TOKEN id="token-22-26" pos="word" morph="none" start_char="2990" end_char="2993">been</TOKEN>
<TOKEN id="token-22-27" pos="word" morph="none" start_char="2995" end_char="3004">engineered</TOKEN>
<TOKEN id="token-22-28" pos="word" morph="none" start_char="3006" end_char="3007">in</TOKEN>
<TOKEN id="token-22-29" pos="word" morph="none" start_char="3009" end_char="3011">the</TOKEN>
<TOKEN id="token-22-30" pos="word" morph="none" start_char="3013" end_char="3017">Wuhan</TOKEN>
<TOKEN id="token-22-31" pos="word" morph="none" start_char="3019" end_char="3021">lab</TOKEN>
<TOKEN id="token-22-32" pos="punct" morph="none" start_char="3022" end_char="3022">,</TOKEN>
<TOKEN id="token-22-33" pos="unknown" morph="none" start_char="3024" end_char="3028">1,000</TOKEN>
<TOKEN id="token-22-34" pos="word" morph="none" start_char="3030" end_char="3034">miles</TOKEN>
<TOKEN id="token-22-35" pos="word" morph="none" start_char="3036" end_char="3039">away</TOKEN>
<TOKEN id="token-22-36" pos="punct" morph="none" start_char="3040" end_char="3040">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="3043" end_char="3261">
<ORIGINAL_TEXT>Hilton noted on his show Sunday night that scientists at the Wuhan lab published a paper in February 2020 stating they had recently discovered a virus in Yunnan province that "showed high sequence identity" to COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="3043" end_char="3048">Hilton</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="3050" end_char="3054">noted</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="3056" end_char="3057">on</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="3059" end_char="3061">his</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="3063" end_char="3066">show</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="3068" end_char="3073">Sunday</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="3075" end_char="3079">night</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="3081" end_char="3084">that</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="3086" end_char="3095">scientists</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="3097" end_char="3098">at</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="3100" end_char="3102">the</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="3104" end_char="3108">Wuhan</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="3110" end_char="3112">lab</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="3114" end_char="3122">published</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="3124" end_char="3124">a</TOKEN>
<TOKEN id="token-23-15" pos="word" morph="none" start_char="3126" end_char="3130">paper</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="3132" end_char="3133">in</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="3135" end_char="3142">February</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="3144" end_char="3147">2020</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="3149" end_char="3155">stating</TOKEN>
<TOKEN id="token-23-20" pos="word" morph="none" start_char="3157" end_char="3160">they</TOKEN>
<TOKEN id="token-23-21" pos="word" morph="none" start_char="3162" end_char="3164">had</TOKEN>
<TOKEN id="token-23-22" pos="word" morph="none" start_char="3166" end_char="3173">recently</TOKEN>
<TOKEN id="token-23-23" pos="word" morph="none" start_char="3175" end_char="3184">discovered</TOKEN>
<TOKEN id="token-23-24" pos="word" morph="none" start_char="3186" end_char="3186">a</TOKEN>
<TOKEN id="token-23-25" pos="word" morph="none" start_char="3188" end_char="3192">virus</TOKEN>
<TOKEN id="token-23-26" pos="word" morph="none" start_char="3194" end_char="3195">in</TOKEN>
<TOKEN id="token-23-27" pos="word" morph="none" start_char="3197" end_char="3202">Yunnan</TOKEN>
<TOKEN id="token-23-28" pos="word" morph="none" start_char="3204" end_char="3211">province</TOKEN>
<TOKEN id="token-23-29" pos="word" morph="none" start_char="3213" end_char="3216">that</TOKEN>
<TOKEN id="token-23-30" pos="punct" morph="none" start_char="3218" end_char="3218">"</TOKEN>
<TOKEN id="token-23-31" pos="word" morph="none" start_char="3219" end_char="3224">showed</TOKEN>
<TOKEN id="token-23-32" pos="word" morph="none" start_char="3226" end_char="3229">high</TOKEN>
<TOKEN id="token-23-33" pos="word" morph="none" start_char="3231" end_char="3238">sequence</TOKEN>
<TOKEN id="token-23-34" pos="word" morph="none" start_char="3240" end_char="3247">identity</TOKEN>
<TOKEN id="token-23-35" pos="punct" morph="none" start_char="3248" end_char="3248">"</TOKEN>
<TOKEN id="token-23-36" pos="word" morph="none" start_char="3250" end_char="3251">to</TOKEN>
<TOKEN id="token-23-37" pos="unknown" morph="none" start_char="3253" end_char="3260">COVID-19</TOKEN>
<TOKEN id="token-23-38" pos="punct" morph="none" start_char="3261" end_char="3261">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="3264" end_char="3418">
<ORIGINAL_TEXT>However, Hilton discovered after running the virus's genome sequence through the NIH's GenBank database that only one virus was an exact match to COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="3264" end_char="3270">However</TOKEN>
<TOKEN id="token-24-1" pos="punct" morph="none" start_char="3271" end_char="3271">,</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="3273" end_char="3278">Hilton</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="3280" end_char="3289">discovered</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="3291" end_char="3295">after</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="3297" end_char="3303">running</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="3305" end_char="3307">the</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="3309" end_char="3315">virus's</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="3317" end_char="3322">genome</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="3324" end_char="3331">sequence</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="3333" end_char="3339">through</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="3341" end_char="3343">the</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="3345" end_char="3349">NIH's</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="3351" end_char="3357">GenBank</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="3359" end_char="3366">database</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="3368" end_char="3371">that</TOKEN>
<TOKEN id="token-24-16" pos="word" morph="none" start_char="3373" end_char="3376">only</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="3378" end_char="3380">one</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="3382" end_char="3386">virus</TOKEN>
<TOKEN id="token-24-19" pos="word" morph="none" start_char="3388" end_char="3390">was</TOKEN>
<TOKEN id="token-24-20" pos="word" morph="none" start_char="3392" end_char="3393">an</TOKEN>
<TOKEN id="token-24-21" pos="word" morph="none" start_char="3395" end_char="3399">exact</TOKEN>
<TOKEN id="token-24-22" pos="word" morph="none" start_char="3401" end_char="3405">match</TOKEN>
<TOKEN id="token-24-23" pos="word" morph="none" start_char="3407" end_char="3408">to</TOKEN>
<TOKEN id="token-24-24" pos="unknown" morph="none" start_char="3410" end_char="3417">COVID-19</TOKEN>
<TOKEN id="token-24-25" pos="punct" morph="none" start_char="3418" end_char="3418">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="3420" end_char="3459">
<ORIGINAL_TEXT>It wasn't the virus discovered recently.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="3420" end_char="3421">It</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="3423" end_char="3428">wasn't</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="3430" end_char="3432">the</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="3434" end_char="3438">virus</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="3440" end_char="3449">discovered</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="3451" end_char="3458">recently</TOKEN>
<TOKEN id="token-25-6" pos="punct" morph="none" start_char="3459" end_char="3459">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="3461" end_char="3567">
<ORIGINAL_TEXT>It was the once discovered a decade ago in Yunnan province that killed miners who had stirred up bat feces.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="3461" end_char="3462">It</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="3464" end_char="3466">was</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="3468" end_char="3470">the</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="3472" end_char="3475">once</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="3477" end_char="3486">discovered</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="3488" end_char="3488">a</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="3490" end_char="3495">decade</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="3497" end_char="3499">ago</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="3501" end_char="3502">in</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="3504" end_char="3509">Yunnan</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="3511" end_char="3518">province</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="3520" end_char="3523">that</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="3525" end_char="3530">killed</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="3532" end_char="3537">miners</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="3539" end_char="3541">who</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="3543" end_char="3545">had</TOKEN>
<TOKEN id="token-26-16" pos="word" morph="none" start_char="3547" end_char="3553">stirred</TOKEN>
<TOKEN id="token-26-17" pos="word" morph="none" start_char="3555" end_char="3556">up</TOKEN>
<TOKEN id="token-26-18" pos="word" morph="none" start_char="3558" end_char="3560">bat</TOKEN>
<TOKEN id="token-26-19" pos="word" morph="none" start_char="3562" end_char="3566">feces</TOKEN>
<TOKEN id="token-26-20" pos="punct" morph="none" start_char="3567" end_char="3567">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="3570" end_char="3721">
<ORIGINAL_TEXT>Hilton found it curious that the Wuhan researchers not only didn't reveal that fact, they changed the name of the Yunnan virus, as indicated by GenBank.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="3570" end_char="3575">Hilton</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="3577" end_char="3581">found</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="3583" end_char="3584">it</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="3586" end_char="3592">curious</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="3594" end_char="3597">that</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="3599" end_char="3601">the</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="3603" end_char="3607">Wuhan</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="3609" end_char="3619">researchers</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="3621" end_char="3623">not</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="3625" end_char="3628">only</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="3630" end_char="3635">didn't</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="3637" end_char="3642">reveal</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="3644" end_char="3647">that</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="3649" end_char="3652">fact</TOKEN>
<TOKEN id="token-27-14" pos="punct" morph="none" start_char="3653" end_char="3653">,</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="3655" end_char="3658">they</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="3660" end_char="3666">changed</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="3668" end_char="3670">the</TOKEN>
<TOKEN id="token-27-18" pos="word" morph="none" start_char="3672" end_char="3675">name</TOKEN>
<TOKEN id="token-27-19" pos="word" morph="none" start_char="3677" end_char="3678">of</TOKEN>
<TOKEN id="token-27-20" pos="word" morph="none" start_char="3680" end_char="3682">the</TOKEN>
<TOKEN id="token-27-21" pos="word" morph="none" start_char="3684" end_char="3689">Yunnan</TOKEN>
<TOKEN id="token-27-22" pos="word" morph="none" start_char="3691" end_char="3695">virus</TOKEN>
<TOKEN id="token-27-23" pos="punct" morph="none" start_char="3696" end_char="3696">,</TOKEN>
<TOKEN id="token-27-24" pos="word" morph="none" start_char="3698" end_char="3699">as</TOKEN>
<TOKEN id="token-27-25" pos="word" morph="none" start_char="3701" end_char="3709">indicated</TOKEN>
<TOKEN id="token-27-26" pos="word" morph="none" start_char="3711" end_char="3712">by</TOKEN>
<TOKEN id="token-27-27" pos="word" morph="none" start_char="3714" end_char="3720">GenBank</TOKEN>
<TOKEN id="token-27-28" pos="punct" morph="none" start_char="3721" end_char="3721">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3724" end_char="3964">
<ORIGINAL_TEXT>As evidence that the Yunnan virus was manipulated in the Wuhan lab, Hilton pointed out that the two viruses are the same, except for two key elements: The COVID-19 virus is more infectious and can enter human cells in the respiratory system.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="3724" end_char="3725">As</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="3727" end_char="3734">evidence</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="3736" end_char="3739">that</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="3741" end_char="3743">the</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="3745" end_char="3750">Yunnan</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="3752" end_char="3756">virus</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="3758" end_char="3760">was</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="3762" end_char="3772">manipulated</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="3774" end_char="3775">in</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="3777" end_char="3779">the</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="3781" end_char="3785">Wuhan</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="3787" end_char="3789">lab</TOKEN>
<TOKEN id="token-28-12" pos="punct" morph="none" start_char="3790" end_char="3790">,</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="3792" end_char="3797">Hilton</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="3799" end_char="3805">pointed</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="3807" end_char="3809">out</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="3811" end_char="3814">that</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="3816" end_char="3818">the</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="3820" end_char="3822">two</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="3824" end_char="3830">viruses</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="3832" end_char="3834">are</TOKEN>
<TOKEN id="token-28-21" pos="word" morph="none" start_char="3836" end_char="3838">the</TOKEN>
<TOKEN id="token-28-22" pos="word" morph="none" start_char="3840" end_char="3843">same</TOKEN>
<TOKEN id="token-28-23" pos="punct" morph="none" start_char="3844" end_char="3844">,</TOKEN>
<TOKEN id="token-28-24" pos="word" morph="none" start_char="3846" end_char="3851">except</TOKEN>
<TOKEN id="token-28-25" pos="word" morph="none" start_char="3853" end_char="3855">for</TOKEN>
<TOKEN id="token-28-26" pos="word" morph="none" start_char="3857" end_char="3859">two</TOKEN>
<TOKEN id="token-28-27" pos="word" morph="none" start_char="3861" end_char="3863">key</TOKEN>
<TOKEN id="token-28-28" pos="word" morph="none" start_char="3865" end_char="3872">elements</TOKEN>
<TOKEN id="token-28-29" pos="punct" morph="none" start_char="3873" end_char="3873">:</TOKEN>
<TOKEN id="token-28-30" pos="word" morph="none" start_char="3875" end_char="3877">The</TOKEN>
<TOKEN id="token-28-31" pos="unknown" morph="none" start_char="3879" end_char="3886">COVID-19</TOKEN>
<TOKEN id="token-28-32" pos="word" morph="none" start_char="3888" end_char="3892">virus</TOKEN>
<TOKEN id="token-28-33" pos="word" morph="none" start_char="3894" end_char="3895">is</TOKEN>
<TOKEN id="token-28-34" pos="word" morph="none" start_char="3897" end_char="3900">more</TOKEN>
<TOKEN id="token-28-35" pos="word" morph="none" start_char="3902" end_char="3911">infectious</TOKEN>
<TOKEN id="token-28-36" pos="word" morph="none" start_char="3913" end_char="3915">and</TOKEN>
<TOKEN id="token-28-37" pos="word" morph="none" start_char="3917" end_char="3919">can</TOKEN>
<TOKEN id="token-28-38" pos="word" morph="none" start_char="3921" end_char="3925">enter</TOKEN>
<TOKEN id="token-28-39" pos="word" morph="none" start_char="3927" end_char="3931">human</TOKEN>
<TOKEN id="token-28-40" pos="word" morph="none" start_char="3933" end_char="3937">cells</TOKEN>
<TOKEN id="token-28-41" pos="word" morph="none" start_char="3939" end_char="3940">in</TOKEN>
<TOKEN id="token-28-42" pos="word" morph="none" start_char="3942" end_char="3944">the</TOKEN>
<TOKEN id="token-28-43" pos="word" morph="none" start_char="3946" end_char="3956">respiratory</TOKEN>
<TOKEN id="token-28-44" pos="word" morph="none" start_char="3958" end_char="3963">system</TOKEN>
<TOKEN id="token-28-45" pos="punct" morph="none" start_char="3964" end_char="3964">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3967" end_char="4188">
<ORIGINAL_TEXT>"Those are the exact places in the viral sequence where gain-of-function techniques would be applied, if ... you were funded by the NAID to research bat coronaviruses to explore emergences or spillover potential," he said.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="punct" morph="none" start_char="3967" end_char="3967">"</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="3968" end_char="3972">Those</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="3974" end_char="3976">are</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="3978" end_char="3980">the</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="3982" end_char="3986">exact</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="3988" end_char="3993">places</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="3995" end_char="3996">in</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="3998" end_char="4000">the</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="4002" end_char="4006">viral</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="4008" end_char="4015">sequence</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="4017" end_char="4021">where</TOKEN>
<TOKEN id="token-29-11" pos="unknown" morph="none" start_char="4023" end_char="4038">gain-of-function</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="4040" end_char="4049">techniques</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="4051" end_char="4055">would</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="4057" end_char="4058">be</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="4060" end_char="4066">applied</TOKEN>
<TOKEN id="token-29-16" pos="punct" morph="none" start_char="4067" end_char="4067">,</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="4069" end_char="4070">if</TOKEN>
<TOKEN id="token-29-18" pos="punct" morph="none" start_char="4072" end_char="4074">...</TOKEN>
<TOKEN id="token-29-19" pos="word" morph="none" start_char="4076" end_char="4078">you</TOKEN>
<TOKEN id="token-29-20" pos="word" morph="none" start_char="4080" end_char="4083">were</TOKEN>
<TOKEN id="token-29-21" pos="word" morph="none" start_char="4085" end_char="4090">funded</TOKEN>
<TOKEN id="token-29-22" pos="word" morph="none" start_char="4092" end_char="4093">by</TOKEN>
<TOKEN id="token-29-23" pos="word" morph="none" start_char="4095" end_char="4097">the</TOKEN>
<TOKEN id="token-29-24" pos="word" morph="none" start_char="4099" end_char="4102">NAID</TOKEN>
<TOKEN id="token-29-25" pos="word" morph="none" start_char="4104" end_char="4105">to</TOKEN>
<TOKEN id="token-29-26" pos="word" morph="none" start_char="4107" end_char="4114">research</TOKEN>
<TOKEN id="token-29-27" pos="word" morph="none" start_char="4116" end_char="4118">bat</TOKEN>
<TOKEN id="token-29-28" pos="word" morph="none" start_char="4120" end_char="4132">coronaviruses</TOKEN>
<TOKEN id="token-29-29" pos="word" morph="none" start_char="4134" end_char="4135">to</TOKEN>
<TOKEN id="token-29-30" pos="word" morph="none" start_char="4137" end_char="4143">explore</TOKEN>
<TOKEN id="token-29-31" pos="word" morph="none" start_char="4145" end_char="4154">emergences</TOKEN>
<TOKEN id="token-29-32" pos="word" morph="none" start_char="4156" end_char="4157">or</TOKEN>
<TOKEN id="token-29-33" pos="word" morph="none" start_char="4159" end_char="4167">spillover</TOKEN>
<TOKEN id="token-29-34" pos="word" morph="none" start_char="4169" end_char="4177">potential</TOKEN>
<TOKEN id="token-29-35" pos="punct" morph="none" start_char="4178" end_char="4179">,"</TOKEN>
<TOKEN id="token-29-36" pos="word" morph="none" start_char="4181" end_char="4182">he</TOKEN>
<TOKEN id="token-29-37" pos="word" morph="none" start_char="4184" end_char="4187">said</TOKEN>
<TOKEN id="token-29-38" pos="punct" morph="none" start_char="4188" end_char="4188">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="4191" end_char="4276">
<ORIGINAL_TEXT>"Spillover potential" refers to the ability of a virus to jump from animals to humans.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="punct" morph="none" start_char="4191" end_char="4191">"</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="4192" end_char="4200">Spillover</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="4202" end_char="4210">potential</TOKEN>
<TOKEN id="token-30-3" pos="punct" morph="none" start_char="4211" end_char="4211">"</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="4213" end_char="4218">refers</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="4220" end_char="4221">to</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="4223" end_char="4225">the</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="4227" end_char="4233">ability</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="4235" end_char="4236">of</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="4238" end_char="4238">a</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="4240" end_char="4244">virus</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="4246" end_char="4247">to</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="4249" end_char="4252">jump</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="4254" end_char="4257">from</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="4259" end_char="4265">animals</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="4267" end_char="4268">to</TOKEN>
<TOKEN id="token-30-16" pos="word" morph="none" start_char="4270" end_char="4275">humans</TOKEN>
<TOKEN id="token-30-17" pos="punct" morph="none" start_char="4276" end_char="4276">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="4279" end_char="4352">
<ORIGINAL_TEXT>That exact gain-of-function research, he pointed out, was touted in a Nov.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="4279" end_char="4282">That</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="4284" end_char="4288">exact</TOKEN>
<TOKEN id="token-31-2" pos="unknown" morph="none" start_char="4290" end_char="4305">gain-of-function</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="4307" end_char="4314">research</TOKEN>
<TOKEN id="token-31-4" pos="punct" morph="none" start_char="4315" end_char="4315">,</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="4317" end_char="4318">he</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="4320" end_char="4326">pointed</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="4328" end_char="4330">out</TOKEN>
<TOKEN id="token-31-8" pos="punct" morph="none" start_char="4331" end_char="4331">,</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="4333" end_char="4335">was</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="4337" end_char="4342">touted</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="4344" end_char="4345">in</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="4347" end_char="4347">a</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="4349" end_char="4351">Nov</TOKEN>
<TOKEN id="token-31-14" pos="punct" morph="none" start_char="4352" end_char="4352">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="4354" end_char="4401">
<ORIGINAL_TEXT>30, 2017, progress report tied to an NAID grant.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="4354" end_char="4355">30</TOKEN>
<TOKEN id="token-32-1" pos="punct" morph="none" start_char="4356" end_char="4356">,</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="4358" end_char="4361">2017</TOKEN>
<TOKEN id="token-32-3" pos="punct" morph="none" start_char="4362" end_char="4362">,</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="4364" end_char="4371">progress</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="4373" end_char="4378">report</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="4380" end_char="4383">tied</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="4385" end_char="4386">to</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="4388" end_char="4389">an</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="4391" end_char="4394">NAID</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="4396" end_char="4400">grant</TOKEN>
<TOKEN id="token-32-11" pos="punct" morph="none" start_char="4401" end_char="4401">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="4404" end_char="4556">
<ORIGINAL_TEXT>The crucial question, Hilton said, was whether the virus at the center of that U.S.-funded work was the one that was discovered in the mine a decade ago.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="4404" end_char="4406">The</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="4408" end_char="4414">crucial</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="4416" end_char="4423">question</TOKEN>
<TOKEN id="token-33-3" pos="punct" morph="none" start_char="4424" end_char="4424">,</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="4426" end_char="4431">Hilton</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="4433" end_char="4436">said</TOKEN>
<TOKEN id="token-33-6" pos="punct" morph="none" start_char="4437" end_char="4437">,</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="4439" end_char="4441">was</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="4443" end_char="4449">whether</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="4451" end_char="4453">the</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="4455" end_char="4459">virus</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="4461" end_char="4462">at</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="4464" end_char="4466">the</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="4468" end_char="4473">center</TOKEN>
<TOKEN id="token-33-14" pos="word" morph="none" start_char="4475" end_char="4476">of</TOKEN>
<TOKEN id="token-33-15" pos="word" morph="none" start_char="4478" end_char="4481">that</TOKEN>
<TOKEN id="token-33-16" pos="unknown" morph="none" start_char="4483" end_char="4493">U.S.-funded</TOKEN>
<TOKEN id="token-33-17" pos="word" morph="none" start_char="4495" end_char="4498">work</TOKEN>
<TOKEN id="token-33-18" pos="word" morph="none" start_char="4500" end_char="4502">was</TOKEN>
<TOKEN id="token-33-19" pos="word" morph="none" start_char="4504" end_char="4506">the</TOKEN>
<TOKEN id="token-33-20" pos="word" morph="none" start_char="4508" end_char="4510">one</TOKEN>
<TOKEN id="token-33-21" pos="word" morph="none" start_char="4512" end_char="4515">that</TOKEN>
<TOKEN id="token-33-22" pos="word" morph="none" start_char="4517" end_char="4519">was</TOKEN>
<TOKEN id="token-33-23" pos="word" morph="none" start_char="4521" end_char="4530">discovered</TOKEN>
<TOKEN id="token-33-24" pos="word" morph="none" start_char="4532" end_char="4533">in</TOKEN>
<TOKEN id="token-33-25" pos="word" morph="none" start_char="4535" end_char="4537">the</TOKEN>
<TOKEN id="token-33-26" pos="word" morph="none" start_char="4539" end_char="4542">mine</TOKEN>
<TOKEN id="token-33-27" pos="word" morph="none" start_char="4544" end_char="4544">a</TOKEN>
<TOKEN id="token-33-28" pos="word" morph="none" start_char="4546" end_char="4551">decade</TOKEN>
<TOKEN id="token-33-29" pos="word" morph="none" start_char="4553" end_char="4555">ago</TOKEN>
<TOKEN id="token-33-30" pos="punct" morph="none" start_char="4556" end_char="4556">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="4559" end_char="4687">
<ORIGINAL_TEXT>"The match between that virus and the work commissioned by NAID is so perfect, it's impossible to believe they weren't," he said.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="punct" morph="none" start_char="4559" end_char="4559">"</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="4560" end_char="4562">The</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="4564" end_char="4568">match</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="4570" end_char="4576">between</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="4578" end_char="4581">that</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="4583" end_char="4587">virus</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="4589" end_char="4591">and</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="4593" end_char="4595">the</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="4597" end_char="4600">work</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="4602" end_char="4613">commissioned</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="4615" end_char="4616">by</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="4618" end_char="4621">NAID</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="4623" end_char="4624">is</TOKEN>
<TOKEN id="token-34-13" pos="word" morph="none" start_char="4626" end_char="4627">so</TOKEN>
<TOKEN id="token-34-14" pos="word" morph="none" start_char="4629" end_char="4635">perfect</TOKEN>
<TOKEN id="token-34-15" pos="punct" morph="none" start_char="4636" end_char="4636">,</TOKEN>
<TOKEN id="token-34-16" pos="word" morph="none" start_char="4638" end_char="4641">it's</TOKEN>
<TOKEN id="token-34-17" pos="word" morph="none" start_char="4643" end_char="4652">impossible</TOKEN>
<TOKEN id="token-34-18" pos="word" morph="none" start_char="4654" end_char="4655">to</TOKEN>
<TOKEN id="token-34-19" pos="word" morph="none" start_char="4657" end_char="4663">believe</TOKEN>
<TOKEN id="token-34-20" pos="word" morph="none" start_char="4665" end_char="4668">they</TOKEN>
<TOKEN id="token-34-21" pos="word" morph="none" start_char="4670" end_char="4676">weren't</TOKEN>
<TOKEN id="token-34-22" pos="punct" morph="none" start_char="4677" end_char="4678">,"</TOKEN>
<TOKEN id="token-34-23" pos="word" morph="none" start_char="4680" end_char="4681">he</TOKEN>
<TOKEN id="token-34-24" pos="word" morph="none" start_char="4683" end_char="4686">said</TOKEN>
<TOKEN id="token-34-25" pos="punct" morph="none" start_char="4687" end_char="4687">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="4690" end_char="4792">
<ORIGINAL_TEXT>He noted that workers in the Wuhan lab were the first identified cases of COVID-19 in the fall of 2019.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="4690" end_char="4691">He</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="4693" end_char="4697">noted</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="4699" end_char="4702">that</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="4704" end_char="4710">workers</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="4712" end_char="4713">in</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="4715" end_char="4717">the</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="4719" end_char="4723">Wuhan</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="4725" end_char="4727">lab</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="4729" end_char="4732">were</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="4734" end_char="4736">the</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="4738" end_char="4742">first</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="4744" end_char="4753">identified</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="4755" end_char="4759">cases</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="4761" end_char="4762">of</TOKEN>
<TOKEN id="token-35-14" pos="unknown" morph="none" start_char="4764" end_char="4771">COVID-19</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="4773" end_char="4774">in</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="4776" end_char="4778">the</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="4780" end_char="4783">fall</TOKEN>
<TOKEN id="token-35-18" pos="word" morph="none" start_char="4785" end_char="4786">of</TOKEN>
<TOKEN id="token-35-19" pos="word" morph="none" start_char="4788" end_char="4791">2019</TOKEN>
<TOKEN id="token-35-20" pos="punct" morph="none" start_char="4792" end_char="4792">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="4795" end_char="4818">
<ORIGINAL_TEXT>Implausible coincidences</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="4795" end_char="4805">Implausible</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="4807" end_char="4818">coincidences</TOKEN>
</SEG>
<SEG id="segment-37" start_char="4821" end_char="4913">
<ORIGINAL_TEXT>The WHO and others are leaning toward a "natural" explanation for the pandemic, Hilton noted.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="4821" end_char="4823">The</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="4825" end_char="4827">WHO</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="4829" end_char="4831">and</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="4833" end_char="4838">others</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="4840" end_char="4842">are</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="4844" end_char="4850">leaning</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="4852" end_char="4857">toward</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="4859" end_char="4859">a</TOKEN>
<TOKEN id="token-37-8" pos="punct" morph="none" start_char="4861" end_char="4861">"</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="4862" end_char="4868">natural</TOKEN>
<TOKEN id="token-37-10" pos="punct" morph="none" start_char="4869" end_char="4869">"</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="4871" end_char="4881">explanation</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="4883" end_char="4885">for</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="4887" end_char="4889">the</TOKEN>
<TOKEN id="token-37-14" pos="word" morph="none" start_char="4891" end_char="4898">pandemic</TOKEN>
<TOKEN id="token-37-15" pos="punct" morph="none" start_char="4899" end_char="4899">,</TOKEN>
<TOKEN id="token-37-16" pos="word" morph="none" start_char="4901" end_char="4906">Hilton</TOKEN>
<TOKEN id="token-37-17" pos="word" morph="none" start_char="4908" end_char="4912">noted</TOKEN>
<TOKEN id="token-37-18" pos="punct" morph="none" start_char="4913" end_char="4913">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="4915" end_char="5149">
<ORIGINAL_TEXT>But if the COVID-19 pandemic originated naturally in the Yunnan mine – as the genome sequence indicates – but had nothing to do with research at the Wuhan lab, you would "have to believe in a laughably implausible set of coincidences."</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="4915" end_char="4917">But</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="4919" end_char="4920">if</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="4922" end_char="4924">the</TOKEN>
<TOKEN id="token-38-3" pos="unknown" morph="none" start_char="4926" end_char="4933">COVID-19</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="4935" end_char="4942">pandemic</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="4944" end_char="4953">originated</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="4955" end_char="4963">naturally</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="4965" end_char="4966">in</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="4968" end_char="4970">the</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="4972" end_char="4977">Yunnan</TOKEN>
<TOKEN id="token-38-10" pos="word" morph="none" start_char="4979" end_char="4982">mine</TOKEN>
<TOKEN id="token-38-11" pos="punct" morph="none" start_char="4984" end_char="4984">–</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="4986" end_char="4987">as</TOKEN>
<TOKEN id="token-38-13" pos="word" morph="none" start_char="4989" end_char="4991">the</TOKEN>
<TOKEN id="token-38-14" pos="word" morph="none" start_char="4993" end_char="4998">genome</TOKEN>
<TOKEN id="token-38-15" pos="word" morph="none" start_char="5000" end_char="5007">sequence</TOKEN>
<TOKEN id="token-38-16" pos="word" morph="none" start_char="5009" end_char="5017">indicates</TOKEN>
<TOKEN id="token-38-17" pos="punct" morph="none" start_char="5019" end_char="5019">–</TOKEN>
<TOKEN id="token-38-18" pos="word" morph="none" start_char="5021" end_char="5023">but</TOKEN>
<TOKEN id="token-38-19" pos="word" morph="none" start_char="5025" end_char="5027">had</TOKEN>
<TOKEN id="token-38-20" pos="word" morph="none" start_char="5029" end_char="5035">nothing</TOKEN>
<TOKEN id="token-38-21" pos="word" morph="none" start_char="5037" end_char="5038">to</TOKEN>
<TOKEN id="token-38-22" pos="word" morph="none" start_char="5040" end_char="5041">do</TOKEN>
<TOKEN id="token-38-23" pos="word" morph="none" start_char="5043" end_char="5046">with</TOKEN>
<TOKEN id="token-38-24" pos="word" morph="none" start_char="5048" end_char="5055">research</TOKEN>
<TOKEN id="token-38-25" pos="word" morph="none" start_char="5057" end_char="5058">at</TOKEN>
<TOKEN id="token-38-26" pos="word" morph="none" start_char="5060" end_char="5062">the</TOKEN>
<TOKEN id="token-38-27" pos="word" morph="none" start_char="5064" end_char="5068">Wuhan</TOKEN>
<TOKEN id="token-38-28" pos="word" morph="none" start_char="5070" end_char="5072">lab</TOKEN>
<TOKEN id="token-38-29" pos="punct" morph="none" start_char="5073" end_char="5073">,</TOKEN>
<TOKEN id="token-38-30" pos="word" morph="none" start_char="5075" end_char="5077">you</TOKEN>
<TOKEN id="token-38-31" pos="word" morph="none" start_char="5079" end_char="5083">would</TOKEN>
<TOKEN id="token-38-32" pos="punct" morph="none" start_char="5085" end_char="5085">"</TOKEN>
<TOKEN id="token-38-33" pos="word" morph="none" start_char="5086" end_char="5089">have</TOKEN>
<TOKEN id="token-38-34" pos="word" morph="none" start_char="5091" end_char="5092">to</TOKEN>
<TOKEN id="token-38-35" pos="word" morph="none" start_char="5094" end_char="5100">believe</TOKEN>
<TOKEN id="token-38-36" pos="word" morph="none" start_char="5102" end_char="5103">in</TOKEN>
<TOKEN id="token-38-37" pos="word" morph="none" start_char="5105" end_char="5105">a</TOKEN>
<TOKEN id="token-38-38" pos="word" morph="none" start_char="5107" end_char="5115">laughably</TOKEN>
<TOKEN id="token-38-39" pos="word" morph="none" start_char="5117" end_char="5127">implausible</TOKEN>
<TOKEN id="token-38-40" pos="word" morph="none" start_char="5129" end_char="5131">set</TOKEN>
<TOKEN id="token-38-41" pos="word" morph="none" start_char="5133" end_char="5134">of</TOKEN>
<TOKEN id="token-38-42" pos="word" morph="none" start_char="5136" end_char="5147">coincidences</TOKEN>
<TOKEN id="token-38-43" pos="punct" morph="none" start_char="5148" end_char="5149">."</TOKEN>
</SEG>
<SEG id="segment-39" start_char="5151" end_char="5338">
<ORIGINAL_TEXT>The bats in Yunnan province would have had to infect each other and another unknown animal or a human and then travel 1,000 miles – without infecting anyone else – until they got to Wuhan.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="5151" end_char="5153">The</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="5155" end_char="5158">bats</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="5160" end_char="5161">in</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="5163" end_char="5168">Yunnan</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="5170" end_char="5177">province</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="5179" end_char="5183">would</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="5185" end_char="5188">have</TOKEN>
<TOKEN id="token-39-7" pos="word" morph="none" start_char="5190" end_char="5192">had</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="5194" end_char="5195">to</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="5197" end_char="5202">infect</TOKEN>
<TOKEN id="token-39-10" pos="word" morph="none" start_char="5204" end_char="5207">each</TOKEN>
<TOKEN id="token-39-11" pos="word" morph="none" start_char="5209" end_char="5213">other</TOKEN>
<TOKEN id="token-39-12" pos="word" morph="none" start_char="5215" end_char="5217">and</TOKEN>
<TOKEN id="token-39-13" pos="word" morph="none" start_char="5219" end_char="5225">another</TOKEN>
<TOKEN id="token-39-14" pos="word" morph="none" start_char="5227" end_char="5233">unknown</TOKEN>
<TOKEN id="token-39-15" pos="word" morph="none" start_char="5235" end_char="5240">animal</TOKEN>
<TOKEN id="token-39-16" pos="word" morph="none" start_char="5242" end_char="5243">or</TOKEN>
<TOKEN id="token-39-17" pos="word" morph="none" start_char="5245" end_char="5245">a</TOKEN>
<TOKEN id="token-39-18" pos="word" morph="none" start_char="5247" end_char="5251">human</TOKEN>
<TOKEN id="token-39-19" pos="word" morph="none" start_char="5253" end_char="5255">and</TOKEN>
<TOKEN id="token-39-20" pos="word" morph="none" start_char="5257" end_char="5260">then</TOKEN>
<TOKEN id="token-39-21" pos="word" morph="none" start_char="5262" end_char="5267">travel</TOKEN>
<TOKEN id="token-39-22" pos="unknown" morph="none" start_char="5269" end_char="5273">1,000</TOKEN>
<TOKEN id="token-39-23" pos="word" morph="none" start_char="5275" end_char="5279">miles</TOKEN>
<TOKEN id="token-39-24" pos="punct" morph="none" start_char="5281" end_char="5281">–</TOKEN>
<TOKEN id="token-39-25" pos="word" morph="none" start_char="5283" end_char="5289">without</TOKEN>
<TOKEN id="token-39-26" pos="word" morph="none" start_char="5291" end_char="5299">infecting</TOKEN>
<TOKEN id="token-39-27" pos="word" morph="none" start_char="5301" end_char="5306">anyone</TOKEN>
<TOKEN id="token-39-28" pos="word" morph="none" start_char="5308" end_char="5311">else</TOKEN>
<TOKEN id="token-39-29" pos="punct" morph="none" start_char="5313" end_char="5313">–</TOKEN>
<TOKEN id="token-39-30" pos="word" morph="none" start_char="5315" end_char="5319">until</TOKEN>
<TOKEN id="token-39-31" pos="word" morph="none" start_char="5321" end_char="5324">they</TOKEN>
<TOKEN id="token-39-32" pos="word" morph="none" start_char="5326" end_char="5328">got</TOKEN>
<TOKEN id="token-39-33" pos="word" morph="none" start_char="5330" end_char="5331">to</TOKEN>
<TOKEN id="token-39-34" pos="word" morph="none" start_char="5333" end_char="5337">Wuhan</TOKEN>
<TOKEN id="token-39-35" pos="punct" morph="none" start_char="5338" end_char="5338">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="5341" end_char="5472">
<ORIGINAL_TEXT>Before any mutations, he argued, the virus was 10 to 20 times more infectious than any previously observed virus occuring in nature.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="5341" end_char="5346">Before</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="5348" end_char="5350">any</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="5352" end_char="5360">mutations</TOKEN>
<TOKEN id="token-40-3" pos="punct" morph="none" start_char="5361" end_char="5361">,</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="5363" end_char="5364">he</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="5366" end_char="5371">argued</TOKEN>
<TOKEN id="token-40-6" pos="punct" morph="none" start_char="5372" end_char="5372">,</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="5374" end_char="5376">the</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="5378" end_char="5382">virus</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="5384" end_char="5386">was</TOKEN>
<TOKEN id="token-40-10" pos="word" morph="none" start_char="5388" end_char="5389">10</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="5391" end_char="5392">to</TOKEN>
<TOKEN id="token-40-12" pos="word" morph="none" start_char="5394" end_char="5395">20</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="5397" end_char="5401">times</TOKEN>
<TOKEN id="token-40-14" pos="word" morph="none" start_char="5403" end_char="5406">more</TOKEN>
<TOKEN id="token-40-15" pos="word" morph="none" start_char="5408" end_char="5417">infectious</TOKEN>
<TOKEN id="token-40-16" pos="word" morph="none" start_char="5419" end_char="5422">than</TOKEN>
<TOKEN id="token-40-17" pos="word" morph="none" start_char="5424" end_char="5426">any</TOKEN>
<TOKEN id="token-40-18" pos="word" morph="none" start_char="5428" end_char="5437">previously</TOKEN>
<TOKEN id="token-40-19" pos="word" morph="none" start_char="5439" end_char="5446">observed</TOKEN>
<TOKEN id="token-40-20" pos="word" morph="none" start_char="5448" end_char="5452">virus</TOKEN>
<TOKEN id="token-40-21" pos="word" morph="none" start_char="5454" end_char="5461">occuring</TOKEN>
<TOKEN id="token-40-22" pos="word" morph="none" start_char="5463" end_char="5464">in</TOKEN>
<TOKEN id="token-40-23" pos="word" morph="none" start_char="5466" end_char="5471">nature</TOKEN>
<TOKEN id="token-40-24" pos="punct" morph="none" start_char="5472" end_char="5472">.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="5475" end_char="5723">
<ORIGINAL_TEXT>"And most incredibly of all," he added, "the infected animal or human would have somehow chosen to make that 1,000-mile trek to the only place in all of China that had been working for years on the virus it was already infected with," the Wuhan lab.</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="punct" morph="none" start_char="5475" end_char="5475">"</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="5476" end_char="5478">And</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="5480" end_char="5483">most</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="5485" end_char="5494">incredibly</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="5496" end_char="5497">of</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="5499" end_char="5501">all</TOKEN>
<TOKEN id="token-41-6" pos="punct" morph="none" start_char="5502" end_char="5503">,"</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="5505" end_char="5506">he</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="5508" end_char="5512">added</TOKEN>
<TOKEN id="token-41-9" pos="punct" morph="none" start_char="5513" end_char="5513">,</TOKEN>
<TOKEN id="token-41-10" pos="punct" morph="none" start_char="5515" end_char="5515">"</TOKEN>
<TOKEN id="token-41-11" pos="word" morph="none" start_char="5516" end_char="5518">the</TOKEN>
<TOKEN id="token-41-12" pos="word" morph="none" start_char="5520" end_char="5527">infected</TOKEN>
<TOKEN id="token-41-13" pos="word" morph="none" start_char="5529" end_char="5534">animal</TOKEN>
<TOKEN id="token-41-14" pos="word" morph="none" start_char="5536" end_char="5537">or</TOKEN>
<TOKEN id="token-41-15" pos="word" morph="none" start_char="5539" end_char="5543">human</TOKEN>
<TOKEN id="token-41-16" pos="word" morph="none" start_char="5545" end_char="5549">would</TOKEN>
<TOKEN id="token-41-17" pos="word" morph="none" start_char="5551" end_char="5554">have</TOKEN>
<TOKEN id="token-41-18" pos="word" morph="none" start_char="5556" end_char="5562">somehow</TOKEN>
<TOKEN id="token-41-19" pos="word" morph="none" start_char="5564" end_char="5569">chosen</TOKEN>
<TOKEN id="token-41-20" pos="word" morph="none" start_char="5571" end_char="5572">to</TOKEN>
<TOKEN id="token-41-21" pos="word" morph="none" start_char="5574" end_char="5577">make</TOKEN>
<TOKEN id="token-41-22" pos="word" morph="none" start_char="5579" end_char="5582">that</TOKEN>
<TOKEN id="token-41-23" pos="unknown" morph="none" start_char="5584" end_char="5593">1,000-mile</TOKEN>
<TOKEN id="token-41-24" pos="word" morph="none" start_char="5595" end_char="5598">trek</TOKEN>
<TOKEN id="token-41-25" pos="word" morph="none" start_char="5600" end_char="5601">to</TOKEN>
<TOKEN id="token-41-26" pos="word" morph="none" start_char="5603" end_char="5605">the</TOKEN>
<TOKEN id="token-41-27" pos="word" morph="none" start_char="5607" end_char="5610">only</TOKEN>
<TOKEN id="token-41-28" pos="word" morph="none" start_char="5612" end_char="5616">place</TOKEN>
<TOKEN id="token-41-29" pos="word" morph="none" start_char="5618" end_char="5619">in</TOKEN>
<TOKEN id="token-41-30" pos="word" morph="none" start_char="5621" end_char="5623">all</TOKEN>
<TOKEN id="token-41-31" pos="word" morph="none" start_char="5625" end_char="5626">of</TOKEN>
<TOKEN id="token-41-32" pos="word" morph="none" start_char="5628" end_char="5632">China</TOKEN>
<TOKEN id="token-41-33" pos="word" morph="none" start_char="5634" end_char="5637">that</TOKEN>
<TOKEN id="token-41-34" pos="word" morph="none" start_char="5639" end_char="5641">had</TOKEN>
<TOKEN id="token-41-35" pos="word" morph="none" start_char="5643" end_char="5646">been</TOKEN>
<TOKEN id="token-41-36" pos="word" morph="none" start_char="5648" end_char="5654">working</TOKEN>
<TOKEN id="token-41-37" pos="word" morph="none" start_char="5656" end_char="5658">for</TOKEN>
<TOKEN id="token-41-38" pos="word" morph="none" start_char="5660" end_char="5664">years</TOKEN>
<TOKEN id="token-41-39" pos="word" morph="none" start_char="5666" end_char="5667">on</TOKEN>
<TOKEN id="token-41-40" pos="word" morph="none" start_char="5669" end_char="5671">the</TOKEN>
<TOKEN id="token-41-41" pos="word" morph="none" start_char="5673" end_char="5677">virus</TOKEN>
<TOKEN id="token-41-42" pos="word" morph="none" start_char="5679" end_char="5680">it</TOKEN>
<TOKEN id="token-41-43" pos="word" morph="none" start_char="5682" end_char="5684">was</TOKEN>
<TOKEN id="token-41-44" pos="word" morph="none" start_char="5686" end_char="5692">already</TOKEN>
<TOKEN id="token-41-45" pos="word" morph="none" start_char="5694" end_char="5701">infected</TOKEN>
<TOKEN id="token-41-46" pos="word" morph="none" start_char="5703" end_char="5706">with</TOKEN>
<TOKEN id="token-41-47" pos="punct" morph="none" start_char="5707" end_char="5708">,"</TOKEN>
<TOKEN id="token-41-48" pos="word" morph="none" start_char="5710" end_char="5712">the</TOKEN>
<TOKEN id="token-41-49" pos="word" morph="none" start_char="5714" end_char="5718">Wuhan</TOKEN>
<TOKEN id="token-41-50" pos="word" morph="none" start_char="5720" end_char="5722">lab</TOKEN>
<TOKEN id="token-41-51" pos="punct" morph="none" start_char="5723" end_char="5723">.</TOKEN>
</SEG>
<SEG id="segment-42" start_char="5726" end_char="5795">
<ORIGINAL_TEXT>Significantly, the Chinese regime has blocked access to the Wuhan lab.</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="5726" end_char="5738">Significantly</TOKEN>
<TOKEN id="token-42-1" pos="punct" morph="none" start_char="5739" end_char="5739">,</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="5741" end_char="5743">the</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="5745" end_char="5751">Chinese</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="5753" end_char="5758">regime</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="5760" end_char="5762">has</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="5764" end_char="5770">blocked</TOKEN>
<TOKEN id="token-42-7" pos="word" morph="none" start_char="5772" end_char="5777">access</TOKEN>
<TOKEN id="token-42-8" pos="word" morph="none" start_char="5779" end_char="5780">to</TOKEN>
<TOKEN id="token-42-9" pos="word" morph="none" start_char="5782" end_char="5784">the</TOKEN>
<TOKEN id="token-42-10" pos="word" morph="none" start_char="5786" end_char="5790">Wuhan</TOKEN>
<TOKEN id="token-42-11" pos="word" morph="none" start_char="5792" end_char="5794">lab</TOKEN>
<TOKEN id="token-42-12" pos="punct" morph="none" start_char="5795" end_char="5795">.</TOKEN>
</SEG>
<SEG id="segment-43" start_char="5797" end_char="5936">
<ORIGINAL_TEXT>Last week, NBC News reported that a Wuhan Institute of Virology database with 20,000 entries was removed last spring for "security reasons."</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="5797" end_char="5800">Last</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="5802" end_char="5805">week</TOKEN>
<TOKEN id="token-43-2" pos="punct" morph="none" start_char="5806" end_char="5806">,</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="5808" end_char="5810">NBC</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="5812" end_char="5815">News</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="5817" end_char="5824">reported</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="5826" end_char="5829">that</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="5831" end_char="5831">a</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="5833" end_char="5837">Wuhan</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="5839" end_char="5847">Institute</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="5849" end_char="5850">of</TOKEN>
<TOKEN id="token-43-11" pos="word" morph="none" start_char="5852" end_char="5859">Virology</TOKEN>
<TOKEN id="token-43-12" pos="word" morph="none" start_char="5861" end_char="5868">database</TOKEN>
<TOKEN id="token-43-13" pos="word" morph="none" start_char="5870" end_char="5873">with</TOKEN>
<TOKEN id="token-43-14" pos="unknown" morph="none" start_char="5875" end_char="5880">20,000</TOKEN>
<TOKEN id="token-43-15" pos="word" morph="none" start_char="5882" end_char="5888">entries</TOKEN>
<TOKEN id="token-43-16" pos="word" morph="none" start_char="5890" end_char="5892">was</TOKEN>
<TOKEN id="token-43-17" pos="word" morph="none" start_char="5894" end_char="5900">removed</TOKEN>
<TOKEN id="token-43-18" pos="word" morph="none" start_char="5902" end_char="5905">last</TOKEN>
<TOKEN id="token-43-19" pos="word" morph="none" start_char="5907" end_char="5912">spring</TOKEN>
<TOKEN id="token-43-20" pos="word" morph="none" start_char="5914" end_char="5916">for</TOKEN>
<TOKEN id="token-43-21" pos="punct" morph="none" start_char="5918" end_char="5918">"</TOKEN>
<TOKEN id="token-43-22" pos="word" morph="none" start_char="5919" end_char="5926">security</TOKEN>
<TOKEN id="token-43-23" pos="word" morph="none" start_char="5928" end_char="5934">reasons</TOKEN>
<TOKEN id="token-43-24" pos="punct" morph="none" start_char="5935" end_char="5936">."</TOKEN>
</SEG>
<SEG id="segment-44" start_char="5939" end_char="6004">
<ORIGINAL_TEXT>But Hilton said the U.S. government also has not been forthcoming.</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="5939" end_char="5941">But</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="5943" end_char="5948">Hilton</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="5950" end_char="5953">said</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="5955" end_char="5957">the</TOKEN>
<TOKEN id="token-44-4" pos="unknown" morph="none" start_char="5959" end_char="5961">U.S</TOKEN>
<TOKEN id="token-44-5" pos="punct" morph="none" start_char="5962" end_char="5962">.</TOKEN>
<TOKEN id="token-44-6" pos="word" morph="none" start_char="5964" end_char="5973">government</TOKEN>
<TOKEN id="token-44-7" pos="word" morph="none" start_char="5975" end_char="5978">also</TOKEN>
<TOKEN id="token-44-8" pos="word" morph="none" start_char="5980" end_char="5982">has</TOKEN>
<TOKEN id="token-44-9" pos="word" morph="none" start_char="5984" end_char="5986">not</TOKEN>
<TOKEN id="token-44-10" pos="word" morph="none" start_char="5988" end_char="5991">been</TOKEN>
<TOKEN id="token-44-11" pos="word" morph="none" start_char="5993" end_char="6003">forthcoming</TOKEN>
<TOKEN id="token-44-12" pos="punct" morph="none" start_char="6004" end_char="6004">.</TOKEN>
</SEG>
<SEG id="segment-45" start_char="6006" end_char="6200">
<ORIGINAL_TEXT>After two weeks, the NIH finally responded last Friday to his request for comment on the coronavirus gain-of-function research project that began after the Obama administration's halt in funding.</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="6006" end_char="6010">After</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="6012" end_char="6014">two</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="6016" end_char="6020">weeks</TOKEN>
<TOKEN id="token-45-3" pos="punct" morph="none" start_char="6021" end_char="6021">,</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="6023" end_char="6025">the</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="6027" end_char="6029">NIH</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="6031" end_char="6037">finally</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="6039" end_char="6047">responded</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="6049" end_char="6052">last</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="6054" end_char="6059">Friday</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="6061" end_char="6062">to</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="6064" end_char="6066">his</TOKEN>
<TOKEN id="token-45-12" pos="word" morph="none" start_char="6068" end_char="6074">request</TOKEN>
<TOKEN id="token-45-13" pos="word" morph="none" start_char="6076" end_char="6078">for</TOKEN>
<TOKEN id="token-45-14" pos="word" morph="none" start_char="6080" end_char="6086">comment</TOKEN>
<TOKEN id="token-45-15" pos="word" morph="none" start_char="6088" end_char="6089">on</TOKEN>
<TOKEN id="token-45-16" pos="word" morph="none" start_char="6091" end_char="6093">the</TOKEN>
<TOKEN id="token-45-17" pos="word" morph="none" start_char="6095" end_char="6105">coronavirus</TOKEN>
<TOKEN id="token-45-18" pos="unknown" morph="none" start_char="6107" end_char="6122">gain-of-function</TOKEN>
<TOKEN id="token-45-19" pos="word" morph="none" start_char="6124" end_char="6131">research</TOKEN>
<TOKEN id="token-45-20" pos="word" morph="none" start_char="6133" end_char="6139">project</TOKEN>
<TOKEN id="token-45-21" pos="word" morph="none" start_char="6141" end_char="6144">that</TOKEN>
<TOKEN id="token-45-22" pos="word" morph="none" start_char="6146" end_char="6150">began</TOKEN>
<TOKEN id="token-45-23" pos="word" morph="none" start_char="6152" end_char="6156">after</TOKEN>
<TOKEN id="token-45-24" pos="word" morph="none" start_char="6158" end_char="6160">the</TOKEN>
<TOKEN id="token-45-25" pos="word" morph="none" start_char="6162" end_char="6166">Obama</TOKEN>
<TOKEN id="token-45-26" pos="word" morph="none" start_char="6168" end_char="6183">administration's</TOKEN>
<TOKEN id="token-45-27" pos="word" morph="none" start_char="6185" end_char="6188">halt</TOKEN>
<TOKEN id="token-45-28" pos="word" morph="none" start_char="6190" end_char="6191">in</TOKEN>
<TOKEN id="token-45-29" pos="word" morph="none" start_char="6193" end_char="6199">funding</TOKEN>
<TOKEN id="token-45-30" pos="punct" morph="none" start_char="6200" end_char="6200">.</TOKEN>
</SEG>
<SEG id="segment-46" start_char="6203" end_char="6277">
<ORIGINAL_TEXT>The NIH replied that the project did not involve gain-of-function research.</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="6203" end_char="6205">The</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="6207" end_char="6209">NIH</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="6211" end_char="6217">replied</TOKEN>
<TOKEN id="token-46-3" pos="word" morph="none" start_char="6219" end_char="6222">that</TOKEN>
<TOKEN id="token-46-4" pos="word" morph="none" start_char="6224" end_char="6226">the</TOKEN>
<TOKEN id="token-46-5" pos="word" morph="none" start_char="6228" end_char="6234">project</TOKEN>
<TOKEN id="token-46-6" pos="word" morph="none" start_char="6236" end_char="6238">did</TOKEN>
<TOKEN id="token-46-7" pos="word" morph="none" start_char="6240" end_char="6242">not</TOKEN>
<TOKEN id="token-46-8" pos="word" morph="none" start_char="6244" end_char="6250">involve</TOKEN>
<TOKEN id="token-46-9" pos="unknown" morph="none" start_char="6252" end_char="6267">gain-of-function</TOKEN>
<TOKEN id="token-46-10" pos="word" morph="none" start_char="6269" end_char="6276">research</TOKEN>
<TOKEN id="token-46-11" pos="punct" morph="none" start_char="6277" end_char="6277">.</TOKEN>
</SEG>
<SEG id="segment-47" start_char="6279" end_char="6419">
<ORIGINAL_TEXT>But Hilton noted that the project to which NIH referred was not the project he was asking about, which clearly was gain-of-function research.</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="6279" end_char="6281">But</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="6283" end_char="6288">Hilton</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="6290" end_char="6294">noted</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="6296" end_char="6299">that</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="6301" end_char="6303">the</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="6305" end_char="6311">project</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="6313" end_char="6314">to</TOKEN>
<TOKEN id="token-47-7" pos="word" morph="none" start_char="6316" end_char="6320">which</TOKEN>
<TOKEN id="token-47-8" pos="word" morph="none" start_char="6322" end_char="6324">NIH</TOKEN>
<TOKEN id="token-47-9" pos="word" morph="none" start_char="6326" end_char="6333">referred</TOKEN>
<TOKEN id="token-47-10" pos="word" morph="none" start_char="6335" end_char="6337">was</TOKEN>
<TOKEN id="token-47-11" pos="word" morph="none" start_char="6339" end_char="6341">not</TOKEN>
<TOKEN id="token-47-12" pos="word" morph="none" start_char="6343" end_char="6345">the</TOKEN>
<TOKEN id="token-47-13" pos="word" morph="none" start_char="6347" end_char="6353">project</TOKEN>
<TOKEN id="token-47-14" pos="word" morph="none" start_char="6355" end_char="6356">he</TOKEN>
<TOKEN id="token-47-15" pos="word" morph="none" start_char="6358" end_char="6360">was</TOKEN>
<TOKEN id="token-47-16" pos="word" morph="none" start_char="6362" end_char="6367">asking</TOKEN>
<TOKEN id="token-47-17" pos="word" morph="none" start_char="6369" end_char="6373">about</TOKEN>
<TOKEN id="token-47-18" pos="punct" morph="none" start_char="6374" end_char="6374">,</TOKEN>
<TOKEN id="token-47-19" pos="word" morph="none" start_char="6376" end_char="6380">which</TOKEN>
<TOKEN id="token-47-20" pos="word" morph="none" start_char="6382" end_char="6388">clearly</TOKEN>
<TOKEN id="token-47-21" pos="word" morph="none" start_char="6390" end_char="6392">was</TOKEN>
<TOKEN id="token-47-22" pos="unknown" morph="none" start_char="6394" end_char="6409">gain-of-function</TOKEN>
<TOKEN id="token-47-23" pos="word" morph="none" start_char="6411" end_char="6418">research</TOKEN>
<TOKEN id="token-47-24" pos="punct" morph="none" start_char="6419" end_char="6419">.</TOKEN>
</SEG>
<SEG id="segment-48" start_char="6422" end_char="6573">
<ORIGINAL_TEXT>Calling the response "deceptive," he wanted to know whether or not the director of NIH, the famed scientist Francis Collins, was aware of the statement.</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="6422" end_char="6428">Calling</TOKEN>
<TOKEN id="token-48-1" pos="word" morph="none" start_char="6430" end_char="6432">the</TOKEN>
<TOKEN id="token-48-2" pos="word" morph="none" start_char="6434" end_char="6441">response</TOKEN>
<TOKEN id="token-48-3" pos="punct" morph="none" start_char="6443" end_char="6443">"</TOKEN>
<TOKEN id="token-48-4" pos="word" morph="none" start_char="6444" end_char="6452">deceptive</TOKEN>
<TOKEN id="token-48-5" pos="punct" morph="none" start_char="6453" end_char="6454">,"</TOKEN>
<TOKEN id="token-48-6" pos="word" morph="none" start_char="6456" end_char="6457">he</TOKEN>
<TOKEN id="token-48-7" pos="word" morph="none" start_char="6459" end_char="6464">wanted</TOKEN>
<TOKEN id="token-48-8" pos="word" morph="none" start_char="6466" end_char="6467">to</TOKEN>
<TOKEN id="token-48-9" pos="word" morph="none" start_char="6469" end_char="6472">know</TOKEN>
<TOKEN id="token-48-10" pos="word" morph="none" start_char="6474" end_char="6480">whether</TOKEN>
<TOKEN id="token-48-11" pos="word" morph="none" start_char="6482" end_char="6483">or</TOKEN>
<TOKEN id="token-48-12" pos="word" morph="none" start_char="6485" end_char="6487">not</TOKEN>
<TOKEN id="token-48-13" pos="word" morph="none" start_char="6489" end_char="6491">the</TOKEN>
<TOKEN id="token-48-14" pos="word" morph="none" start_char="6493" end_char="6500">director</TOKEN>
<TOKEN id="token-48-15" pos="word" morph="none" start_char="6502" end_char="6503">of</TOKEN>
<TOKEN id="token-48-16" pos="word" morph="none" start_char="6505" end_char="6507">NIH</TOKEN>
<TOKEN id="token-48-17" pos="punct" morph="none" start_char="6508" end_char="6508">,</TOKEN>
<TOKEN id="token-48-18" pos="word" morph="none" start_char="6510" end_char="6512">the</TOKEN>
<TOKEN id="token-48-19" pos="word" morph="none" start_char="6514" end_char="6518">famed</TOKEN>
<TOKEN id="token-48-20" pos="word" morph="none" start_char="6520" end_char="6528">scientist</TOKEN>
<TOKEN id="token-48-21" pos="word" morph="none" start_char="6530" end_char="6536">Francis</TOKEN>
<TOKEN id="token-48-22" pos="word" morph="none" start_char="6538" end_char="6544">Collins</TOKEN>
<TOKEN id="token-48-23" pos="punct" morph="none" start_char="6545" end_char="6545">,</TOKEN>
<TOKEN id="token-48-24" pos="word" morph="none" start_char="6547" end_char="6549">was</TOKEN>
<TOKEN id="token-48-25" pos="word" morph="none" start_char="6551" end_char="6555">aware</TOKEN>
<TOKEN id="token-48-26" pos="word" morph="none" start_char="6557" end_char="6558">of</TOKEN>
<TOKEN id="token-48-27" pos="word" morph="none" start_char="6560" end_char="6562">the</TOKEN>
<TOKEN id="token-48-28" pos="word" morph="none" start_char="6564" end_char="6572">statement</TOKEN>
<TOKEN id="token-48-29" pos="punct" morph="none" start_char="6573" end_char="6573">.</TOKEN>
</SEG>
<SEG id="segment-49" start_char="6576" end_char="6696">
<ORIGINAL_TEXT>The Chinese regime can certainly be blamed for a cover-up allowing the outbreak to become a global pandemic, Hilton said.</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="6576" end_char="6578">The</TOKEN>
<TOKEN id="token-49-1" pos="word" morph="none" start_char="6580" end_char="6586">Chinese</TOKEN>
<TOKEN id="token-49-2" pos="word" morph="none" start_char="6588" end_char="6593">regime</TOKEN>
<TOKEN id="token-49-3" pos="word" morph="none" start_char="6595" end_char="6597">can</TOKEN>
<TOKEN id="token-49-4" pos="word" morph="none" start_char="6599" end_char="6607">certainly</TOKEN>
<TOKEN id="token-49-5" pos="word" morph="none" start_char="6609" end_char="6610">be</TOKEN>
<TOKEN id="token-49-6" pos="word" morph="none" start_char="6612" end_char="6617">blamed</TOKEN>
<TOKEN id="token-49-7" pos="word" morph="none" start_char="6619" end_char="6621">for</TOKEN>
<TOKEN id="token-49-8" pos="word" morph="none" start_char="6623" end_char="6623">a</TOKEN>
<TOKEN id="token-49-9" pos="unknown" morph="none" start_char="6625" end_char="6632">cover-up</TOKEN>
<TOKEN id="token-49-10" pos="word" morph="none" start_char="6634" end_char="6641">allowing</TOKEN>
<TOKEN id="token-49-11" pos="word" morph="none" start_char="6643" end_char="6645">the</TOKEN>
<TOKEN id="token-49-12" pos="word" morph="none" start_char="6647" end_char="6654">outbreak</TOKEN>
<TOKEN id="token-49-13" pos="word" morph="none" start_char="6656" end_char="6657">to</TOKEN>
<TOKEN id="token-49-14" pos="word" morph="none" start_char="6659" end_char="6664">become</TOKEN>
<TOKEN id="token-49-15" pos="word" morph="none" start_char="6666" end_char="6666">a</TOKEN>
<TOKEN id="token-49-16" pos="word" morph="none" start_char="6668" end_char="6673">global</TOKEN>
<TOKEN id="token-49-17" pos="word" morph="none" start_char="6675" end_char="6682">pandemic</TOKEN>
<TOKEN id="token-49-18" pos="punct" morph="none" start_char="6683" end_char="6683">,</TOKEN>
<TOKEN id="token-49-19" pos="word" morph="none" start_char="6685" end_char="6690">Hilton</TOKEN>
<TOKEN id="token-49-20" pos="word" morph="none" start_char="6692" end_char="6695">said</TOKEN>
<TOKEN id="token-49-21" pos="punct" morph="none" start_char="6696" end_char="6696">.</TOKEN>
</SEG>
<SEG id="segment-50" start_char="6698" end_char="6943">
<ORIGINAL_TEXT>But the reason the virus exists and is so contagious, he asserted, can be traced back to the decision of Collins and Fauci to go ahead with the gain-of-function research as a "risk worth taking" after the Obama administration stopped the funding.</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="6698" end_char="6700">But</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="6702" end_char="6704">the</TOKEN>
<TOKEN id="token-50-2" pos="word" morph="none" start_char="6706" end_char="6711">reason</TOKEN>
<TOKEN id="token-50-3" pos="word" morph="none" start_char="6713" end_char="6715">the</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="6717" end_char="6721">virus</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="6723" end_char="6728">exists</TOKEN>
<TOKEN id="token-50-6" pos="word" morph="none" start_char="6730" end_char="6732">and</TOKEN>
<TOKEN id="token-50-7" pos="word" morph="none" start_char="6734" end_char="6735">is</TOKEN>
<TOKEN id="token-50-8" pos="word" morph="none" start_char="6737" end_char="6738">so</TOKEN>
<TOKEN id="token-50-9" pos="word" morph="none" start_char="6740" end_char="6749">contagious</TOKEN>
<TOKEN id="token-50-10" pos="punct" morph="none" start_char="6750" end_char="6750">,</TOKEN>
<TOKEN id="token-50-11" pos="word" morph="none" start_char="6752" end_char="6753">he</TOKEN>
<TOKEN id="token-50-12" pos="word" morph="none" start_char="6755" end_char="6762">asserted</TOKEN>
<TOKEN id="token-50-13" pos="punct" morph="none" start_char="6763" end_char="6763">,</TOKEN>
<TOKEN id="token-50-14" pos="word" morph="none" start_char="6765" end_char="6767">can</TOKEN>
<TOKEN id="token-50-15" pos="word" morph="none" start_char="6769" end_char="6770">be</TOKEN>
<TOKEN id="token-50-16" pos="word" morph="none" start_char="6772" end_char="6777">traced</TOKEN>
<TOKEN id="token-50-17" pos="word" morph="none" start_char="6779" end_char="6782">back</TOKEN>
<TOKEN id="token-50-18" pos="word" morph="none" start_char="6784" end_char="6785">to</TOKEN>
<TOKEN id="token-50-19" pos="word" morph="none" start_char="6787" end_char="6789">the</TOKEN>
<TOKEN id="token-50-20" pos="word" morph="none" start_char="6791" end_char="6798">decision</TOKEN>
<TOKEN id="token-50-21" pos="word" morph="none" start_char="6800" end_char="6801">of</TOKEN>
<TOKEN id="token-50-22" pos="word" morph="none" start_char="6803" end_char="6809">Collins</TOKEN>
<TOKEN id="token-50-23" pos="word" morph="none" start_char="6811" end_char="6813">and</TOKEN>
<TOKEN id="token-50-24" pos="word" morph="none" start_char="6815" end_char="6819">Fauci</TOKEN>
<TOKEN id="token-50-25" pos="word" morph="none" start_char="6821" end_char="6822">to</TOKEN>
<TOKEN id="token-50-26" pos="word" morph="none" start_char="6824" end_char="6825">go</TOKEN>
<TOKEN id="token-50-27" pos="word" morph="none" start_char="6827" end_char="6831">ahead</TOKEN>
<TOKEN id="token-50-28" pos="word" morph="none" start_char="6833" end_char="6836">with</TOKEN>
<TOKEN id="token-50-29" pos="word" morph="none" start_char="6838" end_char="6840">the</TOKEN>
<TOKEN id="token-50-30" pos="unknown" morph="none" start_char="6842" end_char="6857">gain-of-function</TOKEN>
<TOKEN id="token-50-31" pos="word" morph="none" start_char="6859" end_char="6866">research</TOKEN>
<TOKEN id="token-50-32" pos="word" morph="none" start_char="6868" end_char="6869">as</TOKEN>
<TOKEN id="token-50-33" pos="word" morph="none" start_char="6871" end_char="6871">a</TOKEN>
<TOKEN id="token-50-34" pos="punct" morph="none" start_char="6873" end_char="6873">"</TOKEN>
<TOKEN id="token-50-35" pos="word" morph="none" start_char="6874" end_char="6877">risk</TOKEN>
<TOKEN id="token-50-36" pos="word" morph="none" start_char="6879" end_char="6883">worth</TOKEN>
<TOKEN id="token-50-37" pos="word" morph="none" start_char="6885" end_char="6890">taking</TOKEN>
<TOKEN id="token-50-38" pos="punct" morph="none" start_char="6891" end_char="6891">"</TOKEN>
<TOKEN id="token-50-39" pos="word" morph="none" start_char="6893" end_char="6897">after</TOKEN>
<TOKEN id="token-50-40" pos="word" morph="none" start_char="6899" end_char="6901">the</TOKEN>
<TOKEN id="token-50-41" pos="word" morph="none" start_char="6903" end_char="6907">Obama</TOKEN>
<TOKEN id="token-50-42" pos="word" morph="none" start_char="6909" end_char="6922">administration</TOKEN>
<TOKEN id="token-50-43" pos="word" morph="none" start_char="6924" end_char="6930">stopped</TOKEN>
<TOKEN id="token-50-44" pos="word" morph="none" start_char="6932" end_char="6934">the</TOKEN>
<TOKEN id="token-50-45" pos="word" morph="none" start_char="6936" end_char="6942">funding</TOKEN>
<TOKEN id="token-50-46" pos="punct" morph="none" start_char="6943" end_char="6943">.</TOKEN>
</SEG>
<SEG id="segment-51" start_char="6946" end_char="7019">
<ORIGINAL_TEXT>"Of course Dr. Collins or Dr. Fauci didn't create the pandemic on purpose.</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="punct" morph="none" start_char="6946" end_char="6946">"</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="6947" end_char="6948">Of</TOKEN>
<TOKEN id="token-51-2" pos="word" morph="none" start_char="6950" end_char="6955">course</TOKEN>
<TOKEN id="token-51-3" pos="word" morph="none" start_char="6957" end_char="6958">Dr</TOKEN>
<TOKEN id="token-51-4" pos="punct" morph="none" start_char="6959" end_char="6959">.</TOKEN>
<TOKEN id="token-51-5" pos="word" morph="none" start_char="6961" end_char="6967">Collins</TOKEN>
<TOKEN id="token-51-6" pos="word" morph="none" start_char="6969" end_char="6970">or</TOKEN>
<TOKEN id="token-51-7" pos="word" morph="none" start_char="6972" end_char="6973">Dr</TOKEN>
<TOKEN id="token-51-8" pos="punct" morph="none" start_char="6974" end_char="6974">.</TOKEN>
<TOKEN id="token-51-9" pos="word" morph="none" start_char="6976" end_char="6980">Fauci</TOKEN>
<TOKEN id="token-51-10" pos="word" morph="none" start_char="6982" end_char="6987">didn't</TOKEN>
<TOKEN id="token-51-11" pos="word" morph="none" start_char="6989" end_char="6994">create</TOKEN>
<TOKEN id="token-51-12" pos="word" morph="none" start_char="6996" end_char="6998">the</TOKEN>
<TOKEN id="token-51-13" pos="word" morph="none" start_char="7000" end_char="7007">pandemic</TOKEN>
<TOKEN id="token-51-14" pos="word" morph="none" start_char="7009" end_char="7010">on</TOKEN>
<TOKEN id="token-51-15" pos="word" morph="none" start_char="7012" end_char="7018">purpose</TOKEN>
<TOKEN id="token-51-16" pos="punct" morph="none" start_char="7019" end_char="7019">.</TOKEN>
</SEG>
<SEG id="segment-52" start_char="7021" end_char="7048">
<ORIGINAL_TEXT>That is obviously ludicrous.</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="7021" end_char="7024">That</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="7026" end_char="7027">is</TOKEN>
<TOKEN id="token-52-2" pos="word" morph="none" start_char="7029" end_char="7037">obviously</TOKEN>
<TOKEN id="token-52-3" pos="word" morph="none" start_char="7039" end_char="7047">ludicrous</TOKEN>
<TOKEN id="token-52-4" pos="punct" morph="none" start_char="7048" end_char="7048">.</TOKEN>
</SEG>
<SEG id="segment-53" start_char="7050" end_char="7115">
<ORIGINAL_TEXT>They've dedicated their careers to fighting disease," Hilton said.</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="word" morph="none" start_char="7050" end_char="7056">They've</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="7058" end_char="7066">dedicated</TOKEN>
<TOKEN id="token-53-2" pos="word" morph="none" start_char="7068" end_char="7072">their</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="7074" end_char="7080">careers</TOKEN>
<TOKEN id="token-53-4" pos="word" morph="none" start_char="7082" end_char="7083">to</TOKEN>
<TOKEN id="token-53-5" pos="word" morph="none" start_char="7085" end_char="7092">fighting</TOKEN>
<TOKEN id="token-53-6" pos="word" morph="none" start_char="7094" end_char="7100">disease</TOKEN>
<TOKEN id="token-53-7" pos="punct" morph="none" start_char="7101" end_char="7102">,"</TOKEN>
<TOKEN id="token-53-8" pos="word" morph="none" start_char="7104" end_char="7109">Hilton</TOKEN>
<TOKEN id="token-53-9" pos="word" morph="none" start_char="7111" end_char="7114">said</TOKEN>
<TOKEN id="token-53-10" pos="punct" morph="none" start_char="7115" end_char="7115">.</TOKEN>
</SEG>
<SEG id="segment-54" start_char="7118" end_char="7220">
<ORIGINAL_TEXT>"But there's little doubt that one of their weapons of choice in that fight did lead to this pandemic."</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="punct" morph="none" start_char="7118" end_char="7118">"</TOKEN>
<TOKEN id="token-54-1" pos="word" morph="none" start_char="7119" end_char="7121">But</TOKEN>
<TOKEN id="token-54-2" pos="word" morph="none" start_char="7123" end_char="7129">there's</TOKEN>
<TOKEN id="token-54-3" pos="word" morph="none" start_char="7131" end_char="7136">little</TOKEN>
<TOKEN id="token-54-4" pos="word" morph="none" start_char="7138" end_char="7142">doubt</TOKEN>
<TOKEN id="token-54-5" pos="word" morph="none" start_char="7144" end_char="7147">that</TOKEN>
<TOKEN id="token-54-6" pos="word" morph="none" start_char="7149" end_char="7151">one</TOKEN>
<TOKEN id="token-54-7" pos="word" morph="none" start_char="7153" end_char="7154">of</TOKEN>
<TOKEN id="token-54-8" pos="word" morph="none" start_char="7156" end_char="7160">their</TOKEN>
<TOKEN id="token-54-9" pos="word" morph="none" start_char="7162" end_char="7168">weapons</TOKEN>
<TOKEN id="token-54-10" pos="word" morph="none" start_char="7170" end_char="7171">of</TOKEN>
<TOKEN id="token-54-11" pos="word" morph="none" start_char="7173" end_char="7178">choice</TOKEN>
<TOKEN id="token-54-12" pos="word" morph="none" start_char="7180" end_char="7181">in</TOKEN>
<TOKEN id="token-54-13" pos="word" morph="none" start_char="7183" end_char="7186">that</TOKEN>
<TOKEN id="token-54-14" pos="word" morph="none" start_char="7188" end_char="7192">fight</TOKEN>
<TOKEN id="token-54-15" pos="word" morph="none" start_char="7194" end_char="7196">did</TOKEN>
<TOKEN id="token-54-16" pos="word" morph="none" start_char="7198" end_char="7201">lead</TOKEN>
<TOKEN id="token-54-17" pos="word" morph="none" start_char="7203" end_char="7204">to</TOKEN>
<TOKEN id="token-54-18" pos="word" morph="none" start_char="7206" end_char="7209">this</TOKEN>
<TOKEN id="token-54-19" pos="word" morph="none" start_char="7211" end_char="7218">pandemic</TOKEN>
<TOKEN id="token-54-20" pos="punct" morph="none" start_char="7219" end_char="7220">."</TOKEN>
</SEG>
<SEG id="segment-55" start_char="7223" end_char="7264">
<ORIGINAL_TEXT>And they were warned that it could happen.</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="word" morph="none" start_char="7223" end_char="7225">And</TOKEN>
<TOKEN id="token-55-1" pos="word" morph="none" start_char="7227" end_char="7230">they</TOKEN>
<TOKEN id="token-55-2" pos="word" morph="none" start_char="7232" end_char="7235">were</TOKEN>
<TOKEN id="token-55-3" pos="word" morph="none" start_char="7237" end_char="7242">warned</TOKEN>
<TOKEN id="token-55-4" pos="word" morph="none" start_char="7244" end_char="7247">that</TOKEN>
<TOKEN id="token-55-5" pos="word" morph="none" start_char="7249" end_char="7250">it</TOKEN>
<TOKEN id="token-55-6" pos="word" morph="none" start_char="7252" end_char="7256">could</TOKEN>
<TOKEN id="token-55-7" pos="word" morph="none" start_char="7258" end_char="7263">happen</TOKEN>
<TOKEN id="token-55-8" pos="punct" morph="none" start_char="7264" end_char="7264">.</TOKEN>
</SEG>
<SEG id="segment-56" start_char="7267" end_char="7292">
<ORIGINAL_TEXT>Finding the Achilles' heel</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="7267" end_char="7273">Finding</TOKEN>
<TOKEN id="token-56-1" pos="word" morph="none" start_char="7275" end_char="7277">the</TOKEN>
<TOKEN id="token-56-2" pos="word" morph="none" start_char="7279" end_char="7286">Achilles</TOKEN>
<TOKEN id="token-56-3" pos="punct" morph="none" start_char="7287" end_char="7287">'</TOKEN>
<TOKEN id="token-56-4" pos="word" morph="none" start_char="7289" end_char="7292">heel</TOKEN>
</SEG>
<SEG id="segment-57" start_char="7295" end_char="7481">
<ORIGINAL_TEXT>A Newsweek report in April 2020 confirmed that NAID funded scientists at the Wuhan Institute of Virology and other institutions for work on gain-of-function research on bat coronaviruses.</ORIGINAL_TEXT>
<TOKEN id="token-57-0" pos="word" morph="none" start_char="7295" end_char="7295">A</TOKEN>
<TOKEN id="token-57-1" pos="word" morph="none" start_char="7297" end_char="7304">Newsweek</TOKEN>
<TOKEN id="token-57-2" pos="word" morph="none" start_char="7306" end_char="7311">report</TOKEN>
<TOKEN id="token-57-3" pos="word" morph="none" start_char="7313" end_char="7314">in</TOKEN>
<TOKEN id="token-57-4" pos="word" morph="none" start_char="7316" end_char="7320">April</TOKEN>
<TOKEN id="token-57-5" pos="word" morph="none" start_char="7322" end_char="7325">2020</TOKEN>
<TOKEN id="token-57-6" pos="word" morph="none" start_char="7327" end_char="7335">confirmed</TOKEN>
<TOKEN id="token-57-7" pos="word" morph="none" start_char="7337" end_char="7340">that</TOKEN>
<TOKEN id="token-57-8" pos="word" morph="none" start_char="7342" end_char="7345">NAID</TOKEN>
<TOKEN id="token-57-9" pos="word" morph="none" start_char="7347" end_char="7352">funded</TOKEN>
<TOKEN id="token-57-10" pos="word" morph="none" start_char="7354" end_char="7363">scientists</TOKEN>
<TOKEN id="token-57-11" pos="word" morph="none" start_char="7365" end_char="7366">at</TOKEN>
<TOKEN id="token-57-12" pos="word" morph="none" start_char="7368" end_char="7370">the</TOKEN>
<TOKEN id="token-57-13" pos="word" morph="none" start_char="7372" end_char="7376">Wuhan</TOKEN>
<TOKEN id="token-57-14" pos="word" morph="none" start_char="7378" end_char="7386">Institute</TOKEN>
<TOKEN id="token-57-15" pos="word" morph="none" start_char="7388" end_char="7389">of</TOKEN>
<TOKEN id="token-57-16" pos="word" morph="none" start_char="7391" end_char="7398">Virology</TOKEN>
<TOKEN id="token-57-17" pos="word" morph="none" start_char="7400" end_char="7402">and</TOKEN>
<TOKEN id="token-57-18" pos="word" morph="none" start_char="7404" end_char="7408">other</TOKEN>
<TOKEN id="token-57-19" pos="word" morph="none" start_char="7410" end_char="7421">institutions</TOKEN>
<TOKEN id="token-57-20" pos="word" morph="none" start_char="7423" end_char="7425">for</TOKEN>
<TOKEN id="token-57-21" pos="word" morph="none" start_char="7427" end_char="7430">work</TOKEN>
<TOKEN id="token-57-22" pos="word" morph="none" start_char="7432" end_char="7433">on</TOKEN>
<TOKEN id="token-57-23" pos="unknown" morph="none" start_char="7435" end_char="7450">gain-of-function</TOKEN>
<TOKEN id="token-57-24" pos="word" morph="none" start_char="7452" end_char="7459">research</TOKEN>
<TOKEN id="token-57-25" pos="word" morph="none" start_char="7461" end_char="7462">on</TOKEN>
<TOKEN id="token-57-26" pos="word" morph="none" start_char="7464" end_char="7466">bat</TOKEN>
<TOKEN id="token-57-27" pos="word" morph="none" start_char="7468" end_char="7480">coronaviruses</TOKEN>
<TOKEN id="token-57-28" pos="punct" morph="none" start_char="7481" end_char="7481">.</TOKEN>
</SEG>
<SEG id="segment-58" start_char="7483" end_char="7705">
<ORIGINAL_TEXT>In 2011, Fauci played an important role in promoting the work, arguing the research was worth the risk, because it could enable scientists to prepare treatments and vaccines in advance if a pandemic occurred, Newsweek said.</ORIGINAL_TEXT>
<TOKEN id="token-58-0" pos="word" morph="none" start_char="7483" end_char="7484">In</TOKEN>
<TOKEN id="token-58-1" pos="word" morph="none" start_char="7486" end_char="7489">2011</TOKEN>
<TOKEN id="token-58-2" pos="punct" morph="none" start_char="7490" end_char="7490">,</TOKEN>
<TOKEN id="token-58-3" pos="word" morph="none" start_char="7492" end_char="7496">Fauci</TOKEN>
<TOKEN id="token-58-4" pos="word" morph="none" start_char="7498" end_char="7503">played</TOKEN>
<TOKEN id="token-58-5" pos="word" morph="none" start_char="7505" end_char="7506">an</TOKEN>
<TOKEN id="token-58-6" pos="word" morph="none" start_char="7508" end_char="7516">important</TOKEN>
<TOKEN id="token-58-7" pos="word" morph="none" start_char="7518" end_char="7521">role</TOKEN>
<TOKEN id="token-58-8" pos="word" morph="none" start_char="7523" end_char="7524">in</TOKEN>
<TOKEN id="token-58-9" pos="word" morph="none" start_char="7526" end_char="7534">promoting</TOKEN>
<TOKEN id="token-58-10" pos="word" morph="none" start_char="7536" end_char="7538">the</TOKEN>
<TOKEN id="token-58-11" pos="word" morph="none" start_char="7540" end_char="7543">work</TOKEN>
<TOKEN id="token-58-12" pos="punct" morph="none" start_char="7544" end_char="7544">,</TOKEN>
<TOKEN id="token-58-13" pos="word" morph="none" start_char="7546" end_char="7552">arguing</TOKEN>
<TOKEN id="token-58-14" pos="word" morph="none" start_char="7554" end_char="7556">the</TOKEN>
<TOKEN id="token-58-15" pos="word" morph="none" start_char="7558" end_char="7565">research</TOKEN>
<TOKEN id="token-58-16" pos="word" morph="none" start_char="7567" end_char="7569">was</TOKEN>
<TOKEN id="token-58-17" pos="word" morph="none" start_char="7571" end_char="7575">worth</TOKEN>
<TOKEN id="token-58-18" pos="word" morph="none" start_char="7577" end_char="7579">the</TOKEN>
<TOKEN id="token-58-19" pos="word" morph="none" start_char="7581" end_char="7584">risk</TOKEN>
<TOKEN id="token-58-20" pos="punct" morph="none" start_char="7585" end_char="7585">,</TOKEN>
<TOKEN id="token-58-21" pos="word" morph="none" start_char="7587" end_char="7593">because</TOKEN>
<TOKEN id="token-58-22" pos="word" morph="none" start_char="7595" end_char="7596">it</TOKEN>
<TOKEN id="token-58-23" pos="word" morph="none" start_char="7598" end_char="7602">could</TOKEN>
<TOKEN id="token-58-24" pos="word" morph="none" start_char="7604" end_char="7609">enable</TOKEN>
<TOKEN id="token-58-25" pos="word" morph="none" start_char="7611" end_char="7620">scientists</TOKEN>
<TOKEN id="token-58-26" pos="word" morph="none" start_char="7622" end_char="7623">to</TOKEN>
<TOKEN id="token-58-27" pos="word" morph="none" start_char="7625" end_char="7631">prepare</TOKEN>
<TOKEN id="token-58-28" pos="word" morph="none" start_char="7633" end_char="7642">treatments</TOKEN>
<TOKEN id="token-58-29" pos="word" morph="none" start_char="7644" end_char="7646">and</TOKEN>
<TOKEN id="token-58-30" pos="word" morph="none" start_char="7648" end_char="7655">vaccines</TOKEN>
<TOKEN id="token-58-31" pos="word" morph="none" start_char="7657" end_char="7658">in</TOKEN>
<TOKEN id="token-58-32" pos="word" morph="none" start_char="7660" end_char="7666">advance</TOKEN>
<TOKEN id="token-58-33" pos="word" morph="none" start_char="7668" end_char="7669">if</TOKEN>
<TOKEN id="token-58-34" pos="word" morph="none" start_char="7671" end_char="7671">a</TOKEN>
<TOKEN id="token-58-35" pos="word" morph="none" start_char="7673" end_char="7680">pandemic</TOKEN>
<TOKEN id="token-58-36" pos="word" morph="none" start_char="7682" end_char="7689">occurred</TOKEN>
<TOKEN id="token-58-37" pos="punct" morph="none" start_char="7690" end_char="7690">,</TOKEN>
<TOKEN id="token-58-38" pos="word" morph="none" start_char="7692" end_char="7699">Newsweek</TOKEN>
<TOKEN id="token-58-39" pos="word" morph="none" start_char="7701" end_char="7704">said</TOKEN>
<TOKEN id="token-58-40" pos="punct" morph="none" start_char="7705" end_char="7705">.</TOKEN>
</SEG>
<SEG id="segment-59" start_char="7708" end_char="8028">
<ORIGINAL_TEXT>Fauci and two co-authors defended the work in the Washington Post in December 2011, arguing that "determining the molecular Achilles' heel of these viruses can allow scientists to identify novel antiviral drug targets that could be used to prevent infection in those at risk or to better treat those who become infected."</ORIGINAL_TEXT>
<TOKEN id="token-59-0" pos="word" morph="none" start_char="7708" end_char="7712">Fauci</TOKEN>
<TOKEN id="token-59-1" pos="word" morph="none" start_char="7714" end_char="7716">and</TOKEN>
<TOKEN id="token-59-2" pos="word" morph="none" start_char="7718" end_char="7720">two</TOKEN>
<TOKEN id="token-59-3" pos="unknown" morph="none" start_char="7722" end_char="7731">co-authors</TOKEN>
<TOKEN id="token-59-4" pos="word" morph="none" start_char="7733" end_char="7740">defended</TOKEN>
<TOKEN id="token-59-5" pos="word" morph="none" start_char="7742" end_char="7744">the</TOKEN>
<TOKEN id="token-59-6" pos="word" morph="none" start_char="7746" end_char="7749">work</TOKEN>
<TOKEN id="token-59-7" pos="word" morph="none" start_char="7751" end_char="7752">in</TOKEN>
<TOKEN id="token-59-8" pos="word" morph="none" start_char="7754" end_char="7756">the</TOKEN>
<TOKEN id="token-59-9" pos="word" morph="none" start_char="7758" end_char="7767">Washington</TOKEN>
<TOKEN id="token-59-10" pos="word" morph="none" start_char="7769" end_char="7772">Post</TOKEN>
<TOKEN id="token-59-11" pos="word" morph="none" start_char="7774" end_char="7775">in</TOKEN>
<TOKEN id="token-59-12" pos="word" morph="none" start_char="7777" end_char="7784">December</TOKEN>
<TOKEN id="token-59-13" pos="word" morph="none" start_char="7786" end_char="7789">2011</TOKEN>
<TOKEN id="token-59-14" pos="punct" morph="none" start_char="7790" end_char="7790">,</TOKEN>
<TOKEN id="token-59-15" pos="word" morph="none" start_char="7792" end_char="7798">arguing</TOKEN>
<TOKEN id="token-59-16" pos="word" morph="none" start_char="7800" end_char="7803">that</TOKEN>
<TOKEN id="token-59-17" pos="punct" morph="none" start_char="7805" end_char="7805">"</TOKEN>
<TOKEN id="token-59-18" pos="word" morph="none" start_char="7806" end_char="7816">determining</TOKEN>
<TOKEN id="token-59-19" pos="word" morph="none" start_char="7818" end_char="7820">the</TOKEN>
<TOKEN id="token-59-20" pos="word" morph="none" start_char="7822" end_char="7830">molecular</TOKEN>
<TOKEN id="token-59-21" pos="word" morph="none" start_char="7832" end_char="7839">Achilles</TOKEN>
<TOKEN id="token-59-22" pos="punct" morph="none" start_char="7840" end_char="7840">'</TOKEN>
<TOKEN id="token-59-23" pos="word" morph="none" start_char="7842" end_char="7845">heel</TOKEN>
<TOKEN id="token-59-24" pos="word" morph="none" start_char="7847" end_char="7848">of</TOKEN>
<TOKEN id="token-59-25" pos="word" morph="none" start_char="7850" end_char="7854">these</TOKEN>
<TOKEN id="token-59-26" pos="word" morph="none" start_char="7856" end_char="7862">viruses</TOKEN>
<TOKEN id="token-59-27" pos="word" morph="none" start_char="7864" end_char="7866">can</TOKEN>
<TOKEN id="token-59-28" pos="word" morph="none" start_char="7868" end_char="7872">allow</TOKEN>
<TOKEN id="token-59-29" pos="word" morph="none" start_char="7874" end_char="7883">scientists</TOKEN>
<TOKEN id="token-59-30" pos="word" morph="none" start_char="7885" end_char="7886">to</TOKEN>
<TOKEN id="token-59-31" pos="word" morph="none" start_char="7888" end_char="7895">identify</TOKEN>
<TOKEN id="token-59-32" pos="word" morph="none" start_char="7897" end_char="7901">novel</TOKEN>
<TOKEN id="token-59-33" pos="word" morph="none" start_char="7903" end_char="7911">antiviral</TOKEN>
<TOKEN id="token-59-34" pos="word" morph="none" start_char="7913" end_char="7916">drug</TOKEN>
<TOKEN id="token-59-35" pos="word" morph="none" start_char="7918" end_char="7924">targets</TOKEN>
<TOKEN id="token-59-36" pos="word" morph="none" start_char="7926" end_char="7929">that</TOKEN>
<TOKEN id="token-59-37" pos="word" morph="none" start_char="7931" end_char="7935">could</TOKEN>
<TOKEN id="token-59-38" pos="word" morph="none" start_char="7937" end_char="7938">be</TOKEN>
<TOKEN id="token-59-39" pos="word" morph="none" start_char="7940" end_char="7943">used</TOKEN>
<TOKEN id="token-59-40" pos="word" morph="none" start_char="7945" end_char="7946">to</TOKEN>
<TOKEN id="token-59-41" pos="word" morph="none" start_char="7948" end_char="7954">prevent</TOKEN>
<TOKEN id="token-59-42" pos="word" morph="none" start_char="7956" end_char="7964">infection</TOKEN>
<TOKEN id="token-59-43" pos="word" morph="none" start_char="7966" end_char="7967">in</TOKEN>
<TOKEN id="token-59-44" pos="word" morph="none" start_char="7969" end_char="7973">those</TOKEN>
<TOKEN id="token-59-45" pos="word" morph="none" start_char="7975" end_char="7976">at</TOKEN>
<TOKEN id="token-59-46" pos="word" morph="none" start_char="7978" end_char="7981">risk</TOKEN>
<TOKEN id="token-59-47" pos="word" morph="none" start_char="7983" end_char="7984">or</TOKEN>
<TOKEN id="token-59-48" pos="word" morph="none" start_char="7986" end_char="7987">to</TOKEN>
<TOKEN id="token-59-49" pos="word" morph="none" start_char="7989" end_char="7994">better</TOKEN>
<TOKEN id="token-59-50" pos="word" morph="none" start_char="7996" end_char="8000">treat</TOKEN>
<TOKEN id="token-59-51" pos="word" morph="none" start_char="8002" end_char="8006">those</TOKEN>
<TOKEN id="token-59-52" pos="word" morph="none" start_char="8008" end_char="8010">who</TOKEN>
<TOKEN id="token-59-53" pos="word" morph="none" start_char="8012" end_char="8017">become</TOKEN>
<TOKEN id="token-59-54" pos="word" morph="none" start_char="8019" end_char="8026">infected</TOKEN>
<TOKEN id="token-59-55" pos="punct" morph="none" start_char="8027" end_char="8028">."</TOKEN>
</SEG>
<SEG id="segment-60" start_char="8031" end_char="8181">
<ORIGINAL_TEXT>The work was halted by the Obama administration in 2014 under pressure from scientists but resumed in December 2017 when the NIH lifted the moratorium.</ORIGINAL_TEXT>
<TOKEN id="token-60-0" pos="word" morph="none" start_char="8031" end_char="8033">The</TOKEN>
<TOKEN id="token-60-1" pos="word" morph="none" start_char="8035" end_char="8038">work</TOKEN>
<TOKEN id="token-60-2" pos="word" morph="none" start_char="8040" end_char="8042">was</TOKEN>
<TOKEN id="token-60-3" pos="word" morph="none" start_char="8044" end_char="8049">halted</TOKEN>
<TOKEN id="token-60-4" pos="word" morph="none" start_char="8051" end_char="8052">by</TOKEN>
<TOKEN id="token-60-5" pos="word" morph="none" start_char="8054" end_char="8056">the</TOKEN>
<TOKEN id="token-60-6" pos="word" morph="none" start_char="8058" end_char="8062">Obama</TOKEN>
<TOKEN id="token-60-7" pos="word" morph="none" start_char="8064" end_char="8077">administration</TOKEN>
<TOKEN id="token-60-8" pos="word" morph="none" start_char="8079" end_char="8080">in</TOKEN>
<TOKEN id="token-60-9" pos="word" morph="none" start_char="8082" end_char="8085">2014</TOKEN>
<TOKEN id="token-60-10" pos="word" morph="none" start_char="8087" end_char="8091">under</TOKEN>
<TOKEN id="token-60-11" pos="word" morph="none" start_char="8093" end_char="8100">pressure</TOKEN>
<TOKEN id="token-60-12" pos="word" morph="none" start_char="8102" end_char="8105">from</TOKEN>
<TOKEN id="token-60-13" pos="word" morph="none" start_char="8107" end_char="8116">scientists</TOKEN>
<TOKEN id="token-60-14" pos="word" morph="none" start_char="8118" end_char="8120">but</TOKEN>
<TOKEN id="token-60-15" pos="word" morph="none" start_char="8122" end_char="8128">resumed</TOKEN>
<TOKEN id="token-60-16" pos="word" morph="none" start_char="8130" end_char="8131">in</TOKEN>
<TOKEN id="token-60-17" pos="word" morph="none" start_char="8133" end_char="8140">December</TOKEN>
<TOKEN id="token-60-18" pos="word" morph="none" start_char="8142" end_char="8145">2017</TOKEN>
<TOKEN id="token-60-19" pos="word" morph="none" start_char="8147" end_char="8150">when</TOKEN>
<TOKEN id="token-60-20" pos="word" morph="none" start_char="8152" end_char="8154">the</TOKEN>
<TOKEN id="token-60-21" pos="word" morph="none" start_char="8156" end_char="8158">NIH</TOKEN>
<TOKEN id="token-60-22" pos="word" morph="none" start_char="8160" end_char="8165">lifted</TOKEN>
<TOKEN id="token-60-23" pos="word" morph="none" start_char="8167" end_char="8169">the</TOKEN>
<TOKEN id="token-60-24" pos="word" morph="none" start_char="8171" end_char="8180">moratorium</TOKEN>
<TOKEN id="token-60-25" pos="punct" morph="none" start_char="8181" end_char="8181">.</TOKEN>
</SEG>
<SEG id="segment-61" start_char="8183" end_char="8312">
<ORIGINAL_TEXT>Going forward, scientists had to get approval from a panel of experts who would determine whether or not the risks were justified.</ORIGINAL_TEXT>
<TOKEN id="token-61-0" pos="word" morph="none" start_char="8183" end_char="8187">Going</TOKEN>
<TOKEN id="token-61-1" pos="word" morph="none" start_char="8189" end_char="8195">forward</TOKEN>
<TOKEN id="token-61-2" pos="punct" morph="none" start_char="8196" end_char="8196">,</TOKEN>
<TOKEN id="token-61-3" pos="word" morph="none" start_char="8198" end_char="8207">scientists</TOKEN>
<TOKEN id="token-61-4" pos="word" morph="none" start_char="8209" end_char="8211">had</TOKEN>
<TOKEN id="token-61-5" pos="word" morph="none" start_char="8213" end_char="8214">to</TOKEN>
<TOKEN id="token-61-6" pos="word" morph="none" start_char="8216" end_char="8218">get</TOKEN>
<TOKEN id="token-61-7" pos="word" morph="none" start_char="8220" end_char="8227">approval</TOKEN>
<TOKEN id="token-61-8" pos="word" morph="none" start_char="8229" end_char="8232">from</TOKEN>
<TOKEN id="token-61-9" pos="word" morph="none" start_char="8234" end_char="8234">a</TOKEN>
<TOKEN id="token-61-10" pos="word" morph="none" start_char="8236" end_char="8240">panel</TOKEN>
<TOKEN id="token-61-11" pos="word" morph="none" start_char="8242" end_char="8243">of</TOKEN>
<TOKEN id="token-61-12" pos="word" morph="none" start_char="8245" end_char="8251">experts</TOKEN>
<TOKEN id="token-61-13" pos="word" morph="none" start_char="8253" end_char="8255">who</TOKEN>
<TOKEN id="token-61-14" pos="word" morph="none" start_char="8257" end_char="8261">would</TOKEN>
<TOKEN id="token-61-15" pos="word" morph="none" start_char="8263" end_char="8271">determine</TOKEN>
<TOKEN id="token-61-16" pos="word" morph="none" start_char="8273" end_char="8279">whether</TOKEN>
<TOKEN id="token-61-17" pos="word" morph="none" start_char="8281" end_char="8282">or</TOKEN>
<TOKEN id="token-61-18" pos="word" morph="none" start_char="8284" end_char="8286">not</TOKEN>
<TOKEN id="token-61-19" pos="word" morph="none" start_char="8288" end_char="8290">the</TOKEN>
<TOKEN id="token-61-20" pos="word" morph="none" start_char="8292" end_char="8296">risks</TOKEN>
<TOKEN id="token-61-21" pos="word" morph="none" start_char="8298" end_char="8301">were</TOKEN>
<TOKEN id="token-61-22" pos="word" morph="none" start_char="8303" end_char="8311">justified</TOKEN>
<TOKEN id="token-61-23" pos="punct" morph="none" start_char="8312" end_char="8312">.</TOKEN>
</SEG>
<SEG id="segment-62" start_char="8315" end_char="8543">
<ORIGINAL_TEXT>The research was conducted in secret until, in early 2019, a reporter for Science magazine discovered that the NIH had approved two gain-of-function projects, drawing rebuke from scientists in an editorial in the Washington Post.</ORIGINAL_TEXT>
<TOKEN id="token-62-0" pos="word" morph="none" start_char="8315" end_char="8317">The</TOKEN>
<TOKEN id="token-62-1" pos="word" morph="none" start_char="8319" end_char="8326">research</TOKEN>
<TOKEN id="token-62-2" pos="word" morph="none" start_char="8328" end_char="8330">was</TOKEN>
<TOKEN id="token-62-3" pos="word" morph="none" start_char="8332" end_char="8340">conducted</TOKEN>
<TOKEN id="token-62-4" pos="word" morph="none" start_char="8342" end_char="8343">in</TOKEN>
<TOKEN id="token-62-5" pos="word" morph="none" start_char="8345" end_char="8350">secret</TOKEN>
<TOKEN id="token-62-6" pos="word" morph="none" start_char="8352" end_char="8356">until</TOKEN>
<TOKEN id="token-62-7" pos="punct" morph="none" start_char="8357" end_char="8357">,</TOKEN>
<TOKEN id="token-62-8" pos="word" morph="none" start_char="8359" end_char="8360">in</TOKEN>
<TOKEN id="token-62-9" pos="word" morph="none" start_char="8362" end_char="8366">early</TOKEN>
<TOKEN id="token-62-10" pos="word" morph="none" start_char="8368" end_char="8371">2019</TOKEN>
<TOKEN id="token-62-11" pos="punct" morph="none" start_char="8372" end_char="8372">,</TOKEN>
<TOKEN id="token-62-12" pos="word" morph="none" start_char="8374" end_char="8374">a</TOKEN>
<TOKEN id="token-62-13" pos="word" morph="none" start_char="8376" end_char="8383">reporter</TOKEN>
<TOKEN id="token-62-14" pos="word" morph="none" start_char="8385" end_char="8387">for</TOKEN>
<TOKEN id="token-62-15" pos="word" morph="none" start_char="8389" end_char="8395">Science</TOKEN>
<TOKEN id="token-62-16" pos="word" morph="none" start_char="8397" end_char="8404">magazine</TOKEN>
<TOKEN id="token-62-17" pos="word" morph="none" start_char="8406" end_char="8415">discovered</TOKEN>
<TOKEN id="token-62-18" pos="word" morph="none" start_char="8417" end_char="8420">that</TOKEN>
<TOKEN id="token-62-19" pos="word" morph="none" start_char="8422" end_char="8424">the</TOKEN>
<TOKEN id="token-62-20" pos="word" morph="none" start_char="8426" end_char="8428">NIH</TOKEN>
<TOKEN id="token-62-21" pos="word" morph="none" start_char="8430" end_char="8432">had</TOKEN>
<TOKEN id="token-62-22" pos="word" morph="none" start_char="8434" end_char="8441">approved</TOKEN>
<TOKEN id="token-62-23" pos="word" morph="none" start_char="8443" end_char="8445">two</TOKEN>
<TOKEN id="token-62-24" pos="unknown" morph="none" start_char="8447" end_char="8462">gain-of-function</TOKEN>
<TOKEN id="token-62-25" pos="word" morph="none" start_char="8464" end_char="8471">projects</TOKEN>
<TOKEN id="token-62-26" pos="punct" morph="none" start_char="8472" end_char="8472">,</TOKEN>
<TOKEN id="token-62-27" pos="word" morph="none" start_char="8474" end_char="8480">drawing</TOKEN>
<TOKEN id="token-62-28" pos="word" morph="none" start_char="8482" end_char="8487">rebuke</TOKEN>
<TOKEN id="token-62-29" pos="word" morph="none" start_char="8489" end_char="8492">from</TOKEN>
<TOKEN id="token-62-30" pos="word" morph="none" start_char="8494" end_char="8503">scientists</TOKEN>
<TOKEN id="token-62-31" pos="word" morph="none" start_char="8505" end_char="8506">in</TOKEN>
<TOKEN id="token-62-32" pos="word" morph="none" start_char="8508" end_char="8509">an</TOKEN>
<TOKEN id="token-62-33" pos="word" morph="none" start_char="8511" end_char="8519">editorial</TOKEN>
<TOKEN id="token-62-34" pos="word" morph="none" start_char="8521" end_char="8522">in</TOKEN>
<TOKEN id="token-62-35" pos="word" morph="none" start_char="8524" end_char="8526">the</TOKEN>
<TOKEN id="token-62-36" pos="word" morph="none" start_char="8528" end_char="8537">Washington</TOKEN>
<TOKEN id="token-62-37" pos="word" morph="none" start_char="8539" end_char="8542">Post</TOKEN>
<TOKEN id="token-62-38" pos="punct" morph="none" start_char="8543" end_char="8543">.</TOKEN>
</SEG>
<SEG id="segment-63" start_char="8546" end_char="8706">
<ORIGINAL_TEXT>"We have serious doubts about whether these experiments should be conducted at all," wrote Tom Inglesby of Johns Hopkins University and Marc Lipsitch of Harvard.</ORIGINAL_TEXT>
<TOKEN id="token-63-0" pos="punct" morph="none" start_char="8546" end_char="8546">"</TOKEN>
<TOKEN id="token-63-1" pos="word" morph="none" start_char="8547" end_char="8548">We</TOKEN>
<TOKEN id="token-63-2" pos="word" morph="none" start_char="8550" end_char="8553">have</TOKEN>
<TOKEN id="token-63-3" pos="word" morph="none" start_char="8555" end_char="8561">serious</TOKEN>
<TOKEN id="token-63-4" pos="word" morph="none" start_char="8563" end_char="8568">doubts</TOKEN>
<TOKEN id="token-63-5" pos="word" morph="none" start_char="8570" end_char="8574">about</TOKEN>
<TOKEN id="token-63-6" pos="word" morph="none" start_char="8576" end_char="8582">whether</TOKEN>
<TOKEN id="token-63-7" pos="word" morph="none" start_char="8584" end_char="8588">these</TOKEN>
<TOKEN id="token-63-8" pos="word" morph="none" start_char="8590" end_char="8600">experiments</TOKEN>
<TOKEN id="token-63-9" pos="word" morph="none" start_char="8602" end_char="8607">should</TOKEN>
<TOKEN id="token-63-10" pos="word" morph="none" start_char="8609" end_char="8610">be</TOKEN>
<TOKEN id="token-63-11" pos="word" morph="none" start_char="8612" end_char="8620">conducted</TOKEN>
<TOKEN id="token-63-12" pos="word" morph="none" start_char="8622" end_char="8623">at</TOKEN>
<TOKEN id="token-63-13" pos="word" morph="none" start_char="8625" end_char="8627">all</TOKEN>
<TOKEN id="token-63-14" pos="punct" morph="none" start_char="8628" end_char="8629">,"</TOKEN>
<TOKEN id="token-63-15" pos="word" morph="none" start_char="8631" end_char="8635">wrote</TOKEN>
<TOKEN id="token-63-16" pos="word" morph="none" start_char="8637" end_char="8639">Tom</TOKEN>
<TOKEN id="token-63-17" pos="word" morph="none" start_char="8641" end_char="8648">Inglesby</TOKEN>
<TOKEN id="token-63-18" pos="word" morph="none" start_char="8650" end_char="8651">of</TOKEN>
<TOKEN id="token-63-19" pos="word" morph="none" start_char="8653" end_char="8657">Johns</TOKEN>
<TOKEN id="token-63-20" pos="word" morph="none" start_char="8659" end_char="8665">Hopkins</TOKEN>
<TOKEN id="token-63-21" pos="word" morph="none" start_char="8667" end_char="8676">University</TOKEN>
<TOKEN id="token-63-22" pos="word" morph="none" start_char="8678" end_char="8680">and</TOKEN>
<TOKEN id="token-63-23" pos="word" morph="none" start_char="8682" end_char="8685">Marc</TOKEN>
<TOKEN id="token-63-24" pos="word" morph="none" start_char="8687" end_char="8694">Lipsitch</TOKEN>
<TOKEN id="token-63-25" pos="word" morph="none" start_char="8696" end_char="8697">of</TOKEN>
<TOKEN id="token-63-26" pos="word" morph="none" start_char="8699" end_char="8705">Harvard</TOKEN>
<TOKEN id="token-63-27" pos="punct" morph="none" start_char="8706" end_char="8706">.</TOKEN>
</SEG>
<SEG id="segment-64" start_char="8708" end_char="8905">
<ORIGINAL_TEXT>"[W]ith deliberations kept behind closed doors, none of us will have the opportunity to understand how the government arrived at these decisions or to judge the rigor and integrity of that process."</ORIGINAL_TEXT>
<TOKEN id="token-64-0" pos="punct" morph="none" start_char="8708" end_char="8709">"[</TOKEN>
<TOKEN id="token-64-1" pos="unknown" morph="none" start_char="8710" end_char="8714">W]ith</TOKEN>
<TOKEN id="token-64-2" pos="word" morph="none" start_char="8716" end_char="8728">deliberations</TOKEN>
<TOKEN id="token-64-3" pos="word" morph="none" start_char="8730" end_char="8733">kept</TOKEN>
<TOKEN id="token-64-4" pos="word" morph="none" start_char="8735" end_char="8740">behind</TOKEN>
<TOKEN id="token-64-5" pos="word" morph="none" start_char="8742" end_char="8747">closed</TOKEN>
<TOKEN id="token-64-6" pos="word" morph="none" start_char="8749" end_char="8753">doors</TOKEN>
<TOKEN id="token-64-7" pos="punct" morph="none" start_char="8754" end_char="8754">,</TOKEN>
<TOKEN id="token-64-8" pos="word" morph="none" start_char="8756" end_char="8759">none</TOKEN>
<TOKEN id="token-64-9" pos="word" morph="none" start_char="8761" end_char="8762">of</TOKEN>
<TOKEN id="token-64-10" pos="word" morph="none" start_char="8764" end_char="8765">us</TOKEN>
<TOKEN id="token-64-11" pos="word" morph="none" start_char="8767" end_char="8770">will</TOKEN>
<TOKEN id="token-64-12" pos="word" morph="none" start_char="8772" end_char="8775">have</TOKEN>
<TOKEN id="token-64-13" pos="word" morph="none" start_char="8777" end_char="8779">the</TOKEN>
<TOKEN id="token-64-14" pos="word" morph="none" start_char="8781" end_char="8791">opportunity</TOKEN>
<TOKEN id="token-64-15" pos="word" morph="none" start_char="8793" end_char="8794">to</TOKEN>
<TOKEN id="token-64-16" pos="word" morph="none" start_char="8796" end_char="8805">understand</TOKEN>
<TOKEN id="token-64-17" pos="word" morph="none" start_char="8807" end_char="8809">how</TOKEN>
<TOKEN id="token-64-18" pos="word" morph="none" start_char="8811" end_char="8813">the</TOKEN>
<TOKEN id="token-64-19" pos="word" morph="none" start_char="8815" end_char="8824">government</TOKEN>
<TOKEN id="token-64-20" pos="word" morph="none" start_char="8826" end_char="8832">arrived</TOKEN>
<TOKEN id="token-64-21" pos="word" morph="none" start_char="8834" end_char="8835">at</TOKEN>
<TOKEN id="token-64-22" pos="word" morph="none" start_char="8837" end_char="8841">these</TOKEN>
<TOKEN id="token-64-23" pos="word" morph="none" start_char="8843" end_char="8851">decisions</TOKEN>
<TOKEN id="token-64-24" pos="word" morph="none" start_char="8853" end_char="8854">or</TOKEN>
<TOKEN id="token-64-25" pos="word" morph="none" start_char="8856" end_char="8857">to</TOKEN>
<TOKEN id="token-64-26" pos="word" morph="none" start_char="8859" end_char="8863">judge</TOKEN>
<TOKEN id="token-64-27" pos="word" morph="none" start_char="8865" end_char="8867">the</TOKEN>
<TOKEN id="token-64-28" pos="word" morph="none" start_char="8869" end_char="8873">rigor</TOKEN>
<TOKEN id="token-64-29" pos="word" morph="none" start_char="8875" end_char="8877">and</TOKEN>
<TOKEN id="token-64-30" pos="word" morph="none" start_char="8879" end_char="8887">integrity</TOKEN>
<TOKEN id="token-64-31" pos="word" morph="none" start_char="8889" end_char="8890">of</TOKEN>
<TOKEN id="token-64-32" pos="word" morph="none" start_char="8892" end_char="8895">that</TOKEN>
<TOKEN id="token-64-33" pos="word" morph="none" start_char="8897" end_char="8903">process</TOKEN>
<TOKEN id="token-64-34" pos="punct" morph="none" start_char="8904" end_char="8905">."</TOKEN>
</SEG>
<SEG id="segment-65" start_char="8908" end_char="8928">
<ORIGINAL_TEXT>See Hilton's segment:</ORIGINAL_TEXT>
<TOKEN id="token-65-0" pos="word" morph="none" start_char="8908" end_char="8910">See</TOKEN>
<TOKEN id="token-65-1" pos="word" morph="none" start_char="8912" end_char="8919">Hilton's</TOKEN>
<TOKEN id="token-65-2" pos="word" morph="none" start_char="8921" end_char="8927">segment</TOKEN>
<TOKEN id="token-65-3" pos="punct" morph="none" start_char="8928" end_char="8928">:</TOKEN>
</SEG>
<SEG id="segment-66" start_char="8932" end_char="8965">
<ORIGINAL_TEXT>Wuhan lab the 'most likely' source</ORIGINAL_TEXT>
<TOKEN id="token-66-0" pos="word" morph="none" start_char="8932" end_char="8936">Wuhan</TOKEN>
<TOKEN id="token-66-1" pos="word" morph="none" start_char="8938" end_char="8940">lab</TOKEN>
<TOKEN id="token-66-2" pos="word" morph="none" start_char="8942" end_char="8944">the</TOKEN>
<TOKEN id="token-66-3" pos="punct" morph="none" start_char="8946" end_char="8946">'</TOKEN>
<TOKEN id="token-66-4" pos="word" morph="none" start_char="8947" end_char="8950">most</TOKEN>
<TOKEN id="token-66-5" pos="word" morph="none" start_char="8952" end_char="8957">likely</TOKEN>
<TOKEN id="token-66-6" pos="punct" morph="none" start_char="8958" end_char="8958">'</TOKEN>
<TOKEN id="token-66-7" pos="word" morph="none" start_char="8960" end_char="8965">source</TOKEN>
</SEG>
<SEG id="segment-67" start_char="8968" end_char="9118">
<ORIGINAL_TEXT>In April 2020, a U.S. government report concluded the Wuhan lab was the "most likely" source of COVID-19, finding other explanations "highly unlikely."</ORIGINAL_TEXT>
<TOKEN id="token-67-0" pos="word" morph="none" start_char="8968" end_char="8969">In</TOKEN>
<TOKEN id="token-67-1" pos="word" morph="none" start_char="8971" end_char="8975">April</TOKEN>
<TOKEN id="token-67-2" pos="word" morph="none" start_char="8977" end_char="8980">2020</TOKEN>
<TOKEN id="token-67-3" pos="punct" morph="none" start_char="8981" end_char="8981">,</TOKEN>
<TOKEN id="token-67-4" pos="word" morph="none" start_char="8983" end_char="8983">a</TOKEN>
<TOKEN id="token-67-5" pos="unknown" morph="none" start_char="8985" end_char="8987">U.S</TOKEN>
<TOKEN id="token-67-6" pos="punct" morph="none" start_char="8988" end_char="8988">.</TOKEN>
<TOKEN id="token-67-7" pos="word" morph="none" start_char="8990" end_char="8999">government</TOKEN>
<TOKEN id="token-67-8" pos="word" morph="none" start_char="9001" end_char="9006">report</TOKEN>
<TOKEN id="token-67-9" pos="word" morph="none" start_char="9008" end_char="9016">concluded</TOKEN>
<TOKEN id="token-67-10" pos="word" morph="none" start_char="9018" end_char="9020">the</TOKEN>
<TOKEN id="token-67-11" pos="word" morph="none" start_char="9022" end_char="9026">Wuhan</TOKEN>
<TOKEN id="token-67-12" pos="word" morph="none" start_char="9028" end_char="9030">lab</TOKEN>
<TOKEN id="token-67-13" pos="word" morph="none" start_char="9032" end_char="9034">was</TOKEN>
<TOKEN id="token-67-14" pos="word" morph="none" start_char="9036" end_char="9038">the</TOKEN>
<TOKEN id="token-67-15" pos="punct" morph="none" start_char="9040" end_char="9040">"</TOKEN>
<TOKEN id="token-67-16" pos="word" morph="none" start_char="9041" end_char="9044">most</TOKEN>
<TOKEN id="token-67-17" pos="word" morph="none" start_char="9046" end_char="9051">likely</TOKEN>
<TOKEN id="token-67-18" pos="punct" morph="none" start_char="9052" end_char="9052">"</TOKEN>
<TOKEN id="token-67-19" pos="word" morph="none" start_char="9054" end_char="9059">source</TOKEN>
<TOKEN id="token-67-20" pos="word" morph="none" start_char="9061" end_char="9062">of</TOKEN>
<TOKEN id="token-67-21" pos="unknown" morph="none" start_char="9064" end_char="9071">COVID-19</TOKEN>
<TOKEN id="token-67-22" pos="punct" morph="none" start_char="9072" end_char="9072">,</TOKEN>
<TOKEN id="token-67-23" pos="word" morph="none" start_char="9074" end_char="9080">finding</TOKEN>
<TOKEN id="token-67-24" pos="word" morph="none" start_char="9082" end_char="9086">other</TOKEN>
<TOKEN id="token-67-25" pos="word" morph="none" start_char="9088" end_char="9099">explanations</TOKEN>
<TOKEN id="token-67-26" pos="punct" morph="none" start_char="9101" end_char="9101">"</TOKEN>
<TOKEN id="token-67-27" pos="word" morph="none" start_char="9102" end_char="9107">highly</TOKEN>
<TOKEN id="token-67-28" pos="word" morph="none" start_char="9109" end_char="9116">unlikely</TOKEN>
<TOKEN id="token-67-29" pos="punct" morph="none" start_char="9117" end_char="9118">."</TOKEN>
</SEG>
<SEG id="segment-68" start_char="9121" end_char="9222">
<ORIGINAL_TEXT>The report noted the activities of Shi Zhengli, a leader in bat coronavirus research at the Wuhan lab.</ORIGINAL_TEXT>
<TOKEN id="token-68-0" pos="word" morph="none" start_char="9121" end_char="9123">The</TOKEN>
<TOKEN id="token-68-1" pos="word" morph="none" start_char="9125" end_char="9130">report</TOKEN>
<TOKEN id="token-68-2" pos="word" morph="none" start_char="9132" end_char="9136">noted</TOKEN>
<TOKEN id="token-68-3" pos="word" morph="none" start_char="9138" end_char="9140">the</TOKEN>
<TOKEN id="token-68-4" pos="word" morph="none" start_char="9142" end_char="9151">activities</TOKEN>
<TOKEN id="token-68-5" pos="word" morph="none" start_char="9153" end_char="9154">of</TOKEN>
<TOKEN id="token-68-6" pos="word" morph="none" start_char="9156" end_char="9158">Shi</TOKEN>
<TOKEN id="token-68-7" pos="word" morph="none" start_char="9160" end_char="9166">Zhengli</TOKEN>
<TOKEN id="token-68-8" pos="punct" morph="none" start_char="9167" end_char="9167">,</TOKEN>
<TOKEN id="token-68-9" pos="word" morph="none" start_char="9169" end_char="9169">a</TOKEN>
<TOKEN id="token-68-10" pos="word" morph="none" start_char="9171" end_char="9176">leader</TOKEN>
<TOKEN id="token-68-11" pos="word" morph="none" start_char="9178" end_char="9179">in</TOKEN>
<TOKEN id="token-68-12" pos="word" morph="none" start_char="9181" end_char="9183">bat</TOKEN>
<TOKEN id="token-68-13" pos="word" morph="none" start_char="9185" end_char="9195">coronavirus</TOKEN>
<TOKEN id="token-68-14" pos="word" morph="none" start_char="9197" end_char="9204">research</TOKEN>
<TOKEN id="token-68-15" pos="word" morph="none" start_char="9206" end_char="9207">at</TOKEN>
<TOKEN id="token-68-16" pos="word" morph="none" start_char="9209" end_char="9211">the</TOKEN>
<TOKEN id="token-68-17" pos="word" morph="none" start_char="9213" end_char="9217">Wuhan</TOKEN>
<TOKEN id="token-68-18" pos="word" morph="none" start_char="9219" end_char="9221">lab</TOKEN>
<TOKEN id="token-68-19" pos="punct" morph="none" start_char="9222" end_char="9222">.</TOKEN>
</SEG>
<SEG id="segment-69" start_char="9224" end_char="9513">
<ORIGINAL_TEXT>A 2015 academic report in Nature Medicine by Shi and 14 other scientists said that while researching the potential for bat coronaviruses to infect humans, "we built a chimeric virus encoding a novel, zoonotic (animal-origin) spike protein ... that was isolated from Chinese horseshoe bats."</ORIGINAL_TEXT>
<TOKEN id="token-69-0" pos="word" morph="none" start_char="9224" end_char="9224">A</TOKEN>
<TOKEN id="token-69-1" pos="word" morph="none" start_char="9226" end_char="9229">2015</TOKEN>
<TOKEN id="token-69-2" pos="word" morph="none" start_char="9231" end_char="9238">academic</TOKEN>
<TOKEN id="token-69-3" pos="word" morph="none" start_char="9240" end_char="9245">report</TOKEN>
<TOKEN id="token-69-4" pos="word" morph="none" start_char="9247" end_char="9248">in</TOKEN>
<TOKEN id="token-69-5" pos="word" morph="none" start_char="9250" end_char="9255">Nature</TOKEN>
<TOKEN id="token-69-6" pos="word" morph="none" start_char="9257" end_char="9264">Medicine</TOKEN>
<TOKEN id="token-69-7" pos="word" morph="none" start_char="9266" end_char="9267">by</TOKEN>
<TOKEN id="token-69-8" pos="word" morph="none" start_char="9269" end_char="9271">Shi</TOKEN>
<TOKEN id="token-69-9" pos="word" morph="none" start_char="9273" end_char="9275">and</TOKEN>
<TOKEN id="token-69-10" pos="word" morph="none" start_char="9277" end_char="9278">14</TOKEN>
<TOKEN id="token-69-11" pos="word" morph="none" start_char="9280" end_char="9284">other</TOKEN>
<TOKEN id="token-69-12" pos="word" morph="none" start_char="9286" end_char="9295">scientists</TOKEN>
<TOKEN id="token-69-13" pos="word" morph="none" start_char="9297" end_char="9300">said</TOKEN>
<TOKEN id="token-69-14" pos="word" morph="none" start_char="9302" end_char="9305">that</TOKEN>
<TOKEN id="token-69-15" pos="word" morph="none" start_char="9307" end_char="9311">while</TOKEN>
<TOKEN id="token-69-16" pos="word" morph="none" start_char="9313" end_char="9323">researching</TOKEN>
<TOKEN id="token-69-17" pos="word" morph="none" start_char="9325" end_char="9327">the</TOKEN>
<TOKEN id="token-69-18" pos="word" morph="none" start_char="9329" end_char="9337">potential</TOKEN>
<TOKEN id="token-69-19" pos="word" morph="none" start_char="9339" end_char="9341">for</TOKEN>
<TOKEN id="token-69-20" pos="word" morph="none" start_char="9343" end_char="9345">bat</TOKEN>
<TOKEN id="token-69-21" pos="word" morph="none" start_char="9347" end_char="9359">coronaviruses</TOKEN>
<TOKEN id="token-69-22" pos="word" morph="none" start_char="9361" end_char="9362">to</TOKEN>
<TOKEN id="token-69-23" pos="word" morph="none" start_char="9364" end_char="9369">infect</TOKEN>
<TOKEN id="token-69-24" pos="word" morph="none" start_char="9371" end_char="9376">humans</TOKEN>
<TOKEN id="token-69-25" pos="punct" morph="none" start_char="9377" end_char="9377">,</TOKEN>
<TOKEN id="token-69-26" pos="punct" morph="none" start_char="9379" end_char="9379">"</TOKEN>
<TOKEN id="token-69-27" pos="word" morph="none" start_char="9380" end_char="9381">we</TOKEN>
<TOKEN id="token-69-28" pos="word" morph="none" start_char="9383" end_char="9387">built</TOKEN>
<TOKEN id="token-69-29" pos="word" morph="none" start_char="9389" end_char="9389">a</TOKEN>
<TOKEN id="token-69-30" pos="word" morph="none" start_char="9391" end_char="9398">chimeric</TOKEN>
<TOKEN id="token-69-31" pos="word" morph="none" start_char="9400" end_char="9404">virus</TOKEN>
<TOKEN id="token-69-32" pos="word" morph="none" start_char="9406" end_char="9413">encoding</TOKEN>
<TOKEN id="token-69-33" pos="word" morph="none" start_char="9415" end_char="9415">a</TOKEN>
<TOKEN id="token-69-34" pos="word" morph="none" start_char="9417" end_char="9421">novel</TOKEN>
<TOKEN id="token-69-35" pos="punct" morph="none" start_char="9422" end_char="9422">,</TOKEN>
<TOKEN id="token-69-36" pos="word" morph="none" start_char="9424" end_char="9431">zoonotic</TOKEN>
<TOKEN id="token-69-37" pos="punct" morph="none" start_char="9433" end_char="9433">(</TOKEN>
<TOKEN id="token-69-38" pos="unknown" morph="none" start_char="9434" end_char="9446">animal-origin</TOKEN>
<TOKEN id="token-69-39" pos="punct" morph="none" start_char="9447" end_char="9447">)</TOKEN>
<TOKEN id="token-69-40" pos="word" morph="none" start_char="9449" end_char="9453">spike</TOKEN>
<TOKEN id="token-69-41" pos="word" morph="none" start_char="9455" end_char="9461">protein</TOKEN>
<TOKEN id="token-69-42" pos="punct" morph="none" start_char="9463" end_char="9465">...</TOKEN>
<TOKEN id="token-69-43" pos="word" morph="none" start_char="9467" end_char="9470">that</TOKEN>
<TOKEN id="token-69-44" pos="word" morph="none" start_char="9472" end_char="9474">was</TOKEN>
<TOKEN id="token-69-45" pos="word" morph="none" start_char="9476" end_char="9483">isolated</TOKEN>
<TOKEN id="token-69-46" pos="word" morph="none" start_char="9485" end_char="9488">from</TOKEN>
<TOKEN id="token-69-47" pos="word" morph="none" start_char="9490" end_char="9496">Chinese</TOKEN>
<TOKEN id="token-69-48" pos="word" morph="none" start_char="9498" end_char="9506">horseshoe</TOKEN>
<TOKEN id="token-69-49" pos="word" morph="none" start_char="9508" end_char="9511">bats</TOKEN>
<TOKEN id="token-69-50" pos="punct" morph="none" start_char="9512" end_char="9513">."</TOKEN>
</SEG>
<SEG id="segment-70" start_char="9516" end_char="9752">
<ORIGINAL_TEXT>The U.S. government analysis, reported by the Washington Times, found virus-carrying animals had been "sold as pets, dead laboratory animals were not properly disposed of, and lab workers were known to boil and eat laboratory-used eggs."</ORIGINAL_TEXT>
<TOKEN id="token-70-0" pos="word" morph="none" start_char="9516" end_char="9518">The</TOKEN>
<TOKEN id="token-70-1" pos="unknown" morph="none" start_char="9520" end_char="9522">U.S</TOKEN>
<TOKEN id="token-70-2" pos="punct" morph="none" start_char="9523" end_char="9523">.</TOKEN>
<TOKEN id="token-70-3" pos="word" morph="none" start_char="9525" end_char="9534">government</TOKEN>
<TOKEN id="token-70-4" pos="word" morph="none" start_char="9536" end_char="9543">analysis</TOKEN>
<TOKEN id="token-70-5" pos="punct" morph="none" start_char="9544" end_char="9544">,</TOKEN>
<TOKEN id="token-70-6" pos="word" morph="none" start_char="9546" end_char="9553">reported</TOKEN>
<TOKEN id="token-70-7" pos="word" morph="none" start_char="9555" end_char="9556">by</TOKEN>
<TOKEN id="token-70-8" pos="word" morph="none" start_char="9558" end_char="9560">the</TOKEN>
<TOKEN id="token-70-9" pos="word" morph="none" start_char="9562" end_char="9571">Washington</TOKEN>
<TOKEN id="token-70-10" pos="word" morph="none" start_char="9573" end_char="9577">Times</TOKEN>
<TOKEN id="token-70-11" pos="punct" morph="none" start_char="9578" end_char="9578">,</TOKEN>
<TOKEN id="token-70-12" pos="word" morph="none" start_char="9580" end_char="9584">found</TOKEN>
<TOKEN id="token-70-13" pos="unknown" morph="none" start_char="9586" end_char="9599">virus-carrying</TOKEN>
<TOKEN id="token-70-14" pos="word" morph="none" start_char="9601" end_char="9607">animals</TOKEN>
<TOKEN id="token-70-15" pos="word" morph="none" start_char="9609" end_char="9611">had</TOKEN>
<TOKEN id="token-70-16" pos="word" morph="none" start_char="9613" end_char="9616">been</TOKEN>
<TOKEN id="token-70-17" pos="punct" morph="none" start_char="9618" end_char="9618">"</TOKEN>
<TOKEN id="token-70-18" pos="word" morph="none" start_char="9619" end_char="9622">sold</TOKEN>
<TOKEN id="token-70-19" pos="word" morph="none" start_char="9624" end_char="9625">as</TOKEN>
<TOKEN id="token-70-20" pos="word" morph="none" start_char="9627" end_char="9630">pets</TOKEN>
<TOKEN id="token-70-21" pos="punct" morph="none" start_char="9631" end_char="9631">,</TOKEN>
<TOKEN id="token-70-22" pos="word" morph="none" start_char="9633" end_char="9636">dead</TOKEN>
<TOKEN id="token-70-23" pos="word" morph="none" start_char="9638" end_char="9647">laboratory</TOKEN>
<TOKEN id="token-70-24" pos="word" morph="none" start_char="9649" end_char="9655">animals</TOKEN>
<TOKEN id="token-70-25" pos="word" morph="none" start_char="9657" end_char="9660">were</TOKEN>
<TOKEN id="token-70-26" pos="word" morph="none" start_char="9662" end_char="9664">not</TOKEN>
<TOKEN id="token-70-27" pos="word" morph="none" start_char="9666" end_char="9673">properly</TOKEN>
<TOKEN id="token-70-28" pos="word" morph="none" start_char="9675" end_char="9682">disposed</TOKEN>
<TOKEN id="token-70-29" pos="word" morph="none" start_char="9684" end_char="9685">of</TOKEN>
<TOKEN id="token-70-30" pos="punct" morph="none" start_char="9686" end_char="9686">,</TOKEN>
<TOKEN id="token-70-31" pos="word" morph="none" start_char="9688" end_char="9690">and</TOKEN>
<TOKEN id="token-70-32" pos="word" morph="none" start_char="9692" end_char="9694">lab</TOKEN>
<TOKEN id="token-70-33" pos="word" morph="none" start_char="9696" end_char="9702">workers</TOKEN>
<TOKEN id="token-70-34" pos="word" morph="none" start_char="9704" end_char="9707">were</TOKEN>
<TOKEN id="token-70-35" pos="word" morph="none" start_char="9709" end_char="9713">known</TOKEN>
<TOKEN id="token-70-36" pos="word" morph="none" start_char="9715" end_char="9716">to</TOKEN>
<TOKEN id="token-70-37" pos="word" morph="none" start_char="9718" end_char="9721">boil</TOKEN>
<TOKEN id="token-70-38" pos="word" morph="none" start_char="9723" end_char="9725">and</TOKEN>
<TOKEN id="token-70-39" pos="word" morph="none" start_char="9727" end_char="9729">eat</TOKEN>
<TOKEN id="token-70-40" pos="unknown" morph="none" start_char="9731" end_char="9745">laboratory-used</TOKEN>
<TOKEN id="token-70-41" pos="word" morph="none" start_char="9747" end_char="9750">eggs</TOKEN>
<TOKEN id="token-70-42" pos="punct" morph="none" start_char="9751" end_char="9752">."</TOKEN>
</SEG>
<SEG id="segment-71" start_char="9755" end_char="9948">
<ORIGINAL_TEXT>The report noted that China was clamping down on efforts to investigate whether the virus came from a lab, issuing a "gag order" and putting a military microbiologist in charge of the Wuhan lab.</ORIGINAL_TEXT>
<TOKEN id="token-71-0" pos="word" morph="none" start_char="9755" end_char="9757">The</TOKEN>
<TOKEN id="token-71-1" pos="word" morph="none" start_char="9759" end_char="9764">report</TOKEN>
<TOKEN id="token-71-2" pos="word" morph="none" start_char="9766" end_char="9770">noted</TOKEN>
<TOKEN id="token-71-3" pos="word" morph="none" start_char="9772" end_char="9775">that</TOKEN>
<TOKEN id="token-71-4" pos="word" morph="none" start_char="9777" end_char="9781">China</TOKEN>
<TOKEN id="token-71-5" pos="word" morph="none" start_char="9783" end_char="9785">was</TOKEN>
<TOKEN id="token-71-6" pos="word" morph="none" start_char="9787" end_char="9794">clamping</TOKEN>
<TOKEN id="token-71-7" pos="word" morph="none" start_char="9796" end_char="9799">down</TOKEN>
<TOKEN id="token-71-8" pos="word" morph="none" start_char="9801" end_char="9802">on</TOKEN>
<TOKEN id="token-71-9" pos="word" morph="none" start_char="9804" end_char="9810">efforts</TOKEN>
<TOKEN id="token-71-10" pos="word" morph="none" start_char="9812" end_char="9813">to</TOKEN>
<TOKEN id="token-71-11" pos="word" morph="none" start_char="9815" end_char="9825">investigate</TOKEN>
<TOKEN id="token-71-12" pos="word" morph="none" start_char="9827" end_char="9833">whether</TOKEN>
<TOKEN id="token-71-13" pos="word" morph="none" start_char="9835" end_char="9837">the</TOKEN>
<TOKEN id="token-71-14" pos="word" morph="none" start_char="9839" end_char="9843">virus</TOKEN>
<TOKEN id="token-71-15" pos="word" morph="none" start_char="9845" end_char="9848">came</TOKEN>
<TOKEN id="token-71-16" pos="word" morph="none" start_char="9850" end_char="9853">from</TOKEN>
<TOKEN id="token-71-17" pos="word" morph="none" start_char="9855" end_char="9855">a</TOKEN>
<TOKEN id="token-71-18" pos="word" morph="none" start_char="9857" end_char="9859">lab</TOKEN>
<TOKEN id="token-71-19" pos="punct" morph="none" start_char="9860" end_char="9860">,</TOKEN>
<TOKEN id="token-71-20" pos="word" morph="none" start_char="9862" end_char="9868">issuing</TOKEN>
<TOKEN id="token-71-21" pos="word" morph="none" start_char="9870" end_char="9870">a</TOKEN>
<TOKEN id="token-71-22" pos="punct" morph="none" start_char="9872" end_char="9872">"</TOKEN>
<TOKEN id="token-71-23" pos="word" morph="none" start_char="9873" end_char="9875">gag</TOKEN>
<TOKEN id="token-71-24" pos="word" morph="none" start_char="9877" end_char="9881">order</TOKEN>
<TOKEN id="token-71-25" pos="punct" morph="none" start_char="9882" end_char="9882">"</TOKEN>
<TOKEN id="token-71-26" pos="word" morph="none" start_char="9884" end_char="9886">and</TOKEN>
<TOKEN id="token-71-27" pos="word" morph="none" start_char="9888" end_char="9894">putting</TOKEN>
<TOKEN id="token-71-28" pos="word" morph="none" start_char="9896" end_char="9896">a</TOKEN>
<TOKEN id="token-71-29" pos="word" morph="none" start_char="9898" end_char="9905">military</TOKEN>
<TOKEN id="token-71-30" pos="word" morph="none" start_char="9907" end_char="9920">microbiologist</TOKEN>
<TOKEN id="token-71-31" pos="word" morph="none" start_char="9922" end_char="9923">in</TOKEN>
<TOKEN id="token-71-32" pos="word" morph="none" start_char="9925" end_char="9930">charge</TOKEN>
<TOKEN id="token-71-33" pos="word" morph="none" start_char="9932" end_char="9933">of</TOKEN>
<TOKEN id="token-71-34" pos="word" morph="none" start_char="9935" end_char="9937">the</TOKEN>
<TOKEN id="token-71-35" pos="word" morph="none" start_char="9939" end_char="9943">Wuhan</TOKEN>
<TOKEN id="token-71-36" pos="word" morph="none" start_char="9945" end_char="9947">lab</TOKEN>
<TOKEN id="token-71-37" pos="punct" morph="none" start_char="9948" end_char="9948">.</TOKEN>
</SEG>
<SEG id="segment-72" start_char="9951" end_char="10101">
<ORIGINAL_TEXT>Content created by the WND News Center is available for re-publication without charge to any eligible news publisher that can provide a large audience.</ORIGINAL_TEXT>
<TOKEN id="token-72-0" pos="word" morph="none" start_char="9951" end_char="9957">Content</TOKEN>
<TOKEN id="token-72-1" pos="word" morph="none" start_char="9959" end_char="9965">created</TOKEN>
<TOKEN id="token-72-2" pos="word" morph="none" start_char="9967" end_char="9968">by</TOKEN>
<TOKEN id="token-72-3" pos="word" morph="none" start_char="9970" end_char="9972">the</TOKEN>
<TOKEN id="token-72-4" pos="word" morph="none" start_char="9974" end_char="9976">WND</TOKEN>
<TOKEN id="token-72-5" pos="word" morph="none" start_char="9978" end_char="9981">News</TOKEN>
<TOKEN id="token-72-6" pos="word" morph="none" start_char="9983" end_char="9988">Center</TOKEN>
<TOKEN id="token-72-7" pos="word" morph="none" start_char="9990" end_char="9991">is</TOKEN>
<TOKEN id="token-72-8" pos="word" morph="none" start_char="9993" end_char="10001">available</TOKEN>
<TOKEN id="token-72-9" pos="word" morph="none" start_char="10003" end_char="10005">for</TOKEN>
<TOKEN id="token-72-10" pos="unknown" morph="none" start_char="10007" end_char="10020">re-publication</TOKEN>
<TOKEN id="token-72-11" pos="word" morph="none" start_char="10022" end_char="10028">without</TOKEN>
<TOKEN id="token-72-12" pos="word" morph="none" start_char="10030" end_char="10035">charge</TOKEN>
<TOKEN id="token-72-13" pos="word" morph="none" start_char="10037" end_char="10038">to</TOKEN>
<TOKEN id="token-72-14" pos="word" morph="none" start_char="10040" end_char="10042">any</TOKEN>
<TOKEN id="token-72-15" pos="word" morph="none" start_char="10044" end_char="10051">eligible</TOKEN>
<TOKEN id="token-72-16" pos="word" morph="none" start_char="10053" end_char="10056">news</TOKEN>
<TOKEN id="token-72-17" pos="word" morph="none" start_char="10058" end_char="10066">publisher</TOKEN>
<TOKEN id="token-72-18" pos="word" morph="none" start_char="10068" end_char="10071">that</TOKEN>
<TOKEN id="token-72-19" pos="word" morph="none" start_char="10073" end_char="10075">can</TOKEN>
<TOKEN id="token-72-20" pos="word" morph="none" start_char="10077" end_char="10083">provide</TOKEN>
<TOKEN id="token-72-21" pos="word" morph="none" start_char="10085" end_char="10085">a</TOKEN>
<TOKEN id="token-72-22" pos="word" morph="none" start_char="10087" end_char="10091">large</TOKEN>
<TOKEN id="token-72-23" pos="word" morph="none" start_char="10093" end_char="10100">audience</TOKEN>
<TOKEN id="token-72-24" pos="punct" morph="none" start_char="10101" end_char="10101">.</TOKEN>
</SEG>
<SEG id="segment-73" start_char="10103" end_char="10198">
<ORIGINAL_TEXT>For licensing opportunities of our original content, please contact licensing@wndnewscenter.org.</ORIGINAL_TEXT>
<TOKEN id="token-73-0" pos="word" morph="none" start_char="10103" end_char="10105">For</TOKEN>
<TOKEN id="token-73-1" pos="word" morph="none" start_char="10107" end_char="10115">licensing</TOKEN>
<TOKEN id="token-73-2" pos="word" morph="none" start_char="10117" end_char="10129">opportunities</TOKEN>
<TOKEN id="token-73-3" pos="word" morph="none" start_char="10131" end_char="10132">of</TOKEN>
<TOKEN id="token-73-4" pos="word" morph="none" start_char="10134" end_char="10136">our</TOKEN>
<TOKEN id="token-73-5" pos="word" morph="none" start_char="10138" end_char="10145">original</TOKEN>
<TOKEN id="token-73-6" pos="word" morph="none" start_char="10147" end_char="10153">content</TOKEN>
<TOKEN id="token-73-7" pos="punct" morph="none" start_char="10154" end_char="10154">,</TOKEN>
<TOKEN id="token-73-8" pos="word" morph="none" start_char="10156" end_char="10161">please</TOKEN>
<TOKEN id="token-73-9" pos="word" morph="none" start_char="10163" end_char="10169">contact</TOKEN>
<TOKEN id="token-73-10" pos="unknown" morph="none" start_char="10171" end_char="10197">licensing@wndnewscenter.org</TOKEN>
<TOKEN id="token-73-11" pos="punct" morph="none" start_char="10198" end_char="10198">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
