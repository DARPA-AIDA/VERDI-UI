<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATIQ" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="2190" raw_text_md5="e088a1abb560d27473d276e215afd653">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="47">
<ORIGINAL_TEXT>La inmunidad ante la Covid-19 podría durar años</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="2">La</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="4" end_char="12">inmunidad</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="14" end_char="17">ante</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="19" end_char="20">la</TOKEN>
<TOKEN id="token-0-4" pos="unknown" morph="none" start_char="22" end_char="29">Covid-19</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="31" end_char="36">podría</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="38" end_char="42">durar</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="44" end_char="47">años</TOKEN>
</SEG>
<SEG id="segment-1" start_char="52" end_char="308">
<ORIGINAL_TEXT>Pese a estar estos meses de pandemia escuchando que los anticuerpos de la covid-19 apenas duran unos meses, variables en cada persona, expertos en EEUU aseguran que podrían durar de por vida o al menos durante mucho tiempo, como pasa con otras enfermedades.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="52" end_char="55">Pese</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="57" end_char="57">a</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="59" end_char="63">estar</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="65" end_char="69">estos</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="71" end_char="75">meses</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="77" end_char="78">de</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="80" end_char="87">pandemia</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="89" end_char="98">escuchando</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="100" end_char="102">que</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="104" end_char="106">los</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="108" end_char="118">anticuerpos</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="120" end_char="121">de</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="123" end_char="124">la</TOKEN>
<TOKEN id="token-1-13" pos="unknown" morph="none" start_char="126" end_char="133">covid-19</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="135" end_char="140">apenas</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="142" end_char="146">duran</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="148" end_char="151">unos</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="153" end_char="157">meses</TOKEN>
<TOKEN id="token-1-18" pos="punct" morph="none" start_char="158" end_char="158">,</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="160" end_char="168">variables</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="170" end_char="171">en</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="173" end_char="176">cada</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="178" end_char="184">persona</TOKEN>
<TOKEN id="token-1-23" pos="punct" morph="none" start_char="185" end_char="185">,</TOKEN>
<TOKEN id="token-1-24" pos="word" morph="none" start_char="187" end_char="194">expertos</TOKEN>
<TOKEN id="token-1-25" pos="word" morph="none" start_char="196" end_char="197">en</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="199" end_char="202">EEUU</TOKEN>
<TOKEN id="token-1-27" pos="word" morph="none" start_char="204" end_char="211">aseguran</TOKEN>
<TOKEN id="token-1-28" pos="word" morph="none" start_char="213" end_char="215">que</TOKEN>
<TOKEN id="token-1-29" pos="word" morph="none" start_char="217" end_char="223">podrían</TOKEN>
<TOKEN id="token-1-30" pos="word" morph="none" start_char="225" end_char="229">durar</TOKEN>
<TOKEN id="token-1-31" pos="word" morph="none" start_char="231" end_char="232">de</TOKEN>
<TOKEN id="token-1-32" pos="word" morph="none" start_char="234" end_char="236">por</TOKEN>
<TOKEN id="token-1-33" pos="word" morph="none" start_char="238" end_char="241">vida</TOKEN>
<TOKEN id="token-1-34" pos="word" morph="none" start_char="243" end_char="243">o</TOKEN>
<TOKEN id="token-1-35" pos="word" morph="none" start_char="245" end_char="246">al</TOKEN>
<TOKEN id="token-1-36" pos="word" morph="none" start_char="248" end_char="252">menos</TOKEN>
<TOKEN id="token-1-37" pos="word" morph="none" start_char="254" end_char="260">durante</TOKEN>
<TOKEN id="token-1-38" pos="word" morph="none" start_char="262" end_char="266">mucho</TOKEN>
<TOKEN id="token-1-39" pos="word" morph="none" start_char="268" end_char="273">tiempo</TOKEN>
<TOKEN id="token-1-40" pos="punct" morph="none" start_char="274" end_char="274">,</TOKEN>
<TOKEN id="token-1-41" pos="word" morph="none" start_char="276" end_char="279">como</TOKEN>
<TOKEN id="token-1-42" pos="word" morph="none" start_char="281" end_char="284">pasa</TOKEN>
<TOKEN id="token-1-43" pos="word" morph="none" start_char="286" end_char="288">con</TOKEN>
<TOKEN id="token-1-44" pos="word" morph="none" start_char="290" end_char="294">otras</TOKEN>
<TOKEN id="token-1-45" pos="word" morph="none" start_char="296" end_char="307">enfermedades</TOKEN>
<TOKEN id="token-1-46" pos="punct" morph="none" start_char="308" end_char="308">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="311" end_char="569">
<ORIGINAL_TEXT>Es la conclusión de un estudio del La Jolla Institute for Immunology (California), especializado en estudios de inmunología, una rama de la medician centrada en el estudio, diagnóstico y tratamiento de las enfermedades relacionadas con el sistema inmunitario.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="311" end_char="312">Es</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="314" end_char="315">la</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="317" end_char="326">conclusión</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="328" end_char="329">de</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="331" end_char="332">un</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="334" end_char="340">estudio</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="342" end_char="344">del</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="346" end_char="347">La</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="349" end_char="353">Jolla</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="355" end_char="363">Institute</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="365" end_char="367">for</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="369" end_char="378">Immunology</TOKEN>
<TOKEN id="token-2-12" pos="punct" morph="none" start_char="380" end_char="380">(</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="381" end_char="390">California</TOKEN>
<TOKEN id="token-2-14" pos="punct" morph="none" start_char="391" end_char="392">),</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="394" end_char="406">especializado</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="408" end_char="409">en</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="411" end_char="418">estudios</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="420" end_char="421">de</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="423" end_char="433">inmunología</TOKEN>
<TOKEN id="token-2-20" pos="punct" morph="none" start_char="434" end_char="434">,</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="436" end_char="438">una</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="440" end_char="443">rama</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="445" end_char="446">de</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="448" end_char="449">la</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="451" end_char="458">medician</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="460" end_char="467">centrada</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="469" end_char="470">en</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="472" end_char="473">el</TOKEN>
<TOKEN id="token-2-29" pos="word" morph="none" start_char="475" end_char="481">estudio</TOKEN>
<TOKEN id="token-2-30" pos="punct" morph="none" start_char="482" end_char="482">,</TOKEN>
<TOKEN id="token-2-31" pos="word" morph="none" start_char="484" end_char="494">diagnóstico</TOKEN>
<TOKEN id="token-2-32" pos="word" morph="none" start_char="496" end_char="496">y</TOKEN>
<TOKEN id="token-2-33" pos="word" morph="none" start_char="498" end_char="508">tratamiento</TOKEN>
<TOKEN id="token-2-34" pos="word" morph="none" start_char="510" end_char="511">de</TOKEN>
<TOKEN id="token-2-35" pos="word" morph="none" start_char="513" end_char="515">las</TOKEN>
<TOKEN id="token-2-36" pos="word" morph="none" start_char="517" end_char="528">enfermedades</TOKEN>
<TOKEN id="token-2-37" pos="word" morph="none" start_char="530" end_char="541">relacionadas</TOKEN>
<TOKEN id="token-2-38" pos="word" morph="none" start_char="543" end_char="545">con</TOKEN>
<TOKEN id="token-2-39" pos="word" morph="none" start_char="547" end_char="548">el</TOKEN>
<TOKEN id="token-2-40" pos="word" morph="none" start_char="550" end_char="556">sistema</TOKEN>
<TOKEN id="token-2-41" pos="word" morph="none" start_char="558" end_char="568">inmunitario</TOKEN>
<TOKEN id="token-2-42" pos="punct" morph="none" start_char="569" end_char="569">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="572" end_char="753">
<ORIGINAL_TEXT>Ante las preguntas sobre si podemos se inmunes al coronavirus y cuánto tiempo dura esa inmunidad, los investigadores de este centro han concluido que podría llegar a ser de por vida.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="572" end_char="575">Ante</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="577" end_char="579">las</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="581" end_char="589">preguntas</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="591" end_char="595">sobre</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="597" end_char="598">si</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="600" end_char="606">podemos</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="608" end_char="609">se</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="611" end_char="617">inmunes</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="619" end_char="620">al</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="622" end_char="632">coronavirus</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="634" end_char="634">y</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="636" end_char="641">cuánto</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="643" end_char="648">tiempo</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="650" end_char="653">dura</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="655" end_char="657">esa</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="659" end_char="667">inmunidad</TOKEN>
<TOKEN id="token-3-16" pos="punct" morph="none" start_char="668" end_char="668">,</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="670" end_char="672">los</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="674" end_char="687">investigadores</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="689" end_char="690">de</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="692" end_char="695">este</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="697" end_char="702">centro</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="704" end_char="706">han</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="708" end_char="716">concluido</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="718" end_char="720">que</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="722" end_char="727">podría</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="729" end_char="734">llegar</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="736" end_char="736">a</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="738" end_char="740">ser</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="742" end_char="743">de</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="745" end_char="747">por</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="749" end_char="752">vida</TOKEN>
<TOKEN id="token-3-32" pos="punct" morph="none" start_char="753" end_char="753">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="756" end_char="867">
<ORIGINAL_TEXT>Dicho estudio, dirigido por Marco Werman, de la Universidad de California en San Diego y del Instituto La Jolla.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="756" end_char="760">Dicho</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="762" end_char="768">estudio</TOKEN>
<TOKEN id="token-4-2" pos="punct" morph="none" start_char="769" end_char="769">,</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="771" end_char="778">dirigido</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="780" end_char="782">por</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="784" end_char="788">Marco</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="790" end_char="795">Werman</TOKEN>
<TOKEN id="token-4-7" pos="punct" morph="none" start_char="796" end_char="796">,</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="798" end_char="799">de</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="801" end_char="802">la</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="804" end_char="814">Universidad</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="816" end_char="817">de</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="819" end_char="828">California</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="830" end_char="831">en</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="833" end_char="835">San</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="837" end_char="841">Diego</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="843" end_char="843">y</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="845" end_char="847">del</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="849" end_char="857">Instituto</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="859" end_char="860">La</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="862" end_char="866">Jolla</TOKEN>
<TOKEN id="token-4-21" pos="punct" morph="none" start_char="867" end_char="867">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="869" end_char="1048">
<ORIGINAL_TEXT>Entre sus conclusiones, se ve cómo 8 meses después de la enfermedad, la mayoría de las personas que se han recuperado todavía tienen células inmunitarias para defenderse del virus.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="869" end_char="873">Entre</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="875" end_char="877">sus</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="879" end_char="890">conclusiones</TOKEN>
<TOKEN id="token-5-3" pos="punct" morph="none" start_char="891" end_char="891">,</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="893" end_char="894">se</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="896" end_char="897">ve</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="899" end_char="902">cómo</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="904" end_char="904">8</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="906" end_char="910">meses</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="912" end_char="918">después</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="920" end_char="921">de</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="923" end_char="924">la</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="926" end_char="935">enfermedad</TOKEN>
<TOKEN id="token-5-13" pos="punct" morph="none" start_char="936" end_char="936">,</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="938" end_char="939">la</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="941" end_char="947">mayoría</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="949" end_char="950">de</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="952" end_char="954">las</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="956" end_char="963">personas</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="965" end_char="967">que</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="969" end_char="970">se</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="972" end_char="974">han</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="976" end_char="985">recuperado</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="987" end_char="993">todavía</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="995" end_char="1000">tienen</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="1002" end_char="1008">células</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="1010" end_char="1021">inmunitarias</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="1023" end_char="1026">para</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="1028" end_char="1037">defenderse</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="1039" end_char="1041">del</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="1043" end_char="1047">virus</TOKEN>
<TOKEN id="token-5-31" pos="punct" morph="none" start_char="1048" end_char="1048">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="1050" end_char="1138">
<ORIGINAL_TEXT>Estas células pueden persistir en el cuerpo durante mucho, quizás años o incluso décadas.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="1050" end_char="1054">Estas</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="1056" end_char="1062">células</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="1064" end_char="1069">pueden</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="1071" end_char="1079">persistir</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="1081" end_char="1082">en</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="1084" end_char="1085">el</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="1087" end_char="1092">cuerpo</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="1094" end_char="1100">durante</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="1102" end_char="1106">mucho</TOKEN>
<TOKEN id="token-6-9" pos="punct" morph="none" start_char="1107" end_char="1107">,</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="1109" end_char="1114">quizás</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="1116" end_char="1119">años</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="1121" end_char="1121">o</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="1123" end_char="1129">incluso</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="1131" end_char="1137">décadas</TOKEN>
<TOKEN id="token-6-15" pos="punct" morph="none" start_char="1138" end_char="1138">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="1141" end_char="1157">
<ORIGINAL_TEXT>Muchas esperanzas</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="1141" end_char="1146">Muchas</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="1148" end_char="1157">esperanzas</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1161" end_char="1436">
<ORIGINAL_TEXT>Ahora bien, este estudio está en entredicho todavía porque se publicó online y todavía no ha sido revisado por otros científicos ni publicado en una revista científica, aunque es el estudio más completo y de mayor alcance sobre la memoria inmune al coronavirus hasta la fecha.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1161" end_char="1165">Ahora</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1167" end_char="1170">bien</TOKEN>
<TOKEN id="token-8-2" pos="punct" morph="none" start_char="1171" end_char="1171">,</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1173" end_char="1176">este</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1178" end_char="1184">estudio</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1186" end_char="1189">está</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1191" end_char="1192">en</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1194" end_char="1203">entredicho</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1205" end_char="1211">todavía</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1213" end_char="1218">porque</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1220" end_char="1221">se</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1223" end_char="1229">publicó</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1231" end_char="1236">online</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1238" end_char="1238">y</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1240" end_char="1246">todavía</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1248" end_char="1249">no</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1251" end_char="1252">ha</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1254" end_char="1257">sido</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1259" end_char="1266">revisado</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1268" end_char="1270">por</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="1272" end_char="1276">otros</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="1278" end_char="1288">científicos</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="1290" end_char="1291">ni</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="1293" end_char="1301">publicado</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="1303" end_char="1304">en</TOKEN>
<TOKEN id="token-8-25" pos="word" morph="none" start_char="1306" end_char="1308">una</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="1310" end_char="1316">revista</TOKEN>
<TOKEN id="token-8-27" pos="word" morph="none" start_char="1318" end_char="1327">científica</TOKEN>
<TOKEN id="token-8-28" pos="punct" morph="none" start_char="1328" end_char="1328">,</TOKEN>
<TOKEN id="token-8-29" pos="word" morph="none" start_char="1330" end_char="1335">aunque</TOKEN>
<TOKEN id="token-8-30" pos="word" morph="none" start_char="1337" end_char="1338">es</TOKEN>
<TOKEN id="token-8-31" pos="word" morph="none" start_char="1340" end_char="1341">el</TOKEN>
<TOKEN id="token-8-32" pos="word" morph="none" start_char="1343" end_char="1349">estudio</TOKEN>
<TOKEN id="token-8-33" pos="word" morph="none" start_char="1351" end_char="1353">más</TOKEN>
<TOKEN id="token-8-34" pos="word" morph="none" start_char="1355" end_char="1362">completo</TOKEN>
<TOKEN id="token-8-35" pos="word" morph="none" start_char="1364" end_char="1364">y</TOKEN>
<TOKEN id="token-8-36" pos="word" morph="none" start_char="1366" end_char="1367">de</TOKEN>
<TOKEN id="token-8-37" pos="word" morph="none" start_char="1369" end_char="1373">mayor</TOKEN>
<TOKEN id="token-8-38" pos="word" morph="none" start_char="1375" end_char="1381">alcance</TOKEN>
<TOKEN id="token-8-39" pos="word" morph="none" start_char="1383" end_char="1387">sobre</TOKEN>
<TOKEN id="token-8-40" pos="word" morph="none" start_char="1389" end_char="1390">la</TOKEN>
<TOKEN id="token-8-41" pos="word" morph="none" start_char="1392" end_char="1398">memoria</TOKEN>
<TOKEN id="token-8-42" pos="word" morph="none" start_char="1400" end_char="1405">inmune</TOKEN>
<TOKEN id="token-8-43" pos="word" morph="none" start_char="1407" end_char="1408">al</TOKEN>
<TOKEN id="token-8-44" pos="word" morph="none" start_char="1410" end_char="1420">coronavirus</TOKEN>
<TOKEN id="token-8-45" pos="word" morph="none" start_char="1422" end_char="1426">hasta</TOKEN>
<TOKEN id="token-8-46" pos="word" morph="none" start_char="1428" end_char="1429">la</TOKEN>
<TOKEN id="token-8-47" pos="word" morph="none" start_char="1431" end_char="1435">fecha</TOKEN>
<TOKEN id="token-8-48" pos="punct" morph="none" start_char="1436" end_char="1436">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1439" end_char="1695">
<ORIGINAL_TEXT>Según Shane Crotty, virólogo del La Jolla y codirector del estudio, "esa cantidad de memoria" del sistema inmune "probablemente evitaría que la gran mayoría de las personas contraigan una enfermedad hospitalizada, una enfermedad grave, durante muchos años".</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1439" end_char="1443">Según</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1445" end_char="1449">Shane</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1451" end_char="1456">Crotty</TOKEN>
<TOKEN id="token-9-3" pos="punct" morph="none" start_char="1457" end_char="1457">,</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1459" end_char="1466">virólogo</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1468" end_char="1470">del</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1472" end_char="1473">La</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1475" end_char="1479">Jolla</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1481" end_char="1481">y</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1483" end_char="1492">codirector</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1494" end_char="1496">del</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1498" end_char="1504">estudio</TOKEN>
<TOKEN id="token-9-12" pos="punct" morph="none" start_char="1505" end_char="1505">,</TOKEN>
<TOKEN id="token-9-13" pos="punct" morph="none" start_char="1507" end_char="1507">"</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1508" end_char="1510">esa</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1512" end_char="1519">cantidad</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1521" end_char="1522">de</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1524" end_char="1530">memoria</TOKEN>
<TOKEN id="token-9-18" pos="punct" morph="none" start_char="1531" end_char="1531">"</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1533" end_char="1535">del</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1537" end_char="1543">sistema</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1545" end_char="1550">inmune</TOKEN>
<TOKEN id="token-9-22" pos="punct" morph="none" start_char="1552" end_char="1552">"</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1553" end_char="1565">probablemente</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1567" end_char="1574">evitaría</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1576" end_char="1578">que</TOKEN>
<TOKEN id="token-9-26" pos="word" morph="none" start_char="1580" end_char="1581">la</TOKEN>
<TOKEN id="token-9-27" pos="word" morph="none" start_char="1583" end_char="1586">gran</TOKEN>
<TOKEN id="token-9-28" pos="word" morph="none" start_char="1588" end_char="1594">mayoría</TOKEN>
<TOKEN id="token-9-29" pos="word" morph="none" start_char="1596" end_char="1597">de</TOKEN>
<TOKEN id="token-9-30" pos="word" morph="none" start_char="1599" end_char="1601">las</TOKEN>
<TOKEN id="token-9-31" pos="word" morph="none" start_char="1603" end_char="1610">personas</TOKEN>
<TOKEN id="token-9-32" pos="word" morph="none" start_char="1612" end_char="1621">contraigan</TOKEN>
<TOKEN id="token-9-33" pos="word" morph="none" start_char="1623" end_char="1625">una</TOKEN>
<TOKEN id="token-9-34" pos="word" morph="none" start_char="1627" end_char="1636">enfermedad</TOKEN>
<TOKEN id="token-9-35" pos="word" morph="none" start_char="1638" end_char="1650">hospitalizada</TOKEN>
<TOKEN id="token-9-36" pos="punct" morph="none" start_char="1651" end_char="1651">,</TOKEN>
<TOKEN id="token-9-37" pos="word" morph="none" start_char="1653" end_char="1655">una</TOKEN>
<TOKEN id="token-9-38" pos="word" morph="none" start_char="1657" end_char="1666">enfermedad</TOKEN>
<TOKEN id="token-9-39" pos="word" morph="none" start_char="1668" end_char="1672">grave</TOKEN>
<TOKEN id="token-9-40" pos="punct" morph="none" start_char="1673" end_char="1673">,</TOKEN>
<TOKEN id="token-9-41" pos="word" morph="none" start_char="1675" end_char="1681">durante</TOKEN>
<TOKEN id="token-9-42" pos="word" morph="none" start_char="1683" end_char="1688">muchos</TOKEN>
<TOKEN id="token-9-43" pos="word" morph="none" start_char="1690" end_char="1693">años</TOKEN>
<TOKEN id="token-9-44" pos="punct" morph="none" start_char="1694" end_char="1695">".</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1698" end_char="1968">
<ORIGINAL_TEXT>Otro hallazo increíble es que las personas que habían padecido una enfermedad de tipo SARS (síndrome respiratorio agudo grave), causado por cualquier otro coronavirus, más allá del que provoca la famosa covid-19, todavía tienen anticuerpos 17 años después de recuperarse.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1698" end_char="1701">Otro</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1703" end_char="1709">hallazo</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1711" end_char="1719">increíble</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1721" end_char="1722">es</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1724" end_char="1726">que</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1728" end_char="1730">las</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1732" end_char="1739">personas</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1741" end_char="1743">que</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1745" end_char="1750">habían</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1752" end_char="1759">padecido</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1761" end_char="1763">una</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1765" end_char="1774">enfermedad</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1776" end_char="1777">de</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1779" end_char="1782">tipo</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1784" end_char="1787">SARS</TOKEN>
<TOKEN id="token-10-15" pos="punct" morph="none" start_char="1789" end_char="1789">(</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1790" end_char="1797">síndrome</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1799" end_char="1810">respiratorio</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1812" end_char="1816">agudo</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1818" end_char="1822">grave</TOKEN>
<TOKEN id="token-10-20" pos="punct" morph="none" start_char="1823" end_char="1824">),</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1826" end_char="1832">causado</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1834" end_char="1836">por</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1838" end_char="1846">cualquier</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1848" end_char="1851">otro</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="1853" end_char="1863">coronavirus</TOKEN>
<TOKEN id="token-10-26" pos="punct" morph="none" start_char="1864" end_char="1864">,</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="1866" end_char="1868">más</TOKEN>
<TOKEN id="token-10-28" pos="word" morph="none" start_char="1870" end_char="1873">allá</TOKEN>
<TOKEN id="token-10-29" pos="word" morph="none" start_char="1875" end_char="1877">del</TOKEN>
<TOKEN id="token-10-30" pos="word" morph="none" start_char="1879" end_char="1881">que</TOKEN>
<TOKEN id="token-10-31" pos="word" morph="none" start_char="1883" end_char="1889">provoca</TOKEN>
<TOKEN id="token-10-32" pos="word" morph="none" start_char="1891" end_char="1892">la</TOKEN>
<TOKEN id="token-10-33" pos="word" morph="none" start_char="1894" end_char="1899">famosa</TOKEN>
<TOKEN id="token-10-34" pos="unknown" morph="none" start_char="1901" end_char="1908">covid-19</TOKEN>
<TOKEN id="token-10-35" pos="punct" morph="none" start_char="1909" end_char="1909">,</TOKEN>
<TOKEN id="token-10-36" pos="word" morph="none" start_char="1911" end_char="1917">todavía</TOKEN>
<TOKEN id="token-10-37" pos="word" morph="none" start_char="1919" end_char="1924">tienen</TOKEN>
<TOKEN id="token-10-38" pos="word" morph="none" start_char="1926" end_char="1936">anticuerpos</TOKEN>
<TOKEN id="token-10-39" pos="word" morph="none" start_char="1938" end_char="1939">17</TOKEN>
<TOKEN id="token-10-40" pos="word" morph="none" start_char="1941" end_char="1944">años</TOKEN>
<TOKEN id="token-10-41" pos="word" morph="none" start_char="1946" end_char="1952">después</TOKEN>
<TOKEN id="token-10-42" pos="word" morph="none" start_char="1954" end_char="1955">de</TOKEN>
<TOKEN id="token-10-43" pos="word" morph="none" start_char="1957" end_char="1967">recuperarse</TOKEN>
<TOKEN id="token-10-44" pos="punct" morph="none" start_char="1968" end_char="1968">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1971" end_char="2186">
<ORIGINAL_TEXT>Hasta ahora la conclusión más optimista era la de la Universidad de Washington, que había constatado que ciertas células de "memoria" tras una infección de coronavirus persisten durante al menos 3 meses en el cuerpo.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1971" end_char="1975">Hasta</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1977" end_char="1981">ahora</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1983" end_char="1984">la</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1986" end_char="1995">conclusión</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1997" end_char="1999">más</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="2001" end_char="2009">optimista</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="2011" end_char="2013">era</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="2015" end_char="2016">la</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="2018" end_char="2019">de</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="2021" end_char="2022">la</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="2024" end_char="2034">Universidad</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="2036" end_char="2037">de</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="2039" end_char="2048">Washington</TOKEN>
<TOKEN id="token-11-13" pos="punct" morph="none" start_char="2049" end_char="2049">,</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="2051" end_char="2053">que</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="2055" end_char="2059">había</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="2061" end_char="2070">constatado</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="2072" end_char="2074">que</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="2076" end_char="2082">ciertas</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="2084" end_char="2090">células</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="2092" end_char="2093">de</TOKEN>
<TOKEN id="token-11-21" pos="punct" morph="none" start_char="2095" end_char="2095">"</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="2096" end_char="2102">memoria</TOKEN>
<TOKEN id="token-11-23" pos="punct" morph="none" start_char="2103" end_char="2103">"</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="2105" end_char="2108">tras</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="2110" end_char="2112">una</TOKEN>
<TOKEN id="token-11-26" pos="word" morph="none" start_char="2114" end_char="2122">infección</TOKEN>
<TOKEN id="token-11-27" pos="word" morph="none" start_char="2124" end_char="2125">de</TOKEN>
<TOKEN id="token-11-28" pos="word" morph="none" start_char="2127" end_char="2137">coronavirus</TOKEN>
<TOKEN id="token-11-29" pos="word" morph="none" start_char="2139" end_char="2147">persisten</TOKEN>
<TOKEN id="token-11-30" pos="word" morph="none" start_char="2149" end_char="2155">durante</TOKEN>
<TOKEN id="token-11-31" pos="word" morph="none" start_char="2157" end_char="2158">al</TOKEN>
<TOKEN id="token-11-32" pos="word" morph="none" start_char="2160" end_char="2164">menos</TOKEN>
<TOKEN id="token-11-33" pos="word" morph="none" start_char="2166" end_char="2166">3</TOKEN>
<TOKEN id="token-11-34" pos="word" morph="none" start_char="2168" end_char="2172">meses</TOKEN>
<TOKEN id="token-11-35" pos="word" morph="none" start_char="2174" end_char="2175">en</TOKEN>
<TOKEN id="token-11-36" pos="word" morph="none" start_char="2177" end_char="2178">el</TOKEN>
<TOKEN id="token-11-37" pos="word" morph="none" start_char="2180" end_char="2185">cuerpo</TOKEN>
<TOKEN id="token-11-38" pos="punct" morph="none" start_char="2186" end_char="2186">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
