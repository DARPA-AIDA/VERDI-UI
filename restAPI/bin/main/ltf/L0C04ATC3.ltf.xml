<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATC3" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="1985" raw_text_md5="8d532f9f9a472b899915948538852902">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="60">
<ORIGINAL_TEXT>Un estudio sitúa de nuevo al pangolín detrás del coronavirus</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="2">Un</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="4" end_char="10">estudio</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="12" end_char="16">sitúa</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="18" end_char="19">de</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="21" end_char="25">nuevo</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="27" end_char="28">al</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="30" end_char="37">pangolín</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="39" end_char="44">detrás</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="46" end_char="48">del</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="50" end_char="60">coronavirus</TOKEN>
</SEG>
<SEG id="segment-1" start_char="65" end_char="176">
<ORIGINAL_TEXT>Un nuevo estudio científico vuelve a apuntar al pangolín como el animal que originó la pandemia del coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="65" end_char="66">Un</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="68" end_char="72">nuevo</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="74" end_char="80">estudio</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="82" end_char="91">científico</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="93" end_char="98">vuelve</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="100" end_char="100">a</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="102" end_char="108">apuntar</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="110" end_char="111">al</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="113" end_char="120">pangolín</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="122" end_char="125">como</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="127" end_char="128">el</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="130" end_char="135">animal</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="137" end_char="139">que</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="141" end_char="147">originó</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="149" end_char="150">la</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="152" end_char="159">pandemia</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="161" end_char="163">del</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="165" end_char="175">coronavirus</TOKEN>
<TOKEN id="token-1-18" pos="punct" morph="none" start_char="176" end_char="176">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="178" end_char="456">
<ORIGINAL_TEXT>Se trata de una investigación liderada por Edward Holmes, un virólogo evolutivo de la Universidad de Sydney (Australia), y en ella se identifica a estos mamíferos como posibles huéspedes intermedios para el virus humano que se está extendiendo por todos los rincones del planeta.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="178" end_char="179">Se</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="181" end_char="185">trata</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="187" end_char="188">de</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="190" end_char="192">una</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="194" end_char="206">investigación</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="208" end_char="215">liderada</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="217" end_char="219">por</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="221" end_char="226">Edward</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="228" end_char="233">Holmes</TOKEN>
<TOKEN id="token-2-9" pos="punct" morph="none" start_char="234" end_char="234">,</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="236" end_char="237">un</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="239" end_char="246">virólogo</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="248" end_char="256">evolutivo</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="258" end_char="259">de</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="261" end_char="262">la</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="264" end_char="274">Universidad</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="276" end_char="277">de</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="279" end_char="284">Sydney</TOKEN>
<TOKEN id="token-2-18" pos="punct" morph="none" start_char="286" end_char="286">(</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="287" end_char="295">Australia</TOKEN>
<TOKEN id="token-2-20" pos="punct" morph="none" start_char="296" end_char="297">),</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="299" end_char="299">y</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="301" end_char="302">en</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="304" end_char="307">ella</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="309" end_char="310">se</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="312" end_char="321">identifica</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="323" end_char="323">a</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="325" end_char="329">estos</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="331" end_char="339">mamíferos</TOKEN>
<TOKEN id="token-2-29" pos="word" morph="none" start_char="341" end_char="344">como</TOKEN>
<TOKEN id="token-2-30" pos="word" morph="none" start_char="346" end_char="353">posibles</TOKEN>
<TOKEN id="token-2-31" pos="word" morph="none" start_char="355" end_char="363">huéspedes</TOKEN>
<TOKEN id="token-2-32" pos="word" morph="none" start_char="365" end_char="375">intermedios</TOKEN>
<TOKEN id="token-2-33" pos="word" morph="none" start_char="377" end_char="380">para</TOKEN>
<TOKEN id="token-2-34" pos="word" morph="none" start_char="382" end_char="383">el</TOKEN>
<TOKEN id="token-2-35" pos="word" morph="none" start_char="385" end_char="389">virus</TOKEN>
<TOKEN id="token-2-36" pos="word" morph="none" start_char="391" end_char="396">humano</TOKEN>
<TOKEN id="token-2-37" pos="word" morph="none" start_char="398" end_char="400">que</TOKEN>
<TOKEN id="token-2-38" pos="word" morph="none" start_char="402" end_char="403">se</TOKEN>
<TOKEN id="token-2-39" pos="word" morph="none" start_char="405" end_char="408">está</TOKEN>
<TOKEN id="token-2-40" pos="word" morph="none" start_char="410" end_char="420">extendiendo</TOKEN>
<TOKEN id="token-2-41" pos="word" morph="none" start_char="422" end_char="424">por</TOKEN>
<TOKEN id="token-2-42" pos="word" morph="none" start_char="426" end_char="430">todos</TOKEN>
<TOKEN id="token-2-43" pos="word" morph="none" start_char="432" end_char="434">los</TOKEN>
<TOKEN id="token-2-44" pos="word" morph="none" start_char="436" end_char="443">rincones</TOKEN>
<TOKEN id="token-2-45" pos="word" morph="none" start_char="445" end_char="447">del</TOKEN>
<TOKEN id="token-2-46" pos="word" morph="none" start_char="449" end_char="455">planeta</TOKEN>
<TOKEN id="token-2-47" pos="punct" morph="none" start_char="456" end_char="456">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="459" end_char="567">
<ORIGINAL_TEXT>"El papel que juegan los pangolines en la aparición del SARS-CoV-2 (la causa del covid-19) aún no está claro.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="punct" morph="none" start_char="459" end_char="459">"</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="460" end_char="461">El</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="463" end_char="467">papel</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="469" end_char="471">que</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="473" end_char="478">juegan</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="480" end_char="482">los</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="484" end_char="493">pangolines</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="495" end_char="496">en</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="498" end_char="499">la</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="501" end_char="509">aparición</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="511" end_char="513">del</TOKEN>
<TOKEN id="token-3-11" pos="unknown" morph="none" start_char="515" end_char="524">SARS-CoV-2</TOKEN>
<TOKEN id="token-3-12" pos="punct" morph="none" start_char="526" end_char="526">(</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="527" end_char="528">la</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="530" end_char="534">causa</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="536" end_char="538">del</TOKEN>
<TOKEN id="token-3-16" pos="unknown" morph="none" start_char="540" end_char="547">covid-19</TOKEN>
<TOKEN id="token-3-17" pos="punct" morph="none" start_char="548" end_char="548">)</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="550" end_char="552">aún</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="554" end_char="555">no</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="557" end_char="560">está</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="562" end_char="566">claro</TOKEN>
<TOKEN id="token-3-22" pos="punct" morph="none" start_char="567" end_char="567">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="569" end_char="710">
<ORIGINAL_TEXT>Sin embargo, es sorprendente que los virus de este animal contengan algunas regiones genómicas que están muy relacionadas con el virus humano.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="569" end_char="571">Sin</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="573" end_char="579">embargo</TOKEN>
<TOKEN id="token-4-2" pos="punct" morph="none" start_char="580" end_char="580">,</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="582" end_char="583">es</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="585" end_char="596">sorprendente</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="598" end_char="600">que</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="602" end_char="604">los</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="606" end_char="610">virus</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="612" end_char="613">de</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="615" end_char="618">este</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="620" end_char="625">animal</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="627" end_char="635">contengan</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="637" end_char="643">algunas</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="645" end_char="652">regiones</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="654" end_char="662">genómicas</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="664" end_char="666">que</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="668" end_char="672">están</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="674" end_char="676">muy</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="678" end_char="689">relacionadas</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="691" end_char="693">con</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="695" end_char="696">el</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="698" end_char="702">virus</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="704" end_char="709">humano</TOKEN>
<TOKEN id="token-4-23" pos="punct" morph="none" start_char="710" end_char="710">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="712" end_char="905">
<ORIGINAL_TEXT>El más importante de estos es el dominio de unión al receptor que dicta cómo el virus puede unirse e infectar células humanas", afirmó Holmes en declaraciones que recoge la agencia Europa Press.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="712" end_char="713">El</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="715" end_char="717">más</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="719" end_char="728">importante</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="730" end_char="731">de</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="733" end_char="737">estos</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="739" end_char="740">es</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="742" end_char="743">el</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="745" end_char="751">dominio</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="753" end_char="754">de</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="756" end_char="760">unión</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="762" end_char="763">al</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="765" end_char="772">receptor</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="774" end_char="776">que</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="778" end_char="782">dicta</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="784" end_char="787">cómo</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="789" end_char="790">el</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="792" end_char="796">virus</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="798" end_char="802">puede</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="804" end_char="809">unirse</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="811" end_char="811">e</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="813" end_char="820">infectar</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="822" end_char="828">células</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="830" end_char="836">humanas</TOKEN>
<TOKEN id="token-5-23" pos="punct" morph="none" start_char="837" end_char="838">",</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="840" end_char="845">afirmó</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="847" end_char="852">Holmes</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="854" end_char="855">en</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="857" end_char="869">declaraciones</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="871" end_char="873">que</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="875" end_char="880">recoge</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="882" end_char="883">la</TOKEN>
<TOKEN id="token-5-31" pos="word" morph="none" start_char="885" end_char="891">agencia</TOKEN>
<TOKEN id="token-5-32" pos="word" morph="none" start_char="893" end_char="898">Europa</TOKEN>
<TOKEN id="token-5-33" pos="word" morph="none" start_char="900" end_char="904">Press</TOKEN>
<TOKEN id="token-5-34" pos="punct" morph="none" start_char="905" end_char="905">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="908" end_char="1112">
<ORIGINAL_TEXT>Los responsables de la investigación han solicitado que se impida la venta de pangolines y otros animales salvajes en mercadillos para evitar que puedan trasmitirse nuevas enfermedades a los seres humanos.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="908" end_char="910">Los</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="912" end_char="923">responsables</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="925" end_char="926">de</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="928" end_char="929">la</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="931" end_char="943">investigación</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="945" end_char="947">han</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="949" end_char="958">solicitado</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="960" end_char="962">que</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="964" end_char="965">se</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="967" end_char="972">impida</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="974" end_char="975">la</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="977" end_char="981">venta</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="983" end_char="984">de</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="986" end_char="995">pangolines</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="997" end_char="997">y</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="999" end_char="1003">otros</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="1005" end_char="1012">animales</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="1014" end_char="1021">salvajes</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="1023" end_char="1024">en</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="1026" end_char="1036">mercadillos</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="1038" end_char="1041">para</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="1043" end_char="1048">evitar</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="1050" end_char="1052">que</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="1054" end_char="1059">puedan</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="1061" end_char="1071">trasmitirse</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="1073" end_char="1078">nuevas</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="1080" end_char="1091">enfermedades</TOKEN>
<TOKEN id="token-6-27" pos="word" morph="none" start_char="1093" end_char="1093">a</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="1095" end_char="1097">los</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="1099" end_char="1103">seres</TOKEN>
<TOKEN id="token-6-30" pos="word" morph="none" start_char="1105" end_char="1111">humanos</TOKEN>
<TOKEN id="token-6-31" pos="punct" morph="none" start_char="1112" end_char="1112">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="1114" end_char="1282">
<ORIGINAL_TEXT>El pangolín, animal que se encuentra en peligro de extinción, es utilizado en China y otros países asiáticos como alimento y para la creación de medicinas tradicionales.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="1114" end_char="1115">El</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="1117" end_char="1124">pangolín</TOKEN>
<TOKEN id="token-7-2" pos="punct" morph="none" start_char="1125" end_char="1125">,</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="1127" end_char="1132">animal</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="1134" end_char="1136">que</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="1138" end_char="1139">se</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="1141" end_char="1149">encuentra</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="1151" end_char="1152">en</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="1154" end_char="1160">peligro</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="1162" end_char="1163">de</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="1165" end_char="1173">extinción</TOKEN>
<TOKEN id="token-7-11" pos="punct" morph="none" start_char="1174" end_char="1174">,</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="1176" end_char="1177">es</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="1179" end_char="1187">utilizado</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="1189" end_char="1190">en</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="1192" end_char="1196">China</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="1198" end_char="1198">y</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="1200" end_char="1204">otros</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="1206" end_char="1211">países</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="1213" end_char="1221">asiáticos</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="1223" end_char="1226">como</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="1228" end_char="1235">alimento</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="1237" end_char="1237">y</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="1239" end_char="1242">para</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="1244" end_char="1245">la</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="1247" end_char="1254">creación</TOKEN>
<TOKEN id="token-7-26" pos="word" morph="none" start_char="1256" end_char="1257">de</TOKEN>
<TOKEN id="token-7-27" pos="word" morph="none" start_char="1259" end_char="1267">medicinas</TOKEN>
<TOKEN id="token-7-28" pos="word" morph="none" start_char="1269" end_char="1281">tradicionales</TOKEN>
<TOKEN id="token-7-29" pos="punct" morph="none" start_char="1282" end_char="1282">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1284" end_char="1521">
<ORIGINAL_TEXT>"Los coronavirus claramente tienen la capacidad de saltar los límites de las especies y adaptarse a los nuevos huéspedes, lo que hace que sea fácil predecir que surgirán más en el futuro", asegura el documento que recoge la investigación.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="punct" morph="none" start_char="1284" end_char="1284">"</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1285" end_char="1287">Los</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1289" end_char="1299">coronavirus</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1301" end_char="1310">claramente</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1312" end_char="1317">tienen</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1319" end_char="1320">la</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1322" end_char="1330">capacidad</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1332" end_char="1333">de</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1335" end_char="1340">saltar</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1342" end_char="1344">los</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1346" end_char="1352">límites</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1354" end_char="1355">de</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1357" end_char="1359">las</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1361" end_char="1368">especies</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1370" end_char="1370">y</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1372" end_char="1380">adaptarse</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1382" end_char="1382">a</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1384" end_char="1386">los</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1388" end_char="1393">nuevos</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1395" end_char="1403">huéspedes</TOKEN>
<TOKEN id="token-8-20" pos="punct" morph="none" start_char="1404" end_char="1404">,</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="1406" end_char="1407">lo</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="1409" end_char="1411">que</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="1413" end_char="1416">hace</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="1418" end_char="1420">que</TOKEN>
<TOKEN id="token-8-25" pos="word" morph="none" start_char="1422" end_char="1424">sea</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="1426" end_char="1430">fácil</TOKEN>
<TOKEN id="token-8-27" pos="word" morph="none" start_char="1432" end_char="1439">predecir</TOKEN>
<TOKEN id="token-8-28" pos="word" morph="none" start_char="1441" end_char="1443">que</TOKEN>
<TOKEN id="token-8-29" pos="word" morph="none" start_char="1445" end_char="1452">surgirán</TOKEN>
<TOKEN id="token-8-30" pos="word" morph="none" start_char="1454" end_char="1456">más</TOKEN>
<TOKEN id="token-8-31" pos="word" morph="none" start_char="1458" end_char="1459">en</TOKEN>
<TOKEN id="token-8-32" pos="word" morph="none" start_char="1461" end_char="1462">el</TOKEN>
<TOKEN id="token-8-33" pos="word" morph="none" start_char="1464" end_char="1469">futuro</TOKEN>
<TOKEN id="token-8-34" pos="punct" morph="none" start_char="1470" end_char="1471">",</TOKEN>
<TOKEN id="token-8-35" pos="word" morph="none" start_char="1473" end_char="1479">asegura</TOKEN>
<TOKEN id="token-8-36" pos="word" morph="none" start_char="1481" end_char="1482">el</TOKEN>
<TOKEN id="token-8-37" pos="word" morph="none" start_char="1484" end_char="1492">documento</TOKEN>
<TOKEN id="token-8-38" pos="word" morph="none" start_char="1494" end_char="1496">que</TOKEN>
<TOKEN id="token-8-39" pos="word" morph="none" start_char="1498" end_char="1503">recoge</TOKEN>
<TOKEN id="token-8-40" pos="word" morph="none" start_char="1505" end_char="1506">la</TOKEN>
<TOKEN id="token-8-41" pos="word" morph="none" start_char="1508" end_char="1520">investigación</TOKEN>
<TOKEN id="token-8-42" pos="punct" morph="none" start_char="1521" end_char="1521">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1524" end_char="1544">
<ORIGINAL_TEXT>Otras investigaciones</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1524" end_char="1528">Otras</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1530" end_char="1544">investigaciones</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1548" end_char="1651">
<ORIGINAL_TEXT>No es el primer estudio que señala a los pangolines como el ser que está detrás del origen del COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1548" end_char="1549">No</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1551" end_char="1552">es</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1554" end_char="1555">el</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1557" end_char="1562">primer</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1564" end_char="1570">estudio</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1572" end_char="1574">que</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1576" end_char="1581">señala</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1583" end_char="1583">a</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1585" end_char="1587">los</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1589" end_char="1598">pangolines</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1600" end_char="1603">como</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1605" end_char="1606">el</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1608" end_char="1610">ser</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1612" end_char="1614">que</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1616" end_char="1619">está</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1621" end_char="1626">detrás</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1628" end_char="1630">del</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1632" end_char="1637">origen</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1639" end_char="1641">del</TOKEN>
<TOKEN id="token-10-19" pos="unknown" morph="none" start_char="1643" end_char="1650">COVID-19</TOKEN>
<TOKEN id="token-10-20" pos="punct" morph="none" start_char="1651" end_char="1651">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1653" end_char="1822">
<ORIGINAL_TEXT>Una investigación de la Universidad Agrícola del Sur de China ya apuntó a la posibilidad real de que este animal hubiera podido ejercer como huésped intermedio del virus.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1653" end_char="1655">Una</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1657" end_char="1669">investigación</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1671" end_char="1672">de</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1674" end_char="1675">la</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1677" end_char="1687">Universidad</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1689" end_char="1696">Agrícola</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1698" end_char="1700">del</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1702" end_char="1704">Sur</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1706" end_char="1707">de</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1709" end_char="1713">China</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1715" end_char="1716">ya</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1718" end_char="1723">apuntó</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1725" end_char="1725">a</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1727" end_char="1728">la</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1730" end_char="1740">posibilidad</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1742" end_char="1745">real</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1747" end_char="1748">de</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1750" end_char="1752">que</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1754" end_char="1757">este</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="1759" end_char="1764">animal</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1766" end_char="1772">hubiera</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="1774" end_char="1779">podido</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="1781" end_char="1787">ejercer</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="1789" end_char="1792">como</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="1794" end_char="1800">huésped</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="1802" end_char="1811">intermedio</TOKEN>
<TOKEN id="token-11-26" pos="word" morph="none" start_char="1813" end_char="1815">del</TOKEN>
<TOKEN id="token-11-27" pos="word" morph="none" start_char="1817" end_char="1821">virus</TOKEN>
<TOKEN id="token-11-28" pos="punct" morph="none" start_char="1822" end_char="1822">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1824" end_char="1979">
<ORIGINAL_TEXT>Según sus conclusiones, la secuencia del genoma de la nueva cepa de coronavirus separada de los pangolines era 99% idéntica a la de las personas infectadas.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1824" end_char="1828">Según</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1830" end_char="1832">sus</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1834" end_char="1845">conclusiones</TOKEN>
<TOKEN id="token-12-3" pos="punct" morph="none" start_char="1846" end_char="1846">,</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1848" end_char="1849">la</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1851" end_char="1859">secuencia</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1861" end_char="1863">del</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1865" end_char="1870">genoma</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1872" end_char="1873">de</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1875" end_char="1876">la</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1878" end_char="1882">nueva</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1884" end_char="1887">cepa</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1889" end_char="1890">de</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1892" end_char="1902">coronavirus</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1904" end_char="1911">separada</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1913" end_char="1914">de</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1916" end_char="1918">los</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1920" end_char="1929">pangolines</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1931" end_char="1933">era</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1935" end_char="1936">99</TOKEN>
<TOKEN id="token-12-20" pos="punct" morph="none" start_char="1937" end_char="1937">%</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1939" end_char="1946">idéntica</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1948" end_char="1948">a</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="1950" end_char="1951">la</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="1953" end_char="1954">de</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="1956" end_char="1958">las</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="1960" end_char="1967">personas</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="1969" end_char="1978">infectadas</TOKEN>
<TOKEN id="token-12-28" pos="punct" morph="none" start_char="1979" end_char="1979">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
