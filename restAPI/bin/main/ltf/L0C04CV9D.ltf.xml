<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CV9D" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="3191" raw_text_md5="2a1ba9c12e191d39d49d198df900aaaf">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="110">
<ORIGINAL_TEXT>Descubrimiento venezolano contra el coronavirus: todavía es pronto para afirmar que es un tratamiento efectivo</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="14">Descubrimiento</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="16" end_char="25">venezolano</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="27" end_char="32">contra</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="34" end_char="35">el</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="37" end_char="47">coronavirus</TOKEN>
<TOKEN id="token-0-5" pos="punct" morph="none" start_char="48" end_char="48">:</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="50" end_char="56">todavía</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="58" end_char="59">es</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="61" end_char="66">pronto</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="68" end_char="71">para</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="73" end_char="79">afirmar</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="81" end_char="83">que</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="85" end_char="86">es</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="88" end_char="89">un</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="91" end_char="101">tratamiento</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="103" end_char="110">efectivo</TOKEN>
</SEG>
<SEG id="segment-1" start_char="115" end_char="247">
<ORIGINAL_TEXT>"Venezuela ha conseguido una medicina que anula el 100% el coronavirus", anunció el presidente de ese país Nicolás Maduro días atrás.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="punct" morph="none" start_char="115" end_char="115">"</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="116" end_char="124">Venezuela</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="126" end_char="127">ha</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="129" end_char="138">conseguido</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="140" end_char="142">una</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="144" end_char="151">medicina</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="153" end_char="155">que</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="157" end_char="161">anula</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="163" end_char="164">el</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="166" end_char="168">100</TOKEN>
<TOKEN id="token-1-10" pos="punct" morph="none" start_char="169" end_char="169">%</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="171" end_char="172">el</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="174" end_char="184">coronavirus</TOKEN>
<TOKEN id="token-1-13" pos="punct" morph="none" start_char="185" end_char="186">",</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="188" end_char="194">anunció</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="196" end_char="197">el</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="199" end_char="208">presidente</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="210" end_char="211">de</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="213" end_char="215">ese</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="217" end_char="220">país</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="222" end_char="228">Nicolás</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="230" end_char="235">Maduro</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="237" end_char="240">días</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="242" end_char="246">atrás</TOKEN>
<TOKEN id="token-1-24" pos="punct" morph="none" start_char="247" end_char="247">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="249" end_char="523">
<ORIGINAL_TEXT>El mandatario se refirió a los resultados de una investigación llevada a cabo por el Instituto Venezolano de Investigaciones Científicas (IVIC), pero todavía es muy pronto para asegurar que este desarrollo se convertirá en un tratamiento efectivo y seguro contra la COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="249" end_char="250">El</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="252" end_char="261">mandatario</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="263" end_char="264">se</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="266" end_char="272">refirió</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="274" end_char="274">a</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="276" end_char="278">los</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="280" end_char="289">resultados</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="291" end_char="292">de</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="294" end_char="296">una</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="298" end_char="310">investigación</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="312" end_char="318">llevada</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="320" end_char="320">a</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="322" end_char="325">cabo</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="327" end_char="329">por</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="331" end_char="332">el</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="334" end_char="342">Instituto</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="344" end_char="353">Venezolano</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="355" end_char="356">de</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="358" end_char="372">Investigaciones</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="374" end_char="384">Científicas</TOKEN>
<TOKEN id="token-2-20" pos="punct" morph="none" start_char="386" end_char="386">(</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="387" end_char="390">IVIC</TOKEN>
<TOKEN id="token-2-22" pos="punct" morph="none" start_char="391" end_char="392">),</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="394" end_char="397">pero</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="399" end_char="405">todavía</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="407" end_char="408">es</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="410" end_char="412">muy</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="414" end_char="419">pronto</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="421" end_char="424">para</TOKEN>
<TOKEN id="token-2-29" pos="word" morph="none" start_char="426" end_char="433">asegurar</TOKEN>
<TOKEN id="token-2-30" pos="word" morph="none" start_char="435" end_char="437">que</TOKEN>
<TOKEN id="token-2-31" pos="word" morph="none" start_char="439" end_char="442">este</TOKEN>
<TOKEN id="token-2-32" pos="word" morph="none" start_char="444" end_char="453">desarrollo</TOKEN>
<TOKEN id="token-2-33" pos="word" morph="none" start_char="455" end_char="456">se</TOKEN>
<TOKEN id="token-2-34" pos="word" morph="none" start_char="458" end_char="467">convertirá</TOKEN>
<TOKEN id="token-2-35" pos="word" morph="none" start_char="469" end_char="470">en</TOKEN>
<TOKEN id="token-2-36" pos="word" morph="none" start_char="472" end_char="473">un</TOKEN>
<TOKEN id="token-2-37" pos="word" morph="none" start_char="475" end_char="485">tratamiento</TOKEN>
<TOKEN id="token-2-38" pos="word" morph="none" start_char="487" end_char="494">efectivo</TOKEN>
<TOKEN id="token-2-39" pos="word" morph="none" start_char="496" end_char="496">y</TOKEN>
<TOKEN id="token-2-40" pos="word" morph="none" start_char="498" end_char="503">seguro</TOKEN>
<TOKEN id="token-2-41" pos="word" morph="none" start_char="505" end_char="510">contra</TOKEN>
<TOKEN id="token-2-42" pos="word" morph="none" start_char="512" end_char="513">la</TOKEN>
<TOKEN id="token-2-43" pos="unknown" morph="none" start_char="515" end_char="522">COVID-19</TOKEN>
<TOKEN id="token-2-44" pos="punct" morph="none" start_char="523" end_char="523">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="526" end_char="819">
<ORIGINAL_TEXT>Según indicó el propio Ministerio para Ciencia y Tecnología de Venezuela a través de su cuenta de Twitter, "Venezuela tiene aislada la molécula descubierta, el informe técnico-químico y la evaluación de la actividad biológica atribuida (100% inhibidora del SARS- CoV-2 en cultivos «in vitro»)".</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="526" end_char="530">Según</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="532" end_char="537">indicó</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="539" end_char="540">el</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="542" end_char="547">propio</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="549" end_char="558">Ministerio</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="560" end_char="563">para</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="565" end_char="571">Ciencia</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="573" end_char="573">y</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="575" end_char="584">Tecnología</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="586" end_char="587">de</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="589" end_char="597">Venezuela</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="599" end_char="599">a</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="601" end_char="606">través</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="608" end_char="609">de</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="611" end_char="612">su</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="614" end_char="619">cuenta</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="621" end_char="622">de</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="624" end_char="630">Twitter</TOKEN>
<TOKEN id="token-3-18" pos="punct" morph="none" start_char="631" end_char="631">,</TOKEN>
<TOKEN id="token-3-19" pos="punct" morph="none" start_char="633" end_char="633">"</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="634" end_char="642">Venezuela</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="644" end_char="648">tiene</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="650" end_char="656">aislada</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="658" end_char="659">la</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="661" end_char="668">molécula</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="670" end_char="680">descubierta</TOKEN>
<TOKEN id="token-3-26" pos="punct" morph="none" start_char="681" end_char="681">,</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="683" end_char="684">el</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="686" end_char="692">informe</TOKEN>
<TOKEN id="token-3-29" pos="unknown" morph="none" start_char="694" end_char="708">técnico-químico</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="710" end_char="710">y</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="712" end_char="713">la</TOKEN>
<TOKEN id="token-3-32" pos="word" morph="none" start_char="715" end_char="724">evaluación</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="726" end_char="727">de</TOKEN>
<TOKEN id="token-3-34" pos="word" morph="none" start_char="729" end_char="730">la</TOKEN>
<TOKEN id="token-3-35" pos="word" morph="none" start_char="732" end_char="740">actividad</TOKEN>
<TOKEN id="token-3-36" pos="word" morph="none" start_char="742" end_char="750">biológica</TOKEN>
<TOKEN id="token-3-37" pos="word" morph="none" start_char="752" end_char="760">atribuida</TOKEN>
<TOKEN id="token-3-38" pos="punct" morph="none" start_char="762" end_char="762">(</TOKEN>
<TOKEN id="token-3-39" pos="word" morph="none" start_char="763" end_char="765">100</TOKEN>
<TOKEN id="token-3-40" pos="punct" morph="none" start_char="766" end_char="766">%</TOKEN>
<TOKEN id="token-3-41" pos="word" morph="none" start_char="768" end_char="777">inhibidora</TOKEN>
<TOKEN id="token-3-42" pos="word" morph="none" start_char="779" end_char="781">del</TOKEN>
<TOKEN id="token-3-43" pos="word" morph="none" start_char="783" end_char="786">SARS</TOKEN>
<TOKEN id="token-3-44" pos="punct" morph="none" start_char="787" end_char="787">-</TOKEN>
<TOKEN id="token-3-45" pos="unknown" morph="none" start_char="789" end_char="793">CoV-2</TOKEN>
<TOKEN id="token-3-46" pos="word" morph="none" start_char="795" end_char="796">en</TOKEN>
<TOKEN id="token-3-47" pos="word" morph="none" start_char="798" end_char="805">cultivos</TOKEN>
<TOKEN id="token-3-48" pos="punct" morph="none" start_char="807" end_char="807">«</TOKEN>
<TOKEN id="token-3-49" pos="word" morph="none" start_char="808" end_char="809">in</TOKEN>
<TOKEN id="token-3-50" pos="word" morph="none" start_char="811" end_char="815">vitro</TOKEN>
<TOKEN id="token-3-51" pos="punct" morph="none" start_char="816" end_char="819">»)".</TOKEN>
</SEG>
<SEG id="segment-4" start_char="822" end_char="1041">
<ORIGINAL_TEXT>Los cultivos in vitro forman parte de estudios pre clínicos, que sirven para probar el efecto que una molécula con uso potencial como medicamento puede tener sobre el virus en condiciones artificiales, en el laboratorio.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="822" end_char="824">Los</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="826" end_char="833">cultivos</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="835" end_char="836">in</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="838" end_char="842">vitro</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="844" end_char="849">forman</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="851" end_char="855">parte</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="857" end_char="858">de</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="860" end_char="867">estudios</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="869" end_char="871">pre</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="873" end_char="880">clínicos</TOKEN>
<TOKEN id="token-4-10" pos="punct" morph="none" start_char="881" end_char="881">,</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="883" end_char="885">que</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="887" end_char="892">sirven</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="894" end_char="897">para</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="899" end_char="904">probar</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="906" end_char="907">el</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="909" end_char="914">efecto</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="916" end_char="918">que</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="920" end_char="922">una</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="924" end_char="931">molécula</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="933" end_char="935">con</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="937" end_char="939">uso</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="941" end_char="949">potencial</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="951" end_char="954">como</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="956" end_char="966">medicamento</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="968" end_char="972">puede</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="974" end_char="978">tener</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="980" end_char="984">sobre</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="986" end_char="987">el</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="989" end_char="993">virus</TOKEN>
<TOKEN id="token-4-30" pos="word" morph="none" start_char="995" end_char="996">en</TOKEN>
<TOKEN id="token-4-31" pos="word" morph="none" start_char="998" end_char="1008">condiciones</TOKEN>
<TOKEN id="token-4-32" pos="word" morph="none" start_char="1010" end_char="1021">artificiales</TOKEN>
<TOKEN id="token-4-33" pos="punct" morph="none" start_char="1022" end_char="1022">,</TOKEN>
<TOKEN id="token-4-34" pos="word" morph="none" start_char="1024" end_char="1025">en</TOKEN>
<TOKEN id="token-4-35" pos="word" morph="none" start_char="1027" end_char="1028">el</TOKEN>
<TOKEN id="token-4-36" pos="word" morph="none" start_char="1030" end_char="1040">laboratorio</TOKEN>
<TOKEN id="token-4-37" pos="punct" morph="none" start_char="1041" end_char="1041">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="1043" end_char="1181">
<ORIGINAL_TEXT>Como no toman en cuenta las particularidades que se pueden dar dentro del cuerpo humano, no son concluyentes, como se explicó en esta nota.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="1043" end_char="1046">Como</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="1048" end_char="1049">no</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="1051" end_char="1055">toman</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="1057" end_char="1058">en</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="1060" end_char="1065">cuenta</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="1067" end_char="1069">las</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="1071" end_char="1086">particularidades</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="1088" end_char="1090">que</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="1092" end_char="1093">se</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="1095" end_char="1100">pueden</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="1102" end_char="1104">dar</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="1106" end_char="1111">dentro</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="1113" end_char="1115">del</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="1117" end_char="1122">cuerpo</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="1124" end_char="1129">humano</TOKEN>
<TOKEN id="token-5-15" pos="punct" morph="none" start_char="1130" end_char="1130">,</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="1132" end_char="1133">no</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="1135" end_char="1137">son</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="1139" end_char="1150">concluyentes</TOKEN>
<TOKEN id="token-5-19" pos="punct" morph="none" start_char="1151" end_char="1151">,</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="1153" end_char="1156">como</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="1158" end_char="1159">se</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="1161" end_char="1167">explicó</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="1169" end_char="1170">en</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="1172" end_char="1175">esta</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="1177" end_char="1180">nota</TOKEN>
<TOKEN id="token-5-26" pos="punct" morph="none" start_char="1181" end_char="1181">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="1184" end_char="1437">
<ORIGINAL_TEXT>Si en los estudios pre clínicos el potencial medicamento produce resultados satisfactorios, luego se pasa a la etapa de ensayos clínicos en seres humanos para comprobar seguridad y eficacia, lo que puede llevar varios meses y hasta años de investigación.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="1184" end_char="1185">Si</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="1187" end_char="1188">en</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="1190" end_char="1192">los</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="1194" end_char="1201">estudios</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="1203" end_char="1205">pre</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="1207" end_char="1214">clínicos</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="1216" end_char="1217">el</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="1219" end_char="1227">potencial</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="1229" end_char="1239">medicamento</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="1241" end_char="1247">produce</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="1249" end_char="1258">resultados</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="1260" end_char="1273">satisfactorios</TOKEN>
<TOKEN id="token-6-12" pos="punct" morph="none" start_char="1274" end_char="1274">,</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="1276" end_char="1280">luego</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="1282" end_char="1283">se</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="1285" end_char="1288">pasa</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="1290" end_char="1290">a</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="1292" end_char="1293">la</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="1295" end_char="1299">etapa</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="1301" end_char="1302">de</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="1304" end_char="1310">ensayos</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="1312" end_char="1319">clínicos</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="1321" end_char="1322">en</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="1324" end_char="1328">seres</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="1330" end_char="1336">humanos</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="1338" end_char="1341">para</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="1343" end_char="1351">comprobar</TOKEN>
<TOKEN id="token-6-27" pos="word" morph="none" start_char="1353" end_char="1361">seguridad</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="1363" end_char="1363">y</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="1365" end_char="1372">eficacia</TOKEN>
<TOKEN id="token-6-30" pos="punct" morph="none" start_char="1373" end_char="1373">,</TOKEN>
<TOKEN id="token-6-31" pos="word" morph="none" start_char="1375" end_char="1376">lo</TOKEN>
<TOKEN id="token-6-32" pos="word" morph="none" start_char="1378" end_char="1380">que</TOKEN>
<TOKEN id="token-6-33" pos="word" morph="none" start_char="1382" end_char="1386">puede</TOKEN>
<TOKEN id="token-6-34" pos="word" morph="none" start_char="1388" end_char="1393">llevar</TOKEN>
<TOKEN id="token-6-35" pos="word" morph="none" start_char="1395" end_char="1400">varios</TOKEN>
<TOKEN id="token-6-36" pos="word" morph="none" start_char="1402" end_char="1406">meses</TOKEN>
<TOKEN id="token-6-37" pos="word" morph="none" start_char="1408" end_char="1408">y</TOKEN>
<TOKEN id="token-6-38" pos="word" morph="none" start_char="1410" end_char="1414">hasta</TOKEN>
<TOKEN id="token-6-39" pos="word" morph="none" start_char="1416" end_char="1419">años</TOKEN>
<TOKEN id="token-6-40" pos="word" morph="none" start_char="1421" end_char="1422">de</TOKEN>
<TOKEN id="token-6-41" pos="word" morph="none" start_char="1424" end_char="1436">investigación</TOKEN>
<TOKEN id="token-6-42" pos="punct" morph="none" start_char="1437" end_char="1437">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="1440" end_char="1585">
<ORIGINAL_TEXT>Los ensayos clínicos aleatorizados, en donde algunos participantes reciben el tratamiento y otros un placebo, producen la evidencia más confiable.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="1440" end_char="1442">Los</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="1444" end_char="1450">ensayos</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="1452" end_char="1459">clínicos</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="1461" end_char="1473">aleatorizados</TOKEN>
<TOKEN id="token-7-4" pos="punct" morph="none" start_char="1474" end_char="1474">,</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="1476" end_char="1477">en</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="1479" end_char="1483">donde</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="1485" end_char="1491">algunos</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="1493" end_char="1505">participantes</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="1507" end_char="1513">reciben</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="1515" end_char="1516">el</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="1518" end_char="1528">tratamiento</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="1530" end_char="1530">y</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="1532" end_char="1536">otros</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="1538" end_char="1539">un</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="1541" end_char="1547">placebo</TOKEN>
<TOKEN id="token-7-16" pos="punct" morph="none" start_char="1548" end_char="1548">,</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="1550" end_char="1557">producen</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="1559" end_char="1560">la</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="1562" end_char="1570">evidencia</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="1572" end_char="1574">más</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="1576" end_char="1584">confiable</TOKEN>
<TOKEN id="token-7-22" pos="punct" morph="none" start_char="1585" end_char="1585">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1587" end_char="1716">
<ORIGINAL_TEXT>Además, es importante que las investigaciones científicas sean publicadas y revisadas por sus pares, para asegurar la rigurosidad.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1587" end_char="1592">Además</TOKEN>
<TOKEN id="token-8-1" pos="punct" morph="none" start_char="1593" end_char="1593">,</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1595" end_char="1596">es</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1598" end_char="1607">importante</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1609" end_char="1611">que</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1613" end_char="1615">las</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1617" end_char="1631">investigaciones</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1633" end_char="1643">científicas</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1645" end_char="1648">sean</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1650" end_char="1659">publicadas</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1661" end_char="1661">y</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1663" end_char="1671">revisadas</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1673" end_char="1675">por</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1677" end_char="1679">sus</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1681" end_char="1685">pares</TOKEN>
<TOKEN id="token-8-15" pos="punct" morph="none" start_char="1686" end_char="1686">,</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1688" end_char="1691">para</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1693" end_char="1700">asegurar</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1702" end_char="1703">la</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1705" end_char="1715">rigurosidad</TOKEN>
<TOKEN id="token-8-20" pos="punct" morph="none" start_char="1716" end_char="1716">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1719" end_char="2159">
<ORIGINAL_TEXT>En esa línea, la Academia de Ciencias Físicas, Matemáticas y Naturales de Venezuela, que nuclea a académicos de distintas ramas, indicó que "no conoce de ninguna publicación en revistas científicas reconocidas internacionalmente que refieran a los resultados descritos" y exhortó "al Gobierno nacional a no publicar información equívoca o crear falsas expectativas en la población sobre la disponibilidad de tratamientos contra la COVID-19".</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1719" end_char="1720">En</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1722" end_char="1724">esa</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1726" end_char="1730">línea</TOKEN>
<TOKEN id="token-9-3" pos="punct" morph="none" start_char="1731" end_char="1731">,</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1733" end_char="1734">la</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1736" end_char="1743">Academia</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1745" end_char="1746">de</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1748" end_char="1755">Ciencias</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1757" end_char="1763">Físicas</TOKEN>
<TOKEN id="token-9-9" pos="punct" morph="none" start_char="1764" end_char="1764">,</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1766" end_char="1776">Matemáticas</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1778" end_char="1778">y</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1780" end_char="1788">Naturales</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1790" end_char="1791">de</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1793" end_char="1801">Venezuela</TOKEN>
<TOKEN id="token-9-15" pos="punct" morph="none" start_char="1802" end_char="1802">,</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1804" end_char="1806">que</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1808" end_char="1813">nuclea</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1815" end_char="1815">a</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1817" end_char="1826">académicos</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1828" end_char="1829">de</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1831" end_char="1839">distintas</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1841" end_char="1845">ramas</TOKEN>
<TOKEN id="token-9-23" pos="punct" morph="none" start_char="1846" end_char="1846">,</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1848" end_char="1853">indicó</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1855" end_char="1857">que</TOKEN>
<TOKEN id="token-9-26" pos="punct" morph="none" start_char="1859" end_char="1859">"</TOKEN>
<TOKEN id="token-9-27" pos="word" morph="none" start_char="1860" end_char="1861">no</TOKEN>
<TOKEN id="token-9-28" pos="word" morph="none" start_char="1863" end_char="1868">conoce</TOKEN>
<TOKEN id="token-9-29" pos="word" morph="none" start_char="1870" end_char="1871">de</TOKEN>
<TOKEN id="token-9-30" pos="word" morph="none" start_char="1873" end_char="1879">ninguna</TOKEN>
<TOKEN id="token-9-31" pos="word" morph="none" start_char="1881" end_char="1891">publicación</TOKEN>
<TOKEN id="token-9-32" pos="word" morph="none" start_char="1893" end_char="1894">en</TOKEN>
<TOKEN id="token-9-33" pos="word" morph="none" start_char="1896" end_char="1903">revistas</TOKEN>
<TOKEN id="token-9-34" pos="word" morph="none" start_char="1905" end_char="1915">científicas</TOKEN>
<TOKEN id="token-9-35" pos="word" morph="none" start_char="1917" end_char="1927">reconocidas</TOKEN>
<TOKEN id="token-9-36" pos="word" morph="none" start_char="1929" end_char="1946">internacionalmente</TOKEN>
<TOKEN id="token-9-37" pos="word" morph="none" start_char="1948" end_char="1950">que</TOKEN>
<TOKEN id="token-9-38" pos="word" morph="none" start_char="1952" end_char="1959">refieran</TOKEN>
<TOKEN id="token-9-39" pos="word" morph="none" start_char="1961" end_char="1961">a</TOKEN>
<TOKEN id="token-9-40" pos="word" morph="none" start_char="1963" end_char="1965">los</TOKEN>
<TOKEN id="token-9-41" pos="word" morph="none" start_char="1967" end_char="1976">resultados</TOKEN>
<TOKEN id="token-9-42" pos="word" morph="none" start_char="1978" end_char="1986">descritos</TOKEN>
<TOKEN id="token-9-43" pos="punct" morph="none" start_char="1987" end_char="1987">"</TOKEN>
<TOKEN id="token-9-44" pos="word" morph="none" start_char="1989" end_char="1989">y</TOKEN>
<TOKEN id="token-9-45" pos="word" morph="none" start_char="1991" end_char="1997">exhortó</TOKEN>
<TOKEN id="token-9-46" pos="punct" morph="none" start_char="1999" end_char="1999">"</TOKEN>
<TOKEN id="token-9-47" pos="word" morph="none" start_char="2000" end_char="2001">al</TOKEN>
<TOKEN id="token-9-48" pos="word" morph="none" start_char="2003" end_char="2010">Gobierno</TOKEN>
<TOKEN id="token-9-49" pos="word" morph="none" start_char="2012" end_char="2019">nacional</TOKEN>
<TOKEN id="token-9-50" pos="word" morph="none" start_char="2021" end_char="2021">a</TOKEN>
<TOKEN id="token-9-51" pos="word" morph="none" start_char="2023" end_char="2024">no</TOKEN>
<TOKEN id="token-9-52" pos="word" morph="none" start_char="2026" end_char="2033">publicar</TOKEN>
<TOKEN id="token-9-53" pos="word" morph="none" start_char="2035" end_char="2045">información</TOKEN>
<TOKEN id="token-9-54" pos="word" morph="none" start_char="2047" end_char="2054">equívoca</TOKEN>
<TOKEN id="token-9-55" pos="word" morph="none" start_char="2056" end_char="2056">o</TOKEN>
<TOKEN id="token-9-56" pos="word" morph="none" start_char="2058" end_char="2062">crear</TOKEN>
<TOKEN id="token-9-57" pos="word" morph="none" start_char="2064" end_char="2069">falsas</TOKEN>
<TOKEN id="token-9-58" pos="word" morph="none" start_char="2071" end_char="2082">expectativas</TOKEN>
<TOKEN id="token-9-59" pos="word" morph="none" start_char="2084" end_char="2085">en</TOKEN>
<TOKEN id="token-9-60" pos="word" morph="none" start_char="2087" end_char="2088">la</TOKEN>
<TOKEN id="token-9-61" pos="word" morph="none" start_char="2090" end_char="2098">población</TOKEN>
<TOKEN id="token-9-62" pos="word" morph="none" start_char="2100" end_char="2104">sobre</TOKEN>
<TOKEN id="token-9-63" pos="word" morph="none" start_char="2106" end_char="2107">la</TOKEN>
<TOKEN id="token-9-64" pos="word" morph="none" start_char="2109" end_char="2122">disponibilidad</TOKEN>
<TOKEN id="token-9-65" pos="word" morph="none" start_char="2124" end_char="2125">de</TOKEN>
<TOKEN id="token-9-66" pos="word" morph="none" start_char="2127" end_char="2138">tratamientos</TOKEN>
<TOKEN id="token-9-67" pos="word" morph="none" start_char="2140" end_char="2145">contra</TOKEN>
<TOKEN id="token-9-68" pos="word" morph="none" start_char="2147" end_char="2148">la</TOKEN>
<TOKEN id="token-9-69" pos="unknown" morph="none" start_char="2150" end_char="2157">COVID-19</TOKEN>
<TOKEN id="token-9-70" pos="punct" morph="none" start_char="2158" end_char="2159">".</TOKEN>
</SEG>
<SEG id="segment-10" start_char="2162" end_char="2516">
<ORIGINAL_TEXT>"El hallazgo de un agente con potencial activo contra cualquier patógeno (…) no es equivalente al descubrimiento de un medicamento", indicó la academia en un comunicado que también fue publicado por el medio venezolano Efecto Cocuyo, y agregó: "El desarrollo de un medicamento requiere de una serie de procedimientos (…) que pueden tomar años y no meses".</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="punct" morph="none" start_char="2162" end_char="2162">"</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="2163" end_char="2164">El</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="2166" end_char="2173">hallazgo</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="2175" end_char="2176">de</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="2178" end_char="2179">un</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="2181" end_char="2186">agente</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="2188" end_char="2190">con</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="2192" end_char="2200">potencial</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="2202" end_char="2207">activo</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="2209" end_char="2214">contra</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="2216" end_char="2224">cualquier</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="2226" end_char="2233">patógeno</TOKEN>
<TOKEN id="token-10-12" pos="punct" morph="none" start_char="2235" end_char="2237">(…)</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="2239" end_char="2240">no</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="2242" end_char="2243">es</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="2245" end_char="2255">equivalente</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="2257" end_char="2258">al</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="2260" end_char="2273">descubrimiento</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="2275" end_char="2276">de</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="2278" end_char="2279">un</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="2281" end_char="2291">medicamento</TOKEN>
<TOKEN id="token-10-21" pos="punct" morph="none" start_char="2292" end_char="2293">",</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="2295" end_char="2300">indicó</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="2302" end_char="2303">la</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="2305" end_char="2312">academia</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="2314" end_char="2315">en</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="2317" end_char="2318">un</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="2320" end_char="2329">comunicado</TOKEN>
<TOKEN id="token-10-28" pos="word" morph="none" start_char="2331" end_char="2333">que</TOKEN>
<TOKEN id="token-10-29" pos="word" morph="none" start_char="2335" end_char="2341">también</TOKEN>
<TOKEN id="token-10-30" pos="word" morph="none" start_char="2343" end_char="2345">fue</TOKEN>
<TOKEN id="token-10-31" pos="word" morph="none" start_char="2347" end_char="2355">publicado</TOKEN>
<TOKEN id="token-10-32" pos="word" morph="none" start_char="2357" end_char="2359">por</TOKEN>
<TOKEN id="token-10-33" pos="word" morph="none" start_char="2361" end_char="2362">el</TOKEN>
<TOKEN id="token-10-34" pos="word" morph="none" start_char="2364" end_char="2368">medio</TOKEN>
<TOKEN id="token-10-35" pos="word" morph="none" start_char="2370" end_char="2379">venezolano</TOKEN>
<TOKEN id="token-10-36" pos="word" morph="none" start_char="2381" end_char="2386">Efecto</TOKEN>
<TOKEN id="token-10-37" pos="word" morph="none" start_char="2388" end_char="2393">Cocuyo</TOKEN>
<TOKEN id="token-10-38" pos="punct" morph="none" start_char="2394" end_char="2394">,</TOKEN>
<TOKEN id="token-10-39" pos="word" morph="none" start_char="2396" end_char="2396">y</TOKEN>
<TOKEN id="token-10-40" pos="word" morph="none" start_char="2398" end_char="2403">agregó</TOKEN>
<TOKEN id="token-10-41" pos="punct" morph="none" start_char="2404" end_char="2404">:</TOKEN>
<TOKEN id="token-10-42" pos="punct" morph="none" start_char="2406" end_char="2406">"</TOKEN>
<TOKEN id="token-10-43" pos="word" morph="none" start_char="2407" end_char="2408">El</TOKEN>
<TOKEN id="token-10-44" pos="word" morph="none" start_char="2410" end_char="2419">desarrollo</TOKEN>
<TOKEN id="token-10-45" pos="word" morph="none" start_char="2421" end_char="2422">de</TOKEN>
<TOKEN id="token-10-46" pos="word" morph="none" start_char="2424" end_char="2425">un</TOKEN>
<TOKEN id="token-10-47" pos="word" morph="none" start_char="2427" end_char="2437">medicamento</TOKEN>
<TOKEN id="token-10-48" pos="word" morph="none" start_char="2439" end_char="2446">requiere</TOKEN>
<TOKEN id="token-10-49" pos="word" morph="none" start_char="2448" end_char="2449">de</TOKEN>
<TOKEN id="token-10-50" pos="word" morph="none" start_char="2451" end_char="2453">una</TOKEN>
<TOKEN id="token-10-51" pos="word" morph="none" start_char="2455" end_char="2459">serie</TOKEN>
<TOKEN id="token-10-52" pos="word" morph="none" start_char="2461" end_char="2462">de</TOKEN>
<TOKEN id="token-10-53" pos="word" morph="none" start_char="2464" end_char="2477">procedimientos</TOKEN>
<TOKEN id="token-10-54" pos="punct" morph="none" start_char="2479" end_char="2481">(…)</TOKEN>
<TOKEN id="token-10-55" pos="word" morph="none" start_char="2483" end_char="2485">que</TOKEN>
<TOKEN id="token-10-56" pos="word" morph="none" start_char="2487" end_char="2492">pueden</TOKEN>
<TOKEN id="token-10-57" pos="word" morph="none" start_char="2494" end_char="2498">tomar</TOKEN>
<TOKEN id="token-10-58" pos="word" morph="none" start_char="2500" end_char="2503">años</TOKEN>
<TOKEN id="token-10-59" pos="word" morph="none" start_char="2505" end_char="2505">y</TOKEN>
<TOKEN id="token-10-60" pos="word" morph="none" start_char="2507" end_char="2508">no</TOKEN>
<TOKEN id="token-10-61" pos="word" morph="none" start_char="2510" end_char="2514">meses</TOKEN>
<TOKEN id="token-10-62" pos="punct" morph="none" start_char="2515" end_char="2516">".</TOKEN>
</SEG>
<SEG id="segment-11" start_char="2519" end_char="2865">
<ORIGINAL_TEXT>Por su parte, la vicepresidenta ejecutiva de Venezuela, Delcy Rodríguez, y el ministro del Poder Popular para la Salud de ese país, Carlos Alvarado, se reunieron con los representantes de la Organización Mundial de la Salud y la Organización Panamericana de la Salud en Venezuela para presentarles "los resultados del estudio de la molécula DR10".</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="2519" end_char="2521">Por</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="2523" end_char="2524">su</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="2526" end_char="2530">parte</TOKEN>
<TOKEN id="token-11-3" pos="punct" morph="none" start_char="2531" end_char="2531">,</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="2533" end_char="2534">la</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="2536" end_char="2549">vicepresidenta</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="2551" end_char="2559">ejecutiva</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="2561" end_char="2562">de</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="2564" end_char="2572">Venezuela</TOKEN>
<TOKEN id="token-11-9" pos="punct" morph="none" start_char="2573" end_char="2573">,</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="2575" end_char="2579">Delcy</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="2581" end_char="2589">Rodríguez</TOKEN>
<TOKEN id="token-11-12" pos="punct" morph="none" start_char="2590" end_char="2590">,</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="2592" end_char="2592">y</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="2594" end_char="2595">el</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="2597" end_char="2604">ministro</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="2606" end_char="2608">del</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="2610" end_char="2614">Poder</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="2616" end_char="2622">Popular</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="2624" end_char="2627">para</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="2629" end_char="2630">la</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="2632" end_char="2636">Salud</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="2638" end_char="2639">de</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="2641" end_char="2643">ese</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="2645" end_char="2648">país</TOKEN>
<TOKEN id="token-11-25" pos="punct" morph="none" start_char="2649" end_char="2649">,</TOKEN>
<TOKEN id="token-11-26" pos="word" morph="none" start_char="2651" end_char="2656">Carlos</TOKEN>
<TOKEN id="token-11-27" pos="word" morph="none" start_char="2658" end_char="2665">Alvarado</TOKEN>
<TOKEN id="token-11-28" pos="punct" morph="none" start_char="2666" end_char="2666">,</TOKEN>
<TOKEN id="token-11-29" pos="word" morph="none" start_char="2668" end_char="2669">se</TOKEN>
<TOKEN id="token-11-30" pos="word" morph="none" start_char="2671" end_char="2679">reunieron</TOKEN>
<TOKEN id="token-11-31" pos="word" morph="none" start_char="2681" end_char="2683">con</TOKEN>
<TOKEN id="token-11-32" pos="word" morph="none" start_char="2685" end_char="2687">los</TOKEN>
<TOKEN id="token-11-33" pos="word" morph="none" start_char="2689" end_char="2702">representantes</TOKEN>
<TOKEN id="token-11-34" pos="word" morph="none" start_char="2704" end_char="2705">de</TOKEN>
<TOKEN id="token-11-35" pos="word" morph="none" start_char="2707" end_char="2708">la</TOKEN>
<TOKEN id="token-11-36" pos="word" morph="none" start_char="2710" end_char="2721">Organización</TOKEN>
<TOKEN id="token-11-37" pos="word" morph="none" start_char="2723" end_char="2729">Mundial</TOKEN>
<TOKEN id="token-11-38" pos="word" morph="none" start_char="2731" end_char="2732">de</TOKEN>
<TOKEN id="token-11-39" pos="word" morph="none" start_char="2734" end_char="2735">la</TOKEN>
<TOKEN id="token-11-40" pos="word" morph="none" start_char="2737" end_char="2741">Salud</TOKEN>
<TOKEN id="token-11-41" pos="word" morph="none" start_char="2743" end_char="2743">y</TOKEN>
<TOKEN id="token-11-42" pos="word" morph="none" start_char="2745" end_char="2746">la</TOKEN>
<TOKEN id="token-11-43" pos="word" morph="none" start_char="2748" end_char="2759">Organización</TOKEN>
<TOKEN id="token-11-44" pos="word" morph="none" start_char="2761" end_char="2772">Panamericana</TOKEN>
<TOKEN id="token-11-45" pos="word" morph="none" start_char="2774" end_char="2775">de</TOKEN>
<TOKEN id="token-11-46" pos="word" morph="none" start_char="2777" end_char="2778">la</TOKEN>
<TOKEN id="token-11-47" pos="word" morph="none" start_char="2780" end_char="2784">Salud</TOKEN>
<TOKEN id="token-11-48" pos="word" morph="none" start_char="2786" end_char="2787">en</TOKEN>
<TOKEN id="token-11-49" pos="word" morph="none" start_char="2789" end_char="2797">Venezuela</TOKEN>
<TOKEN id="token-11-50" pos="word" morph="none" start_char="2799" end_char="2802">para</TOKEN>
<TOKEN id="token-11-51" pos="word" morph="none" start_char="2804" end_char="2815">presentarles</TOKEN>
<TOKEN id="token-11-52" pos="punct" morph="none" start_char="2817" end_char="2817">"</TOKEN>
<TOKEN id="token-11-53" pos="word" morph="none" start_char="2818" end_char="2820">los</TOKEN>
<TOKEN id="token-11-54" pos="word" morph="none" start_char="2822" end_char="2831">resultados</TOKEN>
<TOKEN id="token-11-55" pos="word" morph="none" start_char="2833" end_char="2835">del</TOKEN>
<TOKEN id="token-11-56" pos="word" morph="none" start_char="2837" end_char="2843">estudio</TOKEN>
<TOKEN id="token-11-57" pos="word" morph="none" start_char="2845" end_char="2846">de</TOKEN>
<TOKEN id="token-11-58" pos="word" morph="none" start_char="2848" end_char="2849">la</TOKEN>
<TOKEN id="token-11-59" pos="word" morph="none" start_char="2851" end_char="2858">molécula</TOKEN>
<TOKEN id="token-11-60" pos="word" morph="none" start_char="2860" end_char="2863">DR10</TOKEN>
<TOKEN id="token-11-61" pos="punct" morph="none" start_char="2864" end_char="2865">".</TOKEN>
</SEG>
<SEG id="segment-12" start_char="2868" end_char="3046">
<ORIGINAL_TEXT>Chequeado se comunicó con la OPS para consultarle por los avances del "proceso de certificación" al que se refirió Maduro pero hasta la publicación de esta nota no tuvo respuesta.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="2868" end_char="2876">Chequeado</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="2878" end_char="2879">se</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="2881" end_char="2888">comunicó</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="2890" end_char="2892">con</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="2894" end_char="2895">la</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="2897" end_char="2899">OPS</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="2901" end_char="2904">para</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="2906" end_char="2916">consultarle</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="2918" end_char="2920">por</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="2922" end_char="2924">los</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="2926" end_char="2932">avances</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="2934" end_char="2936">del</TOKEN>
<TOKEN id="token-12-12" pos="punct" morph="none" start_char="2938" end_char="2938">"</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="2939" end_char="2945">proceso</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="2947" end_char="2948">de</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="2950" end_char="2962">certificación</TOKEN>
<TOKEN id="token-12-16" pos="punct" morph="none" start_char="2963" end_char="2963">"</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="2965" end_char="2966">al</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="2968" end_char="2970">que</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="2972" end_char="2973">se</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="2975" end_char="2981">refirió</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="2983" end_char="2988">Maduro</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="2990" end_char="2993">pero</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="2995" end_char="2999">hasta</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="3001" end_char="3002">la</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="3004" end_char="3014">publicación</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="3016" end_char="3017">de</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="3019" end_char="3022">esta</TOKEN>
<TOKEN id="token-12-28" pos="word" morph="none" start_char="3024" end_char="3027">nota</TOKEN>
<TOKEN id="token-12-29" pos="word" morph="none" start_char="3029" end_char="3030">no</TOKEN>
<TOKEN id="token-12-30" pos="word" morph="none" start_char="3032" end_char="3035">tuvo</TOKEN>
<TOKEN id="token-12-31" pos="word" morph="none" start_char="3037" end_char="3045">respuesta</TOKEN>
<TOKEN id="token-12-32" pos="punct" morph="none" start_char="3046" end_char="3046">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="3049" end_char="3129">
<ORIGINAL_TEXT>Si querés estar mejor informado sobre la pandemia, entrá al Especial Coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="3049" end_char="3050">Si</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="3052" end_char="3057">querés</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="3059" end_char="3063">estar</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="3065" end_char="3069">mejor</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="3071" end_char="3079">informado</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="3081" end_char="3085">sobre</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="3087" end_char="3088">la</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="3090" end_char="3097">pandemia</TOKEN>
<TOKEN id="token-13-8" pos="punct" morph="none" start_char="3098" end_char="3098">,</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="3100" end_char="3104">entrá</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="3106" end_char="3107">al</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="3109" end_char="3116">Especial</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="3118" end_char="3128">Coronavirus</TOKEN>
<TOKEN id="token-13-13" pos="punct" morph="none" start_char="3129" end_char="3129">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="3133" end_char="3152">
<ORIGINAL_TEXT>¿Te gustó esta nota?</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="punct" morph="none" start_char="3133" end_char="3133">¿</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="3134" end_char="3135">Te</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="3137" end_char="3141">gustó</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="3143" end_char="3146">esta</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="3148" end_char="3151">nota</TOKEN>
<TOKEN id="token-14-5" pos="punct" morph="none" start_char="3152" end_char="3152">?</TOKEN>
</SEG>
<SEG id="segment-15" start_char="3154" end_char="3187">
<ORIGINAL_TEXT>Ayudanos a mantener este proyecto.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="3154" end_char="3161">Ayudanos</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="3163" end_char="3163">a</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="3165" end_char="3172">mantener</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="3174" end_char="3177">este</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="3179" end_char="3186">proyecto</TOKEN>
<TOKEN id="token-15-5" pos="punct" morph="none" start_char="3187" end_char="3187">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
