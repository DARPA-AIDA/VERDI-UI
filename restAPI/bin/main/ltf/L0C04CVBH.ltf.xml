<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CVBH" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="1953" raw_text_md5="545935b0879e1b714d2bec33ad0a1317">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="80">
<ORIGINAL_TEXT>Antiviral remdesivir no es efectivo contra el coronavirus, según ensayo en China</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="9">Antiviral</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="11" end_char="20">remdesivir</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="22" end_char="23">no</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="25" end_char="26">es</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="28" end_char="35">efectivo</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="37" end_char="42">contra</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="44" end_char="45">el</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="47" end_char="57">coronavirus</TOKEN>
<TOKEN id="token-0-8" pos="punct" morph="none" start_char="58" end_char="58">,</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="60" end_char="64">según</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="66" end_char="71">ensayo</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="73" end_char="74">en</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="76" end_char="80">China</TOKEN>
</SEG>
<SEG id="segment-1" start_char="84" end_char="164">
<ORIGINAL_TEXT>Antiviral remdesivir no es efectivo contra el coronavirus, según ensayo en China.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="84" end_char="92">Antiviral</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="94" end_char="103">remdesivir</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="105" end_char="106">no</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="108" end_char="109">es</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="111" end_char="118">efectivo</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="120" end_char="125">contra</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="127" end_char="128">el</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="130" end_char="140">coronavirus</TOKEN>
<TOKEN id="token-1-8" pos="punct" morph="none" start_char="141" end_char="141">,</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="143" end_char="147">según</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="149" end_char="154">ensayo</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="156" end_char="157">en</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="159" end_char="163">China</TOKEN>
<TOKEN id="token-1-13" pos="punct" morph="none" start_char="164" end_char="164">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="166" end_char="174">
<ORIGINAL_TEXT>Foto: AFP</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="166" end_char="169">Foto</TOKEN>
<TOKEN id="token-2-1" pos="punct" morph="none" start_char="170" end_char="170">:</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="172" end_char="174">AFP</TOKEN>
</SEG>
<SEG id="segment-3" start_char="178" end_char="436">
<ORIGINAL_TEXT>El antiviral remdesivir, del laboratorio estadounidense Gilead Sciences, no ha producido mejoría en pacientes con coronavirus (COVID-19), según uno de los primeros ensayos clínicos en China difundidos prematuramente y publicados por el diario Financial Times.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="178" end_char="179">El</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="181" end_char="189">antiviral</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="191" end_char="200">remdesivir</TOKEN>
<TOKEN id="token-3-3" pos="punct" morph="none" start_char="201" end_char="201">,</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="203" end_char="205">del</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="207" end_char="217">laboratorio</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="219" end_char="232">estadounidense</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="234" end_char="239">Gilead</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="241" end_char="248">Sciences</TOKEN>
<TOKEN id="token-3-9" pos="punct" morph="none" start_char="249" end_char="249">,</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="251" end_char="252">no</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="254" end_char="255">ha</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="257" end_char="265">producido</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="267" end_char="273">mejoría</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="275" end_char="276">en</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="278" end_char="286">pacientes</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="288" end_char="290">con</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="292" end_char="302">coronavirus</TOKEN>
<TOKEN id="token-3-18" pos="punct" morph="none" start_char="304" end_char="304">(</TOKEN>
<TOKEN id="token-3-19" pos="unknown" morph="none" start_char="305" end_char="312">COVID-19</TOKEN>
<TOKEN id="token-3-20" pos="punct" morph="none" start_char="313" end_char="314">),</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="316" end_char="320">según</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="322" end_char="324">uno</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="326" end_char="327">de</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="329" end_char="331">los</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="333" end_char="340">primeros</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="342" end_char="348">ensayos</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="350" end_char="357">clínicos</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="359" end_char="360">en</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="362" end_char="366">China</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="368" end_char="377">difundidos</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="379" end_char="392">prematuramente</TOKEN>
<TOKEN id="token-3-32" pos="word" morph="none" start_char="394" end_char="394">y</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="396" end_char="405">publicados</TOKEN>
<TOKEN id="token-3-34" pos="word" morph="none" start_char="407" end_char="409">por</TOKEN>
<TOKEN id="token-3-35" pos="word" morph="none" start_char="411" end_char="412">el</TOKEN>
<TOKEN id="token-3-36" pos="word" morph="none" start_char="414" end_char="419">diario</TOKEN>
<TOKEN id="token-3-37" pos="word" morph="none" start_char="421" end_char="429">Financial</TOKEN>
<TOKEN id="token-3-38" pos="word" morph="none" start_char="431" end_char="435">Times</TOKEN>
<TOKEN id="token-3-39" pos="punct" morph="none" start_char="436" end_char="436">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="439" end_char="579">
<ORIGINAL_TEXT>Un resumen de la prueba fue divulgado y luego retirado del sitio web de la Organización Mundial de la Salud (OMS), según el diario británico.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="439" end_char="440">Un</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="442" end_char="448">resumen</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="450" end_char="451">de</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="453" end_char="454">la</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="456" end_char="461">prueba</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="463" end_char="465">fue</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="467" end_char="475">divulgado</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="477" end_char="477">y</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="479" end_char="483">luego</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="485" end_char="492">retirado</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="494" end_char="496">del</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="498" end_char="502">sitio</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="504" end_char="506">web</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="508" end_char="509">de</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="511" end_char="512">la</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="514" end_char="525">Organización</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="527" end_char="533">Mundial</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="535" end_char="536">de</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="538" end_char="539">la</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="541" end_char="545">Salud</TOKEN>
<TOKEN id="token-4-20" pos="punct" morph="none" start_char="547" end_char="547">(</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="548" end_char="550">OMS</TOKEN>
<TOKEN id="token-4-22" pos="punct" morph="none" start_char="551" end_char="552">),</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="554" end_char="558">según</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="560" end_char="561">el</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="563" end_char="568">diario</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="570" end_char="578">británico</TOKEN>
<TOKEN id="token-4-27" pos="punct" morph="none" start_char="579" end_char="579">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="582" end_char="830">
<ORIGINAL_TEXT>Hay múltiples ensayos con remdesivir, así como con otros medicamentos, pero la noticia de este fracaso asesta un duro golpe a la comunidad científica, que había depositado esperanzas en este antiviral ante la demora de una vacuna contra la COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="582" end_char="584">Hay</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="586" end_char="594">múltiples</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="596" end_char="602">ensayos</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="604" end_char="606">con</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="608" end_char="617">remdesivir</TOKEN>
<TOKEN id="token-5-5" pos="punct" morph="none" start_char="618" end_char="618">,</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="620" end_char="622">así</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="624" end_char="627">como</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="629" end_char="631">con</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="633" end_char="637">otros</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="639" end_char="650">medicamentos</TOKEN>
<TOKEN id="token-5-11" pos="punct" morph="none" start_char="651" end_char="651">,</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="653" end_char="656">pero</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="658" end_char="659">la</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="661" end_char="667">noticia</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="669" end_char="670">de</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="672" end_char="675">este</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="677" end_char="683">fracaso</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="685" end_char="690">asesta</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="692" end_char="693">un</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="695" end_char="698">duro</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="700" end_char="704">golpe</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="706" end_char="706">a</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="708" end_char="709">la</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="711" end_char="719">comunidad</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="721" end_char="730">científica</TOKEN>
<TOKEN id="token-5-26" pos="punct" morph="none" start_char="731" end_char="731">,</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="733" end_char="735">que</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="737" end_char="741">había</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="743" end_char="752">depositado</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="754" end_char="763">esperanzas</TOKEN>
<TOKEN id="token-5-31" pos="word" morph="none" start_char="765" end_char="766">en</TOKEN>
<TOKEN id="token-5-32" pos="word" morph="none" start_char="768" end_char="771">este</TOKEN>
<TOKEN id="token-5-33" pos="word" morph="none" start_char="773" end_char="781">antiviral</TOKEN>
<TOKEN id="token-5-34" pos="word" morph="none" start_char="783" end_char="786">ante</TOKEN>
<TOKEN id="token-5-35" pos="word" morph="none" start_char="788" end_char="789">la</TOKEN>
<TOKEN id="token-5-36" pos="word" morph="none" start_char="791" end_char="796">demora</TOKEN>
<TOKEN id="token-5-37" pos="word" morph="none" start_char="798" end_char="799">de</TOKEN>
<TOKEN id="token-5-38" pos="word" morph="none" start_char="801" end_char="803">una</TOKEN>
<TOKEN id="token-5-39" pos="word" morph="none" start_char="805" end_char="810">vacuna</TOKEN>
<TOKEN id="token-5-40" pos="word" morph="none" start_char="812" end_char="817">contra</TOKEN>
<TOKEN id="token-5-41" pos="word" morph="none" start_char="819" end_char="820">la</TOKEN>
<TOKEN id="token-5-42" pos="unknown" morph="none" start_char="822" end_char="829">COVID-19</TOKEN>
<TOKEN id="token-5-43" pos="punct" morph="none" start_char="830" end_char="830">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="832" end_char="936">
<ORIGINAL_TEXT>La decepción también se produce en un momento en que muchos países trazan sus planes de desconfinamiento.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="832" end_char="833">La</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="835" end_char="843">decepción</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="845" end_char="851">también</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="853" end_char="854">se</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="856" end_char="862">produce</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="864" end_char="865">en</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="867" end_char="868">un</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="870" end_char="876">momento</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="878" end_char="879">en</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="881" end_char="883">que</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="885" end_char="890">muchos</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="892" end_char="897">países</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="899" end_char="904">trazan</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="906" end_char="908">sus</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="910" end_char="915">planes</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="917" end_char="918">de</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="920" end_char="935">desconfinamiento</TOKEN>
<TOKEN id="token-6-17" pos="punct" morph="none" start_char="936" end_char="936">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="939" end_char="1153">
<ORIGINAL_TEXT>El ensayo chino mostró que el "remdesivir (…) no mejora la condición de los pacientes ni reduce la presencia del patógeno en el sistema sanguíneo", indicó el FT, en base al documento publicado en el sitio de la OMS.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="939" end_char="940">El</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="942" end_char="947">ensayo</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="949" end_char="953">chino</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="955" end_char="960">mostró</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="962" end_char="964">que</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="966" end_char="967">el</TOKEN>
<TOKEN id="token-7-6" pos="punct" morph="none" start_char="969" end_char="969">"</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="970" end_char="979">remdesivir</TOKEN>
<TOKEN id="token-7-8" pos="punct" morph="none" start_char="981" end_char="983">(…)</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="985" end_char="986">no</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="988" end_char="993">mejora</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="995" end_char="996">la</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="998" end_char="1006">condición</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="1008" end_char="1009">de</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="1011" end_char="1013">los</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="1015" end_char="1023">pacientes</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="1025" end_char="1026">ni</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="1028" end_char="1033">reduce</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="1035" end_char="1036">la</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="1038" end_char="1046">presencia</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="1048" end_char="1050">del</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="1052" end_char="1059">patógeno</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="1061" end_char="1062">en</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="1064" end_char="1065">el</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="1067" end_char="1073">sistema</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="1075" end_char="1083">sanguíneo</TOKEN>
<TOKEN id="token-7-26" pos="punct" morph="none" start_char="1084" end_char="1085">",</TOKEN>
<TOKEN id="token-7-27" pos="word" morph="none" start_char="1087" end_char="1092">indicó</TOKEN>
<TOKEN id="token-7-28" pos="word" morph="none" start_char="1094" end_char="1095">el</TOKEN>
<TOKEN id="token-7-29" pos="word" morph="none" start_char="1097" end_char="1098">FT</TOKEN>
<TOKEN id="token-7-30" pos="punct" morph="none" start_char="1099" end_char="1099">,</TOKEN>
<TOKEN id="token-7-31" pos="word" morph="none" start_char="1101" end_char="1102">en</TOKEN>
<TOKEN id="token-7-32" pos="word" morph="none" start_char="1104" end_char="1107">base</TOKEN>
<TOKEN id="token-7-33" pos="word" morph="none" start_char="1109" end_char="1110">al</TOKEN>
<TOKEN id="token-7-34" pos="word" morph="none" start_char="1112" end_char="1120">documento</TOKEN>
<TOKEN id="token-7-35" pos="word" morph="none" start_char="1122" end_char="1130">publicado</TOKEN>
<TOKEN id="token-7-36" pos="word" morph="none" start_char="1132" end_char="1133">en</TOKEN>
<TOKEN id="token-7-37" pos="word" morph="none" start_char="1135" end_char="1136">el</TOKEN>
<TOKEN id="token-7-38" pos="word" morph="none" start_char="1138" end_char="1142">sitio</TOKEN>
<TOKEN id="token-7-39" pos="word" morph="none" start_char="1144" end_char="1145">de</TOKEN>
<TOKEN id="token-7-40" pos="word" morph="none" start_char="1147" end_char="1148">la</TOKEN>
<TOKEN id="token-7-41" pos="word" morph="none" start_char="1150" end_char="1152">OMS</TOKEN>
<TOKEN id="token-7-42" pos="punct" morph="none" start_char="1153" end_char="1153">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1156" end_char="1323">
<ORIGINAL_TEXT>Fuentes de la organización dijeron al sitio especializado Stat que el estudio había sido publicado por error en el sitio antes de ser evaluado por un comité de lectura.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1156" end_char="1162">Fuentes</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1164" end_char="1165">de</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1167" end_char="1168">la</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1170" end_char="1181">organización</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1183" end_char="1189">dijeron</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1191" end_char="1192">al</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1194" end_char="1198">sitio</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1200" end_char="1212">especializado</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1214" end_char="1217">Stat</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1219" end_char="1221">que</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1223" end_char="1224">el</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1226" end_char="1232">estudio</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1234" end_char="1238">había</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1240" end_char="1243">sido</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1245" end_char="1253">publicado</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1255" end_char="1257">por</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1259" end_char="1263">error</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1265" end_char="1266">en</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1268" end_char="1269">el</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1271" end_char="1275">sitio</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="1277" end_char="1281">antes</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="1283" end_char="1284">de</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="1286" end_char="1288">ser</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="1290" end_char="1297">evaluado</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="1299" end_char="1301">por</TOKEN>
<TOKEN id="token-8-25" pos="word" morph="none" start_char="1303" end_char="1304">un</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="1306" end_char="1311">comité</TOKEN>
<TOKEN id="token-8-27" pos="word" morph="none" start_char="1313" end_char="1314">de</TOKEN>
<TOKEN id="token-8-28" pos="word" morph="none" start_char="1316" end_char="1322">lectura</TOKEN>
<TOKEN id="token-8-29" pos="punct" morph="none" start_char="1323" end_char="1323">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1325" end_char="1387">
<ORIGINAL_TEXT>La prueba fue realizada entre 237 pacientes de forma aleatoria.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1325" end_char="1326">La</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1328" end_char="1333">prueba</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1335" end_char="1337">fue</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1339" end_char="1347">realizada</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1349" end_char="1353">entre</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1355" end_char="1357">237</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1359" end_char="1367">pacientes</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1369" end_char="1370">de</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1372" end_char="1376">forma</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1378" end_char="1386">aleatoria</TOKEN>
<TOKEN id="token-9-10" pos="punct" morph="none" start_char="1387" end_char="1387">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1389" end_char="1491">
<ORIGINAL_TEXT>Entre ellos, un grupo de 158 fue tratado con el medicamento, y otro de 79 recibió tratamiento estándar.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1389" end_char="1393">Entre</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1395" end_char="1399">ellos</TOKEN>
<TOKEN id="token-10-2" pos="punct" morph="none" start_char="1400" end_char="1400">,</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1402" end_char="1403">un</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1405" end_char="1409">grupo</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1411" end_char="1412">de</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1414" end_char="1416">158</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1418" end_char="1420">fue</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1422" end_char="1428">tratado</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1430" end_char="1432">con</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1434" end_char="1435">el</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1437" end_char="1447">medicamento</TOKEN>
<TOKEN id="token-10-12" pos="punct" morph="none" start_char="1448" end_char="1448">,</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1450" end_char="1450">y</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1452" end_char="1455">otro</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1457" end_char="1458">de</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1460" end_char="1461">79</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1463" end_char="1469">recibió</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1471" end_char="1481">tratamiento</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1483" end_char="1490">estándar</TOKEN>
<TOKEN id="token-10-20" pos="punct" morph="none" start_char="1491" end_char="1491">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1494" end_char="1707">
<ORIGINAL_TEXT>Los investigadores también concluyeron en que la aplicación del medicamento de Gilead Sciences podría tener efectos secundarios "significativos", por lo que interrumpieron el suministro rápidamente en 18 pacientes.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1494" end_char="1496">Los</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1498" end_char="1511">investigadores</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1513" end_char="1519">también</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1521" end_char="1531">concluyeron</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1533" end_char="1534">en</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1536" end_char="1538">que</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1540" end_char="1541">la</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1543" end_char="1552">aplicación</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1554" end_char="1556">del</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1558" end_char="1568">medicamento</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1570" end_char="1571">de</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1573" end_char="1578">Gilead</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1580" end_char="1587">Sciences</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1589" end_char="1594">podría</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1596" end_char="1600">tener</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1602" end_char="1608">efectos</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1610" end_char="1620">secundarios</TOKEN>
<TOKEN id="token-11-17" pos="punct" morph="none" start_char="1622" end_char="1622">"</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1623" end_char="1636">significativos</TOKEN>
<TOKEN id="token-11-19" pos="punct" morph="none" start_char="1637" end_char="1638">",</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1640" end_char="1642">por</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="1644" end_char="1645">lo</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="1647" end_char="1649">que</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="1651" end_char="1664">interrumpieron</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="1666" end_char="1667">el</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="1669" end_char="1678">suministro</TOKEN>
<TOKEN id="token-11-26" pos="word" morph="none" start_char="1680" end_char="1690">rápidamente</TOKEN>
<TOKEN id="token-11-27" pos="word" morph="none" start_char="1692" end_char="1693">en</TOKEN>
<TOKEN id="token-11-28" pos="word" morph="none" start_char="1695" end_char="1696">18</TOKEN>
<TOKEN id="token-11-29" pos="word" morph="none" start_char="1698" end_char="1706">pacientes</TOKEN>
<TOKEN id="token-11-30" pos="punct" morph="none" start_char="1707" end_char="1707">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1709" end_char="1866">
<ORIGINAL_TEXT>Además de las pruebas en China, el remdesivir también es evaluado en Estados Unidos y Europa, en el gran ensayo Discovery, cuyos resultados se esperan pronto.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1709" end_char="1714">Además</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1716" end_char="1717">de</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1719" end_char="1721">las</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1723" end_char="1729">pruebas</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1731" end_char="1732">en</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1734" end_char="1738">China</TOKEN>
<TOKEN id="token-12-6" pos="punct" morph="none" start_char="1739" end_char="1739">,</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1741" end_char="1742">el</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1744" end_char="1753">remdesivir</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1755" end_char="1761">también</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1763" end_char="1764">es</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1766" end_char="1773">evaluado</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1775" end_char="1776">en</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1778" end_char="1784">Estados</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1786" end_char="1791">Unidos</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1793" end_char="1793">y</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1795" end_char="1800">Europa</TOKEN>
<TOKEN id="token-12-17" pos="punct" morph="none" start_char="1801" end_char="1801">,</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1803" end_char="1804">en</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1806" end_char="1807">el</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1809" end_char="1812">gran</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1814" end_char="1819">ensayo</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1821" end_char="1829">Discovery</TOKEN>
<TOKEN id="token-12-23" pos="punct" morph="none" start_char="1830" end_char="1830">,</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="1832" end_char="1836">cuyos</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="1838" end_char="1847">resultados</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="1849" end_char="1850">se</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="1852" end_char="1858">esperan</TOKEN>
<TOKEN id="token-12-28" pos="word" morph="none" start_char="1860" end_char="1865">pronto</TOKEN>
<TOKEN id="token-12-29" pos="punct" morph="none" start_char="1866" end_char="1866">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1869" end_char="1890">
<ORIGINAL_TEXT>Con información de AFP</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1869" end_char="1871">Con</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1873" end_char="1883">información</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1885" end_char="1886">de</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1888" end_char="1890">AFP</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1894" end_char="1902">
<ORIGINAL_TEXT>ETIQUETAS</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1894" end_char="1902">ETIQUETAS</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1906" end_char="1910">
<ORIGINAL_TEXT>China</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1906" end_char="1910">China</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1914" end_char="1921">
<ORIGINAL_TEXT>COVID-19</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="unknown" morph="none" start_char="1914" end_char="1921">COVID-19</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1925" end_char="1934">
<ORIGINAL_TEXT>remdesivir</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1925" end_char="1934">remdesivir</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1938" end_char="1948">
<ORIGINAL_TEXT>Coronavirus</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="1938" end_char="1948">Coronavirus</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
