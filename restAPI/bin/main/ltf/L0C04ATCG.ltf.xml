<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATCG" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="3882" raw_text_md5="ed054e9a48b6bdb79205509a504829d1">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="126">
<ORIGINAL_TEXT>No hay pruebas de que los perros callejeros hayan sido el origen del coronavirus, a pesar de lo que afirma un reciente estudio</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="2">No</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="4" end_char="6">hay</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="8" end_char="14">pruebas</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="16" end_char="17">de</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="19" end_char="21">que</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="23" end_char="25">los</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="27" end_char="32">perros</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="34" end_char="43">callejeros</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="45" end_char="49">hayan</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="51" end_char="54">sido</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="56" end_char="57">el</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="59" end_char="64">origen</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="66" end_char="68">del</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="70" end_char="80">coronavirus</TOKEN>
<TOKEN id="token-0-14" pos="punct" morph="none" start_char="81" end_char="81">,</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="83" end_char="83">a</TOKEN>
<TOKEN id="token-0-16" pos="word" morph="none" start_char="85" end_char="89">pesar</TOKEN>
<TOKEN id="token-0-17" pos="word" morph="none" start_char="91" end_char="92">de</TOKEN>
<TOKEN id="token-0-18" pos="word" morph="none" start_char="94" end_char="95">lo</TOKEN>
<TOKEN id="token-0-19" pos="word" morph="none" start_char="97" end_char="99">que</TOKEN>
<TOKEN id="token-0-20" pos="word" morph="none" start_char="101" end_char="106">afirma</TOKEN>
<TOKEN id="token-0-21" pos="word" morph="none" start_char="108" end_char="109">un</TOKEN>
<TOKEN id="token-0-22" pos="word" morph="none" start_char="111" end_char="118">reciente</TOKEN>
<TOKEN id="token-0-23" pos="word" morph="none" start_char="120" end_char="126">estudio</TOKEN>
</SEG>
<SEG id="segment-1" start_char="132" end_char="301">
<ORIGINAL_TEXT>Todavía no se conoce con certeza el verdadero origen del COVID-19, aunque muchas de las investigaciones señalan que la transmisión al ser humano se produjo por un animal.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="132" end_char="138">Todavía</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="140" end_char="141">no</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="143" end_char="144">se</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="146" end_char="151">conoce</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="153" end_char="155">con</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="157" end_char="163">certeza</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="165" end_char="166">el</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="168" end_char="176">verdadero</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="178" end_char="183">origen</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="185" end_char="187">del</TOKEN>
<TOKEN id="token-1-10" pos="unknown" morph="none" start_char="189" end_char="196">COVID-19</TOKEN>
<TOKEN id="token-1-11" pos="punct" morph="none" start_char="197" end_char="197">,</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="199" end_char="204">aunque</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="206" end_char="211">muchas</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="213" end_char="214">de</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="216" end_char="218">las</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="220" end_char="234">investigaciones</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="236" end_char="242">señalan</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="244" end_char="246">que</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="248" end_char="249">la</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="251" end_char="261">transmisión</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="263" end_char="264">al</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="266" end_char="268">ser</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="270" end_char="275">humano</TOKEN>
<TOKEN id="token-1-24" pos="word" morph="none" start_char="277" end_char="278">se</TOKEN>
<TOKEN id="token-1-25" pos="word" morph="none" start_char="280" end_char="286">produjo</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="288" end_char="290">por</TOKEN>
<TOKEN id="token-1-27" pos="word" morph="none" start_char="292" end_char="293">un</TOKEN>
<TOKEN id="token-1-28" pos="word" morph="none" start_char="295" end_char="300">animal</TOKEN>
<TOKEN id="token-1-29" pos="punct" morph="none" start_char="301" end_char="301">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="305" end_char="474">
<ORIGINAL_TEXT>En las últimas horas algunos medios se han hecho eco de un estudio que relaciona el origen del virus con los perros callejeros, que podrían ser transmisores del COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="305" end_char="306">En</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="308" end_char="310">las</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="312" end_char="318">últimas</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="320" end_char="324">horas</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="326" end_char="332">algunos</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="334" end_char="339">medios</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="341" end_char="342">se</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="344" end_char="346">han</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="348" end_char="352">hecho</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="354" end_char="356">eco</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="358" end_char="359">de</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="361" end_char="362">un</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="364" end_char="370">estudio</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="372" end_char="374">que</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="376" end_char="384">relaciona</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="386" end_char="387">el</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="389" end_char="394">origen</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="396" end_char="398">del</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="400" end_char="404">virus</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="406" end_char="408">con</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="410" end_char="412">los</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="414" end_char="419">perros</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="421" end_char="430">callejeros</TOKEN>
<TOKEN id="token-2-23" pos="punct" morph="none" start_char="431" end_char="431">,</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="433" end_char="435">que</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="437" end_char="443">podrían</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="445" end_char="447">ser</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="449" end_char="460">transmisores</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="462" end_char="464">del</TOKEN>
<TOKEN id="token-2-29" pos="unknown" morph="none" start_char="466" end_char="473">COVID-19</TOKEN>
<TOKEN id="token-2-30" pos="punct" morph="none" start_char="474" end_char="474">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="478" end_char="592">
<ORIGINAL_TEXT>Sin embargo, se trata sólo de una hipótesis y no cuenta con el fundamento suficiente como para darla por verdadera.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="478" end_char="480">Sin</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="482" end_char="488">embargo</TOKEN>
<TOKEN id="token-3-2" pos="punct" morph="none" start_char="489" end_char="489">,</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="491" end_char="492">se</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="494" end_char="498">trata</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="500" end_char="503">sólo</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="505" end_char="506">de</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="508" end_char="510">una</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="512" end_char="520">hipótesis</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="522" end_char="522">y</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="524" end_char="525">no</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="527" end_char="532">cuenta</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="534" end_char="536">con</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="538" end_char="539">el</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="541" end_char="550">fundamento</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="552" end_char="561">suficiente</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="563" end_char="566">como</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="568" end_char="571">para</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="573" end_char="577">darla</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="579" end_char="581">por</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="583" end_char="591">verdadera</TOKEN>
<TOKEN id="token-3-21" pos="punct" morph="none" start_char="592" end_char="592">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="598" end_char="678">
<ORIGINAL_TEXT>Uno de los mayores debates que rodean al coronavirus tiene que ver con su origen.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="598" end_char="600">Uno</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="602" end_char="603">de</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="605" end_char="607">los</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="609" end_char="615">mayores</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="617" end_char="623">debates</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="625" end_char="627">que</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="629" end_char="634">rodean</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="636" end_char="637">al</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="639" end_char="649">coronavirus</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="651" end_char="655">tiene</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="657" end_char="659">que</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="661" end_char="663">ver</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="665" end_char="667">con</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="669" end_char="670">su</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="672" end_char="677">origen</TOKEN>
<TOKEN id="token-4-15" pos="punct" morph="none" start_char="678" end_char="678">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="680" end_char="795">
<ORIGINAL_TEXT>Aún no ha sido posible conocer qué animal fue el origen del COVID-19 y se lo transmitió por primera vez a un humano.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="680" end_char="682">Aún</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="684" end_char="685">no</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="687" end_char="688">ha</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="690" end_char="693">sido</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="695" end_char="701">posible</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="703" end_char="709">conocer</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="711" end_char="713">qué</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="715" end_char="720">animal</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="722" end_char="724">fue</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="726" end_char="727">el</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="729" end_char="734">origen</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="736" end_char="738">del</TOKEN>
<TOKEN id="token-5-12" pos="unknown" morph="none" start_char="740" end_char="747">COVID-19</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="749" end_char="749">y</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="751" end_char="752">se</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="754" end_char="755">lo</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="757" end_char="766">transmitió</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="768" end_char="770">por</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="772" end_char="778">primera</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="780" end_char="782">vez</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="784" end_char="784">a</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="786" end_char="787">un</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="789" end_char="794">humano</TOKEN>
<TOKEN id="token-5-23" pos="punct" morph="none" start_char="795" end_char="795">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="797" end_char="903">
<ORIGINAL_TEXT>Se ha especulado con los pangolines, los murciélagos y especialmente con los animales del mercado de Wuhan.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="797" end_char="798">Se</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="800" end_char="801">ha</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="803" end_char="812">especulado</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="814" end_char="816">con</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="818" end_char="820">los</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="822" end_char="831">pangolines</TOKEN>
<TOKEN id="token-6-6" pos="punct" morph="none" start_char="832" end_char="832">,</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="834" end_char="836">los</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="838" end_char="848">murciélagos</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="850" end_char="850">y</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="852" end_char="864">especialmente</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="866" end_char="868">con</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="870" end_char="872">los</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="874" end_char="881">animales</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="883" end_char="885">del</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="887" end_char="893">mercado</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="895" end_char="896">de</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="898" end_char="902">Wuhan</TOKEN>
<TOKEN id="token-6-18" pos="punct" morph="none" start_char="903" end_char="903">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="905" end_char="973">
<ORIGINAL_TEXT>Ninguna de las teorías han terminado por convencer a los científicos.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="905" end_char="911">Ninguna</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="913" end_char="914">de</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="916" end_char="918">las</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="920" end_char="926">teorías</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="928" end_char="930">han</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="932" end_char="940">terminado</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="942" end_char="944">por</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="946" end_char="954">convencer</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="956" end_char="956">a</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="958" end_char="960">los</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="962" end_char="972">científicos</TOKEN>
<TOKEN id="token-7-11" pos="punct" morph="none" start_char="973" end_char="973">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="976" end_char="1131">
<ORIGINAL_TEXT>Descubrir el origen del coronavirus es importante conocer mejor la enfermedad y hallar posibles tratamientos y curas, además de poder frenar su propagación.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="976" end_char="984">Descubrir</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="986" end_char="987">el</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="989" end_char="994">origen</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="996" end_char="998">del</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1000" end_char="1010">coronavirus</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1012" end_char="1013">es</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1015" end_char="1024">importante</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1026" end_char="1032">conocer</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1034" end_char="1038">mejor</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1040" end_char="1041">la</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1043" end_char="1052">enfermedad</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1054" end_char="1054">y</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1056" end_char="1061">hallar</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1063" end_char="1070">posibles</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1072" end_char="1083">tratamientos</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1085" end_char="1085">y</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1087" end_char="1091">curas</TOKEN>
<TOKEN id="token-8-17" pos="punct" morph="none" start_char="1092" end_char="1092">,</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1094" end_char="1099">además</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1101" end_char="1102">de</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="1104" end_char="1108">poder</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="1110" end_char="1115">frenar</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="1117" end_char="1118">su</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="1120" end_char="1130">propagación</TOKEN>
<TOKEN id="token-8-24" pos="punct" morph="none" start_char="1131" end_char="1131">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1133" end_char="1203">
<ORIGINAL_TEXT>Por ello no es de extrañar que surjan decenas de hipótesis cada semana.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1133" end_char="1135">Por</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1137" end_char="1140">ello</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1142" end_char="1143">no</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1145" end_char="1146">es</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1148" end_char="1149">de</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1151" end_char="1158">extrañar</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1160" end_char="1162">que</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1164" end_char="1169">surjan</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1171" end_char="1177">decenas</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1179" end_char="1180">de</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1182" end_char="1190">hipótesis</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1192" end_char="1195">cada</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1197" end_char="1202">semana</TOKEN>
<TOKEN id="token-9-13" pos="punct" morph="none" start_char="1203" end_char="1203">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1206" end_char="1370">
<ORIGINAL_TEXT>Un último estudio, publicado por el profesor Xuxhua Xia de la Universidad de Ottawa (Canadá), señala que los perros callejeros son el posible origen del coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1206" end_char="1207">Un</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1209" end_char="1214">último</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1216" end_char="1222">estudio</TOKEN>
<TOKEN id="token-10-3" pos="punct" morph="none" start_char="1223" end_char="1223">,</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1225" end_char="1233">publicado</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1235" end_char="1237">por</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1239" end_char="1240">el</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1242" end_char="1249">profesor</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1251" end_char="1256">Xuxhua</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1258" end_char="1260">Xia</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1262" end_char="1263">de</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1265" end_char="1266">la</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1268" end_char="1278">Universidad</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1280" end_char="1281">de</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1283" end_char="1288">Ottawa</TOKEN>
<TOKEN id="token-10-15" pos="punct" morph="none" start_char="1290" end_char="1290">(</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1291" end_char="1296">Canadá</TOKEN>
<TOKEN id="token-10-17" pos="punct" morph="none" start_char="1297" end_char="1298">),</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1300" end_char="1305">señala</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1307" end_char="1309">que</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1311" end_char="1313">los</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1315" end_char="1320">perros</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1322" end_char="1331">callejeros</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1333" end_char="1335">son</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1337" end_char="1338">el</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="1340" end_char="1346">posible</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="1348" end_char="1353">origen</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="1355" end_char="1357">del</TOKEN>
<TOKEN id="token-10-28" pos="word" morph="none" start_char="1359" end_char="1369">coronavirus</TOKEN>
<TOKEN id="token-10-29" pos="punct" morph="none" start_char="1370" end_char="1370">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1372" end_char="1546">
<ORIGINAL_TEXT>La explicación que ofrece este documento es la siguiente: los perros callejeros de Wuhan comieron murciélagos que ya eran portadores del COVID-19, y de ahí pasó a los humanos.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1372" end_char="1373">La</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1375" end_char="1385">explicación</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1387" end_char="1389">que</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1391" end_char="1396">ofrece</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1398" end_char="1401">este</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1403" end_char="1411">documento</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1413" end_char="1414">es</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1416" end_char="1417">la</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1419" end_char="1427">siguiente</TOKEN>
<TOKEN id="token-11-9" pos="punct" morph="none" start_char="1428" end_char="1428">:</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1430" end_char="1432">los</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1434" end_char="1439">perros</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1441" end_char="1450">callejeros</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1452" end_char="1453">de</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1455" end_char="1459">Wuhan</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1461" end_char="1468">comieron</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1470" end_char="1480">murciélagos</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1482" end_char="1484">que</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1486" end_char="1487">ya</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="1489" end_char="1492">eran</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1494" end_char="1503">portadores</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="1505" end_char="1507">del</TOKEN>
<TOKEN id="token-11-22" pos="unknown" morph="none" start_char="1509" end_char="1516">COVID-19</TOKEN>
<TOKEN id="token-11-23" pos="punct" morph="none" start_char="1517" end_char="1517">,</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="1519" end_char="1519">y</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="1521" end_char="1522">de</TOKEN>
<TOKEN id="token-11-26" pos="word" morph="none" start_char="1524" end_char="1526">ahí</TOKEN>
<TOKEN id="token-11-27" pos="word" morph="none" start_char="1528" end_char="1531">pasó</TOKEN>
<TOKEN id="token-11-28" pos="word" morph="none" start_char="1533" end_char="1533">a</TOKEN>
<TOKEN id="token-11-29" pos="word" morph="none" start_char="1535" end_char="1537">los</TOKEN>
<TOKEN id="token-11-30" pos="word" morph="none" start_char="1539" end_char="1545">humanos</TOKEN>
<TOKEN id="token-11-31" pos="punct" morph="none" start_char="1546" end_char="1546">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1549" end_char="1656">
<ORIGINAL_TEXT>Leer más: Cuándo abrirán los bares y restaurantes en España: la hostelería tardará en salir de la cuarentena</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1549" end_char="1552">Leer</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1554" end_char="1556">más</TOKEN>
<TOKEN id="token-12-2" pos="punct" morph="none" start_char="1557" end_char="1557">:</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1559" end_char="1564">Cuándo</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1566" end_char="1572">abrirán</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1574" end_char="1576">los</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1578" end_char="1582">bares</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1584" end_char="1584">y</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1586" end_char="1597">restaurantes</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1599" end_char="1600">en</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1602" end_char="1607">España</TOKEN>
<TOKEN id="token-12-11" pos="punct" morph="none" start_char="1608" end_char="1608">:</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1610" end_char="1611">la</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1613" end_char="1622">hostelería</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1624" end_char="1630">tardará</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1632" end_char="1633">en</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1635" end_char="1639">salir</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1641" end_char="1642">de</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1644" end_char="1645">la</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1647" end_char="1656">cuarentena</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1660" end_char="1756">
<ORIGINAL_TEXT>Pero el estudio no cuenta con el rigor suficiente, dejando esta afirmación en una mera hipótesis.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1660" end_char="1663">Pero</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1665" end_char="1666">el</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1668" end_char="1674">estudio</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1676" end_char="1677">no</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1679" end_char="1684">cuenta</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1686" end_char="1688">con</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1690" end_char="1691">el</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1693" end_char="1697">rigor</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1699" end_char="1708">suficiente</TOKEN>
<TOKEN id="token-13-9" pos="punct" morph="none" start_char="1709" end_char="1709">,</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1711" end_char="1717">dejando</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1719" end_char="1722">esta</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1724" end_char="1733">afirmación</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1735" end_char="1736">en</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1738" end_char="1740">una</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1742" end_char="1745">mera</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1747" end_char="1755">hipótesis</TOKEN>
<TOKEN id="token-13-17" pos="punct" morph="none" start_char="1756" end_char="1756">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1758" end_char="1949">
<ORIGINAL_TEXT>La investigación se ha hecho en base al análisis informático del genoma de varios tipos de coronavirus, y se ha centrado en una pequeña parte de ese genoma, concretamente el conocido como CpG.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1758" end_char="1759">La</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1761" end_char="1773">investigación</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1775" end_char="1776">se</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1778" end_char="1779">ha</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1781" end_char="1785">hecho</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1787" end_char="1788">en</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1790" end_char="1793">base</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1795" end_char="1796">al</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1798" end_char="1805">análisis</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1807" end_char="1817">informático</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1819" end_char="1821">del</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1823" end_char="1828">genoma</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1830" end_char="1831">de</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1833" end_char="1838">varios</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="1840" end_char="1844">tipos</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1846" end_char="1847">de</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1849" end_char="1859">coronavirus</TOKEN>
<TOKEN id="token-14-17" pos="punct" morph="none" start_char="1860" end_char="1860">,</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="1862" end_char="1862">y</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="1864" end_char="1865">se</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="1867" end_char="1868">ha</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="1870" end_char="1877">centrado</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="1879" end_char="1880">en</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="1882" end_char="1884">una</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="1886" end_char="1892">pequeña</TOKEN>
<TOKEN id="token-14-25" pos="word" morph="none" start_char="1894" end_char="1898">parte</TOKEN>
<TOKEN id="token-14-26" pos="word" morph="none" start_char="1900" end_char="1901">de</TOKEN>
<TOKEN id="token-14-27" pos="word" morph="none" start_char="1903" end_char="1905">ese</TOKEN>
<TOKEN id="token-14-28" pos="word" morph="none" start_char="1907" end_char="1912">genoma</TOKEN>
<TOKEN id="token-14-29" pos="punct" morph="none" start_char="1913" end_char="1913">,</TOKEN>
<TOKEN id="token-14-30" pos="word" morph="none" start_char="1915" end_char="1927">concretamente</TOKEN>
<TOKEN id="token-14-31" pos="word" morph="none" start_char="1929" end_char="1930">el</TOKEN>
<TOKEN id="token-14-32" pos="word" morph="none" start_char="1932" end_char="1939">conocido</TOKEN>
<TOKEN id="token-14-33" pos="word" morph="none" start_char="1941" end_char="1944">como</TOKEN>
<TOKEN id="token-14-34" pos="word" morph="none" start_char="1946" end_char="1948">CpG</TOKEN>
<TOKEN id="token-14-35" pos="punct" morph="none" start_char="1949" end_char="1949">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1952" end_char="2164">
<ORIGINAL_TEXT>Según advierte el estudio, el COVID-19 tiene menor cantidad de CpG que otros coronavirus, y por lo tanto puede esconderse mejor del sistema inmune y replicar la enfermedad sin que el organismo halle una respuesta.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1952" end_char="1956">Según</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1958" end_char="1965">advierte</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1967" end_char="1968">el</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1970" end_char="1976">estudio</TOKEN>
<TOKEN id="token-15-4" pos="punct" morph="none" start_char="1977" end_char="1977">,</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1979" end_char="1980">el</TOKEN>
<TOKEN id="token-15-6" pos="unknown" morph="none" start_char="1982" end_char="1989">COVID-19</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1991" end_char="1995">tiene</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1997" end_char="2001">menor</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="2003" end_char="2010">cantidad</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="2012" end_char="2013">de</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="2015" end_char="2017">CpG</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="2019" end_char="2021">que</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="2023" end_char="2027">otros</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="2029" end_char="2039">coronavirus</TOKEN>
<TOKEN id="token-15-15" pos="punct" morph="none" start_char="2040" end_char="2040">,</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="2042" end_char="2042">y</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="2044" end_char="2046">por</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="2048" end_char="2049">lo</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="2051" end_char="2055">tanto</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="2057" end_char="2061">puede</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="2063" end_char="2072">esconderse</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="2074" end_char="2078">mejor</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="2080" end_char="2082">del</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="2084" end_char="2090">sistema</TOKEN>
<TOKEN id="token-15-25" pos="word" morph="none" start_char="2092" end_char="2097">inmune</TOKEN>
<TOKEN id="token-15-26" pos="word" morph="none" start_char="2099" end_char="2099">y</TOKEN>
<TOKEN id="token-15-27" pos="word" morph="none" start_char="2101" end_char="2108">replicar</TOKEN>
<TOKEN id="token-15-28" pos="word" morph="none" start_char="2110" end_char="2111">la</TOKEN>
<TOKEN id="token-15-29" pos="word" morph="none" start_char="2113" end_char="2122">enfermedad</TOKEN>
<TOKEN id="token-15-30" pos="word" morph="none" start_char="2124" end_char="2126">sin</TOKEN>
<TOKEN id="token-15-31" pos="word" morph="none" start_char="2128" end_char="2130">que</TOKEN>
<TOKEN id="token-15-32" pos="word" morph="none" start_char="2132" end_char="2133">el</TOKEN>
<TOKEN id="token-15-33" pos="word" morph="none" start_char="2135" end_char="2143">organismo</TOKEN>
<TOKEN id="token-15-34" pos="word" morph="none" start_char="2145" end_char="2149">halle</TOKEN>
<TOKEN id="token-15-35" pos="word" morph="none" start_char="2151" end_char="2153">una</TOKEN>
<TOKEN id="token-15-36" pos="word" morph="none" start_char="2155" end_char="2163">respuesta</TOKEN>
<TOKEN id="token-15-37" pos="punct" morph="none" start_char="2164" end_char="2164">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="2167" end_char="2273">
<ORIGINAL_TEXT>Llegados a este punto, los investigadores examinaron los datos de varios mamíferos, entre ellos los perros.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="2167" end_char="2174">Llegados</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="2176" end_char="2176">a</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="2178" end_char="2181">este</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="2183" end_char="2187">punto</TOKEN>
<TOKEN id="token-16-4" pos="punct" morph="none" start_char="2188" end_char="2188">,</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="2190" end_char="2192">los</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="2194" end_char="2207">investigadores</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="2209" end_char="2218">examinaron</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="2220" end_char="2222">los</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="2224" end_char="2228">datos</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="2230" end_char="2231">de</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="2233" end_char="2238">varios</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="2240" end_char="2248">mamíferos</TOKEN>
<TOKEN id="token-16-13" pos="punct" morph="none" start_char="2249" end_char="2249">,</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="2251" end_char="2255">entre</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="2257" end_char="2261">ellos</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="2263" end_char="2265">los</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="2267" end_char="2272">perros</TOKEN>
<TOKEN id="token-16-18" pos="punct" morph="none" start_char="2273" end_char="2273">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2275" end_char="2427">
<ORIGINAL_TEXT>Alcanzaron la conclusión de que sólo los genomas de coronavirus caninos son compatibles con los valores tan bajos de CpG que se encuentra en el COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2275" end_char="2284">Alcanzaron</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2286" end_char="2287">la</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2289" end_char="2298">conclusión</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2300" end_char="2301">de</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2303" end_char="2305">que</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2307" end_char="2310">sólo</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2312" end_char="2314">los</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2316" end_char="2322">genomas</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2324" end_char="2325">de</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2327" end_char="2337">coronavirus</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2339" end_char="2345">caninos</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2347" end_char="2349">son</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2351" end_char="2361">compatibles</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2363" end_char="2365">con</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2367" end_char="2369">los</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2371" end_char="2377">valores</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="2379" end_char="2381">tan</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="2383" end_char="2387">bajos</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="2389" end_char="2390">de</TOKEN>
<TOKEN id="token-17-19" pos="word" morph="none" start_char="2392" end_char="2394">CpG</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="2396" end_char="2398">que</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="2400" end_char="2401">se</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="2403" end_char="2411">encuentra</TOKEN>
<TOKEN id="token-17-23" pos="word" morph="none" start_char="2413" end_char="2414">en</TOKEN>
<TOKEN id="token-17-24" pos="word" morph="none" start_char="2416" end_char="2417">el</TOKEN>
<TOKEN id="token-17-25" pos="unknown" morph="none" start_char="2419" end_char="2426">COVID-19</TOKEN>
<TOKEN id="token-17-26" pos="punct" morph="none" start_char="2427" end_char="2427">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2429" end_char="2483">
<ORIGINAL_TEXT>Así, los perros se convertirían en posibles portadores.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2429" end_char="2431">Así</TOKEN>
<TOKEN id="token-18-1" pos="punct" morph="none" start_char="2432" end_char="2432">,</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2434" end_char="2436">los</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2438" end_char="2443">perros</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2445" end_char="2446">se</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2448" end_char="2459">convertirían</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2461" end_char="2462">en</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2464" end_char="2471">posibles</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2473" end_char="2482">portadores</TOKEN>
<TOKEN id="token-18-9" pos="punct" morph="none" start_char="2483" end_char="2483">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2486" end_char="2540">
<ORIGINAL_TEXT>Por qué la investigación no tiene fundamento suficiente</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2486" end_char="2488">Por</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2490" end_char="2492">qué</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2494" end_char="2495">la</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2497" end_char="2509">investigación</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2511" end_char="2512">no</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2514" end_char="2518">tiene</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2520" end_char="2529">fundamento</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2531" end_char="2540">suficiente</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2544" end_char="2803">
<ORIGINAL_TEXT>Sin embargo, el estudio ha relacionado estas variables de forma especulativa, sin que haya una verdadera correlación que sustente sus afirmaciones, y sin que se haya estudiado a otros muchos mamíferos que pueden presentar los mismos valores, tal y como explica</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2544" end_char="2546">Sin</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2548" end_char="2554">embargo</TOKEN>
<TOKEN id="token-20-2" pos="punct" morph="none" start_char="2555" end_char="2555">,</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2557" end_char="2558">el</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2560" end_char="2566">estudio</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2568" end_char="2569">ha</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2571" end_char="2581">relacionado</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2583" end_char="2587">estas</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="2589" end_char="2597">variables</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2599" end_char="2600">de</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2602" end_char="2606">forma</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="2608" end_char="2619">especulativa</TOKEN>
<TOKEN id="token-20-12" pos="punct" morph="none" start_char="2620" end_char="2620">,</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="2622" end_char="2624">sin</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="2626" end_char="2628">que</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="2630" end_char="2633">haya</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="2635" end_char="2637">una</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="2639" end_char="2647">verdadera</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="2649" end_char="2659">correlación</TOKEN>
<TOKEN id="token-20-19" pos="word" morph="none" start_char="2661" end_char="2663">que</TOKEN>
<TOKEN id="token-20-20" pos="word" morph="none" start_char="2665" end_char="2672">sustente</TOKEN>
<TOKEN id="token-20-21" pos="word" morph="none" start_char="2674" end_char="2676">sus</TOKEN>
<TOKEN id="token-20-22" pos="word" morph="none" start_char="2678" end_char="2689">afirmaciones</TOKEN>
<TOKEN id="token-20-23" pos="punct" morph="none" start_char="2690" end_char="2690">,</TOKEN>
<TOKEN id="token-20-24" pos="word" morph="none" start_char="2692" end_char="2692">y</TOKEN>
<TOKEN id="token-20-25" pos="word" morph="none" start_char="2694" end_char="2696">sin</TOKEN>
<TOKEN id="token-20-26" pos="word" morph="none" start_char="2698" end_char="2700">que</TOKEN>
<TOKEN id="token-20-27" pos="word" morph="none" start_char="2702" end_char="2703">se</TOKEN>
<TOKEN id="token-20-28" pos="word" morph="none" start_char="2705" end_char="2708">haya</TOKEN>
<TOKEN id="token-20-29" pos="word" morph="none" start_char="2710" end_char="2718">estudiado</TOKEN>
<TOKEN id="token-20-30" pos="word" morph="none" start_char="2720" end_char="2720">a</TOKEN>
<TOKEN id="token-20-31" pos="word" morph="none" start_char="2722" end_char="2726">otros</TOKEN>
<TOKEN id="token-20-32" pos="word" morph="none" start_char="2728" end_char="2733">muchos</TOKEN>
<TOKEN id="token-20-33" pos="word" morph="none" start_char="2735" end_char="2743">mamíferos</TOKEN>
<TOKEN id="token-20-34" pos="word" morph="none" start_char="2745" end_char="2747">que</TOKEN>
<TOKEN id="token-20-35" pos="word" morph="none" start_char="2749" end_char="2754">pueden</TOKEN>
<TOKEN id="token-20-36" pos="word" morph="none" start_char="2756" end_char="2764">presentar</TOKEN>
<TOKEN id="token-20-37" pos="word" morph="none" start_char="2766" end_char="2768">los</TOKEN>
<TOKEN id="token-20-38" pos="word" morph="none" start_char="2770" end_char="2775">mismos</TOKEN>
<TOKEN id="token-20-39" pos="word" morph="none" start_char="2777" end_char="2783">valores</TOKEN>
<TOKEN id="token-20-40" pos="punct" morph="none" start_char="2784" end_char="2784">,</TOKEN>
<TOKEN id="token-20-41" pos="word" morph="none" start_char="2786" end_char="2788">tal</TOKEN>
<TOKEN id="token-20-42" pos="word" morph="none" start_char="2790" end_char="2790">y</TOKEN>
<TOKEN id="token-20-43" pos="word" morph="none" start_char="2792" end_char="2795">como</TOKEN>
<TOKEN id="token-20-44" pos="word" morph="none" start_char="2797" end_char="2803">explica</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2806" end_char="2816">
<ORIGINAL_TEXT>CNN Health.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2806" end_char="2808">CNN</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2810" end_char="2815">Health</TOKEN>
<TOKEN id="token-21-2" pos="punct" morph="none" start_char="2816" end_char="2816">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2820" end_char="2949">
<ORIGINAL_TEXT>Además, los datos que se han manejado no están actualizados, y el trabajo no pasa de una mera simulación a través de un ordenador.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2820" end_char="2825">Además</TOKEN>
<TOKEN id="token-22-1" pos="punct" morph="none" start_char="2826" end_char="2826">,</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2828" end_char="2830">los</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2832" end_char="2836">datos</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2838" end_char="2840">que</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2842" end_char="2843">se</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2845" end_char="2847">han</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2849" end_char="2856">manejado</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="2858" end_char="2859">no</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="2861" end_char="2865">están</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="2867" end_char="2878">actualizados</TOKEN>
<TOKEN id="token-22-11" pos="punct" morph="none" start_char="2879" end_char="2879">,</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="2881" end_char="2881">y</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="2883" end_char="2884">el</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="2886" end_char="2892">trabajo</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="2894" end_char="2895">no</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="2897" end_char="2900">pasa</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="2902" end_char="2903">de</TOKEN>
<TOKEN id="token-22-18" pos="word" morph="none" start_char="2905" end_char="2907">una</TOKEN>
<TOKEN id="token-22-19" pos="word" morph="none" start_char="2909" end_char="2912">mera</TOKEN>
<TOKEN id="token-22-20" pos="word" morph="none" start_char="2914" end_char="2923">simulación</TOKEN>
<TOKEN id="token-22-21" pos="word" morph="none" start_char="2925" end_char="2925">a</TOKEN>
<TOKEN id="token-22-22" pos="word" morph="none" start_char="2927" end_char="2932">través</TOKEN>
<TOKEN id="token-22-23" pos="word" morph="none" start_char="2934" end_char="2935">de</TOKEN>
<TOKEN id="token-22-24" pos="word" morph="none" start_char="2937" end_char="2938">un</TOKEN>
<TOKEN id="token-22-25" pos="word" morph="none" start_char="2940" end_char="2948">ordenador</TOKEN>
<TOKEN id="token-22-26" pos="punct" morph="none" start_char="2949" end_char="2949">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2951" end_char="3087">
<ORIGINAL_TEXT>La investigación es similar a otras que señalaron a las serpientes como origen del COVID-19, y que finalmente se demostraron equivocadas.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2951" end_char="2952">La</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2954" end_char="2966">investigación</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2968" end_char="2969">es</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2971" end_char="2977">similar</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="2979" end_char="2979">a</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="2981" end_char="2985">otras</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="2987" end_char="2989">que</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="2991" end_char="2999">señalaron</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="3001" end_char="3001">a</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="3003" end_char="3005">las</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="3007" end_char="3016">serpientes</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="3018" end_char="3021">como</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="3023" end_char="3028">origen</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="3030" end_char="3032">del</TOKEN>
<TOKEN id="token-23-14" pos="unknown" morph="none" start_char="3034" end_char="3041">COVID-19</TOKEN>
<TOKEN id="token-23-15" pos="punct" morph="none" start_char="3042" end_char="3042">,</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="3044" end_char="3044">y</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="3046" end_char="3048">que</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="3050" end_char="3059">finalmente</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="3061" end_char="3062">se</TOKEN>
<TOKEN id="token-23-20" pos="word" morph="none" start_char="3064" end_char="3074">demostraron</TOKEN>
<TOKEN id="token-23-21" pos="word" morph="none" start_char="3076" end_char="3086">equivocadas</TOKEN>
<TOKEN id="token-23-22" pos="punct" morph="none" start_char="3087" end_char="3087">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="3090" end_char="3291">
<ORIGINAL_TEXT>El propio artículo descarta que el virus se transmita comiendo a un animal, por lo que la hipótesis de que estos perros fuesen vendidos en el mercado de Wuhan también queda como un dato sin importancia.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="3090" end_char="3091">El</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="3093" end_char="3098">propio</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="3100" end_char="3107">artículo</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="3109" end_char="3116">descarta</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="3118" end_char="3120">que</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="3122" end_char="3123">el</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="3125" end_char="3129">virus</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="3131" end_char="3132">se</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="3134" end_char="3142">transmita</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="3144" end_char="3151">comiendo</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="3153" end_char="3153">a</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="3155" end_char="3156">un</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="3158" end_char="3163">animal</TOKEN>
<TOKEN id="token-24-13" pos="punct" morph="none" start_char="3164" end_char="3164">,</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="3166" end_char="3168">por</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="3170" end_char="3171">lo</TOKEN>
<TOKEN id="token-24-16" pos="word" morph="none" start_char="3173" end_char="3175">que</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="3177" end_char="3178">la</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="3180" end_char="3188">hipótesis</TOKEN>
<TOKEN id="token-24-19" pos="word" morph="none" start_char="3190" end_char="3191">de</TOKEN>
<TOKEN id="token-24-20" pos="word" morph="none" start_char="3193" end_char="3195">que</TOKEN>
<TOKEN id="token-24-21" pos="word" morph="none" start_char="3197" end_char="3201">estos</TOKEN>
<TOKEN id="token-24-22" pos="word" morph="none" start_char="3203" end_char="3208">perros</TOKEN>
<TOKEN id="token-24-23" pos="word" morph="none" start_char="3210" end_char="3215">fuesen</TOKEN>
<TOKEN id="token-24-24" pos="word" morph="none" start_char="3217" end_char="3224">vendidos</TOKEN>
<TOKEN id="token-24-25" pos="word" morph="none" start_char="3226" end_char="3227">en</TOKEN>
<TOKEN id="token-24-26" pos="word" morph="none" start_char="3229" end_char="3230">el</TOKEN>
<TOKEN id="token-24-27" pos="word" morph="none" start_char="3232" end_char="3238">mercado</TOKEN>
<TOKEN id="token-24-28" pos="word" morph="none" start_char="3240" end_char="3241">de</TOKEN>
<TOKEN id="token-24-29" pos="word" morph="none" start_char="3243" end_char="3247">Wuhan</TOKEN>
<TOKEN id="token-24-30" pos="word" morph="none" start_char="3249" end_char="3255">también</TOKEN>
<TOKEN id="token-24-31" pos="word" morph="none" start_char="3257" end_char="3261">queda</TOKEN>
<TOKEN id="token-24-32" pos="word" morph="none" start_char="3263" end_char="3266">como</TOKEN>
<TOKEN id="token-24-33" pos="word" morph="none" start_char="3268" end_char="3269">un</TOKEN>
<TOKEN id="token-24-34" pos="word" morph="none" start_char="3271" end_char="3274">dato</TOKEN>
<TOKEN id="token-24-35" pos="word" morph="none" start_char="3276" end_char="3278">sin</TOKEN>
<TOKEN id="token-24-36" pos="word" morph="none" start_char="3280" end_char="3290">importancia</TOKEN>
<TOKEN id="token-24-37" pos="punct" morph="none" start_char="3291" end_char="3291">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="3294" end_char="3404">
<ORIGINAL_TEXT>Leer más: Esta sería la fecha final del confinamiento en España si se siguiese la misma cuarentena que en China</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="3294" end_char="3297">Leer</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="3299" end_char="3301">más</TOKEN>
<TOKEN id="token-25-2" pos="punct" morph="none" start_char="3302" end_char="3302">:</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="3304" end_char="3307">Esta</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="3309" end_char="3313">sería</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="3315" end_char="3316">la</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="3318" end_char="3322">fecha</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="3324" end_char="3328">final</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="3330" end_char="3332">del</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="3334" end_char="3346">confinamiento</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="3348" end_char="3349">en</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="3351" end_char="3356">España</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="3358" end_char="3359">si</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="3361" end_char="3362">se</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="3364" end_char="3371">siguiese</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="3373" end_char="3374">la</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="3376" end_char="3380">misma</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="3382" end_char="3391">cuarentena</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="3393" end_char="3395">que</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="3397" end_char="3398">en</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="3400" end_char="3404">China</TOKEN>
</SEG>
<SEG id="segment-26" start_char="3408" end_char="3478">
<ORIGINAL_TEXT>Aún tomando como cierta esta hipótesis quedan muchas dudas al respecto.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="3408" end_char="3410">Aún</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="3412" end_char="3418">tomando</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="3420" end_char="3423">como</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="3425" end_char="3430">cierta</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="3432" end_char="3435">esta</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="3437" end_char="3445">hipótesis</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="3447" end_char="3452">quedan</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="3454" end_char="3459">muchas</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="3461" end_char="3465">dudas</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="3467" end_char="3468">al</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="3470" end_char="3477">respecto</TOKEN>
<TOKEN id="token-26-11" pos="punct" morph="none" start_char="3478" end_char="3478">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="3480" end_char="3548">
<ORIGINAL_TEXT>¿Cómo se transmite el virus desde un perro callejero a un ser humano?</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="punct" morph="none" start_char="3480" end_char="3480">¿</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="3481" end_char="3484">Cómo</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="3486" end_char="3487">se</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="3489" end_char="3497">transmite</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="3499" end_char="3500">el</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="3502" end_char="3506">virus</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="3508" end_char="3512">desde</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="3514" end_char="3515">un</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="3517" end_char="3521">perro</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="3523" end_char="3531">callejero</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="3533" end_char="3533">a</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="3535" end_char="3536">un</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="3538" end_char="3540">ser</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="3542" end_char="3547">humano</TOKEN>
<TOKEN id="token-27-14" pos="punct" morph="none" start_char="3548" end_char="3548">?</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3550" end_char="3703">
<ORIGINAL_TEXT>La única posibilidad, según el mismo estudio, es entrando en contacto con las heces del animal para después tocar las membranas de tu propia boca o nariz.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="3550" end_char="3551">La</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="3553" end_char="3557">única</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="3559" end_char="3569">posibilidad</TOKEN>
<TOKEN id="token-28-3" pos="punct" morph="none" start_char="3570" end_char="3570">,</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="3572" end_char="3576">según</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="3578" end_char="3579">el</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="3581" end_char="3585">mismo</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="3587" end_char="3593">estudio</TOKEN>
<TOKEN id="token-28-8" pos="punct" morph="none" start_char="3594" end_char="3594">,</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="3596" end_char="3597">es</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="3599" end_char="3606">entrando</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="3608" end_char="3609">en</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="3611" end_char="3618">contacto</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="3620" end_char="3622">con</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="3624" end_char="3626">las</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="3628" end_char="3632">heces</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="3634" end_char="3636">del</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="3638" end_char="3643">animal</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="3645" end_char="3648">para</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="3650" end_char="3656">después</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="3658" end_char="3662">tocar</TOKEN>
<TOKEN id="token-28-21" pos="word" morph="none" start_char="3664" end_char="3666">las</TOKEN>
<TOKEN id="token-28-22" pos="word" morph="none" start_char="3668" end_char="3676">membranas</TOKEN>
<TOKEN id="token-28-23" pos="word" morph="none" start_char="3678" end_char="3679">de</TOKEN>
<TOKEN id="token-28-24" pos="word" morph="none" start_char="3681" end_char="3682">tu</TOKEN>
<TOKEN id="token-28-25" pos="word" morph="none" start_char="3684" end_char="3689">propia</TOKEN>
<TOKEN id="token-28-26" pos="word" morph="none" start_char="3691" end_char="3694">boca</TOKEN>
<TOKEN id="token-28-27" pos="word" morph="none" start_char="3696" end_char="3696">o</TOKEN>
<TOKEN id="token-28-28" pos="word" morph="none" start_char="3698" end_char="3702">nariz</TOKEN>
<TOKEN id="token-28-29" pos="punct" morph="none" start_char="3703" end_char="3703">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3706" end_char="3805">
<ORIGINAL_TEXT>Otra opción es sufrir la mordedura de un perro justo después de que este haya lamido su área rectal.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="3706" end_char="3709">Otra</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="3711" end_char="3716">opción</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="3718" end_char="3719">es</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="3721" end_char="3726">sufrir</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="3728" end_char="3729">la</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="3731" end_char="3739">mordedura</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="3741" end_char="3742">de</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="3744" end_char="3745">un</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="3747" end_char="3751">perro</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="3753" end_char="3757">justo</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="3759" end_char="3765">después</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="3767" end_char="3768">de</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="3770" end_char="3772">que</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="3774" end_char="3777">este</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="3779" end_char="3782">haya</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="3784" end_char="3789">lamido</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="3791" end_char="3792">su</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="3794" end_char="3797">área</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="3799" end_char="3804">rectal</TOKEN>
<TOKEN id="token-29-19" pos="punct" morph="none" start_char="3805" end_char="3805">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3807" end_char="3878">
<ORIGINAL_TEXT>Es decir, las posibles explicaciones no van más allá de la especulación.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="3807" end_char="3808">Es</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="3810" end_char="3814">decir</TOKEN>
<TOKEN id="token-30-2" pos="punct" morph="none" start_char="3815" end_char="3815">,</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="3817" end_char="3819">las</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="3821" end_char="3828">posibles</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="3830" end_char="3842">explicaciones</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="3844" end_char="3845">no</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="3847" end_char="3849">van</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="3851" end_char="3853">más</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="3855" end_char="3858">allá</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="3860" end_char="3861">de</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="3863" end_char="3864">la</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="3866" end_char="3877">especulación</TOKEN>
<TOKEN id="token-30-13" pos="punct" morph="none" start_char="3878" end_char="3878">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
