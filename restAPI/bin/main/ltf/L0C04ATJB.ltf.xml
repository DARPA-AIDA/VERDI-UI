<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATJB" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="2391" raw_text_md5="e6e1c1bc6cb7986af232331a254c40d2">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="80">
<ORIGINAL_TEXT>Does the coronavirus no longer exist clinically as claimed by an Italian doctor?</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="4">Does</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="6" end_char="8">the</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="10" end_char="20">coronavirus</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="22" end_char="23">no</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="25" end_char="30">longer</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="32" end_char="36">exist</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="38" end_char="47">clinically</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="49" end_char="50">as</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="52" end_char="58">claimed</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="60" end_char="61">by</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="63" end_char="64">an</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="66" end_char="72">Italian</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="74" end_char="79">doctor</TOKEN>
<TOKEN id="token-0-13" pos="punct" morph="none" start_char="80" end_char="80">?</TOKEN>
</SEG>
<SEG id="segment-1" start_char="82" end_char="102">
<ORIGINAL_TEXT>Belgian experts speak</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="82" end_char="88">Belgian</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="90" end_char="96">experts</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="98" end_char="102">speak</TOKEN>
</SEG>
<SEG id="segment-2" start_char="107" end_char="161">
<ORIGINAL_TEXT>Marc Van Ranst and Geert Meyfroidt warned the Belgians.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="107" end_char="110">Marc</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="112" end_char="114">Van</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="116" end_char="120">Ranst</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="122" end_char="124">and</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="126" end_char="130">Geert</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="132" end_char="140">Meyfroidt</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="142" end_char="147">warned</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="149" end_char="151">the</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="153" end_char="160">Belgians</TOKEN>
<TOKEN id="token-2-9" pos="punct" morph="none" start_char="161" end_char="161">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="165" end_char="204">
<ORIGINAL_TEXT>"The virus no longer exists clinically".</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="punct" morph="none" start_char="165" end_char="165">"</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="166" end_char="168">The</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="170" end_char="174">virus</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="176" end_char="177">no</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="179" end_char="184">longer</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="186" end_char="191">exists</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="193" end_char="202">clinically</TOKEN>
<TOKEN id="token-3-7" pos="punct" morph="none" start_char="203" end_char="204">".</TOKEN>
</SEG>
<SEG id="segment-4" start_char="206" end_char="227">
<ORIGINAL_TEXT>This was stated by Dr.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="206" end_char="209">This</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="211" end_char="213">was</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="215" end_char="220">stated</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="222" end_char="223">by</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="225" end_char="226">Dr</TOKEN>
<TOKEN id="token-4-5" pos="punct" morph="none" start_char="227" end_char="227">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="229" end_char="314">
<ORIGINAL_TEXT>Albert Zangrillo, director of the San Raffaele hospital in Milan, this Monday, June 1.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="229" end_char="234">Albert</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="236" end_char="244">Zangrillo</TOKEN>
<TOKEN id="token-5-2" pos="punct" morph="none" start_char="245" end_char="245">,</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="247" end_char="254">director</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="256" end_char="257">of</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="259" end_char="261">the</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="263" end_char="265">San</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="267" end_char="274">Raffaele</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="276" end_char="283">hospital</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="285" end_char="286">in</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="288" end_char="292">Milan</TOKEN>
<TOKEN id="token-5-11" pos="punct" morph="none" start_char="293" end_char="293">,</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="295" end_char="298">this</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="300" end_char="305">Monday</TOKEN>
<TOKEN id="token-5-14" pos="punct" morph="none" start_char="306" end_char="306">,</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="308" end_char="311">June</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="313" end_char="313">1</TOKEN>
<TOKEN id="token-5-17" pos="punct" morph="none" start_char="314" end_char="314">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="316" end_char="447">
<ORIGINAL_TEXT>Comments emphasizing that the strength of the virus would have considerably weakened which were just as quickly reframed by the WHO.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="316" end_char="323">Comments</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="325" end_char="335">emphasizing</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="337" end_char="340">that</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="342" end_char="344">the</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="346" end_char="353">strength</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="355" end_char="356">of</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="358" end_char="360">the</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="362" end_char="366">virus</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="368" end_char="372">would</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="374" end_char="377">have</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="379" end_char="390">considerably</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="392" end_char="399">weakened</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="401" end_char="405">which</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="407" end_char="410">were</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="412" end_char="415">just</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="417" end_char="418">as</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="420" end_char="426">quickly</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="428" end_char="435">reframed</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="437" end_char="438">by</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="440" end_char="442">the</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="444" end_char="446">WHO</TOKEN>
<TOKEN id="token-6-21" pos="punct" morph="none" start_char="447" end_char="447">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="449" end_char="493">
<ORIGINAL_TEXT>The agency pointed to a misleading statement.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="449" end_char="451">The</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="453" end_char="458">agency</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="460" end_char="466">pointed</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="468" end_char="469">to</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="471" end_char="471">a</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="473" end_char="482">misleading</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="484" end_char="492">statement</TOKEN>
<TOKEN id="token-7-7" pos="punct" morph="none" start_char="493" end_char="493">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="495" end_char="711">
<ORIGINAL_TEXT>"We must be exceptionally careful not to give the impression that suddenly the virus, by its own free will, has decided to become less pathogenic, responded Michael Ryan, head of the emergency response program at WHO.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="punct" morph="none" start_char="495" end_char="495">"</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="496" end_char="497">We</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="499" end_char="502">must</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="504" end_char="505">be</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="507" end_char="519">exceptionally</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="521" end_char="527">careful</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="529" end_char="531">not</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="533" end_char="534">to</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="536" end_char="539">give</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="541" end_char="543">the</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="545" end_char="554">impression</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="556" end_char="559">that</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="561" end_char="568">suddenly</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="570" end_char="572">the</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="574" end_char="578">virus</TOKEN>
<TOKEN id="token-8-15" pos="punct" morph="none" start_char="579" end_char="579">,</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="581" end_char="582">by</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="584" end_char="586">its</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="588" end_char="590">own</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="592" end_char="595">free</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="597" end_char="600">will</TOKEN>
<TOKEN id="token-8-21" pos="punct" morph="none" start_char="601" end_char="601">,</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="603" end_char="605">has</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="607" end_char="613">decided</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="615" end_char="616">to</TOKEN>
<TOKEN id="token-8-25" pos="word" morph="none" start_char="618" end_char="623">become</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="625" end_char="628">less</TOKEN>
<TOKEN id="token-8-27" pos="word" morph="none" start_char="630" end_char="639">pathogenic</TOKEN>
<TOKEN id="token-8-28" pos="punct" morph="none" start_char="640" end_char="640">,</TOKEN>
<TOKEN id="token-8-29" pos="word" morph="none" start_char="642" end_char="650">responded</TOKEN>
<TOKEN id="token-8-30" pos="word" morph="none" start_char="652" end_char="658">Michael</TOKEN>
<TOKEN id="token-8-31" pos="word" morph="none" start_char="660" end_char="663">Ryan</TOKEN>
<TOKEN id="token-8-32" pos="punct" morph="none" start_char="664" end_char="664">,</TOKEN>
<TOKEN id="token-8-33" pos="word" morph="none" start_char="666" end_char="669">head</TOKEN>
<TOKEN id="token-8-34" pos="word" morph="none" start_char="671" end_char="672">of</TOKEN>
<TOKEN id="token-8-35" pos="word" morph="none" start_char="674" end_char="676">the</TOKEN>
<TOKEN id="token-8-36" pos="word" morph="none" start_char="678" end_char="686">emergency</TOKEN>
<TOKEN id="token-8-37" pos="word" morph="none" start_char="688" end_char="695">response</TOKEN>
<TOKEN id="token-8-38" pos="word" morph="none" start_char="697" end_char="703">program</TOKEN>
<TOKEN id="token-8-39" pos="word" morph="none" start_char="705" end_char="706">at</TOKEN>
<TOKEN id="token-8-40" pos="word" morph="none" start_char="708" end_char="710">WHO</TOKEN>
<TOKEN id="token-8-41" pos="punct" morph="none" start_char="711" end_char="711">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="713" end_char="739">
<ORIGINAL_TEXT>It is not the case at all."</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="713" end_char="714">It</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="716" end_char="717">is</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="719" end_char="721">not</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="723" end_char="725">the</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="727" end_char="730">case</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="732" end_char="733">at</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="735" end_char="737">all</TOKEN>
<TOKEN id="token-9-7" pos="punct" morph="none" start_char="738" end_char="739">."</TOKEN>
</SEG>
<SEG id="segment-10" start_char="742" end_char="751">
<ORIGINAL_TEXT>"No proof"</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="punct" morph="none" start_char="742" end_char="742">"</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="743" end_char="744">No</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="746" end_char="750">proof</TOKEN>
<TOKEN id="token-10-3" pos="punct" morph="none" start_char="751" end_char="751">"</TOKEN>
</SEG>
<SEG id="segment-11" start_char="755" end_char="951">
<ORIGINAL_TEXT>While in Belgium the trend is optimistic in view of the fairly low figures from the latest epidemiological reports, the experts also wished to remain cautious regarding the Italian doctor’s claims.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="755" end_char="759">While</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="761" end_char="762">in</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="764" end_char="770">Belgium</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="772" end_char="774">the</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="776" end_char="780">trend</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="782" end_char="783">is</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="785" end_char="794">optimistic</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="796" end_char="797">in</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="799" end_char="802">view</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="804" end_char="805">of</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="807" end_char="809">the</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="811" end_char="816">fairly</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="818" end_char="820">low</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="822" end_char="828">figures</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="830" end_char="833">from</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="835" end_char="837">the</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="839" end_char="844">latest</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="846" end_char="860">epidemiological</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="862" end_char="868">reports</TOKEN>
<TOKEN id="token-11-19" pos="punct" morph="none" start_char="869" end_char="869">,</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="871" end_char="873">the</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="875" end_char="881">experts</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="883" end_char="886">also</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="888" end_char="893">wished</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="895" end_char="896">to</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="898" end_char="903">remain</TOKEN>
<TOKEN id="token-11-26" pos="word" morph="none" start_char="905" end_char="912">cautious</TOKEN>
<TOKEN id="token-11-27" pos="word" morph="none" start_char="914" end_char="922">regarding</TOKEN>
<TOKEN id="token-11-28" pos="word" morph="none" start_char="924" end_char="926">the</TOKEN>
<TOKEN id="token-11-29" pos="word" morph="none" start_char="928" end_char="934">Italian</TOKEN>
<TOKEN id="token-11-30" pos="word" morph="none" start_char="936" end_char="943">doctor’s</TOKEN>
<TOKEN id="token-11-31" pos="word" morph="none" start_char="945" end_char="950">claims</TOKEN>
<TOKEN id="token-11-32" pos="punct" morph="none" start_char="951" end_char="951">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="953" end_char="1090">
<ORIGINAL_TEXT>"There is no evidence that the coronavirus has weakened or become less contagious," warned specialists, interviewed by our colleagues from</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="punct" morph="none" start_char="953" end_char="953">"</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="954" end_char="958">There</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="960" end_char="961">is</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="963" end_char="964">no</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="966" end_char="973">evidence</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="975" end_char="978">that</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="980" end_char="982">the</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="984" end_char="994">coronavirus</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="996" end_char="998">has</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1000" end_char="1007">weakened</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1009" end_char="1010">or</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1012" end_char="1017">become</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1019" end_char="1022">less</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1024" end_char="1033">contagious</TOKEN>
<TOKEN id="token-12-14" pos="punct" morph="none" start_char="1034" end_char="1035">,"</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1037" end_char="1042">warned</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1044" end_char="1054">specialists</TOKEN>
<TOKEN id="token-12-17" pos="punct" morph="none" start_char="1055" end_char="1055">,</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1057" end_char="1067">interviewed</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1069" end_char="1070">by</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1072" end_char="1074">our</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1076" end_char="1085">colleagues</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1087" end_char="1090">from</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1093" end_char="1110">
<ORIGINAL_TEXT>Het Laatste Nieuws</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1093" end_char="1095">Het</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1097" end_char="1103">Laatste</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1105" end_char="1110">Nieuws</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1113" end_char="1113">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="punct" morph="none" start_char="1113" end_char="1113">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1115" end_char="1238">
<ORIGINAL_TEXT>Virologist Marc Van Ranst (KULeuven), for his part, recalled that one could always be as sick in the event of contamination.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1115" end_char="1124">Virologist</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1126" end_char="1129">Marc</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1131" end_char="1133">Van</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1135" end_char="1139">Ranst</TOKEN>
<TOKEN id="token-15-4" pos="punct" morph="none" start_char="1141" end_char="1141">(</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1142" end_char="1149">KULeuven</TOKEN>
<TOKEN id="token-15-6" pos="punct" morph="none" start_char="1150" end_char="1151">),</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1153" end_char="1155">for</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1157" end_char="1159">his</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1161" end_char="1164">part</TOKEN>
<TOKEN id="token-15-10" pos="punct" morph="none" start_char="1165" end_char="1165">,</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1167" end_char="1174">recalled</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1176" end_char="1179">that</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1181" end_char="1183">one</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1185" end_char="1189">could</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="1191" end_char="1196">always</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="1198" end_char="1199">be</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="1201" end_char="1202">as</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="1204" end_char="1207">sick</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="1209" end_char="1210">in</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="1212" end_char="1214">the</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="1216" end_char="1220">event</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="1222" end_char="1223">of</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="1225" end_char="1237">contamination</TOKEN>
<TOKEN id="token-15-24" pos="punct" morph="none" start_char="1238" end_char="1238">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1240" end_char="1422">
<ORIGINAL_TEXT>"People have the impression that a virus does less damage at the beginning or at the end of the epidemic, because there are fewer people affected, noted the expert member of the GEES.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="punct" morph="none" start_char="1240" end_char="1240">"</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1241" end_char="1246">People</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1248" end_char="1251">have</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1253" end_char="1255">the</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1257" end_char="1266">impression</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1268" end_char="1271">that</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1273" end_char="1273">a</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1275" end_char="1279">virus</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1281" end_char="1284">does</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="1286" end_char="1289">less</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="1291" end_char="1296">damage</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="1298" end_char="1299">at</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="1301" end_char="1303">the</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="1305" end_char="1313">beginning</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="1315" end_char="1316">or</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="1318" end_char="1319">at</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="1321" end_char="1323">the</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="1325" end_char="1327">end</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="1329" end_char="1330">of</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="1332" end_char="1334">the</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="1336" end_char="1343">epidemic</TOKEN>
<TOKEN id="token-16-21" pos="punct" morph="none" start_char="1344" end_char="1344">,</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="1346" end_char="1352">because</TOKEN>
<TOKEN id="token-16-23" pos="word" morph="none" start_char="1354" end_char="1358">there</TOKEN>
<TOKEN id="token-16-24" pos="word" morph="none" start_char="1360" end_char="1362">are</TOKEN>
<TOKEN id="token-16-25" pos="word" morph="none" start_char="1364" end_char="1368">fewer</TOKEN>
<TOKEN id="token-16-26" pos="word" morph="none" start_char="1370" end_char="1375">people</TOKEN>
<TOKEN id="token-16-27" pos="word" morph="none" start_char="1377" end_char="1384">affected</TOKEN>
<TOKEN id="token-16-28" pos="punct" morph="none" start_char="1385" end_char="1385">,</TOKEN>
<TOKEN id="token-16-29" pos="word" morph="none" start_char="1387" end_char="1391">noted</TOKEN>
<TOKEN id="token-16-30" pos="word" morph="none" start_char="1393" end_char="1395">the</TOKEN>
<TOKEN id="token-16-31" pos="word" morph="none" start_char="1397" end_char="1402">expert</TOKEN>
<TOKEN id="token-16-32" pos="word" morph="none" start_char="1404" end_char="1409">member</TOKEN>
<TOKEN id="token-16-33" pos="word" morph="none" start_char="1411" end_char="1412">of</TOKEN>
<TOKEN id="token-16-34" pos="word" morph="none" start_char="1414" end_char="1416">the</TOKEN>
<TOKEN id="token-16-35" pos="word" morph="none" start_char="1418" end_char="1421">GEES</TOKEN>
<TOKEN id="token-16-36" pos="punct" morph="none" start_char="1422" end_char="1422">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1424" end_char="1511">
<ORIGINAL_TEXT>But whether you are infected at start or end of the pandemic, you will always be sick. "</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1424" end_char="1426">But</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1428" end_char="1434">whether</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="1436" end_char="1438">you</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="1440" end_char="1442">are</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="1444" end_char="1451">infected</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="1453" end_char="1454">at</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="1456" end_char="1460">start</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="1462" end_char="1463">or</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="1465" end_char="1467">end</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="1469" end_char="1470">of</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="1472" end_char="1474">the</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="1476" end_char="1483">pandemic</TOKEN>
<TOKEN id="token-17-12" pos="punct" morph="none" start_char="1484" end_char="1484">,</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="1486" end_char="1488">you</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="1490" end_char="1493">will</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="1495" end_char="1500">always</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="1502" end_char="1503">be</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="1505" end_char="1508">sick</TOKEN>
<TOKEN id="token-17-18" pos="punct" morph="none" start_char="1509" end_char="1509">.</TOKEN>
<TOKEN id="token-17-19" pos="punct" morph="none" start_char="1511" end_char="1511">"</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1514" end_char="1605">
<ORIGINAL_TEXT>Same story with Geert Meyfroidt, president of the Belgian Association of Intensive Medicine.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="1514" end_char="1517">Same</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="1519" end_char="1523">story</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="1525" end_char="1528">with</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="1530" end_char="1534">Geert</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="1536" end_char="1544">Meyfroidt</TOKEN>
<TOKEN id="token-18-5" pos="punct" morph="none" start_char="1545" end_char="1545">,</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="1547" end_char="1555">president</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="1557" end_char="1558">of</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="1560" end_char="1562">the</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="1564" end_char="1570">Belgian</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="1572" end_char="1582">Association</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="1584" end_char="1585">of</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="1587" end_char="1595">Intensive</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="1597" end_char="1604">Medicine</TOKEN>
<TOKEN id="token-18-14" pos="punct" morph="none" start_char="1605" end_char="1605">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="1607" end_char="1718">
<ORIGINAL_TEXT>"We will reach the end of the epidemic when no new infection has been registered for at least a month," he said.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="punct" morph="none" start_char="1607" end_char="1607">"</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="1608" end_char="1609">We</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="1611" end_char="1614">will</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="1616" end_char="1620">reach</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="1622" end_char="1624">the</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="1626" end_char="1628">end</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="1630" end_char="1631">of</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="1633" end_char="1635">the</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="1637" end_char="1644">epidemic</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="1646" end_char="1649">when</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="1651" end_char="1652">no</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="1654" end_char="1656">new</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="1658" end_char="1666">infection</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="1668" end_char="1670">has</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="1672" end_char="1675">been</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="1677" end_char="1686">registered</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="1688" end_char="1690">for</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="1692" end_char="1693">at</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="1695" end_char="1699">least</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="1701" end_char="1701">a</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="1703" end_char="1707">month</TOKEN>
<TOKEN id="token-19-21" pos="punct" morph="none" start_char="1708" end_char="1709">,"</TOKEN>
<TOKEN id="token-19-22" pos="word" morph="none" start_char="1711" end_char="1712">he</TOKEN>
<TOKEN id="token-19-23" pos="word" morph="none" start_char="1714" end_char="1717">said</TOKEN>
<TOKEN id="token-19-24" pos="punct" morph="none" start_char="1718" end_char="1718">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="1721" end_char="1738">
<ORIGINAL_TEXT>Het Laatste Nieuws</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="1721" end_char="1723">Het</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="1725" end_char="1731">Laatste</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="1733" end_char="1738">Nieuws</TOKEN>
</SEG>
<SEG id="segment-21" start_char="1741" end_char="1741">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="punct" morph="none" start_char="1741" end_char="1741">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="1743" end_char="1770">
<ORIGINAL_TEXT>We are not there yet at all.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="1743" end_char="1744">We</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="1746" end_char="1748">are</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="1750" end_char="1752">not</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="1754" end_char="1758">there</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="1760" end_char="1762">yet</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="1764" end_char="1765">at</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="1767" end_char="1769">all</TOKEN>
<TOKEN id="token-22-7" pos="punct" morph="none" start_char="1770" end_char="1770">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="1772" end_char="1948">
<ORIGINAL_TEXT>There are now no more new patients entering intensive care, but if you look at the percentages there are still as many people who fall seriously ill as those who are less ill. "</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="1772" end_char="1776">There</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="1778" end_char="1780">are</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="1782" end_char="1784">now</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="1786" end_char="1787">no</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="1789" end_char="1792">more</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="1794" end_char="1796">new</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="1798" end_char="1805">patients</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="1807" end_char="1814">entering</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="1816" end_char="1824">intensive</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="1826" end_char="1829">care</TOKEN>
<TOKEN id="token-23-10" pos="punct" morph="none" start_char="1830" end_char="1830">,</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="1832" end_char="1834">but</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="1836" end_char="1837">if</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="1839" end_char="1841">you</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="1843" end_char="1846">look</TOKEN>
<TOKEN id="token-23-15" pos="word" morph="none" start_char="1848" end_char="1849">at</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="1851" end_char="1853">the</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="1855" end_char="1865">percentages</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="1867" end_char="1871">there</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="1873" end_char="1875">are</TOKEN>
<TOKEN id="token-23-20" pos="word" morph="none" start_char="1877" end_char="1881">still</TOKEN>
<TOKEN id="token-23-21" pos="word" morph="none" start_char="1883" end_char="1884">as</TOKEN>
<TOKEN id="token-23-22" pos="word" morph="none" start_char="1886" end_char="1889">many</TOKEN>
<TOKEN id="token-23-23" pos="word" morph="none" start_char="1891" end_char="1896">people</TOKEN>
<TOKEN id="token-23-24" pos="word" morph="none" start_char="1898" end_char="1900">who</TOKEN>
<TOKEN id="token-23-25" pos="word" morph="none" start_char="1902" end_char="1905">fall</TOKEN>
<TOKEN id="token-23-26" pos="word" morph="none" start_char="1907" end_char="1915">seriously</TOKEN>
<TOKEN id="token-23-27" pos="word" morph="none" start_char="1917" end_char="1919">ill</TOKEN>
<TOKEN id="token-23-28" pos="word" morph="none" start_char="1921" end_char="1922">as</TOKEN>
<TOKEN id="token-23-29" pos="word" morph="none" start_char="1924" end_char="1928">those</TOKEN>
<TOKEN id="token-23-30" pos="word" morph="none" start_char="1930" end_char="1932">who</TOKEN>
<TOKEN id="token-23-31" pos="word" morph="none" start_char="1934" end_char="1936">are</TOKEN>
<TOKEN id="token-23-32" pos="word" morph="none" start_char="1938" end_char="1941">less</TOKEN>
<TOKEN id="token-23-33" pos="word" morph="none" start_char="1943" end_char="1945">ill</TOKEN>
<TOKEN id="token-23-34" pos="punct" morph="none" start_char="1946" end_char="1946">.</TOKEN>
<TOKEN id="token-23-35" pos="punct" morph="none" start_char="1948" end_char="1948">"</TOKEN>
</SEG>
<SEG id="segment-24" start_char="1951" end_char="1962">
<ORIGINAL_TEXT>Like a pizza</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="1951" end_char="1954">Like</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="1956" end_char="1956">a</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="1958" end_char="1962">pizza</TOKEN>
</SEG>
<SEG id="segment-25" start_char="1966" end_char="2070">
<ORIGINAL_TEXT>Dr. Zangrillo relied on samples from his hospital to state that the "virus no longer existed clinically".</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="1966" end_char="1967">Dr</TOKEN>
<TOKEN id="token-25-1" pos="punct" morph="none" start_char="1968" end_char="1968">.</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="1970" end_char="1978">Zangrillo</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="1980" end_char="1985">relied</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="1987" end_char="1988">on</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="1990" end_char="1996">samples</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="1998" end_char="2001">from</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="2003" end_char="2005">his</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="2007" end_char="2014">hospital</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="2016" end_char="2017">to</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="2019" end_char="2023">state</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="2025" end_char="2028">that</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="2030" end_char="2032">the</TOKEN>
<TOKEN id="token-25-13" pos="punct" morph="none" start_char="2034" end_char="2034">"</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="2035" end_char="2039">virus</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="2041" end_char="2042">no</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="2044" end_char="2049">longer</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="2051" end_char="2057">existed</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="2059" end_char="2068">clinically</TOKEN>
<TOKEN id="token-25-19" pos="punct" morph="none" start_char="2069" end_char="2070">".</TOKEN>
</SEG>
<SEG id="segment-26" start_char="2072" end_char="2161">
<ORIGINAL_TEXT>According to an American researcher, it does not make sense to make certain cases general.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="2072" end_char="2080">According</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="2082" end_char="2083">to</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="2085" end_char="2086">an</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="2088" end_char="2095">American</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="2097" end_char="2106">researcher</TOKEN>
<TOKEN id="token-26-5" pos="punct" morph="none" start_char="2107" end_char="2107">,</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="2109" end_char="2110">it</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="2112" end_char="2115">does</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="2117" end_char="2119">not</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="2121" end_char="2124">make</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="2126" end_char="2130">sense</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="2132" end_char="2133">to</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="2135" end_char="2138">make</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="2140" end_char="2146">certain</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="2148" end_char="2152">cases</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="2154" end_char="2160">general</TOKEN>
<TOKEN id="token-26-16" pos="punct" morph="none" start_char="2161" end_char="2161">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="2163" end_char="2205">
<ORIGINAL_TEXT>The latter thus gave the example of pizzas.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="2163" end_char="2165">The</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="2167" end_char="2172">latter</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="2174" end_char="2177">thus</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="2179" end_char="2182">gave</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="2184" end_char="2186">the</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="2188" end_char="2194">example</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="2196" end_char="2197">of</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="2199" end_char="2204">pizzas</TOKEN>
<TOKEN id="token-27-8" pos="punct" morph="none" start_char="2205" end_char="2205">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="2207" end_char="2270">
<ORIGINAL_TEXT>Just because a restaurant pizza is tasty doesn’t mean it is all.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="2207" end_char="2210">Just</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="2212" end_char="2218">because</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="2220" end_char="2220">a</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="2222" end_char="2231">restaurant</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="2233" end_char="2237">pizza</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="2239" end_char="2240">is</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="2242" end_char="2246">tasty</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="2248" end_char="2254">doesn’t</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="2256" end_char="2259">mean</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="2261" end_char="2262">it</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="2264" end_char="2265">is</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="2267" end_char="2269">all</TOKEN>
<TOKEN id="token-28-12" pos="punct" morph="none" start_char="2270" end_char="2270">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="2273" end_char="2279">
<ORIGINAL_TEXT>Related</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="2273" end_char="2279">Related</TOKEN>
</SEG>
<SEG id="segment-30" start_char="2283" end_char="2319">
<ORIGINAL_TEXT>Does the coronavirus no longer exist?</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="2283" end_char="2286">Does</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="2288" end_char="2290">the</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="2292" end_char="2302">coronavirus</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="2304" end_char="2305">no</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="2307" end_char="2312">longer</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="2314" end_char="2318">exist</TOKEN>
<TOKEN id="token-30-6" pos="punct" morph="none" start_char="2319" end_char="2319">?</TOKEN>
</SEG>
<SEG id="segment-31" start_char="2321" end_char="2387">
<ORIGINAL_TEXT>The controversy between an eminence of Italian medicine and the WHO</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="2321" end_char="2323">The</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="2325" end_char="2335">controversy</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="2337" end_char="2343">between</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="2345" end_char="2346">an</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="2348" end_char="2355">eminence</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="2357" end_char="2358">of</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="2360" end_char="2366">Italian</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="2368" end_char="2375">medicine</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="2377" end_char="2379">and</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="2381" end_char="2383">the</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="2385" end_char="2387">WHO</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
