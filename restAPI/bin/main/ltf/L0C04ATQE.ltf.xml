<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATQE" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="1019" raw_text_md5="a086b5938cf9adc5099d5526379e9aa4">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="65">
<ORIGINAL_TEXT>El virus covid ya estaba en Barcelona en marzo....perooo...de2019</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="2">El</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="4" end_char="8">virus</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="10" end_char="14">covid</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="16" end_char="17">ya</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="19" end_char="24">estaba</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="26" end_char="27">en</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="29" end_char="37">Barcelona</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="39" end_char="40">en</TOKEN>
<TOKEN id="token-0-8" pos="unknown" morph="none" start_char="42" end_char="65">marzo....perooo...de2019</TOKEN>
</SEG>
<SEG id="segment-1" start_char="69" end_char="127">
<ORIGINAL_TEXT>Detectan coronavirus en aguas de Barcelona en marzo de 2019</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="69" end_char="76">Detectan</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="78" end_char="88">coronavirus</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="90" end_char="91">en</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="93" end_char="97">aguas</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="99" end_char="100">de</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="102" end_char="110">Barcelona</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="112" end_char="113">en</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="115" end_char="119">marzo</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="121" end_char="122">de</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="124" end_char="127">2019</TOKEN>
</SEG>
<SEG id="segment-2" start_char="131" end_char="172">
<ORIGINAL_TEXT>El virus es suyo y aparece cuando quieren.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="131" end_char="132">El</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="134" end_char="138">virus</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="140" end_char="141">es</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="143" end_char="146">suyo</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="148" end_char="148">y</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="150" end_char="156">aparece</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="158" end_char="163">cuando</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="165" end_char="171">quieren</TOKEN>
<TOKEN id="token-2-8" pos="punct" morph="none" start_char="172" end_char="172">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="175" end_char="248">
<ORIGINAL_TEXT>Y se producen los rebrotes que quieran, donde quieran y por alguna fiesta.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="175" end_char="175">Y</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="177" end_char="178">se</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="180" end_char="187">producen</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="189" end_char="191">los</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="193" end_char="200">rebrotes</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="202" end_char="204">que</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="206" end_char="212">quieran</TOKEN>
<TOKEN id="token-3-7" pos="punct" morph="none" start_char="213" end_char="213">,</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="215" end_char="219">donde</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="221" end_char="227">quieran</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="229" end_char="229">y</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="231" end_char="233">por</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="235" end_char="240">alguna</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="242" end_char="247">fiesta</TOKEN>
<TOKEN id="token-3-14" pos="punct" morph="none" start_char="248" end_char="248">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="252" end_char="284">
<ORIGINAL_TEXT>Osea que mucho antes que en wuhan</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="252" end_char="255">Osea</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="257" end_char="259">que</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="261" end_char="265">mucho</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="267" end_char="271">antes</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="273" end_char="275">que</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="277" end_char="278">en</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="280" end_char="284">wuhan</TOKEN>
</SEG>
<SEG id="segment-5" start_char="288" end_char="410">
<ORIGINAL_TEXT>Huy, va a terminar siendo que el virus ha estado entre nosotros desde el comienzo de la historia, o que viaja en el tiempo.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="288" end_char="290">Huy</TOKEN>
<TOKEN id="token-5-1" pos="punct" morph="none" start_char="291" end_char="291">,</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="293" end_char="294">va</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="296" end_char="296">a</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="298" end_char="305">terminar</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="307" end_char="312">siendo</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="314" end_char="316">que</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="318" end_char="319">el</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="321" end_char="325">virus</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="327" end_char="328">ha</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="330" end_char="335">estado</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="337" end_char="341">entre</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="343" end_char="350">nosotros</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="352" end_char="356">desde</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="358" end_char="359">el</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="361" end_char="368">comienzo</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="370" end_char="371">de</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="373" end_char="374">la</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="376" end_char="383">historia</TOKEN>
<TOKEN id="token-5-19" pos="punct" morph="none" start_char="384" end_char="384">,</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="386" end_char="386">o</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="388" end_char="390">que</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="392" end_char="396">viaja</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="398" end_char="399">en</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="401" end_char="402">el</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="404" end_char="409">tiempo</TOKEN>
<TOKEN id="token-5-26" pos="punct" morph="none" start_char="410" end_char="410">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="415" end_char="485">
<ORIGINAL_TEXT>estiercol inmobiliario dijo: El virus es suyo y aparece cuando quieren.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="415" end_char="423">estiercol</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="425" end_char="436">inmobiliario</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="438" end_char="441">dijo</TOKEN>
<TOKEN id="token-6-3" pos="punct" morph="none" start_char="442" end_char="442">:</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="444" end_char="445">El</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="447" end_char="451">virus</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="453" end_char="454">es</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="456" end_char="459">suyo</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="461" end_char="461">y</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="463" end_char="469">aparece</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="471" end_char="476">cuando</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="478" end_char="484">quieren</TOKEN>
<TOKEN id="token-6-12" pos="punct" morph="none" start_char="485" end_char="485">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="487" end_char="560">
<ORIGINAL_TEXT>Y se producen los rebrotes que quieran, donde quieran y por alguna fiesta.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="487" end_char="487">Y</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="489" end_char="490">se</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="492" end_char="499">producen</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="501" end_char="503">los</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="505" end_char="512">rebrotes</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="514" end_char="516">que</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="518" end_char="524">quieran</TOKEN>
<TOKEN id="token-7-7" pos="punct" morph="none" start_char="525" end_char="525">,</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="527" end_char="531">donde</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="533" end_char="539">quieran</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="541" end_char="541">y</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="543" end_char="545">por</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="547" end_char="552">alguna</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="554" end_char="559">fiesta</TOKEN>
<TOKEN id="token-7-14" pos="punct" morph="none" start_char="560" end_char="560">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="563" end_char="618">
<ORIGINAL_TEXT>Detectado en agua congelada de residuos de Barcelona....</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="563" end_char="571">Detectado</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="573" end_char="574">en</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="576" end_char="579">agua</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="581" end_char="589">congelada</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="591" end_char="592">de</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="594" end_char="601">residuos</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="603" end_char="604">de</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="606" end_char="614">Barcelona</TOKEN>
<TOKEN id="token-8-8" pos="punct" morph="none" start_char="615" end_char="618">....</TOKEN>
</SEG>
<SEG id="segment-9" start_char="623" end_char="766">
<ORIGINAL_TEXT>Amancio Ortega dijo: Huy, va a terminar siendo que el virus ha estado entre nosotros desde el comienzo de la historia, o que viaja en el tiempo.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="623" end_char="629">Amancio</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="631" end_char="636">Ortega</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="638" end_char="641">dijo</TOKEN>
<TOKEN id="token-9-3" pos="punct" morph="none" start_char="642" end_char="642">:</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="644" end_char="646">Huy</TOKEN>
<TOKEN id="token-9-5" pos="punct" morph="none" start_char="647" end_char="647">,</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="649" end_char="650">va</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="652" end_char="652">a</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="654" end_char="661">terminar</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="663" end_char="668">siendo</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="670" end_char="672">que</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="674" end_char="675">el</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="677" end_char="681">virus</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="683" end_char="684">ha</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="686" end_char="691">estado</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="693" end_char="697">entre</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="699" end_char="706">nosotros</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="708" end_char="712">desde</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="714" end_char="715">el</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="717" end_char="724">comienzo</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="726" end_char="727">de</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="729" end_char="730">la</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="732" end_char="739">historia</TOKEN>
<TOKEN id="token-9-23" pos="punct" morph="none" start_char="740" end_char="740">,</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="742" end_char="742">o</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="744" end_char="746">que</TOKEN>
<TOKEN id="token-9-26" pos="word" morph="none" start_char="748" end_char="752">viaja</TOKEN>
<TOKEN id="token-9-27" pos="word" morph="none" start_char="754" end_char="755">en</TOKEN>
<TOKEN id="token-9-28" pos="word" morph="none" start_char="757" end_char="758">el</TOKEN>
<TOKEN id="token-9-29" pos="word" morph="none" start_char="760" end_char="765">tiempo</TOKEN>
<TOKEN id="token-9-30" pos="punct" morph="none" start_char="766" end_char="766">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="770" end_char="848">
<ORIGINAL_TEXT>Está demostrado que circuló en aguas residuales de Barcelona antes que en china</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="770" end_char="773">Está</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="775" end_char="784">demostrado</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="786" end_char="788">que</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="790" end_char="796">circuló</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="798" end_char="799">en</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="801" end_char="805">aguas</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="807" end_char="816">residuales</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="818" end_char="819">de</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="821" end_char="829">Barcelona</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="831" end_char="835">antes</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="837" end_char="839">que</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="841" end_char="842">en</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="844" end_char="848">china</TOKEN>
</SEG>
<SEG id="segment-11" start_char="852" end_char="912">
<ORIGINAL_TEXT>Tiene pinta de contaminación de la muestra en el laboratorio.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="852" end_char="856">Tiene</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="858" end_char="862">pinta</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="864" end_char="865">de</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="867" end_char="879">contaminación</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="881" end_char="882">de</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="884" end_char="885">la</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="887" end_char="893">muestra</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="895" end_char="896">en</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="898" end_char="899">el</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="901" end_char="911">laboratorio</TOKEN>
<TOKEN id="token-11-10" pos="punct" morph="none" start_char="912" end_char="912">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="916" end_char="1002">
<ORIGINAL_TEXT>Y mañana dirán que el virus ya circulaba en el Cenozoico y así se va haciendo que pase.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="916" end_char="916">Y</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="918" end_char="923">mañana</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="925" end_char="929">dirán</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="931" end_char="933">que</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="935" end_char="936">el</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="938" end_char="942">virus</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="944" end_char="945">ya</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="947" end_char="955">circulaba</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="957" end_char="958">en</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="960" end_char="961">el</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="963" end_char="971">Cenozoico</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="973" end_char="973">y</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="975" end_char="977">así</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="979" end_char="980">se</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="982" end_char="983">va</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="985" end_char="992">haciendo</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="994" end_char="996">que</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="998" end_char="1001">pase</TOKEN>
<TOKEN id="token-12-18" pos="punct" morph="none" start_char="1002" end_char="1002">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1004" end_char="1015">
<ORIGINAL_TEXT>Poco a poco.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1004" end_char="1007">Poco</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1009" end_char="1009">a</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1011" end_char="1014">poco</TOKEN>
<TOKEN id="token-13-3" pos="punct" morph="none" start_char="1015" end_char="1015">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
