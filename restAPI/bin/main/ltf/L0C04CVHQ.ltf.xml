<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CVHQ" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="1649" raw_text_md5="4dba1bfe3d5e94399e59038bfa6dcf27">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="72">
<ORIGINAL_TEXT>Why doesn’t Florida use contact tracing apps to help combat coronavirus?</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="3">Why</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="5" end_char="11">doesn’t</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="13" end_char="19">Florida</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="21" end_char="23">use</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="25" end_char="31">contact</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="33" end_char="39">tracing</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="41" end_char="44">apps</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="46" end_char="47">to</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="49" end_char="52">help</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="54" end_char="59">combat</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="61" end_char="71">coronavirus</TOKEN>
<TOKEN id="token-0-11" pos="punct" morph="none" start_char="72" end_char="72">?</TOKEN>
</SEG>
<SEG id="segment-1" start_char="76" end_char="86">
<ORIGINAL_TEXT>TAMPA, Fla.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="76" end_char="80">TAMPA</TOKEN>
<TOKEN id="token-1-1" pos="punct" morph="none" start_char="81" end_char="81">,</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="83" end_char="85">Fla</TOKEN>
<TOKEN id="token-1-3" pos="punct" morph="none" start_char="86" end_char="86">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="88" end_char="200">
<ORIGINAL_TEXT>(WFLA) — As COVID-19 cases surge across the country, states are looking for ways to slow the spread of the virus.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="punct" morph="none" start_char="88" end_char="88">(</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="89" end_char="92">WFLA</TOKEN>
<TOKEN id="token-2-2" pos="punct" morph="none" start_char="93" end_char="93">)</TOKEN>
<TOKEN id="token-2-3" pos="punct" morph="none" start_char="95" end_char="95">—</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="97" end_char="98">As</TOKEN>
<TOKEN id="token-2-5" pos="unknown" morph="none" start_char="100" end_char="107">COVID-19</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="109" end_char="113">cases</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="115" end_char="119">surge</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="121" end_char="126">across</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="128" end_char="130">the</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="132" end_char="138">country</TOKEN>
<TOKEN id="token-2-11" pos="punct" morph="none" start_char="139" end_char="139">,</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="141" end_char="146">states</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="148" end_char="150">are</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="152" end_char="158">looking</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="160" end_char="162">for</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="164" end_char="167">ways</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="169" end_char="170">to</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="172" end_char="175">slow</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="177" end_char="179">the</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="181" end_char="186">spread</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="188" end_char="189">of</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="191" end_char="193">the</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="195" end_char="199">virus</TOKEN>
<TOKEN id="token-2-24" pos="punct" morph="none" start_char="200" end_char="200">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="203" end_char="301">
<ORIGINAL_TEXT>There’s a tool health experts say could help, but has yet to really take off: Contact tracing apps.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="203" end_char="209">There’s</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="211" end_char="211">a</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="213" end_char="216">tool</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="218" end_char="223">health</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="225" end_char="231">experts</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="233" end_char="235">say</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="237" end_char="241">could</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="243" end_char="246">help</TOKEN>
<TOKEN id="token-3-8" pos="punct" morph="none" start_char="247" end_char="247">,</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="249" end_char="251">but</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="253" end_char="255">has</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="257" end_char="259">yet</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="261" end_char="262">to</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="264" end_char="269">really</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="271" end_char="274">take</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="276" end_char="278">off</TOKEN>
<TOKEN id="token-3-16" pos="punct" morph="none" start_char="279" end_char="279">:</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="281" end_char="287">Contact</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="289" end_char="295">tracing</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="297" end_char="300">apps</TOKEN>
<TOKEN id="token-3-20" pos="punct" morph="none" start_char="301" end_char="301">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="303" end_char="428">
<ORIGINAL_TEXT>States that have rolled out apps are seeing low enrollment numbers as residents are hesitant to sign up over privacy concerns.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="303" end_char="308">States</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="310" end_char="313">that</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="315" end_char="318">have</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="320" end_char="325">rolled</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="327" end_char="329">out</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="331" end_char="334">apps</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="336" end_char="338">are</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="340" end_char="345">seeing</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="347" end_char="349">low</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="351" end_char="360">enrollment</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="362" end_char="368">numbers</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="370" end_char="371">as</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="373" end_char="381">residents</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="383" end_char="385">are</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="387" end_char="394">hesitant</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="396" end_char="397">to</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="399" end_char="402">sign</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="404" end_char="405">up</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="407" end_char="410">over</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="412" end_char="418">privacy</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="420" end_char="427">concerns</TOKEN>
<TOKEN id="token-4-21" pos="punct" morph="none" start_char="428" end_char="428">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="431" end_char="497">
<ORIGINAL_TEXT>"People are very reluctant to share any information right now," Dr.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="punct" morph="none" start_char="431" end_char="431">"</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="432" end_char="437">People</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="439" end_char="441">are</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="443" end_char="446">very</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="448" end_char="456">reluctant</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="458" end_char="459">to</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="461" end_char="465">share</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="467" end_char="469">any</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="471" end_char="481">information</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="483" end_char="487">right</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="489" end_char="491">now</TOKEN>
<TOKEN id="token-5-11" pos="punct" morph="none" start_char="492" end_char="493">,"</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="495" end_char="496">Dr</TOKEN>
<TOKEN id="token-5-13" pos="punct" morph="none" start_char="497" end_char="497">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="499" end_char="568">
<ORIGINAL_TEXT>Jay Wolfson, the senior associate dean at Morsani College of Medicine.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="499" end_char="501">Jay</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="503" end_char="509">Wolfson</TOKEN>
<TOKEN id="token-6-2" pos="punct" morph="none" start_char="510" end_char="510">,</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="512" end_char="514">the</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="516" end_char="521">senior</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="523" end_char="531">associate</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="533" end_char="536">dean</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="538" end_char="539">at</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="541" end_char="547">Morsani</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="549" end_char="555">College</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="557" end_char="558">of</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="560" end_char="567">Medicine</TOKEN>
<TOKEN id="token-6-12" pos="punct" morph="none" start_char="568" end_char="568">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="571" end_char="686">
<ORIGINAL_TEXT>Unlike states like New York, New Jersey, Virginia and Nevada, Florida does not have an official contact tracing app.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="571" end_char="576">Unlike</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="578" end_char="583">states</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="585" end_char="588">like</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="590" end_char="592">New</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="594" end_char="597">York</TOKEN>
<TOKEN id="token-7-5" pos="punct" morph="none" start_char="598" end_char="598">,</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="600" end_char="602">New</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="604" end_char="609">Jersey</TOKEN>
<TOKEN id="token-7-8" pos="punct" morph="none" start_char="610" end_char="610">,</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="612" end_char="619">Virginia</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="621" end_char="623">and</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="625" end_char="630">Nevada</TOKEN>
<TOKEN id="token-7-12" pos="punct" morph="none" start_char="631" end_char="631">,</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="633" end_char="639">Florida</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="641" end_char="644">does</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="646" end_char="648">not</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="650" end_char="653">have</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="655" end_char="656">an</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="658" end_char="665">official</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="667" end_char="673">contact</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="675" end_char="681">tracing</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="683" end_char="685">app</TOKEN>
<TOKEN id="token-7-22" pos="punct" morph="none" start_char="686" end_char="686">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="689" end_char="853">
<ORIGINAL_TEXT>"The state’s resources are limited and the state is putting all the resources and the data management into vaccination preparation and [traditional] contact tracing.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="punct" morph="none" start_char="689" end_char="689">"</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="690" end_char="692">The</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="694" end_char="700">state’s</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="702" end_char="710">resources</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="712" end_char="714">are</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="716" end_char="722">limited</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="724" end_char="726">and</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="728" end_char="730">the</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="732" end_char="736">state</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="738" end_char="739">is</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="741" end_char="747">putting</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="749" end_char="751">all</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="753" end_char="755">the</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="757" end_char="765">resources</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="767" end_char="769">and</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="771" end_char="773">the</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="775" end_char="778">data</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="780" end_char="789">management</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="791" end_char="794">into</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="796" end_char="806">vaccination</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="808" end_char="818">preparation</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="820" end_char="822">and</TOKEN>
<TOKEN id="token-8-22" pos="punct" morph="none" start_char="824" end_char="824">[</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="825" end_char="835">traditional</TOKEN>
<TOKEN id="token-8-24" pos="punct" morph="none" start_char="836" end_char="836">]</TOKEN>
<TOKEN id="token-8-25" pos="word" morph="none" start_char="838" end_char="844">contact</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="846" end_char="852">tracing</TOKEN>
<TOKEN id="token-8-27" pos="punct" morph="none" start_char="853" end_char="853">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="855" end_char="984">
<ORIGINAL_TEXT>We are one of four states participating in a pilot study to figure out how to logistically distribute the stuff once it gets here.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="855" end_char="856">We</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="858" end_char="860">are</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="862" end_char="864">one</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="866" end_char="867">of</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="869" end_char="872">four</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="874" end_char="879">states</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="881" end_char="893">participating</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="895" end_char="896">in</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="898" end_char="898">a</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="900" end_char="904">pilot</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="906" end_char="910">study</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="912" end_char="913">to</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="915" end_char="920">figure</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="922" end_char="924">out</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="926" end_char="928">how</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="930" end_char="931">to</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="933" end_char="944">logistically</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="946" end_char="955">distribute</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="957" end_char="959">the</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="961" end_char="965">stuff</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="967" end_char="970">once</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="972" end_char="973">it</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="975" end_char="978">gets</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="980" end_char="983">here</TOKEN>
<TOKEN id="token-9-24" pos="punct" morph="none" start_char="984" end_char="984">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="986" end_char="1055">
<ORIGINAL_TEXT>Once the vaccine gets here, it is a huge endeavor," Wolfson explained.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="986" end_char="989">Once</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="991" end_char="993">the</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="995" end_char="1001">vaccine</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1003" end_char="1006">gets</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1008" end_char="1011">here</TOKEN>
<TOKEN id="token-10-5" pos="punct" morph="none" start_char="1012" end_char="1012">,</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1014" end_char="1015">it</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1017" end_char="1018">is</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1020" end_char="1020">a</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1022" end_char="1025">huge</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1027" end_char="1034">endeavor</TOKEN>
<TOKEN id="token-10-11" pos="punct" morph="none" start_char="1035" end_char="1036">,"</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1038" end_char="1044">Wolfson</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1046" end_char="1054">explained</TOKEN>
<TOKEN id="token-10-14" pos="punct" morph="none" start_char="1055" end_char="1055">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1057" end_char="1124">
<ORIGINAL_TEXT>"We don’t really have a health department that is that well-staffed.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="punct" morph="none" start_char="1057" end_char="1057">"</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1058" end_char="1059">We</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1061" end_char="1065">don’t</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1067" end_char="1072">really</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1074" end_char="1077">have</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1079" end_char="1079">a</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1081" end_char="1086">health</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1088" end_char="1097">department</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1099" end_char="1102">that</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1104" end_char="1105">is</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1107" end_char="1110">that</TOKEN>
<TOKEN id="token-11-11" pos="unknown" morph="none" start_char="1112" end_char="1123">well-staffed</TOKEN>
<TOKEN id="token-11-12" pos="punct" morph="none" start_char="1124" end_char="1124">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1126" end_char="1238">
<ORIGINAL_TEXT>For the last 20 years or so, the legislature underfunded – in some cases defunded – our state health department."</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1126" end_char="1128">For</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1130" end_char="1132">the</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1134" end_char="1137">last</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1139" end_char="1140">20</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1142" end_char="1146">years</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1148" end_char="1149">or</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1151" end_char="1152">so</TOKEN>
<TOKEN id="token-12-7" pos="punct" morph="none" start_char="1153" end_char="1153">,</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1155" end_char="1157">the</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1159" end_char="1169">legislature</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1171" end_char="1181">underfunded</TOKEN>
<TOKEN id="token-12-11" pos="punct" morph="none" start_char="1183" end_char="1183">–</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1185" end_char="1186">in</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1188" end_char="1191">some</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1193" end_char="1197">cases</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1199" end_char="1206">defunded</TOKEN>
<TOKEN id="token-12-16" pos="punct" morph="none" start_char="1208" end_char="1208">–</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1210" end_char="1212">our</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1214" end_char="1218">state</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1220" end_char="1225">health</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1227" end_char="1236">department</TOKEN>
<TOKEN id="token-12-21" pos="punct" morph="none" start_char="1237" end_char="1238">."</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1241" end_char="1374">
<ORIGINAL_TEXT>Wolfson believes contact tracing apps could help but they are not being marketed enough by states and people are reluctant to sign up.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1241" end_char="1247">Wolfson</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1249" end_char="1256">believes</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1258" end_char="1264">contact</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1266" end_char="1272">tracing</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1274" end_char="1277">apps</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1279" end_char="1283">could</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1285" end_char="1288">help</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1290" end_char="1292">but</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1294" end_char="1297">they</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1299" end_char="1301">are</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1303" end_char="1305">not</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1307" end_char="1311">being</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1313" end_char="1320">marketed</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1322" end_char="1327">enough</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1329" end_char="1330">by</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1332" end_char="1337">states</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1339" end_char="1341">and</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1343" end_char="1348">people</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1350" end_char="1352">are</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1354" end_char="1362">reluctant</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1364" end_char="1365">to</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="1367" end_char="1370">sign</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="1372" end_char="1373">up</TOKEN>
<TOKEN id="token-13-23" pos="punct" morph="none" start_char="1374" end_char="1374">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1377" end_char="1428">
<ORIGINAL_TEXT>"Even 10-15% [people signing up] makes a difference.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="punct" morph="none" start_char="1377" end_char="1377">"</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1378" end_char="1381">Even</TOKEN>
<TOKEN id="token-14-2" pos="unknown" morph="none" start_char="1383" end_char="1387">10-15</TOKEN>
<TOKEN id="token-14-3" pos="punct" morph="none" start_char="1388" end_char="1388">%</TOKEN>
<TOKEN id="token-14-4" pos="punct" morph="none" start_char="1390" end_char="1390">[</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1391" end_char="1396">people</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1398" end_char="1404">signing</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1406" end_char="1407">up</TOKEN>
<TOKEN id="token-14-8" pos="punct" morph="none" start_char="1408" end_char="1408">]</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1410" end_char="1414">makes</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1416" end_char="1416">a</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1418" end_char="1427">difference</TOKEN>
<TOKEN id="token-14-12" pos="punct" morph="none" start_char="1428" end_char="1428">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1430" end_char="1636">
<ORIGINAL_TEXT>I mean you may not find everybody but anything you can do to push that curve down, to early identify people who have been exposed or potentially exposed, that can make a tremendous difference," said Wolfson.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1430" end_char="1430">I</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1432" end_char="1435">mean</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1437" end_char="1439">you</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1441" end_char="1443">may</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1445" end_char="1447">not</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1449" end_char="1452">find</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1454" end_char="1462">everybody</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1464" end_char="1466">but</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1468" end_char="1475">anything</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1477" end_char="1479">you</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1481" end_char="1483">can</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1485" end_char="1486">do</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1488" end_char="1489">to</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1491" end_char="1494">push</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1496" end_char="1499">that</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="1501" end_char="1505">curve</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="1507" end_char="1510">down</TOKEN>
<TOKEN id="token-15-17" pos="punct" morph="none" start_char="1511" end_char="1511">,</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="1513" end_char="1514">to</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="1516" end_char="1520">early</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="1522" end_char="1529">identify</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="1531" end_char="1536">people</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="1538" end_char="1540">who</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="1542" end_char="1545">have</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="1547" end_char="1550">been</TOKEN>
<TOKEN id="token-15-25" pos="word" morph="none" start_char="1552" end_char="1558">exposed</TOKEN>
<TOKEN id="token-15-26" pos="word" morph="none" start_char="1560" end_char="1561">or</TOKEN>
<TOKEN id="token-15-27" pos="word" morph="none" start_char="1563" end_char="1573">potentially</TOKEN>
<TOKEN id="token-15-28" pos="word" morph="none" start_char="1575" end_char="1581">exposed</TOKEN>
<TOKEN id="token-15-29" pos="punct" morph="none" start_char="1582" end_char="1582">,</TOKEN>
<TOKEN id="token-15-30" pos="word" morph="none" start_char="1584" end_char="1587">that</TOKEN>
<TOKEN id="token-15-31" pos="word" morph="none" start_char="1589" end_char="1591">can</TOKEN>
<TOKEN id="token-15-32" pos="word" morph="none" start_char="1593" end_char="1596">make</TOKEN>
<TOKEN id="token-15-33" pos="word" morph="none" start_char="1598" end_char="1598">a</TOKEN>
<TOKEN id="token-15-34" pos="word" morph="none" start_char="1600" end_char="1609">tremendous</TOKEN>
<TOKEN id="token-15-35" pos="word" morph="none" start_char="1611" end_char="1620">difference</TOKEN>
<TOKEN id="token-15-36" pos="punct" morph="none" start_char="1621" end_char="1622">,"</TOKEN>
<TOKEN id="token-15-37" pos="word" morph="none" start_char="1624" end_char="1627">said</TOKEN>
<TOKEN id="token-15-38" pos="word" morph="none" start_char="1629" end_char="1635">Wolfson</TOKEN>
<TOKEN id="token-15-39" pos="punct" morph="none" start_char="1636" end_char="1636">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1641" end_char="1645">
<ORIGINAL_TEXT>Video</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1641" end_char="1645">Video</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
