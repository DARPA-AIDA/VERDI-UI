<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATA7" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="3692" raw_text_md5="69fbf7ba908d64772018b09682921e7c">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="75">
<ORIGINAL_TEXT>Estas son las 5 razones por las que el coronavirus estaría perdiendo fuerza</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="5">Estas</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="7" end_char="9">son</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="11" end_char="13">las</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="15" end_char="15">5</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="17" end_char="23">razones</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="25" end_char="27">por</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="29" end_char="31">las</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="33" end_char="35">que</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="37" end_char="38">el</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="40" end_char="50">coronavirus</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="52" end_char="58">estaría</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="60" end_char="68">perdiendo</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="70" end_char="75">fuerza</TOKEN>
</SEG>
<SEG id="segment-1" start_char="79" end_char="208">
<ORIGINAL_TEXT>El coronavirus del tipo SARS-CoV-2 está perdiendo fuerza por diversas razones, es lo que se asegura desde un sector de la ciencia.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="79" end_char="80">El</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="82" end_char="92">coronavirus</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="94" end_char="96">del</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="98" end_char="101">tipo</TOKEN>
<TOKEN id="token-1-4" pos="unknown" morph="none" start_char="103" end_char="112">SARS-CoV-2</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="114" end_char="117">está</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="119" end_char="127">perdiendo</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="129" end_char="134">fuerza</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="136" end_char="138">por</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="140" end_char="147">diversas</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="149" end_char="155">razones</TOKEN>
<TOKEN id="token-1-11" pos="punct" morph="none" start_char="156" end_char="156">,</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="158" end_char="159">es</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="161" end_char="162">lo</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="164" end_char="166">que</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="168" end_char="169">se</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="171" end_char="177">asegura</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="179" end_char="183">desde</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="185" end_char="186">un</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="188" end_char="193">sector</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="195" end_char="196">de</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="198" end_char="199">la</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="201" end_char="207">ciencia</TOKEN>
<TOKEN id="token-1-23" pos="punct" morph="none" start_char="208" end_char="208">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="210" end_char="346">
<ORIGINAL_TEXT>Incluso se asegura que el fin de la crisis estaría más cerca de lo esperado, al menos en Europa, donde golpeó antes que en Latinoamérica.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="210" end_char="216">Incluso</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="218" end_char="219">se</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="221" end_char="227">asegura</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="229" end_char="231">que</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="233" end_char="234">el</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="236" end_char="238">fin</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="240" end_char="241">de</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="243" end_char="244">la</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="246" end_char="251">crisis</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="253" end_char="259">estaría</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="261" end_char="263">más</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="265" end_char="269">cerca</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="271" end_char="272">de</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="274" end_char="275">lo</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="277" end_char="284">esperado</TOKEN>
<TOKEN id="token-2-15" pos="punct" morph="none" start_char="285" end_char="285">,</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="287" end_char="288">al</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="290" end_char="294">menos</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="296" end_char="297">en</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="299" end_char="304">Europa</TOKEN>
<TOKEN id="token-2-20" pos="punct" morph="none" start_char="305" end_char="305">,</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="307" end_char="311">donde</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="313" end_char="318">golpeó</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="320" end_char="324">antes</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="326" end_char="328">que</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="330" end_char="331">en</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="333" end_char="345">Latinoamérica</TOKEN>
<TOKEN id="token-2-27" pos="punct" morph="none" start_char="346" end_char="346">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="349" end_char="703">
<ORIGINAL_TEXT>"Cuando los expertos aluden a que el coronavirus se puede estar debilitando no se agarran como argumento único a un descenso numérico de los contagios, sino al hecho de que los cuadros clínicos generados en los últimos brotes serían más leves que los registrados en los momentos más intensos de la pandemia", se menciona en una investigación publicada por</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="punct" morph="none" start_char="349" end_char="349">"</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="350" end_char="355">Cuando</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="357" end_char="359">los</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="361" end_char="368">expertos</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="370" end_char="375">aluden</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="377" end_char="377">a</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="379" end_char="381">que</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="383" end_char="384">el</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="386" end_char="396">coronavirus</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="398" end_char="399">se</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="401" end_char="405">puede</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="407" end_char="411">estar</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="413" end_char="423">debilitando</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="425" end_char="426">no</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="428" end_char="429">se</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="431" end_char="437">agarran</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="439" end_char="442">como</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="444" end_char="452">argumento</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="454" end_char="458">único</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="460" end_char="460">a</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="462" end_char="463">un</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="465" end_char="472">descenso</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="474" end_char="481">numérico</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="483" end_char="484">de</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="486" end_char="488">los</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="490" end_char="498">contagios</TOKEN>
<TOKEN id="token-3-26" pos="punct" morph="none" start_char="499" end_char="499">,</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="501" end_char="504">sino</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="506" end_char="507">al</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="509" end_char="513">hecho</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="515" end_char="516">de</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="518" end_char="520">que</TOKEN>
<TOKEN id="token-3-32" pos="word" morph="none" start_char="522" end_char="524">los</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="526" end_char="532">cuadros</TOKEN>
<TOKEN id="token-3-34" pos="word" morph="none" start_char="534" end_char="541">clínicos</TOKEN>
<TOKEN id="token-3-35" pos="word" morph="none" start_char="543" end_char="551">generados</TOKEN>
<TOKEN id="token-3-36" pos="word" morph="none" start_char="553" end_char="554">en</TOKEN>
<TOKEN id="token-3-37" pos="word" morph="none" start_char="556" end_char="558">los</TOKEN>
<TOKEN id="token-3-38" pos="word" morph="none" start_char="560" end_char="566">últimos</TOKEN>
<TOKEN id="token-3-39" pos="word" morph="none" start_char="568" end_char="573">brotes</TOKEN>
<TOKEN id="token-3-40" pos="word" morph="none" start_char="575" end_char="580">serían</TOKEN>
<TOKEN id="token-3-41" pos="word" morph="none" start_char="582" end_char="584">más</TOKEN>
<TOKEN id="token-3-42" pos="word" morph="none" start_char="586" end_char="590">leves</TOKEN>
<TOKEN id="token-3-43" pos="word" morph="none" start_char="592" end_char="594">que</TOKEN>
<TOKEN id="token-3-44" pos="word" morph="none" start_char="596" end_char="598">los</TOKEN>
<TOKEN id="token-3-45" pos="word" morph="none" start_char="600" end_char="610">registrados</TOKEN>
<TOKEN id="token-3-46" pos="word" morph="none" start_char="612" end_char="613">en</TOKEN>
<TOKEN id="token-3-47" pos="word" morph="none" start_char="615" end_char="617">los</TOKEN>
<TOKEN id="token-3-48" pos="word" morph="none" start_char="619" end_char="626">momentos</TOKEN>
<TOKEN id="token-3-49" pos="word" morph="none" start_char="628" end_char="630">más</TOKEN>
<TOKEN id="token-3-50" pos="word" morph="none" start_char="632" end_char="639">intensos</TOKEN>
<TOKEN id="token-3-51" pos="word" morph="none" start_char="641" end_char="642">de</TOKEN>
<TOKEN id="token-3-52" pos="word" morph="none" start_char="644" end_char="645">la</TOKEN>
<TOKEN id="token-3-53" pos="word" morph="none" start_char="647" end_char="654">pandemia</TOKEN>
<TOKEN id="token-3-54" pos="punct" morph="none" start_char="655" end_char="656">",</TOKEN>
<TOKEN id="token-3-55" pos="word" morph="none" start_char="658" end_char="659">se</TOKEN>
<TOKEN id="token-3-56" pos="word" morph="none" start_char="661" end_char="668">menciona</TOKEN>
<TOKEN id="token-3-57" pos="word" morph="none" start_char="670" end_char="671">en</TOKEN>
<TOKEN id="token-3-58" pos="word" morph="none" start_char="673" end_char="675">una</TOKEN>
<TOKEN id="token-3-59" pos="word" morph="none" start_char="677" end_char="689">investigación</TOKEN>
<TOKEN id="token-3-60" pos="word" morph="none" start_char="691" end_char="699">publicada</TOKEN>
<TOKEN id="token-3-61" pos="word" morph="none" start_char="701" end_char="703">por</TOKEN>
</SEG>
<SEG id="segment-4" start_char="706" end_char="708">
<ORIGINAL_TEXT>ABC</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="706" end_char="708">ABC</TOKEN>
</SEG>
<SEG id="segment-5" start_char="711" end_char="796">
<ORIGINAL_TEXT>y elaborada por Sara Lumbreras, Joaquín Fernández-Crehuet Navajas y Luis Oviedo Torró.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="711" end_char="711">y</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="713" end_char="721">elaborada</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="723" end_char="725">por</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="727" end_char="730">Sara</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="732" end_char="740">Lumbreras</TOKEN>
<TOKEN id="token-5-5" pos="punct" morph="none" start_char="741" end_char="741">,</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="743" end_char="749">Joaquín</TOKEN>
<TOKEN id="token-5-7" pos="unknown" morph="none" start_char="751" end_char="767">Fernández-Crehuet</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="769" end_char="775">Navajas</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="777" end_char="777">y</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="779" end_char="782">Luis</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="784" end_char="789">Oviedo</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="791" end_char="795">Torró</TOKEN>
<TOKEN id="token-5-13" pos="punct" morph="none" start_char="796" end_char="796">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="799" end_char="966">
<ORIGINAL_TEXT>Reconocen que no existen pruebas contundentes para afirmar que este coronavirus se esté debilitando pero mencionan cinco factores que podrían incidir en que eso suceda.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="799" end_char="807">Reconocen</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="809" end_char="811">que</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="813" end_char="814">no</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="816" end_char="822">existen</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="824" end_char="830">pruebas</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="832" end_char="843">contundentes</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="845" end_char="848">para</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="850" end_char="856">afirmar</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="858" end_char="860">que</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="862" end_char="865">este</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="867" end_char="877">coronavirus</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="879" end_char="880">se</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="882" end_char="885">esté</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="887" end_char="897">debilitando</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="899" end_char="902">pero</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="904" end_char="912">mencionan</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="914" end_char="918">cinco</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="920" end_char="927">factores</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="929" end_char="931">que</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="933" end_char="939">podrían</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="941" end_char="947">incidir</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="949" end_char="950">en</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="952" end_char="954">que</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="956" end_char="958">eso</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="960" end_char="965">suceda</TOKEN>
<TOKEN id="token-6-25" pos="punct" morph="none" start_char="966" end_char="966">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="968" end_char="1062">
<ORIGINAL_TEXT>El aparente debilitamiento podría deberse a uno de ellos o a la conjunción de todos, mencionan.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="968" end_char="969">El</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="971" end_char="978">aparente</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="980" end_char="993">debilitamiento</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="995" end_char="1000">podría</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="1002" end_char="1008">deberse</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="1010" end_char="1010">a</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="1012" end_char="1014">uno</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="1016" end_char="1017">de</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="1019" end_char="1023">ellos</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="1025" end_char="1025">o</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="1027" end_char="1027">a</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="1029" end_char="1030">la</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="1032" end_char="1041">conjunción</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="1043" end_char="1044">de</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="1046" end_char="1050">todos</TOKEN>
<TOKEN id="token-7-15" pos="punct" morph="none" start_char="1051" end_char="1051">,</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="1053" end_char="1061">mencionan</TOKEN>
<TOKEN id="token-7-17" pos="punct" morph="none" start_char="1062" end_char="1062">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1065" end_char="1103">
<ORIGINAL_TEXT>Estas son las cinco causas que señalan:</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1065" end_char="1069">Estas</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1071" end_char="1073">son</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1075" end_char="1077">las</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1079" end_char="1083">cinco</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1085" end_char="1090">causas</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1092" end_char="1094">que</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1096" end_char="1102">señalan</TOKEN>
<TOKEN id="token-8-7" pos="punct" morph="none" start_char="1103" end_char="1103">:</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1107" end_char="1125">
<ORIGINAL_TEXT>1.- Cepas más leves</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1107" end_char="1107">1</TOKEN>
<TOKEN id="token-9-1" pos="punct" morph="none" start_char="1108" end_char="1109">.-</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1111" end_char="1115">Cepas</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1117" end_char="1119">más</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1121" end_char="1125">leves</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1129" end_char="1263">
<ORIGINAL_TEXT>El SARS-CoV-2 es más fuerte que la gripe pero ha tenido mutaciones, unas que lo vuelven más contagioso, y otras que pueden debilitarlo.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1129" end_char="1130">El</TOKEN>
<TOKEN id="token-10-1" pos="unknown" morph="none" start_char="1132" end_char="1141">SARS-CoV-2</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1143" end_char="1144">es</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1146" end_char="1148">más</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1150" end_char="1155">fuerte</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1157" end_char="1159">que</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1161" end_char="1162">la</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1164" end_char="1168">gripe</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1170" end_char="1173">pero</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1175" end_char="1176">ha</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1178" end_char="1183">tenido</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1185" end_char="1194">mutaciones</TOKEN>
<TOKEN id="token-10-12" pos="punct" morph="none" start_char="1195" end_char="1195">,</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1197" end_char="1200">unas</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1202" end_char="1204">que</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1206" end_char="1207">lo</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1209" end_char="1215">vuelven</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1217" end_char="1219">más</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1221" end_char="1230">contagioso</TOKEN>
<TOKEN id="token-10-19" pos="punct" morph="none" start_char="1231" end_char="1231">,</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1233" end_char="1233">y</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1235" end_char="1239">otras</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1241" end_char="1243">que</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1245" end_char="1250">pueden</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1252" end_char="1262">debilitarlo</TOKEN>
<TOKEN id="token-10-25" pos="punct" morph="none" start_char="1263" end_char="1263">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1266" end_char="1369">
<ORIGINAL_TEXT>"Debemos recordar que tanto el SARS como el MERS sufrieron mutaciones que los volvieron menos agresivos.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="punct" morph="none" start_char="1266" end_char="1266">"</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1267" end_char="1273">Debemos</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1275" end_char="1282">recordar</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1284" end_char="1286">que</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1288" end_char="1292">tanto</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1294" end_char="1295">el</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1297" end_char="1300">SARS</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1302" end_char="1305">como</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1307" end_char="1308">el</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1310" end_char="1313">MERS</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1315" end_char="1323">sufrieron</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1325" end_char="1334">mutaciones</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1336" end_char="1338">que</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1340" end_char="1342">los</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1344" end_char="1352">volvieron</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1354" end_char="1358">menos</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1360" end_char="1368">agresivos</TOKEN>
<TOKEN id="token-11-17" pos="punct" morph="none" start_char="1369" end_char="1369">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1371" end_char="1526">
<ORIGINAL_TEXT>Es clave continuar haciendo estudios de secuenciación que puedan confirmar qué evolución está experimentando el virus", advierte el equipo de investigación.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1371" end_char="1372">Es</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1374" end_char="1378">clave</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1380" end_char="1388">continuar</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1390" end_char="1397">haciendo</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1399" end_char="1406">estudios</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1408" end_char="1409">de</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1411" end_char="1423">secuenciación</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1425" end_char="1427">que</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1429" end_char="1434">puedan</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1436" end_char="1444">confirmar</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1446" end_char="1448">qué</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1450" end_char="1458">evolución</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1460" end_char="1463">está</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1465" end_char="1478">experimentando</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1480" end_char="1481">el</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1483" end_char="1487">virus</TOKEN>
<TOKEN id="token-12-16" pos="punct" morph="none" start_char="1488" end_char="1489">",</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1491" end_char="1498">advierte</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1500" end_char="1501">el</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1503" end_char="1508">equipo</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1510" end_char="1511">de</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1513" end_char="1525">investigación</TOKEN>
<TOKEN id="token-12-22" pos="punct" morph="none" start_char="1526" end_char="1526">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1529" end_char="1554">
<ORIGINAL_TEXT>2.- Cambios en el ambiente</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1529" end_char="1529">2</TOKEN>
<TOKEN id="token-13-1" pos="punct" morph="none" start_char="1530" end_char="1531">.-</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1533" end_char="1539">Cambios</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1541" end_char="1542">en</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1544" end_char="1545">el</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1547" end_char="1554">ambiente</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1558" end_char="1673">
<ORIGINAL_TEXT>La temperatura impactaría en la fuerza del virus e incluso la radiación ultravioleta (una de las fuentes es el Sol).</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1558" end_char="1559">La</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1561" end_char="1571">temperatura</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1573" end_char="1582">impactaría</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1584" end_char="1585">en</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1587" end_char="1588">la</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1590" end_char="1595">fuerza</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1597" end_char="1599">del</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1601" end_char="1605">virus</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1607" end_char="1607">e</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1609" end_char="1615">incluso</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1617" end_char="1618">la</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1620" end_char="1628">radiación</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1630" end_char="1641">ultravioleta</TOKEN>
<TOKEN id="token-14-13" pos="punct" morph="none" start_char="1643" end_char="1643">(</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="1644" end_char="1646">una</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1648" end_char="1649">de</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1651" end_char="1653">las</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="1655" end_char="1661">fuentes</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="1663" end_char="1664">es</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="1666" end_char="1667">el</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="1669" end_char="1671">Sol</TOKEN>
<TOKEN id="token-14-21" pos="punct" morph="none" start_char="1672" end_char="1673">).</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1675" end_char="1850">
<ORIGINAL_TEXT>"Pero estas afirmaciones no están respaldadas por la evidencia, sino más bien en comparaciones extraídas del comportamiento de otros coronavirus", se asegura en la publicación.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="punct" morph="none" start_char="1675" end_char="1675">"</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1676" end_char="1679">Pero</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1681" end_char="1685">estas</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1687" end_char="1698">afirmaciones</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1700" end_char="1701">no</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1703" end_char="1707">están</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1709" end_char="1719">respaldadas</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1721" end_char="1723">por</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1725" end_char="1726">la</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1728" end_char="1736">evidencia</TOKEN>
<TOKEN id="token-15-10" pos="punct" morph="none" start_char="1737" end_char="1737">,</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1739" end_char="1742">sino</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1744" end_char="1746">más</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1748" end_char="1751">bien</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1753" end_char="1754">en</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="1756" end_char="1768">comparaciones</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="1770" end_char="1778">extraídas</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="1780" end_char="1782">del</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="1784" end_char="1797">comportamiento</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="1799" end_char="1800">de</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="1802" end_char="1806">otros</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="1808" end_char="1818">coronavirus</TOKEN>
<TOKEN id="token-15-22" pos="punct" morph="none" start_char="1819" end_char="1820">",</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="1822" end_char="1823">se</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="1825" end_char="1831">asegura</TOKEN>
<TOKEN id="token-15-25" pos="word" morph="none" start_char="1833" end_char="1834">en</TOKEN>
<TOKEN id="token-15-26" pos="word" morph="none" start_char="1836" end_char="1837">la</TOKEN>
<TOKEN id="token-15-27" pos="word" morph="none" start_char="1839" end_char="1849">publicación</TOKEN>
<TOKEN id="token-15-28" pos="punct" morph="none" start_char="1850" end_char="1850">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1853" end_char="1888">
<ORIGINAL_TEXT>3.- Afectó primero a los más débiles</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1853" end_char="1853">3</TOKEN>
<TOKEN id="token-16-1" pos="punct" morph="none" start_char="1854" end_char="1855">.-</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1857" end_char="1862">Afectó</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1864" end_char="1870">primero</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1872" end_char="1872">a</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1874" end_char="1876">los</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1878" end_char="1880">más</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1882" end_char="1888">débiles</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1892" end_char="1962">
<ORIGINAL_TEXT>Se cree que las personas más vulnerables fueron las primeras afectadas.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1892" end_char="1893">Se</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1895" end_char="1898">cree</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="1900" end_char="1902">que</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="1904" end_char="1906">las</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="1908" end_char="1915">personas</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="1917" end_char="1919">más</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="1921" end_char="1931">vulnerables</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="1933" end_char="1938">fueron</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="1940" end_char="1942">las</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="1944" end_char="1951">primeras</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="1953" end_char="1961">afectadas</TOKEN>
<TOKEN id="token-17-11" pos="punct" morph="none" start_char="1962" end_char="1962">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1964" end_char="2094">
<ORIGINAL_TEXT>Al pasar los momentos más difíciles de la pandemia, con gran cantidad de casos, el virus encuentra a pacientes con más resistencia.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="1964" end_char="1965">Al</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="1967" end_char="1971">pasar</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="1973" end_char="1975">los</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="1977" end_char="1984">momentos</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="1986" end_char="1988">más</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="1990" end_char="1998">difíciles</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2000" end_char="2001">de</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2003" end_char="2004">la</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2006" end_char="2013">pandemia</TOKEN>
<TOKEN id="token-18-9" pos="punct" morph="none" start_char="2014" end_char="2014">,</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="2016" end_char="2018">con</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="2020" end_char="2023">gran</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2025" end_char="2032">cantidad</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="2034" end_char="2035">de</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="2037" end_char="2041">casos</TOKEN>
<TOKEN id="token-18-15" pos="punct" morph="none" start_char="2042" end_char="2042">,</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="2044" end_char="2045">el</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="2047" end_char="2051">virus</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="2053" end_char="2061">encuentra</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="2063" end_char="2063">a</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="2065" end_char="2073">pacientes</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="2075" end_char="2077">con</TOKEN>
<TOKEN id="token-18-22" pos="word" morph="none" start_char="2079" end_char="2081">más</TOKEN>
<TOKEN id="token-18-23" pos="word" morph="none" start_char="2083" end_char="2093">resistencia</TOKEN>
<TOKEN id="token-18-24" pos="punct" morph="none" start_char="2094" end_char="2094">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2096" end_char="2163">
<ORIGINAL_TEXT>Mientras, personas con enfermedades riesgosas, tienen mayor cuidado.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2096" end_char="2103">Mientras</TOKEN>
<TOKEN id="token-19-1" pos="punct" morph="none" start_char="2104" end_char="2104">,</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2106" end_char="2113">personas</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2115" end_char="2117">con</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2119" end_char="2130">enfermedades</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2132" end_char="2140">riesgosas</TOKEN>
<TOKEN id="token-19-6" pos="punct" morph="none" start_char="2141" end_char="2141">,</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2143" end_char="2148">tienen</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2150" end_char="2154">mayor</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="2156" end_char="2162">cuidado</TOKEN>
<TOKEN id="token-19-10" pos="punct" morph="none" start_char="2163" end_char="2163">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2166" end_char="2436">
<ORIGINAL_TEXT>En el caso de España, en la investigación se indica: "Si tuviésemos datos sobre la demografía de los últimos brotes, podríamos estudiar si estos están afectando desproporcionadamente a jóvenes o si siguen siendo importantes los brotes en residencias, hospitales o asilos.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2166" end_char="2167">En</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2169" end_char="2170">el</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2172" end_char="2175">caso</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2177" end_char="2178">de</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2180" end_char="2185">España</TOKEN>
<TOKEN id="token-20-5" pos="punct" morph="none" start_char="2186" end_char="2186">,</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2188" end_char="2189">en</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2191" end_char="2192">la</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="2194" end_char="2206">investigación</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2208" end_char="2209">se</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2211" end_char="2216">indica</TOKEN>
<TOKEN id="token-20-11" pos="punct" morph="none" start_char="2217" end_char="2217">:</TOKEN>
<TOKEN id="token-20-12" pos="punct" morph="none" start_char="2219" end_char="2219">"</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="2220" end_char="2221">Si</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="2223" end_char="2232">tuviésemos</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="2234" end_char="2238">datos</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="2240" end_char="2244">sobre</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="2246" end_char="2247">la</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="2249" end_char="2258">demografía</TOKEN>
<TOKEN id="token-20-19" pos="word" morph="none" start_char="2260" end_char="2261">de</TOKEN>
<TOKEN id="token-20-20" pos="word" morph="none" start_char="2263" end_char="2265">los</TOKEN>
<TOKEN id="token-20-21" pos="word" morph="none" start_char="2267" end_char="2273">últimos</TOKEN>
<TOKEN id="token-20-22" pos="word" morph="none" start_char="2275" end_char="2280">brotes</TOKEN>
<TOKEN id="token-20-23" pos="punct" morph="none" start_char="2281" end_char="2281">,</TOKEN>
<TOKEN id="token-20-24" pos="word" morph="none" start_char="2283" end_char="2291">podríamos</TOKEN>
<TOKEN id="token-20-25" pos="word" morph="none" start_char="2293" end_char="2300">estudiar</TOKEN>
<TOKEN id="token-20-26" pos="word" morph="none" start_char="2302" end_char="2303">si</TOKEN>
<TOKEN id="token-20-27" pos="word" morph="none" start_char="2305" end_char="2309">estos</TOKEN>
<TOKEN id="token-20-28" pos="word" morph="none" start_char="2311" end_char="2315">están</TOKEN>
<TOKEN id="token-20-29" pos="word" morph="none" start_char="2317" end_char="2325">afectando</TOKEN>
<TOKEN id="token-20-30" pos="word" morph="none" start_char="2327" end_char="2347">desproporcionadamente</TOKEN>
<TOKEN id="token-20-31" pos="word" morph="none" start_char="2349" end_char="2349">a</TOKEN>
<TOKEN id="token-20-32" pos="word" morph="none" start_char="2351" end_char="2357">jóvenes</TOKEN>
<TOKEN id="token-20-33" pos="word" morph="none" start_char="2359" end_char="2359">o</TOKEN>
<TOKEN id="token-20-34" pos="word" morph="none" start_char="2361" end_char="2362">si</TOKEN>
<TOKEN id="token-20-35" pos="word" morph="none" start_char="2364" end_char="2369">siguen</TOKEN>
<TOKEN id="token-20-36" pos="word" morph="none" start_char="2371" end_char="2376">siendo</TOKEN>
<TOKEN id="token-20-37" pos="word" morph="none" start_char="2378" end_char="2388">importantes</TOKEN>
<TOKEN id="token-20-38" pos="word" morph="none" start_char="2390" end_char="2392">los</TOKEN>
<TOKEN id="token-20-39" pos="word" morph="none" start_char="2394" end_char="2399">brotes</TOKEN>
<TOKEN id="token-20-40" pos="word" morph="none" start_char="2401" end_char="2402">en</TOKEN>
<TOKEN id="token-20-41" pos="word" morph="none" start_char="2404" end_char="2414">residencias</TOKEN>
<TOKEN id="token-20-42" pos="punct" morph="none" start_char="2415" end_char="2415">,</TOKEN>
<TOKEN id="token-20-43" pos="word" morph="none" start_char="2417" end_char="2426">hospitales</TOKEN>
<TOKEN id="token-20-44" pos="word" morph="none" start_char="2428" end_char="2428">o</TOKEN>
<TOKEN id="token-20-45" pos="word" morph="none" start_char="2430" end_char="2435">asilos</TOKEN>
<TOKEN id="token-20-46" pos="punct" morph="none" start_char="2436" end_char="2436">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2438" end_char="2545">
<ORIGINAL_TEXT>Es razonable pensar que este sea un factor clave en la gravedad de los rebrotes que estamos experimentando".</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2438" end_char="2439">Es</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2441" end_char="2449">razonable</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2451" end_char="2456">pensar</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2458" end_char="2460">que</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2462" end_char="2465">este</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="2467" end_char="2469">sea</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2471" end_char="2472">un</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="2474" end_char="2479">factor</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="2481" end_char="2485">clave</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="2487" end_char="2488">en</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="2490" end_char="2491">la</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="2493" end_char="2500">gravedad</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="2502" end_char="2503">de</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="2505" end_char="2507">los</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="2509" end_char="2516">rebrotes</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="2518" end_char="2520">que</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="2522" end_char="2528">estamos</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="2530" end_char="2543">experimentando</TOKEN>
<TOKEN id="token-21-18" pos="punct" morph="none" start_char="2544" end_char="2545">".</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2548" end_char="2577">
<ORIGINAL_TEXT>4.- Conocemos mejor a la covid</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2548" end_char="2548">4</TOKEN>
<TOKEN id="token-22-1" pos="punct" morph="none" start_char="2549" end_char="2550">.-</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2552" end_char="2560">Conocemos</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2562" end_char="2566">mejor</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2568" end_char="2568">a</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2570" end_char="2571">la</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2573" end_char="2577">covid</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2581" end_char="2689">
<ORIGINAL_TEXT>Una de las características de este coronavirus, que lo vuelven tan peligroso, es que era nuevo y desconocido.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2581" end_char="2583">Una</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2585" end_char="2586">de</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2588" end_char="2590">las</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2592" end_char="2606">características</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="2608" end_char="2609">de</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="2611" end_char="2614">este</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="2616" end_char="2626">coronavirus</TOKEN>
<TOKEN id="token-23-7" pos="punct" morph="none" start_char="2627" end_char="2627">,</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="2629" end_char="2631">que</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="2633" end_char="2634">lo</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="2636" end_char="2642">vuelven</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="2644" end_char="2646">tan</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="2648" end_char="2656">peligroso</TOKEN>
<TOKEN id="token-23-13" pos="punct" morph="none" start_char="2657" end_char="2657">,</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="2659" end_char="2660">es</TOKEN>
<TOKEN id="token-23-15" pos="word" morph="none" start_char="2662" end_char="2664">que</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="2666" end_char="2668">era</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="2670" end_char="2674">nuevo</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="2676" end_char="2676">y</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="2678" end_char="2688">desconocido</TOKEN>
<TOKEN id="token-23-20" pos="punct" morph="none" start_char="2689" end_char="2689">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2691" end_char="2806">
<ORIGINAL_TEXT>Meses después de su llegada, la comunidad científica ha identificado tratamientos efectivos para reducir su impacto.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="2691" end_char="2695">Meses</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="2697" end_char="2703">después</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="2705" end_char="2706">de</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="2708" end_char="2709">su</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="2711" end_char="2717">llegada</TOKEN>
<TOKEN id="token-24-5" pos="punct" morph="none" start_char="2718" end_char="2718">,</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="2720" end_char="2721">la</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="2723" end_char="2731">comunidad</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="2733" end_char="2742">científica</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="2744" end_char="2745">ha</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="2747" end_char="2758">identificado</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="2760" end_char="2771">tratamientos</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="2773" end_char="2781">efectivos</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="2783" end_char="2786">para</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="2788" end_char="2794">reducir</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="2796" end_char="2797">su</TOKEN>
<TOKEN id="token-24-16" pos="word" morph="none" start_char="2799" end_char="2805">impacto</TOKEN>
<TOKEN id="token-24-17" pos="punct" morph="none" start_char="2806" end_char="2806">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2809" end_char="3017">
<ORIGINAL_TEXT>"Por ejemplo, sabemos que en las primeras etapas de la epidemia muchos casos no recibieron atención hospitalaria hasta que la enfermedad ya había progresado a una etapa crítica", se menciona en la publicación.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="punct" morph="none" start_char="2809" end_char="2809">"</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="2810" end_char="2812">Por</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="2814" end_char="2820">ejemplo</TOKEN>
<TOKEN id="token-25-3" pos="punct" morph="none" start_char="2821" end_char="2821">,</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="2823" end_char="2829">sabemos</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="2831" end_char="2833">que</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="2835" end_char="2836">en</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="2838" end_char="2840">las</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="2842" end_char="2849">primeras</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="2851" end_char="2856">etapas</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="2858" end_char="2859">de</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="2861" end_char="2862">la</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="2864" end_char="2871">epidemia</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="2873" end_char="2878">muchos</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="2880" end_char="2884">casos</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="2886" end_char="2887">no</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="2889" end_char="2898">recibieron</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="2900" end_char="2907">atención</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="2909" end_char="2920">hospitalaria</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="2922" end_char="2926">hasta</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="2928" end_char="2930">que</TOKEN>
<TOKEN id="token-25-21" pos="word" morph="none" start_char="2932" end_char="2933">la</TOKEN>
<TOKEN id="token-25-22" pos="word" morph="none" start_char="2935" end_char="2944">enfermedad</TOKEN>
<TOKEN id="token-25-23" pos="word" morph="none" start_char="2946" end_char="2947">ya</TOKEN>
<TOKEN id="token-25-24" pos="word" morph="none" start_char="2949" end_char="2953">había</TOKEN>
<TOKEN id="token-25-25" pos="word" morph="none" start_char="2955" end_char="2964">progresado</TOKEN>
<TOKEN id="token-25-26" pos="word" morph="none" start_char="2966" end_char="2966">a</TOKEN>
<TOKEN id="token-25-27" pos="word" morph="none" start_char="2968" end_char="2970">una</TOKEN>
<TOKEN id="token-25-28" pos="word" morph="none" start_char="2972" end_char="2976">etapa</TOKEN>
<TOKEN id="token-25-29" pos="word" morph="none" start_char="2978" end_char="2984">crítica</TOKEN>
<TOKEN id="token-25-30" pos="punct" morph="none" start_char="2985" end_char="2986">",</TOKEN>
<TOKEN id="token-25-31" pos="word" morph="none" start_char="2988" end_char="2989">se</TOKEN>
<TOKEN id="token-25-32" pos="word" morph="none" start_char="2991" end_char="2998">menciona</TOKEN>
<TOKEN id="token-25-33" pos="word" morph="none" start_char="3000" end_char="3001">en</TOKEN>
<TOKEN id="token-25-34" pos="word" morph="none" start_char="3003" end_char="3004">la</TOKEN>
<TOKEN id="token-25-35" pos="word" morph="none" start_char="3006" end_char="3016">publicación</TOKEN>
<TOKEN id="token-25-36" pos="punct" morph="none" start_char="3017" end_char="3017">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="3020" end_char="3047">
<ORIGINAL_TEXT>5.- Distanciamiento es clave</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="3020" end_char="3020">5</TOKEN>
<TOKEN id="token-26-1" pos="punct" morph="none" start_char="3021" end_char="3022">.-</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="3024" end_char="3038">Distanciamiento</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="3040" end_char="3041">es</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="3043" end_char="3047">clave</TOKEN>
</SEG>
<SEG id="segment-27" start_char="3051" end_char="3199">
<ORIGINAL_TEXT>Hemos aprendido que el distanciamiento físico es clave para reducir el riesgo de contagio, sumado al lavado continuo de manos y el uso de mascarilla.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="3051" end_char="3055">Hemos</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="3057" end_char="3065">aprendido</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="3067" end_char="3069">que</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="3071" end_char="3072">el</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="3074" end_char="3088">distanciamiento</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="3090" end_char="3095">físico</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="3097" end_char="3098">es</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="3100" end_char="3104">clave</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="3106" end_char="3109">para</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="3111" end_char="3117">reducir</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="3119" end_char="3120">el</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="3122" end_char="3127">riesgo</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="3129" end_char="3130">de</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="3132" end_char="3139">contagio</TOKEN>
<TOKEN id="token-27-14" pos="punct" morph="none" start_char="3140" end_char="3140">,</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="3142" end_char="3147">sumado</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="3149" end_char="3150">al</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="3152" end_char="3157">lavado</TOKEN>
<TOKEN id="token-27-18" pos="word" morph="none" start_char="3159" end_char="3166">continuo</TOKEN>
<TOKEN id="token-27-19" pos="word" morph="none" start_char="3168" end_char="3169">de</TOKEN>
<TOKEN id="token-27-20" pos="word" morph="none" start_char="3171" end_char="3175">manos</TOKEN>
<TOKEN id="token-27-21" pos="word" morph="none" start_char="3177" end_char="3177">y</TOKEN>
<TOKEN id="token-27-22" pos="word" morph="none" start_char="3179" end_char="3180">el</TOKEN>
<TOKEN id="token-27-23" pos="word" morph="none" start_char="3182" end_char="3184">uso</TOKEN>
<TOKEN id="token-27-24" pos="word" morph="none" start_char="3186" end_char="3187">de</TOKEN>
<TOKEN id="token-27-25" pos="word" morph="none" start_char="3189" end_char="3198">mascarilla</TOKEN>
<TOKEN id="token-27-26" pos="punct" morph="none" start_char="3199" end_char="3199">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3202" end_char="3558">
<ORIGINAL_TEXT>"Es necesaria la investigación para clarificar el posible debilitamiento, pero es aún más urgente la publicación de los datos relacionados con la gravedad de los casos que van emergiendo en la epidemia: no solo necesitamos datos actualizados y localizados de casos y muertes, sino también de hospitalizaciones o ingresos en las áreas de cuidados intensivos.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="punct" morph="none" start_char="3202" end_char="3202">"</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="3203" end_char="3204">Es</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="3206" end_char="3214">necesaria</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="3216" end_char="3217">la</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="3219" end_char="3231">investigación</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="3233" end_char="3236">para</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="3238" end_char="3247">clarificar</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="3249" end_char="3250">el</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="3252" end_char="3258">posible</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="3260" end_char="3273">debilitamiento</TOKEN>
<TOKEN id="token-28-10" pos="punct" morph="none" start_char="3274" end_char="3274">,</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="3276" end_char="3279">pero</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="3281" end_char="3282">es</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="3284" end_char="3286">aún</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="3288" end_char="3290">más</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="3292" end_char="3298">urgente</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="3300" end_char="3301">la</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="3303" end_char="3313">publicación</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="3315" end_char="3316">de</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="3318" end_char="3320">los</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="3322" end_char="3326">datos</TOKEN>
<TOKEN id="token-28-21" pos="word" morph="none" start_char="3328" end_char="3339">relacionados</TOKEN>
<TOKEN id="token-28-22" pos="word" morph="none" start_char="3341" end_char="3343">con</TOKEN>
<TOKEN id="token-28-23" pos="word" morph="none" start_char="3345" end_char="3346">la</TOKEN>
<TOKEN id="token-28-24" pos="word" morph="none" start_char="3348" end_char="3355">gravedad</TOKEN>
<TOKEN id="token-28-25" pos="word" morph="none" start_char="3357" end_char="3358">de</TOKEN>
<TOKEN id="token-28-26" pos="word" morph="none" start_char="3360" end_char="3362">los</TOKEN>
<TOKEN id="token-28-27" pos="word" morph="none" start_char="3364" end_char="3368">casos</TOKEN>
<TOKEN id="token-28-28" pos="word" morph="none" start_char="3370" end_char="3372">que</TOKEN>
<TOKEN id="token-28-29" pos="word" morph="none" start_char="3374" end_char="3376">van</TOKEN>
<TOKEN id="token-28-30" pos="word" morph="none" start_char="3378" end_char="3387">emergiendo</TOKEN>
<TOKEN id="token-28-31" pos="word" morph="none" start_char="3389" end_char="3390">en</TOKEN>
<TOKEN id="token-28-32" pos="word" morph="none" start_char="3392" end_char="3393">la</TOKEN>
<TOKEN id="token-28-33" pos="word" morph="none" start_char="3395" end_char="3402">epidemia</TOKEN>
<TOKEN id="token-28-34" pos="punct" morph="none" start_char="3403" end_char="3403">:</TOKEN>
<TOKEN id="token-28-35" pos="word" morph="none" start_char="3405" end_char="3406">no</TOKEN>
<TOKEN id="token-28-36" pos="word" morph="none" start_char="3408" end_char="3411">solo</TOKEN>
<TOKEN id="token-28-37" pos="word" morph="none" start_char="3413" end_char="3423">necesitamos</TOKEN>
<TOKEN id="token-28-38" pos="word" morph="none" start_char="3425" end_char="3429">datos</TOKEN>
<TOKEN id="token-28-39" pos="word" morph="none" start_char="3431" end_char="3442">actualizados</TOKEN>
<TOKEN id="token-28-40" pos="word" morph="none" start_char="3444" end_char="3444">y</TOKEN>
<TOKEN id="token-28-41" pos="word" morph="none" start_char="3446" end_char="3456">localizados</TOKEN>
<TOKEN id="token-28-42" pos="word" morph="none" start_char="3458" end_char="3459">de</TOKEN>
<TOKEN id="token-28-43" pos="word" morph="none" start_char="3461" end_char="3465">casos</TOKEN>
<TOKEN id="token-28-44" pos="word" morph="none" start_char="3467" end_char="3467">y</TOKEN>
<TOKEN id="token-28-45" pos="word" morph="none" start_char="3469" end_char="3475">muertes</TOKEN>
<TOKEN id="token-28-46" pos="punct" morph="none" start_char="3476" end_char="3476">,</TOKEN>
<TOKEN id="token-28-47" pos="word" morph="none" start_char="3478" end_char="3481">sino</TOKEN>
<TOKEN id="token-28-48" pos="word" morph="none" start_char="3483" end_char="3489">también</TOKEN>
<TOKEN id="token-28-49" pos="word" morph="none" start_char="3491" end_char="3492">de</TOKEN>
<TOKEN id="token-28-50" pos="word" morph="none" start_char="3494" end_char="3510">hospitalizaciones</TOKEN>
<TOKEN id="token-28-51" pos="word" morph="none" start_char="3512" end_char="3512">o</TOKEN>
<TOKEN id="token-28-52" pos="word" morph="none" start_char="3514" end_char="3521">ingresos</TOKEN>
<TOKEN id="token-28-53" pos="word" morph="none" start_char="3523" end_char="3524">en</TOKEN>
<TOKEN id="token-28-54" pos="word" morph="none" start_char="3526" end_char="3528">las</TOKEN>
<TOKEN id="token-28-55" pos="word" morph="none" start_char="3530" end_char="3534">áreas</TOKEN>
<TOKEN id="token-28-56" pos="word" morph="none" start_char="3536" end_char="3537">de</TOKEN>
<TOKEN id="token-28-57" pos="word" morph="none" start_char="3539" end_char="3546">cuidados</TOKEN>
<TOKEN id="token-28-58" pos="word" morph="none" start_char="3548" end_char="3557">intensivos</TOKEN>
<TOKEN id="token-28-59" pos="punct" morph="none" start_char="3558" end_char="3558">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3560" end_char="3684">
<ORIGINAL_TEXT>Solo así podremos determinar con claridad nuestro próximo paso en la lucha contra la pandemia", se añade en la investigación.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="3560" end_char="3563">Solo</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="3565" end_char="3567">así</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="3569" end_char="3576">podremos</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="3578" end_char="3587">determinar</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="3589" end_char="3591">con</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="3593" end_char="3600">claridad</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="3602" end_char="3608">nuestro</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="3610" end_char="3616">próximo</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="3618" end_char="3621">paso</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="3623" end_char="3624">en</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="3626" end_char="3627">la</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="3629" end_char="3633">lucha</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="3635" end_char="3640">contra</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="3642" end_char="3643">la</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="3645" end_char="3652">pandemia</TOKEN>
<TOKEN id="token-29-15" pos="punct" morph="none" start_char="3653" end_char="3654">",</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="3656" end_char="3657">se</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="3659" end_char="3663">añade</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="3665" end_char="3666">en</TOKEN>
<TOKEN id="token-29-19" pos="word" morph="none" start_char="3668" end_char="3669">la</TOKEN>
<TOKEN id="token-29-20" pos="word" morph="none" start_char="3671" end_char="3683">investigación</TOKEN>
<TOKEN id="token-29-21" pos="punct" morph="none" start_char="3684" end_char="3684">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3686" end_char="3688">
<ORIGINAL_TEXT>(I)</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="punct" morph="none" start_char="3686" end_char="3686">(</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="3687" end_char="3687">I</TOKEN>
<TOKEN id="token-30-2" pos="punct" morph="none" start_char="3688" end_char="3688">)</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
