<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATS1" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="14783" raw_text_md5="ef43025f6b9b83d2cc0a49385821b207">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="74">
<ORIGINAL_TEXT>Coronavirus: ¿El origen del Covid-19 está en un laboratorio chino en 2015?</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="11">Coronavirus</TOKEN>
<TOKEN id="token-0-1" pos="punct" morph="none" start_char="12" end_char="12">:</TOKEN>
<TOKEN id="token-0-2" pos="punct" morph="none" start_char="14" end_char="14">¿</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="15" end_char="16">El</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="18" end_char="23">origen</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="25" end_char="27">del</TOKEN>
<TOKEN id="token-0-6" pos="unknown" morph="none" start_char="29" end_char="36">Covid-19</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="38" end_char="41">está</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="43" end_char="44">en</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="46" end_char="47">un</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="49" end_char="59">laboratorio</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="61" end_char="65">chino</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="67" end_char="68">en</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="70" end_char="73">2015</TOKEN>
<TOKEN id="token-0-14" pos="punct" morph="none" start_char="74" end_char="74">?</TOKEN>
</SEG>
<SEG id="segment-1" start_char="78" end_char="276">
<ORIGINAL_TEXT>Yo creo que sí ha sido creado en el laboratorio de Wuhan, entre otras cosas porque hoy sabemos, esta noche mismo han dado nombres y registros verosímiles de que se trata del SARS Covid 2, nada de 19.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="78" end_char="79">Yo</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="81" end_char="84">creo</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="86" end_char="88">que</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="90" end_char="91">sí</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="93" end_char="94">ha</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="96" end_char="99">sido</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="101" end_char="106">creado</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="108" end_char="109">en</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="111" end_char="112">el</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="114" end_char="124">laboratorio</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="126" end_char="127">de</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="129" end_char="133">Wuhan</TOKEN>
<TOKEN id="token-1-12" pos="punct" morph="none" start_char="134" end_char="134">,</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="136" end_char="140">entre</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="142" end_char="146">otras</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="148" end_char="152">cosas</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="154" end_char="159">porque</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="161" end_char="163">hoy</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="165" end_char="171">sabemos</TOKEN>
<TOKEN id="token-1-19" pos="punct" morph="none" start_char="172" end_char="172">,</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="174" end_char="177">esta</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="179" end_char="183">noche</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="185" end_char="189">mismo</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="191" end_char="193">han</TOKEN>
<TOKEN id="token-1-24" pos="word" morph="none" start_char="195" end_char="198">dado</TOKEN>
<TOKEN id="token-1-25" pos="word" morph="none" start_char="200" end_char="206">nombres</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="208" end_char="208">y</TOKEN>
<TOKEN id="token-1-27" pos="word" morph="none" start_char="210" end_char="218">registros</TOKEN>
<TOKEN id="token-1-28" pos="word" morph="none" start_char="220" end_char="230">verosímiles</TOKEN>
<TOKEN id="token-1-29" pos="word" morph="none" start_char="232" end_char="233">de</TOKEN>
<TOKEN id="token-1-30" pos="word" morph="none" start_char="235" end_char="237">que</TOKEN>
<TOKEN id="token-1-31" pos="word" morph="none" start_char="239" end_char="240">se</TOKEN>
<TOKEN id="token-1-32" pos="word" morph="none" start_char="242" end_char="246">trata</TOKEN>
<TOKEN id="token-1-33" pos="word" morph="none" start_char="248" end_char="250">del</TOKEN>
<TOKEN id="token-1-34" pos="word" morph="none" start_char="252" end_char="255">SARS</TOKEN>
<TOKEN id="token-1-35" pos="word" morph="none" start_char="257" end_char="261">Covid</TOKEN>
<TOKEN id="token-1-36" pos="word" morph="none" start_char="263" end_char="263">2</TOKEN>
<TOKEN id="token-1-37" pos="punct" morph="none" start_char="264" end_char="264">,</TOKEN>
<TOKEN id="token-1-38" pos="word" morph="none" start_char="266" end_char="269">nada</TOKEN>
<TOKEN id="token-1-39" pos="word" morph="none" start_char="271" end_char="272">de</TOKEN>
<TOKEN id="token-1-40" pos="word" morph="none" start_char="274" end_char="275">19</TOKEN>
<TOKEN id="token-1-41" pos="punct" morph="none" start_char="276" end_char="276">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="278" end_char="420">
<ORIGINAL_TEXT>Hay declaraciones de distintos países, han hecho seguimiento de científicos y sí, si que ha sido creado en laboratorio introduciendo proteínas.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="278" end_char="280">Hay</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="282" end_char="294">declaraciones</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="296" end_char="297">de</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="299" end_char="307">distintos</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="309" end_char="314">países</TOKEN>
<TOKEN id="token-2-5" pos="punct" morph="none" start_char="315" end_char="315">,</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="317" end_char="319">han</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="321" end_char="325">hecho</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="327" end_char="337">seguimiento</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="339" end_char="340">de</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="342" end_char="352">científicos</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="354" end_char="354">y</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="356" end_char="357">sí</TOKEN>
<TOKEN id="token-2-13" pos="punct" morph="none" start_char="358" end_char="358">,</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="360" end_char="361">si</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="363" end_char="365">que</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="367" end_char="368">ha</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="370" end_char="373">sido</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="375" end_char="380">creado</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="382" end_char="383">en</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="385" end_char="395">laboratorio</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="397" end_char="409">introduciendo</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="411" end_char="419">proteínas</TOKEN>
<TOKEN id="token-2-23" pos="punct" morph="none" start_char="420" end_char="420">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="422" end_char="547">
<ORIGINAL_TEXT>Lo que creen los que destaparon esto es que se les escapo de las manos, bien por inyectárselo a un animal de laboratorio, etc.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="422" end_char="423">Lo</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="425" end_char="427">que</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="429" end_char="433">creen</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="435" end_char="437">los</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="439" end_char="441">que</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="443" end_char="452">destaparon</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="454" end_char="457">esto</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="459" end_char="460">es</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="462" end_char="464">que</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="466" end_char="467">se</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="469" end_char="471">les</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="473" end_char="478">escapo</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="480" end_char="481">de</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="483" end_char="485">las</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="487" end_char="491">manos</TOKEN>
<TOKEN id="token-3-15" pos="punct" morph="none" start_char="492" end_char="492">,</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="494" end_char="497">bien</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="499" end_char="501">por</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="503" end_char="514">inyectárselo</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="516" end_char="516">a</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="518" end_char="519">un</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="521" end_char="526">animal</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="528" end_char="529">de</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="531" end_char="541">laboratorio</TOKEN>
<TOKEN id="token-3-24" pos="punct" morph="none" start_char="542" end_char="542">,</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="544" end_char="546">etc</TOKEN>
<TOKEN id="token-3-26" pos="punct" morph="none" start_char="547" end_char="547">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="549" end_char="626">
<ORIGINAL_TEXT>Son personas con documentos, certificaciones, declaraciones testificales y TV.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="549" end_char="551">Son</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="553" end_char="560">personas</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="562" end_char="564">con</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="566" end_char="575">documentos</TOKEN>
<TOKEN id="token-4-4" pos="punct" morph="none" start_char="576" end_char="576">,</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="578" end_char="592">certificaciones</TOKEN>
<TOKEN id="token-4-6" pos="punct" morph="none" start_char="593" end_char="593">,</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="595" end_char="607">declaraciones</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="609" end_char="620">testificales</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="622" end_char="622">y</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="624" end_char="625">TV</TOKEN>
<TOKEN id="token-4-11" pos="punct" morph="none" start_char="626" end_char="626">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="630" end_char="819">
<ORIGINAL_TEXT>Esta claro, que nadie discute que el origen es de Wuhan .La excusa perfecta el mercadillo de animales .El laboratorio WIV de Wuhan paso años probando coronavirus de murciélagos en animales .</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="630" end_char="633">Esta</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="635" end_char="639">claro</TOKEN>
<TOKEN id="token-5-2" pos="punct" morph="none" start_char="640" end_char="640">,</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="642" end_char="644">que</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="646" end_char="650">nadie</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="652" end_char="658">discute</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="660" end_char="662">que</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="664" end_char="665">el</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="667" end_char="672">origen</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="674" end_char="675">es</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="677" end_char="678">de</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="680" end_char="684">Wuhan</TOKEN>
<TOKEN id="token-5-12" pos="punct" morph="none" start_char="686" end_char="686">.</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="687" end_char="688">La</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="690" end_char="695">excusa</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="697" end_char="704">perfecta</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="706" end_char="707">el</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="709" end_char="718">mercadillo</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="720" end_char="721">de</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="723" end_char="730">animales</TOKEN>
<TOKEN id="token-5-20" pos="punct" morph="none" start_char="732" end_char="732">.</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="733" end_char="734">El</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="736" end_char="746">laboratorio</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="748" end_char="750">WIV</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="752" end_char="753">de</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="755" end_char="759">Wuhan</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="761" end_char="764">paso</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="766" end_char="769">años</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="771" end_char="778">probando</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="780" end_char="790">coronavirus</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="792" end_char="793">de</TOKEN>
<TOKEN id="token-5-31" pos="word" morph="none" start_char="795" end_char="805">murciélagos</TOKEN>
<TOKEN id="token-5-32" pos="word" morph="none" start_char="807" end_char="808">en</TOKEN>
<TOKEN id="token-5-33" pos="word" morph="none" start_char="810" end_char="817">animales</TOKEN>
<TOKEN id="token-5-34" pos="punct" morph="none" start_char="819" end_char="819">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="823" end_char="1036">
<ORIGINAL_TEXT>En mi opinión el virus no solo proviene del laboratorio Wuhan, sino que además es probable que sea un arma biológica para situarse con supremacía después de que superemos esta ya denominada "Tercera guerra mundial"</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="823" end_char="824">En</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="826" end_char="827">mi</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="829" end_char="835">opinión</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="837" end_char="838">el</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="840" end_char="844">virus</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="846" end_char="847">no</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="849" end_char="852">solo</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="854" end_char="861">proviene</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="863" end_char="865">del</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="867" end_char="877">laboratorio</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="879" end_char="883">Wuhan</TOKEN>
<TOKEN id="token-6-11" pos="punct" morph="none" start_char="884" end_char="884">,</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="886" end_char="889">sino</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="891" end_char="893">que</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="895" end_char="900">además</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="902" end_char="903">es</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="905" end_char="912">probable</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="914" end_char="916">que</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="918" end_char="920">sea</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="922" end_char="923">un</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="925" end_char="928">arma</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="930" end_char="938">biológica</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="940" end_char="943">para</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="945" end_char="952">situarse</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="954" end_char="956">con</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="958" end_char="967">supremacía</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="969" end_char="975">después</TOKEN>
<TOKEN id="token-6-27" pos="word" morph="none" start_char="977" end_char="978">de</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="980" end_char="982">que</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="984" end_char="992">superemos</TOKEN>
<TOKEN id="token-6-30" pos="word" morph="none" start_char="994" end_char="997">esta</TOKEN>
<TOKEN id="token-6-31" pos="word" morph="none" start_char="999" end_char="1000">ya</TOKEN>
<TOKEN id="token-6-32" pos="word" morph="none" start_char="1002" end_char="1011">denominada</TOKEN>
<TOKEN id="token-6-33" pos="punct" morph="none" start_char="1013" end_char="1013">"</TOKEN>
<TOKEN id="token-6-34" pos="word" morph="none" start_char="1014" end_char="1020">Tercera</TOKEN>
<TOKEN id="token-6-35" pos="word" morph="none" start_char="1022" end_char="1027">guerra</TOKEN>
<TOKEN id="token-6-36" pos="word" morph="none" start_char="1029" end_char="1035">mundial</TOKEN>
<TOKEN id="token-6-37" pos="punct" morph="none" start_char="1036" end_char="1036">"</TOKEN>
</SEG>
<SEG id="segment-7" start_char="1039" end_char="1187">
<ORIGINAL_TEXT>Lo que sí es una obviedad, y que por favor me expliquen por qué los chinos han ido un paso por delante con respecto al mundo al combatir la pandemia.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="1039" end_char="1040">Lo</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="1042" end_char="1044">que</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="1046" end_char="1047">sí</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="1049" end_char="1050">es</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="1052" end_char="1054">una</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="1056" end_char="1063">obviedad</TOKEN>
<TOKEN id="token-7-6" pos="punct" morph="none" start_char="1064" end_char="1064">,</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="1066" end_char="1066">y</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="1068" end_char="1070">que</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="1072" end_char="1074">por</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="1076" end_char="1080">favor</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="1082" end_char="1083">me</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="1085" end_char="1093">expliquen</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="1095" end_char="1097">por</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="1099" end_char="1101">qué</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="1103" end_char="1105">los</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="1107" end_char="1112">chinos</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="1114" end_char="1116">han</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="1118" end_char="1120">ido</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="1122" end_char="1123">un</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="1125" end_char="1128">paso</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="1130" end_char="1132">por</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="1134" end_char="1140">delante</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="1142" end_char="1144">con</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="1146" end_char="1153">respecto</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="1155" end_char="1156">al</TOKEN>
<TOKEN id="token-7-26" pos="word" morph="none" start_char="1158" end_char="1162">mundo</TOKEN>
<TOKEN id="token-7-27" pos="word" morph="none" start_char="1164" end_char="1165">al</TOKEN>
<TOKEN id="token-7-28" pos="word" morph="none" start_char="1167" end_char="1174">combatir</TOKEN>
<TOKEN id="token-7-29" pos="word" morph="none" start_char="1176" end_char="1177">la</TOKEN>
<TOKEN id="token-7-30" pos="word" morph="none" start_char="1179" end_char="1186">pandemia</TOKEN>
<TOKEN id="token-7-31" pos="punct" morph="none" start_char="1187" end_char="1187">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1189" end_char="1321">
<ORIGINAL_TEXT>Su bajo número de fallecidos y la eficacia en la contención del virus con respecto al resto de países es fundamento de toda sospecha.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1189" end_char="1190">Su</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1192" end_char="1195">bajo</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1197" end_char="1202">número</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1204" end_char="1205">de</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1207" end_char="1216">fallecidos</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1218" end_char="1218">y</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1220" end_char="1221">la</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1223" end_char="1230">eficacia</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1232" end_char="1233">en</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1235" end_char="1236">la</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1238" end_char="1247">contención</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1249" end_char="1251">del</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1253" end_char="1257">virus</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1259" end_char="1261">con</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1263" end_char="1270">respecto</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1272" end_char="1273">al</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1275" end_char="1279">resto</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1281" end_char="1282">de</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1284" end_char="1289">países</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1291" end_char="1292">es</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="1294" end_char="1303">fundamento</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="1305" end_char="1306">de</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="1308" end_char="1311">toda</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="1313" end_char="1320">sospecha</TOKEN>
<TOKEN id="token-8-24" pos="punct" morph="none" start_char="1321" end_char="1321">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1323" end_char="1456">
<ORIGINAL_TEXT>Sus menos de 5.000 muertos para una población de 1.400 millones es un indicativo de que eran conocedores del impacto y sus paliativos.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1323" end_char="1325">Sus</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1327" end_char="1331">menos</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1333" end_char="1334">de</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1336" end_char="1340">5.000</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1342" end_char="1348">muertos</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1350" end_char="1353">para</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1355" end_char="1357">una</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1359" end_char="1367">población</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1369" end_char="1370">de</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1372" end_char="1376">1.400</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1378" end_char="1385">millones</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1387" end_char="1388">es</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1390" end_char="1391">un</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1393" end_char="1402">indicativo</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1404" end_char="1405">de</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1407" end_char="1409">que</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1411" end_char="1414">eran</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1416" end_char="1426">conocedores</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1428" end_char="1430">del</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1432" end_char="1438">impacto</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1440" end_char="1440">y</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1442" end_char="1444">sus</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1446" end_char="1455">paliativos</TOKEN>
<TOKEN id="token-9-23" pos="punct" morph="none" start_char="1456" end_char="1456">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1459" end_char="1587">
<ORIGINAL_TEXT>Hagan comparaciones con respecto al número de habitantes y la incidencia de la pandemia en China, Europa y en los Estados Unidos.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1459" end_char="1463">Hagan</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1465" end_char="1477">comparaciones</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1479" end_char="1481">con</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1483" end_char="1490">respecto</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1492" end_char="1493">al</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1495" end_char="1500">número</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1502" end_char="1503">de</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1505" end_char="1514">habitantes</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1516" end_char="1516">y</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1518" end_char="1519">la</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1521" end_char="1530">incidencia</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1532" end_char="1533">de</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1535" end_char="1536">la</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1538" end_char="1545">pandemia</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1547" end_char="1548">en</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1550" end_char="1554">China</TOKEN>
<TOKEN id="token-10-16" pos="punct" morph="none" start_char="1555" end_char="1555">,</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1557" end_char="1562">Europa</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1564" end_char="1564">y</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1566" end_char="1567">en</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1569" end_char="1571">los</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1573" end_char="1579">Estados</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1581" end_char="1586">Unidos</TOKEN>
<TOKEN id="token-10-23" pos="punct" morph="none" start_char="1587" end_char="1587">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1589" end_char="1728">
<ORIGINAL_TEXT>Quién sabe que medicamento habrán utilizado los chinos para tener el virus ya a día de hoy prácticamente erradicado en un país superpoblado.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1589" end_char="1593">Quién</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1595" end_char="1598">sabe</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1600" end_char="1602">que</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1604" end_char="1614">medicamento</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1616" end_char="1621">habrán</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1623" end_char="1631">utilizado</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1633" end_char="1635">los</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1637" end_char="1642">chinos</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1644" end_char="1647">para</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1649" end_char="1653">tener</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1655" end_char="1656">el</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1658" end_char="1662">virus</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1664" end_char="1665">ya</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1667" end_char="1667">a</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1669" end_char="1671">día</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1673" end_char="1674">de</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1676" end_char="1678">hoy</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1680" end_char="1692">prácticamente</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1694" end_char="1703">erradicado</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="1705" end_char="1706">en</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1708" end_char="1709">un</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="1711" end_char="1714">país</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="1716" end_char="1727">superpoblado</TOKEN>
<TOKEN id="token-11-23" pos="punct" morph="none" start_char="1728" end_char="1728">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1731" end_char="1814">
<ORIGINAL_TEXT>Y la pregunta del millón es... ¿Cuál es el resultado de esta Tercera guerra mundial?</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1731" end_char="1731">Y</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1733" end_char="1734">la</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1736" end_char="1743">pregunta</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1745" end_char="1747">del</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1749" end_char="1754">millón</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1756" end_char="1757">es</TOKEN>
<TOKEN id="token-12-6" pos="punct" morph="none" start_char="1758" end_char="1760">...</TOKEN>
<TOKEN id="token-12-7" pos="punct" morph="none" start_char="1762" end_char="1762">¿</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1763" end_char="1766">Cuál</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1768" end_char="1769">es</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1771" end_char="1772">el</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1774" end_char="1782">resultado</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1784" end_char="1785">de</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1787" end_char="1790">esta</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1792" end_char="1798">Tercera</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1800" end_char="1805">guerra</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1807" end_char="1813">mundial</TOKEN>
<TOKEN id="token-12-17" pos="punct" morph="none" start_char="1814" end_char="1814">?</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1816" end_char="2121">
<ORIGINAL_TEXT>El resultado es una recesión en Europa y Estados unidos que según los expertos economistas es comparable a la de principios del siglo XX, y por otro lado con la producción al máximo rendimiento tenemos una gran potencia china, que con supremacía ha tomado el control de la batalla para salvarnos a todos...</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1816" end_char="1817">El</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1819" end_char="1827">resultado</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1829" end_char="1830">es</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1832" end_char="1834">una</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1836" end_char="1843">recesión</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1845" end_char="1846">en</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1848" end_char="1853">Europa</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1855" end_char="1855">y</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1857" end_char="1863">Estados</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1865" end_char="1870">unidos</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1872" end_char="1874">que</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1876" end_char="1880">según</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1882" end_char="1884">los</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1886" end_char="1893">expertos</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1895" end_char="1905">economistas</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1907" end_char="1908">es</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1910" end_char="1919">comparable</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1921" end_char="1921">a</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1923" end_char="1924">la</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1926" end_char="1927">de</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1929" end_char="1938">principios</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="1940" end_char="1942">del</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="1944" end_char="1948">siglo</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="1950" end_char="1951">XX</TOKEN>
<TOKEN id="token-13-24" pos="punct" morph="none" start_char="1952" end_char="1952">,</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="1954" end_char="1954">y</TOKEN>
<TOKEN id="token-13-26" pos="word" morph="none" start_char="1956" end_char="1958">por</TOKEN>
<TOKEN id="token-13-27" pos="word" morph="none" start_char="1960" end_char="1963">otro</TOKEN>
<TOKEN id="token-13-28" pos="word" morph="none" start_char="1965" end_char="1968">lado</TOKEN>
<TOKEN id="token-13-29" pos="word" morph="none" start_char="1970" end_char="1972">con</TOKEN>
<TOKEN id="token-13-30" pos="word" morph="none" start_char="1974" end_char="1975">la</TOKEN>
<TOKEN id="token-13-31" pos="word" morph="none" start_char="1977" end_char="1986">producción</TOKEN>
<TOKEN id="token-13-32" pos="word" morph="none" start_char="1988" end_char="1989">al</TOKEN>
<TOKEN id="token-13-33" pos="word" morph="none" start_char="1991" end_char="1996">máximo</TOKEN>
<TOKEN id="token-13-34" pos="word" morph="none" start_char="1998" end_char="2008">rendimiento</TOKEN>
<TOKEN id="token-13-35" pos="word" morph="none" start_char="2010" end_char="2016">tenemos</TOKEN>
<TOKEN id="token-13-36" pos="word" morph="none" start_char="2018" end_char="2020">una</TOKEN>
<TOKEN id="token-13-37" pos="word" morph="none" start_char="2022" end_char="2025">gran</TOKEN>
<TOKEN id="token-13-38" pos="word" morph="none" start_char="2027" end_char="2034">potencia</TOKEN>
<TOKEN id="token-13-39" pos="word" morph="none" start_char="2036" end_char="2040">china</TOKEN>
<TOKEN id="token-13-40" pos="punct" morph="none" start_char="2041" end_char="2041">,</TOKEN>
<TOKEN id="token-13-41" pos="word" morph="none" start_char="2043" end_char="2045">que</TOKEN>
<TOKEN id="token-13-42" pos="word" morph="none" start_char="2047" end_char="2049">con</TOKEN>
<TOKEN id="token-13-43" pos="word" morph="none" start_char="2051" end_char="2060">supremacía</TOKEN>
<TOKEN id="token-13-44" pos="word" morph="none" start_char="2062" end_char="2063">ha</TOKEN>
<TOKEN id="token-13-45" pos="word" morph="none" start_char="2065" end_char="2070">tomado</TOKEN>
<TOKEN id="token-13-46" pos="word" morph="none" start_char="2072" end_char="2073">el</TOKEN>
<TOKEN id="token-13-47" pos="word" morph="none" start_char="2075" end_char="2081">control</TOKEN>
<TOKEN id="token-13-48" pos="word" morph="none" start_char="2083" end_char="2084">de</TOKEN>
<TOKEN id="token-13-49" pos="word" morph="none" start_char="2086" end_char="2087">la</TOKEN>
<TOKEN id="token-13-50" pos="word" morph="none" start_char="2089" end_char="2095">batalla</TOKEN>
<TOKEN id="token-13-51" pos="word" morph="none" start_char="2097" end_char="2100">para</TOKEN>
<TOKEN id="token-13-52" pos="word" morph="none" start_char="2102" end_char="2110">salvarnos</TOKEN>
<TOKEN id="token-13-53" pos="word" morph="none" start_char="2112" end_char="2112">a</TOKEN>
<TOKEN id="token-13-54" pos="word" morph="none" start_char="2114" end_char="2118">todos</TOKEN>
<TOKEN id="token-13-55" pos="punct" morph="none" start_char="2119" end_char="2121">...</TOKEN>
</SEG>
<SEG id="segment-14" start_char="2124" end_char="2315">
<ORIGINAL_TEXT>Lo peor de todo es que ahora ningún gobierno puede apoyar esta teoría y cuestionar a China, porque son los chinos quienes nos están salvando y su exportación nos resulta vital desde hace años.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="2124" end_char="2125">Lo</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="2127" end_char="2130">peor</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="2132" end_char="2133">de</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="2135" end_char="2138">todo</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="2140" end_char="2141">es</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="2143" end_char="2145">que</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="2147" end_char="2151">ahora</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="2153" end_char="2158">ningún</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="2160" end_char="2167">gobierno</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="2169" end_char="2173">puede</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="2175" end_char="2180">apoyar</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="2182" end_char="2185">esta</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="2187" end_char="2192">teoría</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="2194" end_char="2194">y</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="2196" end_char="2205">cuestionar</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="2207" end_char="2207">a</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="2209" end_char="2213">China</TOKEN>
<TOKEN id="token-14-17" pos="punct" morph="none" start_char="2214" end_char="2214">,</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="2216" end_char="2221">porque</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="2223" end_char="2225">son</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="2227" end_char="2229">los</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="2231" end_char="2236">chinos</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="2238" end_char="2244">quienes</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="2246" end_char="2248">nos</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="2250" end_char="2254">están</TOKEN>
<TOKEN id="token-14-25" pos="word" morph="none" start_char="2256" end_char="2263">salvando</TOKEN>
<TOKEN id="token-14-26" pos="word" morph="none" start_char="2265" end_char="2265">y</TOKEN>
<TOKEN id="token-14-27" pos="word" morph="none" start_char="2267" end_char="2268">su</TOKEN>
<TOKEN id="token-14-28" pos="word" morph="none" start_char="2270" end_char="2280">exportación</TOKEN>
<TOKEN id="token-14-29" pos="word" morph="none" start_char="2282" end_char="2284">nos</TOKEN>
<TOKEN id="token-14-30" pos="word" morph="none" start_char="2286" end_char="2292">resulta</TOKEN>
<TOKEN id="token-14-31" pos="word" morph="none" start_char="2294" end_char="2298">vital</TOKEN>
<TOKEN id="token-14-32" pos="word" morph="none" start_char="2300" end_char="2304">desde</TOKEN>
<TOKEN id="token-14-33" pos="word" morph="none" start_char="2306" end_char="2309">hace</TOKEN>
<TOKEN id="token-14-34" pos="word" morph="none" start_char="2311" end_char="2314">años</TOKEN>
<TOKEN id="token-14-35" pos="punct" morph="none" start_char="2315" end_char="2315">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="2319" end_char="2528">
<ORIGINAL_TEXT>LOS MEDIOS NO ESTÁN DANDO LA TALLA Sinceramente no puedo entender porque los telediarios y la mayoría de la prensa en España omiten información importantísima sobre el origen y las intenciones de esta pandemia.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="2319" end_char="2321">LOS</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="2323" end_char="2328">MEDIOS</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="2330" end_char="2331">NO</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="2333" end_char="2337">ESTÁN</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="2339" end_char="2343">DANDO</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="2345" end_char="2346">LA</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="2348" end_char="2352">TALLA</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="2354" end_char="2365">Sinceramente</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="2367" end_char="2368">no</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="2370" end_char="2374">puedo</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="2376" end_char="2383">entender</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="2385" end_char="2390">porque</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="2392" end_char="2394">los</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="2396" end_char="2406">telediarios</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="2408" end_char="2408">y</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="2410" end_char="2411">la</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="2413" end_char="2419">mayoría</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="2421" end_char="2422">de</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="2424" end_char="2425">la</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="2427" end_char="2432">prensa</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="2434" end_char="2435">en</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="2437" end_char="2442">España</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="2444" end_char="2449">omiten</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="2451" end_char="2461">información</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="2463" end_char="2476">importantísima</TOKEN>
<TOKEN id="token-15-25" pos="word" morph="none" start_char="2478" end_char="2482">sobre</TOKEN>
<TOKEN id="token-15-26" pos="word" morph="none" start_char="2484" end_char="2485">el</TOKEN>
<TOKEN id="token-15-27" pos="word" morph="none" start_char="2487" end_char="2492">origen</TOKEN>
<TOKEN id="token-15-28" pos="word" morph="none" start_char="2494" end_char="2494">y</TOKEN>
<TOKEN id="token-15-29" pos="word" morph="none" start_char="2496" end_char="2498">las</TOKEN>
<TOKEN id="token-15-30" pos="word" morph="none" start_char="2500" end_char="2510">intenciones</TOKEN>
<TOKEN id="token-15-31" pos="word" morph="none" start_char="2512" end_char="2513">de</TOKEN>
<TOKEN id="token-15-32" pos="word" morph="none" start_char="2515" end_char="2518">esta</TOKEN>
<TOKEN id="token-15-33" pos="word" morph="none" start_char="2520" end_char="2527">pandemia</TOKEN>
<TOKEN id="token-15-34" pos="punct" morph="none" start_char="2528" end_char="2528">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="2530" end_char="2686">
<ORIGINAL_TEXT>Solo nos informan de los aplausos, violinistas en los balcones, niños en bicicletas, mascarillas sí o no, y de estadísticas que no hacen honor a la verdad...</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="2530" end_char="2533">Solo</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="2535" end_char="2537">nos</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="2539" end_char="2546">informan</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="2548" end_char="2549">de</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="2551" end_char="2553">los</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="2555" end_char="2562">aplausos</TOKEN>
<TOKEN id="token-16-6" pos="punct" morph="none" start_char="2563" end_char="2563">,</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="2565" end_char="2575">violinistas</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="2577" end_char="2578">en</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="2580" end_char="2582">los</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="2584" end_char="2591">balcones</TOKEN>
<TOKEN id="token-16-11" pos="punct" morph="none" start_char="2592" end_char="2592">,</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="2594" end_char="2598">niños</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="2600" end_char="2601">en</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="2603" end_char="2612">bicicletas</TOKEN>
<TOKEN id="token-16-15" pos="punct" morph="none" start_char="2613" end_char="2613">,</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="2615" end_char="2625">mascarillas</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="2627" end_char="2628">sí</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="2630" end_char="2630">o</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="2632" end_char="2633">no</TOKEN>
<TOKEN id="token-16-20" pos="punct" morph="none" start_char="2634" end_char="2634">,</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="2636" end_char="2636">y</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="2638" end_char="2639">de</TOKEN>
<TOKEN id="token-16-23" pos="word" morph="none" start_char="2641" end_char="2652">estadísticas</TOKEN>
<TOKEN id="token-16-24" pos="word" morph="none" start_char="2654" end_char="2656">que</TOKEN>
<TOKEN id="token-16-25" pos="word" morph="none" start_char="2658" end_char="2659">no</TOKEN>
<TOKEN id="token-16-26" pos="word" morph="none" start_char="2661" end_char="2665">hacen</TOKEN>
<TOKEN id="token-16-27" pos="word" morph="none" start_char="2667" end_char="2671">honor</TOKEN>
<TOKEN id="token-16-28" pos="word" morph="none" start_char="2673" end_char="2673">a</TOKEN>
<TOKEN id="token-16-29" pos="word" morph="none" start_char="2675" end_char="2676">la</TOKEN>
<TOKEN id="token-16-30" pos="word" morph="none" start_char="2678" end_char="2683">verdad</TOKEN>
<TOKEN id="token-16-31" pos="punct" morph="none" start_char="2684" end_char="2686">...</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2689" end_char="2881">
<ORIGINAL_TEXT>No se le está prestando atención a las sospechas de corrupción que se evidencian con las declaraciones de tantos países como Japón y Estados Unidos acusando a la OMS de estar vendida a China...</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2689" end_char="2690">No</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2692" end_char="2693">se</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2695" end_char="2696">le</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2698" end_char="2701">está</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2703" end_char="2711">prestando</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2713" end_char="2720">atención</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2722" end_char="2722">a</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2724" end_char="2726">las</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2728" end_char="2736">sospechas</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2738" end_char="2739">de</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2741" end_char="2750">corrupción</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2752" end_char="2754">que</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2756" end_char="2757">se</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2759" end_char="2768">evidencian</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2770" end_char="2772">con</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2774" end_char="2776">las</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="2778" end_char="2790">declaraciones</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="2792" end_char="2793">de</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="2795" end_char="2800">tantos</TOKEN>
<TOKEN id="token-17-19" pos="word" morph="none" start_char="2802" end_char="2807">países</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="2809" end_char="2812">como</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="2814" end_char="2818">Japón</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="2820" end_char="2820">y</TOKEN>
<TOKEN id="token-17-23" pos="word" morph="none" start_char="2822" end_char="2828">Estados</TOKEN>
<TOKEN id="token-17-24" pos="word" morph="none" start_char="2830" end_char="2835">Unidos</TOKEN>
<TOKEN id="token-17-25" pos="word" morph="none" start_char="2837" end_char="2844">acusando</TOKEN>
<TOKEN id="token-17-26" pos="word" morph="none" start_char="2846" end_char="2846">a</TOKEN>
<TOKEN id="token-17-27" pos="word" morph="none" start_char="2848" end_char="2849">la</TOKEN>
<TOKEN id="token-17-28" pos="word" morph="none" start_char="2851" end_char="2853">OMS</TOKEN>
<TOKEN id="token-17-29" pos="word" morph="none" start_char="2855" end_char="2856">de</TOKEN>
<TOKEN id="token-17-30" pos="word" morph="none" start_char="2858" end_char="2862">estar</TOKEN>
<TOKEN id="token-17-31" pos="word" morph="none" start_char="2864" end_char="2870">vendida</TOKEN>
<TOKEN id="token-17-32" pos="word" morph="none" start_char="2872" end_char="2872">a</TOKEN>
<TOKEN id="token-17-33" pos="word" morph="none" start_char="2874" end_char="2878">China</TOKEN>
<TOKEN id="token-17-34" pos="punct" morph="none" start_char="2879" end_char="2881">...</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2884" end_char="3189">
<ORIGINAL_TEXT>Por otra parte tenemos a un rebatido pero prestigioso virólogo que es Premio Novel, además de ser también Premio príncipe de Asturias y descubridor del VHI-1, que asegura que el COVID-19 está creado en el laboratorio de Wuhan y como evidencia aporta que a este virus se le ha añadido secuencia del VHI-1...</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2884" end_char="2886">Por</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2888" end_char="2891">otra</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2893" end_char="2897">parte</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2899" end_char="2905">tenemos</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2907" end_char="2907">a</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2909" end_char="2910">un</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2912" end_char="2919">rebatido</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2921" end_char="2924">pero</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2926" end_char="2936">prestigioso</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="2938" end_char="2945">virólogo</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="2947" end_char="2949">que</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="2951" end_char="2952">es</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2954" end_char="2959">Premio</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="2961" end_char="2965">Novel</TOKEN>
<TOKEN id="token-18-14" pos="punct" morph="none" start_char="2966" end_char="2966">,</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="2968" end_char="2973">además</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="2975" end_char="2976">de</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="2978" end_char="2980">ser</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="2982" end_char="2988">también</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="2990" end_char="2995">Premio</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="2997" end_char="3004">príncipe</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="3006" end_char="3007">de</TOKEN>
<TOKEN id="token-18-22" pos="word" morph="none" start_char="3009" end_char="3016">Asturias</TOKEN>
<TOKEN id="token-18-23" pos="word" morph="none" start_char="3018" end_char="3018">y</TOKEN>
<TOKEN id="token-18-24" pos="word" morph="none" start_char="3020" end_char="3030">descubridor</TOKEN>
<TOKEN id="token-18-25" pos="word" morph="none" start_char="3032" end_char="3034">del</TOKEN>
<TOKEN id="token-18-26" pos="unknown" morph="none" start_char="3036" end_char="3040">VHI-1</TOKEN>
<TOKEN id="token-18-27" pos="punct" morph="none" start_char="3041" end_char="3041">,</TOKEN>
<TOKEN id="token-18-28" pos="word" morph="none" start_char="3043" end_char="3045">que</TOKEN>
<TOKEN id="token-18-29" pos="word" morph="none" start_char="3047" end_char="3053">asegura</TOKEN>
<TOKEN id="token-18-30" pos="word" morph="none" start_char="3055" end_char="3057">que</TOKEN>
<TOKEN id="token-18-31" pos="word" morph="none" start_char="3059" end_char="3060">el</TOKEN>
<TOKEN id="token-18-32" pos="unknown" morph="none" start_char="3062" end_char="3069">COVID-19</TOKEN>
<TOKEN id="token-18-33" pos="word" morph="none" start_char="3071" end_char="3074">está</TOKEN>
<TOKEN id="token-18-34" pos="word" morph="none" start_char="3076" end_char="3081">creado</TOKEN>
<TOKEN id="token-18-35" pos="word" morph="none" start_char="3083" end_char="3084">en</TOKEN>
<TOKEN id="token-18-36" pos="word" morph="none" start_char="3086" end_char="3087">el</TOKEN>
<TOKEN id="token-18-37" pos="word" morph="none" start_char="3089" end_char="3099">laboratorio</TOKEN>
<TOKEN id="token-18-38" pos="word" morph="none" start_char="3101" end_char="3102">de</TOKEN>
<TOKEN id="token-18-39" pos="word" morph="none" start_char="3104" end_char="3108">Wuhan</TOKEN>
<TOKEN id="token-18-40" pos="word" morph="none" start_char="3110" end_char="3110">y</TOKEN>
<TOKEN id="token-18-41" pos="word" morph="none" start_char="3112" end_char="3115">como</TOKEN>
<TOKEN id="token-18-42" pos="word" morph="none" start_char="3117" end_char="3125">evidencia</TOKEN>
<TOKEN id="token-18-43" pos="word" morph="none" start_char="3127" end_char="3132">aporta</TOKEN>
<TOKEN id="token-18-44" pos="word" morph="none" start_char="3134" end_char="3136">que</TOKEN>
<TOKEN id="token-18-45" pos="word" morph="none" start_char="3138" end_char="3138">a</TOKEN>
<TOKEN id="token-18-46" pos="word" morph="none" start_char="3140" end_char="3143">este</TOKEN>
<TOKEN id="token-18-47" pos="word" morph="none" start_char="3145" end_char="3149">virus</TOKEN>
<TOKEN id="token-18-48" pos="word" morph="none" start_char="3151" end_char="3152">se</TOKEN>
<TOKEN id="token-18-49" pos="word" morph="none" start_char="3154" end_char="3155">le</TOKEN>
<TOKEN id="token-18-50" pos="word" morph="none" start_char="3157" end_char="3158">ha</TOKEN>
<TOKEN id="token-18-51" pos="word" morph="none" start_char="3160" end_char="3166">añadido</TOKEN>
<TOKEN id="token-18-52" pos="word" morph="none" start_char="3168" end_char="3176">secuencia</TOKEN>
<TOKEN id="token-18-53" pos="word" morph="none" start_char="3178" end_char="3180">del</TOKEN>
<TOKEN id="token-18-54" pos="unknown" morph="none" start_char="3182" end_char="3186">VHI-1</TOKEN>
<TOKEN id="token-18-55" pos="punct" morph="none" start_char="3187" end_char="3189">...</TOKEN>
</SEG>
<SEG id="segment-19" start_char="3192" end_char="3433">
<ORIGINAL_TEXT>Estamos ante un virus que muta en sus replicas y genera errores en su cadena ARN mostrando síntomas de autodestrucción, pero no sin antes habernos hecho estremecernos ante el terror para que veamos en la vacuna la salvación de la humanidad...</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="3192" end_char="3198">Estamos</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="3200" end_char="3203">ante</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="3205" end_char="3206">un</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="3208" end_char="3212">virus</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="3214" end_char="3216">que</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="3218" end_char="3221">muta</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="3223" end_char="3224">en</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="3226" end_char="3228">sus</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="3230" end_char="3237">replicas</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="3239" end_char="3239">y</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="3241" end_char="3246">genera</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="3248" end_char="3254">errores</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="3256" end_char="3257">en</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="3259" end_char="3260">su</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="3262" end_char="3267">cadena</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="3269" end_char="3271">ARN</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="3273" end_char="3281">mostrando</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="3283" end_char="3290">síntomas</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="3292" end_char="3293">de</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="3295" end_char="3309">autodestrucción</TOKEN>
<TOKEN id="token-19-20" pos="punct" morph="none" start_char="3310" end_char="3310">,</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="3312" end_char="3315">pero</TOKEN>
<TOKEN id="token-19-22" pos="word" morph="none" start_char="3317" end_char="3318">no</TOKEN>
<TOKEN id="token-19-23" pos="word" morph="none" start_char="3320" end_char="3322">sin</TOKEN>
<TOKEN id="token-19-24" pos="word" morph="none" start_char="3324" end_char="3328">antes</TOKEN>
<TOKEN id="token-19-25" pos="word" morph="none" start_char="3330" end_char="3337">habernos</TOKEN>
<TOKEN id="token-19-26" pos="word" morph="none" start_char="3339" end_char="3343">hecho</TOKEN>
<TOKEN id="token-19-27" pos="word" morph="none" start_char="3345" end_char="3357">estremecernos</TOKEN>
<TOKEN id="token-19-28" pos="word" morph="none" start_char="3359" end_char="3362">ante</TOKEN>
<TOKEN id="token-19-29" pos="word" morph="none" start_char="3364" end_char="3365">el</TOKEN>
<TOKEN id="token-19-30" pos="word" morph="none" start_char="3367" end_char="3372">terror</TOKEN>
<TOKEN id="token-19-31" pos="word" morph="none" start_char="3374" end_char="3377">para</TOKEN>
<TOKEN id="token-19-32" pos="word" morph="none" start_char="3379" end_char="3381">que</TOKEN>
<TOKEN id="token-19-33" pos="word" morph="none" start_char="3383" end_char="3388">veamos</TOKEN>
<TOKEN id="token-19-34" pos="word" morph="none" start_char="3390" end_char="3391">en</TOKEN>
<TOKEN id="token-19-35" pos="word" morph="none" start_char="3393" end_char="3394">la</TOKEN>
<TOKEN id="token-19-36" pos="word" morph="none" start_char="3396" end_char="3401">vacuna</TOKEN>
<TOKEN id="token-19-37" pos="word" morph="none" start_char="3403" end_char="3404">la</TOKEN>
<TOKEN id="token-19-38" pos="word" morph="none" start_char="3406" end_char="3414">salvación</TOKEN>
<TOKEN id="token-19-39" pos="word" morph="none" start_char="3416" end_char="3417">de</TOKEN>
<TOKEN id="token-19-40" pos="word" morph="none" start_char="3419" end_char="3420">la</TOKEN>
<TOKEN id="token-19-41" pos="word" morph="none" start_char="3422" end_char="3430">humanidad</TOKEN>
<TOKEN id="token-19-42" pos="punct" morph="none" start_char="3431" end_char="3433">...</TOKEN>
</SEG>
<SEG id="segment-20" start_char="3436" end_char="3543">
<ORIGINAL_TEXT>LA GRAN MENTIRA DE LAS ESTADÍSTICAS Nos hicieron estudiar durante años para ahora tratarnos como borregos...</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="3436" end_char="3437">LA</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="3439" end_char="3442">GRAN</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="3444" end_char="3450">MENTIRA</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="3452" end_char="3453">DE</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="3455" end_char="3457">LAS</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="3459" end_char="3470">ESTADÍSTICAS</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="3472" end_char="3474">Nos</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="3476" end_char="3483">hicieron</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="3485" end_char="3492">estudiar</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="3494" end_char="3500">durante</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="3502" end_char="3505">años</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="3507" end_char="3510">para</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="3512" end_char="3516">ahora</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="3518" end_char="3526">tratarnos</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="3528" end_char="3531">como</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="3533" end_char="3540">borregos</TOKEN>
<TOKEN id="token-20-16" pos="punct" morph="none" start_char="3541" end_char="3543">...</TOKEN>
</SEG>
<SEG id="segment-21" start_char="3546" end_char="3590">
<ORIGINAL_TEXT>Que me expliquen como se le puede denominar "</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="3546" end_char="3548">Que</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="3550" end_char="3551">me</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="3553" end_char="3561">expliquen</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="3563" end_char="3566">como</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="3568" end_char="3569">se</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="3571" end_char="3572">le</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="3574" end_char="3578">puede</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="3580" end_char="3588">denominar</TOKEN>
<TOKEN id="token-21-8" pos="punct" morph="none" start_char="3590" end_char="3590">"</TOKEN>
</SEG>
<SEG id="segment-22" start_char="3593" end_char="3603">
<ORIGINAL_TEXT>Contagiados</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="3593" end_char="3603">Contagiados</TOKEN>
</SEG>
<SEG id="segment-23" start_char="3606" end_char="3646">
<ORIGINAL_TEXT>" a una variable que realmente se llama "</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="punct" morph="none" start_char="3606" end_char="3606">"</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="3608" end_char="3608">a</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="3610" end_char="3612">una</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="3614" end_char="3621">variable</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="3623" end_char="3625">que</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="3627" end_char="3635">realmente</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="3637" end_char="3638">se</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="3640" end_char="3644">llama</TOKEN>
<TOKEN id="token-23-8" pos="punct" morph="none" start_char="3646" end_char="3646">"</TOKEN>
</SEG>
<SEG id="segment-24" start_char="3649" end_char="3665">
<ORIGINAL_TEXT>Casos registrados</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="3649" end_char="3653">Casos</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="3655" end_char="3665">registrados</TOKEN>
</SEG>
<SEG id="segment-25" start_char="3668" end_char="3721">
<ORIGINAL_TEXT>"... La diferencia entre ambos conceptos es abismal...</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="punct" morph="none" start_char="3668" end_char="3671">"...</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="3673" end_char="3674">La</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="3676" end_char="3685">diferencia</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="3687" end_char="3691">entre</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="3693" end_char="3697">ambos</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="3699" end_char="3707">conceptos</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="3709" end_char="3710">es</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="3712" end_char="3718">abismal</TOKEN>
<TOKEN id="token-25-8" pos="punct" morph="none" start_char="3719" end_char="3721">...</TOKEN>
</SEG>
<SEG id="segment-26" start_char="3724" end_char="3792">
<ORIGINAL_TEXT>Por otro lado vemos que se extraen conclusiones entre las variables "</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="3724" end_char="3726">Por</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="3728" end_char="3731">otro</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="3733" end_char="3736">lado</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="3738" end_char="3742">vemos</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="3744" end_char="3746">que</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="3748" end_char="3749">se</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="3751" end_char="3757">extraen</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="3759" end_char="3770">conclusiones</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="3772" end_char="3776">entre</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="3778" end_char="3780">las</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="3782" end_char="3790">variables</TOKEN>
<TOKEN id="token-26-11" pos="punct" morph="none" start_char="3792" end_char="3792">"</TOKEN>
</SEG>
<SEG id="segment-27" start_char="3795" end_char="3811">
<ORIGINAL_TEXT>Casos registrados</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="3795" end_char="3799">Casos</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="3801" end_char="3811">registrados</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3814" end_char="3821">
<ORIGINAL_TEXT>" y la "</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="punct" morph="none" start_char="3814" end_char="3814">"</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="3816" end_char="3816">y</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="3818" end_char="3819">la</TOKEN>
<TOKEN id="token-28-3" pos="punct" morph="none" start_char="3821" end_char="3821">"</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3824" end_char="3833">
<ORIGINAL_TEXT>mortalidad</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="3824" end_char="3833">mortalidad</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3836" end_char="3936">
<ORIGINAL_TEXT>" cuando el vinculo entre ambos es solo subjetivo al numero de casos que se hayan podido registrar...</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="punct" morph="none" start_char="3836" end_char="3836">"</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="3838" end_char="3843">cuando</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="3845" end_char="3846">el</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="3848" end_char="3854">vinculo</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="3856" end_char="3860">entre</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="3862" end_char="3866">ambos</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="3868" end_char="3869">es</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="3871" end_char="3874">solo</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="3876" end_char="3884">subjetivo</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="3886" end_char="3887">al</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="3889" end_char="3894">numero</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="3896" end_char="3897">de</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="3899" end_char="3903">casos</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="3905" end_char="3907">que</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="3909" end_char="3910">se</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="3912" end_char="3916">hayan</TOKEN>
<TOKEN id="token-30-16" pos="word" morph="none" start_char="3918" end_char="3923">podido</TOKEN>
<TOKEN id="token-30-17" pos="word" morph="none" start_char="3925" end_char="3933">registrar</TOKEN>
<TOKEN id="token-30-18" pos="punct" morph="none" start_char="3934" end_char="3936">...</TOKEN>
</SEG>
<SEG id="segment-31" start_char="3939" end_char="3971">
<ORIGINAL_TEXT>He leído barbaridades como esta "</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="3939" end_char="3940">He</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="3942" end_char="3946">leído</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="3948" end_char="3959">barbaridades</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="3961" end_char="3964">como</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="3966" end_char="3969">esta</TOKEN>
<TOKEN id="token-31-5" pos="punct" morph="none" start_char="3971" end_char="3971">"</TOKEN>
</SEG>
<SEG id="segment-32" start_char="3974" end_char="4039">
<ORIGINAL_TEXT>Dos de cada tres personas contagiadas por el virus sale a adelante</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="3974" end_char="3976">Dos</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="3978" end_char="3979">de</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="3981" end_char="3984">cada</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="3986" end_char="3989">tres</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="3991" end_char="3998">personas</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="4000" end_char="4010">contagiadas</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="4012" end_char="4014">por</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="4016" end_char="4017">el</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="4019" end_char="4023">virus</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="4025" end_char="4028">sale</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="4030" end_char="4030">a</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="4032" end_char="4039">adelante</TOKEN>
</SEG>
<SEG id="segment-33" start_char="4042" end_char="4045">
<ORIGINAL_TEXT>"...</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="punct" morph="none" start_char="4042" end_char="4045">"...</TOKEN>
</SEG>
<SEG id="segment-34" start_char="4047" end_char="4298">
<ORIGINAL_TEXT>Declaraciones que son vergonzosas porque no existe el dato que nos haga saber cuál es el numero de contagios reales, ya que muchos han sido asintomáticos o han superado la enfermedad en sus casas sin dejar constancia de ello ni registro en ningún lado.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="4047" end_char="4059">Declaraciones</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="4061" end_char="4063">que</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="4065" end_char="4067">son</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="4069" end_char="4079">vergonzosas</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="4081" end_char="4086">porque</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="4088" end_char="4089">no</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="4091" end_char="4096">existe</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="4098" end_char="4099">el</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="4101" end_char="4104">dato</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="4106" end_char="4108">que</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="4110" end_char="4112">nos</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="4114" end_char="4117">haga</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="4119" end_char="4123">saber</TOKEN>
<TOKEN id="token-34-13" pos="word" morph="none" start_char="4125" end_char="4128">cuál</TOKEN>
<TOKEN id="token-34-14" pos="word" morph="none" start_char="4130" end_char="4131">es</TOKEN>
<TOKEN id="token-34-15" pos="word" morph="none" start_char="4133" end_char="4134">el</TOKEN>
<TOKEN id="token-34-16" pos="word" morph="none" start_char="4136" end_char="4141">numero</TOKEN>
<TOKEN id="token-34-17" pos="word" morph="none" start_char="4143" end_char="4144">de</TOKEN>
<TOKEN id="token-34-18" pos="word" morph="none" start_char="4146" end_char="4154">contagios</TOKEN>
<TOKEN id="token-34-19" pos="word" morph="none" start_char="4156" end_char="4161">reales</TOKEN>
<TOKEN id="token-34-20" pos="punct" morph="none" start_char="4162" end_char="4162">,</TOKEN>
<TOKEN id="token-34-21" pos="word" morph="none" start_char="4164" end_char="4165">ya</TOKEN>
<TOKEN id="token-34-22" pos="word" morph="none" start_char="4167" end_char="4169">que</TOKEN>
<TOKEN id="token-34-23" pos="word" morph="none" start_char="4171" end_char="4176">muchos</TOKEN>
<TOKEN id="token-34-24" pos="word" morph="none" start_char="4178" end_char="4180">han</TOKEN>
<TOKEN id="token-34-25" pos="word" morph="none" start_char="4182" end_char="4185">sido</TOKEN>
<TOKEN id="token-34-26" pos="word" morph="none" start_char="4187" end_char="4199">asintomáticos</TOKEN>
<TOKEN id="token-34-27" pos="word" morph="none" start_char="4201" end_char="4201">o</TOKEN>
<TOKEN id="token-34-28" pos="word" morph="none" start_char="4203" end_char="4205">han</TOKEN>
<TOKEN id="token-34-29" pos="word" morph="none" start_char="4207" end_char="4214">superado</TOKEN>
<TOKEN id="token-34-30" pos="word" morph="none" start_char="4216" end_char="4217">la</TOKEN>
<TOKEN id="token-34-31" pos="word" morph="none" start_char="4219" end_char="4228">enfermedad</TOKEN>
<TOKEN id="token-34-32" pos="word" morph="none" start_char="4230" end_char="4231">en</TOKEN>
<TOKEN id="token-34-33" pos="word" morph="none" start_char="4233" end_char="4235">sus</TOKEN>
<TOKEN id="token-34-34" pos="word" morph="none" start_char="4237" end_char="4241">casas</TOKEN>
<TOKEN id="token-34-35" pos="word" morph="none" start_char="4243" end_char="4245">sin</TOKEN>
<TOKEN id="token-34-36" pos="word" morph="none" start_char="4247" end_char="4251">dejar</TOKEN>
<TOKEN id="token-34-37" pos="word" morph="none" start_char="4253" end_char="4262">constancia</TOKEN>
<TOKEN id="token-34-38" pos="word" morph="none" start_char="4264" end_char="4265">de</TOKEN>
<TOKEN id="token-34-39" pos="word" morph="none" start_char="4267" end_char="4270">ello</TOKEN>
<TOKEN id="token-34-40" pos="word" morph="none" start_char="4272" end_char="4273">ni</TOKEN>
<TOKEN id="token-34-41" pos="word" morph="none" start_char="4275" end_char="4282">registro</TOKEN>
<TOKEN id="token-34-42" pos="word" morph="none" start_char="4284" end_char="4285">en</TOKEN>
<TOKEN id="token-34-43" pos="word" morph="none" start_char="4287" end_char="4292">ningún</TOKEN>
<TOKEN id="token-34-44" pos="word" morph="none" start_char="4294" end_char="4297">lado</TOKEN>
<TOKEN id="token-34-45" pos="punct" morph="none" start_char="4298" end_char="4298">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="4301" end_char="4532">
<ORIGINAL_TEXT>Sin embargo nadie se molesta en mostrarnos una comparativa real de los indices de mortalidad del virus por países, algo que resulta tan sencillo como extraer el numero de muertos por cada 100.000 habitantes sobre su población total.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="4301" end_char="4303">Sin</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="4305" end_char="4311">embargo</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="4313" end_char="4317">nadie</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="4319" end_char="4320">se</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="4322" end_char="4328">molesta</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="4330" end_char="4331">en</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="4333" end_char="4342">mostrarnos</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="4344" end_char="4346">una</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="4348" end_char="4358">comparativa</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="4360" end_char="4363">real</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="4365" end_char="4366">de</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="4368" end_char="4370">los</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="4372" end_char="4378">indices</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="4380" end_char="4381">de</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="4383" end_char="4392">mortalidad</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="4394" end_char="4396">del</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="4398" end_char="4402">virus</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="4404" end_char="4406">por</TOKEN>
<TOKEN id="token-35-18" pos="word" morph="none" start_char="4408" end_char="4413">países</TOKEN>
<TOKEN id="token-35-19" pos="punct" morph="none" start_char="4414" end_char="4414">,</TOKEN>
<TOKEN id="token-35-20" pos="word" morph="none" start_char="4416" end_char="4419">algo</TOKEN>
<TOKEN id="token-35-21" pos="word" morph="none" start_char="4421" end_char="4423">que</TOKEN>
<TOKEN id="token-35-22" pos="word" morph="none" start_char="4425" end_char="4431">resulta</TOKEN>
<TOKEN id="token-35-23" pos="word" morph="none" start_char="4433" end_char="4435">tan</TOKEN>
<TOKEN id="token-35-24" pos="word" morph="none" start_char="4437" end_char="4444">sencillo</TOKEN>
<TOKEN id="token-35-25" pos="word" morph="none" start_char="4446" end_char="4449">como</TOKEN>
<TOKEN id="token-35-26" pos="word" morph="none" start_char="4451" end_char="4457">extraer</TOKEN>
<TOKEN id="token-35-27" pos="word" morph="none" start_char="4459" end_char="4460">el</TOKEN>
<TOKEN id="token-35-28" pos="word" morph="none" start_char="4462" end_char="4467">numero</TOKEN>
<TOKEN id="token-35-29" pos="word" morph="none" start_char="4469" end_char="4470">de</TOKEN>
<TOKEN id="token-35-30" pos="word" morph="none" start_char="4472" end_char="4478">muertos</TOKEN>
<TOKEN id="token-35-31" pos="word" morph="none" start_char="4480" end_char="4482">por</TOKEN>
<TOKEN id="token-35-32" pos="word" morph="none" start_char="4484" end_char="4487">cada</TOKEN>
<TOKEN id="token-35-33" pos="word" morph="none" start_char="4489" end_char="4495">100.000</TOKEN>
<TOKEN id="token-35-34" pos="word" morph="none" start_char="4497" end_char="4506">habitantes</TOKEN>
<TOKEN id="token-35-35" pos="word" morph="none" start_char="4508" end_char="4512">sobre</TOKEN>
<TOKEN id="token-35-36" pos="word" morph="none" start_char="4514" end_char="4515">su</TOKEN>
<TOKEN id="token-35-37" pos="word" morph="none" start_char="4517" end_char="4525">población</TOKEN>
<TOKEN id="token-35-38" pos="word" morph="none" start_char="4527" end_char="4531">total</TOKEN>
<TOKEN id="token-35-39" pos="punct" morph="none" start_char="4532" end_char="4532">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="4535" end_char="4624">
<ORIGINAL_TEXT>Y es que ni siquiera se nos informa de cuantos test se realizan para obtener la variable "</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="4535" end_char="4535">Y</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="4537" end_char="4538">es</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="4540" end_char="4542">que</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="4544" end_char="4545">ni</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="4547" end_char="4554">siquiera</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="4556" end_char="4557">se</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="4559" end_char="4561">nos</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="4563" end_char="4569">informa</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="4571" end_char="4572">de</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="4574" end_char="4580">cuantos</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="4582" end_char="4585">test</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="4587" end_char="4588">se</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="4590" end_char="4597">realizan</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="4599" end_char="4602">para</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="4604" end_char="4610">obtener</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="4612" end_char="4613">la</TOKEN>
<TOKEN id="token-36-16" pos="word" morph="none" start_char="4615" end_char="4622">variable</TOKEN>
<TOKEN id="token-36-17" pos="punct" morph="none" start_char="4624" end_char="4624">"</TOKEN>
</SEG>
<SEG id="segment-37" start_char="4627" end_char="4656">
<ORIGINAL_TEXT>Casos registrados o detectados</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="4627" end_char="4631">Casos</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="4633" end_char="4643">registrados</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="4645" end_char="4645">o</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="4647" end_char="4656">detectados</TOKEN>
</SEG>
<SEG id="segment-38" start_char="4659" end_char="4798">
<ORIGINAL_TEXT>" faltándose a la verdad cuando se nos ofrece el dato de repunte de positivos sin decirnos si esto se debe realmente a un repunte de test...</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="punct" morph="none" start_char="4659" end_char="4659">"</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="4661" end_char="4670">faltándose</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="4672" end_char="4672">a</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="4674" end_char="4675">la</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="4677" end_char="4682">verdad</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="4684" end_char="4689">cuando</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="4691" end_char="4692">se</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="4694" end_char="4696">nos</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="4698" end_char="4703">ofrece</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="4705" end_char="4706">el</TOKEN>
<TOKEN id="token-38-10" pos="word" morph="none" start_char="4708" end_char="4711">dato</TOKEN>
<TOKEN id="token-38-11" pos="word" morph="none" start_char="4713" end_char="4714">de</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="4716" end_char="4722">repunte</TOKEN>
<TOKEN id="token-38-13" pos="word" morph="none" start_char="4724" end_char="4725">de</TOKEN>
<TOKEN id="token-38-14" pos="word" morph="none" start_char="4727" end_char="4735">positivos</TOKEN>
<TOKEN id="token-38-15" pos="word" morph="none" start_char="4737" end_char="4739">sin</TOKEN>
<TOKEN id="token-38-16" pos="word" morph="none" start_char="4741" end_char="4748">decirnos</TOKEN>
<TOKEN id="token-38-17" pos="word" morph="none" start_char="4750" end_char="4751">si</TOKEN>
<TOKEN id="token-38-18" pos="word" morph="none" start_char="4753" end_char="4756">esto</TOKEN>
<TOKEN id="token-38-19" pos="word" morph="none" start_char="4758" end_char="4759">se</TOKEN>
<TOKEN id="token-38-20" pos="word" morph="none" start_char="4761" end_char="4764">debe</TOKEN>
<TOKEN id="token-38-21" pos="word" morph="none" start_char="4766" end_char="4774">realmente</TOKEN>
<TOKEN id="token-38-22" pos="word" morph="none" start_char="4776" end_char="4776">a</TOKEN>
<TOKEN id="token-38-23" pos="word" morph="none" start_char="4778" end_char="4779">un</TOKEN>
<TOKEN id="token-38-24" pos="word" morph="none" start_char="4781" end_char="4787">repunte</TOKEN>
<TOKEN id="token-38-25" pos="word" morph="none" start_char="4789" end_char="4790">de</TOKEN>
<TOKEN id="token-38-26" pos="word" morph="none" start_char="4792" end_char="4795">test</TOKEN>
<TOKEN id="token-38-27" pos="punct" morph="none" start_char="4796" end_char="4798">...</TOKEN>
</SEG>
<SEG id="segment-39" start_char="4801" end_char="4832">
<ORIGINAL_TEXT>Ejemplo de un titular de prensa:</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="4801" end_char="4807">Ejemplo</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="4809" end_char="4810">de</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="4812" end_char="4813">un</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="4815" end_char="4821">titular</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="4823" end_char="4824">de</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="4826" end_char="4831">prensa</TOKEN>
<TOKEN id="token-39-6" pos="punct" morph="none" start_char="4832" end_char="4832">:</TOKEN>
</SEG>
<SEG id="segment-40" start_char="4835" end_char="4925">
<ORIGINAL_TEXT>- "Hoy es el numero de positivos más alto desde el inicio de la pandemia con 838 contagios"</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="punct" morph="none" start_char="4835" end_char="4835">-</TOKEN>
<TOKEN id="token-40-1" pos="punct" morph="none" start_char="4837" end_char="4837">"</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="4838" end_char="4840">Hoy</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="4842" end_char="4843">es</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="4845" end_char="4846">el</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="4848" end_char="4853">numero</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="4855" end_char="4856">de</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="4858" end_char="4866">positivos</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="4868" end_char="4870">más</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="4872" end_char="4875">alto</TOKEN>
<TOKEN id="token-40-10" pos="word" morph="none" start_char="4877" end_char="4881">desde</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="4883" end_char="4884">el</TOKEN>
<TOKEN id="token-40-12" pos="word" morph="none" start_char="4886" end_char="4891">inicio</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="4893" end_char="4894">de</TOKEN>
<TOKEN id="token-40-14" pos="word" morph="none" start_char="4896" end_char="4897">la</TOKEN>
<TOKEN id="token-40-15" pos="word" morph="none" start_char="4899" end_char="4906">pandemia</TOKEN>
<TOKEN id="token-40-16" pos="word" morph="none" start_char="4908" end_char="4910">con</TOKEN>
<TOKEN id="token-40-17" pos="word" morph="none" start_char="4912" end_char="4914">838</TOKEN>
<TOKEN id="token-40-18" pos="word" morph="none" start_char="4916" end_char="4924">contagios</TOKEN>
<TOKEN id="token-40-19" pos="punct" morph="none" start_char="4925" end_char="4925">"</TOKEN>
</SEG>
<SEG id="segment-41" start_char="4928" end_char="5304">
<ORIGINAL_TEXT>Para darle valor a este titular de prensa tendríamos que saber cuantos test se han realizado en las distintas situaciones que se describen, porque obviamente si mañana realizamos 4 test obtendríamos la conclusión de que se ha erradicado totalmente la pandemia, pero si por el contrario realizamos 10 millones de test se dispararía el repunte de positivos a niveles de alarma...</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="4928" end_char="4931">Para</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="4933" end_char="4937">darle</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="4939" end_char="4943">valor</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="4945" end_char="4945">a</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="4947" end_char="4950">este</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="4952" end_char="4958">titular</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="4960" end_char="4961">de</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="4963" end_char="4968">prensa</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="4970" end_char="4979">tendríamos</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="4981" end_char="4983">que</TOKEN>
<TOKEN id="token-41-10" pos="word" morph="none" start_char="4985" end_char="4989">saber</TOKEN>
<TOKEN id="token-41-11" pos="word" morph="none" start_char="4991" end_char="4997">cuantos</TOKEN>
<TOKEN id="token-41-12" pos="word" morph="none" start_char="4999" end_char="5002">test</TOKEN>
<TOKEN id="token-41-13" pos="word" morph="none" start_char="5004" end_char="5005">se</TOKEN>
<TOKEN id="token-41-14" pos="word" morph="none" start_char="5007" end_char="5009">han</TOKEN>
<TOKEN id="token-41-15" pos="word" morph="none" start_char="5011" end_char="5019">realizado</TOKEN>
<TOKEN id="token-41-16" pos="word" morph="none" start_char="5021" end_char="5022">en</TOKEN>
<TOKEN id="token-41-17" pos="word" morph="none" start_char="5024" end_char="5026">las</TOKEN>
<TOKEN id="token-41-18" pos="word" morph="none" start_char="5028" end_char="5036">distintas</TOKEN>
<TOKEN id="token-41-19" pos="word" morph="none" start_char="5038" end_char="5048">situaciones</TOKEN>
<TOKEN id="token-41-20" pos="word" morph="none" start_char="5050" end_char="5052">que</TOKEN>
<TOKEN id="token-41-21" pos="word" morph="none" start_char="5054" end_char="5055">se</TOKEN>
<TOKEN id="token-41-22" pos="word" morph="none" start_char="5057" end_char="5065">describen</TOKEN>
<TOKEN id="token-41-23" pos="punct" morph="none" start_char="5066" end_char="5066">,</TOKEN>
<TOKEN id="token-41-24" pos="word" morph="none" start_char="5068" end_char="5073">porque</TOKEN>
<TOKEN id="token-41-25" pos="word" morph="none" start_char="5075" end_char="5084">obviamente</TOKEN>
<TOKEN id="token-41-26" pos="word" morph="none" start_char="5086" end_char="5087">si</TOKEN>
<TOKEN id="token-41-27" pos="word" morph="none" start_char="5089" end_char="5094">mañana</TOKEN>
<TOKEN id="token-41-28" pos="word" morph="none" start_char="5096" end_char="5105">realizamos</TOKEN>
<TOKEN id="token-41-29" pos="word" morph="none" start_char="5107" end_char="5107">4</TOKEN>
<TOKEN id="token-41-30" pos="word" morph="none" start_char="5109" end_char="5112">test</TOKEN>
<TOKEN id="token-41-31" pos="word" morph="none" start_char="5114" end_char="5125">obtendríamos</TOKEN>
<TOKEN id="token-41-32" pos="word" morph="none" start_char="5127" end_char="5128">la</TOKEN>
<TOKEN id="token-41-33" pos="word" morph="none" start_char="5130" end_char="5139">conclusión</TOKEN>
<TOKEN id="token-41-34" pos="word" morph="none" start_char="5141" end_char="5142">de</TOKEN>
<TOKEN id="token-41-35" pos="word" morph="none" start_char="5144" end_char="5146">que</TOKEN>
<TOKEN id="token-41-36" pos="word" morph="none" start_char="5148" end_char="5149">se</TOKEN>
<TOKEN id="token-41-37" pos="word" morph="none" start_char="5151" end_char="5152">ha</TOKEN>
<TOKEN id="token-41-38" pos="word" morph="none" start_char="5154" end_char="5163">erradicado</TOKEN>
<TOKEN id="token-41-39" pos="word" morph="none" start_char="5165" end_char="5174">totalmente</TOKEN>
<TOKEN id="token-41-40" pos="word" morph="none" start_char="5176" end_char="5177">la</TOKEN>
<TOKEN id="token-41-41" pos="word" morph="none" start_char="5179" end_char="5186">pandemia</TOKEN>
<TOKEN id="token-41-42" pos="punct" morph="none" start_char="5187" end_char="5187">,</TOKEN>
<TOKEN id="token-41-43" pos="word" morph="none" start_char="5189" end_char="5192">pero</TOKEN>
<TOKEN id="token-41-44" pos="word" morph="none" start_char="5194" end_char="5195">si</TOKEN>
<TOKEN id="token-41-45" pos="word" morph="none" start_char="5197" end_char="5199">por</TOKEN>
<TOKEN id="token-41-46" pos="word" morph="none" start_char="5201" end_char="5202">el</TOKEN>
<TOKEN id="token-41-47" pos="word" morph="none" start_char="5204" end_char="5212">contrario</TOKEN>
<TOKEN id="token-41-48" pos="word" morph="none" start_char="5214" end_char="5223">realizamos</TOKEN>
<TOKEN id="token-41-49" pos="word" morph="none" start_char="5225" end_char="5226">10</TOKEN>
<TOKEN id="token-41-50" pos="word" morph="none" start_char="5228" end_char="5235">millones</TOKEN>
<TOKEN id="token-41-51" pos="word" morph="none" start_char="5237" end_char="5238">de</TOKEN>
<TOKEN id="token-41-52" pos="word" morph="none" start_char="5240" end_char="5243">test</TOKEN>
<TOKEN id="token-41-53" pos="word" morph="none" start_char="5245" end_char="5246">se</TOKEN>
<TOKEN id="token-41-54" pos="word" morph="none" start_char="5248" end_char="5257">dispararía</TOKEN>
<TOKEN id="token-41-55" pos="word" morph="none" start_char="5259" end_char="5260">el</TOKEN>
<TOKEN id="token-41-56" pos="word" morph="none" start_char="5262" end_char="5268">repunte</TOKEN>
<TOKEN id="token-41-57" pos="word" morph="none" start_char="5270" end_char="5271">de</TOKEN>
<TOKEN id="token-41-58" pos="word" morph="none" start_char="5273" end_char="5281">positivos</TOKEN>
<TOKEN id="token-41-59" pos="word" morph="none" start_char="5283" end_char="5283">a</TOKEN>
<TOKEN id="token-41-60" pos="word" morph="none" start_char="5285" end_char="5291">niveles</TOKEN>
<TOKEN id="token-41-61" pos="word" morph="none" start_char="5293" end_char="5294">de</TOKEN>
<TOKEN id="token-41-62" pos="word" morph="none" start_char="5296" end_char="5301">alarma</TOKEN>
<TOKEN id="token-41-63" pos="punct" morph="none" start_char="5302" end_char="5304">...</TOKEN>
</SEG>
<SEG id="segment-42" start_char="5307" end_char="5605">
<ORIGINAL_TEXT>Debo decir que las estadísticas serían reales si lo que se nos ofrece es un indice extraído del total de positivos, pero extrayéndolo de la media por cada 100 test realizados... En ese caso sí podríamos hablar de repuntes o estabilidad en la pandemia y los ciudadanos sabríamos cuál es la evolución.</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="5307" end_char="5310">Debo</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="5312" end_char="5316">decir</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="5318" end_char="5320">que</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="5322" end_char="5324">las</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="5326" end_char="5337">estadísticas</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="5339" end_char="5344">serían</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="5346" end_char="5351">reales</TOKEN>
<TOKEN id="token-42-7" pos="word" morph="none" start_char="5353" end_char="5354">si</TOKEN>
<TOKEN id="token-42-8" pos="word" morph="none" start_char="5356" end_char="5357">lo</TOKEN>
<TOKEN id="token-42-9" pos="word" morph="none" start_char="5359" end_char="5361">que</TOKEN>
<TOKEN id="token-42-10" pos="word" morph="none" start_char="5363" end_char="5364">se</TOKEN>
<TOKEN id="token-42-11" pos="word" morph="none" start_char="5366" end_char="5368">nos</TOKEN>
<TOKEN id="token-42-12" pos="word" morph="none" start_char="5370" end_char="5375">ofrece</TOKEN>
<TOKEN id="token-42-13" pos="word" morph="none" start_char="5377" end_char="5378">es</TOKEN>
<TOKEN id="token-42-14" pos="word" morph="none" start_char="5380" end_char="5381">un</TOKEN>
<TOKEN id="token-42-15" pos="word" morph="none" start_char="5383" end_char="5388">indice</TOKEN>
<TOKEN id="token-42-16" pos="word" morph="none" start_char="5390" end_char="5397">extraído</TOKEN>
<TOKEN id="token-42-17" pos="word" morph="none" start_char="5399" end_char="5401">del</TOKEN>
<TOKEN id="token-42-18" pos="word" morph="none" start_char="5403" end_char="5407">total</TOKEN>
<TOKEN id="token-42-19" pos="word" morph="none" start_char="5409" end_char="5410">de</TOKEN>
<TOKEN id="token-42-20" pos="word" morph="none" start_char="5412" end_char="5420">positivos</TOKEN>
<TOKEN id="token-42-21" pos="punct" morph="none" start_char="5421" end_char="5421">,</TOKEN>
<TOKEN id="token-42-22" pos="word" morph="none" start_char="5423" end_char="5426">pero</TOKEN>
<TOKEN id="token-42-23" pos="word" morph="none" start_char="5428" end_char="5439">extrayéndolo</TOKEN>
<TOKEN id="token-42-24" pos="word" morph="none" start_char="5441" end_char="5442">de</TOKEN>
<TOKEN id="token-42-25" pos="word" morph="none" start_char="5444" end_char="5445">la</TOKEN>
<TOKEN id="token-42-26" pos="word" morph="none" start_char="5447" end_char="5451">media</TOKEN>
<TOKEN id="token-42-27" pos="word" morph="none" start_char="5453" end_char="5455">por</TOKEN>
<TOKEN id="token-42-28" pos="word" morph="none" start_char="5457" end_char="5460">cada</TOKEN>
<TOKEN id="token-42-29" pos="word" morph="none" start_char="5462" end_char="5464">100</TOKEN>
<TOKEN id="token-42-30" pos="word" morph="none" start_char="5466" end_char="5469">test</TOKEN>
<TOKEN id="token-42-31" pos="word" morph="none" start_char="5471" end_char="5480">realizados</TOKEN>
<TOKEN id="token-42-32" pos="punct" morph="none" start_char="5481" end_char="5483">...</TOKEN>
<TOKEN id="token-42-33" pos="word" morph="none" start_char="5485" end_char="5486">En</TOKEN>
<TOKEN id="token-42-34" pos="word" morph="none" start_char="5488" end_char="5490">ese</TOKEN>
<TOKEN id="token-42-35" pos="word" morph="none" start_char="5492" end_char="5495">caso</TOKEN>
<TOKEN id="token-42-36" pos="word" morph="none" start_char="5497" end_char="5498">sí</TOKEN>
<TOKEN id="token-42-37" pos="word" morph="none" start_char="5500" end_char="5508">podríamos</TOKEN>
<TOKEN id="token-42-38" pos="word" morph="none" start_char="5510" end_char="5515">hablar</TOKEN>
<TOKEN id="token-42-39" pos="word" morph="none" start_char="5517" end_char="5518">de</TOKEN>
<TOKEN id="token-42-40" pos="word" morph="none" start_char="5520" end_char="5527">repuntes</TOKEN>
<TOKEN id="token-42-41" pos="word" morph="none" start_char="5529" end_char="5529">o</TOKEN>
<TOKEN id="token-42-42" pos="word" morph="none" start_char="5531" end_char="5541">estabilidad</TOKEN>
<TOKEN id="token-42-43" pos="word" morph="none" start_char="5543" end_char="5544">en</TOKEN>
<TOKEN id="token-42-44" pos="word" morph="none" start_char="5546" end_char="5547">la</TOKEN>
<TOKEN id="token-42-45" pos="word" morph="none" start_char="5549" end_char="5556">pandemia</TOKEN>
<TOKEN id="token-42-46" pos="word" morph="none" start_char="5558" end_char="5558">y</TOKEN>
<TOKEN id="token-42-47" pos="word" morph="none" start_char="5560" end_char="5562">los</TOKEN>
<TOKEN id="token-42-48" pos="word" morph="none" start_char="5564" end_char="5573">ciudadanos</TOKEN>
<TOKEN id="token-42-49" pos="word" morph="none" start_char="5575" end_char="5583">sabríamos</TOKEN>
<TOKEN id="token-42-50" pos="word" morph="none" start_char="5585" end_char="5588">cuál</TOKEN>
<TOKEN id="token-42-51" pos="word" morph="none" start_char="5590" end_char="5591">es</TOKEN>
<TOKEN id="token-42-52" pos="word" morph="none" start_char="5593" end_char="5594">la</TOKEN>
<TOKEN id="token-42-53" pos="word" morph="none" start_char="5596" end_char="5604">evolución</TOKEN>
<TOKEN id="token-42-54" pos="punct" morph="none" start_char="5605" end_char="5605">.</TOKEN>
</SEG>
<SEG id="segment-43" start_char="5607" end_char="5715">
<ORIGINAL_TEXT>Porque mientras esto no se haga, los "positivos" solo serán un dato subjetivo al número de test realizados...</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="5607" end_char="5612">Porque</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="5614" end_char="5621">mientras</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="5623" end_char="5626">esto</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="5628" end_char="5629">no</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="5631" end_char="5632">se</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="5634" end_char="5637">haga</TOKEN>
<TOKEN id="token-43-6" pos="punct" morph="none" start_char="5638" end_char="5638">,</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="5640" end_char="5642">los</TOKEN>
<TOKEN id="token-43-8" pos="punct" morph="none" start_char="5644" end_char="5644">"</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="5645" end_char="5653">positivos</TOKEN>
<TOKEN id="token-43-10" pos="punct" morph="none" start_char="5654" end_char="5654">"</TOKEN>
<TOKEN id="token-43-11" pos="word" morph="none" start_char="5656" end_char="5659">solo</TOKEN>
<TOKEN id="token-43-12" pos="word" morph="none" start_char="5661" end_char="5665">serán</TOKEN>
<TOKEN id="token-43-13" pos="word" morph="none" start_char="5667" end_char="5668">un</TOKEN>
<TOKEN id="token-43-14" pos="word" morph="none" start_char="5670" end_char="5673">dato</TOKEN>
<TOKEN id="token-43-15" pos="word" morph="none" start_char="5675" end_char="5683">subjetivo</TOKEN>
<TOKEN id="token-43-16" pos="word" morph="none" start_char="5685" end_char="5686">al</TOKEN>
<TOKEN id="token-43-17" pos="word" morph="none" start_char="5688" end_char="5693">número</TOKEN>
<TOKEN id="token-43-18" pos="word" morph="none" start_char="5695" end_char="5696">de</TOKEN>
<TOKEN id="token-43-19" pos="word" morph="none" start_char="5698" end_char="5701">test</TOKEN>
<TOKEN id="token-43-20" pos="word" morph="none" start_char="5703" end_char="5712">realizados</TOKEN>
<TOKEN id="token-43-21" pos="punct" morph="none" start_char="5713" end_char="5715">...</TOKEN>
</SEG>
<SEG id="segment-44" start_char="5719" end_char="5955">
<ORIGINAL_TEXT>CHINA BAJO SOSPECHA A lo que hace unos días llamábamos "conspiranoia", hoy ya se ha convertido en una "hipótesis" perfectamente creíble... Y es que tenemos a los mandatarios de varios países sospechando y exigiendo explicaciones a China.</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="5719" end_char="5723">CHINA</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="5725" end_char="5728">BAJO</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="5730" end_char="5737">SOSPECHA</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="5739" end_char="5739">A</TOKEN>
<TOKEN id="token-44-4" pos="word" morph="none" start_char="5741" end_char="5742">lo</TOKEN>
<TOKEN id="token-44-5" pos="word" morph="none" start_char="5744" end_char="5746">que</TOKEN>
<TOKEN id="token-44-6" pos="word" morph="none" start_char="5748" end_char="5751">hace</TOKEN>
<TOKEN id="token-44-7" pos="word" morph="none" start_char="5753" end_char="5756">unos</TOKEN>
<TOKEN id="token-44-8" pos="word" morph="none" start_char="5758" end_char="5761">días</TOKEN>
<TOKEN id="token-44-9" pos="word" morph="none" start_char="5763" end_char="5772">llamábamos</TOKEN>
<TOKEN id="token-44-10" pos="punct" morph="none" start_char="5774" end_char="5774">"</TOKEN>
<TOKEN id="token-44-11" pos="word" morph="none" start_char="5775" end_char="5786">conspiranoia</TOKEN>
<TOKEN id="token-44-12" pos="punct" morph="none" start_char="5787" end_char="5788">",</TOKEN>
<TOKEN id="token-44-13" pos="word" morph="none" start_char="5790" end_char="5792">hoy</TOKEN>
<TOKEN id="token-44-14" pos="word" morph="none" start_char="5794" end_char="5795">ya</TOKEN>
<TOKEN id="token-44-15" pos="word" morph="none" start_char="5797" end_char="5798">se</TOKEN>
<TOKEN id="token-44-16" pos="word" morph="none" start_char="5800" end_char="5801">ha</TOKEN>
<TOKEN id="token-44-17" pos="word" morph="none" start_char="5803" end_char="5812">convertido</TOKEN>
<TOKEN id="token-44-18" pos="word" morph="none" start_char="5814" end_char="5815">en</TOKEN>
<TOKEN id="token-44-19" pos="word" morph="none" start_char="5817" end_char="5819">una</TOKEN>
<TOKEN id="token-44-20" pos="punct" morph="none" start_char="5821" end_char="5821">"</TOKEN>
<TOKEN id="token-44-21" pos="word" morph="none" start_char="5822" end_char="5830">hipótesis</TOKEN>
<TOKEN id="token-44-22" pos="punct" morph="none" start_char="5831" end_char="5831">"</TOKEN>
<TOKEN id="token-44-23" pos="word" morph="none" start_char="5833" end_char="5845">perfectamente</TOKEN>
<TOKEN id="token-44-24" pos="word" morph="none" start_char="5847" end_char="5853">creíble</TOKEN>
<TOKEN id="token-44-25" pos="punct" morph="none" start_char="5854" end_char="5856">...</TOKEN>
<TOKEN id="token-44-26" pos="word" morph="none" start_char="5858" end_char="5858">Y</TOKEN>
<TOKEN id="token-44-27" pos="word" morph="none" start_char="5860" end_char="5861">es</TOKEN>
<TOKEN id="token-44-28" pos="word" morph="none" start_char="5863" end_char="5865">que</TOKEN>
<TOKEN id="token-44-29" pos="word" morph="none" start_char="5867" end_char="5873">tenemos</TOKEN>
<TOKEN id="token-44-30" pos="word" morph="none" start_char="5875" end_char="5875">a</TOKEN>
<TOKEN id="token-44-31" pos="word" morph="none" start_char="5877" end_char="5879">los</TOKEN>
<TOKEN id="token-44-32" pos="word" morph="none" start_char="5881" end_char="5891">mandatarios</TOKEN>
<TOKEN id="token-44-33" pos="word" morph="none" start_char="5893" end_char="5894">de</TOKEN>
<TOKEN id="token-44-34" pos="word" morph="none" start_char="5896" end_char="5901">varios</TOKEN>
<TOKEN id="token-44-35" pos="word" morph="none" start_char="5903" end_char="5908">países</TOKEN>
<TOKEN id="token-44-36" pos="word" morph="none" start_char="5910" end_char="5920">sospechando</TOKEN>
<TOKEN id="token-44-37" pos="word" morph="none" start_char="5922" end_char="5922">y</TOKEN>
<TOKEN id="token-44-38" pos="word" morph="none" start_char="5924" end_char="5932">exigiendo</TOKEN>
<TOKEN id="token-44-39" pos="word" morph="none" start_char="5934" end_char="5946">explicaciones</TOKEN>
<TOKEN id="token-44-40" pos="word" morph="none" start_char="5948" end_char="5948">a</TOKEN>
<TOKEN id="token-44-41" pos="word" morph="none" start_char="5950" end_char="5954">China</TOKEN>
<TOKEN id="token-44-42" pos="punct" morph="none" start_char="5955" end_char="5955">.</TOKEN>
</SEG>
<SEG id="segment-45" start_char="5958" end_char="6069">
<ORIGINAL_TEXT>A la cabeza está Estados Unidos amenazando con tomar represalias si descubre que el virus fue algo intencionado.</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="5958" end_char="5958">A</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="5960" end_char="5961">la</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="5963" end_char="5968">cabeza</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="5970" end_char="5973">está</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="5975" end_char="5981">Estados</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="5983" end_char="5988">Unidos</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="5990" end_char="5999">amenazando</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="6001" end_char="6003">con</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="6005" end_char="6009">tomar</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="6011" end_char="6021">represalias</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="6023" end_char="6024">si</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="6026" end_char="6033">descubre</TOKEN>
<TOKEN id="token-45-12" pos="word" morph="none" start_char="6035" end_char="6037">que</TOKEN>
<TOKEN id="token-45-13" pos="word" morph="none" start_char="6039" end_char="6040">el</TOKEN>
<TOKEN id="token-45-14" pos="word" morph="none" start_char="6042" end_char="6046">virus</TOKEN>
<TOKEN id="token-45-15" pos="word" morph="none" start_char="6048" end_char="6050">fue</TOKEN>
<TOKEN id="token-45-16" pos="word" morph="none" start_char="6052" end_char="6055">algo</TOKEN>
<TOKEN id="token-45-17" pos="word" morph="none" start_char="6057" end_char="6068">intencionado</TOKEN>
<TOKEN id="token-45-18" pos="punct" morph="none" start_char="6069" end_char="6069">.</TOKEN>
</SEG>
<SEG id="segment-46" start_char="6071" end_char="6154">
<ORIGINAL_TEXT>Por otro lado tenemos a Francia que se muestra reticente al origen de esta pandemia.</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="6071" end_char="6073">Por</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="6075" end_char="6078">otro</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="6080" end_char="6083">lado</TOKEN>
<TOKEN id="token-46-3" pos="word" morph="none" start_char="6085" end_char="6091">tenemos</TOKEN>
<TOKEN id="token-46-4" pos="word" morph="none" start_char="6093" end_char="6093">a</TOKEN>
<TOKEN id="token-46-5" pos="word" morph="none" start_char="6095" end_char="6101">Francia</TOKEN>
<TOKEN id="token-46-6" pos="word" morph="none" start_char="6103" end_char="6105">que</TOKEN>
<TOKEN id="token-46-7" pos="word" morph="none" start_char="6107" end_char="6108">se</TOKEN>
<TOKEN id="token-46-8" pos="word" morph="none" start_char="6110" end_char="6116">muestra</TOKEN>
<TOKEN id="token-46-9" pos="word" morph="none" start_char="6118" end_char="6126">reticente</TOKEN>
<TOKEN id="token-46-10" pos="word" morph="none" start_char="6128" end_char="6129">al</TOKEN>
<TOKEN id="token-46-11" pos="word" morph="none" start_char="6131" end_char="6136">origen</TOKEN>
<TOKEN id="token-46-12" pos="word" morph="none" start_char="6138" end_char="6139">de</TOKEN>
<TOKEN id="token-46-13" pos="word" morph="none" start_char="6141" end_char="6144">esta</TOKEN>
<TOKEN id="token-46-14" pos="word" morph="none" start_char="6146" end_char="6153">pandemia</TOKEN>
<TOKEN id="token-46-15" pos="punct" morph="none" start_char="6154" end_char="6154">.</TOKEN>
</SEG>
<SEG id="segment-47" start_char="6156" end_char="6254">
<ORIGINAL_TEXT>Además Australia solicita hacer una investigación independiente que está siendo denegada por China.</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="6156" end_char="6161">Además</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="6163" end_char="6171">Australia</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="6173" end_char="6180">solicita</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="6182" end_char="6186">hacer</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="6188" end_char="6190">una</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="6192" end_char="6204">investigación</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="6206" end_char="6218">independiente</TOKEN>
<TOKEN id="token-47-7" pos="word" morph="none" start_char="6220" end_char="6222">que</TOKEN>
<TOKEN id="token-47-8" pos="word" morph="none" start_char="6224" end_char="6227">está</TOKEN>
<TOKEN id="token-47-9" pos="word" morph="none" start_char="6229" end_char="6234">siendo</TOKEN>
<TOKEN id="token-47-10" pos="word" morph="none" start_char="6236" end_char="6243">denegada</TOKEN>
<TOKEN id="token-47-11" pos="word" morph="none" start_char="6245" end_char="6247">por</TOKEN>
<TOKEN id="token-47-12" pos="word" morph="none" start_char="6249" end_char="6253">China</TOKEN>
<TOKEN id="token-47-13" pos="punct" morph="none" start_char="6254" end_char="6254">.</TOKEN>
</SEG>
<SEG id="segment-48" start_char="6256" end_char="6354">
<ORIGINAL_TEXT>Y es que a tanto descrédito también se suman Reino Unido y Alemania que pide a China transparencia.</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="6256" end_char="6256">Y</TOKEN>
<TOKEN id="token-48-1" pos="word" morph="none" start_char="6258" end_char="6259">es</TOKEN>
<TOKEN id="token-48-2" pos="word" morph="none" start_char="6261" end_char="6263">que</TOKEN>
<TOKEN id="token-48-3" pos="word" morph="none" start_char="6265" end_char="6265">a</TOKEN>
<TOKEN id="token-48-4" pos="word" morph="none" start_char="6267" end_char="6271">tanto</TOKEN>
<TOKEN id="token-48-5" pos="word" morph="none" start_char="6273" end_char="6282">descrédito</TOKEN>
<TOKEN id="token-48-6" pos="word" morph="none" start_char="6284" end_char="6290">también</TOKEN>
<TOKEN id="token-48-7" pos="word" morph="none" start_char="6292" end_char="6293">se</TOKEN>
<TOKEN id="token-48-8" pos="word" morph="none" start_char="6295" end_char="6299">suman</TOKEN>
<TOKEN id="token-48-9" pos="word" morph="none" start_char="6301" end_char="6305">Reino</TOKEN>
<TOKEN id="token-48-10" pos="word" morph="none" start_char="6307" end_char="6311">Unido</TOKEN>
<TOKEN id="token-48-11" pos="word" morph="none" start_char="6313" end_char="6313">y</TOKEN>
<TOKEN id="token-48-12" pos="word" morph="none" start_char="6315" end_char="6322">Alemania</TOKEN>
<TOKEN id="token-48-13" pos="word" morph="none" start_char="6324" end_char="6326">que</TOKEN>
<TOKEN id="token-48-14" pos="word" morph="none" start_char="6328" end_char="6331">pide</TOKEN>
<TOKEN id="token-48-15" pos="word" morph="none" start_char="6333" end_char="6333">a</TOKEN>
<TOKEN id="token-48-16" pos="word" morph="none" start_char="6335" end_char="6339">China</TOKEN>
<TOKEN id="token-48-17" pos="word" morph="none" start_char="6341" end_char="6353">transparencia</TOKEN>
<TOKEN id="token-48-18" pos="punct" morph="none" start_char="6354" end_char="6354">.</TOKEN>
</SEG>
<SEG id="segment-49" start_char="6357" end_char="6537">
<ORIGINAL_TEXT>Obviamente aunque para algunos científicos no haya evidencias de que el virus proviene de un laboratorio, la falta de estas evidencias tampoco excluye la posibilidad de que así sea.</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="6357" end_char="6366">Obviamente</TOKEN>
<TOKEN id="token-49-1" pos="word" morph="none" start_char="6368" end_char="6373">aunque</TOKEN>
<TOKEN id="token-49-2" pos="word" morph="none" start_char="6375" end_char="6378">para</TOKEN>
<TOKEN id="token-49-3" pos="word" morph="none" start_char="6380" end_char="6386">algunos</TOKEN>
<TOKEN id="token-49-4" pos="word" morph="none" start_char="6388" end_char="6398">científicos</TOKEN>
<TOKEN id="token-49-5" pos="word" morph="none" start_char="6400" end_char="6401">no</TOKEN>
<TOKEN id="token-49-6" pos="word" morph="none" start_char="6403" end_char="6406">haya</TOKEN>
<TOKEN id="token-49-7" pos="word" morph="none" start_char="6408" end_char="6417">evidencias</TOKEN>
<TOKEN id="token-49-8" pos="word" morph="none" start_char="6419" end_char="6420">de</TOKEN>
<TOKEN id="token-49-9" pos="word" morph="none" start_char="6422" end_char="6424">que</TOKEN>
<TOKEN id="token-49-10" pos="word" morph="none" start_char="6426" end_char="6427">el</TOKEN>
<TOKEN id="token-49-11" pos="word" morph="none" start_char="6429" end_char="6433">virus</TOKEN>
<TOKEN id="token-49-12" pos="word" morph="none" start_char="6435" end_char="6442">proviene</TOKEN>
<TOKEN id="token-49-13" pos="word" morph="none" start_char="6444" end_char="6445">de</TOKEN>
<TOKEN id="token-49-14" pos="word" morph="none" start_char="6447" end_char="6448">un</TOKEN>
<TOKEN id="token-49-15" pos="word" morph="none" start_char="6450" end_char="6460">laboratorio</TOKEN>
<TOKEN id="token-49-16" pos="punct" morph="none" start_char="6461" end_char="6461">,</TOKEN>
<TOKEN id="token-49-17" pos="word" morph="none" start_char="6463" end_char="6464">la</TOKEN>
<TOKEN id="token-49-18" pos="word" morph="none" start_char="6466" end_char="6470">falta</TOKEN>
<TOKEN id="token-49-19" pos="word" morph="none" start_char="6472" end_char="6473">de</TOKEN>
<TOKEN id="token-49-20" pos="word" morph="none" start_char="6475" end_char="6479">estas</TOKEN>
<TOKEN id="token-49-21" pos="word" morph="none" start_char="6481" end_char="6490">evidencias</TOKEN>
<TOKEN id="token-49-22" pos="word" morph="none" start_char="6492" end_char="6498">tampoco</TOKEN>
<TOKEN id="token-49-23" pos="word" morph="none" start_char="6500" end_char="6506">excluye</TOKEN>
<TOKEN id="token-49-24" pos="word" morph="none" start_char="6508" end_char="6509">la</TOKEN>
<TOKEN id="token-49-25" pos="word" morph="none" start_char="6511" end_char="6521">posibilidad</TOKEN>
<TOKEN id="token-49-26" pos="word" morph="none" start_char="6523" end_char="6524">de</TOKEN>
<TOKEN id="token-49-27" pos="word" morph="none" start_char="6526" end_char="6528">que</TOKEN>
<TOKEN id="token-49-28" pos="word" morph="none" start_char="6530" end_char="6532">así</TOKEN>
<TOKEN id="token-49-29" pos="word" morph="none" start_char="6534" end_char="6536">sea</TOKEN>
<TOKEN id="token-49-30" pos="punct" morph="none" start_char="6537" end_char="6537">.</TOKEN>
</SEG>
<SEG id="segment-50" start_char="6541" end_char="6645">
<ORIGINAL_TEXT>China miente, a estas alturas me parece mentira que haya gente que se crea lo que dice el gobierno chino.</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="6541" end_char="6545">China</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="6547" end_char="6552">miente</TOKEN>
<TOKEN id="token-50-2" pos="punct" morph="none" start_char="6553" end_char="6553">,</TOKEN>
<TOKEN id="token-50-3" pos="word" morph="none" start_char="6555" end_char="6555">a</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="6557" end_char="6561">estas</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="6563" end_char="6569">alturas</TOKEN>
<TOKEN id="token-50-6" pos="word" morph="none" start_char="6571" end_char="6572">me</TOKEN>
<TOKEN id="token-50-7" pos="word" morph="none" start_char="6574" end_char="6579">parece</TOKEN>
<TOKEN id="token-50-8" pos="word" morph="none" start_char="6581" end_char="6587">mentira</TOKEN>
<TOKEN id="token-50-9" pos="word" morph="none" start_char="6589" end_char="6591">que</TOKEN>
<TOKEN id="token-50-10" pos="word" morph="none" start_char="6593" end_char="6596">haya</TOKEN>
<TOKEN id="token-50-11" pos="word" morph="none" start_char="6598" end_char="6602">gente</TOKEN>
<TOKEN id="token-50-12" pos="word" morph="none" start_char="6604" end_char="6606">que</TOKEN>
<TOKEN id="token-50-13" pos="word" morph="none" start_char="6608" end_char="6609">se</TOKEN>
<TOKEN id="token-50-14" pos="word" morph="none" start_char="6611" end_char="6614">crea</TOKEN>
<TOKEN id="token-50-15" pos="word" morph="none" start_char="6616" end_char="6617">lo</TOKEN>
<TOKEN id="token-50-16" pos="word" morph="none" start_char="6619" end_char="6621">que</TOKEN>
<TOKEN id="token-50-17" pos="word" morph="none" start_char="6623" end_char="6626">dice</TOKEN>
<TOKEN id="token-50-18" pos="word" morph="none" start_char="6628" end_char="6629">el</TOKEN>
<TOKEN id="token-50-19" pos="word" morph="none" start_char="6631" end_char="6638">gobierno</TOKEN>
<TOKEN id="token-50-20" pos="word" morph="none" start_char="6640" end_char="6644">chino</TOKEN>
<TOKEN id="token-50-21" pos="punct" morph="none" start_char="6645" end_char="6645">.</TOKEN>
</SEG>
<SEG id="segment-51" start_char="6647" end_char="6696">
<ORIGINAL_TEXT>Ni son esos los muertos, ni los infectados reales.</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="word" morph="none" start_char="6647" end_char="6648">Ni</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="6650" end_char="6652">son</TOKEN>
<TOKEN id="token-51-2" pos="word" morph="none" start_char="6654" end_char="6657">esos</TOKEN>
<TOKEN id="token-51-3" pos="word" morph="none" start_char="6659" end_char="6661">los</TOKEN>
<TOKEN id="token-51-4" pos="word" morph="none" start_char="6663" end_char="6669">muertos</TOKEN>
<TOKEN id="token-51-5" pos="punct" morph="none" start_char="6670" end_char="6670">,</TOKEN>
<TOKEN id="token-51-6" pos="word" morph="none" start_char="6672" end_char="6673">ni</TOKEN>
<TOKEN id="token-51-7" pos="word" morph="none" start_char="6675" end_char="6677">los</TOKEN>
<TOKEN id="token-51-8" pos="word" morph="none" start_char="6679" end_char="6688">infectados</TOKEN>
<TOKEN id="token-51-9" pos="word" morph="none" start_char="6690" end_char="6695">reales</TOKEN>
<TOKEN id="token-51-10" pos="punct" morph="none" start_char="6696" end_char="6696">.</TOKEN>
</SEG>
<SEG id="segment-52" start_char="6698" end_char="6892">
<ORIGINAL_TEXT>Además yo veo evidencias más que fundadas para sospechar que han sido ellos, no estoy diciendo que lo hayan hecho a posta, eso es otra cosa, aquí me incluno más a pensar que ha sido un accidente.</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="6698" end_char="6703">Además</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="6705" end_char="6706">yo</TOKEN>
<TOKEN id="token-52-2" pos="word" morph="none" start_char="6708" end_char="6710">veo</TOKEN>
<TOKEN id="token-52-3" pos="word" morph="none" start_char="6712" end_char="6721">evidencias</TOKEN>
<TOKEN id="token-52-4" pos="word" morph="none" start_char="6723" end_char="6725">más</TOKEN>
<TOKEN id="token-52-5" pos="word" morph="none" start_char="6727" end_char="6729">que</TOKEN>
<TOKEN id="token-52-6" pos="word" morph="none" start_char="6731" end_char="6738">fundadas</TOKEN>
<TOKEN id="token-52-7" pos="word" morph="none" start_char="6740" end_char="6743">para</TOKEN>
<TOKEN id="token-52-8" pos="word" morph="none" start_char="6745" end_char="6753">sospechar</TOKEN>
<TOKEN id="token-52-9" pos="word" morph="none" start_char="6755" end_char="6757">que</TOKEN>
<TOKEN id="token-52-10" pos="word" morph="none" start_char="6759" end_char="6761">han</TOKEN>
<TOKEN id="token-52-11" pos="word" morph="none" start_char="6763" end_char="6766">sido</TOKEN>
<TOKEN id="token-52-12" pos="word" morph="none" start_char="6768" end_char="6772">ellos</TOKEN>
<TOKEN id="token-52-13" pos="punct" morph="none" start_char="6773" end_char="6773">,</TOKEN>
<TOKEN id="token-52-14" pos="word" morph="none" start_char="6775" end_char="6776">no</TOKEN>
<TOKEN id="token-52-15" pos="word" morph="none" start_char="6778" end_char="6782">estoy</TOKEN>
<TOKEN id="token-52-16" pos="word" morph="none" start_char="6784" end_char="6791">diciendo</TOKEN>
<TOKEN id="token-52-17" pos="word" morph="none" start_char="6793" end_char="6795">que</TOKEN>
<TOKEN id="token-52-18" pos="word" morph="none" start_char="6797" end_char="6798">lo</TOKEN>
<TOKEN id="token-52-19" pos="word" morph="none" start_char="6800" end_char="6804">hayan</TOKEN>
<TOKEN id="token-52-20" pos="word" morph="none" start_char="6806" end_char="6810">hecho</TOKEN>
<TOKEN id="token-52-21" pos="word" morph="none" start_char="6812" end_char="6812">a</TOKEN>
<TOKEN id="token-52-22" pos="word" morph="none" start_char="6814" end_char="6818">posta</TOKEN>
<TOKEN id="token-52-23" pos="punct" morph="none" start_char="6819" end_char="6819">,</TOKEN>
<TOKEN id="token-52-24" pos="word" morph="none" start_char="6821" end_char="6823">eso</TOKEN>
<TOKEN id="token-52-25" pos="word" morph="none" start_char="6825" end_char="6826">es</TOKEN>
<TOKEN id="token-52-26" pos="word" morph="none" start_char="6828" end_char="6831">otra</TOKEN>
<TOKEN id="token-52-27" pos="word" morph="none" start_char="6833" end_char="6836">cosa</TOKEN>
<TOKEN id="token-52-28" pos="punct" morph="none" start_char="6837" end_char="6837">,</TOKEN>
<TOKEN id="token-52-29" pos="word" morph="none" start_char="6839" end_char="6842">aquí</TOKEN>
<TOKEN id="token-52-30" pos="word" morph="none" start_char="6844" end_char="6845">me</TOKEN>
<TOKEN id="token-52-31" pos="word" morph="none" start_char="6847" end_char="6853">incluno</TOKEN>
<TOKEN id="token-52-32" pos="word" morph="none" start_char="6855" end_char="6857">más</TOKEN>
<TOKEN id="token-52-33" pos="word" morph="none" start_char="6859" end_char="6859">a</TOKEN>
<TOKEN id="token-52-34" pos="word" morph="none" start_char="6861" end_char="6866">pensar</TOKEN>
<TOKEN id="token-52-35" pos="word" morph="none" start_char="6868" end_char="6870">que</TOKEN>
<TOKEN id="token-52-36" pos="word" morph="none" start_char="6872" end_char="6873">ha</TOKEN>
<TOKEN id="token-52-37" pos="word" morph="none" start_char="6875" end_char="6878">sido</TOKEN>
<TOKEN id="token-52-38" pos="word" morph="none" start_char="6880" end_char="6881">un</TOKEN>
<TOKEN id="token-52-39" pos="word" morph="none" start_char="6883" end_char="6891">accidente</TOKEN>
<TOKEN id="token-52-40" pos="punct" morph="none" start_char="6892" end_char="6892">.</TOKEN>
</SEG>
<SEG id="segment-53" start_char="6894" end_char="6960">
<ORIGINAL_TEXT>Hay muchas preguntas sin responder, ¿por que ese afán en ocultarlo?</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="word" morph="none" start_char="6894" end_char="6896">Hay</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="6898" end_char="6903">muchas</TOKEN>
<TOKEN id="token-53-2" pos="word" morph="none" start_char="6905" end_char="6913">preguntas</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="6915" end_char="6917">sin</TOKEN>
<TOKEN id="token-53-4" pos="word" morph="none" start_char="6919" end_char="6927">responder</TOKEN>
<TOKEN id="token-53-5" pos="punct" morph="none" start_char="6928" end_char="6928">,</TOKEN>
<TOKEN id="token-53-6" pos="punct" morph="none" start_char="6930" end_char="6930">¿</TOKEN>
<TOKEN id="token-53-7" pos="word" morph="none" start_char="6931" end_char="6933">por</TOKEN>
<TOKEN id="token-53-8" pos="word" morph="none" start_char="6935" end_char="6937">que</TOKEN>
<TOKEN id="token-53-9" pos="word" morph="none" start_char="6939" end_char="6941">ese</TOKEN>
<TOKEN id="token-53-10" pos="word" morph="none" start_char="6943" end_char="6946">afán</TOKEN>
<TOKEN id="token-53-11" pos="word" morph="none" start_char="6948" end_char="6949">en</TOKEN>
<TOKEN id="token-53-12" pos="word" morph="none" start_char="6951" end_char="6959">ocultarlo</TOKEN>
<TOKEN id="token-53-13" pos="punct" morph="none" start_char="6960" end_char="6960">?</TOKEN>
</SEG>
<SEG id="segment-54" start_char="6962" end_char="7135">
<ORIGINAL_TEXT>metían en la cárcel al que diera la voz de alarma y lo tachaban de traidor, si fuera natural el virus no tendrían ningún problema en comunicarlo a la comunidad internacional.</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="word" morph="none" start_char="6962" end_char="6967">metían</TOKEN>
<TOKEN id="token-54-1" pos="word" morph="none" start_char="6969" end_char="6970">en</TOKEN>
<TOKEN id="token-54-2" pos="word" morph="none" start_char="6972" end_char="6973">la</TOKEN>
<TOKEN id="token-54-3" pos="word" morph="none" start_char="6975" end_char="6980">cárcel</TOKEN>
<TOKEN id="token-54-4" pos="word" morph="none" start_char="6982" end_char="6983">al</TOKEN>
<TOKEN id="token-54-5" pos="word" morph="none" start_char="6985" end_char="6987">que</TOKEN>
<TOKEN id="token-54-6" pos="word" morph="none" start_char="6989" end_char="6993">diera</TOKEN>
<TOKEN id="token-54-7" pos="word" morph="none" start_char="6995" end_char="6996">la</TOKEN>
<TOKEN id="token-54-8" pos="word" morph="none" start_char="6998" end_char="7000">voz</TOKEN>
<TOKEN id="token-54-9" pos="word" morph="none" start_char="7002" end_char="7003">de</TOKEN>
<TOKEN id="token-54-10" pos="word" morph="none" start_char="7005" end_char="7010">alarma</TOKEN>
<TOKEN id="token-54-11" pos="word" morph="none" start_char="7012" end_char="7012">y</TOKEN>
<TOKEN id="token-54-12" pos="word" morph="none" start_char="7014" end_char="7015">lo</TOKEN>
<TOKEN id="token-54-13" pos="word" morph="none" start_char="7017" end_char="7024">tachaban</TOKEN>
<TOKEN id="token-54-14" pos="word" morph="none" start_char="7026" end_char="7027">de</TOKEN>
<TOKEN id="token-54-15" pos="word" morph="none" start_char="7029" end_char="7035">traidor</TOKEN>
<TOKEN id="token-54-16" pos="punct" morph="none" start_char="7036" end_char="7036">,</TOKEN>
<TOKEN id="token-54-17" pos="word" morph="none" start_char="7038" end_char="7039">si</TOKEN>
<TOKEN id="token-54-18" pos="word" morph="none" start_char="7041" end_char="7045">fuera</TOKEN>
<TOKEN id="token-54-19" pos="word" morph="none" start_char="7047" end_char="7053">natural</TOKEN>
<TOKEN id="token-54-20" pos="word" morph="none" start_char="7055" end_char="7056">el</TOKEN>
<TOKEN id="token-54-21" pos="word" morph="none" start_char="7058" end_char="7062">virus</TOKEN>
<TOKEN id="token-54-22" pos="word" morph="none" start_char="7064" end_char="7065">no</TOKEN>
<TOKEN id="token-54-23" pos="word" morph="none" start_char="7067" end_char="7074">tendrían</TOKEN>
<TOKEN id="token-54-24" pos="word" morph="none" start_char="7076" end_char="7081">ningún</TOKEN>
<TOKEN id="token-54-25" pos="word" morph="none" start_char="7083" end_char="7090">problema</TOKEN>
<TOKEN id="token-54-26" pos="word" morph="none" start_char="7092" end_char="7093">en</TOKEN>
<TOKEN id="token-54-27" pos="word" morph="none" start_char="7095" end_char="7105">comunicarlo</TOKEN>
<TOKEN id="token-54-28" pos="word" morph="none" start_char="7107" end_char="7107">a</TOKEN>
<TOKEN id="token-54-29" pos="word" morph="none" start_char="7109" end_char="7110">la</TOKEN>
<TOKEN id="token-54-30" pos="word" morph="none" start_char="7112" end_char="7120">comunidad</TOKEN>
<TOKEN id="token-54-31" pos="word" morph="none" start_char="7122" end_char="7134">internacional</TOKEN>
<TOKEN id="token-54-32" pos="punct" morph="none" start_char="7135" end_char="7135">.</TOKEN>
</SEG>
<SEG id="segment-55" start_char="7137" end_char="7163">
<ORIGINAL_TEXT>¿os acordais del Chernovil?</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="punct" morph="none" start_char="7137" end_char="7137">¿</TOKEN>
<TOKEN id="token-55-1" pos="word" morph="none" start_char="7138" end_char="7139">os</TOKEN>
<TOKEN id="token-55-2" pos="word" morph="none" start_char="7141" end_char="7148">acordais</TOKEN>
<TOKEN id="token-55-3" pos="word" morph="none" start_char="7150" end_char="7152">del</TOKEN>
<TOKEN id="token-55-4" pos="word" morph="none" start_char="7154" end_char="7162">Chernovil</TOKEN>
<TOKEN id="token-55-5" pos="punct" morph="none" start_char="7163" end_char="7163">?</TOKEN>
</SEG>
<SEG id="segment-56" start_char="7165" end_char="7263">
<ORIGINAL_TEXT>fueron otros países quienes detectaron la fuga radiactiva, los rusos estaban callados como muertos.</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="7165" end_char="7170">fueron</TOKEN>
<TOKEN id="token-56-1" pos="word" morph="none" start_char="7172" end_char="7176">otros</TOKEN>
<TOKEN id="token-56-2" pos="word" morph="none" start_char="7178" end_char="7183">países</TOKEN>
<TOKEN id="token-56-3" pos="word" morph="none" start_char="7185" end_char="7191">quienes</TOKEN>
<TOKEN id="token-56-4" pos="word" morph="none" start_char="7193" end_char="7202">detectaron</TOKEN>
<TOKEN id="token-56-5" pos="word" morph="none" start_char="7204" end_char="7205">la</TOKEN>
<TOKEN id="token-56-6" pos="word" morph="none" start_char="7207" end_char="7210">fuga</TOKEN>
<TOKEN id="token-56-7" pos="word" morph="none" start_char="7212" end_char="7221">radiactiva</TOKEN>
<TOKEN id="token-56-8" pos="punct" morph="none" start_char="7222" end_char="7222">,</TOKEN>
<TOKEN id="token-56-9" pos="word" morph="none" start_char="7224" end_char="7226">los</TOKEN>
<TOKEN id="token-56-10" pos="word" morph="none" start_char="7228" end_char="7232">rusos</TOKEN>
<TOKEN id="token-56-11" pos="word" morph="none" start_char="7234" end_char="7240">estaban</TOKEN>
<TOKEN id="token-56-12" pos="word" morph="none" start_char="7242" end_char="7249">callados</TOKEN>
<TOKEN id="token-56-13" pos="word" morph="none" start_char="7251" end_char="7254">como</TOKEN>
<TOKEN id="token-56-14" pos="word" morph="none" start_char="7256" end_char="7262">muertos</TOKEN>
<TOKEN id="token-56-15" pos="punct" morph="none" start_char="7263" end_char="7263">.</TOKEN>
</SEG>
<SEG id="segment-57" start_char="7265" end_char="7437">
<ORIGINAL_TEXT>Por otro lado CIA lleva denunciando desde hace mucho que ese laboratorio (a 300 metros del mercado) tiene muchos fallos de seguridad y que ahí se hacen cosas muy peligrosas.</ORIGINAL_TEXT>
<TOKEN id="token-57-0" pos="word" morph="none" start_char="7265" end_char="7267">Por</TOKEN>
<TOKEN id="token-57-1" pos="word" morph="none" start_char="7269" end_char="7272">otro</TOKEN>
<TOKEN id="token-57-2" pos="word" morph="none" start_char="7274" end_char="7277">lado</TOKEN>
<TOKEN id="token-57-3" pos="word" morph="none" start_char="7279" end_char="7281">CIA</TOKEN>
<TOKEN id="token-57-4" pos="word" morph="none" start_char="7283" end_char="7287">lleva</TOKEN>
<TOKEN id="token-57-5" pos="word" morph="none" start_char="7289" end_char="7299">denunciando</TOKEN>
<TOKEN id="token-57-6" pos="word" morph="none" start_char="7301" end_char="7305">desde</TOKEN>
<TOKEN id="token-57-7" pos="word" morph="none" start_char="7307" end_char="7310">hace</TOKEN>
<TOKEN id="token-57-8" pos="word" morph="none" start_char="7312" end_char="7316">mucho</TOKEN>
<TOKEN id="token-57-9" pos="word" morph="none" start_char="7318" end_char="7320">que</TOKEN>
<TOKEN id="token-57-10" pos="word" morph="none" start_char="7322" end_char="7324">ese</TOKEN>
<TOKEN id="token-57-11" pos="word" morph="none" start_char="7326" end_char="7336">laboratorio</TOKEN>
<TOKEN id="token-57-12" pos="punct" morph="none" start_char="7338" end_char="7338">(</TOKEN>
<TOKEN id="token-57-13" pos="word" morph="none" start_char="7339" end_char="7339">a</TOKEN>
<TOKEN id="token-57-14" pos="word" morph="none" start_char="7341" end_char="7343">300</TOKEN>
<TOKEN id="token-57-15" pos="word" morph="none" start_char="7345" end_char="7350">metros</TOKEN>
<TOKEN id="token-57-16" pos="word" morph="none" start_char="7352" end_char="7354">del</TOKEN>
<TOKEN id="token-57-17" pos="word" morph="none" start_char="7356" end_char="7362">mercado</TOKEN>
<TOKEN id="token-57-18" pos="punct" morph="none" start_char="7363" end_char="7363">)</TOKEN>
<TOKEN id="token-57-19" pos="word" morph="none" start_char="7365" end_char="7369">tiene</TOKEN>
<TOKEN id="token-57-20" pos="word" morph="none" start_char="7371" end_char="7376">muchos</TOKEN>
<TOKEN id="token-57-21" pos="word" morph="none" start_char="7378" end_char="7383">fallos</TOKEN>
<TOKEN id="token-57-22" pos="word" morph="none" start_char="7385" end_char="7386">de</TOKEN>
<TOKEN id="token-57-23" pos="word" morph="none" start_char="7388" end_char="7396">seguridad</TOKEN>
<TOKEN id="token-57-24" pos="word" morph="none" start_char="7398" end_char="7398">y</TOKEN>
<TOKEN id="token-57-25" pos="word" morph="none" start_char="7400" end_char="7402">que</TOKEN>
<TOKEN id="token-57-26" pos="word" morph="none" start_char="7404" end_char="7406">ahí</TOKEN>
<TOKEN id="token-57-27" pos="word" morph="none" start_char="7408" end_char="7409">se</TOKEN>
<TOKEN id="token-57-28" pos="word" morph="none" start_char="7411" end_char="7415">hacen</TOKEN>
<TOKEN id="token-57-29" pos="word" morph="none" start_char="7417" end_char="7421">cosas</TOKEN>
<TOKEN id="token-57-30" pos="word" morph="none" start_char="7423" end_char="7425">muy</TOKEN>
<TOKEN id="token-57-31" pos="word" morph="none" start_char="7427" end_char="7436">peligrosas</TOKEN>
<TOKEN id="token-57-32" pos="punct" morph="none" start_char="7437" end_char="7437">.</TOKEN>
</SEG>
<SEG id="segment-58" start_char="7439" end_char="7552">
<ORIGINAL_TEXT>El muerciélago en cuestion está a 800 km de ese mercado, además invernando y además el mercado SOLO VENDE MARISCO.</ORIGINAL_TEXT>
<TOKEN id="token-58-0" pos="word" morph="none" start_char="7439" end_char="7440">El</TOKEN>
<TOKEN id="token-58-1" pos="word" morph="none" start_char="7442" end_char="7452">muerciélago</TOKEN>
<TOKEN id="token-58-2" pos="word" morph="none" start_char="7454" end_char="7455">en</TOKEN>
<TOKEN id="token-58-3" pos="word" morph="none" start_char="7457" end_char="7464">cuestion</TOKEN>
<TOKEN id="token-58-4" pos="word" morph="none" start_char="7466" end_char="7469">está</TOKEN>
<TOKEN id="token-58-5" pos="word" morph="none" start_char="7471" end_char="7471">a</TOKEN>
<TOKEN id="token-58-6" pos="word" morph="none" start_char="7473" end_char="7475">800</TOKEN>
<TOKEN id="token-58-7" pos="word" morph="none" start_char="7477" end_char="7478">km</TOKEN>
<TOKEN id="token-58-8" pos="word" morph="none" start_char="7480" end_char="7481">de</TOKEN>
<TOKEN id="token-58-9" pos="word" morph="none" start_char="7483" end_char="7485">ese</TOKEN>
<TOKEN id="token-58-10" pos="word" morph="none" start_char="7487" end_char="7493">mercado</TOKEN>
<TOKEN id="token-58-11" pos="punct" morph="none" start_char="7494" end_char="7494">,</TOKEN>
<TOKEN id="token-58-12" pos="word" morph="none" start_char="7496" end_char="7501">además</TOKEN>
<TOKEN id="token-58-13" pos="word" morph="none" start_char="7503" end_char="7512">invernando</TOKEN>
<TOKEN id="token-58-14" pos="word" morph="none" start_char="7514" end_char="7514">y</TOKEN>
<TOKEN id="token-58-15" pos="word" morph="none" start_char="7516" end_char="7521">además</TOKEN>
<TOKEN id="token-58-16" pos="word" morph="none" start_char="7523" end_char="7524">el</TOKEN>
<TOKEN id="token-58-17" pos="word" morph="none" start_char="7526" end_char="7532">mercado</TOKEN>
<TOKEN id="token-58-18" pos="word" morph="none" start_char="7534" end_char="7537">SOLO</TOKEN>
<TOKEN id="token-58-19" pos="word" morph="none" start_char="7539" end_char="7543">VENDE</TOKEN>
<TOKEN id="token-58-20" pos="word" morph="none" start_char="7545" end_char="7551">MARISCO</TOKEN>
<TOKEN id="token-58-21" pos="punct" morph="none" start_char="7552" end_char="7552">.</TOKEN>
</SEG>
<SEG id="segment-59" start_char="7554" end_char="7587">
<ORIGINAL_TEXT>¿entendeis lo que os quiero decir?</ORIGINAL_TEXT>
<TOKEN id="token-59-0" pos="punct" morph="none" start_char="7554" end_char="7554">¿</TOKEN>
<TOKEN id="token-59-1" pos="word" morph="none" start_char="7555" end_char="7563">entendeis</TOKEN>
<TOKEN id="token-59-2" pos="word" morph="none" start_char="7565" end_char="7566">lo</TOKEN>
<TOKEN id="token-59-3" pos="word" morph="none" start_char="7568" end_char="7570">que</TOKEN>
<TOKEN id="token-59-4" pos="word" morph="none" start_char="7572" end_char="7573">os</TOKEN>
<TOKEN id="token-59-5" pos="word" morph="none" start_char="7575" end_char="7580">quiero</TOKEN>
<TOKEN id="token-59-6" pos="word" morph="none" start_char="7582" end_char="7586">decir</TOKEN>
<TOKEN id="token-59-7" pos="punct" morph="none" start_char="7587" end_char="7587">?</TOKEN>
</SEG>
<SEG id="segment-60" start_char="7589" end_char="7616">
<ORIGINAL_TEXT>Amigos, Blanco y en botella.</ORIGINAL_TEXT>
<TOKEN id="token-60-0" pos="word" morph="none" start_char="7589" end_char="7594">Amigos</TOKEN>
<TOKEN id="token-60-1" pos="punct" morph="none" start_char="7595" end_char="7595">,</TOKEN>
<TOKEN id="token-60-2" pos="word" morph="none" start_char="7597" end_char="7602">Blanco</TOKEN>
<TOKEN id="token-60-3" pos="word" morph="none" start_char="7604" end_char="7604">y</TOKEN>
<TOKEN id="token-60-4" pos="word" morph="none" start_char="7606" end_char="7607">en</TOKEN>
<TOKEN id="token-60-5" pos="word" morph="none" start_char="7609" end_char="7615">botella</TOKEN>
<TOKEN id="token-60-6" pos="punct" morph="none" start_char="7616" end_char="7616">.</TOKEN>
</SEG>
<SEG id="segment-61" start_char="7620" end_char="7877">
<ORIGINAL_TEXT>Puede que no sea el COVID-19 el virus del cual se hablaba en aquella nota, pero también nadie caerá en la ingenuidad que, en vista de los acontecimientos, cualquier laboratorio responsable articularía los medios a su alcance para encubrir su responsabilidad.</ORIGINAL_TEXT>
<TOKEN id="token-61-0" pos="word" morph="none" start_char="7620" end_char="7624">Puede</TOKEN>
<TOKEN id="token-61-1" pos="word" morph="none" start_char="7626" end_char="7628">que</TOKEN>
<TOKEN id="token-61-2" pos="word" morph="none" start_char="7630" end_char="7631">no</TOKEN>
<TOKEN id="token-61-3" pos="word" morph="none" start_char="7633" end_char="7635">sea</TOKEN>
<TOKEN id="token-61-4" pos="word" morph="none" start_char="7637" end_char="7638">el</TOKEN>
<TOKEN id="token-61-5" pos="unknown" morph="none" start_char="7640" end_char="7647">COVID-19</TOKEN>
<TOKEN id="token-61-6" pos="word" morph="none" start_char="7649" end_char="7650">el</TOKEN>
<TOKEN id="token-61-7" pos="word" morph="none" start_char="7652" end_char="7656">virus</TOKEN>
<TOKEN id="token-61-8" pos="word" morph="none" start_char="7658" end_char="7660">del</TOKEN>
<TOKEN id="token-61-9" pos="word" morph="none" start_char="7662" end_char="7665">cual</TOKEN>
<TOKEN id="token-61-10" pos="word" morph="none" start_char="7667" end_char="7668">se</TOKEN>
<TOKEN id="token-61-11" pos="word" morph="none" start_char="7670" end_char="7676">hablaba</TOKEN>
<TOKEN id="token-61-12" pos="word" morph="none" start_char="7678" end_char="7679">en</TOKEN>
<TOKEN id="token-61-13" pos="word" morph="none" start_char="7681" end_char="7687">aquella</TOKEN>
<TOKEN id="token-61-14" pos="word" morph="none" start_char="7689" end_char="7692">nota</TOKEN>
<TOKEN id="token-61-15" pos="punct" morph="none" start_char="7693" end_char="7693">,</TOKEN>
<TOKEN id="token-61-16" pos="word" morph="none" start_char="7695" end_char="7698">pero</TOKEN>
<TOKEN id="token-61-17" pos="word" morph="none" start_char="7700" end_char="7706">también</TOKEN>
<TOKEN id="token-61-18" pos="word" morph="none" start_char="7708" end_char="7712">nadie</TOKEN>
<TOKEN id="token-61-19" pos="word" morph="none" start_char="7714" end_char="7718">caerá</TOKEN>
<TOKEN id="token-61-20" pos="word" morph="none" start_char="7720" end_char="7721">en</TOKEN>
<TOKEN id="token-61-21" pos="word" morph="none" start_char="7723" end_char="7724">la</TOKEN>
<TOKEN id="token-61-22" pos="word" morph="none" start_char="7726" end_char="7735">ingenuidad</TOKEN>
<TOKEN id="token-61-23" pos="word" morph="none" start_char="7737" end_char="7739">que</TOKEN>
<TOKEN id="token-61-24" pos="punct" morph="none" start_char="7740" end_char="7740">,</TOKEN>
<TOKEN id="token-61-25" pos="word" morph="none" start_char="7742" end_char="7743">en</TOKEN>
<TOKEN id="token-61-26" pos="word" morph="none" start_char="7745" end_char="7749">vista</TOKEN>
<TOKEN id="token-61-27" pos="word" morph="none" start_char="7751" end_char="7752">de</TOKEN>
<TOKEN id="token-61-28" pos="word" morph="none" start_char="7754" end_char="7756">los</TOKEN>
<TOKEN id="token-61-29" pos="word" morph="none" start_char="7758" end_char="7772">acontecimientos</TOKEN>
<TOKEN id="token-61-30" pos="punct" morph="none" start_char="7773" end_char="7773">,</TOKEN>
<TOKEN id="token-61-31" pos="word" morph="none" start_char="7775" end_char="7783">cualquier</TOKEN>
<TOKEN id="token-61-32" pos="word" morph="none" start_char="7785" end_char="7795">laboratorio</TOKEN>
<TOKEN id="token-61-33" pos="word" morph="none" start_char="7797" end_char="7807">responsable</TOKEN>
<TOKEN id="token-61-34" pos="word" morph="none" start_char="7809" end_char="7819">articularía</TOKEN>
<TOKEN id="token-61-35" pos="word" morph="none" start_char="7821" end_char="7823">los</TOKEN>
<TOKEN id="token-61-36" pos="word" morph="none" start_char="7825" end_char="7830">medios</TOKEN>
<TOKEN id="token-61-37" pos="word" morph="none" start_char="7832" end_char="7832">a</TOKEN>
<TOKEN id="token-61-38" pos="word" morph="none" start_char="7834" end_char="7835">su</TOKEN>
<TOKEN id="token-61-39" pos="word" morph="none" start_char="7837" end_char="7843">alcance</TOKEN>
<TOKEN id="token-61-40" pos="word" morph="none" start_char="7845" end_char="7848">para</TOKEN>
<TOKEN id="token-61-41" pos="word" morph="none" start_char="7850" end_char="7857">encubrir</TOKEN>
<TOKEN id="token-61-42" pos="word" morph="none" start_char="7859" end_char="7860">su</TOKEN>
<TOKEN id="token-61-43" pos="word" morph="none" start_char="7862" end_char="7876">responsabilidad</TOKEN>
<TOKEN id="token-61-44" pos="punct" morph="none" start_char="7877" end_char="7877">.</TOKEN>
</SEG>
<SEG id="segment-62" start_char="7879" end_char="8029">
<ORIGINAL_TEXT>Quiero creer que el virólogo Roberto Burioni no tiene ninguna vinculación con las experimentaciones, de lo contrario, su interés estaría más que claro.</ORIGINAL_TEXT>
<TOKEN id="token-62-0" pos="word" morph="none" start_char="7879" end_char="7884">Quiero</TOKEN>
<TOKEN id="token-62-1" pos="word" morph="none" start_char="7886" end_char="7890">creer</TOKEN>
<TOKEN id="token-62-2" pos="word" morph="none" start_char="7892" end_char="7894">que</TOKEN>
<TOKEN id="token-62-3" pos="word" morph="none" start_char="7896" end_char="7897">el</TOKEN>
<TOKEN id="token-62-4" pos="word" morph="none" start_char="7899" end_char="7906">virólogo</TOKEN>
<TOKEN id="token-62-5" pos="word" morph="none" start_char="7908" end_char="7914">Roberto</TOKEN>
<TOKEN id="token-62-6" pos="word" morph="none" start_char="7916" end_char="7922">Burioni</TOKEN>
<TOKEN id="token-62-7" pos="word" morph="none" start_char="7924" end_char="7925">no</TOKEN>
<TOKEN id="token-62-8" pos="word" morph="none" start_char="7927" end_char="7931">tiene</TOKEN>
<TOKEN id="token-62-9" pos="word" morph="none" start_char="7933" end_char="7939">ninguna</TOKEN>
<TOKEN id="token-62-10" pos="word" morph="none" start_char="7941" end_char="7951">vinculación</TOKEN>
<TOKEN id="token-62-11" pos="word" morph="none" start_char="7953" end_char="7955">con</TOKEN>
<TOKEN id="token-62-12" pos="word" morph="none" start_char="7957" end_char="7959">las</TOKEN>
<TOKEN id="token-62-13" pos="word" morph="none" start_char="7961" end_char="7977">experimentaciones</TOKEN>
<TOKEN id="token-62-14" pos="punct" morph="none" start_char="7978" end_char="7978">,</TOKEN>
<TOKEN id="token-62-15" pos="word" morph="none" start_char="7980" end_char="7981">de</TOKEN>
<TOKEN id="token-62-16" pos="word" morph="none" start_char="7983" end_char="7984">lo</TOKEN>
<TOKEN id="token-62-17" pos="word" morph="none" start_char="7986" end_char="7994">contrario</TOKEN>
<TOKEN id="token-62-18" pos="punct" morph="none" start_char="7995" end_char="7995">,</TOKEN>
<TOKEN id="token-62-19" pos="word" morph="none" start_char="7997" end_char="7998">su</TOKEN>
<TOKEN id="token-62-20" pos="word" morph="none" start_char="8000" end_char="8006">interés</TOKEN>
<TOKEN id="token-62-21" pos="word" morph="none" start_char="8008" end_char="8014">estaría</TOKEN>
<TOKEN id="token-62-22" pos="word" morph="none" start_char="8016" end_char="8018">más</TOKEN>
<TOKEN id="token-62-23" pos="word" morph="none" start_char="8020" end_char="8022">que</TOKEN>
<TOKEN id="token-62-24" pos="word" morph="none" start_char="8024" end_char="8028">claro</TOKEN>
<TOKEN id="token-62-25" pos="punct" morph="none" start_char="8029" end_char="8029">.</TOKEN>
</SEG>
<SEG id="segment-63" start_char="8031" end_char="8284">
<ORIGINAL_TEXT>En todo caso, no estamos hablando de "conspiranoia", sino de gente que sabe perfectamente que el mundo y la industria farmacéutica no es un liceo de inocentes señoritas quinceañeras, ¿se le puede reprochar a la población la sospecha?, desde luego que no.</ORIGINAL_TEXT>
<TOKEN id="token-63-0" pos="word" morph="none" start_char="8031" end_char="8032">En</TOKEN>
<TOKEN id="token-63-1" pos="word" morph="none" start_char="8034" end_char="8037">todo</TOKEN>
<TOKEN id="token-63-2" pos="word" morph="none" start_char="8039" end_char="8042">caso</TOKEN>
<TOKEN id="token-63-3" pos="punct" morph="none" start_char="8043" end_char="8043">,</TOKEN>
<TOKEN id="token-63-4" pos="word" morph="none" start_char="8045" end_char="8046">no</TOKEN>
<TOKEN id="token-63-5" pos="word" morph="none" start_char="8048" end_char="8054">estamos</TOKEN>
<TOKEN id="token-63-6" pos="word" morph="none" start_char="8056" end_char="8063">hablando</TOKEN>
<TOKEN id="token-63-7" pos="word" morph="none" start_char="8065" end_char="8066">de</TOKEN>
<TOKEN id="token-63-8" pos="punct" morph="none" start_char="8068" end_char="8068">"</TOKEN>
<TOKEN id="token-63-9" pos="word" morph="none" start_char="8069" end_char="8080">conspiranoia</TOKEN>
<TOKEN id="token-63-10" pos="punct" morph="none" start_char="8081" end_char="8082">",</TOKEN>
<TOKEN id="token-63-11" pos="word" morph="none" start_char="8084" end_char="8087">sino</TOKEN>
<TOKEN id="token-63-12" pos="word" morph="none" start_char="8089" end_char="8090">de</TOKEN>
<TOKEN id="token-63-13" pos="word" morph="none" start_char="8092" end_char="8096">gente</TOKEN>
<TOKEN id="token-63-14" pos="word" morph="none" start_char="8098" end_char="8100">que</TOKEN>
<TOKEN id="token-63-15" pos="word" morph="none" start_char="8102" end_char="8105">sabe</TOKEN>
<TOKEN id="token-63-16" pos="word" morph="none" start_char="8107" end_char="8119">perfectamente</TOKEN>
<TOKEN id="token-63-17" pos="word" morph="none" start_char="8121" end_char="8123">que</TOKEN>
<TOKEN id="token-63-18" pos="word" morph="none" start_char="8125" end_char="8126">el</TOKEN>
<TOKEN id="token-63-19" pos="word" morph="none" start_char="8128" end_char="8132">mundo</TOKEN>
<TOKEN id="token-63-20" pos="word" morph="none" start_char="8134" end_char="8134">y</TOKEN>
<TOKEN id="token-63-21" pos="word" morph="none" start_char="8136" end_char="8137">la</TOKEN>
<TOKEN id="token-63-22" pos="word" morph="none" start_char="8139" end_char="8147">industria</TOKEN>
<TOKEN id="token-63-23" pos="word" morph="none" start_char="8149" end_char="8160">farmacéutica</TOKEN>
<TOKEN id="token-63-24" pos="word" morph="none" start_char="8162" end_char="8163">no</TOKEN>
<TOKEN id="token-63-25" pos="word" morph="none" start_char="8165" end_char="8166">es</TOKEN>
<TOKEN id="token-63-26" pos="word" morph="none" start_char="8168" end_char="8169">un</TOKEN>
<TOKEN id="token-63-27" pos="word" morph="none" start_char="8171" end_char="8175">liceo</TOKEN>
<TOKEN id="token-63-28" pos="word" morph="none" start_char="8177" end_char="8178">de</TOKEN>
<TOKEN id="token-63-29" pos="word" morph="none" start_char="8180" end_char="8188">inocentes</TOKEN>
<TOKEN id="token-63-30" pos="word" morph="none" start_char="8190" end_char="8198">señoritas</TOKEN>
<TOKEN id="token-63-31" pos="word" morph="none" start_char="8200" end_char="8211">quinceañeras</TOKEN>
<TOKEN id="token-63-32" pos="punct" morph="none" start_char="8212" end_char="8212">,</TOKEN>
<TOKEN id="token-63-33" pos="punct" morph="none" start_char="8214" end_char="8214">¿</TOKEN>
<TOKEN id="token-63-34" pos="word" morph="none" start_char="8215" end_char="8216">se</TOKEN>
<TOKEN id="token-63-35" pos="word" morph="none" start_char="8218" end_char="8219">le</TOKEN>
<TOKEN id="token-63-36" pos="word" morph="none" start_char="8221" end_char="8225">puede</TOKEN>
<TOKEN id="token-63-37" pos="word" morph="none" start_char="8227" end_char="8235">reprochar</TOKEN>
<TOKEN id="token-63-38" pos="word" morph="none" start_char="8237" end_char="8237">a</TOKEN>
<TOKEN id="token-63-39" pos="word" morph="none" start_char="8239" end_char="8240">la</TOKEN>
<TOKEN id="token-63-40" pos="word" morph="none" start_char="8242" end_char="8250">población</TOKEN>
<TOKEN id="token-63-41" pos="word" morph="none" start_char="8252" end_char="8253">la</TOKEN>
<TOKEN id="token-63-42" pos="word" morph="none" start_char="8255" end_char="8262">sospecha</TOKEN>
<TOKEN id="token-63-43" pos="punct" morph="none" start_char="8263" end_char="8264">?,</TOKEN>
<TOKEN id="token-63-44" pos="word" morph="none" start_char="8266" end_char="8270">desde</TOKEN>
<TOKEN id="token-63-45" pos="word" morph="none" start_char="8272" end_char="8276">luego</TOKEN>
<TOKEN id="token-63-46" pos="word" morph="none" start_char="8278" end_char="8280">que</TOKEN>
<TOKEN id="token-63-47" pos="word" morph="none" start_char="8282" end_char="8283">no</TOKEN>
<TOKEN id="token-63-48" pos="punct" morph="none" start_char="8284" end_char="8284">.</TOKEN>
</SEG>
<SEG id="segment-64" start_char="8288" end_char="8492">
<ORIGINAL_TEXT>El virus de la gripe lo cambian cada año para que sea mas virulento ,para hacer nuevas vacunas asi ganan dinero estos sin verguenzas ,quien se cree que la naturaleza va a dispersar un virus asi de la nada?</ORIGINAL_TEXT>
<TOKEN id="token-64-0" pos="word" morph="none" start_char="8288" end_char="8289">El</TOKEN>
<TOKEN id="token-64-1" pos="word" morph="none" start_char="8291" end_char="8295">virus</TOKEN>
<TOKEN id="token-64-2" pos="word" morph="none" start_char="8297" end_char="8298">de</TOKEN>
<TOKEN id="token-64-3" pos="word" morph="none" start_char="8300" end_char="8301">la</TOKEN>
<TOKEN id="token-64-4" pos="word" morph="none" start_char="8303" end_char="8307">gripe</TOKEN>
<TOKEN id="token-64-5" pos="word" morph="none" start_char="8309" end_char="8310">lo</TOKEN>
<TOKEN id="token-64-6" pos="word" morph="none" start_char="8312" end_char="8318">cambian</TOKEN>
<TOKEN id="token-64-7" pos="word" morph="none" start_char="8320" end_char="8323">cada</TOKEN>
<TOKEN id="token-64-8" pos="word" morph="none" start_char="8325" end_char="8327">año</TOKEN>
<TOKEN id="token-64-9" pos="word" morph="none" start_char="8329" end_char="8332">para</TOKEN>
<TOKEN id="token-64-10" pos="word" morph="none" start_char="8334" end_char="8336">que</TOKEN>
<TOKEN id="token-64-11" pos="word" morph="none" start_char="8338" end_char="8340">sea</TOKEN>
<TOKEN id="token-64-12" pos="word" morph="none" start_char="8342" end_char="8344">mas</TOKEN>
<TOKEN id="token-64-13" pos="word" morph="none" start_char="8346" end_char="8354">virulento</TOKEN>
<TOKEN id="token-64-14" pos="punct" morph="none" start_char="8356" end_char="8356">,</TOKEN>
<TOKEN id="token-64-15" pos="word" morph="none" start_char="8357" end_char="8360">para</TOKEN>
<TOKEN id="token-64-16" pos="word" morph="none" start_char="8362" end_char="8366">hacer</TOKEN>
<TOKEN id="token-64-17" pos="word" morph="none" start_char="8368" end_char="8373">nuevas</TOKEN>
<TOKEN id="token-64-18" pos="word" morph="none" start_char="8375" end_char="8381">vacunas</TOKEN>
<TOKEN id="token-64-19" pos="word" morph="none" start_char="8383" end_char="8385">asi</TOKEN>
<TOKEN id="token-64-20" pos="word" morph="none" start_char="8387" end_char="8391">ganan</TOKEN>
<TOKEN id="token-64-21" pos="word" morph="none" start_char="8393" end_char="8398">dinero</TOKEN>
<TOKEN id="token-64-22" pos="word" morph="none" start_char="8400" end_char="8404">estos</TOKEN>
<TOKEN id="token-64-23" pos="word" morph="none" start_char="8406" end_char="8408">sin</TOKEN>
<TOKEN id="token-64-24" pos="word" morph="none" start_char="8410" end_char="8419">verguenzas</TOKEN>
<TOKEN id="token-64-25" pos="punct" morph="none" start_char="8421" end_char="8421">,</TOKEN>
<TOKEN id="token-64-26" pos="word" morph="none" start_char="8422" end_char="8426">quien</TOKEN>
<TOKEN id="token-64-27" pos="word" morph="none" start_char="8428" end_char="8429">se</TOKEN>
<TOKEN id="token-64-28" pos="word" morph="none" start_char="8431" end_char="8434">cree</TOKEN>
<TOKEN id="token-64-29" pos="word" morph="none" start_char="8436" end_char="8438">que</TOKEN>
<TOKEN id="token-64-30" pos="word" morph="none" start_char="8440" end_char="8441">la</TOKEN>
<TOKEN id="token-64-31" pos="word" morph="none" start_char="8443" end_char="8452">naturaleza</TOKEN>
<TOKEN id="token-64-32" pos="word" morph="none" start_char="8454" end_char="8455">va</TOKEN>
<TOKEN id="token-64-33" pos="word" morph="none" start_char="8457" end_char="8457">a</TOKEN>
<TOKEN id="token-64-34" pos="word" morph="none" start_char="8459" end_char="8467">dispersar</TOKEN>
<TOKEN id="token-64-35" pos="word" morph="none" start_char="8469" end_char="8470">un</TOKEN>
<TOKEN id="token-64-36" pos="word" morph="none" start_char="8472" end_char="8476">virus</TOKEN>
<TOKEN id="token-64-37" pos="word" morph="none" start_char="8478" end_char="8480">asi</TOKEN>
<TOKEN id="token-64-38" pos="word" morph="none" start_char="8482" end_char="8483">de</TOKEN>
<TOKEN id="token-64-39" pos="word" morph="none" start_char="8485" end_char="8486">la</TOKEN>
<TOKEN id="token-64-40" pos="word" morph="none" start_char="8488" end_char="8491">nada</TOKEN>
<TOKEN id="token-64-41" pos="punct" morph="none" start_char="8492" end_char="8492">?</TOKEN>
</SEG>
<SEG id="segment-65" start_char="8494" end_char="8817">
<ORIGINAL_TEXT>?yo no me lo creo es tan factible eso como de que mañana seamos todos millonarios ,los laboratorios estan blindados con el poder politico esa es la clave por eso nunca se admitira que salio de un laboratorio pero todo lo que se lleva echo desde hace años ha salido de laboratorios para muchas cosas que antes no se sabian !!</ORIGINAL_TEXT>
<TOKEN id="token-65-0" pos="punct" morph="none" start_char="8494" end_char="8494">?</TOKEN>
<TOKEN id="token-65-1" pos="word" morph="none" start_char="8495" end_char="8496">yo</TOKEN>
<TOKEN id="token-65-2" pos="word" morph="none" start_char="8498" end_char="8499">no</TOKEN>
<TOKEN id="token-65-3" pos="word" morph="none" start_char="8501" end_char="8502">me</TOKEN>
<TOKEN id="token-65-4" pos="word" morph="none" start_char="8504" end_char="8505">lo</TOKEN>
<TOKEN id="token-65-5" pos="word" morph="none" start_char="8507" end_char="8510">creo</TOKEN>
<TOKEN id="token-65-6" pos="word" morph="none" start_char="8512" end_char="8513">es</TOKEN>
<TOKEN id="token-65-7" pos="word" morph="none" start_char="8515" end_char="8517">tan</TOKEN>
<TOKEN id="token-65-8" pos="word" morph="none" start_char="8519" end_char="8526">factible</TOKEN>
<TOKEN id="token-65-9" pos="word" morph="none" start_char="8528" end_char="8530">eso</TOKEN>
<TOKEN id="token-65-10" pos="word" morph="none" start_char="8532" end_char="8535">como</TOKEN>
<TOKEN id="token-65-11" pos="word" morph="none" start_char="8537" end_char="8538">de</TOKEN>
<TOKEN id="token-65-12" pos="word" morph="none" start_char="8540" end_char="8542">que</TOKEN>
<TOKEN id="token-65-13" pos="word" morph="none" start_char="8544" end_char="8549">mañana</TOKEN>
<TOKEN id="token-65-14" pos="word" morph="none" start_char="8551" end_char="8556">seamos</TOKEN>
<TOKEN id="token-65-15" pos="word" morph="none" start_char="8558" end_char="8562">todos</TOKEN>
<TOKEN id="token-65-16" pos="word" morph="none" start_char="8564" end_char="8574">millonarios</TOKEN>
<TOKEN id="token-65-17" pos="punct" morph="none" start_char="8576" end_char="8576">,</TOKEN>
<TOKEN id="token-65-18" pos="word" morph="none" start_char="8577" end_char="8579">los</TOKEN>
<TOKEN id="token-65-19" pos="word" morph="none" start_char="8581" end_char="8592">laboratorios</TOKEN>
<TOKEN id="token-65-20" pos="word" morph="none" start_char="8594" end_char="8598">estan</TOKEN>
<TOKEN id="token-65-21" pos="word" morph="none" start_char="8600" end_char="8608">blindados</TOKEN>
<TOKEN id="token-65-22" pos="word" morph="none" start_char="8610" end_char="8612">con</TOKEN>
<TOKEN id="token-65-23" pos="word" morph="none" start_char="8614" end_char="8615">el</TOKEN>
<TOKEN id="token-65-24" pos="word" morph="none" start_char="8617" end_char="8621">poder</TOKEN>
<TOKEN id="token-65-25" pos="word" morph="none" start_char="8623" end_char="8630">politico</TOKEN>
<TOKEN id="token-65-26" pos="word" morph="none" start_char="8632" end_char="8634">esa</TOKEN>
<TOKEN id="token-65-27" pos="word" morph="none" start_char="8636" end_char="8637">es</TOKEN>
<TOKEN id="token-65-28" pos="word" morph="none" start_char="8639" end_char="8640">la</TOKEN>
<TOKEN id="token-65-29" pos="word" morph="none" start_char="8642" end_char="8646">clave</TOKEN>
<TOKEN id="token-65-30" pos="word" morph="none" start_char="8648" end_char="8650">por</TOKEN>
<TOKEN id="token-65-31" pos="word" morph="none" start_char="8652" end_char="8654">eso</TOKEN>
<TOKEN id="token-65-32" pos="word" morph="none" start_char="8656" end_char="8660">nunca</TOKEN>
<TOKEN id="token-65-33" pos="word" morph="none" start_char="8662" end_char="8663">se</TOKEN>
<TOKEN id="token-65-34" pos="word" morph="none" start_char="8665" end_char="8672">admitira</TOKEN>
<TOKEN id="token-65-35" pos="word" morph="none" start_char="8674" end_char="8676">que</TOKEN>
<TOKEN id="token-65-36" pos="word" morph="none" start_char="8678" end_char="8682">salio</TOKEN>
<TOKEN id="token-65-37" pos="word" morph="none" start_char="8684" end_char="8685">de</TOKEN>
<TOKEN id="token-65-38" pos="word" morph="none" start_char="8687" end_char="8688">un</TOKEN>
<TOKEN id="token-65-39" pos="word" morph="none" start_char="8690" end_char="8700">laboratorio</TOKEN>
<TOKEN id="token-65-40" pos="word" morph="none" start_char="8702" end_char="8705">pero</TOKEN>
<TOKEN id="token-65-41" pos="word" morph="none" start_char="8707" end_char="8710">todo</TOKEN>
<TOKEN id="token-65-42" pos="word" morph="none" start_char="8712" end_char="8713">lo</TOKEN>
<TOKEN id="token-65-43" pos="word" morph="none" start_char="8715" end_char="8717">que</TOKEN>
<TOKEN id="token-65-44" pos="word" morph="none" start_char="8719" end_char="8720">se</TOKEN>
<TOKEN id="token-65-45" pos="word" morph="none" start_char="8722" end_char="8726">lleva</TOKEN>
<TOKEN id="token-65-46" pos="word" morph="none" start_char="8728" end_char="8731">echo</TOKEN>
<TOKEN id="token-65-47" pos="word" morph="none" start_char="8733" end_char="8737">desde</TOKEN>
<TOKEN id="token-65-48" pos="word" morph="none" start_char="8739" end_char="8742">hace</TOKEN>
<TOKEN id="token-65-49" pos="word" morph="none" start_char="8744" end_char="8747">años</TOKEN>
<TOKEN id="token-65-50" pos="word" morph="none" start_char="8749" end_char="8750">ha</TOKEN>
<TOKEN id="token-65-51" pos="word" morph="none" start_char="8752" end_char="8757">salido</TOKEN>
<TOKEN id="token-65-52" pos="word" morph="none" start_char="8759" end_char="8760">de</TOKEN>
<TOKEN id="token-65-53" pos="word" morph="none" start_char="8762" end_char="8773">laboratorios</TOKEN>
<TOKEN id="token-65-54" pos="word" morph="none" start_char="8775" end_char="8778">para</TOKEN>
<TOKEN id="token-65-55" pos="word" morph="none" start_char="8780" end_char="8785">muchas</TOKEN>
<TOKEN id="token-65-56" pos="word" morph="none" start_char="8787" end_char="8791">cosas</TOKEN>
<TOKEN id="token-65-57" pos="word" morph="none" start_char="8793" end_char="8795">que</TOKEN>
<TOKEN id="token-65-58" pos="word" morph="none" start_char="8797" end_char="8801">antes</TOKEN>
<TOKEN id="token-65-59" pos="word" morph="none" start_char="8803" end_char="8804">no</TOKEN>
<TOKEN id="token-65-60" pos="word" morph="none" start_char="8806" end_char="8807">se</TOKEN>
<TOKEN id="token-65-61" pos="word" morph="none" start_char="8809" end_char="8814">sabian</TOKEN>
<TOKEN id="token-65-62" pos="punct" morph="none" start_char="8816" end_char="8817">!!</TOKEN>
</SEG>
<SEG id="segment-66" start_char="8821" end_char="8908">
<ORIGINAL_TEXT>Esto es como la maquinaria del gobierno, diciendo ellos lo que es verdad y no es verdad.</ORIGINAL_TEXT>
<TOKEN id="token-66-0" pos="word" morph="none" start_char="8821" end_char="8824">Esto</TOKEN>
<TOKEN id="token-66-1" pos="word" morph="none" start_char="8826" end_char="8827">es</TOKEN>
<TOKEN id="token-66-2" pos="word" morph="none" start_char="8829" end_char="8832">como</TOKEN>
<TOKEN id="token-66-3" pos="word" morph="none" start_char="8834" end_char="8835">la</TOKEN>
<TOKEN id="token-66-4" pos="word" morph="none" start_char="8837" end_char="8846">maquinaria</TOKEN>
<TOKEN id="token-66-5" pos="word" morph="none" start_char="8848" end_char="8850">del</TOKEN>
<TOKEN id="token-66-6" pos="word" morph="none" start_char="8852" end_char="8859">gobierno</TOKEN>
<TOKEN id="token-66-7" pos="punct" morph="none" start_char="8860" end_char="8860">,</TOKEN>
<TOKEN id="token-66-8" pos="word" morph="none" start_char="8862" end_char="8869">diciendo</TOKEN>
<TOKEN id="token-66-9" pos="word" morph="none" start_char="8871" end_char="8875">ellos</TOKEN>
<TOKEN id="token-66-10" pos="word" morph="none" start_char="8877" end_char="8878">lo</TOKEN>
<TOKEN id="token-66-11" pos="word" morph="none" start_char="8880" end_char="8882">que</TOKEN>
<TOKEN id="token-66-12" pos="word" morph="none" start_char="8884" end_char="8885">es</TOKEN>
<TOKEN id="token-66-13" pos="word" morph="none" start_char="8887" end_char="8892">verdad</TOKEN>
<TOKEN id="token-66-14" pos="word" morph="none" start_char="8894" end_char="8894">y</TOKEN>
<TOKEN id="token-66-15" pos="word" morph="none" start_char="8896" end_char="8897">no</TOKEN>
<TOKEN id="token-66-16" pos="word" morph="none" start_char="8899" end_char="8900">es</TOKEN>
<TOKEN id="token-66-17" pos="word" morph="none" start_char="8902" end_char="8907">verdad</TOKEN>
<TOKEN id="token-66-18" pos="punct" morph="none" start_char="8908" end_char="8908">.</TOKEN>
</SEG>
<SEG id="segment-67" start_char="8910" end_char="9058">
<ORIGINAL_TEXT>Este virus es de laboratorio el que no vea eso es tonto, otra cosa es que logicamente su origen es del murcielago, es la materia prima que han usado.</ORIGINAL_TEXT>
<TOKEN id="token-67-0" pos="word" morph="none" start_char="8910" end_char="8913">Este</TOKEN>
<TOKEN id="token-67-1" pos="word" morph="none" start_char="8915" end_char="8919">virus</TOKEN>
<TOKEN id="token-67-2" pos="word" morph="none" start_char="8921" end_char="8922">es</TOKEN>
<TOKEN id="token-67-3" pos="word" morph="none" start_char="8924" end_char="8925">de</TOKEN>
<TOKEN id="token-67-4" pos="word" morph="none" start_char="8927" end_char="8937">laboratorio</TOKEN>
<TOKEN id="token-67-5" pos="word" morph="none" start_char="8939" end_char="8940">el</TOKEN>
<TOKEN id="token-67-6" pos="word" morph="none" start_char="8942" end_char="8944">que</TOKEN>
<TOKEN id="token-67-7" pos="word" morph="none" start_char="8946" end_char="8947">no</TOKEN>
<TOKEN id="token-67-8" pos="word" morph="none" start_char="8949" end_char="8951">vea</TOKEN>
<TOKEN id="token-67-9" pos="word" morph="none" start_char="8953" end_char="8955">eso</TOKEN>
<TOKEN id="token-67-10" pos="word" morph="none" start_char="8957" end_char="8958">es</TOKEN>
<TOKEN id="token-67-11" pos="word" morph="none" start_char="8960" end_char="8964">tonto</TOKEN>
<TOKEN id="token-67-12" pos="punct" morph="none" start_char="8965" end_char="8965">,</TOKEN>
<TOKEN id="token-67-13" pos="word" morph="none" start_char="8967" end_char="8970">otra</TOKEN>
<TOKEN id="token-67-14" pos="word" morph="none" start_char="8972" end_char="8975">cosa</TOKEN>
<TOKEN id="token-67-15" pos="word" morph="none" start_char="8977" end_char="8978">es</TOKEN>
<TOKEN id="token-67-16" pos="word" morph="none" start_char="8980" end_char="8982">que</TOKEN>
<TOKEN id="token-67-17" pos="word" morph="none" start_char="8984" end_char="8994">logicamente</TOKEN>
<TOKEN id="token-67-18" pos="word" morph="none" start_char="8996" end_char="8997">su</TOKEN>
<TOKEN id="token-67-19" pos="word" morph="none" start_char="8999" end_char="9004">origen</TOKEN>
<TOKEN id="token-67-20" pos="word" morph="none" start_char="9006" end_char="9007">es</TOKEN>
<TOKEN id="token-67-21" pos="word" morph="none" start_char="9009" end_char="9011">del</TOKEN>
<TOKEN id="token-67-22" pos="word" morph="none" start_char="9013" end_char="9022">murcielago</TOKEN>
<TOKEN id="token-67-23" pos="punct" morph="none" start_char="9023" end_char="9023">,</TOKEN>
<TOKEN id="token-67-24" pos="word" morph="none" start_char="9025" end_char="9026">es</TOKEN>
<TOKEN id="token-67-25" pos="word" morph="none" start_char="9028" end_char="9029">la</TOKEN>
<TOKEN id="token-67-26" pos="word" morph="none" start_char="9031" end_char="9037">materia</TOKEN>
<TOKEN id="token-67-27" pos="word" morph="none" start_char="9039" end_char="9043">prima</TOKEN>
<TOKEN id="token-67-28" pos="word" morph="none" start_char="9045" end_char="9047">que</TOKEN>
<TOKEN id="token-67-29" pos="word" morph="none" start_char="9049" end_char="9051">han</TOKEN>
<TOKEN id="token-67-30" pos="word" morph="none" start_char="9053" end_char="9057">usado</TOKEN>
<TOKEN id="token-67-31" pos="punct" morph="none" start_char="9058" end_char="9058">.</TOKEN>
</SEG>
<SEG id="segment-68" start_char="9060" end_char="9213">
<ORIGINAL_TEXT>Hay muchos indicios que apuntan a eso pero la maquinaria propagandistica está desmintiendo que eso es así, pero no pueden para lo que es más que evidente.</ORIGINAL_TEXT>
<TOKEN id="token-68-0" pos="word" morph="none" start_char="9060" end_char="9062">Hay</TOKEN>
<TOKEN id="token-68-1" pos="word" morph="none" start_char="9064" end_char="9069">muchos</TOKEN>
<TOKEN id="token-68-2" pos="word" morph="none" start_char="9071" end_char="9078">indicios</TOKEN>
<TOKEN id="token-68-3" pos="word" morph="none" start_char="9080" end_char="9082">que</TOKEN>
<TOKEN id="token-68-4" pos="word" morph="none" start_char="9084" end_char="9090">apuntan</TOKEN>
<TOKEN id="token-68-5" pos="word" morph="none" start_char="9092" end_char="9092">a</TOKEN>
<TOKEN id="token-68-6" pos="word" morph="none" start_char="9094" end_char="9096">eso</TOKEN>
<TOKEN id="token-68-7" pos="word" morph="none" start_char="9098" end_char="9101">pero</TOKEN>
<TOKEN id="token-68-8" pos="word" morph="none" start_char="9103" end_char="9104">la</TOKEN>
<TOKEN id="token-68-9" pos="word" morph="none" start_char="9106" end_char="9115">maquinaria</TOKEN>
<TOKEN id="token-68-10" pos="word" morph="none" start_char="9117" end_char="9131">propagandistica</TOKEN>
<TOKEN id="token-68-11" pos="word" morph="none" start_char="9133" end_char="9136">está</TOKEN>
<TOKEN id="token-68-12" pos="word" morph="none" start_char="9138" end_char="9149">desmintiendo</TOKEN>
<TOKEN id="token-68-13" pos="word" morph="none" start_char="9151" end_char="9153">que</TOKEN>
<TOKEN id="token-68-14" pos="word" morph="none" start_char="9155" end_char="9157">eso</TOKEN>
<TOKEN id="token-68-15" pos="word" morph="none" start_char="9159" end_char="9160">es</TOKEN>
<TOKEN id="token-68-16" pos="word" morph="none" start_char="9162" end_char="9164">así</TOKEN>
<TOKEN id="token-68-17" pos="punct" morph="none" start_char="9165" end_char="9165">,</TOKEN>
<TOKEN id="token-68-18" pos="word" morph="none" start_char="9167" end_char="9170">pero</TOKEN>
<TOKEN id="token-68-19" pos="word" morph="none" start_char="9172" end_char="9173">no</TOKEN>
<TOKEN id="token-68-20" pos="word" morph="none" start_char="9175" end_char="9180">pueden</TOKEN>
<TOKEN id="token-68-21" pos="word" morph="none" start_char="9182" end_char="9185">para</TOKEN>
<TOKEN id="token-68-22" pos="word" morph="none" start_char="9187" end_char="9188">lo</TOKEN>
<TOKEN id="token-68-23" pos="word" morph="none" start_char="9190" end_char="9192">que</TOKEN>
<TOKEN id="token-68-24" pos="word" morph="none" start_char="9194" end_char="9195">es</TOKEN>
<TOKEN id="token-68-25" pos="word" morph="none" start_char="9197" end_char="9199">más</TOKEN>
<TOKEN id="token-68-26" pos="word" morph="none" start_char="9201" end_char="9203">que</TOKEN>
<TOKEN id="token-68-27" pos="word" morph="none" start_char="9205" end_char="9212">evidente</TOKEN>
<TOKEN id="token-68-28" pos="punct" morph="none" start_char="9213" end_char="9213">.</TOKEN>
</SEG>
<SEG id="segment-69" start_char="9217" end_char="9322">
<ORIGINAL_TEXT>El hecho de que en Wuhan donde hay un laboratorio que trabaja con este tipo de virus da pie a la sospecha.</ORIGINAL_TEXT>
<TOKEN id="token-69-0" pos="word" morph="none" start_char="9217" end_char="9218">El</TOKEN>
<TOKEN id="token-69-1" pos="word" morph="none" start_char="9220" end_char="9224">hecho</TOKEN>
<TOKEN id="token-69-2" pos="word" morph="none" start_char="9226" end_char="9227">de</TOKEN>
<TOKEN id="token-69-3" pos="word" morph="none" start_char="9229" end_char="9231">que</TOKEN>
<TOKEN id="token-69-4" pos="word" morph="none" start_char="9233" end_char="9234">en</TOKEN>
<TOKEN id="token-69-5" pos="word" morph="none" start_char="9236" end_char="9240">Wuhan</TOKEN>
<TOKEN id="token-69-6" pos="word" morph="none" start_char="9242" end_char="9246">donde</TOKEN>
<TOKEN id="token-69-7" pos="word" morph="none" start_char="9248" end_char="9250">hay</TOKEN>
<TOKEN id="token-69-8" pos="word" morph="none" start_char="9252" end_char="9253">un</TOKEN>
<TOKEN id="token-69-9" pos="word" morph="none" start_char="9255" end_char="9265">laboratorio</TOKEN>
<TOKEN id="token-69-10" pos="word" morph="none" start_char="9267" end_char="9269">que</TOKEN>
<TOKEN id="token-69-11" pos="word" morph="none" start_char="9271" end_char="9277">trabaja</TOKEN>
<TOKEN id="token-69-12" pos="word" morph="none" start_char="9279" end_char="9281">con</TOKEN>
<TOKEN id="token-69-13" pos="word" morph="none" start_char="9283" end_char="9286">este</TOKEN>
<TOKEN id="token-69-14" pos="word" morph="none" start_char="9288" end_char="9291">tipo</TOKEN>
<TOKEN id="token-69-15" pos="word" morph="none" start_char="9293" end_char="9294">de</TOKEN>
<TOKEN id="token-69-16" pos="word" morph="none" start_char="9296" end_char="9300">virus</TOKEN>
<TOKEN id="token-69-17" pos="word" morph="none" start_char="9302" end_char="9303">da</TOKEN>
<TOKEN id="token-69-18" pos="word" morph="none" start_char="9305" end_char="9307">pie</TOKEN>
<TOKEN id="token-69-19" pos="word" morph="none" start_char="9309" end_char="9309">a</TOKEN>
<TOKEN id="token-69-20" pos="word" morph="none" start_char="9311" end_char="9312">la</TOKEN>
<TOKEN id="token-69-21" pos="word" morph="none" start_char="9314" end_char="9321">sospecha</TOKEN>
<TOKEN id="token-69-22" pos="punct" morph="none" start_char="9322" end_char="9322">.</TOKEN>
</SEG>
<SEG id="segment-70" start_char="9324" end_char="9425">
<ORIGINAL_TEXT>Es difícil establecer el origen, de momento no hay una conclusión cierta ¿porqué no pudo salir de ahí?</ORIGINAL_TEXT>
<TOKEN id="token-70-0" pos="word" morph="none" start_char="9324" end_char="9325">Es</TOKEN>
<TOKEN id="token-70-1" pos="word" morph="none" start_char="9327" end_char="9333">difícil</TOKEN>
<TOKEN id="token-70-2" pos="word" morph="none" start_char="9335" end_char="9344">establecer</TOKEN>
<TOKEN id="token-70-3" pos="word" morph="none" start_char="9346" end_char="9347">el</TOKEN>
<TOKEN id="token-70-4" pos="word" morph="none" start_char="9349" end_char="9354">origen</TOKEN>
<TOKEN id="token-70-5" pos="punct" morph="none" start_char="9355" end_char="9355">,</TOKEN>
<TOKEN id="token-70-6" pos="word" morph="none" start_char="9357" end_char="9358">de</TOKEN>
<TOKEN id="token-70-7" pos="word" morph="none" start_char="9360" end_char="9366">momento</TOKEN>
<TOKEN id="token-70-8" pos="word" morph="none" start_char="9368" end_char="9369">no</TOKEN>
<TOKEN id="token-70-9" pos="word" morph="none" start_char="9371" end_char="9373">hay</TOKEN>
<TOKEN id="token-70-10" pos="word" morph="none" start_char="9375" end_char="9377">una</TOKEN>
<TOKEN id="token-70-11" pos="word" morph="none" start_char="9379" end_char="9388">conclusión</TOKEN>
<TOKEN id="token-70-12" pos="word" morph="none" start_char="9390" end_char="9395">cierta</TOKEN>
<TOKEN id="token-70-13" pos="punct" morph="none" start_char="9397" end_char="9397">¿</TOKEN>
<TOKEN id="token-70-14" pos="word" morph="none" start_char="9398" end_char="9403">porqué</TOKEN>
<TOKEN id="token-70-15" pos="word" morph="none" start_char="9405" end_char="9406">no</TOKEN>
<TOKEN id="token-70-16" pos="word" morph="none" start_char="9408" end_char="9411">pudo</TOKEN>
<TOKEN id="token-70-17" pos="word" morph="none" start_char="9413" end_char="9417">salir</TOKEN>
<TOKEN id="token-70-18" pos="word" morph="none" start_char="9419" end_char="9420">de</TOKEN>
<TOKEN id="token-70-19" pos="word" morph="none" start_char="9422" end_char="9424">ahí</TOKEN>
<TOKEN id="token-70-20" pos="punct" morph="none" start_char="9425" end_char="9425">?</TOKEN>
</SEG>
<SEG id="segment-71" start_char="9429" end_char="9640">
<ORIGINAL_TEXT>No nada oculto que no pueda ser descubierto en el mundo, tarde o temprano, más temprano que tarde sabremos si covid-19 es producto de la casualidad, o producto de la mentes más infames que existe en esta planeta.</ORIGINAL_TEXT>
<TOKEN id="token-71-0" pos="word" morph="none" start_char="9429" end_char="9430">No</TOKEN>
<TOKEN id="token-71-1" pos="word" morph="none" start_char="9432" end_char="9435">nada</TOKEN>
<TOKEN id="token-71-2" pos="word" morph="none" start_char="9437" end_char="9442">oculto</TOKEN>
<TOKEN id="token-71-3" pos="word" morph="none" start_char="9444" end_char="9446">que</TOKEN>
<TOKEN id="token-71-4" pos="word" morph="none" start_char="9448" end_char="9449">no</TOKEN>
<TOKEN id="token-71-5" pos="word" morph="none" start_char="9451" end_char="9455">pueda</TOKEN>
<TOKEN id="token-71-6" pos="word" morph="none" start_char="9457" end_char="9459">ser</TOKEN>
<TOKEN id="token-71-7" pos="word" morph="none" start_char="9461" end_char="9471">descubierto</TOKEN>
<TOKEN id="token-71-8" pos="word" morph="none" start_char="9473" end_char="9474">en</TOKEN>
<TOKEN id="token-71-9" pos="word" morph="none" start_char="9476" end_char="9477">el</TOKEN>
<TOKEN id="token-71-10" pos="word" morph="none" start_char="9479" end_char="9483">mundo</TOKEN>
<TOKEN id="token-71-11" pos="punct" morph="none" start_char="9484" end_char="9484">,</TOKEN>
<TOKEN id="token-71-12" pos="word" morph="none" start_char="9486" end_char="9490">tarde</TOKEN>
<TOKEN id="token-71-13" pos="word" morph="none" start_char="9492" end_char="9492">o</TOKEN>
<TOKEN id="token-71-14" pos="word" morph="none" start_char="9494" end_char="9501">temprano</TOKEN>
<TOKEN id="token-71-15" pos="punct" morph="none" start_char="9502" end_char="9502">,</TOKEN>
<TOKEN id="token-71-16" pos="word" morph="none" start_char="9504" end_char="9506">más</TOKEN>
<TOKEN id="token-71-17" pos="word" morph="none" start_char="9508" end_char="9515">temprano</TOKEN>
<TOKEN id="token-71-18" pos="word" morph="none" start_char="9517" end_char="9519">que</TOKEN>
<TOKEN id="token-71-19" pos="word" morph="none" start_char="9521" end_char="9525">tarde</TOKEN>
<TOKEN id="token-71-20" pos="word" morph="none" start_char="9527" end_char="9534">sabremos</TOKEN>
<TOKEN id="token-71-21" pos="word" morph="none" start_char="9536" end_char="9537">si</TOKEN>
<TOKEN id="token-71-22" pos="unknown" morph="none" start_char="9539" end_char="9546">covid-19</TOKEN>
<TOKEN id="token-71-23" pos="word" morph="none" start_char="9548" end_char="9549">es</TOKEN>
<TOKEN id="token-71-24" pos="word" morph="none" start_char="9551" end_char="9558">producto</TOKEN>
<TOKEN id="token-71-25" pos="word" morph="none" start_char="9560" end_char="9561">de</TOKEN>
<TOKEN id="token-71-26" pos="word" morph="none" start_char="9563" end_char="9564">la</TOKEN>
<TOKEN id="token-71-27" pos="word" morph="none" start_char="9566" end_char="9575">casualidad</TOKEN>
<TOKEN id="token-71-28" pos="punct" morph="none" start_char="9576" end_char="9576">,</TOKEN>
<TOKEN id="token-71-29" pos="word" morph="none" start_char="9578" end_char="9578">o</TOKEN>
<TOKEN id="token-71-30" pos="word" morph="none" start_char="9580" end_char="9587">producto</TOKEN>
<TOKEN id="token-71-31" pos="word" morph="none" start_char="9589" end_char="9590">de</TOKEN>
<TOKEN id="token-71-32" pos="word" morph="none" start_char="9592" end_char="9593">la</TOKEN>
<TOKEN id="token-71-33" pos="word" morph="none" start_char="9595" end_char="9600">mentes</TOKEN>
<TOKEN id="token-71-34" pos="word" morph="none" start_char="9602" end_char="9604">más</TOKEN>
<TOKEN id="token-71-35" pos="word" morph="none" start_char="9606" end_char="9612">infames</TOKEN>
<TOKEN id="token-71-36" pos="word" morph="none" start_char="9614" end_char="9616">que</TOKEN>
<TOKEN id="token-71-37" pos="word" morph="none" start_char="9618" end_char="9623">existe</TOKEN>
<TOKEN id="token-71-38" pos="word" morph="none" start_char="9625" end_char="9626">en</TOKEN>
<TOKEN id="token-71-39" pos="word" morph="none" start_char="9628" end_char="9631">esta</TOKEN>
<TOKEN id="token-71-40" pos="word" morph="none" start_char="9633" end_char="9639">planeta</TOKEN>
<TOKEN id="token-71-41" pos="punct" morph="none" start_char="9640" end_char="9640">.</TOKEN>
</SEG>
<SEG id="segment-72" start_char="9642" end_char="9740">
<ORIGINAL_TEXT>Porque hay gente malvada que quiere llegar al dominio total de la humanidad, en todos los aspectos.</ORIGINAL_TEXT>
<TOKEN id="token-72-0" pos="word" morph="none" start_char="9642" end_char="9647">Porque</TOKEN>
<TOKEN id="token-72-1" pos="word" morph="none" start_char="9649" end_char="9651">hay</TOKEN>
<TOKEN id="token-72-2" pos="word" morph="none" start_char="9653" end_char="9657">gente</TOKEN>
<TOKEN id="token-72-3" pos="word" morph="none" start_char="9659" end_char="9665">malvada</TOKEN>
<TOKEN id="token-72-4" pos="word" morph="none" start_char="9667" end_char="9669">que</TOKEN>
<TOKEN id="token-72-5" pos="word" morph="none" start_char="9671" end_char="9676">quiere</TOKEN>
<TOKEN id="token-72-6" pos="word" morph="none" start_char="9678" end_char="9683">llegar</TOKEN>
<TOKEN id="token-72-7" pos="word" morph="none" start_char="9685" end_char="9686">al</TOKEN>
<TOKEN id="token-72-8" pos="word" morph="none" start_char="9688" end_char="9694">dominio</TOKEN>
<TOKEN id="token-72-9" pos="word" morph="none" start_char="9696" end_char="9700">total</TOKEN>
<TOKEN id="token-72-10" pos="word" morph="none" start_char="9702" end_char="9703">de</TOKEN>
<TOKEN id="token-72-11" pos="word" morph="none" start_char="9705" end_char="9706">la</TOKEN>
<TOKEN id="token-72-12" pos="word" morph="none" start_char="9708" end_char="9716">humanidad</TOKEN>
<TOKEN id="token-72-13" pos="punct" morph="none" start_char="9717" end_char="9717">,</TOKEN>
<TOKEN id="token-72-14" pos="word" morph="none" start_char="9719" end_char="9720">en</TOKEN>
<TOKEN id="token-72-15" pos="word" morph="none" start_char="9722" end_char="9726">todos</TOKEN>
<TOKEN id="token-72-16" pos="word" morph="none" start_char="9728" end_char="9730">los</TOKEN>
<TOKEN id="token-72-17" pos="word" morph="none" start_char="9732" end_char="9739">aspectos</TOKEN>
<TOKEN id="token-72-18" pos="punct" morph="none" start_char="9740" end_char="9740">.</TOKEN>
</SEG>
<SEG id="segment-73" start_char="9742" end_char="9853">
<ORIGINAL_TEXT>y los que piensan así son de EE.UU. y por que no China también, estos están en pugna de quien va a ser el mundo.</ORIGINAL_TEXT>
<TOKEN id="token-73-0" pos="word" morph="none" start_char="9742" end_char="9742">y</TOKEN>
<TOKEN id="token-73-1" pos="word" morph="none" start_char="9744" end_char="9746">los</TOKEN>
<TOKEN id="token-73-2" pos="word" morph="none" start_char="9748" end_char="9750">que</TOKEN>
<TOKEN id="token-73-3" pos="word" morph="none" start_char="9752" end_char="9758">piensan</TOKEN>
<TOKEN id="token-73-4" pos="word" morph="none" start_char="9760" end_char="9762">así</TOKEN>
<TOKEN id="token-73-5" pos="word" morph="none" start_char="9764" end_char="9766">son</TOKEN>
<TOKEN id="token-73-6" pos="word" morph="none" start_char="9768" end_char="9769">de</TOKEN>
<TOKEN id="token-73-7" pos="unknown" morph="none" start_char="9771" end_char="9775">EE.UU</TOKEN>
<TOKEN id="token-73-8" pos="punct" morph="none" start_char="9776" end_char="9776">.</TOKEN>
<TOKEN id="token-73-9" pos="word" morph="none" start_char="9778" end_char="9778">y</TOKEN>
<TOKEN id="token-73-10" pos="word" morph="none" start_char="9780" end_char="9782">por</TOKEN>
<TOKEN id="token-73-11" pos="word" morph="none" start_char="9784" end_char="9786">que</TOKEN>
<TOKEN id="token-73-12" pos="word" morph="none" start_char="9788" end_char="9789">no</TOKEN>
<TOKEN id="token-73-13" pos="word" morph="none" start_char="9791" end_char="9795">China</TOKEN>
<TOKEN id="token-73-14" pos="word" morph="none" start_char="9797" end_char="9803">también</TOKEN>
<TOKEN id="token-73-15" pos="punct" morph="none" start_char="9804" end_char="9804">,</TOKEN>
<TOKEN id="token-73-16" pos="word" morph="none" start_char="9806" end_char="9810">estos</TOKEN>
<TOKEN id="token-73-17" pos="word" morph="none" start_char="9812" end_char="9816">están</TOKEN>
<TOKEN id="token-73-18" pos="word" morph="none" start_char="9818" end_char="9819">en</TOKEN>
<TOKEN id="token-73-19" pos="word" morph="none" start_char="9821" end_char="9825">pugna</TOKEN>
<TOKEN id="token-73-20" pos="word" morph="none" start_char="9827" end_char="9828">de</TOKEN>
<TOKEN id="token-73-21" pos="word" morph="none" start_char="9830" end_char="9834">quien</TOKEN>
<TOKEN id="token-73-22" pos="word" morph="none" start_char="9836" end_char="9837">va</TOKEN>
<TOKEN id="token-73-23" pos="word" morph="none" start_char="9839" end_char="9839">a</TOKEN>
<TOKEN id="token-73-24" pos="word" morph="none" start_char="9841" end_char="9843">ser</TOKEN>
<TOKEN id="token-73-25" pos="word" morph="none" start_char="9845" end_char="9846">el</TOKEN>
<TOKEN id="token-73-26" pos="word" morph="none" start_char="9848" end_char="9852">mundo</TOKEN>
<TOKEN id="token-73-27" pos="punct" morph="none" start_char="9853" end_char="9853">.</TOKEN>
</SEG>
<SEG id="segment-74" start_char="9855" end_char="10071">
<ORIGINAL_TEXT>Los seres humanos de otras naciones seguimos siendo usados como conejillos de Indias, los presidentes simplemente son títeres de las mafias corruptas, que maquinan dia y noche de cómo sacar mayor ventaja de las cosas.</ORIGINAL_TEXT>
<TOKEN id="token-74-0" pos="word" morph="none" start_char="9855" end_char="9857">Los</TOKEN>
<TOKEN id="token-74-1" pos="word" morph="none" start_char="9859" end_char="9863">seres</TOKEN>
<TOKEN id="token-74-2" pos="word" morph="none" start_char="9865" end_char="9871">humanos</TOKEN>
<TOKEN id="token-74-3" pos="word" morph="none" start_char="9873" end_char="9874">de</TOKEN>
<TOKEN id="token-74-4" pos="word" morph="none" start_char="9876" end_char="9880">otras</TOKEN>
<TOKEN id="token-74-5" pos="word" morph="none" start_char="9882" end_char="9889">naciones</TOKEN>
<TOKEN id="token-74-6" pos="word" morph="none" start_char="9891" end_char="9898">seguimos</TOKEN>
<TOKEN id="token-74-7" pos="word" morph="none" start_char="9900" end_char="9905">siendo</TOKEN>
<TOKEN id="token-74-8" pos="word" morph="none" start_char="9907" end_char="9912">usados</TOKEN>
<TOKEN id="token-74-9" pos="word" morph="none" start_char="9914" end_char="9917">como</TOKEN>
<TOKEN id="token-74-10" pos="word" morph="none" start_char="9919" end_char="9928">conejillos</TOKEN>
<TOKEN id="token-74-11" pos="word" morph="none" start_char="9930" end_char="9931">de</TOKEN>
<TOKEN id="token-74-12" pos="word" morph="none" start_char="9933" end_char="9938">Indias</TOKEN>
<TOKEN id="token-74-13" pos="punct" morph="none" start_char="9939" end_char="9939">,</TOKEN>
<TOKEN id="token-74-14" pos="word" morph="none" start_char="9941" end_char="9943">los</TOKEN>
<TOKEN id="token-74-15" pos="word" morph="none" start_char="9945" end_char="9955">presidentes</TOKEN>
<TOKEN id="token-74-16" pos="word" morph="none" start_char="9957" end_char="9967">simplemente</TOKEN>
<TOKEN id="token-74-17" pos="word" morph="none" start_char="9969" end_char="9971">son</TOKEN>
<TOKEN id="token-74-18" pos="word" morph="none" start_char="9973" end_char="9979">títeres</TOKEN>
<TOKEN id="token-74-19" pos="word" morph="none" start_char="9981" end_char="9982">de</TOKEN>
<TOKEN id="token-74-20" pos="word" morph="none" start_char="9984" end_char="9986">las</TOKEN>
<TOKEN id="token-74-21" pos="word" morph="none" start_char="9988" end_char="9993">mafias</TOKEN>
<TOKEN id="token-74-22" pos="word" morph="none" start_char="9995" end_char="10003">corruptas</TOKEN>
<TOKEN id="token-74-23" pos="punct" morph="none" start_char="10004" end_char="10004">,</TOKEN>
<TOKEN id="token-74-24" pos="word" morph="none" start_char="10006" end_char="10008">que</TOKEN>
<TOKEN id="token-74-25" pos="word" morph="none" start_char="10010" end_char="10017">maquinan</TOKEN>
<TOKEN id="token-74-26" pos="word" morph="none" start_char="10019" end_char="10021">dia</TOKEN>
<TOKEN id="token-74-27" pos="word" morph="none" start_char="10023" end_char="10023">y</TOKEN>
<TOKEN id="token-74-28" pos="word" morph="none" start_char="10025" end_char="10029">noche</TOKEN>
<TOKEN id="token-74-29" pos="word" morph="none" start_char="10031" end_char="10032">de</TOKEN>
<TOKEN id="token-74-30" pos="word" morph="none" start_char="10034" end_char="10037">cómo</TOKEN>
<TOKEN id="token-74-31" pos="word" morph="none" start_char="10039" end_char="10043">sacar</TOKEN>
<TOKEN id="token-74-32" pos="word" morph="none" start_char="10045" end_char="10049">mayor</TOKEN>
<TOKEN id="token-74-33" pos="word" morph="none" start_char="10051" end_char="10057">ventaja</TOKEN>
<TOKEN id="token-74-34" pos="word" morph="none" start_char="10059" end_char="10060">de</TOKEN>
<TOKEN id="token-74-35" pos="word" morph="none" start_char="10062" end_char="10064">las</TOKEN>
<TOKEN id="token-74-36" pos="word" morph="none" start_char="10066" end_char="10070">cosas</TOKEN>
<TOKEN id="token-74-37" pos="punct" morph="none" start_char="10071" end_char="10071">.</TOKEN>
</SEG>
<SEG id="segment-75" start_char="10073" end_char="10210">
<ORIGINAL_TEXT>Pero de una cosa estoy más que seguro, que todo aquél que actúa en desmedro de otros, ciertamente la naturaleza les cobrará pero muy caro.</ORIGINAL_TEXT>
<TOKEN id="token-75-0" pos="word" morph="none" start_char="10073" end_char="10076">Pero</TOKEN>
<TOKEN id="token-75-1" pos="word" morph="none" start_char="10078" end_char="10079">de</TOKEN>
<TOKEN id="token-75-2" pos="word" morph="none" start_char="10081" end_char="10083">una</TOKEN>
<TOKEN id="token-75-3" pos="word" morph="none" start_char="10085" end_char="10088">cosa</TOKEN>
<TOKEN id="token-75-4" pos="word" morph="none" start_char="10090" end_char="10094">estoy</TOKEN>
<TOKEN id="token-75-5" pos="word" morph="none" start_char="10096" end_char="10098">más</TOKEN>
<TOKEN id="token-75-6" pos="word" morph="none" start_char="10100" end_char="10102">que</TOKEN>
<TOKEN id="token-75-7" pos="word" morph="none" start_char="10104" end_char="10109">seguro</TOKEN>
<TOKEN id="token-75-8" pos="punct" morph="none" start_char="10110" end_char="10110">,</TOKEN>
<TOKEN id="token-75-9" pos="word" morph="none" start_char="10112" end_char="10114">que</TOKEN>
<TOKEN id="token-75-10" pos="word" morph="none" start_char="10116" end_char="10119">todo</TOKEN>
<TOKEN id="token-75-11" pos="word" morph="none" start_char="10121" end_char="10125">aquél</TOKEN>
<TOKEN id="token-75-12" pos="word" morph="none" start_char="10127" end_char="10129">que</TOKEN>
<TOKEN id="token-75-13" pos="word" morph="none" start_char="10131" end_char="10135">actúa</TOKEN>
<TOKEN id="token-75-14" pos="word" morph="none" start_char="10137" end_char="10138">en</TOKEN>
<TOKEN id="token-75-15" pos="word" morph="none" start_char="10140" end_char="10147">desmedro</TOKEN>
<TOKEN id="token-75-16" pos="word" morph="none" start_char="10149" end_char="10150">de</TOKEN>
<TOKEN id="token-75-17" pos="word" morph="none" start_char="10152" end_char="10156">otros</TOKEN>
<TOKEN id="token-75-18" pos="punct" morph="none" start_char="10157" end_char="10157">,</TOKEN>
<TOKEN id="token-75-19" pos="word" morph="none" start_char="10159" end_char="10169">ciertamente</TOKEN>
<TOKEN id="token-75-20" pos="word" morph="none" start_char="10171" end_char="10172">la</TOKEN>
<TOKEN id="token-75-21" pos="word" morph="none" start_char="10174" end_char="10183">naturaleza</TOKEN>
<TOKEN id="token-75-22" pos="word" morph="none" start_char="10185" end_char="10187">les</TOKEN>
<TOKEN id="token-75-23" pos="word" morph="none" start_char="10189" end_char="10195">cobrará</TOKEN>
<TOKEN id="token-75-24" pos="word" morph="none" start_char="10197" end_char="10200">pero</TOKEN>
<TOKEN id="token-75-25" pos="word" morph="none" start_char="10202" end_char="10204">muy</TOKEN>
<TOKEN id="token-75-26" pos="word" morph="none" start_char="10206" end_char="10209">caro</TOKEN>
<TOKEN id="token-75-27" pos="punct" morph="none" start_char="10210" end_char="10210">.</TOKEN>
</SEG>
<SEG id="segment-76" start_char="10212" end_char="10230">
<ORIGINAL_TEXT>Eso téngalo seguro.</ORIGINAL_TEXT>
<TOKEN id="token-76-0" pos="word" morph="none" start_char="10212" end_char="10214">Eso</TOKEN>
<TOKEN id="token-76-1" pos="word" morph="none" start_char="10216" end_char="10222">téngalo</TOKEN>
<TOKEN id="token-76-2" pos="word" morph="none" start_char="10224" end_char="10229">seguro</TOKEN>
<TOKEN id="token-76-3" pos="punct" morph="none" start_char="10230" end_char="10230">.</TOKEN>
</SEG>
<SEG id="segment-77" start_char="10232" end_char="10423">
<ORIGINAL_TEXT>Porque nada en este mundo cae en saco roto, Bíblicamente dice; todo el que siembra cosechará también; físicamente toda acción provoca una reacción; metafísicamente todo efecto tiene una causa.</ORIGINAL_TEXT>
<TOKEN id="token-77-0" pos="word" morph="none" start_char="10232" end_char="10237">Porque</TOKEN>
<TOKEN id="token-77-1" pos="word" morph="none" start_char="10239" end_char="10242">nada</TOKEN>
<TOKEN id="token-77-2" pos="word" morph="none" start_char="10244" end_char="10245">en</TOKEN>
<TOKEN id="token-77-3" pos="word" morph="none" start_char="10247" end_char="10250">este</TOKEN>
<TOKEN id="token-77-4" pos="word" morph="none" start_char="10252" end_char="10256">mundo</TOKEN>
<TOKEN id="token-77-5" pos="word" morph="none" start_char="10258" end_char="10260">cae</TOKEN>
<TOKEN id="token-77-6" pos="word" morph="none" start_char="10262" end_char="10263">en</TOKEN>
<TOKEN id="token-77-7" pos="word" morph="none" start_char="10265" end_char="10268">saco</TOKEN>
<TOKEN id="token-77-8" pos="word" morph="none" start_char="10270" end_char="10273">roto</TOKEN>
<TOKEN id="token-77-9" pos="punct" morph="none" start_char="10274" end_char="10274">,</TOKEN>
<TOKEN id="token-77-10" pos="word" morph="none" start_char="10276" end_char="10287">Bíblicamente</TOKEN>
<TOKEN id="token-77-11" pos="word" morph="none" start_char="10289" end_char="10292">dice</TOKEN>
<TOKEN id="token-77-12" pos="punct" morph="none" start_char="10293" end_char="10293">;</TOKEN>
<TOKEN id="token-77-13" pos="word" morph="none" start_char="10295" end_char="10298">todo</TOKEN>
<TOKEN id="token-77-14" pos="word" morph="none" start_char="10300" end_char="10301">el</TOKEN>
<TOKEN id="token-77-15" pos="word" morph="none" start_char="10303" end_char="10305">que</TOKEN>
<TOKEN id="token-77-16" pos="word" morph="none" start_char="10307" end_char="10313">siembra</TOKEN>
<TOKEN id="token-77-17" pos="word" morph="none" start_char="10315" end_char="10323">cosechará</TOKEN>
<TOKEN id="token-77-18" pos="word" morph="none" start_char="10325" end_char="10331">también</TOKEN>
<TOKEN id="token-77-19" pos="punct" morph="none" start_char="10332" end_char="10332">;</TOKEN>
<TOKEN id="token-77-20" pos="word" morph="none" start_char="10334" end_char="10344">físicamente</TOKEN>
<TOKEN id="token-77-21" pos="word" morph="none" start_char="10346" end_char="10349">toda</TOKEN>
<TOKEN id="token-77-22" pos="word" morph="none" start_char="10351" end_char="10356">acción</TOKEN>
<TOKEN id="token-77-23" pos="word" morph="none" start_char="10358" end_char="10364">provoca</TOKEN>
<TOKEN id="token-77-24" pos="word" morph="none" start_char="10366" end_char="10368">una</TOKEN>
<TOKEN id="token-77-25" pos="word" morph="none" start_char="10370" end_char="10377">reacción</TOKEN>
<TOKEN id="token-77-26" pos="punct" morph="none" start_char="10378" end_char="10378">;</TOKEN>
<TOKEN id="token-77-27" pos="word" morph="none" start_char="10380" end_char="10394">metafísicamente</TOKEN>
<TOKEN id="token-77-28" pos="word" morph="none" start_char="10396" end_char="10399">todo</TOKEN>
<TOKEN id="token-77-29" pos="word" morph="none" start_char="10401" end_char="10406">efecto</TOKEN>
<TOKEN id="token-77-30" pos="word" morph="none" start_char="10408" end_char="10412">tiene</TOKEN>
<TOKEN id="token-77-31" pos="word" morph="none" start_char="10414" end_char="10416">una</TOKEN>
<TOKEN id="token-77-32" pos="word" morph="none" start_char="10418" end_char="10422">causa</TOKEN>
<TOKEN id="token-77-33" pos="punct" morph="none" start_char="10423" end_char="10423">.</TOKEN>
</SEG>
<SEG id="segment-78" start_char="10425" end_char="10431">
<ORIGINAL_TEXT>saludos</ORIGINAL_TEXT>
<TOKEN id="token-78-0" pos="word" morph="none" start_char="10425" end_char="10431">saludos</TOKEN>
</SEG>
<SEG id="segment-79" start_char="10435" end_char="10644">
<ORIGINAL_TEXT>Vivimos en un mundo lleno de "casualidades "muy extrañas, que casualidad que en 2015 se hable de este tema y con ese enfoque y que en el 2020 estemos enfrentando un pandemia justamente con esas características.</ORIGINAL_TEXT>
<TOKEN id="token-79-0" pos="word" morph="none" start_char="10435" end_char="10441">Vivimos</TOKEN>
<TOKEN id="token-79-1" pos="word" morph="none" start_char="10443" end_char="10444">en</TOKEN>
<TOKEN id="token-79-2" pos="word" morph="none" start_char="10446" end_char="10447">un</TOKEN>
<TOKEN id="token-79-3" pos="word" morph="none" start_char="10449" end_char="10453">mundo</TOKEN>
<TOKEN id="token-79-4" pos="word" morph="none" start_char="10455" end_char="10459">lleno</TOKEN>
<TOKEN id="token-79-5" pos="word" morph="none" start_char="10461" end_char="10462">de</TOKEN>
<TOKEN id="token-79-6" pos="punct" morph="none" start_char="10464" end_char="10464">"</TOKEN>
<TOKEN id="token-79-7" pos="word" morph="none" start_char="10465" end_char="10476">casualidades</TOKEN>
<TOKEN id="token-79-8" pos="punct" morph="none" start_char="10478" end_char="10478">"</TOKEN>
<TOKEN id="token-79-9" pos="word" morph="none" start_char="10479" end_char="10481">muy</TOKEN>
<TOKEN id="token-79-10" pos="word" morph="none" start_char="10483" end_char="10490">extrañas</TOKEN>
<TOKEN id="token-79-11" pos="punct" morph="none" start_char="10491" end_char="10491">,</TOKEN>
<TOKEN id="token-79-12" pos="word" morph="none" start_char="10493" end_char="10495">que</TOKEN>
<TOKEN id="token-79-13" pos="word" morph="none" start_char="10497" end_char="10506">casualidad</TOKEN>
<TOKEN id="token-79-14" pos="word" morph="none" start_char="10508" end_char="10510">que</TOKEN>
<TOKEN id="token-79-15" pos="word" morph="none" start_char="10512" end_char="10513">en</TOKEN>
<TOKEN id="token-79-16" pos="word" morph="none" start_char="10515" end_char="10518">2015</TOKEN>
<TOKEN id="token-79-17" pos="word" morph="none" start_char="10520" end_char="10521">se</TOKEN>
<TOKEN id="token-79-18" pos="word" morph="none" start_char="10523" end_char="10527">hable</TOKEN>
<TOKEN id="token-79-19" pos="word" morph="none" start_char="10529" end_char="10530">de</TOKEN>
<TOKEN id="token-79-20" pos="word" morph="none" start_char="10532" end_char="10535">este</TOKEN>
<TOKEN id="token-79-21" pos="word" morph="none" start_char="10537" end_char="10540">tema</TOKEN>
<TOKEN id="token-79-22" pos="word" morph="none" start_char="10542" end_char="10542">y</TOKEN>
<TOKEN id="token-79-23" pos="word" morph="none" start_char="10544" end_char="10546">con</TOKEN>
<TOKEN id="token-79-24" pos="word" morph="none" start_char="10548" end_char="10550">ese</TOKEN>
<TOKEN id="token-79-25" pos="word" morph="none" start_char="10552" end_char="10558">enfoque</TOKEN>
<TOKEN id="token-79-26" pos="word" morph="none" start_char="10560" end_char="10560">y</TOKEN>
<TOKEN id="token-79-27" pos="word" morph="none" start_char="10562" end_char="10564">que</TOKEN>
<TOKEN id="token-79-28" pos="word" morph="none" start_char="10566" end_char="10567">en</TOKEN>
<TOKEN id="token-79-29" pos="word" morph="none" start_char="10569" end_char="10570">el</TOKEN>
<TOKEN id="token-79-30" pos="word" morph="none" start_char="10572" end_char="10575">2020</TOKEN>
<TOKEN id="token-79-31" pos="word" morph="none" start_char="10577" end_char="10583">estemos</TOKEN>
<TOKEN id="token-79-32" pos="word" morph="none" start_char="10585" end_char="10595">enfrentando</TOKEN>
<TOKEN id="token-79-33" pos="word" morph="none" start_char="10597" end_char="10598">un</TOKEN>
<TOKEN id="token-79-34" pos="word" morph="none" start_char="10600" end_char="10607">pandemia</TOKEN>
<TOKEN id="token-79-35" pos="word" morph="none" start_char="10609" end_char="10618">justamente</TOKEN>
<TOKEN id="token-79-36" pos="word" morph="none" start_char="10620" end_char="10622">con</TOKEN>
<TOKEN id="token-79-37" pos="word" morph="none" start_char="10624" end_char="10627">esas</TOKEN>
<TOKEN id="token-79-38" pos="word" morph="none" start_char="10629" end_char="10643">características</TOKEN>
<TOKEN id="token-79-39" pos="punct" morph="none" start_char="10644" end_char="10644">.</TOKEN>
</SEG>
<SEG id="segment-80" start_char="10646" end_char="10865">
<ORIGINAL_TEXT>Qué casualidad que se cite justamente un laboratorio chino y que Wuhan la ciudad en donde inicio el brote de Covid-19 cuente con un laboratorio de BIOSEGURIDAD en donde se realizan pruebas con virus altamente peligrosos.</ORIGINAL_TEXT>
<TOKEN id="token-80-0" pos="word" morph="none" start_char="10646" end_char="10648">Qué</TOKEN>
<TOKEN id="token-80-1" pos="word" morph="none" start_char="10650" end_char="10659">casualidad</TOKEN>
<TOKEN id="token-80-2" pos="word" morph="none" start_char="10661" end_char="10663">que</TOKEN>
<TOKEN id="token-80-3" pos="word" morph="none" start_char="10665" end_char="10666">se</TOKEN>
<TOKEN id="token-80-4" pos="word" morph="none" start_char="10668" end_char="10671">cite</TOKEN>
<TOKEN id="token-80-5" pos="word" morph="none" start_char="10673" end_char="10682">justamente</TOKEN>
<TOKEN id="token-80-6" pos="word" morph="none" start_char="10684" end_char="10685">un</TOKEN>
<TOKEN id="token-80-7" pos="word" morph="none" start_char="10687" end_char="10697">laboratorio</TOKEN>
<TOKEN id="token-80-8" pos="word" morph="none" start_char="10699" end_char="10703">chino</TOKEN>
<TOKEN id="token-80-9" pos="word" morph="none" start_char="10705" end_char="10705">y</TOKEN>
<TOKEN id="token-80-10" pos="word" morph="none" start_char="10707" end_char="10709">que</TOKEN>
<TOKEN id="token-80-11" pos="word" morph="none" start_char="10711" end_char="10715">Wuhan</TOKEN>
<TOKEN id="token-80-12" pos="word" morph="none" start_char="10717" end_char="10718">la</TOKEN>
<TOKEN id="token-80-13" pos="word" morph="none" start_char="10720" end_char="10725">ciudad</TOKEN>
<TOKEN id="token-80-14" pos="word" morph="none" start_char="10727" end_char="10728">en</TOKEN>
<TOKEN id="token-80-15" pos="word" morph="none" start_char="10730" end_char="10734">donde</TOKEN>
<TOKEN id="token-80-16" pos="word" morph="none" start_char="10736" end_char="10741">inicio</TOKEN>
<TOKEN id="token-80-17" pos="word" morph="none" start_char="10743" end_char="10744">el</TOKEN>
<TOKEN id="token-80-18" pos="word" morph="none" start_char="10746" end_char="10750">brote</TOKEN>
<TOKEN id="token-80-19" pos="word" morph="none" start_char="10752" end_char="10753">de</TOKEN>
<TOKEN id="token-80-20" pos="unknown" morph="none" start_char="10755" end_char="10762">Covid-19</TOKEN>
<TOKEN id="token-80-21" pos="word" morph="none" start_char="10764" end_char="10769">cuente</TOKEN>
<TOKEN id="token-80-22" pos="word" morph="none" start_char="10771" end_char="10773">con</TOKEN>
<TOKEN id="token-80-23" pos="word" morph="none" start_char="10775" end_char="10776">un</TOKEN>
<TOKEN id="token-80-24" pos="word" morph="none" start_char="10778" end_char="10788">laboratorio</TOKEN>
<TOKEN id="token-80-25" pos="word" morph="none" start_char="10790" end_char="10791">de</TOKEN>
<TOKEN id="token-80-26" pos="word" morph="none" start_char="10793" end_char="10804">BIOSEGURIDAD</TOKEN>
<TOKEN id="token-80-27" pos="word" morph="none" start_char="10806" end_char="10807">en</TOKEN>
<TOKEN id="token-80-28" pos="word" morph="none" start_char="10809" end_char="10813">donde</TOKEN>
<TOKEN id="token-80-29" pos="word" morph="none" start_char="10815" end_char="10816">se</TOKEN>
<TOKEN id="token-80-30" pos="word" morph="none" start_char="10818" end_char="10825">realizan</TOKEN>
<TOKEN id="token-80-31" pos="word" morph="none" start_char="10827" end_char="10833">pruebas</TOKEN>
<TOKEN id="token-80-32" pos="word" morph="none" start_char="10835" end_char="10837">con</TOKEN>
<TOKEN id="token-80-33" pos="word" morph="none" start_char="10839" end_char="10843">virus</TOKEN>
<TOKEN id="token-80-34" pos="word" morph="none" start_char="10845" end_char="10853">altamente</TOKEN>
<TOKEN id="token-80-35" pos="word" morph="none" start_char="10855" end_char="10864">peligrosos</TOKEN>
<TOKEN id="token-80-36" pos="punct" morph="none" start_char="10865" end_char="10865">.</TOKEN>
</SEG>
<SEG id="segment-81" start_char="10867" end_char="10973">
<ORIGINAL_TEXT>No creen ustedes que son muchas "casualidades "o no serán más bien CAUSALIDADES con un origen muy definido.</ORIGINAL_TEXT>
<TOKEN id="token-81-0" pos="word" morph="none" start_char="10867" end_char="10868">No</TOKEN>
<TOKEN id="token-81-1" pos="word" morph="none" start_char="10870" end_char="10874">creen</TOKEN>
<TOKEN id="token-81-2" pos="word" morph="none" start_char="10876" end_char="10882">ustedes</TOKEN>
<TOKEN id="token-81-3" pos="word" morph="none" start_char="10884" end_char="10886">que</TOKEN>
<TOKEN id="token-81-4" pos="word" morph="none" start_char="10888" end_char="10890">son</TOKEN>
<TOKEN id="token-81-5" pos="word" morph="none" start_char="10892" end_char="10897">muchas</TOKEN>
<TOKEN id="token-81-6" pos="punct" morph="none" start_char="10899" end_char="10899">"</TOKEN>
<TOKEN id="token-81-7" pos="word" morph="none" start_char="10900" end_char="10911">casualidades</TOKEN>
<TOKEN id="token-81-8" pos="punct" morph="none" start_char="10913" end_char="10913">"</TOKEN>
<TOKEN id="token-81-9" pos="word" morph="none" start_char="10914" end_char="10914">o</TOKEN>
<TOKEN id="token-81-10" pos="word" morph="none" start_char="10916" end_char="10917">no</TOKEN>
<TOKEN id="token-81-11" pos="word" morph="none" start_char="10919" end_char="10923">serán</TOKEN>
<TOKEN id="token-81-12" pos="word" morph="none" start_char="10925" end_char="10927">más</TOKEN>
<TOKEN id="token-81-13" pos="word" morph="none" start_char="10929" end_char="10932">bien</TOKEN>
<TOKEN id="token-81-14" pos="word" morph="none" start_char="10934" end_char="10945">CAUSALIDADES</TOKEN>
<TOKEN id="token-81-15" pos="word" morph="none" start_char="10947" end_char="10949">con</TOKEN>
<TOKEN id="token-81-16" pos="word" morph="none" start_char="10951" end_char="10952">un</TOKEN>
<TOKEN id="token-81-17" pos="word" morph="none" start_char="10954" end_char="10959">origen</TOKEN>
<TOKEN id="token-81-18" pos="word" morph="none" start_char="10961" end_char="10963">muy</TOKEN>
<TOKEN id="token-81-19" pos="word" morph="none" start_char="10965" end_char="10972">definido</TOKEN>
<TOKEN id="token-81-20" pos="punct" morph="none" start_char="10973" end_char="10973">.</TOKEN>
</SEG>
<SEG id="segment-82" start_char="10975" end_char="11278">
<ORIGINAL_TEXT>El simple hecho de que a un laboratorio se le permita manipular genéticamente estos virus altamente peligrosos y MORTIFEROS ya es un acto CRIMINAL, ya que nadie está exento de cometer errores y si por un error un virus de estos escapa de un laboratorio, es obvio que nadie va a asumir la responsabilidad.</ORIGINAL_TEXT>
<TOKEN id="token-82-0" pos="word" morph="none" start_char="10975" end_char="10976">El</TOKEN>
<TOKEN id="token-82-1" pos="word" morph="none" start_char="10978" end_char="10983">simple</TOKEN>
<TOKEN id="token-82-2" pos="word" morph="none" start_char="10985" end_char="10989">hecho</TOKEN>
<TOKEN id="token-82-3" pos="word" morph="none" start_char="10991" end_char="10992">de</TOKEN>
<TOKEN id="token-82-4" pos="word" morph="none" start_char="10994" end_char="10996">que</TOKEN>
<TOKEN id="token-82-5" pos="word" morph="none" start_char="10998" end_char="10998">a</TOKEN>
<TOKEN id="token-82-6" pos="word" morph="none" start_char="11000" end_char="11001">un</TOKEN>
<TOKEN id="token-82-7" pos="word" morph="none" start_char="11003" end_char="11013">laboratorio</TOKEN>
<TOKEN id="token-82-8" pos="word" morph="none" start_char="11015" end_char="11016">se</TOKEN>
<TOKEN id="token-82-9" pos="word" morph="none" start_char="11018" end_char="11019">le</TOKEN>
<TOKEN id="token-82-10" pos="word" morph="none" start_char="11021" end_char="11027">permita</TOKEN>
<TOKEN id="token-82-11" pos="word" morph="none" start_char="11029" end_char="11037">manipular</TOKEN>
<TOKEN id="token-82-12" pos="word" morph="none" start_char="11039" end_char="11051">genéticamente</TOKEN>
<TOKEN id="token-82-13" pos="word" morph="none" start_char="11053" end_char="11057">estos</TOKEN>
<TOKEN id="token-82-14" pos="word" morph="none" start_char="11059" end_char="11063">virus</TOKEN>
<TOKEN id="token-82-15" pos="word" morph="none" start_char="11065" end_char="11073">altamente</TOKEN>
<TOKEN id="token-82-16" pos="word" morph="none" start_char="11075" end_char="11084">peligrosos</TOKEN>
<TOKEN id="token-82-17" pos="word" morph="none" start_char="11086" end_char="11086">y</TOKEN>
<TOKEN id="token-82-18" pos="word" morph="none" start_char="11088" end_char="11097">MORTIFEROS</TOKEN>
<TOKEN id="token-82-19" pos="word" morph="none" start_char="11099" end_char="11100">ya</TOKEN>
<TOKEN id="token-82-20" pos="word" morph="none" start_char="11102" end_char="11103">es</TOKEN>
<TOKEN id="token-82-21" pos="word" morph="none" start_char="11105" end_char="11106">un</TOKEN>
<TOKEN id="token-82-22" pos="word" morph="none" start_char="11108" end_char="11111">acto</TOKEN>
<TOKEN id="token-82-23" pos="word" morph="none" start_char="11113" end_char="11120">CRIMINAL</TOKEN>
<TOKEN id="token-82-24" pos="punct" morph="none" start_char="11121" end_char="11121">,</TOKEN>
<TOKEN id="token-82-25" pos="word" morph="none" start_char="11123" end_char="11124">ya</TOKEN>
<TOKEN id="token-82-26" pos="word" morph="none" start_char="11126" end_char="11128">que</TOKEN>
<TOKEN id="token-82-27" pos="word" morph="none" start_char="11130" end_char="11134">nadie</TOKEN>
<TOKEN id="token-82-28" pos="word" morph="none" start_char="11136" end_char="11139">está</TOKEN>
<TOKEN id="token-82-29" pos="word" morph="none" start_char="11141" end_char="11146">exento</TOKEN>
<TOKEN id="token-82-30" pos="word" morph="none" start_char="11148" end_char="11149">de</TOKEN>
<TOKEN id="token-82-31" pos="word" morph="none" start_char="11151" end_char="11157">cometer</TOKEN>
<TOKEN id="token-82-32" pos="word" morph="none" start_char="11159" end_char="11165">errores</TOKEN>
<TOKEN id="token-82-33" pos="word" morph="none" start_char="11167" end_char="11167">y</TOKEN>
<TOKEN id="token-82-34" pos="word" morph="none" start_char="11169" end_char="11170">si</TOKEN>
<TOKEN id="token-82-35" pos="word" morph="none" start_char="11172" end_char="11174">por</TOKEN>
<TOKEN id="token-82-36" pos="word" morph="none" start_char="11176" end_char="11177">un</TOKEN>
<TOKEN id="token-82-37" pos="word" morph="none" start_char="11179" end_char="11183">error</TOKEN>
<TOKEN id="token-82-38" pos="word" morph="none" start_char="11185" end_char="11186">un</TOKEN>
<TOKEN id="token-82-39" pos="word" morph="none" start_char="11188" end_char="11192">virus</TOKEN>
<TOKEN id="token-82-40" pos="word" morph="none" start_char="11194" end_char="11195">de</TOKEN>
<TOKEN id="token-82-41" pos="word" morph="none" start_char="11197" end_char="11201">estos</TOKEN>
<TOKEN id="token-82-42" pos="word" morph="none" start_char="11203" end_char="11208">escapa</TOKEN>
<TOKEN id="token-82-43" pos="word" morph="none" start_char="11210" end_char="11211">de</TOKEN>
<TOKEN id="token-82-44" pos="word" morph="none" start_char="11213" end_char="11214">un</TOKEN>
<TOKEN id="token-82-45" pos="word" morph="none" start_char="11216" end_char="11226">laboratorio</TOKEN>
<TOKEN id="token-82-46" pos="punct" morph="none" start_char="11227" end_char="11227">,</TOKEN>
<TOKEN id="token-82-47" pos="word" morph="none" start_char="11229" end_char="11230">es</TOKEN>
<TOKEN id="token-82-48" pos="word" morph="none" start_char="11232" end_char="11236">obvio</TOKEN>
<TOKEN id="token-82-49" pos="word" morph="none" start_char="11238" end_char="11240">que</TOKEN>
<TOKEN id="token-82-50" pos="word" morph="none" start_char="11242" end_char="11246">nadie</TOKEN>
<TOKEN id="token-82-51" pos="word" morph="none" start_char="11248" end_char="11249">va</TOKEN>
<TOKEN id="token-82-52" pos="word" morph="none" start_char="11251" end_char="11251">a</TOKEN>
<TOKEN id="token-82-53" pos="word" morph="none" start_char="11253" end_char="11258">asumir</TOKEN>
<TOKEN id="token-82-54" pos="word" morph="none" start_char="11260" end_char="11261">la</TOKEN>
<TOKEN id="token-82-55" pos="word" morph="none" start_char="11263" end_char="11277">responsabilidad</TOKEN>
<TOKEN id="token-82-56" pos="punct" morph="none" start_char="11278" end_char="11278">.</TOKEN>
</SEG>
<SEG id="segment-83" start_char="11280" end_char="11534">
<ORIGINAL_TEXT>Es muy extraño que hasta hace unas décadas nadie se preocupaba del surgimiento de estos "extraños "virus ya que aunque siempre han existido quizás al no existir una interacción con ellos o manipulación genética, esto no les permitía " despertar " y mutar.</ORIGINAL_TEXT>
<TOKEN id="token-83-0" pos="word" morph="none" start_char="11280" end_char="11281">Es</TOKEN>
<TOKEN id="token-83-1" pos="word" morph="none" start_char="11283" end_char="11285">muy</TOKEN>
<TOKEN id="token-83-2" pos="word" morph="none" start_char="11287" end_char="11293">extraño</TOKEN>
<TOKEN id="token-83-3" pos="word" morph="none" start_char="11295" end_char="11297">que</TOKEN>
<TOKEN id="token-83-4" pos="word" morph="none" start_char="11299" end_char="11303">hasta</TOKEN>
<TOKEN id="token-83-5" pos="word" morph="none" start_char="11305" end_char="11308">hace</TOKEN>
<TOKEN id="token-83-6" pos="word" morph="none" start_char="11310" end_char="11313">unas</TOKEN>
<TOKEN id="token-83-7" pos="word" morph="none" start_char="11315" end_char="11321">décadas</TOKEN>
<TOKEN id="token-83-8" pos="word" morph="none" start_char="11323" end_char="11327">nadie</TOKEN>
<TOKEN id="token-83-9" pos="word" morph="none" start_char="11329" end_char="11330">se</TOKEN>
<TOKEN id="token-83-10" pos="word" morph="none" start_char="11332" end_char="11341">preocupaba</TOKEN>
<TOKEN id="token-83-11" pos="word" morph="none" start_char="11343" end_char="11345">del</TOKEN>
<TOKEN id="token-83-12" pos="word" morph="none" start_char="11347" end_char="11357">surgimiento</TOKEN>
<TOKEN id="token-83-13" pos="word" morph="none" start_char="11359" end_char="11360">de</TOKEN>
<TOKEN id="token-83-14" pos="word" morph="none" start_char="11362" end_char="11366">estos</TOKEN>
<TOKEN id="token-83-15" pos="punct" morph="none" start_char="11368" end_char="11368">"</TOKEN>
<TOKEN id="token-83-16" pos="word" morph="none" start_char="11369" end_char="11376">extraños</TOKEN>
<TOKEN id="token-83-17" pos="punct" morph="none" start_char="11378" end_char="11378">"</TOKEN>
<TOKEN id="token-83-18" pos="word" morph="none" start_char="11379" end_char="11383">virus</TOKEN>
<TOKEN id="token-83-19" pos="word" morph="none" start_char="11385" end_char="11386">ya</TOKEN>
<TOKEN id="token-83-20" pos="word" morph="none" start_char="11388" end_char="11390">que</TOKEN>
<TOKEN id="token-83-21" pos="word" morph="none" start_char="11392" end_char="11397">aunque</TOKEN>
<TOKEN id="token-83-22" pos="word" morph="none" start_char="11399" end_char="11405">siempre</TOKEN>
<TOKEN id="token-83-23" pos="word" morph="none" start_char="11407" end_char="11409">han</TOKEN>
<TOKEN id="token-83-24" pos="word" morph="none" start_char="11411" end_char="11418">existido</TOKEN>
<TOKEN id="token-83-25" pos="word" morph="none" start_char="11420" end_char="11425">quizás</TOKEN>
<TOKEN id="token-83-26" pos="word" morph="none" start_char="11427" end_char="11428">al</TOKEN>
<TOKEN id="token-83-27" pos="word" morph="none" start_char="11430" end_char="11431">no</TOKEN>
<TOKEN id="token-83-28" pos="word" morph="none" start_char="11433" end_char="11439">existir</TOKEN>
<TOKEN id="token-83-29" pos="word" morph="none" start_char="11441" end_char="11443">una</TOKEN>
<TOKEN id="token-83-30" pos="word" morph="none" start_char="11445" end_char="11455">interacción</TOKEN>
<TOKEN id="token-83-31" pos="word" morph="none" start_char="11457" end_char="11459">con</TOKEN>
<TOKEN id="token-83-32" pos="word" morph="none" start_char="11461" end_char="11465">ellos</TOKEN>
<TOKEN id="token-83-33" pos="word" morph="none" start_char="11467" end_char="11467">o</TOKEN>
<TOKEN id="token-83-34" pos="word" morph="none" start_char="11469" end_char="11480">manipulación</TOKEN>
<TOKEN id="token-83-35" pos="word" morph="none" start_char="11482" end_char="11489">genética</TOKEN>
<TOKEN id="token-83-36" pos="punct" morph="none" start_char="11490" end_char="11490">,</TOKEN>
<TOKEN id="token-83-37" pos="word" morph="none" start_char="11492" end_char="11495">esto</TOKEN>
<TOKEN id="token-83-38" pos="word" morph="none" start_char="11497" end_char="11498">no</TOKEN>
<TOKEN id="token-83-39" pos="word" morph="none" start_char="11500" end_char="11502">les</TOKEN>
<TOKEN id="token-83-40" pos="word" morph="none" start_char="11504" end_char="11511">permitía</TOKEN>
<TOKEN id="token-83-41" pos="punct" morph="none" start_char="11513" end_char="11513">"</TOKEN>
<TOKEN id="token-83-42" pos="word" morph="none" start_char="11515" end_char="11523">despertar</TOKEN>
<TOKEN id="token-83-43" pos="punct" morph="none" start_char="11525" end_char="11525">"</TOKEN>
<TOKEN id="token-83-44" pos="word" morph="none" start_char="11527" end_char="11527">y</TOKEN>
<TOKEN id="token-83-45" pos="word" morph="none" start_char="11529" end_char="11533">mutar</TOKEN>
<TOKEN id="token-83-46" pos="punct" morph="none" start_char="11534" end_char="11534">.</TOKEN>
</SEG>
<SEG id="segment-84" start_char="11536" end_char="11889">
<ORIGINAL_TEXT>Para finalizar, las costumbres gastronómicas "exóticas "de los pueblos Asiáticos con énfasis en los de China no son de ahora vienen de raíces ancestrales, con esto quiero decir que es muy extraño que hasta ahora veamos surgir tantos virus de este país por mutaciones "naturales "siendo que SIEMPRE han consumido este tipo de especies silvestres salvajes.</ORIGINAL_TEXT>
<TOKEN id="token-84-0" pos="word" morph="none" start_char="11536" end_char="11539">Para</TOKEN>
<TOKEN id="token-84-1" pos="word" morph="none" start_char="11541" end_char="11549">finalizar</TOKEN>
<TOKEN id="token-84-2" pos="punct" morph="none" start_char="11550" end_char="11550">,</TOKEN>
<TOKEN id="token-84-3" pos="word" morph="none" start_char="11552" end_char="11554">las</TOKEN>
<TOKEN id="token-84-4" pos="word" morph="none" start_char="11556" end_char="11565">costumbres</TOKEN>
<TOKEN id="token-84-5" pos="word" morph="none" start_char="11567" end_char="11579">gastronómicas</TOKEN>
<TOKEN id="token-84-6" pos="punct" morph="none" start_char="11581" end_char="11581">"</TOKEN>
<TOKEN id="token-84-7" pos="word" morph="none" start_char="11582" end_char="11589">exóticas</TOKEN>
<TOKEN id="token-84-8" pos="punct" morph="none" start_char="11591" end_char="11591">"</TOKEN>
<TOKEN id="token-84-9" pos="word" morph="none" start_char="11592" end_char="11593">de</TOKEN>
<TOKEN id="token-84-10" pos="word" morph="none" start_char="11595" end_char="11597">los</TOKEN>
<TOKEN id="token-84-11" pos="word" morph="none" start_char="11599" end_char="11605">pueblos</TOKEN>
<TOKEN id="token-84-12" pos="word" morph="none" start_char="11607" end_char="11615">Asiáticos</TOKEN>
<TOKEN id="token-84-13" pos="word" morph="none" start_char="11617" end_char="11619">con</TOKEN>
<TOKEN id="token-84-14" pos="word" morph="none" start_char="11621" end_char="11627">énfasis</TOKEN>
<TOKEN id="token-84-15" pos="word" morph="none" start_char="11629" end_char="11630">en</TOKEN>
<TOKEN id="token-84-16" pos="word" morph="none" start_char="11632" end_char="11634">los</TOKEN>
<TOKEN id="token-84-17" pos="word" morph="none" start_char="11636" end_char="11637">de</TOKEN>
<TOKEN id="token-84-18" pos="word" morph="none" start_char="11639" end_char="11643">China</TOKEN>
<TOKEN id="token-84-19" pos="word" morph="none" start_char="11645" end_char="11646">no</TOKEN>
<TOKEN id="token-84-20" pos="word" morph="none" start_char="11648" end_char="11650">son</TOKEN>
<TOKEN id="token-84-21" pos="word" morph="none" start_char="11652" end_char="11653">de</TOKEN>
<TOKEN id="token-84-22" pos="word" morph="none" start_char="11655" end_char="11659">ahora</TOKEN>
<TOKEN id="token-84-23" pos="word" morph="none" start_char="11661" end_char="11666">vienen</TOKEN>
<TOKEN id="token-84-24" pos="word" morph="none" start_char="11668" end_char="11669">de</TOKEN>
<TOKEN id="token-84-25" pos="word" morph="none" start_char="11671" end_char="11676">raíces</TOKEN>
<TOKEN id="token-84-26" pos="word" morph="none" start_char="11678" end_char="11688">ancestrales</TOKEN>
<TOKEN id="token-84-27" pos="punct" morph="none" start_char="11689" end_char="11689">,</TOKEN>
<TOKEN id="token-84-28" pos="word" morph="none" start_char="11691" end_char="11693">con</TOKEN>
<TOKEN id="token-84-29" pos="word" morph="none" start_char="11695" end_char="11698">esto</TOKEN>
<TOKEN id="token-84-30" pos="word" morph="none" start_char="11700" end_char="11705">quiero</TOKEN>
<TOKEN id="token-84-31" pos="word" morph="none" start_char="11707" end_char="11711">decir</TOKEN>
<TOKEN id="token-84-32" pos="word" morph="none" start_char="11713" end_char="11715">que</TOKEN>
<TOKEN id="token-84-33" pos="word" morph="none" start_char="11717" end_char="11718">es</TOKEN>
<TOKEN id="token-84-34" pos="word" morph="none" start_char="11720" end_char="11722">muy</TOKEN>
<TOKEN id="token-84-35" pos="word" morph="none" start_char="11724" end_char="11730">extraño</TOKEN>
<TOKEN id="token-84-36" pos="word" morph="none" start_char="11732" end_char="11734">que</TOKEN>
<TOKEN id="token-84-37" pos="word" morph="none" start_char="11736" end_char="11740">hasta</TOKEN>
<TOKEN id="token-84-38" pos="word" morph="none" start_char="11742" end_char="11746">ahora</TOKEN>
<TOKEN id="token-84-39" pos="word" morph="none" start_char="11748" end_char="11753">veamos</TOKEN>
<TOKEN id="token-84-40" pos="word" morph="none" start_char="11755" end_char="11760">surgir</TOKEN>
<TOKEN id="token-84-41" pos="word" morph="none" start_char="11762" end_char="11767">tantos</TOKEN>
<TOKEN id="token-84-42" pos="word" morph="none" start_char="11769" end_char="11773">virus</TOKEN>
<TOKEN id="token-84-43" pos="word" morph="none" start_char="11775" end_char="11776">de</TOKEN>
<TOKEN id="token-84-44" pos="word" morph="none" start_char="11778" end_char="11781">este</TOKEN>
<TOKEN id="token-84-45" pos="word" morph="none" start_char="11783" end_char="11786">país</TOKEN>
<TOKEN id="token-84-46" pos="word" morph="none" start_char="11788" end_char="11790">por</TOKEN>
<TOKEN id="token-84-47" pos="word" morph="none" start_char="11792" end_char="11801">mutaciones</TOKEN>
<TOKEN id="token-84-48" pos="punct" morph="none" start_char="11803" end_char="11803">"</TOKEN>
<TOKEN id="token-84-49" pos="word" morph="none" start_char="11804" end_char="11812">naturales</TOKEN>
<TOKEN id="token-84-50" pos="punct" morph="none" start_char="11814" end_char="11814">"</TOKEN>
<TOKEN id="token-84-51" pos="word" morph="none" start_char="11815" end_char="11820">siendo</TOKEN>
<TOKEN id="token-84-52" pos="word" morph="none" start_char="11822" end_char="11824">que</TOKEN>
<TOKEN id="token-84-53" pos="word" morph="none" start_char="11826" end_char="11832">SIEMPRE</TOKEN>
<TOKEN id="token-84-54" pos="word" morph="none" start_char="11834" end_char="11836">han</TOKEN>
<TOKEN id="token-84-55" pos="word" morph="none" start_char="11838" end_char="11846">consumido</TOKEN>
<TOKEN id="token-84-56" pos="word" morph="none" start_char="11848" end_char="11851">este</TOKEN>
<TOKEN id="token-84-57" pos="word" morph="none" start_char="11853" end_char="11856">tipo</TOKEN>
<TOKEN id="token-84-58" pos="word" morph="none" start_char="11858" end_char="11859">de</TOKEN>
<TOKEN id="token-84-59" pos="word" morph="none" start_char="11861" end_char="11868">especies</TOKEN>
<TOKEN id="token-84-60" pos="word" morph="none" start_char="11870" end_char="11879">silvestres</TOKEN>
<TOKEN id="token-84-61" pos="word" morph="none" start_char="11881" end_char="11888">salvajes</TOKEN>
<TOKEN id="token-84-62" pos="punct" morph="none" start_char="11889" end_char="11889">.</TOKEN>
</SEG>
<SEG id="segment-85" start_char="11891" end_char="11994">
<ORIGINAL_TEXT>Nos pueden llamar "conspiranoicos "pero el peor ciego es el que no quiere ver, la realidad que le rodea.</ORIGINAL_TEXT>
<TOKEN id="token-85-0" pos="word" morph="none" start_char="11891" end_char="11893">Nos</TOKEN>
<TOKEN id="token-85-1" pos="word" morph="none" start_char="11895" end_char="11900">pueden</TOKEN>
<TOKEN id="token-85-2" pos="word" morph="none" start_char="11902" end_char="11907">llamar</TOKEN>
<TOKEN id="token-85-3" pos="punct" morph="none" start_char="11909" end_char="11909">"</TOKEN>
<TOKEN id="token-85-4" pos="word" morph="none" start_char="11910" end_char="11923">conspiranoicos</TOKEN>
<TOKEN id="token-85-5" pos="punct" morph="none" start_char="11925" end_char="11925">"</TOKEN>
<TOKEN id="token-85-6" pos="word" morph="none" start_char="11926" end_char="11929">pero</TOKEN>
<TOKEN id="token-85-7" pos="word" morph="none" start_char="11931" end_char="11932">el</TOKEN>
<TOKEN id="token-85-8" pos="word" morph="none" start_char="11934" end_char="11937">peor</TOKEN>
<TOKEN id="token-85-9" pos="word" morph="none" start_char="11939" end_char="11943">ciego</TOKEN>
<TOKEN id="token-85-10" pos="word" morph="none" start_char="11945" end_char="11946">es</TOKEN>
<TOKEN id="token-85-11" pos="word" morph="none" start_char="11948" end_char="11949">el</TOKEN>
<TOKEN id="token-85-12" pos="word" morph="none" start_char="11951" end_char="11953">que</TOKEN>
<TOKEN id="token-85-13" pos="word" morph="none" start_char="11955" end_char="11956">no</TOKEN>
<TOKEN id="token-85-14" pos="word" morph="none" start_char="11958" end_char="11963">quiere</TOKEN>
<TOKEN id="token-85-15" pos="word" morph="none" start_char="11965" end_char="11967">ver</TOKEN>
<TOKEN id="token-85-16" pos="punct" morph="none" start_char="11968" end_char="11968">,</TOKEN>
<TOKEN id="token-85-17" pos="word" morph="none" start_char="11970" end_char="11971">la</TOKEN>
<TOKEN id="token-85-18" pos="word" morph="none" start_char="11973" end_char="11980">realidad</TOKEN>
<TOKEN id="token-85-19" pos="word" morph="none" start_char="11982" end_char="11984">que</TOKEN>
<TOKEN id="token-85-20" pos="word" morph="none" start_char="11986" end_char="11987">le</TOKEN>
<TOKEN id="token-85-21" pos="word" morph="none" start_char="11989" end_char="11993">rodea</TOKEN>
<TOKEN id="token-85-22" pos="punct" morph="none" start_char="11994" end_char="11994">.</TOKEN>
</SEG>
<SEG id="segment-86" start_char="11998" end_char="12004">
<ORIGINAL_TEXT>Exacto.</ORIGINAL_TEXT>
<TOKEN id="token-86-0" pos="word" morph="none" start_char="11998" end_char="12003">Exacto</TOKEN>
<TOKEN id="token-86-1" pos="punct" morph="none" start_char="12004" end_char="12004">.</TOKEN>
</SEG>
<SEG id="segment-87" start_char="12006" end_char="12072">
<ORIGINAL_TEXT>Cuando surge esto el gobierno chino lo mantiene en oculto ¿por qué?</ORIGINAL_TEXT>
<TOKEN id="token-87-0" pos="word" morph="none" start_char="12006" end_char="12011">Cuando</TOKEN>
<TOKEN id="token-87-1" pos="word" morph="none" start_char="12013" end_char="12017">surge</TOKEN>
<TOKEN id="token-87-2" pos="word" morph="none" start_char="12019" end_char="12022">esto</TOKEN>
<TOKEN id="token-87-3" pos="word" morph="none" start_char="12024" end_char="12025">el</TOKEN>
<TOKEN id="token-87-4" pos="word" morph="none" start_char="12027" end_char="12034">gobierno</TOKEN>
<TOKEN id="token-87-5" pos="word" morph="none" start_char="12036" end_char="12040">chino</TOKEN>
<TOKEN id="token-87-6" pos="word" morph="none" start_char="12042" end_char="12043">lo</TOKEN>
<TOKEN id="token-87-7" pos="word" morph="none" start_char="12045" end_char="12052">mantiene</TOKEN>
<TOKEN id="token-87-8" pos="word" morph="none" start_char="12054" end_char="12055">en</TOKEN>
<TOKEN id="token-87-9" pos="word" morph="none" start_char="12057" end_char="12062">oculto</TOKEN>
<TOKEN id="token-87-10" pos="punct" morph="none" start_char="12064" end_char="12064">¿</TOKEN>
<TOKEN id="token-87-11" pos="word" morph="none" start_char="12065" end_char="12067">por</TOKEN>
<TOKEN id="token-87-12" pos="word" morph="none" start_char="12069" end_char="12071">qué</TOKEN>
<TOKEN id="token-87-13" pos="punct" morph="none" start_char="12072" end_char="12072">?</TOKEN>
</SEG>
<SEG id="segment-88" start_char="12074" end_char="12201">
<ORIGINAL_TEXT>si ellos no tuvieran la culpa ¿por que meter en la cárcel y tachar de antipatrióticos a los médicos que daban la voz de alarma?.</ORIGINAL_TEXT>
<TOKEN id="token-88-0" pos="word" morph="none" start_char="12074" end_char="12075">si</TOKEN>
<TOKEN id="token-88-1" pos="word" morph="none" start_char="12077" end_char="12081">ellos</TOKEN>
<TOKEN id="token-88-2" pos="word" morph="none" start_char="12083" end_char="12084">no</TOKEN>
<TOKEN id="token-88-3" pos="word" morph="none" start_char="12086" end_char="12093">tuvieran</TOKEN>
<TOKEN id="token-88-4" pos="word" morph="none" start_char="12095" end_char="12096">la</TOKEN>
<TOKEN id="token-88-5" pos="word" morph="none" start_char="12098" end_char="12102">culpa</TOKEN>
<TOKEN id="token-88-6" pos="punct" morph="none" start_char="12104" end_char="12104">¿</TOKEN>
<TOKEN id="token-88-7" pos="word" morph="none" start_char="12105" end_char="12107">por</TOKEN>
<TOKEN id="token-88-8" pos="word" morph="none" start_char="12109" end_char="12111">que</TOKEN>
<TOKEN id="token-88-9" pos="word" morph="none" start_char="12113" end_char="12117">meter</TOKEN>
<TOKEN id="token-88-10" pos="word" morph="none" start_char="12119" end_char="12120">en</TOKEN>
<TOKEN id="token-88-11" pos="word" morph="none" start_char="12122" end_char="12123">la</TOKEN>
<TOKEN id="token-88-12" pos="word" morph="none" start_char="12125" end_char="12130">cárcel</TOKEN>
<TOKEN id="token-88-13" pos="word" morph="none" start_char="12132" end_char="12132">y</TOKEN>
<TOKEN id="token-88-14" pos="word" morph="none" start_char="12134" end_char="12139">tachar</TOKEN>
<TOKEN id="token-88-15" pos="word" morph="none" start_char="12141" end_char="12142">de</TOKEN>
<TOKEN id="token-88-16" pos="word" morph="none" start_char="12144" end_char="12158">antipatrióticos</TOKEN>
<TOKEN id="token-88-17" pos="word" morph="none" start_char="12160" end_char="12160">a</TOKEN>
<TOKEN id="token-88-18" pos="word" morph="none" start_char="12162" end_char="12164">los</TOKEN>
<TOKEN id="token-88-19" pos="word" morph="none" start_char="12166" end_char="12172">médicos</TOKEN>
<TOKEN id="token-88-20" pos="word" morph="none" start_char="12174" end_char="12176">que</TOKEN>
<TOKEN id="token-88-21" pos="word" morph="none" start_char="12178" end_char="12182">daban</TOKEN>
<TOKEN id="token-88-22" pos="word" morph="none" start_char="12184" end_char="12185">la</TOKEN>
<TOKEN id="token-88-23" pos="word" morph="none" start_char="12187" end_char="12189">voz</TOKEN>
<TOKEN id="token-88-24" pos="word" morph="none" start_char="12191" end_char="12192">de</TOKEN>
<TOKEN id="token-88-25" pos="word" morph="none" start_char="12194" end_char="12199">alarma</TOKEN>
<TOKEN id="token-88-26" pos="punct" morph="none" start_char="12200" end_char="12201">?.</TOKEN>
</SEG>
<SEG id="segment-89" start_char="12203" end_char="12271">
<ORIGINAL_TEXT>No permitieron que entraran a investigar médicos de la OMS, ¿por qué?</ORIGINAL_TEXT>
<TOKEN id="token-89-0" pos="word" morph="none" start_char="12203" end_char="12204">No</TOKEN>
<TOKEN id="token-89-1" pos="word" morph="none" start_char="12206" end_char="12216">permitieron</TOKEN>
<TOKEN id="token-89-2" pos="word" morph="none" start_char="12218" end_char="12220">que</TOKEN>
<TOKEN id="token-89-3" pos="word" morph="none" start_char="12222" end_char="12229">entraran</TOKEN>
<TOKEN id="token-89-4" pos="word" morph="none" start_char="12231" end_char="12231">a</TOKEN>
<TOKEN id="token-89-5" pos="word" morph="none" start_char="12233" end_char="12242">investigar</TOKEN>
<TOKEN id="token-89-6" pos="word" morph="none" start_char="12244" end_char="12250">médicos</TOKEN>
<TOKEN id="token-89-7" pos="word" morph="none" start_char="12252" end_char="12253">de</TOKEN>
<TOKEN id="token-89-8" pos="word" morph="none" start_char="12255" end_char="12256">la</TOKEN>
<TOKEN id="token-89-9" pos="word" morph="none" start_char="12258" end_char="12260">OMS</TOKEN>
<TOKEN id="token-89-10" pos="punct" morph="none" start_char="12261" end_char="12261">,</TOKEN>
<TOKEN id="token-89-11" pos="punct" morph="none" start_char="12263" end_char="12263">¿</TOKEN>
<TOKEN id="token-89-12" pos="word" morph="none" start_char="12264" end_char="12266">por</TOKEN>
<TOKEN id="token-89-13" pos="word" morph="none" start_char="12268" end_char="12270">qué</TOKEN>
<TOKEN id="token-89-14" pos="punct" morph="none" start_char="12271" end_char="12271">?</TOKEN>
</SEG>
<SEG id="segment-90" start_char="12273" end_char="12356">
<ORIGINAL_TEXT>muy sencillo tenían algo que ocultar, es que es tan claro que es insultante negarlo.</ORIGINAL_TEXT>
<TOKEN id="token-90-0" pos="word" morph="none" start_char="12273" end_char="12275">muy</TOKEN>
<TOKEN id="token-90-1" pos="word" morph="none" start_char="12277" end_char="12284">sencillo</TOKEN>
<TOKEN id="token-90-2" pos="word" morph="none" start_char="12286" end_char="12291">tenían</TOKEN>
<TOKEN id="token-90-3" pos="word" morph="none" start_char="12293" end_char="12296">algo</TOKEN>
<TOKEN id="token-90-4" pos="word" morph="none" start_char="12298" end_char="12300">que</TOKEN>
<TOKEN id="token-90-5" pos="word" morph="none" start_char="12302" end_char="12308">ocultar</TOKEN>
<TOKEN id="token-90-6" pos="punct" morph="none" start_char="12309" end_char="12309">,</TOKEN>
<TOKEN id="token-90-7" pos="word" morph="none" start_char="12311" end_char="12312">es</TOKEN>
<TOKEN id="token-90-8" pos="word" morph="none" start_char="12314" end_char="12316">que</TOKEN>
<TOKEN id="token-90-9" pos="word" morph="none" start_char="12318" end_char="12319">es</TOKEN>
<TOKEN id="token-90-10" pos="word" morph="none" start_char="12321" end_char="12323">tan</TOKEN>
<TOKEN id="token-90-11" pos="word" morph="none" start_char="12325" end_char="12329">claro</TOKEN>
<TOKEN id="token-90-12" pos="word" morph="none" start_char="12331" end_char="12333">que</TOKEN>
<TOKEN id="token-90-13" pos="word" morph="none" start_char="12335" end_char="12336">es</TOKEN>
<TOKEN id="token-90-14" pos="word" morph="none" start_char="12338" end_char="12347">insultante</TOKEN>
<TOKEN id="token-90-15" pos="word" morph="none" start_char="12349" end_char="12355">negarlo</TOKEN>
<TOKEN id="token-90-16" pos="punct" morph="none" start_char="12356" end_char="12356">.</TOKEN>
</SEG>
<SEG id="segment-91" start_char="12358" end_char="12553">
<ORIGINAL_TEXT>Una vez que esto se les va de las manos y tiene cientos de miles de infectados y muertos no tiene más remedios y confiesan el problema, pero claro ellos no tiene la culpa esto es algo "natural"...</ORIGINAL_TEXT>
<TOKEN id="token-91-0" pos="word" morph="none" start_char="12358" end_char="12360">Una</TOKEN>
<TOKEN id="token-91-1" pos="word" morph="none" start_char="12362" end_char="12364">vez</TOKEN>
<TOKEN id="token-91-2" pos="word" morph="none" start_char="12366" end_char="12368">que</TOKEN>
<TOKEN id="token-91-3" pos="word" morph="none" start_char="12370" end_char="12373">esto</TOKEN>
<TOKEN id="token-91-4" pos="word" morph="none" start_char="12375" end_char="12376">se</TOKEN>
<TOKEN id="token-91-5" pos="word" morph="none" start_char="12378" end_char="12380">les</TOKEN>
<TOKEN id="token-91-6" pos="word" morph="none" start_char="12382" end_char="12383">va</TOKEN>
<TOKEN id="token-91-7" pos="word" morph="none" start_char="12385" end_char="12386">de</TOKEN>
<TOKEN id="token-91-8" pos="word" morph="none" start_char="12388" end_char="12390">las</TOKEN>
<TOKEN id="token-91-9" pos="word" morph="none" start_char="12392" end_char="12396">manos</TOKEN>
<TOKEN id="token-91-10" pos="word" morph="none" start_char="12398" end_char="12398">y</TOKEN>
<TOKEN id="token-91-11" pos="word" morph="none" start_char="12400" end_char="12404">tiene</TOKEN>
<TOKEN id="token-91-12" pos="word" morph="none" start_char="12406" end_char="12412">cientos</TOKEN>
<TOKEN id="token-91-13" pos="word" morph="none" start_char="12414" end_char="12415">de</TOKEN>
<TOKEN id="token-91-14" pos="word" morph="none" start_char="12417" end_char="12421">miles</TOKEN>
<TOKEN id="token-91-15" pos="word" morph="none" start_char="12423" end_char="12424">de</TOKEN>
<TOKEN id="token-91-16" pos="word" morph="none" start_char="12426" end_char="12435">infectados</TOKEN>
<TOKEN id="token-91-17" pos="word" morph="none" start_char="12437" end_char="12437">y</TOKEN>
<TOKEN id="token-91-18" pos="word" morph="none" start_char="12439" end_char="12445">muertos</TOKEN>
<TOKEN id="token-91-19" pos="word" morph="none" start_char="12447" end_char="12448">no</TOKEN>
<TOKEN id="token-91-20" pos="word" morph="none" start_char="12450" end_char="12454">tiene</TOKEN>
<TOKEN id="token-91-21" pos="word" morph="none" start_char="12456" end_char="12458">más</TOKEN>
<TOKEN id="token-91-22" pos="word" morph="none" start_char="12460" end_char="12467">remedios</TOKEN>
<TOKEN id="token-91-23" pos="word" morph="none" start_char="12469" end_char="12469">y</TOKEN>
<TOKEN id="token-91-24" pos="word" morph="none" start_char="12471" end_char="12479">confiesan</TOKEN>
<TOKEN id="token-91-25" pos="word" morph="none" start_char="12481" end_char="12482">el</TOKEN>
<TOKEN id="token-91-26" pos="word" morph="none" start_char="12484" end_char="12491">problema</TOKEN>
<TOKEN id="token-91-27" pos="punct" morph="none" start_char="12492" end_char="12492">,</TOKEN>
<TOKEN id="token-91-28" pos="word" morph="none" start_char="12494" end_char="12497">pero</TOKEN>
<TOKEN id="token-91-29" pos="word" morph="none" start_char="12499" end_char="12503">claro</TOKEN>
<TOKEN id="token-91-30" pos="word" morph="none" start_char="12505" end_char="12509">ellos</TOKEN>
<TOKEN id="token-91-31" pos="word" morph="none" start_char="12511" end_char="12512">no</TOKEN>
<TOKEN id="token-91-32" pos="word" morph="none" start_char="12514" end_char="12518">tiene</TOKEN>
<TOKEN id="token-91-33" pos="word" morph="none" start_char="12520" end_char="12521">la</TOKEN>
<TOKEN id="token-91-34" pos="word" morph="none" start_char="12523" end_char="12527">culpa</TOKEN>
<TOKEN id="token-91-35" pos="word" morph="none" start_char="12529" end_char="12532">esto</TOKEN>
<TOKEN id="token-91-36" pos="word" morph="none" start_char="12534" end_char="12535">es</TOKEN>
<TOKEN id="token-91-37" pos="word" morph="none" start_char="12537" end_char="12540">algo</TOKEN>
<TOKEN id="token-91-38" pos="punct" morph="none" start_char="12542" end_char="12542">"</TOKEN>
<TOKEN id="token-91-39" pos="word" morph="none" start_char="12543" end_char="12549">natural</TOKEN>
<TOKEN id="token-91-40" pos="punct" morph="none" start_char="12550" end_char="12553">"...</TOKEN>
</SEG>
<SEG id="segment-92" start_char="12555" end_char="12721">
<ORIGINAL_TEXT>Por otro lado a los pocos días publican el genoma completo del virus y además disponibles en tiempo record y preparados para distribuirse cientos de miles de test pcr.</ORIGINAL_TEXT>
<TOKEN id="token-92-0" pos="word" morph="none" start_char="12555" end_char="12557">Por</TOKEN>
<TOKEN id="token-92-1" pos="word" morph="none" start_char="12559" end_char="12562">otro</TOKEN>
<TOKEN id="token-92-2" pos="word" morph="none" start_char="12564" end_char="12567">lado</TOKEN>
<TOKEN id="token-92-3" pos="word" morph="none" start_char="12569" end_char="12569">a</TOKEN>
<TOKEN id="token-92-4" pos="word" morph="none" start_char="12571" end_char="12573">los</TOKEN>
<TOKEN id="token-92-5" pos="word" morph="none" start_char="12575" end_char="12579">pocos</TOKEN>
<TOKEN id="token-92-6" pos="word" morph="none" start_char="12581" end_char="12584">días</TOKEN>
<TOKEN id="token-92-7" pos="word" morph="none" start_char="12586" end_char="12593">publican</TOKEN>
<TOKEN id="token-92-8" pos="word" morph="none" start_char="12595" end_char="12596">el</TOKEN>
<TOKEN id="token-92-9" pos="word" morph="none" start_char="12598" end_char="12603">genoma</TOKEN>
<TOKEN id="token-92-10" pos="word" morph="none" start_char="12605" end_char="12612">completo</TOKEN>
<TOKEN id="token-92-11" pos="word" morph="none" start_char="12614" end_char="12616">del</TOKEN>
<TOKEN id="token-92-12" pos="word" morph="none" start_char="12618" end_char="12622">virus</TOKEN>
<TOKEN id="token-92-13" pos="word" morph="none" start_char="12624" end_char="12624">y</TOKEN>
<TOKEN id="token-92-14" pos="word" morph="none" start_char="12626" end_char="12631">además</TOKEN>
<TOKEN id="token-92-15" pos="word" morph="none" start_char="12633" end_char="12643">disponibles</TOKEN>
<TOKEN id="token-92-16" pos="word" morph="none" start_char="12645" end_char="12646">en</TOKEN>
<TOKEN id="token-92-17" pos="word" morph="none" start_char="12648" end_char="12653">tiempo</TOKEN>
<TOKEN id="token-92-18" pos="word" morph="none" start_char="12655" end_char="12660">record</TOKEN>
<TOKEN id="token-92-19" pos="word" morph="none" start_char="12662" end_char="12662">y</TOKEN>
<TOKEN id="token-92-20" pos="word" morph="none" start_char="12664" end_char="12673">preparados</TOKEN>
<TOKEN id="token-92-21" pos="word" morph="none" start_char="12675" end_char="12678">para</TOKEN>
<TOKEN id="token-92-22" pos="word" morph="none" start_char="12680" end_char="12691">distribuirse</TOKEN>
<TOKEN id="token-92-23" pos="word" morph="none" start_char="12693" end_char="12699">cientos</TOKEN>
<TOKEN id="token-92-24" pos="word" morph="none" start_char="12701" end_char="12702">de</TOKEN>
<TOKEN id="token-92-25" pos="word" morph="none" start_char="12704" end_char="12708">miles</TOKEN>
<TOKEN id="token-92-26" pos="word" morph="none" start_char="12710" end_char="12711">de</TOKEN>
<TOKEN id="token-92-27" pos="word" morph="none" start_char="12713" end_char="12716">test</TOKEN>
<TOKEN id="token-92-28" pos="word" morph="none" start_char="12718" end_char="12720">pcr</TOKEN>
<TOKEN id="token-92-29" pos="punct" morph="none" start_char="12721" end_char="12721">.</TOKEN>
</SEG>
<SEG id="segment-93" start_char="12723" end_char="13062">
<ORIGINAL_TEXT>Y ahora los chinos nos quieren hacer creer que un murciélago que vive a 800 km de Wuhan y que la época en que aparece está invernando en cuevas profundas se ha vendido en un mercado de mariscos (donde no se vende murcielago ni mamiferos) y que además despues de miles de años comiendose murciélagos ahora a infectado a un humano, porque sí.</ORIGINAL_TEXT>
<TOKEN id="token-93-0" pos="word" morph="none" start_char="12723" end_char="12723">Y</TOKEN>
<TOKEN id="token-93-1" pos="word" morph="none" start_char="12725" end_char="12729">ahora</TOKEN>
<TOKEN id="token-93-2" pos="word" morph="none" start_char="12731" end_char="12733">los</TOKEN>
<TOKEN id="token-93-3" pos="word" morph="none" start_char="12735" end_char="12740">chinos</TOKEN>
<TOKEN id="token-93-4" pos="word" morph="none" start_char="12742" end_char="12744">nos</TOKEN>
<TOKEN id="token-93-5" pos="word" morph="none" start_char="12746" end_char="12752">quieren</TOKEN>
<TOKEN id="token-93-6" pos="word" morph="none" start_char="12754" end_char="12758">hacer</TOKEN>
<TOKEN id="token-93-7" pos="word" morph="none" start_char="12760" end_char="12764">creer</TOKEN>
<TOKEN id="token-93-8" pos="word" morph="none" start_char="12766" end_char="12768">que</TOKEN>
<TOKEN id="token-93-9" pos="word" morph="none" start_char="12770" end_char="12771">un</TOKEN>
<TOKEN id="token-93-10" pos="word" morph="none" start_char="12773" end_char="12782">murciélago</TOKEN>
<TOKEN id="token-93-11" pos="word" morph="none" start_char="12784" end_char="12786">que</TOKEN>
<TOKEN id="token-93-12" pos="word" morph="none" start_char="12788" end_char="12791">vive</TOKEN>
<TOKEN id="token-93-13" pos="word" morph="none" start_char="12793" end_char="12793">a</TOKEN>
<TOKEN id="token-93-14" pos="word" morph="none" start_char="12795" end_char="12797">800</TOKEN>
<TOKEN id="token-93-15" pos="word" morph="none" start_char="12799" end_char="12800">km</TOKEN>
<TOKEN id="token-93-16" pos="word" morph="none" start_char="12802" end_char="12803">de</TOKEN>
<TOKEN id="token-93-17" pos="word" morph="none" start_char="12805" end_char="12809">Wuhan</TOKEN>
<TOKEN id="token-93-18" pos="word" morph="none" start_char="12811" end_char="12811">y</TOKEN>
<TOKEN id="token-93-19" pos="word" morph="none" start_char="12813" end_char="12815">que</TOKEN>
<TOKEN id="token-93-20" pos="word" morph="none" start_char="12817" end_char="12818">la</TOKEN>
<TOKEN id="token-93-21" pos="word" morph="none" start_char="12820" end_char="12824">época</TOKEN>
<TOKEN id="token-93-22" pos="word" morph="none" start_char="12826" end_char="12827">en</TOKEN>
<TOKEN id="token-93-23" pos="word" morph="none" start_char="12829" end_char="12831">que</TOKEN>
<TOKEN id="token-93-24" pos="word" morph="none" start_char="12833" end_char="12839">aparece</TOKEN>
<TOKEN id="token-93-25" pos="word" morph="none" start_char="12841" end_char="12844">está</TOKEN>
<TOKEN id="token-93-26" pos="word" morph="none" start_char="12846" end_char="12855">invernando</TOKEN>
<TOKEN id="token-93-27" pos="word" morph="none" start_char="12857" end_char="12858">en</TOKEN>
<TOKEN id="token-93-28" pos="word" morph="none" start_char="12860" end_char="12865">cuevas</TOKEN>
<TOKEN id="token-93-29" pos="word" morph="none" start_char="12867" end_char="12875">profundas</TOKEN>
<TOKEN id="token-93-30" pos="word" morph="none" start_char="12877" end_char="12878">se</TOKEN>
<TOKEN id="token-93-31" pos="word" morph="none" start_char="12880" end_char="12881">ha</TOKEN>
<TOKEN id="token-93-32" pos="word" morph="none" start_char="12883" end_char="12889">vendido</TOKEN>
<TOKEN id="token-93-33" pos="word" morph="none" start_char="12891" end_char="12892">en</TOKEN>
<TOKEN id="token-93-34" pos="word" morph="none" start_char="12894" end_char="12895">un</TOKEN>
<TOKEN id="token-93-35" pos="word" morph="none" start_char="12897" end_char="12903">mercado</TOKEN>
<TOKEN id="token-93-36" pos="word" morph="none" start_char="12905" end_char="12906">de</TOKEN>
<TOKEN id="token-93-37" pos="word" morph="none" start_char="12908" end_char="12915">mariscos</TOKEN>
<TOKEN id="token-93-38" pos="punct" morph="none" start_char="12917" end_char="12917">(</TOKEN>
<TOKEN id="token-93-39" pos="word" morph="none" start_char="12918" end_char="12922">donde</TOKEN>
<TOKEN id="token-93-40" pos="word" morph="none" start_char="12924" end_char="12925">no</TOKEN>
<TOKEN id="token-93-41" pos="word" morph="none" start_char="12927" end_char="12928">se</TOKEN>
<TOKEN id="token-93-42" pos="word" morph="none" start_char="12930" end_char="12934">vende</TOKEN>
<TOKEN id="token-93-43" pos="word" morph="none" start_char="12936" end_char="12945">murcielago</TOKEN>
<TOKEN id="token-93-44" pos="word" morph="none" start_char="12947" end_char="12948">ni</TOKEN>
<TOKEN id="token-93-45" pos="word" morph="none" start_char="12950" end_char="12958">mamiferos</TOKEN>
<TOKEN id="token-93-46" pos="punct" morph="none" start_char="12959" end_char="12959">)</TOKEN>
<TOKEN id="token-93-47" pos="word" morph="none" start_char="12961" end_char="12961">y</TOKEN>
<TOKEN id="token-93-48" pos="word" morph="none" start_char="12963" end_char="12965">que</TOKEN>
<TOKEN id="token-93-49" pos="word" morph="none" start_char="12967" end_char="12972">además</TOKEN>
<TOKEN id="token-93-50" pos="word" morph="none" start_char="12974" end_char="12980">despues</TOKEN>
<TOKEN id="token-93-51" pos="word" morph="none" start_char="12982" end_char="12983">de</TOKEN>
<TOKEN id="token-93-52" pos="word" morph="none" start_char="12985" end_char="12989">miles</TOKEN>
<TOKEN id="token-93-53" pos="word" morph="none" start_char="12991" end_char="12992">de</TOKEN>
<TOKEN id="token-93-54" pos="word" morph="none" start_char="12994" end_char="12997">años</TOKEN>
<TOKEN id="token-93-55" pos="word" morph="none" start_char="12999" end_char="13008">comiendose</TOKEN>
<TOKEN id="token-93-56" pos="word" morph="none" start_char="13010" end_char="13020">murciélagos</TOKEN>
<TOKEN id="token-93-57" pos="word" morph="none" start_char="13022" end_char="13026">ahora</TOKEN>
<TOKEN id="token-93-58" pos="word" morph="none" start_char="13028" end_char="13028">a</TOKEN>
<TOKEN id="token-93-59" pos="word" morph="none" start_char="13030" end_char="13038">infectado</TOKEN>
<TOKEN id="token-93-60" pos="word" morph="none" start_char="13040" end_char="13040">a</TOKEN>
<TOKEN id="token-93-61" pos="word" morph="none" start_char="13042" end_char="13043">un</TOKEN>
<TOKEN id="token-93-62" pos="word" morph="none" start_char="13045" end_char="13050">humano</TOKEN>
<TOKEN id="token-93-63" pos="punct" morph="none" start_char="13051" end_char="13051">,</TOKEN>
<TOKEN id="token-93-64" pos="word" morph="none" start_char="13053" end_char="13058">porque</TOKEN>
<TOKEN id="token-93-65" pos="word" morph="none" start_char="13060" end_char="13061">sí</TOKEN>
<TOKEN id="token-93-66" pos="punct" morph="none" start_char="13062" end_char="13062">.</TOKEN>
</SEG>
<SEG id="segment-94" start_char="13064" end_char="13388">
<ORIGINAL_TEXT>En cambio tratan de que veamos imposible que un labortatorio, denunciado por la CIA de ser poco seguro,para el nivel 4 de bioseguridad que dice tener y saberse que tratan genéticamente virus como el murciélago para usarlo como arma biológica y que además está a 300 metros del mercado famoso no ha sido la causa más probable.</ORIGINAL_TEXT>
<TOKEN id="token-94-0" pos="word" morph="none" start_char="13064" end_char="13065">En</TOKEN>
<TOKEN id="token-94-1" pos="word" morph="none" start_char="13067" end_char="13072">cambio</TOKEN>
<TOKEN id="token-94-2" pos="word" morph="none" start_char="13074" end_char="13079">tratan</TOKEN>
<TOKEN id="token-94-3" pos="word" morph="none" start_char="13081" end_char="13082">de</TOKEN>
<TOKEN id="token-94-4" pos="word" morph="none" start_char="13084" end_char="13086">que</TOKEN>
<TOKEN id="token-94-5" pos="word" morph="none" start_char="13088" end_char="13093">veamos</TOKEN>
<TOKEN id="token-94-6" pos="word" morph="none" start_char="13095" end_char="13103">imposible</TOKEN>
<TOKEN id="token-94-7" pos="word" morph="none" start_char="13105" end_char="13107">que</TOKEN>
<TOKEN id="token-94-8" pos="word" morph="none" start_char="13109" end_char="13110">un</TOKEN>
<TOKEN id="token-94-9" pos="word" morph="none" start_char="13112" end_char="13123">labortatorio</TOKEN>
<TOKEN id="token-94-10" pos="punct" morph="none" start_char="13124" end_char="13124">,</TOKEN>
<TOKEN id="token-94-11" pos="word" morph="none" start_char="13126" end_char="13135">denunciado</TOKEN>
<TOKEN id="token-94-12" pos="word" morph="none" start_char="13137" end_char="13139">por</TOKEN>
<TOKEN id="token-94-13" pos="word" morph="none" start_char="13141" end_char="13142">la</TOKEN>
<TOKEN id="token-94-14" pos="word" morph="none" start_char="13144" end_char="13146">CIA</TOKEN>
<TOKEN id="token-94-15" pos="word" morph="none" start_char="13148" end_char="13149">de</TOKEN>
<TOKEN id="token-94-16" pos="word" morph="none" start_char="13151" end_char="13153">ser</TOKEN>
<TOKEN id="token-94-17" pos="word" morph="none" start_char="13155" end_char="13158">poco</TOKEN>
<TOKEN id="token-94-18" pos="unknown" morph="none" start_char="13160" end_char="13170">seguro,para</TOKEN>
<TOKEN id="token-94-19" pos="word" morph="none" start_char="13172" end_char="13173">el</TOKEN>
<TOKEN id="token-94-20" pos="word" morph="none" start_char="13175" end_char="13179">nivel</TOKEN>
<TOKEN id="token-94-21" pos="word" morph="none" start_char="13181" end_char="13181">4</TOKEN>
<TOKEN id="token-94-22" pos="word" morph="none" start_char="13183" end_char="13184">de</TOKEN>
<TOKEN id="token-94-23" pos="word" morph="none" start_char="13186" end_char="13197">bioseguridad</TOKEN>
<TOKEN id="token-94-24" pos="word" morph="none" start_char="13199" end_char="13201">que</TOKEN>
<TOKEN id="token-94-25" pos="word" morph="none" start_char="13203" end_char="13206">dice</TOKEN>
<TOKEN id="token-94-26" pos="word" morph="none" start_char="13208" end_char="13212">tener</TOKEN>
<TOKEN id="token-94-27" pos="word" morph="none" start_char="13214" end_char="13214">y</TOKEN>
<TOKEN id="token-94-28" pos="word" morph="none" start_char="13216" end_char="13222">saberse</TOKEN>
<TOKEN id="token-94-29" pos="word" morph="none" start_char="13224" end_char="13226">que</TOKEN>
<TOKEN id="token-94-30" pos="word" morph="none" start_char="13228" end_char="13233">tratan</TOKEN>
<TOKEN id="token-94-31" pos="word" morph="none" start_char="13235" end_char="13247">genéticamente</TOKEN>
<TOKEN id="token-94-32" pos="word" morph="none" start_char="13249" end_char="13253">virus</TOKEN>
<TOKEN id="token-94-33" pos="word" morph="none" start_char="13255" end_char="13258">como</TOKEN>
<TOKEN id="token-94-34" pos="word" morph="none" start_char="13260" end_char="13261">el</TOKEN>
<TOKEN id="token-94-35" pos="word" morph="none" start_char="13263" end_char="13272">murciélago</TOKEN>
<TOKEN id="token-94-36" pos="word" morph="none" start_char="13274" end_char="13277">para</TOKEN>
<TOKEN id="token-94-37" pos="word" morph="none" start_char="13279" end_char="13284">usarlo</TOKEN>
<TOKEN id="token-94-38" pos="word" morph="none" start_char="13286" end_char="13289">como</TOKEN>
<TOKEN id="token-94-39" pos="word" morph="none" start_char="13291" end_char="13294">arma</TOKEN>
<TOKEN id="token-94-40" pos="word" morph="none" start_char="13296" end_char="13304">biológica</TOKEN>
<TOKEN id="token-94-41" pos="word" morph="none" start_char="13306" end_char="13306">y</TOKEN>
<TOKEN id="token-94-42" pos="word" morph="none" start_char="13308" end_char="13310">que</TOKEN>
<TOKEN id="token-94-43" pos="word" morph="none" start_char="13312" end_char="13317">además</TOKEN>
<TOKEN id="token-94-44" pos="word" morph="none" start_char="13319" end_char="13322">está</TOKEN>
<TOKEN id="token-94-45" pos="word" morph="none" start_char="13324" end_char="13324">a</TOKEN>
<TOKEN id="token-94-46" pos="word" morph="none" start_char="13326" end_char="13328">300</TOKEN>
<TOKEN id="token-94-47" pos="word" morph="none" start_char="13330" end_char="13335">metros</TOKEN>
<TOKEN id="token-94-48" pos="word" morph="none" start_char="13337" end_char="13339">del</TOKEN>
<TOKEN id="token-94-49" pos="word" morph="none" start_char="13341" end_char="13347">mercado</TOKEN>
<TOKEN id="token-94-50" pos="word" morph="none" start_char="13349" end_char="13354">famoso</TOKEN>
<TOKEN id="token-94-51" pos="word" morph="none" start_char="13356" end_char="13357">no</TOKEN>
<TOKEN id="token-94-52" pos="word" morph="none" start_char="13359" end_char="13360">ha</TOKEN>
<TOKEN id="token-94-53" pos="word" morph="none" start_char="13362" end_char="13365">sido</TOKEN>
<TOKEN id="token-94-54" pos="word" morph="none" start_char="13367" end_char="13368">la</TOKEN>
<TOKEN id="token-94-55" pos="word" morph="none" start_char="13370" end_char="13374">causa</TOKEN>
<TOKEN id="token-94-56" pos="word" morph="none" start_char="13376" end_char="13378">más</TOKEN>
<TOKEN id="token-94-57" pos="word" morph="none" start_char="13380" end_char="13387">probable</TOKEN>
<TOKEN id="token-94-58" pos="punct" morph="none" start_char="13388" end_char="13388">.</TOKEN>
</SEG>
<SEG id="segment-95" start_char="13390" end_char="13409">
<ORIGINAL_TEXT>Blanco y en botella.</ORIGINAL_TEXT>
<TOKEN id="token-95-0" pos="word" morph="none" start_char="13390" end_char="13395">Blanco</TOKEN>
<TOKEN id="token-95-1" pos="word" morph="none" start_char="13397" end_char="13397">y</TOKEN>
<TOKEN id="token-95-2" pos="word" morph="none" start_char="13399" end_char="13400">en</TOKEN>
<TOKEN id="token-95-3" pos="word" morph="none" start_char="13402" end_char="13408">botella</TOKEN>
<TOKEN id="token-95-4" pos="punct" morph="none" start_char="13409" end_char="13409">.</TOKEN>
</SEG>
<SEG id="segment-96" start_char="13411" end_char="13610">
<ORIGINAL_TEXT>Los chinos saben que si esto se descubre, su metedura de pata, las demandas millonarias serían inasumibles, así que pagan, niegan y reniegan aunque la explicación que den sea para niños de parbulitos.</ORIGINAL_TEXT>
<TOKEN id="token-96-0" pos="word" morph="none" start_char="13411" end_char="13413">Los</TOKEN>
<TOKEN id="token-96-1" pos="word" morph="none" start_char="13415" end_char="13420">chinos</TOKEN>
<TOKEN id="token-96-2" pos="word" morph="none" start_char="13422" end_char="13426">saben</TOKEN>
<TOKEN id="token-96-3" pos="word" morph="none" start_char="13428" end_char="13430">que</TOKEN>
<TOKEN id="token-96-4" pos="word" morph="none" start_char="13432" end_char="13433">si</TOKEN>
<TOKEN id="token-96-5" pos="word" morph="none" start_char="13435" end_char="13438">esto</TOKEN>
<TOKEN id="token-96-6" pos="word" morph="none" start_char="13440" end_char="13441">se</TOKEN>
<TOKEN id="token-96-7" pos="word" morph="none" start_char="13443" end_char="13450">descubre</TOKEN>
<TOKEN id="token-96-8" pos="punct" morph="none" start_char="13451" end_char="13451">,</TOKEN>
<TOKEN id="token-96-9" pos="word" morph="none" start_char="13453" end_char="13454">su</TOKEN>
<TOKEN id="token-96-10" pos="word" morph="none" start_char="13456" end_char="13463">metedura</TOKEN>
<TOKEN id="token-96-11" pos="word" morph="none" start_char="13465" end_char="13466">de</TOKEN>
<TOKEN id="token-96-12" pos="word" morph="none" start_char="13468" end_char="13471">pata</TOKEN>
<TOKEN id="token-96-13" pos="punct" morph="none" start_char="13472" end_char="13472">,</TOKEN>
<TOKEN id="token-96-14" pos="word" morph="none" start_char="13474" end_char="13476">las</TOKEN>
<TOKEN id="token-96-15" pos="word" morph="none" start_char="13478" end_char="13485">demandas</TOKEN>
<TOKEN id="token-96-16" pos="word" morph="none" start_char="13487" end_char="13497">millonarias</TOKEN>
<TOKEN id="token-96-17" pos="word" morph="none" start_char="13499" end_char="13504">serían</TOKEN>
<TOKEN id="token-96-18" pos="word" morph="none" start_char="13506" end_char="13516">inasumibles</TOKEN>
<TOKEN id="token-96-19" pos="punct" morph="none" start_char="13517" end_char="13517">,</TOKEN>
<TOKEN id="token-96-20" pos="word" morph="none" start_char="13519" end_char="13521">así</TOKEN>
<TOKEN id="token-96-21" pos="word" morph="none" start_char="13523" end_char="13525">que</TOKEN>
<TOKEN id="token-96-22" pos="word" morph="none" start_char="13527" end_char="13531">pagan</TOKEN>
<TOKEN id="token-96-23" pos="punct" morph="none" start_char="13532" end_char="13532">,</TOKEN>
<TOKEN id="token-96-24" pos="word" morph="none" start_char="13534" end_char="13539">niegan</TOKEN>
<TOKEN id="token-96-25" pos="word" morph="none" start_char="13541" end_char="13541">y</TOKEN>
<TOKEN id="token-96-26" pos="word" morph="none" start_char="13543" end_char="13550">reniegan</TOKEN>
<TOKEN id="token-96-27" pos="word" morph="none" start_char="13552" end_char="13557">aunque</TOKEN>
<TOKEN id="token-96-28" pos="word" morph="none" start_char="13559" end_char="13560">la</TOKEN>
<TOKEN id="token-96-29" pos="word" morph="none" start_char="13562" end_char="13572">explicación</TOKEN>
<TOKEN id="token-96-30" pos="word" morph="none" start_char="13574" end_char="13576">que</TOKEN>
<TOKEN id="token-96-31" pos="word" morph="none" start_char="13578" end_char="13580">den</TOKEN>
<TOKEN id="token-96-32" pos="word" morph="none" start_char="13582" end_char="13584">sea</TOKEN>
<TOKEN id="token-96-33" pos="word" morph="none" start_char="13586" end_char="13589">para</TOKEN>
<TOKEN id="token-96-34" pos="word" morph="none" start_char="13591" end_char="13595">niños</TOKEN>
<TOKEN id="token-96-35" pos="word" morph="none" start_char="13597" end_char="13598">de</TOKEN>
<TOKEN id="token-96-36" pos="word" morph="none" start_char="13600" end_char="13609">parbulitos</TOKEN>
<TOKEN id="token-96-37" pos="punct" morph="none" start_char="13610" end_char="13610">.</TOKEN>
</SEG>
<SEG id="segment-97" start_char="13612" end_char="13754">
<ORIGINAL_TEXT>No os creais a los "científicos" que dicen que es natural están untados, los chinos están gastando mucho para tapar bocas y comprar voluntades.</ORIGINAL_TEXT>
<TOKEN id="token-97-0" pos="word" morph="none" start_char="13612" end_char="13613">No</TOKEN>
<TOKEN id="token-97-1" pos="word" morph="none" start_char="13615" end_char="13616">os</TOKEN>
<TOKEN id="token-97-2" pos="word" morph="none" start_char="13618" end_char="13623">creais</TOKEN>
<TOKEN id="token-97-3" pos="word" morph="none" start_char="13625" end_char="13625">a</TOKEN>
<TOKEN id="token-97-4" pos="word" morph="none" start_char="13627" end_char="13629">los</TOKEN>
<TOKEN id="token-97-5" pos="punct" morph="none" start_char="13631" end_char="13631">"</TOKEN>
<TOKEN id="token-97-6" pos="word" morph="none" start_char="13632" end_char="13642">científicos</TOKEN>
<TOKEN id="token-97-7" pos="punct" morph="none" start_char="13643" end_char="13643">"</TOKEN>
<TOKEN id="token-97-8" pos="word" morph="none" start_char="13645" end_char="13647">que</TOKEN>
<TOKEN id="token-97-9" pos="word" morph="none" start_char="13649" end_char="13653">dicen</TOKEN>
<TOKEN id="token-97-10" pos="word" morph="none" start_char="13655" end_char="13657">que</TOKEN>
<TOKEN id="token-97-11" pos="word" morph="none" start_char="13659" end_char="13660">es</TOKEN>
<TOKEN id="token-97-12" pos="word" morph="none" start_char="13662" end_char="13668">natural</TOKEN>
<TOKEN id="token-97-13" pos="word" morph="none" start_char="13670" end_char="13674">están</TOKEN>
<TOKEN id="token-97-14" pos="word" morph="none" start_char="13676" end_char="13682">untados</TOKEN>
<TOKEN id="token-97-15" pos="punct" morph="none" start_char="13683" end_char="13683">,</TOKEN>
<TOKEN id="token-97-16" pos="word" morph="none" start_char="13685" end_char="13687">los</TOKEN>
<TOKEN id="token-97-17" pos="word" morph="none" start_char="13689" end_char="13694">chinos</TOKEN>
<TOKEN id="token-97-18" pos="word" morph="none" start_char="13696" end_char="13700">están</TOKEN>
<TOKEN id="token-97-19" pos="word" morph="none" start_char="13702" end_char="13709">gastando</TOKEN>
<TOKEN id="token-97-20" pos="word" morph="none" start_char="13711" end_char="13715">mucho</TOKEN>
<TOKEN id="token-97-21" pos="word" morph="none" start_char="13717" end_char="13720">para</TOKEN>
<TOKEN id="token-97-22" pos="word" morph="none" start_char="13722" end_char="13726">tapar</TOKEN>
<TOKEN id="token-97-23" pos="word" morph="none" start_char="13728" end_char="13732">bocas</TOKEN>
<TOKEN id="token-97-24" pos="word" morph="none" start_char="13734" end_char="13734">y</TOKEN>
<TOKEN id="token-97-25" pos="word" morph="none" start_char="13736" end_char="13742">comprar</TOKEN>
<TOKEN id="token-97-26" pos="word" morph="none" start_char="13744" end_char="13753">voluntades</TOKEN>
<TOKEN id="token-97-27" pos="punct" morph="none" start_char="13754" end_char="13754">.</TOKEN>
</SEG>
<SEG id="segment-98" start_char="13756" end_char="13793">
<ORIGINAL_TEXT>Tarde o temprano saldrá todo a la luz.</ORIGINAL_TEXT>
<TOKEN id="token-98-0" pos="word" morph="none" start_char="13756" end_char="13760">Tarde</TOKEN>
<TOKEN id="token-98-1" pos="word" morph="none" start_char="13762" end_char="13762">o</TOKEN>
<TOKEN id="token-98-2" pos="word" morph="none" start_char="13764" end_char="13771">temprano</TOKEN>
<TOKEN id="token-98-3" pos="word" morph="none" start_char="13773" end_char="13778">saldrá</TOKEN>
<TOKEN id="token-98-4" pos="word" morph="none" start_char="13780" end_char="13783">todo</TOKEN>
<TOKEN id="token-98-5" pos="word" morph="none" start_char="13785" end_char="13785">a</TOKEN>
<TOKEN id="token-98-6" pos="word" morph="none" start_char="13787" end_char="13788">la</TOKEN>
<TOKEN id="token-98-7" pos="word" morph="none" start_char="13790" end_char="13792">luz</TOKEN>
<TOKEN id="token-98-8" pos="punct" morph="none" start_char="13793" end_char="13793">.</TOKEN>
</SEG>
<SEG id="segment-99" start_char="13795" end_char="13909">
<ORIGINAL_TEXT>Ya veremos si asumen o no, eso es otra cosa, el mundo en general es muy dependiente de China, hay muchos intereses.</ORIGINAL_TEXT>
<TOKEN id="token-99-0" pos="word" morph="none" start_char="13795" end_char="13796">Ya</TOKEN>
<TOKEN id="token-99-1" pos="word" morph="none" start_char="13798" end_char="13804">veremos</TOKEN>
<TOKEN id="token-99-2" pos="word" morph="none" start_char="13806" end_char="13807">si</TOKEN>
<TOKEN id="token-99-3" pos="word" morph="none" start_char="13809" end_char="13814">asumen</TOKEN>
<TOKEN id="token-99-4" pos="word" morph="none" start_char="13816" end_char="13816">o</TOKEN>
<TOKEN id="token-99-5" pos="word" morph="none" start_char="13818" end_char="13819">no</TOKEN>
<TOKEN id="token-99-6" pos="punct" morph="none" start_char="13820" end_char="13820">,</TOKEN>
<TOKEN id="token-99-7" pos="word" morph="none" start_char="13822" end_char="13824">eso</TOKEN>
<TOKEN id="token-99-8" pos="word" morph="none" start_char="13826" end_char="13827">es</TOKEN>
<TOKEN id="token-99-9" pos="word" morph="none" start_char="13829" end_char="13832">otra</TOKEN>
<TOKEN id="token-99-10" pos="word" morph="none" start_char="13834" end_char="13837">cosa</TOKEN>
<TOKEN id="token-99-11" pos="punct" morph="none" start_char="13838" end_char="13838">,</TOKEN>
<TOKEN id="token-99-12" pos="word" morph="none" start_char="13840" end_char="13841">el</TOKEN>
<TOKEN id="token-99-13" pos="word" morph="none" start_char="13843" end_char="13847">mundo</TOKEN>
<TOKEN id="token-99-14" pos="word" morph="none" start_char="13849" end_char="13850">en</TOKEN>
<TOKEN id="token-99-15" pos="word" morph="none" start_char="13852" end_char="13858">general</TOKEN>
<TOKEN id="token-99-16" pos="word" morph="none" start_char="13860" end_char="13861">es</TOKEN>
<TOKEN id="token-99-17" pos="word" morph="none" start_char="13863" end_char="13865">muy</TOKEN>
<TOKEN id="token-99-18" pos="word" morph="none" start_char="13867" end_char="13877">dependiente</TOKEN>
<TOKEN id="token-99-19" pos="word" morph="none" start_char="13879" end_char="13880">de</TOKEN>
<TOKEN id="token-99-20" pos="word" morph="none" start_char="13882" end_char="13886">China</TOKEN>
<TOKEN id="token-99-21" pos="punct" morph="none" start_char="13887" end_char="13887">,</TOKEN>
<TOKEN id="token-99-22" pos="word" morph="none" start_char="13889" end_char="13891">hay</TOKEN>
<TOKEN id="token-99-23" pos="word" morph="none" start_char="13893" end_char="13898">muchos</TOKEN>
<TOKEN id="token-99-24" pos="word" morph="none" start_char="13900" end_char="13908">intereses</TOKEN>
<TOKEN id="token-99-25" pos="punct" morph="none" start_char="13909" end_char="13909">.</TOKEN>
</SEG>
<SEG id="segment-100" start_char="13913" end_char="14071">
<ORIGINAL_TEXT>Ha salido el tesis de Cambridge, el origen de Covid19 tiene lugar en América y Australia, la raíz tipo A, El que se propagó en Wuhan se mutó, que es el tipo B.</ORIGINAL_TEXT>
<TOKEN id="token-100-0" pos="word" morph="none" start_char="13913" end_char="13914">Ha</TOKEN>
<TOKEN id="token-100-1" pos="word" morph="none" start_char="13916" end_char="13921">salido</TOKEN>
<TOKEN id="token-100-2" pos="word" morph="none" start_char="13923" end_char="13924">el</TOKEN>
<TOKEN id="token-100-3" pos="word" morph="none" start_char="13926" end_char="13930">tesis</TOKEN>
<TOKEN id="token-100-4" pos="word" morph="none" start_char="13932" end_char="13933">de</TOKEN>
<TOKEN id="token-100-5" pos="word" morph="none" start_char="13935" end_char="13943">Cambridge</TOKEN>
<TOKEN id="token-100-6" pos="punct" morph="none" start_char="13944" end_char="13944">,</TOKEN>
<TOKEN id="token-100-7" pos="word" morph="none" start_char="13946" end_char="13947">el</TOKEN>
<TOKEN id="token-100-8" pos="word" morph="none" start_char="13949" end_char="13954">origen</TOKEN>
<TOKEN id="token-100-9" pos="word" morph="none" start_char="13956" end_char="13957">de</TOKEN>
<TOKEN id="token-100-10" pos="word" morph="none" start_char="13959" end_char="13965">Covid19</TOKEN>
<TOKEN id="token-100-11" pos="word" morph="none" start_char="13967" end_char="13971">tiene</TOKEN>
<TOKEN id="token-100-12" pos="word" morph="none" start_char="13973" end_char="13977">lugar</TOKEN>
<TOKEN id="token-100-13" pos="word" morph="none" start_char="13979" end_char="13980">en</TOKEN>
<TOKEN id="token-100-14" pos="word" morph="none" start_char="13982" end_char="13988">América</TOKEN>
<TOKEN id="token-100-15" pos="word" morph="none" start_char="13990" end_char="13990">y</TOKEN>
<TOKEN id="token-100-16" pos="word" morph="none" start_char="13992" end_char="14000">Australia</TOKEN>
<TOKEN id="token-100-17" pos="punct" morph="none" start_char="14001" end_char="14001">,</TOKEN>
<TOKEN id="token-100-18" pos="word" morph="none" start_char="14003" end_char="14004">la</TOKEN>
<TOKEN id="token-100-19" pos="word" morph="none" start_char="14006" end_char="14009">raíz</TOKEN>
<TOKEN id="token-100-20" pos="word" morph="none" start_char="14011" end_char="14014">tipo</TOKEN>
<TOKEN id="token-100-21" pos="word" morph="none" start_char="14016" end_char="14016">A</TOKEN>
<TOKEN id="token-100-22" pos="punct" morph="none" start_char="14017" end_char="14017">,</TOKEN>
<TOKEN id="token-100-23" pos="word" morph="none" start_char="14019" end_char="14020">El</TOKEN>
<TOKEN id="token-100-24" pos="word" morph="none" start_char="14022" end_char="14024">que</TOKEN>
<TOKEN id="token-100-25" pos="word" morph="none" start_char="14026" end_char="14027">se</TOKEN>
<TOKEN id="token-100-26" pos="word" morph="none" start_char="14029" end_char="14035">propagó</TOKEN>
<TOKEN id="token-100-27" pos="word" morph="none" start_char="14037" end_char="14038">en</TOKEN>
<TOKEN id="token-100-28" pos="word" morph="none" start_char="14040" end_char="14044">Wuhan</TOKEN>
<TOKEN id="token-100-29" pos="word" morph="none" start_char="14046" end_char="14047">se</TOKEN>
<TOKEN id="token-100-30" pos="word" morph="none" start_char="14049" end_char="14052">mutó</TOKEN>
<TOKEN id="token-100-31" pos="punct" morph="none" start_char="14053" end_char="14053">,</TOKEN>
<TOKEN id="token-100-32" pos="word" morph="none" start_char="14055" end_char="14057">que</TOKEN>
<TOKEN id="token-100-33" pos="word" morph="none" start_char="14059" end_char="14060">es</TOKEN>
<TOKEN id="token-100-34" pos="word" morph="none" start_char="14062" end_char="14063">el</TOKEN>
<TOKEN id="token-100-35" pos="word" morph="none" start_char="14065" end_char="14068">tipo</TOKEN>
<TOKEN id="token-100-36" pos="word" morph="none" start_char="14070" end_char="14070">B</TOKEN>
<TOKEN id="token-100-37" pos="punct" morph="none" start_char="14071" end_char="14071">.</TOKEN>
</SEG>
<SEG id="segment-101" start_char="14073" end_char="14177">
<ORIGINAL_TEXT>Hay muchas noticias falsas de los medios de comunicaciones del oeste, no dejes que te hagan brainwashing.</ORIGINAL_TEXT>
<TOKEN id="token-101-0" pos="word" morph="none" start_char="14073" end_char="14075">Hay</TOKEN>
<TOKEN id="token-101-1" pos="word" morph="none" start_char="14077" end_char="14082">muchas</TOKEN>
<TOKEN id="token-101-2" pos="word" morph="none" start_char="14084" end_char="14091">noticias</TOKEN>
<TOKEN id="token-101-3" pos="word" morph="none" start_char="14093" end_char="14098">falsas</TOKEN>
<TOKEN id="token-101-4" pos="word" morph="none" start_char="14100" end_char="14101">de</TOKEN>
<TOKEN id="token-101-5" pos="word" morph="none" start_char="14103" end_char="14105">los</TOKEN>
<TOKEN id="token-101-6" pos="word" morph="none" start_char="14107" end_char="14112">medios</TOKEN>
<TOKEN id="token-101-7" pos="word" morph="none" start_char="14114" end_char="14115">de</TOKEN>
<TOKEN id="token-101-8" pos="word" morph="none" start_char="14117" end_char="14130">comunicaciones</TOKEN>
<TOKEN id="token-101-9" pos="word" morph="none" start_char="14132" end_char="14134">del</TOKEN>
<TOKEN id="token-101-10" pos="word" morph="none" start_char="14136" end_char="14140">oeste</TOKEN>
<TOKEN id="token-101-11" pos="punct" morph="none" start_char="14141" end_char="14141">,</TOKEN>
<TOKEN id="token-101-12" pos="word" morph="none" start_char="14143" end_char="14144">no</TOKEN>
<TOKEN id="token-101-13" pos="word" morph="none" start_char="14146" end_char="14150">dejes</TOKEN>
<TOKEN id="token-101-14" pos="word" morph="none" start_char="14152" end_char="14154">que</TOKEN>
<TOKEN id="token-101-15" pos="word" morph="none" start_char="14156" end_char="14157">te</TOKEN>
<TOKEN id="token-101-16" pos="word" morph="none" start_char="14159" end_char="14163">hagan</TOKEN>
<TOKEN id="token-101-17" pos="word" morph="none" start_char="14165" end_char="14176">brainwashing</TOKEN>
<TOKEN id="token-101-18" pos="punct" morph="none" start_char="14177" end_char="14177">.</TOKEN>
</SEG>
<SEG id="segment-102" start_char="14179" end_char="14215">
<ORIGINAL_TEXT>Pero la verdad has razonado muy bien.</ORIGINAL_TEXT>
<TOKEN id="token-102-0" pos="word" morph="none" start_char="14179" end_char="14182">Pero</TOKEN>
<TOKEN id="token-102-1" pos="word" morph="none" start_char="14184" end_char="14185">la</TOKEN>
<TOKEN id="token-102-2" pos="word" morph="none" start_char="14187" end_char="14192">verdad</TOKEN>
<TOKEN id="token-102-3" pos="word" morph="none" start_char="14194" end_char="14196">has</TOKEN>
<TOKEN id="token-102-4" pos="word" morph="none" start_char="14198" end_char="14205">razonado</TOKEN>
<TOKEN id="token-102-5" pos="word" morph="none" start_char="14207" end_char="14209">muy</TOKEN>
<TOKEN id="token-102-6" pos="word" morph="none" start_char="14211" end_char="14214">bien</TOKEN>
<TOKEN id="token-102-7" pos="punct" morph="none" start_char="14215" end_char="14215">.</TOKEN>
</SEG>
<SEG id="segment-103" start_char="14219" end_char="14373">
<ORIGINAL_TEXT>Sin que me den datos científicos que desmientan la noticia, no me lo creo mucho... Desde 2015 les ha dado tiempo a mutar el virus tanto como hayan querido.</ORIGINAL_TEXT>
<TOKEN id="token-103-0" pos="word" morph="none" start_char="14219" end_char="14221">Sin</TOKEN>
<TOKEN id="token-103-1" pos="word" morph="none" start_char="14223" end_char="14225">que</TOKEN>
<TOKEN id="token-103-2" pos="word" morph="none" start_char="14227" end_char="14228">me</TOKEN>
<TOKEN id="token-103-3" pos="word" morph="none" start_char="14230" end_char="14232">den</TOKEN>
<TOKEN id="token-103-4" pos="word" morph="none" start_char="14234" end_char="14238">datos</TOKEN>
<TOKEN id="token-103-5" pos="word" morph="none" start_char="14240" end_char="14250">científicos</TOKEN>
<TOKEN id="token-103-6" pos="word" morph="none" start_char="14252" end_char="14254">que</TOKEN>
<TOKEN id="token-103-7" pos="word" morph="none" start_char="14256" end_char="14265">desmientan</TOKEN>
<TOKEN id="token-103-8" pos="word" morph="none" start_char="14267" end_char="14268">la</TOKEN>
<TOKEN id="token-103-9" pos="word" morph="none" start_char="14270" end_char="14276">noticia</TOKEN>
<TOKEN id="token-103-10" pos="punct" morph="none" start_char="14277" end_char="14277">,</TOKEN>
<TOKEN id="token-103-11" pos="word" morph="none" start_char="14279" end_char="14280">no</TOKEN>
<TOKEN id="token-103-12" pos="word" morph="none" start_char="14282" end_char="14283">me</TOKEN>
<TOKEN id="token-103-13" pos="word" morph="none" start_char="14285" end_char="14286">lo</TOKEN>
<TOKEN id="token-103-14" pos="word" morph="none" start_char="14288" end_char="14291">creo</TOKEN>
<TOKEN id="token-103-15" pos="word" morph="none" start_char="14293" end_char="14297">mucho</TOKEN>
<TOKEN id="token-103-16" pos="punct" morph="none" start_char="14298" end_char="14300">...</TOKEN>
<TOKEN id="token-103-17" pos="word" morph="none" start_char="14302" end_char="14306">Desde</TOKEN>
<TOKEN id="token-103-18" pos="word" morph="none" start_char="14308" end_char="14311">2015</TOKEN>
<TOKEN id="token-103-19" pos="word" morph="none" start_char="14313" end_char="14315">les</TOKEN>
<TOKEN id="token-103-20" pos="word" morph="none" start_char="14317" end_char="14318">ha</TOKEN>
<TOKEN id="token-103-21" pos="word" morph="none" start_char="14320" end_char="14323">dado</TOKEN>
<TOKEN id="token-103-22" pos="word" morph="none" start_char="14325" end_char="14330">tiempo</TOKEN>
<TOKEN id="token-103-23" pos="word" morph="none" start_char="14332" end_char="14332">a</TOKEN>
<TOKEN id="token-103-24" pos="word" morph="none" start_char="14334" end_char="14338">mutar</TOKEN>
<TOKEN id="token-103-25" pos="word" morph="none" start_char="14340" end_char="14341">el</TOKEN>
<TOKEN id="token-103-26" pos="word" morph="none" start_char="14343" end_char="14347">virus</TOKEN>
<TOKEN id="token-103-27" pos="word" morph="none" start_char="14349" end_char="14353">tanto</TOKEN>
<TOKEN id="token-103-28" pos="word" morph="none" start_char="14355" end_char="14358">como</TOKEN>
<TOKEN id="token-103-29" pos="word" morph="none" start_char="14360" end_char="14364">hayan</TOKEN>
<TOKEN id="token-103-30" pos="word" morph="none" start_char="14366" end_char="14372">querido</TOKEN>
<TOKEN id="token-103-31" pos="punct" morph="none" start_char="14373" end_char="14373">.</TOKEN>
</SEG>
<SEG id="segment-104" start_char="14377" end_char="14437">
<ORIGINAL_TEXT>Claro, porque afirmar lo contrario es mucho más "científico".</ORIGINAL_TEXT>
<TOKEN id="token-104-0" pos="word" morph="none" start_char="14377" end_char="14381">Claro</TOKEN>
<TOKEN id="token-104-1" pos="punct" morph="none" start_char="14382" end_char="14382">,</TOKEN>
<TOKEN id="token-104-2" pos="word" morph="none" start_char="14384" end_char="14389">porque</TOKEN>
<TOKEN id="token-104-3" pos="word" morph="none" start_char="14391" end_char="14397">afirmar</TOKEN>
<TOKEN id="token-104-4" pos="word" morph="none" start_char="14399" end_char="14400">lo</TOKEN>
<TOKEN id="token-104-5" pos="word" morph="none" start_char="14402" end_char="14410">contrario</TOKEN>
<TOKEN id="token-104-6" pos="word" morph="none" start_char="14412" end_char="14413">es</TOKEN>
<TOKEN id="token-104-7" pos="word" morph="none" start_char="14415" end_char="14419">mucho</TOKEN>
<TOKEN id="token-104-8" pos="word" morph="none" start_char="14421" end_char="14423">más</TOKEN>
<TOKEN id="token-104-9" pos="punct" morph="none" start_char="14425" end_char="14425">"</TOKEN>
<TOKEN id="token-104-10" pos="word" morph="none" start_char="14426" end_char="14435">científico</TOKEN>
<TOKEN id="token-104-11" pos="punct" morph="none" start_char="14436" end_char="14437">".</TOKEN>
</SEG>
<SEG id="segment-105" start_char="14441" end_char="14631">
<ORIGINAL_TEXT>Afirmar lo contrario no tiene porqué ser científico, el que asegura que no es verdad, es el que tiene que demostrar, y esos han sido los que niegan la creación de ese virus en el laboratorio.</ORIGINAL_TEXT>
<TOKEN id="token-105-0" pos="word" morph="none" start_char="14441" end_char="14447">Afirmar</TOKEN>
<TOKEN id="token-105-1" pos="word" morph="none" start_char="14449" end_char="14450">lo</TOKEN>
<TOKEN id="token-105-2" pos="word" morph="none" start_char="14452" end_char="14460">contrario</TOKEN>
<TOKEN id="token-105-3" pos="word" morph="none" start_char="14462" end_char="14463">no</TOKEN>
<TOKEN id="token-105-4" pos="word" morph="none" start_char="14465" end_char="14469">tiene</TOKEN>
<TOKEN id="token-105-5" pos="word" morph="none" start_char="14471" end_char="14476">porqué</TOKEN>
<TOKEN id="token-105-6" pos="word" morph="none" start_char="14478" end_char="14480">ser</TOKEN>
<TOKEN id="token-105-7" pos="word" morph="none" start_char="14482" end_char="14491">científico</TOKEN>
<TOKEN id="token-105-8" pos="punct" morph="none" start_char="14492" end_char="14492">,</TOKEN>
<TOKEN id="token-105-9" pos="word" morph="none" start_char="14494" end_char="14495">el</TOKEN>
<TOKEN id="token-105-10" pos="word" morph="none" start_char="14497" end_char="14499">que</TOKEN>
<TOKEN id="token-105-11" pos="word" morph="none" start_char="14501" end_char="14507">asegura</TOKEN>
<TOKEN id="token-105-12" pos="word" morph="none" start_char="14509" end_char="14511">que</TOKEN>
<TOKEN id="token-105-13" pos="word" morph="none" start_char="14513" end_char="14514">no</TOKEN>
<TOKEN id="token-105-14" pos="word" morph="none" start_char="14516" end_char="14517">es</TOKEN>
<TOKEN id="token-105-15" pos="word" morph="none" start_char="14519" end_char="14524">verdad</TOKEN>
<TOKEN id="token-105-16" pos="punct" morph="none" start_char="14525" end_char="14525">,</TOKEN>
<TOKEN id="token-105-17" pos="word" morph="none" start_char="14527" end_char="14528">es</TOKEN>
<TOKEN id="token-105-18" pos="word" morph="none" start_char="14530" end_char="14531">el</TOKEN>
<TOKEN id="token-105-19" pos="word" morph="none" start_char="14533" end_char="14535">que</TOKEN>
<TOKEN id="token-105-20" pos="word" morph="none" start_char="14537" end_char="14541">tiene</TOKEN>
<TOKEN id="token-105-21" pos="word" morph="none" start_char="14543" end_char="14545">que</TOKEN>
<TOKEN id="token-105-22" pos="word" morph="none" start_char="14547" end_char="14555">demostrar</TOKEN>
<TOKEN id="token-105-23" pos="punct" morph="none" start_char="14556" end_char="14556">,</TOKEN>
<TOKEN id="token-105-24" pos="word" morph="none" start_char="14558" end_char="14558">y</TOKEN>
<TOKEN id="token-105-25" pos="word" morph="none" start_char="14560" end_char="14563">esos</TOKEN>
<TOKEN id="token-105-26" pos="word" morph="none" start_char="14565" end_char="14567">han</TOKEN>
<TOKEN id="token-105-27" pos="word" morph="none" start_char="14569" end_char="14572">sido</TOKEN>
<TOKEN id="token-105-28" pos="word" morph="none" start_char="14574" end_char="14576">los</TOKEN>
<TOKEN id="token-105-29" pos="word" morph="none" start_char="14578" end_char="14580">que</TOKEN>
<TOKEN id="token-105-30" pos="word" morph="none" start_char="14582" end_char="14587">niegan</TOKEN>
<TOKEN id="token-105-31" pos="word" morph="none" start_char="14589" end_char="14590">la</TOKEN>
<TOKEN id="token-105-32" pos="word" morph="none" start_char="14592" end_char="14599">creación</TOKEN>
<TOKEN id="token-105-33" pos="word" morph="none" start_char="14601" end_char="14602">de</TOKEN>
<TOKEN id="token-105-34" pos="word" morph="none" start_char="14604" end_char="14606">ese</TOKEN>
<TOKEN id="token-105-35" pos="word" morph="none" start_char="14608" end_char="14612">virus</TOKEN>
<TOKEN id="token-105-36" pos="word" morph="none" start_char="14614" end_char="14615">en</TOKEN>
<TOKEN id="token-105-37" pos="word" morph="none" start_char="14617" end_char="14618">el</TOKEN>
<TOKEN id="token-105-38" pos="word" morph="none" start_char="14620" end_char="14630">laboratorio</TOKEN>
<TOKEN id="token-105-39" pos="punct" morph="none" start_char="14631" end_char="14631">.</TOKEN>
</SEG>
<SEG id="segment-106" start_char="14633" end_char="14743">
<ORIGINAL_TEXT>Porque claro, tú contradices con tus afirmación a alguien que quiere que se lo justifiquen, no impone su razón.</ORIGINAL_TEXT>
<TOKEN id="token-106-0" pos="word" morph="none" start_char="14633" end_char="14638">Porque</TOKEN>
<TOKEN id="token-106-1" pos="word" morph="none" start_char="14640" end_char="14644">claro</TOKEN>
<TOKEN id="token-106-2" pos="punct" morph="none" start_char="14645" end_char="14645">,</TOKEN>
<TOKEN id="token-106-3" pos="word" morph="none" start_char="14647" end_char="14648">tú</TOKEN>
<TOKEN id="token-106-4" pos="word" morph="none" start_char="14650" end_char="14660">contradices</TOKEN>
<TOKEN id="token-106-5" pos="word" morph="none" start_char="14662" end_char="14664">con</TOKEN>
<TOKEN id="token-106-6" pos="word" morph="none" start_char="14666" end_char="14668">tus</TOKEN>
<TOKEN id="token-106-7" pos="word" morph="none" start_char="14670" end_char="14679">afirmación</TOKEN>
<TOKEN id="token-106-8" pos="word" morph="none" start_char="14681" end_char="14681">a</TOKEN>
<TOKEN id="token-106-9" pos="word" morph="none" start_char="14683" end_char="14689">alguien</TOKEN>
<TOKEN id="token-106-10" pos="word" morph="none" start_char="14691" end_char="14693">que</TOKEN>
<TOKEN id="token-106-11" pos="word" morph="none" start_char="14695" end_char="14700">quiere</TOKEN>
<TOKEN id="token-106-12" pos="word" morph="none" start_char="14702" end_char="14704">que</TOKEN>
<TOKEN id="token-106-13" pos="word" morph="none" start_char="14706" end_char="14707">se</TOKEN>
<TOKEN id="token-106-14" pos="word" morph="none" start_char="14709" end_char="14710">lo</TOKEN>
<TOKEN id="token-106-15" pos="word" morph="none" start_char="14712" end_char="14722">justifiquen</TOKEN>
<TOKEN id="token-106-16" pos="punct" morph="none" start_char="14723" end_char="14723">,</TOKEN>
<TOKEN id="token-106-17" pos="word" morph="none" start_char="14725" end_char="14726">no</TOKEN>
<TOKEN id="token-106-18" pos="word" morph="none" start_char="14728" end_char="14733">impone</TOKEN>
<TOKEN id="token-106-19" pos="word" morph="none" start_char="14735" end_char="14736">su</TOKEN>
<TOKEN id="token-106-20" pos="word" morph="none" start_char="14738" end_char="14742">razón</TOKEN>
<TOKEN id="token-106-21" pos="punct" morph="none" start_char="14743" end_char="14743">.</TOKEN>
</SEG>
<SEG id="segment-107" start_char="14745" end_char="14779">
<ORIGINAL_TEXT>Simplemente no se cree el artículo.</ORIGINAL_TEXT>
<TOKEN id="token-107-0" pos="word" morph="none" start_char="14745" end_char="14755">Simplemente</TOKEN>
<TOKEN id="token-107-1" pos="word" morph="none" start_char="14757" end_char="14758">no</TOKEN>
<TOKEN id="token-107-2" pos="word" morph="none" start_char="14760" end_char="14761">se</TOKEN>
<TOKEN id="token-107-3" pos="word" morph="none" start_char="14763" end_char="14766">cree</TOKEN>
<TOKEN id="token-107-4" pos="word" morph="none" start_char="14768" end_char="14769">el</TOKEN>
<TOKEN id="token-107-5" pos="word" morph="none" start_char="14771" end_char="14778">artículo</TOKEN>
<TOKEN id="token-107-6" pos="punct" morph="none" start_char="14779" end_char="14779">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
