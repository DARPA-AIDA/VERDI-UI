<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATS7" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="7075" raw_text_md5="d87068236315cf128f2d8c6f46b07975">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="121">
<ORIGINAL_TEXT>El reportaje de la TV italiana de 2015 sobre un virus creado en un laboratorio en China no tiene relación con el COVID-19</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="2">El</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="4" end_char="12">reportaje</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="14" end_char="15">de</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="17" end_char="18">la</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="20" end_char="21">TV</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="23" end_char="30">italiana</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="32" end_char="33">de</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="35" end_char="38">2015</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="40" end_char="44">sobre</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="46" end_char="47">un</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="49" end_char="53">virus</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="55" end_char="60">creado</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="62" end_char="63">en</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="65" end_char="66">un</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="68" end_char="78">laboratorio</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="80" end_char="81">en</TOKEN>
<TOKEN id="token-0-16" pos="word" morph="none" start_char="83" end_char="87">China</TOKEN>
<TOKEN id="token-0-17" pos="word" morph="none" start_char="89" end_char="90">no</TOKEN>
<TOKEN id="token-0-18" pos="word" morph="none" start_char="92" end_char="96">tiene</TOKEN>
<TOKEN id="token-0-19" pos="word" morph="none" start_char="98" end_char="105">relación</TOKEN>
<TOKEN id="token-0-20" pos="word" morph="none" start_char="107" end_char="109">con</TOKEN>
<TOKEN id="token-0-21" pos="word" morph="none" start_char="111" end_char="112">el</TOKEN>
<TOKEN id="token-0-22" pos="unknown" morph="none" start_char="114" end_char="121">COVID-19</TOKEN>
</SEG>
<SEG id="segment-1" start_char="125" end_char="381">
<ORIGINAL_TEXT>Publicaciones compartidas miles de veces en redes sociales al menos desde el 27 de marzo, aseguran que un informe emitido en 2015 por el canal italiano de televisión RAI, demuestra que el nuevo coronavirus fue creado en un laboratorio por el gobierno chino.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="125" end_char="137">Publicaciones</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="139" end_char="149">compartidas</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="151" end_char="155">miles</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="157" end_char="158">de</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="160" end_char="164">veces</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="166" end_char="167">en</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="169" end_char="173">redes</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="175" end_char="182">sociales</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="184" end_char="185">al</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="187" end_char="191">menos</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="193" end_char="197">desde</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="199" end_char="200">el</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="202" end_char="203">27</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="205" end_char="206">de</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="208" end_char="212">marzo</TOKEN>
<TOKEN id="token-1-15" pos="punct" morph="none" start_char="213" end_char="213">,</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="215" end_char="222">aseguran</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="224" end_char="226">que</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="228" end_char="229">un</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="231" end_char="237">informe</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="239" end_char="245">emitido</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="247" end_char="248">en</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="250" end_char="253">2015</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="255" end_char="257">por</TOKEN>
<TOKEN id="token-1-24" pos="word" morph="none" start_char="259" end_char="260">el</TOKEN>
<TOKEN id="token-1-25" pos="word" morph="none" start_char="262" end_char="266">canal</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="268" end_char="275">italiano</TOKEN>
<TOKEN id="token-1-27" pos="word" morph="none" start_char="277" end_char="278">de</TOKEN>
<TOKEN id="token-1-28" pos="word" morph="none" start_char="280" end_char="289">televisión</TOKEN>
<TOKEN id="token-1-29" pos="word" morph="none" start_char="291" end_char="293">RAI</TOKEN>
<TOKEN id="token-1-30" pos="punct" morph="none" start_char="294" end_char="294">,</TOKEN>
<TOKEN id="token-1-31" pos="word" morph="none" start_char="296" end_char="304">demuestra</TOKEN>
<TOKEN id="token-1-32" pos="word" morph="none" start_char="306" end_char="308">que</TOKEN>
<TOKEN id="token-1-33" pos="word" morph="none" start_char="310" end_char="311">el</TOKEN>
<TOKEN id="token-1-34" pos="word" morph="none" start_char="313" end_char="317">nuevo</TOKEN>
<TOKEN id="token-1-35" pos="word" morph="none" start_char="319" end_char="329">coronavirus</TOKEN>
<TOKEN id="token-1-36" pos="word" morph="none" start_char="331" end_char="333">fue</TOKEN>
<TOKEN id="token-1-37" pos="word" morph="none" start_char="335" end_char="340">creado</TOKEN>
<TOKEN id="token-1-38" pos="word" morph="none" start_char="342" end_char="343">en</TOKEN>
<TOKEN id="token-1-39" pos="word" morph="none" start_char="345" end_char="346">un</TOKEN>
<TOKEN id="token-1-40" pos="word" morph="none" start_char="348" end_char="358">laboratorio</TOKEN>
<TOKEN id="token-1-41" pos="word" morph="none" start_char="360" end_char="362">por</TOKEN>
<TOKEN id="token-1-42" pos="word" morph="none" start_char="364" end_char="365">el</TOKEN>
<TOKEN id="token-1-43" pos="word" morph="none" start_char="367" end_char="374">gobierno</TOKEN>
<TOKEN id="token-1-44" pos="word" morph="none" start_char="376" end_char="380">chino</TOKEN>
<TOKEN id="token-1-45" pos="punct" morph="none" start_char="381" end_char="381">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="383" end_char="599">
<ORIGINAL_TEXT>El video, que ha circulado en otros idiomas y habla de científicos que fabricaron entonces una versión híbrida de un coronavirus de murciélago en China, se basó en un estudio publicado en la revista científica Nature.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="383" end_char="384">El</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="386" end_char="390">video</TOKEN>
<TOKEN id="token-2-2" pos="punct" morph="none" start_char="391" end_char="391">,</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="393" end_char="395">que</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="397" end_char="398">ha</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="400" end_char="408">circulado</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="410" end_char="411">en</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="413" end_char="417">otros</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="419" end_char="425">idiomas</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="427" end_char="427">y</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="429" end_char="433">habla</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="435" end_char="436">de</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="438" end_char="448">científicos</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="450" end_char="452">que</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="454" end_char="463">fabricaron</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="465" end_char="472">entonces</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="474" end_char="476">una</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="478" end_char="484">versión</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="486" end_char="492">híbrida</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="494" end_char="495">de</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="497" end_char="498">un</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="500" end_char="510">coronavirus</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="512" end_char="513">de</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="515" end_char="524">murciélago</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="526" end_char="527">en</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="529" end_char="533">China</TOKEN>
<TOKEN id="token-2-26" pos="punct" morph="none" start_char="534" end_char="534">,</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="536" end_char="537">se</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="539" end_char="542">basó</TOKEN>
<TOKEN id="token-2-29" pos="word" morph="none" start_char="544" end_char="545">en</TOKEN>
<TOKEN id="token-2-30" pos="word" morph="none" start_char="547" end_char="548">un</TOKEN>
<TOKEN id="token-2-31" pos="word" morph="none" start_char="550" end_char="556">estudio</TOKEN>
<TOKEN id="token-2-32" pos="word" morph="none" start_char="558" end_char="566">publicado</TOKEN>
<TOKEN id="token-2-33" pos="word" morph="none" start_char="568" end_char="569">en</TOKEN>
<TOKEN id="token-2-34" pos="word" morph="none" start_char="571" end_char="572">la</TOKEN>
<TOKEN id="token-2-35" pos="word" morph="none" start_char="574" end_char="580">revista</TOKEN>
<TOKEN id="token-2-36" pos="word" morph="none" start_char="582" end_char="591">científica</TOKEN>
<TOKEN id="token-2-37" pos="word" morph="none" start_char="593" end_char="598">Nature</TOKEN>
<TOKEN id="token-2-38" pos="punct" morph="none" start_char="599" end_char="599">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="601" end_char="734">
<ORIGINAL_TEXT>En marzo de 2020, dicha revista aclaró que no existe evidencia de que ese experimento se relacione con la pandemia actual de COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="601" end_char="602">En</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="604" end_char="608">marzo</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="610" end_char="611">de</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="613" end_char="616">2020</TOKEN>
<TOKEN id="token-3-4" pos="punct" morph="none" start_char="617" end_char="617">,</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="619" end_char="623">dicha</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="625" end_char="631">revista</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="633" end_char="638">aclaró</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="640" end_char="642">que</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="644" end_char="645">no</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="647" end_char="652">existe</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="654" end_char="662">evidencia</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="664" end_char="665">de</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="667" end_char="669">que</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="671" end_char="673">ese</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="675" end_char="685">experimento</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="687" end_char="688">se</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="690" end_char="698">relacione</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="700" end_char="702">con</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="704" end_char="705">la</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="707" end_char="714">pandemia</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="716" end_char="721">actual</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="723" end_char="724">de</TOKEN>
<TOKEN id="token-3-23" pos="unknown" morph="none" start_char="726" end_char="733">COVID-19</TOKEN>
<TOKEN id="token-3-24" pos="punct" morph="none" start_char="734" end_char="734">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="738" end_char="916">
<ORIGINAL_TEXT>"Programa de la RAI de 2015 contó la creación del actual coronavirus", así se titula un video de YouTube publicado el 27 de marzo pasado y que lleva más de 700.000 reproducciones.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="punct" morph="none" start_char="738" end_char="738">"</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="739" end_char="746">Programa</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="748" end_char="749">de</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="751" end_char="752">la</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="754" end_char="756">RAI</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="758" end_char="759">de</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="761" end_char="764">2015</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="766" end_char="770">contó</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="772" end_char="773">la</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="775" end_char="782">creación</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="784" end_char="786">del</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="788" end_char="793">actual</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="795" end_char="805">coronavirus</TOKEN>
<TOKEN id="token-4-13" pos="punct" morph="none" start_char="806" end_char="807">",</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="809" end_char="811">así</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="813" end_char="814">se</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="816" end_char="821">titula</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="823" end_char="824">un</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="826" end_char="830">video</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="832" end_char="833">de</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="835" end_char="841">YouTube</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="843" end_char="851">publicado</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="853" end_char="854">el</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="856" end_char="857">27</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="859" end_char="860">de</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="862" end_char="866">marzo</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="868" end_char="873">pasado</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="875" end_char="875">y</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="877" end_char="879">que</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="881" end_char="885">lleva</TOKEN>
<TOKEN id="token-4-30" pos="word" morph="none" start_char="887" end_char="889">más</TOKEN>
<TOKEN id="token-4-31" pos="word" morph="none" start_char="891" end_char="892">de</TOKEN>
<TOKEN id="token-4-32" pos="word" morph="none" start_char="894" end_char="900">700.000</TOKEN>
<TOKEN id="token-4-33" pos="word" morph="none" start_char="902" end_char="915">reproducciones</TOKEN>
<TOKEN id="token-4-34" pos="punct" morph="none" start_char="916" end_char="916">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="918" end_char="996">
<ORIGINAL_TEXT>La descripción de la secuencia, compartida más de 5.500 veces en Facebook dice:</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="918" end_char="919">La</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="921" end_char="931">descripción</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="933" end_char="934">de</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="936" end_char="937">la</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="939" end_char="947">secuencia</TOKEN>
<TOKEN id="token-5-5" pos="punct" morph="none" start_char="948" end_char="948">,</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="950" end_char="959">compartida</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="961" end_char="963">más</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="965" end_char="966">de</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="968" end_char="972">5.500</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="974" end_char="978">veces</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="980" end_char="981">en</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="983" end_char="990">Facebook</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="992" end_char="995">dice</TOKEN>
<TOKEN id="token-5-14" pos="punct" morph="none" start_char="996" end_char="996">:</TOKEN>
</SEG>
<SEG id="segment-6" start_char="999" end_char="1256">
<ORIGINAL_TEXT>"Un programa de la televisión pública italiana RAI 3 especializado en información científica contó en el año 2015 el "logro" de unos científicos chinos que habían conseguido modificar el virus del SARS para que pudiera transmitirse de murciélagos a humanos".</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="punct" morph="none" start_char="999" end_char="999">"</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="1000" end_char="1001">Un</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="1003" end_char="1010">programa</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="1012" end_char="1013">de</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="1015" end_char="1016">la</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="1018" end_char="1027">televisión</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="1029" end_char="1035">pública</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="1037" end_char="1044">italiana</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="1046" end_char="1048">RAI</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="1050" end_char="1050">3</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="1052" end_char="1064">especializado</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="1066" end_char="1067">en</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="1069" end_char="1079">información</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="1081" end_char="1090">científica</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="1092" end_char="1096">contó</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="1098" end_char="1099">en</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="1101" end_char="1102">el</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="1104" end_char="1106">año</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="1108" end_char="1111">2015</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="1113" end_char="1114">el</TOKEN>
<TOKEN id="token-6-20" pos="punct" morph="none" start_char="1116" end_char="1116">"</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="1117" end_char="1121">logro</TOKEN>
<TOKEN id="token-6-22" pos="punct" morph="none" start_char="1122" end_char="1122">"</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="1124" end_char="1125">de</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="1127" end_char="1130">unos</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="1132" end_char="1142">científicos</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="1144" end_char="1149">chinos</TOKEN>
<TOKEN id="token-6-27" pos="word" morph="none" start_char="1151" end_char="1153">que</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="1155" end_char="1160">habían</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="1162" end_char="1171">conseguido</TOKEN>
<TOKEN id="token-6-30" pos="word" morph="none" start_char="1173" end_char="1181">modificar</TOKEN>
<TOKEN id="token-6-31" pos="word" morph="none" start_char="1183" end_char="1184">el</TOKEN>
<TOKEN id="token-6-32" pos="word" morph="none" start_char="1186" end_char="1190">virus</TOKEN>
<TOKEN id="token-6-33" pos="word" morph="none" start_char="1192" end_char="1194">del</TOKEN>
<TOKEN id="token-6-34" pos="word" morph="none" start_char="1196" end_char="1199">SARS</TOKEN>
<TOKEN id="token-6-35" pos="word" morph="none" start_char="1201" end_char="1204">para</TOKEN>
<TOKEN id="token-6-36" pos="word" morph="none" start_char="1206" end_char="1208">que</TOKEN>
<TOKEN id="token-6-37" pos="word" morph="none" start_char="1210" end_char="1216">pudiera</TOKEN>
<TOKEN id="token-6-38" pos="word" morph="none" start_char="1218" end_char="1229">transmitirse</TOKEN>
<TOKEN id="token-6-39" pos="word" morph="none" start_char="1231" end_char="1232">de</TOKEN>
<TOKEN id="token-6-40" pos="word" morph="none" start_char="1234" end_char="1244">murciélagos</TOKEN>
<TOKEN id="token-6-41" pos="word" morph="none" start_char="1246" end_char="1246">a</TOKEN>
<TOKEN id="token-6-42" pos="word" morph="none" start_char="1248" end_char="1254">humanos</TOKEN>
<TOKEN id="token-6-43" pos="punct" morph="none" start_char="1255" end_char="1256">".</TOKEN>
</SEG>
<SEG id="segment-7" start_char="1260" end_char="1338">
<ORIGINAL_TEXT>Captura de pantalla de una publicación en Facebook tomada el 1 de abril de 2020</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="1260" end_char="1266">Captura</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="1268" end_char="1269">de</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="1271" end_char="1278">pantalla</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="1280" end_char="1281">de</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="1283" end_char="1285">una</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="1287" end_char="1297">publicación</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="1299" end_char="1300">en</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="1302" end_char="1309">Facebook</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="1311" end_char="1316">tomada</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="1318" end_char="1319">el</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="1321" end_char="1321">1</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="1323" end_char="1324">de</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="1326" end_char="1330">abril</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="1332" end_char="1333">de</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="1335" end_char="1338">2020</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1342" end_char="1528">
<ORIGINAL_TEXT>El mismo video, asociado a la actual pandemia de COVID-19, también ha circulado en Twitter (1, 2), ha sido publicado en otros dos canales de YouTube (1, 2) y también circuló en portugués.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1342" end_char="1343">El</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1345" end_char="1349">mismo</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1351" end_char="1355">video</TOKEN>
<TOKEN id="token-8-3" pos="punct" morph="none" start_char="1356" end_char="1356">,</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1358" end_char="1365">asociado</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1367" end_char="1367">a</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1369" end_char="1370">la</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1372" end_char="1377">actual</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1379" end_char="1386">pandemia</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1388" end_char="1389">de</TOKEN>
<TOKEN id="token-8-10" pos="unknown" morph="none" start_char="1391" end_char="1398">COVID-19</TOKEN>
<TOKEN id="token-8-11" pos="punct" morph="none" start_char="1399" end_char="1399">,</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1401" end_char="1407">también</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1409" end_char="1410">ha</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1412" end_char="1420">circulado</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1422" end_char="1423">en</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1425" end_char="1431">Twitter</TOKEN>
<TOKEN id="token-8-17" pos="punct" morph="none" start_char="1433" end_char="1433">(</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1434" end_char="1434">1</TOKEN>
<TOKEN id="token-8-19" pos="punct" morph="none" start_char="1435" end_char="1435">,</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="1437" end_char="1437">2</TOKEN>
<TOKEN id="token-8-21" pos="punct" morph="none" start_char="1438" end_char="1439">),</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="1441" end_char="1442">ha</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="1444" end_char="1447">sido</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="1449" end_char="1457">publicado</TOKEN>
<TOKEN id="token-8-25" pos="word" morph="none" start_char="1459" end_char="1460">en</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="1462" end_char="1466">otros</TOKEN>
<TOKEN id="token-8-27" pos="word" morph="none" start_char="1468" end_char="1470">dos</TOKEN>
<TOKEN id="token-8-28" pos="word" morph="none" start_char="1472" end_char="1478">canales</TOKEN>
<TOKEN id="token-8-29" pos="word" morph="none" start_char="1480" end_char="1481">de</TOKEN>
<TOKEN id="token-8-30" pos="word" morph="none" start_char="1483" end_char="1489">YouTube</TOKEN>
<TOKEN id="token-8-31" pos="punct" morph="none" start_char="1491" end_char="1491">(</TOKEN>
<TOKEN id="token-8-32" pos="word" morph="none" start_char="1492" end_char="1492">1</TOKEN>
<TOKEN id="token-8-33" pos="punct" morph="none" start_char="1493" end_char="1493">,</TOKEN>
<TOKEN id="token-8-34" pos="word" morph="none" start_char="1495" end_char="1495">2</TOKEN>
<TOKEN id="token-8-35" pos="punct" morph="none" start_char="1496" end_char="1496">)</TOKEN>
<TOKEN id="token-8-36" pos="word" morph="none" start_char="1498" end_char="1498">y</TOKEN>
<TOKEN id="token-8-37" pos="word" morph="none" start_char="1500" end_char="1506">también</TOKEN>
<TOKEN id="token-8-38" pos="word" morph="none" start_char="1508" end_char="1514">circuló</TOKEN>
<TOKEN id="token-8-39" pos="word" morph="none" start_char="1516" end_char="1517">en</TOKEN>
<TOKEN id="token-8-40" pos="word" morph="none" start_char="1519" end_char="1527">portugués</TOKEN>
<TOKEN id="token-8-41" pos="punct" morph="none" start_char="1528" end_char="1528">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1531" end_char="1753">
<ORIGINAL_TEXT>En Facebook, se ha compartido más de 45.000 veces un video donde un presentador español junto a un panelista sugieren que dicho experimento informado por la RAI en 2015, estaría relacionado con el actual brote (1, 2, 3, 4).</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1531" end_char="1532">En</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1534" end_char="1541">Facebook</TOKEN>
<TOKEN id="token-9-2" pos="punct" morph="none" start_char="1542" end_char="1542">,</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1544" end_char="1545">se</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1547" end_char="1548">ha</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1550" end_char="1559">compartido</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1561" end_char="1563">más</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1565" end_char="1566">de</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1568" end_char="1573">45.000</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1575" end_char="1579">veces</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1581" end_char="1582">un</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1584" end_char="1588">video</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1590" end_char="1594">donde</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1596" end_char="1597">un</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1599" end_char="1609">presentador</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1611" end_char="1617">español</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1619" end_char="1623">junto</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1625" end_char="1625">a</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1627" end_char="1628">un</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1630" end_char="1638">panelista</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1640" end_char="1647">sugieren</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1649" end_char="1651">que</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1653" end_char="1657">dicho</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1659" end_char="1669">experimento</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1671" end_char="1679">informado</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1681" end_char="1683">por</TOKEN>
<TOKEN id="token-9-26" pos="word" morph="none" start_char="1685" end_char="1686">la</TOKEN>
<TOKEN id="token-9-27" pos="word" morph="none" start_char="1688" end_char="1690">RAI</TOKEN>
<TOKEN id="token-9-28" pos="word" morph="none" start_char="1692" end_char="1693">en</TOKEN>
<TOKEN id="token-9-29" pos="word" morph="none" start_char="1695" end_char="1698">2015</TOKEN>
<TOKEN id="token-9-30" pos="punct" morph="none" start_char="1699" end_char="1699">,</TOKEN>
<TOKEN id="token-9-31" pos="word" morph="none" start_char="1701" end_char="1707">estaría</TOKEN>
<TOKEN id="token-9-32" pos="word" morph="none" start_char="1709" end_char="1719">relacionado</TOKEN>
<TOKEN id="token-9-33" pos="word" morph="none" start_char="1721" end_char="1723">con</TOKEN>
<TOKEN id="token-9-34" pos="word" morph="none" start_char="1725" end_char="1726">el</TOKEN>
<TOKEN id="token-9-35" pos="word" morph="none" start_char="1728" end_char="1733">actual</TOKEN>
<TOKEN id="token-9-36" pos="word" morph="none" start_char="1735" end_char="1739">brote</TOKEN>
<TOKEN id="token-9-37" pos="punct" morph="none" start_char="1741" end_char="1741">(</TOKEN>
<TOKEN id="token-9-38" pos="word" morph="none" start_char="1742" end_char="1742">1</TOKEN>
<TOKEN id="token-9-39" pos="punct" morph="none" start_char="1743" end_char="1743">,</TOKEN>
<TOKEN id="token-9-40" pos="word" morph="none" start_char="1745" end_char="1745">2</TOKEN>
<TOKEN id="token-9-41" pos="punct" morph="none" start_char="1746" end_char="1746">,</TOKEN>
<TOKEN id="token-9-42" pos="word" morph="none" start_char="1748" end_char="1748">3</TOKEN>
<TOKEN id="token-9-43" pos="punct" morph="none" start_char="1749" end_char="1749">,</TOKEN>
<TOKEN id="token-9-44" pos="word" morph="none" start_char="1751" end_char="1751">4</TOKEN>
<TOKEN id="token-9-45" pos="punct" morph="none" start_char="1752" end_char="1753">).</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1756" end_char="2017">
<ORIGINAL_TEXT>Este mismo reportaje fue publicado el 25 de marzo pasado por el ex vice primer ministro de Italia, Matteo Salvini, informando que su partido, Liga del Norte, enviaría una consulta urgente al primer ministro y al ministro de Relaciones Exteriores sobre el asunto.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1756" end_char="1759">Este</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1761" end_char="1765">mismo</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1767" end_char="1775">reportaje</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1777" end_char="1779">fue</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1781" end_char="1789">publicado</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1791" end_char="1792">el</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1794" end_char="1795">25</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1797" end_char="1798">de</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1800" end_char="1804">marzo</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1806" end_char="1811">pasado</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1813" end_char="1815">por</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1817" end_char="1818">el</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1820" end_char="1821">ex</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1823" end_char="1826">vice</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1828" end_char="1833">primer</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1835" end_char="1842">ministro</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1844" end_char="1845">de</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1847" end_char="1852">Italia</TOKEN>
<TOKEN id="token-10-18" pos="punct" morph="none" start_char="1853" end_char="1853">,</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1855" end_char="1860">Matteo</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1862" end_char="1868">Salvini</TOKEN>
<TOKEN id="token-10-21" pos="punct" morph="none" start_char="1869" end_char="1869">,</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1871" end_char="1880">informando</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1882" end_char="1884">que</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1886" end_char="1887">su</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="1889" end_char="1895">partido</TOKEN>
<TOKEN id="token-10-26" pos="punct" morph="none" start_char="1896" end_char="1896">,</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="1898" end_char="1901">Liga</TOKEN>
<TOKEN id="token-10-28" pos="word" morph="none" start_char="1903" end_char="1905">del</TOKEN>
<TOKEN id="token-10-29" pos="word" morph="none" start_char="1907" end_char="1911">Norte</TOKEN>
<TOKEN id="token-10-30" pos="punct" morph="none" start_char="1912" end_char="1912">,</TOKEN>
<TOKEN id="token-10-31" pos="word" morph="none" start_char="1914" end_char="1921">enviaría</TOKEN>
<TOKEN id="token-10-32" pos="word" morph="none" start_char="1923" end_char="1925">una</TOKEN>
<TOKEN id="token-10-33" pos="word" morph="none" start_char="1927" end_char="1934">consulta</TOKEN>
<TOKEN id="token-10-34" pos="word" morph="none" start_char="1936" end_char="1942">urgente</TOKEN>
<TOKEN id="token-10-35" pos="word" morph="none" start_char="1944" end_char="1945">al</TOKEN>
<TOKEN id="token-10-36" pos="word" morph="none" start_char="1947" end_char="1952">primer</TOKEN>
<TOKEN id="token-10-37" pos="word" morph="none" start_char="1954" end_char="1961">ministro</TOKEN>
<TOKEN id="token-10-38" pos="word" morph="none" start_char="1963" end_char="1963">y</TOKEN>
<TOKEN id="token-10-39" pos="word" morph="none" start_char="1965" end_char="1966">al</TOKEN>
<TOKEN id="token-10-40" pos="word" morph="none" start_char="1968" end_char="1975">ministro</TOKEN>
<TOKEN id="token-10-41" pos="word" morph="none" start_char="1977" end_char="1978">de</TOKEN>
<TOKEN id="token-10-42" pos="word" morph="none" start_char="1980" end_char="1989">Relaciones</TOKEN>
<TOKEN id="token-10-43" pos="word" morph="none" start_char="1991" end_char="2000">Exteriores</TOKEN>
<TOKEN id="token-10-44" pos="word" morph="none" start_char="2002" end_char="2006">sobre</TOKEN>
<TOKEN id="token-10-45" pos="word" morph="none" start_char="2008" end_char="2009">el</TOKEN>
<TOKEN id="token-10-46" pos="word" morph="none" start_char="2011" end_char="2016">asunto</TOKEN>
<TOKEN id="token-10-47" pos="punct" morph="none" start_char="2017" end_char="2017">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="2020" end_char="2138">
<ORIGINAL_TEXT>Sin embargo, el informe emitido en 2015 por la Radiotelevisión Italiana (RAI) no tiene relación con la actual pandemia.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="2020" end_char="2022">Sin</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="2024" end_char="2030">embargo</TOKEN>
<TOKEN id="token-11-2" pos="punct" morph="none" start_char="2031" end_char="2031">,</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="2033" end_char="2034">el</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="2036" end_char="2042">informe</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="2044" end_char="2050">emitido</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="2052" end_char="2053">en</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="2055" end_char="2058">2015</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="2060" end_char="2062">por</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="2064" end_char="2065">la</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="2067" end_char="2081">Radiotelevisión</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="2083" end_char="2090">Italiana</TOKEN>
<TOKEN id="token-11-12" pos="punct" morph="none" start_char="2092" end_char="2092">(</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="2093" end_char="2095">RAI</TOKEN>
<TOKEN id="token-11-14" pos="punct" morph="none" start_char="2096" end_char="2096">)</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="2098" end_char="2099">no</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="2101" end_char="2105">tiene</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="2107" end_char="2114">relación</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="2116" end_char="2118">con</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="2120" end_char="2121">la</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="2123" end_char="2128">actual</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="2130" end_char="2137">pandemia</TOKEN>
<TOKEN id="token-11-22" pos="punct" morph="none" start_char="2138" end_char="2138">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="2141" end_char="2158">
<ORIGINAL_TEXT>El informe de 2015</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="2141" end_char="2142">El</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="2144" end_char="2150">informe</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="2152" end_char="2153">de</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="2155" end_char="2158">2015</TOKEN>
</SEG>
<SEG id="segment-13" start_char="2162" end_char="2365">
<ORIGINAL_TEXT>El programa, emitido el 16 de noviembre de 2015 en la sección científica del programa de noticias de la estación RAI, "TGR Leonardo", detalla cómo científicos chinos lograron crear un organismo modificado</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="2162" end_char="2163">El</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="2165" end_char="2172">programa</TOKEN>
<TOKEN id="token-13-2" pos="punct" morph="none" start_char="2173" end_char="2173">,</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="2175" end_char="2181">emitido</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="2183" end_char="2184">el</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="2186" end_char="2187">16</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="2189" end_char="2190">de</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="2192" end_char="2200">noviembre</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="2202" end_char="2203">de</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="2205" end_char="2208">2015</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="2210" end_char="2211">en</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="2213" end_char="2214">la</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="2216" end_char="2222">sección</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="2224" end_char="2233">científica</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="2235" end_char="2237">del</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="2239" end_char="2246">programa</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="2248" end_char="2249">de</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="2251" end_char="2258">noticias</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="2260" end_char="2261">de</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="2263" end_char="2264">la</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="2266" end_char="2273">estación</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="2275" end_char="2277">RAI</TOKEN>
<TOKEN id="token-13-22" pos="punct" morph="none" start_char="2278" end_char="2278">,</TOKEN>
<TOKEN id="token-13-23" pos="punct" morph="none" start_char="2280" end_char="2280">"</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="2281" end_char="2283">TGR</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="2285" end_char="2292">Leonardo</TOKEN>
<TOKEN id="token-13-26" pos="punct" morph="none" start_char="2293" end_char="2294">",</TOKEN>
<TOKEN id="token-13-27" pos="word" morph="none" start_char="2296" end_char="2302">detalla</TOKEN>
<TOKEN id="token-13-28" pos="word" morph="none" start_char="2304" end_char="2307">cómo</TOKEN>
<TOKEN id="token-13-29" pos="word" morph="none" start_char="2309" end_char="2319">científicos</TOKEN>
<TOKEN id="token-13-30" pos="word" morph="none" start_char="2321" end_char="2326">chinos</TOKEN>
<TOKEN id="token-13-31" pos="word" morph="none" start_char="2328" end_char="2335">lograron</TOKEN>
<TOKEN id="token-13-32" pos="word" morph="none" start_char="2337" end_char="2341">crear</TOKEN>
<TOKEN id="token-13-33" pos="word" morph="none" start_char="2343" end_char="2344">un</TOKEN>
<TOKEN id="token-13-34" pos="word" morph="none" start_char="2346" end_char="2354">organismo</TOKEN>
<TOKEN id="token-13-35" pos="word" morph="none" start_char="2356" end_char="2365">modificado</TOKEN>
</SEG>
<SEG id="segment-14" start_char="2368" end_char="2456">
<ORIGINAL_TEXT>"al alterar la proteína de la superficie de un coronavirus encontrado en los murciélagos"</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="punct" morph="none" start_char="2368" end_char="2368">"</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="2369" end_char="2370">al</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="2372" end_char="2378">alterar</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="2380" end_char="2381">la</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="2383" end_char="2390">proteína</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="2392" end_char="2393">de</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="2395" end_char="2396">la</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="2398" end_char="2407">superficie</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="2409" end_char="2410">de</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="2412" end_char="2413">un</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="2415" end_char="2425">coronavirus</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="2427" end_char="2436">encontrado</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="2438" end_char="2439">en</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="2441" end_char="2443">los</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="2445" end_char="2455">murciélagos</TOKEN>
<TOKEN id="token-14-15" pos="punct" morph="none" start_char="2456" end_char="2456">"</TOKEN>
</SEG>
<SEG id="segment-15" start_char="2459" end_char="2524">
<ORIGINAL_TEXT>, de modo que genera un síndrome respiratorio agudo severo (SRAS).</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="punct" morph="none" start_char="2459" end_char="2459">,</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="2461" end_char="2462">de</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="2464" end_char="2467">modo</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="2469" end_char="2471">que</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="2473" end_char="2478">genera</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="2480" end_char="2481">un</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="2483" end_char="2490">síndrome</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="2492" end_char="2503">respiratorio</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="2505" end_char="2509">agudo</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="2511" end_char="2516">severo</TOKEN>
<TOKEN id="token-15-10" pos="punct" morph="none" start_char="2518" end_char="2518">(</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="2519" end_char="2522">SRAS</TOKEN>
<TOKEN id="token-15-12" pos="punct" morph="none" start_char="2523" end_char="2524">).</TOKEN>
</SEG>
<SEG id="segment-16" start_char="2527" end_char="2746">
<ORIGINAL_TEXT>Según el informe, este virus creado en un laboratorio podría infectar a los humanos, lo que despertó un debate sobre si los aprendizajes obtenidos a través de este experimento justifican los posibles riesgos que implica.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="2527" end_char="2531">Según</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="2533" end_char="2534">el</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="2536" end_char="2542">informe</TOKEN>
<TOKEN id="token-16-3" pos="punct" morph="none" start_char="2543" end_char="2543">,</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="2545" end_char="2548">este</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="2550" end_char="2554">virus</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="2556" end_char="2561">creado</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="2563" end_char="2564">en</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="2566" end_char="2567">un</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="2569" end_char="2579">laboratorio</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="2581" end_char="2586">podría</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="2588" end_char="2595">infectar</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="2597" end_char="2597">a</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="2599" end_char="2601">los</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="2603" end_char="2609">humanos</TOKEN>
<TOKEN id="token-16-15" pos="punct" morph="none" start_char="2610" end_char="2610">,</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="2612" end_char="2613">lo</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="2615" end_char="2617">que</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="2619" end_char="2626">despertó</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="2628" end_char="2629">un</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="2631" end_char="2636">debate</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="2638" end_char="2642">sobre</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="2644" end_char="2645">si</TOKEN>
<TOKEN id="token-16-23" pos="word" morph="none" start_char="2647" end_char="2649">los</TOKEN>
<TOKEN id="token-16-24" pos="word" morph="none" start_char="2651" end_char="2662">aprendizajes</TOKEN>
<TOKEN id="token-16-25" pos="word" morph="none" start_char="2664" end_char="2672">obtenidos</TOKEN>
<TOKEN id="token-16-26" pos="word" morph="none" start_char="2674" end_char="2674">a</TOKEN>
<TOKEN id="token-16-27" pos="word" morph="none" start_char="2676" end_char="2681">través</TOKEN>
<TOKEN id="token-16-28" pos="word" morph="none" start_char="2683" end_char="2684">de</TOKEN>
<TOKEN id="token-16-29" pos="word" morph="none" start_char="2686" end_char="2689">este</TOKEN>
<TOKEN id="token-16-30" pos="word" morph="none" start_char="2691" end_char="2701">experimento</TOKEN>
<TOKEN id="token-16-31" pos="word" morph="none" start_char="2703" end_char="2712">justifican</TOKEN>
<TOKEN id="token-16-32" pos="word" morph="none" start_char="2714" end_char="2716">los</TOKEN>
<TOKEN id="token-16-33" pos="word" morph="none" start_char="2718" end_char="2725">posibles</TOKEN>
<TOKEN id="token-16-34" pos="word" morph="none" start_char="2727" end_char="2733">riesgos</TOKEN>
<TOKEN id="token-16-35" pos="word" morph="none" start_char="2735" end_char="2737">que</TOKEN>
<TOKEN id="token-16-36" pos="word" morph="none" start_char="2739" end_char="2745">implica</TOKEN>
<TOKEN id="token-16-37" pos="punct" morph="none" start_char="2746" end_char="2746">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2749" end_char="3078">
<ORIGINAL_TEXT>Una búsqueda en Google de las palabras mencionadas en el reportaje, más el nombre del noticiero, condujo a un artículo de la agencia italiana de noticias ANSA del 25 de marzo de 2020, en el que el director de TGR Leonardo, Alessandro Casarin, explica que el informe se basó en una publicación de la revista científica Nature y que</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2749" end_char="2751">Una</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2753" end_char="2760">búsqueda</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2762" end_char="2763">en</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2765" end_char="2770">Google</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2772" end_char="2773">de</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2775" end_char="2777">las</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2779" end_char="2786">palabras</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2788" end_char="2798">mencionadas</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2800" end_char="2801">en</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2803" end_char="2804">el</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2806" end_char="2814">reportaje</TOKEN>
<TOKEN id="token-17-11" pos="punct" morph="none" start_char="2815" end_char="2815">,</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2817" end_char="2819">más</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2821" end_char="2822">el</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2824" end_char="2829">nombre</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2831" end_char="2833">del</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="2835" end_char="2843">noticiero</TOKEN>
<TOKEN id="token-17-17" pos="punct" morph="none" start_char="2844" end_char="2844">,</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="2846" end_char="2852">condujo</TOKEN>
<TOKEN id="token-17-19" pos="word" morph="none" start_char="2854" end_char="2854">a</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="2856" end_char="2857">un</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="2859" end_char="2866">artículo</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="2868" end_char="2869">de</TOKEN>
<TOKEN id="token-17-23" pos="word" morph="none" start_char="2871" end_char="2872">la</TOKEN>
<TOKEN id="token-17-24" pos="word" morph="none" start_char="2874" end_char="2880">agencia</TOKEN>
<TOKEN id="token-17-25" pos="word" morph="none" start_char="2882" end_char="2889">italiana</TOKEN>
<TOKEN id="token-17-26" pos="word" morph="none" start_char="2891" end_char="2892">de</TOKEN>
<TOKEN id="token-17-27" pos="word" morph="none" start_char="2894" end_char="2901">noticias</TOKEN>
<TOKEN id="token-17-28" pos="word" morph="none" start_char="2903" end_char="2906">ANSA</TOKEN>
<TOKEN id="token-17-29" pos="word" morph="none" start_char="2908" end_char="2910">del</TOKEN>
<TOKEN id="token-17-30" pos="word" morph="none" start_char="2912" end_char="2913">25</TOKEN>
<TOKEN id="token-17-31" pos="word" morph="none" start_char="2915" end_char="2916">de</TOKEN>
<TOKEN id="token-17-32" pos="word" morph="none" start_char="2918" end_char="2922">marzo</TOKEN>
<TOKEN id="token-17-33" pos="word" morph="none" start_char="2924" end_char="2925">de</TOKEN>
<TOKEN id="token-17-34" pos="word" morph="none" start_char="2927" end_char="2930">2020</TOKEN>
<TOKEN id="token-17-35" pos="punct" morph="none" start_char="2931" end_char="2931">,</TOKEN>
<TOKEN id="token-17-36" pos="word" morph="none" start_char="2933" end_char="2934">en</TOKEN>
<TOKEN id="token-17-37" pos="word" morph="none" start_char="2936" end_char="2937">el</TOKEN>
<TOKEN id="token-17-38" pos="word" morph="none" start_char="2939" end_char="2941">que</TOKEN>
<TOKEN id="token-17-39" pos="word" morph="none" start_char="2943" end_char="2944">el</TOKEN>
<TOKEN id="token-17-40" pos="word" morph="none" start_char="2946" end_char="2953">director</TOKEN>
<TOKEN id="token-17-41" pos="word" morph="none" start_char="2955" end_char="2956">de</TOKEN>
<TOKEN id="token-17-42" pos="word" morph="none" start_char="2958" end_char="2960">TGR</TOKEN>
<TOKEN id="token-17-43" pos="word" morph="none" start_char="2962" end_char="2969">Leonardo</TOKEN>
<TOKEN id="token-17-44" pos="punct" morph="none" start_char="2970" end_char="2970">,</TOKEN>
<TOKEN id="token-17-45" pos="word" morph="none" start_char="2972" end_char="2981">Alessandro</TOKEN>
<TOKEN id="token-17-46" pos="word" morph="none" start_char="2983" end_char="2989">Casarin</TOKEN>
<TOKEN id="token-17-47" pos="punct" morph="none" start_char="2990" end_char="2990">,</TOKEN>
<TOKEN id="token-17-48" pos="word" morph="none" start_char="2992" end_char="2998">explica</TOKEN>
<TOKEN id="token-17-49" pos="word" morph="none" start_char="3000" end_char="3002">que</TOKEN>
<TOKEN id="token-17-50" pos="word" morph="none" start_char="3004" end_char="3005">el</TOKEN>
<TOKEN id="token-17-51" pos="word" morph="none" start_char="3007" end_char="3013">informe</TOKEN>
<TOKEN id="token-17-52" pos="word" morph="none" start_char="3015" end_char="3016">se</TOKEN>
<TOKEN id="token-17-53" pos="word" morph="none" start_char="3018" end_char="3021">basó</TOKEN>
<TOKEN id="token-17-54" pos="word" morph="none" start_char="3023" end_char="3024">en</TOKEN>
<TOKEN id="token-17-55" pos="word" morph="none" start_char="3026" end_char="3028">una</TOKEN>
<TOKEN id="token-17-56" pos="word" morph="none" start_char="3030" end_char="3040">publicación</TOKEN>
<TOKEN id="token-17-57" pos="word" morph="none" start_char="3042" end_char="3043">de</TOKEN>
<TOKEN id="token-17-58" pos="word" morph="none" start_char="3045" end_char="3046">la</TOKEN>
<TOKEN id="token-17-59" pos="word" morph="none" start_char="3048" end_char="3054">revista</TOKEN>
<TOKEN id="token-17-60" pos="word" morph="none" start_char="3056" end_char="3065">científica</TOKEN>
<TOKEN id="token-17-61" pos="word" morph="none" start_char="3067" end_char="3072">Nature</TOKEN>
<TOKEN id="token-17-62" pos="word" morph="none" start_char="3074" end_char="3074">y</TOKEN>
<TOKEN id="token-17-63" pos="word" morph="none" start_char="3076" end_char="3078">que</TOKEN>
</SEG>
<SEG id="segment-18" start_char="3081" end_char="3261">
<ORIGINAL_TEXT>"hace solo tres días, la misma revista dejó en claro que el virus sobre el que se informó, creado en el laboratorio, no tiene relación con el virus natural [que causa] el COVID-19".</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="punct" morph="none" start_char="3081" end_char="3081">"</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="3082" end_char="3085">hace</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="3087" end_char="3090">solo</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="3092" end_char="3095">tres</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="3097" end_char="3100">días</TOKEN>
<TOKEN id="token-18-5" pos="punct" morph="none" start_char="3101" end_char="3101">,</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="3103" end_char="3104">la</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="3106" end_char="3110">misma</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="3112" end_char="3118">revista</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="3120" end_char="3123">dejó</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="3125" end_char="3126">en</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="3128" end_char="3132">claro</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="3134" end_char="3136">que</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="3138" end_char="3139">el</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="3141" end_char="3145">virus</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="3147" end_char="3151">sobre</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="3153" end_char="3154">el</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="3156" end_char="3158">que</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="3160" end_char="3161">se</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="3163" end_char="3169">informó</TOKEN>
<TOKEN id="token-18-20" pos="punct" morph="none" start_char="3170" end_char="3170">,</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="3172" end_char="3177">creado</TOKEN>
<TOKEN id="token-18-22" pos="word" morph="none" start_char="3179" end_char="3180">en</TOKEN>
<TOKEN id="token-18-23" pos="word" morph="none" start_char="3182" end_char="3183">el</TOKEN>
<TOKEN id="token-18-24" pos="word" morph="none" start_char="3185" end_char="3195">laboratorio</TOKEN>
<TOKEN id="token-18-25" pos="punct" morph="none" start_char="3196" end_char="3196">,</TOKEN>
<TOKEN id="token-18-26" pos="word" morph="none" start_char="3198" end_char="3199">no</TOKEN>
<TOKEN id="token-18-27" pos="word" morph="none" start_char="3201" end_char="3205">tiene</TOKEN>
<TOKEN id="token-18-28" pos="word" morph="none" start_char="3207" end_char="3214">relación</TOKEN>
<TOKEN id="token-18-29" pos="word" morph="none" start_char="3216" end_char="3218">con</TOKEN>
<TOKEN id="token-18-30" pos="word" morph="none" start_char="3220" end_char="3221">el</TOKEN>
<TOKEN id="token-18-31" pos="word" morph="none" start_char="3223" end_char="3227">virus</TOKEN>
<TOKEN id="token-18-32" pos="word" morph="none" start_char="3229" end_char="3235">natural</TOKEN>
<TOKEN id="token-18-33" pos="punct" morph="none" start_char="3237" end_char="3237">[</TOKEN>
<TOKEN id="token-18-34" pos="word" morph="none" start_char="3238" end_char="3240">que</TOKEN>
<TOKEN id="token-18-35" pos="word" morph="none" start_char="3242" end_char="3246">causa</TOKEN>
<TOKEN id="token-18-36" pos="punct" morph="none" start_char="3247" end_char="3247">]</TOKEN>
<TOKEN id="token-18-37" pos="word" morph="none" start_char="3249" end_char="3250">el</TOKEN>
<TOKEN id="token-18-38" pos="unknown" morph="none" start_char="3252" end_char="3259">COVID-19</TOKEN>
<TOKEN id="token-18-39" pos="punct" morph="none" start_char="3260" end_char="3261">".</TOKEN>
</SEG>
<SEG id="segment-19" start_char="3265" end_char="3363">
<ORIGINAL_TEXT>Al revisar los artículos publicados por Nature en noviembre de 2015, se pudo encontrar uno titulado</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="3265" end_char="3266">Al</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="3268" end_char="3274">revisar</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="3276" end_char="3278">los</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="3280" end_char="3288">artículos</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="3290" end_char="3299">publicados</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="3301" end_char="3303">por</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="3305" end_char="3310">Nature</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="3312" end_char="3313">en</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="3315" end_char="3323">noviembre</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="3325" end_char="3326">de</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="3328" end_char="3331">2015</TOKEN>
<TOKEN id="token-19-11" pos="punct" morph="none" start_char="3332" end_char="3332">,</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="3334" end_char="3335">se</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="3337" end_char="3340">pudo</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="3342" end_char="3350">encontrar</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="3352" end_char="3354">uno</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="3356" end_char="3363">titulado</TOKEN>
</SEG>
<SEG id="segment-20" start_char="3366" end_char="3444">
<ORIGINAL_TEXT>"El virus creado de murciélago genera debate sobre riesgos de la investigación"</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="punct" morph="none" start_char="3366" end_char="3366">"</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="3367" end_char="3368">El</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="3370" end_char="3374">virus</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="3376" end_char="3381">creado</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="3383" end_char="3384">de</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="3386" end_char="3395">murciélago</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="3397" end_char="3402">genera</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="3404" end_char="3409">debate</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="3411" end_char="3415">sobre</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="3417" end_char="3423">riesgos</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="3425" end_char="3426">de</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="3428" end_char="3429">la</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="3431" end_char="3443">investigación</TOKEN>
<TOKEN id="token-20-13" pos="punct" morph="none" start_char="3444" end_char="3444">"</TOKEN>
</SEG>
<SEG id="segment-21" start_char="3447" end_char="3447">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="punct" morph="none" start_char="3447" end_char="3447">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="3449" end_char="3528">
<ORIGINAL_TEXT>La publicación fue actualizada en marzo de 2020 con una nota editorial que dice:</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="3449" end_char="3450">La</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="3452" end_char="3462">publicación</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="3464" end_char="3466">fue</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="3468" end_char="3478">actualizada</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="3480" end_char="3481">en</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="3483" end_char="3487">marzo</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="3489" end_char="3490">de</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="3492" end_char="3495">2020</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="3497" end_char="3499">con</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="3501" end_char="3503">una</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="3505" end_char="3508">nota</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="3510" end_char="3518">editorial</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="3520" end_char="3522">que</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="3524" end_char="3527">dice</TOKEN>
<TOKEN id="token-22-14" pos="punct" morph="none" start_char="3528" end_char="3528">:</TOKEN>
</SEG>
<SEG id="segment-23" start_char="3531" end_char="3675">
<ORIGINAL_TEXT>"Sabemos que esta historia se está utilizando como base de teorías no verificadas de que el nuevo coronavirus que causa el COVID-19 fue diseñado.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="punct" morph="none" start_char="3531" end_char="3531">"</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="3532" end_char="3538">Sabemos</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="3540" end_char="3542">que</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="3544" end_char="3547">esta</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="3549" end_char="3556">historia</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="3558" end_char="3559">se</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="3561" end_char="3564">está</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="3566" end_char="3575">utilizando</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="3577" end_char="3580">como</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="3582" end_char="3585">base</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="3587" end_char="3588">de</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="3590" end_char="3596">teorías</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="3598" end_char="3599">no</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="3601" end_char="3611">verificadas</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="3613" end_char="3614">de</TOKEN>
<TOKEN id="token-23-15" pos="word" morph="none" start_char="3616" end_char="3618">que</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="3620" end_char="3621">el</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="3623" end_char="3627">nuevo</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="3629" end_char="3639">coronavirus</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="3641" end_char="3643">que</TOKEN>
<TOKEN id="token-23-20" pos="word" morph="none" start_char="3645" end_char="3649">causa</TOKEN>
<TOKEN id="token-23-21" pos="word" morph="none" start_char="3651" end_char="3652">el</TOKEN>
<TOKEN id="token-23-22" pos="unknown" morph="none" start_char="3654" end_char="3661">COVID-19</TOKEN>
<TOKEN id="token-23-23" pos="word" morph="none" start_char="3663" end_char="3665">fue</TOKEN>
<TOKEN id="token-23-24" pos="word" morph="none" start_char="3667" end_char="3674">diseñado</TOKEN>
<TOKEN id="token-23-25" pos="punct" morph="none" start_char="3675" end_char="3675">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="3677" end_char="3716">
<ORIGINAL_TEXT>No hay evidencia de que esto sea cierto.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="3677" end_char="3678">No</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="3680" end_char="3682">hay</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="3684" end_char="3692">evidencia</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="3694" end_char="3695">de</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="3697" end_char="3699">que</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="3701" end_char="3704">esto</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="3706" end_char="3708">sea</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="3710" end_char="3715">cierto</TOKEN>
<TOKEN id="token-24-8" pos="punct" morph="none" start_char="3716" end_char="3716">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="3718" end_char="3796">
<ORIGINAL_TEXT>Los científicos creen que un animal es la fuente más probable del coronavirus".</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="3718" end_char="3720">Los</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="3722" end_char="3732">científicos</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="3734" end_char="3738">creen</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="3740" end_char="3742">que</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="3744" end_char="3745">un</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="3747" end_char="3752">animal</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="3754" end_char="3755">es</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="3757" end_char="3758">la</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="3760" end_char="3765">fuente</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="3767" end_char="3769">más</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="3771" end_char="3778">probable</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="3780" end_char="3782">del</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="3784" end_char="3794">coronavirus</TOKEN>
<TOKEN id="token-25-13" pos="punct" morph="none" start_char="3795" end_char="3796">".</TOKEN>
</SEG>
<SEG id="segment-26" start_char="3801" end_char="3913">
<ORIGINAL_TEXT>Captura de pantalla tomada el 31 de marzo de 2020 donde se muestra la nota agregada al artículo de 2015 de Nature</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="3801" end_char="3807">Captura</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="3809" end_char="3810">de</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="3812" end_char="3819">pantalla</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="3821" end_char="3826">tomada</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="3828" end_char="3829">el</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="3831" end_char="3832">31</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="3834" end_char="3835">de</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="3837" end_char="3841">marzo</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="3843" end_char="3844">de</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="3846" end_char="3849">2020</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="3851" end_char="3855">donde</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="3857" end_char="3858">se</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="3860" end_char="3866">muestra</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="3868" end_char="3869">la</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="3871" end_char="3874">nota</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="3876" end_char="3883">agregada</TOKEN>
<TOKEN id="token-26-16" pos="word" morph="none" start_char="3885" end_char="3886">al</TOKEN>
<TOKEN id="token-26-17" pos="word" morph="none" start_char="3888" end_char="3895">artículo</TOKEN>
<TOKEN id="token-26-18" pos="word" morph="none" start_char="3897" end_char="3898">de</TOKEN>
<TOKEN id="token-26-19" pos="word" morph="none" start_char="3900" end_char="3903">2015</TOKEN>
<TOKEN id="token-26-20" pos="word" morph="none" start_char="3905" end_char="3906">de</TOKEN>
<TOKEN id="token-26-21" pos="word" morph="none" start_char="3908" end_char="3913">Nature</TOKEN>
</SEG>
<SEG id="segment-27" start_char="3916" end_char="4109">
<ORIGINAL_TEXT>Luego de la difusión del informe de 2015, relacionándolo ahora al nuevo coronavirus, el programa "Porta a Porta", también de la estación italiana RAI, invitó a un especialista a debatir el tema.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="3916" end_char="3920">Luego</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="3922" end_char="3923">de</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="3925" end_char="3926">la</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="3928" end_char="3935">difusión</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="3937" end_char="3939">del</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="3941" end_char="3947">informe</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="3949" end_char="3950">de</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="3952" end_char="3955">2015</TOKEN>
<TOKEN id="token-27-8" pos="punct" morph="none" start_char="3956" end_char="3956">,</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="3958" end_char="3971">relacionándolo</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="3973" end_char="3977">ahora</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="3979" end_char="3980">al</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="3982" end_char="3986">nuevo</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="3988" end_char="3998">coronavirus</TOKEN>
<TOKEN id="token-27-14" pos="punct" morph="none" start_char="3999" end_char="3999">,</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="4001" end_char="4002">el</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="4004" end_char="4011">programa</TOKEN>
<TOKEN id="token-27-17" pos="punct" morph="none" start_char="4013" end_char="4013">"</TOKEN>
<TOKEN id="token-27-18" pos="word" morph="none" start_char="4014" end_char="4018">Porta</TOKEN>
<TOKEN id="token-27-19" pos="word" morph="none" start_char="4020" end_char="4020">a</TOKEN>
<TOKEN id="token-27-20" pos="word" morph="none" start_char="4022" end_char="4026">Porta</TOKEN>
<TOKEN id="token-27-21" pos="punct" morph="none" start_char="4027" end_char="4028">",</TOKEN>
<TOKEN id="token-27-22" pos="word" morph="none" start_char="4030" end_char="4036">también</TOKEN>
<TOKEN id="token-27-23" pos="word" morph="none" start_char="4038" end_char="4039">de</TOKEN>
<TOKEN id="token-27-24" pos="word" morph="none" start_char="4041" end_char="4042">la</TOKEN>
<TOKEN id="token-27-25" pos="word" morph="none" start_char="4044" end_char="4051">estación</TOKEN>
<TOKEN id="token-27-26" pos="word" morph="none" start_char="4053" end_char="4060">italiana</TOKEN>
<TOKEN id="token-27-27" pos="word" morph="none" start_char="4062" end_char="4064">RAI</TOKEN>
<TOKEN id="token-27-28" pos="punct" morph="none" start_char="4065" end_char="4065">,</TOKEN>
<TOKEN id="token-27-29" pos="word" morph="none" start_char="4067" end_char="4072">invitó</TOKEN>
<TOKEN id="token-27-30" pos="word" morph="none" start_char="4074" end_char="4074">a</TOKEN>
<TOKEN id="token-27-31" pos="word" morph="none" start_char="4076" end_char="4077">un</TOKEN>
<TOKEN id="token-27-32" pos="word" morph="none" start_char="4079" end_char="4090">especialista</TOKEN>
<TOKEN id="token-27-33" pos="word" morph="none" start_char="4092" end_char="4092">a</TOKEN>
<TOKEN id="token-27-34" pos="word" morph="none" start_char="4094" end_char="4100">debatir</TOKEN>
<TOKEN id="token-27-35" pos="word" morph="none" start_char="4102" end_char="4103">el</TOKEN>
<TOKEN id="token-27-36" pos="word" morph="none" start_char="4105" end_char="4108">tema</TOKEN>
<TOKEN id="token-27-37" pos="punct" morph="none" start_char="4109" end_char="4109">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="4111" end_char="4231">
<ORIGINAL_TEXT>En la emisión, el profesor Fabrizio Pregliasco, especialista en virología de la Universidad de Milán, calificó como una "</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="4111" end_char="4112">En</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="4114" end_char="4115">la</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="4117" end_char="4123">emisión</TOKEN>
<TOKEN id="token-28-3" pos="punct" morph="none" start_char="4124" end_char="4124">,</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="4126" end_char="4127">el</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="4129" end_char="4136">profesor</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="4138" end_char="4145">Fabrizio</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="4147" end_char="4156">Pregliasco</TOKEN>
<TOKEN id="token-28-8" pos="punct" morph="none" start_char="4157" end_char="4157">,</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="4159" end_char="4170">especialista</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="4172" end_char="4173">en</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="4175" end_char="4183">virología</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="4185" end_char="4186">de</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="4188" end_char="4189">la</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="4191" end_char="4201">Universidad</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="4203" end_char="4204">de</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="4206" end_char="4210">Milán</TOKEN>
<TOKEN id="token-28-17" pos="punct" morph="none" start_char="4211" end_char="4211">,</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="4213" end_char="4220">calificó</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="4222" end_char="4225">como</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="4227" end_char="4229">una</TOKEN>
<TOKEN id="token-28-21" pos="punct" morph="none" start_char="4231" end_char="4231">"</TOKEN>
</SEG>
<SEG id="segment-29" start_char="4234" end_char="4258">
<ORIGINAL_TEXT>teoría de la conspiración</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="4234" end_char="4239">teoría</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="4241" end_char="4242">de</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="4244" end_char="4245">la</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="4247" end_char="4258">conspiración</TOKEN>
</SEG>
<SEG id="segment-30" start_char="4261" end_char="4306">
<ORIGINAL_TEXT>" la posibilidad de que el nuevo coronavirus "</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="punct" morph="none" start_char="4261" end_char="4261">"</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="4263" end_char="4264">la</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="4266" end_char="4276">posibilidad</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="4278" end_char="4279">de</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="4281" end_char="4283">que</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="4285" end_char="4286">el</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="4288" end_char="4292">nuevo</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="4294" end_char="4304">coronavirus</TOKEN>
<TOKEN id="token-30-8" pos="punct" morph="none" start_char="4306" end_char="4306">"</TOKEN>
</SEG>
<SEG id="segment-31" start_char="4309" end_char="4316">
<ORIGINAL_TEXT>escapara</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="4309" end_char="4316">escapara</TOKEN>
</SEG>
<SEG id="segment-32" start_char="4319" end_char="4338">
<ORIGINAL_TEXT>" de un laboratorio.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="punct" morph="none" start_char="4319" end_char="4319">"</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="4321" end_char="4322">de</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="4324" end_char="4325">un</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="4327" end_char="4337">laboratorio</TOKEN>
<TOKEN id="token-32-4" pos="punct" morph="none" start_char="4338" end_char="4338">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="4341" end_char="4468">
<ORIGINAL_TEXT>"Por el contrario, hay confirmaciones de que es de origen natural, siempre a través de una variación de un virus del murciélago.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="punct" morph="none" start_char="4341" end_char="4341">"</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="4342" end_char="4344">Por</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="4346" end_char="4347">el</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="4349" end_char="4357">contrario</TOKEN>
<TOKEN id="token-33-4" pos="punct" morph="none" start_char="4358" end_char="4358">,</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="4360" end_char="4362">hay</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="4364" end_char="4377">confirmaciones</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="4379" end_char="4380">de</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="4382" end_char="4384">que</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="4386" end_char="4387">es</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="4389" end_char="4390">de</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="4392" end_char="4397">origen</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="4399" end_char="4405">natural</TOKEN>
<TOKEN id="token-33-13" pos="punct" morph="none" start_char="4406" end_char="4406">,</TOKEN>
<TOKEN id="token-33-14" pos="word" morph="none" start_char="4408" end_char="4414">siempre</TOKEN>
<TOKEN id="token-33-15" pos="word" morph="none" start_char="4416" end_char="4416">a</TOKEN>
<TOKEN id="token-33-16" pos="word" morph="none" start_char="4418" end_char="4423">través</TOKEN>
<TOKEN id="token-33-17" pos="word" morph="none" start_char="4425" end_char="4426">de</TOKEN>
<TOKEN id="token-33-18" pos="word" morph="none" start_char="4428" end_char="4430">una</TOKEN>
<TOKEN id="token-33-19" pos="word" morph="none" start_char="4432" end_char="4440">variación</TOKEN>
<TOKEN id="token-33-20" pos="word" morph="none" start_char="4442" end_char="4443">de</TOKEN>
<TOKEN id="token-33-21" pos="word" morph="none" start_char="4445" end_char="4446">un</TOKEN>
<TOKEN id="token-33-22" pos="word" morph="none" start_char="4448" end_char="4452">virus</TOKEN>
<TOKEN id="token-33-23" pos="word" morph="none" start_char="4454" end_char="4456">del</TOKEN>
<TOKEN id="token-33-24" pos="word" morph="none" start_char="4458" end_char="4467">murciélago</TOKEN>
<TOKEN id="token-33-25" pos="punct" morph="none" start_char="4468" end_char="4468">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="4470" end_char="4521">
<ORIGINAL_TEXT>El genoma que fue aislado muestra un origen natural.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="4470" end_char="4471">El</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="4473" end_char="4478">genoma</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="4480" end_char="4482">que</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="4484" end_char="4486">fue</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="4488" end_char="4494">aislado</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="4496" end_char="4502">muestra</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="4504" end_char="4505">un</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="4507" end_char="4512">origen</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="4514" end_char="4520">natural</TOKEN>
<TOKEN id="token-34-9" pos="punct" morph="none" start_char="4521" end_char="4521">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="4523" end_char="4717">
<ORIGINAL_TEXT>Esta posibilidad es parte de las teorías de complots, teorías de conspiración, también vinculadas al hecho de que en Wuhan hay un hermoso laboratorio de alta seguridad donde se realizan estudios.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="4523" end_char="4526">Esta</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="4528" end_char="4538">posibilidad</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="4540" end_char="4541">es</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="4543" end_char="4547">parte</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="4549" end_char="4550">de</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="4552" end_char="4554">las</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="4556" end_char="4562">teorías</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="4564" end_char="4565">de</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="4567" end_char="4574">complots</TOKEN>
<TOKEN id="token-35-9" pos="punct" morph="none" start_char="4575" end_char="4575">,</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="4577" end_char="4583">teorías</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="4585" end_char="4586">de</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="4588" end_char="4599">conspiración</TOKEN>
<TOKEN id="token-35-13" pos="punct" morph="none" start_char="4600" end_char="4600">,</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="4602" end_char="4608">también</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="4610" end_char="4619">vinculadas</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="4621" end_char="4622">al</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="4624" end_char="4628">hecho</TOKEN>
<TOKEN id="token-35-18" pos="word" morph="none" start_char="4630" end_char="4631">de</TOKEN>
<TOKEN id="token-35-19" pos="word" morph="none" start_char="4633" end_char="4635">que</TOKEN>
<TOKEN id="token-35-20" pos="word" morph="none" start_char="4637" end_char="4638">en</TOKEN>
<TOKEN id="token-35-21" pos="word" morph="none" start_char="4640" end_char="4644">Wuhan</TOKEN>
<TOKEN id="token-35-22" pos="word" morph="none" start_char="4646" end_char="4648">hay</TOKEN>
<TOKEN id="token-35-23" pos="word" morph="none" start_char="4650" end_char="4651">un</TOKEN>
<TOKEN id="token-35-24" pos="word" morph="none" start_char="4653" end_char="4659">hermoso</TOKEN>
<TOKEN id="token-35-25" pos="word" morph="none" start_char="4661" end_char="4671">laboratorio</TOKEN>
<TOKEN id="token-35-26" pos="word" morph="none" start_char="4673" end_char="4674">de</TOKEN>
<TOKEN id="token-35-27" pos="word" morph="none" start_char="4676" end_char="4679">alta</TOKEN>
<TOKEN id="token-35-28" pos="word" morph="none" start_char="4681" end_char="4689">seguridad</TOKEN>
<TOKEN id="token-35-29" pos="word" morph="none" start_char="4691" end_char="4695">donde</TOKEN>
<TOKEN id="token-35-30" pos="word" morph="none" start_char="4697" end_char="4698">se</TOKEN>
<TOKEN id="token-35-31" pos="word" morph="none" start_char="4700" end_char="4707">realizan</TOKEN>
<TOKEN id="token-35-32" pos="word" morph="none" start_char="4709" end_char="4716">estudios</TOKEN>
<TOKEN id="token-35-33" pos="punct" morph="none" start_char="4717" end_char="4717">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="4719" end_char="4785">
<ORIGINAL_TEXT>Pero insisto en que, en realidad, ése no sería el origen del virus"</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="4719" end_char="4722">Pero</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="4724" end_char="4730">insisto</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="4732" end_char="4733">en</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="4735" end_char="4737">que</TOKEN>
<TOKEN id="token-36-4" pos="punct" morph="none" start_char="4738" end_char="4738">,</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="4740" end_char="4741">en</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="4743" end_char="4750">realidad</TOKEN>
<TOKEN id="token-36-7" pos="punct" morph="none" start_char="4751" end_char="4751">,</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="4753" end_char="4755">ése</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="4757" end_char="4758">no</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="4760" end_char="4764">sería</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="4766" end_char="4767">el</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="4769" end_char="4774">origen</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="4776" end_char="4778">del</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="4780" end_char="4784">virus</TOKEN>
<TOKEN id="token-36-15" pos="punct" morph="none" start_char="4785" end_char="4785">"</TOKEN>
</SEG>
<SEG id="segment-37" start_char="4788" end_char="4805">
<ORIGINAL_TEXT>, dijo Pregliasco.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="punct" morph="none" start_char="4788" end_char="4788">,</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="4790" end_char="4793">dijo</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="4795" end_char="4804">Pregliasco</TOKEN>
<TOKEN id="token-37-3" pos="punct" morph="none" start_char="4805" end_char="4805">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="4808" end_char="4838">
<ORIGINAL_TEXT>El origen del nuevo coronavirus</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="4808" end_char="4809">El</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="4811" end_char="4816">origen</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="4818" end_char="4820">del</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="4822" end_char="4826">nuevo</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="4828" end_char="4838">coronavirus</TOKEN>
</SEG>
<SEG id="segment-39" start_char="4842" end_char="4978">
<ORIGINAL_TEXT>Un estudio publicado el 17 de marzo de este año en la revista científica Nature reitera que el nuevo coronavirus tiene un origen natural:</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="4842" end_char="4843">Un</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="4845" end_char="4851">estudio</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="4853" end_char="4861">publicado</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="4863" end_char="4864">el</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="4866" end_char="4867">17</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="4869" end_char="4870">de</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="4872" end_char="4876">marzo</TOKEN>
<TOKEN id="token-39-7" pos="word" morph="none" start_char="4878" end_char="4879">de</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="4881" end_char="4884">este</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="4886" end_char="4888">año</TOKEN>
<TOKEN id="token-39-10" pos="word" morph="none" start_char="4890" end_char="4891">en</TOKEN>
<TOKEN id="token-39-11" pos="word" morph="none" start_char="4893" end_char="4894">la</TOKEN>
<TOKEN id="token-39-12" pos="word" morph="none" start_char="4896" end_char="4902">revista</TOKEN>
<TOKEN id="token-39-13" pos="word" morph="none" start_char="4904" end_char="4913">científica</TOKEN>
<TOKEN id="token-39-14" pos="word" morph="none" start_char="4915" end_char="4920">Nature</TOKEN>
<TOKEN id="token-39-15" pos="word" morph="none" start_char="4922" end_char="4928">reitera</TOKEN>
<TOKEN id="token-39-16" pos="word" morph="none" start_char="4930" end_char="4932">que</TOKEN>
<TOKEN id="token-39-17" pos="word" morph="none" start_char="4934" end_char="4935">el</TOKEN>
<TOKEN id="token-39-18" pos="word" morph="none" start_char="4937" end_char="4941">nuevo</TOKEN>
<TOKEN id="token-39-19" pos="word" morph="none" start_char="4943" end_char="4953">coronavirus</TOKEN>
<TOKEN id="token-39-20" pos="word" morph="none" start_char="4955" end_char="4959">tiene</TOKEN>
<TOKEN id="token-39-21" pos="word" morph="none" start_char="4961" end_char="4962">un</TOKEN>
<TOKEN id="token-39-22" pos="word" morph="none" start_char="4964" end_char="4969">origen</TOKEN>
<TOKEN id="token-39-23" pos="word" morph="none" start_char="4971" end_char="4977">natural</TOKEN>
<TOKEN id="token-39-24" pos="punct" morph="none" start_char="4978" end_char="4978">:</TOKEN>
</SEG>
<SEG id="segment-40" start_char="4981" end_char="5111">
<ORIGINAL_TEXT>"Nuestro análisis muestra claramente que el SARS-CoV-2 no es una creación de laboratorio o un virus que fue manipulado a propósito"</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="punct" morph="none" start_char="4981" end_char="4981">"</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="4982" end_char="4988">Nuestro</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="4990" end_char="4997">análisis</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="4999" end_char="5005">muestra</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="5007" end_char="5016">claramente</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="5018" end_char="5020">que</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="5022" end_char="5023">el</TOKEN>
<TOKEN id="token-40-7" pos="unknown" morph="none" start_char="5025" end_char="5034">SARS-CoV-2</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="5036" end_char="5037">no</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="5039" end_char="5040">es</TOKEN>
<TOKEN id="token-40-10" pos="word" morph="none" start_char="5042" end_char="5044">una</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="5046" end_char="5053">creación</TOKEN>
<TOKEN id="token-40-12" pos="word" morph="none" start_char="5055" end_char="5056">de</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="5058" end_char="5068">laboratorio</TOKEN>
<TOKEN id="token-40-14" pos="word" morph="none" start_char="5070" end_char="5070">o</TOKEN>
<TOKEN id="token-40-15" pos="word" morph="none" start_char="5072" end_char="5073">un</TOKEN>
<TOKEN id="token-40-16" pos="word" morph="none" start_char="5075" end_char="5079">virus</TOKEN>
<TOKEN id="token-40-17" pos="word" morph="none" start_char="5081" end_char="5083">que</TOKEN>
<TOKEN id="token-40-18" pos="word" morph="none" start_char="5085" end_char="5087">fue</TOKEN>
<TOKEN id="token-40-19" pos="word" morph="none" start_char="5089" end_char="5098">manipulado</TOKEN>
<TOKEN id="token-40-20" pos="word" morph="none" start_char="5100" end_char="5100">a</TOKEN>
<TOKEN id="token-40-21" pos="word" morph="none" start_char="5102" end_char="5110">propósito</TOKEN>
<TOKEN id="token-40-22" pos="punct" morph="none" start_char="5111" end_char="5111">"</TOKEN>
</SEG>
<SEG id="segment-41" start_char="5114" end_char="5146">
<ORIGINAL_TEXT>, escribieron los investigadores.</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="punct" morph="none" start_char="5114" end_char="5114">,</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="5116" end_char="5126">escribieron</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="5128" end_char="5130">los</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="5132" end_char="5145">investigadores</TOKEN>
<TOKEN id="token-41-4" pos="punct" morph="none" start_char="5146" end_char="5146">.</TOKEN>
</SEG>
<SEG id="segment-42" start_char="5149" end_char="5364">
<ORIGINAL_TEXT>Como parte del estudio, los autores analizaron la estructura genética del SARS-CoV-2, concluyendo que, si hubiera una manipulación en laboratorio, su estructura sería similar a la de otros organismos ya existentes. "</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="5149" end_char="5152">Como</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="5154" end_char="5158">parte</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="5160" end_char="5162">del</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="5164" end_char="5170">estudio</TOKEN>
<TOKEN id="token-42-4" pos="punct" morph="none" start_char="5171" end_char="5171">,</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="5173" end_char="5175">los</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="5177" end_char="5183">autores</TOKEN>
<TOKEN id="token-42-7" pos="word" morph="none" start_char="5185" end_char="5194">analizaron</TOKEN>
<TOKEN id="token-42-8" pos="word" morph="none" start_char="5196" end_char="5197">la</TOKEN>
<TOKEN id="token-42-9" pos="word" morph="none" start_char="5199" end_char="5208">estructura</TOKEN>
<TOKEN id="token-42-10" pos="word" morph="none" start_char="5210" end_char="5217">genética</TOKEN>
<TOKEN id="token-42-11" pos="word" morph="none" start_char="5219" end_char="5221">del</TOKEN>
<TOKEN id="token-42-12" pos="unknown" morph="none" start_char="5223" end_char="5232">SARS-CoV-2</TOKEN>
<TOKEN id="token-42-13" pos="punct" morph="none" start_char="5233" end_char="5233">,</TOKEN>
<TOKEN id="token-42-14" pos="word" morph="none" start_char="5235" end_char="5245">concluyendo</TOKEN>
<TOKEN id="token-42-15" pos="word" morph="none" start_char="5247" end_char="5249">que</TOKEN>
<TOKEN id="token-42-16" pos="punct" morph="none" start_char="5250" end_char="5250">,</TOKEN>
<TOKEN id="token-42-17" pos="word" morph="none" start_char="5252" end_char="5253">si</TOKEN>
<TOKEN id="token-42-18" pos="word" morph="none" start_char="5255" end_char="5261">hubiera</TOKEN>
<TOKEN id="token-42-19" pos="word" morph="none" start_char="5263" end_char="5265">una</TOKEN>
<TOKEN id="token-42-20" pos="word" morph="none" start_char="5267" end_char="5278">manipulación</TOKEN>
<TOKEN id="token-42-21" pos="word" morph="none" start_char="5280" end_char="5281">en</TOKEN>
<TOKEN id="token-42-22" pos="word" morph="none" start_char="5283" end_char="5293">laboratorio</TOKEN>
<TOKEN id="token-42-23" pos="punct" morph="none" start_char="5294" end_char="5294">,</TOKEN>
<TOKEN id="token-42-24" pos="word" morph="none" start_char="5296" end_char="5297">su</TOKEN>
<TOKEN id="token-42-25" pos="word" morph="none" start_char="5299" end_char="5308">estructura</TOKEN>
<TOKEN id="token-42-26" pos="word" morph="none" start_char="5310" end_char="5314">sería</TOKEN>
<TOKEN id="token-42-27" pos="word" morph="none" start_char="5316" end_char="5322">similar</TOKEN>
<TOKEN id="token-42-28" pos="word" morph="none" start_char="5324" end_char="5324">a</TOKEN>
<TOKEN id="token-42-29" pos="word" morph="none" start_char="5326" end_char="5327">la</TOKEN>
<TOKEN id="token-42-30" pos="word" morph="none" start_char="5329" end_char="5330">de</TOKEN>
<TOKEN id="token-42-31" pos="word" morph="none" start_char="5332" end_char="5336">otros</TOKEN>
<TOKEN id="token-42-32" pos="word" morph="none" start_char="5338" end_char="5347">organismos</TOKEN>
<TOKEN id="token-42-33" pos="word" morph="none" start_char="5349" end_char="5350">ya</TOKEN>
<TOKEN id="token-42-34" pos="word" morph="none" start_char="5352" end_char="5361">existentes</TOKEN>
<TOKEN id="token-42-35" pos="punct" morph="none" start_char="5362" end_char="5362">.</TOKEN>
<TOKEN id="token-42-36" pos="punct" morph="none" start_char="5364" end_char="5364">"</TOKEN>
</SEG>
<SEG id="segment-43" start_char="5367" end_char="5519">
<ORIGINAL_TEXT>Sin embargo, los datos genéticos muestran irrefutablemente que el SARS-CoV-2 no se deriva de ninguna estructura de virus central utilizada anteriormente"</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="5367" end_char="5369">Sin</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="5371" end_char="5377">embargo</TOKEN>
<TOKEN id="token-43-2" pos="punct" morph="none" start_char="5378" end_char="5378">,</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="5380" end_char="5382">los</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="5384" end_char="5388">datos</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="5390" end_char="5398">genéticos</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="5400" end_char="5407">muestran</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="5409" end_char="5424">irrefutablemente</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="5426" end_char="5428">que</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="5430" end_char="5431">el</TOKEN>
<TOKEN id="token-43-10" pos="unknown" morph="none" start_char="5433" end_char="5442">SARS-CoV-2</TOKEN>
<TOKEN id="token-43-11" pos="word" morph="none" start_char="5444" end_char="5445">no</TOKEN>
<TOKEN id="token-43-12" pos="word" morph="none" start_char="5447" end_char="5448">se</TOKEN>
<TOKEN id="token-43-13" pos="word" morph="none" start_char="5450" end_char="5455">deriva</TOKEN>
<TOKEN id="token-43-14" pos="word" morph="none" start_char="5457" end_char="5458">de</TOKEN>
<TOKEN id="token-43-15" pos="word" morph="none" start_char="5460" end_char="5466">ninguna</TOKEN>
<TOKEN id="token-43-16" pos="word" morph="none" start_char="5468" end_char="5477">estructura</TOKEN>
<TOKEN id="token-43-17" pos="word" morph="none" start_char="5479" end_char="5480">de</TOKEN>
<TOKEN id="token-43-18" pos="word" morph="none" start_char="5482" end_char="5486">virus</TOKEN>
<TOKEN id="token-43-19" pos="word" morph="none" start_char="5488" end_char="5494">central</TOKEN>
<TOKEN id="token-43-20" pos="word" morph="none" start_char="5496" end_char="5504">utilizada</TOKEN>
<TOKEN id="token-43-21" pos="word" morph="none" start_char="5506" end_char="5518">anteriormente</TOKEN>
<TOKEN id="token-43-22" pos="punct" morph="none" start_char="5519" end_char="5519">"</TOKEN>
</SEG>
<SEG id="segment-44" start_char="5522" end_char="5547">
<ORIGINAL_TEXT>, indica la investigación.</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="punct" morph="none" start_char="5522" end_char="5522">,</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="5524" end_char="5529">indica</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="5531" end_char="5532">la</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="5534" end_char="5546">investigación</TOKEN>
<TOKEN id="token-44-4" pos="punct" morph="none" start_char="5547" end_char="5547">.</TOKEN>
</SEG>
<SEG id="segment-45" start_char="5551" end_char="5657">
<ORIGINAL_TEXT>Esta posibilidad también es considerada como la más probable por la Organización Mundial de la Salud (OMS).</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="5551" end_char="5554">Esta</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="5556" end_char="5566">posibilidad</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="5568" end_char="5574">también</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="5576" end_char="5577">es</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="5579" end_char="5589">considerada</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="5591" end_char="5594">como</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="5596" end_char="5597">la</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="5599" end_char="5601">más</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="5603" end_char="5610">probable</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="5612" end_char="5614">por</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="5616" end_char="5617">la</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="5619" end_char="5630">Organización</TOKEN>
<TOKEN id="token-45-12" pos="word" morph="none" start_char="5632" end_char="5638">Mundial</TOKEN>
<TOKEN id="token-45-13" pos="word" morph="none" start_char="5640" end_char="5641">de</TOKEN>
<TOKEN id="token-45-14" pos="word" morph="none" start_char="5643" end_char="5644">la</TOKEN>
<TOKEN id="token-45-15" pos="word" morph="none" start_char="5646" end_char="5650">Salud</TOKEN>
<TOKEN id="token-45-16" pos="punct" morph="none" start_char="5652" end_char="5652">(</TOKEN>
<TOKEN id="token-45-17" pos="word" morph="none" start_char="5653" end_char="5655">OMS</TOKEN>
<TOKEN id="token-45-18" pos="punct" morph="none" start_char="5656" end_char="5657">).</TOKEN>
</SEG>
<SEG id="segment-46" start_char="5660" end_char="5660">
<ORIGINAL_TEXT>"</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="punct" morph="none" start_char="5660" end_char="5660">"</TOKEN>
</SEG>
<SEG id="segment-47" start_char="5663" end_char="5748">
<ORIGINAL_TEXT>Actualmente, se desconoce el origen del SARS-CoV-2, el coronavirus que causa COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="5663" end_char="5673">Actualmente</TOKEN>
<TOKEN id="token-47-1" pos="punct" morph="none" start_char="5674" end_char="5674">,</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="5676" end_char="5677">se</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="5679" end_char="5687">desconoce</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="5689" end_char="5690">el</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="5692" end_char="5697">origen</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="5699" end_char="5701">del</TOKEN>
<TOKEN id="token-47-7" pos="unknown" morph="none" start_char="5703" end_char="5712">SARS-CoV-2</TOKEN>
<TOKEN id="token-47-8" pos="punct" morph="none" start_char="5713" end_char="5713">,</TOKEN>
<TOKEN id="token-47-9" pos="word" morph="none" start_char="5715" end_char="5716">el</TOKEN>
<TOKEN id="token-47-10" pos="word" morph="none" start_char="5718" end_char="5728">coronavirus</TOKEN>
<TOKEN id="token-47-11" pos="word" morph="none" start_char="5730" end_char="5732">que</TOKEN>
<TOKEN id="token-47-12" pos="word" morph="none" start_char="5734" end_char="5738">causa</TOKEN>
<TOKEN id="token-47-13" pos="unknown" morph="none" start_char="5740" end_char="5747">COVID-19</TOKEN>
<TOKEN id="token-47-14" pos="punct" morph="none" start_char="5748" end_char="5748">.</TOKEN>
</SEG>
<SEG id="segment-48" start_char="5750" end_char="5864">
<ORIGINAL_TEXT>Toda la evidencia disponible sugiere que el SARS-CoV-2 tiene un origen animal natural y no es un virus construido",</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="5750" end_char="5753">Toda</TOKEN>
<TOKEN id="token-48-1" pos="word" morph="none" start_char="5755" end_char="5756">la</TOKEN>
<TOKEN id="token-48-2" pos="word" morph="none" start_char="5758" end_char="5766">evidencia</TOKEN>
<TOKEN id="token-48-3" pos="word" morph="none" start_char="5768" end_char="5777">disponible</TOKEN>
<TOKEN id="token-48-4" pos="word" morph="none" start_char="5779" end_char="5785">sugiere</TOKEN>
<TOKEN id="token-48-5" pos="word" morph="none" start_char="5787" end_char="5789">que</TOKEN>
<TOKEN id="token-48-6" pos="word" morph="none" start_char="5791" end_char="5792">el</TOKEN>
<TOKEN id="token-48-7" pos="unknown" morph="none" start_char="5794" end_char="5803">SARS-CoV-2</TOKEN>
<TOKEN id="token-48-8" pos="word" morph="none" start_char="5805" end_char="5809">tiene</TOKEN>
<TOKEN id="token-48-9" pos="word" morph="none" start_char="5811" end_char="5812">un</TOKEN>
<TOKEN id="token-48-10" pos="word" morph="none" start_char="5814" end_char="5819">origen</TOKEN>
<TOKEN id="token-48-11" pos="word" morph="none" start_char="5821" end_char="5826">animal</TOKEN>
<TOKEN id="token-48-12" pos="word" morph="none" start_char="5828" end_char="5834">natural</TOKEN>
<TOKEN id="token-48-13" pos="word" morph="none" start_char="5836" end_char="5836">y</TOKEN>
<TOKEN id="token-48-14" pos="word" morph="none" start_char="5838" end_char="5839">no</TOKEN>
<TOKEN id="token-48-15" pos="word" morph="none" start_char="5841" end_char="5842">es</TOKEN>
<TOKEN id="token-48-16" pos="word" morph="none" start_char="5844" end_char="5845">un</TOKEN>
<TOKEN id="token-48-17" pos="word" morph="none" start_char="5847" end_char="5851">virus</TOKEN>
<TOKEN id="token-48-18" pos="word" morph="none" start_char="5853" end_char="5862">construido</TOKEN>
<TOKEN id="token-48-19" pos="punct" morph="none" start_char="5863" end_char="5864">",</TOKEN>
</SEG>
<SEG id="segment-49" start_char="5867" end_char="5901">
<ORIGINAL_TEXT>explican en su sitio web en inglés.</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="5867" end_char="5874">explican</TOKEN>
<TOKEN id="token-49-1" pos="word" morph="none" start_char="5876" end_char="5877">en</TOKEN>
<TOKEN id="token-49-2" pos="word" morph="none" start_char="5879" end_char="5880">su</TOKEN>
<TOKEN id="token-49-3" pos="word" morph="none" start_char="5882" end_char="5886">sitio</TOKEN>
<TOKEN id="token-49-4" pos="word" morph="none" start_char="5888" end_char="5890">web</TOKEN>
<TOKEN id="token-49-5" pos="word" morph="none" start_char="5892" end_char="5893">en</TOKEN>
<TOKEN id="token-49-6" pos="word" morph="none" start_char="5895" end_char="5900">inglés</TOKEN>
<TOKEN id="token-49-7" pos="punct" morph="none" start_char="5901" end_char="5901">.</TOKEN>
</SEG>
<SEG id="segment-50" start_char="5904" end_char="6027">
<ORIGINAL_TEXT>Los primero casos de infección con el nuevo coronavirus fueron confirmados en diciembre de 2019 en la ciudad china de Wuhan.</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="5904" end_char="5906">Los</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="5908" end_char="5914">primero</TOKEN>
<TOKEN id="token-50-2" pos="word" morph="none" start_char="5916" end_char="5920">casos</TOKEN>
<TOKEN id="token-50-3" pos="word" morph="none" start_char="5922" end_char="5923">de</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="5925" end_char="5933">infección</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="5935" end_char="5937">con</TOKEN>
<TOKEN id="token-50-6" pos="word" morph="none" start_char="5939" end_char="5940">el</TOKEN>
<TOKEN id="token-50-7" pos="word" morph="none" start_char="5942" end_char="5946">nuevo</TOKEN>
<TOKEN id="token-50-8" pos="word" morph="none" start_char="5948" end_char="5958">coronavirus</TOKEN>
<TOKEN id="token-50-9" pos="word" morph="none" start_char="5960" end_char="5965">fueron</TOKEN>
<TOKEN id="token-50-10" pos="word" morph="none" start_char="5967" end_char="5977">confirmados</TOKEN>
<TOKEN id="token-50-11" pos="word" morph="none" start_char="5979" end_char="5980">en</TOKEN>
<TOKEN id="token-50-12" pos="word" morph="none" start_char="5982" end_char="5990">diciembre</TOKEN>
<TOKEN id="token-50-13" pos="word" morph="none" start_char="5992" end_char="5993">de</TOKEN>
<TOKEN id="token-50-14" pos="word" morph="none" start_char="5995" end_char="5998">2019</TOKEN>
<TOKEN id="token-50-15" pos="word" morph="none" start_char="6000" end_char="6001">en</TOKEN>
<TOKEN id="token-50-16" pos="word" morph="none" start_char="6003" end_char="6004">la</TOKEN>
<TOKEN id="token-50-17" pos="word" morph="none" start_char="6006" end_char="6011">ciudad</TOKEN>
<TOKEN id="token-50-18" pos="word" morph="none" start_char="6013" end_char="6017">china</TOKEN>
<TOKEN id="token-50-19" pos="word" morph="none" start_char="6019" end_char="6020">de</TOKEN>
<TOKEN id="token-50-20" pos="word" morph="none" start_char="6022" end_char="6026">Wuhan</TOKEN>
<TOKEN id="token-50-21" pos="punct" morph="none" start_char="6027" end_char="6027">.</TOKEN>
</SEG>
<SEG id="segment-51" start_char="6029" end_char="6187">
<ORIGINAL_TEXT>La región, que registró miles de casos nuevos por día durante el punto más álgido del brote a fines de febrero, fue considerada el 28 de marzo pasado zona de "</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="word" morph="none" start_char="6029" end_char="6030">La</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="6032" end_char="6037">región</TOKEN>
<TOKEN id="token-51-2" pos="punct" morph="none" start_char="6038" end_char="6038">,</TOKEN>
<TOKEN id="token-51-3" pos="word" morph="none" start_char="6040" end_char="6042">que</TOKEN>
<TOKEN id="token-51-4" pos="word" morph="none" start_char="6044" end_char="6051">registró</TOKEN>
<TOKEN id="token-51-5" pos="word" morph="none" start_char="6053" end_char="6057">miles</TOKEN>
<TOKEN id="token-51-6" pos="word" morph="none" start_char="6059" end_char="6060">de</TOKEN>
<TOKEN id="token-51-7" pos="word" morph="none" start_char="6062" end_char="6066">casos</TOKEN>
<TOKEN id="token-51-8" pos="word" morph="none" start_char="6068" end_char="6073">nuevos</TOKEN>
<TOKEN id="token-51-9" pos="word" morph="none" start_char="6075" end_char="6077">por</TOKEN>
<TOKEN id="token-51-10" pos="word" morph="none" start_char="6079" end_char="6081">día</TOKEN>
<TOKEN id="token-51-11" pos="word" morph="none" start_char="6083" end_char="6089">durante</TOKEN>
<TOKEN id="token-51-12" pos="word" morph="none" start_char="6091" end_char="6092">el</TOKEN>
<TOKEN id="token-51-13" pos="word" morph="none" start_char="6094" end_char="6098">punto</TOKEN>
<TOKEN id="token-51-14" pos="word" morph="none" start_char="6100" end_char="6102">más</TOKEN>
<TOKEN id="token-51-15" pos="word" morph="none" start_char="6104" end_char="6109">álgido</TOKEN>
<TOKEN id="token-51-16" pos="word" morph="none" start_char="6111" end_char="6113">del</TOKEN>
<TOKEN id="token-51-17" pos="word" morph="none" start_char="6115" end_char="6119">brote</TOKEN>
<TOKEN id="token-51-18" pos="word" morph="none" start_char="6121" end_char="6121">a</TOKEN>
<TOKEN id="token-51-19" pos="word" morph="none" start_char="6123" end_char="6127">fines</TOKEN>
<TOKEN id="token-51-20" pos="word" morph="none" start_char="6129" end_char="6130">de</TOKEN>
<TOKEN id="token-51-21" pos="word" morph="none" start_char="6132" end_char="6138">febrero</TOKEN>
<TOKEN id="token-51-22" pos="punct" morph="none" start_char="6139" end_char="6139">,</TOKEN>
<TOKEN id="token-51-23" pos="word" morph="none" start_char="6141" end_char="6143">fue</TOKEN>
<TOKEN id="token-51-24" pos="word" morph="none" start_char="6145" end_char="6155">considerada</TOKEN>
<TOKEN id="token-51-25" pos="word" morph="none" start_char="6157" end_char="6158">el</TOKEN>
<TOKEN id="token-51-26" pos="word" morph="none" start_char="6160" end_char="6161">28</TOKEN>
<TOKEN id="token-51-27" pos="word" morph="none" start_char="6163" end_char="6164">de</TOKEN>
<TOKEN id="token-51-28" pos="word" morph="none" start_char="6166" end_char="6170">marzo</TOKEN>
<TOKEN id="token-51-29" pos="word" morph="none" start_char="6172" end_char="6177">pasado</TOKEN>
<TOKEN id="token-51-30" pos="word" morph="none" start_char="6179" end_char="6182">zona</TOKEN>
<TOKEN id="token-51-31" pos="word" morph="none" start_char="6184" end_char="6185">de</TOKEN>
<TOKEN id="token-51-32" pos="punct" morph="none" start_char="6187" end_char="6187">"</TOKEN>
</SEG>
<SEG id="segment-52" start_char="6190" end_char="6200">
<ORIGINAL_TEXT>bajo riesgo</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="6190" end_char="6193">bajo</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="6195" end_char="6200">riesgo</TOKEN>
</SEG>
<SEG id="segment-53" start_char="6203" end_char="6238">
<ORIGINAL_TEXT>", según fuentes del gobierno local.</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="punct" morph="none" start_char="6203" end_char="6204">",</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="6206" end_char="6210">según</TOKEN>
<TOKEN id="token-53-2" pos="word" morph="none" start_char="6212" end_char="6218">fuentes</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="6220" end_char="6222">del</TOKEN>
<TOKEN id="token-53-4" pos="word" morph="none" start_char="6224" end_char="6231">gobierno</TOKEN>
<TOKEN id="token-53-5" pos="word" morph="none" start_char="6233" end_char="6237">local</TOKEN>
<TOKEN id="token-53-6" pos="punct" morph="none" start_char="6238" end_char="6238">.</TOKEN>
</SEG>
<SEG id="segment-54" start_char="6241" end_char="6420">
<ORIGINAL_TEXT>En el resto del mundo, los países están intensificando las medidas de contención para controlar la enfermedad, que ha dejado más de 50.000 muertos y más de un millón de infectados.</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="word" morph="none" start_char="6241" end_char="6242">En</TOKEN>
<TOKEN id="token-54-1" pos="word" morph="none" start_char="6244" end_char="6245">el</TOKEN>
<TOKEN id="token-54-2" pos="word" morph="none" start_char="6247" end_char="6251">resto</TOKEN>
<TOKEN id="token-54-3" pos="word" morph="none" start_char="6253" end_char="6255">del</TOKEN>
<TOKEN id="token-54-4" pos="word" morph="none" start_char="6257" end_char="6261">mundo</TOKEN>
<TOKEN id="token-54-5" pos="punct" morph="none" start_char="6262" end_char="6262">,</TOKEN>
<TOKEN id="token-54-6" pos="word" morph="none" start_char="6264" end_char="6266">los</TOKEN>
<TOKEN id="token-54-7" pos="word" morph="none" start_char="6268" end_char="6273">países</TOKEN>
<TOKEN id="token-54-8" pos="word" morph="none" start_char="6275" end_char="6279">están</TOKEN>
<TOKEN id="token-54-9" pos="word" morph="none" start_char="6281" end_char="6294">intensificando</TOKEN>
<TOKEN id="token-54-10" pos="word" morph="none" start_char="6296" end_char="6298">las</TOKEN>
<TOKEN id="token-54-11" pos="word" morph="none" start_char="6300" end_char="6306">medidas</TOKEN>
<TOKEN id="token-54-12" pos="word" morph="none" start_char="6308" end_char="6309">de</TOKEN>
<TOKEN id="token-54-13" pos="word" morph="none" start_char="6311" end_char="6320">contención</TOKEN>
<TOKEN id="token-54-14" pos="word" morph="none" start_char="6322" end_char="6325">para</TOKEN>
<TOKEN id="token-54-15" pos="word" morph="none" start_char="6327" end_char="6335">controlar</TOKEN>
<TOKEN id="token-54-16" pos="word" morph="none" start_char="6337" end_char="6338">la</TOKEN>
<TOKEN id="token-54-17" pos="word" morph="none" start_char="6340" end_char="6349">enfermedad</TOKEN>
<TOKEN id="token-54-18" pos="punct" morph="none" start_char="6350" end_char="6350">,</TOKEN>
<TOKEN id="token-54-19" pos="word" morph="none" start_char="6352" end_char="6354">que</TOKEN>
<TOKEN id="token-54-20" pos="word" morph="none" start_char="6356" end_char="6357">ha</TOKEN>
<TOKEN id="token-54-21" pos="word" morph="none" start_char="6359" end_char="6364">dejado</TOKEN>
<TOKEN id="token-54-22" pos="word" morph="none" start_char="6366" end_char="6368">más</TOKEN>
<TOKEN id="token-54-23" pos="word" morph="none" start_char="6370" end_char="6371">de</TOKEN>
<TOKEN id="token-54-24" pos="word" morph="none" start_char="6373" end_char="6378">50.000</TOKEN>
<TOKEN id="token-54-25" pos="word" morph="none" start_char="6380" end_char="6386">muertos</TOKEN>
<TOKEN id="token-54-26" pos="word" morph="none" start_char="6388" end_char="6388">y</TOKEN>
<TOKEN id="token-54-27" pos="word" morph="none" start_char="6390" end_char="6392">más</TOKEN>
<TOKEN id="token-54-28" pos="word" morph="none" start_char="6394" end_char="6395">de</TOKEN>
<TOKEN id="token-54-29" pos="word" morph="none" start_char="6397" end_char="6398">un</TOKEN>
<TOKEN id="token-54-30" pos="word" morph="none" start_char="6400" end_char="6405">millón</TOKEN>
<TOKEN id="token-54-31" pos="word" morph="none" start_char="6407" end_char="6408">de</TOKEN>
<TOKEN id="token-54-32" pos="word" morph="none" start_char="6410" end_char="6419">infectados</TOKEN>
<TOKEN id="token-54-33" pos="punct" morph="none" start_char="6420" end_char="6420">.</TOKEN>
</SEG>
<SEG id="segment-55" start_char="6423" end_char="6596">
<ORIGINAL_TEXT>En resumen, las publicaciones que afirman que el informe de 2015 de la emisora italiana RAI prueba que el nuevo coronavirus fue creado en un laboratorio en China es engañoso.</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="word" morph="none" start_char="6423" end_char="6424">En</TOKEN>
<TOKEN id="token-55-1" pos="word" morph="none" start_char="6426" end_char="6432">resumen</TOKEN>
<TOKEN id="token-55-2" pos="punct" morph="none" start_char="6433" end_char="6433">,</TOKEN>
<TOKEN id="token-55-3" pos="word" morph="none" start_char="6435" end_char="6437">las</TOKEN>
<TOKEN id="token-55-4" pos="word" morph="none" start_char="6439" end_char="6451">publicaciones</TOKEN>
<TOKEN id="token-55-5" pos="word" morph="none" start_char="6453" end_char="6455">que</TOKEN>
<TOKEN id="token-55-6" pos="word" morph="none" start_char="6457" end_char="6463">afirman</TOKEN>
<TOKEN id="token-55-7" pos="word" morph="none" start_char="6465" end_char="6467">que</TOKEN>
<TOKEN id="token-55-8" pos="word" morph="none" start_char="6469" end_char="6470">el</TOKEN>
<TOKEN id="token-55-9" pos="word" morph="none" start_char="6472" end_char="6478">informe</TOKEN>
<TOKEN id="token-55-10" pos="word" morph="none" start_char="6480" end_char="6481">de</TOKEN>
<TOKEN id="token-55-11" pos="word" morph="none" start_char="6483" end_char="6486">2015</TOKEN>
<TOKEN id="token-55-12" pos="word" morph="none" start_char="6488" end_char="6489">de</TOKEN>
<TOKEN id="token-55-13" pos="word" morph="none" start_char="6491" end_char="6492">la</TOKEN>
<TOKEN id="token-55-14" pos="word" morph="none" start_char="6494" end_char="6500">emisora</TOKEN>
<TOKEN id="token-55-15" pos="word" morph="none" start_char="6502" end_char="6509">italiana</TOKEN>
<TOKEN id="token-55-16" pos="word" morph="none" start_char="6511" end_char="6513">RAI</TOKEN>
<TOKEN id="token-55-17" pos="word" morph="none" start_char="6515" end_char="6520">prueba</TOKEN>
<TOKEN id="token-55-18" pos="word" morph="none" start_char="6522" end_char="6524">que</TOKEN>
<TOKEN id="token-55-19" pos="word" morph="none" start_char="6526" end_char="6527">el</TOKEN>
<TOKEN id="token-55-20" pos="word" morph="none" start_char="6529" end_char="6533">nuevo</TOKEN>
<TOKEN id="token-55-21" pos="word" morph="none" start_char="6535" end_char="6545">coronavirus</TOKEN>
<TOKEN id="token-55-22" pos="word" morph="none" start_char="6547" end_char="6549">fue</TOKEN>
<TOKEN id="token-55-23" pos="word" morph="none" start_char="6551" end_char="6556">creado</TOKEN>
<TOKEN id="token-55-24" pos="word" morph="none" start_char="6558" end_char="6559">en</TOKEN>
<TOKEN id="token-55-25" pos="word" morph="none" start_char="6561" end_char="6562">un</TOKEN>
<TOKEN id="token-55-26" pos="word" morph="none" start_char="6564" end_char="6574">laboratorio</TOKEN>
<TOKEN id="token-55-27" pos="word" morph="none" start_char="6576" end_char="6577">en</TOKEN>
<TOKEN id="token-55-28" pos="word" morph="none" start_char="6579" end_char="6583">China</TOKEN>
<TOKEN id="token-55-29" pos="word" morph="none" start_char="6585" end_char="6586">es</TOKEN>
<TOKEN id="token-55-30" pos="word" morph="none" start_char="6588" end_char="6595">engañoso</TOKEN>
<TOKEN id="token-55-31" pos="punct" morph="none" start_char="6596" end_char="6596">.</TOKEN>
</SEG>
<SEG id="segment-56" start_char="6598" end_char="6769">
<ORIGINAL_TEXT>El artículo se basó en un estudio de la revista científica Nature, que aclaró que no hay evidencia de que el experimento presentado esté relacionado con la pandemia actual.</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="6598" end_char="6599">El</TOKEN>
<TOKEN id="token-56-1" pos="word" morph="none" start_char="6601" end_char="6608">artículo</TOKEN>
<TOKEN id="token-56-2" pos="word" morph="none" start_char="6610" end_char="6611">se</TOKEN>
<TOKEN id="token-56-3" pos="word" morph="none" start_char="6613" end_char="6616">basó</TOKEN>
<TOKEN id="token-56-4" pos="word" morph="none" start_char="6618" end_char="6619">en</TOKEN>
<TOKEN id="token-56-5" pos="word" morph="none" start_char="6621" end_char="6622">un</TOKEN>
<TOKEN id="token-56-6" pos="word" morph="none" start_char="6624" end_char="6630">estudio</TOKEN>
<TOKEN id="token-56-7" pos="word" morph="none" start_char="6632" end_char="6633">de</TOKEN>
<TOKEN id="token-56-8" pos="word" morph="none" start_char="6635" end_char="6636">la</TOKEN>
<TOKEN id="token-56-9" pos="word" morph="none" start_char="6638" end_char="6644">revista</TOKEN>
<TOKEN id="token-56-10" pos="word" morph="none" start_char="6646" end_char="6655">científica</TOKEN>
<TOKEN id="token-56-11" pos="word" morph="none" start_char="6657" end_char="6662">Nature</TOKEN>
<TOKEN id="token-56-12" pos="punct" morph="none" start_char="6663" end_char="6663">,</TOKEN>
<TOKEN id="token-56-13" pos="word" morph="none" start_char="6665" end_char="6667">que</TOKEN>
<TOKEN id="token-56-14" pos="word" morph="none" start_char="6669" end_char="6674">aclaró</TOKEN>
<TOKEN id="token-56-15" pos="word" morph="none" start_char="6676" end_char="6678">que</TOKEN>
<TOKEN id="token-56-16" pos="word" morph="none" start_char="6680" end_char="6681">no</TOKEN>
<TOKEN id="token-56-17" pos="word" morph="none" start_char="6683" end_char="6685">hay</TOKEN>
<TOKEN id="token-56-18" pos="word" morph="none" start_char="6687" end_char="6695">evidencia</TOKEN>
<TOKEN id="token-56-19" pos="word" morph="none" start_char="6697" end_char="6698">de</TOKEN>
<TOKEN id="token-56-20" pos="word" morph="none" start_char="6700" end_char="6702">que</TOKEN>
<TOKEN id="token-56-21" pos="word" morph="none" start_char="6704" end_char="6705">el</TOKEN>
<TOKEN id="token-56-22" pos="word" morph="none" start_char="6707" end_char="6717">experimento</TOKEN>
<TOKEN id="token-56-23" pos="word" morph="none" start_char="6719" end_char="6728">presentado</TOKEN>
<TOKEN id="token-56-24" pos="word" morph="none" start_char="6730" end_char="6733">esté</TOKEN>
<TOKEN id="token-56-25" pos="word" morph="none" start_char="6735" end_char="6745">relacionado</TOKEN>
<TOKEN id="token-56-26" pos="word" morph="none" start_char="6747" end_char="6749">con</TOKEN>
<TOKEN id="token-56-27" pos="word" morph="none" start_char="6751" end_char="6752">la</TOKEN>
<TOKEN id="token-56-28" pos="word" morph="none" start_char="6754" end_char="6761">pandemia</TOKEN>
<TOKEN id="token-56-29" pos="word" morph="none" start_char="6763" end_char="6768">actual</TOKEN>
<TOKEN id="token-56-30" pos="punct" morph="none" start_char="6769" end_char="6769">.</TOKEN>
</SEG>
<SEG id="segment-57" start_char="6771" end_char="6910">
<ORIGINAL_TEXT>Un análisis posterior publicado en la revista británica muestra que el SARS-CoV-2 no se fabricó en el laboratorio ni se produjo a propósito.</ORIGINAL_TEXT>
<TOKEN id="token-57-0" pos="word" morph="none" start_char="6771" end_char="6772">Un</TOKEN>
<TOKEN id="token-57-1" pos="word" morph="none" start_char="6774" end_char="6781">análisis</TOKEN>
<TOKEN id="token-57-2" pos="word" morph="none" start_char="6783" end_char="6791">posterior</TOKEN>
<TOKEN id="token-57-3" pos="word" morph="none" start_char="6793" end_char="6801">publicado</TOKEN>
<TOKEN id="token-57-4" pos="word" morph="none" start_char="6803" end_char="6804">en</TOKEN>
<TOKEN id="token-57-5" pos="word" morph="none" start_char="6806" end_char="6807">la</TOKEN>
<TOKEN id="token-57-6" pos="word" morph="none" start_char="6809" end_char="6815">revista</TOKEN>
<TOKEN id="token-57-7" pos="word" morph="none" start_char="6817" end_char="6825">británica</TOKEN>
<TOKEN id="token-57-8" pos="word" morph="none" start_char="6827" end_char="6833">muestra</TOKEN>
<TOKEN id="token-57-9" pos="word" morph="none" start_char="6835" end_char="6837">que</TOKEN>
<TOKEN id="token-57-10" pos="word" morph="none" start_char="6839" end_char="6840">el</TOKEN>
<TOKEN id="token-57-11" pos="unknown" morph="none" start_char="6842" end_char="6851">SARS-CoV-2</TOKEN>
<TOKEN id="token-57-12" pos="word" morph="none" start_char="6853" end_char="6854">no</TOKEN>
<TOKEN id="token-57-13" pos="word" morph="none" start_char="6856" end_char="6857">se</TOKEN>
<TOKEN id="token-57-14" pos="word" morph="none" start_char="6859" end_char="6865">fabricó</TOKEN>
<TOKEN id="token-57-15" pos="word" morph="none" start_char="6867" end_char="6868">en</TOKEN>
<TOKEN id="token-57-16" pos="word" morph="none" start_char="6870" end_char="6871">el</TOKEN>
<TOKEN id="token-57-17" pos="word" morph="none" start_char="6873" end_char="6883">laboratorio</TOKEN>
<TOKEN id="token-57-18" pos="word" morph="none" start_char="6885" end_char="6886">ni</TOKEN>
<TOKEN id="token-57-19" pos="word" morph="none" start_char="6888" end_char="6889">se</TOKEN>
<TOKEN id="token-57-20" pos="word" morph="none" start_char="6891" end_char="6897">produjo</TOKEN>
<TOKEN id="token-57-21" pos="word" morph="none" start_char="6899" end_char="6899">a</TOKEN>
<TOKEN id="token-57-22" pos="word" morph="none" start_char="6901" end_char="6909">propósito</TOKEN>
<TOKEN id="token-57-23" pos="punct" morph="none" start_char="6910" end_char="6910">.</TOKEN>
</SEG>
<SEG id="segment-58" start_char="6913" end_char="7071">
<ORIGINAL_TEXT>Esta verificación fue realizada en el marco de la coalición periodística para combatir la desinformación Projeto Comprova en Brasil, de la que la AFP es parte.</ORIGINAL_TEXT>
<TOKEN id="token-58-0" pos="word" morph="none" start_char="6913" end_char="6916">Esta</TOKEN>
<TOKEN id="token-58-1" pos="word" morph="none" start_char="6918" end_char="6929">verificación</TOKEN>
<TOKEN id="token-58-2" pos="word" morph="none" start_char="6931" end_char="6933">fue</TOKEN>
<TOKEN id="token-58-3" pos="word" morph="none" start_char="6935" end_char="6943">realizada</TOKEN>
<TOKEN id="token-58-4" pos="word" morph="none" start_char="6945" end_char="6946">en</TOKEN>
<TOKEN id="token-58-5" pos="word" morph="none" start_char="6948" end_char="6949">el</TOKEN>
<TOKEN id="token-58-6" pos="word" morph="none" start_char="6951" end_char="6955">marco</TOKEN>
<TOKEN id="token-58-7" pos="word" morph="none" start_char="6957" end_char="6958">de</TOKEN>
<TOKEN id="token-58-8" pos="word" morph="none" start_char="6960" end_char="6961">la</TOKEN>
<TOKEN id="token-58-9" pos="word" morph="none" start_char="6963" end_char="6971">coalición</TOKEN>
<TOKEN id="token-58-10" pos="word" morph="none" start_char="6973" end_char="6984">periodística</TOKEN>
<TOKEN id="token-58-11" pos="word" morph="none" start_char="6986" end_char="6989">para</TOKEN>
<TOKEN id="token-58-12" pos="word" morph="none" start_char="6991" end_char="6998">combatir</TOKEN>
<TOKEN id="token-58-13" pos="word" morph="none" start_char="7000" end_char="7001">la</TOKEN>
<TOKEN id="token-58-14" pos="word" morph="none" start_char="7003" end_char="7016">desinformación</TOKEN>
<TOKEN id="token-58-15" pos="word" morph="none" start_char="7018" end_char="7024">Projeto</TOKEN>
<TOKEN id="token-58-16" pos="word" morph="none" start_char="7026" end_char="7033">Comprova</TOKEN>
<TOKEN id="token-58-17" pos="word" morph="none" start_char="7035" end_char="7036">en</TOKEN>
<TOKEN id="token-58-18" pos="word" morph="none" start_char="7038" end_char="7043">Brasil</TOKEN>
<TOKEN id="token-58-19" pos="punct" morph="none" start_char="7044" end_char="7044">,</TOKEN>
<TOKEN id="token-58-20" pos="word" morph="none" start_char="7046" end_char="7047">de</TOKEN>
<TOKEN id="token-58-21" pos="word" morph="none" start_char="7049" end_char="7050">la</TOKEN>
<TOKEN id="token-58-22" pos="word" morph="none" start_char="7052" end_char="7054">que</TOKEN>
<TOKEN id="token-58-23" pos="word" morph="none" start_char="7056" end_char="7057">la</TOKEN>
<TOKEN id="token-58-24" pos="word" morph="none" start_char="7059" end_char="7061">AFP</TOKEN>
<TOKEN id="token-58-25" pos="word" morph="none" start_char="7063" end_char="7064">es</TOKEN>
<TOKEN id="token-58-26" pos="word" morph="none" start_char="7066" end_char="7070">parte</TOKEN>
<TOKEN id="token-58-27" pos="punct" morph="none" start_char="7071" end_char="7071">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
