<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CAFX" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="6498" raw_text_md5="6b76aec49a34dd10fdcbec7186d49e8b">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="107">
<ORIGINAL_TEXT>Sin confinamientos pero con rastreo intensivo de contactos: la estrategia de Taiwán para vencer al COVID-19</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="3">Sin</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="5" end_char="18">confinamientos</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="20" end_char="23">pero</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="25" end_char="27">con</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="29" end_char="35">rastreo</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="37" end_char="45">intensivo</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="47" end_char="48">de</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="50" end_char="58">contactos</TOKEN>
<TOKEN id="token-0-8" pos="punct" morph="none" start_char="59" end_char="59">:</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="61" end_char="62">la</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="64" end_char="73">estrategia</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="75" end_char="76">de</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="78" end_char="83">Taiwán</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="85" end_char="88">para</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="90" end_char="95">vencer</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="97" end_char="98">al</TOKEN>
<TOKEN id="token-0-16" pos="unknown" morph="none" start_char="100" end_char="107">COVID-19</TOKEN>
</SEG>
<SEG id="segment-1" start_char="111" end_char="301">
<ORIGINAL_TEXT>Las políticas de estado que aplicó el gobierno taiwanés enfrentar el coronavirus fueron efectivas, tanto que solo registran 11 fallecidos por el virus desde el inicio de la pandemia (REUTERS)</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="111" end_char="113">Las</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="115" end_char="123">políticas</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="125" end_char="126">de</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="128" end_char="133">estado</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="135" end_char="137">que</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="139" end_char="144">aplicó</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="146" end_char="147">el</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="149" end_char="156">gobierno</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="158" end_char="165">taiwanés</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="167" end_char="175">enfrentar</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="177" end_char="178">el</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="180" end_char="190">coronavirus</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="192" end_char="197">fueron</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="199" end_char="207">efectivas</TOKEN>
<TOKEN id="token-1-14" pos="punct" morph="none" start_char="208" end_char="208">,</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="210" end_char="214">tanto</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="216" end_char="218">que</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="220" end_char="223">solo</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="225" end_char="233">registran</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="235" end_char="236">11</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="238" end_char="247">fallecidos</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="249" end_char="251">por</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="253" end_char="254">el</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="256" end_char="260">virus</TOKEN>
<TOKEN id="token-1-24" pos="word" morph="none" start_char="262" end_char="266">desde</TOKEN>
<TOKEN id="token-1-25" pos="word" morph="none" start_char="268" end_char="269">el</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="271" end_char="276">inicio</TOKEN>
<TOKEN id="token-1-27" pos="word" morph="none" start_char="278" end_char="279">de</TOKEN>
<TOKEN id="token-1-28" pos="word" morph="none" start_char="281" end_char="282">la</TOKEN>
<TOKEN id="token-1-29" pos="word" morph="none" start_char="284" end_char="291">pandemia</TOKEN>
<TOKEN id="token-1-30" pos="punct" morph="none" start_char="293" end_char="293">(</TOKEN>
<TOKEN id="token-1-31" pos="word" morph="none" start_char="294" end_char="300">REUTERS</TOKEN>
<TOKEN id="token-1-32" pos="punct" morph="none" start_char="301" end_char="301">)</TOKEN>
</SEG>
<SEG id="segment-2" start_char="305" end_char="366">
<ORIGINAL_TEXT>En Taiwán durante el 2020 la vida fue, medianamente, "normal".</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="305" end_char="306">En</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="308" end_char="313">Taiwán</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="315" end_char="321">durante</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="323" end_char="324">el</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="326" end_char="329">2020</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="331" end_char="332">la</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="334" end_char="337">vida</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="339" end_char="341">fue</TOKEN>
<TOKEN id="token-2-8" pos="punct" morph="none" start_char="342" end_char="342">,</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="344" end_char="355">medianamente</TOKEN>
<TOKEN id="token-2-10" pos="punct" morph="none" start_char="356" end_char="356">,</TOKEN>
<TOKEN id="token-2-11" pos="punct" morph="none" start_char="358" end_char="358">"</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="359" end_char="364">normal</TOKEN>
<TOKEN id="token-2-13" pos="punct" morph="none" start_char="365" end_char="366">".</TOKEN>
</SEG>
<SEG id="segment-3" start_char="368" end_char="441">
<ORIGINAL_TEXT>Se celebraron bodas, fiestas, se realizaron conciertos, ferias y deportes.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="368" end_char="369">Se</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="371" end_char="380">celebraron</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="382" end_char="386">bodas</TOKEN>
<TOKEN id="token-3-3" pos="punct" morph="none" start_char="387" end_char="387">,</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="389" end_char="395">fiestas</TOKEN>
<TOKEN id="token-3-5" pos="punct" morph="none" start_char="396" end_char="396">,</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="398" end_char="399">se</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="401" end_char="410">realizaron</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="412" end_char="421">conciertos</TOKEN>
<TOKEN id="token-3-9" pos="punct" morph="none" start_char="422" end_char="422">,</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="424" end_char="429">ferias</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="431" end_char="431">y</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="433" end_char="440">deportes</TOKEN>
<TOKEN id="token-3-13" pos="punct" morph="none" start_char="441" end_char="441">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="443" end_char="635">
<ORIGINAL_TEXT>Esta situación fue diferente al resto del mundo donde esa "normalidad" se vio trastocada por el coronavirus y el confinamiento, los tapabocas y la distancia social fueron la "nueva" normalidad.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="443" end_char="446">Esta</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="448" end_char="456">situación</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="458" end_char="460">fue</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="462" end_char="470">diferente</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="472" end_char="473">al</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="475" end_char="479">resto</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="481" end_char="483">del</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="485" end_char="489">mundo</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="491" end_char="495">donde</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="497" end_char="499">esa</TOKEN>
<TOKEN id="token-4-10" pos="punct" morph="none" start_char="501" end_char="501">"</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="502" end_char="511">normalidad</TOKEN>
<TOKEN id="token-4-12" pos="punct" morph="none" start_char="512" end_char="512">"</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="514" end_char="515">se</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="517" end_char="519">vio</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="521" end_char="530">trastocada</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="532" end_char="534">por</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="536" end_char="537">el</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="539" end_char="549">coronavirus</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="551" end_char="551">y</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="553" end_char="554">el</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="556" end_char="568">confinamiento</TOKEN>
<TOKEN id="token-4-22" pos="punct" morph="none" start_char="569" end_char="569">,</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="571" end_char="573">los</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="575" end_char="583">tapabocas</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="585" end_char="585">y</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="587" end_char="588">la</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="590" end_char="598">distancia</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="600" end_char="605">social</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="607" end_char="612">fueron</TOKEN>
<TOKEN id="token-4-30" pos="word" morph="none" start_char="614" end_char="615">la</TOKEN>
<TOKEN id="token-4-31" pos="punct" morph="none" start_char="617" end_char="617">"</TOKEN>
<TOKEN id="token-4-32" pos="word" morph="none" start_char="618" end_char="622">nueva</TOKEN>
<TOKEN id="token-4-33" pos="punct" morph="none" start_char="623" end_char="623">"</TOKEN>
<TOKEN id="token-4-34" pos="word" morph="none" start_char="625" end_char="634">normalidad</TOKEN>
<TOKEN id="token-4-35" pos="punct" morph="none" start_char="635" end_char="635">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="638" end_char="839">
<ORIGINAL_TEXT>Solo 11 personas han muerto de COVID-19 en la pequeña nación insular a 180 km al este de China, desde el comienzo de la pandemia, una hazaña impresionante para un país que nunca llegó a estar confinado.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="638" end_char="641">Solo</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="643" end_char="644">11</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="646" end_char="653">personas</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="655" end_char="657">han</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="659" end_char="664">muerto</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="666" end_char="667">de</TOKEN>
<TOKEN id="token-5-6" pos="unknown" morph="none" start_char="669" end_char="676">COVID-19</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="678" end_char="679">en</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="681" end_char="682">la</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="684" end_char="690">pequeña</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="692" end_char="697">nación</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="699" end_char="705">insular</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="707" end_char="707">a</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="709" end_char="711">180</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="713" end_char="714">km</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="716" end_char="717">al</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="719" end_char="722">este</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="724" end_char="725">de</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="727" end_char="731">China</TOKEN>
<TOKEN id="token-5-19" pos="punct" morph="none" start_char="732" end_char="732">,</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="734" end_char="738">desde</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="740" end_char="741">el</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="743" end_char="750">comienzo</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="752" end_char="753">de</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="755" end_char="756">la</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="758" end_char="765">pandemia</TOKEN>
<TOKEN id="token-5-26" pos="punct" morph="none" start_char="766" end_char="766">,</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="768" end_char="770">una</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="772" end_char="777">hazaña</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="779" end_char="791">impresionante</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="793" end_char="796">para</TOKEN>
<TOKEN id="token-5-31" pos="word" morph="none" start_char="798" end_char="799">un</TOKEN>
<TOKEN id="token-5-32" pos="word" morph="none" start_char="801" end_char="804">país</TOKEN>
<TOKEN id="token-5-33" pos="word" morph="none" start_char="806" end_char="808">que</TOKEN>
<TOKEN id="token-5-34" pos="word" morph="none" start_char="810" end_char="814">nunca</TOKEN>
<TOKEN id="token-5-35" pos="word" morph="none" start_char="816" end_char="820">llegó</TOKEN>
<TOKEN id="token-5-36" pos="word" morph="none" start_char="822" end_char="822">a</TOKEN>
<TOKEN id="token-5-37" pos="word" morph="none" start_char="824" end_char="828">estar</TOKEN>
<TOKEN id="token-5-38" pos="word" morph="none" start_char="830" end_char="838">confinado</TOKEN>
<TOKEN id="token-5-39" pos="punct" morph="none" start_char="839" end_char="839">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="841" end_char="973">
<ORIGINAL_TEXT>Con una de las tasas de COVID-19 per cápita más bajas del mundo, Taiwán ha recibido un aplauso unánime por su gestión de la pandemia.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="841" end_char="843">Con</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="845" end_char="847">una</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="849" end_char="850">de</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="852" end_char="854">las</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="856" end_char="860">tasas</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="862" end_char="863">de</TOKEN>
<TOKEN id="token-6-6" pos="unknown" morph="none" start_char="865" end_char="872">COVID-19</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="874" end_char="876">per</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="878" end_char="883">cápita</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="885" end_char="887">más</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="889" end_char="893">bajas</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="895" end_char="897">del</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="899" end_char="903">mundo</TOKEN>
<TOKEN id="token-6-13" pos="punct" morph="none" start_char="904" end_char="904">,</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="906" end_char="911">Taiwán</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="913" end_char="914">ha</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="916" end_char="923">recibido</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="925" end_char="926">un</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="928" end_char="934">aplauso</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="936" end_char="942">unánime</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="944" end_char="946">por</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="948" end_char="949">su</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="951" end_char="957">gestión</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="959" end_char="960">de</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="962" end_char="963">la</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="965" end_char="972">pandemia</TOKEN>
<TOKEN id="token-6-26" pos="punct" morph="none" start_char="973" end_char="973">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="976" end_char="1151">
<ORIGINAL_TEXT>Al comienzo de la pandemia, fue considerado un país de alto riesgo para la COVID-19 debido a su proximidad a China y a los frecuentes viajes que se realizan entre ambos países.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="976" end_char="977">Al</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="979" end_char="986">comienzo</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="988" end_char="989">de</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="991" end_char="992">la</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="994" end_char="1001">pandemia</TOKEN>
<TOKEN id="token-7-5" pos="punct" morph="none" start_char="1002" end_char="1002">,</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="1004" end_char="1006">fue</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="1008" end_char="1018">considerado</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="1020" end_char="1021">un</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="1023" end_char="1026">país</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="1028" end_char="1029">de</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="1031" end_char="1034">alto</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="1036" end_char="1041">riesgo</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="1043" end_char="1046">para</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="1048" end_char="1049">la</TOKEN>
<TOKEN id="token-7-15" pos="unknown" morph="none" start_char="1051" end_char="1058">COVID-19</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="1060" end_char="1065">debido</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="1067" end_char="1067">a</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="1069" end_char="1070">su</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="1072" end_char="1081">proximidad</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="1083" end_char="1083">a</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="1085" end_char="1089">China</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="1091" end_char="1091">y</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="1093" end_char="1093">a</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="1095" end_char="1097">los</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="1099" end_char="1108">frecuentes</TOKEN>
<TOKEN id="token-7-26" pos="word" morph="none" start_char="1110" end_char="1115">viajes</TOKEN>
<TOKEN id="token-7-27" pos="word" morph="none" start_char="1117" end_char="1119">que</TOKEN>
<TOKEN id="token-7-28" pos="word" morph="none" start_char="1121" end_char="1122">se</TOKEN>
<TOKEN id="token-7-29" pos="word" morph="none" start_char="1124" end_char="1131">realizan</TOKEN>
<TOKEN id="token-7-30" pos="word" morph="none" start_char="1133" end_char="1137">entre</TOKEN>
<TOKEN id="token-7-31" pos="word" morph="none" start_char="1139" end_char="1143">ambos</TOKEN>
<TOKEN id="token-7-32" pos="word" morph="none" start_char="1145" end_char="1150">países</TOKEN>
<TOKEN id="token-7-33" pos="punct" morph="none" start_char="1151" end_char="1151">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1153" end_char="1312">
<ORIGINAL_TEXT>Esto, sumado a un historial de SARS en 2003 que no se gestionó particularmente bien, obligó al Gobierno taiwanés a actuar rápidamente para cerrar sus fronteras.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1153" end_char="1156">Esto</TOKEN>
<TOKEN id="token-8-1" pos="punct" morph="none" start_char="1157" end_char="1157">,</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1159" end_char="1164">sumado</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1166" end_char="1166">a</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1168" end_char="1169">un</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1171" end_char="1179">historial</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1181" end_char="1182">de</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1184" end_char="1187">SARS</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1189" end_char="1190">en</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1192" end_char="1195">2003</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1197" end_char="1199">que</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1201" end_char="1202">no</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1204" end_char="1205">se</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1207" end_char="1214">gestionó</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1216" end_char="1230">particularmente</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1232" end_char="1235">bien</TOKEN>
<TOKEN id="token-8-16" pos="punct" morph="none" start_char="1236" end_char="1236">,</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1238" end_char="1243">obligó</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1245" end_char="1246">al</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1248" end_char="1255">Gobierno</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="1257" end_char="1264">taiwanés</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="1266" end_char="1266">a</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="1268" end_char="1273">actuar</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="1275" end_char="1285">rápidamente</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="1287" end_char="1290">para</TOKEN>
<TOKEN id="token-8-25" pos="word" morph="none" start_char="1292" end_char="1297">cerrar</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="1299" end_char="1301">sus</TOKEN>
<TOKEN id="token-8-27" pos="word" morph="none" start_char="1303" end_char="1311">fronteras</TOKEN>
<TOKEN id="token-8-28" pos="punct" morph="none" start_char="1312" end_char="1312">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1314" end_char="1497">
<ORIGINAL_TEXT>El 20 de enero de 2020 creó un Mando Central de Epidemias para coordinar la cooperación entre los diferentes ministerios y agencias gubernamentales, y entre el gobierno y las empresas.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1314" end_char="1315">El</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1317" end_char="1318">20</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1320" end_char="1321">de</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1323" end_char="1327">enero</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1329" end_char="1330">de</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1332" end_char="1335">2020</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1337" end_char="1340">creó</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1342" end_char="1343">un</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1345" end_char="1349">Mando</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1351" end_char="1357">Central</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1359" end_char="1360">de</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1362" end_char="1370">Epidemias</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1372" end_char="1375">para</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1377" end_char="1385">coordinar</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1387" end_char="1388">la</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1390" end_char="1400">cooperación</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1402" end_char="1406">entre</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1408" end_char="1410">los</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1412" end_char="1421">diferentes</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1423" end_char="1433">ministerios</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1435" end_char="1435">y</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1437" end_char="1444">agencias</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1446" end_char="1460">gubernamentales</TOKEN>
<TOKEN id="token-9-23" pos="punct" morph="none" start_char="1461" end_char="1461">,</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1463" end_char="1463">y</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1465" end_char="1469">entre</TOKEN>
<TOKEN id="token-9-26" pos="word" morph="none" start_char="1471" end_char="1472">el</TOKEN>
<TOKEN id="token-9-27" pos="word" morph="none" start_char="1474" end_char="1481">gobierno</TOKEN>
<TOKEN id="token-9-28" pos="word" morph="none" start_char="1483" end_char="1483">y</TOKEN>
<TOKEN id="token-9-29" pos="word" morph="none" start_char="1485" end_char="1487">las</TOKEN>
<TOKEN id="token-9-30" pos="word" morph="none" start_char="1489" end_char="1496">empresas</TOKEN>
<TOKEN id="token-9-31" pos="punct" morph="none" start_char="1497" end_char="1497">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1500" end_char="1546">
<ORIGINAL_TEXT>Recientemente, un nuevo estudio publicado en el</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1500" end_char="1512">Recientemente</TOKEN>
<TOKEN id="token-10-1" pos="punct" morph="none" start_char="1513" end_char="1513">,</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1515" end_char="1516">un</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1518" end_char="1522">nuevo</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1524" end_char="1530">estudio</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1532" end_char="1540">publicado</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1542" end_char="1543">en</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1545" end_char="1546">el</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1549" end_char="1591">
<ORIGINAL_TEXT>Journal of the American Medical Association</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1549" end_char="1555">Journal</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1557" end_char="1558">of</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1560" end_char="1562">the</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1564" end_char="1571">American</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1573" end_char="1579">Medical</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1581" end_char="1591">Association</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1594" end_char="1680">
<ORIGINAL_TEXT>examinó más a fondo por qué a Taiwán le ha ido tan bien en la lucha contra la COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1594" end_char="1600">examinó</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1602" end_char="1604">más</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1606" end_char="1606">a</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1608" end_char="1612">fondo</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1614" end_char="1616">por</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1618" end_char="1620">qué</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1622" end_char="1622">a</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1624" end_char="1629">Taiwán</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1631" end_char="1632">le</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1634" end_char="1635">ha</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1637" end_char="1639">ido</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1641" end_char="1643">tan</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1645" end_char="1648">bien</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1650" end_char="1651">en</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1653" end_char="1654">la</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1656" end_char="1660">lucha</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1662" end_char="1667">contra</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1669" end_char="1670">la</TOKEN>
<TOKEN id="token-12-18" pos="unknown" morph="none" start_char="1672" end_char="1679">COVID-19</TOKEN>
<TOKEN id="token-12-19" pos="punct" morph="none" start_char="1680" end_char="1680">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1682" end_char="1954">
<ORIGINAL_TEXT>Los autores de la investigación, procedentes de diversos institutos de salud y hospitales de Taiwán y Estados Unidos, compararon la eficacia estimada de dos tipos de políticas en los primeros meses de la pandemia: medidas basadas en casos y medidas basadas en la población.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1682" end_char="1684">Los</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1686" end_char="1692">autores</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1694" end_char="1695">de</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1697" end_char="1698">la</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1700" end_char="1712">investigación</TOKEN>
<TOKEN id="token-13-5" pos="punct" morph="none" start_char="1713" end_char="1713">,</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1715" end_char="1725">procedentes</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1727" end_char="1728">de</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1730" end_char="1737">diversos</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1739" end_char="1748">institutos</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1750" end_char="1751">de</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1753" end_char="1757">salud</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1759" end_char="1759">y</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1761" end_char="1770">hospitales</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1772" end_char="1773">de</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1775" end_char="1780">Taiwán</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1782" end_char="1782">y</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1784" end_char="1790">Estados</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1792" end_char="1797">Unidos</TOKEN>
<TOKEN id="token-13-19" pos="punct" morph="none" start_char="1798" end_char="1798">,</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1800" end_char="1809">compararon</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="1811" end_char="1812">la</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="1814" end_char="1821">eficacia</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="1823" end_char="1830">estimada</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="1832" end_char="1833">de</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="1835" end_char="1837">dos</TOKEN>
<TOKEN id="token-13-26" pos="word" morph="none" start_char="1839" end_char="1843">tipos</TOKEN>
<TOKEN id="token-13-27" pos="word" morph="none" start_char="1845" end_char="1846">de</TOKEN>
<TOKEN id="token-13-28" pos="word" morph="none" start_char="1848" end_char="1856">políticas</TOKEN>
<TOKEN id="token-13-29" pos="word" morph="none" start_char="1858" end_char="1859">en</TOKEN>
<TOKEN id="token-13-30" pos="word" morph="none" start_char="1861" end_char="1863">los</TOKEN>
<TOKEN id="token-13-31" pos="word" morph="none" start_char="1865" end_char="1872">primeros</TOKEN>
<TOKEN id="token-13-32" pos="word" morph="none" start_char="1874" end_char="1878">meses</TOKEN>
<TOKEN id="token-13-33" pos="word" morph="none" start_char="1880" end_char="1881">de</TOKEN>
<TOKEN id="token-13-34" pos="word" morph="none" start_char="1883" end_char="1884">la</TOKEN>
<TOKEN id="token-13-35" pos="word" morph="none" start_char="1886" end_char="1893">pandemia</TOKEN>
<TOKEN id="token-13-36" pos="punct" morph="none" start_char="1894" end_char="1894">:</TOKEN>
<TOKEN id="token-13-37" pos="word" morph="none" start_char="1896" end_char="1902">medidas</TOKEN>
<TOKEN id="token-13-38" pos="word" morph="none" start_char="1904" end_char="1910">basadas</TOKEN>
<TOKEN id="token-13-39" pos="word" morph="none" start_char="1912" end_char="1913">en</TOKEN>
<TOKEN id="token-13-40" pos="word" morph="none" start_char="1915" end_char="1919">casos</TOKEN>
<TOKEN id="token-13-41" pos="word" morph="none" start_char="1921" end_char="1921">y</TOKEN>
<TOKEN id="token-13-42" pos="word" morph="none" start_char="1923" end_char="1929">medidas</TOKEN>
<TOKEN id="token-13-43" pos="word" morph="none" start_char="1931" end_char="1937">basadas</TOKEN>
<TOKEN id="token-13-44" pos="word" morph="none" start_char="1939" end_char="1940">en</TOKEN>
<TOKEN id="token-13-45" pos="word" morph="none" start_char="1942" end_char="1943">la</TOKEN>
<TOKEN id="token-13-46" pos="word" morph="none" start_char="1945" end_char="1953">población</TOKEN>
<TOKEN id="token-13-47" pos="punct" morph="none" start_char="1954" end_char="1954">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1957" end_char="2244">
<ORIGINAL_TEXT>Cuando llegaron las primeras noticias sobre un virus no identificado en la ciudad china de Wuhan y los informes no confirmados de pacientes que tenían que aislarse, Taiwán activó su Centro de Comando Central de Epidemias que coordina diferentes ministerios en caso de emergencia (REUTERS)</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1957" end_char="1962">Cuando</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1964" end_char="1971">llegaron</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1973" end_char="1975">las</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1977" end_char="1984">primeras</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1986" end_char="1993">noticias</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1995" end_char="1999">sobre</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="2001" end_char="2002">un</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="2004" end_char="2008">virus</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="2010" end_char="2011">no</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="2013" end_char="2024">identificado</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="2026" end_char="2027">en</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="2029" end_char="2030">la</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="2032" end_char="2037">ciudad</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="2039" end_char="2043">china</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="2045" end_char="2046">de</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="2048" end_char="2052">Wuhan</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="2054" end_char="2054">y</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="2056" end_char="2058">los</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="2060" end_char="2067">informes</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="2069" end_char="2070">no</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="2072" end_char="2082">confirmados</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="2084" end_char="2085">de</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="2087" end_char="2095">pacientes</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="2097" end_char="2099">que</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="2101" end_char="2106">tenían</TOKEN>
<TOKEN id="token-14-25" pos="word" morph="none" start_char="2108" end_char="2110">que</TOKEN>
<TOKEN id="token-14-26" pos="word" morph="none" start_char="2112" end_char="2119">aislarse</TOKEN>
<TOKEN id="token-14-27" pos="punct" morph="none" start_char="2120" end_char="2120">,</TOKEN>
<TOKEN id="token-14-28" pos="word" morph="none" start_char="2122" end_char="2127">Taiwán</TOKEN>
<TOKEN id="token-14-29" pos="word" morph="none" start_char="2129" end_char="2134">activó</TOKEN>
<TOKEN id="token-14-30" pos="word" morph="none" start_char="2136" end_char="2137">su</TOKEN>
<TOKEN id="token-14-31" pos="word" morph="none" start_char="2139" end_char="2144">Centro</TOKEN>
<TOKEN id="token-14-32" pos="word" morph="none" start_char="2146" end_char="2147">de</TOKEN>
<TOKEN id="token-14-33" pos="word" morph="none" start_char="2149" end_char="2155">Comando</TOKEN>
<TOKEN id="token-14-34" pos="word" morph="none" start_char="2157" end_char="2163">Central</TOKEN>
<TOKEN id="token-14-35" pos="word" morph="none" start_char="2165" end_char="2166">de</TOKEN>
<TOKEN id="token-14-36" pos="word" morph="none" start_char="2168" end_char="2176">Epidemias</TOKEN>
<TOKEN id="token-14-37" pos="word" morph="none" start_char="2178" end_char="2180">que</TOKEN>
<TOKEN id="token-14-38" pos="word" morph="none" start_char="2182" end_char="2189">coordina</TOKEN>
<TOKEN id="token-14-39" pos="word" morph="none" start_char="2191" end_char="2200">diferentes</TOKEN>
<TOKEN id="token-14-40" pos="word" morph="none" start_char="2202" end_char="2212">ministerios</TOKEN>
<TOKEN id="token-14-41" pos="word" morph="none" start_char="2214" end_char="2215">en</TOKEN>
<TOKEN id="token-14-42" pos="word" morph="none" start_char="2217" end_char="2220">caso</TOKEN>
<TOKEN id="token-14-43" pos="word" morph="none" start_char="2222" end_char="2223">de</TOKEN>
<TOKEN id="token-14-44" pos="word" morph="none" start_char="2225" end_char="2234">emergencia</TOKEN>
<TOKEN id="token-14-45" pos="punct" morph="none" start_char="2236" end_char="2236">(</TOKEN>
<TOKEN id="token-14-46" pos="word" morph="none" start_char="2237" end_char="2243">REUTERS</TOKEN>
<TOKEN id="token-14-47" pos="punct" morph="none" start_char="2244" end_char="2244">)</TOKEN>
</SEG>
<SEG id="segment-15" start_char="2248" end_char="2439">
<ORIGINAL_TEXT>Las primeras incluyen la detección de personas infectadas mediante pruebas, el aislamiento de los casos positivos, el rastreo de contactos y la cuarentena de 14 días de los contactos cercanos.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="2248" end_char="2250">Las</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="2252" end_char="2259">primeras</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="2261" end_char="2268">incluyen</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="2270" end_char="2271">la</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="2273" end_char="2281">detección</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="2283" end_char="2284">de</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="2286" end_char="2293">personas</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="2295" end_char="2304">infectadas</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="2306" end_char="2313">mediante</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="2315" end_char="2321">pruebas</TOKEN>
<TOKEN id="token-15-10" pos="punct" morph="none" start_char="2322" end_char="2322">,</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="2324" end_char="2325">el</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="2327" end_char="2337">aislamiento</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="2339" end_char="2340">de</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="2342" end_char="2344">los</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="2346" end_char="2350">casos</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="2352" end_char="2360">positivos</TOKEN>
<TOKEN id="token-15-17" pos="punct" morph="none" start_char="2361" end_char="2361">,</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="2363" end_char="2364">el</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="2366" end_char="2372">rastreo</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="2374" end_char="2375">de</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="2377" end_char="2385">contactos</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="2387" end_char="2387">y</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="2389" end_char="2390">la</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="2392" end_char="2401">cuarentena</TOKEN>
<TOKEN id="token-15-25" pos="word" morph="none" start_char="2403" end_char="2404">de</TOKEN>
<TOKEN id="token-15-26" pos="word" morph="none" start_char="2406" end_char="2407">14</TOKEN>
<TOKEN id="token-15-27" pos="word" morph="none" start_char="2409" end_char="2412">días</TOKEN>
<TOKEN id="token-15-28" pos="word" morph="none" start_char="2414" end_char="2415">de</TOKEN>
<TOKEN id="token-15-29" pos="word" morph="none" start_char="2417" end_char="2419">los</TOKEN>
<TOKEN id="token-15-30" pos="word" morph="none" start_char="2421" end_char="2429">contactos</TOKEN>
<TOKEN id="token-15-31" pos="word" morph="none" start_char="2431" end_char="2438">cercanos</TOKEN>
<TOKEN id="token-15-32" pos="punct" morph="none" start_char="2439" end_char="2439">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="2441" end_char="2525">
<ORIGINAL_TEXT>Y las segundas incluían uso de mascarilla, higiene personal y distanciamiento social.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="2441" end_char="2441">Y</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="2443" end_char="2445">las</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="2447" end_char="2454">segundas</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="2456" end_char="2463">incluían</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="2465" end_char="2467">uso</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="2469" end_char="2470">de</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="2472" end_char="2481">mascarilla</TOKEN>
<TOKEN id="token-16-7" pos="punct" morph="none" start_char="2482" end_char="2482">,</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="2484" end_char="2490">higiene</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="2492" end_char="2499">personal</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="2501" end_char="2501">y</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="2503" end_char="2517">distanciamiento</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="2519" end_char="2524">social</TOKEN>
<TOKEN id="token-16-13" pos="punct" morph="none" start_char="2525" end_char="2525">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2528" end_char="2724">
<ORIGINAL_TEXT>Los efectos de estas medidas se cuantificaron mediante la estimación del número efectivo de reproducción (número R), una forma de calificar la capacidad de propagación de una enfermedad infecciosa.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2528" end_char="2530">Los</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2532" end_char="2538">efectos</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2540" end_char="2541">de</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2543" end_char="2547">estas</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2549" end_char="2555">medidas</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2557" end_char="2558">se</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2560" end_char="2572">cuantificaron</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2574" end_char="2581">mediante</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2583" end_char="2584">la</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2586" end_char="2595">estimación</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2597" end_char="2599">del</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2601" end_char="2606">número</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2608" end_char="2615">efectivo</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2617" end_char="2618">de</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2620" end_char="2631">reproducción</TOKEN>
<TOKEN id="token-17-15" pos="punct" morph="none" start_char="2633" end_char="2633">(</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="2634" end_char="2639">número</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="2641" end_char="2641">R</TOKEN>
<TOKEN id="token-17-18" pos="punct" morph="none" start_char="2642" end_char="2643">),</TOKEN>
<TOKEN id="token-17-19" pos="word" morph="none" start_char="2645" end_char="2647">una</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="2649" end_char="2653">forma</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="2655" end_char="2656">de</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="2658" end_char="2666">calificar</TOKEN>
<TOKEN id="token-17-23" pos="word" morph="none" start_char="2668" end_char="2669">la</TOKEN>
<TOKEN id="token-17-24" pos="word" morph="none" start_char="2671" end_char="2679">capacidad</TOKEN>
<TOKEN id="token-17-25" pos="word" morph="none" start_char="2681" end_char="2682">de</TOKEN>
<TOKEN id="token-17-26" pos="word" morph="none" start_char="2684" end_char="2694">propagación</TOKEN>
<TOKEN id="token-17-27" pos="word" morph="none" start_char="2696" end_char="2697">de</TOKEN>
<TOKEN id="token-17-28" pos="word" morph="none" start_char="2699" end_char="2701">una</TOKEN>
<TOKEN id="token-17-29" pos="word" morph="none" start_char="2703" end_char="2712">enfermedad</TOKEN>
<TOKEN id="token-17-30" pos="word" morph="none" start_char="2714" end_char="2723">infecciosa</TOKEN>
<TOKEN id="token-17-31" pos="punct" morph="none" start_char="2724" end_char="2724">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2726" end_char="2819">
<ORIGINAL_TEXT>Un número R superior a 1 significa que el virus seguirá propagándose y los brotes continuarán.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2726" end_char="2727">Un</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2729" end_char="2734">número</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2736" end_char="2736">R</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2738" end_char="2745">superior</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2747" end_char="2747">a</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2749" end_char="2749">1</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2751" end_char="2759">significa</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2761" end_char="2763">que</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2765" end_char="2766">el</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="2768" end_char="2772">virus</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="2774" end_char="2780">seguirá</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="2782" end_char="2793">propagándose</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2795" end_char="2795">y</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="2797" end_char="2799">los</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="2801" end_char="2806">brotes</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="2808" end_char="2818">continuarán</TOKEN>
<TOKEN id="token-18-16" pos="punct" morph="none" start_char="2819" end_char="2819">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2821" end_char="2899">
<ORIGINAL_TEXT>Un número R inferior a 1 significa que el número de casos empezará a reducirse.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2821" end_char="2822">Un</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2824" end_char="2829">número</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2831" end_char="2831">R</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2833" end_char="2840">inferior</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2842" end_char="2842">a</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2844" end_char="2844">1</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2846" end_char="2854">significa</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2856" end_char="2858">que</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2860" end_char="2861">el</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="2863" end_char="2868">número</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="2870" end_char="2871">de</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="2873" end_char="2877">casos</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="2879" end_char="2886">empezará</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="2888" end_char="2888">a</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="2890" end_char="2898">reducirse</TOKEN>
<TOKEN id="token-19-15" pos="punct" morph="none" start_char="2899" end_char="2899">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2902" end_char="3099">
<ORIGINAL_TEXT>Mientras que los estudios anteriores en otros países han simulado escenarios hipotéticos, este trabajo combinó la modelización de la transmisión con datos reales detallados para estimar la eficacia.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2902" end_char="2909">Mientras</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2911" end_char="2913">que</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2915" end_char="2917">los</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2919" end_char="2926">estudios</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2928" end_char="2937">anteriores</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2939" end_char="2940">en</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2942" end_char="2946">otros</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2948" end_char="2953">países</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="2955" end_char="2957">han</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2959" end_char="2966">simulado</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2968" end_char="2977">escenarios</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="2979" end_char="2989">hipotéticos</TOKEN>
<TOKEN id="token-20-12" pos="punct" morph="none" start_char="2990" end_char="2990">,</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="2992" end_char="2995">este</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="2997" end_char="3003">trabajo</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="3005" end_char="3011">combinó</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="3013" end_char="3014">la</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="3016" end_char="3027">modelización</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="3029" end_char="3030">de</TOKEN>
<TOKEN id="token-20-19" pos="word" morph="none" start_char="3032" end_char="3033">la</TOKEN>
<TOKEN id="token-20-20" pos="word" morph="none" start_char="3035" end_char="3045">transmisión</TOKEN>
<TOKEN id="token-20-21" pos="word" morph="none" start_char="3047" end_char="3049">con</TOKEN>
<TOKEN id="token-20-22" pos="word" morph="none" start_char="3051" end_char="3055">datos</TOKEN>
<TOKEN id="token-20-23" pos="word" morph="none" start_char="3057" end_char="3062">reales</TOKEN>
<TOKEN id="token-20-24" pos="word" morph="none" start_char="3064" end_char="3073">detallados</TOKEN>
<TOKEN id="token-20-25" pos="word" morph="none" start_char="3075" end_char="3078">para</TOKEN>
<TOKEN id="token-20-26" pos="word" morph="none" start_char="3080" end_char="3086">estimar</TOKEN>
<TOKEN id="token-20-27" pos="word" morph="none" start_char="3088" end_char="3089">la</TOKEN>
<TOKEN id="token-20-28" pos="word" morph="none" start_char="3091" end_char="3098">eficacia</TOKEN>
<TOKEN id="token-20-29" pos="punct" morph="none" start_char="3099" end_char="3099">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="3101" end_char="3243">
<ORIGINAL_TEXT>Los autores recopilaron datos sobre 158 casos entre el 10 de enero y el 1 de junio de 2020 de los Centros de Control de Enfermedades de Taiwán.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="3101" end_char="3103">Los</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="3105" end_char="3111">autores</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="3113" end_char="3123">recopilaron</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="3125" end_char="3129">datos</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="3131" end_char="3135">sobre</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="3137" end_char="3139">158</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="3141" end_char="3145">casos</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="3147" end_char="3151">entre</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="3153" end_char="3154">el</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="3156" end_char="3157">10</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="3159" end_char="3160">de</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="3162" end_char="3166">enero</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="3168" end_char="3168">y</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="3170" end_char="3171">el</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="3173" end_char="3173">1</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="3175" end_char="3176">de</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="3178" end_char="3182">junio</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="3184" end_char="3185">de</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="3187" end_char="3190">2020</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="3192" end_char="3193">de</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="3195" end_char="3197">los</TOKEN>
<TOKEN id="token-21-21" pos="word" morph="none" start_char="3199" end_char="3205">Centros</TOKEN>
<TOKEN id="token-21-22" pos="word" morph="none" start_char="3207" end_char="3208">de</TOKEN>
<TOKEN id="token-21-23" pos="word" morph="none" start_char="3210" end_char="3216">Control</TOKEN>
<TOKEN id="token-21-24" pos="word" morph="none" start_char="3218" end_char="3219">de</TOKEN>
<TOKEN id="token-21-25" pos="word" morph="none" start_char="3221" end_char="3232">Enfermedades</TOKEN>
<TOKEN id="token-21-26" pos="word" morph="none" start_char="3234" end_char="3235">de</TOKEN>
<TOKEN id="token-21-27" pos="word" morph="none" start_char="3237" end_char="3242">Taiwán</TOKEN>
<TOKEN id="token-21-28" pos="punct" morph="none" start_char="3243" end_char="3243">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="3245" end_char="3449">
<ORIGINAL_TEXT>Todos los casos se confirmaron mediante pruebas de PCR. Los datos se referían a infecciones locales, a grupos confirmados y a casos importados de personas que entraron en Taiwán antes del 21 de marzo 2020.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="3245" end_char="3249">Todos</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="3251" end_char="3253">los</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="3255" end_char="3259">casos</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="3261" end_char="3262">se</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="3264" end_char="3274">confirmaron</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="3276" end_char="3283">mediante</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="3285" end_char="3291">pruebas</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="3293" end_char="3294">de</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="3296" end_char="3298">PCR</TOKEN>
<TOKEN id="token-22-9" pos="punct" morph="none" start_char="3299" end_char="3299">.</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="3301" end_char="3303">Los</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="3305" end_char="3309">datos</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="3311" end_char="3312">se</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="3314" end_char="3321">referían</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="3323" end_char="3323">a</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="3325" end_char="3335">infecciones</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="3337" end_char="3343">locales</TOKEN>
<TOKEN id="token-22-17" pos="punct" morph="none" start_char="3344" end_char="3344">,</TOKEN>
<TOKEN id="token-22-18" pos="word" morph="none" start_char="3346" end_char="3346">a</TOKEN>
<TOKEN id="token-22-19" pos="word" morph="none" start_char="3348" end_char="3353">grupos</TOKEN>
<TOKEN id="token-22-20" pos="word" morph="none" start_char="3355" end_char="3365">confirmados</TOKEN>
<TOKEN id="token-22-21" pos="word" morph="none" start_char="3367" end_char="3367">y</TOKEN>
<TOKEN id="token-22-22" pos="word" morph="none" start_char="3369" end_char="3369">a</TOKEN>
<TOKEN id="token-22-23" pos="word" morph="none" start_char="3371" end_char="3375">casos</TOKEN>
<TOKEN id="token-22-24" pos="word" morph="none" start_char="3377" end_char="3386">importados</TOKEN>
<TOKEN id="token-22-25" pos="word" morph="none" start_char="3388" end_char="3389">de</TOKEN>
<TOKEN id="token-22-26" pos="word" morph="none" start_char="3391" end_char="3398">personas</TOKEN>
<TOKEN id="token-22-27" pos="word" morph="none" start_char="3400" end_char="3402">que</TOKEN>
<TOKEN id="token-22-28" pos="word" morph="none" start_char="3404" end_char="3411">entraron</TOKEN>
<TOKEN id="token-22-29" pos="word" morph="none" start_char="3413" end_char="3414">en</TOKEN>
<TOKEN id="token-22-30" pos="word" morph="none" start_char="3416" end_char="3421">Taiwán</TOKEN>
<TOKEN id="token-22-31" pos="word" morph="none" start_char="3423" end_char="3427">antes</TOKEN>
<TOKEN id="token-22-32" pos="word" morph="none" start_char="3429" end_char="3431">del</TOKEN>
<TOKEN id="token-22-33" pos="word" morph="none" start_char="3433" end_char="3434">21</TOKEN>
<TOKEN id="token-22-34" pos="word" morph="none" start_char="3436" end_char="3437">de</TOKEN>
<TOKEN id="token-22-35" pos="word" morph="none" start_char="3439" end_char="3443">marzo</TOKEN>
<TOKEN id="token-22-36" pos="word" morph="none" start_char="3445" end_char="3448">2020</TOKEN>
<TOKEN id="token-22-37" pos="punct" morph="none" start_char="3449" end_char="3449">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="3452" end_char="3632">
<ORIGINAL_TEXT>A continuación, compararon los resultados que encontraron en Taiwán con un R de 2,5, basado en el número equivalente estimado en la vecina China al comienzo de su brote de COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="3452" end_char="3452">A</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="3454" end_char="3465">continuación</TOKEN>
<TOKEN id="token-23-2" pos="punct" morph="none" start_char="3466" end_char="3466">,</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="3468" end_char="3477">compararon</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="3479" end_char="3481">los</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="3483" end_char="3492">resultados</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="3494" end_char="3496">que</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="3498" end_char="3508">encontraron</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="3510" end_char="3511">en</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="3513" end_char="3518">Taiwán</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="3520" end_char="3522">con</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="3524" end_char="3525">un</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="3527" end_char="3527">R</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="3529" end_char="3530">de</TOKEN>
<TOKEN id="token-23-14" pos="unknown" morph="none" start_char="3532" end_char="3534">2,5</TOKEN>
<TOKEN id="token-23-15" pos="punct" morph="none" start_char="3535" end_char="3535">,</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="3537" end_char="3542">basado</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="3544" end_char="3545">en</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="3547" end_char="3548">el</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="3550" end_char="3555">número</TOKEN>
<TOKEN id="token-23-20" pos="word" morph="none" start_char="3557" end_char="3567">equivalente</TOKEN>
<TOKEN id="token-23-21" pos="word" morph="none" start_char="3569" end_char="3576">estimado</TOKEN>
<TOKEN id="token-23-22" pos="word" morph="none" start_char="3578" end_char="3579">en</TOKEN>
<TOKEN id="token-23-23" pos="word" morph="none" start_char="3581" end_char="3582">la</TOKEN>
<TOKEN id="token-23-24" pos="word" morph="none" start_char="3584" end_char="3589">vecina</TOKEN>
<TOKEN id="token-23-25" pos="word" morph="none" start_char="3591" end_char="3595">China</TOKEN>
<TOKEN id="token-23-26" pos="word" morph="none" start_char="3597" end_char="3598">al</TOKEN>
<TOKEN id="token-23-27" pos="word" morph="none" start_char="3600" end_char="3607">comienzo</TOKEN>
<TOKEN id="token-23-28" pos="word" morph="none" start_char="3609" end_char="3610">de</TOKEN>
<TOKEN id="token-23-29" pos="word" morph="none" start_char="3612" end_char="3613">su</TOKEN>
<TOKEN id="token-23-30" pos="word" morph="none" start_char="3615" end_char="3619">brote</TOKEN>
<TOKEN id="token-23-31" pos="word" morph="none" start_char="3621" end_char="3622">de</TOKEN>
<TOKEN id="token-23-32" pos="unknown" morph="none" start_char="3624" end_char="3631">COVID-19</TOKEN>
<TOKEN id="token-23-33" pos="punct" morph="none" start_char="3632" end_char="3632">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="3634" end_char="3790">
<ORIGINAL_TEXT>El estudio descubrió que las políticas basadas en casos por sí solas, como el rastreo de contactos y la cuarentena, podían reducir el número R de 2,5 a 1,53.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="3634" end_char="3635">El</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="3637" end_char="3643">estudio</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="3645" end_char="3653">descubrió</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="3655" end_char="3657">que</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="3659" end_char="3661">las</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="3663" end_char="3671">políticas</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="3673" end_char="3679">basadas</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="3681" end_char="3682">en</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="3684" end_char="3688">casos</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="3690" end_char="3692">por</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="3694" end_char="3695">sí</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="3697" end_char="3701">solas</TOKEN>
<TOKEN id="token-24-12" pos="punct" morph="none" start_char="3702" end_char="3702">,</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="3704" end_char="3707">como</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="3709" end_char="3710">el</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="3712" end_char="3718">rastreo</TOKEN>
<TOKEN id="token-24-16" pos="word" morph="none" start_char="3720" end_char="3721">de</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="3723" end_char="3731">contactos</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="3733" end_char="3733">y</TOKEN>
<TOKEN id="token-24-19" pos="word" morph="none" start_char="3735" end_char="3736">la</TOKEN>
<TOKEN id="token-24-20" pos="word" morph="none" start_char="3738" end_char="3747">cuarentena</TOKEN>
<TOKEN id="token-24-21" pos="punct" morph="none" start_char="3748" end_char="3748">,</TOKEN>
<TOKEN id="token-24-22" pos="word" morph="none" start_char="3750" end_char="3755">podían</TOKEN>
<TOKEN id="token-24-23" pos="word" morph="none" start_char="3757" end_char="3763">reducir</TOKEN>
<TOKEN id="token-24-24" pos="word" morph="none" start_char="3765" end_char="3766">el</TOKEN>
<TOKEN id="token-24-25" pos="word" morph="none" start_char="3768" end_char="3773">número</TOKEN>
<TOKEN id="token-24-26" pos="word" morph="none" start_char="3775" end_char="3775">R</TOKEN>
<TOKEN id="token-24-27" pos="word" morph="none" start_char="3777" end_char="3778">de</TOKEN>
<TOKEN id="token-24-28" pos="unknown" morph="none" start_char="3780" end_char="3782">2,5</TOKEN>
<TOKEN id="token-24-29" pos="word" morph="none" start_char="3784" end_char="3784">a</TOKEN>
<TOKEN id="token-24-30" pos="unknown" morph="none" start_char="3786" end_char="3789">1,53</TOKEN>
<TOKEN id="token-24-31" pos="punct" morph="none" start_char="3790" end_char="3790">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="3792" end_char="3856">
<ORIGINAL_TEXT>El confinamiento fue el que más contribuyó a reducir el número R.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="3792" end_char="3793">El</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="3795" end_char="3807">confinamiento</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="3809" end_char="3811">fue</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="3813" end_char="3814">el</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="3816" end_char="3818">que</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="3820" end_char="3822">más</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="3824" end_char="3833">contribuyó</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="3835" end_char="3835">a</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="3837" end_char="3843">reducir</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="3845" end_char="3846">el</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="3848" end_char="3853">número</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="3855" end_char="3855">R</TOKEN>
<TOKEN id="token-25-12" pos="punct" morph="none" start_char="3856" end_char="3856">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="3859" end_char="4107">
<ORIGINAL_TEXT>Las intervenciones basadas en casos no pudieron prevenir sustancialmente la transmisión de una persona a otra, pero sí lograron reducir la transmisión posterior a una tercera o cuarta persona, siempre que esos contactos próximos hicieran cuarentena.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="3859" end_char="3861">Las</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="3863" end_char="3876">intervenciones</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="3878" end_char="3884">basadas</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="3886" end_char="3887">en</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="3889" end_char="3893">casos</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="3895" end_char="3896">no</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="3898" end_char="3905">pudieron</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="3907" end_char="3914">prevenir</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="3916" end_char="3930">sustancialmente</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="3932" end_char="3933">la</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="3935" end_char="3945">transmisión</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="3947" end_char="3948">de</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="3950" end_char="3952">una</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="3954" end_char="3960">persona</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="3962" end_char="3962">a</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="3964" end_char="3967">otra</TOKEN>
<TOKEN id="token-26-16" pos="punct" morph="none" start_char="3968" end_char="3968">,</TOKEN>
<TOKEN id="token-26-17" pos="word" morph="none" start_char="3970" end_char="3973">pero</TOKEN>
<TOKEN id="token-26-18" pos="word" morph="none" start_char="3975" end_char="3976">sí</TOKEN>
<TOKEN id="token-26-19" pos="word" morph="none" start_char="3978" end_char="3985">lograron</TOKEN>
<TOKEN id="token-26-20" pos="word" morph="none" start_char="3987" end_char="3993">reducir</TOKEN>
<TOKEN id="token-26-21" pos="word" morph="none" start_char="3995" end_char="3996">la</TOKEN>
<TOKEN id="token-26-22" pos="word" morph="none" start_char="3998" end_char="4008">transmisión</TOKEN>
<TOKEN id="token-26-23" pos="word" morph="none" start_char="4010" end_char="4018">posterior</TOKEN>
<TOKEN id="token-26-24" pos="word" morph="none" start_char="4020" end_char="4020">a</TOKEN>
<TOKEN id="token-26-25" pos="word" morph="none" start_char="4022" end_char="4024">una</TOKEN>
<TOKEN id="token-26-26" pos="word" morph="none" start_char="4026" end_char="4032">tercera</TOKEN>
<TOKEN id="token-26-27" pos="word" morph="none" start_char="4034" end_char="4034">o</TOKEN>
<TOKEN id="token-26-28" pos="word" morph="none" start_char="4036" end_char="4041">cuarta</TOKEN>
<TOKEN id="token-26-29" pos="word" morph="none" start_char="4043" end_char="4049">persona</TOKEN>
<TOKEN id="token-26-30" pos="punct" morph="none" start_char="4050" end_char="4050">,</TOKEN>
<TOKEN id="token-26-31" pos="word" morph="none" start_char="4052" end_char="4058">siempre</TOKEN>
<TOKEN id="token-26-32" pos="word" morph="none" start_char="4060" end_char="4062">que</TOKEN>
<TOKEN id="token-26-33" pos="word" morph="none" start_char="4064" end_char="4067">esos</TOKEN>
<TOKEN id="token-26-34" pos="word" morph="none" start_char="4069" end_char="4077">contactos</TOKEN>
<TOKEN id="token-26-35" pos="word" morph="none" start_char="4079" end_char="4086">próximos</TOKEN>
<TOKEN id="token-26-36" pos="word" morph="none" start_char="4088" end_char="4095">hicieran</TOKEN>
<TOKEN id="token-26-37" pos="word" morph="none" start_char="4097" end_char="4106">cuarentena</TOKEN>
<TOKEN id="token-26-38" pos="punct" morph="none" start_char="4107" end_char="4107">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="4109" end_char="4244">
<ORIGINAL_TEXT>Por su parte, las medidas basadas en la población, como el distanciamiento social y las mascarillas, redujeron el número R de 2,5 a 1,3.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="4109" end_char="4111">Por</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="4113" end_char="4114">su</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="4116" end_char="4120">parte</TOKEN>
<TOKEN id="token-27-3" pos="punct" morph="none" start_char="4121" end_char="4121">,</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="4123" end_char="4125">las</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="4127" end_char="4133">medidas</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="4135" end_char="4141">basadas</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="4143" end_char="4144">en</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="4146" end_char="4147">la</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="4149" end_char="4157">población</TOKEN>
<TOKEN id="token-27-10" pos="punct" morph="none" start_char="4158" end_char="4158">,</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="4160" end_char="4163">como</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="4165" end_char="4166">el</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="4168" end_char="4182">distanciamiento</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="4184" end_char="4189">social</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="4191" end_char="4191">y</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="4193" end_char="4195">las</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="4197" end_char="4207">mascarillas</TOKEN>
<TOKEN id="token-27-18" pos="punct" morph="none" start_char="4208" end_char="4208">,</TOKEN>
<TOKEN id="token-27-19" pos="word" morph="none" start_char="4210" end_char="4218">redujeron</TOKEN>
<TOKEN id="token-27-20" pos="word" morph="none" start_char="4220" end_char="4221">el</TOKEN>
<TOKEN id="token-27-21" pos="word" morph="none" start_char="4223" end_char="4228">número</TOKEN>
<TOKEN id="token-27-22" pos="word" morph="none" start_char="4230" end_char="4230">R</TOKEN>
<TOKEN id="token-27-23" pos="word" morph="none" start_char="4232" end_char="4233">de</TOKEN>
<TOKEN id="token-27-24" pos="unknown" morph="none" start_char="4235" end_char="4237">2,5</TOKEN>
<TOKEN id="token-27-25" pos="word" morph="none" start_char="4239" end_char="4239">a</TOKEN>
<TOKEN id="token-27-26" pos="unknown" morph="none" start_char="4241" end_char="4243">1,3</TOKEN>
<TOKEN id="token-27-27" pos="punct" morph="none" start_char="4244" end_char="4244">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="4248" end_char="4413">
<ORIGINAL_TEXT>Los autores concluyeron que la combinación de medidas basadas en casos y en la población fue lo que condujo al éxito de Taiwán en la contención del COVID-19 (REUTERS)</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="4248" end_char="4250">Los</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="4252" end_char="4258">autores</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="4260" end_char="4270">concluyeron</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="4272" end_char="4274">que</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="4276" end_char="4277">la</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="4279" end_char="4289">combinación</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="4291" end_char="4292">de</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="4294" end_char="4300">medidas</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="4302" end_char="4308">basadas</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="4310" end_char="4311">en</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="4313" end_char="4317">casos</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="4319" end_char="4319">y</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="4321" end_char="4322">en</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="4324" end_char="4325">la</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="4327" end_char="4335">población</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="4337" end_char="4339">fue</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="4341" end_char="4342">lo</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="4344" end_char="4346">que</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="4348" end_char="4354">condujo</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="4356" end_char="4357">al</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="4359" end_char="4363">éxito</TOKEN>
<TOKEN id="token-28-21" pos="word" morph="none" start_char="4365" end_char="4366">de</TOKEN>
<TOKEN id="token-28-22" pos="word" morph="none" start_char="4368" end_char="4373">Taiwán</TOKEN>
<TOKEN id="token-28-23" pos="word" morph="none" start_char="4375" end_char="4376">en</TOKEN>
<TOKEN id="token-28-24" pos="word" morph="none" start_char="4378" end_char="4379">la</TOKEN>
<TOKEN id="token-28-25" pos="word" morph="none" start_char="4381" end_char="4390">contención</TOKEN>
<TOKEN id="token-28-26" pos="word" morph="none" start_char="4392" end_char="4394">del</TOKEN>
<TOKEN id="token-28-27" pos="unknown" morph="none" start_char="4396" end_char="4403">COVID-19</TOKEN>
<TOKEN id="token-28-28" pos="punct" morph="none" start_char="4405" end_char="4405">(</TOKEN>
<TOKEN id="token-28-29" pos="word" morph="none" start_char="4406" end_char="4412">REUTERS</TOKEN>
<TOKEN id="token-28-30" pos="punct" morph="none" start_char="4413" end_char="4413">)</TOKEN>
</SEG>
<SEG id="segment-29" start_char="4416" end_char="4572">
<ORIGINAL_TEXT>Los autores concluyeron que la combinación de medidas basadas en casos y en la población fue lo que condujo al éxito de Taiwán en la contención del COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="4416" end_char="4418">Los</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="4420" end_char="4426">autores</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="4428" end_char="4438">concluyeron</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="4440" end_char="4442">que</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="4444" end_char="4445">la</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="4447" end_char="4457">combinación</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="4459" end_char="4460">de</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="4462" end_char="4468">medidas</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="4470" end_char="4476">basadas</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="4478" end_char="4479">en</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="4481" end_char="4485">casos</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="4487" end_char="4487">y</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="4489" end_char="4490">en</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="4492" end_char="4493">la</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="4495" end_char="4503">población</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="4505" end_char="4507">fue</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="4509" end_char="4510">lo</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="4512" end_char="4514">que</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="4516" end_char="4522">condujo</TOKEN>
<TOKEN id="token-29-19" pos="word" morph="none" start_char="4524" end_char="4525">al</TOKEN>
<TOKEN id="token-29-20" pos="word" morph="none" start_char="4527" end_char="4531">éxito</TOKEN>
<TOKEN id="token-29-21" pos="word" morph="none" start_char="4533" end_char="4534">de</TOKEN>
<TOKEN id="token-29-22" pos="word" morph="none" start_char="4536" end_char="4541">Taiwán</TOKEN>
<TOKEN id="token-29-23" pos="word" morph="none" start_char="4543" end_char="4544">en</TOKEN>
<TOKEN id="token-29-24" pos="word" morph="none" start_char="4546" end_char="4547">la</TOKEN>
<TOKEN id="token-29-25" pos="word" morph="none" start_char="4549" end_char="4558">contención</TOKEN>
<TOKEN id="token-29-26" pos="word" morph="none" start_char="4560" end_char="4562">del</TOKEN>
<TOKEN id="token-29-27" pos="unknown" morph="none" start_char="4564" end_char="4571">COVID-19</TOKEN>
<TOKEN id="token-29-28" pos="punct" morph="none" start_char="4572" end_char="4572">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="4574" end_char="4702">
<ORIGINAL_TEXT>La combinación de ambos enfoques condujo a un número R, estimado mediante dos métodos diferentes, de 0,82 y o incluso de un 0,62.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="4574" end_char="4575">La</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="4577" end_char="4587">combinación</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="4589" end_char="4590">de</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="4592" end_char="4596">ambos</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="4598" end_char="4605">enfoques</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="4607" end_char="4613">condujo</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="4615" end_char="4615">a</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="4617" end_char="4618">un</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="4620" end_char="4625">número</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="4627" end_char="4627">R</TOKEN>
<TOKEN id="token-30-10" pos="punct" morph="none" start_char="4628" end_char="4628">,</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="4630" end_char="4637">estimado</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="4639" end_char="4646">mediante</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="4648" end_char="4650">dos</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="4652" end_char="4658">métodos</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="4660" end_char="4669">diferentes</TOKEN>
<TOKEN id="token-30-16" pos="punct" morph="none" start_char="4670" end_char="4670">,</TOKEN>
<TOKEN id="token-30-17" pos="word" morph="none" start_char="4672" end_char="4673">de</TOKEN>
<TOKEN id="token-30-18" pos="unknown" morph="none" start_char="4675" end_char="4678">0,82</TOKEN>
<TOKEN id="token-30-19" pos="word" morph="none" start_char="4680" end_char="4680">y</TOKEN>
<TOKEN id="token-30-20" pos="word" morph="none" start_char="4682" end_char="4682">o</TOKEN>
<TOKEN id="token-30-21" pos="word" morph="none" start_char="4684" end_char="4690">incluso</TOKEN>
<TOKEN id="token-30-22" pos="word" morph="none" start_char="4692" end_char="4693">de</TOKEN>
<TOKEN id="token-30-23" pos="word" morph="none" start_char="4695" end_char="4696">un</TOKEN>
<TOKEN id="token-30-24" pos="unknown" morph="none" start_char="4698" end_char="4701">0,62</TOKEN>
<TOKEN id="token-30-25" pos="punct" morph="none" start_char="4702" end_char="4702">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="4704" end_char="4873">
<ORIGINAL_TEXT>También descubrieron que se necesitaban medidas basadas en la población contundentes para lograr la contención, aunque el número de infecciones circulantes fuera pequeño.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="4704" end_char="4710">También</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="4712" end_char="4723">descubrieron</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="4725" end_char="4727">que</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="4729" end_char="4730">se</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="4732" end_char="4742">necesitaban</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="4744" end_char="4750">medidas</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="4752" end_char="4758">basadas</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="4760" end_char="4761">en</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="4763" end_char="4764">la</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="4766" end_char="4774">población</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="4776" end_char="4787">contundentes</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="4789" end_char="4792">para</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="4794" end_char="4799">lograr</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="4801" end_char="4802">la</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="4804" end_char="4813">contención</TOKEN>
<TOKEN id="token-31-15" pos="punct" morph="none" start_char="4814" end_char="4814">,</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="4816" end_char="4821">aunque</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="4823" end_char="4824">el</TOKEN>
<TOKEN id="token-31-18" pos="word" morph="none" start_char="4826" end_char="4831">número</TOKEN>
<TOKEN id="token-31-19" pos="word" morph="none" start_char="4833" end_char="4834">de</TOKEN>
<TOKEN id="token-31-20" pos="word" morph="none" start_char="4836" end_char="4846">infecciones</TOKEN>
<TOKEN id="token-31-21" pos="word" morph="none" start_char="4848" end_char="4858">circulantes</TOKEN>
<TOKEN id="token-31-22" pos="word" morph="none" start_char="4860" end_char="4864">fuera</TOKEN>
<TOKEN id="token-31-23" pos="word" morph="none" start_char="4866" end_char="4872">pequeño</TOKEN>
<TOKEN id="token-31-24" pos="punct" morph="none" start_char="4873" end_char="4873">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="4875" end_char="5045">
<ORIGINAL_TEXT>Ninguno de los dos enfoques habría sido suficiente por sí solo, incluso en un país con un sistema de salud pública eficaz y un sofisticado sistema de rastreo de contactos.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="4875" end_char="4881">Ninguno</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="4883" end_char="4884">de</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="4886" end_char="4888">los</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="4890" end_char="4892">dos</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="4894" end_char="4901">enfoques</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="4903" end_char="4908">habría</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="4910" end_char="4913">sido</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="4915" end_char="4924">suficiente</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="4926" end_char="4928">por</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="4930" end_char="4931">sí</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="4933" end_char="4936">solo</TOKEN>
<TOKEN id="token-32-11" pos="punct" morph="none" start_char="4937" end_char="4937">,</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="4939" end_char="4945">incluso</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="4947" end_char="4948">en</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="4950" end_char="4951">un</TOKEN>
<TOKEN id="token-32-15" pos="word" morph="none" start_char="4953" end_char="4956">país</TOKEN>
<TOKEN id="token-32-16" pos="word" morph="none" start_char="4958" end_char="4960">con</TOKEN>
<TOKEN id="token-32-17" pos="word" morph="none" start_char="4962" end_char="4963">un</TOKEN>
<TOKEN id="token-32-18" pos="word" morph="none" start_char="4965" end_char="4971">sistema</TOKEN>
<TOKEN id="token-32-19" pos="word" morph="none" start_char="4973" end_char="4974">de</TOKEN>
<TOKEN id="token-32-20" pos="word" morph="none" start_char="4976" end_char="4980">salud</TOKEN>
<TOKEN id="token-32-21" pos="word" morph="none" start_char="4982" end_char="4988">pública</TOKEN>
<TOKEN id="token-32-22" pos="word" morph="none" start_char="4990" end_char="4995">eficaz</TOKEN>
<TOKEN id="token-32-23" pos="word" morph="none" start_char="4997" end_char="4997">y</TOKEN>
<TOKEN id="token-32-24" pos="word" morph="none" start_char="4999" end_char="5000">un</TOKEN>
<TOKEN id="token-32-25" pos="word" morph="none" start_char="5002" end_char="5012">sofisticado</TOKEN>
<TOKEN id="token-32-26" pos="word" morph="none" start_char="5014" end_char="5020">sistema</TOKEN>
<TOKEN id="token-32-27" pos="word" morph="none" start_char="5022" end_char="5023">de</TOKEN>
<TOKEN id="token-32-28" pos="word" morph="none" start_char="5025" end_char="5031">rastreo</TOKEN>
<TOKEN id="token-32-29" pos="word" morph="none" start_char="5033" end_char="5034">de</TOKEN>
<TOKEN id="token-32-30" pos="word" morph="none" start_char="5036" end_char="5044">contactos</TOKEN>
<TOKEN id="token-32-31" pos="punct" morph="none" start_char="5045" end_char="5045">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="5048" end_char="5348">
<ORIGINAL_TEXT>Reconociendo que todos los modelos hacen suposiciones, y este análisis no es diferente, el documento confirma que todo el conjunto de medidas de salud pública que hemos estado utilizando de forma bastante consistente en todo el mundo –en diferentes grados de temporalidad y rigor– han sido necesarias.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="5048" end_char="5059">Reconociendo</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="5061" end_char="5063">que</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="5065" end_char="5069">todos</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="5071" end_char="5073">los</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="5075" end_char="5081">modelos</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="5083" end_char="5087">hacen</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="5089" end_char="5100">suposiciones</TOKEN>
<TOKEN id="token-33-7" pos="punct" morph="none" start_char="5101" end_char="5101">,</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="5103" end_char="5103">y</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="5105" end_char="5108">este</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="5110" end_char="5117">análisis</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="5119" end_char="5120">no</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="5122" end_char="5123">es</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="5125" end_char="5133">diferente</TOKEN>
<TOKEN id="token-33-14" pos="punct" morph="none" start_char="5134" end_char="5134">,</TOKEN>
<TOKEN id="token-33-15" pos="word" morph="none" start_char="5136" end_char="5137">el</TOKEN>
<TOKEN id="token-33-16" pos="word" morph="none" start_char="5139" end_char="5147">documento</TOKEN>
<TOKEN id="token-33-17" pos="word" morph="none" start_char="5149" end_char="5156">confirma</TOKEN>
<TOKEN id="token-33-18" pos="word" morph="none" start_char="5158" end_char="5160">que</TOKEN>
<TOKEN id="token-33-19" pos="word" morph="none" start_char="5162" end_char="5165">todo</TOKEN>
<TOKEN id="token-33-20" pos="word" morph="none" start_char="5167" end_char="5168">el</TOKEN>
<TOKEN id="token-33-21" pos="word" morph="none" start_char="5170" end_char="5177">conjunto</TOKEN>
<TOKEN id="token-33-22" pos="word" morph="none" start_char="5179" end_char="5180">de</TOKEN>
<TOKEN id="token-33-23" pos="word" morph="none" start_char="5182" end_char="5188">medidas</TOKEN>
<TOKEN id="token-33-24" pos="word" morph="none" start_char="5190" end_char="5191">de</TOKEN>
<TOKEN id="token-33-25" pos="word" morph="none" start_char="5193" end_char="5197">salud</TOKEN>
<TOKEN id="token-33-26" pos="word" morph="none" start_char="5199" end_char="5205">pública</TOKEN>
<TOKEN id="token-33-27" pos="word" morph="none" start_char="5207" end_char="5209">que</TOKEN>
<TOKEN id="token-33-28" pos="word" morph="none" start_char="5211" end_char="5215">hemos</TOKEN>
<TOKEN id="token-33-29" pos="word" morph="none" start_char="5217" end_char="5222">estado</TOKEN>
<TOKEN id="token-33-30" pos="word" morph="none" start_char="5224" end_char="5233">utilizando</TOKEN>
<TOKEN id="token-33-31" pos="word" morph="none" start_char="5235" end_char="5236">de</TOKEN>
<TOKEN id="token-33-32" pos="word" morph="none" start_char="5238" end_char="5242">forma</TOKEN>
<TOKEN id="token-33-33" pos="word" morph="none" start_char="5244" end_char="5251">bastante</TOKEN>
<TOKEN id="token-33-34" pos="word" morph="none" start_char="5253" end_char="5263">consistente</TOKEN>
<TOKEN id="token-33-35" pos="word" morph="none" start_char="5265" end_char="5266">en</TOKEN>
<TOKEN id="token-33-36" pos="word" morph="none" start_char="5268" end_char="5271">todo</TOKEN>
<TOKEN id="token-33-37" pos="word" morph="none" start_char="5273" end_char="5274">el</TOKEN>
<TOKEN id="token-33-38" pos="word" morph="none" start_char="5276" end_char="5280">mundo</TOKEN>
<TOKEN id="token-33-39" pos="punct" morph="none" start_char="5282" end_char="5282">–</TOKEN>
<TOKEN id="token-33-40" pos="word" morph="none" start_char="5283" end_char="5284">en</TOKEN>
<TOKEN id="token-33-41" pos="word" morph="none" start_char="5286" end_char="5295">diferentes</TOKEN>
<TOKEN id="token-33-42" pos="word" morph="none" start_char="5297" end_char="5302">grados</TOKEN>
<TOKEN id="token-33-43" pos="word" morph="none" start_char="5304" end_char="5305">de</TOKEN>
<TOKEN id="token-33-44" pos="word" morph="none" start_char="5307" end_char="5318">temporalidad</TOKEN>
<TOKEN id="token-33-45" pos="word" morph="none" start_char="5320" end_char="5320">y</TOKEN>
<TOKEN id="token-33-46" pos="word" morph="none" start_char="5322" end_char="5326">rigor</TOKEN>
<TOKEN id="token-33-47" pos="punct" morph="none" start_char="5327" end_char="5327">–</TOKEN>
<TOKEN id="token-33-48" pos="word" morph="none" start_char="5329" end_char="5331">han</TOKEN>
<TOKEN id="token-33-49" pos="word" morph="none" start_char="5333" end_char="5336">sido</TOKEN>
<TOKEN id="token-33-50" pos="word" morph="none" start_char="5338" end_char="5347">necesarias</TOKEN>
<TOKEN id="token-33-51" pos="punct" morph="none" start_char="5348" end_char="5348">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="5350" end_char="5505">
<ORIGINAL_TEXT>Sin embargo, cabe destacar que los resultados del estudio reflejan un periodo en el que las nuevas variantes con mayor transmisibilidad no eran un problema.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="5350" end_char="5352">Sin</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="5354" end_char="5360">embargo</TOKEN>
<TOKEN id="token-34-2" pos="punct" morph="none" start_char="5361" end_char="5361">,</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="5363" end_char="5366">cabe</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="5368" end_char="5375">destacar</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="5377" end_char="5379">que</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="5381" end_char="5383">los</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="5385" end_char="5394">resultados</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="5396" end_char="5398">del</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="5400" end_char="5406">estudio</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="5408" end_char="5415">reflejan</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="5417" end_char="5418">un</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="5420" end_char="5426">periodo</TOKEN>
<TOKEN id="token-34-13" pos="word" morph="none" start_char="5428" end_char="5429">en</TOKEN>
<TOKEN id="token-34-14" pos="word" morph="none" start_char="5431" end_char="5432">el</TOKEN>
<TOKEN id="token-34-15" pos="word" morph="none" start_char="5434" end_char="5436">que</TOKEN>
<TOKEN id="token-34-16" pos="word" morph="none" start_char="5438" end_char="5440">las</TOKEN>
<TOKEN id="token-34-17" pos="word" morph="none" start_char="5442" end_char="5447">nuevas</TOKEN>
<TOKEN id="token-34-18" pos="word" morph="none" start_char="5449" end_char="5457">variantes</TOKEN>
<TOKEN id="token-34-19" pos="word" morph="none" start_char="5459" end_char="5461">con</TOKEN>
<TOKEN id="token-34-20" pos="word" morph="none" start_char="5463" end_char="5467">mayor</TOKEN>
<TOKEN id="token-34-21" pos="word" morph="none" start_char="5469" end_char="5484">transmisibilidad</TOKEN>
<TOKEN id="token-34-22" pos="word" morph="none" start_char="5486" end_char="5487">no</TOKEN>
<TOKEN id="token-34-23" pos="word" morph="none" start_char="5489" end_char="5492">eran</TOKEN>
<TOKEN id="token-34-24" pos="word" morph="none" start_char="5494" end_char="5495">un</TOKEN>
<TOKEN id="token-34-25" pos="word" morph="none" start_char="5497" end_char="5504">problema</TOKEN>
<TOKEN id="token-34-26" pos="punct" morph="none" start_char="5505" end_char="5505">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="5508" end_char="5742">
<ORIGINAL_TEXT>Taiwán es una nación insular con capacidad para controlar la introducción de nuevos casos a través del control fronterizo, y los autores reconocen que las conclusiones de este estudio pueden no ser totalmente aplicables a otros países.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="5508" end_char="5513">Taiwán</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="5515" end_char="5516">es</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="5518" end_char="5520">una</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="5522" end_char="5527">nación</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="5529" end_char="5535">insular</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="5537" end_char="5539">con</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="5541" end_char="5549">capacidad</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="5551" end_char="5554">para</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="5556" end_char="5564">controlar</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="5566" end_char="5567">la</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="5569" end_char="5580">introducción</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="5582" end_char="5583">de</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="5585" end_char="5590">nuevos</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="5592" end_char="5596">casos</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="5598" end_char="5598">a</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="5600" end_char="5605">través</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="5607" end_char="5609">del</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="5611" end_char="5617">control</TOKEN>
<TOKEN id="token-35-18" pos="word" morph="none" start_char="5619" end_char="5628">fronterizo</TOKEN>
<TOKEN id="token-35-19" pos="punct" morph="none" start_char="5629" end_char="5629">,</TOKEN>
<TOKEN id="token-35-20" pos="word" morph="none" start_char="5631" end_char="5631">y</TOKEN>
<TOKEN id="token-35-21" pos="word" morph="none" start_char="5633" end_char="5635">los</TOKEN>
<TOKEN id="token-35-22" pos="word" morph="none" start_char="5637" end_char="5643">autores</TOKEN>
<TOKEN id="token-35-23" pos="word" morph="none" start_char="5645" end_char="5653">reconocen</TOKEN>
<TOKEN id="token-35-24" pos="word" morph="none" start_char="5655" end_char="5657">que</TOKEN>
<TOKEN id="token-35-25" pos="word" morph="none" start_char="5659" end_char="5661">las</TOKEN>
<TOKEN id="token-35-26" pos="word" morph="none" start_char="5663" end_char="5674">conclusiones</TOKEN>
<TOKEN id="token-35-27" pos="word" morph="none" start_char="5676" end_char="5677">de</TOKEN>
<TOKEN id="token-35-28" pos="word" morph="none" start_char="5679" end_char="5682">este</TOKEN>
<TOKEN id="token-35-29" pos="word" morph="none" start_char="5684" end_char="5690">estudio</TOKEN>
<TOKEN id="token-35-30" pos="word" morph="none" start_char="5692" end_char="5697">pueden</TOKEN>
<TOKEN id="token-35-31" pos="word" morph="none" start_char="5699" end_char="5700">no</TOKEN>
<TOKEN id="token-35-32" pos="word" morph="none" start_char="5702" end_char="5704">ser</TOKEN>
<TOKEN id="token-35-33" pos="word" morph="none" start_char="5706" end_char="5715">totalmente</TOKEN>
<TOKEN id="token-35-34" pos="word" morph="none" start_char="5717" end_char="5726">aplicables</TOKEN>
<TOKEN id="token-35-35" pos="word" morph="none" start_char="5728" end_char="5728">a</TOKEN>
<TOKEN id="token-35-36" pos="word" morph="none" start_char="5730" end_char="5734">otros</TOKEN>
<TOKEN id="token-35-37" pos="word" morph="none" start_char="5736" end_char="5741">países</TOKEN>
<TOKEN id="token-35-38" pos="punct" morph="none" start_char="5742" end_char="5742">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="5744" end_char="5985">
<ORIGINAL_TEXT>Esta es la razón por la que los investigadores se centraron en la eficacia de las intervenciones basadas en casos y en la población sobre la transmisión local, y no en los controles fronterizos sobre el número de casos importados de COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="5744" end_char="5747">Esta</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="5749" end_char="5750">es</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="5752" end_char="5753">la</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="5755" end_char="5759">razón</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="5761" end_char="5763">por</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="5765" end_char="5766">la</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="5768" end_char="5770">que</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="5772" end_char="5774">los</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="5776" end_char="5789">investigadores</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="5791" end_char="5792">se</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="5794" end_char="5802">centraron</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="5804" end_char="5805">en</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="5807" end_char="5808">la</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="5810" end_char="5817">eficacia</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="5819" end_char="5820">de</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="5822" end_char="5824">las</TOKEN>
<TOKEN id="token-36-16" pos="word" morph="none" start_char="5826" end_char="5839">intervenciones</TOKEN>
<TOKEN id="token-36-17" pos="word" morph="none" start_char="5841" end_char="5847">basadas</TOKEN>
<TOKEN id="token-36-18" pos="word" morph="none" start_char="5849" end_char="5850">en</TOKEN>
<TOKEN id="token-36-19" pos="word" morph="none" start_char="5852" end_char="5856">casos</TOKEN>
<TOKEN id="token-36-20" pos="word" morph="none" start_char="5858" end_char="5858">y</TOKEN>
<TOKEN id="token-36-21" pos="word" morph="none" start_char="5860" end_char="5861">en</TOKEN>
<TOKEN id="token-36-22" pos="word" morph="none" start_char="5863" end_char="5864">la</TOKEN>
<TOKEN id="token-36-23" pos="word" morph="none" start_char="5866" end_char="5874">población</TOKEN>
<TOKEN id="token-36-24" pos="word" morph="none" start_char="5876" end_char="5880">sobre</TOKEN>
<TOKEN id="token-36-25" pos="word" morph="none" start_char="5882" end_char="5883">la</TOKEN>
<TOKEN id="token-36-26" pos="word" morph="none" start_char="5885" end_char="5895">transmisión</TOKEN>
<TOKEN id="token-36-27" pos="word" morph="none" start_char="5897" end_char="5901">local</TOKEN>
<TOKEN id="token-36-28" pos="punct" morph="none" start_char="5902" end_char="5902">,</TOKEN>
<TOKEN id="token-36-29" pos="word" morph="none" start_char="5904" end_char="5904">y</TOKEN>
<TOKEN id="token-36-30" pos="word" morph="none" start_char="5906" end_char="5907">no</TOKEN>
<TOKEN id="token-36-31" pos="word" morph="none" start_char="5909" end_char="5910">en</TOKEN>
<TOKEN id="token-36-32" pos="word" morph="none" start_char="5912" end_char="5914">los</TOKEN>
<TOKEN id="token-36-33" pos="word" morph="none" start_char="5916" end_char="5924">controles</TOKEN>
<TOKEN id="token-36-34" pos="word" morph="none" start_char="5926" end_char="5936">fronterizos</TOKEN>
<TOKEN id="token-36-35" pos="word" morph="none" start_char="5938" end_char="5942">sobre</TOKEN>
<TOKEN id="token-36-36" pos="word" morph="none" start_char="5944" end_char="5945">el</TOKEN>
<TOKEN id="token-36-37" pos="word" morph="none" start_char="5947" end_char="5952">número</TOKEN>
<TOKEN id="token-36-38" pos="word" morph="none" start_char="5954" end_char="5955">de</TOKEN>
<TOKEN id="token-36-39" pos="word" morph="none" start_char="5957" end_char="5961">casos</TOKEN>
<TOKEN id="token-36-40" pos="word" morph="none" start_char="5963" end_char="5972">importados</TOKEN>
<TOKEN id="token-36-41" pos="word" morph="none" start_char="5974" end_char="5975">de</TOKEN>
<TOKEN id="token-36-42" pos="unknown" morph="none" start_char="5977" end_char="5984">COVID-19</TOKEN>
<TOKEN id="token-36-43" pos="punct" morph="none" start_char="5985" end_char="5985">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="5988" end_char="6118">
<ORIGINAL_TEXT>Los autores concluyeron que el rastreo intensivo de contactos no es posible cuando los sistemas de salud pública están desbordados.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="5988" end_char="5990">Los</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="5992" end_char="5998">autores</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="6000" end_char="6010">concluyeron</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="6012" end_char="6014">que</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="6016" end_char="6017">el</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="6019" end_char="6025">rastreo</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="6027" end_char="6035">intensivo</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="6037" end_char="6038">de</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="6040" end_char="6048">contactos</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="6050" end_char="6051">no</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="6053" end_char="6054">es</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="6056" end_char="6062">posible</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="6064" end_char="6069">cuando</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="6071" end_char="6073">los</TOKEN>
<TOKEN id="token-37-14" pos="word" morph="none" start_char="6075" end_char="6082">sistemas</TOKEN>
<TOKEN id="token-37-15" pos="word" morph="none" start_char="6084" end_char="6085">de</TOKEN>
<TOKEN id="token-37-16" pos="word" morph="none" start_char="6087" end_char="6091">salud</TOKEN>
<TOKEN id="token-37-17" pos="word" morph="none" start_char="6093" end_char="6099">pública</TOKEN>
<TOKEN id="token-37-18" pos="word" morph="none" start_char="6101" end_char="6105">están</TOKEN>
<TOKEN id="token-37-19" pos="word" morph="none" start_char="6107" end_char="6117">desbordados</TOKEN>
<TOKEN id="token-37-20" pos="punct" morph="none" start_char="6118" end_char="6118">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="6120" end_char="6183">
<ORIGINAL_TEXT>Esto nunca ocurrió en Taiwán debido al éxito de sus estrategias.</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="6120" end_char="6123">Esto</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="6125" end_char="6129">nunca</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="6131" end_char="6137">ocurrió</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="6139" end_char="6140">en</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="6142" end_char="6147">Taiwán</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="6149" end_char="6154">debido</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="6156" end_char="6157">al</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="6159" end_char="6163">éxito</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="6165" end_char="6166">de</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="6168" end_char="6170">sus</TOKEN>
<TOKEN id="token-38-10" pos="word" morph="none" start_char="6172" end_char="6182">estrategias</TOKEN>
<TOKEN id="token-38-11" pos="punct" morph="none" start_char="6183" end_char="6183">.</TOKEN>
</SEG>
<SEG id="segment-39" start_char="6185" end_char="6336">
<ORIGINAL_TEXT>Por último, el documento encontró resultados similares para la cuarentena de siete y 14 días y sugiere que el periodo de confinamiento podría acortarse.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="6185" end_char="6187">Por</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="6189" end_char="6194">último</TOKEN>
<TOKEN id="token-39-2" pos="punct" morph="none" start_char="6195" end_char="6195">,</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="6197" end_char="6198">el</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="6200" end_char="6208">documento</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="6210" end_char="6217">encontró</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="6219" end_char="6228">resultados</TOKEN>
<TOKEN id="token-39-7" pos="word" morph="none" start_char="6230" end_char="6238">similares</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="6240" end_char="6243">para</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="6245" end_char="6246">la</TOKEN>
<TOKEN id="token-39-10" pos="word" morph="none" start_char="6248" end_char="6257">cuarentena</TOKEN>
<TOKEN id="token-39-11" pos="word" morph="none" start_char="6259" end_char="6260">de</TOKEN>
<TOKEN id="token-39-12" pos="word" morph="none" start_char="6262" end_char="6266">siete</TOKEN>
<TOKEN id="token-39-13" pos="word" morph="none" start_char="6268" end_char="6268">y</TOKEN>
<TOKEN id="token-39-14" pos="word" morph="none" start_char="6270" end_char="6271">14</TOKEN>
<TOKEN id="token-39-15" pos="word" morph="none" start_char="6273" end_char="6276">días</TOKEN>
<TOKEN id="token-39-16" pos="word" morph="none" start_char="6278" end_char="6278">y</TOKEN>
<TOKEN id="token-39-17" pos="word" morph="none" start_char="6280" end_char="6286">sugiere</TOKEN>
<TOKEN id="token-39-18" pos="word" morph="none" start_char="6288" end_char="6290">que</TOKEN>
<TOKEN id="token-39-19" pos="word" morph="none" start_char="6292" end_char="6293">el</TOKEN>
<TOKEN id="token-39-20" pos="word" morph="none" start_char="6295" end_char="6301">periodo</TOKEN>
<TOKEN id="token-39-21" pos="word" morph="none" start_char="6303" end_char="6304">de</TOKEN>
<TOKEN id="token-39-22" pos="word" morph="none" start_char="6306" end_char="6318">confinamiento</TOKEN>
<TOKEN id="token-39-23" pos="word" morph="none" start_char="6320" end_char="6325">podría</TOKEN>
<TOKEN id="token-39-24" pos="word" morph="none" start_char="6327" end_char="6335">acortarse</TOKEN>
<TOKEN id="token-39-25" pos="punct" morph="none" start_char="6336" end_char="6336">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="6338" end_char="6477">
<ORIGINAL_TEXT>Algunos países están considerando esta posibilidad, incluido Estados Unidos, pero hasta la fecha no se ha introducido de forma generalizada.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="6338" end_char="6344">Algunos</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="6346" end_char="6351">países</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="6353" end_char="6357">están</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="6359" end_char="6370">considerando</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="6372" end_char="6375">esta</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="6377" end_char="6387">posibilidad</TOKEN>
<TOKEN id="token-40-6" pos="punct" morph="none" start_char="6388" end_char="6388">,</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="6390" end_char="6397">incluido</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="6399" end_char="6405">Estados</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="6407" end_char="6412">Unidos</TOKEN>
<TOKEN id="token-40-10" pos="punct" morph="none" start_char="6413" end_char="6413">,</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="6415" end_char="6418">pero</TOKEN>
<TOKEN id="token-40-12" pos="word" morph="none" start_char="6420" end_char="6424">hasta</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="6426" end_char="6427">la</TOKEN>
<TOKEN id="token-40-14" pos="word" morph="none" start_char="6429" end_char="6433">fecha</TOKEN>
<TOKEN id="token-40-15" pos="word" morph="none" start_char="6435" end_char="6436">no</TOKEN>
<TOKEN id="token-40-16" pos="word" morph="none" start_char="6438" end_char="6439">se</TOKEN>
<TOKEN id="token-40-17" pos="word" morph="none" start_char="6441" end_char="6442">ha</TOKEN>
<TOKEN id="token-40-18" pos="word" morph="none" start_char="6444" end_char="6454">introducido</TOKEN>
<TOKEN id="token-40-19" pos="word" morph="none" start_char="6456" end_char="6457">de</TOKEN>
<TOKEN id="token-40-20" pos="word" morph="none" start_char="6459" end_char="6463">forma</TOKEN>
<TOKEN id="token-40-21" pos="word" morph="none" start_char="6465" end_char="6476">generalizada</TOKEN>
<TOKEN id="token-40-22" pos="punct" morph="none" start_char="6477" end_char="6477">.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="6480" end_char="6494">
<ORIGINAL_TEXT>SEGUIR LEYENDO:</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="6480" end_char="6485">SEGUIR</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="6487" end_char="6493">LEYENDO</TOKEN>
<TOKEN id="token-41-2" pos="punct" morph="none" start_char="6494" end_char="6494">:</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
