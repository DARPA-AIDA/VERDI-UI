<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CVHC" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="1978" raw_text_md5="2e01b64e0e9aac513a0685443191944a">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="63">
<ORIGINAL_TEXT>Contact tracing doesn't work, says Orange County Health Officer</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="7">Contact</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="9" end_char="15">tracing</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="17" end_char="23">doesn't</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="25" end_char="28">work</TOKEN>
<TOKEN id="token-0-4" pos="punct" morph="none" start_char="29" end_char="29">,</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="31" end_char="34">says</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="36" end_char="41">Orange</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="43" end_char="48">County</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="50" end_char="55">Health</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="57" end_char="63">Officer</TOKEN>
</SEG>
<SEG id="segment-1" start_char="67" end_char="194">
<ORIGINAL_TEXT>Delays in COVID-19 test results make contact tracing ineffective Most coronavirus cases in Central Florida are in Orange County.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="67" end_char="72">Delays</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="74" end_char="75">in</TOKEN>
<TOKEN id="token-1-2" pos="unknown" morph="none" start_char="77" end_char="84">COVID-19</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="86" end_char="89">test</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="91" end_char="97">results</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="99" end_char="102">make</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="104" end_char="110">contact</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="112" end_char="118">tracing</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="120" end_char="130">ineffective</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="132" end_char="135">Most</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="137" end_char="147">coronavirus</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="149" end_char="153">cases</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="155" end_char="156">in</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="158" end_char="164">Central</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="166" end_char="172">Florida</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="174" end_char="176">are</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="178" end_char="179">in</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="181" end_char="186">Orange</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="188" end_char="193">County</TOKEN>
<TOKEN id="token-1-19" pos="punct" morph="none" start_char="194" end_char="194">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="196" end_char="309">
<ORIGINAL_TEXT>Health officials are concerned that delays in test results are rendering contact tracing ineffective.CONNECTING...</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="196" end_char="201">Health</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="203" end_char="211">officials</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="213" end_char="215">are</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="217" end_char="225">concerned</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="227" end_char="230">that</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="232" end_char="237">delays</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="239" end_char="240">in</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="242" end_char="245">test</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="247" end_char="253">results</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="255" end_char="257">are</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="259" end_char="267">rendering</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="269" end_char="275">contact</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="277" end_char="283">tracing</TOKEN>
<TOKEN id="token-2-13" pos="unknown" morph="none" start_char="285" end_char="306">ineffective.CONNECTING</TOKEN>
<TOKEN id="token-2-14" pos="punct" morph="none" start_char="307" end_char="309">...</TOKEN>
</SEG>
<SEG id="segment-3" start_char="313" end_char="325">
<ORIGINAL_TEXT>ORLANDO, Fla.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="313" end_char="319">ORLANDO</TOKEN>
<TOKEN id="token-3-1" pos="punct" morph="none" start_char="320" end_char="320">,</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="322" end_char="324">Fla</TOKEN>
<TOKEN id="token-3-3" pos="punct" morph="none" start_char="325" end_char="325">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="327" end_char="462">
<ORIGINAL_TEXT>- The Orange County health officer says contact tracing doesn't work in the county because of delays in testing and the number of cases.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="punct" morph="none" start_char="327" end_char="327">-</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="329" end_char="331">The</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="333" end_char="338">Orange</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="340" end_char="345">County</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="347" end_char="352">health</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="354" end_char="360">officer</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="362" end_char="365">says</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="367" end_char="373">contact</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="375" end_char="381">tracing</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="383" end_char="389">doesn't</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="391" end_char="394">work</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="396" end_char="397">in</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="399" end_char="401">the</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="403" end_char="408">county</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="410" end_char="416">because</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="418" end_char="419">of</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="421" end_char="426">delays</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="428" end_char="429">in</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="431" end_char="437">testing</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="439" end_char="441">and</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="443" end_char="445">the</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="447" end_char="452">number</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="454" end_char="455">of</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="457" end_char="461">cases</TOKEN>
<TOKEN id="token-4-24" pos="punct" morph="none" start_char="462" end_char="462">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="465" end_char="496">
<ORIGINAL_TEXT>Orange County Health Officer Dr.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="465" end_char="470">Orange</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="472" end_char="477">County</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="479" end_char="484">Health</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="486" end_char="492">Officer</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="494" end_char="495">Dr</TOKEN>
<TOKEN id="token-5-5" pos="punct" morph="none" start_char="496" end_char="496">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="498" end_char="644">
<ORIGINAL_TEXT>Raul Pino says that because of delays in testing and the number of cases they are not contact tracing every person who tests positive for COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="498" end_char="501">Raul</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="503" end_char="506">Pino</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="508" end_char="511">says</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="513" end_char="516">that</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="518" end_char="524">because</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="526" end_char="527">of</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="529" end_char="534">delays</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="536" end_char="537">in</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="539" end_char="545">testing</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="547" end_char="549">and</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="551" end_char="553">the</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="555" end_char="560">number</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="562" end_char="563">of</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="565" end_char="569">cases</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="571" end_char="574">they</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="576" end_char="578">are</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="580" end_char="582">not</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="584" end_char="590">contact</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="592" end_char="598">tracing</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="600" end_char="604">every</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="606" end_char="611">person</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="613" end_char="615">who</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="617" end_char="621">tests</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="623" end_char="630">positive</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="632" end_char="634">for</TOKEN>
<TOKEN id="token-6-25" pos="unknown" morph="none" start_char="636" end_char="643">COVID-19</TOKEN>
<TOKEN id="token-6-26" pos="punct" morph="none" start_char="644" end_char="644">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="646" end_char="728">
<ORIGINAL_TEXT>Some people tell FOX 35 News that it's been taking more than a week to get results.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="646" end_char="649">Some</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="651" end_char="656">people</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="658" end_char="661">tell</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="663" end_char="665">FOX</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="667" end_char="668">35</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="670" end_char="673">News</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="675" end_char="678">that</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="680" end_char="683">it's</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="685" end_char="688">been</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="690" end_char="695">taking</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="697" end_char="700">more</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="702" end_char="705">than</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="707" end_char="707">a</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="709" end_char="712">week</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="714" end_char="715">to</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="717" end_char="719">get</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="721" end_char="727">results</TOKEN>
<TOKEN id="token-7-17" pos="punct" morph="none" start_char="728" end_char="728">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="731" end_char="845">
<ORIGINAL_TEXT>"If that lab takes seven days, you're already 12 days into the infection, and this is between 7-14 days you're out.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="punct" morph="none" start_char="731" end_char="731">"</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="732" end_char="733">If</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="735" end_char="738">that</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="740" end_char="742">lab</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="744" end_char="748">takes</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="750" end_char="754">seven</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="756" end_char="759">days</TOKEN>
<TOKEN id="token-8-7" pos="punct" morph="none" start_char="760" end_char="760">,</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="762" end_char="767">you're</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="769" end_char="775">already</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="777" end_char="778">12</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="780" end_char="783">days</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="785" end_char="788">into</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="790" end_char="792">the</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="794" end_char="802">infection</TOKEN>
<TOKEN id="token-8-15" pos="punct" morph="none" start_char="803" end_char="803">,</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="805" end_char="807">and</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="809" end_char="812">this</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="814" end_char="815">is</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="817" end_char="823">between</TOKEN>
<TOKEN id="token-8-20" pos="unknown" morph="none" start_char="825" end_char="828">7-14</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="830" end_char="833">days</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="835" end_char="840">you're</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="842" end_char="844">out</TOKEN>
<TOKEN id="token-8-24" pos="punct" morph="none" start_char="845" end_char="845">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="847" end_char="978">
<ORIGINAL_TEXT>And, then it takes us a couple of days to get to you because of the number of cases then the tracing has no meaning," said Dr. Pino.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="847" end_char="849">And</TOKEN>
<TOKEN id="token-9-1" pos="punct" morph="none" start_char="850" end_char="850">,</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="852" end_char="855">then</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="857" end_char="858">it</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="860" end_char="864">takes</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="866" end_char="867">us</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="869" end_char="869">a</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="871" end_char="876">couple</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="878" end_char="879">of</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="881" end_char="884">days</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="886" end_char="887">to</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="889" end_char="891">get</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="893" end_char="894">to</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="896" end_char="898">you</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="900" end_char="906">because</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="908" end_char="909">of</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="911" end_char="913">the</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="915" end_char="920">number</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="922" end_char="923">of</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="925" end_char="929">cases</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="931" end_char="934">then</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="936" end_char="938">the</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="940" end_char="946">tracing</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="948" end_char="950">has</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="952" end_char="953">no</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="955" end_char="961">meaning</TOKEN>
<TOKEN id="token-9-26" pos="punct" morph="none" start_char="962" end_char="963">,"</TOKEN>
<TOKEN id="token-9-27" pos="word" morph="none" start_char="965" end_char="968">said</TOKEN>
<TOKEN id="token-9-28" pos="word" morph="none" start_char="970" end_char="971">Dr</TOKEN>
<TOKEN id="token-9-29" pos="punct" morph="none" start_char="972" end_char="972">.</TOKEN>
<TOKEN id="token-9-30" pos="word" morph="none" start_char="974" end_char="977">Pino</TOKEN>
<TOKEN id="token-9-31" pos="punct" morph="none" start_char="978" end_char="978">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="980" end_char="1040">
<ORIGINAL_TEXT>"Tracing works as long as you can handle the number of cases.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="punct" morph="none" start_char="980" end_char="980">"</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="981" end_char="987">Tracing</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="989" end_char="993">works</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="995" end_char="996">as</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="998" end_char="1001">long</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1003" end_char="1004">as</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1006" end_char="1008">you</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1010" end_char="1012">can</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1014" end_char="1019">handle</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1021" end_char="1023">the</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1025" end_char="1030">number</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1032" end_char="1033">of</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1035" end_char="1039">cases</TOKEN>
<TOKEN id="token-10-13" pos="punct" morph="none" start_char="1040" end_char="1040">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1042" end_char="1088">
<ORIGINAL_TEXT>When you get to these numbers, it doesn't work.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1042" end_char="1045">When</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1047" end_char="1049">you</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1051" end_char="1053">get</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1055" end_char="1056">to</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1058" end_char="1062">these</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1064" end_char="1070">numbers</TOKEN>
<TOKEN id="token-11-6" pos="punct" morph="none" start_char="1071" end_char="1071">,</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1073" end_char="1074">it</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1076" end_char="1082">doesn't</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1084" end_char="1087">work</TOKEN>
<TOKEN id="token-11-10" pos="punct" morph="none" start_char="1088" end_char="1088">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1090" end_char="1183">
<ORIGINAL_TEXT>When you get to how long it takes to get a lab results it doesn't work either," said Dr. Pino.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1090" end_char="1093">When</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1095" end_char="1097">you</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1099" end_char="1101">get</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1103" end_char="1104">to</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1106" end_char="1108">how</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1110" end_char="1113">long</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1115" end_char="1116">it</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1118" end_char="1122">takes</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1124" end_char="1125">to</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1127" end_char="1129">get</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1131" end_char="1131">a</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1133" end_char="1135">lab</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1137" end_char="1143">results</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1145" end_char="1146">it</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1148" end_char="1154">doesn't</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1156" end_char="1159">work</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1161" end_char="1166">either</TOKEN>
<TOKEN id="token-12-17" pos="punct" morph="none" start_char="1167" end_char="1168">,"</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1170" end_char="1173">said</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1175" end_char="1176">Dr</TOKEN>
<TOKEN id="token-12-20" pos="punct" morph="none" start_char="1177" end_char="1177">.</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1179" end_char="1182">Pino</TOKEN>
<TOKEN id="token-12-22" pos="punct" morph="none" start_char="1183" end_char="1183">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1186" end_char="1401">
<ORIGINAL_TEXT>Dr. Pino says while the county is not contact tracing every person who tests positive for COVID-19 they are tracing at places that have outbreaks, assisted living facilities, healthcare workers, and first responders.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1186" end_char="1187">Dr</TOKEN>
<TOKEN id="token-13-1" pos="punct" morph="none" start_char="1188" end_char="1188">.</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1190" end_char="1193">Pino</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1195" end_char="1198">says</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1200" end_char="1204">while</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1206" end_char="1208">the</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1210" end_char="1215">county</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1217" end_char="1218">is</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1220" end_char="1222">not</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1224" end_char="1230">contact</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1232" end_char="1238">tracing</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1240" end_char="1244">every</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1246" end_char="1251">person</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1253" end_char="1255">who</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1257" end_char="1261">tests</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1263" end_char="1270">positive</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1272" end_char="1274">for</TOKEN>
<TOKEN id="token-13-17" pos="unknown" morph="none" start_char="1276" end_char="1283">COVID-19</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1285" end_char="1288">they</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1290" end_char="1292">are</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1294" end_char="1300">tracing</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="1302" end_char="1303">at</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="1305" end_char="1310">places</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="1312" end_char="1315">that</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="1317" end_char="1320">have</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="1322" end_char="1330">outbreaks</TOKEN>
<TOKEN id="token-13-26" pos="punct" morph="none" start_char="1331" end_char="1331">,</TOKEN>
<TOKEN id="token-13-27" pos="word" morph="none" start_char="1333" end_char="1340">assisted</TOKEN>
<TOKEN id="token-13-28" pos="word" morph="none" start_char="1342" end_char="1347">living</TOKEN>
<TOKEN id="token-13-29" pos="word" morph="none" start_char="1349" end_char="1358">facilities</TOKEN>
<TOKEN id="token-13-30" pos="punct" morph="none" start_char="1359" end_char="1359">,</TOKEN>
<TOKEN id="token-13-31" pos="word" morph="none" start_char="1361" end_char="1370">healthcare</TOKEN>
<TOKEN id="token-13-32" pos="word" morph="none" start_char="1372" end_char="1378">workers</TOKEN>
<TOKEN id="token-13-33" pos="punct" morph="none" start_char="1379" end_char="1379">,</TOKEN>
<TOKEN id="token-13-34" pos="word" morph="none" start_char="1381" end_char="1383">and</TOKEN>
<TOKEN id="token-13-35" pos="word" morph="none" start_char="1385" end_char="1389">first</TOKEN>
<TOKEN id="token-13-36" pos="word" morph="none" start_char="1391" end_char="1400">responders</TOKEN>
<TOKEN id="token-13-37" pos="punct" morph="none" start_char="1401" end_char="1401">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1404" end_char="1541">
<ORIGINAL_TEXT>"Contact tracing is only as good as the completeness of when you can do it when you start getting too much it becomes difficult," said Dr.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="punct" morph="none" start_char="1404" end_char="1404">"</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1405" end_char="1411">Contact</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1413" end_char="1419">tracing</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1421" end_char="1422">is</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1424" end_char="1427">only</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1429" end_char="1430">as</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1432" end_char="1435">good</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1437" end_char="1438">as</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1440" end_char="1442">the</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1444" end_char="1455">completeness</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1457" end_char="1458">of</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1460" end_char="1463">when</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1465" end_char="1467">you</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1469" end_char="1471">can</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="1473" end_char="1474">do</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1476" end_char="1477">it</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1479" end_char="1482">when</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="1484" end_char="1486">you</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="1488" end_char="1492">start</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="1494" end_char="1500">getting</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="1502" end_char="1504">too</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="1506" end_char="1509">much</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="1511" end_char="1512">it</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="1514" end_char="1520">becomes</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="1522" end_char="1530">difficult</TOKEN>
<TOKEN id="token-14-25" pos="punct" morph="none" start_char="1531" end_char="1532">,"</TOKEN>
<TOKEN id="token-14-26" pos="word" morph="none" start_char="1534" end_char="1537">said</TOKEN>
<TOKEN id="token-14-27" pos="word" morph="none" start_char="1539" end_char="1540">Dr</TOKEN>
<TOKEN id="token-14-28" pos="punct" morph="none" start_char="1541" end_char="1541">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1543" end_char="1572">
<ORIGINAL_TEXT>Vincent Hsu with AdventHealth.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1543" end_char="1549">Vincent</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1551" end_char="1553">Hsu</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1555" end_char="1558">with</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1560" end_char="1571">AdventHealth</TOKEN>
<TOKEN id="token-15-4" pos="punct" morph="none" start_char="1572" end_char="1572">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1575" end_char="1630">
<ORIGINAL_TEXT>Contact tracing is meant to find the source of COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1575" end_char="1581">Contact</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1583" end_char="1589">tracing</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1591" end_char="1592">is</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1594" end_char="1598">meant</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1600" end_char="1601">to</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1603" end_char="1606">find</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1608" end_char="1610">the</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1612" end_char="1617">source</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1619" end_char="1620">of</TOKEN>
<TOKEN id="token-16-9" pos="unknown" morph="none" start_char="1622" end_char="1629">COVID-19</TOKEN>
<TOKEN id="token-16-10" pos="punct" morph="none" start_char="1630" end_char="1630">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1632" end_char="1770">
<ORIGINAL_TEXT>Tracers call people who test positive to find out how they contracted the virus and who else might be exposed so they could get tested too.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1632" end_char="1638">Tracers</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1640" end_char="1643">call</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="1645" end_char="1650">people</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="1652" end_char="1654">who</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="1656" end_char="1659">test</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="1661" end_char="1668">positive</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="1670" end_char="1671">to</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="1673" end_char="1676">find</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="1678" end_char="1680">out</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="1682" end_char="1684">how</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="1686" end_char="1689">they</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="1691" end_char="1700">contracted</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="1702" end_char="1704">the</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="1706" end_char="1710">virus</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="1712" end_char="1714">and</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="1716" end_char="1718">who</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="1720" end_char="1723">else</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="1725" end_char="1729">might</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="1731" end_char="1732">be</TOKEN>
<TOKEN id="token-17-19" pos="word" morph="none" start_char="1734" end_char="1740">exposed</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="1742" end_char="1743">so</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="1745" end_char="1748">they</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="1750" end_char="1754">could</TOKEN>
<TOKEN id="token-17-23" pos="word" morph="none" start_char="1756" end_char="1758">get</TOKEN>
<TOKEN id="token-17-24" pos="word" morph="none" start_char="1760" end_char="1765">tested</TOKEN>
<TOKEN id="token-17-25" pos="word" morph="none" start_char="1767" end_char="1769">too</TOKEN>
<TOKEN id="token-17-26" pos="punct" morph="none" start_char="1770" end_char="1770">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1773" end_char="1974">
<ORIGINAL_TEXT>"The hope is that you can get to those people that may have acquired the disease before they even experience symptoms, but with the delays we have experienced lately, that's less likely," Dr. Pino said.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="punct" morph="none" start_char="1773" end_char="1773">"</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="1774" end_char="1776">The</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="1778" end_char="1781">hope</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="1783" end_char="1784">is</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="1786" end_char="1789">that</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="1791" end_char="1793">you</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="1795" end_char="1797">can</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="1799" end_char="1801">get</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="1803" end_char="1804">to</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="1806" end_char="1810">those</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="1812" end_char="1817">people</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="1819" end_char="1822">that</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="1824" end_char="1826">may</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="1828" end_char="1831">have</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="1833" end_char="1840">acquired</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="1842" end_char="1844">the</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="1846" end_char="1852">disease</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="1854" end_char="1859">before</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="1861" end_char="1864">they</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="1866" end_char="1869">even</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="1871" end_char="1880">experience</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="1882" end_char="1889">symptoms</TOKEN>
<TOKEN id="token-18-22" pos="punct" morph="none" start_char="1890" end_char="1890">,</TOKEN>
<TOKEN id="token-18-23" pos="word" morph="none" start_char="1892" end_char="1894">but</TOKEN>
<TOKEN id="token-18-24" pos="word" morph="none" start_char="1896" end_char="1899">with</TOKEN>
<TOKEN id="token-18-25" pos="word" morph="none" start_char="1901" end_char="1903">the</TOKEN>
<TOKEN id="token-18-26" pos="word" morph="none" start_char="1905" end_char="1910">delays</TOKEN>
<TOKEN id="token-18-27" pos="word" morph="none" start_char="1912" end_char="1913">we</TOKEN>
<TOKEN id="token-18-28" pos="word" morph="none" start_char="1915" end_char="1918">have</TOKEN>
<TOKEN id="token-18-29" pos="word" morph="none" start_char="1920" end_char="1930">experienced</TOKEN>
<TOKEN id="token-18-30" pos="word" morph="none" start_char="1932" end_char="1937">lately</TOKEN>
<TOKEN id="token-18-31" pos="punct" morph="none" start_char="1938" end_char="1938">,</TOKEN>
<TOKEN id="token-18-32" pos="word" morph="none" start_char="1940" end_char="1945">that's</TOKEN>
<TOKEN id="token-18-33" pos="word" morph="none" start_char="1947" end_char="1950">less</TOKEN>
<TOKEN id="token-18-34" pos="word" morph="none" start_char="1952" end_char="1957">likely</TOKEN>
<TOKEN id="token-18-35" pos="punct" morph="none" start_char="1958" end_char="1959">,"</TOKEN>
<TOKEN id="token-18-36" pos="word" morph="none" start_char="1961" end_char="1962">Dr</TOKEN>
<TOKEN id="token-18-37" pos="punct" morph="none" start_char="1963" end_char="1963">.</TOKEN>
<TOKEN id="token-18-38" pos="word" morph="none" start_char="1965" end_char="1968">Pino</TOKEN>
<TOKEN id="token-18-39" pos="word" morph="none" start_char="1970" end_char="1973">said</TOKEN>
<TOKEN id="token-18-40" pos="punct" morph="none" start_char="1974" end_char="1974">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
