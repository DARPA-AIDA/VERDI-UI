<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATMN" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="2019" raw_text_md5="8a008c6d73ac7f75ad60c98e4a8a0cbf">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="58">
<ORIGINAL_TEXT>Two Studies Find That Humidity Prevents Coronavirus Spread</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="3">Two</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="5" end_char="11">Studies</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="13" end_char="16">Find</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="18" end_char="21">That</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="23" end_char="30">Humidity</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="32" end_char="39">Prevents</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="41" end_char="51">Coronavirus</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="53" end_char="58">Spread</TOKEN>
</SEG>
<SEG id="segment-1" start_char="62" end_char="84">
<ORIGINAL_TEXT>NIAID/Victor Tangermann</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="unknown" morph="none" start_char="62" end_char="73">NIAID/Victor</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="75" end_char="84">Tangermann</TOKEN>
</SEG>
<SEG id="segment-2" start_char="88" end_char="181">
<ORIGINAL_TEXT>Two independent studies have identified a useful tool for stopping the coronavirus: humid air.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="88" end_char="90">Two</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="92" end_char="102">independent</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="104" end_char="110">studies</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="112" end_char="115">have</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="117" end_char="126">identified</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="128" end_char="128">a</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="130" end_char="135">useful</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="137" end_char="140">tool</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="142" end_char="144">for</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="146" end_char="153">stopping</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="155" end_char="157">the</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="159" end_char="169">coronavirus</TOKEN>
<TOKEN id="token-2-12" pos="punct" morph="none" start_char="170" end_char="170">:</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="172" end_char="176">humid</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="178" end_char="180">air</TOKEN>
<TOKEN id="token-2-15" pos="punct" morph="none" start_char="181" end_char="181">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="184" end_char="393">
<ORIGINAL_TEXT>According to the research, dry air not only hampers our lungs’ ability to clear out respiratory viruses like SARS-CoV-2, but also makes it harder for our immune systems to fight it off once we’ve been infected,</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="184" end_char="192">According</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="194" end_char="195">to</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="197" end_char="199">the</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="201" end_char="208">research</TOKEN>
<TOKEN id="token-3-4" pos="punct" morph="none" start_char="209" end_char="209">,</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="211" end_char="213">dry</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="215" end_char="217">air</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="219" end_char="221">not</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="223" end_char="226">only</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="228" end_char="234">hampers</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="236" end_char="238">our</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="240" end_char="244">lungs</TOKEN>
<TOKEN id="token-3-12" pos="punct" morph="none" start_char="245" end_char="245">’</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="247" end_char="253">ability</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="255" end_char="256">to</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="258" end_char="262">clear</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="264" end_char="266">out</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="268" end_char="278">respiratory</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="280" end_char="286">viruses</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="288" end_char="291">like</TOKEN>
<TOKEN id="token-3-20" pos="unknown" morph="none" start_char="293" end_char="302">SARS-CoV-2</TOKEN>
<TOKEN id="token-3-21" pos="punct" morph="none" start_char="303" end_char="303">,</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="305" end_char="307">but</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="309" end_char="312">also</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="314" end_char="318">makes</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="320" end_char="321">it</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="323" end_char="328">harder</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="330" end_char="332">for</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="334" end_char="336">our</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="338" end_char="343">immune</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="345" end_char="351">systems</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="353" end_char="354">to</TOKEN>
<TOKEN id="token-3-32" pos="word" morph="none" start_char="356" end_char="360">fight</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="362" end_char="363">it</TOKEN>
<TOKEN id="token-3-34" pos="word" morph="none" start_char="365" end_char="367">off</TOKEN>
<TOKEN id="token-3-35" pos="word" morph="none" start_char="369" end_char="372">once</TOKEN>
<TOKEN id="token-3-36" pos="word" morph="none" start_char="374" end_char="378">we’ve</TOKEN>
<TOKEN id="token-3-37" pos="word" morph="none" start_char="380" end_char="383">been</TOKEN>
<TOKEN id="token-3-38" pos="word" morph="none" start_char="385" end_char="392">infected</TOKEN>
<TOKEN id="token-3-39" pos="punct" morph="none" start_char="393" end_char="393">,</TOKEN>
</SEG>
<SEG id="segment-4" start_char="396" end_char="403">
<ORIGINAL_TEXT>Newsweek</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="396" end_char="403">Newsweek</TOKEN>
</SEG>
<SEG id="segment-5" start_char="406" end_char="413">
<ORIGINAL_TEXT>reports.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="406" end_char="412">reports</TOKEN>
<TOKEN id="token-5-1" pos="punct" morph="none" start_char="413" end_char="413">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="416" end_char="610">
<ORIGINAL_TEXT>And on the contrary, relative humidity between 40 and 60 percent seems to make it much harder for the coronavirus to take hold — an epidemiological clue that we could weaponize against the virus.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="416" end_char="418">And</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="420" end_char="421">on</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="423" end_char="425">the</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="427" end_char="434">contrary</TOKEN>
<TOKEN id="token-6-4" pos="punct" morph="none" start_char="435" end_char="435">,</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="437" end_char="444">relative</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="446" end_char="453">humidity</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="455" end_char="461">between</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="463" end_char="464">40</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="466" end_char="468">and</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="470" end_char="471">60</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="473" end_char="479">percent</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="481" end_char="485">seems</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="487" end_char="488">to</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="490" end_char="493">make</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="495" end_char="496">it</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="498" end_char="501">much</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="503" end_char="508">harder</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="510" end_char="512">for</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="514" end_char="516">the</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="518" end_char="528">coronavirus</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="530" end_char="531">to</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="533" end_char="536">take</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="538" end_char="541">hold</TOKEN>
<TOKEN id="token-6-24" pos="punct" morph="none" start_char="543" end_char="543">—</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="545" end_char="546">an</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="548" end_char="562">epidemiological</TOKEN>
<TOKEN id="token-6-27" pos="word" morph="none" start_char="564" end_char="567">clue</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="569" end_char="572">that</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="574" end_char="575">we</TOKEN>
<TOKEN id="token-6-30" pos="word" morph="none" start_char="577" end_char="581">could</TOKEN>
<TOKEN id="token-6-31" pos="word" morph="none" start_char="583" end_char="591">weaponize</TOKEN>
<TOKEN id="token-6-32" pos="word" morph="none" start_char="593" end_char="599">against</TOKEN>
<TOKEN id="token-6-33" pos="word" morph="none" start_char="601" end_char="603">the</TOKEN>
<TOKEN id="token-6-34" pos="word" morph="none" start_char="605" end_char="609">virus</TOKEN>
<TOKEN id="token-6-35" pos="punct" morph="none" start_char="610" end_char="610">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="613" end_char="765">
<ORIGINAL_TEXT>"We spend 90 percent of our lives indoors, where the air is very dry in the winter," Yale immunobiologist Akiko Iwasaki, who led one of the studies, told</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="punct" morph="none" start_char="613" end_char="613">"</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="614" end_char="615">We</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="617" end_char="621">spend</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="623" end_char="624">90</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="626" end_char="632">percent</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="634" end_char="635">of</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="637" end_char="639">our</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="641" end_char="645">lives</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="647" end_char="653">indoors</TOKEN>
<TOKEN id="token-7-9" pos="punct" morph="none" start_char="654" end_char="654">,</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="656" end_char="660">where</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="662" end_char="664">the</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="666" end_char="668">air</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="670" end_char="671">is</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="673" end_char="676">very</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="678" end_char="680">dry</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="682" end_char="683">in</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="685" end_char="687">the</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="689" end_char="694">winter</TOKEN>
<TOKEN id="token-7-19" pos="punct" morph="none" start_char="695" end_char="696">,"</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="698" end_char="701">Yale</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="703" end_char="717">immunobiologist</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="719" end_char="723">Akiko</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="725" end_char="731">Iwasaki</TOKEN>
<TOKEN id="token-7-24" pos="punct" morph="none" start_char="732" end_char="732">,</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="734" end_char="736">who</TOKEN>
<TOKEN id="token-7-26" pos="word" morph="none" start_char="738" end_char="740">led</TOKEN>
<TOKEN id="token-7-27" pos="word" morph="none" start_char="742" end_char="744">one</TOKEN>
<TOKEN id="token-7-28" pos="word" morph="none" start_char="746" end_char="747">of</TOKEN>
<TOKEN id="token-7-29" pos="word" morph="none" start_char="749" end_char="751">the</TOKEN>
<TOKEN id="token-7-30" pos="word" morph="none" start_char="753" end_char="759">studies</TOKEN>
<TOKEN id="token-7-31" pos="punct" morph="none" start_char="760" end_char="760">,</TOKEN>
<TOKEN id="token-7-32" pos="word" morph="none" start_char="762" end_char="765">told</TOKEN>
</SEG>
<SEG id="segment-8" start_char="768" end_char="775">
<ORIGINAL_TEXT>Newsweek</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="768" end_char="775">Newsweek</TOKEN>
</SEG>
<SEG id="segment-9" start_char="778" end_char="778">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="punct" morph="none" start_char="778" end_char="778">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="780" end_char="839">
<ORIGINAL_TEXT>"That’s exactly when the virus best survives and transmits."</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="punct" morph="none" start_char="780" end_char="780">"</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="781" end_char="786">That’s</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="788" end_char="794">exactly</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="796" end_char="799">when</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="801" end_char="803">the</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="805" end_char="809">virus</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="811" end_char="814">best</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="816" end_char="823">survives</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="825" end_char="827">and</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="829" end_char="837">transmits</TOKEN>
<TOKEN id="token-10-10" pos="punct" morph="none" start_char="838" end_char="839">."</TOKEN>
</SEG>
<SEG id="segment-11" start_char="842" end_char="1063">
<ORIGINAL_TEXT>Iwasaki collaborated with Swiss physician Walter Hugentobler, who noticed that pilots and flight attendants caught the flu at unusually-high rates, eventually linking the phenomenon to extremely-dry cabin air, according to</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="842" end_char="848">Iwasaki</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="850" end_char="861">collaborated</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="863" end_char="866">with</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="868" end_char="872">Swiss</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="874" end_char="882">physician</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="884" end_char="889">Walter</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="891" end_char="901">Hugentobler</TOKEN>
<TOKEN id="token-11-7" pos="punct" morph="none" start_char="902" end_char="902">,</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="904" end_char="906">who</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="908" end_char="914">noticed</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="916" end_char="919">that</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="921" end_char="926">pilots</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="928" end_char="930">and</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="932" end_char="937">flight</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="939" end_char="948">attendants</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="950" end_char="955">caught</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="957" end_char="959">the</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="961" end_char="963">flu</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="965" end_char="966">at</TOKEN>
<TOKEN id="token-11-19" pos="unknown" morph="none" start_char="968" end_char="981">unusually-high</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="983" end_char="987">rates</TOKEN>
<TOKEN id="token-11-21" pos="punct" morph="none" start_char="988" end_char="988">,</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="990" end_char="999">eventually</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="1001" end_char="1007">linking</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="1009" end_char="1011">the</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="1013" end_char="1022">phenomenon</TOKEN>
<TOKEN id="token-11-26" pos="word" morph="none" start_char="1024" end_char="1025">to</TOKEN>
<TOKEN id="token-11-27" pos="unknown" morph="none" start_char="1027" end_char="1039">extremely-dry</TOKEN>
<TOKEN id="token-11-28" pos="word" morph="none" start_char="1041" end_char="1045">cabin</TOKEN>
<TOKEN id="token-11-29" pos="word" morph="none" start_char="1047" end_char="1049">air</TOKEN>
<TOKEN id="token-11-30" pos="punct" morph="none" start_char="1050" end_char="1050">,</TOKEN>
<TOKEN id="token-11-31" pos="word" morph="none" start_char="1052" end_char="1060">according</TOKEN>
<TOKEN id="token-11-32" pos="word" morph="none" start_char="1062" end_char="1063">to</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1066" end_char="1073">
<ORIGINAL_TEXT>Newsweek</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1066" end_char="1073">Newsweek</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1076" end_char="1076">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="punct" morph="none" start_char="1076" end_char="1076">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1078" end_char="1218">
<ORIGINAL_TEXT>More recently, MIT engineer Hazhir Rahmandad found that COVID-19 spread more rapidly in dry regions of Iran than those with greater humidity.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1078" end_char="1081">More</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1083" end_char="1090">recently</TOKEN>
<TOKEN id="token-14-2" pos="punct" morph="none" start_char="1091" end_char="1091">,</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1093" end_char="1095">MIT</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1097" end_char="1104">engineer</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1106" end_char="1111">Hazhir</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1113" end_char="1121">Rahmandad</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1123" end_char="1127">found</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1129" end_char="1132">that</TOKEN>
<TOKEN id="token-14-9" pos="unknown" morph="none" start_char="1134" end_char="1141">COVID-19</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1143" end_char="1148">spread</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1150" end_char="1153">more</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1155" end_char="1161">rapidly</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1163" end_char="1164">in</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="1166" end_char="1168">dry</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1170" end_char="1176">regions</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1178" end_char="1179">of</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="1181" end_char="1184">Iran</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="1186" end_char="1189">than</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="1191" end_char="1195">those</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="1197" end_char="1200">with</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="1202" end_char="1208">greater</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="1210" end_char="1217">humidity</TOKEN>
<TOKEN id="token-14-23" pos="punct" morph="none" start_char="1218" end_char="1218">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1221" end_char="1427">
<ORIGINAL_TEXT>While the news seems to indicate that the pandemic may drop off during the summer, government leaders and the public could take that as a sign to relax protective lockdown measures and return to normal life.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1221" end_char="1225">While</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1227" end_char="1229">the</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1231" end_char="1234">news</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1236" end_char="1240">seems</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1242" end_char="1243">to</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1245" end_char="1252">indicate</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1254" end_char="1257">that</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1259" end_char="1261">the</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1263" end_char="1270">pandemic</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1272" end_char="1274">may</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1276" end_char="1279">drop</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1281" end_char="1283">off</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1285" end_char="1290">during</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1292" end_char="1294">the</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1296" end_char="1301">summer</TOKEN>
<TOKEN id="token-15-15" pos="punct" morph="none" start_char="1302" end_char="1302">,</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="1304" end_char="1313">government</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="1315" end_char="1321">leaders</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="1323" end_char="1325">and</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="1327" end_char="1329">the</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="1331" end_char="1336">public</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="1338" end_char="1342">could</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="1344" end_char="1347">take</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="1349" end_char="1352">that</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="1354" end_char="1355">as</TOKEN>
<TOKEN id="token-15-25" pos="word" morph="none" start_char="1357" end_char="1357">a</TOKEN>
<TOKEN id="token-15-26" pos="word" morph="none" start_char="1359" end_char="1362">sign</TOKEN>
<TOKEN id="token-15-27" pos="word" morph="none" start_char="1364" end_char="1365">to</TOKEN>
<TOKEN id="token-15-28" pos="word" morph="none" start_char="1367" end_char="1371">relax</TOKEN>
<TOKEN id="token-15-29" pos="word" morph="none" start_char="1373" end_char="1382">protective</TOKEN>
<TOKEN id="token-15-30" pos="word" morph="none" start_char="1384" end_char="1391">lockdown</TOKEN>
<TOKEN id="token-15-31" pos="word" morph="none" start_char="1393" end_char="1400">measures</TOKEN>
<TOKEN id="token-15-32" pos="word" morph="none" start_char="1402" end_char="1404">and</TOKEN>
<TOKEN id="token-15-33" pos="word" morph="none" start_char="1406" end_char="1411">return</TOKEN>
<TOKEN id="token-15-34" pos="word" morph="none" start_char="1413" end_char="1414">to</TOKEN>
<TOKEN id="token-15-35" pos="word" morph="none" start_char="1416" end_char="1421">normal</TOKEN>
<TOKEN id="token-15-36" pos="word" morph="none" start_char="1423" end_char="1426">life</TOKEN>
<TOKEN id="token-15-37" pos="punct" morph="none" start_char="1427" end_char="1427">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1429" end_char="1444">
<ORIGINAL_TEXT>If that happens,</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1429" end_char="1430">If</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1432" end_char="1435">that</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1437" end_char="1443">happens</TOKEN>
<TOKEN id="token-16-3" pos="punct" morph="none" start_char="1444" end_char="1444">,</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1447" end_char="1454">
<ORIGINAL_TEXT>Newsweek</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1447" end_char="1454">Newsweek</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1457" end_char="1549">
<ORIGINAL_TEXT>theorizes that there could be even greater spikes and outbreaks when the air dries out again.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="1457" end_char="1465">theorizes</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="1467" end_char="1470">that</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="1472" end_char="1476">there</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="1478" end_char="1482">could</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="1484" end_char="1485">be</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="1487" end_char="1490">even</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="1492" end_char="1498">greater</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="1500" end_char="1505">spikes</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="1507" end_char="1509">and</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="1511" end_char="1519">outbreaks</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="1521" end_char="1524">when</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="1526" end_char="1528">the</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="1530" end_char="1532">air</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="1534" end_char="1538">dries</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="1540" end_char="1542">out</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="1544" end_char="1548">again</TOKEN>
<TOKEN id="token-18-16" pos="punct" morph="none" start_char="1549" end_char="1549">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="1552" end_char="1584">
<ORIGINAL_TEXT>But in the meantime, Iwasaki told</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="1552" end_char="1554">But</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="1556" end_char="1557">in</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="1559" end_char="1561">the</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="1563" end_char="1570">meantime</TOKEN>
<TOKEN id="token-19-4" pos="punct" morph="none" start_char="1571" end_char="1571">,</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="1573" end_char="1579">Iwasaki</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="1581" end_char="1584">told</TOKEN>
</SEG>
<SEG id="segment-20" start_char="1587" end_char="1594">
<ORIGINAL_TEXT>Newsweek</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="1587" end_char="1594">Newsweek</TOKEN>
</SEG>
<SEG id="segment-21" start_char="1597" end_char="1790">
<ORIGINAL_TEXT>she’s lobbying the World Health Organization to call for greater indoor humidification as a protective measure, especially in places like nursing homes — but the organization has yet to respond.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="1597" end_char="1601">she’s</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="1603" end_char="1610">lobbying</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="1612" end_char="1614">the</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="1616" end_char="1620">World</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="1622" end_char="1627">Health</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="1629" end_char="1640">Organization</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="1642" end_char="1643">to</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="1645" end_char="1648">call</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="1650" end_char="1652">for</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="1654" end_char="1660">greater</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="1662" end_char="1667">indoor</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="1669" end_char="1682">humidification</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="1684" end_char="1685">as</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="1687" end_char="1687">a</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="1689" end_char="1698">protective</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="1700" end_char="1706">measure</TOKEN>
<TOKEN id="token-21-16" pos="punct" morph="none" start_char="1707" end_char="1707">,</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="1709" end_char="1718">especially</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="1720" end_char="1721">in</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="1723" end_char="1728">places</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="1730" end_char="1733">like</TOKEN>
<TOKEN id="token-21-21" pos="word" morph="none" start_char="1735" end_char="1741">nursing</TOKEN>
<TOKEN id="token-21-22" pos="word" morph="none" start_char="1743" end_char="1747">homes</TOKEN>
<TOKEN id="token-21-23" pos="punct" morph="none" start_char="1749" end_char="1749">—</TOKEN>
<TOKEN id="token-21-24" pos="word" morph="none" start_char="1751" end_char="1753">but</TOKEN>
<TOKEN id="token-21-25" pos="word" morph="none" start_char="1755" end_char="1757">the</TOKEN>
<TOKEN id="token-21-26" pos="word" morph="none" start_char="1759" end_char="1770">organization</TOKEN>
<TOKEN id="token-21-27" pos="word" morph="none" start_char="1772" end_char="1774">has</TOKEN>
<TOKEN id="token-21-28" pos="word" morph="none" start_char="1776" end_char="1778">yet</TOKEN>
<TOKEN id="token-21-29" pos="word" morph="none" start_char="1780" end_char="1781">to</TOKEN>
<TOKEN id="token-21-30" pos="word" morph="none" start_char="1783" end_char="1789">respond</TOKEN>
<TOKEN id="token-21-31" pos="punct" morph="none" start_char="1790" end_char="1790">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="1793" end_char="1983">
<ORIGINAL_TEXT>As a Futurism reader, we invite you join the Singularity Global Community, our parent company’s forum to discuss futuristic science technology with like-minded people from all over the world.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="1793" end_char="1794">As</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="1796" end_char="1796">a</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="1798" end_char="1805">Futurism</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="1807" end_char="1812">reader</TOKEN>
<TOKEN id="token-22-4" pos="punct" morph="none" start_char="1813" end_char="1813">,</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="1815" end_char="1816">we</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="1818" end_char="1823">invite</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="1825" end_char="1827">you</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="1829" end_char="1832">join</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="1834" end_char="1836">the</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="1838" end_char="1848">Singularity</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="1850" end_char="1855">Global</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="1857" end_char="1865">Community</TOKEN>
<TOKEN id="token-22-13" pos="punct" morph="none" start_char="1866" end_char="1866">,</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="1868" end_char="1870">our</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="1872" end_char="1877">parent</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="1879" end_char="1887">company’s</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="1889" end_char="1893">forum</TOKEN>
<TOKEN id="token-22-18" pos="word" morph="none" start_char="1895" end_char="1896">to</TOKEN>
<TOKEN id="token-22-19" pos="word" morph="none" start_char="1898" end_char="1904">discuss</TOKEN>
<TOKEN id="token-22-20" pos="word" morph="none" start_char="1906" end_char="1915">futuristic</TOKEN>
<TOKEN id="token-22-21" pos="word" morph="none" start_char="1917" end_char="1923">science</TOKEN>
<TOKEN id="token-22-22" pos="word" morph="none" start_char="1925" end_char="1934">technology</TOKEN>
<TOKEN id="token-22-23" pos="word" morph="none" start_char="1936" end_char="1939">with</TOKEN>
<TOKEN id="token-22-24" pos="unknown" morph="none" start_char="1941" end_char="1951">like-minded</TOKEN>
<TOKEN id="token-22-25" pos="word" morph="none" start_char="1953" end_char="1958">people</TOKEN>
<TOKEN id="token-22-26" pos="word" morph="none" start_char="1960" end_char="1963">from</TOKEN>
<TOKEN id="token-22-27" pos="word" morph="none" start_char="1965" end_char="1967">all</TOKEN>
<TOKEN id="token-22-28" pos="word" morph="none" start_char="1969" end_char="1972">over</TOKEN>
<TOKEN id="token-22-29" pos="word" morph="none" start_char="1974" end_char="1976">the</TOKEN>
<TOKEN id="token-22-30" pos="word" morph="none" start_char="1978" end_char="1982">world</TOKEN>
<TOKEN id="token-22-31" pos="punct" morph="none" start_char="1983" end_char="1983">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="1985" end_char="2015">
<ORIGINAL_TEXT>It’s free to join, sign up now!</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="1985" end_char="1988">It’s</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="1990" end_char="1993">free</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="1995" end_char="1996">to</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="1998" end_char="2001">join</TOKEN>
<TOKEN id="token-23-4" pos="punct" morph="none" start_char="2002" end_char="2002">,</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="2004" end_char="2007">sign</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="2009" end_char="2010">up</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="2012" end_char="2014">now</TOKEN>
<TOKEN id="token-23-8" pos="punct" morph="none" start_char="2015" end_char="2015">!</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
