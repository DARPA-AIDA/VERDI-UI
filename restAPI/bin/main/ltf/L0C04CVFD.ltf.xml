<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CVFD" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="14531" raw_text_md5="87f5ade207e10e8b7fcba46caf01e7b9">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="50">
<ORIGINAL_TEXT>Why France is hiding a cheap and tested virus cure</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="3">Why</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="5" end_char="10">France</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="12" end_char="13">is</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="15" end_char="20">hiding</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="22" end_char="22">a</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="24" end_char="28">cheap</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="30" end_char="32">and</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="34" end_char="39">tested</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="41" end_char="45">virus</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="47" end_char="50">cure</TOKEN>
</SEG>
<SEG id="segment-1" start_char="56" end_char="266">
<ORIGINAL_TEXT>Islam Times - What’s going on in the fifth largest economy in the world arguably points to a major collusion scandal in which the French government is helping Big Pharma to profit from the expansion of Covid-19.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="56" end_char="60">Islam</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="62" end_char="66">Times</TOKEN>
<TOKEN id="token-1-2" pos="punct" morph="none" start_char="68" end_char="68">-</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="70" end_char="75">What’s</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="77" end_char="81">going</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="83" end_char="84">on</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="86" end_char="87">in</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="89" end_char="91">the</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="93" end_char="97">fifth</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="99" end_char="105">largest</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="107" end_char="113">economy</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="115" end_char="116">in</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="118" end_char="120">the</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="122" end_char="126">world</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="128" end_char="135">arguably</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="137" end_char="142">points</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="144" end_char="145">to</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="147" end_char="147">a</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="149" end_char="153">major</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="155" end_char="163">collusion</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="165" end_char="171">scandal</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="173" end_char="174">in</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="176" end_char="180">which</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="182" end_char="184">the</TOKEN>
<TOKEN id="token-1-24" pos="word" morph="none" start_char="186" end_char="191">French</TOKEN>
<TOKEN id="token-1-25" pos="word" morph="none" start_char="193" end_char="202">government</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="204" end_char="205">is</TOKEN>
<TOKEN id="token-1-27" pos="word" morph="none" start_char="207" end_char="213">helping</TOKEN>
<TOKEN id="token-1-28" pos="word" morph="none" start_char="215" end_char="217">Big</TOKEN>
<TOKEN id="token-1-29" pos="word" morph="none" start_char="219" end_char="224">Pharma</TOKEN>
<TOKEN id="token-1-30" pos="word" morph="none" start_char="226" end_char="227">to</TOKEN>
<TOKEN id="token-1-31" pos="word" morph="none" start_char="229" end_char="234">profit</TOKEN>
<TOKEN id="token-1-32" pos="word" morph="none" start_char="236" end_char="239">from</TOKEN>
<TOKEN id="token-1-33" pos="word" morph="none" start_char="241" end_char="243">the</TOKEN>
<TOKEN id="token-1-34" pos="word" morph="none" start_char="245" end_char="253">expansion</TOKEN>
<TOKEN id="token-1-35" pos="word" morph="none" start_char="255" end_char="256">of</TOKEN>
<TOKEN id="token-1-36" pos="unknown" morph="none" start_char="258" end_char="265">Covid-19</TOKEN>
<TOKEN id="token-1-37" pos="punct" morph="none" start_char="266" end_char="266">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="268" end_char="324">
<ORIGINAL_TEXT>Informed French citizens are absolutely furious about it.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="268" end_char="275">Informed</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="277" end_char="282">French</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="284" end_char="291">citizens</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="293" end_char="295">are</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="297" end_char="306">absolutely</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="308" end_char="314">furious</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="316" end_char="320">about</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="322" end_char="323">it</TOKEN>
<TOKEN id="token-2-8" pos="punct" morph="none" start_char="324" end_char="324">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="328" end_char="636">
<ORIGINAL_TEXT>My initial question to a serious, unimpeachable Paris source, jurist Valerie Bugault, was about the liaisons dangereuses between Macronism and Big Pharma and especially about the mysterious "disappearance" – more likely outright theft – of all the stocks of chloroquine in possession of the French government.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="328" end_char="329">My</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="331" end_char="337">initial</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="339" end_char="346">question</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="348" end_char="349">to</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="351" end_char="351">a</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="353" end_char="359">serious</TOKEN>
<TOKEN id="token-3-6" pos="punct" morph="none" start_char="360" end_char="360">,</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="362" end_char="374">unimpeachable</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="376" end_char="380">Paris</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="382" end_char="387">source</TOKEN>
<TOKEN id="token-3-10" pos="punct" morph="none" start_char="388" end_char="388">,</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="390" end_char="395">jurist</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="397" end_char="403">Valerie</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="405" end_char="411">Bugault</TOKEN>
<TOKEN id="token-3-14" pos="punct" morph="none" start_char="412" end_char="412">,</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="414" end_char="416">was</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="418" end_char="422">about</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="424" end_char="426">the</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="428" end_char="435">liaisons</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="437" end_char="447">dangereuses</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="449" end_char="455">between</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="457" end_char="465">Macronism</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="467" end_char="469">and</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="471" end_char="473">Big</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="475" end_char="480">Pharma</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="482" end_char="484">and</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="486" end_char="495">especially</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="497" end_char="501">about</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="503" end_char="505">the</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="507" end_char="516">mysterious</TOKEN>
<TOKEN id="token-3-30" pos="punct" morph="none" start_char="518" end_char="518">"</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="519" end_char="531">disappearance</TOKEN>
<TOKEN id="token-3-32" pos="punct" morph="none" start_char="532" end_char="532">"</TOKEN>
<TOKEN id="token-3-33" pos="punct" morph="none" start_char="534" end_char="534">–</TOKEN>
<TOKEN id="token-3-34" pos="word" morph="none" start_char="536" end_char="539">more</TOKEN>
<TOKEN id="token-3-35" pos="word" morph="none" start_char="541" end_char="546">likely</TOKEN>
<TOKEN id="token-3-36" pos="word" morph="none" start_char="548" end_char="555">outright</TOKEN>
<TOKEN id="token-3-37" pos="word" morph="none" start_char="557" end_char="561">theft</TOKEN>
<TOKEN id="token-3-38" pos="punct" morph="none" start_char="563" end_char="563">–</TOKEN>
<TOKEN id="token-3-39" pos="word" morph="none" start_char="565" end_char="566">of</TOKEN>
<TOKEN id="token-3-40" pos="word" morph="none" start_char="568" end_char="570">all</TOKEN>
<TOKEN id="token-3-41" pos="word" morph="none" start_char="572" end_char="574">the</TOKEN>
<TOKEN id="token-3-42" pos="word" morph="none" start_char="576" end_char="581">stocks</TOKEN>
<TOKEN id="token-3-43" pos="word" morph="none" start_char="583" end_char="584">of</TOKEN>
<TOKEN id="token-3-44" pos="word" morph="none" start_char="586" end_char="596">chloroquine</TOKEN>
<TOKEN id="token-3-45" pos="word" morph="none" start_char="598" end_char="599">in</TOKEN>
<TOKEN id="token-3-46" pos="word" morph="none" start_char="601" end_char="610">possession</TOKEN>
<TOKEN id="token-3-47" pos="word" morph="none" start_char="612" end_char="613">of</TOKEN>
<TOKEN id="token-3-48" pos="word" morph="none" start_char="615" end_char="617">the</TOKEN>
<TOKEN id="token-3-49" pos="word" morph="none" start_char="619" end_char="624">French</TOKEN>
<TOKEN id="token-3-50" pos="word" morph="none" start_char="626" end_char="635">government</TOKEN>
<TOKEN id="token-3-51" pos="punct" morph="none" start_char="636" end_char="636">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="639" end_char="874">
<ORIGINAL_TEXT>Respected Professor Christian Perronne talked about the theft live in one of France’s 24/7 info channels: "The central pharmacy for the hospitals announced today that they were facing a total rupture of stocks, that they were pillaged."</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="639" end_char="647">Respected</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="649" end_char="657">Professor</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="659" end_char="667">Christian</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="669" end_char="676">Perronne</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="678" end_char="683">talked</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="685" end_char="689">about</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="691" end_char="693">the</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="695" end_char="699">theft</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="701" end_char="704">live</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="706" end_char="707">in</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="709" end_char="711">one</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="713" end_char="714">of</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="716" end_char="723">France’s</TOKEN>
<TOKEN id="token-4-13" pos="unknown" morph="none" start_char="725" end_char="728">24/7</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="730" end_char="733">info</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="735" end_char="742">channels</TOKEN>
<TOKEN id="token-4-16" pos="punct" morph="none" start_char="743" end_char="743">:</TOKEN>
<TOKEN id="token-4-17" pos="punct" morph="none" start_char="745" end_char="745">"</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="746" end_char="748">The</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="750" end_char="756">central</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="758" end_char="765">pharmacy</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="767" end_char="769">for</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="771" end_char="773">the</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="775" end_char="783">hospitals</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="785" end_char="793">announced</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="795" end_char="799">today</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="801" end_char="804">that</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="806" end_char="809">they</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="811" end_char="814">were</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="816" end_char="821">facing</TOKEN>
<TOKEN id="token-4-30" pos="word" morph="none" start_char="823" end_char="823">a</TOKEN>
<TOKEN id="token-4-31" pos="word" morph="none" start_char="825" end_char="829">total</TOKEN>
<TOKEN id="token-4-32" pos="word" morph="none" start_char="831" end_char="837">rupture</TOKEN>
<TOKEN id="token-4-33" pos="word" morph="none" start_char="839" end_char="840">of</TOKEN>
<TOKEN id="token-4-34" pos="word" morph="none" start_char="842" end_char="847">stocks</TOKEN>
<TOKEN id="token-4-35" pos="punct" morph="none" start_char="848" end_char="848">,</TOKEN>
<TOKEN id="token-4-36" pos="word" morph="none" start_char="850" end_char="853">that</TOKEN>
<TOKEN id="token-4-37" pos="word" morph="none" start_char="855" end_char="858">they</TOKEN>
<TOKEN id="token-4-38" pos="word" morph="none" start_char="860" end_char="863">were</TOKEN>
<TOKEN id="token-4-39" pos="word" morph="none" start_char="865" end_char="872">pillaged</TOKEN>
<TOKEN id="token-4-40" pos="punct" morph="none" start_char="873" end_char="874">."</TOKEN>
</SEG>
<SEG id="segment-5" start_char="877" end_char="1042">
<ORIGINAL_TEXT>With input from another, anonymous source, it’s now possible to establish a timeline that puts in much-needed perspective the recent actions of the French government.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="877" end_char="880">With</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="882" end_char="886">input</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="888" end_char="891">from</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="893" end_char="899">another</TOKEN>
<TOKEN id="token-5-4" pos="punct" morph="none" start_char="900" end_char="900">,</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="902" end_char="910">anonymous</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="912" end_char="917">source</TOKEN>
<TOKEN id="token-5-7" pos="punct" morph="none" start_char="918" end_char="918">,</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="920" end_char="923">it’s</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="925" end_char="927">now</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="929" end_char="936">possible</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="938" end_char="939">to</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="941" end_char="949">establish</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="951" end_char="951">a</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="953" end_char="960">timeline</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="962" end_char="965">that</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="967" end_char="970">puts</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="972" end_char="973">in</TOKEN>
<TOKEN id="token-5-18" pos="unknown" morph="none" start_char="975" end_char="985">much-needed</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="987" end_char="997">perspective</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="999" end_char="1001">the</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="1003" end_char="1008">recent</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="1010" end_char="1016">actions</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="1018" end_char="1019">of</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="1021" end_char="1023">the</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="1025" end_char="1030">French</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="1032" end_char="1041">government</TOKEN>
<TOKEN id="token-5-27" pos="punct" morph="none" start_char="1042" end_char="1042">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="1045" end_char="1268">
<ORIGINAL_TEXT>Let’s start with Yves Levy, who was the head of INSERM – the French National Institute of Health and Medical Research – from 2014 to 2018, when he was appointed as extraordinary state councilor for the Macron administration.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="1045" end_char="1049">Let’s</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="1051" end_char="1055">start</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="1057" end_char="1060">with</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="1062" end_char="1065">Yves</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="1067" end_char="1070">Levy</TOKEN>
<TOKEN id="token-6-5" pos="punct" morph="none" start_char="1071" end_char="1071">,</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="1073" end_char="1075">who</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="1077" end_char="1079">was</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="1081" end_char="1083">the</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="1085" end_char="1088">head</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="1090" end_char="1091">of</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="1093" end_char="1098">INSERM</TOKEN>
<TOKEN id="token-6-12" pos="punct" morph="none" start_char="1100" end_char="1100">–</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="1102" end_char="1104">the</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="1106" end_char="1111">French</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="1113" end_char="1120">National</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="1122" end_char="1130">Institute</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="1132" end_char="1133">of</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="1135" end_char="1140">Health</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="1142" end_char="1144">and</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="1146" end_char="1152">Medical</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="1154" end_char="1161">Research</TOKEN>
<TOKEN id="token-6-22" pos="punct" morph="none" start_char="1163" end_char="1163">–</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="1165" end_char="1168">from</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="1170" end_char="1173">2014</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="1175" end_char="1176">to</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="1178" end_char="1181">2018</TOKEN>
<TOKEN id="token-6-27" pos="punct" morph="none" start_char="1182" end_char="1182">,</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="1184" end_char="1187">when</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="1189" end_char="1190">he</TOKEN>
<TOKEN id="token-6-30" pos="word" morph="none" start_char="1192" end_char="1194">was</TOKEN>
<TOKEN id="token-6-31" pos="word" morph="none" start_char="1196" end_char="1204">appointed</TOKEN>
<TOKEN id="token-6-32" pos="word" morph="none" start_char="1206" end_char="1207">as</TOKEN>
<TOKEN id="token-6-33" pos="word" morph="none" start_char="1209" end_char="1221">extraordinary</TOKEN>
<TOKEN id="token-6-34" pos="word" morph="none" start_char="1223" end_char="1227">state</TOKEN>
<TOKEN id="token-6-35" pos="word" morph="none" start_char="1229" end_char="1237">councilor</TOKEN>
<TOKEN id="token-6-36" pos="word" morph="none" start_char="1239" end_char="1241">for</TOKEN>
<TOKEN id="token-6-37" pos="word" morph="none" start_char="1243" end_char="1245">the</TOKEN>
<TOKEN id="token-6-38" pos="word" morph="none" start_char="1247" end_char="1252">Macron</TOKEN>
<TOKEN id="token-6-39" pos="word" morph="none" start_char="1254" end_char="1267">administration</TOKEN>
<TOKEN id="token-6-40" pos="punct" morph="none" start_char="1268" end_char="1268">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="1270" end_char="1319">
<ORIGINAL_TEXT>Only 12 people in France have reached this status.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="1270" end_char="1273">Only</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="1275" end_char="1276">12</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="1278" end_char="1283">people</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="1285" end_char="1286">in</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="1288" end_char="1293">France</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="1295" end_char="1298">have</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="1300" end_char="1306">reached</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="1308" end_char="1311">this</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="1313" end_char="1318">status</TOKEN>
<TOKEN id="token-7-9" pos="punct" morph="none" start_char="1319" end_char="1319">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1322" end_char="1407">
<ORIGINAL_TEXT>Levy is married to Agnes Buzy, who until recently was minister of health under Macron.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1322" end_char="1325">Levy</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1327" end_char="1328">is</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1330" end_char="1336">married</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1338" end_char="1339">to</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1341" end_char="1345">Agnes</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1347" end_char="1350">Buzy</TOKEN>
<TOKEN id="token-8-6" pos="punct" morph="none" start_char="1351" end_char="1351">,</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1353" end_char="1355">who</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1357" end_char="1361">until</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1363" end_char="1370">recently</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1372" end_char="1374">was</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1376" end_char="1383">minister</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1385" end_char="1386">of</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1388" end_char="1393">health</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1395" end_char="1399">under</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1401" end_char="1406">Macron</TOKEN>
<TOKEN id="token-8-16" pos="punct" morph="none" start_char="1407" end_char="1407">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1409" end_char="1650">
<ORIGINAL_TEXT>Buzy was essentially presented with an "offer you can’t refuse" by Macron’s party to leave the ministry – in the middle of the coronavirus crisis – and run for Mayor of Paris, where she was mercilessly trounced in the first round on March 16.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1409" end_char="1412">Buzy</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1414" end_char="1416">was</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1418" end_char="1428">essentially</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1430" end_char="1438">presented</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1440" end_char="1443">with</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1445" end_char="1446">an</TOKEN>
<TOKEN id="token-9-6" pos="punct" morph="none" start_char="1448" end_char="1448">"</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1449" end_char="1453">offer</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1455" end_char="1457">you</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1459" end_char="1463">can’t</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1465" end_char="1470">refuse</TOKEN>
<TOKEN id="token-9-11" pos="punct" morph="none" start_char="1471" end_char="1471">"</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1473" end_char="1474">by</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1476" end_char="1483">Macron’s</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1485" end_char="1489">party</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1491" end_char="1492">to</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1494" end_char="1498">leave</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1500" end_char="1502">the</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1504" end_char="1511">ministry</TOKEN>
<TOKEN id="token-9-19" pos="punct" morph="none" start_char="1513" end_char="1513">–</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1515" end_char="1516">in</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1518" end_char="1520">the</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1522" end_char="1527">middle</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1529" end_char="1530">of</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1532" end_char="1534">the</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1536" end_char="1546">coronavirus</TOKEN>
<TOKEN id="token-9-26" pos="word" morph="none" start_char="1548" end_char="1553">crisis</TOKEN>
<TOKEN id="token-9-27" pos="punct" morph="none" start_char="1555" end_char="1555">–</TOKEN>
<TOKEN id="token-9-28" pos="word" morph="none" start_char="1557" end_char="1559">and</TOKEN>
<TOKEN id="token-9-29" pos="word" morph="none" start_char="1561" end_char="1563">run</TOKEN>
<TOKEN id="token-9-30" pos="word" morph="none" start_char="1565" end_char="1567">for</TOKEN>
<TOKEN id="token-9-31" pos="word" morph="none" start_char="1569" end_char="1573">Mayor</TOKEN>
<TOKEN id="token-9-32" pos="word" morph="none" start_char="1575" end_char="1576">of</TOKEN>
<TOKEN id="token-9-33" pos="word" morph="none" start_char="1578" end_char="1582">Paris</TOKEN>
<TOKEN id="token-9-34" pos="punct" morph="none" start_char="1583" end_char="1583">,</TOKEN>
<TOKEN id="token-9-35" pos="word" morph="none" start_char="1585" end_char="1589">where</TOKEN>
<TOKEN id="token-9-36" pos="word" morph="none" start_char="1591" end_char="1593">she</TOKEN>
<TOKEN id="token-9-37" pos="word" morph="none" start_char="1595" end_char="1597">was</TOKEN>
<TOKEN id="token-9-38" pos="word" morph="none" start_char="1599" end_char="1609">mercilessly</TOKEN>
<TOKEN id="token-9-39" pos="word" morph="none" start_char="1611" end_char="1618">trounced</TOKEN>
<TOKEN id="token-9-40" pos="word" morph="none" start_char="1620" end_char="1621">in</TOKEN>
<TOKEN id="token-9-41" pos="word" morph="none" start_char="1623" end_char="1625">the</TOKEN>
<TOKEN id="token-9-42" pos="word" morph="none" start_char="1627" end_char="1631">first</TOKEN>
<TOKEN id="token-9-43" pos="word" morph="none" start_char="1633" end_char="1637">round</TOKEN>
<TOKEN id="token-9-44" pos="word" morph="none" start_char="1639" end_char="1640">on</TOKEN>
<TOKEN id="token-9-45" pos="word" morph="none" start_char="1642" end_char="1646">March</TOKEN>
<TOKEN id="token-9-46" pos="word" morph="none" start_char="1648" end_char="1649">16</TOKEN>
<TOKEN id="token-9-47" pos="punct" morph="none" start_char="1650" end_char="1650">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1653" end_char="1792">
<ORIGINAL_TEXT>Levy has a vicious running feud with Professor Didier Raoult – prolific and often-cited Marseille-based specialist in communicable diseases.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1653" end_char="1656">Levy</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1658" end_char="1660">has</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1662" end_char="1662">a</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1664" end_char="1670">vicious</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1672" end_char="1678">running</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1680" end_char="1683">feud</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1685" end_char="1688">with</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1690" end_char="1698">Professor</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1700" end_char="1705">Didier</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1707" end_char="1712">Raoult</TOKEN>
<TOKEN id="token-10-10" pos="punct" morph="none" start_char="1714" end_char="1714">–</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1716" end_char="1723">prolific</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1725" end_char="1727">and</TOKEN>
<TOKEN id="token-10-13" pos="unknown" morph="none" start_char="1729" end_char="1739">often-cited</TOKEN>
<TOKEN id="token-10-14" pos="unknown" morph="none" start_char="1741" end_char="1755">Marseille-based</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1757" end_char="1766">specialist</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1768" end_char="1769">in</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1771" end_char="1782">communicable</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1784" end_char="1791">diseases</TOKEN>
<TOKEN id="token-10-19" pos="punct" morph="none" start_char="1792" end_char="1792">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1794" end_char="1919">
<ORIGINAL_TEXT>Levy withheld the INSERM label from the world-renowned IHU (Hospital-University Institute) research center directed by Raoult.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1794" end_char="1797">Levy</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1799" end_char="1806">withheld</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1808" end_char="1810">the</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1812" end_char="1817">INSERM</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1819" end_char="1823">label</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1825" end_char="1828">from</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1830" end_char="1832">the</TOKEN>
<TOKEN id="token-11-7" pos="unknown" morph="none" start_char="1834" end_char="1847">world-renowned</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1849" end_char="1851">IHU</TOKEN>
<TOKEN id="token-11-9" pos="punct" morph="none" start_char="1853" end_char="1853">(</TOKEN>
<TOKEN id="token-11-10" pos="unknown" morph="none" start_char="1854" end_char="1872">Hospital-University</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1874" end_char="1882">Institute</TOKEN>
<TOKEN id="token-11-12" pos="punct" morph="none" start_char="1883" end_char="1883">)</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1885" end_char="1892">research</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1894" end_char="1899">center</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1901" end_char="1908">directed</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1910" end_char="1911">by</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1913" end_char="1918">Raoult</TOKEN>
<TOKEN id="token-11-18" pos="punct" morph="none" start_char="1919" end_char="1919">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1922" end_char="2050">
<ORIGINAL_TEXT>In practice, in October 2019, Levy revoked the status of "foundation" of the different IHUs so he could take over their research.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1922" end_char="1923">In</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1925" end_char="1932">practice</TOKEN>
<TOKEN id="token-12-2" pos="punct" morph="none" start_char="1933" end_char="1933">,</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1935" end_char="1936">in</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1938" end_char="1944">October</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1946" end_char="1949">2019</TOKEN>
<TOKEN id="token-12-6" pos="punct" morph="none" start_char="1950" end_char="1950">,</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1952" end_char="1955">Levy</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1957" end_char="1963">revoked</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1965" end_char="1967">the</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1969" end_char="1974">status</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1976" end_char="1977">of</TOKEN>
<TOKEN id="token-12-12" pos="punct" morph="none" start_char="1979" end_char="1979">"</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1980" end_char="1989">foundation</TOKEN>
<TOKEN id="token-12-14" pos="punct" morph="none" start_char="1990" end_char="1990">"</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1992" end_char="1993">of</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1995" end_char="1997">the</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1999" end_char="2007">different</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="2009" end_char="2012">IHUs</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="2014" end_char="2015">so</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="2017" end_char="2018">he</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="2020" end_char="2024">could</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="2026" end_char="2029">take</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="2031" end_char="2034">over</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="2036" end_char="2040">their</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="2042" end_char="2049">research</TOKEN>
<TOKEN id="token-12-26" pos="punct" morph="none" start_char="2050" end_char="2050">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="2053" end_char="2198">
<ORIGINAL_TEXT>Raoult was part of a clinical trial that in which hydroxychloroquine and azithromycin healed 90% of Covid-19 cases if they were tested very early.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="2053" end_char="2058">Raoult</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="2060" end_char="2062">was</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="2064" end_char="2067">part</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="2069" end_char="2070">of</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="2072" end_char="2072">a</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="2074" end_char="2081">clinical</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="2083" end_char="2087">trial</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="2089" end_char="2092">that</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="2094" end_char="2095">in</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="2097" end_char="2101">which</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="2103" end_char="2120">hydroxychloroquine</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="2122" end_char="2124">and</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="2126" end_char="2137">azithromycin</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="2139" end_char="2144">healed</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="2146" end_char="2147">90</TOKEN>
<TOKEN id="token-13-15" pos="punct" morph="none" start_char="2148" end_char="2148">%</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="2150" end_char="2151">of</TOKEN>
<TOKEN id="token-13-17" pos="unknown" morph="none" start_char="2153" end_char="2160">Covid-19</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="2162" end_char="2166">cases</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="2168" end_char="2169">if</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="2171" end_char="2174">they</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="2176" end_char="2179">were</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="2181" end_char="2186">tested</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="2188" end_char="2191">very</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="2193" end_char="2197">early</TOKEN>
<TOKEN id="token-13-25" pos="punct" morph="none" start_char="2198" end_char="2198">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="2200" end_char="2280">
<ORIGINAL_TEXT>(Early, massive testing is at the heart of the successful South Korean strategy.)</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="punct" morph="none" start_char="2200" end_char="2200">(</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="2201" end_char="2205">Early</TOKEN>
<TOKEN id="token-14-2" pos="punct" morph="none" start_char="2206" end_char="2206">,</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="2208" end_char="2214">massive</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="2216" end_char="2222">testing</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="2224" end_char="2225">is</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="2227" end_char="2228">at</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="2230" end_char="2232">the</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="2234" end_char="2238">heart</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="2240" end_char="2241">of</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="2243" end_char="2245">the</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="2247" end_char="2256">successful</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="2258" end_char="2262">South</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="2264" end_char="2269">Korean</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="2271" end_char="2278">strategy</TOKEN>
<TOKEN id="token-14-15" pos="punct" morph="none" start_char="2279" end_char="2280">.)</TOKEN>
</SEG>
<SEG id="segment-15" start_char="2283" end_char="2423">
<ORIGINAL_TEXT>Raoult is opposed to the total lockdown of sane individuals and possible carriers – which he considers "medieval," in an anachronistic sense.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="2283" end_char="2288">Raoult</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="2290" end_char="2291">is</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="2293" end_char="2299">opposed</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="2301" end_char="2302">to</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="2304" end_char="2306">the</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="2308" end_char="2312">total</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="2314" end_char="2321">lockdown</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="2323" end_char="2324">of</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="2326" end_char="2329">sane</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="2331" end_char="2341">individuals</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="2343" end_char="2345">and</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="2347" end_char="2354">possible</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="2356" end_char="2363">carriers</TOKEN>
<TOKEN id="token-15-13" pos="punct" morph="none" start_char="2365" end_char="2365">–</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="2367" end_char="2371">which</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="2373" end_char="2374">he</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="2376" end_char="2384">considers</TOKEN>
<TOKEN id="token-15-17" pos="punct" morph="none" start_char="2386" end_char="2386">"</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="2387" end_char="2394">medieval</TOKEN>
<TOKEN id="token-15-19" pos="punct" morph="none" start_char="2395" end_char="2396">,"</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="2398" end_char="2399">in</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="2401" end_char="2402">an</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="2404" end_char="2416">anachronistic</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="2418" end_char="2422">sense</TOKEN>
<TOKEN id="token-15-24" pos="punct" morph="none" start_char="2423" end_char="2423">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="2425" end_char="2580">
<ORIGINAL_TEXT>He’s in favor of massive testing (which, besides South Korea, was successful in Singapore, Taiwan and Vietnam) and a fast treatment with hydroxychloroquine.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="2425" end_char="2428">He’s</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="2430" end_char="2431">in</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="2433" end_char="2437">favor</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="2439" end_char="2440">of</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="2442" end_char="2448">massive</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="2450" end_char="2456">testing</TOKEN>
<TOKEN id="token-16-6" pos="punct" morph="none" start_char="2458" end_char="2458">(</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="2459" end_char="2463">which</TOKEN>
<TOKEN id="token-16-8" pos="punct" morph="none" start_char="2464" end_char="2464">,</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="2466" end_char="2472">besides</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="2474" end_char="2478">South</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="2480" end_char="2484">Korea</TOKEN>
<TOKEN id="token-16-12" pos="punct" morph="none" start_char="2485" end_char="2485">,</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="2487" end_char="2489">was</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="2491" end_char="2500">successful</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="2502" end_char="2503">in</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="2505" end_char="2513">Singapore</TOKEN>
<TOKEN id="token-16-17" pos="punct" morph="none" start_char="2514" end_char="2514">,</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="2516" end_char="2521">Taiwan</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="2523" end_char="2525">and</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="2527" end_char="2533">Vietnam</TOKEN>
<TOKEN id="token-16-21" pos="punct" morph="none" start_char="2534" end_char="2534">)</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="2536" end_char="2538">and</TOKEN>
<TOKEN id="token-16-23" pos="word" morph="none" start_char="2540" end_char="2540">a</TOKEN>
<TOKEN id="token-16-24" pos="word" morph="none" start_char="2542" end_char="2545">fast</TOKEN>
<TOKEN id="token-16-25" pos="word" morph="none" start_char="2547" end_char="2555">treatment</TOKEN>
<TOKEN id="token-16-26" pos="word" morph="none" start_char="2557" end_char="2560">with</TOKEN>
<TOKEN id="token-16-27" pos="word" morph="none" start_char="2562" end_char="2579">hydroxychloroquine</TOKEN>
<TOKEN id="token-16-28" pos="punct" morph="none" start_char="2580" end_char="2580">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2582" end_char="2630">
<ORIGINAL_TEXT>Only contaminated individuals should be confined.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2582" end_char="2585">Only</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2587" end_char="2598">contaminated</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2600" end_char="2610">individuals</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2612" end_char="2617">should</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2619" end_char="2620">be</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2622" end_char="2629">confined</TOKEN>
<TOKEN id="token-17-6" pos="punct" morph="none" start_char="2630" end_char="2630">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2633" end_char="2673">
<ORIGINAL_TEXT>Chloroquine costs one euro for ten pills.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2633" end_char="2643">Chloroquine</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2645" end_char="2649">costs</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2651" end_char="2653">one</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2655" end_char="2658">euro</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2660" end_char="2662">for</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2664" end_char="2666">ten</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2668" end_char="2672">pills</TOKEN>
<TOKEN id="token-18-7" pos="punct" morph="none" start_char="2673" end_char="2673">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2675" end_char="2836">
<ORIGINAL_TEXT>And there’s the rub: Big Pharma – which, crucially, finances INSERM, and includes "national champion" Sanofi – would rather go for a way more profitable solution.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2675" end_char="2677">And</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2679" end_char="2685">there’s</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2687" end_char="2689">the</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2691" end_char="2693">rub</TOKEN>
<TOKEN id="token-19-4" pos="punct" morph="none" start_char="2694" end_char="2694">:</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2696" end_char="2698">Big</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2700" end_char="2705">Pharma</TOKEN>
<TOKEN id="token-19-7" pos="punct" morph="none" start_char="2707" end_char="2707">–</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2709" end_char="2713">which</TOKEN>
<TOKEN id="token-19-9" pos="punct" morph="none" start_char="2714" end_char="2714">,</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="2716" end_char="2724">crucially</TOKEN>
<TOKEN id="token-19-11" pos="punct" morph="none" start_char="2725" end_char="2725">,</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="2727" end_char="2734">finances</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="2736" end_char="2741">INSERM</TOKEN>
<TOKEN id="token-19-14" pos="punct" morph="none" start_char="2742" end_char="2742">,</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="2744" end_char="2746">and</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="2748" end_char="2755">includes</TOKEN>
<TOKEN id="token-19-17" pos="punct" morph="none" start_char="2757" end_char="2757">"</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="2758" end_char="2765">national</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="2767" end_char="2774">champion</TOKEN>
<TOKEN id="token-19-20" pos="punct" morph="none" start_char="2775" end_char="2775">"</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="2777" end_char="2782">Sanofi</TOKEN>
<TOKEN id="token-19-22" pos="punct" morph="none" start_char="2784" end_char="2784">–</TOKEN>
<TOKEN id="token-19-23" pos="word" morph="none" start_char="2786" end_char="2790">would</TOKEN>
<TOKEN id="token-19-24" pos="word" morph="none" start_char="2792" end_char="2797">rather</TOKEN>
<TOKEN id="token-19-25" pos="word" morph="none" start_char="2799" end_char="2800">go</TOKEN>
<TOKEN id="token-19-26" pos="word" morph="none" start_char="2802" end_char="2804">for</TOKEN>
<TOKEN id="token-19-27" pos="word" morph="none" start_char="2806" end_char="2806">a</TOKEN>
<TOKEN id="token-19-28" pos="word" morph="none" start_char="2808" end_char="2810">way</TOKEN>
<TOKEN id="token-19-29" pos="word" morph="none" start_char="2812" end_char="2815">more</TOKEN>
<TOKEN id="token-19-30" pos="word" morph="none" start_char="2817" end_char="2826">profitable</TOKEN>
<TOKEN id="token-19-31" pos="word" morph="none" start_char="2828" end_char="2835">solution</TOKEN>
<TOKEN id="token-19-32" pos="punct" morph="none" start_char="2836" end_char="2836">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2838" end_char="2979">
<ORIGINAL_TEXT>Sanofi for the moment says it is "actively preparing" to produce chloroquine, but that may take "weeks," and there’s no mention about pricing.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2838" end_char="2843">Sanofi</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2845" end_char="2847">for</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2849" end_char="2851">the</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2853" end_char="2858">moment</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2860" end_char="2863">says</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2865" end_char="2866">it</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2868" end_char="2869">is</TOKEN>
<TOKEN id="token-20-7" pos="punct" morph="none" start_char="2871" end_char="2871">"</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="2872" end_char="2879">actively</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2881" end_char="2889">preparing</TOKEN>
<TOKEN id="token-20-10" pos="punct" morph="none" start_char="2890" end_char="2890">"</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="2892" end_char="2893">to</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="2895" end_char="2901">produce</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="2903" end_char="2913">chloroquine</TOKEN>
<TOKEN id="token-20-14" pos="punct" morph="none" start_char="2914" end_char="2914">,</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="2916" end_char="2918">but</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="2920" end_char="2923">that</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="2925" end_char="2927">may</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="2929" end_char="2932">take</TOKEN>
<TOKEN id="token-20-19" pos="punct" morph="none" start_char="2934" end_char="2934">"</TOKEN>
<TOKEN id="token-20-20" pos="word" morph="none" start_char="2935" end_char="2939">weeks</TOKEN>
<TOKEN id="token-20-21" pos="punct" morph="none" start_char="2940" end_char="2941">,"</TOKEN>
<TOKEN id="token-20-22" pos="word" morph="none" start_char="2943" end_char="2945">and</TOKEN>
<TOKEN id="token-20-23" pos="word" morph="none" start_char="2947" end_char="2953">there’s</TOKEN>
<TOKEN id="token-20-24" pos="word" morph="none" start_char="2955" end_char="2956">no</TOKEN>
<TOKEN id="token-20-25" pos="word" morph="none" start_char="2958" end_char="2964">mention</TOKEN>
<TOKEN id="token-20-26" pos="word" morph="none" start_char="2966" end_char="2970">about</TOKEN>
<TOKEN id="token-20-27" pos="word" morph="none" start_char="2972" end_char="2978">pricing</TOKEN>
<TOKEN id="token-20-28" pos="punct" morph="none" start_char="2979" end_char="2979">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2982" end_char="3009">
<ORIGINAL_TEXT>A minister fleeing a tsunami</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2982" end_char="2982">A</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2984" end_char="2991">minister</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2993" end_char="2999">fleeing</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="3001" end_char="3001">a</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="3003" end_char="3009">tsunami</TOKEN>
</SEG>
<SEG id="segment-22" start_char="3012" end_char="3031">
<ORIGINAL_TEXT>Here’s the timeline:</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="3012" end_char="3017">Here’s</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="3019" end_char="3021">the</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="3023" end_char="3030">timeline</TOKEN>
<TOKEN id="token-22-3" pos="punct" morph="none" start_char="3031" end_char="3031">:</TOKEN>
</SEG>
<SEG id="segment-23" start_char="3034" end_char="3187">
<ORIGINAL_TEXT>On January 13, Agnes Buzyn, still France’s Health Minister, classifies chloroquine as a "poisonous substance," from now on only available by prescription.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="3034" end_char="3035">On</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="3037" end_char="3043">January</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="3045" end_char="3046">13</TOKEN>
<TOKEN id="token-23-3" pos="punct" morph="none" start_char="3047" end_char="3047">,</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="3049" end_char="3053">Agnes</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="3055" end_char="3059">Buzyn</TOKEN>
<TOKEN id="token-23-6" pos="punct" morph="none" start_char="3060" end_char="3060">,</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="3062" end_char="3066">still</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="3068" end_char="3075">France’s</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="3077" end_char="3082">Health</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="3084" end_char="3091">Minister</TOKEN>
<TOKEN id="token-23-11" pos="punct" morph="none" start_char="3092" end_char="3092">,</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="3094" end_char="3103">classifies</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="3105" end_char="3115">chloroquine</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="3117" end_char="3118">as</TOKEN>
<TOKEN id="token-23-15" pos="word" morph="none" start_char="3120" end_char="3120">a</TOKEN>
<TOKEN id="token-23-16" pos="punct" morph="none" start_char="3122" end_char="3122">"</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="3123" end_char="3131">poisonous</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="3133" end_char="3141">substance</TOKEN>
<TOKEN id="token-23-19" pos="punct" morph="none" start_char="3142" end_char="3143">,"</TOKEN>
<TOKEN id="token-23-20" pos="word" morph="none" start_char="3145" end_char="3148">from</TOKEN>
<TOKEN id="token-23-21" pos="word" morph="none" start_char="3150" end_char="3152">now</TOKEN>
<TOKEN id="token-23-22" pos="word" morph="none" start_char="3154" end_char="3155">on</TOKEN>
<TOKEN id="token-23-23" pos="word" morph="none" start_char="3157" end_char="3160">only</TOKEN>
<TOKEN id="token-23-24" pos="word" morph="none" start_char="3162" end_char="3170">available</TOKEN>
<TOKEN id="token-23-25" pos="word" morph="none" start_char="3172" end_char="3173">by</TOKEN>
<TOKEN id="token-23-26" pos="word" morph="none" start_char="3175" end_char="3186">prescription</TOKEN>
<TOKEN id="token-23-27" pos="punct" morph="none" start_char="3187" end_char="3187">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="3189" end_char="3286">
<ORIGINAL_TEXT>An astonishing move, considering that it has been sold off the shelf in France for half a century.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="3189" end_char="3190">An</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="3192" end_char="3202">astonishing</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="3204" end_char="3207">move</TOKEN>
<TOKEN id="token-24-3" pos="punct" morph="none" start_char="3208" end_char="3208">,</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="3210" end_char="3220">considering</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="3222" end_char="3225">that</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="3227" end_char="3228">it</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="3230" end_char="3232">has</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="3234" end_char="3237">been</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="3239" end_char="3242">sold</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="3244" end_char="3246">off</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="3248" end_char="3250">the</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="3252" end_char="3256">shelf</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="3258" end_char="3259">in</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="3261" end_char="3266">France</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="3268" end_char="3270">for</TOKEN>
<TOKEN id="token-24-16" pos="word" morph="none" start_char="3272" end_char="3275">half</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="3277" end_char="3277">a</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="3279" end_char="3285">century</TOKEN>
<TOKEN id="token-24-19" pos="punct" morph="none" start_char="3286" end_char="3286">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="3289" end_char="3349">
<ORIGINAL_TEXT>On March 16, the Macron government orders a partial lockdown.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="3289" end_char="3290">On</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="3292" end_char="3296">March</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="3298" end_char="3299">16</TOKEN>
<TOKEN id="token-25-3" pos="punct" morph="none" start_char="3300" end_char="3300">,</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="3302" end_char="3304">the</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="3306" end_char="3311">Macron</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="3313" end_char="3322">government</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="3324" end_char="3329">orders</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="3331" end_char="3331">a</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="3333" end_char="3339">partial</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="3341" end_char="3348">lockdown</TOKEN>
<TOKEN id="token-25-11" pos="punct" morph="none" start_char="3349" end_char="3349">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="3351" end_char="3387">
<ORIGINAL_TEXT>There’s not a peep about chloroquine.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="3351" end_char="3357">There’s</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="3359" end_char="3361">not</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="3363" end_char="3363">a</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="3365" end_char="3368">peep</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="3370" end_char="3374">about</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="3376" end_char="3386">chloroquine</TOKEN>
<TOKEN id="token-26-6" pos="punct" morph="none" start_char="3387" end_char="3387">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="3389" end_char="3522">
<ORIGINAL_TEXT>Police initially are not required to wear masks; most have been stolen anyway, and there are not enough masks even for health workers.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="3389" end_char="3394">Police</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="3396" end_char="3404">initially</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="3406" end_char="3408">are</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="3410" end_char="3412">not</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="3414" end_char="3421">required</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="3423" end_char="3424">to</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="3426" end_char="3429">wear</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="3431" end_char="3435">masks</TOKEN>
<TOKEN id="token-27-8" pos="punct" morph="none" start_char="3436" end_char="3436">;</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="3438" end_char="3441">most</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="3443" end_char="3446">have</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="3448" end_char="3451">been</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="3453" end_char="3458">stolen</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="3460" end_char="3465">anyway</TOKEN>
<TOKEN id="token-27-14" pos="punct" morph="none" start_char="3466" end_char="3466">,</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="3468" end_char="3470">and</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="3472" end_char="3476">there</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="3478" end_char="3480">are</TOKEN>
<TOKEN id="token-27-18" pos="word" morph="none" start_char="3482" end_char="3484">not</TOKEN>
<TOKEN id="token-27-19" pos="word" morph="none" start_char="3486" end_char="3491">enough</TOKEN>
<TOKEN id="token-27-20" pos="word" morph="none" start_char="3493" end_char="3497">masks</TOKEN>
<TOKEN id="token-27-21" pos="word" morph="none" start_char="3499" end_char="3502">even</TOKEN>
<TOKEN id="token-27-22" pos="word" morph="none" start_char="3504" end_char="3506">for</TOKEN>
<TOKEN id="token-27-23" pos="word" morph="none" start_char="3508" end_char="3513">health</TOKEN>
<TOKEN id="token-27-24" pos="word" morph="none" start_char="3515" end_char="3521">workers</TOKEN>
<TOKEN id="token-27-25" pos="punct" morph="none" start_char="3522" end_char="3522">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3524" end_char="3652">
<ORIGINAL_TEXT>In 2011 France had nearly 1.5 billion masks: 800 million surgical masks and 600 million masks for health professionals generally.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="3524" end_char="3525">In</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="3527" end_char="3530">2011</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="3532" end_char="3537">France</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="3539" end_char="3541">had</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="3543" end_char="3548">nearly</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="3550" end_char="3552">1.5</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="3554" end_char="3560">billion</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="3562" end_char="3566">masks</TOKEN>
<TOKEN id="token-28-8" pos="punct" morph="none" start_char="3567" end_char="3567">:</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="3569" end_char="3571">800</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="3573" end_char="3579">million</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="3581" end_char="3588">surgical</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="3590" end_char="3594">masks</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="3596" end_char="3598">and</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="3600" end_char="3602">600</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="3604" end_char="3610">million</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="3612" end_char="3616">masks</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="3618" end_char="3620">for</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="3622" end_char="3627">health</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="3629" end_char="3641">professionals</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="3643" end_char="3651">generally</TOKEN>
<TOKEN id="token-28-21" pos="punct" morph="none" start_char="3652" end_char="3652">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3655" end_char="3892">
<ORIGINAL_TEXT>But then, over the years, the strategic stocks were not renewed, to please the EU and to apply the Maastricht criteria, which limited membership in the Growth and Stability Pact to countries whose budget deficits did not exceed 3% of GDP.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="3655" end_char="3657">But</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="3659" end_char="3662">then</TOKEN>
<TOKEN id="token-29-2" pos="punct" morph="none" start_char="3663" end_char="3663">,</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="3665" end_char="3668">over</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="3670" end_char="3672">the</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="3674" end_char="3678">years</TOKEN>
<TOKEN id="token-29-6" pos="punct" morph="none" start_char="3679" end_char="3679">,</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="3681" end_char="3683">the</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="3685" end_char="3693">strategic</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="3695" end_char="3700">stocks</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="3702" end_char="3705">were</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="3707" end_char="3709">not</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="3711" end_char="3717">renewed</TOKEN>
<TOKEN id="token-29-13" pos="punct" morph="none" start_char="3718" end_char="3718">,</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="3720" end_char="3721">to</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="3723" end_char="3728">please</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="3730" end_char="3732">the</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="3734" end_char="3735">EU</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="3737" end_char="3739">and</TOKEN>
<TOKEN id="token-29-19" pos="word" morph="none" start_char="3741" end_char="3742">to</TOKEN>
<TOKEN id="token-29-20" pos="word" morph="none" start_char="3744" end_char="3748">apply</TOKEN>
<TOKEN id="token-29-21" pos="word" morph="none" start_char="3750" end_char="3752">the</TOKEN>
<TOKEN id="token-29-22" pos="word" morph="none" start_char="3754" end_char="3763">Maastricht</TOKEN>
<TOKEN id="token-29-23" pos="word" morph="none" start_char="3765" end_char="3772">criteria</TOKEN>
<TOKEN id="token-29-24" pos="punct" morph="none" start_char="3773" end_char="3773">,</TOKEN>
<TOKEN id="token-29-25" pos="word" morph="none" start_char="3775" end_char="3779">which</TOKEN>
<TOKEN id="token-29-26" pos="word" morph="none" start_char="3781" end_char="3787">limited</TOKEN>
<TOKEN id="token-29-27" pos="word" morph="none" start_char="3789" end_char="3798">membership</TOKEN>
<TOKEN id="token-29-28" pos="word" morph="none" start_char="3800" end_char="3801">in</TOKEN>
<TOKEN id="token-29-29" pos="word" morph="none" start_char="3803" end_char="3805">the</TOKEN>
<TOKEN id="token-29-30" pos="word" morph="none" start_char="3807" end_char="3812">Growth</TOKEN>
<TOKEN id="token-29-31" pos="word" morph="none" start_char="3814" end_char="3816">and</TOKEN>
<TOKEN id="token-29-32" pos="word" morph="none" start_char="3818" end_char="3826">Stability</TOKEN>
<TOKEN id="token-29-33" pos="word" morph="none" start_char="3828" end_char="3831">Pact</TOKEN>
<TOKEN id="token-29-34" pos="word" morph="none" start_char="3833" end_char="3834">to</TOKEN>
<TOKEN id="token-29-35" pos="word" morph="none" start_char="3836" end_char="3844">countries</TOKEN>
<TOKEN id="token-29-36" pos="word" morph="none" start_char="3846" end_char="3850">whose</TOKEN>
<TOKEN id="token-29-37" pos="word" morph="none" start_char="3852" end_char="3857">budget</TOKEN>
<TOKEN id="token-29-38" pos="word" morph="none" start_char="3859" end_char="3866">deficits</TOKEN>
<TOKEN id="token-29-39" pos="word" morph="none" start_char="3868" end_char="3870">did</TOKEN>
<TOKEN id="token-29-40" pos="word" morph="none" start_char="3872" end_char="3874">not</TOKEN>
<TOKEN id="token-29-41" pos="word" morph="none" start_char="3876" end_char="3881">exceed</TOKEN>
<TOKEN id="token-29-42" pos="word" morph="none" start_char="3883" end_char="3883">3</TOKEN>
<TOKEN id="token-29-43" pos="punct" morph="none" start_char="3884" end_char="3884">%</TOKEN>
<TOKEN id="token-29-44" pos="word" morph="none" start_char="3886" end_char="3887">of</TOKEN>
<TOKEN id="token-29-45" pos="word" morph="none" start_char="3889" end_char="3891">GDP</TOKEN>
<TOKEN id="token-29-46" pos="punct" morph="none" start_char="3892" end_char="3892">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3894" end_char="4000">
<ORIGINAL_TEXT>One of those in charge at the time was Jerome Salomon, now a scientific counselor to the Macron government.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="3894" end_char="3896">One</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="3898" end_char="3899">of</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="3901" end_char="3905">those</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="3907" end_char="3908">in</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="3910" end_char="3915">charge</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="3917" end_char="3918">at</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="3920" end_char="3922">the</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="3924" end_char="3927">time</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="3929" end_char="3931">was</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="3933" end_char="3938">Jerome</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="3940" end_char="3946">Salomon</TOKEN>
<TOKEN id="token-30-11" pos="punct" morph="none" start_char="3947" end_char="3947">,</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="3949" end_char="3951">now</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="3953" end_char="3953">a</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="3955" end_char="3964">scientific</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="3966" end_char="3974">counselor</TOKEN>
<TOKEN id="token-30-16" pos="word" morph="none" start_char="3976" end_char="3977">to</TOKEN>
<TOKEN id="token-30-17" pos="word" morph="none" start_char="3979" end_char="3981">the</TOKEN>
<TOKEN id="token-30-18" pos="word" morph="none" start_char="3983" end_char="3988">Macron</TOKEN>
<TOKEN id="token-30-19" pos="word" morph="none" start_char="3990" end_char="3999">government</TOKEN>
<TOKEN id="token-30-20" pos="punct" morph="none" start_char="4000" end_char="4000">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="4003" end_char="4147">
<ORIGINAL_TEXT>On March 17, Agnes Buzyn says she has learned the spread of Covid-19 will be a major tsunami, for which the French health system has no solution.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="4003" end_char="4004">On</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="4006" end_char="4010">March</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="4012" end_char="4013">17</TOKEN>
<TOKEN id="token-31-3" pos="punct" morph="none" start_char="4014" end_char="4014">,</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="4016" end_char="4020">Agnes</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="4022" end_char="4026">Buzyn</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="4028" end_char="4031">says</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="4033" end_char="4035">she</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="4037" end_char="4039">has</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="4041" end_char="4047">learned</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="4049" end_char="4051">the</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="4053" end_char="4058">spread</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="4060" end_char="4061">of</TOKEN>
<TOKEN id="token-31-13" pos="unknown" morph="none" start_char="4063" end_char="4070">Covid-19</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="4072" end_char="4075">will</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="4077" end_char="4078">be</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="4080" end_char="4080">a</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="4082" end_char="4086">major</TOKEN>
<TOKEN id="token-31-18" pos="word" morph="none" start_char="4088" end_char="4094">tsunami</TOKEN>
<TOKEN id="token-31-19" pos="punct" morph="none" start_char="4095" end_char="4095">,</TOKEN>
<TOKEN id="token-31-20" pos="word" morph="none" start_char="4097" end_char="4099">for</TOKEN>
<TOKEN id="token-31-21" pos="word" morph="none" start_char="4101" end_char="4105">which</TOKEN>
<TOKEN id="token-31-22" pos="word" morph="none" start_char="4107" end_char="4109">the</TOKEN>
<TOKEN id="token-31-23" pos="word" morph="none" start_char="4111" end_char="4116">French</TOKEN>
<TOKEN id="token-31-24" pos="word" morph="none" start_char="4118" end_char="4123">health</TOKEN>
<TOKEN id="token-31-25" pos="word" morph="none" start_char="4125" end_char="4130">system</TOKEN>
<TOKEN id="token-31-26" pos="word" morph="none" start_char="4132" end_char="4134">has</TOKEN>
<TOKEN id="token-31-27" pos="word" morph="none" start_char="4136" end_char="4137">no</TOKEN>
<TOKEN id="token-31-28" pos="word" morph="none" start_char="4139" end_char="4146">solution</TOKEN>
<TOKEN id="token-31-29" pos="punct" morph="none" start_char="4147" end_char="4147">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="4149" end_char="4291">
<ORIGINAL_TEXT>She also says it had been her understanding that the Paris mayoral election "would not take place" and that it was, ultimately, "a masquerade."</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="4149" end_char="4151">She</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="4153" end_char="4156">also</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="4158" end_char="4161">says</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="4163" end_char="4164">it</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="4166" end_char="4168">had</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="4170" end_char="4173">been</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="4175" end_char="4177">her</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="4179" end_char="4191">understanding</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="4193" end_char="4196">that</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="4198" end_char="4200">the</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="4202" end_char="4206">Paris</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="4208" end_char="4214">mayoral</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="4216" end_char="4223">election</TOKEN>
<TOKEN id="token-32-13" pos="punct" morph="none" start_char="4225" end_char="4225">"</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="4226" end_char="4230">would</TOKEN>
<TOKEN id="token-32-15" pos="word" morph="none" start_char="4232" end_char="4234">not</TOKEN>
<TOKEN id="token-32-16" pos="word" morph="none" start_char="4236" end_char="4239">take</TOKEN>
<TOKEN id="token-32-17" pos="word" morph="none" start_char="4241" end_char="4245">place</TOKEN>
<TOKEN id="token-32-18" pos="punct" morph="none" start_char="4246" end_char="4246">"</TOKEN>
<TOKEN id="token-32-19" pos="word" morph="none" start_char="4248" end_char="4250">and</TOKEN>
<TOKEN id="token-32-20" pos="word" morph="none" start_char="4252" end_char="4255">that</TOKEN>
<TOKEN id="token-32-21" pos="word" morph="none" start_char="4257" end_char="4258">it</TOKEN>
<TOKEN id="token-32-22" pos="word" morph="none" start_char="4260" end_char="4262">was</TOKEN>
<TOKEN id="token-32-23" pos="punct" morph="none" start_char="4263" end_char="4263">,</TOKEN>
<TOKEN id="token-32-24" pos="word" morph="none" start_char="4265" end_char="4274">ultimately</TOKEN>
<TOKEN id="token-32-25" pos="punct" morph="none" start_char="4275" end_char="4275">,</TOKEN>
<TOKEN id="token-32-26" pos="punct" morph="none" start_char="4277" end_char="4277">"</TOKEN>
<TOKEN id="token-32-27" pos="word" morph="none" start_char="4278" end_char="4278">a</TOKEN>
<TOKEN id="token-32-28" pos="word" morph="none" start_char="4280" end_char="4289">masquerade</TOKEN>
<TOKEN id="token-32-29" pos="punct" morph="none" start_char="4290" end_char="4291">."</TOKEN>
</SEG>
<SEG id="segment-33" start_char="4294" end_char="4470">
<ORIGINAL_TEXT>What she does not say is that she didn’t go public at the time she was running because the whole political focus by the Macron political machine was on winning the "masquerade."</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="4294" end_char="4297">What</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="4299" end_char="4301">she</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="4303" end_char="4306">does</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="4308" end_char="4310">not</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="4312" end_char="4314">say</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="4316" end_char="4317">is</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="4319" end_char="4322">that</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="4324" end_char="4326">she</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="4328" end_char="4333">didn’t</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="4335" end_char="4336">go</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="4338" end_char="4343">public</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="4345" end_char="4346">at</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="4348" end_char="4350">the</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="4352" end_char="4355">time</TOKEN>
<TOKEN id="token-33-14" pos="word" morph="none" start_char="4357" end_char="4359">she</TOKEN>
<TOKEN id="token-33-15" pos="word" morph="none" start_char="4361" end_char="4363">was</TOKEN>
<TOKEN id="token-33-16" pos="word" morph="none" start_char="4365" end_char="4371">running</TOKEN>
<TOKEN id="token-33-17" pos="word" morph="none" start_char="4373" end_char="4379">because</TOKEN>
<TOKEN id="token-33-18" pos="word" morph="none" start_char="4381" end_char="4383">the</TOKEN>
<TOKEN id="token-33-19" pos="word" morph="none" start_char="4385" end_char="4389">whole</TOKEN>
<TOKEN id="token-33-20" pos="word" morph="none" start_char="4391" end_char="4399">political</TOKEN>
<TOKEN id="token-33-21" pos="word" morph="none" start_char="4401" end_char="4405">focus</TOKEN>
<TOKEN id="token-33-22" pos="word" morph="none" start_char="4407" end_char="4408">by</TOKEN>
<TOKEN id="token-33-23" pos="word" morph="none" start_char="4410" end_char="4412">the</TOKEN>
<TOKEN id="token-33-24" pos="word" morph="none" start_char="4414" end_char="4419">Macron</TOKEN>
<TOKEN id="token-33-25" pos="word" morph="none" start_char="4421" end_char="4429">political</TOKEN>
<TOKEN id="token-33-26" pos="word" morph="none" start_char="4431" end_char="4437">machine</TOKEN>
<TOKEN id="token-33-27" pos="word" morph="none" start_char="4439" end_char="4441">was</TOKEN>
<TOKEN id="token-33-28" pos="word" morph="none" start_char="4443" end_char="4444">on</TOKEN>
<TOKEN id="token-33-29" pos="word" morph="none" start_char="4446" end_char="4452">winning</TOKEN>
<TOKEN id="token-33-30" pos="word" morph="none" start_char="4454" end_char="4456">the</TOKEN>
<TOKEN id="token-33-31" pos="punct" morph="none" start_char="4458" end_char="4458">"</TOKEN>
<TOKEN id="token-33-32" pos="word" morph="none" start_char="4459" end_char="4468">masquerade</TOKEN>
<TOKEN id="token-33-33" pos="punct" morph="none" start_char="4469" end_char="4470">."</TOKEN>
</SEG>
<SEG id="segment-34" start_char="4472" end_char="4544">
<ORIGINAL_TEXT>The first round of the election meant nothing, as Covid-19 was advancing.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="4472" end_char="4474">The</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="4476" end_char="4480">first</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="4482" end_char="4486">round</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="4488" end_char="4489">of</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="4491" end_char="4493">the</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="4495" end_char="4502">election</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="4504" end_char="4508">meant</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="4510" end_char="4516">nothing</TOKEN>
<TOKEN id="token-34-8" pos="punct" morph="none" start_char="4517" end_char="4517">,</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="4519" end_char="4520">as</TOKEN>
<TOKEN id="token-34-10" pos="unknown" morph="none" start_char="4522" end_char="4529">Covid-19</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="4531" end_char="4533">was</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="4535" end_char="4543">advancing</TOKEN>
<TOKEN id="token-34-13" pos="punct" morph="none" start_char="4544" end_char="4544">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="4546" end_char="4589">
<ORIGINAL_TEXT>The second round was postponed indefinitely.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="4546" end_char="4548">The</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="4550" end_char="4555">second</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="4557" end_char="4561">round</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="4563" end_char="4565">was</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="4567" end_char="4575">postponed</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="4577" end_char="4588">indefinitely</TOKEN>
<TOKEN id="token-35-6" pos="punct" morph="none" start_char="4589" end_char="4589">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="4591" end_char="4646">
<ORIGINAL_TEXT>She had to know about the impending healthcare disaster.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="4591" end_char="4593">She</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="4595" end_char="4597">had</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="4599" end_char="4600">to</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="4602" end_char="4605">know</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="4607" end_char="4611">about</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="4613" end_char="4615">the</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="4617" end_char="4625">impending</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="4627" end_char="4636">healthcare</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="4638" end_char="4645">disaster</TOKEN>
<TOKEN id="token-36-9" pos="punct" morph="none" start_char="4646" end_char="4646">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="4648" end_char="4728">
<ORIGINAL_TEXT>But as a candidate of the Macron machine she did not go public in timely fashion.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="4648" end_char="4650">But</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="4652" end_char="4653">as</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="4655" end_char="4655">a</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="4657" end_char="4665">candidate</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="4667" end_char="4668">of</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="4670" end_char="4672">the</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="4674" end_char="4679">Macron</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="4681" end_char="4687">machine</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="4689" end_char="4691">she</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="4693" end_char="4695">did</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="4697" end_char="4699">not</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="4701" end_char="4702">go</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="4704" end_char="4709">public</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="4711" end_char="4712">in</TOKEN>
<TOKEN id="token-37-14" pos="word" morph="none" start_char="4714" end_char="4719">timely</TOKEN>
<TOKEN id="token-37-15" pos="word" morph="none" start_char="4721" end_char="4727">fashion</TOKEN>
<TOKEN id="token-37-16" pos="punct" morph="none" start_char="4728" end_char="4728">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="4731" end_char="4750">
<ORIGINAL_TEXT>In quick succession:</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="4731" end_char="4732">In</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="4734" end_char="4738">quick</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="4740" end_char="4749">succession</TOKEN>
<TOKEN id="token-38-3" pos="punct" morph="none" start_char="4750" end_char="4750">:</TOKEN>
</SEG>
<SEG id="segment-39" start_char="4753" end_char="4858">
<ORIGINAL_TEXT>The Macron government refuses to apply mass testing, as practiced with success in South Korea and Germany.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="4753" end_char="4755">The</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="4757" end_char="4762">Macron</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="4764" end_char="4773">government</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="4775" end_char="4781">refuses</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="4783" end_char="4784">to</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="4786" end_char="4790">apply</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="4792" end_char="4795">mass</TOKEN>
<TOKEN id="token-39-7" pos="word" morph="none" start_char="4797" end_char="4803">testing</TOKEN>
<TOKEN id="token-39-8" pos="punct" morph="none" start_char="4804" end_char="4804">,</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="4806" end_char="4807">as</TOKEN>
<TOKEN id="token-39-10" pos="word" morph="none" start_char="4809" end_char="4817">practiced</TOKEN>
<TOKEN id="token-39-11" pos="word" morph="none" start_char="4819" end_char="4822">with</TOKEN>
<TOKEN id="token-39-12" pos="word" morph="none" start_char="4824" end_char="4830">success</TOKEN>
<TOKEN id="token-39-13" pos="word" morph="none" start_char="4832" end_char="4833">in</TOKEN>
<TOKEN id="token-39-14" pos="word" morph="none" start_char="4835" end_char="4839">South</TOKEN>
<TOKEN id="token-39-15" pos="word" morph="none" start_char="4841" end_char="4845">Korea</TOKEN>
<TOKEN id="token-39-16" pos="word" morph="none" start_char="4847" end_char="4849">and</TOKEN>
<TOKEN id="token-39-17" pos="word" morph="none" start_char="4851" end_char="4857">Germany</TOKEN>
<TOKEN id="token-39-18" pos="punct" morph="none" start_char="4858" end_char="4858">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="4861" end_char="4977">
<ORIGINAL_TEXT>Le Monde and the French state health agency characterize Raoult’s research as fake news, before issuing a retraction.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="4861" end_char="4862">Le</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="4864" end_char="4868">Monde</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="4870" end_char="4872">and</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="4874" end_char="4876">the</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="4878" end_char="4883">French</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="4885" end_char="4889">state</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="4891" end_char="4896">health</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="4898" end_char="4903">agency</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="4905" end_char="4916">characterize</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="4918" end_char="4925">Raoult’s</TOKEN>
<TOKEN id="token-40-10" pos="word" morph="none" start_char="4927" end_char="4934">research</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="4936" end_char="4937">as</TOKEN>
<TOKEN id="token-40-12" pos="word" morph="none" start_char="4939" end_char="4942">fake</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="4944" end_char="4947">news</TOKEN>
<TOKEN id="token-40-14" pos="punct" morph="none" start_char="4948" end_char="4948">,</TOKEN>
<TOKEN id="token-40-15" pos="word" morph="none" start_char="4950" end_char="4955">before</TOKEN>
<TOKEN id="token-40-16" pos="word" morph="none" start_char="4957" end_char="4963">issuing</TOKEN>
<TOKEN id="token-40-17" pos="word" morph="none" start_char="4965" end_char="4965">a</TOKEN>
<TOKEN id="token-40-18" pos="word" morph="none" start_char="4967" end_char="4976">retraction</TOKEN>
<TOKEN id="token-40-19" pos="punct" morph="none" start_char="4977" end_char="4977">.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="4980" end_char="5111">
<ORIGINAL_TEXT>Professor Perrone reveals on the 24/7 LCI news channel that the stock of chloroquine at the French central pharmacy has been stolen.</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="4980" end_char="4988">Professor</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="4990" end_char="4996">Perrone</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="4998" end_char="5004">reveals</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="5006" end_char="5007">on</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="5009" end_char="5011">the</TOKEN>
<TOKEN id="token-41-5" pos="unknown" morph="none" start_char="5013" end_char="5016">24/7</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="5018" end_char="5020">LCI</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="5022" end_char="5025">news</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="5027" end_char="5033">channel</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="5035" end_char="5038">that</TOKEN>
<TOKEN id="token-41-10" pos="word" morph="none" start_char="5040" end_char="5042">the</TOKEN>
<TOKEN id="token-41-11" pos="word" morph="none" start_char="5044" end_char="5048">stock</TOKEN>
<TOKEN id="token-41-12" pos="word" morph="none" start_char="5050" end_char="5051">of</TOKEN>
<TOKEN id="token-41-13" pos="word" morph="none" start_char="5053" end_char="5063">chloroquine</TOKEN>
<TOKEN id="token-41-14" pos="word" morph="none" start_char="5065" end_char="5066">at</TOKEN>
<TOKEN id="token-41-15" pos="word" morph="none" start_char="5068" end_char="5070">the</TOKEN>
<TOKEN id="token-41-16" pos="word" morph="none" start_char="5072" end_char="5077">French</TOKEN>
<TOKEN id="token-41-17" pos="word" morph="none" start_char="5079" end_char="5085">central</TOKEN>
<TOKEN id="token-41-18" pos="word" morph="none" start_char="5087" end_char="5094">pharmacy</TOKEN>
<TOKEN id="token-41-19" pos="word" morph="none" start_char="5096" end_char="5098">has</TOKEN>
<TOKEN id="token-41-20" pos="word" morph="none" start_char="5100" end_char="5103">been</TOKEN>
<TOKEN id="token-41-21" pos="word" morph="none" start_char="5105" end_char="5110">stolen</TOKEN>
<TOKEN id="token-41-22" pos="punct" morph="none" start_char="5111" end_char="5111">.</TOKEN>
</SEG>
<SEG id="segment-42" start_char="5114" end_char="5215">
<ORIGINAL_TEXT>Thanks to a tweet by Elon Musk, President Trump says chloroquine should be available to all Americans.</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="5114" end_char="5119">Thanks</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="5121" end_char="5122">to</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="5124" end_char="5124">a</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="5126" end_char="5130">tweet</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="5132" end_char="5133">by</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="5135" end_char="5138">Elon</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="5140" end_char="5143">Musk</TOKEN>
<TOKEN id="token-42-7" pos="punct" morph="none" start_char="5144" end_char="5144">,</TOKEN>
<TOKEN id="token-42-8" pos="word" morph="none" start_char="5146" end_char="5154">President</TOKEN>
<TOKEN id="token-42-9" pos="word" morph="none" start_char="5156" end_char="5160">Trump</TOKEN>
<TOKEN id="token-42-10" pos="word" morph="none" start_char="5162" end_char="5165">says</TOKEN>
<TOKEN id="token-42-11" pos="word" morph="none" start_char="5167" end_char="5177">chloroquine</TOKEN>
<TOKEN id="token-42-12" pos="word" morph="none" start_char="5179" end_char="5184">should</TOKEN>
<TOKEN id="token-42-13" pos="word" morph="none" start_char="5186" end_char="5187">be</TOKEN>
<TOKEN id="token-42-14" pos="word" morph="none" start_char="5189" end_char="5197">available</TOKEN>
<TOKEN id="token-42-15" pos="word" morph="none" start_char="5199" end_char="5200">to</TOKEN>
<TOKEN id="token-42-16" pos="word" morph="none" start_char="5202" end_char="5204">all</TOKEN>
<TOKEN id="token-42-17" pos="word" morph="none" start_char="5206" end_char="5214">Americans</TOKEN>
<TOKEN id="token-42-18" pos="punct" morph="none" start_char="5215" end_char="5215">.</TOKEN>
</SEG>
<SEG id="segment-43" start_char="5217" end_char="5378">
<ORIGINAL_TEXT>Sufferers of lupus and rheumatoid arthritis, who already have supply problems with the only drug that offers them relief, set social media afire with their panic.</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="5217" end_char="5225">Sufferers</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="5227" end_char="5228">of</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="5230" end_char="5234">lupus</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="5236" end_char="5238">and</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="5240" end_char="5249">rheumatoid</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="5251" end_char="5259">arthritis</TOKEN>
<TOKEN id="token-43-6" pos="punct" morph="none" start_char="5260" end_char="5260">,</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="5262" end_char="5264">who</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="5266" end_char="5272">already</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="5274" end_char="5277">have</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="5279" end_char="5284">supply</TOKEN>
<TOKEN id="token-43-11" pos="word" morph="none" start_char="5286" end_char="5293">problems</TOKEN>
<TOKEN id="token-43-12" pos="word" morph="none" start_char="5295" end_char="5298">with</TOKEN>
<TOKEN id="token-43-13" pos="word" morph="none" start_char="5300" end_char="5302">the</TOKEN>
<TOKEN id="token-43-14" pos="word" morph="none" start_char="5304" end_char="5307">only</TOKEN>
<TOKEN id="token-43-15" pos="word" morph="none" start_char="5309" end_char="5312">drug</TOKEN>
<TOKEN id="token-43-16" pos="word" morph="none" start_char="5314" end_char="5317">that</TOKEN>
<TOKEN id="token-43-17" pos="word" morph="none" start_char="5319" end_char="5324">offers</TOKEN>
<TOKEN id="token-43-18" pos="word" morph="none" start_char="5326" end_char="5329">them</TOKEN>
<TOKEN id="token-43-19" pos="word" morph="none" start_char="5331" end_char="5336">relief</TOKEN>
<TOKEN id="token-43-20" pos="punct" morph="none" start_char="5337" end_char="5337">,</TOKEN>
<TOKEN id="token-43-21" pos="word" morph="none" start_char="5339" end_char="5341">set</TOKEN>
<TOKEN id="token-43-22" pos="word" morph="none" start_char="5343" end_char="5348">social</TOKEN>
<TOKEN id="token-43-23" pos="word" morph="none" start_char="5350" end_char="5354">media</TOKEN>
<TOKEN id="token-43-24" pos="word" morph="none" start_char="5356" end_char="5360">afire</TOKEN>
<TOKEN id="token-43-25" pos="word" morph="none" start_char="5362" end_char="5365">with</TOKEN>
<TOKEN id="token-43-26" pos="word" morph="none" start_char="5367" end_char="5371">their</TOKEN>
<TOKEN id="token-43-27" pos="word" morph="none" start_char="5373" end_char="5377">panic</TOKEN>
<TOKEN id="token-43-28" pos="punct" morph="none" start_char="5378" end_char="5378">.</TOKEN>
</SEG>
<SEG id="segment-44" start_char="5381" end_char="5594">
<ORIGINAL_TEXT>US doctors and other medical professionals take to hoarding the medicine for the use of themselves and those close to them, faking prescriptions to indicate they are for patients with lupus or rheumatoid arthritis.</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="5381" end_char="5382">US</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="5384" end_char="5390">doctors</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="5392" end_char="5394">and</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="5396" end_char="5400">other</TOKEN>
<TOKEN id="token-44-4" pos="word" morph="none" start_char="5402" end_char="5408">medical</TOKEN>
<TOKEN id="token-44-5" pos="word" morph="none" start_char="5410" end_char="5422">professionals</TOKEN>
<TOKEN id="token-44-6" pos="word" morph="none" start_char="5424" end_char="5427">take</TOKEN>
<TOKEN id="token-44-7" pos="word" morph="none" start_char="5429" end_char="5430">to</TOKEN>
<TOKEN id="token-44-8" pos="word" morph="none" start_char="5432" end_char="5439">hoarding</TOKEN>
<TOKEN id="token-44-9" pos="word" morph="none" start_char="5441" end_char="5443">the</TOKEN>
<TOKEN id="token-44-10" pos="word" morph="none" start_char="5445" end_char="5452">medicine</TOKEN>
<TOKEN id="token-44-11" pos="word" morph="none" start_char="5454" end_char="5456">for</TOKEN>
<TOKEN id="token-44-12" pos="word" morph="none" start_char="5458" end_char="5460">the</TOKEN>
<TOKEN id="token-44-13" pos="word" morph="none" start_char="5462" end_char="5464">use</TOKEN>
<TOKEN id="token-44-14" pos="word" morph="none" start_char="5466" end_char="5467">of</TOKEN>
<TOKEN id="token-44-15" pos="word" morph="none" start_char="5469" end_char="5478">themselves</TOKEN>
<TOKEN id="token-44-16" pos="word" morph="none" start_char="5480" end_char="5482">and</TOKEN>
<TOKEN id="token-44-17" pos="word" morph="none" start_char="5484" end_char="5488">those</TOKEN>
<TOKEN id="token-44-18" pos="word" morph="none" start_char="5490" end_char="5494">close</TOKEN>
<TOKEN id="token-44-19" pos="word" morph="none" start_char="5496" end_char="5497">to</TOKEN>
<TOKEN id="token-44-20" pos="word" morph="none" start_char="5499" end_char="5502">them</TOKEN>
<TOKEN id="token-44-21" pos="punct" morph="none" start_char="5503" end_char="5503">,</TOKEN>
<TOKEN id="token-44-22" pos="word" morph="none" start_char="5505" end_char="5510">faking</TOKEN>
<TOKEN id="token-44-23" pos="word" morph="none" start_char="5512" end_char="5524">prescriptions</TOKEN>
<TOKEN id="token-44-24" pos="word" morph="none" start_char="5526" end_char="5527">to</TOKEN>
<TOKEN id="token-44-25" pos="word" morph="none" start_char="5529" end_char="5536">indicate</TOKEN>
<TOKEN id="token-44-26" pos="word" morph="none" start_char="5538" end_char="5541">they</TOKEN>
<TOKEN id="token-44-27" pos="word" morph="none" start_char="5543" end_char="5545">are</TOKEN>
<TOKEN id="token-44-28" pos="word" morph="none" start_char="5547" end_char="5549">for</TOKEN>
<TOKEN id="token-44-29" pos="word" morph="none" start_char="5551" end_char="5558">patients</TOKEN>
<TOKEN id="token-44-30" pos="word" morph="none" start_char="5560" end_char="5563">with</TOKEN>
<TOKEN id="token-44-31" pos="word" morph="none" start_char="5565" end_char="5569">lupus</TOKEN>
<TOKEN id="token-44-32" pos="word" morph="none" start_char="5571" end_char="5572">or</TOKEN>
<TOKEN id="token-44-33" pos="word" morph="none" start_char="5574" end_char="5583">rheumatoid</TOKEN>
<TOKEN id="token-44-34" pos="word" morph="none" start_char="5585" end_char="5593">arthritis</TOKEN>
<TOKEN id="token-44-35" pos="punct" morph="none" start_char="5594" end_char="5594">.</TOKEN>
</SEG>
<SEG id="segment-45" start_char="5597" end_char="5660">
<ORIGINAL_TEXT>Morocco buys the stock of chloroquine from Sanofi in Casablanca.</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="5597" end_char="5603">Morocco</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="5605" end_char="5608">buys</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="5610" end_char="5612">the</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="5614" end_char="5618">stock</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="5620" end_char="5621">of</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="5623" end_char="5633">chloroquine</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="5635" end_char="5638">from</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="5640" end_char="5645">Sanofi</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="5647" end_char="5648">in</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="5650" end_char="5659">Casablanca</TOKEN>
<TOKEN id="token-45-10" pos="punct" morph="none" start_char="5660" end_char="5660">.</TOKEN>
</SEG>
<SEG id="segment-46" start_char="5663" end_char="5741">
<ORIGINAL_TEXT>Pakistan decides to increase its production of chloroquine to be sent to China.</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="5663" end_char="5670">Pakistan</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="5672" end_char="5678">decides</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="5680" end_char="5681">to</TOKEN>
<TOKEN id="token-46-3" pos="word" morph="none" start_char="5683" end_char="5690">increase</TOKEN>
<TOKEN id="token-46-4" pos="word" morph="none" start_char="5692" end_char="5694">its</TOKEN>
<TOKEN id="token-46-5" pos="word" morph="none" start_char="5696" end_char="5705">production</TOKEN>
<TOKEN id="token-46-6" pos="word" morph="none" start_char="5707" end_char="5708">of</TOKEN>
<TOKEN id="token-46-7" pos="word" morph="none" start_char="5710" end_char="5720">chloroquine</TOKEN>
<TOKEN id="token-46-8" pos="word" morph="none" start_char="5722" end_char="5723">to</TOKEN>
<TOKEN id="token-46-9" pos="word" morph="none" start_char="5725" end_char="5726">be</TOKEN>
<TOKEN id="token-46-10" pos="word" morph="none" start_char="5728" end_char="5731">sent</TOKEN>
<TOKEN id="token-46-11" pos="word" morph="none" start_char="5733" end_char="5734">to</TOKEN>
<TOKEN id="token-46-12" pos="word" morph="none" start_char="5736" end_char="5740">China</TOKEN>
<TOKEN id="token-46-13" pos="punct" morph="none" start_char="5741" end_char="5741">.</TOKEN>
</SEG>
<SEG id="segment-47" start_char="5744" end_char="5898">
<ORIGINAL_TEXT>Switzerland discards the total lockdown of its population; goes for mass testing and fast treatment; and accuses France of practicing "spectacle politics."</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="5744" end_char="5754">Switzerland</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="5756" end_char="5763">discards</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="5765" end_char="5767">the</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="5769" end_char="5773">total</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="5775" end_char="5782">lockdown</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="5784" end_char="5785">of</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="5787" end_char="5789">its</TOKEN>
<TOKEN id="token-47-7" pos="word" morph="none" start_char="5791" end_char="5800">population</TOKEN>
<TOKEN id="token-47-8" pos="punct" morph="none" start_char="5801" end_char="5801">;</TOKEN>
<TOKEN id="token-47-9" pos="word" morph="none" start_char="5803" end_char="5806">goes</TOKEN>
<TOKEN id="token-47-10" pos="word" morph="none" start_char="5808" end_char="5810">for</TOKEN>
<TOKEN id="token-47-11" pos="word" morph="none" start_char="5812" end_char="5815">mass</TOKEN>
<TOKEN id="token-47-12" pos="word" morph="none" start_char="5817" end_char="5823">testing</TOKEN>
<TOKEN id="token-47-13" pos="word" morph="none" start_char="5825" end_char="5827">and</TOKEN>
<TOKEN id="token-47-14" pos="word" morph="none" start_char="5829" end_char="5832">fast</TOKEN>
<TOKEN id="token-47-15" pos="word" morph="none" start_char="5834" end_char="5842">treatment</TOKEN>
<TOKEN id="token-47-16" pos="punct" morph="none" start_char="5843" end_char="5843">;</TOKEN>
<TOKEN id="token-47-17" pos="word" morph="none" start_char="5845" end_char="5847">and</TOKEN>
<TOKEN id="token-47-18" pos="word" morph="none" start_char="5849" end_char="5855">accuses</TOKEN>
<TOKEN id="token-47-19" pos="word" morph="none" start_char="5857" end_char="5862">France</TOKEN>
<TOKEN id="token-47-20" pos="word" morph="none" start_char="5864" end_char="5865">of</TOKEN>
<TOKEN id="token-47-21" pos="word" morph="none" start_char="5867" end_char="5876">practicing</TOKEN>
<TOKEN id="token-47-22" pos="punct" morph="none" start_char="5878" end_char="5878">"</TOKEN>
<TOKEN id="token-47-23" pos="word" morph="none" start_char="5879" end_char="5887">spectacle</TOKEN>
<TOKEN id="token-47-24" pos="word" morph="none" start_char="5889" end_char="5896">politics</TOKEN>
<TOKEN id="token-47-25" pos="punct" morph="none" start_char="5897" end_char="5898">."</TOKEN>
</SEG>
<SEG id="segment-48" start_char="5901" end_char="6085">
<ORIGINAL_TEXT>Christian Estrosi, the mayor of Nice, having had himself treated with chloroquine, without any government input, directly calls Sanofi so they may deliver chloroquine to Nice hospitals.</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="5901" end_char="5909">Christian</TOKEN>
<TOKEN id="token-48-1" pos="word" morph="none" start_char="5911" end_char="5917">Estrosi</TOKEN>
<TOKEN id="token-48-2" pos="punct" morph="none" start_char="5918" end_char="5918">,</TOKEN>
<TOKEN id="token-48-3" pos="word" morph="none" start_char="5920" end_char="5922">the</TOKEN>
<TOKEN id="token-48-4" pos="word" morph="none" start_char="5924" end_char="5928">mayor</TOKEN>
<TOKEN id="token-48-5" pos="word" morph="none" start_char="5930" end_char="5931">of</TOKEN>
<TOKEN id="token-48-6" pos="word" morph="none" start_char="5933" end_char="5936">Nice</TOKEN>
<TOKEN id="token-48-7" pos="punct" morph="none" start_char="5937" end_char="5937">,</TOKEN>
<TOKEN id="token-48-8" pos="word" morph="none" start_char="5939" end_char="5944">having</TOKEN>
<TOKEN id="token-48-9" pos="word" morph="none" start_char="5946" end_char="5948">had</TOKEN>
<TOKEN id="token-48-10" pos="word" morph="none" start_char="5950" end_char="5956">himself</TOKEN>
<TOKEN id="token-48-11" pos="word" morph="none" start_char="5958" end_char="5964">treated</TOKEN>
<TOKEN id="token-48-12" pos="word" morph="none" start_char="5966" end_char="5969">with</TOKEN>
<TOKEN id="token-48-13" pos="word" morph="none" start_char="5971" end_char="5981">chloroquine</TOKEN>
<TOKEN id="token-48-14" pos="punct" morph="none" start_char="5982" end_char="5982">,</TOKEN>
<TOKEN id="token-48-15" pos="word" morph="none" start_char="5984" end_char="5990">without</TOKEN>
<TOKEN id="token-48-16" pos="word" morph="none" start_char="5992" end_char="5994">any</TOKEN>
<TOKEN id="token-48-17" pos="word" morph="none" start_char="5996" end_char="6005">government</TOKEN>
<TOKEN id="token-48-18" pos="word" morph="none" start_char="6007" end_char="6011">input</TOKEN>
<TOKEN id="token-48-19" pos="punct" morph="none" start_char="6012" end_char="6012">,</TOKEN>
<TOKEN id="token-48-20" pos="word" morph="none" start_char="6014" end_char="6021">directly</TOKEN>
<TOKEN id="token-48-21" pos="word" morph="none" start_char="6023" end_char="6027">calls</TOKEN>
<TOKEN id="token-48-22" pos="word" morph="none" start_char="6029" end_char="6034">Sanofi</TOKEN>
<TOKEN id="token-48-23" pos="word" morph="none" start_char="6036" end_char="6037">so</TOKEN>
<TOKEN id="token-48-24" pos="word" morph="none" start_char="6039" end_char="6042">they</TOKEN>
<TOKEN id="token-48-25" pos="word" morph="none" start_char="6044" end_char="6046">may</TOKEN>
<TOKEN id="token-48-26" pos="word" morph="none" start_char="6048" end_char="6054">deliver</TOKEN>
<TOKEN id="token-48-27" pos="word" morph="none" start_char="6056" end_char="6066">chloroquine</TOKEN>
<TOKEN id="token-48-28" pos="word" morph="none" start_char="6068" end_char="6069">to</TOKEN>
<TOKEN id="token-48-29" pos="word" morph="none" start_char="6071" end_char="6074">Nice</TOKEN>
<TOKEN id="token-48-30" pos="word" morph="none" start_char="6076" end_char="6084">hospitals</TOKEN>
<TOKEN id="token-48-31" pos="punct" morph="none" start_char="6085" end_char="6085">.</TOKEN>
</SEG>
<SEG id="segment-49" start_char="6088" end_char="6298">
<ORIGINAL_TEXT>Because of Raoult’s research, a large-scale chloroquine test finally starts in France, under the – predictable – direction of INSERM, which wants to "remake the experiments in other independent medical centers."</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="6088" end_char="6094">Because</TOKEN>
<TOKEN id="token-49-1" pos="word" morph="none" start_char="6096" end_char="6097">of</TOKEN>
<TOKEN id="token-49-2" pos="word" morph="none" start_char="6099" end_char="6106">Raoult’s</TOKEN>
<TOKEN id="token-49-3" pos="word" morph="none" start_char="6108" end_char="6115">research</TOKEN>
<TOKEN id="token-49-4" pos="punct" morph="none" start_char="6116" end_char="6116">,</TOKEN>
<TOKEN id="token-49-5" pos="word" morph="none" start_char="6118" end_char="6118">a</TOKEN>
<TOKEN id="token-49-6" pos="unknown" morph="none" start_char="6120" end_char="6130">large-scale</TOKEN>
<TOKEN id="token-49-7" pos="word" morph="none" start_char="6132" end_char="6142">chloroquine</TOKEN>
<TOKEN id="token-49-8" pos="word" morph="none" start_char="6144" end_char="6147">test</TOKEN>
<TOKEN id="token-49-9" pos="word" morph="none" start_char="6149" end_char="6155">finally</TOKEN>
<TOKEN id="token-49-10" pos="word" morph="none" start_char="6157" end_char="6162">starts</TOKEN>
<TOKEN id="token-49-11" pos="word" morph="none" start_char="6164" end_char="6165">in</TOKEN>
<TOKEN id="token-49-12" pos="word" morph="none" start_char="6167" end_char="6172">France</TOKEN>
<TOKEN id="token-49-13" pos="punct" morph="none" start_char="6173" end_char="6173">,</TOKEN>
<TOKEN id="token-49-14" pos="word" morph="none" start_char="6175" end_char="6179">under</TOKEN>
<TOKEN id="token-49-15" pos="word" morph="none" start_char="6181" end_char="6183">the</TOKEN>
<TOKEN id="token-49-16" pos="punct" morph="none" start_char="6185" end_char="6185">–</TOKEN>
<TOKEN id="token-49-17" pos="word" morph="none" start_char="6187" end_char="6197">predictable</TOKEN>
<TOKEN id="token-49-18" pos="punct" morph="none" start_char="6199" end_char="6199">–</TOKEN>
<TOKEN id="token-49-19" pos="word" morph="none" start_char="6201" end_char="6209">direction</TOKEN>
<TOKEN id="token-49-20" pos="word" morph="none" start_char="6211" end_char="6212">of</TOKEN>
<TOKEN id="token-49-21" pos="word" morph="none" start_char="6214" end_char="6219">INSERM</TOKEN>
<TOKEN id="token-49-22" pos="punct" morph="none" start_char="6220" end_char="6220">,</TOKEN>
<TOKEN id="token-49-23" pos="word" morph="none" start_char="6222" end_char="6226">which</TOKEN>
<TOKEN id="token-49-24" pos="word" morph="none" start_char="6228" end_char="6232">wants</TOKEN>
<TOKEN id="token-49-25" pos="word" morph="none" start_char="6234" end_char="6235">to</TOKEN>
<TOKEN id="token-49-26" pos="punct" morph="none" start_char="6237" end_char="6237">"</TOKEN>
<TOKEN id="token-49-27" pos="word" morph="none" start_char="6238" end_char="6243">remake</TOKEN>
<TOKEN id="token-49-28" pos="word" morph="none" start_char="6245" end_char="6247">the</TOKEN>
<TOKEN id="token-49-29" pos="word" morph="none" start_char="6249" end_char="6259">experiments</TOKEN>
<TOKEN id="token-49-30" pos="word" morph="none" start_char="6261" end_char="6262">in</TOKEN>
<TOKEN id="token-49-31" pos="word" morph="none" start_char="6264" end_char="6268">other</TOKEN>
<TOKEN id="token-49-32" pos="word" morph="none" start_char="6270" end_char="6280">independent</TOKEN>
<TOKEN id="token-49-33" pos="word" morph="none" start_char="6282" end_char="6288">medical</TOKEN>
<TOKEN id="token-49-34" pos="word" morph="none" start_char="6290" end_char="6296">centers</TOKEN>
<TOKEN id="token-49-35" pos="punct" morph="none" start_char="6297" end_char="6298">."</TOKEN>
</SEG>
<SEG id="segment-50" start_char="6300" end_char="6452">
<ORIGINAL_TEXT>This will take at least an extra six weeks – as the Elysee Palace’s scientific council now mulls the extension of France’s total lockdown to … six weeks.</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="6300" end_char="6303">This</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="6305" end_char="6308">will</TOKEN>
<TOKEN id="token-50-2" pos="word" morph="none" start_char="6310" end_char="6313">take</TOKEN>
<TOKEN id="token-50-3" pos="word" morph="none" start_char="6315" end_char="6316">at</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="6318" end_char="6322">least</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="6324" end_char="6325">an</TOKEN>
<TOKEN id="token-50-6" pos="word" morph="none" start_char="6327" end_char="6331">extra</TOKEN>
<TOKEN id="token-50-7" pos="word" morph="none" start_char="6333" end_char="6335">six</TOKEN>
<TOKEN id="token-50-8" pos="word" morph="none" start_char="6337" end_char="6341">weeks</TOKEN>
<TOKEN id="token-50-9" pos="punct" morph="none" start_char="6343" end_char="6343">–</TOKEN>
<TOKEN id="token-50-10" pos="word" morph="none" start_char="6345" end_char="6346">as</TOKEN>
<TOKEN id="token-50-11" pos="word" morph="none" start_char="6348" end_char="6350">the</TOKEN>
<TOKEN id="token-50-12" pos="word" morph="none" start_char="6352" end_char="6357">Elysee</TOKEN>
<TOKEN id="token-50-13" pos="word" morph="none" start_char="6359" end_char="6366">Palace’s</TOKEN>
<TOKEN id="token-50-14" pos="word" morph="none" start_char="6368" end_char="6377">scientific</TOKEN>
<TOKEN id="token-50-15" pos="word" morph="none" start_char="6379" end_char="6385">council</TOKEN>
<TOKEN id="token-50-16" pos="word" morph="none" start_char="6387" end_char="6389">now</TOKEN>
<TOKEN id="token-50-17" pos="word" morph="none" start_char="6391" end_char="6395">mulls</TOKEN>
<TOKEN id="token-50-18" pos="word" morph="none" start_char="6397" end_char="6399">the</TOKEN>
<TOKEN id="token-50-19" pos="word" morph="none" start_char="6401" end_char="6409">extension</TOKEN>
<TOKEN id="token-50-20" pos="word" morph="none" start_char="6411" end_char="6412">of</TOKEN>
<TOKEN id="token-50-21" pos="word" morph="none" start_char="6414" end_char="6421">France’s</TOKEN>
<TOKEN id="token-50-22" pos="word" morph="none" start_char="6423" end_char="6427">total</TOKEN>
<TOKEN id="token-50-23" pos="word" morph="none" start_char="6429" end_char="6436">lockdown</TOKEN>
<TOKEN id="token-50-24" pos="word" morph="none" start_char="6438" end_char="6439">to</TOKEN>
<TOKEN id="token-50-25" pos="punct" morph="none" start_char="6441" end_char="6441">…</TOKEN>
<TOKEN id="token-50-26" pos="word" morph="none" start_char="6443" end_char="6445">six</TOKEN>
<TOKEN id="token-50-27" pos="word" morph="none" start_char="6447" end_char="6451">weeks</TOKEN>
<TOKEN id="token-50-28" pos="punct" morph="none" start_char="6452" end_char="6452">.</TOKEN>
</SEG>
<SEG id="segment-51" start_char="6455" end_char="6608">
<ORIGINAL_TEXT>If joint use of hydroxychloroquine and azithromycin proves definitely effective among the most gravely ill, quarantines may be reduced in select clusters.</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="word" morph="none" start_char="6455" end_char="6456">If</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="6458" end_char="6462">joint</TOKEN>
<TOKEN id="token-51-2" pos="word" morph="none" start_char="6464" end_char="6466">use</TOKEN>
<TOKEN id="token-51-3" pos="word" morph="none" start_char="6468" end_char="6469">of</TOKEN>
<TOKEN id="token-51-4" pos="word" morph="none" start_char="6471" end_char="6488">hydroxychloroquine</TOKEN>
<TOKEN id="token-51-5" pos="word" morph="none" start_char="6490" end_char="6492">and</TOKEN>
<TOKEN id="token-51-6" pos="word" morph="none" start_char="6494" end_char="6505">azithromycin</TOKEN>
<TOKEN id="token-51-7" pos="word" morph="none" start_char="6507" end_char="6512">proves</TOKEN>
<TOKEN id="token-51-8" pos="word" morph="none" start_char="6514" end_char="6523">definitely</TOKEN>
<TOKEN id="token-51-9" pos="word" morph="none" start_char="6525" end_char="6533">effective</TOKEN>
<TOKEN id="token-51-10" pos="word" morph="none" start_char="6535" end_char="6539">among</TOKEN>
<TOKEN id="token-51-11" pos="word" morph="none" start_char="6541" end_char="6543">the</TOKEN>
<TOKEN id="token-51-12" pos="word" morph="none" start_char="6545" end_char="6548">most</TOKEN>
<TOKEN id="token-51-13" pos="word" morph="none" start_char="6550" end_char="6556">gravely</TOKEN>
<TOKEN id="token-51-14" pos="word" morph="none" start_char="6558" end_char="6560">ill</TOKEN>
<TOKEN id="token-51-15" pos="punct" morph="none" start_char="6561" end_char="6561">,</TOKEN>
<TOKEN id="token-51-16" pos="word" morph="none" start_char="6563" end_char="6573">quarantines</TOKEN>
<TOKEN id="token-51-17" pos="word" morph="none" start_char="6575" end_char="6577">may</TOKEN>
<TOKEN id="token-51-18" pos="word" morph="none" start_char="6579" end_char="6580">be</TOKEN>
<TOKEN id="token-51-19" pos="word" morph="none" start_char="6582" end_char="6588">reduced</TOKEN>
<TOKEN id="token-51-20" pos="word" morph="none" start_char="6590" end_char="6591">in</TOKEN>
<TOKEN id="token-51-21" pos="word" morph="none" start_char="6593" end_char="6598">select</TOKEN>
<TOKEN id="token-51-22" pos="word" morph="none" start_char="6600" end_char="6607">clusters</TOKEN>
<TOKEN id="token-51-23" pos="punct" morph="none" start_char="6608" end_char="6608">.</TOKEN>
</SEG>
<SEG id="segment-52" start_char="6611" end_char="6701">
<ORIGINAL_TEXT>The only French company that still manufactures chloroquine is under judicial intervention.</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="6611" end_char="6613">The</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="6615" end_char="6618">only</TOKEN>
<TOKEN id="token-52-2" pos="word" morph="none" start_char="6620" end_char="6625">French</TOKEN>
<TOKEN id="token-52-3" pos="word" morph="none" start_char="6627" end_char="6633">company</TOKEN>
<TOKEN id="token-52-4" pos="word" morph="none" start_char="6635" end_char="6638">that</TOKEN>
<TOKEN id="token-52-5" pos="word" morph="none" start_char="6640" end_char="6644">still</TOKEN>
<TOKEN id="token-52-6" pos="word" morph="none" start_char="6646" end_char="6657">manufactures</TOKEN>
<TOKEN id="token-52-7" pos="word" morph="none" start_char="6659" end_char="6669">chloroquine</TOKEN>
<TOKEN id="token-52-8" pos="word" morph="none" start_char="6671" end_char="6672">is</TOKEN>
<TOKEN id="token-52-9" pos="word" morph="none" start_char="6674" end_char="6678">under</TOKEN>
<TOKEN id="token-52-10" pos="word" morph="none" start_char="6680" end_char="6687">judicial</TOKEN>
<TOKEN id="token-52-11" pos="word" morph="none" start_char="6689" end_char="6700">intervention</TOKEN>
<TOKEN id="token-52-12" pos="punct" morph="none" start_char="6701" end_char="6701">.</TOKEN>
</SEG>
<SEG id="segment-53" start_char="6703" end_char="6769">
<ORIGINAL_TEXT>That puts the chloroquine hoarding and theft into full perspective.</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="word" morph="none" start_char="6703" end_char="6706">That</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="6708" end_char="6711">puts</TOKEN>
<TOKEN id="token-53-2" pos="word" morph="none" start_char="6713" end_char="6715">the</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="6717" end_char="6727">chloroquine</TOKEN>
<TOKEN id="token-53-4" pos="word" morph="none" start_char="6729" end_char="6736">hoarding</TOKEN>
<TOKEN id="token-53-5" pos="word" morph="none" start_char="6738" end_char="6740">and</TOKEN>
<TOKEN id="token-53-6" pos="word" morph="none" start_char="6742" end_char="6746">theft</TOKEN>
<TOKEN id="token-53-7" pos="word" morph="none" start_char="6748" end_char="6751">into</TOKEN>
<TOKEN id="token-53-8" pos="word" morph="none" start_char="6753" end_char="6756">full</TOKEN>
<TOKEN id="token-53-9" pos="word" morph="none" start_char="6758" end_char="6768">perspective</TOKEN>
<TOKEN id="token-53-10" pos="punct" morph="none" start_char="6769" end_char="6769">.</TOKEN>
</SEG>
<SEG id="segment-54" start_char="6771" end_char="6901">
<ORIGINAL_TEXT>It will take time for these stocks to be replenished, thus allowing Big Pharma the leeway to have what it wants: a costly solution.</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="word" morph="none" start_char="6771" end_char="6772">It</TOKEN>
<TOKEN id="token-54-1" pos="word" morph="none" start_char="6774" end_char="6777">will</TOKEN>
<TOKEN id="token-54-2" pos="word" morph="none" start_char="6779" end_char="6782">take</TOKEN>
<TOKEN id="token-54-3" pos="word" morph="none" start_char="6784" end_char="6787">time</TOKEN>
<TOKEN id="token-54-4" pos="word" morph="none" start_char="6789" end_char="6791">for</TOKEN>
<TOKEN id="token-54-5" pos="word" morph="none" start_char="6793" end_char="6797">these</TOKEN>
<TOKEN id="token-54-6" pos="word" morph="none" start_char="6799" end_char="6804">stocks</TOKEN>
<TOKEN id="token-54-7" pos="word" morph="none" start_char="6806" end_char="6807">to</TOKEN>
<TOKEN id="token-54-8" pos="word" morph="none" start_char="6809" end_char="6810">be</TOKEN>
<TOKEN id="token-54-9" pos="word" morph="none" start_char="6812" end_char="6822">replenished</TOKEN>
<TOKEN id="token-54-10" pos="punct" morph="none" start_char="6823" end_char="6823">,</TOKEN>
<TOKEN id="token-54-11" pos="word" morph="none" start_char="6825" end_char="6828">thus</TOKEN>
<TOKEN id="token-54-12" pos="word" morph="none" start_char="6830" end_char="6837">allowing</TOKEN>
<TOKEN id="token-54-13" pos="word" morph="none" start_char="6839" end_char="6841">Big</TOKEN>
<TOKEN id="token-54-14" pos="word" morph="none" start_char="6843" end_char="6848">Pharma</TOKEN>
<TOKEN id="token-54-15" pos="word" morph="none" start_char="6850" end_char="6852">the</TOKEN>
<TOKEN id="token-54-16" pos="word" morph="none" start_char="6854" end_char="6859">leeway</TOKEN>
<TOKEN id="token-54-17" pos="word" morph="none" start_char="6861" end_char="6862">to</TOKEN>
<TOKEN id="token-54-18" pos="word" morph="none" start_char="6864" end_char="6867">have</TOKEN>
<TOKEN id="token-54-19" pos="word" morph="none" start_char="6869" end_char="6872">what</TOKEN>
<TOKEN id="token-54-20" pos="word" morph="none" start_char="6874" end_char="6875">it</TOKEN>
<TOKEN id="token-54-21" pos="word" morph="none" start_char="6877" end_char="6881">wants</TOKEN>
<TOKEN id="token-54-22" pos="punct" morph="none" start_char="6882" end_char="6882">:</TOKEN>
<TOKEN id="token-54-23" pos="word" morph="none" start_char="6884" end_char="6884">a</TOKEN>
<TOKEN id="token-54-24" pos="word" morph="none" start_char="6886" end_char="6891">costly</TOKEN>
<TOKEN id="token-54-25" pos="word" morph="none" start_char="6893" end_char="6900">solution</TOKEN>
<TOKEN id="token-54-26" pos="punct" morph="none" start_char="6901" end_char="6901">.</TOKEN>
</SEG>
<SEG id="segment-55" start_char="6904" end_char="6980">
<ORIGINAL_TEXT>It appears the perpetrators of the chloroquine theft were very well informed.</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="word" morph="none" start_char="6904" end_char="6905">It</TOKEN>
<TOKEN id="token-55-1" pos="word" morph="none" start_char="6907" end_char="6913">appears</TOKEN>
<TOKEN id="token-55-2" pos="word" morph="none" start_char="6915" end_char="6917">the</TOKEN>
<TOKEN id="token-55-3" pos="word" morph="none" start_char="6919" end_char="6930">perpetrators</TOKEN>
<TOKEN id="token-55-4" pos="word" morph="none" start_char="6932" end_char="6933">of</TOKEN>
<TOKEN id="token-55-5" pos="word" morph="none" start_char="6935" end_char="6937">the</TOKEN>
<TOKEN id="token-55-6" pos="word" morph="none" start_char="6939" end_char="6949">chloroquine</TOKEN>
<TOKEN id="token-55-7" pos="word" morph="none" start_char="6951" end_char="6955">theft</TOKEN>
<TOKEN id="token-55-8" pos="word" morph="none" start_char="6957" end_char="6960">were</TOKEN>
<TOKEN id="token-55-9" pos="word" morph="none" start_char="6962" end_char="6965">very</TOKEN>
<TOKEN id="token-55-10" pos="word" morph="none" start_char="6967" end_char="6970">well</TOKEN>
<TOKEN id="token-55-11" pos="word" morph="none" start_char="6972" end_char="6979">informed</TOKEN>
<TOKEN id="token-55-12" pos="punct" morph="none" start_char="6980" end_char="6980">.</TOKEN>
</SEG>
<SEG id="segment-56" start_char="6983" end_char="6995">
<ORIGINAL_TEXT>Bagged nurses</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="6983" end_char="6988">Bagged</TOKEN>
<TOKEN id="token-56-1" pos="word" morph="none" start_char="6990" end_char="6995">nurses</TOKEN>
</SEG>
<SEG id="segment-57" start_char="6998" end_char="7158">
<ORIGINAL_TEXT>This chain of events, astonishing for a highly developed G-7 nation proud of its health service, is part of a long, painful process embedded in neoliberal dogma.</ORIGINAL_TEXT>
<TOKEN id="token-57-0" pos="word" morph="none" start_char="6998" end_char="7001">This</TOKEN>
<TOKEN id="token-57-1" pos="word" morph="none" start_char="7003" end_char="7007">chain</TOKEN>
<TOKEN id="token-57-2" pos="word" morph="none" start_char="7009" end_char="7010">of</TOKEN>
<TOKEN id="token-57-3" pos="word" morph="none" start_char="7012" end_char="7017">events</TOKEN>
<TOKEN id="token-57-4" pos="punct" morph="none" start_char="7018" end_char="7018">,</TOKEN>
<TOKEN id="token-57-5" pos="word" morph="none" start_char="7020" end_char="7030">astonishing</TOKEN>
<TOKEN id="token-57-6" pos="word" morph="none" start_char="7032" end_char="7034">for</TOKEN>
<TOKEN id="token-57-7" pos="word" morph="none" start_char="7036" end_char="7036">a</TOKEN>
<TOKEN id="token-57-8" pos="word" morph="none" start_char="7038" end_char="7043">highly</TOKEN>
<TOKEN id="token-57-9" pos="word" morph="none" start_char="7045" end_char="7053">developed</TOKEN>
<TOKEN id="token-57-10" pos="unknown" morph="none" start_char="7055" end_char="7057">G-7</TOKEN>
<TOKEN id="token-57-11" pos="word" morph="none" start_char="7059" end_char="7064">nation</TOKEN>
<TOKEN id="token-57-12" pos="word" morph="none" start_char="7066" end_char="7070">proud</TOKEN>
<TOKEN id="token-57-13" pos="word" morph="none" start_char="7072" end_char="7073">of</TOKEN>
<TOKEN id="token-57-14" pos="word" morph="none" start_char="7075" end_char="7077">its</TOKEN>
<TOKEN id="token-57-15" pos="word" morph="none" start_char="7079" end_char="7084">health</TOKEN>
<TOKEN id="token-57-16" pos="word" morph="none" start_char="7086" end_char="7092">service</TOKEN>
<TOKEN id="token-57-17" pos="punct" morph="none" start_char="7093" end_char="7093">,</TOKEN>
<TOKEN id="token-57-18" pos="word" morph="none" start_char="7095" end_char="7096">is</TOKEN>
<TOKEN id="token-57-19" pos="word" morph="none" start_char="7098" end_char="7101">part</TOKEN>
<TOKEN id="token-57-20" pos="word" morph="none" start_char="7103" end_char="7104">of</TOKEN>
<TOKEN id="token-57-21" pos="word" morph="none" start_char="7106" end_char="7106">a</TOKEN>
<TOKEN id="token-57-22" pos="word" morph="none" start_char="7108" end_char="7111">long</TOKEN>
<TOKEN id="token-57-23" pos="punct" morph="none" start_char="7112" end_char="7112">,</TOKEN>
<TOKEN id="token-57-24" pos="word" morph="none" start_char="7114" end_char="7120">painful</TOKEN>
<TOKEN id="token-57-25" pos="word" morph="none" start_char="7122" end_char="7128">process</TOKEN>
<TOKEN id="token-57-26" pos="word" morph="none" start_char="7130" end_char="7137">embedded</TOKEN>
<TOKEN id="token-57-27" pos="word" morph="none" start_char="7139" end_char="7140">in</TOKEN>
<TOKEN id="token-57-28" pos="word" morph="none" start_char="7142" end_char="7151">neoliberal</TOKEN>
<TOKEN id="token-57-29" pos="word" morph="none" start_char="7153" end_char="7157">dogma</TOKEN>
<TOKEN id="token-57-30" pos="punct" morph="none" start_char="7158" end_char="7158">.</TOKEN>
</SEG>
<SEG id="segment-58" start_char="7160" end_char="7266">
<ORIGINAL_TEXT>EU-driven austerity mixed with the profit motive resulted in a very lax attitude towards the health system.</ORIGINAL_TEXT>
<TOKEN id="token-58-0" pos="unknown" morph="none" start_char="7160" end_char="7168">EU-driven</TOKEN>
<TOKEN id="token-58-1" pos="word" morph="none" start_char="7170" end_char="7178">austerity</TOKEN>
<TOKEN id="token-58-2" pos="word" morph="none" start_char="7180" end_char="7184">mixed</TOKEN>
<TOKEN id="token-58-3" pos="word" morph="none" start_char="7186" end_char="7189">with</TOKEN>
<TOKEN id="token-58-4" pos="word" morph="none" start_char="7191" end_char="7193">the</TOKEN>
<TOKEN id="token-58-5" pos="word" morph="none" start_char="7195" end_char="7200">profit</TOKEN>
<TOKEN id="token-58-6" pos="word" morph="none" start_char="7202" end_char="7207">motive</TOKEN>
<TOKEN id="token-58-7" pos="word" morph="none" start_char="7209" end_char="7216">resulted</TOKEN>
<TOKEN id="token-58-8" pos="word" morph="none" start_char="7218" end_char="7219">in</TOKEN>
<TOKEN id="token-58-9" pos="word" morph="none" start_char="7221" end_char="7221">a</TOKEN>
<TOKEN id="token-58-10" pos="word" morph="none" start_char="7223" end_char="7226">very</TOKEN>
<TOKEN id="token-58-11" pos="word" morph="none" start_char="7228" end_char="7230">lax</TOKEN>
<TOKEN id="token-58-12" pos="word" morph="none" start_char="7232" end_char="7239">attitude</TOKEN>
<TOKEN id="token-58-13" pos="word" morph="none" start_char="7241" end_char="7247">towards</TOKEN>
<TOKEN id="token-58-14" pos="word" morph="none" start_char="7249" end_char="7251">the</TOKEN>
<TOKEN id="token-58-15" pos="word" morph="none" start_char="7253" end_char="7258">health</TOKEN>
<TOKEN id="token-58-16" pos="word" morph="none" start_char="7260" end_char="7265">system</TOKEN>
<TOKEN id="token-58-17" pos="punct" morph="none" start_char="7266" end_char="7266">.</TOKEN>
</SEG>
<SEG id="segment-59" start_char="7269" end_char="7526">
<ORIGINAL_TEXT>As Bugault told me, "test kits – very few in number – were always available but mostly for a small group connected to the French government [ former officials of the Ministry of Finance, CEOs of large corporations, oligarchs, media and entertainment moguls].</ORIGINAL_TEXT>
<TOKEN id="token-59-0" pos="word" morph="none" start_char="7269" end_char="7270">As</TOKEN>
<TOKEN id="token-59-1" pos="word" morph="none" start_char="7272" end_char="7278">Bugault</TOKEN>
<TOKEN id="token-59-2" pos="word" morph="none" start_char="7280" end_char="7283">told</TOKEN>
<TOKEN id="token-59-3" pos="word" morph="none" start_char="7285" end_char="7286">me</TOKEN>
<TOKEN id="token-59-4" pos="punct" morph="none" start_char="7287" end_char="7287">,</TOKEN>
<TOKEN id="token-59-5" pos="punct" morph="none" start_char="7289" end_char="7289">"</TOKEN>
<TOKEN id="token-59-6" pos="word" morph="none" start_char="7290" end_char="7293">test</TOKEN>
<TOKEN id="token-59-7" pos="word" morph="none" start_char="7295" end_char="7298">kits</TOKEN>
<TOKEN id="token-59-8" pos="punct" morph="none" start_char="7300" end_char="7300">–</TOKEN>
<TOKEN id="token-59-9" pos="word" morph="none" start_char="7302" end_char="7305">very</TOKEN>
<TOKEN id="token-59-10" pos="word" morph="none" start_char="7307" end_char="7309">few</TOKEN>
<TOKEN id="token-59-11" pos="word" morph="none" start_char="7311" end_char="7312">in</TOKEN>
<TOKEN id="token-59-12" pos="word" morph="none" start_char="7314" end_char="7319">number</TOKEN>
<TOKEN id="token-59-13" pos="punct" morph="none" start_char="7321" end_char="7321">–</TOKEN>
<TOKEN id="token-59-14" pos="word" morph="none" start_char="7323" end_char="7326">were</TOKEN>
<TOKEN id="token-59-15" pos="word" morph="none" start_char="7328" end_char="7333">always</TOKEN>
<TOKEN id="token-59-16" pos="word" morph="none" start_char="7335" end_char="7343">available</TOKEN>
<TOKEN id="token-59-17" pos="word" morph="none" start_char="7345" end_char="7347">but</TOKEN>
<TOKEN id="token-59-18" pos="word" morph="none" start_char="7349" end_char="7354">mostly</TOKEN>
<TOKEN id="token-59-19" pos="word" morph="none" start_char="7356" end_char="7358">for</TOKEN>
<TOKEN id="token-59-20" pos="word" morph="none" start_char="7360" end_char="7360">a</TOKEN>
<TOKEN id="token-59-21" pos="word" morph="none" start_char="7362" end_char="7366">small</TOKEN>
<TOKEN id="token-59-22" pos="word" morph="none" start_char="7368" end_char="7372">group</TOKEN>
<TOKEN id="token-59-23" pos="word" morph="none" start_char="7374" end_char="7382">connected</TOKEN>
<TOKEN id="token-59-24" pos="word" morph="none" start_char="7384" end_char="7385">to</TOKEN>
<TOKEN id="token-59-25" pos="word" morph="none" start_char="7387" end_char="7389">the</TOKEN>
<TOKEN id="token-59-26" pos="word" morph="none" start_char="7391" end_char="7396">French</TOKEN>
<TOKEN id="token-59-27" pos="word" morph="none" start_char="7398" end_char="7407">government</TOKEN>
<TOKEN id="token-59-28" pos="punct" morph="none" start_char="7409" end_char="7409">[</TOKEN>
<TOKEN id="token-59-29" pos="word" morph="none" start_char="7411" end_char="7416">former</TOKEN>
<TOKEN id="token-59-30" pos="word" morph="none" start_char="7418" end_char="7426">officials</TOKEN>
<TOKEN id="token-59-31" pos="word" morph="none" start_char="7428" end_char="7429">of</TOKEN>
<TOKEN id="token-59-32" pos="word" morph="none" start_char="7431" end_char="7433">the</TOKEN>
<TOKEN id="token-59-33" pos="word" morph="none" start_char="7435" end_char="7442">Ministry</TOKEN>
<TOKEN id="token-59-34" pos="word" morph="none" start_char="7444" end_char="7445">of</TOKEN>
<TOKEN id="token-59-35" pos="word" morph="none" start_char="7447" end_char="7453">Finance</TOKEN>
<TOKEN id="token-59-36" pos="punct" morph="none" start_char="7454" end_char="7454">,</TOKEN>
<TOKEN id="token-59-37" pos="word" morph="none" start_char="7456" end_char="7459">CEOs</TOKEN>
<TOKEN id="token-59-38" pos="word" morph="none" start_char="7461" end_char="7462">of</TOKEN>
<TOKEN id="token-59-39" pos="word" morph="none" start_char="7464" end_char="7468">large</TOKEN>
<TOKEN id="token-59-40" pos="word" morph="none" start_char="7470" end_char="7481">corporations</TOKEN>
<TOKEN id="token-59-41" pos="punct" morph="none" start_char="7482" end_char="7482">,</TOKEN>
<TOKEN id="token-59-42" pos="word" morph="none" start_char="7484" end_char="7492">oligarchs</TOKEN>
<TOKEN id="token-59-43" pos="punct" morph="none" start_char="7493" end_char="7493">,</TOKEN>
<TOKEN id="token-59-44" pos="word" morph="none" start_char="7495" end_char="7499">media</TOKEN>
<TOKEN id="token-59-45" pos="word" morph="none" start_char="7501" end_char="7503">and</TOKEN>
<TOKEN id="token-59-46" pos="word" morph="none" start_char="7505" end_char="7517">entertainment</TOKEN>
<TOKEN id="token-59-47" pos="word" morph="none" start_char="7519" end_char="7524">moguls</TOKEN>
<TOKEN id="token-59-48" pos="punct" morph="none" start_char="7525" end_char="7526">].</TOKEN>
</SEG>
<SEG id="segment-60" start_char="7528" end_char="7626">
<ORIGINAL_TEXT>Same for chloroquine, which this government did everything to make inaccessible for the population.</ORIGINAL_TEXT>
<TOKEN id="token-60-0" pos="word" morph="none" start_char="7528" end_char="7531">Same</TOKEN>
<TOKEN id="token-60-1" pos="word" morph="none" start_char="7533" end_char="7535">for</TOKEN>
<TOKEN id="token-60-2" pos="word" morph="none" start_char="7537" end_char="7547">chloroquine</TOKEN>
<TOKEN id="token-60-3" pos="punct" morph="none" start_char="7548" end_char="7548">,</TOKEN>
<TOKEN id="token-60-4" pos="word" morph="none" start_char="7550" end_char="7554">which</TOKEN>
<TOKEN id="token-60-5" pos="word" morph="none" start_char="7556" end_char="7559">this</TOKEN>
<TOKEN id="token-60-6" pos="word" morph="none" start_char="7561" end_char="7570">government</TOKEN>
<TOKEN id="token-60-7" pos="word" morph="none" start_char="7572" end_char="7574">did</TOKEN>
<TOKEN id="token-60-8" pos="word" morph="none" start_char="7576" end_char="7585">everything</TOKEN>
<TOKEN id="token-60-9" pos="word" morph="none" start_char="7587" end_char="7588">to</TOKEN>
<TOKEN id="token-60-10" pos="word" morph="none" start_char="7590" end_char="7593">make</TOKEN>
<TOKEN id="token-60-11" pos="word" morph="none" start_char="7595" end_char="7606">inaccessible</TOKEN>
<TOKEN id="token-60-12" pos="word" morph="none" start_char="7608" end_char="7610">for</TOKEN>
<TOKEN id="token-60-13" pos="word" morph="none" start_char="7612" end_char="7614">the</TOKEN>
<TOKEN id="token-60-14" pos="word" morph="none" start_char="7616" end_char="7625">population</TOKEN>
<TOKEN id="token-60-15" pos="punct" morph="none" start_char="7626" end_char="7626">.</TOKEN>
</SEG>
<SEG id="segment-61" start_char="7629" end_char="7742">
<ORIGINAL_TEXT>They did not make life easy for Professor Raoult – he received death threats and was intimidated by ‘journalists.’</ORIGINAL_TEXT>
<TOKEN id="token-61-0" pos="word" morph="none" start_char="7629" end_char="7632">They</TOKEN>
<TOKEN id="token-61-1" pos="word" morph="none" start_char="7634" end_char="7636">did</TOKEN>
<TOKEN id="token-61-2" pos="word" morph="none" start_char="7638" end_char="7640">not</TOKEN>
<TOKEN id="token-61-3" pos="word" morph="none" start_char="7642" end_char="7645">make</TOKEN>
<TOKEN id="token-61-4" pos="word" morph="none" start_char="7647" end_char="7650">life</TOKEN>
<TOKEN id="token-61-5" pos="word" morph="none" start_char="7652" end_char="7655">easy</TOKEN>
<TOKEN id="token-61-6" pos="word" morph="none" start_char="7657" end_char="7659">for</TOKEN>
<TOKEN id="token-61-7" pos="word" morph="none" start_char="7661" end_char="7669">Professor</TOKEN>
<TOKEN id="token-61-8" pos="word" morph="none" start_char="7671" end_char="7676">Raoult</TOKEN>
<TOKEN id="token-61-9" pos="punct" morph="none" start_char="7678" end_char="7678">–</TOKEN>
<TOKEN id="token-61-10" pos="word" morph="none" start_char="7680" end_char="7681">he</TOKEN>
<TOKEN id="token-61-11" pos="word" morph="none" start_char="7683" end_char="7690">received</TOKEN>
<TOKEN id="token-61-12" pos="word" morph="none" start_char="7692" end_char="7696">death</TOKEN>
<TOKEN id="token-61-13" pos="word" morph="none" start_char="7698" end_char="7704">threats</TOKEN>
<TOKEN id="token-61-14" pos="word" morph="none" start_char="7706" end_char="7708">and</TOKEN>
<TOKEN id="token-61-15" pos="word" morph="none" start_char="7710" end_char="7712">was</TOKEN>
<TOKEN id="token-61-16" pos="word" morph="none" start_char="7714" end_char="7724">intimidated</TOKEN>
<TOKEN id="token-61-17" pos="word" morph="none" start_char="7726" end_char="7727">by</TOKEN>
<TOKEN id="token-61-18" pos="punct" morph="none" start_char="7729" end_char="7729">‘</TOKEN>
<TOKEN id="token-61-19" pos="word" morph="none" start_char="7730" end_char="7740">journalists</TOKEN>
<TOKEN id="token-61-20" pos="punct" morph="none" start_char="7741" end_char="7742">.’</TOKEN>
</SEG>
<SEG id="segment-62" start_char="7745" end_char="7782">
<ORIGINAL_TEXT>And they did not protect vital stocks.</ORIGINAL_TEXT>
<TOKEN id="token-62-0" pos="word" morph="none" start_char="7745" end_char="7747">And</TOKEN>
<TOKEN id="token-62-1" pos="word" morph="none" start_char="7749" end_char="7752">they</TOKEN>
<TOKEN id="token-62-2" pos="word" morph="none" start_char="7754" end_char="7756">did</TOKEN>
<TOKEN id="token-62-3" pos="word" morph="none" start_char="7758" end_char="7760">not</TOKEN>
<TOKEN id="token-62-4" pos="word" morph="none" start_char="7762" end_char="7768">protect</TOKEN>
<TOKEN id="token-62-5" pos="word" morph="none" start_char="7770" end_char="7774">vital</TOKEN>
<TOKEN id="token-62-6" pos="word" morph="none" start_char="7776" end_char="7781">stocks</TOKEN>
<TOKEN id="token-62-7" pos="punct" morph="none" start_char="7782" end_char="7782">.</TOKEN>
</SEG>
<SEG id="segment-63" start_char="7784" end_char="7933">
<ORIGINAL_TEXT>Still under the Hollande government, there was a conscious liquidation of the stock of masks – which had existed in large quantities in all hospitals.</ORIGINAL_TEXT>
<TOKEN id="token-63-0" pos="word" morph="none" start_char="7784" end_char="7788">Still</TOKEN>
<TOKEN id="token-63-1" pos="word" morph="none" start_char="7790" end_char="7794">under</TOKEN>
<TOKEN id="token-63-2" pos="word" morph="none" start_char="7796" end_char="7798">the</TOKEN>
<TOKEN id="token-63-3" pos="word" morph="none" start_char="7800" end_char="7807">Hollande</TOKEN>
<TOKEN id="token-63-4" pos="word" morph="none" start_char="7809" end_char="7818">government</TOKEN>
<TOKEN id="token-63-5" pos="punct" morph="none" start_char="7819" end_char="7819">,</TOKEN>
<TOKEN id="token-63-6" pos="word" morph="none" start_char="7821" end_char="7825">there</TOKEN>
<TOKEN id="token-63-7" pos="word" morph="none" start_char="7827" end_char="7829">was</TOKEN>
<TOKEN id="token-63-8" pos="word" morph="none" start_char="7831" end_char="7831">a</TOKEN>
<TOKEN id="token-63-9" pos="word" morph="none" start_char="7833" end_char="7841">conscious</TOKEN>
<TOKEN id="token-63-10" pos="word" morph="none" start_char="7843" end_char="7853">liquidation</TOKEN>
<TOKEN id="token-63-11" pos="word" morph="none" start_char="7855" end_char="7856">of</TOKEN>
<TOKEN id="token-63-12" pos="word" morph="none" start_char="7858" end_char="7860">the</TOKEN>
<TOKEN id="token-63-13" pos="word" morph="none" start_char="7862" end_char="7866">stock</TOKEN>
<TOKEN id="token-63-14" pos="word" morph="none" start_char="7868" end_char="7869">of</TOKEN>
<TOKEN id="token-63-15" pos="word" morph="none" start_char="7871" end_char="7875">masks</TOKEN>
<TOKEN id="token-63-16" pos="punct" morph="none" start_char="7877" end_char="7877">–</TOKEN>
<TOKEN id="token-63-17" pos="word" morph="none" start_char="7879" end_char="7883">which</TOKEN>
<TOKEN id="token-63-18" pos="word" morph="none" start_char="7885" end_char="7887">had</TOKEN>
<TOKEN id="token-63-19" pos="word" morph="none" start_char="7889" end_char="7895">existed</TOKEN>
<TOKEN id="token-63-20" pos="word" morph="none" start_char="7897" end_char="7898">in</TOKEN>
<TOKEN id="token-63-21" pos="word" morph="none" start_char="7900" end_char="7904">large</TOKEN>
<TOKEN id="token-63-22" pos="word" morph="none" start_char="7906" end_char="7915">quantities</TOKEN>
<TOKEN id="token-63-23" pos="word" morph="none" start_char="7917" end_char="7918">in</TOKEN>
<TOKEN id="token-63-24" pos="word" morph="none" start_char="7920" end_char="7922">all</TOKEN>
<TOKEN id="token-63-25" pos="word" morph="none" start_char="7924" end_char="7932">hospitals</TOKEN>
<TOKEN id="token-63-26" pos="punct" morph="none" start_char="7933" end_char="7933">.</TOKEN>
</SEG>
<SEG id="segment-64" start_char="7935" end_char="8033">
<ORIGINAL_TEXT>Not to mention that the suppression of hospital beds and hospital means accelerated under Sarkozy."</ORIGINAL_TEXT>
<TOKEN id="token-64-0" pos="word" morph="none" start_char="7935" end_char="7937">Not</TOKEN>
<TOKEN id="token-64-1" pos="word" morph="none" start_char="7939" end_char="7940">to</TOKEN>
<TOKEN id="token-64-2" pos="word" morph="none" start_char="7942" end_char="7948">mention</TOKEN>
<TOKEN id="token-64-3" pos="word" morph="none" start_char="7950" end_char="7953">that</TOKEN>
<TOKEN id="token-64-4" pos="word" morph="none" start_char="7955" end_char="7957">the</TOKEN>
<TOKEN id="token-64-5" pos="word" morph="none" start_char="7959" end_char="7969">suppression</TOKEN>
<TOKEN id="token-64-6" pos="word" morph="none" start_char="7971" end_char="7972">of</TOKEN>
<TOKEN id="token-64-7" pos="word" morph="none" start_char="7974" end_char="7981">hospital</TOKEN>
<TOKEN id="token-64-8" pos="word" morph="none" start_char="7983" end_char="7986">beds</TOKEN>
<TOKEN id="token-64-9" pos="word" morph="none" start_char="7988" end_char="7990">and</TOKEN>
<TOKEN id="token-64-10" pos="word" morph="none" start_char="7992" end_char="7999">hospital</TOKEN>
<TOKEN id="token-64-11" pos="word" morph="none" start_char="8001" end_char="8005">means</TOKEN>
<TOKEN id="token-64-12" pos="word" morph="none" start_char="8007" end_char="8017">accelerated</TOKEN>
<TOKEN id="token-64-13" pos="word" morph="none" start_char="8019" end_char="8023">under</TOKEN>
<TOKEN id="token-64-14" pos="word" morph="none" start_char="8025" end_char="8031">Sarkozy</TOKEN>
<TOKEN id="token-64-15" pos="punct" morph="none" start_char="8032" end_char="8033">."</TOKEN>
</SEG>
<SEG id="segment-65" start_char="8036" end_char="8168">
<ORIGINAL_TEXT>This ties in with anguished reports by French citizens of nurses now having to use trash bags due to the lack of proper medical gear.</ORIGINAL_TEXT>
<TOKEN id="token-65-0" pos="word" morph="none" start_char="8036" end_char="8039">This</TOKEN>
<TOKEN id="token-65-1" pos="word" morph="none" start_char="8041" end_char="8044">ties</TOKEN>
<TOKEN id="token-65-2" pos="word" morph="none" start_char="8046" end_char="8047">in</TOKEN>
<TOKEN id="token-65-3" pos="word" morph="none" start_char="8049" end_char="8052">with</TOKEN>
<TOKEN id="token-65-4" pos="word" morph="none" start_char="8054" end_char="8062">anguished</TOKEN>
<TOKEN id="token-65-5" pos="word" morph="none" start_char="8064" end_char="8070">reports</TOKEN>
<TOKEN id="token-65-6" pos="word" morph="none" start_char="8072" end_char="8073">by</TOKEN>
<TOKEN id="token-65-7" pos="word" morph="none" start_char="8075" end_char="8080">French</TOKEN>
<TOKEN id="token-65-8" pos="word" morph="none" start_char="8082" end_char="8089">citizens</TOKEN>
<TOKEN id="token-65-9" pos="word" morph="none" start_char="8091" end_char="8092">of</TOKEN>
<TOKEN id="token-65-10" pos="word" morph="none" start_char="8094" end_char="8099">nurses</TOKEN>
<TOKEN id="token-65-11" pos="word" morph="none" start_char="8101" end_char="8103">now</TOKEN>
<TOKEN id="token-65-12" pos="word" morph="none" start_char="8105" end_char="8110">having</TOKEN>
<TOKEN id="token-65-13" pos="word" morph="none" start_char="8112" end_char="8113">to</TOKEN>
<TOKEN id="token-65-14" pos="word" morph="none" start_char="8115" end_char="8117">use</TOKEN>
<TOKEN id="token-65-15" pos="word" morph="none" start_char="8119" end_char="8123">trash</TOKEN>
<TOKEN id="token-65-16" pos="word" morph="none" start_char="8125" end_char="8128">bags</TOKEN>
<TOKEN id="token-65-17" pos="word" morph="none" start_char="8130" end_char="8132">due</TOKEN>
<TOKEN id="token-65-18" pos="word" morph="none" start_char="8134" end_char="8135">to</TOKEN>
<TOKEN id="token-65-19" pos="word" morph="none" start_char="8137" end_char="8139">the</TOKEN>
<TOKEN id="token-65-20" pos="word" morph="none" start_char="8141" end_char="8144">lack</TOKEN>
<TOKEN id="token-65-21" pos="word" morph="none" start_char="8146" end_char="8147">of</TOKEN>
<TOKEN id="token-65-22" pos="word" morph="none" start_char="8149" end_char="8154">proper</TOKEN>
<TOKEN id="token-65-23" pos="word" morph="none" start_char="8156" end_char="8162">medical</TOKEN>
<TOKEN id="token-65-24" pos="word" morph="none" start_char="8164" end_char="8167">gear</TOKEN>
<TOKEN id="token-65-25" pos="punct" morph="none" start_char="8168" end_char="8168">.</TOKEN>
</SEG>
<SEG id="segment-66" start_char="8171" end_char="8522">
<ORIGINAL_TEXT>At the same time, in another astonishing development, the French state refuses to requisition private hospitals and clinics – which are practically empty at this stage – even as the president of their own association, Lamine Garbi, has pleaded for such a public service initiative: "I solemnly demand that we are requisitioned to help public hospitals.</ORIGINAL_TEXT>
<TOKEN id="token-66-0" pos="word" morph="none" start_char="8171" end_char="8172">At</TOKEN>
<TOKEN id="token-66-1" pos="word" morph="none" start_char="8174" end_char="8176">the</TOKEN>
<TOKEN id="token-66-2" pos="word" morph="none" start_char="8178" end_char="8181">same</TOKEN>
<TOKEN id="token-66-3" pos="word" morph="none" start_char="8183" end_char="8186">time</TOKEN>
<TOKEN id="token-66-4" pos="punct" morph="none" start_char="8187" end_char="8187">,</TOKEN>
<TOKEN id="token-66-5" pos="word" morph="none" start_char="8189" end_char="8190">in</TOKEN>
<TOKEN id="token-66-6" pos="word" morph="none" start_char="8192" end_char="8198">another</TOKEN>
<TOKEN id="token-66-7" pos="word" morph="none" start_char="8200" end_char="8210">astonishing</TOKEN>
<TOKEN id="token-66-8" pos="word" morph="none" start_char="8212" end_char="8222">development</TOKEN>
<TOKEN id="token-66-9" pos="punct" morph="none" start_char="8223" end_char="8223">,</TOKEN>
<TOKEN id="token-66-10" pos="word" morph="none" start_char="8225" end_char="8227">the</TOKEN>
<TOKEN id="token-66-11" pos="word" morph="none" start_char="8229" end_char="8234">French</TOKEN>
<TOKEN id="token-66-12" pos="word" morph="none" start_char="8236" end_char="8240">state</TOKEN>
<TOKEN id="token-66-13" pos="word" morph="none" start_char="8242" end_char="8248">refuses</TOKEN>
<TOKEN id="token-66-14" pos="word" morph="none" start_char="8250" end_char="8251">to</TOKEN>
<TOKEN id="token-66-15" pos="word" morph="none" start_char="8253" end_char="8263">requisition</TOKEN>
<TOKEN id="token-66-16" pos="word" morph="none" start_char="8265" end_char="8271">private</TOKEN>
<TOKEN id="token-66-17" pos="word" morph="none" start_char="8273" end_char="8281">hospitals</TOKEN>
<TOKEN id="token-66-18" pos="word" morph="none" start_char="8283" end_char="8285">and</TOKEN>
<TOKEN id="token-66-19" pos="word" morph="none" start_char="8287" end_char="8293">clinics</TOKEN>
<TOKEN id="token-66-20" pos="punct" morph="none" start_char="8295" end_char="8295">–</TOKEN>
<TOKEN id="token-66-21" pos="word" morph="none" start_char="8297" end_char="8301">which</TOKEN>
<TOKEN id="token-66-22" pos="word" morph="none" start_char="8303" end_char="8305">are</TOKEN>
<TOKEN id="token-66-23" pos="word" morph="none" start_char="8307" end_char="8317">practically</TOKEN>
<TOKEN id="token-66-24" pos="word" morph="none" start_char="8319" end_char="8323">empty</TOKEN>
<TOKEN id="token-66-25" pos="word" morph="none" start_char="8325" end_char="8326">at</TOKEN>
<TOKEN id="token-66-26" pos="word" morph="none" start_char="8328" end_char="8331">this</TOKEN>
<TOKEN id="token-66-27" pos="word" morph="none" start_char="8333" end_char="8337">stage</TOKEN>
<TOKEN id="token-66-28" pos="punct" morph="none" start_char="8339" end_char="8339">–</TOKEN>
<TOKEN id="token-66-29" pos="word" morph="none" start_char="8341" end_char="8344">even</TOKEN>
<TOKEN id="token-66-30" pos="word" morph="none" start_char="8346" end_char="8347">as</TOKEN>
<TOKEN id="token-66-31" pos="word" morph="none" start_char="8349" end_char="8351">the</TOKEN>
<TOKEN id="token-66-32" pos="word" morph="none" start_char="8353" end_char="8361">president</TOKEN>
<TOKEN id="token-66-33" pos="word" morph="none" start_char="8363" end_char="8364">of</TOKEN>
<TOKEN id="token-66-34" pos="word" morph="none" start_char="8366" end_char="8370">their</TOKEN>
<TOKEN id="token-66-35" pos="word" morph="none" start_char="8372" end_char="8374">own</TOKEN>
<TOKEN id="token-66-36" pos="word" morph="none" start_char="8376" end_char="8386">association</TOKEN>
<TOKEN id="token-66-37" pos="punct" morph="none" start_char="8387" end_char="8387">,</TOKEN>
<TOKEN id="token-66-38" pos="word" morph="none" start_char="8389" end_char="8394">Lamine</TOKEN>
<TOKEN id="token-66-39" pos="word" morph="none" start_char="8396" end_char="8400">Garbi</TOKEN>
<TOKEN id="token-66-40" pos="punct" morph="none" start_char="8401" end_char="8401">,</TOKEN>
<TOKEN id="token-66-41" pos="word" morph="none" start_char="8403" end_char="8405">has</TOKEN>
<TOKEN id="token-66-42" pos="word" morph="none" start_char="8407" end_char="8413">pleaded</TOKEN>
<TOKEN id="token-66-43" pos="word" morph="none" start_char="8415" end_char="8417">for</TOKEN>
<TOKEN id="token-66-44" pos="word" morph="none" start_char="8419" end_char="8422">such</TOKEN>
<TOKEN id="token-66-45" pos="word" morph="none" start_char="8424" end_char="8424">a</TOKEN>
<TOKEN id="token-66-46" pos="word" morph="none" start_char="8426" end_char="8431">public</TOKEN>
<TOKEN id="token-66-47" pos="word" morph="none" start_char="8433" end_char="8439">service</TOKEN>
<TOKEN id="token-66-48" pos="word" morph="none" start_char="8441" end_char="8450">initiative</TOKEN>
<TOKEN id="token-66-49" pos="punct" morph="none" start_char="8451" end_char="8451">:</TOKEN>
<TOKEN id="token-66-50" pos="punct" morph="none" start_char="8453" end_char="8453">"</TOKEN>
<TOKEN id="token-66-51" pos="word" morph="none" start_char="8454" end_char="8454">I</TOKEN>
<TOKEN id="token-66-52" pos="word" morph="none" start_char="8456" end_char="8463">solemnly</TOKEN>
<TOKEN id="token-66-53" pos="word" morph="none" start_char="8465" end_char="8470">demand</TOKEN>
<TOKEN id="token-66-54" pos="word" morph="none" start_char="8472" end_char="8475">that</TOKEN>
<TOKEN id="token-66-55" pos="word" morph="none" start_char="8477" end_char="8478">we</TOKEN>
<TOKEN id="token-66-56" pos="word" morph="none" start_char="8480" end_char="8482">are</TOKEN>
<TOKEN id="token-66-57" pos="word" morph="none" start_char="8484" end_char="8496">requisitioned</TOKEN>
<TOKEN id="token-66-58" pos="word" morph="none" start_char="8498" end_char="8499">to</TOKEN>
<TOKEN id="token-66-59" pos="word" morph="none" start_char="8501" end_char="8504">help</TOKEN>
<TOKEN id="token-66-60" pos="word" morph="none" start_char="8506" end_char="8511">public</TOKEN>
<TOKEN id="token-66-61" pos="word" morph="none" start_char="8513" end_char="8521">hospitals</TOKEN>
<TOKEN id="token-66-62" pos="punct" morph="none" start_char="8522" end_char="8522">.</TOKEN>
</SEG>
<SEG id="segment-67" start_char="8524" end_char="8551">
<ORIGINAL_TEXT>Our facilities are prepared.</ORIGINAL_TEXT>
<TOKEN id="token-67-0" pos="word" morph="none" start_char="8524" end_char="8526">Our</TOKEN>
<TOKEN id="token-67-1" pos="word" morph="none" start_char="8528" end_char="8537">facilities</TOKEN>
<TOKEN id="token-67-2" pos="word" morph="none" start_char="8539" end_char="8541">are</TOKEN>
<TOKEN id="token-67-3" pos="word" morph="none" start_char="8543" end_char="8550">prepared</TOKEN>
<TOKEN id="token-67-4" pos="punct" morph="none" start_char="8551" end_char="8551">.</TOKEN>
</SEG>
<SEG id="segment-68" start_char="8553" end_char="8619">
<ORIGINAL_TEXT>The wave that surprised the east of France must teach us a lesson."</ORIGINAL_TEXT>
<TOKEN id="token-68-0" pos="word" morph="none" start_char="8553" end_char="8555">The</TOKEN>
<TOKEN id="token-68-1" pos="word" morph="none" start_char="8557" end_char="8560">wave</TOKEN>
<TOKEN id="token-68-2" pos="word" morph="none" start_char="8562" end_char="8565">that</TOKEN>
<TOKEN id="token-68-3" pos="word" morph="none" start_char="8567" end_char="8575">surprised</TOKEN>
<TOKEN id="token-68-4" pos="word" morph="none" start_char="8577" end_char="8579">the</TOKEN>
<TOKEN id="token-68-5" pos="word" morph="none" start_char="8581" end_char="8584">east</TOKEN>
<TOKEN id="token-68-6" pos="word" morph="none" start_char="8586" end_char="8587">of</TOKEN>
<TOKEN id="token-68-7" pos="word" morph="none" start_char="8589" end_char="8594">France</TOKEN>
<TOKEN id="token-68-8" pos="word" morph="none" start_char="8596" end_char="8599">must</TOKEN>
<TOKEN id="token-68-9" pos="word" morph="none" start_char="8601" end_char="8605">teach</TOKEN>
<TOKEN id="token-68-10" pos="word" morph="none" start_char="8607" end_char="8608">us</TOKEN>
<TOKEN id="token-68-11" pos="word" morph="none" start_char="8610" end_char="8610">a</TOKEN>
<TOKEN id="token-68-12" pos="word" morph="none" start_char="8612" end_char="8617">lesson</TOKEN>
<TOKEN id="token-68-13" pos="punct" morph="none" start_char="8618" end_char="8619">."</TOKEN>
</SEG>
<SEG id="segment-69" start_char="8622" end_char="8902">
<ORIGINAL_TEXT>Bugault reconfirms the health situation in France "is very serious and will become even worse due to these political decisions – absence of masks, political refusal to massively test people, refusal of free access to chloroquine – in a context of supreme distress at the hospitals.</ORIGINAL_TEXT>
<TOKEN id="token-69-0" pos="word" morph="none" start_char="8622" end_char="8628">Bugault</TOKEN>
<TOKEN id="token-69-1" pos="word" morph="none" start_char="8630" end_char="8639">reconfirms</TOKEN>
<TOKEN id="token-69-2" pos="word" morph="none" start_char="8641" end_char="8643">the</TOKEN>
<TOKEN id="token-69-3" pos="word" morph="none" start_char="8645" end_char="8650">health</TOKEN>
<TOKEN id="token-69-4" pos="word" morph="none" start_char="8652" end_char="8660">situation</TOKEN>
<TOKEN id="token-69-5" pos="word" morph="none" start_char="8662" end_char="8663">in</TOKEN>
<TOKEN id="token-69-6" pos="word" morph="none" start_char="8665" end_char="8670">France</TOKEN>
<TOKEN id="token-69-7" pos="punct" morph="none" start_char="8672" end_char="8672">"</TOKEN>
<TOKEN id="token-69-8" pos="word" morph="none" start_char="8673" end_char="8674">is</TOKEN>
<TOKEN id="token-69-9" pos="word" morph="none" start_char="8676" end_char="8679">very</TOKEN>
<TOKEN id="token-69-10" pos="word" morph="none" start_char="8681" end_char="8687">serious</TOKEN>
<TOKEN id="token-69-11" pos="word" morph="none" start_char="8689" end_char="8691">and</TOKEN>
<TOKEN id="token-69-12" pos="word" morph="none" start_char="8693" end_char="8696">will</TOKEN>
<TOKEN id="token-69-13" pos="word" morph="none" start_char="8698" end_char="8703">become</TOKEN>
<TOKEN id="token-69-14" pos="word" morph="none" start_char="8705" end_char="8708">even</TOKEN>
<TOKEN id="token-69-15" pos="word" morph="none" start_char="8710" end_char="8714">worse</TOKEN>
<TOKEN id="token-69-16" pos="word" morph="none" start_char="8716" end_char="8718">due</TOKEN>
<TOKEN id="token-69-17" pos="word" morph="none" start_char="8720" end_char="8721">to</TOKEN>
<TOKEN id="token-69-18" pos="word" morph="none" start_char="8723" end_char="8727">these</TOKEN>
<TOKEN id="token-69-19" pos="word" morph="none" start_char="8729" end_char="8737">political</TOKEN>
<TOKEN id="token-69-20" pos="word" morph="none" start_char="8739" end_char="8747">decisions</TOKEN>
<TOKEN id="token-69-21" pos="punct" morph="none" start_char="8749" end_char="8749">–</TOKEN>
<TOKEN id="token-69-22" pos="word" morph="none" start_char="8751" end_char="8757">absence</TOKEN>
<TOKEN id="token-69-23" pos="word" morph="none" start_char="8759" end_char="8760">of</TOKEN>
<TOKEN id="token-69-24" pos="word" morph="none" start_char="8762" end_char="8766">masks</TOKEN>
<TOKEN id="token-69-25" pos="punct" morph="none" start_char="8767" end_char="8767">,</TOKEN>
<TOKEN id="token-69-26" pos="word" morph="none" start_char="8769" end_char="8777">political</TOKEN>
<TOKEN id="token-69-27" pos="word" morph="none" start_char="8779" end_char="8785">refusal</TOKEN>
<TOKEN id="token-69-28" pos="word" morph="none" start_char="8787" end_char="8788">to</TOKEN>
<TOKEN id="token-69-29" pos="word" morph="none" start_char="8790" end_char="8798">massively</TOKEN>
<TOKEN id="token-69-30" pos="word" morph="none" start_char="8800" end_char="8803">test</TOKEN>
<TOKEN id="token-69-31" pos="word" morph="none" start_char="8805" end_char="8810">people</TOKEN>
<TOKEN id="token-69-32" pos="punct" morph="none" start_char="8811" end_char="8811">,</TOKEN>
<TOKEN id="token-69-33" pos="word" morph="none" start_char="8813" end_char="8819">refusal</TOKEN>
<TOKEN id="token-69-34" pos="word" morph="none" start_char="8821" end_char="8822">of</TOKEN>
<TOKEN id="token-69-35" pos="word" morph="none" start_char="8824" end_char="8827">free</TOKEN>
<TOKEN id="token-69-36" pos="word" morph="none" start_char="8829" end_char="8834">access</TOKEN>
<TOKEN id="token-69-37" pos="word" morph="none" start_char="8836" end_char="8837">to</TOKEN>
<TOKEN id="token-69-38" pos="word" morph="none" start_char="8839" end_char="8849">chloroquine</TOKEN>
<TOKEN id="token-69-39" pos="punct" morph="none" start_char="8851" end_char="8851">–</TOKEN>
<TOKEN id="token-69-40" pos="word" morph="none" start_char="8853" end_char="8854">in</TOKEN>
<TOKEN id="token-69-41" pos="word" morph="none" start_char="8856" end_char="8856">a</TOKEN>
<TOKEN id="token-69-42" pos="word" morph="none" start_char="8858" end_char="8864">context</TOKEN>
<TOKEN id="token-69-43" pos="word" morph="none" start_char="8866" end_char="8867">of</TOKEN>
<TOKEN id="token-69-44" pos="word" morph="none" start_char="8869" end_char="8875">supreme</TOKEN>
<TOKEN id="token-69-45" pos="word" morph="none" start_char="8877" end_char="8884">distress</TOKEN>
<TOKEN id="token-69-46" pos="word" morph="none" start_char="8886" end_char="8887">at</TOKEN>
<TOKEN id="token-69-47" pos="word" morph="none" start_char="8889" end_char="8891">the</TOKEN>
<TOKEN id="token-69-48" pos="word" morph="none" start_char="8893" end_char="8901">hospitals</TOKEN>
<TOKEN id="token-69-49" pos="punct" morph="none" start_char="8902" end_char="8902">.</TOKEN>
</SEG>
<SEG id="segment-70" start_char="8904" end_char="8952">
<ORIGINAL_TEXT>This will last and destitution will be the norm."</ORIGINAL_TEXT>
<TOKEN id="token-70-0" pos="word" morph="none" start_char="8904" end_char="8907">This</TOKEN>
<TOKEN id="token-70-1" pos="word" morph="none" start_char="8909" end_char="8912">will</TOKEN>
<TOKEN id="token-70-2" pos="word" morph="none" start_char="8914" end_char="8917">last</TOKEN>
<TOKEN id="token-70-3" pos="word" morph="none" start_char="8919" end_char="8921">and</TOKEN>
<TOKEN id="token-70-4" pos="word" morph="none" start_char="8923" end_char="8933">destitution</TOKEN>
<TOKEN id="token-70-5" pos="word" morph="none" start_char="8935" end_char="8938">will</TOKEN>
<TOKEN id="token-70-6" pos="word" morph="none" start_char="8940" end_char="8941">be</TOKEN>
<TOKEN id="token-70-7" pos="word" morph="none" start_char="8943" end_char="8945">the</TOKEN>
<TOKEN id="token-70-8" pos="word" morph="none" start_char="8947" end_char="8950">norm</TOKEN>
<TOKEN id="token-70-9" pos="punct" morph="none" start_char="8951" end_char="8952">."</TOKEN>
</SEG>
<SEG id="segment-71" start_char="8955" end_char="8976">
<ORIGINAL_TEXT>Professor vs president</ORIGINAL_TEXT>
<TOKEN id="token-71-0" pos="word" morph="none" start_char="8955" end_char="8963">Professor</TOKEN>
<TOKEN id="token-71-1" pos="word" morph="none" start_char="8965" end_char="8966">vs</TOKEN>
<TOKEN id="token-71-2" pos="word" morph="none" start_char="8968" end_char="8976">president</TOKEN>
</SEG>
<SEG id="segment-72" start_char="8979" end_char="9137">
<ORIGINAL_TEXT>In an explosive development on Tuesday, Raoult said he’s not participating in Macron’s scientific council anymore, even though he’s not quitting it altogether.</ORIGINAL_TEXT>
<TOKEN id="token-72-0" pos="word" morph="none" start_char="8979" end_char="8980">In</TOKEN>
<TOKEN id="token-72-1" pos="word" morph="none" start_char="8982" end_char="8983">an</TOKEN>
<TOKEN id="token-72-2" pos="word" morph="none" start_char="8985" end_char="8993">explosive</TOKEN>
<TOKEN id="token-72-3" pos="word" morph="none" start_char="8995" end_char="9005">development</TOKEN>
<TOKEN id="token-72-4" pos="word" morph="none" start_char="9007" end_char="9008">on</TOKEN>
<TOKEN id="token-72-5" pos="word" morph="none" start_char="9010" end_char="9016">Tuesday</TOKEN>
<TOKEN id="token-72-6" pos="punct" morph="none" start_char="9017" end_char="9017">,</TOKEN>
<TOKEN id="token-72-7" pos="word" morph="none" start_char="9019" end_char="9024">Raoult</TOKEN>
<TOKEN id="token-72-8" pos="word" morph="none" start_char="9026" end_char="9029">said</TOKEN>
<TOKEN id="token-72-9" pos="word" morph="none" start_char="9031" end_char="9034">he’s</TOKEN>
<TOKEN id="token-72-10" pos="word" morph="none" start_char="9036" end_char="9038">not</TOKEN>
<TOKEN id="token-72-11" pos="word" morph="none" start_char="9040" end_char="9052">participating</TOKEN>
<TOKEN id="token-72-12" pos="word" morph="none" start_char="9054" end_char="9055">in</TOKEN>
<TOKEN id="token-72-13" pos="word" morph="none" start_char="9057" end_char="9064">Macron’s</TOKEN>
<TOKEN id="token-72-14" pos="word" morph="none" start_char="9066" end_char="9075">scientific</TOKEN>
<TOKEN id="token-72-15" pos="word" morph="none" start_char="9077" end_char="9083">council</TOKEN>
<TOKEN id="token-72-16" pos="word" morph="none" start_char="9085" end_char="9091">anymore</TOKEN>
<TOKEN id="token-72-17" pos="punct" morph="none" start_char="9092" end_char="9092">,</TOKEN>
<TOKEN id="token-72-18" pos="word" morph="none" start_char="9094" end_char="9097">even</TOKEN>
<TOKEN id="token-72-19" pos="word" morph="none" start_char="9099" end_char="9104">though</TOKEN>
<TOKEN id="token-72-20" pos="word" morph="none" start_char="9106" end_char="9109">he’s</TOKEN>
<TOKEN id="token-72-21" pos="word" morph="none" start_char="9111" end_char="9113">not</TOKEN>
<TOKEN id="token-72-22" pos="word" morph="none" start_char="9115" end_char="9122">quitting</TOKEN>
<TOKEN id="token-72-23" pos="word" morph="none" start_char="9124" end_char="9125">it</TOKEN>
<TOKEN id="token-72-24" pos="word" morph="none" start_char="9127" end_char="9136">altogether</TOKEN>
<TOKEN id="token-72-25" pos="punct" morph="none" start_char="9137" end_char="9137">.</TOKEN>
</SEG>
<SEG id="segment-73" start_char="9139" end_char="9286">
<ORIGINAL_TEXT>Raoult once again insists on massive testing on a national scale to detect suspected cases, and then isolate and treat patients who tested positive.</ORIGINAL_TEXT>
<TOKEN id="token-73-0" pos="word" morph="none" start_char="9139" end_char="9144">Raoult</TOKEN>
<TOKEN id="token-73-1" pos="word" morph="none" start_char="9146" end_char="9149">once</TOKEN>
<TOKEN id="token-73-2" pos="word" morph="none" start_char="9151" end_char="9155">again</TOKEN>
<TOKEN id="token-73-3" pos="word" morph="none" start_char="9157" end_char="9163">insists</TOKEN>
<TOKEN id="token-73-4" pos="word" morph="none" start_char="9165" end_char="9166">on</TOKEN>
<TOKEN id="token-73-5" pos="word" morph="none" start_char="9168" end_char="9174">massive</TOKEN>
<TOKEN id="token-73-6" pos="word" morph="none" start_char="9176" end_char="9182">testing</TOKEN>
<TOKEN id="token-73-7" pos="word" morph="none" start_char="9184" end_char="9185">on</TOKEN>
<TOKEN id="token-73-8" pos="word" morph="none" start_char="9187" end_char="9187">a</TOKEN>
<TOKEN id="token-73-9" pos="word" morph="none" start_char="9189" end_char="9196">national</TOKEN>
<TOKEN id="token-73-10" pos="word" morph="none" start_char="9198" end_char="9202">scale</TOKEN>
<TOKEN id="token-73-11" pos="word" morph="none" start_char="9204" end_char="9205">to</TOKEN>
<TOKEN id="token-73-12" pos="word" morph="none" start_char="9207" end_char="9212">detect</TOKEN>
<TOKEN id="token-73-13" pos="word" morph="none" start_char="9214" end_char="9222">suspected</TOKEN>
<TOKEN id="token-73-14" pos="word" morph="none" start_char="9224" end_char="9228">cases</TOKEN>
<TOKEN id="token-73-15" pos="punct" morph="none" start_char="9229" end_char="9229">,</TOKEN>
<TOKEN id="token-73-16" pos="word" morph="none" start_char="9231" end_char="9233">and</TOKEN>
<TOKEN id="token-73-17" pos="word" morph="none" start_char="9235" end_char="9238">then</TOKEN>
<TOKEN id="token-73-18" pos="word" morph="none" start_char="9240" end_char="9246">isolate</TOKEN>
<TOKEN id="token-73-19" pos="word" morph="none" start_char="9248" end_char="9250">and</TOKEN>
<TOKEN id="token-73-20" pos="word" morph="none" start_char="9252" end_char="9256">treat</TOKEN>
<TOKEN id="token-73-21" pos="word" morph="none" start_char="9258" end_char="9265">patients</TOKEN>
<TOKEN id="token-73-22" pos="word" morph="none" start_char="9267" end_char="9269">who</TOKEN>
<TOKEN id="token-73-23" pos="word" morph="none" start_char="9271" end_char="9276">tested</TOKEN>
<TOKEN id="token-73-24" pos="word" morph="none" start_char="9278" end_char="9285">positive</TOKEN>
<TOKEN id="token-73-25" pos="punct" morph="none" start_char="9286" end_char="9286">.</TOKEN>
</SEG>
<SEG id="segment-74" start_char="9288" end_char="9325">
<ORIGINAL_TEXT>In a nutshell: the South Korean model.</ORIGINAL_TEXT>
<TOKEN id="token-74-0" pos="word" morph="none" start_char="9288" end_char="9289">In</TOKEN>
<TOKEN id="token-74-1" pos="word" morph="none" start_char="9291" end_char="9291">a</TOKEN>
<TOKEN id="token-74-2" pos="word" morph="none" start_char="9293" end_char="9300">nutshell</TOKEN>
<TOKEN id="token-74-3" pos="punct" morph="none" start_char="9301" end_char="9301">:</TOKEN>
<TOKEN id="token-74-4" pos="word" morph="none" start_char="9303" end_char="9305">the</TOKEN>
<TOKEN id="token-74-5" pos="word" morph="none" start_char="9307" end_char="9311">South</TOKEN>
<TOKEN id="token-74-6" pos="word" morph="none" start_char="9313" end_char="9318">Korean</TOKEN>
<TOKEN id="token-74-7" pos="word" morph="none" start_char="9320" end_char="9324">model</TOKEN>
<TOKEN id="token-74-8" pos="punct" morph="none" start_char="9325" end_char="9325">.</TOKEN>
</SEG>
<SEG id="segment-75" start_char="9328" end_char="9447">
<ORIGINAL_TEXT>That’s exactly what is expected from the IHU in Marseille, where hundreds of residents continue to queue up for testing.</ORIGINAL_TEXT>
<TOKEN id="token-75-0" pos="word" morph="none" start_char="9328" end_char="9333">That’s</TOKEN>
<TOKEN id="token-75-1" pos="word" morph="none" start_char="9335" end_char="9341">exactly</TOKEN>
<TOKEN id="token-75-2" pos="word" morph="none" start_char="9343" end_char="9346">what</TOKEN>
<TOKEN id="token-75-3" pos="word" morph="none" start_char="9348" end_char="9349">is</TOKEN>
<TOKEN id="token-75-4" pos="word" morph="none" start_char="9351" end_char="9358">expected</TOKEN>
<TOKEN id="token-75-5" pos="word" morph="none" start_char="9360" end_char="9363">from</TOKEN>
<TOKEN id="token-75-6" pos="word" morph="none" start_char="9365" end_char="9367">the</TOKEN>
<TOKEN id="token-75-7" pos="word" morph="none" start_char="9369" end_char="9371">IHU</TOKEN>
<TOKEN id="token-75-8" pos="word" morph="none" start_char="9373" end_char="9374">in</TOKEN>
<TOKEN id="token-75-9" pos="word" morph="none" start_char="9376" end_char="9384">Marseille</TOKEN>
<TOKEN id="token-75-10" pos="punct" morph="none" start_char="9385" end_char="9385">,</TOKEN>
<TOKEN id="token-75-11" pos="word" morph="none" start_char="9387" end_char="9391">where</TOKEN>
<TOKEN id="token-75-12" pos="word" morph="none" start_char="9393" end_char="9400">hundreds</TOKEN>
<TOKEN id="token-75-13" pos="word" morph="none" start_char="9402" end_char="9403">of</TOKEN>
<TOKEN id="token-75-14" pos="word" morph="none" start_char="9405" end_char="9413">residents</TOKEN>
<TOKEN id="token-75-15" pos="word" morph="none" start_char="9415" end_char="9422">continue</TOKEN>
<TOKEN id="token-75-16" pos="word" morph="none" start_char="9424" end_char="9425">to</TOKEN>
<TOKEN id="token-75-17" pos="word" morph="none" start_char="9427" end_char="9431">queue</TOKEN>
<TOKEN id="token-75-18" pos="word" morph="none" start_char="9433" end_char="9434">up</TOKEN>
<TOKEN id="token-75-19" pos="word" morph="none" start_char="9436" end_char="9438">for</TOKEN>
<TOKEN id="token-75-20" pos="word" morph="none" start_char="9440" end_char="9446">testing</TOKEN>
<TOKEN id="token-75-21" pos="punct" morph="none" start_char="9447" end_char="9447">.</TOKEN>
</SEG>
<SEG id="segment-76" start_char="9449" end_char="9667">
<ORIGINAL_TEXT>And that ties in with the conclusions by a top Chinese expert on Covid-19, Zhang Nanshan, who says that treatment with chloroquine phospate had a "positive impact," with patients testing negative after around four days.</ORIGINAL_TEXT>
<TOKEN id="token-76-0" pos="word" morph="none" start_char="9449" end_char="9451">And</TOKEN>
<TOKEN id="token-76-1" pos="word" morph="none" start_char="9453" end_char="9456">that</TOKEN>
<TOKEN id="token-76-2" pos="word" morph="none" start_char="9458" end_char="9461">ties</TOKEN>
<TOKEN id="token-76-3" pos="word" morph="none" start_char="9463" end_char="9464">in</TOKEN>
<TOKEN id="token-76-4" pos="word" morph="none" start_char="9466" end_char="9469">with</TOKEN>
<TOKEN id="token-76-5" pos="word" morph="none" start_char="9471" end_char="9473">the</TOKEN>
<TOKEN id="token-76-6" pos="word" morph="none" start_char="9475" end_char="9485">conclusions</TOKEN>
<TOKEN id="token-76-7" pos="word" morph="none" start_char="9487" end_char="9488">by</TOKEN>
<TOKEN id="token-76-8" pos="word" morph="none" start_char="9490" end_char="9490">a</TOKEN>
<TOKEN id="token-76-9" pos="word" morph="none" start_char="9492" end_char="9494">top</TOKEN>
<TOKEN id="token-76-10" pos="word" morph="none" start_char="9496" end_char="9502">Chinese</TOKEN>
<TOKEN id="token-76-11" pos="word" morph="none" start_char="9504" end_char="9509">expert</TOKEN>
<TOKEN id="token-76-12" pos="word" morph="none" start_char="9511" end_char="9512">on</TOKEN>
<TOKEN id="token-76-13" pos="unknown" morph="none" start_char="9514" end_char="9521">Covid-19</TOKEN>
<TOKEN id="token-76-14" pos="punct" morph="none" start_char="9522" end_char="9522">,</TOKEN>
<TOKEN id="token-76-15" pos="word" morph="none" start_char="9524" end_char="9528">Zhang</TOKEN>
<TOKEN id="token-76-16" pos="word" morph="none" start_char="9530" end_char="9536">Nanshan</TOKEN>
<TOKEN id="token-76-17" pos="punct" morph="none" start_char="9537" end_char="9537">,</TOKEN>
<TOKEN id="token-76-18" pos="word" morph="none" start_char="9539" end_char="9541">who</TOKEN>
<TOKEN id="token-76-19" pos="word" morph="none" start_char="9543" end_char="9546">says</TOKEN>
<TOKEN id="token-76-20" pos="word" morph="none" start_char="9548" end_char="9551">that</TOKEN>
<TOKEN id="token-76-21" pos="word" morph="none" start_char="9553" end_char="9561">treatment</TOKEN>
<TOKEN id="token-76-22" pos="word" morph="none" start_char="9563" end_char="9566">with</TOKEN>
<TOKEN id="token-76-23" pos="word" morph="none" start_char="9568" end_char="9578">chloroquine</TOKEN>
<TOKEN id="token-76-24" pos="word" morph="none" start_char="9580" end_char="9587">phospate</TOKEN>
<TOKEN id="token-76-25" pos="word" morph="none" start_char="9589" end_char="9591">had</TOKEN>
<TOKEN id="token-76-26" pos="word" morph="none" start_char="9593" end_char="9593">a</TOKEN>
<TOKEN id="token-76-27" pos="punct" morph="none" start_char="9595" end_char="9595">"</TOKEN>
<TOKEN id="token-76-28" pos="word" morph="none" start_char="9596" end_char="9603">positive</TOKEN>
<TOKEN id="token-76-29" pos="word" morph="none" start_char="9605" end_char="9610">impact</TOKEN>
<TOKEN id="token-76-30" pos="punct" morph="none" start_char="9611" end_char="9612">,"</TOKEN>
<TOKEN id="token-76-31" pos="word" morph="none" start_char="9614" end_char="9617">with</TOKEN>
<TOKEN id="token-76-32" pos="word" morph="none" start_char="9619" end_char="9626">patients</TOKEN>
<TOKEN id="token-76-33" pos="word" morph="none" start_char="9628" end_char="9634">testing</TOKEN>
<TOKEN id="token-76-34" pos="word" morph="none" start_char="9636" end_char="9643">negative</TOKEN>
<TOKEN id="token-76-35" pos="word" morph="none" start_char="9645" end_char="9649">after</TOKEN>
<TOKEN id="token-76-36" pos="word" morph="none" start_char="9651" end_char="9656">around</TOKEN>
<TOKEN id="token-76-37" pos="word" morph="none" start_char="9658" end_char="9661">four</TOKEN>
<TOKEN id="token-76-38" pos="word" morph="none" start_char="9663" end_char="9666">days</TOKEN>
<TOKEN id="token-76-39" pos="punct" morph="none" start_char="9667" end_char="9667">.</TOKEN>
</SEG>
<SEG id="segment-77" start_char="9670" end_char="9851">
<ORIGINAL_TEXT>The key point has been stressed by Raoult: Use chloroquine in very special circumstances, for people tested very early, when the disease is not advanced yet, and only in these cases.</ORIGINAL_TEXT>
<TOKEN id="token-77-0" pos="word" morph="none" start_char="9670" end_char="9672">The</TOKEN>
<TOKEN id="token-77-1" pos="word" morph="none" start_char="9674" end_char="9676">key</TOKEN>
<TOKEN id="token-77-2" pos="word" morph="none" start_char="9678" end_char="9682">point</TOKEN>
<TOKEN id="token-77-3" pos="word" morph="none" start_char="9684" end_char="9686">has</TOKEN>
<TOKEN id="token-77-4" pos="word" morph="none" start_char="9688" end_char="9691">been</TOKEN>
<TOKEN id="token-77-5" pos="word" morph="none" start_char="9693" end_char="9700">stressed</TOKEN>
<TOKEN id="token-77-6" pos="word" morph="none" start_char="9702" end_char="9703">by</TOKEN>
<TOKEN id="token-77-7" pos="word" morph="none" start_char="9705" end_char="9710">Raoult</TOKEN>
<TOKEN id="token-77-8" pos="punct" morph="none" start_char="9711" end_char="9711">:</TOKEN>
<TOKEN id="token-77-9" pos="word" morph="none" start_char="9713" end_char="9715">Use</TOKEN>
<TOKEN id="token-77-10" pos="word" morph="none" start_char="9717" end_char="9727">chloroquine</TOKEN>
<TOKEN id="token-77-11" pos="word" morph="none" start_char="9729" end_char="9730">in</TOKEN>
<TOKEN id="token-77-12" pos="word" morph="none" start_char="9732" end_char="9735">very</TOKEN>
<TOKEN id="token-77-13" pos="word" morph="none" start_char="9737" end_char="9743">special</TOKEN>
<TOKEN id="token-77-14" pos="word" morph="none" start_char="9745" end_char="9757">circumstances</TOKEN>
<TOKEN id="token-77-15" pos="punct" morph="none" start_char="9758" end_char="9758">,</TOKEN>
<TOKEN id="token-77-16" pos="word" morph="none" start_char="9760" end_char="9762">for</TOKEN>
<TOKEN id="token-77-17" pos="word" morph="none" start_char="9764" end_char="9769">people</TOKEN>
<TOKEN id="token-77-18" pos="word" morph="none" start_char="9771" end_char="9776">tested</TOKEN>
<TOKEN id="token-77-19" pos="word" morph="none" start_char="9778" end_char="9781">very</TOKEN>
<TOKEN id="token-77-20" pos="word" morph="none" start_char="9783" end_char="9787">early</TOKEN>
<TOKEN id="token-77-21" pos="punct" morph="none" start_char="9788" end_char="9788">,</TOKEN>
<TOKEN id="token-77-22" pos="word" morph="none" start_char="9790" end_char="9793">when</TOKEN>
<TOKEN id="token-77-23" pos="word" morph="none" start_char="9795" end_char="9797">the</TOKEN>
<TOKEN id="token-77-24" pos="word" morph="none" start_char="9799" end_char="9805">disease</TOKEN>
<TOKEN id="token-77-25" pos="word" morph="none" start_char="9807" end_char="9808">is</TOKEN>
<TOKEN id="token-77-26" pos="word" morph="none" start_char="9810" end_char="9812">not</TOKEN>
<TOKEN id="token-77-27" pos="word" morph="none" start_char="9814" end_char="9821">advanced</TOKEN>
<TOKEN id="token-77-28" pos="word" morph="none" start_char="9823" end_char="9825">yet</TOKEN>
<TOKEN id="token-77-29" pos="punct" morph="none" start_char="9826" end_char="9826">,</TOKEN>
<TOKEN id="token-77-30" pos="word" morph="none" start_char="9828" end_char="9830">and</TOKEN>
<TOKEN id="token-77-31" pos="word" morph="none" start_char="9832" end_char="9835">only</TOKEN>
<TOKEN id="token-77-32" pos="word" morph="none" start_char="9837" end_char="9838">in</TOKEN>
<TOKEN id="token-77-33" pos="word" morph="none" start_char="9840" end_char="9844">these</TOKEN>
<TOKEN id="token-77-34" pos="word" morph="none" start_char="9846" end_char="9850">cases</TOKEN>
<TOKEN id="token-77-35" pos="punct" morph="none" start_char="9851" end_char="9851">.</TOKEN>
</SEG>
<SEG id="segment-78" start_char="9853" end_char="9897">
<ORIGINAL_TEXT>He’s not advocating chloroquine for everyone.</ORIGINAL_TEXT>
<TOKEN id="token-78-0" pos="word" morph="none" start_char="9853" end_char="9856">He’s</TOKEN>
<TOKEN id="token-78-1" pos="word" morph="none" start_char="9858" end_char="9860">not</TOKEN>
<TOKEN id="token-78-2" pos="word" morph="none" start_char="9862" end_char="9871">advocating</TOKEN>
<TOKEN id="token-78-3" pos="word" morph="none" start_char="9873" end_char="9883">chloroquine</TOKEN>
<TOKEN id="token-78-4" pos="word" morph="none" start_char="9885" end_char="9887">for</TOKEN>
<TOKEN id="token-78-5" pos="word" morph="none" start_char="9889" end_char="9896">everyone</TOKEN>
<TOKEN id="token-78-6" pos="punct" morph="none" start_char="9897" end_char="9897">.</TOKEN>
</SEG>
<SEG id="segment-79" start_char="9899" end_char="9968">
<ORIGINAL_TEXT>It’s exactly what the Chinese did, along with their use of Interferon.</ORIGINAL_TEXT>
<TOKEN id="token-79-0" pos="word" morph="none" start_char="9899" end_char="9902">It’s</TOKEN>
<TOKEN id="token-79-1" pos="word" morph="none" start_char="9904" end_char="9910">exactly</TOKEN>
<TOKEN id="token-79-2" pos="word" morph="none" start_char="9912" end_char="9915">what</TOKEN>
<TOKEN id="token-79-3" pos="word" morph="none" start_char="9917" end_char="9919">the</TOKEN>
<TOKEN id="token-79-4" pos="word" morph="none" start_char="9921" end_char="9927">Chinese</TOKEN>
<TOKEN id="token-79-5" pos="word" morph="none" start_char="9929" end_char="9931">did</TOKEN>
<TOKEN id="token-79-6" pos="punct" morph="none" start_char="9932" end_char="9932">,</TOKEN>
<TOKEN id="token-79-7" pos="word" morph="none" start_char="9934" end_char="9938">along</TOKEN>
<TOKEN id="token-79-8" pos="word" morph="none" start_char="9940" end_char="9943">with</TOKEN>
<TOKEN id="token-79-9" pos="word" morph="none" start_char="9945" end_char="9949">their</TOKEN>
<TOKEN id="token-79-10" pos="word" morph="none" start_char="9951" end_char="9953">use</TOKEN>
<TOKEN id="token-79-11" pos="word" morph="none" start_char="9955" end_char="9956">of</TOKEN>
<TOKEN id="token-79-12" pos="word" morph="none" start_char="9958" end_char="9967">Interferon</TOKEN>
<TOKEN id="token-79-13" pos="punct" morph="none" start_char="9968" end_char="9968">.</TOKEN>
</SEG>
<SEG id="segment-80" start_char="9971" end_char="10192">
<ORIGINAL_TEXT>For years, Raoult has been pleading for a drastic revision of health economic models, so the treatments, cure and therapies created mostly during the 20th century, are considered a patrimony in the service of all humanity.</ORIGINAL_TEXT>
<TOKEN id="token-80-0" pos="word" morph="none" start_char="9971" end_char="9973">For</TOKEN>
<TOKEN id="token-80-1" pos="word" morph="none" start_char="9975" end_char="9979">years</TOKEN>
<TOKEN id="token-80-2" pos="punct" morph="none" start_char="9980" end_char="9980">,</TOKEN>
<TOKEN id="token-80-3" pos="word" morph="none" start_char="9982" end_char="9987">Raoult</TOKEN>
<TOKEN id="token-80-4" pos="word" morph="none" start_char="9989" end_char="9991">has</TOKEN>
<TOKEN id="token-80-5" pos="word" morph="none" start_char="9993" end_char="9996">been</TOKEN>
<TOKEN id="token-80-6" pos="word" morph="none" start_char="9998" end_char="10005">pleading</TOKEN>
<TOKEN id="token-80-7" pos="word" morph="none" start_char="10007" end_char="10009">for</TOKEN>
<TOKEN id="token-80-8" pos="word" morph="none" start_char="10011" end_char="10011">a</TOKEN>
<TOKEN id="token-80-9" pos="word" morph="none" start_char="10013" end_char="10019">drastic</TOKEN>
<TOKEN id="token-80-10" pos="word" morph="none" start_char="10021" end_char="10028">revision</TOKEN>
<TOKEN id="token-80-11" pos="word" morph="none" start_char="10030" end_char="10031">of</TOKEN>
<TOKEN id="token-80-12" pos="word" morph="none" start_char="10033" end_char="10038">health</TOKEN>
<TOKEN id="token-80-13" pos="word" morph="none" start_char="10040" end_char="10047">economic</TOKEN>
<TOKEN id="token-80-14" pos="word" morph="none" start_char="10049" end_char="10054">models</TOKEN>
<TOKEN id="token-80-15" pos="punct" morph="none" start_char="10055" end_char="10055">,</TOKEN>
<TOKEN id="token-80-16" pos="word" morph="none" start_char="10057" end_char="10058">so</TOKEN>
<TOKEN id="token-80-17" pos="word" morph="none" start_char="10060" end_char="10062">the</TOKEN>
<TOKEN id="token-80-18" pos="word" morph="none" start_char="10064" end_char="10073">treatments</TOKEN>
<TOKEN id="token-80-19" pos="punct" morph="none" start_char="10074" end_char="10074">,</TOKEN>
<TOKEN id="token-80-20" pos="word" morph="none" start_char="10076" end_char="10079">cure</TOKEN>
<TOKEN id="token-80-21" pos="word" morph="none" start_char="10081" end_char="10083">and</TOKEN>
<TOKEN id="token-80-22" pos="word" morph="none" start_char="10085" end_char="10093">therapies</TOKEN>
<TOKEN id="token-80-23" pos="word" morph="none" start_char="10095" end_char="10101">created</TOKEN>
<TOKEN id="token-80-24" pos="word" morph="none" start_char="10103" end_char="10108">mostly</TOKEN>
<TOKEN id="token-80-25" pos="word" morph="none" start_char="10110" end_char="10115">during</TOKEN>
<TOKEN id="token-80-26" pos="word" morph="none" start_char="10117" end_char="10119">the</TOKEN>
<TOKEN id="token-80-27" pos="word" morph="none" start_char="10121" end_char="10124">20th</TOKEN>
<TOKEN id="token-80-28" pos="word" morph="none" start_char="10126" end_char="10132">century</TOKEN>
<TOKEN id="token-80-29" pos="punct" morph="none" start_char="10133" end_char="10133">,</TOKEN>
<TOKEN id="token-80-30" pos="word" morph="none" start_char="10135" end_char="10137">are</TOKEN>
<TOKEN id="token-80-31" pos="word" morph="none" start_char="10139" end_char="10148">considered</TOKEN>
<TOKEN id="token-80-32" pos="word" morph="none" start_char="10150" end_char="10150">a</TOKEN>
<TOKEN id="token-80-33" pos="word" morph="none" start_char="10152" end_char="10160">patrimony</TOKEN>
<TOKEN id="token-80-34" pos="word" morph="none" start_char="10162" end_char="10163">in</TOKEN>
<TOKEN id="token-80-35" pos="word" morph="none" start_char="10165" end_char="10167">the</TOKEN>
<TOKEN id="token-80-36" pos="word" morph="none" start_char="10169" end_char="10175">service</TOKEN>
<TOKEN id="token-80-37" pos="word" morph="none" start_char="10177" end_char="10178">of</TOKEN>
<TOKEN id="token-80-38" pos="word" morph="none" start_char="10180" end_char="10182">all</TOKEN>
<TOKEN id="token-80-39" pos="word" morph="none" start_char="10184" end_char="10191">humanity</TOKEN>
<TOKEN id="token-80-40" pos="punct" morph="none" start_char="10192" end_char="10192">.</TOKEN>
</SEG>
<SEG id="segment-81" start_char="10194" end_char="10301">
<ORIGINAL_TEXT>"That’s not the case", he says, "because we abandon medicine that is not profitable, even if it’s effective.</ORIGINAL_TEXT>
<TOKEN id="token-81-0" pos="punct" morph="none" start_char="10194" end_char="10194">"</TOKEN>
<TOKEN id="token-81-1" pos="word" morph="none" start_char="10195" end_char="10200">That’s</TOKEN>
<TOKEN id="token-81-2" pos="word" morph="none" start_char="10202" end_char="10204">not</TOKEN>
<TOKEN id="token-81-3" pos="word" morph="none" start_char="10206" end_char="10208">the</TOKEN>
<TOKEN id="token-81-4" pos="word" morph="none" start_char="10210" end_char="10213">case</TOKEN>
<TOKEN id="token-81-5" pos="punct" morph="none" start_char="10214" end_char="10215">",</TOKEN>
<TOKEN id="token-81-6" pos="word" morph="none" start_char="10217" end_char="10218">he</TOKEN>
<TOKEN id="token-81-7" pos="word" morph="none" start_char="10220" end_char="10223">says</TOKEN>
<TOKEN id="token-81-8" pos="punct" morph="none" start_char="10224" end_char="10224">,</TOKEN>
<TOKEN id="token-81-9" pos="punct" morph="none" start_char="10226" end_char="10226">"</TOKEN>
<TOKEN id="token-81-10" pos="word" morph="none" start_char="10227" end_char="10233">because</TOKEN>
<TOKEN id="token-81-11" pos="word" morph="none" start_char="10235" end_char="10236">we</TOKEN>
<TOKEN id="token-81-12" pos="word" morph="none" start_char="10238" end_char="10244">abandon</TOKEN>
<TOKEN id="token-81-13" pos="word" morph="none" start_char="10246" end_char="10253">medicine</TOKEN>
<TOKEN id="token-81-14" pos="word" morph="none" start_char="10255" end_char="10258">that</TOKEN>
<TOKEN id="token-81-15" pos="word" morph="none" start_char="10260" end_char="10261">is</TOKEN>
<TOKEN id="token-81-16" pos="word" morph="none" start_char="10263" end_char="10265">not</TOKEN>
<TOKEN id="token-81-17" pos="word" morph="none" start_char="10267" end_char="10276">profitable</TOKEN>
<TOKEN id="token-81-18" pos="punct" morph="none" start_char="10277" end_char="10277">,</TOKEN>
<TOKEN id="token-81-19" pos="word" morph="none" start_char="10279" end_char="10282">even</TOKEN>
<TOKEN id="token-81-20" pos="word" morph="none" start_char="10284" end_char="10285">if</TOKEN>
<TOKEN id="token-81-21" pos="word" morph="none" start_char="10287" end_char="10290">it’s</TOKEN>
<TOKEN id="token-81-22" pos="word" morph="none" start_char="10292" end_char="10300">effective</TOKEN>
<TOKEN id="token-81-23" pos="punct" morph="none" start_char="10301" end_char="10301">.</TOKEN>
</SEG>
<SEG id="segment-82" start_char="10303" end_char="10365">
<ORIGINAL_TEXT>That’s why almost no antibiotics are manufactured in the West."</ORIGINAL_TEXT>
<TOKEN id="token-82-0" pos="word" morph="none" start_char="10303" end_char="10308">That’s</TOKEN>
<TOKEN id="token-82-1" pos="word" morph="none" start_char="10310" end_char="10312">why</TOKEN>
<TOKEN id="token-82-2" pos="word" morph="none" start_char="10314" end_char="10319">almost</TOKEN>
<TOKEN id="token-82-3" pos="word" morph="none" start_char="10321" end_char="10322">no</TOKEN>
<TOKEN id="token-82-4" pos="word" morph="none" start_char="10324" end_char="10334">antibiotics</TOKEN>
<TOKEN id="token-82-5" pos="word" morph="none" start_char="10336" end_char="10338">are</TOKEN>
<TOKEN id="token-82-6" pos="word" morph="none" start_char="10340" end_char="10351">manufactured</TOKEN>
<TOKEN id="token-82-7" pos="word" morph="none" start_char="10353" end_char="10354">in</TOKEN>
<TOKEN id="token-82-8" pos="word" morph="none" start_char="10356" end_char="10358">the</TOKEN>
<TOKEN id="token-82-9" pos="word" morph="none" start_char="10360" end_char="10363">West</TOKEN>
<TOKEN id="token-82-10" pos="punct" morph="none" start_char="10364" end_char="10365">."</TOKEN>
</SEG>
<SEG id="segment-83" start_char="10368" end_char="10500">
<ORIGINAL_TEXT>On Tuesday, the French Health Ministry officially prohibited the utilization of treatment based on chloroquine recommended by Raoult.</ORIGINAL_TEXT>
<TOKEN id="token-83-0" pos="word" morph="none" start_char="10368" end_char="10369">On</TOKEN>
<TOKEN id="token-83-1" pos="word" morph="none" start_char="10371" end_char="10377">Tuesday</TOKEN>
<TOKEN id="token-83-2" pos="punct" morph="none" start_char="10378" end_char="10378">,</TOKEN>
<TOKEN id="token-83-3" pos="word" morph="none" start_char="10380" end_char="10382">the</TOKEN>
<TOKEN id="token-83-4" pos="word" morph="none" start_char="10384" end_char="10389">French</TOKEN>
<TOKEN id="token-83-5" pos="word" morph="none" start_char="10391" end_char="10396">Health</TOKEN>
<TOKEN id="token-83-6" pos="word" morph="none" start_char="10398" end_char="10405">Ministry</TOKEN>
<TOKEN id="token-83-7" pos="word" morph="none" start_char="10407" end_char="10416">officially</TOKEN>
<TOKEN id="token-83-8" pos="word" morph="none" start_char="10418" end_char="10427">prohibited</TOKEN>
<TOKEN id="token-83-9" pos="word" morph="none" start_char="10429" end_char="10431">the</TOKEN>
<TOKEN id="token-83-10" pos="word" morph="none" start_char="10433" end_char="10443">utilization</TOKEN>
<TOKEN id="token-83-11" pos="word" morph="none" start_char="10445" end_char="10446">of</TOKEN>
<TOKEN id="token-83-12" pos="word" morph="none" start_char="10448" end_char="10456">treatment</TOKEN>
<TOKEN id="token-83-13" pos="word" morph="none" start_char="10458" end_char="10462">based</TOKEN>
<TOKEN id="token-83-14" pos="word" morph="none" start_char="10464" end_char="10465">on</TOKEN>
<TOKEN id="token-83-15" pos="word" morph="none" start_char="10467" end_char="10477">chloroquine</TOKEN>
<TOKEN id="token-83-16" pos="word" morph="none" start_char="10479" end_char="10489">recommended</TOKEN>
<TOKEN id="token-83-17" pos="word" morph="none" start_char="10491" end_char="10492">by</TOKEN>
<TOKEN id="token-83-18" pos="word" morph="none" start_char="10494" end_char="10499">Raoult</TOKEN>
<TOKEN id="token-83-19" pos="punct" morph="none" start_char="10500" end_char="10500">.</TOKEN>
</SEG>
<SEG id="segment-84" start_char="10502" end_char="10608">
<ORIGINAL_TEXT>In fact the treatment is only allowed for terminal Covid-19 patients, with no other possibility of healing.</ORIGINAL_TEXT>
<TOKEN id="token-84-0" pos="word" morph="none" start_char="10502" end_char="10503">In</TOKEN>
<TOKEN id="token-84-1" pos="word" morph="none" start_char="10505" end_char="10508">fact</TOKEN>
<TOKEN id="token-84-2" pos="word" morph="none" start_char="10510" end_char="10512">the</TOKEN>
<TOKEN id="token-84-3" pos="word" morph="none" start_char="10514" end_char="10522">treatment</TOKEN>
<TOKEN id="token-84-4" pos="word" morph="none" start_char="10524" end_char="10525">is</TOKEN>
<TOKEN id="token-84-5" pos="word" morph="none" start_char="10527" end_char="10530">only</TOKEN>
<TOKEN id="token-84-6" pos="word" morph="none" start_char="10532" end_char="10538">allowed</TOKEN>
<TOKEN id="token-84-7" pos="word" morph="none" start_char="10540" end_char="10542">for</TOKEN>
<TOKEN id="token-84-8" pos="word" morph="none" start_char="10544" end_char="10551">terminal</TOKEN>
<TOKEN id="token-84-9" pos="unknown" morph="none" start_char="10553" end_char="10560">Covid-19</TOKEN>
<TOKEN id="token-84-10" pos="word" morph="none" start_char="10562" end_char="10569">patients</TOKEN>
<TOKEN id="token-84-11" pos="punct" morph="none" start_char="10570" end_char="10570">,</TOKEN>
<TOKEN id="token-84-12" pos="word" morph="none" start_char="10572" end_char="10575">with</TOKEN>
<TOKEN id="token-84-13" pos="word" morph="none" start_char="10577" end_char="10578">no</TOKEN>
<TOKEN id="token-84-14" pos="word" morph="none" start_char="10580" end_char="10584">other</TOKEN>
<TOKEN id="token-84-15" pos="word" morph="none" start_char="10586" end_char="10596">possibility</TOKEN>
<TOKEN id="token-84-16" pos="word" morph="none" start_char="10598" end_char="10599">of</TOKEN>
<TOKEN id="token-84-17" pos="word" morph="none" start_char="10601" end_char="10607">healing</TOKEN>
<TOKEN id="token-84-18" pos="punct" morph="none" start_char="10608" end_char="10608">.</TOKEN>
</SEG>
<SEG id="segment-85" start_char="10610" end_char="10771">
<ORIGINAL_TEXT>This cannot but expose the Macron government to more accusations of at least inefficiency – added to the absence of masks, tests, contact tracing and ventilators.</ORIGINAL_TEXT>
<TOKEN id="token-85-0" pos="word" morph="none" start_char="10610" end_char="10613">This</TOKEN>
<TOKEN id="token-85-1" pos="word" morph="none" start_char="10615" end_char="10620">cannot</TOKEN>
<TOKEN id="token-85-2" pos="word" morph="none" start_char="10622" end_char="10624">but</TOKEN>
<TOKEN id="token-85-3" pos="word" morph="none" start_char="10626" end_char="10631">expose</TOKEN>
<TOKEN id="token-85-4" pos="word" morph="none" start_char="10633" end_char="10635">the</TOKEN>
<TOKEN id="token-85-5" pos="word" morph="none" start_char="10637" end_char="10642">Macron</TOKEN>
<TOKEN id="token-85-6" pos="word" morph="none" start_char="10644" end_char="10653">government</TOKEN>
<TOKEN id="token-85-7" pos="word" morph="none" start_char="10655" end_char="10656">to</TOKEN>
<TOKEN id="token-85-8" pos="word" morph="none" start_char="10658" end_char="10661">more</TOKEN>
<TOKEN id="token-85-9" pos="word" morph="none" start_char="10663" end_char="10673">accusations</TOKEN>
<TOKEN id="token-85-10" pos="word" morph="none" start_char="10675" end_char="10676">of</TOKEN>
<TOKEN id="token-85-11" pos="word" morph="none" start_char="10678" end_char="10679">at</TOKEN>
<TOKEN id="token-85-12" pos="word" morph="none" start_char="10681" end_char="10685">least</TOKEN>
<TOKEN id="token-85-13" pos="word" morph="none" start_char="10687" end_char="10698">inefficiency</TOKEN>
<TOKEN id="token-85-14" pos="punct" morph="none" start_char="10700" end_char="10700">–</TOKEN>
<TOKEN id="token-85-15" pos="word" morph="none" start_char="10702" end_char="10706">added</TOKEN>
<TOKEN id="token-85-16" pos="word" morph="none" start_char="10708" end_char="10709">to</TOKEN>
<TOKEN id="token-85-17" pos="word" morph="none" start_char="10711" end_char="10713">the</TOKEN>
<TOKEN id="token-85-18" pos="word" morph="none" start_char="10715" end_char="10721">absence</TOKEN>
<TOKEN id="token-85-19" pos="word" morph="none" start_char="10723" end_char="10724">of</TOKEN>
<TOKEN id="token-85-20" pos="word" morph="none" start_char="10726" end_char="10730">masks</TOKEN>
<TOKEN id="token-85-21" pos="punct" morph="none" start_char="10731" end_char="10731">,</TOKEN>
<TOKEN id="token-85-22" pos="word" morph="none" start_char="10733" end_char="10737">tests</TOKEN>
<TOKEN id="token-85-23" pos="punct" morph="none" start_char="10738" end_char="10738">,</TOKEN>
<TOKEN id="token-85-24" pos="word" morph="none" start_char="10740" end_char="10746">contact</TOKEN>
<TOKEN id="token-85-25" pos="word" morph="none" start_char="10748" end_char="10754">tracing</TOKEN>
<TOKEN id="token-85-26" pos="word" morph="none" start_char="10756" end_char="10758">and</TOKEN>
<TOKEN id="token-85-27" pos="word" morph="none" start_char="10760" end_char="10770">ventilators</TOKEN>
<TOKEN id="token-85-28" pos="punct" morph="none" start_char="10771" end_char="10771">.</TOKEN>
</SEG>
<SEG id="segment-86" start_char="10774" end_char="10990">
<ORIGINAL_TEXT>On Wednesday, commenting on the new government guidelines, Raoult said, "When damage to the lungs is too important, and patients arrive for reanimation, they practically do not harbor viruses in their bodies any more.</ORIGINAL_TEXT>
<TOKEN id="token-86-0" pos="word" morph="none" start_char="10774" end_char="10775">On</TOKEN>
<TOKEN id="token-86-1" pos="word" morph="none" start_char="10777" end_char="10785">Wednesday</TOKEN>
<TOKEN id="token-86-2" pos="punct" morph="none" start_char="10786" end_char="10786">,</TOKEN>
<TOKEN id="token-86-3" pos="word" morph="none" start_char="10788" end_char="10797">commenting</TOKEN>
<TOKEN id="token-86-4" pos="word" morph="none" start_char="10799" end_char="10800">on</TOKEN>
<TOKEN id="token-86-5" pos="word" morph="none" start_char="10802" end_char="10804">the</TOKEN>
<TOKEN id="token-86-6" pos="word" morph="none" start_char="10806" end_char="10808">new</TOKEN>
<TOKEN id="token-86-7" pos="word" morph="none" start_char="10810" end_char="10819">government</TOKEN>
<TOKEN id="token-86-8" pos="word" morph="none" start_char="10821" end_char="10830">guidelines</TOKEN>
<TOKEN id="token-86-9" pos="punct" morph="none" start_char="10831" end_char="10831">,</TOKEN>
<TOKEN id="token-86-10" pos="word" morph="none" start_char="10833" end_char="10838">Raoult</TOKEN>
<TOKEN id="token-86-11" pos="word" morph="none" start_char="10840" end_char="10843">said</TOKEN>
<TOKEN id="token-86-12" pos="punct" morph="none" start_char="10844" end_char="10844">,</TOKEN>
<TOKEN id="token-86-13" pos="punct" morph="none" start_char="10846" end_char="10846">"</TOKEN>
<TOKEN id="token-86-14" pos="word" morph="none" start_char="10847" end_char="10850">When</TOKEN>
<TOKEN id="token-86-15" pos="word" morph="none" start_char="10852" end_char="10857">damage</TOKEN>
<TOKEN id="token-86-16" pos="word" morph="none" start_char="10859" end_char="10860">to</TOKEN>
<TOKEN id="token-86-17" pos="word" morph="none" start_char="10862" end_char="10864">the</TOKEN>
<TOKEN id="token-86-18" pos="word" morph="none" start_char="10866" end_char="10870">lungs</TOKEN>
<TOKEN id="token-86-19" pos="word" morph="none" start_char="10872" end_char="10873">is</TOKEN>
<TOKEN id="token-86-20" pos="word" morph="none" start_char="10875" end_char="10877">too</TOKEN>
<TOKEN id="token-86-21" pos="word" morph="none" start_char="10879" end_char="10887">important</TOKEN>
<TOKEN id="token-86-22" pos="punct" morph="none" start_char="10888" end_char="10888">,</TOKEN>
<TOKEN id="token-86-23" pos="word" morph="none" start_char="10890" end_char="10892">and</TOKEN>
<TOKEN id="token-86-24" pos="word" morph="none" start_char="10894" end_char="10901">patients</TOKEN>
<TOKEN id="token-86-25" pos="word" morph="none" start_char="10903" end_char="10908">arrive</TOKEN>
<TOKEN id="token-86-26" pos="word" morph="none" start_char="10910" end_char="10912">for</TOKEN>
<TOKEN id="token-86-27" pos="word" morph="none" start_char="10914" end_char="10924">reanimation</TOKEN>
<TOKEN id="token-86-28" pos="punct" morph="none" start_char="10925" end_char="10925">,</TOKEN>
<TOKEN id="token-86-29" pos="word" morph="none" start_char="10927" end_char="10930">they</TOKEN>
<TOKEN id="token-86-30" pos="word" morph="none" start_char="10932" end_char="10942">practically</TOKEN>
<TOKEN id="token-86-31" pos="word" morph="none" start_char="10944" end_char="10945">do</TOKEN>
<TOKEN id="token-86-32" pos="word" morph="none" start_char="10947" end_char="10949">not</TOKEN>
<TOKEN id="token-86-33" pos="word" morph="none" start_char="10951" end_char="10956">harbor</TOKEN>
<TOKEN id="token-86-34" pos="word" morph="none" start_char="10958" end_char="10964">viruses</TOKEN>
<TOKEN id="token-86-35" pos="word" morph="none" start_char="10966" end_char="10967">in</TOKEN>
<TOKEN id="token-86-36" pos="word" morph="none" start_char="10969" end_char="10973">their</TOKEN>
<TOKEN id="token-86-37" pos="word" morph="none" start_char="10975" end_char="10980">bodies</TOKEN>
<TOKEN id="token-86-38" pos="word" morph="none" start_char="10982" end_char="10984">any</TOKEN>
<TOKEN id="token-86-39" pos="word" morph="none" start_char="10986" end_char="10989">more</TOKEN>
<TOKEN id="token-86-40" pos="punct" morph="none" start_char="10990" end_char="10990">.</TOKEN>
</SEG>
<SEG id="segment-87" start_char="10992" end_char="11036">
<ORIGINAL_TEXT>It’s too late to treat them with chloroquine.</ORIGINAL_TEXT>
<TOKEN id="token-87-0" pos="word" morph="none" start_char="10992" end_char="10995">It’s</TOKEN>
<TOKEN id="token-87-1" pos="word" morph="none" start_char="10997" end_char="10999">too</TOKEN>
<TOKEN id="token-87-2" pos="word" morph="none" start_char="11001" end_char="11004">late</TOKEN>
<TOKEN id="token-87-3" pos="word" morph="none" start_char="11006" end_char="11007">to</TOKEN>
<TOKEN id="token-87-4" pos="word" morph="none" start_char="11009" end_char="11013">treat</TOKEN>
<TOKEN id="token-87-5" pos="word" morph="none" start_char="11015" end_char="11018">them</TOKEN>
<TOKEN id="token-87-6" pos="word" morph="none" start_char="11020" end_char="11023">with</TOKEN>
<TOKEN id="token-87-7" pos="word" morph="none" start_char="11025" end_char="11035">chloroquine</TOKEN>
<TOKEN id="token-87-8" pos="punct" morph="none" start_char="11036" end_char="11036">.</TOKEN>
</SEG>
<SEG id="segment-88" start_char="11038" end_char="11186">
<ORIGINAL_TEXT>Are these the only cases – the very serious cases – that will be treated with chloroquine under the new directive by [French Health Minister] Veran?"</ORIGINAL_TEXT>
<TOKEN id="token-88-0" pos="word" morph="none" start_char="11038" end_char="11040">Are</TOKEN>
<TOKEN id="token-88-1" pos="word" morph="none" start_char="11042" end_char="11046">these</TOKEN>
<TOKEN id="token-88-2" pos="word" morph="none" start_char="11048" end_char="11050">the</TOKEN>
<TOKEN id="token-88-3" pos="word" morph="none" start_char="11052" end_char="11055">only</TOKEN>
<TOKEN id="token-88-4" pos="word" morph="none" start_char="11057" end_char="11061">cases</TOKEN>
<TOKEN id="token-88-5" pos="punct" morph="none" start_char="11063" end_char="11063">–</TOKEN>
<TOKEN id="token-88-6" pos="word" morph="none" start_char="11065" end_char="11067">the</TOKEN>
<TOKEN id="token-88-7" pos="word" morph="none" start_char="11069" end_char="11072">very</TOKEN>
<TOKEN id="token-88-8" pos="word" morph="none" start_char="11074" end_char="11080">serious</TOKEN>
<TOKEN id="token-88-9" pos="word" morph="none" start_char="11082" end_char="11086">cases</TOKEN>
<TOKEN id="token-88-10" pos="punct" morph="none" start_char="11088" end_char="11088">–</TOKEN>
<TOKEN id="token-88-11" pos="word" morph="none" start_char="11090" end_char="11093">that</TOKEN>
<TOKEN id="token-88-12" pos="word" morph="none" start_char="11095" end_char="11098">will</TOKEN>
<TOKEN id="token-88-13" pos="word" morph="none" start_char="11100" end_char="11101">be</TOKEN>
<TOKEN id="token-88-14" pos="word" morph="none" start_char="11103" end_char="11109">treated</TOKEN>
<TOKEN id="token-88-15" pos="word" morph="none" start_char="11111" end_char="11114">with</TOKEN>
<TOKEN id="token-88-16" pos="word" morph="none" start_char="11116" end_char="11126">chloroquine</TOKEN>
<TOKEN id="token-88-17" pos="word" morph="none" start_char="11128" end_char="11132">under</TOKEN>
<TOKEN id="token-88-18" pos="word" morph="none" start_char="11134" end_char="11136">the</TOKEN>
<TOKEN id="token-88-19" pos="word" morph="none" start_char="11138" end_char="11140">new</TOKEN>
<TOKEN id="token-88-20" pos="word" morph="none" start_char="11142" end_char="11150">directive</TOKEN>
<TOKEN id="token-88-21" pos="word" morph="none" start_char="11152" end_char="11153">by</TOKEN>
<TOKEN id="token-88-22" pos="punct" morph="none" start_char="11155" end_char="11155">[</TOKEN>
<TOKEN id="token-88-23" pos="word" morph="none" start_char="11156" end_char="11161">French</TOKEN>
<TOKEN id="token-88-24" pos="word" morph="none" start_char="11163" end_char="11168">Health</TOKEN>
<TOKEN id="token-88-25" pos="word" morph="none" start_char="11170" end_char="11177">Minister</TOKEN>
<TOKEN id="token-88-26" pos="punct" morph="none" start_char="11178" end_char="11178">]</TOKEN>
<TOKEN id="token-88-27" pos="word" morph="none" start_char="11180" end_char="11184">Veran</TOKEN>
<TOKEN id="token-88-28" pos="punct" morph="none" start_char="11185" end_char="11186">?"</TOKEN>
</SEG>
<SEG id="segment-89" start_char="11188" end_char="11304">
<ORIGINAL_TEXT>If so, he added ironically, "then they will be able to say with scientific certainty that chloroquine does not work."</ORIGINAL_TEXT>
<TOKEN id="token-89-0" pos="word" morph="none" start_char="11188" end_char="11189">If</TOKEN>
<TOKEN id="token-89-1" pos="word" morph="none" start_char="11191" end_char="11192">so</TOKEN>
<TOKEN id="token-89-2" pos="punct" morph="none" start_char="11193" end_char="11193">,</TOKEN>
<TOKEN id="token-89-3" pos="word" morph="none" start_char="11195" end_char="11196">he</TOKEN>
<TOKEN id="token-89-4" pos="word" morph="none" start_char="11198" end_char="11202">added</TOKEN>
<TOKEN id="token-89-5" pos="word" morph="none" start_char="11204" end_char="11213">ironically</TOKEN>
<TOKEN id="token-89-6" pos="punct" morph="none" start_char="11214" end_char="11214">,</TOKEN>
<TOKEN id="token-89-7" pos="punct" morph="none" start_char="11216" end_char="11216">"</TOKEN>
<TOKEN id="token-89-8" pos="word" morph="none" start_char="11217" end_char="11220">then</TOKEN>
<TOKEN id="token-89-9" pos="word" morph="none" start_char="11222" end_char="11225">they</TOKEN>
<TOKEN id="token-89-10" pos="word" morph="none" start_char="11227" end_char="11230">will</TOKEN>
<TOKEN id="token-89-11" pos="word" morph="none" start_char="11232" end_char="11233">be</TOKEN>
<TOKEN id="token-89-12" pos="word" morph="none" start_char="11235" end_char="11238">able</TOKEN>
<TOKEN id="token-89-13" pos="word" morph="none" start_char="11240" end_char="11241">to</TOKEN>
<TOKEN id="token-89-14" pos="word" morph="none" start_char="11243" end_char="11245">say</TOKEN>
<TOKEN id="token-89-15" pos="word" morph="none" start_char="11247" end_char="11250">with</TOKEN>
<TOKEN id="token-89-16" pos="word" morph="none" start_char="11252" end_char="11261">scientific</TOKEN>
<TOKEN id="token-89-17" pos="word" morph="none" start_char="11263" end_char="11271">certainty</TOKEN>
<TOKEN id="token-89-18" pos="word" morph="none" start_char="11273" end_char="11276">that</TOKEN>
<TOKEN id="token-89-19" pos="word" morph="none" start_char="11278" end_char="11288">chloroquine</TOKEN>
<TOKEN id="token-89-20" pos="word" morph="none" start_char="11290" end_char="11293">does</TOKEN>
<TOKEN id="token-89-21" pos="word" morph="none" start_char="11295" end_char="11297">not</TOKEN>
<TOKEN id="token-89-22" pos="word" morph="none" start_char="11299" end_char="11302">work</TOKEN>
<TOKEN id="token-89-23" pos="punct" morph="none" start_char="11303" end_char="11304">."</TOKEN>
</SEG>
<SEG id="segment-90" start_char="11307" end_char="11504">
<ORIGINAL_TEXT>Raoult was unavailable for comment on Western news media articles citing Chinese test results that would suggest he is wrong about the efficacy of chloroquine in dealing with mild cases of Covid-19.</ORIGINAL_TEXT>
<TOKEN id="token-90-0" pos="word" morph="none" start_char="11307" end_char="11312">Raoult</TOKEN>
<TOKEN id="token-90-1" pos="word" morph="none" start_char="11314" end_char="11316">was</TOKEN>
<TOKEN id="token-90-2" pos="word" morph="none" start_char="11318" end_char="11328">unavailable</TOKEN>
<TOKEN id="token-90-3" pos="word" morph="none" start_char="11330" end_char="11332">for</TOKEN>
<TOKEN id="token-90-4" pos="word" morph="none" start_char="11334" end_char="11340">comment</TOKEN>
<TOKEN id="token-90-5" pos="word" morph="none" start_char="11342" end_char="11343">on</TOKEN>
<TOKEN id="token-90-6" pos="word" morph="none" start_char="11345" end_char="11351">Western</TOKEN>
<TOKEN id="token-90-7" pos="word" morph="none" start_char="11353" end_char="11356">news</TOKEN>
<TOKEN id="token-90-8" pos="word" morph="none" start_char="11358" end_char="11362">media</TOKEN>
<TOKEN id="token-90-9" pos="word" morph="none" start_char="11364" end_char="11371">articles</TOKEN>
<TOKEN id="token-90-10" pos="word" morph="none" start_char="11373" end_char="11378">citing</TOKEN>
<TOKEN id="token-90-11" pos="word" morph="none" start_char="11380" end_char="11386">Chinese</TOKEN>
<TOKEN id="token-90-12" pos="word" morph="none" start_char="11388" end_char="11391">test</TOKEN>
<TOKEN id="token-90-13" pos="word" morph="none" start_char="11393" end_char="11399">results</TOKEN>
<TOKEN id="token-90-14" pos="word" morph="none" start_char="11401" end_char="11404">that</TOKEN>
<TOKEN id="token-90-15" pos="word" morph="none" start_char="11406" end_char="11410">would</TOKEN>
<TOKEN id="token-90-16" pos="word" morph="none" start_char="11412" end_char="11418">suggest</TOKEN>
<TOKEN id="token-90-17" pos="word" morph="none" start_char="11420" end_char="11421">he</TOKEN>
<TOKEN id="token-90-18" pos="word" morph="none" start_char="11423" end_char="11424">is</TOKEN>
<TOKEN id="token-90-19" pos="word" morph="none" start_char="11426" end_char="11430">wrong</TOKEN>
<TOKEN id="token-90-20" pos="word" morph="none" start_char="11432" end_char="11436">about</TOKEN>
<TOKEN id="token-90-21" pos="word" morph="none" start_char="11438" end_char="11440">the</TOKEN>
<TOKEN id="token-90-22" pos="word" morph="none" start_char="11442" end_char="11449">efficacy</TOKEN>
<TOKEN id="token-90-23" pos="word" morph="none" start_char="11451" end_char="11452">of</TOKEN>
<TOKEN id="token-90-24" pos="word" morph="none" start_char="11454" end_char="11464">chloroquine</TOKEN>
<TOKEN id="token-90-25" pos="word" morph="none" start_char="11466" end_char="11467">in</TOKEN>
<TOKEN id="token-90-26" pos="word" morph="none" start_char="11469" end_char="11475">dealing</TOKEN>
<TOKEN id="token-90-27" pos="word" morph="none" start_char="11477" end_char="11480">with</TOKEN>
<TOKEN id="token-90-28" pos="word" morph="none" start_char="11482" end_char="11485">mild</TOKEN>
<TOKEN id="token-90-29" pos="word" morph="none" start_char="11487" end_char="11491">cases</TOKEN>
<TOKEN id="token-90-30" pos="word" morph="none" start_char="11493" end_char="11494">of</TOKEN>
<TOKEN id="token-90-31" pos="unknown" morph="none" start_char="11496" end_char="11503">Covid-19</TOKEN>
<TOKEN id="token-90-32" pos="punct" morph="none" start_char="11504" end_char="11504">.</TOKEN>
</SEG>
<SEG id="segment-91" start_char="11507" end_char="11567">
<ORIGINAL_TEXT>Staffers pointed instead to his comments in the IHU bulletin.</ORIGINAL_TEXT>
<TOKEN id="token-91-0" pos="word" morph="none" start_char="11507" end_char="11514">Staffers</TOKEN>
<TOKEN id="token-91-1" pos="word" morph="none" start_char="11516" end_char="11522">pointed</TOKEN>
<TOKEN id="token-91-2" pos="word" morph="none" start_char="11524" end_char="11530">instead</TOKEN>
<TOKEN id="token-91-3" pos="word" morph="none" start_char="11532" end_char="11533">to</TOKEN>
<TOKEN id="token-91-4" pos="word" morph="none" start_char="11535" end_char="11537">his</TOKEN>
<TOKEN id="token-91-5" pos="word" morph="none" start_char="11539" end_char="11546">comments</TOKEN>
<TOKEN id="token-91-6" pos="word" morph="none" start_char="11548" end_char="11549">in</TOKEN>
<TOKEN id="token-91-7" pos="word" morph="none" start_char="11551" end_char="11553">the</TOKEN>
<TOKEN id="token-91-8" pos="word" morph="none" start_char="11555" end_char="11557">IHU</TOKEN>
<TOKEN id="token-91-9" pos="word" morph="none" start_char="11559" end_char="11566">bulletin</TOKEN>
<TOKEN id="token-91-10" pos="punct" morph="none" start_char="11567" end_char="11567">.</TOKEN>
</SEG>
<SEG id="segment-92" start_char="11569" end_char="11664">
<ORIGINAL_TEXT>There Raoult says it’s "insulting" to ask if we can trust the Chinese on the use of chloroquine.</ORIGINAL_TEXT>
<TOKEN id="token-92-0" pos="word" morph="none" start_char="11569" end_char="11573">There</TOKEN>
<TOKEN id="token-92-1" pos="word" morph="none" start_char="11575" end_char="11580">Raoult</TOKEN>
<TOKEN id="token-92-2" pos="word" morph="none" start_char="11582" end_char="11585">says</TOKEN>
<TOKEN id="token-92-3" pos="word" morph="none" start_char="11587" end_char="11590">it’s</TOKEN>
<TOKEN id="token-92-4" pos="punct" morph="none" start_char="11592" end_char="11592">"</TOKEN>
<TOKEN id="token-92-5" pos="word" morph="none" start_char="11593" end_char="11601">insulting</TOKEN>
<TOKEN id="token-92-6" pos="punct" morph="none" start_char="11602" end_char="11602">"</TOKEN>
<TOKEN id="token-92-7" pos="word" morph="none" start_char="11604" end_char="11605">to</TOKEN>
<TOKEN id="token-92-8" pos="word" morph="none" start_char="11607" end_char="11609">ask</TOKEN>
<TOKEN id="token-92-9" pos="word" morph="none" start_char="11611" end_char="11612">if</TOKEN>
<TOKEN id="token-92-10" pos="word" morph="none" start_char="11614" end_char="11615">we</TOKEN>
<TOKEN id="token-92-11" pos="word" morph="none" start_char="11617" end_char="11619">can</TOKEN>
<TOKEN id="token-92-12" pos="word" morph="none" start_char="11621" end_char="11625">trust</TOKEN>
<TOKEN id="token-92-13" pos="word" morph="none" start_char="11627" end_char="11629">the</TOKEN>
<TOKEN id="token-92-14" pos="word" morph="none" start_char="11631" end_char="11637">Chinese</TOKEN>
<TOKEN id="token-92-15" pos="word" morph="none" start_char="11639" end_char="11640">on</TOKEN>
<TOKEN id="token-92-16" pos="word" morph="none" start_char="11642" end_char="11644">the</TOKEN>
<TOKEN id="token-92-17" pos="word" morph="none" start_char="11646" end_char="11648">use</TOKEN>
<TOKEN id="token-92-18" pos="word" morph="none" start_char="11650" end_char="11651">of</TOKEN>
<TOKEN id="token-92-19" pos="word" morph="none" start_char="11653" end_char="11663">chloroquine</TOKEN>
<TOKEN id="token-92-20" pos="punct" morph="none" start_char="11664" end_char="11664">.</TOKEN>
</SEG>
<SEG id="segment-93" start_char="11666" end_char="11808">
<ORIGINAL_TEXT>"If this was an American disease, and the president of the United States said, ‘We need to treat patients with that,’ nobody would discuss it."</ORIGINAL_TEXT>
<TOKEN id="token-93-0" pos="punct" morph="none" start_char="11666" end_char="11666">"</TOKEN>
<TOKEN id="token-93-1" pos="word" morph="none" start_char="11667" end_char="11668">If</TOKEN>
<TOKEN id="token-93-2" pos="word" morph="none" start_char="11670" end_char="11673">this</TOKEN>
<TOKEN id="token-93-3" pos="word" morph="none" start_char="11675" end_char="11677">was</TOKEN>
<TOKEN id="token-93-4" pos="word" morph="none" start_char="11679" end_char="11680">an</TOKEN>
<TOKEN id="token-93-5" pos="word" morph="none" start_char="11682" end_char="11689">American</TOKEN>
<TOKEN id="token-93-6" pos="word" morph="none" start_char="11691" end_char="11697">disease</TOKEN>
<TOKEN id="token-93-7" pos="punct" morph="none" start_char="11698" end_char="11698">,</TOKEN>
<TOKEN id="token-93-8" pos="word" morph="none" start_char="11700" end_char="11702">and</TOKEN>
<TOKEN id="token-93-9" pos="word" morph="none" start_char="11704" end_char="11706">the</TOKEN>
<TOKEN id="token-93-10" pos="word" morph="none" start_char="11708" end_char="11716">president</TOKEN>
<TOKEN id="token-93-11" pos="word" morph="none" start_char="11718" end_char="11719">of</TOKEN>
<TOKEN id="token-93-12" pos="word" morph="none" start_char="11721" end_char="11723">the</TOKEN>
<TOKEN id="token-93-13" pos="word" morph="none" start_char="11725" end_char="11730">United</TOKEN>
<TOKEN id="token-93-14" pos="word" morph="none" start_char="11732" end_char="11737">States</TOKEN>
<TOKEN id="token-93-15" pos="word" morph="none" start_char="11739" end_char="11742">said</TOKEN>
<TOKEN id="token-93-16" pos="punct" morph="none" start_char="11743" end_char="11743">,</TOKEN>
<TOKEN id="token-93-17" pos="punct" morph="none" start_char="11745" end_char="11745">‘</TOKEN>
<TOKEN id="token-93-18" pos="word" morph="none" start_char="11746" end_char="11747">We</TOKEN>
<TOKEN id="token-93-19" pos="word" morph="none" start_char="11749" end_char="11752">need</TOKEN>
<TOKEN id="token-93-20" pos="word" morph="none" start_char="11754" end_char="11755">to</TOKEN>
<TOKEN id="token-93-21" pos="word" morph="none" start_char="11757" end_char="11761">treat</TOKEN>
<TOKEN id="token-93-22" pos="word" morph="none" start_char="11763" end_char="11770">patients</TOKEN>
<TOKEN id="token-93-23" pos="word" morph="none" start_char="11772" end_char="11775">with</TOKEN>
<TOKEN id="token-93-24" pos="word" morph="none" start_char="11777" end_char="11780">that</TOKEN>
<TOKEN id="token-93-25" pos="punct" morph="none" start_char="11781" end_char="11782">,’</TOKEN>
<TOKEN id="token-93-26" pos="word" morph="none" start_char="11784" end_char="11789">nobody</TOKEN>
<TOKEN id="token-93-27" pos="word" morph="none" start_char="11791" end_char="11795">would</TOKEN>
<TOKEN id="token-93-28" pos="word" morph="none" start_char="11797" end_char="11803">discuss</TOKEN>
<TOKEN id="token-93-29" pos="word" morph="none" start_char="11805" end_char="11806">it</TOKEN>
<TOKEN id="token-93-30" pos="punct" morph="none" start_char="11807" end_char="11808">."</TOKEN>
</SEG>
<SEG id="segment-94" start_char="11811" end_char="11994">
<ORIGINAL_TEXT>In China, he adds, there were "enough elements so the Chinese government and all Chinese experts who know coronaviruses took an official position that ‘we must treat with chloroquine.’</ORIGINAL_TEXT>
<TOKEN id="token-94-0" pos="word" morph="none" start_char="11811" end_char="11812">In</TOKEN>
<TOKEN id="token-94-1" pos="word" morph="none" start_char="11814" end_char="11818">China</TOKEN>
<TOKEN id="token-94-2" pos="punct" morph="none" start_char="11819" end_char="11819">,</TOKEN>
<TOKEN id="token-94-3" pos="word" morph="none" start_char="11821" end_char="11822">he</TOKEN>
<TOKEN id="token-94-4" pos="word" morph="none" start_char="11824" end_char="11827">adds</TOKEN>
<TOKEN id="token-94-5" pos="punct" morph="none" start_char="11828" end_char="11828">,</TOKEN>
<TOKEN id="token-94-6" pos="word" morph="none" start_char="11830" end_char="11834">there</TOKEN>
<TOKEN id="token-94-7" pos="word" morph="none" start_char="11836" end_char="11839">were</TOKEN>
<TOKEN id="token-94-8" pos="punct" morph="none" start_char="11841" end_char="11841">"</TOKEN>
<TOKEN id="token-94-9" pos="word" morph="none" start_char="11842" end_char="11847">enough</TOKEN>
<TOKEN id="token-94-10" pos="word" morph="none" start_char="11849" end_char="11856">elements</TOKEN>
<TOKEN id="token-94-11" pos="word" morph="none" start_char="11858" end_char="11859">so</TOKEN>
<TOKEN id="token-94-12" pos="word" morph="none" start_char="11861" end_char="11863">the</TOKEN>
<TOKEN id="token-94-13" pos="word" morph="none" start_char="11865" end_char="11871">Chinese</TOKEN>
<TOKEN id="token-94-14" pos="word" morph="none" start_char="11873" end_char="11882">government</TOKEN>
<TOKEN id="token-94-15" pos="word" morph="none" start_char="11884" end_char="11886">and</TOKEN>
<TOKEN id="token-94-16" pos="word" morph="none" start_char="11888" end_char="11890">all</TOKEN>
<TOKEN id="token-94-17" pos="word" morph="none" start_char="11892" end_char="11898">Chinese</TOKEN>
<TOKEN id="token-94-18" pos="word" morph="none" start_char="11900" end_char="11906">experts</TOKEN>
<TOKEN id="token-94-19" pos="word" morph="none" start_char="11908" end_char="11910">who</TOKEN>
<TOKEN id="token-94-20" pos="word" morph="none" start_char="11912" end_char="11915">know</TOKEN>
<TOKEN id="token-94-21" pos="word" morph="none" start_char="11917" end_char="11929">coronaviruses</TOKEN>
<TOKEN id="token-94-22" pos="word" morph="none" start_char="11931" end_char="11934">took</TOKEN>
<TOKEN id="token-94-23" pos="word" morph="none" start_char="11936" end_char="11937">an</TOKEN>
<TOKEN id="token-94-24" pos="word" morph="none" start_char="11939" end_char="11946">official</TOKEN>
<TOKEN id="token-94-25" pos="word" morph="none" start_char="11948" end_char="11955">position</TOKEN>
<TOKEN id="token-94-26" pos="word" morph="none" start_char="11957" end_char="11960">that</TOKEN>
<TOKEN id="token-94-27" pos="punct" morph="none" start_char="11962" end_char="11962">‘</TOKEN>
<TOKEN id="token-94-28" pos="word" morph="none" start_char="11963" end_char="11964">we</TOKEN>
<TOKEN id="token-94-29" pos="word" morph="none" start_char="11966" end_char="11969">must</TOKEN>
<TOKEN id="token-94-30" pos="word" morph="none" start_char="11971" end_char="11975">treat</TOKEN>
<TOKEN id="token-94-31" pos="word" morph="none" start_char="11977" end_char="11980">with</TOKEN>
<TOKEN id="token-94-32" pos="word" morph="none" start_char="11982" end_char="11992">chloroquine</TOKEN>
<TOKEN id="token-94-33" pos="punct" morph="none" start_char="11993" end_char="11994">.’</TOKEN>
</SEG>
<SEG id="segment-95" start_char="11996" end_char="12178">
<ORIGINAL_TEXT>Between the moment when we have the first results and an accepted international publication, there is no credible alternative among people who are the most knowledgeable in the world.</ORIGINAL_TEXT>
<TOKEN id="token-95-0" pos="word" morph="none" start_char="11996" end_char="12002">Between</TOKEN>
<TOKEN id="token-95-1" pos="word" morph="none" start_char="12004" end_char="12006">the</TOKEN>
<TOKEN id="token-95-2" pos="word" morph="none" start_char="12008" end_char="12013">moment</TOKEN>
<TOKEN id="token-95-3" pos="word" morph="none" start_char="12015" end_char="12018">when</TOKEN>
<TOKEN id="token-95-4" pos="word" morph="none" start_char="12020" end_char="12021">we</TOKEN>
<TOKEN id="token-95-5" pos="word" morph="none" start_char="12023" end_char="12026">have</TOKEN>
<TOKEN id="token-95-6" pos="word" morph="none" start_char="12028" end_char="12030">the</TOKEN>
<TOKEN id="token-95-7" pos="word" morph="none" start_char="12032" end_char="12036">first</TOKEN>
<TOKEN id="token-95-8" pos="word" morph="none" start_char="12038" end_char="12044">results</TOKEN>
<TOKEN id="token-95-9" pos="word" morph="none" start_char="12046" end_char="12048">and</TOKEN>
<TOKEN id="token-95-10" pos="word" morph="none" start_char="12050" end_char="12051">an</TOKEN>
<TOKEN id="token-95-11" pos="word" morph="none" start_char="12053" end_char="12060">accepted</TOKEN>
<TOKEN id="token-95-12" pos="word" morph="none" start_char="12062" end_char="12074">international</TOKEN>
<TOKEN id="token-95-13" pos="word" morph="none" start_char="12076" end_char="12086">publication</TOKEN>
<TOKEN id="token-95-14" pos="punct" morph="none" start_char="12087" end_char="12087">,</TOKEN>
<TOKEN id="token-95-15" pos="word" morph="none" start_char="12089" end_char="12093">there</TOKEN>
<TOKEN id="token-95-16" pos="word" morph="none" start_char="12095" end_char="12096">is</TOKEN>
<TOKEN id="token-95-17" pos="word" morph="none" start_char="12098" end_char="12099">no</TOKEN>
<TOKEN id="token-95-18" pos="word" morph="none" start_char="12101" end_char="12108">credible</TOKEN>
<TOKEN id="token-95-19" pos="word" morph="none" start_char="12110" end_char="12120">alternative</TOKEN>
<TOKEN id="token-95-20" pos="word" morph="none" start_char="12122" end_char="12126">among</TOKEN>
<TOKEN id="token-95-21" pos="word" morph="none" start_char="12128" end_char="12133">people</TOKEN>
<TOKEN id="token-95-22" pos="word" morph="none" start_char="12135" end_char="12137">who</TOKEN>
<TOKEN id="token-95-23" pos="word" morph="none" start_char="12139" end_char="12141">are</TOKEN>
<TOKEN id="token-95-24" pos="word" morph="none" start_char="12143" end_char="12145">the</TOKEN>
<TOKEN id="token-95-25" pos="word" morph="none" start_char="12147" end_char="12150">most</TOKEN>
<TOKEN id="token-95-26" pos="word" morph="none" start_char="12152" end_char="12164">knowledgeable</TOKEN>
<TOKEN id="token-95-27" pos="word" morph="none" start_char="12166" end_char="12167">in</TOKEN>
<TOKEN id="token-95-28" pos="word" morph="none" start_char="12169" end_char="12171">the</TOKEN>
<TOKEN id="token-95-29" pos="word" morph="none" start_char="12173" end_char="12177">world</TOKEN>
<TOKEN id="token-95-30" pos="punct" morph="none" start_char="12178" end_char="12178">.</TOKEN>
</SEG>
<SEG id="segment-96" start_char="12180" end_char="12236">
<ORIGINAL_TEXT>They took this measure in the interest of public health."</ORIGINAL_TEXT>
<TOKEN id="token-96-0" pos="word" morph="none" start_char="12180" end_char="12183">They</TOKEN>
<TOKEN id="token-96-1" pos="word" morph="none" start_char="12185" end_char="12188">took</TOKEN>
<TOKEN id="token-96-2" pos="word" morph="none" start_char="12190" end_char="12193">this</TOKEN>
<TOKEN id="token-96-3" pos="word" morph="none" start_char="12195" end_char="12201">measure</TOKEN>
<TOKEN id="token-96-4" pos="word" morph="none" start_char="12203" end_char="12204">in</TOKEN>
<TOKEN id="token-96-5" pos="word" morph="none" start_char="12206" end_char="12208">the</TOKEN>
<TOKEN id="token-96-6" pos="word" morph="none" start_char="12210" end_char="12217">interest</TOKEN>
<TOKEN id="token-96-7" pos="word" morph="none" start_char="12219" end_char="12220">of</TOKEN>
<TOKEN id="token-96-8" pos="word" morph="none" start_char="12222" end_char="12227">public</TOKEN>
<TOKEN id="token-96-9" pos="word" morph="none" start_char="12229" end_char="12234">health</TOKEN>
<TOKEN id="token-96-10" pos="punct" morph="none" start_char="12235" end_char="12236">."</TOKEN>
</SEG>
<SEG id="segment-97" start_char="12239" end_char="12310">
<ORIGINAL_TEXT>Crucially: if he had coronavirus, Raoult says he would take chloroquine.</ORIGINAL_TEXT>
<TOKEN id="token-97-0" pos="word" morph="none" start_char="12239" end_char="12247">Crucially</TOKEN>
<TOKEN id="token-97-1" pos="punct" morph="none" start_char="12248" end_char="12248">:</TOKEN>
<TOKEN id="token-97-2" pos="word" morph="none" start_char="12250" end_char="12251">if</TOKEN>
<TOKEN id="token-97-3" pos="word" morph="none" start_char="12253" end_char="12254">he</TOKEN>
<TOKEN id="token-97-4" pos="word" morph="none" start_char="12256" end_char="12258">had</TOKEN>
<TOKEN id="token-97-5" pos="word" morph="none" start_char="12260" end_char="12270">coronavirus</TOKEN>
<TOKEN id="token-97-6" pos="punct" morph="none" start_char="12271" end_char="12271">,</TOKEN>
<TOKEN id="token-97-7" pos="word" morph="none" start_char="12273" end_char="12278">Raoult</TOKEN>
<TOKEN id="token-97-8" pos="word" morph="none" start_char="12280" end_char="12283">says</TOKEN>
<TOKEN id="token-97-9" pos="word" morph="none" start_char="12285" end_char="12286">he</TOKEN>
<TOKEN id="token-97-10" pos="word" morph="none" start_char="12288" end_char="12292">would</TOKEN>
<TOKEN id="token-97-11" pos="word" morph="none" start_char="12294" end_char="12297">take</TOKEN>
<TOKEN id="token-97-12" pos="word" morph="none" start_char="12299" end_char="12309">chloroquine</TOKEN>
<TOKEN id="token-97-13" pos="punct" morph="none" start_char="12310" end_char="12310">.</TOKEN>
</SEG>
<SEG id="segment-98" start_char="12312" end_char="12416">
<ORIGINAL_TEXT>Since Raoult is rated by his peers as the number one world expert in communicable diseases, way above Dr.</ORIGINAL_TEXT>
<TOKEN id="token-98-0" pos="word" morph="none" start_char="12312" end_char="12316">Since</TOKEN>
<TOKEN id="token-98-1" pos="word" morph="none" start_char="12318" end_char="12323">Raoult</TOKEN>
<TOKEN id="token-98-2" pos="word" morph="none" start_char="12325" end_char="12326">is</TOKEN>
<TOKEN id="token-98-3" pos="word" morph="none" start_char="12328" end_char="12332">rated</TOKEN>
<TOKEN id="token-98-4" pos="word" morph="none" start_char="12334" end_char="12335">by</TOKEN>
<TOKEN id="token-98-5" pos="word" morph="none" start_char="12337" end_char="12339">his</TOKEN>
<TOKEN id="token-98-6" pos="word" morph="none" start_char="12341" end_char="12345">peers</TOKEN>
<TOKEN id="token-98-7" pos="word" morph="none" start_char="12347" end_char="12348">as</TOKEN>
<TOKEN id="token-98-8" pos="word" morph="none" start_char="12350" end_char="12352">the</TOKEN>
<TOKEN id="token-98-9" pos="word" morph="none" start_char="12354" end_char="12359">number</TOKEN>
<TOKEN id="token-98-10" pos="word" morph="none" start_char="12361" end_char="12363">one</TOKEN>
<TOKEN id="token-98-11" pos="word" morph="none" start_char="12365" end_char="12369">world</TOKEN>
<TOKEN id="token-98-12" pos="word" morph="none" start_char="12371" end_char="12376">expert</TOKEN>
<TOKEN id="token-98-13" pos="word" morph="none" start_char="12378" end_char="12379">in</TOKEN>
<TOKEN id="token-98-14" pos="word" morph="none" start_char="12381" end_char="12392">communicable</TOKEN>
<TOKEN id="token-98-15" pos="word" morph="none" start_char="12394" end_char="12401">diseases</TOKEN>
<TOKEN id="token-98-16" pos="punct" morph="none" start_char="12402" end_char="12402">,</TOKEN>
<TOKEN id="token-98-17" pos="word" morph="none" start_char="12404" end_char="12406">way</TOKEN>
<TOKEN id="token-98-18" pos="word" morph="none" start_char="12408" end_char="12412">above</TOKEN>
<TOKEN id="token-98-19" pos="word" morph="none" start_char="12414" end_char="12415">Dr</TOKEN>
<TOKEN id="token-98-20" pos="punct" morph="none" start_char="12416" end_char="12416">.</TOKEN>
</SEG>
<SEG id="segment-99" start_char="12418" end_char="12499">
<ORIGINAL_TEXT>Anthony Fauci in the US, I would say the new reports represent Big Pharma talking.</ORIGINAL_TEXT>
<TOKEN id="token-99-0" pos="word" morph="none" start_char="12418" end_char="12424">Anthony</TOKEN>
<TOKEN id="token-99-1" pos="word" morph="none" start_char="12426" end_char="12430">Fauci</TOKEN>
<TOKEN id="token-99-2" pos="word" morph="none" start_char="12432" end_char="12433">in</TOKEN>
<TOKEN id="token-99-3" pos="word" morph="none" start_char="12435" end_char="12437">the</TOKEN>
<TOKEN id="token-99-4" pos="word" morph="none" start_char="12439" end_char="12440">US</TOKEN>
<TOKEN id="token-99-5" pos="punct" morph="none" start_char="12441" end_char="12441">,</TOKEN>
<TOKEN id="token-99-6" pos="word" morph="none" start_char="12443" end_char="12443">I</TOKEN>
<TOKEN id="token-99-7" pos="word" morph="none" start_char="12445" end_char="12449">would</TOKEN>
<TOKEN id="token-99-8" pos="word" morph="none" start_char="12451" end_char="12453">say</TOKEN>
<TOKEN id="token-99-9" pos="word" morph="none" start_char="12455" end_char="12457">the</TOKEN>
<TOKEN id="token-99-10" pos="word" morph="none" start_char="12459" end_char="12461">new</TOKEN>
<TOKEN id="token-99-11" pos="word" morph="none" start_char="12463" end_char="12469">reports</TOKEN>
<TOKEN id="token-99-12" pos="word" morph="none" start_char="12471" end_char="12479">represent</TOKEN>
<TOKEN id="token-99-13" pos="word" morph="none" start_char="12481" end_char="12483">Big</TOKEN>
<TOKEN id="token-99-14" pos="word" morph="none" start_char="12485" end_char="12490">Pharma</TOKEN>
<TOKEN id="token-99-15" pos="word" morph="none" start_char="12492" end_char="12498">talking</TOKEN>
<TOKEN id="token-99-16" pos="punct" morph="none" start_char="12499" end_char="12499">.</TOKEN>
</SEG>
<SEG id="segment-100" start_char="12502" end_char="12644">
<ORIGINAL_TEXT>Raoult has been mercilessly savaged and demonized by French corporate media that are controlled by a few oligarchs closely linked to Macronism.</ORIGINAL_TEXT>
<TOKEN id="token-100-0" pos="word" morph="none" start_char="12502" end_char="12507">Raoult</TOKEN>
<TOKEN id="token-100-1" pos="word" morph="none" start_char="12509" end_char="12511">has</TOKEN>
<TOKEN id="token-100-2" pos="word" morph="none" start_char="12513" end_char="12516">been</TOKEN>
<TOKEN id="token-100-3" pos="word" morph="none" start_char="12518" end_char="12528">mercilessly</TOKEN>
<TOKEN id="token-100-4" pos="word" morph="none" start_char="12530" end_char="12536">savaged</TOKEN>
<TOKEN id="token-100-5" pos="word" morph="none" start_char="12538" end_char="12540">and</TOKEN>
<TOKEN id="token-100-6" pos="word" morph="none" start_char="12542" end_char="12550">demonized</TOKEN>
<TOKEN id="token-100-7" pos="word" morph="none" start_char="12552" end_char="12553">by</TOKEN>
<TOKEN id="token-100-8" pos="word" morph="none" start_char="12555" end_char="12560">French</TOKEN>
<TOKEN id="token-100-9" pos="word" morph="none" start_char="12562" end_char="12570">corporate</TOKEN>
<TOKEN id="token-100-10" pos="word" morph="none" start_char="12572" end_char="12576">media</TOKEN>
<TOKEN id="token-100-11" pos="word" morph="none" start_char="12578" end_char="12581">that</TOKEN>
<TOKEN id="token-100-12" pos="word" morph="none" start_char="12583" end_char="12585">are</TOKEN>
<TOKEN id="token-100-13" pos="word" morph="none" start_char="12587" end_char="12596">controlled</TOKEN>
<TOKEN id="token-100-14" pos="word" morph="none" start_char="12598" end_char="12599">by</TOKEN>
<TOKEN id="token-100-15" pos="word" morph="none" start_char="12601" end_char="12601">a</TOKEN>
<TOKEN id="token-100-16" pos="word" morph="none" start_char="12603" end_char="12605">few</TOKEN>
<TOKEN id="token-100-17" pos="word" morph="none" start_char="12607" end_char="12615">oligarchs</TOKEN>
<TOKEN id="token-100-18" pos="word" morph="none" start_char="12617" end_char="12623">closely</TOKEN>
<TOKEN id="token-100-19" pos="word" morph="none" start_char="12625" end_char="12630">linked</TOKEN>
<TOKEN id="token-100-20" pos="word" morph="none" start_char="12632" end_char="12633">to</TOKEN>
<TOKEN id="token-100-21" pos="word" morph="none" start_char="12635" end_char="12643">Macronism</TOKEN>
<TOKEN id="token-100-22" pos="punct" morph="none" start_char="12644" end_char="12644">.</TOKEN>
</SEG>
<SEG id="segment-101" start_char="12646" end_char="12979">
<ORIGINAL_TEXT>Not by accident the demonization has reached gilets jaunes (yellow vest) levels, especially because of the extremely popular hashtag #IlsSavaient ("They knew"), with which the yellow vests stress that French elites have "managed" the Covid-19 crisis by protecting themselves while leaving the population defenseless against the virus.</ORIGINAL_TEXT>
<TOKEN id="token-101-0" pos="word" morph="none" start_char="12646" end_char="12648">Not</TOKEN>
<TOKEN id="token-101-1" pos="word" morph="none" start_char="12650" end_char="12651">by</TOKEN>
<TOKEN id="token-101-2" pos="word" morph="none" start_char="12653" end_char="12660">accident</TOKEN>
<TOKEN id="token-101-3" pos="word" morph="none" start_char="12662" end_char="12664">the</TOKEN>
<TOKEN id="token-101-4" pos="word" morph="none" start_char="12666" end_char="12677">demonization</TOKEN>
<TOKEN id="token-101-5" pos="word" morph="none" start_char="12679" end_char="12681">has</TOKEN>
<TOKEN id="token-101-6" pos="word" morph="none" start_char="12683" end_char="12689">reached</TOKEN>
<TOKEN id="token-101-7" pos="word" morph="none" start_char="12691" end_char="12696">gilets</TOKEN>
<TOKEN id="token-101-8" pos="word" morph="none" start_char="12698" end_char="12703">jaunes</TOKEN>
<TOKEN id="token-101-9" pos="punct" morph="none" start_char="12705" end_char="12705">(</TOKEN>
<TOKEN id="token-101-10" pos="word" morph="none" start_char="12706" end_char="12711">yellow</TOKEN>
<TOKEN id="token-101-11" pos="word" morph="none" start_char="12713" end_char="12716">vest</TOKEN>
<TOKEN id="token-101-12" pos="punct" morph="none" start_char="12717" end_char="12717">)</TOKEN>
<TOKEN id="token-101-13" pos="word" morph="none" start_char="12719" end_char="12724">levels</TOKEN>
<TOKEN id="token-101-14" pos="punct" morph="none" start_char="12725" end_char="12725">,</TOKEN>
<TOKEN id="token-101-15" pos="word" morph="none" start_char="12727" end_char="12736">especially</TOKEN>
<TOKEN id="token-101-16" pos="word" morph="none" start_char="12738" end_char="12744">because</TOKEN>
<TOKEN id="token-101-17" pos="word" morph="none" start_char="12746" end_char="12747">of</TOKEN>
<TOKEN id="token-101-18" pos="word" morph="none" start_char="12749" end_char="12751">the</TOKEN>
<TOKEN id="token-101-19" pos="word" morph="none" start_char="12753" end_char="12761">extremely</TOKEN>
<TOKEN id="token-101-20" pos="word" morph="none" start_char="12763" end_char="12769">popular</TOKEN>
<TOKEN id="token-101-21" pos="word" morph="none" start_char="12771" end_char="12777">hashtag</TOKEN>
<TOKEN id="token-101-22" pos="tag" morph="none" start_char="12779" end_char="12790">#IlsSavaient</TOKEN>
<TOKEN id="token-101-23" pos="punct" morph="none" start_char="12792" end_char="12793">("</TOKEN>
<TOKEN id="token-101-24" pos="word" morph="none" start_char="12794" end_char="12797">They</TOKEN>
<TOKEN id="token-101-25" pos="word" morph="none" start_char="12799" end_char="12802">knew</TOKEN>
<TOKEN id="token-101-26" pos="punct" morph="none" start_char="12803" end_char="12805">"),</TOKEN>
<TOKEN id="token-101-27" pos="word" morph="none" start_char="12807" end_char="12810">with</TOKEN>
<TOKEN id="token-101-28" pos="word" morph="none" start_char="12812" end_char="12816">which</TOKEN>
<TOKEN id="token-101-29" pos="word" morph="none" start_char="12818" end_char="12820">the</TOKEN>
<TOKEN id="token-101-30" pos="word" morph="none" start_char="12822" end_char="12827">yellow</TOKEN>
<TOKEN id="token-101-31" pos="word" morph="none" start_char="12829" end_char="12833">vests</TOKEN>
<TOKEN id="token-101-32" pos="word" morph="none" start_char="12835" end_char="12840">stress</TOKEN>
<TOKEN id="token-101-33" pos="word" morph="none" start_char="12842" end_char="12845">that</TOKEN>
<TOKEN id="token-101-34" pos="word" morph="none" start_char="12847" end_char="12852">French</TOKEN>
<TOKEN id="token-101-35" pos="word" morph="none" start_char="12854" end_char="12859">elites</TOKEN>
<TOKEN id="token-101-36" pos="word" morph="none" start_char="12861" end_char="12864">have</TOKEN>
<TOKEN id="token-101-37" pos="punct" morph="none" start_char="12866" end_char="12866">"</TOKEN>
<TOKEN id="token-101-38" pos="word" morph="none" start_char="12867" end_char="12873">managed</TOKEN>
<TOKEN id="token-101-39" pos="punct" morph="none" start_char="12874" end_char="12874">"</TOKEN>
<TOKEN id="token-101-40" pos="word" morph="none" start_char="12876" end_char="12878">the</TOKEN>
<TOKEN id="token-101-41" pos="unknown" morph="none" start_char="12880" end_char="12887">Covid-19</TOKEN>
<TOKEN id="token-101-42" pos="word" morph="none" start_char="12889" end_char="12894">crisis</TOKEN>
<TOKEN id="token-101-43" pos="word" morph="none" start_char="12896" end_char="12897">by</TOKEN>
<TOKEN id="token-101-44" pos="word" morph="none" start_char="12899" end_char="12908">protecting</TOKEN>
<TOKEN id="token-101-45" pos="word" morph="none" start_char="12910" end_char="12919">themselves</TOKEN>
<TOKEN id="token-101-46" pos="word" morph="none" start_char="12921" end_char="12925">while</TOKEN>
<TOKEN id="token-101-47" pos="word" morph="none" start_char="12927" end_char="12933">leaving</TOKEN>
<TOKEN id="token-101-48" pos="word" morph="none" start_char="12935" end_char="12937">the</TOKEN>
<TOKEN id="token-101-49" pos="word" morph="none" start_char="12939" end_char="12948">population</TOKEN>
<TOKEN id="token-101-50" pos="word" morph="none" start_char="12950" end_char="12960">defenseless</TOKEN>
<TOKEN id="token-101-51" pos="word" morph="none" start_char="12962" end_char="12968">against</TOKEN>
<TOKEN id="token-101-52" pos="word" morph="none" start_char="12970" end_char="12972">the</TOKEN>
<TOKEN id="token-101-53" pos="word" morph="none" start_char="12974" end_char="12978">virus</TOKEN>
<TOKEN id="token-101-54" pos="punct" morph="none" start_char="12979" end_char="12979">.</TOKEN>
</SEG>
<SEG id="segment-102" start_char="12982" end_char="13306">
<ORIGINAL_TEXT>That ties in with the controversial analysis by crack philosopher Giorgio Agamben in a column published a month ago, where he was already arguing that Covid-19 clearly shows that the state of exception – similar to a state of emergency but with differences important to philosophers – has become fully normalized in the West.</ORIGINAL_TEXT>
<TOKEN id="token-102-0" pos="word" morph="none" start_char="12982" end_char="12985">That</TOKEN>
<TOKEN id="token-102-1" pos="word" morph="none" start_char="12987" end_char="12990">ties</TOKEN>
<TOKEN id="token-102-2" pos="word" morph="none" start_char="12992" end_char="12993">in</TOKEN>
<TOKEN id="token-102-3" pos="word" morph="none" start_char="12995" end_char="12998">with</TOKEN>
<TOKEN id="token-102-4" pos="word" morph="none" start_char="13000" end_char="13002">the</TOKEN>
<TOKEN id="token-102-5" pos="word" morph="none" start_char="13004" end_char="13016">controversial</TOKEN>
<TOKEN id="token-102-6" pos="word" morph="none" start_char="13018" end_char="13025">analysis</TOKEN>
<TOKEN id="token-102-7" pos="word" morph="none" start_char="13027" end_char="13028">by</TOKEN>
<TOKEN id="token-102-8" pos="word" morph="none" start_char="13030" end_char="13034">crack</TOKEN>
<TOKEN id="token-102-9" pos="word" morph="none" start_char="13036" end_char="13046">philosopher</TOKEN>
<TOKEN id="token-102-10" pos="word" morph="none" start_char="13048" end_char="13054">Giorgio</TOKEN>
<TOKEN id="token-102-11" pos="word" morph="none" start_char="13056" end_char="13062">Agamben</TOKEN>
<TOKEN id="token-102-12" pos="word" morph="none" start_char="13064" end_char="13065">in</TOKEN>
<TOKEN id="token-102-13" pos="word" morph="none" start_char="13067" end_char="13067">a</TOKEN>
<TOKEN id="token-102-14" pos="word" morph="none" start_char="13069" end_char="13074">column</TOKEN>
<TOKEN id="token-102-15" pos="word" morph="none" start_char="13076" end_char="13084">published</TOKEN>
<TOKEN id="token-102-16" pos="word" morph="none" start_char="13086" end_char="13086">a</TOKEN>
<TOKEN id="token-102-17" pos="word" morph="none" start_char="13088" end_char="13092">month</TOKEN>
<TOKEN id="token-102-18" pos="word" morph="none" start_char="13094" end_char="13096">ago</TOKEN>
<TOKEN id="token-102-19" pos="punct" morph="none" start_char="13097" end_char="13097">,</TOKEN>
<TOKEN id="token-102-20" pos="word" morph="none" start_char="13099" end_char="13103">where</TOKEN>
<TOKEN id="token-102-21" pos="word" morph="none" start_char="13105" end_char="13106">he</TOKEN>
<TOKEN id="token-102-22" pos="word" morph="none" start_char="13108" end_char="13110">was</TOKEN>
<TOKEN id="token-102-23" pos="word" morph="none" start_char="13112" end_char="13118">already</TOKEN>
<TOKEN id="token-102-24" pos="word" morph="none" start_char="13120" end_char="13126">arguing</TOKEN>
<TOKEN id="token-102-25" pos="word" morph="none" start_char="13128" end_char="13131">that</TOKEN>
<TOKEN id="token-102-26" pos="unknown" morph="none" start_char="13133" end_char="13140">Covid-19</TOKEN>
<TOKEN id="token-102-27" pos="word" morph="none" start_char="13142" end_char="13148">clearly</TOKEN>
<TOKEN id="token-102-28" pos="word" morph="none" start_char="13150" end_char="13154">shows</TOKEN>
<TOKEN id="token-102-29" pos="word" morph="none" start_char="13156" end_char="13159">that</TOKEN>
<TOKEN id="token-102-30" pos="word" morph="none" start_char="13161" end_char="13163">the</TOKEN>
<TOKEN id="token-102-31" pos="word" morph="none" start_char="13165" end_char="13169">state</TOKEN>
<TOKEN id="token-102-32" pos="word" morph="none" start_char="13171" end_char="13172">of</TOKEN>
<TOKEN id="token-102-33" pos="word" morph="none" start_char="13174" end_char="13182">exception</TOKEN>
<TOKEN id="token-102-34" pos="punct" morph="none" start_char="13184" end_char="13184">–</TOKEN>
<TOKEN id="token-102-35" pos="word" morph="none" start_char="13186" end_char="13192">similar</TOKEN>
<TOKEN id="token-102-36" pos="word" morph="none" start_char="13194" end_char="13195">to</TOKEN>
<TOKEN id="token-102-37" pos="word" morph="none" start_char="13197" end_char="13197">a</TOKEN>
<TOKEN id="token-102-38" pos="word" morph="none" start_char="13199" end_char="13203">state</TOKEN>
<TOKEN id="token-102-39" pos="word" morph="none" start_char="13205" end_char="13206">of</TOKEN>
<TOKEN id="token-102-40" pos="word" morph="none" start_char="13208" end_char="13216">emergency</TOKEN>
<TOKEN id="token-102-41" pos="word" morph="none" start_char="13218" end_char="13220">but</TOKEN>
<TOKEN id="token-102-42" pos="word" morph="none" start_char="13222" end_char="13225">with</TOKEN>
<TOKEN id="token-102-43" pos="word" morph="none" start_char="13227" end_char="13237">differences</TOKEN>
<TOKEN id="token-102-44" pos="word" morph="none" start_char="13239" end_char="13247">important</TOKEN>
<TOKEN id="token-102-45" pos="word" morph="none" start_char="13249" end_char="13250">to</TOKEN>
<TOKEN id="token-102-46" pos="word" morph="none" start_char="13252" end_char="13263">philosophers</TOKEN>
<TOKEN id="token-102-47" pos="punct" morph="none" start_char="13265" end_char="13265">–</TOKEN>
<TOKEN id="token-102-48" pos="word" morph="none" start_char="13267" end_char="13269">has</TOKEN>
<TOKEN id="token-102-49" pos="word" morph="none" start_char="13271" end_char="13276">become</TOKEN>
<TOKEN id="token-102-50" pos="word" morph="none" start_char="13278" end_char="13282">fully</TOKEN>
<TOKEN id="token-102-51" pos="word" morph="none" start_char="13284" end_char="13293">normalized</TOKEN>
<TOKEN id="token-102-52" pos="word" morph="none" start_char="13295" end_char="13296">in</TOKEN>
<TOKEN id="token-102-53" pos="word" morph="none" start_char="13298" end_char="13300">the</TOKEN>
<TOKEN id="token-102-54" pos="word" morph="none" start_char="13302" end_char="13305">West</TOKEN>
<TOKEN id="token-102-55" pos="punct" morph="none" start_char="13306" end_char="13306">.</TOKEN>
</SEG>
<SEG id="segment-103" start_char="13309" end_char="13456">
<ORIGINAL_TEXT>Agamben was speaking not as a doctor or a virologist but as a master thinker, following in the steps of Foucault, Walter Benjamin and Hannah Arendt.</ORIGINAL_TEXT>
<TOKEN id="token-103-0" pos="word" morph="none" start_char="13309" end_char="13315">Agamben</TOKEN>
<TOKEN id="token-103-1" pos="word" morph="none" start_char="13317" end_char="13319">was</TOKEN>
<TOKEN id="token-103-2" pos="word" morph="none" start_char="13321" end_char="13328">speaking</TOKEN>
<TOKEN id="token-103-3" pos="word" morph="none" start_char="13330" end_char="13332">not</TOKEN>
<TOKEN id="token-103-4" pos="word" morph="none" start_char="13334" end_char="13335">as</TOKEN>
<TOKEN id="token-103-5" pos="word" morph="none" start_char="13337" end_char="13337">a</TOKEN>
<TOKEN id="token-103-6" pos="word" morph="none" start_char="13339" end_char="13344">doctor</TOKEN>
<TOKEN id="token-103-7" pos="word" morph="none" start_char="13346" end_char="13347">or</TOKEN>
<TOKEN id="token-103-8" pos="word" morph="none" start_char="13349" end_char="13349">a</TOKEN>
<TOKEN id="token-103-9" pos="word" morph="none" start_char="13351" end_char="13360">virologist</TOKEN>
<TOKEN id="token-103-10" pos="word" morph="none" start_char="13362" end_char="13364">but</TOKEN>
<TOKEN id="token-103-11" pos="word" morph="none" start_char="13366" end_char="13367">as</TOKEN>
<TOKEN id="token-103-12" pos="word" morph="none" start_char="13369" end_char="13369">a</TOKEN>
<TOKEN id="token-103-13" pos="word" morph="none" start_char="13371" end_char="13376">master</TOKEN>
<TOKEN id="token-103-14" pos="word" morph="none" start_char="13378" end_char="13384">thinker</TOKEN>
<TOKEN id="token-103-15" pos="punct" morph="none" start_char="13385" end_char="13385">,</TOKEN>
<TOKEN id="token-103-16" pos="word" morph="none" start_char="13387" end_char="13395">following</TOKEN>
<TOKEN id="token-103-17" pos="word" morph="none" start_char="13397" end_char="13398">in</TOKEN>
<TOKEN id="token-103-18" pos="word" morph="none" start_char="13400" end_char="13402">the</TOKEN>
<TOKEN id="token-103-19" pos="word" morph="none" start_char="13404" end_char="13408">steps</TOKEN>
<TOKEN id="token-103-20" pos="word" morph="none" start_char="13410" end_char="13411">of</TOKEN>
<TOKEN id="token-103-21" pos="word" morph="none" start_char="13413" end_char="13420">Foucault</TOKEN>
<TOKEN id="token-103-22" pos="punct" morph="none" start_char="13421" end_char="13421">,</TOKEN>
<TOKEN id="token-103-23" pos="word" morph="none" start_char="13423" end_char="13428">Walter</TOKEN>
<TOKEN id="token-103-24" pos="word" morph="none" start_char="13430" end_char="13437">Benjamin</TOKEN>
<TOKEN id="token-103-25" pos="word" morph="none" start_char="13439" end_char="13441">and</TOKEN>
<TOKEN id="token-103-26" pos="word" morph="none" start_char="13443" end_char="13448">Hannah</TOKEN>
<TOKEN id="token-103-27" pos="word" morph="none" start_char="13450" end_char="13455">Arendt</TOKEN>
<TOKEN id="token-103-28" pos="punct" morph="none" start_char="13456" end_char="13456">.</TOKEN>
</SEG>
<SEG id="segment-104" start_char="13458" end_char="13822">
<ORIGINAL_TEXT>Noting how a latent state of fear has metastasized into a state of collective panic, for which Covid-19 "offers once again the ideal pretext," he described how, "in a perverse vicious circle, the limitation of freedom imposed by governments is accepted in the name of a desire for security that was induced by the same governments that now intervene to satisfy it."</ORIGINAL_TEXT>
<TOKEN id="token-104-0" pos="word" morph="none" start_char="13458" end_char="13463">Noting</TOKEN>
<TOKEN id="token-104-1" pos="word" morph="none" start_char="13465" end_char="13467">how</TOKEN>
<TOKEN id="token-104-2" pos="word" morph="none" start_char="13469" end_char="13469">a</TOKEN>
<TOKEN id="token-104-3" pos="word" morph="none" start_char="13471" end_char="13476">latent</TOKEN>
<TOKEN id="token-104-4" pos="word" morph="none" start_char="13478" end_char="13482">state</TOKEN>
<TOKEN id="token-104-5" pos="word" morph="none" start_char="13484" end_char="13485">of</TOKEN>
<TOKEN id="token-104-6" pos="word" morph="none" start_char="13487" end_char="13490">fear</TOKEN>
<TOKEN id="token-104-7" pos="word" morph="none" start_char="13492" end_char="13494">has</TOKEN>
<TOKEN id="token-104-8" pos="word" morph="none" start_char="13496" end_char="13507">metastasized</TOKEN>
<TOKEN id="token-104-9" pos="word" morph="none" start_char="13509" end_char="13512">into</TOKEN>
<TOKEN id="token-104-10" pos="word" morph="none" start_char="13514" end_char="13514">a</TOKEN>
<TOKEN id="token-104-11" pos="word" morph="none" start_char="13516" end_char="13520">state</TOKEN>
<TOKEN id="token-104-12" pos="word" morph="none" start_char="13522" end_char="13523">of</TOKEN>
<TOKEN id="token-104-13" pos="word" morph="none" start_char="13525" end_char="13534">collective</TOKEN>
<TOKEN id="token-104-14" pos="word" morph="none" start_char="13536" end_char="13540">panic</TOKEN>
<TOKEN id="token-104-15" pos="punct" morph="none" start_char="13541" end_char="13541">,</TOKEN>
<TOKEN id="token-104-16" pos="word" morph="none" start_char="13543" end_char="13545">for</TOKEN>
<TOKEN id="token-104-17" pos="word" morph="none" start_char="13547" end_char="13551">which</TOKEN>
<TOKEN id="token-104-18" pos="unknown" morph="none" start_char="13553" end_char="13560">Covid-19</TOKEN>
<TOKEN id="token-104-19" pos="punct" morph="none" start_char="13562" end_char="13562">"</TOKEN>
<TOKEN id="token-104-20" pos="word" morph="none" start_char="13563" end_char="13568">offers</TOKEN>
<TOKEN id="token-104-21" pos="word" morph="none" start_char="13570" end_char="13573">once</TOKEN>
<TOKEN id="token-104-22" pos="word" morph="none" start_char="13575" end_char="13579">again</TOKEN>
<TOKEN id="token-104-23" pos="word" morph="none" start_char="13581" end_char="13583">the</TOKEN>
<TOKEN id="token-104-24" pos="word" morph="none" start_char="13585" end_char="13589">ideal</TOKEN>
<TOKEN id="token-104-25" pos="word" morph="none" start_char="13591" end_char="13597">pretext</TOKEN>
<TOKEN id="token-104-26" pos="punct" morph="none" start_char="13598" end_char="13599">,"</TOKEN>
<TOKEN id="token-104-27" pos="word" morph="none" start_char="13601" end_char="13602">he</TOKEN>
<TOKEN id="token-104-28" pos="word" morph="none" start_char="13604" end_char="13612">described</TOKEN>
<TOKEN id="token-104-29" pos="word" morph="none" start_char="13614" end_char="13616">how</TOKEN>
<TOKEN id="token-104-30" pos="punct" morph="none" start_char="13617" end_char="13617">,</TOKEN>
<TOKEN id="token-104-31" pos="punct" morph="none" start_char="13619" end_char="13619">"</TOKEN>
<TOKEN id="token-104-32" pos="word" morph="none" start_char="13620" end_char="13621">in</TOKEN>
<TOKEN id="token-104-33" pos="word" morph="none" start_char="13623" end_char="13623">a</TOKEN>
<TOKEN id="token-104-34" pos="word" morph="none" start_char="13625" end_char="13632">perverse</TOKEN>
<TOKEN id="token-104-35" pos="word" morph="none" start_char="13634" end_char="13640">vicious</TOKEN>
<TOKEN id="token-104-36" pos="word" morph="none" start_char="13642" end_char="13647">circle</TOKEN>
<TOKEN id="token-104-37" pos="punct" morph="none" start_char="13648" end_char="13648">,</TOKEN>
<TOKEN id="token-104-38" pos="word" morph="none" start_char="13650" end_char="13652">the</TOKEN>
<TOKEN id="token-104-39" pos="word" morph="none" start_char="13654" end_char="13663">limitation</TOKEN>
<TOKEN id="token-104-40" pos="word" morph="none" start_char="13665" end_char="13666">of</TOKEN>
<TOKEN id="token-104-41" pos="word" morph="none" start_char="13668" end_char="13674">freedom</TOKEN>
<TOKEN id="token-104-42" pos="word" morph="none" start_char="13676" end_char="13682">imposed</TOKEN>
<TOKEN id="token-104-43" pos="word" morph="none" start_char="13684" end_char="13685">by</TOKEN>
<TOKEN id="token-104-44" pos="word" morph="none" start_char="13687" end_char="13697">governments</TOKEN>
<TOKEN id="token-104-45" pos="word" morph="none" start_char="13699" end_char="13700">is</TOKEN>
<TOKEN id="token-104-46" pos="word" morph="none" start_char="13702" end_char="13709">accepted</TOKEN>
<TOKEN id="token-104-47" pos="word" morph="none" start_char="13711" end_char="13712">in</TOKEN>
<TOKEN id="token-104-48" pos="word" morph="none" start_char="13714" end_char="13716">the</TOKEN>
<TOKEN id="token-104-49" pos="word" morph="none" start_char="13718" end_char="13721">name</TOKEN>
<TOKEN id="token-104-50" pos="word" morph="none" start_char="13723" end_char="13724">of</TOKEN>
<TOKEN id="token-104-51" pos="word" morph="none" start_char="13726" end_char="13726">a</TOKEN>
<TOKEN id="token-104-52" pos="word" morph="none" start_char="13728" end_char="13733">desire</TOKEN>
<TOKEN id="token-104-53" pos="word" morph="none" start_char="13735" end_char="13737">for</TOKEN>
<TOKEN id="token-104-54" pos="word" morph="none" start_char="13739" end_char="13746">security</TOKEN>
<TOKEN id="token-104-55" pos="word" morph="none" start_char="13748" end_char="13751">that</TOKEN>
<TOKEN id="token-104-56" pos="word" morph="none" start_char="13753" end_char="13755">was</TOKEN>
<TOKEN id="token-104-57" pos="word" morph="none" start_char="13757" end_char="13763">induced</TOKEN>
<TOKEN id="token-104-58" pos="word" morph="none" start_char="13765" end_char="13766">by</TOKEN>
<TOKEN id="token-104-59" pos="word" morph="none" start_char="13768" end_char="13770">the</TOKEN>
<TOKEN id="token-104-60" pos="word" morph="none" start_char="13772" end_char="13775">same</TOKEN>
<TOKEN id="token-104-61" pos="word" morph="none" start_char="13777" end_char="13787">governments</TOKEN>
<TOKEN id="token-104-62" pos="word" morph="none" start_char="13789" end_char="13792">that</TOKEN>
<TOKEN id="token-104-63" pos="word" morph="none" start_char="13794" end_char="13796">now</TOKEN>
<TOKEN id="token-104-64" pos="word" morph="none" start_char="13798" end_char="13806">intervene</TOKEN>
<TOKEN id="token-104-65" pos="word" morph="none" start_char="13808" end_char="13809">to</TOKEN>
<TOKEN id="token-104-66" pos="word" morph="none" start_char="13811" end_char="13817">satisfy</TOKEN>
<TOKEN id="token-104-67" pos="word" morph="none" start_char="13819" end_char="13820">it</TOKEN>
<TOKEN id="token-104-68" pos="punct" morph="none" start_char="13821" end_char="13822">."</TOKEN>
</SEG>
<SEG id="segment-105" start_char="13825" end_char="13959">
<ORIGINAL_TEXT>There was no state of collective panic in South Korea, Singapore, Taiwan and Vietnam – to mention four Asian examples outside of China.</ORIGINAL_TEXT>
<TOKEN id="token-105-0" pos="word" morph="none" start_char="13825" end_char="13829">There</TOKEN>
<TOKEN id="token-105-1" pos="word" morph="none" start_char="13831" end_char="13833">was</TOKEN>
<TOKEN id="token-105-2" pos="word" morph="none" start_char="13835" end_char="13836">no</TOKEN>
<TOKEN id="token-105-3" pos="word" morph="none" start_char="13838" end_char="13842">state</TOKEN>
<TOKEN id="token-105-4" pos="word" morph="none" start_char="13844" end_char="13845">of</TOKEN>
<TOKEN id="token-105-5" pos="word" morph="none" start_char="13847" end_char="13856">collective</TOKEN>
<TOKEN id="token-105-6" pos="word" morph="none" start_char="13858" end_char="13862">panic</TOKEN>
<TOKEN id="token-105-7" pos="word" morph="none" start_char="13864" end_char="13865">in</TOKEN>
<TOKEN id="token-105-8" pos="word" morph="none" start_char="13867" end_char="13871">South</TOKEN>
<TOKEN id="token-105-9" pos="word" morph="none" start_char="13873" end_char="13877">Korea</TOKEN>
<TOKEN id="token-105-10" pos="punct" morph="none" start_char="13878" end_char="13878">,</TOKEN>
<TOKEN id="token-105-11" pos="word" morph="none" start_char="13880" end_char="13888">Singapore</TOKEN>
<TOKEN id="token-105-12" pos="punct" morph="none" start_char="13889" end_char="13889">,</TOKEN>
<TOKEN id="token-105-13" pos="word" morph="none" start_char="13891" end_char="13896">Taiwan</TOKEN>
<TOKEN id="token-105-14" pos="word" morph="none" start_char="13898" end_char="13900">and</TOKEN>
<TOKEN id="token-105-15" pos="word" morph="none" start_char="13902" end_char="13908">Vietnam</TOKEN>
<TOKEN id="token-105-16" pos="punct" morph="none" start_char="13910" end_char="13910">–</TOKEN>
<TOKEN id="token-105-17" pos="word" morph="none" start_char="13912" end_char="13913">to</TOKEN>
<TOKEN id="token-105-18" pos="word" morph="none" start_char="13915" end_char="13921">mention</TOKEN>
<TOKEN id="token-105-19" pos="word" morph="none" start_char="13923" end_char="13926">four</TOKEN>
<TOKEN id="token-105-20" pos="word" morph="none" start_char="13928" end_char="13932">Asian</TOKEN>
<TOKEN id="token-105-21" pos="word" morph="none" start_char="13934" end_char="13941">examples</TOKEN>
<TOKEN id="token-105-22" pos="word" morph="none" start_char="13943" end_char="13949">outside</TOKEN>
<TOKEN id="token-105-23" pos="word" morph="none" start_char="13951" end_char="13952">of</TOKEN>
<TOKEN id="token-105-24" pos="word" morph="none" start_char="13954" end_char="13958">China</TOKEN>
<TOKEN id="token-105-25" pos="punct" morph="none" start_char="13959" end_char="13959">.</TOKEN>
</SEG>
<SEG id="segment-106" start_char="13961" end_char="14058">
<ORIGINAL_TEXT>A dogged combination of mass testing and contact tracing was applied with immense professionalism.</ORIGINAL_TEXT>
<TOKEN id="token-106-0" pos="word" morph="none" start_char="13961" end_char="13961">A</TOKEN>
<TOKEN id="token-106-1" pos="word" morph="none" start_char="13963" end_char="13968">dogged</TOKEN>
<TOKEN id="token-106-2" pos="word" morph="none" start_char="13970" end_char="13980">combination</TOKEN>
<TOKEN id="token-106-3" pos="word" morph="none" start_char="13982" end_char="13983">of</TOKEN>
<TOKEN id="token-106-4" pos="word" morph="none" start_char="13985" end_char="13988">mass</TOKEN>
<TOKEN id="token-106-5" pos="word" morph="none" start_char="13990" end_char="13996">testing</TOKEN>
<TOKEN id="token-106-6" pos="word" morph="none" start_char="13998" end_char="14000">and</TOKEN>
<TOKEN id="token-106-7" pos="word" morph="none" start_char="14002" end_char="14008">contact</TOKEN>
<TOKEN id="token-106-8" pos="word" morph="none" start_char="14010" end_char="14016">tracing</TOKEN>
<TOKEN id="token-106-9" pos="word" morph="none" start_char="14018" end_char="14020">was</TOKEN>
<TOKEN id="token-106-10" pos="word" morph="none" start_char="14022" end_char="14028">applied</TOKEN>
<TOKEN id="token-106-11" pos="word" morph="none" start_char="14030" end_char="14033">with</TOKEN>
<TOKEN id="token-106-12" pos="word" morph="none" start_char="14035" end_char="14041">immense</TOKEN>
<TOKEN id="token-106-13" pos="word" morph="none" start_char="14043" end_char="14057">professionalism</TOKEN>
<TOKEN id="token-106-14" pos="punct" morph="none" start_char="14058" end_char="14058">.</TOKEN>
</SEG>
<SEG id="segment-107" start_char="14060" end_char="14069">
<ORIGINAL_TEXT>It worked.</ORIGINAL_TEXT>
<TOKEN id="token-107-0" pos="word" morph="none" start_char="14060" end_char="14061">It</TOKEN>
<TOKEN id="token-107-1" pos="word" morph="none" start_char="14063" end_char="14068">worked</TOKEN>
<TOKEN id="token-107-2" pos="punct" morph="none" start_char="14069" end_char="14069">.</TOKEN>
</SEG>
<SEG id="segment-108" start_char="14071" end_char="14120">
<ORIGINAL_TEXT>In the Chinese case, with the help of chloroquine.</ORIGINAL_TEXT>
<TOKEN id="token-108-0" pos="word" morph="none" start_char="14071" end_char="14072">In</TOKEN>
<TOKEN id="token-108-1" pos="word" morph="none" start_char="14074" end_char="14076">the</TOKEN>
<TOKEN id="token-108-2" pos="word" morph="none" start_char="14078" end_char="14084">Chinese</TOKEN>
<TOKEN id="token-108-3" pos="word" morph="none" start_char="14086" end_char="14089">case</TOKEN>
<TOKEN id="token-108-4" pos="punct" morph="none" start_char="14090" end_char="14090">,</TOKEN>
<TOKEN id="token-108-5" pos="word" morph="none" start_char="14092" end_char="14095">with</TOKEN>
<TOKEN id="token-108-6" pos="word" morph="none" start_char="14097" end_char="14099">the</TOKEN>
<TOKEN id="token-108-7" pos="word" morph="none" start_char="14101" end_char="14104">help</TOKEN>
<TOKEN id="token-108-8" pos="word" morph="none" start_char="14106" end_char="14107">of</TOKEN>
<TOKEN id="token-108-9" pos="word" morph="none" start_char="14109" end_char="14119">chloroquine</TOKEN>
<TOKEN id="token-108-10" pos="punct" morph="none" start_char="14120" end_char="14120">.</TOKEN>
</SEG>
<SEG id="segment-109" start_char="14122" end_char="14204">
<ORIGINAL_TEXT>And in all Asian cases, without a murky profit motive to the benefit of Big Pharma.</ORIGINAL_TEXT>
<TOKEN id="token-109-0" pos="word" morph="none" start_char="14122" end_char="14124">And</TOKEN>
<TOKEN id="token-109-1" pos="word" morph="none" start_char="14126" end_char="14127">in</TOKEN>
<TOKEN id="token-109-2" pos="word" morph="none" start_char="14129" end_char="14131">all</TOKEN>
<TOKEN id="token-109-3" pos="word" morph="none" start_char="14133" end_char="14137">Asian</TOKEN>
<TOKEN id="token-109-4" pos="word" morph="none" start_char="14139" end_char="14143">cases</TOKEN>
<TOKEN id="token-109-5" pos="punct" morph="none" start_char="14144" end_char="14144">,</TOKEN>
<TOKEN id="token-109-6" pos="word" morph="none" start_char="14146" end_char="14152">without</TOKEN>
<TOKEN id="token-109-7" pos="word" morph="none" start_char="14154" end_char="14154">a</TOKEN>
<TOKEN id="token-109-8" pos="word" morph="none" start_char="14156" end_char="14160">murky</TOKEN>
<TOKEN id="token-109-9" pos="word" morph="none" start_char="14162" end_char="14167">profit</TOKEN>
<TOKEN id="token-109-10" pos="word" morph="none" start_char="14169" end_char="14174">motive</TOKEN>
<TOKEN id="token-109-11" pos="word" morph="none" start_char="14176" end_char="14177">to</TOKEN>
<TOKEN id="token-109-12" pos="word" morph="none" start_char="14179" end_char="14181">the</TOKEN>
<TOKEN id="token-109-13" pos="word" morph="none" start_char="14183" end_char="14189">benefit</TOKEN>
<TOKEN id="token-109-14" pos="word" morph="none" start_char="14191" end_char="14192">of</TOKEN>
<TOKEN id="token-109-15" pos="word" morph="none" start_char="14194" end_char="14196">Big</TOKEN>
<TOKEN id="token-109-16" pos="word" morph="none" start_char="14198" end_char="14203">Pharma</TOKEN>
<TOKEN id="token-109-17" pos="punct" morph="none" start_char="14204" end_char="14204">.</TOKEN>
</SEG>
<SEG id="segment-110" start_char="14207" end_char="14412">
<ORIGINAL_TEXT>There hasn’t yet appeared the smoking gun that proves the Macron system not only is incompetent to deal with Covid-19 but also is dragging the process so Big Pharma can come up with a miracle vaccine, fast.</ORIGINAL_TEXT>
<TOKEN id="token-110-0" pos="word" morph="none" start_char="14207" end_char="14211">There</TOKEN>
<TOKEN id="token-110-1" pos="word" morph="none" start_char="14213" end_char="14218">hasn’t</TOKEN>
<TOKEN id="token-110-2" pos="word" morph="none" start_char="14220" end_char="14222">yet</TOKEN>
<TOKEN id="token-110-3" pos="word" morph="none" start_char="14224" end_char="14231">appeared</TOKEN>
<TOKEN id="token-110-4" pos="word" morph="none" start_char="14233" end_char="14235">the</TOKEN>
<TOKEN id="token-110-5" pos="word" morph="none" start_char="14237" end_char="14243">smoking</TOKEN>
<TOKEN id="token-110-6" pos="word" morph="none" start_char="14245" end_char="14247">gun</TOKEN>
<TOKEN id="token-110-7" pos="word" morph="none" start_char="14249" end_char="14252">that</TOKEN>
<TOKEN id="token-110-8" pos="word" morph="none" start_char="14254" end_char="14259">proves</TOKEN>
<TOKEN id="token-110-9" pos="word" morph="none" start_char="14261" end_char="14263">the</TOKEN>
<TOKEN id="token-110-10" pos="word" morph="none" start_char="14265" end_char="14270">Macron</TOKEN>
<TOKEN id="token-110-11" pos="word" morph="none" start_char="14272" end_char="14277">system</TOKEN>
<TOKEN id="token-110-12" pos="word" morph="none" start_char="14279" end_char="14281">not</TOKEN>
<TOKEN id="token-110-13" pos="word" morph="none" start_char="14283" end_char="14286">only</TOKEN>
<TOKEN id="token-110-14" pos="word" morph="none" start_char="14288" end_char="14289">is</TOKEN>
<TOKEN id="token-110-15" pos="word" morph="none" start_char="14291" end_char="14301">incompetent</TOKEN>
<TOKEN id="token-110-16" pos="word" morph="none" start_char="14303" end_char="14304">to</TOKEN>
<TOKEN id="token-110-17" pos="word" morph="none" start_char="14306" end_char="14309">deal</TOKEN>
<TOKEN id="token-110-18" pos="word" morph="none" start_char="14311" end_char="14314">with</TOKEN>
<TOKEN id="token-110-19" pos="unknown" morph="none" start_char="14316" end_char="14323">Covid-19</TOKEN>
<TOKEN id="token-110-20" pos="word" morph="none" start_char="14325" end_char="14327">but</TOKEN>
<TOKEN id="token-110-21" pos="word" morph="none" start_char="14329" end_char="14332">also</TOKEN>
<TOKEN id="token-110-22" pos="word" morph="none" start_char="14334" end_char="14335">is</TOKEN>
<TOKEN id="token-110-23" pos="word" morph="none" start_char="14337" end_char="14344">dragging</TOKEN>
<TOKEN id="token-110-24" pos="word" morph="none" start_char="14346" end_char="14348">the</TOKEN>
<TOKEN id="token-110-25" pos="word" morph="none" start_char="14350" end_char="14356">process</TOKEN>
<TOKEN id="token-110-26" pos="word" morph="none" start_char="14358" end_char="14359">so</TOKEN>
<TOKEN id="token-110-27" pos="word" morph="none" start_char="14361" end_char="14363">Big</TOKEN>
<TOKEN id="token-110-28" pos="word" morph="none" start_char="14365" end_char="14370">Pharma</TOKEN>
<TOKEN id="token-110-29" pos="word" morph="none" start_char="14372" end_char="14374">can</TOKEN>
<TOKEN id="token-110-30" pos="word" morph="none" start_char="14376" end_char="14379">come</TOKEN>
<TOKEN id="token-110-31" pos="word" morph="none" start_char="14381" end_char="14382">up</TOKEN>
<TOKEN id="token-110-32" pos="word" morph="none" start_char="14384" end_char="14387">with</TOKEN>
<TOKEN id="token-110-33" pos="word" morph="none" start_char="14389" end_char="14389">a</TOKEN>
<TOKEN id="token-110-34" pos="word" morph="none" start_char="14391" end_char="14397">miracle</TOKEN>
<TOKEN id="token-110-35" pos="word" morph="none" start_char="14399" end_char="14405">vaccine</TOKEN>
<TOKEN id="token-110-36" pos="punct" morph="none" start_char="14406" end_char="14406">,</TOKEN>
<TOKEN id="token-110-37" pos="word" morph="none" start_char="14408" end_char="14411">fast</TOKEN>
<TOKEN id="token-110-38" pos="punct" morph="none" start_char="14412" end_char="14412">.</TOKEN>
</SEG>
<SEG id="segment-111" start_char="14414" end_char="14527">
<ORIGINAL_TEXT>But the pattern to discourage chloroquine is more than laid out above – in parallel to the demonization of Raoult.</ORIGINAL_TEXT>
<TOKEN id="token-111-0" pos="word" morph="none" start_char="14414" end_char="14416">But</TOKEN>
<TOKEN id="token-111-1" pos="word" morph="none" start_char="14418" end_char="14420">the</TOKEN>
<TOKEN id="token-111-2" pos="word" morph="none" start_char="14422" end_char="14428">pattern</TOKEN>
<TOKEN id="token-111-3" pos="word" morph="none" start_char="14430" end_char="14431">to</TOKEN>
<TOKEN id="token-111-4" pos="word" morph="none" start_char="14433" end_char="14442">discourage</TOKEN>
<TOKEN id="token-111-5" pos="word" morph="none" start_char="14444" end_char="14454">chloroquine</TOKEN>
<TOKEN id="token-111-6" pos="word" morph="none" start_char="14456" end_char="14457">is</TOKEN>
<TOKEN id="token-111-7" pos="word" morph="none" start_char="14459" end_char="14462">more</TOKEN>
<TOKEN id="token-111-8" pos="word" morph="none" start_char="14464" end_char="14467">than</TOKEN>
<TOKEN id="token-111-9" pos="word" morph="none" start_char="14469" end_char="14472">laid</TOKEN>
<TOKEN id="token-111-10" pos="word" morph="none" start_char="14474" end_char="14476">out</TOKEN>
<TOKEN id="token-111-11" pos="word" morph="none" start_char="14478" end_char="14482">above</TOKEN>
<TOKEN id="token-111-12" pos="punct" morph="none" start_char="14484" end_char="14484">–</TOKEN>
<TOKEN id="token-111-13" pos="word" morph="none" start_char="14486" end_char="14487">in</TOKEN>
<TOKEN id="token-111-14" pos="word" morph="none" start_char="14489" end_char="14496">parallel</TOKEN>
<TOKEN id="token-111-15" pos="word" morph="none" start_char="14498" end_char="14499">to</TOKEN>
<TOKEN id="token-111-16" pos="word" morph="none" start_char="14501" end_char="14503">the</TOKEN>
<TOKEN id="token-111-17" pos="word" morph="none" start_char="14505" end_char="14516">demonization</TOKEN>
<TOKEN id="token-111-18" pos="word" morph="none" start_char="14518" end_char="14519">of</TOKEN>
<TOKEN id="token-111-19" pos="word" morph="none" start_char="14521" end_char="14526">Raoult</TOKEN>
<TOKEN id="token-111-20" pos="punct" morph="none" start_char="14527" end_char="14527">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
