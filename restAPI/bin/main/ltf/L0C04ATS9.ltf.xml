<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATS9" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="3515" raw_text_md5="b487afbad30ee21c3f755c72cfddffa9">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="125">
<ORIGINAL_TEXT>Documentos filtrados del Banco Mundial indican que el Covid fue creado en 2018 en laboratorios y que durará hasta el año 2025</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="10">Documentos</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="12" end_char="20">filtrados</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="22" end_char="24">del</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="26" end_char="30">Banco</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="32" end_char="38">Mundial</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="40" end_char="46">indican</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="48" end_char="50">que</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="52" end_char="53">el</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="55" end_char="59">Covid</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="61" end_char="63">fue</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="65" end_char="70">creado</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="72" end_char="73">en</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="75" end_char="78">2018</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="80" end_char="81">en</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="83" end_char="94">laboratorios</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="96" end_char="96">y</TOKEN>
<TOKEN id="token-0-16" pos="word" morph="none" start_char="98" end_char="100">que</TOKEN>
<TOKEN id="token-0-17" pos="word" morph="none" start_char="102" end_char="107">durará</TOKEN>
<TOKEN id="token-0-18" pos="word" morph="none" start_char="109" end_char="113">hasta</TOKEN>
<TOKEN id="token-0-19" pos="word" morph="none" start_char="115" end_char="116">el</TOKEN>
<TOKEN id="token-0-20" pos="word" morph="none" start_char="118" end_char="120">año</TOKEN>
<TOKEN id="token-0-21" pos="word" morph="none" start_char="122" end_char="125">2025</TOKEN>
</SEG>
<SEG id="segment-1" start_char="131" end_char="275">
<ORIGINAL_TEXT>Informes filtrados del Banco Mundial indican que la propagación del Covid forma parte de un plan diseñado en 2018 y que se prolongará hasta 2025.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="131" end_char="138">Informes</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="140" end_char="148">filtrados</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="150" end_char="152">del</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="154" end_char="158">Banco</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="160" end_char="166">Mundial</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="168" end_char="174">indican</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="176" end_char="178">que</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="180" end_char="181">la</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="183" end_char="193">propagación</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="195" end_char="197">del</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="199" end_char="203">Covid</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="205" end_char="209">forma</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="211" end_char="215">parte</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="217" end_char="218">de</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="220" end_char="221">un</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="223" end_char="226">plan</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="228" end_char="235">diseñado</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="237" end_char="238">en</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="240" end_char="243">2018</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="245" end_char="245">y</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="247" end_char="249">que</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="251" end_char="252">se</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="254" end_char="263">prolongará</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="265" end_char="269">hasta</TOKEN>
<TOKEN id="token-1-24" pos="word" morph="none" start_char="271" end_char="274">2025</TOKEN>
<TOKEN id="token-1-25" pos="punct" morph="none" start_char="275" end_char="275">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="277" end_char="467">
<ORIGINAL_TEXT>De acuerdo a las mismas fuentes, el Banco Mundial previó la compra masiva de test en el año 2018, lo que reforzaría los argumentos de quienes sostienen que la pandemia surgió deliberadamente.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="277" end_char="278">De</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="280" end_char="286">acuerdo</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="288" end_char="288">a</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="290" end_char="292">las</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="294" end_char="299">mismas</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="301" end_char="307">fuentes</TOKEN>
<TOKEN id="token-2-6" pos="punct" morph="none" start_char="308" end_char="308">,</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="310" end_char="311">el</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="313" end_char="317">Banco</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="319" end_char="325">Mundial</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="327" end_char="332">previó</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="334" end_char="335">la</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="337" end_char="342">compra</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="344" end_char="349">masiva</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="351" end_char="352">de</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="354" end_char="357">test</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="359" end_char="360">en</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="362" end_char="363">el</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="365" end_char="367">año</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="369" end_char="372">2018</TOKEN>
<TOKEN id="token-2-20" pos="punct" morph="none" start_char="373" end_char="373">,</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="375" end_char="376">lo</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="378" end_char="380">que</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="382" end_char="391">reforzaría</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="393" end_char="395">los</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="397" end_char="406">argumentos</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="408" end_char="409">de</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="411" end_char="417">quienes</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="419" end_char="427">sostienen</TOKEN>
<TOKEN id="token-2-29" pos="word" morph="none" start_char="429" end_char="431">que</TOKEN>
<TOKEN id="token-2-30" pos="word" morph="none" start_char="433" end_char="434">la</TOKEN>
<TOKEN id="token-2-31" pos="word" morph="none" start_char="436" end_char="443">pandemia</TOKEN>
<TOKEN id="token-2-32" pos="word" morph="none" start_char="445" end_char="450">surgió</TOKEN>
<TOKEN id="token-2-33" pos="word" morph="none" start_char="452" end_char="466">deliberadamente</TOKEN>
<TOKEN id="token-2-34" pos="punct" morph="none" start_char="467" end_char="467">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="470" end_char="571">
<ORIGINAL_TEXT>Según los informes, el virus surgió de la mezcla y selección de genes virales de murciélagos y cerdos.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="470" end_char="474">Según</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="476" end_char="478">los</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="480" end_char="487">informes</TOKEN>
<TOKEN id="token-3-3" pos="punct" morph="none" start_char="488" end_char="488">,</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="490" end_char="491">el</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="493" end_char="497">virus</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="499" end_char="504">surgió</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="506" end_char="507">de</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="509" end_char="510">la</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="512" end_char="517">mezcla</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="519" end_char="519">y</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="521" end_char="529">selección</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="531" end_char="532">de</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="534" end_char="538">genes</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="540" end_char="546">virales</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="548" end_char="549">de</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="551" end_char="561">murciélagos</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="563" end_char="563">y</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="565" end_char="570">cerdos</TOKEN>
<TOKEN id="token-3-19" pos="punct" morph="none" start_char="571" end_char="571">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="573" end_char="784">
<ORIGINAL_TEXT>Entre 2016 y 2017, se identificó un coronavirus en los murciélagos de herradura y confirmó que fue el responsable de la muerte de unos 25.000 lechones en el país asiático, utilizados presumiblemente como cobayas.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="573" end_char="577">Entre</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="579" end_char="582">2016</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="584" end_char="584">y</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="586" end_char="589">2017</TOKEN>
<TOKEN id="token-4-4" pos="punct" morph="none" start_char="590" end_char="590">,</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="592" end_char="593">se</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="595" end_char="604">identificó</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="606" end_char="607">un</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="609" end_char="619">coronavirus</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="621" end_char="622">en</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="624" end_char="626">los</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="628" end_char="638">murciélagos</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="640" end_char="641">de</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="643" end_char="651">herradura</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="653" end_char="653">y</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="655" end_char="662">confirmó</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="664" end_char="666">que</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="668" end_char="670">fue</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="672" end_char="673">el</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="675" end_char="685">responsable</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="687" end_char="688">de</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="690" end_char="691">la</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="693" end_char="698">muerte</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="700" end_char="701">de</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="703" end_char="706">unos</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="708" end_char="713">25.000</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="715" end_char="722">lechones</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="724" end_char="725">en</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="727" end_char="728">el</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="730" end_char="733">país</TOKEN>
<TOKEN id="token-4-30" pos="word" morph="none" start_char="735" end_char="742">asiático</TOKEN>
<TOKEN id="token-4-31" pos="punct" morph="none" start_char="743" end_char="743">,</TOKEN>
<TOKEN id="token-4-32" pos="word" morph="none" start_char="745" end_char="754">utilizados</TOKEN>
<TOKEN id="token-4-33" pos="word" morph="none" start_char="756" end_char="770">presumiblemente</TOKEN>
<TOKEN id="token-4-34" pos="word" morph="none" start_char="772" end_char="775">como</TOKEN>
<TOKEN id="token-4-35" pos="word" morph="none" start_char="777" end_char="783">cobayas</TOKEN>
<TOKEN id="token-4-36" pos="punct" morph="none" start_char="784" end_char="784">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="787" end_char="974">
<ORIGINAL_TEXT>Entre 2016 y 2017, miles de cerdos recién nacidos en numerosas granjas de la provincia meridional de Guangdong empezaron a morir misteriosamente, padeciendo síntomas como diarrea y vómito.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="787" end_char="791">Entre</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="793" end_char="796">2016</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="798" end_char="798">y</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="800" end_char="803">2017</TOKEN>
<TOKEN id="token-5-4" pos="punct" morph="none" start_char="804" end_char="804">,</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="806" end_char="810">miles</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="812" end_char="813">de</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="815" end_char="820">cerdos</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="822" end_char="827">recién</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="829" end_char="835">nacidos</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="837" end_char="838">en</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="840" end_char="848">numerosas</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="850" end_char="856">granjas</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="858" end_char="859">de</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="861" end_char="862">la</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="864" end_char="872">provincia</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="874" end_char="883">meridional</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="885" end_char="886">de</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="888" end_char="896">Guangdong</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="898" end_char="906">empezaron</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="908" end_char="908">a</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="910" end_char="914">morir</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="916" end_char="930">misteriosamente</TOKEN>
<TOKEN id="token-5-23" pos="punct" morph="none" start_char="931" end_char="931">,</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="933" end_char="942">padeciendo</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="944" end_char="951">síntomas</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="953" end_char="956">como</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="958" end_char="964">diarrea</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="966" end_char="966">y</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="968" end_char="973">vómito</TOKEN>
<TOKEN id="token-5-30" pos="punct" morph="none" start_char="974" end_char="974">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="977" end_char="1244">
<ORIGINAL_TEXT>En principio los investigadores sospecharon que el culpable era el virus de la diarrea epidémica porcina (PEDV, siglas en inglés), pero nuevos exámenes, basados en análisis genéticos, les permitieron comprobar que se trataba del SADS, o síndrome diarrea aguda porcina.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="977" end_char="978">En</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="980" end_char="988">principio</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="990" end_char="992">los</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="994" end_char="1007">investigadores</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="1009" end_char="1019">sospecharon</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="1021" end_char="1023">que</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="1025" end_char="1026">el</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="1028" end_char="1035">culpable</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="1037" end_char="1039">era</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="1041" end_char="1042">el</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="1044" end_char="1048">virus</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="1050" end_char="1051">de</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="1053" end_char="1054">la</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="1056" end_char="1062">diarrea</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="1064" end_char="1072">epidémica</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="1074" end_char="1080">porcina</TOKEN>
<TOKEN id="token-6-16" pos="punct" morph="none" start_char="1082" end_char="1082">(</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="1083" end_char="1086">PEDV</TOKEN>
<TOKEN id="token-6-18" pos="punct" morph="none" start_char="1087" end_char="1087">,</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="1089" end_char="1094">siglas</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="1096" end_char="1097">en</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="1099" end_char="1104">inglés</TOKEN>
<TOKEN id="token-6-22" pos="punct" morph="none" start_char="1105" end_char="1106">),</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="1108" end_char="1111">pero</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="1113" end_char="1118">nuevos</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="1120" end_char="1127">exámenes</TOKEN>
<TOKEN id="token-6-26" pos="punct" morph="none" start_char="1128" end_char="1128">,</TOKEN>
<TOKEN id="token-6-27" pos="word" morph="none" start_char="1130" end_char="1136">basados</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="1138" end_char="1139">en</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="1141" end_char="1148">análisis</TOKEN>
<TOKEN id="token-6-30" pos="word" morph="none" start_char="1150" end_char="1158">genéticos</TOKEN>
<TOKEN id="token-6-31" pos="punct" morph="none" start_char="1159" end_char="1159">,</TOKEN>
<TOKEN id="token-6-32" pos="word" morph="none" start_char="1161" end_char="1163">les</TOKEN>
<TOKEN id="token-6-33" pos="word" morph="none" start_char="1165" end_char="1175">permitieron</TOKEN>
<TOKEN id="token-6-34" pos="word" morph="none" start_char="1177" end_char="1185">comprobar</TOKEN>
<TOKEN id="token-6-35" pos="word" morph="none" start_char="1187" end_char="1189">que</TOKEN>
<TOKEN id="token-6-36" pos="word" morph="none" start_char="1191" end_char="1192">se</TOKEN>
<TOKEN id="token-6-37" pos="word" morph="none" start_char="1194" end_char="1200">trataba</TOKEN>
<TOKEN id="token-6-38" pos="word" morph="none" start_char="1202" end_char="1204">del</TOKEN>
<TOKEN id="token-6-39" pos="word" morph="none" start_char="1206" end_char="1209">SADS</TOKEN>
<TOKEN id="token-6-40" pos="punct" morph="none" start_char="1210" end_char="1210">,</TOKEN>
<TOKEN id="token-6-41" pos="word" morph="none" start_char="1212" end_char="1212">o</TOKEN>
<TOKEN id="token-6-42" pos="word" morph="none" start_char="1214" end_char="1221">síndrome</TOKEN>
<TOKEN id="token-6-43" pos="word" morph="none" start_char="1223" end_char="1229">diarrea</TOKEN>
<TOKEN id="token-6-44" pos="word" morph="none" start_char="1231" end_char="1235">aguda</TOKEN>
<TOKEN id="token-6-45" pos="word" morph="none" start_char="1237" end_char="1243">porcina</TOKEN>
<TOKEN id="token-6-46" pos="punct" morph="none" start_char="1244" end_char="1244">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="1247" end_char="1408">
<ORIGINAL_TEXT>«Cuando pusimos este germen bajo el microscopio, confirmamos que era un virus nuevo de la misma familia del PEDV y el SARS (Síndrome Respiratorio Agudo y Severo).</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="punct" morph="none" start_char="1247" end_char="1247">«</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="1248" end_char="1253">Cuando</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="1255" end_char="1261">pusimos</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="1263" end_char="1266">este</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="1268" end_char="1273">germen</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="1275" end_char="1278">bajo</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="1280" end_char="1281">el</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="1283" end_char="1293">microscopio</TOKEN>
<TOKEN id="token-7-8" pos="punct" morph="none" start_char="1294" end_char="1294">,</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="1296" end_char="1306">confirmamos</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="1308" end_char="1310">que</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="1312" end_char="1314">era</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="1316" end_char="1317">un</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="1319" end_char="1323">virus</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="1325" end_char="1329">nuevo</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="1331" end_char="1332">de</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="1334" end_char="1335">la</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="1337" end_char="1341">misma</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="1343" end_char="1349">familia</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="1351" end_char="1353">del</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="1355" end_char="1358">PEDV</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="1360" end_char="1360">y</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="1362" end_char="1363">el</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="1365" end_char="1368">SARS</TOKEN>
<TOKEN id="token-7-24" pos="punct" morph="none" start_char="1370" end_char="1370">(</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="1371" end_char="1378">Síndrome</TOKEN>
<TOKEN id="token-7-26" pos="word" morph="none" start_char="1380" end_char="1391">Respiratorio</TOKEN>
<TOKEN id="token-7-27" pos="word" morph="none" start_char="1393" end_char="1397">Agudo</TOKEN>
<TOKEN id="token-7-28" pos="word" morph="none" start_char="1399" end_char="1399">y</TOKEN>
<TOKEN id="token-7-29" pos="word" morph="none" start_char="1401" end_char="1406">Severo</TOKEN>
<TOKEN id="token-7-30" pos="punct" morph="none" start_char="1407" end_char="1408">).</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1410" end_char="1677">
<ORIGINAL_TEXT>Los murciélagos son reconocidos como depositarios de un gran número de patógenos, por lo tanto empezamos a rastrear el virus en muestras de murciélagos», dijo Shi Zhengli, un virólogo del Instituto de Virología de Wuhan, subordinado a la Academia de Ciencias de China.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1410" end_char="1412">Los</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1414" end_char="1424">murciélagos</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1426" end_char="1428">son</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1430" end_char="1440">reconocidos</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1442" end_char="1445">como</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1447" end_char="1458">depositarios</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1460" end_char="1461">de</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1463" end_char="1464">un</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1466" end_char="1469">gran</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1471" end_char="1476">número</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1478" end_char="1479">de</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1481" end_char="1489">patógenos</TOKEN>
<TOKEN id="token-8-12" pos="punct" morph="none" start_char="1490" end_char="1490">,</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1492" end_char="1494">por</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1496" end_char="1497">lo</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1499" end_char="1503">tanto</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1505" end_char="1513">empezamos</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1515" end_char="1515">a</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1517" end_char="1524">rastrear</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1526" end_char="1527">el</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="1529" end_char="1533">virus</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="1535" end_char="1536">en</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="1538" end_char="1545">muestras</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="1547" end_char="1548">de</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="1550" end_char="1560">murciélagos</TOKEN>
<TOKEN id="token-8-25" pos="punct" morph="none" start_char="1561" end_char="1562">»,</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="1564" end_char="1567">dijo</TOKEN>
<TOKEN id="token-8-27" pos="word" morph="none" start_char="1569" end_char="1571">Shi</TOKEN>
<TOKEN id="token-8-28" pos="word" morph="none" start_char="1573" end_char="1579">Zhengli</TOKEN>
<TOKEN id="token-8-29" pos="punct" morph="none" start_char="1580" end_char="1580">,</TOKEN>
<TOKEN id="token-8-30" pos="word" morph="none" start_char="1582" end_char="1583">un</TOKEN>
<TOKEN id="token-8-31" pos="word" morph="none" start_char="1585" end_char="1592">virólogo</TOKEN>
<TOKEN id="token-8-32" pos="word" morph="none" start_char="1594" end_char="1596">del</TOKEN>
<TOKEN id="token-8-33" pos="word" morph="none" start_char="1598" end_char="1606">Instituto</TOKEN>
<TOKEN id="token-8-34" pos="word" morph="none" start_char="1608" end_char="1609">de</TOKEN>
<TOKEN id="token-8-35" pos="word" morph="none" start_char="1611" end_char="1619">Virología</TOKEN>
<TOKEN id="token-8-36" pos="word" morph="none" start_char="1621" end_char="1622">de</TOKEN>
<TOKEN id="token-8-37" pos="word" morph="none" start_char="1624" end_char="1628">Wuhan</TOKEN>
<TOKEN id="token-8-38" pos="punct" morph="none" start_char="1629" end_char="1629">,</TOKEN>
<TOKEN id="token-8-39" pos="word" morph="none" start_char="1631" end_char="1641">subordinado</TOKEN>
<TOKEN id="token-8-40" pos="word" morph="none" start_char="1643" end_char="1643">a</TOKEN>
<TOKEN id="token-8-41" pos="word" morph="none" start_char="1645" end_char="1646">la</TOKEN>
<TOKEN id="token-8-42" pos="word" morph="none" start_char="1648" end_char="1655">Academia</TOKEN>
<TOKEN id="token-8-43" pos="word" morph="none" start_char="1657" end_char="1658">de</TOKEN>
<TOKEN id="token-8-44" pos="word" morph="none" start_char="1660" end_char="1667">Ciencias</TOKEN>
<TOKEN id="token-8-45" pos="word" morph="none" start_char="1669" end_char="1670">de</TOKEN>
<TOKEN id="token-8-46" pos="word" morph="none" start_char="1672" end_char="1676">China</TOKEN>
<TOKEN id="token-8-47" pos="punct" morph="none" start_char="1677" end_char="1677">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1680" end_char="1835">
<ORIGINAL_TEXT>De acuerdo con Shi, los investigadores recolectaron 591 muestras de murciélagos, mayoritariamente de aquellos de la familia de herradura, entre 2013 y 2016.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1680" end_char="1681">De</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1683" end_char="1689">acuerdo</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1691" end_char="1693">con</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1695" end_char="1697">Shi</TOKEN>
<TOKEN id="token-9-4" pos="punct" morph="none" start_char="1698" end_char="1698">,</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1700" end_char="1702">los</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1704" end_char="1717">investigadores</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1719" end_char="1730">recolectaron</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1732" end_char="1734">591</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1736" end_char="1743">muestras</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1745" end_char="1746">de</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1748" end_char="1758">murciélagos</TOKEN>
<TOKEN id="token-9-12" pos="punct" morph="none" start_char="1759" end_char="1759">,</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1761" end_char="1776">mayoritariamente</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1778" end_char="1779">de</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1781" end_char="1788">aquellos</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1790" end_char="1791">de</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1793" end_char="1794">la</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1796" end_char="1802">familia</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1804" end_char="1805">de</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1807" end_char="1815">herradura</TOKEN>
<TOKEN id="token-9-21" pos="punct" morph="none" start_char="1816" end_char="1816">,</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1818" end_char="1822">entre</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1824" end_char="1827">2013</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1829" end_char="1829">y</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1831" end_char="1834">2016</TOKEN>
<TOKEN id="token-9-26" pos="punct" morph="none" start_char="1835" end_char="1835">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1837" end_char="1886">
<ORIGINAL_TEXT>De todas ellas, el 10 por ciento resultó positivo.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1837" end_char="1838">De</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1840" end_char="1844">todas</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1846" end_char="1850">ellas</TOKEN>
<TOKEN id="token-10-3" pos="punct" morph="none" start_char="1851" end_char="1851">,</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1853" end_char="1854">el</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1856" end_char="1857">10</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1859" end_char="1861">por</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1863" end_char="1868">ciento</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1870" end_char="1876">resultó</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1878" end_char="1885">positivo</TOKEN>
<TOKEN id="token-10-10" pos="punct" morph="none" start_char="1886" end_char="1886">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1889" end_char="2084">
<ORIGINAL_TEXT>La investigación fue desarrollada de manera conjunta por científicos de China, Singapur y Estados Unidos, y los descubrimientos fueron publicados la semana pasada en la prestigiosa revista Nature.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1889" end_char="1890">La</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1892" end_char="1904">investigación</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1906" end_char="1908">fue</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1910" end_char="1921">desarrollada</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1923" end_char="1924">de</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1926" end_char="1931">manera</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1933" end_char="1940">conjunta</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1942" end_char="1944">por</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1946" end_char="1956">científicos</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1958" end_char="1959">de</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1961" end_char="1965">China</TOKEN>
<TOKEN id="token-11-11" pos="punct" morph="none" start_char="1966" end_char="1966">,</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1968" end_char="1975">Singapur</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1977" end_char="1977">y</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1979" end_char="1985">Estados</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1987" end_char="1992">Unidos</TOKEN>
<TOKEN id="token-11-16" pos="punct" morph="none" start_char="1993" end_char="1993">,</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1995" end_char="1995">y</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1997" end_char="1999">los</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="2001" end_char="2015">descubrimientos</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="2017" end_char="2022">fueron</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="2024" end_char="2033">publicados</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="2035" end_char="2036">la</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="2038" end_char="2043">semana</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="2045" end_char="2050">pasada</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="2052" end_char="2053">en</TOKEN>
<TOKEN id="token-11-26" pos="word" morph="none" start_char="2055" end_char="2056">la</TOKEN>
<TOKEN id="token-11-27" pos="word" morph="none" start_char="2058" end_char="2068">prestigiosa</TOKEN>
<TOKEN id="token-11-28" pos="word" morph="none" start_char="2070" end_char="2076">revista</TOKEN>
<TOKEN id="token-11-29" pos="word" morph="none" start_char="2078" end_char="2083">Nature</TOKEN>
<TOKEN id="token-11-30" pos="punct" morph="none" start_char="2084" end_char="2084">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="2087" end_char="2346">
<ORIGINAL_TEXT>«El estudio subraya la importancia de identificar la diversidad y la distribución de los coronavirus en los murciélagos para mitigar futuros brotes que podrían amenazar al ganado, la salud pública y el crecimiento económico», de acuerdo con los investigadores.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="punct" morph="none" start_char="2087" end_char="2087">«</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="2088" end_char="2089">El</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="2091" end_char="2097">estudio</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="2099" end_char="2105">subraya</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="2107" end_char="2108">la</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="2110" end_char="2120">importancia</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="2122" end_char="2123">de</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="2125" end_char="2135">identificar</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="2137" end_char="2138">la</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="2140" end_char="2149">diversidad</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="2151" end_char="2151">y</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="2153" end_char="2154">la</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="2156" end_char="2167">distribución</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="2169" end_char="2170">de</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="2172" end_char="2174">los</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="2176" end_char="2186">coronavirus</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="2188" end_char="2189">en</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="2191" end_char="2193">los</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="2195" end_char="2205">murciélagos</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="2207" end_char="2210">para</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="2212" end_char="2218">mitigar</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="2220" end_char="2226">futuros</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="2228" end_char="2233">brotes</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="2235" end_char="2237">que</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="2239" end_char="2245">podrían</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="2247" end_char="2254">amenazar</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="2256" end_char="2257">al</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="2259" end_char="2264">ganado</TOKEN>
<TOKEN id="token-12-28" pos="punct" morph="none" start_char="2265" end_char="2265">,</TOKEN>
<TOKEN id="token-12-29" pos="word" morph="none" start_char="2267" end_char="2268">la</TOKEN>
<TOKEN id="token-12-30" pos="word" morph="none" start_char="2270" end_char="2274">salud</TOKEN>
<TOKEN id="token-12-31" pos="word" morph="none" start_char="2276" end_char="2282">pública</TOKEN>
<TOKEN id="token-12-32" pos="word" morph="none" start_char="2284" end_char="2284">y</TOKEN>
<TOKEN id="token-12-33" pos="word" morph="none" start_char="2286" end_char="2287">el</TOKEN>
<TOKEN id="token-12-34" pos="word" morph="none" start_char="2289" end_char="2299">crecimiento</TOKEN>
<TOKEN id="token-12-35" pos="word" morph="none" start_char="2301" end_char="2309">económico</TOKEN>
<TOKEN id="token-12-36" pos="punct" morph="none" start_char="2310" end_char="2311">»,</TOKEN>
<TOKEN id="token-12-37" pos="word" morph="none" start_char="2313" end_char="2314">de</TOKEN>
<TOKEN id="token-12-38" pos="word" morph="none" start_char="2316" end_char="2322">acuerdo</TOKEN>
<TOKEN id="token-12-39" pos="word" morph="none" start_char="2324" end_char="2326">con</TOKEN>
<TOKEN id="token-12-40" pos="word" morph="none" start_char="2328" end_char="2330">los</TOKEN>
<TOKEN id="token-12-41" pos="word" morph="none" start_char="2332" end_char="2345">investigadores</TOKEN>
<TOKEN id="token-12-42" pos="punct" morph="none" start_char="2346" end_char="2346">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="2349" end_char="2571">
<ORIGINAL_TEXT>Los expertos manifestaron sentirse «aliviados» de comprobar que el virus no es transmisible a los seres humanos, después de examinar a los trabajadores que habían entrado en contacto con los cerdos contagiados en Guangdong.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="2349" end_char="2351">Los</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="2353" end_char="2360">expertos</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="2362" end_char="2373">manifestaron</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="2375" end_char="2382">sentirse</TOKEN>
<TOKEN id="token-13-4" pos="punct" morph="none" start_char="2384" end_char="2384">«</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="2385" end_char="2393">aliviados</TOKEN>
<TOKEN id="token-13-6" pos="punct" morph="none" start_char="2394" end_char="2394">»</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="2396" end_char="2397">de</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="2399" end_char="2407">comprobar</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="2409" end_char="2411">que</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="2413" end_char="2414">el</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="2416" end_char="2420">virus</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="2422" end_char="2423">no</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="2425" end_char="2426">es</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="2428" end_char="2439">transmisible</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="2441" end_char="2441">a</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="2443" end_char="2445">los</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="2447" end_char="2451">seres</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="2453" end_char="2459">humanos</TOKEN>
<TOKEN id="token-13-19" pos="punct" morph="none" start_char="2460" end_char="2460">,</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="2462" end_char="2468">después</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="2470" end_char="2471">de</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="2473" end_char="2480">examinar</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="2482" end_char="2482">a</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="2484" end_char="2486">los</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="2488" end_char="2499">trabajadores</TOKEN>
<TOKEN id="token-13-26" pos="word" morph="none" start_char="2501" end_char="2503">que</TOKEN>
<TOKEN id="token-13-27" pos="word" morph="none" start_char="2505" end_char="2510">habían</TOKEN>
<TOKEN id="token-13-28" pos="word" morph="none" start_char="2512" end_char="2518">entrado</TOKEN>
<TOKEN id="token-13-29" pos="word" morph="none" start_char="2520" end_char="2521">en</TOKEN>
<TOKEN id="token-13-30" pos="word" morph="none" start_char="2523" end_char="2530">contacto</TOKEN>
<TOKEN id="token-13-31" pos="word" morph="none" start_char="2532" end_char="2534">con</TOKEN>
<TOKEN id="token-13-32" pos="word" morph="none" start_char="2536" end_char="2538">los</TOKEN>
<TOKEN id="token-13-33" pos="word" morph="none" start_char="2540" end_char="2545">cerdos</TOKEN>
<TOKEN id="token-13-34" pos="word" morph="none" start_char="2547" end_char="2557">contagiados</TOKEN>
<TOKEN id="token-13-35" pos="word" morph="none" start_char="2559" end_char="2560">en</TOKEN>
<TOKEN id="token-13-36" pos="word" morph="none" start_char="2562" end_char="2570">Guangdong</TOKEN>
<TOKEN id="token-13-37" pos="punct" morph="none" start_char="2571" end_char="2571">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="2574" end_char="2657">
<ORIGINAL_TEXT>«Muchas enfermedades infecciosas en los humanos, como el SARS, son de origen animal.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="punct" morph="none" start_char="2574" end_char="2574">«</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="2575" end_char="2580">Muchas</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="2582" end_char="2593">enfermedades</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="2595" end_char="2605">infecciosas</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="2607" end_char="2608">en</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="2610" end_char="2612">los</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="2614" end_char="2620">humanos</TOKEN>
<TOKEN id="token-14-7" pos="punct" morph="none" start_char="2621" end_char="2621">,</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="2623" end_char="2626">como</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="2628" end_char="2629">el</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="2631" end_char="2634">SARS</TOKEN>
<TOKEN id="token-14-11" pos="punct" morph="none" start_char="2635" end_char="2635">,</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="2637" end_char="2639">son</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="2641" end_char="2642">de</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="2644" end_char="2649">origen</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="2651" end_char="2656">animal</TOKEN>
<TOKEN id="token-14-16" pos="punct" morph="none" start_char="2657" end_char="2657">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="2659" end_char="2925">
<ORIGINAL_TEXT>Es posible que en el futuro el SADS se transmita de los murciélagos a los animales domésticos y, luego, de estos a los seres humanos», advirtió Ma Jingyun, investigador de la Universidad Agrícola del Sur de China, y uno de los coautores del artículo de investigación.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="2659" end_char="2660">Es</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="2662" end_char="2668">posible</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="2670" end_char="2672">que</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="2674" end_char="2675">en</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="2677" end_char="2678">el</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="2680" end_char="2685">futuro</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="2687" end_char="2688">el</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="2690" end_char="2693">SADS</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="2695" end_char="2696">se</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="2698" end_char="2706">transmita</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="2708" end_char="2709">de</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="2711" end_char="2713">los</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="2715" end_char="2725">murciélagos</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="2727" end_char="2727">a</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="2729" end_char="2731">los</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="2733" end_char="2740">animales</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="2742" end_char="2751">domésticos</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="2753" end_char="2753">y</TOKEN>
<TOKEN id="token-15-18" pos="punct" morph="none" start_char="2754" end_char="2754">,</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="2756" end_char="2760">luego</TOKEN>
<TOKEN id="token-15-20" pos="punct" morph="none" start_char="2761" end_char="2761">,</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="2763" end_char="2764">de</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="2766" end_char="2770">estos</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="2772" end_char="2772">a</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="2774" end_char="2776">los</TOKEN>
<TOKEN id="token-15-25" pos="word" morph="none" start_char="2778" end_char="2782">seres</TOKEN>
<TOKEN id="token-15-26" pos="word" morph="none" start_char="2784" end_char="2790">humanos</TOKEN>
<TOKEN id="token-15-27" pos="punct" morph="none" start_char="2791" end_char="2792">»,</TOKEN>
<TOKEN id="token-15-28" pos="word" morph="none" start_char="2794" end_char="2801">advirtió</TOKEN>
<TOKEN id="token-15-29" pos="word" morph="none" start_char="2803" end_char="2804">Ma</TOKEN>
<TOKEN id="token-15-30" pos="word" morph="none" start_char="2806" end_char="2812">Jingyun</TOKEN>
<TOKEN id="token-15-31" pos="punct" morph="none" start_char="2813" end_char="2813">,</TOKEN>
<TOKEN id="token-15-32" pos="word" morph="none" start_char="2815" end_char="2826">investigador</TOKEN>
<TOKEN id="token-15-33" pos="word" morph="none" start_char="2828" end_char="2829">de</TOKEN>
<TOKEN id="token-15-34" pos="word" morph="none" start_char="2831" end_char="2832">la</TOKEN>
<TOKEN id="token-15-35" pos="word" morph="none" start_char="2834" end_char="2844">Universidad</TOKEN>
<TOKEN id="token-15-36" pos="word" morph="none" start_char="2846" end_char="2853">Agrícola</TOKEN>
<TOKEN id="token-15-37" pos="word" morph="none" start_char="2855" end_char="2857">del</TOKEN>
<TOKEN id="token-15-38" pos="word" morph="none" start_char="2859" end_char="2861">Sur</TOKEN>
<TOKEN id="token-15-39" pos="word" morph="none" start_char="2863" end_char="2864">de</TOKEN>
<TOKEN id="token-15-40" pos="word" morph="none" start_char="2866" end_char="2870">China</TOKEN>
<TOKEN id="token-15-41" pos="punct" morph="none" start_char="2871" end_char="2871">,</TOKEN>
<TOKEN id="token-15-42" pos="word" morph="none" start_char="2873" end_char="2873">y</TOKEN>
<TOKEN id="token-15-43" pos="word" morph="none" start_char="2875" end_char="2877">uno</TOKEN>
<TOKEN id="token-15-44" pos="word" morph="none" start_char="2879" end_char="2880">de</TOKEN>
<TOKEN id="token-15-45" pos="word" morph="none" start_char="2882" end_char="2884">los</TOKEN>
<TOKEN id="token-15-46" pos="word" morph="none" start_char="2886" end_char="2894">coautores</TOKEN>
<TOKEN id="token-15-47" pos="word" morph="none" start_char="2896" end_char="2898">del</TOKEN>
<TOKEN id="token-15-48" pos="word" morph="none" start_char="2900" end_char="2907">artículo</TOKEN>
<TOKEN id="token-15-49" pos="word" morph="none" start_char="2909" end_char="2910">de</TOKEN>
<TOKEN id="token-15-50" pos="word" morph="none" start_char="2912" end_char="2924">investigación</TOKEN>
<TOKEN id="token-15-51" pos="punct" morph="none" start_char="2925" end_char="2925">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="2928" end_char="3212">
<ORIGINAL_TEXT>El trabajo fue una colaboración entre científicos de EcoHealth Alliance, Duke-NUS Medical School, Wuhan Institute of Virology y otras organizaciones, y fue financiado por el Instituto Nacional de Alergias y Enfermedades Infecciosas, un componente de los Institutos Nacionales de Salud.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="2928" end_char="2929">El</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="2931" end_char="2937">trabajo</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="2939" end_char="2941">fue</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="2943" end_char="2945">una</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="2947" end_char="2958">colaboración</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="2960" end_char="2964">entre</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="2966" end_char="2976">científicos</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="2978" end_char="2979">de</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="2981" end_char="2989">EcoHealth</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="2991" end_char="2998">Alliance</TOKEN>
<TOKEN id="token-16-10" pos="punct" morph="none" start_char="2999" end_char="2999">,</TOKEN>
<TOKEN id="token-16-11" pos="unknown" morph="none" start_char="3001" end_char="3008">Duke-NUS</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="3010" end_char="3016">Medical</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="3018" end_char="3023">School</TOKEN>
<TOKEN id="token-16-14" pos="punct" morph="none" start_char="3024" end_char="3024">,</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="3026" end_char="3030">Wuhan</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="3032" end_char="3040">Institute</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="3042" end_char="3043">of</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="3045" end_char="3052">Virology</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="3054" end_char="3054">y</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="3056" end_char="3060">otras</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="3062" end_char="3075">organizaciones</TOKEN>
<TOKEN id="token-16-22" pos="punct" morph="none" start_char="3076" end_char="3076">,</TOKEN>
<TOKEN id="token-16-23" pos="word" morph="none" start_char="3078" end_char="3078">y</TOKEN>
<TOKEN id="token-16-24" pos="word" morph="none" start_char="3080" end_char="3082">fue</TOKEN>
<TOKEN id="token-16-25" pos="word" morph="none" start_char="3084" end_char="3093">financiado</TOKEN>
<TOKEN id="token-16-26" pos="word" morph="none" start_char="3095" end_char="3097">por</TOKEN>
<TOKEN id="token-16-27" pos="word" morph="none" start_char="3099" end_char="3100">el</TOKEN>
<TOKEN id="token-16-28" pos="word" morph="none" start_char="3102" end_char="3110">Instituto</TOKEN>
<TOKEN id="token-16-29" pos="word" morph="none" start_char="3112" end_char="3119">Nacional</TOKEN>
<TOKEN id="token-16-30" pos="word" morph="none" start_char="3121" end_char="3122">de</TOKEN>
<TOKEN id="token-16-31" pos="word" morph="none" start_char="3124" end_char="3131">Alergias</TOKEN>
<TOKEN id="token-16-32" pos="word" morph="none" start_char="3133" end_char="3133">y</TOKEN>
<TOKEN id="token-16-33" pos="word" morph="none" start_char="3135" end_char="3146">Enfermedades</TOKEN>
<TOKEN id="token-16-34" pos="word" morph="none" start_char="3148" end_char="3158">Infecciosas</TOKEN>
<TOKEN id="token-16-35" pos="punct" morph="none" start_char="3159" end_char="3159">,</TOKEN>
<TOKEN id="token-16-36" pos="word" morph="none" start_char="3161" end_char="3162">un</TOKEN>
<TOKEN id="token-16-37" pos="word" morph="none" start_char="3164" end_char="3173">componente</TOKEN>
<TOKEN id="token-16-38" pos="word" morph="none" start_char="3175" end_char="3176">de</TOKEN>
<TOKEN id="token-16-39" pos="word" morph="none" start_char="3178" end_char="3180">los</TOKEN>
<TOKEN id="token-16-40" pos="word" morph="none" start_char="3182" end_char="3191">Institutos</TOKEN>
<TOKEN id="token-16-41" pos="word" morph="none" start_char="3193" end_char="3202">Nacionales</TOKEN>
<TOKEN id="token-16-42" pos="word" morph="none" start_char="3204" end_char="3205">de</TOKEN>
<TOKEN id="token-16-43" pos="word" morph="none" start_char="3207" end_char="3211">Salud</TOKEN>
<TOKEN id="token-16-44" pos="punct" morph="none" start_char="3212" end_char="3212">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="3215" end_char="3511">
<ORIGINAL_TEXT>Por consiguiente, la noticia ya no es tanto la conspiración en sí misma, sino que «alguien» ha filtrado esos documentos para que no quede ninguna duda de que nos hallamos ante una pandemia creada por el hombre, confirmando así los argumentos defendidos por militares franceses hace sólo unos días.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="3215" end_char="3217">Por</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="3219" end_char="3230">consiguiente</TOKEN>
<TOKEN id="token-17-2" pos="punct" morph="none" start_char="3231" end_char="3231">,</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="3233" end_char="3234">la</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="3236" end_char="3242">noticia</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="3244" end_char="3245">ya</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="3247" end_char="3248">no</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="3250" end_char="3251">es</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="3253" end_char="3257">tanto</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="3259" end_char="3260">la</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="3262" end_char="3273">conspiración</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="3275" end_char="3276">en</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="3278" end_char="3279">sí</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="3281" end_char="3285">misma</TOKEN>
<TOKEN id="token-17-14" pos="punct" morph="none" start_char="3286" end_char="3286">,</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="3288" end_char="3291">sino</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="3293" end_char="3295">que</TOKEN>
<TOKEN id="token-17-17" pos="punct" morph="none" start_char="3297" end_char="3297">«</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="3298" end_char="3304">alguien</TOKEN>
<TOKEN id="token-17-19" pos="punct" morph="none" start_char="3305" end_char="3305">»</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="3307" end_char="3308">ha</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="3310" end_char="3317">filtrado</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="3319" end_char="3322">esos</TOKEN>
<TOKEN id="token-17-23" pos="word" morph="none" start_char="3324" end_char="3333">documentos</TOKEN>
<TOKEN id="token-17-24" pos="word" morph="none" start_char="3335" end_char="3338">para</TOKEN>
<TOKEN id="token-17-25" pos="word" morph="none" start_char="3340" end_char="3342">que</TOKEN>
<TOKEN id="token-17-26" pos="word" morph="none" start_char="3344" end_char="3345">no</TOKEN>
<TOKEN id="token-17-27" pos="word" morph="none" start_char="3347" end_char="3351">quede</TOKEN>
<TOKEN id="token-17-28" pos="word" morph="none" start_char="3353" end_char="3359">ninguna</TOKEN>
<TOKEN id="token-17-29" pos="word" morph="none" start_char="3361" end_char="3364">duda</TOKEN>
<TOKEN id="token-17-30" pos="word" morph="none" start_char="3366" end_char="3367">de</TOKEN>
<TOKEN id="token-17-31" pos="word" morph="none" start_char="3369" end_char="3371">que</TOKEN>
<TOKEN id="token-17-32" pos="word" morph="none" start_char="3373" end_char="3375">nos</TOKEN>
<TOKEN id="token-17-33" pos="word" morph="none" start_char="3377" end_char="3384">hallamos</TOKEN>
<TOKEN id="token-17-34" pos="word" morph="none" start_char="3386" end_char="3389">ante</TOKEN>
<TOKEN id="token-17-35" pos="word" morph="none" start_char="3391" end_char="3393">una</TOKEN>
<TOKEN id="token-17-36" pos="word" morph="none" start_char="3395" end_char="3402">pandemia</TOKEN>
<TOKEN id="token-17-37" pos="word" morph="none" start_char="3404" end_char="3409">creada</TOKEN>
<TOKEN id="token-17-38" pos="word" morph="none" start_char="3411" end_char="3413">por</TOKEN>
<TOKEN id="token-17-39" pos="word" morph="none" start_char="3415" end_char="3416">el</TOKEN>
<TOKEN id="token-17-40" pos="word" morph="none" start_char="3418" end_char="3423">hombre</TOKEN>
<TOKEN id="token-17-41" pos="punct" morph="none" start_char="3424" end_char="3424">,</TOKEN>
<TOKEN id="token-17-42" pos="word" morph="none" start_char="3426" end_char="3436">confirmando</TOKEN>
<TOKEN id="token-17-43" pos="word" morph="none" start_char="3438" end_char="3440">así</TOKEN>
<TOKEN id="token-17-44" pos="word" morph="none" start_char="3442" end_char="3444">los</TOKEN>
<TOKEN id="token-17-45" pos="word" morph="none" start_char="3446" end_char="3455">argumentos</TOKEN>
<TOKEN id="token-17-46" pos="word" morph="none" start_char="3457" end_char="3466">defendidos</TOKEN>
<TOKEN id="token-17-47" pos="word" morph="none" start_char="3468" end_char="3470">por</TOKEN>
<TOKEN id="token-17-48" pos="word" morph="none" start_char="3472" end_char="3480">militares</TOKEN>
<TOKEN id="token-17-49" pos="word" morph="none" start_char="3482" end_char="3490">franceses</TOKEN>
<TOKEN id="token-17-50" pos="word" morph="none" start_char="3492" end_char="3495">hace</TOKEN>
<TOKEN id="token-17-51" pos="word" morph="none" start_char="3497" end_char="3500">sólo</TOKEN>
<TOKEN id="token-17-52" pos="word" morph="none" start_char="3502" end_char="3505">unos</TOKEN>
<TOKEN id="token-17-53" pos="word" morph="none" start_char="3507" end_char="3510">días</TOKEN>
<TOKEN id="token-17-54" pos="punct" morph="none" start_char="3511" end_char="3511">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
