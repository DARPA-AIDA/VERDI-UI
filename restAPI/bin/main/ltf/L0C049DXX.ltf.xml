<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="eng">
<DOC id="L0C049DXX" lang="eng" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="340" raw_text_md5="727ec6b42ebd1728ecf3a2e51a2b6300">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="79">
<ORIGINAL_TEXT>Delhi hospital says it successfully cured COVID-19 patient using plasma therapy</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="5">Delhi</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="7" end_char="14">hospital</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="16" end_char="19">says</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="21" end_char="22">it</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="24" end_char="35">successfully</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="37" end_char="41">cured</TOKEN>
<TOKEN id="token-0-6" pos="unknown" morph="none" start_char="43" end_char="50">COVID-19</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="52" end_char="58">patient</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="60" end_char="64">using</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="66" end_char="71">plasma</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="73" end_char="79">therapy</TOKEN>
</SEG>
<SEG id="segment-1" start_char="84" end_char="241">
<ORIGINAL_TEXT>The patient was administered fresh plasma as a treatment modality as a side-line to standard treatment protocols on the night of April 14, the statement said.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="84" end_char="86">The</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="88" end_char="94">patient</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="96" end_char="98">was</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="100" end_char="111">administered</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="113" end_char="117">fresh</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="119" end_char="124">plasma</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="126" end_char="127">as</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="129" end_char="129">a</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="131" end_char="139">treatment</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="141" end_char="148">modality</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="150" end_char="151">as</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="153" end_char="153">a</TOKEN>
<TOKEN id="token-1-12" pos="unknown" morph="none" start_char="155" end_char="163">side-line</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="165" end_char="166">to</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="168" end_char="175">standard</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="177" end_char="185">treatment</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="187" end_char="195">protocols</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="197" end_char="198">on</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="200" end_char="202">the</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="204" end_char="208">night</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="210" end_char="211">of</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="213" end_char="217">April</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="219" end_char="220">14</TOKEN>
<TOKEN id="token-1-23" pos="punct" morph="none" start_char="221" end_char="221">,</TOKEN>
<TOKEN id="token-1-24" pos="word" morph="none" start_char="223" end_char="225">the</TOKEN>
<TOKEN id="token-1-25" pos="word" morph="none" start_char="227" end_char="235">statement</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="237" end_char="240">said</TOKEN>
<TOKEN id="token-1-27" pos="punct" morph="none" start_char="241" end_char="241">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="245" end_char="336">
<ORIGINAL_TEXT>'We can say that plasma therapy could have worked as a catalyst in speeding up his recovery'</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="punct" morph="none" start_char="245" end_char="245">'</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="246" end_char="247">We</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="249" end_char="251">can</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="253" end_char="255">say</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="257" end_char="260">that</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="262" end_char="267">plasma</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="269" end_char="275">therapy</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="277" end_char="281">could</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="283" end_char="286">have</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="288" end_char="293">worked</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="295" end_char="296">as</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="298" end_char="298">a</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="300" end_char="307">catalyst</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="309" end_char="310">in</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="312" end_char="319">speeding</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="321" end_char="322">up</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="324" end_char="326">his</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="328" end_char="335">recovery</TOKEN>
<TOKEN id="token-2-18" pos="punct" morph="none" start_char="336" end_char="336">'</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
