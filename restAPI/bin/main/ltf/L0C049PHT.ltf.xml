<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="ukr">
<DOC id="L0C049PHT" lang="ukr" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="6792" raw_text_md5="f6fc59b5d4d0c8a1a3e7e640a25a0715">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="59">
<ORIGINAL_TEXT>Desmontando bulos: comer congelados no contagia la Covid-19</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="11">Desmontando</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="13" end_char="17">bulos</TOKEN>
<TOKEN id="token-0-2" pos="punct" morph="none" start_char="18" end_char="18">:</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="20" end_char="24">comer</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="26" end_char="35">congelados</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="37" end_char="38">no</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="40" end_char="47">contagia</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="49" end_char="50">la</TOKEN>
<TOKEN id="token-0-8" pos="unknown" morph="none" start_char="52" end_char="59">Covid-19</TOKEN>
</SEG>
<SEG id="segment-1" start_char="63" end_char="78">
<ORIGINAL_TEXT>Comida congelada</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="63" end_char="68">Comida</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="70" end_char="78">congelada</TOKEN>
</SEG>
<SEG id="segment-2" start_char="82" end_char="215">
<ORIGINAL_TEXT>La pandemia de la Covid-19 tiene a la humanidad en alerta y cualquier sospecha de un nuevo foco despierta todo tipo de especulaciones.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="82" end_char="83">La</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="85" end_char="92">pandemia</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="94" end_char="95">de</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="97" end_char="98">la</TOKEN>
<TOKEN id="token-2-4" pos="unknown" morph="none" start_char="100" end_char="107">Covid-19</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="109" end_char="113">tiene</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="115" end_char="115">a</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="117" end_char="118">la</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="120" end_char="128">humanidad</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="130" end_char="131">en</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="133" end_char="138">alerta</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="140" end_char="140">y</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="142" end_char="150">cualquier</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="152" end_char="159">sospecha</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="161" end_char="162">de</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="164" end_char="165">un</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="167" end_char="171">nuevo</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="173" end_char="176">foco</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="178" end_char="186">despierta</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="188" end_char="191">todo</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="193" end_char="196">tipo</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="198" end_char="199">de</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="201" end_char="214">especulaciones</TOKEN>
<TOKEN id="token-2-23" pos="punct" morph="none" start_char="215" end_char="215">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="217" end_char="246">
<ORIGINAL_TEXT>Y alarmas a menudo infundadas.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="217" end_char="217">Y</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="219" end_char="225">alarmas</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="227" end_char="227">a</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="229" end_char="234">menudo</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="236" end_char="245">infundadas</TOKEN>
<TOKEN id="token-3-5" pos="punct" morph="none" start_char="246" end_char="246">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="249" end_char="458">
<ORIGINAL_TEXT>Como probablemente sea la que partió hace unas semanas de Nueva Zelanda y China, donde la presencia de nuevos casos después de varios meses sin ninguno, creó una gran preocupación en las autoridades sanitarias.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="249" end_char="252">Como</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="254" end_char="266">probablemente</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="268" end_char="270">sea</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="272" end_char="273">la</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="275" end_char="277">que</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="279" end_char="284">partió</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="286" end_char="289">hace</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="291" end_char="294">unas</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="296" end_char="302">semanas</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="304" end_char="305">de</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="307" end_char="311">Nueva</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="313" end_char="319">Zelanda</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="321" end_char="321">y</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="323" end_char="327">China</TOKEN>
<TOKEN id="token-4-14" pos="punct" morph="none" start_char="328" end_char="328">,</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="330" end_char="334">donde</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="336" end_char="337">la</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="339" end_char="347">presencia</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="349" end_char="350">de</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="352" end_char="357">nuevos</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="359" end_char="363">casos</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="365" end_char="371">después</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="373" end_char="374">de</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="376" end_char="381">varios</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="383" end_char="387">meses</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="389" end_char="391">sin</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="393" end_char="399">ninguno</TOKEN>
<TOKEN id="token-4-27" pos="punct" morph="none" start_char="400" end_char="400">,</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="402" end_char="405">creó</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="407" end_char="409">una</TOKEN>
<TOKEN id="token-4-30" pos="word" morph="none" start_char="411" end_char="414">gran</TOKEN>
<TOKEN id="token-4-31" pos="word" morph="none" start_char="416" end_char="427">preocupación</TOKEN>
<TOKEN id="token-4-32" pos="word" morph="none" start_char="429" end_char="430">en</TOKEN>
<TOKEN id="token-4-33" pos="word" morph="none" start_char="432" end_char="434">las</TOKEN>
<TOKEN id="token-4-34" pos="word" morph="none" start_char="436" end_char="446">autoridades</TOKEN>
<TOKEN id="token-4-35" pos="word" morph="none" start_char="448" end_char="457">sanitarias</TOKEN>
<TOKEN id="token-4-36" pos="punct" morph="none" start_char="458" end_char="458">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="461" end_char="480">
<ORIGINAL_TEXT>Camarones congelados</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="461" end_char="469">Camarones</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="471" end_char="480">congelados</TOKEN>
</SEG>
<SEG id="segment-6" start_char="484" end_char="775">
<ORIGINAL_TEXT>"En Nueva Zelanda en concreto llevaban cien días sin ningún positivo nuevo y se puso sobre la mesa la hipótesis de que el virus hubiera llegado desde algún otro país a través de comida importada", explica Miguel Ángel Lurueña, doctor en Ciencia y Tecnología de los Alimentos, y autor del blog</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="punct" morph="none" start_char="484" end_char="484">"</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="485" end_char="486">En</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="488" end_char="492">Nueva</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="494" end_char="500">Zelanda</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="502" end_char="503">en</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="505" end_char="512">concreto</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="514" end_char="521">llevaban</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="523" end_char="526">cien</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="528" end_char="531">días</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="533" end_char="535">sin</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="537" end_char="542">ningún</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="544" end_char="551">positivo</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="553" end_char="557">nuevo</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="559" end_char="559">y</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="561" end_char="562">se</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="564" end_char="567">puso</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="569" end_char="573">sobre</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="575" end_char="576">la</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="578" end_char="581">mesa</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="583" end_char="584">la</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="586" end_char="594">hipótesis</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="596" end_char="597">de</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="599" end_char="601">que</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="603" end_char="604">el</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="606" end_char="610">virus</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="612" end_char="618">hubiera</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="620" end_char="626">llegado</TOKEN>
<TOKEN id="token-6-27" pos="word" morph="none" start_char="628" end_char="632">desde</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="634" end_char="638">algún</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="640" end_char="643">otro</TOKEN>
<TOKEN id="token-6-30" pos="word" morph="none" start_char="645" end_char="648">país</TOKEN>
<TOKEN id="token-6-31" pos="word" morph="none" start_char="650" end_char="650">a</TOKEN>
<TOKEN id="token-6-32" pos="word" morph="none" start_char="652" end_char="657">través</TOKEN>
<TOKEN id="token-6-33" pos="word" morph="none" start_char="659" end_char="660">de</TOKEN>
<TOKEN id="token-6-34" pos="word" morph="none" start_char="662" end_char="667">comida</TOKEN>
<TOKEN id="token-6-35" pos="word" morph="none" start_char="669" end_char="677">importada</TOKEN>
<TOKEN id="token-6-36" pos="punct" morph="none" start_char="678" end_char="679">",</TOKEN>
<TOKEN id="token-6-37" pos="word" morph="none" start_char="681" end_char="687">explica</TOKEN>
<TOKEN id="token-6-38" pos="word" morph="none" start_char="689" end_char="694">Miguel</TOKEN>
<TOKEN id="token-6-39" pos="word" morph="none" start_char="696" end_char="700">Ángel</TOKEN>
<TOKEN id="token-6-40" pos="word" morph="none" start_char="702" end_char="708">Lurueña</TOKEN>
<TOKEN id="token-6-41" pos="punct" morph="none" start_char="709" end_char="709">,</TOKEN>
<TOKEN id="token-6-42" pos="word" morph="none" start_char="711" end_char="716">doctor</TOKEN>
<TOKEN id="token-6-43" pos="word" morph="none" start_char="718" end_char="719">en</TOKEN>
<TOKEN id="token-6-44" pos="word" morph="none" start_char="721" end_char="727">Ciencia</TOKEN>
<TOKEN id="token-6-45" pos="word" morph="none" start_char="729" end_char="729">y</TOKEN>
<TOKEN id="token-6-46" pos="word" morph="none" start_char="731" end_char="740">Tecnología</TOKEN>
<TOKEN id="token-6-47" pos="word" morph="none" start_char="742" end_char="743">de</TOKEN>
<TOKEN id="token-6-48" pos="word" morph="none" start_char="745" end_char="747">los</TOKEN>
<TOKEN id="token-6-49" pos="word" morph="none" start_char="749" end_char="757">Alimentos</TOKEN>
<TOKEN id="token-6-50" pos="punct" morph="none" start_char="758" end_char="758">,</TOKEN>
<TOKEN id="token-6-51" pos="word" morph="none" start_char="760" end_char="760">y</TOKEN>
<TOKEN id="token-6-52" pos="word" morph="none" start_char="762" end_char="766">autor</TOKEN>
<TOKEN id="token-6-53" pos="word" morph="none" start_char="768" end_char="770">del</TOKEN>
<TOKEN id="token-6-54" pos="word" morph="none" start_char="772" end_char="775">blog</TOKEN>
</SEG>
<SEG id="segment-7" start_char="778" end_char="797">
<ORIGINAL_TEXT>gominolasdepetroleo.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="778" end_char="796">gominolasdepetroleo</TOKEN>
<TOKEN id="token-7-1" pos="punct" morph="none" start_char="797" end_char="797">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="801" end_char="994">
<ORIGINAL_TEXT>Por ese motivo se intensificaron los análisis de alimentos congelados procedentes de otros países y se detectaron restos de coronavirus en alitas de pollo llegadas de Brasil y gambas de Ecuador.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="801" end_char="803">Por</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="805" end_char="807">ese</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="809" end_char="814">motivo</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="816" end_char="817">se</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="819" end_char="832">intensificaron</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="834" end_char="836">los</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="838" end_char="845">análisis</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="847" end_char="848">de</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="850" end_char="858">alimentos</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="860" end_char="869">congelados</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="871" end_char="881">procedentes</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="883" end_char="884">de</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="886" end_char="890">otros</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="892" end_char="897">países</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="899" end_char="899">y</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="901" end_char="902">se</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="904" end_char="913">detectaron</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="915" end_char="920">restos</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="922" end_char="923">de</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="925" end_char="935">coronavirus</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="937" end_char="938">en</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="940" end_char="945">alitas</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="947" end_char="948">de</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="950" end_char="954">pollo</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="956" end_char="963">llegadas</TOKEN>
<TOKEN id="token-8-25" pos="word" morph="none" start_char="965" end_char="966">de</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="968" end_char="973">Brasil</TOKEN>
<TOKEN id="token-8-27" pos="word" morph="none" start_char="975" end_char="975">y</TOKEN>
<TOKEN id="token-8-28" pos="word" morph="none" start_char="977" end_char="982">gambas</TOKEN>
<TOKEN id="token-8-29" pos="word" morph="none" start_char="984" end_char="985">de</TOKEN>
<TOKEN id="token-8-30" pos="word" morph="none" start_char="987" end_char="993">Ecuador</TOKEN>
<TOKEN id="token-8-31" pos="punct" morph="none" start_char="994" end_char="994">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="997" end_char="1089">
<ORIGINAL_TEXT>Que se tratara sólo de restos y no los virus completos es la clave del asunto, según Lurueña.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="997" end_char="999">Que</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1001" end_char="1002">se</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1004" end_char="1010">tratara</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1012" end_char="1015">sólo</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1017" end_char="1018">de</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1020" end_char="1025">restos</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1027" end_char="1027">y</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1029" end_char="1030">no</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1032" end_char="1034">los</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1036" end_char="1040">virus</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1042" end_char="1050">completos</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1052" end_char="1053">es</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1055" end_char="1056">la</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1058" end_char="1062">clave</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1064" end_char="1066">del</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1068" end_char="1073">asunto</TOKEN>
<TOKEN id="token-9-16" pos="punct" morph="none" start_char="1074" end_char="1074">,</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1076" end_char="1080">según</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1082" end_char="1088">Lurueña</TOKEN>
<TOKEN id="token-9-19" pos="punct" morph="none" start_char="1089" end_char="1089">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1092" end_char="1280">
<ORIGINAL_TEXT>"El virus, comenta, sólo puede infectar si está completo, y en los casos analizados lo que se encontró fue RNA (ácido ribonucleico) procedente de la parte interna, nunca un virus completo".</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="punct" morph="none" start_char="1092" end_char="1092">"</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1093" end_char="1094">El</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1096" end_char="1100">virus</TOKEN>
<TOKEN id="token-10-3" pos="punct" morph="none" start_char="1101" end_char="1101">,</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1103" end_char="1109">comenta</TOKEN>
<TOKEN id="token-10-5" pos="punct" morph="none" start_char="1110" end_char="1110">,</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1112" end_char="1115">sólo</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1117" end_char="1121">puede</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1123" end_char="1130">infectar</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1132" end_char="1133">si</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1135" end_char="1138">está</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1140" end_char="1147">completo</TOKEN>
<TOKEN id="token-10-12" pos="punct" morph="none" start_char="1148" end_char="1148">,</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1150" end_char="1150">y</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1152" end_char="1153">en</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1155" end_char="1157">los</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1159" end_char="1163">casos</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1165" end_char="1174">analizados</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1176" end_char="1177">lo</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1179" end_char="1181">que</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1183" end_char="1184">se</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1186" end_char="1193">encontró</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1195" end_char="1197">fue</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1199" end_char="1201">RNA</TOKEN>
<TOKEN id="token-10-24" pos="punct" morph="none" start_char="1203" end_char="1203">(</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="1204" end_char="1208">ácido</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="1210" end_char="1221">ribonucleico</TOKEN>
<TOKEN id="token-10-27" pos="punct" morph="none" start_char="1222" end_char="1222">)</TOKEN>
<TOKEN id="token-10-28" pos="word" morph="none" start_char="1224" end_char="1233">procedente</TOKEN>
<TOKEN id="token-10-29" pos="word" morph="none" start_char="1235" end_char="1236">de</TOKEN>
<TOKEN id="token-10-30" pos="word" morph="none" start_char="1238" end_char="1239">la</TOKEN>
<TOKEN id="token-10-31" pos="word" morph="none" start_char="1241" end_char="1245">parte</TOKEN>
<TOKEN id="token-10-32" pos="word" morph="none" start_char="1247" end_char="1253">interna</TOKEN>
<TOKEN id="token-10-33" pos="punct" morph="none" start_char="1254" end_char="1254">,</TOKEN>
<TOKEN id="token-10-34" pos="word" morph="none" start_char="1256" end_char="1260">nunca</TOKEN>
<TOKEN id="token-10-35" pos="word" morph="none" start_char="1262" end_char="1263">un</TOKEN>
<TOKEN id="token-10-36" pos="word" morph="none" start_char="1265" end_char="1269">virus</TOKEN>
<TOKEN id="token-10-37" pos="word" morph="none" start_char="1271" end_char="1278">completo</TOKEN>
<TOKEN id="token-10-38" pos="punct" morph="none" start_char="1279" end_char="1280">".</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1283" end_char="1306">
<ORIGINAL_TEXT>Descripción de la imagen</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1283" end_char="1293">Descripción</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1295" end_char="1296">de</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1298" end_char="1299">la</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1301" end_char="1306">imagen</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1310" end_char="1371">
<ORIGINAL_TEXT>El virus "ocupa" células vivas para alimentarse y reproducirse</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1310" end_char="1311">El</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1313" end_char="1317">virus</TOKEN>
<TOKEN id="token-12-2" pos="punct" morph="none" start_char="1319" end_char="1319">"</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1320" end_char="1324">ocupa</TOKEN>
<TOKEN id="token-12-4" pos="punct" morph="none" start_char="1325" end_char="1325">"</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1327" end_char="1333">células</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1335" end_char="1339">vivas</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1341" end_char="1344">para</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1346" end_char="1356">alimentarse</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1358" end_char="1358">y</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1360" end_char="1371">reproducirse</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1374" end_char="1449">
<ORIGINAL_TEXT>Y nos pone en antecedentes para conocer un poco más sobre su comportamiento.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1374" end_char="1374">Y</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1376" end_char="1378">nos</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1380" end_char="1383">pone</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1385" end_char="1386">en</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1388" end_char="1399">antecedentes</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1401" end_char="1404">para</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1406" end_char="1412">conocer</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1414" end_char="1415">un</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1417" end_char="1420">poco</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1422" end_char="1424">más</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1426" end_char="1430">sobre</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1432" end_char="1433">su</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1435" end_char="1448">comportamiento</TOKEN>
<TOKEN id="token-13-13" pos="punct" morph="none" start_char="1449" end_char="1449">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1451" end_char="1586">
<ORIGINAL_TEXT>"Un virus, explica, es material genético sin orgánulos ni herramientas para realizar funciones vitales, como alimentarse o reproducirse.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="punct" morph="none" start_char="1451" end_char="1451">"</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1452" end_char="1453">Un</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1455" end_char="1459">virus</TOKEN>
<TOKEN id="token-14-3" pos="punct" morph="none" start_char="1460" end_char="1460">,</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1462" end_char="1468">explica</TOKEN>
<TOKEN id="token-14-5" pos="punct" morph="none" start_char="1469" end_char="1469">,</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1471" end_char="1472">es</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1474" end_char="1481">material</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1483" end_char="1490">genético</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1492" end_char="1494">sin</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1496" end_char="1504">orgánulos</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1506" end_char="1507">ni</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1509" end_char="1520">herramientas</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1522" end_char="1525">para</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="1527" end_char="1534">realizar</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1536" end_char="1544">funciones</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1546" end_char="1552">vitales</TOKEN>
<TOKEN id="token-14-17" pos="punct" morph="none" start_char="1553" end_char="1553">,</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="1555" end_char="1558">como</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="1560" end_char="1570">alimentarse</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="1572" end_char="1572">o</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="1574" end_char="1585">reproducirse</TOKEN>
<TOKEN id="token-14-22" pos="punct" morph="none" start_char="1586" end_char="1586">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1588" end_char="1740">
<ORIGINAL_TEXT>Y eso supone, añade, que siempre necesita inyectar su material genético en una célula viva que trabajará para él y realizará esas funciones en su lugar".</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1588" end_char="1588">Y</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1590" end_char="1592">eso</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1594" end_char="1599">supone</TOKEN>
<TOKEN id="token-15-3" pos="punct" morph="none" start_char="1600" end_char="1600">,</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1602" end_char="1606">añade</TOKEN>
<TOKEN id="token-15-5" pos="punct" morph="none" start_char="1607" end_char="1607">,</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1609" end_char="1611">que</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1613" end_char="1619">siempre</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1621" end_char="1628">necesita</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1630" end_char="1637">inyectar</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1639" end_char="1640">su</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1642" end_char="1649">material</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1651" end_char="1658">genético</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1660" end_char="1661">en</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1663" end_char="1665">una</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="1667" end_char="1672">célula</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="1674" end_char="1677">viva</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="1679" end_char="1681">que</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="1683" end_char="1691">trabajará</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="1693" end_char="1696">para</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="1698" end_char="1699">él</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="1701" end_char="1701">y</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="1703" end_char="1711">realizará</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="1713" end_char="1716">esas</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="1718" end_char="1726">funciones</TOKEN>
<TOKEN id="token-15-25" pos="word" morph="none" start_char="1728" end_char="1729">en</TOKEN>
<TOKEN id="token-15-26" pos="word" morph="none" start_char="1731" end_char="1732">su</TOKEN>
<TOKEN id="token-15-27" pos="word" morph="none" start_char="1734" end_char="1738">lugar</TOKEN>
<TOKEN id="token-15-28" pos="punct" morph="none" start_char="1739" end_char="1740">".</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1743" end_char="1826">
<ORIGINAL_TEXT>De ahí que no pueda reproducirse sobre los alimentos, ni congelados ni sin congelar.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1743" end_char="1744">De</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1746" end_char="1748">ahí</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1750" end_char="1752">que</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1754" end_char="1755">no</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1757" end_char="1761">pueda</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1763" end_char="1774">reproducirse</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1776" end_char="1780">sobre</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1782" end_char="1784">los</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1786" end_char="1794">alimentos</TOKEN>
<TOKEN id="token-16-9" pos="punct" morph="none" start_char="1795" end_char="1795">,</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="1797" end_char="1798">ni</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="1800" end_char="1809">congelados</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="1811" end_char="1812">ni</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="1814" end_char="1816">sin</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="1818" end_char="1825">congelar</TOKEN>
<TOKEN id="token-16-15" pos="punct" morph="none" start_char="1826" end_char="1826">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1828" end_char="2025">
<ORIGINAL_TEXT>Sí puede ocurrir, advierte, que la comida se haya contaminado porque la persona que la manipula haya expulsado algún virus sobre él, mediante diminutas gotas de saliva al estornudar, toser o hablar.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1828" end_char="1829">Sí</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1831" end_char="1835">puede</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="1837" end_char="1843">ocurrir</TOKEN>
<TOKEN id="token-17-3" pos="punct" morph="none" start_char="1844" end_char="1844">,</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="1846" end_char="1853">advierte</TOKEN>
<TOKEN id="token-17-5" pos="punct" morph="none" start_char="1854" end_char="1854">,</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="1856" end_char="1858">que</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="1860" end_char="1861">la</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="1863" end_char="1868">comida</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="1870" end_char="1871">se</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="1873" end_char="1876">haya</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="1878" end_char="1888">contaminado</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="1890" end_char="1895">porque</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="1897" end_char="1898">la</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="1900" end_char="1906">persona</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="1908" end_char="1910">que</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="1912" end_char="1913">la</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="1915" end_char="1922">manipula</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="1924" end_char="1927">haya</TOKEN>
<TOKEN id="token-17-19" pos="word" morph="none" start_char="1929" end_char="1937">expulsado</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="1939" end_char="1943">algún</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="1945" end_char="1949">virus</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="1951" end_char="1955">sobre</TOKEN>
<TOKEN id="token-17-23" pos="word" morph="none" start_char="1957" end_char="1958">él</TOKEN>
<TOKEN id="token-17-24" pos="punct" morph="none" start_char="1959" end_char="1959">,</TOKEN>
<TOKEN id="token-17-25" pos="word" morph="none" start_char="1961" end_char="1968">mediante</TOKEN>
<TOKEN id="token-17-26" pos="word" morph="none" start_char="1970" end_char="1978">diminutas</TOKEN>
<TOKEN id="token-17-27" pos="word" morph="none" start_char="1980" end_char="1984">gotas</TOKEN>
<TOKEN id="token-17-28" pos="word" morph="none" start_char="1986" end_char="1987">de</TOKEN>
<TOKEN id="token-17-29" pos="word" morph="none" start_char="1989" end_char="1994">saliva</TOKEN>
<TOKEN id="token-17-30" pos="word" morph="none" start_char="1996" end_char="1997">al</TOKEN>
<TOKEN id="token-17-31" pos="word" morph="none" start_char="1999" end_char="2008">estornudar</TOKEN>
<TOKEN id="token-17-32" pos="punct" morph="none" start_char="2009" end_char="2009">,</TOKEN>
<TOKEN id="token-17-33" pos="word" morph="none" start_char="2011" end_char="2015">toser</TOKEN>
<TOKEN id="token-17-34" pos="word" morph="none" start_char="2017" end_char="2017">o</TOKEN>
<TOKEN id="token-17-35" pos="word" morph="none" start_char="2019" end_char="2024">hablar</TOKEN>
<TOKEN id="token-17-36" pos="punct" morph="none" start_char="2025" end_char="2025">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2028" end_char="2258">
<ORIGINAL_TEXT>Pero si los virus no puede crecer ni desarrollarse sobre comida, porque carece de células vivas, también es cierto que, tanto estos como las bacterias, no mueren al congelarlos, sino que se conservan, aunque tampoco se multiplican.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2028" end_char="2031">Pero</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2033" end_char="2034">si</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2036" end_char="2038">los</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2040" end_char="2044">virus</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2046" end_char="2047">no</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2049" end_char="2053">puede</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2055" end_char="2060">crecer</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2062" end_char="2063">ni</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2065" end_char="2077">desarrollarse</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="2079" end_char="2083">sobre</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="2085" end_char="2090">comida</TOKEN>
<TOKEN id="token-18-11" pos="punct" morph="none" start_char="2091" end_char="2091">,</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2093" end_char="2098">porque</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="2100" end_char="2105">carece</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="2107" end_char="2108">de</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="2110" end_char="2116">células</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="2118" end_char="2122">vivas</TOKEN>
<TOKEN id="token-18-17" pos="punct" morph="none" start_char="2123" end_char="2123">,</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="2125" end_char="2131">también</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="2133" end_char="2134">es</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="2136" end_char="2141">cierto</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="2143" end_char="2145">que</TOKEN>
<TOKEN id="token-18-22" pos="punct" morph="none" start_char="2146" end_char="2146">,</TOKEN>
<TOKEN id="token-18-23" pos="word" morph="none" start_char="2148" end_char="2152">tanto</TOKEN>
<TOKEN id="token-18-24" pos="word" morph="none" start_char="2154" end_char="2158">estos</TOKEN>
<TOKEN id="token-18-25" pos="word" morph="none" start_char="2160" end_char="2163">como</TOKEN>
<TOKEN id="token-18-26" pos="word" morph="none" start_char="2165" end_char="2167">las</TOKEN>
<TOKEN id="token-18-27" pos="word" morph="none" start_char="2169" end_char="2177">bacterias</TOKEN>
<TOKEN id="token-18-28" pos="punct" morph="none" start_char="2178" end_char="2178">,</TOKEN>
<TOKEN id="token-18-29" pos="word" morph="none" start_char="2180" end_char="2181">no</TOKEN>
<TOKEN id="token-18-30" pos="word" morph="none" start_char="2183" end_char="2188">mueren</TOKEN>
<TOKEN id="token-18-31" pos="word" morph="none" start_char="2190" end_char="2191">al</TOKEN>
<TOKEN id="token-18-32" pos="word" morph="none" start_char="2193" end_char="2203">congelarlos</TOKEN>
<TOKEN id="token-18-33" pos="punct" morph="none" start_char="2204" end_char="2204">,</TOKEN>
<TOKEN id="token-18-34" pos="word" morph="none" start_char="2206" end_char="2209">sino</TOKEN>
<TOKEN id="token-18-35" pos="word" morph="none" start_char="2211" end_char="2213">que</TOKEN>
<TOKEN id="token-18-36" pos="word" morph="none" start_char="2215" end_char="2216">se</TOKEN>
<TOKEN id="token-18-37" pos="word" morph="none" start_char="2218" end_char="2226">conservan</TOKEN>
<TOKEN id="token-18-38" pos="punct" morph="none" start_char="2227" end_char="2227">,</TOKEN>
<TOKEN id="token-18-39" pos="word" morph="none" start_char="2229" end_char="2234">aunque</TOKEN>
<TOKEN id="token-18-40" pos="word" morph="none" start_char="2236" end_char="2242">tampoco</TOKEN>
<TOKEN id="token-18-41" pos="word" morph="none" start_char="2244" end_char="2245">se</TOKEN>
<TOKEN id="token-18-42" pos="word" morph="none" start_char="2247" end_char="2257">multiplican</TOKEN>
<TOKEN id="token-18-43" pos="punct" morph="none" start_char="2258" end_char="2258">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2260" end_char="2367">
<ORIGINAL_TEXT>"Si un alimento tenía diez virus antes de congelarlo seguirá teniendo los mismos después", añade el experto.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="punct" morph="none" start_char="2260" end_char="2260">"</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2261" end_char="2262">Si</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2264" end_char="2265">un</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2267" end_char="2274">alimento</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2276" end_char="2280">tenía</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2282" end_char="2285">diez</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2287" end_char="2291">virus</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2293" end_char="2297">antes</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2299" end_char="2300">de</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="2302" end_char="2311">congelarlo</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="2313" end_char="2319">seguirá</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="2321" end_char="2328">teniendo</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="2330" end_char="2332">los</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="2334" end_char="2339">mismos</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="2341" end_char="2347">después</TOKEN>
<TOKEN id="token-19-15" pos="punct" morph="none" start_char="2348" end_char="2349">",</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="2351" end_char="2355">añade</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="2357" end_char="2358">el</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="2360" end_char="2366">experto</TOKEN>
<TOKEN id="token-19-19" pos="punct" morph="none" start_char="2367" end_char="2367">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2370" end_char="2386">
<ORIGINAL_TEXT>Pescado congelado</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2370" end_char="2376">Pescado</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2378" end_char="2386">congelado</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2390" end_char="2618">
<ORIGINAL_TEXT>"Por eso los alimentos, prosigue, pueden ser una fuente potencial de contaminación, pero no se ha podido demostrar en ningún caso que sea por comerlos, sino por tocar la comida afectada y llevarse las manos a la boca o la nariz".</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="punct" morph="none" start_char="2390" end_char="2390">"</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2391" end_char="2393">Por</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2395" end_char="2397">eso</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2399" end_char="2401">los</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2403" end_char="2411">alimentos</TOKEN>
<TOKEN id="token-21-5" pos="punct" morph="none" start_char="2412" end_char="2412">,</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2414" end_char="2421">prosigue</TOKEN>
<TOKEN id="token-21-7" pos="punct" morph="none" start_char="2422" end_char="2422">,</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="2424" end_char="2429">pueden</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="2431" end_char="2433">ser</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="2435" end_char="2437">una</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="2439" end_char="2444">fuente</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="2446" end_char="2454">potencial</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="2456" end_char="2457">de</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="2459" end_char="2471">contaminación</TOKEN>
<TOKEN id="token-21-15" pos="punct" morph="none" start_char="2472" end_char="2472">,</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="2474" end_char="2477">pero</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="2479" end_char="2480">no</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="2482" end_char="2483">se</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="2485" end_char="2486">ha</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="2488" end_char="2493">podido</TOKEN>
<TOKEN id="token-21-21" pos="word" morph="none" start_char="2495" end_char="2503">demostrar</TOKEN>
<TOKEN id="token-21-22" pos="word" morph="none" start_char="2505" end_char="2506">en</TOKEN>
<TOKEN id="token-21-23" pos="word" morph="none" start_char="2508" end_char="2513">ningún</TOKEN>
<TOKEN id="token-21-24" pos="word" morph="none" start_char="2515" end_char="2518">caso</TOKEN>
<TOKEN id="token-21-25" pos="word" morph="none" start_char="2520" end_char="2522">que</TOKEN>
<TOKEN id="token-21-26" pos="word" morph="none" start_char="2524" end_char="2526">sea</TOKEN>
<TOKEN id="token-21-27" pos="word" morph="none" start_char="2528" end_char="2530">por</TOKEN>
<TOKEN id="token-21-28" pos="word" morph="none" start_char="2532" end_char="2539">comerlos</TOKEN>
<TOKEN id="token-21-29" pos="punct" morph="none" start_char="2540" end_char="2540">,</TOKEN>
<TOKEN id="token-21-30" pos="word" morph="none" start_char="2542" end_char="2545">sino</TOKEN>
<TOKEN id="token-21-31" pos="word" morph="none" start_char="2547" end_char="2549">por</TOKEN>
<TOKEN id="token-21-32" pos="word" morph="none" start_char="2551" end_char="2555">tocar</TOKEN>
<TOKEN id="token-21-33" pos="word" morph="none" start_char="2557" end_char="2558">la</TOKEN>
<TOKEN id="token-21-34" pos="word" morph="none" start_char="2560" end_char="2565">comida</TOKEN>
<TOKEN id="token-21-35" pos="word" morph="none" start_char="2567" end_char="2574">afectada</TOKEN>
<TOKEN id="token-21-36" pos="word" morph="none" start_char="2576" end_char="2576">y</TOKEN>
<TOKEN id="token-21-37" pos="word" morph="none" start_char="2578" end_char="2585">llevarse</TOKEN>
<TOKEN id="token-21-38" pos="word" morph="none" start_char="2587" end_char="2589">las</TOKEN>
<TOKEN id="token-21-39" pos="word" morph="none" start_char="2591" end_char="2595">manos</TOKEN>
<TOKEN id="token-21-40" pos="word" morph="none" start_char="2597" end_char="2597">a</TOKEN>
<TOKEN id="token-21-41" pos="word" morph="none" start_char="2599" end_char="2600">la</TOKEN>
<TOKEN id="token-21-42" pos="word" morph="none" start_char="2602" end_char="2605">boca</TOKEN>
<TOKEN id="token-21-43" pos="word" morph="none" start_char="2607" end_char="2607">o</TOKEN>
<TOKEN id="token-21-44" pos="word" morph="none" start_char="2609" end_char="2610">la</TOKEN>
<TOKEN id="token-21-45" pos="word" morph="none" start_char="2612" end_char="2616">nariz</TOKEN>
<TOKEN id="token-21-46" pos="punct" morph="none" start_char="2617" end_char="2618">".</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2620" end_char="2713">
<ORIGINAL_TEXT>Y es seguro comerlos cocinados, porque los virus no sobreviven a temperaturas sobre 65 grados.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2620" end_char="2620">Y</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2622" end_char="2623">es</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2625" end_char="2630">seguro</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2632" end_char="2639">comerlos</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2641" end_char="2649">cocinados</TOKEN>
<TOKEN id="token-22-5" pos="punct" morph="none" start_char="2650" end_char="2650">,</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2652" end_char="2657">porque</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2659" end_char="2661">los</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="2663" end_char="2667">virus</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="2669" end_char="2670">no</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="2672" end_char="2681">sobreviven</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="2683" end_char="2683">a</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="2685" end_char="2696">temperaturas</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="2698" end_char="2702">sobre</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="2704" end_char="2705">65</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="2707" end_char="2712">grados</TOKEN>
<TOKEN id="token-22-16" pos="punct" morph="none" start_char="2713" end_char="2713">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2716" end_char="2754">
<ORIGINAL_TEXT>Experimentos de laboratorio en Singapur</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2716" end_char="2727">Experimentos</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2729" end_char="2730">de</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2732" end_char="2742">laboratorio</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2744" end_char="2745">en</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="2747" end_char="2754">Singapur</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2757" end_char="2821">
<ORIGINAL_TEXT>A este respecto se han hecho algunos experimentos de laboratorio.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="2757" end_char="2757">A</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="2759" end_char="2762">este</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="2764" end_char="2771">respecto</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="2773" end_char="2774">se</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="2776" end_char="2778">han</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="2780" end_char="2784">hecho</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="2786" end_char="2792">algunos</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="2794" end_char="2805">experimentos</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="2807" end_char="2808">de</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="2810" end_char="2820">laboratorio</TOKEN>
<TOKEN id="token-24-10" pos="punct" morph="none" start_char="2821" end_char="2821">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2823" end_char="2908">
<ORIGINAL_TEXT>Uno de los más reveladores es el llevado a cabo por científicos de Irlanda y Singapur.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="2823" end_char="2825">Uno</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="2827" end_char="2828">de</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="2830" end_char="2832">los</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="2834" end_char="2836">más</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="2838" end_char="2848">reveladores</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="2850" end_char="2851">es</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="2853" end_char="2854">el</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="2856" end_char="2862">llevado</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="2864" end_char="2864">a</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="2866" end_char="2869">cabo</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="2871" end_char="2873">por</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="2875" end_char="2885">científicos</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="2887" end_char="2888">de</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="2890" end_char="2896">Irlanda</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="2898" end_char="2898">y</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="2900" end_char="2907">Singapur</TOKEN>
<TOKEN id="token-25-16" pos="punct" morph="none" start_char="2908" end_char="2908">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="2910" end_char="3079">
<ORIGINAL_TEXT>Contaminaron con coronavirus, viables y en una cantidad capaz de infectar, piezas congeladas y refrigeradas de salmón, pollo y cerdo de un supermercado local de Singapur.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="2910" end_char="2921">Contaminaron</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="2923" end_char="2925">con</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="2927" end_char="2937">coronavirus</TOKEN>
<TOKEN id="token-26-3" pos="punct" morph="none" start_char="2938" end_char="2938">,</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="2940" end_char="2946">viables</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="2948" end_char="2948">y</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="2950" end_char="2951">en</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="2953" end_char="2955">una</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="2957" end_char="2964">cantidad</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="2966" end_char="2970">capaz</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="2972" end_char="2973">de</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="2975" end_char="2982">infectar</TOKEN>
<TOKEN id="token-26-12" pos="punct" morph="none" start_char="2983" end_char="2983">,</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="2985" end_char="2990">piezas</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="2992" end_char="3001">congeladas</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="3003" end_char="3003">y</TOKEN>
<TOKEN id="token-26-16" pos="word" morph="none" start_char="3005" end_char="3016">refrigeradas</TOKEN>
<TOKEN id="token-26-17" pos="word" morph="none" start_char="3018" end_char="3019">de</TOKEN>
<TOKEN id="token-26-18" pos="word" morph="none" start_char="3021" end_char="3026">salmón</TOKEN>
<TOKEN id="token-26-19" pos="punct" morph="none" start_char="3027" end_char="3027">,</TOKEN>
<TOKEN id="token-26-20" pos="word" morph="none" start_char="3029" end_char="3033">pollo</TOKEN>
<TOKEN id="token-26-21" pos="word" morph="none" start_char="3035" end_char="3035">y</TOKEN>
<TOKEN id="token-26-22" pos="word" morph="none" start_char="3037" end_char="3041">cerdo</TOKEN>
<TOKEN id="token-26-23" pos="word" morph="none" start_char="3043" end_char="3044">de</TOKEN>
<TOKEN id="token-26-24" pos="word" morph="none" start_char="3046" end_char="3047">un</TOKEN>
<TOKEN id="token-26-25" pos="word" morph="none" start_char="3049" end_char="3060">supermercado</TOKEN>
<TOKEN id="token-26-26" pos="word" morph="none" start_char="3062" end_char="3066">local</TOKEN>
<TOKEN id="token-26-27" pos="word" morph="none" start_char="3068" end_char="3069">de</TOKEN>
<TOKEN id="token-26-28" pos="word" morph="none" start_char="3071" end_char="3078">Singapur</TOKEN>
<TOKEN id="token-26-29" pos="punct" morph="none" start_char="3079" end_char="3079">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="3081" end_char="3241">
<ORIGINAL_TEXT>Luego los almacenaron en un frigorífico o congelador durante 21 días a temperaturas de 4, -20 y -80 grados centígrados, y fueron tomando muestras periódicamente.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="3081" end_char="3085">Luego</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="3087" end_char="3089">los</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="3091" end_char="3101">almacenaron</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="3103" end_char="3104">en</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="3106" end_char="3107">un</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="3109" end_char="3119">frigorífico</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="3121" end_char="3121">o</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="3123" end_char="3132">congelador</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="3134" end_char="3140">durante</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="3142" end_char="3143">21</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="3145" end_char="3148">días</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="3150" end_char="3150">a</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="3152" end_char="3163">temperaturas</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="3165" end_char="3166">de</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="3168" end_char="3168">4</TOKEN>
<TOKEN id="token-27-15" pos="punct" morph="none" start_char="3169" end_char="3169">,</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="3171" end_char="3173">-20</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="3175" end_char="3175">y</TOKEN>
<TOKEN id="token-27-18" pos="word" morph="none" start_char="3177" end_char="3179">-80</TOKEN>
<TOKEN id="token-27-19" pos="word" morph="none" start_char="3181" end_char="3186">grados</TOKEN>
<TOKEN id="token-27-20" pos="word" morph="none" start_char="3188" end_char="3198">centígrados</TOKEN>
<TOKEN id="token-27-21" pos="punct" morph="none" start_char="3199" end_char="3199">,</TOKEN>
<TOKEN id="token-27-22" pos="word" morph="none" start_char="3201" end_char="3201">y</TOKEN>
<TOKEN id="token-27-23" pos="word" morph="none" start_char="3203" end_char="3208">fueron</TOKEN>
<TOKEN id="token-27-24" pos="word" morph="none" start_char="3210" end_char="3216">tomando</TOKEN>
<TOKEN id="token-27-25" pos="word" morph="none" start_char="3218" end_char="3225">muestras</TOKEN>
<TOKEN id="token-27-26" pos="word" morph="none" start_char="3227" end_char="3240">periódicamente</TOKEN>
<TOKEN id="token-27-27" pos="punct" morph="none" start_char="3241" end_char="3241">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3243" end_char="3432">
<ORIGINAL_TEXT>Los investigadores comprobaron que los virus permanecían a lo largo de todo el periodo del estudio y que tenían la capacidad de infectar tanto los alimentos congelados como los refrigerados.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="3243" end_char="3245">Los</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="3247" end_char="3260">investigadores</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="3262" end_char="3272">comprobaron</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="3274" end_char="3276">que</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="3278" end_char="3280">los</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="3282" end_char="3286">virus</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="3288" end_char="3298">permanecían</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="3300" end_char="3300">a</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="3302" end_char="3303">lo</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="3305" end_char="3309">largo</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="3311" end_char="3312">de</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="3314" end_char="3317">todo</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="3319" end_char="3320">el</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="3322" end_char="3328">periodo</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="3330" end_char="3332">del</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="3334" end_char="3340">estudio</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="3342" end_char="3342">y</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="3344" end_char="3346">que</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="3348" end_char="3353">tenían</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="3355" end_char="3356">la</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="3358" end_char="3366">capacidad</TOKEN>
<TOKEN id="token-28-21" pos="word" morph="none" start_char="3368" end_char="3369">de</TOKEN>
<TOKEN id="token-28-22" pos="word" morph="none" start_char="3371" end_char="3378">infectar</TOKEN>
<TOKEN id="token-28-23" pos="word" morph="none" start_char="3380" end_char="3384">tanto</TOKEN>
<TOKEN id="token-28-24" pos="word" morph="none" start_char="3386" end_char="3388">los</TOKEN>
<TOKEN id="token-28-25" pos="word" morph="none" start_char="3390" end_char="3398">alimentos</TOKEN>
<TOKEN id="token-28-26" pos="word" morph="none" start_char="3400" end_char="3409">congelados</TOKEN>
<TOKEN id="token-28-27" pos="word" morph="none" start_char="3411" end_char="3414">como</TOKEN>
<TOKEN id="token-28-28" pos="word" morph="none" start_char="3416" end_char="3418">los</TOKEN>
<TOKEN id="token-28-29" pos="word" morph="none" start_char="3420" end_char="3431">refrigerados</TOKEN>
<TOKEN id="token-28-30" pos="punct" morph="none" start_char="3432" end_char="3432">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3434" end_char="3513">
<ORIGINAL_TEXT>Pero sólo si una persona los tocaba y se llevaba las manos a la nariz o la boca.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="3434" end_char="3437">Pero</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="3439" end_char="3442">sólo</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="3444" end_char="3445">si</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="3447" end_char="3449">una</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="3451" end_char="3457">persona</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="3459" end_char="3461">los</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="3463" end_char="3468">tocaba</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="3470" end_char="3470">y</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="3472" end_char="3473">se</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="3475" end_char="3481">llevaba</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="3483" end_char="3485">las</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="3487" end_char="3491">manos</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="3493" end_char="3493">a</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="3495" end_char="3496">la</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="3498" end_char="3502">nariz</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="3504" end_char="3504">o</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="3506" end_char="3507">la</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="3509" end_char="3512">boca</TOKEN>
<TOKEN id="token-29-18" pos="punct" morph="none" start_char="3513" end_char="3513">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3515" end_char="3550">
<ORIGINAL_TEXT>No ocurría lo mismo si se consumían.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="3515" end_char="3516">No</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="3518" end_char="3524">ocurría</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="3526" end_char="3527">lo</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="3529" end_char="3533">mismo</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="3535" end_char="3536">si</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="3538" end_char="3539">se</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="3541" end_char="3549">consumían</TOKEN>
<TOKEN id="token-30-7" pos="punct" morph="none" start_char="3550" end_char="3550">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="3553" end_char="3562">
<ORIGINAL_TEXT>Congelador</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="3553" end_char="3562">Congelador</TOKEN>
</SEG>
<SEG id="segment-32" start_char="3566" end_char="3784">
<ORIGINAL_TEXT>"Nuestro laboratorio ha demostrado que el sars coV-2 puede sobrevivir el tiempo y a las temperaturas asociadas con el transporte manipulación habituales en el comercio internacional", declararon los autores del estudio.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="punct" morph="none" start_char="3566" end_char="3566">"</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="3567" end_char="3573">Nuestro</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="3575" end_char="3585">laboratorio</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="3587" end_char="3588">ha</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="3590" end_char="3599">demostrado</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="3601" end_char="3603">que</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="3605" end_char="3606">el</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="3608" end_char="3611">sars</TOKEN>
<TOKEN id="token-32-8" pos="unknown" morph="none" start_char="3613" end_char="3617">coV-2</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="3619" end_char="3623">puede</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="3625" end_char="3634">sobrevivir</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="3636" end_char="3637">el</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="3639" end_char="3644">tiempo</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="3646" end_char="3646">y</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="3648" end_char="3648">a</TOKEN>
<TOKEN id="token-32-15" pos="word" morph="none" start_char="3650" end_char="3652">las</TOKEN>
<TOKEN id="token-32-16" pos="word" morph="none" start_char="3654" end_char="3665">temperaturas</TOKEN>
<TOKEN id="token-32-17" pos="word" morph="none" start_char="3667" end_char="3675">asociadas</TOKEN>
<TOKEN id="token-32-18" pos="word" morph="none" start_char="3677" end_char="3679">con</TOKEN>
<TOKEN id="token-32-19" pos="word" morph="none" start_char="3681" end_char="3682">el</TOKEN>
<TOKEN id="token-32-20" pos="word" morph="none" start_char="3684" end_char="3693">transporte</TOKEN>
<TOKEN id="token-32-21" pos="word" morph="none" start_char="3695" end_char="3706">manipulación</TOKEN>
<TOKEN id="token-32-22" pos="word" morph="none" start_char="3708" end_char="3717">habituales</TOKEN>
<TOKEN id="token-32-23" pos="word" morph="none" start_char="3719" end_char="3720">en</TOKEN>
<TOKEN id="token-32-24" pos="word" morph="none" start_char="3722" end_char="3723">el</TOKEN>
<TOKEN id="token-32-25" pos="word" morph="none" start_char="3725" end_char="3732">comercio</TOKEN>
<TOKEN id="token-32-26" pos="word" morph="none" start_char="3734" end_char="3746">internacional</TOKEN>
<TOKEN id="token-32-27" pos="punct" morph="none" start_char="3747" end_char="3748">",</TOKEN>
<TOKEN id="token-32-28" pos="word" morph="none" start_char="3750" end_char="3759">declararon</TOKEN>
<TOKEN id="token-32-29" pos="word" morph="none" start_char="3761" end_char="3763">los</TOKEN>
<TOKEN id="token-32-30" pos="word" morph="none" start_char="3765" end_char="3771">autores</TOKEN>
<TOKEN id="token-32-31" pos="word" morph="none" start_char="3773" end_char="3775">del</TOKEN>
<TOKEN id="token-32-32" pos="word" morph="none" start_char="3777" end_char="3783">estudio</TOKEN>
<TOKEN id="token-32-33" pos="punct" morph="none" start_char="3784" end_char="3784">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="3787" end_char="4051">
<ORIGINAL_TEXT>Aunque en este caso no se han realizado las comprobaciones posteriores de los trabajos de este tipo, ello no significa que no se hiciera con toda precisión y garantías: pero nada permite afirmar que se hayan producido infecciones masivas por tocar comida congelada.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="3787" end_char="3792">Aunque</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="3794" end_char="3795">en</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="3797" end_char="3800">este</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="3802" end_char="3805">caso</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="3807" end_char="3808">no</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="3810" end_char="3811">se</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="3813" end_char="3815">han</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="3817" end_char="3825">realizado</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="3827" end_char="3829">las</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="3831" end_char="3844">comprobaciones</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="3846" end_char="3856">posteriores</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="3858" end_char="3859">de</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="3861" end_char="3863">los</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="3865" end_char="3872">trabajos</TOKEN>
<TOKEN id="token-33-14" pos="word" morph="none" start_char="3874" end_char="3875">de</TOKEN>
<TOKEN id="token-33-15" pos="word" morph="none" start_char="3877" end_char="3880">este</TOKEN>
<TOKEN id="token-33-16" pos="word" morph="none" start_char="3882" end_char="3885">tipo</TOKEN>
<TOKEN id="token-33-17" pos="punct" morph="none" start_char="3886" end_char="3886">,</TOKEN>
<TOKEN id="token-33-18" pos="word" morph="none" start_char="3888" end_char="3891">ello</TOKEN>
<TOKEN id="token-33-19" pos="word" morph="none" start_char="3893" end_char="3894">no</TOKEN>
<TOKEN id="token-33-20" pos="word" morph="none" start_char="3896" end_char="3904">significa</TOKEN>
<TOKEN id="token-33-21" pos="word" morph="none" start_char="3906" end_char="3908">que</TOKEN>
<TOKEN id="token-33-22" pos="word" morph="none" start_char="3910" end_char="3911">no</TOKEN>
<TOKEN id="token-33-23" pos="word" morph="none" start_char="3913" end_char="3914">se</TOKEN>
<TOKEN id="token-33-24" pos="word" morph="none" start_char="3916" end_char="3922">hiciera</TOKEN>
<TOKEN id="token-33-25" pos="word" morph="none" start_char="3924" end_char="3926">con</TOKEN>
<TOKEN id="token-33-26" pos="word" morph="none" start_char="3928" end_char="3931">toda</TOKEN>
<TOKEN id="token-33-27" pos="word" morph="none" start_char="3933" end_char="3941">precisión</TOKEN>
<TOKEN id="token-33-28" pos="word" morph="none" start_char="3943" end_char="3943">y</TOKEN>
<TOKEN id="token-33-29" pos="word" morph="none" start_char="3945" end_char="3953">garantías</TOKEN>
<TOKEN id="token-33-30" pos="punct" morph="none" start_char="3954" end_char="3954">:</TOKEN>
<TOKEN id="token-33-31" pos="word" morph="none" start_char="3956" end_char="3959">pero</TOKEN>
<TOKEN id="token-33-32" pos="word" morph="none" start_char="3961" end_char="3964">nada</TOKEN>
<TOKEN id="token-33-33" pos="word" morph="none" start_char="3966" end_char="3972">permite</TOKEN>
<TOKEN id="token-33-34" pos="word" morph="none" start_char="3974" end_char="3980">afirmar</TOKEN>
<TOKEN id="token-33-35" pos="word" morph="none" start_char="3982" end_char="3984">que</TOKEN>
<TOKEN id="token-33-36" pos="word" morph="none" start_char="3986" end_char="3987">se</TOKEN>
<TOKEN id="token-33-37" pos="word" morph="none" start_char="3989" end_char="3993">hayan</TOKEN>
<TOKEN id="token-33-38" pos="word" morph="none" start_char="3995" end_char="4003">producido</TOKEN>
<TOKEN id="token-33-39" pos="word" morph="none" start_char="4005" end_char="4015">infecciones</TOKEN>
<TOKEN id="token-33-40" pos="word" morph="none" start_char="4017" end_char="4023">masivas</TOKEN>
<TOKEN id="token-33-41" pos="word" morph="none" start_char="4025" end_char="4027">por</TOKEN>
<TOKEN id="token-33-42" pos="word" morph="none" start_char="4029" end_char="4033">tocar</TOKEN>
<TOKEN id="token-33-43" pos="word" morph="none" start_char="4035" end_char="4040">comida</TOKEN>
<TOKEN id="token-33-44" pos="word" morph="none" start_char="4042" end_char="4050">congelada</TOKEN>
<TOKEN id="token-33-45" pos="punct" morph="none" start_char="4051" end_char="4051">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="4054" end_char="4249">
<ORIGINAL_TEXT>Sin embargo, aunque pueda parecer que se trata de un virus muy resistente, "en realidad es muy vulnerable, y prueba de ello es que se acaba con él con un simple lavado de manos", concluye Lurueña.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="4054" end_char="4056">Sin</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="4058" end_char="4064">embargo</TOKEN>
<TOKEN id="token-34-2" pos="punct" morph="none" start_char="4065" end_char="4065">,</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="4067" end_char="4072">aunque</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="4074" end_char="4078">pueda</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="4080" end_char="4086">parecer</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="4088" end_char="4090">que</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="4092" end_char="4093">se</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="4095" end_char="4099">trata</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="4101" end_char="4102">de</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="4104" end_char="4105">un</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="4107" end_char="4111">virus</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="4113" end_char="4115">muy</TOKEN>
<TOKEN id="token-34-13" pos="word" morph="none" start_char="4117" end_char="4126">resistente</TOKEN>
<TOKEN id="token-34-14" pos="punct" morph="none" start_char="4127" end_char="4127">,</TOKEN>
<TOKEN id="token-34-15" pos="punct" morph="none" start_char="4129" end_char="4129">"</TOKEN>
<TOKEN id="token-34-16" pos="word" morph="none" start_char="4130" end_char="4131">en</TOKEN>
<TOKEN id="token-34-17" pos="word" morph="none" start_char="4133" end_char="4140">realidad</TOKEN>
<TOKEN id="token-34-18" pos="word" morph="none" start_char="4142" end_char="4143">es</TOKEN>
<TOKEN id="token-34-19" pos="word" morph="none" start_char="4145" end_char="4147">muy</TOKEN>
<TOKEN id="token-34-20" pos="word" morph="none" start_char="4149" end_char="4158">vulnerable</TOKEN>
<TOKEN id="token-34-21" pos="punct" morph="none" start_char="4159" end_char="4159">,</TOKEN>
<TOKEN id="token-34-22" pos="word" morph="none" start_char="4161" end_char="4161">y</TOKEN>
<TOKEN id="token-34-23" pos="word" morph="none" start_char="4163" end_char="4168">prueba</TOKEN>
<TOKEN id="token-34-24" pos="word" morph="none" start_char="4170" end_char="4171">de</TOKEN>
<TOKEN id="token-34-25" pos="word" morph="none" start_char="4173" end_char="4176">ello</TOKEN>
<TOKEN id="token-34-26" pos="word" morph="none" start_char="4178" end_char="4179">es</TOKEN>
<TOKEN id="token-34-27" pos="word" morph="none" start_char="4181" end_char="4183">que</TOKEN>
<TOKEN id="token-34-28" pos="word" morph="none" start_char="4185" end_char="4186">se</TOKEN>
<TOKEN id="token-34-29" pos="word" morph="none" start_char="4188" end_char="4192">acaba</TOKEN>
<TOKEN id="token-34-30" pos="word" morph="none" start_char="4194" end_char="4196">con</TOKEN>
<TOKEN id="token-34-31" pos="word" morph="none" start_char="4198" end_char="4199">él</TOKEN>
<TOKEN id="token-34-32" pos="word" morph="none" start_char="4201" end_char="4203">con</TOKEN>
<TOKEN id="token-34-33" pos="word" morph="none" start_char="4205" end_char="4206">un</TOKEN>
<TOKEN id="token-34-34" pos="word" morph="none" start_char="4208" end_char="4213">simple</TOKEN>
<TOKEN id="token-34-35" pos="word" morph="none" start_char="4215" end_char="4220">lavado</TOKEN>
<TOKEN id="token-34-36" pos="word" morph="none" start_char="4222" end_char="4223">de</TOKEN>
<TOKEN id="token-34-37" pos="word" morph="none" start_char="4225" end_char="4229">manos</TOKEN>
<TOKEN id="token-34-38" pos="punct" morph="none" start_char="4230" end_char="4231">",</TOKEN>
<TOKEN id="token-34-39" pos="word" morph="none" start_char="4233" end_char="4240">concluye</TOKEN>
<TOKEN id="token-34-40" pos="word" morph="none" start_char="4242" end_char="4248">Lurueña</TOKEN>
<TOKEN id="token-34-41" pos="punct" morph="none" start_char="4249" end_char="4249">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="4251" end_char="4338">
<ORIGINAL_TEXT>También son muy sensibles a los rayos UV del sol y a los cambios bruscos de temperatura.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="4251" end_char="4257">También</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="4259" end_char="4261">son</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="4263" end_char="4265">muy</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="4267" end_char="4275">sensibles</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="4277" end_char="4277">a</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="4279" end_char="4281">los</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="4283" end_char="4287">rayos</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="4289" end_char="4290">UV</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="4292" end_char="4294">del</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="4296" end_char="4298">sol</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="4300" end_char="4300">y</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="4302" end_char="4302">a</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="4304" end_char="4306">los</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="4308" end_char="4314">cambios</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="4316" end_char="4322">bruscos</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="4324" end_char="4325">de</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="4327" end_char="4337">temperatura</TOKEN>
<TOKEN id="token-35-17" pos="punct" morph="none" start_char="4338" end_char="4338">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="4341" end_char="4534">
<ORIGINAL_TEXT>Para comprobar que un virus peligroso y viable persiste en un alimento o en su envoltorio los investigadores deberían aislar el microbio en un laboratorio y demostrar que es capaz de replicarse.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="4341" end_char="4344">Para</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="4346" end_char="4354">comprobar</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="4356" end_char="4358">que</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="4360" end_char="4361">un</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="4363" end_char="4367">virus</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="4369" end_char="4377">peligroso</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="4379" end_char="4379">y</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="4381" end_char="4386">viable</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="4388" end_char="4395">persiste</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="4397" end_char="4398">en</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="4400" end_char="4401">un</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="4403" end_char="4410">alimento</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="4412" end_char="4412">o</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="4414" end_char="4415">en</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="4417" end_char="4418">su</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="4420" end_char="4429">envoltorio</TOKEN>
<TOKEN id="token-36-16" pos="word" morph="none" start_char="4431" end_char="4433">los</TOKEN>
<TOKEN id="token-36-17" pos="word" morph="none" start_char="4435" end_char="4448">investigadores</TOKEN>
<TOKEN id="token-36-18" pos="word" morph="none" start_char="4450" end_char="4457">deberían</TOKEN>
<TOKEN id="token-36-19" pos="word" morph="none" start_char="4459" end_char="4464">aislar</TOKEN>
<TOKEN id="token-36-20" pos="word" morph="none" start_char="4466" end_char="4467">el</TOKEN>
<TOKEN id="token-36-21" pos="word" morph="none" start_char="4469" end_char="4476">microbio</TOKEN>
<TOKEN id="token-36-22" pos="word" morph="none" start_char="4478" end_char="4479">en</TOKEN>
<TOKEN id="token-36-23" pos="word" morph="none" start_char="4481" end_char="4482">un</TOKEN>
<TOKEN id="token-36-24" pos="word" morph="none" start_char="4484" end_char="4494">laboratorio</TOKEN>
<TOKEN id="token-36-25" pos="word" morph="none" start_char="4496" end_char="4496">y</TOKEN>
<TOKEN id="token-36-26" pos="word" morph="none" start_char="4498" end_char="4506">demostrar</TOKEN>
<TOKEN id="token-36-27" pos="word" morph="none" start_char="4508" end_char="4510">que</TOKEN>
<TOKEN id="token-36-28" pos="word" morph="none" start_char="4512" end_char="4513">es</TOKEN>
<TOKEN id="token-36-29" pos="word" morph="none" start_char="4515" end_char="4519">capaz</TOKEN>
<TOKEN id="token-36-30" pos="word" morph="none" start_char="4521" end_char="4522">de</TOKEN>
<TOKEN id="token-36-31" pos="word" morph="none" start_char="4524" end_char="4533">replicarse</TOKEN>
<TOKEN id="token-36-32" pos="punct" morph="none" start_char="4534" end_char="4534">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="4536" end_char="4622">
<ORIGINAL_TEXT>Son experimentos complicados y que de momento no entran en los protocolos de actuación.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="4536" end_char="4538">Son</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="4540" end_char="4551">experimentos</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="4553" end_char="4563">complicados</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="4565" end_char="4565">y</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="4567" end_char="4569">que</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="4571" end_char="4572">de</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="4574" end_char="4580">momento</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="4582" end_char="4583">no</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="4585" end_char="4590">entran</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="4592" end_char="4593">en</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="4595" end_char="4597">los</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="4599" end_char="4608">protocolos</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="4610" end_char="4611">de</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="4613" end_char="4621">actuación</TOKEN>
<TOKEN id="token-37-14" pos="punct" morph="none" start_char="4622" end_char="4622">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="4625" end_char="4641">
<ORIGINAL_TEXT>Brocoli congelado</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="4625" end_char="4631">Brocoli</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="4633" end_char="4641">congelado</TOKEN>
</SEG>
<SEG id="segment-39" start_char="4645" end_char="4800">
<ORIGINAL_TEXT>Está visto que esa forma de contagio es muy poco probable, y la única que se ha podido probar hasta ahora es la de persona a persona y a través del aliento.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="4645" end_char="4648">Está</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="4650" end_char="4654">visto</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="4656" end_char="4658">que</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="4660" end_char="4662">esa</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="4664" end_char="4668">forma</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="4670" end_char="4671">de</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="4673" end_char="4680">contagio</TOKEN>
<TOKEN id="token-39-7" pos="word" morph="none" start_char="4682" end_char="4683">es</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="4685" end_char="4687">muy</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="4689" end_char="4692">poco</TOKEN>
<TOKEN id="token-39-10" pos="word" morph="none" start_char="4694" end_char="4701">probable</TOKEN>
<TOKEN id="token-39-11" pos="punct" morph="none" start_char="4702" end_char="4702">,</TOKEN>
<TOKEN id="token-39-12" pos="word" morph="none" start_char="4704" end_char="4704">y</TOKEN>
<TOKEN id="token-39-13" pos="word" morph="none" start_char="4706" end_char="4707">la</TOKEN>
<TOKEN id="token-39-14" pos="word" morph="none" start_char="4709" end_char="4713">única</TOKEN>
<TOKEN id="token-39-15" pos="word" morph="none" start_char="4715" end_char="4717">que</TOKEN>
<TOKEN id="token-39-16" pos="word" morph="none" start_char="4719" end_char="4720">se</TOKEN>
<TOKEN id="token-39-17" pos="word" morph="none" start_char="4722" end_char="4723">ha</TOKEN>
<TOKEN id="token-39-18" pos="word" morph="none" start_char="4725" end_char="4730">podido</TOKEN>
<TOKEN id="token-39-19" pos="word" morph="none" start_char="4732" end_char="4737">probar</TOKEN>
<TOKEN id="token-39-20" pos="word" morph="none" start_char="4739" end_char="4743">hasta</TOKEN>
<TOKEN id="token-39-21" pos="word" morph="none" start_char="4745" end_char="4749">ahora</TOKEN>
<TOKEN id="token-39-22" pos="word" morph="none" start_char="4751" end_char="4752">es</TOKEN>
<TOKEN id="token-39-23" pos="word" morph="none" start_char="4754" end_char="4755">la</TOKEN>
<TOKEN id="token-39-24" pos="word" morph="none" start_char="4757" end_char="4758">de</TOKEN>
<TOKEN id="token-39-25" pos="word" morph="none" start_char="4760" end_char="4766">persona</TOKEN>
<TOKEN id="token-39-26" pos="word" morph="none" start_char="4768" end_char="4768">a</TOKEN>
<TOKEN id="token-39-27" pos="word" morph="none" start_char="4770" end_char="4776">persona</TOKEN>
<TOKEN id="token-39-28" pos="word" morph="none" start_char="4778" end_char="4778">y</TOKEN>
<TOKEN id="token-39-29" pos="word" morph="none" start_char="4780" end_char="4780">a</TOKEN>
<TOKEN id="token-39-30" pos="word" morph="none" start_char="4782" end_char="4787">través</TOKEN>
<TOKEN id="token-39-31" pos="word" morph="none" start_char="4789" end_char="4791">del</TOKEN>
<TOKEN id="token-39-32" pos="word" morph="none" start_char="4793" end_char="4799">aliento</TOKEN>
<TOKEN id="token-39-33" pos="punct" morph="none" start_char="4800" end_char="4800">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="4803" end_char="4860">
<ORIGINAL_TEXT>Tres horas sobre un papel, tres días encima de un plástico</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="4803" end_char="4806">Tres</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="4808" end_char="4812">horas</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="4814" end_char="4818">sobre</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="4820" end_char="4821">un</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="4823" end_char="4827">papel</TOKEN>
<TOKEN id="token-40-5" pos="punct" morph="none" start_char="4828" end_char="4828">,</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="4830" end_char="4833">tres</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="4835" end_char="4838">días</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="4840" end_char="4845">encima</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="4847" end_char="4848">de</TOKEN>
<TOKEN id="token-40-10" pos="word" morph="none" start_char="4850" end_char="4851">un</TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="4853" end_char="4860">plástico</TOKEN>
</SEG>
<SEG id="segment-41" start_char="4863" end_char="4968">
<ORIGINAL_TEXT>En definitiva se intenta transmitir a los consumidores que no hay que tener miedo de enfermar por esa vía.</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="4863" end_char="4864">En</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="4866" end_char="4875">definitiva</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="4877" end_char="4878">se</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="4880" end_char="4886">intenta</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="4888" end_char="4897">transmitir</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="4899" end_char="4899">a</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="4901" end_char="4903">los</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="4905" end_char="4916">consumidores</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="4918" end_char="4920">que</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="4922" end_char="4923">no</TOKEN>
<TOKEN id="token-41-10" pos="word" morph="none" start_char="4925" end_char="4927">hay</TOKEN>
<TOKEN id="token-41-11" pos="word" morph="none" start_char="4929" end_char="4931">que</TOKEN>
<TOKEN id="token-41-12" pos="word" morph="none" start_char="4933" end_char="4937">tener</TOKEN>
<TOKEN id="token-41-13" pos="word" morph="none" start_char="4939" end_char="4943">miedo</TOKEN>
<TOKEN id="token-41-14" pos="word" morph="none" start_char="4945" end_char="4946">de</TOKEN>
<TOKEN id="token-41-15" pos="word" morph="none" start_char="4948" end_char="4955">enfermar</TOKEN>
<TOKEN id="token-41-16" pos="word" morph="none" start_char="4957" end_char="4959">por</TOKEN>
<TOKEN id="token-41-17" pos="word" morph="none" start_char="4961" end_char="4963">esa</TOKEN>
<TOKEN id="token-41-18" pos="word" morph="none" start_char="4965" end_char="4967">vía</TOKEN>
<TOKEN id="token-41-19" pos="punct" morph="none" start_char="4968" end_char="4968">.</TOKEN>
</SEG>
<SEG id="segment-42" start_char="4970" end_char="5082">
<ORIGINAL_TEXT>Las autoridades chinas han analizado varios cientos de miles de muestras y menos de diez han resultado positivas.</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="4970" end_char="4972">Las</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="4974" end_char="4984">autoridades</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="4986" end_char="4991">chinas</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="4993" end_char="4995">han</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="4997" end_char="5005">analizado</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="5007" end_char="5012">varios</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="5014" end_char="5020">cientos</TOKEN>
<TOKEN id="token-42-7" pos="word" morph="none" start_char="5022" end_char="5023">de</TOKEN>
<TOKEN id="token-42-8" pos="word" morph="none" start_char="5025" end_char="5029">miles</TOKEN>
<TOKEN id="token-42-9" pos="word" morph="none" start_char="5031" end_char="5032">de</TOKEN>
<TOKEN id="token-42-10" pos="word" morph="none" start_char="5034" end_char="5041">muestras</TOKEN>
<TOKEN id="token-42-11" pos="word" morph="none" start_char="5043" end_char="5043">y</TOKEN>
<TOKEN id="token-42-12" pos="word" morph="none" start_char="5045" end_char="5049">menos</TOKEN>
<TOKEN id="token-42-13" pos="word" morph="none" start_char="5051" end_char="5052">de</TOKEN>
<TOKEN id="token-42-14" pos="word" morph="none" start_char="5054" end_char="5057">diez</TOKEN>
<TOKEN id="token-42-15" pos="word" morph="none" start_char="5059" end_char="5061">han</TOKEN>
<TOKEN id="token-42-16" pos="word" morph="none" start_char="5063" end_char="5071">resultado</TOKEN>
<TOKEN id="token-42-17" pos="word" morph="none" start_char="5073" end_char="5081">positivas</TOKEN>
<TOKEN id="token-42-18" pos="punct" morph="none" start_char="5082" end_char="5082">.</TOKEN>
</SEG>
<SEG id="segment-43" start_char="5084" end_char="5201">
<ORIGINAL_TEXT>Eso es porque aunque esté ahí, en el largo viaje de un lugar a otro acaba desecándose y perdiendo su poder infeccioso.</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="5084" end_char="5086">Eso</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="5088" end_char="5089">es</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="5091" end_char="5096">porque</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="5098" end_char="5103">aunque</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="5105" end_char="5108">esté</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="5110" end_char="5112">ahí</TOKEN>
<TOKEN id="token-43-6" pos="punct" morph="none" start_char="5113" end_char="5113">,</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="5115" end_char="5116">en</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="5118" end_char="5119">el</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="5121" end_char="5125">largo</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="5127" end_char="5131">viaje</TOKEN>
<TOKEN id="token-43-11" pos="word" morph="none" start_char="5133" end_char="5134">de</TOKEN>
<TOKEN id="token-43-12" pos="word" morph="none" start_char="5136" end_char="5137">un</TOKEN>
<TOKEN id="token-43-13" pos="word" morph="none" start_char="5139" end_char="5143">lugar</TOKEN>
<TOKEN id="token-43-14" pos="word" morph="none" start_char="5145" end_char="5145">a</TOKEN>
<TOKEN id="token-43-15" pos="word" morph="none" start_char="5147" end_char="5150">otro</TOKEN>
<TOKEN id="token-43-16" pos="word" morph="none" start_char="5152" end_char="5156">acaba</TOKEN>
<TOKEN id="token-43-17" pos="word" morph="none" start_char="5158" end_char="5168">desecándose</TOKEN>
<TOKEN id="token-43-18" pos="word" morph="none" start_char="5170" end_char="5170">y</TOKEN>
<TOKEN id="token-43-19" pos="word" morph="none" start_char="5172" end_char="5180">perdiendo</TOKEN>
<TOKEN id="token-43-20" pos="word" morph="none" start_char="5182" end_char="5183">su</TOKEN>
<TOKEN id="token-43-21" pos="word" morph="none" start_char="5185" end_char="5189">poder</TOKEN>
<TOKEN id="token-43-22" pos="word" morph="none" start_char="5191" end_char="5200">infeccioso</TOKEN>
<TOKEN id="token-43-23" pos="punct" morph="none" start_char="5201" end_char="5201">.</TOKEN>
</SEG>
<SEG id="segment-44" start_char="5204" end_char="5328">
<ORIGINAL_TEXT>Es cierto que puede permanecer en determinadas superficies durante bastante tiempo, pero con pocas posibilidades de infectar.</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="5204" end_char="5205">Es</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="5207" end_char="5212">cierto</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="5214" end_char="5216">que</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="5218" end_char="5222">puede</TOKEN>
<TOKEN id="token-44-4" pos="word" morph="none" start_char="5224" end_char="5233">permanecer</TOKEN>
<TOKEN id="token-44-5" pos="word" morph="none" start_char="5235" end_char="5236">en</TOKEN>
<TOKEN id="token-44-6" pos="word" morph="none" start_char="5238" end_char="5249">determinadas</TOKEN>
<TOKEN id="token-44-7" pos="word" morph="none" start_char="5251" end_char="5261">superficies</TOKEN>
<TOKEN id="token-44-8" pos="word" morph="none" start_char="5263" end_char="5269">durante</TOKEN>
<TOKEN id="token-44-9" pos="word" morph="none" start_char="5271" end_char="5278">bastante</TOKEN>
<TOKEN id="token-44-10" pos="word" morph="none" start_char="5280" end_char="5285">tiempo</TOKEN>
<TOKEN id="token-44-11" pos="punct" morph="none" start_char="5286" end_char="5286">,</TOKEN>
<TOKEN id="token-44-12" pos="word" morph="none" start_char="5288" end_char="5291">pero</TOKEN>
<TOKEN id="token-44-13" pos="word" morph="none" start_char="5293" end_char="5295">con</TOKEN>
<TOKEN id="token-44-14" pos="word" morph="none" start_char="5297" end_char="5301">pocas</TOKEN>
<TOKEN id="token-44-15" pos="word" morph="none" start_char="5303" end_char="5315">posibilidades</TOKEN>
<TOKEN id="token-44-16" pos="word" morph="none" start_char="5317" end_char="5318">de</TOKEN>
<TOKEN id="token-44-17" pos="word" morph="none" start_char="5320" end_char="5327">infectar</TOKEN>
<TOKEN id="token-44-18" pos="punct" morph="none" start_char="5328" end_char="5328">.</TOKEN>
</SEG>
<SEG id="segment-45" start_char="5330" end_char="5397">
<ORIGINAL_TEXT>La vida del virus depende también del material sobre el que se pose.</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="5330" end_char="5331">La</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="5333" end_char="5336">vida</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="5338" end_char="5340">del</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="5342" end_char="5346">virus</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="5348" end_char="5354">depende</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="5356" end_char="5362">también</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="5364" end_char="5366">del</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="5368" end_char="5375">material</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="5377" end_char="5381">sobre</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="5383" end_char="5384">el</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="5386" end_char="5388">que</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="5390" end_char="5391">se</TOKEN>
<TOKEN id="token-45-12" pos="word" morph="none" start_char="5393" end_char="5396">pose</TOKEN>
<TOKEN id="token-45-13" pos="punct" morph="none" start_char="5397" end_char="5397">.</TOKEN>
</SEG>
<SEG id="segment-46" start_char="5400" end_char="5463">
<ORIGINAL_TEXT>Ford convierte las botellas de plástico en alfombrillas de coche</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="5400" end_char="5403">Ford</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="5405" end_char="5413">convierte</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="5415" end_char="5417">las</TOKEN>
<TOKEN id="token-46-3" pos="word" morph="none" start_char="5419" end_char="5426">botellas</TOKEN>
<TOKEN id="token-46-4" pos="word" morph="none" start_char="5428" end_char="5429">de</TOKEN>
<TOKEN id="token-46-5" pos="word" morph="none" start_char="5431" end_char="5438">plástico</TOKEN>
<TOKEN id="token-46-6" pos="word" morph="none" start_char="5440" end_char="5441">en</TOKEN>
<TOKEN id="token-46-7" pos="word" morph="none" start_char="5443" end_char="5454">alfombrillas</TOKEN>
<TOKEN id="token-46-8" pos="word" morph="none" start_char="5456" end_char="5457">de</TOKEN>
<TOKEN id="token-46-9" pos="word" morph="none" start_char="5459" end_char="5463">coche</TOKEN>
</SEG>
<SEG id="segment-47" start_char="5467" end_char="5613">
<ORIGINAL_TEXT>Según diversos estudios, permanece unas tres horas en tejidos y papel impreso; un día sobre una cartulina y tres sobre plástico o acero inoxidable.</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="5467" end_char="5471">Según</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="5473" end_char="5480">diversos</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="5482" end_char="5489">estudios</TOKEN>
<TOKEN id="token-47-3" pos="punct" morph="none" start_char="5490" end_char="5490">,</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="5492" end_char="5500">permanece</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="5502" end_char="5505">unas</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="5507" end_char="5510">tres</TOKEN>
<TOKEN id="token-47-7" pos="word" morph="none" start_char="5512" end_char="5516">horas</TOKEN>
<TOKEN id="token-47-8" pos="word" morph="none" start_char="5518" end_char="5519">en</TOKEN>
<TOKEN id="token-47-9" pos="word" morph="none" start_char="5521" end_char="5527">tejidos</TOKEN>
<TOKEN id="token-47-10" pos="word" morph="none" start_char="5529" end_char="5529">y</TOKEN>
<TOKEN id="token-47-11" pos="word" morph="none" start_char="5531" end_char="5535">papel</TOKEN>
<TOKEN id="token-47-12" pos="word" morph="none" start_char="5537" end_char="5543">impreso</TOKEN>
<TOKEN id="token-47-13" pos="punct" morph="none" start_char="5544" end_char="5544">;</TOKEN>
<TOKEN id="token-47-14" pos="word" morph="none" start_char="5546" end_char="5547">un</TOKEN>
<TOKEN id="token-47-15" pos="word" morph="none" start_char="5549" end_char="5551">día</TOKEN>
<TOKEN id="token-47-16" pos="word" morph="none" start_char="5553" end_char="5557">sobre</TOKEN>
<TOKEN id="token-47-17" pos="word" morph="none" start_char="5559" end_char="5561">una</TOKEN>
<TOKEN id="token-47-18" pos="word" morph="none" start_char="5563" end_char="5571">cartulina</TOKEN>
<TOKEN id="token-47-19" pos="word" morph="none" start_char="5573" end_char="5573">y</TOKEN>
<TOKEN id="token-47-20" pos="word" morph="none" start_char="5575" end_char="5578">tres</TOKEN>
<TOKEN id="token-47-21" pos="word" morph="none" start_char="5580" end_char="5584">sobre</TOKEN>
<TOKEN id="token-47-22" pos="word" morph="none" start_char="5586" end_char="5593">plástico</TOKEN>
<TOKEN id="token-47-23" pos="word" morph="none" start_char="5595" end_char="5595">o</TOKEN>
<TOKEN id="token-47-24" pos="word" morph="none" start_char="5597" end_char="5601">acero</TOKEN>
<TOKEN id="token-47-25" pos="word" morph="none" start_char="5603" end_char="5612">inoxidable</TOKEN>
<TOKEN id="token-47-26" pos="punct" morph="none" start_char="5613" end_char="5613">.</TOKEN>
</SEG>
<SEG id="segment-48" start_char="5615" end_char="5738">
<ORIGINAL_TEXT>Y aunque no es la forma más común de transmisión, sigue siendo aconsejable mantener las superficies limpias y desinfectadas.</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="5615" end_char="5615">Y</TOKEN>
<TOKEN id="token-48-1" pos="word" morph="none" start_char="5617" end_char="5622">aunque</TOKEN>
<TOKEN id="token-48-2" pos="word" morph="none" start_char="5624" end_char="5625">no</TOKEN>
<TOKEN id="token-48-3" pos="word" morph="none" start_char="5627" end_char="5628">es</TOKEN>
<TOKEN id="token-48-4" pos="word" morph="none" start_char="5630" end_char="5631">la</TOKEN>
<TOKEN id="token-48-5" pos="word" morph="none" start_char="5633" end_char="5637">forma</TOKEN>
<TOKEN id="token-48-6" pos="word" morph="none" start_char="5639" end_char="5641">más</TOKEN>
<TOKEN id="token-48-7" pos="word" morph="none" start_char="5643" end_char="5647">común</TOKEN>
<TOKEN id="token-48-8" pos="word" morph="none" start_char="5649" end_char="5650">de</TOKEN>
<TOKEN id="token-48-9" pos="word" morph="none" start_char="5652" end_char="5662">transmisión</TOKEN>
<TOKEN id="token-48-10" pos="punct" morph="none" start_char="5663" end_char="5663">,</TOKEN>
<TOKEN id="token-48-11" pos="word" morph="none" start_char="5665" end_char="5669">sigue</TOKEN>
<TOKEN id="token-48-12" pos="word" morph="none" start_char="5671" end_char="5676">siendo</TOKEN>
<TOKEN id="token-48-13" pos="word" morph="none" start_char="5678" end_char="5688">aconsejable</TOKEN>
<TOKEN id="token-48-14" pos="word" morph="none" start_char="5690" end_char="5697">mantener</TOKEN>
<TOKEN id="token-48-15" pos="word" morph="none" start_char="5699" end_char="5701">las</TOKEN>
<TOKEN id="token-48-16" pos="word" morph="none" start_char="5703" end_char="5713">superficies</TOKEN>
<TOKEN id="token-48-17" pos="word" morph="none" start_char="5715" end_char="5721">limpias</TOKEN>
<TOKEN id="token-48-18" pos="word" morph="none" start_char="5723" end_char="5723">y</TOKEN>
<TOKEN id="token-48-19" pos="word" morph="none" start_char="5725" end_char="5737">desinfectadas</TOKEN>
<TOKEN id="token-48-20" pos="punct" morph="none" start_char="5738" end_char="5738">.</TOKEN>
</SEG>
<SEG id="segment-49" start_char="5741" end_char="5946">
<ORIGINAL_TEXT>Lo que está claro es que si el virus se contagiara de forma eficaz a través de productos que viajan de un país a otro, estaríamos hablando de cifras de infectados exponencialmente superiores a las actuales.</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="5741" end_char="5742">Lo</TOKEN>
<TOKEN id="token-49-1" pos="word" morph="none" start_char="5744" end_char="5746">que</TOKEN>
<TOKEN id="token-49-2" pos="word" morph="none" start_char="5748" end_char="5751">está</TOKEN>
<TOKEN id="token-49-3" pos="word" morph="none" start_char="5753" end_char="5757">claro</TOKEN>
<TOKEN id="token-49-4" pos="word" morph="none" start_char="5759" end_char="5760">es</TOKEN>
<TOKEN id="token-49-5" pos="word" morph="none" start_char="5762" end_char="5764">que</TOKEN>
<TOKEN id="token-49-6" pos="word" morph="none" start_char="5766" end_char="5767">si</TOKEN>
<TOKEN id="token-49-7" pos="word" morph="none" start_char="5769" end_char="5770">el</TOKEN>
<TOKEN id="token-49-8" pos="word" morph="none" start_char="5772" end_char="5776">virus</TOKEN>
<TOKEN id="token-49-9" pos="word" morph="none" start_char="5778" end_char="5779">se</TOKEN>
<TOKEN id="token-49-10" pos="word" morph="none" start_char="5781" end_char="5790">contagiara</TOKEN>
<TOKEN id="token-49-11" pos="word" morph="none" start_char="5792" end_char="5793">de</TOKEN>
<TOKEN id="token-49-12" pos="word" morph="none" start_char="5795" end_char="5799">forma</TOKEN>
<TOKEN id="token-49-13" pos="word" morph="none" start_char="5801" end_char="5806">eficaz</TOKEN>
<TOKEN id="token-49-14" pos="word" morph="none" start_char="5808" end_char="5808">a</TOKEN>
<TOKEN id="token-49-15" pos="word" morph="none" start_char="5810" end_char="5815">través</TOKEN>
<TOKEN id="token-49-16" pos="word" morph="none" start_char="5817" end_char="5818">de</TOKEN>
<TOKEN id="token-49-17" pos="word" morph="none" start_char="5820" end_char="5828">productos</TOKEN>
<TOKEN id="token-49-18" pos="word" morph="none" start_char="5830" end_char="5832">que</TOKEN>
<TOKEN id="token-49-19" pos="word" morph="none" start_char="5834" end_char="5839">viajan</TOKEN>
<TOKEN id="token-49-20" pos="word" morph="none" start_char="5841" end_char="5842">de</TOKEN>
<TOKEN id="token-49-21" pos="word" morph="none" start_char="5844" end_char="5845">un</TOKEN>
<TOKEN id="token-49-22" pos="word" morph="none" start_char="5847" end_char="5850">país</TOKEN>
<TOKEN id="token-49-23" pos="word" morph="none" start_char="5852" end_char="5852">a</TOKEN>
<TOKEN id="token-49-24" pos="word" morph="none" start_char="5854" end_char="5857">otro</TOKEN>
<TOKEN id="token-49-25" pos="punct" morph="none" start_char="5858" end_char="5858">,</TOKEN>
<TOKEN id="token-49-26" pos="word" morph="none" start_char="5860" end_char="5869">estaríamos</TOKEN>
<TOKEN id="token-49-27" pos="word" morph="none" start_char="5871" end_char="5878">hablando</TOKEN>
<TOKEN id="token-49-28" pos="word" morph="none" start_char="5880" end_char="5881">de</TOKEN>
<TOKEN id="token-49-29" pos="word" morph="none" start_char="5883" end_char="5888">cifras</TOKEN>
<TOKEN id="token-49-30" pos="word" morph="none" start_char="5890" end_char="5891">de</TOKEN>
<TOKEN id="token-49-31" pos="word" morph="none" start_char="5893" end_char="5902">infectados</TOKEN>
<TOKEN id="token-49-32" pos="word" morph="none" start_char="5904" end_char="5919">exponencialmente</TOKEN>
<TOKEN id="token-49-33" pos="word" morph="none" start_char="5921" end_char="5930">superiores</TOKEN>
<TOKEN id="token-49-34" pos="word" morph="none" start_char="5932" end_char="5932">a</TOKEN>
<TOKEN id="token-49-35" pos="word" morph="none" start_char="5934" end_char="5936">las</TOKEN>
<TOKEN id="token-49-36" pos="word" morph="none" start_char="5938" end_char="5945">actuales</TOKEN>
<TOKEN id="token-49-37" pos="punct" morph="none" start_char="5946" end_char="5946">.</TOKEN>
</SEG>
<SEG id="segment-50" start_char="5949" end_char="6151">
<ORIGINAL_TEXT>De todas formas, la mejor protección es seguir las medidas de higiene establecidas y, entre otras cosas, procurar no tocarse la piel después de coger productos de los supermercados, sean congelados o no.</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="5949" end_char="5950">De</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="5952" end_char="5956">todas</TOKEN>
<TOKEN id="token-50-2" pos="word" morph="none" start_char="5958" end_char="5963">formas</TOKEN>
<TOKEN id="token-50-3" pos="punct" morph="none" start_char="5964" end_char="5964">,</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="5966" end_char="5967">la</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="5969" end_char="5973">mejor</TOKEN>
<TOKEN id="token-50-6" pos="word" morph="none" start_char="5975" end_char="5984">protección</TOKEN>
<TOKEN id="token-50-7" pos="word" morph="none" start_char="5986" end_char="5987">es</TOKEN>
<TOKEN id="token-50-8" pos="word" morph="none" start_char="5989" end_char="5994">seguir</TOKEN>
<TOKEN id="token-50-9" pos="word" morph="none" start_char="5996" end_char="5998">las</TOKEN>
<TOKEN id="token-50-10" pos="word" morph="none" start_char="6000" end_char="6006">medidas</TOKEN>
<TOKEN id="token-50-11" pos="word" morph="none" start_char="6008" end_char="6009">de</TOKEN>
<TOKEN id="token-50-12" pos="word" morph="none" start_char="6011" end_char="6017">higiene</TOKEN>
<TOKEN id="token-50-13" pos="word" morph="none" start_char="6019" end_char="6030">establecidas</TOKEN>
<TOKEN id="token-50-14" pos="word" morph="none" start_char="6032" end_char="6032">y</TOKEN>
<TOKEN id="token-50-15" pos="punct" morph="none" start_char="6033" end_char="6033">,</TOKEN>
<TOKEN id="token-50-16" pos="word" morph="none" start_char="6035" end_char="6039">entre</TOKEN>
<TOKEN id="token-50-17" pos="word" morph="none" start_char="6041" end_char="6045">otras</TOKEN>
<TOKEN id="token-50-18" pos="word" morph="none" start_char="6047" end_char="6051">cosas</TOKEN>
<TOKEN id="token-50-19" pos="punct" morph="none" start_char="6052" end_char="6052">,</TOKEN>
<TOKEN id="token-50-20" pos="word" morph="none" start_char="6054" end_char="6061">procurar</TOKEN>
<TOKEN id="token-50-21" pos="word" morph="none" start_char="6063" end_char="6064">no</TOKEN>
<TOKEN id="token-50-22" pos="word" morph="none" start_char="6066" end_char="6072">tocarse</TOKEN>
<TOKEN id="token-50-23" pos="word" morph="none" start_char="6074" end_char="6075">la</TOKEN>
<TOKEN id="token-50-24" pos="word" morph="none" start_char="6077" end_char="6080">piel</TOKEN>
<TOKEN id="token-50-25" pos="word" morph="none" start_char="6082" end_char="6088">después</TOKEN>
<TOKEN id="token-50-26" pos="word" morph="none" start_char="6090" end_char="6091">de</TOKEN>
<TOKEN id="token-50-27" pos="word" morph="none" start_char="6093" end_char="6097">coger</TOKEN>
<TOKEN id="token-50-28" pos="word" morph="none" start_char="6099" end_char="6107">productos</TOKEN>
<TOKEN id="token-50-29" pos="word" morph="none" start_char="6109" end_char="6110">de</TOKEN>
<TOKEN id="token-50-30" pos="word" morph="none" start_char="6112" end_char="6114">los</TOKEN>
<TOKEN id="token-50-31" pos="word" morph="none" start_char="6116" end_char="6128">supermercados</TOKEN>
<TOKEN id="token-50-32" pos="punct" morph="none" start_char="6129" end_char="6129">,</TOKEN>
<TOKEN id="token-50-33" pos="word" morph="none" start_char="6131" end_char="6134">sean</TOKEN>
<TOKEN id="token-50-34" pos="word" morph="none" start_char="6136" end_char="6145">congelados</TOKEN>
<TOKEN id="token-50-35" pos="word" morph="none" start_char="6147" end_char="6147">o</TOKEN>
<TOKEN id="token-50-36" pos="word" morph="none" start_char="6149" end_char="6150">no</TOKEN>
<TOKEN id="token-50-37" pos="punct" morph="none" start_char="6151" end_char="6151">.</TOKEN>
</SEG>
<SEG id="segment-51" start_char="6154" end_char="6162">
<ORIGINAL_TEXT>congelado</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="word" morph="none" start_char="6154" end_char="6162">congelado</TOKEN>
</SEG>
<SEG id="segment-52" start_char="6166" end_char="6311">
<ORIGINAL_TEXT>La relación entre la manipulación de alimentos y contagios se ha establecido también por los muchos casos que se han dado en ese tipo de empresas.</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="6166" end_char="6167">La</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="6169" end_char="6176">relación</TOKEN>
<TOKEN id="token-52-2" pos="word" morph="none" start_char="6178" end_char="6182">entre</TOKEN>
<TOKEN id="token-52-3" pos="word" morph="none" start_char="6184" end_char="6185">la</TOKEN>
<TOKEN id="token-52-4" pos="word" morph="none" start_char="6187" end_char="6198">manipulación</TOKEN>
<TOKEN id="token-52-5" pos="word" morph="none" start_char="6200" end_char="6201">de</TOKEN>
<TOKEN id="token-52-6" pos="word" morph="none" start_char="6203" end_char="6211">alimentos</TOKEN>
<TOKEN id="token-52-7" pos="word" morph="none" start_char="6213" end_char="6213">y</TOKEN>
<TOKEN id="token-52-8" pos="word" morph="none" start_char="6215" end_char="6223">contagios</TOKEN>
<TOKEN id="token-52-9" pos="word" morph="none" start_char="6225" end_char="6226">se</TOKEN>
<TOKEN id="token-52-10" pos="word" morph="none" start_char="6228" end_char="6229">ha</TOKEN>
<TOKEN id="token-52-11" pos="word" morph="none" start_char="6231" end_char="6241">establecido</TOKEN>
<TOKEN id="token-52-12" pos="word" morph="none" start_char="6243" end_char="6249">también</TOKEN>
<TOKEN id="token-52-13" pos="word" morph="none" start_char="6251" end_char="6253">por</TOKEN>
<TOKEN id="token-52-14" pos="word" morph="none" start_char="6255" end_char="6257">los</TOKEN>
<TOKEN id="token-52-15" pos="word" morph="none" start_char="6259" end_char="6264">muchos</TOKEN>
<TOKEN id="token-52-16" pos="word" morph="none" start_char="6266" end_char="6270">casos</TOKEN>
<TOKEN id="token-52-17" pos="word" morph="none" start_char="6272" end_char="6274">que</TOKEN>
<TOKEN id="token-52-18" pos="word" morph="none" start_char="6276" end_char="6277">se</TOKEN>
<TOKEN id="token-52-19" pos="word" morph="none" start_char="6279" end_char="6281">han</TOKEN>
<TOKEN id="token-52-20" pos="word" morph="none" start_char="6283" end_char="6286">dado</TOKEN>
<TOKEN id="token-52-21" pos="word" morph="none" start_char="6288" end_char="6289">en</TOKEN>
<TOKEN id="token-52-22" pos="word" morph="none" start_char="6291" end_char="6293">ese</TOKEN>
<TOKEN id="token-52-23" pos="word" morph="none" start_char="6295" end_char="6298">tipo</TOKEN>
<TOKEN id="token-52-24" pos="word" morph="none" start_char="6300" end_char="6301">de</TOKEN>
<TOKEN id="token-52-25" pos="word" morph="none" start_char="6303" end_char="6310">empresas</TOKEN>
<TOKEN id="token-52-26" pos="punct" morph="none" start_char="6311" end_char="6311">.</TOKEN>
</SEG>
<SEG id="segment-53" start_char="6313" end_char="6534">
<ORIGINAL_TEXT>Pero los expertos no creen que puede achacarse a los alimentos en sí, sino a las propias condiciones de trabajo en estos centros y a que suele encontrarse en comunidades donde la exposición al virus ya es bastante elevada.</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="word" morph="none" start_char="6313" end_char="6316">Pero</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="6318" end_char="6320">los</TOKEN>
<TOKEN id="token-53-2" pos="word" morph="none" start_char="6322" end_char="6329">expertos</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="6331" end_char="6332">no</TOKEN>
<TOKEN id="token-53-4" pos="word" morph="none" start_char="6334" end_char="6338">creen</TOKEN>
<TOKEN id="token-53-5" pos="word" morph="none" start_char="6340" end_char="6342">que</TOKEN>
<TOKEN id="token-53-6" pos="word" morph="none" start_char="6344" end_char="6348">puede</TOKEN>
<TOKEN id="token-53-7" pos="word" morph="none" start_char="6350" end_char="6358">achacarse</TOKEN>
<TOKEN id="token-53-8" pos="word" morph="none" start_char="6360" end_char="6360">a</TOKEN>
<TOKEN id="token-53-9" pos="word" morph="none" start_char="6362" end_char="6364">los</TOKEN>
<TOKEN id="token-53-10" pos="word" morph="none" start_char="6366" end_char="6374">alimentos</TOKEN>
<TOKEN id="token-53-11" pos="word" morph="none" start_char="6376" end_char="6377">en</TOKEN>
<TOKEN id="token-53-12" pos="word" morph="none" start_char="6379" end_char="6380">sí</TOKEN>
<TOKEN id="token-53-13" pos="punct" morph="none" start_char="6381" end_char="6381">,</TOKEN>
<TOKEN id="token-53-14" pos="word" morph="none" start_char="6383" end_char="6386">sino</TOKEN>
<TOKEN id="token-53-15" pos="word" morph="none" start_char="6388" end_char="6388">a</TOKEN>
<TOKEN id="token-53-16" pos="word" morph="none" start_char="6390" end_char="6392">las</TOKEN>
<TOKEN id="token-53-17" pos="word" morph="none" start_char="6394" end_char="6400">propias</TOKEN>
<TOKEN id="token-53-18" pos="word" morph="none" start_char="6402" end_char="6412">condiciones</TOKEN>
<TOKEN id="token-53-19" pos="word" morph="none" start_char="6414" end_char="6415">de</TOKEN>
<TOKEN id="token-53-20" pos="word" morph="none" start_char="6417" end_char="6423">trabajo</TOKEN>
<TOKEN id="token-53-21" pos="word" morph="none" start_char="6425" end_char="6426">en</TOKEN>
<TOKEN id="token-53-22" pos="word" morph="none" start_char="6428" end_char="6432">estos</TOKEN>
<TOKEN id="token-53-23" pos="word" morph="none" start_char="6434" end_char="6440">centros</TOKEN>
<TOKEN id="token-53-24" pos="word" morph="none" start_char="6442" end_char="6442">y</TOKEN>
<TOKEN id="token-53-25" pos="word" morph="none" start_char="6444" end_char="6444">a</TOKEN>
<TOKEN id="token-53-26" pos="word" morph="none" start_char="6446" end_char="6448">que</TOKEN>
<TOKEN id="token-53-27" pos="word" morph="none" start_char="6450" end_char="6454">suele</TOKEN>
<TOKEN id="token-53-28" pos="word" morph="none" start_char="6456" end_char="6466">encontrarse</TOKEN>
<TOKEN id="token-53-29" pos="word" morph="none" start_char="6468" end_char="6469">en</TOKEN>
<TOKEN id="token-53-30" pos="word" morph="none" start_char="6471" end_char="6481">comunidades</TOKEN>
<TOKEN id="token-53-31" pos="word" morph="none" start_char="6483" end_char="6487">donde</TOKEN>
<TOKEN id="token-53-32" pos="word" morph="none" start_char="6489" end_char="6490">la</TOKEN>
<TOKEN id="token-53-33" pos="word" morph="none" start_char="6492" end_char="6501">exposición</TOKEN>
<TOKEN id="token-53-34" pos="word" morph="none" start_char="6503" end_char="6504">al</TOKEN>
<TOKEN id="token-53-35" pos="word" morph="none" start_char="6506" end_char="6510">virus</TOKEN>
<TOKEN id="token-53-36" pos="word" morph="none" start_char="6512" end_char="6513">ya</TOKEN>
<TOKEN id="token-53-37" pos="word" morph="none" start_char="6515" end_char="6516">es</TOKEN>
<TOKEN id="token-53-38" pos="word" morph="none" start_char="6518" end_char="6525">bastante</TOKEN>
<TOKEN id="token-53-39" pos="word" morph="none" start_char="6527" end_char="6533">elevada</TOKEN>
<TOKEN id="token-53-40" pos="punct" morph="none" start_char="6534" end_char="6534">.</TOKEN>
</SEG>
<SEG id="segment-54" start_char="6537" end_char="6649">
<ORIGINAL_TEXT>Así que la posibilidad de que esos trabajadores se infecten y pasen el virus a los productos alimentarios existe.</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="word" morph="none" start_char="6537" end_char="6539">Así</TOKEN>
<TOKEN id="token-54-1" pos="word" morph="none" start_char="6541" end_char="6543">que</TOKEN>
<TOKEN id="token-54-2" pos="word" morph="none" start_char="6545" end_char="6546">la</TOKEN>
<TOKEN id="token-54-3" pos="word" morph="none" start_char="6548" end_char="6558">posibilidad</TOKEN>
<TOKEN id="token-54-4" pos="word" morph="none" start_char="6560" end_char="6561">de</TOKEN>
<TOKEN id="token-54-5" pos="word" morph="none" start_char="6563" end_char="6565">que</TOKEN>
<TOKEN id="token-54-6" pos="word" morph="none" start_char="6567" end_char="6570">esos</TOKEN>
<TOKEN id="token-54-7" pos="word" morph="none" start_char="6572" end_char="6583">trabajadores</TOKEN>
<TOKEN id="token-54-8" pos="word" morph="none" start_char="6585" end_char="6586">se</TOKEN>
<TOKEN id="token-54-9" pos="word" morph="none" start_char="6588" end_char="6595">infecten</TOKEN>
<TOKEN id="token-54-10" pos="word" morph="none" start_char="6597" end_char="6597">y</TOKEN>
<TOKEN id="token-54-11" pos="word" morph="none" start_char="6599" end_char="6603">pasen</TOKEN>
<TOKEN id="token-54-12" pos="word" morph="none" start_char="6605" end_char="6606">el</TOKEN>
<TOKEN id="token-54-13" pos="word" morph="none" start_char="6608" end_char="6612">virus</TOKEN>
<TOKEN id="token-54-14" pos="word" morph="none" start_char="6614" end_char="6614">a</TOKEN>
<TOKEN id="token-54-15" pos="word" morph="none" start_char="6616" end_char="6618">los</TOKEN>
<TOKEN id="token-54-16" pos="word" morph="none" start_char="6620" end_char="6628">productos</TOKEN>
<TOKEN id="token-54-17" pos="word" morph="none" start_char="6630" end_char="6641">alimentarios</TOKEN>
<TOKEN id="token-54-18" pos="word" morph="none" start_char="6643" end_char="6648">existe</TOKEN>
<TOKEN id="token-54-19" pos="punct" morph="none" start_char="6649" end_char="6649">.</TOKEN>
</SEG>
<SEG id="segment-55" start_char="6651" end_char="6726">
<ORIGINAL_TEXT>Y también las probabilidades de que acabe llegado al otro extremo del mundo.</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="word" morph="none" start_char="6651" end_char="6651">Y</TOKEN>
<TOKEN id="token-55-1" pos="word" morph="none" start_char="6653" end_char="6659">también</TOKEN>
<TOKEN id="token-55-2" pos="word" morph="none" start_char="6661" end_char="6663">las</TOKEN>
<TOKEN id="token-55-3" pos="word" morph="none" start_char="6665" end_char="6678">probabilidades</TOKEN>
<TOKEN id="token-55-4" pos="word" morph="none" start_char="6680" end_char="6681">de</TOKEN>
<TOKEN id="token-55-5" pos="word" morph="none" start_char="6683" end_char="6685">que</TOKEN>
<TOKEN id="token-55-6" pos="word" morph="none" start_char="6687" end_char="6691">acabe</TOKEN>
<TOKEN id="token-55-7" pos="word" morph="none" start_char="6693" end_char="6699">llegado</TOKEN>
<TOKEN id="token-55-8" pos="word" morph="none" start_char="6701" end_char="6702">al</TOKEN>
<TOKEN id="token-55-9" pos="word" morph="none" start_char="6704" end_char="6707">otro</TOKEN>
<TOKEN id="token-55-10" pos="word" morph="none" start_char="6709" end_char="6715">extremo</TOKEN>
<TOKEN id="token-55-11" pos="word" morph="none" start_char="6717" end_char="6719">del</TOKEN>
<TOKEN id="token-55-12" pos="word" morph="none" start_char="6721" end_char="6725">mundo</TOKEN>
<TOKEN id="token-55-13" pos="punct" morph="none" start_char="6726" end_char="6726">.</TOKEN>
</SEG>
<SEG id="segment-56" start_char="6728" end_char="6788">
<ORIGINAL_TEXT>Otra cosa es que sea en condiciones óptimas para el contagio.</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="6728" end_char="6731">Otra</TOKEN>
<TOKEN id="token-56-1" pos="word" morph="none" start_char="6733" end_char="6736">cosa</TOKEN>
<TOKEN id="token-56-2" pos="word" morph="none" start_char="6738" end_char="6739">es</TOKEN>
<TOKEN id="token-56-3" pos="word" morph="none" start_char="6741" end_char="6743">que</TOKEN>
<TOKEN id="token-56-4" pos="word" morph="none" start_char="6745" end_char="6747">sea</TOKEN>
<TOKEN id="token-56-5" pos="word" morph="none" start_char="6749" end_char="6750">en</TOKEN>
<TOKEN id="token-56-6" pos="word" morph="none" start_char="6752" end_char="6762">condiciones</TOKEN>
<TOKEN id="token-56-7" pos="word" morph="none" start_char="6764" end_char="6770">óptimas</TOKEN>
<TOKEN id="token-56-8" pos="word" morph="none" start_char="6772" end_char="6775">para</TOKEN>
<TOKEN id="token-56-9" pos="word" morph="none" start_char="6777" end_char="6778">el</TOKEN>
<TOKEN id="token-56-10" pos="word" morph="none" start_char="6780" end_char="6787">contagio</TOKEN>
<TOKEN id="token-56-11" pos="punct" morph="none" start_char="6788" end_char="6788">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
