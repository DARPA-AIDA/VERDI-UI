<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="ukr">
<DOC id="L0C049P8E" lang="ukr" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="4239" raw_text_md5="eddd642c7b35fe5b70ac21f6c917f41b">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="62">
<ORIGINAL_TEXT>Is China Seeking Approval to Kill 20,000 Coronavirus Patients?</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="2">Is</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="4" end_char="8">China</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="10" end_char="16">Seeking</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="18" end_char="25">Approval</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="27" end_char="28">to</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="30" end_char="33">Kill</TOKEN>
<TOKEN id="token-0-6" pos="unknown" morph="none" start_char="35" end_char="40">20,000</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="42" end_char="52">Coronavirus</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="54" end_char="61">Patients</TOKEN>
<TOKEN id="token-0-9" pos="punct" morph="none" start_char="62" end_char="62">?</TOKEN>
</SEG>
<SEG id="segment-1" start_char="67" end_char="101">
<ORIGINAL_TEXT>Image via Anthony Kwan/Getty Images</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="67" end_char="71">Image</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="73" end_char="75">via</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="77" end_char="83">Anthony</TOKEN>
<TOKEN id="token-1-3" pos="unknown" morph="none" start_char="85" end_char="94">Kwan/Getty</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="96" end_char="101">Images</TOKEN>
</SEG>
<SEG id="segment-2" start_char="105" end_char="111">
<ORIGINAL_TEXT>On Feb.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="105" end_char="106">On</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="108" end_char="110">Feb</TOKEN>
<TOKEN id="token-2-2" pos="punct" morph="none" start_char="111" end_char="111">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="113" end_char="375">
<ORIGINAL_TEXT>5, 2020, the website AB-TC (aka City News) published an article that claimed Chinese officials were seeking approval from the Supreme People’s Court to start the mass killing of 20,000 people infected with the new coronavirus in an attempt to contain the disease:</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="113" end_char="113">5</TOKEN>
<TOKEN id="token-3-1" pos="punct" morph="none" start_char="114" end_char="114">,</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="116" end_char="119">2020</TOKEN>
<TOKEN id="token-3-3" pos="punct" morph="none" start_char="120" end_char="120">,</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="122" end_char="124">the</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="126" end_char="132">website</TOKEN>
<TOKEN id="token-3-6" pos="unknown" morph="none" start_char="134" end_char="138">AB-TC</TOKEN>
<TOKEN id="token-3-7" pos="punct" morph="none" start_char="140" end_char="140">(</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="141" end_char="143">aka</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="145" end_char="148">City</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="150" end_char="153">News</TOKEN>
<TOKEN id="token-3-11" pos="punct" morph="none" start_char="154" end_char="154">)</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="156" end_char="164">published</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="166" end_char="167">an</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="169" end_char="175">article</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="177" end_char="180">that</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="182" end_char="188">claimed</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="190" end_char="196">Chinese</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="198" end_char="206">officials</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="208" end_char="211">were</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="213" end_char="219">seeking</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="221" end_char="228">approval</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="230" end_char="233">from</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="235" end_char="237">the</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="239" end_char="245">Supreme</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="247" end_char="254">People’s</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="256" end_char="260">Court</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="262" end_char="263">to</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="265" end_char="269">start</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="271" end_char="273">the</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="275" end_char="278">mass</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="280" end_char="286">killing</TOKEN>
<TOKEN id="token-3-32" pos="word" morph="none" start_char="288" end_char="289">of</TOKEN>
<TOKEN id="token-3-33" pos="unknown" morph="none" start_char="291" end_char="296">20,000</TOKEN>
<TOKEN id="token-3-34" pos="word" morph="none" start_char="298" end_char="303">people</TOKEN>
<TOKEN id="token-3-35" pos="word" morph="none" start_char="305" end_char="312">infected</TOKEN>
<TOKEN id="token-3-36" pos="word" morph="none" start_char="314" end_char="317">with</TOKEN>
<TOKEN id="token-3-37" pos="word" morph="none" start_char="319" end_char="321">the</TOKEN>
<TOKEN id="token-3-38" pos="word" morph="none" start_char="323" end_char="325">new</TOKEN>
<TOKEN id="token-3-39" pos="word" morph="none" start_char="327" end_char="337">coronavirus</TOKEN>
<TOKEN id="token-3-40" pos="word" morph="none" start_char="339" end_char="340">in</TOKEN>
<TOKEN id="token-3-41" pos="word" morph="none" start_char="342" end_char="343">an</TOKEN>
<TOKEN id="token-3-42" pos="word" morph="none" start_char="345" end_char="351">attempt</TOKEN>
<TOKEN id="token-3-43" pos="word" morph="none" start_char="353" end_char="354">to</TOKEN>
<TOKEN id="token-3-44" pos="word" morph="none" start_char="356" end_char="362">contain</TOKEN>
<TOKEN id="token-3-45" pos="word" morph="none" start_char="364" end_char="366">the</TOKEN>
<TOKEN id="token-3-46" pos="word" morph="none" start_char="368" end_char="374">disease</TOKEN>
<TOKEN id="token-3-47" pos="punct" morph="none" start_char="375" end_char="375">:</TOKEN>
</SEG>
<SEG id="segment-4" start_char="378" end_char="715">
<ORIGINAL_TEXT>China seek for court’s approval to kill the over 20,000 coronavirus patients to avoid further spread of the virus The highest level of court in Chhina [sic], Supreme People’s Court, is expected to give an approval on Friday for the mass killing of coronavirus patients in China as sure means of controlling the spread of the deadly virus.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="378" end_char="382">China</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="384" end_char="387">seek</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="389" end_char="391">for</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="393" end_char="399">court’s</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="401" end_char="408">approval</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="410" end_char="411">to</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="413" end_char="416">kill</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="418" end_char="420">the</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="422" end_char="425">over</TOKEN>
<TOKEN id="token-4-9" pos="unknown" morph="none" start_char="427" end_char="432">20,000</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="434" end_char="444">coronavirus</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="446" end_char="453">patients</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="455" end_char="456">to</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="458" end_char="462">avoid</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="464" end_char="470">further</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="472" end_char="477">spread</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="479" end_char="480">of</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="482" end_char="484">the</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="486" end_char="490">virus</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="492" end_char="494">The</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="496" end_char="502">highest</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="504" end_char="508">level</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="510" end_char="511">of</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="513" end_char="517">court</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="519" end_char="520">in</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="522" end_char="527">Chhina</TOKEN>
<TOKEN id="token-4-26" pos="punct" morph="none" start_char="529" end_char="529">[</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="530" end_char="532">sic</TOKEN>
<TOKEN id="token-4-28" pos="punct" morph="none" start_char="533" end_char="534">],</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="536" end_char="542">Supreme</TOKEN>
<TOKEN id="token-4-30" pos="word" morph="none" start_char="544" end_char="551">People’s</TOKEN>
<TOKEN id="token-4-31" pos="word" morph="none" start_char="553" end_char="557">Court</TOKEN>
<TOKEN id="token-4-32" pos="punct" morph="none" start_char="558" end_char="558">,</TOKEN>
<TOKEN id="token-4-33" pos="word" morph="none" start_char="560" end_char="561">is</TOKEN>
<TOKEN id="token-4-34" pos="word" morph="none" start_char="563" end_char="570">expected</TOKEN>
<TOKEN id="token-4-35" pos="word" morph="none" start_char="572" end_char="573">to</TOKEN>
<TOKEN id="token-4-36" pos="word" morph="none" start_char="575" end_char="578">give</TOKEN>
<TOKEN id="token-4-37" pos="word" morph="none" start_char="580" end_char="581">an</TOKEN>
<TOKEN id="token-4-38" pos="word" morph="none" start_char="583" end_char="590">approval</TOKEN>
<TOKEN id="token-4-39" pos="word" morph="none" start_char="592" end_char="593">on</TOKEN>
<TOKEN id="token-4-40" pos="word" morph="none" start_char="595" end_char="600">Friday</TOKEN>
<TOKEN id="token-4-41" pos="word" morph="none" start_char="602" end_char="604">for</TOKEN>
<TOKEN id="token-4-42" pos="word" morph="none" start_char="606" end_char="608">the</TOKEN>
<TOKEN id="token-4-43" pos="word" morph="none" start_char="610" end_char="613">mass</TOKEN>
<TOKEN id="token-4-44" pos="word" morph="none" start_char="615" end_char="621">killing</TOKEN>
<TOKEN id="token-4-45" pos="word" morph="none" start_char="623" end_char="624">of</TOKEN>
<TOKEN id="token-4-46" pos="word" morph="none" start_char="626" end_char="636">coronavirus</TOKEN>
<TOKEN id="token-4-47" pos="word" morph="none" start_char="638" end_char="645">patients</TOKEN>
<TOKEN id="token-4-48" pos="word" morph="none" start_char="647" end_char="648">in</TOKEN>
<TOKEN id="token-4-49" pos="word" morph="none" start_char="650" end_char="654">China</TOKEN>
<TOKEN id="token-4-50" pos="word" morph="none" start_char="656" end_char="657">as</TOKEN>
<TOKEN id="token-4-51" pos="word" morph="none" start_char="659" end_char="662">sure</TOKEN>
<TOKEN id="token-4-52" pos="word" morph="none" start_char="664" end_char="668">means</TOKEN>
<TOKEN id="token-4-53" pos="word" morph="none" start_char="670" end_char="671">of</TOKEN>
<TOKEN id="token-4-54" pos="word" morph="none" start_char="673" end_char="683">controlling</TOKEN>
<TOKEN id="token-4-55" pos="word" morph="none" start_char="685" end_char="687">the</TOKEN>
<TOKEN id="token-4-56" pos="word" morph="none" start_char="689" end_char="694">spread</TOKEN>
<TOKEN id="token-4-57" pos="word" morph="none" start_char="696" end_char="697">of</TOKEN>
<TOKEN id="token-4-58" pos="word" morph="none" start_char="699" end_char="701">the</TOKEN>
<TOKEN id="token-4-59" pos="word" morph="none" start_char="703" end_char="708">deadly</TOKEN>
<TOKEN id="token-4-60" pos="word" morph="none" start_char="710" end_char="714">virus</TOKEN>
<TOKEN id="token-4-61" pos="punct" morph="none" start_char="715" end_char="715">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="717" end_char="868">
<ORIGINAL_TEXT>The State tells the court that China is on the verge of losing its health workers to Coronavirus as at least 20 health workers contract the virus daily.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="717" end_char="719">The</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="721" end_char="725">State</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="727" end_char="731">tells</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="733" end_char="735">the</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="737" end_char="741">court</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="743" end_char="746">that</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="748" end_char="752">China</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="754" end_char="755">is</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="757" end_char="758">on</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="760" end_char="762">the</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="764" end_char="768">verge</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="770" end_char="771">of</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="773" end_char="778">losing</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="780" end_char="782">its</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="784" end_char="789">health</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="791" end_char="797">workers</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="799" end_char="800">to</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="802" end_char="812">Coronavirus</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="814" end_char="815">as</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="817" end_char="818">at</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="820" end_char="824">least</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="826" end_char="827">20</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="829" end_char="834">health</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="836" end_char="842">workers</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="844" end_char="851">contract</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="853" end_char="855">the</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="857" end_char="861">virus</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="863" end_char="867">daily</TOKEN>
<TOKEN id="token-5-28" pos="punct" morph="none" start_char="868" end_char="868">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="872" end_char="905">
<ORIGINAL_TEXT>This is not a genuine news report.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="872" end_char="875">This</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="877" end_char="878">is</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="880" end_char="882">not</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="884" end_char="884">a</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="886" end_char="892">genuine</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="894" end_char="897">news</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="899" end_char="904">report</TOKEN>
<TOKEN id="token-6-7" pos="punct" morph="none" start_char="905" end_char="905">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="907" end_char="1078">
<ORIGINAL_TEXT>While the AB-TC website does not carry any disclaimers labeling its content as fiction, we found a number of red flags concerning the legitimacy of this outlet’s reporting.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="907" end_char="911">While</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="913" end_char="915">the</TOKEN>
<TOKEN id="token-7-2" pos="unknown" morph="none" start_char="917" end_char="921">AB-TC</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="923" end_char="929">website</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="931" end_char="934">does</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="936" end_char="938">not</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="940" end_char="944">carry</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="946" end_char="948">any</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="950" end_char="960">disclaimers</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="962" end_char="969">labeling</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="971" end_char="973">its</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="975" end_char="981">content</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="983" end_char="984">as</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="986" end_char="992">fiction</TOKEN>
<TOKEN id="token-7-14" pos="punct" morph="none" start_char="993" end_char="993">,</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="995" end_char="996">we</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="998" end_char="1002">found</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="1004" end_char="1004">a</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="1006" end_char="1011">number</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="1013" end_char="1014">of</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="1016" end_char="1018">red</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="1020" end_char="1024">flags</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="1026" end_char="1035">concerning</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="1037" end_char="1039">the</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="1041" end_char="1050">legitimacy</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="1052" end_char="1053">of</TOKEN>
<TOKEN id="token-7-26" pos="word" morph="none" start_char="1055" end_char="1058">this</TOKEN>
<TOKEN id="token-7-27" pos="word" morph="none" start_char="1060" end_char="1067">outlet’s</TOKEN>
<TOKEN id="token-7-28" pos="word" morph="none" start_char="1069" end_char="1077">reporting</TOKEN>
<TOKEN id="token-7-29" pos="punct" morph="none" start_char="1078" end_char="1078">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1081" end_char="1136">
<ORIGINAL_TEXT>For starters, this website is full of junk news stories.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1081" end_char="1083">For</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1085" end_char="1092">starters</TOKEN>
<TOKEN id="token-8-2" pos="punct" morph="none" start_char="1093" end_char="1093">,</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1095" end_char="1098">this</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1100" end_char="1106">website</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1108" end_char="1109">is</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1111" end_char="1114">full</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1116" end_char="1117">of</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1119" end_char="1122">junk</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1124" end_char="1127">news</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1129" end_char="1135">stories</TOKEN>
<TOKEN id="token-8-11" pos="punct" morph="none" start_char="1136" end_char="1136">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1138" end_char="1281">
<ORIGINAL_TEXT>For instance, a July 2010 article (still featured on the homepage) carries the headline, "BREAKING: New York Giants coach Pat Shurmur has died."</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1138" end_char="1140">For</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1142" end_char="1149">instance</TOKEN>
<TOKEN id="token-9-2" pos="punct" morph="none" start_char="1150" end_char="1150">,</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1152" end_char="1152">a</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1154" end_char="1157">July</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1159" end_char="1162">2010</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1164" end_char="1170">article</TOKEN>
<TOKEN id="token-9-7" pos="punct" morph="none" start_char="1172" end_char="1172">(</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1173" end_char="1177">still</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1179" end_char="1186">featured</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1188" end_char="1189">on</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1191" end_char="1193">the</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1195" end_char="1202">homepage</TOKEN>
<TOKEN id="token-9-13" pos="punct" morph="none" start_char="1203" end_char="1203">)</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1205" end_char="1211">carries</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1213" end_char="1215">the</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1217" end_char="1224">headline</TOKEN>
<TOKEN id="token-9-17" pos="punct" morph="none" start_char="1225" end_char="1225">,</TOKEN>
<TOKEN id="token-9-18" pos="punct" morph="none" start_char="1227" end_char="1227">"</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1228" end_char="1235">BREAKING</TOKEN>
<TOKEN id="token-9-20" pos="punct" morph="none" start_char="1236" end_char="1236">:</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1238" end_char="1240">New</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1242" end_char="1245">York</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1247" end_char="1252">Giants</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1254" end_char="1258">coach</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1260" end_char="1262">Pat</TOKEN>
<TOKEN id="token-9-26" pos="word" morph="none" start_char="1264" end_char="1270">Shurmur</TOKEN>
<TOKEN id="token-9-27" pos="word" morph="none" start_char="1272" end_char="1274">has</TOKEN>
<TOKEN id="token-9-28" pos="word" morph="none" start_char="1276" end_char="1279">died</TOKEN>
<TOKEN id="token-9-29" pos="punct" morph="none" start_char="1280" end_char="1281">."</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1283" end_char="1313">
<ORIGINAL_TEXT>But Shurmur didn’t die in 2010.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1283" end_char="1285">But</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1287" end_char="1293">Shurmur</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1295" end_char="1300">didn’t</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1302" end_char="1304">die</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1306" end_char="1307">in</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1309" end_char="1312">2010</TOKEN>
<TOKEN id="token-10-6" pos="punct" morph="none" start_char="1313" end_char="1313">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1315" end_char="1442">
<ORIGINAL_TEXT>In fact, he is still alive as of this writing and was hired as the offensive coordinator for the Denver Broncos in January 2020.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1315" end_char="1316">In</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1318" end_char="1321">fact</TOKEN>
<TOKEN id="token-11-2" pos="punct" morph="none" start_char="1322" end_char="1322">,</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1324" end_char="1325">he</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1327" end_char="1328">is</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1330" end_char="1334">still</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1336" end_char="1340">alive</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1342" end_char="1343">as</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1345" end_char="1346">of</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1348" end_char="1351">this</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1353" end_char="1359">writing</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1361" end_char="1363">and</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1365" end_char="1367">was</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1369" end_char="1373">hired</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1375" end_char="1376">as</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1378" end_char="1380">the</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1382" end_char="1390">offensive</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1392" end_char="1402">coordinator</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1404" end_char="1406">for</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="1408" end_char="1410">the</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1412" end_char="1417">Denver</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="1419" end_char="1425">Broncos</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="1427" end_char="1428">in</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="1430" end_char="1436">January</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="1438" end_char="1441">2020</TOKEN>
<TOKEN id="token-11-25" pos="punct" morph="none" start_char="1442" end_char="1442">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1445" end_char="1720">
<ORIGINAL_TEXT>The website has also published hoax articles about "cannibal restaurants" (debunked here), death hoaxes about celebrity couples (debunked here), doctored tweets from U.S. President Donald Trump, and a junk news article that falsely claimed Prince Andrew had committed suicide.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1445" end_char="1447">The</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1449" end_char="1455">website</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1457" end_char="1459">has</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1461" end_char="1464">also</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1466" end_char="1474">published</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1476" end_char="1479">hoax</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1481" end_char="1488">articles</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1490" end_char="1494">about</TOKEN>
<TOKEN id="token-12-8" pos="punct" morph="none" start_char="1496" end_char="1496">"</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1497" end_char="1504">cannibal</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1506" end_char="1516">restaurants</TOKEN>
<TOKEN id="token-12-11" pos="punct" morph="none" start_char="1517" end_char="1517">"</TOKEN>
<TOKEN id="token-12-12" pos="punct" morph="none" start_char="1519" end_char="1519">(</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1520" end_char="1527">debunked</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1529" end_char="1532">here</TOKEN>
<TOKEN id="token-12-15" pos="punct" morph="none" start_char="1533" end_char="1534">),</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1536" end_char="1540">death</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1542" end_char="1547">hoaxes</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1549" end_char="1553">about</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1555" end_char="1563">celebrity</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1565" end_char="1571">couples</TOKEN>
<TOKEN id="token-12-21" pos="punct" morph="none" start_char="1573" end_char="1573">(</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1574" end_char="1581">debunked</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="1583" end_char="1586">here</TOKEN>
<TOKEN id="token-12-24" pos="punct" morph="none" start_char="1587" end_char="1588">),</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="1590" end_char="1597">doctored</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="1599" end_char="1604">tweets</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="1606" end_char="1609">from</TOKEN>
<TOKEN id="token-12-28" pos="unknown" morph="none" start_char="1611" end_char="1613">U.S</TOKEN>
<TOKEN id="token-12-29" pos="punct" morph="none" start_char="1614" end_char="1614">.</TOKEN>
<TOKEN id="token-12-30" pos="word" morph="none" start_char="1616" end_char="1624">President</TOKEN>
<TOKEN id="token-12-31" pos="word" morph="none" start_char="1626" end_char="1631">Donald</TOKEN>
<TOKEN id="token-12-32" pos="word" morph="none" start_char="1633" end_char="1637">Trump</TOKEN>
<TOKEN id="token-12-33" pos="punct" morph="none" start_char="1638" end_char="1638">,</TOKEN>
<TOKEN id="token-12-34" pos="word" morph="none" start_char="1640" end_char="1642">and</TOKEN>
<TOKEN id="token-12-35" pos="word" morph="none" start_char="1644" end_char="1644">a</TOKEN>
<TOKEN id="token-12-36" pos="word" morph="none" start_char="1646" end_char="1649">junk</TOKEN>
<TOKEN id="token-12-37" pos="word" morph="none" start_char="1651" end_char="1654">news</TOKEN>
<TOKEN id="token-12-38" pos="word" morph="none" start_char="1656" end_char="1662">article</TOKEN>
<TOKEN id="token-12-39" pos="word" morph="none" start_char="1664" end_char="1667">that</TOKEN>
<TOKEN id="token-12-40" pos="word" morph="none" start_char="1669" end_char="1675">falsely</TOKEN>
<TOKEN id="token-12-41" pos="word" morph="none" start_char="1677" end_char="1683">claimed</TOKEN>
<TOKEN id="token-12-42" pos="word" morph="none" start_char="1685" end_char="1690">Prince</TOKEN>
<TOKEN id="token-12-43" pos="word" morph="none" start_char="1692" end_char="1697">Andrew</TOKEN>
<TOKEN id="token-12-44" pos="word" morph="none" start_char="1699" end_char="1701">had</TOKEN>
<TOKEN id="token-12-45" pos="word" morph="none" start_char="1703" end_char="1711">committed</TOKEN>
<TOKEN id="token-12-46" pos="word" morph="none" start_char="1713" end_char="1719">suicide</TOKEN>
<TOKEN id="token-12-47" pos="punct" morph="none" start_char="1720" end_char="1720">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1723" end_char="1839">
<ORIGINAL_TEXT>This website has also previously spread misinformation about the coronavirus, or 2019-nCoV acute respiratory disease.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1723" end_char="1726">This</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1728" end_char="1734">website</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1736" end_char="1738">has</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1740" end_char="1743">also</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1745" end_char="1754">previously</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1756" end_char="1761">spread</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1763" end_char="1776">misinformation</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1778" end_char="1782">about</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1784" end_char="1786">the</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1788" end_char="1798">coronavirus</TOKEN>
<TOKEN id="token-13-10" pos="punct" morph="none" start_char="1799" end_char="1799">,</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1801" end_char="1802">or</TOKEN>
<TOKEN id="token-13-12" pos="unknown" morph="none" start_char="1804" end_char="1812">2019-nCoV</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1814" end_char="1818">acute</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1820" end_char="1830">respiratory</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1832" end_char="1838">disease</TOKEN>
<TOKEN id="token-13-16" pos="punct" morph="none" start_char="1839" end_char="1839">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1841" end_char="1896">
<ORIGINAL_TEXT>The government of Singapore released a statement on Jan.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1841" end_char="1843">The</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1845" end_char="1854">government</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1856" end_char="1857">of</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1859" end_char="1867">Singapore</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1869" end_char="1876">released</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1878" end_char="1878">a</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1880" end_char="1888">statement</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1890" end_char="1891">on</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1893" end_char="1895">Jan</TOKEN>
<TOKEN id="token-14-9" pos="punct" morph="none" start_char="1896" end_char="1896">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1898" end_char="1953">
<ORIGINAL_TEXT>30, 2020, to refute claims published in an AB-TC report:</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1898" end_char="1899">30</TOKEN>
<TOKEN id="token-15-1" pos="punct" morph="none" start_char="1900" end_char="1900">,</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1902" end_char="1905">2020</TOKEN>
<TOKEN id="token-15-3" pos="punct" morph="none" start_char="1906" end_char="1906">,</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1908" end_char="1909">to</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1911" end_char="1916">refute</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1918" end_char="1923">claims</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1925" end_char="1933">published</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1935" end_char="1936">in</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1938" end_char="1939">an</TOKEN>
<TOKEN id="token-15-10" pos="unknown" morph="none" start_char="1941" end_char="1945">AB-TC</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1947" end_char="1952">report</TOKEN>
<TOKEN id="token-15-12" pos="punct" morph="none" start_char="1953" end_char="1953">:</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1956" end_char="2338">
<ORIGINAL_TEXT>Corrections and clarifications regarding falsehoods published by AB-TC City News’ website On 30 Jan 2020, a website called ‘City News’ published an article titled "BREAKING NEWS: Singapore records six more coronavirus case, total of 16 now" (https://ab-tc.com/singapore-coronavirus-cases/) claiming that five Singaporeans have contracted the Wuhan coronavirus without going to China.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1956" end_char="1966">Corrections</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1968" end_char="1970">and</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1972" end_char="1985">clarifications</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1987" end_char="1995">regarding</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1997" end_char="2006">falsehoods</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="2008" end_char="2016">published</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="2018" end_char="2019">by</TOKEN>
<TOKEN id="token-16-7" pos="unknown" morph="none" start_char="2021" end_char="2025">AB-TC</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="2027" end_char="2030">City</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="2032" end_char="2035">News</TOKEN>
<TOKEN id="token-16-10" pos="punct" morph="none" start_char="2036" end_char="2036">’</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="2038" end_char="2044">website</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="2046" end_char="2047">On</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="2049" end_char="2050">30</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="2052" end_char="2054">Jan</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="2056" end_char="2059">2020</TOKEN>
<TOKEN id="token-16-16" pos="punct" morph="none" start_char="2060" end_char="2060">,</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="2062" end_char="2062">a</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="2064" end_char="2070">website</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="2072" end_char="2077">called</TOKEN>
<TOKEN id="token-16-20" pos="punct" morph="none" start_char="2079" end_char="2079">‘</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="2080" end_char="2083">City</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="2085" end_char="2088">News</TOKEN>
<TOKEN id="token-16-23" pos="punct" morph="none" start_char="2089" end_char="2089">’</TOKEN>
<TOKEN id="token-16-24" pos="word" morph="none" start_char="2091" end_char="2099">published</TOKEN>
<TOKEN id="token-16-25" pos="word" morph="none" start_char="2101" end_char="2102">an</TOKEN>
<TOKEN id="token-16-26" pos="word" morph="none" start_char="2104" end_char="2110">article</TOKEN>
<TOKEN id="token-16-27" pos="word" morph="none" start_char="2112" end_char="2117">titled</TOKEN>
<TOKEN id="token-16-28" pos="punct" morph="none" start_char="2119" end_char="2119">"</TOKEN>
<TOKEN id="token-16-29" pos="word" morph="none" start_char="2120" end_char="2127">BREAKING</TOKEN>
<TOKEN id="token-16-30" pos="word" morph="none" start_char="2129" end_char="2132">NEWS</TOKEN>
<TOKEN id="token-16-31" pos="punct" morph="none" start_char="2133" end_char="2133">:</TOKEN>
<TOKEN id="token-16-32" pos="word" morph="none" start_char="2135" end_char="2143">Singapore</TOKEN>
<TOKEN id="token-16-33" pos="word" morph="none" start_char="2145" end_char="2151">records</TOKEN>
<TOKEN id="token-16-34" pos="word" morph="none" start_char="2153" end_char="2155">six</TOKEN>
<TOKEN id="token-16-35" pos="word" morph="none" start_char="2157" end_char="2160">more</TOKEN>
<TOKEN id="token-16-36" pos="word" morph="none" start_char="2162" end_char="2172">coronavirus</TOKEN>
<TOKEN id="token-16-37" pos="word" morph="none" start_char="2174" end_char="2177">case</TOKEN>
<TOKEN id="token-16-38" pos="punct" morph="none" start_char="2178" end_char="2178">,</TOKEN>
<TOKEN id="token-16-39" pos="word" morph="none" start_char="2180" end_char="2184">total</TOKEN>
<TOKEN id="token-16-40" pos="word" morph="none" start_char="2186" end_char="2187">of</TOKEN>
<TOKEN id="token-16-41" pos="word" morph="none" start_char="2189" end_char="2190">16</TOKEN>
<TOKEN id="token-16-42" pos="word" morph="none" start_char="2192" end_char="2194">now</TOKEN>
<TOKEN id="token-16-43" pos="punct" morph="none" start_char="2195" end_char="2195">"</TOKEN>
<TOKEN id="token-16-44" pos="punct" morph="none" start_char="2197" end_char="2197">(</TOKEN>
<TOKEN id="token-16-45" pos="unknown" morph="none" start_char="2198" end_char="2242">https://ab-tc.com/singapore-coronavirus-cases</TOKEN>
<TOKEN id="token-16-46" pos="punct" morph="none" start_char="2243" end_char="2244">/)</TOKEN>
<TOKEN id="token-16-47" pos="word" morph="none" start_char="2246" end_char="2253">claiming</TOKEN>
<TOKEN id="token-16-48" pos="word" morph="none" start_char="2255" end_char="2258">that</TOKEN>
<TOKEN id="token-16-49" pos="word" morph="none" start_char="2260" end_char="2263">five</TOKEN>
<TOKEN id="token-16-50" pos="word" morph="none" start_char="2265" end_char="2276">Singaporeans</TOKEN>
<TOKEN id="token-16-51" pos="word" morph="none" start_char="2278" end_char="2281">have</TOKEN>
<TOKEN id="token-16-52" pos="word" morph="none" start_char="2283" end_char="2292">contracted</TOKEN>
<TOKEN id="token-16-53" pos="word" morph="none" start_char="2294" end_char="2296">the</TOKEN>
<TOKEN id="token-16-54" pos="word" morph="none" start_char="2298" end_char="2302">Wuhan</TOKEN>
<TOKEN id="token-16-55" pos="word" morph="none" start_char="2304" end_char="2314">coronavirus</TOKEN>
<TOKEN id="token-16-56" pos="word" morph="none" start_char="2316" end_char="2322">without</TOKEN>
<TOKEN id="token-16-57" pos="word" morph="none" start_char="2324" end_char="2328">going</TOKEN>
<TOKEN id="token-16-58" pos="word" morph="none" start_char="2330" end_char="2331">to</TOKEN>
<TOKEN id="token-16-59" pos="word" morph="none" start_char="2333" end_char="2337">China</TOKEN>
<TOKEN id="token-16-60" pos="punct" morph="none" start_char="2338" end_char="2338">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2340" end_char="2428">
<ORIGINAL_TEXT>As of 9pm on 30 Jan 2020, there is no local transmission of the Wuhan virus in Singapore.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2340" end_char="2341">As</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2343" end_char="2344">of</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2346" end_char="2348">9pm</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2350" end_char="2351">on</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2353" end_char="2354">30</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2356" end_char="2358">Jan</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2360" end_char="2363">2020</TOKEN>
<TOKEN id="token-17-7" pos="punct" morph="none" start_char="2364" end_char="2364">,</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2366" end_char="2370">there</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2372" end_char="2373">is</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2375" end_char="2376">no</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2378" end_char="2382">local</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2384" end_char="2395">transmission</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2397" end_char="2398">of</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2400" end_char="2402">the</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2404" end_char="2408">Wuhan</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="2410" end_char="2414">virus</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="2416" end_char="2417">in</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="2419" end_char="2427">Singapore</TOKEN>
<TOKEN id="token-17-19" pos="punct" morph="none" start_char="2428" end_char="2428">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2430" end_char="2517">
<ORIGINAL_TEXT>All confirmed cases in Singapore to date are Chinese nationals who travelled from Wuhan.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2430" end_char="2432">All</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2434" end_char="2442">confirmed</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2444" end_char="2448">cases</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2450" end_char="2451">in</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2453" end_char="2461">Singapore</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2463" end_char="2464">to</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2466" end_char="2469">date</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2471" end_char="2473">are</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2475" end_char="2481">Chinese</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="2483" end_char="2491">nationals</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="2493" end_char="2495">who</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="2497" end_char="2505">travelled</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2507" end_char="2510">from</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="2512" end_char="2516">Wuhan</TOKEN>
<TOKEN id="token-18-14" pos="punct" morph="none" start_char="2517" end_char="2517">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2521" end_char="2596">
<ORIGINAL_TEXT>None of the AB-TC articles we examined was accompanied by a person’s byline.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2521" end_char="2524">None</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2526" end_char="2527">of</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2529" end_char="2531">the</TOKEN>
<TOKEN id="token-19-3" pos="unknown" morph="none" start_char="2533" end_char="2537">AB-TC</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2539" end_char="2546">articles</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2548" end_char="2549">we</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2551" end_char="2558">examined</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2560" end_char="2562">was</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2564" end_char="2574">accompanied</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="2576" end_char="2577">by</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="2579" end_char="2579">a</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="2581" end_char="2588">person’s</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="2590" end_char="2595">byline</TOKEN>
<TOKEN id="token-19-13" pos="punct" morph="none" start_char="2596" end_char="2596">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2598" end_char="2663">
<ORIGINAL_TEXT>Rather, they were all written by so-called "local correspondents."</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2598" end_char="2603">Rather</TOKEN>
<TOKEN id="token-20-1" pos="punct" morph="none" start_char="2604" end_char="2604">,</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2606" end_char="2609">they</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2611" end_char="2614">were</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2616" end_char="2618">all</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2620" end_char="2626">written</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2628" end_char="2629">by</TOKEN>
<TOKEN id="token-20-7" pos="unknown" morph="none" start_char="2631" end_char="2639">so-called</TOKEN>
<TOKEN id="token-20-8" pos="punct" morph="none" start_char="2641" end_char="2641">"</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2642" end_char="2646">local</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2648" end_char="2661">correspondents</TOKEN>
<TOKEN id="token-20-11" pos="punct" morph="none" start_char="2662" end_char="2663">."</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2666" end_char="2762">
<ORIGINAL_TEXT>In other words, this website doesn’t exactly have a great track record of genuine news reporting.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2666" end_char="2667">In</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2669" end_char="2673">other</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2675" end_char="2679">words</TOKEN>
<TOKEN id="token-21-3" pos="punct" morph="none" start_char="2680" end_char="2680">,</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2682" end_char="2685">this</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="2687" end_char="2693">website</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2695" end_char="2701">doesn’t</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="2703" end_char="2709">exactly</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="2711" end_char="2714">have</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="2716" end_char="2716">a</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="2718" end_char="2722">great</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="2724" end_char="2728">track</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="2730" end_char="2735">record</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="2737" end_char="2738">of</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="2740" end_char="2746">genuine</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="2748" end_char="2751">news</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="2753" end_char="2761">reporting</TOKEN>
<TOKEN id="token-21-17" pos="punct" morph="none" start_char="2762" end_char="2762">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2765" end_char="2915">
<ORIGINAL_TEXT>In addition to its history of pushing misinformation, there are also a few red flags in AB-TC’s article about the mass killing of coronavirus patients.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2765" end_char="2766">In</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2768" end_char="2775">addition</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2777" end_char="2778">to</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2780" end_char="2782">its</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2784" end_char="2790">history</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2792" end_char="2793">of</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2795" end_char="2801">pushing</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2803" end_char="2816">misinformation</TOKEN>
<TOKEN id="token-22-8" pos="punct" morph="none" start_char="2817" end_char="2817">,</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="2819" end_char="2823">there</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="2825" end_char="2827">are</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="2829" end_char="2832">also</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="2834" end_char="2834">a</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="2836" end_char="2838">few</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="2840" end_char="2842">red</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="2844" end_char="2848">flags</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="2850" end_char="2851">in</TOKEN>
<TOKEN id="token-22-17" pos="unknown" morph="none" start_char="2853" end_char="2859">AB-TC’s</TOKEN>
<TOKEN id="token-22-18" pos="word" morph="none" start_char="2861" end_char="2867">article</TOKEN>
<TOKEN id="token-22-19" pos="word" morph="none" start_char="2869" end_char="2873">about</TOKEN>
<TOKEN id="token-22-20" pos="word" morph="none" start_char="2875" end_char="2877">the</TOKEN>
<TOKEN id="token-22-21" pos="word" morph="none" start_char="2879" end_char="2882">mass</TOKEN>
<TOKEN id="token-22-22" pos="word" morph="none" start_char="2884" end_char="2890">killing</TOKEN>
<TOKEN id="token-22-23" pos="word" morph="none" start_char="2892" end_char="2893">of</TOKEN>
<TOKEN id="token-22-24" pos="word" morph="none" start_char="2895" end_char="2905">coronavirus</TOKEN>
<TOKEN id="token-22-25" pos="word" morph="none" start_char="2907" end_char="2914">patients</TOKEN>
<TOKEN id="token-22-26" pos="punct" morph="none" start_char="2915" end_char="2915">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2917" end_char="3038">
<ORIGINAL_TEXT>For instance, like most of the other articles on this website, this article contains no links back to supporting evidence.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2917" end_char="2919">For</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2921" end_char="2928">instance</TOKEN>
<TOKEN id="token-23-2" pos="punct" morph="none" start_char="2929" end_char="2929">,</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2931" end_char="2934">like</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="2936" end_char="2939">most</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="2941" end_char="2942">of</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="2944" end_char="2946">the</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="2948" end_char="2952">other</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="2954" end_char="2961">articles</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="2963" end_char="2964">on</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="2966" end_char="2969">this</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="2971" end_char="2977">website</TOKEN>
<TOKEN id="token-23-12" pos="punct" morph="none" start_char="2978" end_char="2978">,</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="2980" end_char="2983">this</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="2985" end_char="2991">article</TOKEN>
<TOKEN id="token-23-15" pos="word" morph="none" start_char="2993" end_char="3000">contains</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="3002" end_char="3003">no</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="3005" end_char="3009">links</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="3011" end_char="3014">back</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="3016" end_char="3017">to</TOKEN>
<TOKEN id="token-23-20" pos="word" morph="none" start_char="3019" end_char="3028">supporting</TOKEN>
<TOKEN id="token-23-21" pos="word" morph="none" start_char="3030" end_char="3037">evidence</TOKEN>
<TOKEN id="token-23-22" pos="punct" morph="none" start_char="3038" end_char="3038">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="3040" end_char="3214">
<ORIGINAL_TEXT>Even when the article mentions secondary sources, such as a "document" or a "press conference," they provide no evidence to show that these items actually exist or took place.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="3040" end_char="3043">Even</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="3045" end_char="3048">when</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="3050" end_char="3052">the</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="3054" end_char="3060">article</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="3062" end_char="3069">mentions</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="3071" end_char="3079">secondary</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="3081" end_char="3087">sources</TOKEN>
<TOKEN id="token-24-7" pos="punct" morph="none" start_char="3088" end_char="3088">,</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="3090" end_char="3093">such</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="3095" end_char="3096">as</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="3098" end_char="3098">a</TOKEN>
<TOKEN id="token-24-11" pos="punct" morph="none" start_char="3100" end_char="3100">"</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="3101" end_char="3108">document</TOKEN>
<TOKEN id="token-24-13" pos="punct" morph="none" start_char="3109" end_char="3109">"</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="3111" end_char="3112">or</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="3114" end_char="3114">a</TOKEN>
<TOKEN id="token-24-16" pos="punct" morph="none" start_char="3116" end_char="3116">"</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="3117" end_char="3121">press</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="3123" end_char="3132">conference</TOKEN>
<TOKEN id="token-24-19" pos="punct" morph="none" start_char="3133" end_char="3134">,"</TOKEN>
<TOKEN id="token-24-20" pos="word" morph="none" start_char="3136" end_char="3139">they</TOKEN>
<TOKEN id="token-24-21" pos="word" morph="none" start_char="3141" end_char="3147">provide</TOKEN>
<TOKEN id="token-24-22" pos="word" morph="none" start_char="3149" end_char="3150">no</TOKEN>
<TOKEN id="token-24-23" pos="word" morph="none" start_char="3152" end_char="3159">evidence</TOKEN>
<TOKEN id="token-24-24" pos="word" morph="none" start_char="3161" end_char="3162">to</TOKEN>
<TOKEN id="token-24-25" pos="word" morph="none" start_char="3164" end_char="3167">show</TOKEN>
<TOKEN id="token-24-26" pos="word" morph="none" start_char="3169" end_char="3172">that</TOKEN>
<TOKEN id="token-24-27" pos="word" morph="none" start_char="3174" end_char="3178">these</TOKEN>
<TOKEN id="token-24-28" pos="word" morph="none" start_char="3180" end_char="3184">items</TOKEN>
<TOKEN id="token-24-29" pos="word" morph="none" start_char="3186" end_char="3193">actually</TOKEN>
<TOKEN id="token-24-30" pos="word" morph="none" start_char="3195" end_char="3199">exist</TOKEN>
<TOKEN id="token-24-31" pos="word" morph="none" start_char="3201" end_char="3202">or</TOKEN>
<TOKEN id="token-24-32" pos="word" morph="none" start_char="3204" end_char="3207">took</TOKEN>
<TOKEN id="token-24-33" pos="word" morph="none" start_char="3209" end_char="3213">place</TOKEN>
<TOKEN id="token-24-34" pos="punct" morph="none" start_char="3214" end_char="3214">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="3216" end_char="3266">
<ORIGINAL_TEXT>The article is also suspiciously void of specifics.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="3216" end_char="3218">The</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="3220" end_char="3226">article</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="3228" end_char="3229">is</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="3231" end_char="3234">also</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="3236" end_char="3247">suspiciously</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="3249" end_char="3252">void</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="3254" end_char="3255">of</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="3257" end_char="3265">specifics</TOKEN>
<TOKEN id="token-25-8" pos="punct" morph="none" start_char="3266" end_char="3266">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="3268" end_char="3409">
<ORIGINAL_TEXT>AB-TC reports that "the state" or "the court" or an "official" made a statement, but doesn’t provide any direct quotes or names in its report.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="unknown" morph="none" start_char="3268" end_char="3272">AB-TC</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="3274" end_char="3280">reports</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="3282" end_char="3285">that</TOKEN>
<TOKEN id="token-26-3" pos="punct" morph="none" start_char="3287" end_char="3287">"</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="3288" end_char="3290">the</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="3292" end_char="3296">state</TOKEN>
<TOKEN id="token-26-6" pos="punct" morph="none" start_char="3297" end_char="3297">"</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="3299" end_char="3300">or</TOKEN>
<TOKEN id="token-26-8" pos="punct" morph="none" start_char="3302" end_char="3302">"</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="3303" end_char="3305">the</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="3307" end_char="3311">court</TOKEN>
<TOKEN id="token-26-11" pos="punct" morph="none" start_char="3312" end_char="3312">"</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="3314" end_char="3315">or</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="3317" end_char="3318">an</TOKEN>
<TOKEN id="token-26-14" pos="punct" morph="none" start_char="3320" end_char="3320">"</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="3321" end_char="3328">official</TOKEN>
<TOKEN id="token-26-16" pos="punct" morph="none" start_char="3329" end_char="3329">"</TOKEN>
<TOKEN id="token-26-17" pos="word" morph="none" start_char="3331" end_char="3334">made</TOKEN>
<TOKEN id="token-26-18" pos="word" morph="none" start_char="3336" end_char="3336">a</TOKEN>
<TOKEN id="token-26-19" pos="word" morph="none" start_char="3338" end_char="3346">statement</TOKEN>
<TOKEN id="token-26-20" pos="punct" morph="none" start_char="3347" end_char="3347">,</TOKEN>
<TOKEN id="token-26-21" pos="word" morph="none" start_char="3349" end_char="3351">but</TOKEN>
<TOKEN id="token-26-22" pos="word" morph="none" start_char="3353" end_char="3359">doesn’t</TOKEN>
<TOKEN id="token-26-23" pos="word" morph="none" start_char="3361" end_char="3367">provide</TOKEN>
<TOKEN id="token-26-24" pos="word" morph="none" start_char="3369" end_char="3371">any</TOKEN>
<TOKEN id="token-26-25" pos="word" morph="none" start_char="3373" end_char="3378">direct</TOKEN>
<TOKEN id="token-26-26" pos="word" morph="none" start_char="3380" end_char="3385">quotes</TOKEN>
<TOKEN id="token-26-27" pos="word" morph="none" start_char="3387" end_char="3388">or</TOKEN>
<TOKEN id="token-26-28" pos="word" morph="none" start_char="3390" end_char="3394">names</TOKEN>
<TOKEN id="token-26-29" pos="word" morph="none" start_char="3396" end_char="3397">in</TOKEN>
<TOKEN id="token-26-30" pos="word" morph="none" start_char="3399" end_char="3401">its</TOKEN>
<TOKEN id="token-26-31" pos="word" morph="none" start_char="3403" end_char="3408">report</TOKEN>
<TOKEN id="token-26-32" pos="punct" morph="none" start_char="3409" end_char="3409">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="3412" end_char="3489">
<ORIGINAL_TEXT>Lastly, no credible news outlets have published reports containing this claim.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="3412" end_char="3417">Lastly</TOKEN>
<TOKEN id="token-27-1" pos="punct" morph="none" start_char="3418" end_char="3418">,</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="3420" end_char="3421">no</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="3423" end_char="3430">credible</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="3432" end_char="3435">news</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="3437" end_char="3443">outlets</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="3445" end_char="3448">have</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="3450" end_char="3458">published</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="3460" end_char="3466">reports</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="3468" end_char="3477">containing</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="3479" end_char="3482">this</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="3484" end_char="3488">claim</TOKEN>
<TOKEN id="token-27-12" pos="punct" morph="none" start_char="3489" end_char="3489">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3491" end_char="3525">
<ORIGINAL_TEXT>The New York Times reported on Feb.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="3491" end_char="3493">The</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="3495" end_char="3497">New</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="3499" end_char="3502">York</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="3504" end_char="3508">Times</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="3510" end_char="3517">reported</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="3519" end_char="3520">on</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="3522" end_char="3524">Feb</TOKEN>
<TOKEN id="token-28-7" pos="punct" morph="none" start_char="3525" end_char="3525">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3527" end_char="3760">
<ORIGINAL_TEXT>6, 2020, that a senior official in China "ordered the authorities in the city of Wuhan to immediately round up all residents who have been infected with the coronavirus and place them in isolation, quarantine or designated hospitals."</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="3527" end_char="3527">6</TOKEN>
<TOKEN id="token-29-1" pos="punct" morph="none" start_char="3528" end_char="3528">,</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="3530" end_char="3533">2020</TOKEN>
<TOKEN id="token-29-3" pos="punct" morph="none" start_char="3534" end_char="3534">,</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="3536" end_char="3539">that</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="3541" end_char="3541">a</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="3543" end_char="3548">senior</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="3550" end_char="3557">official</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="3559" end_char="3560">in</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="3562" end_char="3566">China</TOKEN>
<TOKEN id="token-29-10" pos="punct" morph="none" start_char="3568" end_char="3568">"</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="3569" end_char="3575">ordered</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="3577" end_char="3579">the</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="3581" end_char="3591">authorities</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="3593" end_char="3594">in</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="3596" end_char="3598">the</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="3600" end_char="3603">city</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="3605" end_char="3606">of</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="3608" end_char="3612">Wuhan</TOKEN>
<TOKEN id="token-29-19" pos="word" morph="none" start_char="3614" end_char="3615">to</TOKEN>
<TOKEN id="token-29-20" pos="word" morph="none" start_char="3617" end_char="3627">immediately</TOKEN>
<TOKEN id="token-29-21" pos="word" morph="none" start_char="3629" end_char="3633">round</TOKEN>
<TOKEN id="token-29-22" pos="word" morph="none" start_char="3635" end_char="3636">up</TOKEN>
<TOKEN id="token-29-23" pos="word" morph="none" start_char="3638" end_char="3640">all</TOKEN>
<TOKEN id="token-29-24" pos="word" morph="none" start_char="3642" end_char="3650">residents</TOKEN>
<TOKEN id="token-29-25" pos="word" morph="none" start_char="3652" end_char="3654">who</TOKEN>
<TOKEN id="token-29-26" pos="word" morph="none" start_char="3656" end_char="3659">have</TOKEN>
<TOKEN id="token-29-27" pos="word" morph="none" start_char="3661" end_char="3664">been</TOKEN>
<TOKEN id="token-29-28" pos="word" morph="none" start_char="3666" end_char="3673">infected</TOKEN>
<TOKEN id="token-29-29" pos="word" morph="none" start_char="3675" end_char="3678">with</TOKEN>
<TOKEN id="token-29-30" pos="word" morph="none" start_char="3680" end_char="3682">the</TOKEN>
<TOKEN id="token-29-31" pos="word" morph="none" start_char="3684" end_char="3694">coronavirus</TOKEN>
<TOKEN id="token-29-32" pos="word" morph="none" start_char="3696" end_char="3698">and</TOKEN>
<TOKEN id="token-29-33" pos="word" morph="none" start_char="3700" end_char="3704">place</TOKEN>
<TOKEN id="token-29-34" pos="word" morph="none" start_char="3706" end_char="3709">them</TOKEN>
<TOKEN id="token-29-35" pos="word" morph="none" start_char="3711" end_char="3712">in</TOKEN>
<TOKEN id="token-29-36" pos="word" morph="none" start_char="3714" end_char="3722">isolation</TOKEN>
<TOKEN id="token-29-37" pos="punct" morph="none" start_char="3723" end_char="3723">,</TOKEN>
<TOKEN id="token-29-38" pos="word" morph="none" start_char="3725" end_char="3734">quarantine</TOKEN>
<TOKEN id="token-29-39" pos="word" morph="none" start_char="3736" end_char="3737">or</TOKEN>
<TOKEN id="token-29-40" pos="word" morph="none" start_char="3739" end_char="3748">designated</TOKEN>
<TOKEN id="token-29-41" pos="word" morph="none" start_char="3750" end_char="3758">hospitals</TOKEN>
<TOKEN id="token-29-42" pos="punct" morph="none" start_char="3759" end_char="3760">."</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3762" end_char="3820">
<ORIGINAL_TEXT>That report, of course, made no mention of "mass killings."</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="3762" end_char="3765">That</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="3767" end_char="3772">report</TOKEN>
<TOKEN id="token-30-2" pos="punct" morph="none" start_char="3773" end_char="3773">,</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="3775" end_char="3776">of</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="3778" end_char="3783">course</TOKEN>
<TOKEN id="token-30-5" pos="punct" morph="none" start_char="3784" end_char="3784">,</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="3786" end_char="3789">made</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="3791" end_char="3792">no</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="3794" end_char="3800">mention</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="3802" end_char="3803">of</TOKEN>
<TOKEN id="token-30-10" pos="punct" morph="none" start_char="3805" end_char="3805">"</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="3806" end_char="3809">mass</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="3811" end_char="3818">killings</TOKEN>
<TOKEN id="token-30-13" pos="punct" morph="none" start_char="3819" end_char="3820">."</TOKEN>
</SEG>
<SEG id="segment-31" start_char="3823" end_char="3951">
<ORIGINAL_TEXT>There is also no mention of this supposed court case on the The Supreme People’s Court of the People’s Republic of China website.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="3823" end_char="3827">There</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="3829" end_char="3830">is</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="3832" end_char="3835">also</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="3837" end_char="3838">no</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="3840" end_char="3846">mention</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="3848" end_char="3849">of</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="3851" end_char="3854">this</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="3856" end_char="3863">supposed</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="3865" end_char="3869">court</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="3871" end_char="3874">case</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="3876" end_char="3877">on</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="3879" end_char="3881">the</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="3883" end_char="3885">The</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="3887" end_char="3893">Supreme</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="3895" end_char="3902">People’s</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="3904" end_char="3908">Court</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="3910" end_char="3911">of</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="3913" end_char="3915">the</TOKEN>
<TOKEN id="token-31-18" pos="word" morph="none" start_char="3917" end_char="3924">People’s</TOKEN>
<TOKEN id="token-31-19" pos="word" morph="none" start_char="3926" end_char="3933">Republic</TOKEN>
<TOKEN id="token-31-20" pos="word" morph="none" start_char="3935" end_char="3936">of</TOKEN>
<TOKEN id="token-31-21" pos="word" morph="none" start_char="3938" end_char="3942">China</TOKEN>
<TOKEN id="token-31-22" pos="word" morph="none" start_char="3944" end_char="3950">website</TOKEN>
<TOKEN id="token-31-23" pos="punct" morph="none" start_char="3951" end_char="3951">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="3954" end_char="3992">
<ORIGINAL_TEXT>AB-TC is the sole source of this rumor.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="unknown" morph="none" start_char="3954" end_char="3958">AB-TC</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="3960" end_char="3961">is</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="3963" end_char="3965">the</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="3967" end_char="3970">sole</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="3972" end_char="3977">source</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="3979" end_char="3980">of</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="3982" end_char="3985">this</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="3987" end_char="3991">rumor</TOKEN>
<TOKEN id="token-32-8" pos="punct" morph="none" start_char="3992" end_char="3992">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="3994" end_char="4057">
<ORIGINAL_TEXT>However, this website provided no evidence to support its claim.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="3994" end_char="4000">However</TOKEN>
<TOKEN id="token-33-1" pos="punct" morph="none" start_char="4001" end_char="4001">,</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="4003" end_char="4006">this</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="4008" end_char="4014">website</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="4016" end_char="4023">provided</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="4025" end_char="4026">no</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="4028" end_char="4035">evidence</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="4037" end_char="4038">to</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="4040" end_char="4046">support</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="4048" end_char="4050">its</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="4052" end_char="4056">claim</TOKEN>
<TOKEN id="token-33-11" pos="punct" morph="none" start_char="4057" end_char="4057">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="4059" end_char="4118">
<ORIGINAL_TEXT>This website also has a history of spreading misinformation.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="4059" end_char="4062">This</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="4064" end_char="4070">website</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="4072" end_char="4075">also</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="4077" end_char="4079">has</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="4081" end_char="4081">a</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="4083" end_char="4089">history</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="4091" end_char="4092">of</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="4094" end_char="4102">spreading</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="4104" end_char="4117">misinformation</TOKEN>
<TOKEN id="token-34-9" pos="punct" morph="none" start_char="4118" end_char="4118">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="4120" end_char="4235">
<ORIGINAL_TEXT>As this claim is not supported by any other credible news reports, we’ve concluded that this report is indeed false.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="4120" end_char="4121">As</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="4123" end_char="4126">this</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="4128" end_char="4132">claim</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="4134" end_char="4135">is</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="4137" end_char="4139">not</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="4141" end_char="4149">supported</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="4151" end_char="4152">by</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="4154" end_char="4156">any</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="4158" end_char="4162">other</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="4164" end_char="4171">credible</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="4173" end_char="4176">news</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="4178" end_char="4184">reports</TOKEN>
<TOKEN id="token-35-12" pos="punct" morph="none" start_char="4185" end_char="4185">,</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="4187" end_char="4191">we’ve</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="4193" end_char="4201">concluded</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="4203" end_char="4206">that</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="4208" end_char="4211">this</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="4213" end_char="4218">report</TOKEN>
<TOKEN id="token-35-18" pos="word" morph="none" start_char="4220" end_char="4221">is</TOKEN>
<TOKEN id="token-35-19" pos="word" morph="none" start_char="4223" end_char="4228">indeed</TOKEN>
<TOKEN id="token-35-20" pos="word" morph="none" start_char="4230" end_char="4234">false</TOKEN>
<TOKEN id="token-35-21" pos="punct" morph="none" start_char="4235" end_char="4235">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
