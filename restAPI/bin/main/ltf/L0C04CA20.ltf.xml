<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CA20" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="7116" raw_text_md5="40ec3ade432c63dfafe002eb79e9baac">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="79">
<ORIGINAL_TEXT>WHO investigation uncovers potential evidence of earlier than known 2019 spread</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="3">WHO</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="5" end_char="17">investigation</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="19" end_char="26">uncovers</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="28" end_char="36">potential</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="38" end_char="45">evidence</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="47" end_char="48">of</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="50" end_char="56">earlier</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="58" end_char="61">than</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="63" end_char="67">known</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="69" end_char="72">2019</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="74" end_char="79">spread</TOKEN>
</SEG>
<SEG id="segment-1" start_char="84" end_char="316">
<ORIGINAL_TEXT>There have been rumors and speculation for over a year: Just when did COVID-19 actually begin.. if you remember back to the early days of the pandemic lockdowns, many reported feeling sicker than normal in November and December 2019.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="84" end_char="88">There</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="90" end_char="93">have</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="95" end_char="98">been</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="100" end_char="105">rumors</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="107" end_char="109">and</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="111" end_char="121">speculation</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="123" end_char="125">for</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="127" end_char="130">over</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="132" end_char="132">a</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="134" end_char="137">year</TOKEN>
<TOKEN id="token-1-10" pos="punct" morph="none" start_char="138" end_char="138">:</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="140" end_char="143">Just</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="145" end_char="148">when</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="150" end_char="152">did</TOKEN>
<TOKEN id="token-1-14" pos="unknown" morph="none" start_char="154" end_char="161">COVID-19</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="163" end_char="170">actually</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="172" end_char="176">begin</TOKEN>
<TOKEN id="token-1-17" pos="punct" morph="none" start_char="177" end_char="178">..</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="180" end_char="181">if</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="183" end_char="185">you</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="187" end_char="194">remember</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="196" end_char="199">back</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="201" end_char="202">to</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="204" end_char="206">the</TOKEN>
<TOKEN id="token-1-24" pos="word" morph="none" start_char="208" end_char="212">early</TOKEN>
<TOKEN id="token-1-25" pos="word" morph="none" start_char="214" end_char="217">days</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="219" end_char="220">of</TOKEN>
<TOKEN id="token-1-27" pos="word" morph="none" start_char="222" end_char="224">the</TOKEN>
<TOKEN id="token-1-28" pos="word" morph="none" start_char="226" end_char="233">pandemic</TOKEN>
<TOKEN id="token-1-29" pos="word" morph="none" start_char="235" end_char="243">lockdowns</TOKEN>
<TOKEN id="token-1-30" pos="punct" morph="none" start_char="244" end_char="244">,</TOKEN>
<TOKEN id="token-1-31" pos="word" morph="none" start_char="246" end_char="249">many</TOKEN>
<TOKEN id="token-1-32" pos="word" morph="none" start_char="251" end_char="258">reported</TOKEN>
<TOKEN id="token-1-33" pos="word" morph="none" start_char="260" end_char="266">feeling</TOKEN>
<TOKEN id="token-1-34" pos="word" morph="none" start_char="268" end_char="273">sicker</TOKEN>
<TOKEN id="token-1-35" pos="word" morph="none" start_char="275" end_char="278">than</TOKEN>
<TOKEN id="token-1-36" pos="word" morph="none" start_char="280" end_char="285">normal</TOKEN>
<TOKEN id="token-1-37" pos="word" morph="none" start_char="287" end_char="288">in</TOKEN>
<TOKEN id="token-1-38" pos="word" morph="none" start_char="290" end_char="297">November</TOKEN>
<TOKEN id="token-1-39" pos="word" morph="none" start_char="299" end_char="301">and</TOKEN>
<TOKEN id="token-1-40" pos="word" morph="none" start_char="303" end_char="310">December</TOKEN>
<TOKEN id="token-1-41" pos="word" morph="none" start_char="312" end_char="315">2019</TOKEN>
<TOKEN id="token-1-42" pos="punct" morph="none" start_char="316" end_char="316">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="318" end_char="482">
<ORIGINAL_TEXT>Italy had various reports of strange lung diseases in the autumn of 2019.. and a nursing home in the United States had a not so average outbreak in the late summer..</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="318" end_char="322">Italy</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="324" end_char="326">had</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="328" end_char="334">various</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="336" end_char="342">reports</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="344" end_char="345">of</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="347" end_char="353">strange</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="355" end_char="358">lung</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="360" end_char="367">diseases</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="369" end_char="370">in</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="372" end_char="374">the</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="376" end_char="381">autumn</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="383" end_char="384">of</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="386" end_char="389">2019</TOKEN>
<TOKEN id="token-2-13" pos="punct" morph="none" start_char="390" end_char="391">..</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="393" end_char="395">and</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="397" end_char="397">a</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="399" end_char="405">nursing</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="407" end_char="410">home</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="412" end_char="413">in</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="415" end_char="417">the</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="419" end_char="424">United</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="426" end_char="431">States</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="433" end_char="435">had</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="437" end_char="437">a</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="439" end_char="441">not</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="443" end_char="444">so</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="446" end_char="452">average</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="454" end_char="461">outbreak</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="463" end_char="464">in</TOKEN>
<TOKEN id="token-2-29" pos="word" morph="none" start_char="466" end_char="468">the</TOKEN>
<TOKEN id="token-2-30" pos="word" morph="none" start_char="470" end_char="473">late</TOKEN>
<TOKEN id="token-2-31" pos="word" morph="none" start_char="475" end_char="480">summer</TOKEN>
<TOKEN id="token-2-32" pos="punct" morph="none" start_char="481" end_char="482">..</TOKEN>
</SEG>
<SEG id="segment-3" start_char="485" end_char="589">
<ORIGINAL_TEXT>Speculation and rumor aside, fact finders are now on the case of just when–and where–did COVID come from.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="485" end_char="495">Speculation</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="497" end_char="499">and</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="501" end_char="505">rumor</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="507" end_char="511">aside</TOKEN>
<TOKEN id="token-3-4" pos="punct" morph="none" start_char="512" end_char="512">,</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="514" end_char="517">fact</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="519" end_char="525">finders</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="527" end_char="529">are</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="531" end_char="533">now</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="535" end_char="536">on</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="538" end_char="540">the</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="542" end_char="545">case</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="547" end_char="548">of</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="550" end_char="553">just</TOKEN>
<TOKEN id="token-3-14" pos="unknown" morph="none" start_char="555" end_char="562">when–and</TOKEN>
<TOKEN id="token-3-15" pos="unknown" morph="none" start_char="564" end_char="572">where–did</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="574" end_char="578">COVID</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="580" end_char="583">come</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="585" end_char="588">from</TOKEN>
<TOKEN id="token-3-19" pos="punct" morph="none" start_char="589" end_char="589">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="592" end_char="754">
<ORIGINAL_TEXT>A growing body of evidence suggests the coronavirus was spreading globally months before the first cases in a Wuhan market captured global attention last December.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="592" end_char="592">A</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="594" end_char="600">growing</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="602" end_char="605">body</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="607" end_char="608">of</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="610" end_char="617">evidence</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="619" end_char="626">suggests</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="628" end_char="630">the</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="632" end_char="642">coronavirus</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="644" end_char="646">was</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="648" end_char="656">spreading</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="658" end_char="665">globally</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="667" end_char="672">months</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="674" end_char="679">before</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="681" end_char="683">the</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="685" end_char="689">first</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="691" end_char="695">cases</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="697" end_char="698">in</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="700" end_char="700">a</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="702" end_char="706">Wuhan</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="708" end_char="713">market</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="715" end_char="722">captured</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="724" end_char="729">global</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="731" end_char="739">attention</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="741" end_char="744">last</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="746" end_char="753">December</TOKEN>
<TOKEN id="token-4-25" pos="punct" morph="none" start_char="754" end_char="754">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="756" end_char="898">
<ORIGINAL_TEXT>The World Health Organization sent an international team to China in January to investigate the virus’ origins and when it started circulating.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="756" end_char="758">The</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="760" end_char="764">World</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="766" end_char="771">Health</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="773" end_char="784">Organization</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="786" end_char="789">sent</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="791" end_char="792">an</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="794" end_char="806">international</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="808" end_char="811">team</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="813" end_char="814">to</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="816" end_char="820">China</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="822" end_char="823">in</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="825" end_char="831">January</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="833" end_char="834">to</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="836" end_char="846">investigate</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="848" end_char="850">the</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="852" end_char="856">virus</TOKEN>
<TOKEN id="token-5-16" pos="punct" morph="none" start_char="857" end_char="857">’</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="859" end_char="865">origins</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="867" end_char="869">and</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="871" end_char="874">when</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="876" end_char="877">it</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="879" end_char="885">started</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="887" end_char="897">circulating</TOKEN>
<TOKEN id="token-5-23" pos="punct" morph="none" start_char="898" end_char="898">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="900" end_char="1031">
<ORIGINAL_TEXT>The team assessed medical records from more than 230 clinics across Hubei — the province where Wuhan is located — to look for clues.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="900" end_char="902">The</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="904" end_char="907">team</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="909" end_char="916">assessed</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="918" end_char="924">medical</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="926" end_char="932">records</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="934" end_char="937">from</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="939" end_char="942">more</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="944" end_char="947">than</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="949" end_char="951">230</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="953" end_char="959">clinics</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="961" end_char="966">across</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="968" end_char="972">Hubei</TOKEN>
<TOKEN id="token-6-12" pos="punct" morph="none" start_char="974" end_char="974">—</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="976" end_char="978">the</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="980" end_char="987">province</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="989" end_char="993">where</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="995" end_char="999">Wuhan</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="1001" end_char="1002">is</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="1004" end_char="1010">located</TOKEN>
<TOKEN id="token-6-19" pos="punct" morph="none" start_char="1012" end_char="1012">—</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="1014" end_char="1015">to</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="1017" end_char="1020">look</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="1022" end_char="1024">for</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="1026" end_char="1030">clues</TOKEN>
<TOKEN id="token-6-24" pos="punct" morph="none" start_char="1031" end_char="1031">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="1033" end_char="1205">
<ORIGINAL_TEXT>More than 90 patients in the province were hospitalized with pneumonia or coronavirus-like symptoms in October and November 2019, the Wall Street Journal reported Wednesday.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="1033" end_char="1036">More</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="1038" end_char="1041">than</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="1043" end_char="1044">90</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="1046" end_char="1053">patients</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="1055" end_char="1056">in</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="1058" end_char="1060">the</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="1062" end_char="1069">province</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="1071" end_char="1074">were</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="1076" end_char="1087">hospitalized</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="1089" end_char="1092">with</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="1094" end_char="1102">pneumonia</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="1104" end_char="1105">or</TOKEN>
<TOKEN id="token-7-12" pos="unknown" morph="none" start_char="1107" end_char="1122">coronavirus-like</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="1124" end_char="1131">symptoms</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="1133" end_char="1134">in</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="1136" end_char="1142">October</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="1144" end_char="1146">and</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="1148" end_char="1155">November</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="1157" end_char="1160">2019</TOKEN>
<TOKEN id="token-7-19" pos="punct" morph="none" start_char="1161" end_char="1161">,</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="1163" end_char="1165">the</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="1167" end_char="1170">Wall</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="1172" end_char="1177">Street</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="1179" end_char="1185">Journal</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="1187" end_char="1194">reported</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="1196" end_char="1204">Wednesday</TOKEN>
<TOKEN id="token-7-26" pos="punct" morph="none" start_char="1205" end_char="1205">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1209" end_char="1341">
<ORIGINAL_TEXT>This finding lends credence to other research from China that shows people were getting sick in Wuhan in November and early December.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1209" end_char="1212">This</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1214" end_char="1220">finding</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1222" end_char="1226">lends</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1228" end_char="1235">credence</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1237" end_char="1238">to</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1240" end_char="1244">other</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1246" end_char="1253">research</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1255" end_char="1258">from</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1260" end_char="1264">China</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1266" end_char="1269">that</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1271" end_char="1275">shows</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1277" end_char="1282">people</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1284" end_char="1287">were</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1289" end_char="1295">getting</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1297" end_char="1300">sick</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1302" end_char="1303">in</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1305" end_char="1309">Wuhan</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1311" end_char="1312">in</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1314" end_char="1321">November</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1323" end_char="1325">and</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="1327" end_char="1331">early</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="1333" end_char="1340">December</TOKEN>
<TOKEN id="token-8-22" pos="punct" morph="none" start_char="1341" end_char="1341">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1343" end_char="1535">
<ORIGINAL_TEXT>One analysis, based on satellite images of Wuhan hospitals and online searches for COVID-19 symptoms in the area, suggested the virus may have started circulating there as early as late summer.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1343" end_char="1345">One</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1347" end_char="1354">analysis</TOKEN>
<TOKEN id="token-9-2" pos="punct" morph="none" start_char="1355" end_char="1355">,</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1357" end_char="1361">based</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1363" end_char="1364">on</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1366" end_char="1374">satellite</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1376" end_char="1381">images</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1383" end_char="1384">of</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1386" end_char="1390">Wuhan</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1392" end_char="1400">hospitals</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1402" end_char="1404">and</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1406" end_char="1411">online</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1413" end_char="1420">searches</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1422" end_char="1424">for</TOKEN>
<TOKEN id="token-9-14" pos="unknown" morph="none" start_char="1426" end_char="1433">COVID-19</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1435" end_char="1442">symptoms</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1444" end_char="1445">in</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1447" end_char="1449">the</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1451" end_char="1454">area</TOKEN>
<TOKEN id="token-9-19" pos="punct" morph="none" start_char="1455" end_char="1455">,</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1457" end_char="1465">suggested</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1467" end_char="1469">the</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1471" end_char="1475">virus</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1477" end_char="1479">may</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1481" end_char="1484">have</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1486" end_char="1492">started</TOKEN>
<TOKEN id="token-9-26" pos="word" morph="none" start_char="1494" end_char="1504">circulating</TOKEN>
<TOKEN id="token-9-27" pos="word" morph="none" start_char="1506" end_char="1510">there</TOKEN>
<TOKEN id="token-9-28" pos="word" morph="none" start_char="1512" end_char="1513">as</TOKEN>
<TOKEN id="token-9-29" pos="word" morph="none" start_char="1515" end_char="1519">early</TOKEN>
<TOKEN id="token-9-30" pos="word" morph="none" start_char="1521" end_char="1522">as</TOKEN>
<TOKEN id="token-9-31" pos="word" morph="none" start_char="1524" end_char="1527">late</TOKEN>
<TOKEN id="token-9-32" pos="word" morph="none" start_char="1529" end_char="1534">summer</TOKEN>
<TOKEN id="token-9-33" pos="punct" morph="none" start_char="1535" end_char="1535">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1538" end_char="1688">
<ORIGINAL_TEXT>According to an April report, 13 of the 41 original cases had no link to the market — which suggests the market wasn’t the origin site of the pandemic.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1538" end_char="1546">According</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1548" end_char="1549">to</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1551" end_char="1552">an</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1554" end_char="1558">April</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1560" end_char="1565">report</TOKEN>
<TOKEN id="token-10-5" pos="punct" morph="none" start_char="1566" end_char="1566">,</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1568" end_char="1569">13</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1571" end_char="1572">of</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1574" end_char="1576">the</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1578" end_char="1579">41</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1581" end_char="1588">original</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1590" end_char="1594">cases</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1596" end_char="1598">had</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1600" end_char="1601">no</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1603" end_char="1606">link</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1608" end_char="1609">to</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1611" end_char="1613">the</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1615" end_char="1620">market</TOKEN>
<TOKEN id="token-10-18" pos="punct" morph="none" start_char="1622" end_char="1622">—</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1624" end_char="1628">which</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1630" end_char="1637">suggests</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1639" end_char="1641">the</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1643" end_char="1648">market</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1650" end_char="1655">wasn’t</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1657" end_char="1659">the</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="1661" end_char="1666">origin</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="1668" end_char="1671">site</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="1673" end_char="1674">of</TOKEN>
<TOKEN id="token-10-28" pos="word" morph="none" start_char="1676" end_char="1678">the</TOKEN>
<TOKEN id="token-10-29" pos="word" morph="none" start_char="1680" end_char="1687">pandemic</TOKEN>
<TOKEN id="token-10-30" pos="punct" morph="none" start_char="1688" end_char="1688">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1691" end_char="1796">
<ORIGINAL_TEXT>The WHO team confirmed the virus didn’t make its initial jump from animals to humans at the Huanan market.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1691" end_char="1693">The</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1695" end_char="1697">WHO</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1699" end_char="1702">team</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1704" end_char="1712">confirmed</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1714" end_char="1716">the</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1718" end_char="1722">virus</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1724" end_char="1729">didn’t</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1731" end_char="1734">make</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1736" end_char="1738">its</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1740" end_char="1746">initial</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1748" end_char="1751">jump</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1753" end_char="1756">from</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1758" end_char="1764">animals</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1766" end_char="1767">to</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1769" end_char="1774">humans</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1776" end_char="1777">at</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1779" end_char="1781">the</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1783" end_char="1788">Huanan</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1790" end_char="1795">market</TOKEN>
<TOKEN id="token-11-19" pos="punct" morph="none" start_char="1796" end_char="1796">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1798" end_char="2035">
<ORIGINAL_TEXT>Evidence suggests the virus was circulating elsewhere in Wuhan before the market outbreak happened, Liang Wannian, a member of China’s National Health Commission who assisted with the WHO investigation, said in a press conference Tuesday.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1798" end_char="1805">Evidence</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1807" end_char="1814">suggests</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1816" end_char="1818">the</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1820" end_char="1824">virus</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1826" end_char="1828">was</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1830" end_char="1840">circulating</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1842" end_char="1850">elsewhere</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1852" end_char="1853">in</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1855" end_char="1859">Wuhan</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1861" end_char="1866">before</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1868" end_char="1870">the</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1872" end_char="1877">market</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1879" end_char="1886">outbreak</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1888" end_char="1895">happened</TOKEN>
<TOKEN id="token-12-14" pos="punct" morph="none" start_char="1896" end_char="1896">,</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1898" end_char="1902">Liang</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1904" end_char="1910">Wannian</TOKEN>
<TOKEN id="token-12-17" pos="punct" morph="none" start_char="1911" end_char="1911">,</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1913" end_char="1913">a</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1915" end_char="1920">member</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1922" end_char="1923">of</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1925" end_char="1931">China’s</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1933" end_char="1940">National</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="1942" end_char="1947">Health</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="1949" end_char="1958">Commission</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="1960" end_char="1962">who</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="1964" end_char="1971">assisted</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="1973" end_char="1976">with</TOKEN>
<TOKEN id="token-12-28" pos="word" morph="none" start_char="1978" end_char="1980">the</TOKEN>
<TOKEN id="token-12-29" pos="word" morph="none" start_char="1982" end_char="1984">WHO</TOKEN>
<TOKEN id="token-12-30" pos="word" morph="none" start_char="1986" end_char="1998">investigation</TOKEN>
<TOKEN id="token-12-31" pos="punct" morph="none" start_char="1999" end_char="1999">,</TOKEN>
<TOKEN id="token-12-32" pos="word" morph="none" start_char="2001" end_char="2004">said</TOKEN>
<TOKEN id="token-12-33" pos="word" morph="none" start_char="2006" end_char="2007">in</TOKEN>
<TOKEN id="token-12-34" pos="word" morph="none" start_char="2009" end_char="2009">a</TOKEN>
<TOKEN id="token-12-35" pos="word" morph="none" start_char="2011" end_char="2015">press</TOKEN>
<TOKEN id="token-12-36" pos="word" morph="none" start_char="2017" end_char="2026">conference</TOKEN>
<TOKEN id="token-12-37" pos="word" morph="none" start_char="2028" end_char="2034">Tuesday</TOKEN>
<TOKEN id="token-12-38" pos="punct" morph="none" start_char="2035" end_char="2035">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="2038" end_char="2045">
<ORIGINAL_TEXT>MEMORIES</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="2038" end_char="2045">MEMORIES</TOKEN>
</SEG>
<SEG id="segment-14" start_char="2049" end_char="2109">
<ORIGINAL_TEXT>The SOUTH CHINA MORNING POST wrote this on December 31, 2019:</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="2049" end_char="2051">The</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="2053" end_char="2057">SOUTH</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="2059" end_char="2063">CHINA</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="2065" end_char="2071">MORNING</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="2073" end_char="2076">POST</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="2078" end_char="2082">wrote</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="2084" end_char="2087">this</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="2089" end_char="2090">on</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="2092" end_char="2099">December</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="2101" end_char="2102">31</TOKEN>
<TOKEN id="token-14-10" pos="punct" morph="none" start_char="2103" end_char="2103">,</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="2105" end_char="2108">2019</TOKEN>
<TOKEN id="token-14-12" pos="punct" morph="none" start_char="2109" end_char="2109">:</TOKEN>
</SEG>
<SEG id="segment-15" start_char="2112" end_char="2355">
<ORIGINAL_TEXT>Hong Kong health authorities are taking no chances with a mysterious outbreak of viral pneumonia in the central Chinese city of Wuhan, warning of symptoms similar to Sars and bird flu as they step up border screening and put hospitals on alert.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="2112" end_char="2115">Hong</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="2117" end_char="2120">Kong</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="2122" end_char="2127">health</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="2129" end_char="2139">authorities</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="2141" end_char="2143">are</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="2145" end_char="2150">taking</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="2152" end_char="2153">no</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="2155" end_char="2161">chances</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="2163" end_char="2166">with</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="2168" end_char="2168">a</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="2170" end_char="2179">mysterious</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="2181" end_char="2188">outbreak</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="2190" end_char="2191">of</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="2193" end_char="2197">viral</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="2199" end_char="2207">pneumonia</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="2209" end_char="2210">in</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="2212" end_char="2214">the</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="2216" end_char="2222">central</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="2224" end_char="2230">Chinese</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="2232" end_char="2235">city</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="2237" end_char="2238">of</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="2240" end_char="2244">Wuhan</TOKEN>
<TOKEN id="token-15-22" pos="punct" morph="none" start_char="2245" end_char="2245">,</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="2247" end_char="2253">warning</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="2255" end_char="2256">of</TOKEN>
<TOKEN id="token-15-25" pos="word" morph="none" start_char="2258" end_char="2265">symptoms</TOKEN>
<TOKEN id="token-15-26" pos="word" morph="none" start_char="2267" end_char="2273">similar</TOKEN>
<TOKEN id="token-15-27" pos="word" morph="none" start_char="2275" end_char="2276">to</TOKEN>
<TOKEN id="token-15-28" pos="word" morph="none" start_char="2278" end_char="2281">Sars</TOKEN>
<TOKEN id="token-15-29" pos="word" morph="none" start_char="2283" end_char="2285">and</TOKEN>
<TOKEN id="token-15-30" pos="word" morph="none" start_char="2287" end_char="2290">bird</TOKEN>
<TOKEN id="token-15-31" pos="word" morph="none" start_char="2292" end_char="2294">flu</TOKEN>
<TOKEN id="token-15-32" pos="word" morph="none" start_char="2296" end_char="2297">as</TOKEN>
<TOKEN id="token-15-33" pos="word" morph="none" start_char="2299" end_char="2302">they</TOKEN>
<TOKEN id="token-15-34" pos="word" morph="none" start_char="2304" end_char="2307">step</TOKEN>
<TOKEN id="token-15-35" pos="word" morph="none" start_char="2309" end_char="2310">up</TOKEN>
<TOKEN id="token-15-36" pos="word" morph="none" start_char="2312" end_char="2317">border</TOKEN>
<TOKEN id="token-15-37" pos="word" morph="none" start_char="2319" end_char="2327">screening</TOKEN>
<TOKEN id="token-15-38" pos="word" morph="none" start_char="2329" end_char="2331">and</TOKEN>
<TOKEN id="token-15-39" pos="word" morph="none" start_char="2333" end_char="2335">put</TOKEN>
<TOKEN id="token-15-40" pos="word" morph="none" start_char="2337" end_char="2345">hospitals</TOKEN>
<TOKEN id="token-15-41" pos="word" morph="none" start_char="2347" end_char="2348">on</TOKEN>
<TOKEN id="token-15-42" pos="word" morph="none" start_char="2350" end_char="2354">alert</TOKEN>
<TOKEN id="token-15-43" pos="punct" morph="none" start_char="2355" end_char="2355">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="2357" end_char="2597">
<ORIGINAL_TEXT>"The situation in Wuhan is unusual, and we are not sure about the reasons behind the outbreak yet," said Secretary for Food and Health Sophia Chan Siu-chee said after an urgent night-time meeting with officials and experts on New Year’s Eve.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="punct" morph="none" start_char="2357" end_char="2357">"</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="2358" end_char="2360">The</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="2362" end_char="2370">situation</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="2372" end_char="2373">in</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="2375" end_char="2379">Wuhan</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="2381" end_char="2382">is</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="2384" end_char="2390">unusual</TOKEN>
<TOKEN id="token-16-7" pos="punct" morph="none" start_char="2391" end_char="2391">,</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="2393" end_char="2395">and</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="2397" end_char="2398">we</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="2400" end_char="2402">are</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="2404" end_char="2406">not</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="2408" end_char="2411">sure</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="2413" end_char="2417">about</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="2419" end_char="2421">the</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="2423" end_char="2429">reasons</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="2431" end_char="2436">behind</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="2438" end_char="2440">the</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="2442" end_char="2449">outbreak</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="2451" end_char="2453">yet</TOKEN>
<TOKEN id="token-16-20" pos="punct" morph="none" start_char="2454" end_char="2455">,"</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="2457" end_char="2460">said</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="2462" end_char="2470">Secretary</TOKEN>
<TOKEN id="token-16-23" pos="word" morph="none" start_char="2472" end_char="2474">for</TOKEN>
<TOKEN id="token-16-24" pos="word" morph="none" start_char="2476" end_char="2479">Food</TOKEN>
<TOKEN id="token-16-25" pos="word" morph="none" start_char="2481" end_char="2483">and</TOKEN>
<TOKEN id="token-16-26" pos="word" morph="none" start_char="2485" end_char="2490">Health</TOKEN>
<TOKEN id="token-16-27" pos="word" morph="none" start_char="2492" end_char="2497">Sophia</TOKEN>
<TOKEN id="token-16-28" pos="word" morph="none" start_char="2499" end_char="2502">Chan</TOKEN>
<TOKEN id="token-16-29" pos="unknown" morph="none" start_char="2504" end_char="2511">Siu-chee</TOKEN>
<TOKEN id="token-16-30" pos="word" morph="none" start_char="2513" end_char="2516">said</TOKEN>
<TOKEN id="token-16-31" pos="word" morph="none" start_char="2518" end_char="2522">after</TOKEN>
<TOKEN id="token-16-32" pos="word" morph="none" start_char="2524" end_char="2525">an</TOKEN>
<TOKEN id="token-16-33" pos="word" morph="none" start_char="2527" end_char="2532">urgent</TOKEN>
<TOKEN id="token-16-34" pos="unknown" morph="none" start_char="2534" end_char="2543">night-time</TOKEN>
<TOKEN id="token-16-35" pos="word" morph="none" start_char="2545" end_char="2551">meeting</TOKEN>
<TOKEN id="token-16-36" pos="word" morph="none" start_char="2553" end_char="2556">with</TOKEN>
<TOKEN id="token-16-37" pos="word" morph="none" start_char="2558" end_char="2566">officials</TOKEN>
<TOKEN id="token-16-38" pos="word" morph="none" start_char="2568" end_char="2570">and</TOKEN>
<TOKEN id="token-16-39" pos="word" morph="none" start_char="2572" end_char="2578">experts</TOKEN>
<TOKEN id="token-16-40" pos="word" morph="none" start_char="2580" end_char="2581">on</TOKEN>
<TOKEN id="token-16-41" pos="word" morph="none" start_char="2583" end_char="2585">New</TOKEN>
<TOKEN id="token-16-42" pos="word" morph="none" start_char="2587" end_char="2592">Year’s</TOKEN>
<TOKEN id="token-16-43" pos="word" morph="none" start_char="2594" end_char="2596">Eve</TOKEN>
<TOKEN id="token-16-44" pos="punct" morph="none" start_char="2597" end_char="2597">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2599" end_char="2710">
<ORIGINAL_TEXT>"Since we are now in the holiday season, and Hong Kong has close transport ties with Wuhan, we must stay alert."</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="punct" morph="none" start_char="2599" end_char="2599">"</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2600" end_char="2604">Since</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2606" end_char="2607">we</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2609" end_char="2611">are</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2613" end_char="2615">now</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2617" end_char="2618">in</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2620" end_char="2622">the</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2624" end_char="2630">holiday</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2632" end_char="2637">season</TOKEN>
<TOKEN id="token-17-9" pos="punct" morph="none" start_char="2638" end_char="2638">,</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2640" end_char="2642">and</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2644" end_char="2647">Hong</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2649" end_char="2652">Kong</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2654" end_char="2656">has</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2658" end_char="2662">close</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2664" end_char="2672">transport</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="2674" end_char="2677">ties</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="2679" end_char="2682">with</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="2684" end_char="2688">Wuhan</TOKEN>
<TOKEN id="token-17-19" pos="punct" morph="none" start_char="2689" end_char="2689">,</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="2691" end_char="2692">we</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="2694" end_char="2697">must</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="2699" end_char="2702">stay</TOKEN>
<TOKEN id="token-17-23" pos="word" morph="none" start_char="2704" end_char="2708">alert</TOKEN>
<TOKEN id="token-17-24" pos="punct" morph="none" start_char="2709" end_char="2710">."</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2714" end_char="2751">
<ORIGINAL_TEXT>Seeds of confusion were planted early!</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2714" end_char="2718">Seeds</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2720" end_char="2721">of</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2723" end_char="2731">confusion</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2733" end_char="2736">were</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2738" end_char="2744">planted</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2746" end_char="2750">early</TOKEN>
<TOKEN id="token-18-6" pos="punct" morph="none" start_char="2751" end_char="2751">!</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2753" end_char="2757">
<ORIGINAL_TEXT>Mask?</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2753" end_char="2756">Mask</TOKEN>
<TOKEN id="token-19-1" pos="punct" morph="none" start_char="2757" end_char="2757">?</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2759" end_char="2770">
<ORIGINAL_TEXT>Or no mask!?</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2759" end_char="2760">Or</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2762" end_char="2763">no</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2765" end_char="2768">mask</TOKEN>
<TOKEN id="token-20-3" pos="punct" morph="none" start_char="2769" end_char="2770">!?</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2772" end_char="2790">
<ORIGINAL_TEXT>Human transmission!</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2772" end_char="2776">Human</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2778" end_char="2789">transmission</TOKEN>
<TOKEN id="token-21-2" pos="punct" morph="none" start_char="2790" end_char="2790">!</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2792" end_char="2799">
<ORIGINAL_TEXT>Or safe!</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2792" end_char="2793">Or</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2795" end_char="2798">safe</TOKEN>
<TOKEN id="token-22-2" pos="punct" morph="none" start_char="2799" end_char="2799">!</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2802" end_char="2872">
<ORIGINAL_TEXT>As the year 2019 ended an "unidentified" virus was identified in Wuhan.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2802" end_char="2803">As</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2805" end_char="2807">the</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2809" end_char="2812">year</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2814" end_char="2817">2019</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="2819" end_char="2823">ended</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="2825" end_char="2826">an</TOKEN>
<TOKEN id="token-23-6" pos="punct" morph="none" start_char="2828" end_char="2828">"</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="2829" end_char="2840">unidentified</TOKEN>
<TOKEN id="token-23-8" pos="punct" morph="none" start_char="2841" end_char="2841">"</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="2843" end_char="2847">virus</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="2849" end_char="2851">was</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="2853" end_char="2862">identified</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="2864" end_char="2865">in</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="2867" end_char="2871">Wuhan</TOKEN>
<TOKEN id="token-23-14" pos="punct" morph="none" start_char="2872" end_char="2872">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2875" end_char="2944">
<ORIGINAL_TEXT>New Years celebrations ushered in the roaring 20s of the 21st century.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="2875" end_char="2877">New</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="2879" end_char="2883">Years</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="2885" end_char="2896">celebrations</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="2898" end_char="2904">ushered</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="2906" end_char="2907">in</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="2909" end_char="2911">the</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="2913" end_char="2919">roaring</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="2921" end_char="2923">20s</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="2925" end_char="2926">of</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="2928" end_char="2930">the</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="2932" end_char="2935">21st</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="2937" end_char="2943">century</TOKEN>
<TOKEN id="token-24-12" pos="punct" morph="none" start_char="2944" end_char="2944">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2947" end_char="3006">
<ORIGINAL_TEXT>Meanwhile, backstage, officials were scrambling for answers.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="2947" end_char="2955">Meanwhile</TOKEN>
<TOKEN id="token-25-1" pos="punct" morph="none" start_char="2956" end_char="2956">,</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="2958" end_char="2966">backstage</TOKEN>
<TOKEN id="token-25-3" pos="punct" morph="none" start_char="2967" end_char="2967">,</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="2969" end_char="2977">officials</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="2979" end_char="2982">were</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="2984" end_char="2993">scrambling</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="2995" end_char="2997">for</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="2999" end_char="3005">answers</TOKEN>
<TOKEN id="token-25-9" pos="punct" morph="none" start_char="3006" end_char="3006">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="3009" end_char="3200">
<ORIGINAL_TEXT>The cause of mysterious pneumonia cases in the Chinese city of Wuhan remains unknown, health authorities in the city said Sunday, as the number of infected people rose to 59 from 44 on Friday.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="3009" end_char="3011">The</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="3013" end_char="3017">cause</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="3019" end_char="3020">of</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="3022" end_char="3031">mysterious</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="3033" end_char="3041">pneumonia</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="3043" end_char="3047">cases</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="3049" end_char="3050">in</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="3052" end_char="3054">the</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="3056" end_char="3062">Chinese</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="3064" end_char="3067">city</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="3069" end_char="3070">of</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="3072" end_char="3076">Wuhan</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="3078" end_char="3084">remains</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="3086" end_char="3092">unknown</TOKEN>
<TOKEN id="token-26-14" pos="punct" morph="none" start_char="3093" end_char="3093">,</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="3095" end_char="3100">health</TOKEN>
<TOKEN id="token-26-16" pos="word" morph="none" start_char="3102" end_char="3112">authorities</TOKEN>
<TOKEN id="token-26-17" pos="word" morph="none" start_char="3114" end_char="3115">in</TOKEN>
<TOKEN id="token-26-18" pos="word" morph="none" start_char="3117" end_char="3119">the</TOKEN>
<TOKEN id="token-26-19" pos="word" morph="none" start_char="3121" end_char="3124">city</TOKEN>
<TOKEN id="token-26-20" pos="word" morph="none" start_char="3126" end_char="3129">said</TOKEN>
<TOKEN id="token-26-21" pos="word" morph="none" start_char="3131" end_char="3136">Sunday</TOKEN>
<TOKEN id="token-26-22" pos="punct" morph="none" start_char="3137" end_char="3137">,</TOKEN>
<TOKEN id="token-26-23" pos="word" morph="none" start_char="3139" end_char="3140">as</TOKEN>
<TOKEN id="token-26-24" pos="word" morph="none" start_char="3142" end_char="3144">the</TOKEN>
<TOKEN id="token-26-25" pos="word" morph="none" start_char="3146" end_char="3151">number</TOKEN>
<TOKEN id="token-26-26" pos="word" morph="none" start_char="3153" end_char="3154">of</TOKEN>
<TOKEN id="token-26-27" pos="word" morph="none" start_char="3156" end_char="3163">infected</TOKEN>
<TOKEN id="token-26-28" pos="word" morph="none" start_char="3165" end_char="3170">people</TOKEN>
<TOKEN id="token-26-29" pos="word" morph="none" start_char="3172" end_char="3175">rose</TOKEN>
<TOKEN id="token-26-30" pos="word" morph="none" start_char="3177" end_char="3178">to</TOKEN>
<TOKEN id="token-26-31" pos="word" morph="none" start_char="3180" end_char="3181">59</TOKEN>
<TOKEN id="token-26-32" pos="word" morph="none" start_char="3183" end_char="3186">from</TOKEN>
<TOKEN id="token-26-33" pos="word" morph="none" start_char="3188" end_char="3189">44</TOKEN>
<TOKEN id="token-26-34" pos="word" morph="none" start_char="3191" end_char="3192">on</TOKEN>
<TOKEN id="token-26-35" pos="word" morph="none" start_char="3194" end_char="3199">Friday</TOKEN>
<TOKEN id="token-26-36" pos="punct" morph="none" start_char="3200" end_char="3200">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="3202" end_char="3272">
<ORIGINAL_TEXT>Seven of the sick are listed as critically ill, down from 11 on Friday.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="3202" end_char="3206">Seven</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="3208" end_char="3209">of</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="3211" end_char="3213">the</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="3215" end_char="3218">sick</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="3220" end_char="3222">are</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="3224" end_char="3229">listed</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="3231" end_char="3232">as</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="3234" end_char="3243">critically</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="3245" end_char="3247">ill</TOKEN>
<TOKEN id="token-27-9" pos="punct" morph="none" start_char="3248" end_char="3248">,</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="3250" end_char="3253">down</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="3255" end_char="3258">from</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="3260" end_char="3261">11</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="3263" end_char="3264">on</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="3266" end_char="3271">Friday</TOKEN>
<TOKEN id="token-27-15" pos="punct" morph="none" start_char="3272" end_char="3272">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3274" end_char="3354">
<ORIGINAL_TEXT>The number of close contacts of cases under medical observation has risen to 163.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="3274" end_char="3276">The</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="3278" end_char="3283">number</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="3285" end_char="3286">of</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="3288" end_char="3292">close</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="3294" end_char="3301">contacts</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="3303" end_char="3304">of</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="3306" end_char="3310">cases</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="3312" end_char="3316">under</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="3318" end_char="3324">medical</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="3326" end_char="3336">observation</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="3338" end_char="3340">has</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="3342" end_char="3346">risen</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="3348" end_char="3349">to</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="3351" end_char="3353">163</TOKEN>
<TOKEN id="token-28-14" pos="punct" morph="none" start_char="3354" end_char="3354">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3356" end_char="3515">
<ORIGINAL_TEXT>Sunday’s statement, the third from the Wuhan Municipal Health Commission about the incident, is the first to give information about when people became infected.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="3356" end_char="3363">Sunday’s</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="3365" end_char="3373">statement</TOKEN>
<TOKEN id="token-29-2" pos="punct" morph="none" start_char="3374" end_char="3374">,</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="3376" end_char="3378">the</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="3380" end_char="3384">third</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="3386" end_char="3389">from</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="3391" end_char="3393">the</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="3395" end_char="3399">Wuhan</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="3401" end_char="3409">Municipal</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="3411" end_char="3416">Health</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="3418" end_char="3427">Commission</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="3429" end_char="3433">about</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="3435" end_char="3437">the</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="3439" end_char="3446">incident</TOKEN>
<TOKEN id="token-29-14" pos="punct" morph="none" start_char="3447" end_char="3447">,</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="3449" end_char="3450">is</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="3452" end_char="3454">the</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="3456" end_char="3460">first</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="3462" end_char="3463">to</TOKEN>
<TOKEN id="token-29-19" pos="word" morph="none" start_char="3465" end_char="3468">give</TOKEN>
<TOKEN id="token-29-20" pos="word" morph="none" start_char="3470" end_char="3480">information</TOKEN>
<TOKEN id="token-29-21" pos="word" morph="none" start_char="3482" end_char="3486">about</TOKEN>
<TOKEN id="token-29-22" pos="word" morph="none" start_char="3488" end_char="3491">when</TOKEN>
<TOKEN id="token-29-23" pos="word" morph="none" start_char="3493" end_char="3498">people</TOKEN>
<TOKEN id="token-29-24" pos="word" morph="none" start_char="3500" end_char="3505">became</TOKEN>
<TOKEN id="token-29-25" pos="word" morph="none" start_char="3507" end_char="3514">infected</TOKEN>
<TOKEN id="token-29-26" pos="punct" morph="none" start_char="3515" end_char="3515">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3517" end_char="3588">
<ORIGINAL_TEXT>The first person known to have become ill began to show symptoms on Dec.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="3517" end_char="3519">The</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="3521" end_char="3525">first</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="3527" end_char="3532">person</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="3534" end_char="3538">known</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="3540" end_char="3541">to</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="3543" end_char="3546">have</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="3548" end_char="3553">become</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="3555" end_char="3557">ill</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="3559" end_char="3563">began</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="3565" end_char="3566">to</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="3568" end_char="3571">show</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="3573" end_char="3580">symptoms</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="3582" end_char="3583">on</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="3585" end_char="3587">Dec</TOKEN>
<TOKEN id="token-30-14" pos="punct" morph="none" start_char="3588" end_char="3588">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="3590" end_char="3650">
<ORIGINAL_TEXT>12 and the last date of symptom onset among the sick was Dec.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="3590" end_char="3591">12</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="3593" end_char="3595">and</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="3597" end_char="3599">the</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="3601" end_char="3604">last</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="3606" end_char="3609">date</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="3611" end_char="3612">of</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="3614" end_char="3620">symptom</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="3622" end_char="3626">onset</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="3628" end_char="3632">among</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="3634" end_char="3636">the</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="3638" end_char="3641">sick</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="3643" end_char="3645">was</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="3647" end_char="3649">Dec</TOKEN>
<TOKEN id="token-31-13" pos="punct" morph="none" start_char="3650" end_char="3650">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="3652" end_char="3674">
<ORIGINAL_TEXT>29, the statement said.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="3652" end_char="3653">29</TOKEN>
<TOKEN id="token-32-1" pos="punct" morph="none" start_char="3654" end_char="3654">,</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="3656" end_char="3658">the</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="3660" end_char="3668">statement</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="3670" end_char="3673">said</TOKEN>
<TOKEN id="token-32-5" pos="punct" morph="none" start_char="3674" end_char="3674">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="3678" end_char="3809">
<ORIGINAL_TEXT>But the rest of the press information aged even worse, a clear sign that early reports were taking what China was releasing as fact.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="3678" end_char="3680">But</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="3682" end_char="3684">the</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="3686" end_char="3689">rest</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="3691" end_char="3692">of</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="3694" end_char="3696">the</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="3698" end_char="3702">press</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="3704" end_char="3714">information</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="3716" end_char="3719">aged</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="3721" end_char="3724">even</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="3726" end_char="3730">worse</TOKEN>
<TOKEN id="token-33-10" pos="punct" morph="none" start_char="3731" end_char="3731">,</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="3733" end_char="3733">a</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="3735" end_char="3739">clear</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="3741" end_char="3744">sign</TOKEN>
<TOKEN id="token-33-14" pos="word" morph="none" start_char="3746" end_char="3749">that</TOKEN>
<TOKEN id="token-33-15" pos="word" morph="none" start_char="3751" end_char="3755">early</TOKEN>
<TOKEN id="token-33-16" pos="word" morph="none" start_char="3757" end_char="3763">reports</TOKEN>
<TOKEN id="token-33-17" pos="word" morph="none" start_char="3765" end_char="3768">were</TOKEN>
<TOKEN id="token-33-18" pos="word" morph="none" start_char="3770" end_char="3775">taking</TOKEN>
<TOKEN id="token-33-19" pos="word" morph="none" start_char="3777" end_char="3780">what</TOKEN>
<TOKEN id="token-33-20" pos="word" morph="none" start_char="3782" end_char="3786">China</TOKEN>
<TOKEN id="token-33-21" pos="word" morph="none" start_char="3788" end_char="3790">was</TOKEN>
<TOKEN id="token-33-22" pos="word" morph="none" start_char="3792" end_char="3800">releasing</TOKEN>
<TOKEN id="token-33-23" pos="word" morph="none" start_char="3802" end_char="3803">as</TOKEN>
<TOKEN id="token-33-24" pos="word" morph="none" start_char="3805" end_char="3808">fact</TOKEN>
<TOKEN id="token-33-25" pos="punct" morph="none" start_char="3809" end_char="3809">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="3812" end_char="3824">
<ORIGINAL_TEXT>EARLY SPREAD?</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="3812" end_char="3816">EARLY</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="3818" end_char="3823">SPREAD</TOKEN>
<TOKEN id="token-34-2" pos="punct" morph="none" start_char="3824" end_char="3824">?</TOKEN>
</SEG>
<SEG id="segment-35" start_char="3828" end_char="3915">
<ORIGINAL_TEXT>There have been some reports that Italy was seeing a spread in the late summer of 2019..</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="3828" end_char="3832">There</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="3834" end_char="3837">have</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="3839" end_char="3842">been</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="3844" end_char="3847">some</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="3849" end_char="3855">reports</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="3857" end_char="3860">that</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="3862" end_char="3866">Italy</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="3868" end_char="3870">was</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="3872" end_char="3877">seeing</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="3879" end_char="3879">a</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="3881" end_char="3886">spread</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="3888" end_char="3889">in</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="3891" end_char="3893">the</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="3895" end_char="3898">late</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="3900" end_char="3905">summer</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="3907" end_char="3908">of</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="3910" end_char="3913">2019</TOKEN>
<TOKEN id="token-35-17" pos="punct" morph="none" start_char="3914" end_char="3915">..</TOKEN>
</SEG>
<SEG id="segment-36" start_char="3917" end_char="4064">
<ORIGINAL_TEXT>While people are skeptical, this new information coming from the WHO may make an earlier spread more acceptable by the normally doubtful mainstream.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="3917" end_char="3921">While</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="3923" end_char="3928">people</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="3930" end_char="3932">are</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="3934" end_char="3942">skeptical</TOKEN>
<TOKEN id="token-36-4" pos="punct" morph="none" start_char="3943" end_char="3943">,</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="3945" end_char="3948">this</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="3950" end_char="3952">new</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="3954" end_char="3964">information</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="3966" end_char="3971">coming</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="3973" end_char="3976">from</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="3978" end_char="3980">the</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="3982" end_char="3984">WHO</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="3986" end_char="3988">may</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="3990" end_char="3993">make</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="3995" end_char="3996">an</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="3998" end_char="4004">earlier</TOKEN>
<TOKEN id="token-36-16" pos="word" morph="none" start_char="4006" end_char="4011">spread</TOKEN>
<TOKEN id="token-36-17" pos="word" morph="none" start_char="4013" end_char="4016">more</TOKEN>
<TOKEN id="token-36-18" pos="word" morph="none" start_char="4018" end_char="4027">acceptable</TOKEN>
<TOKEN id="token-36-19" pos="word" morph="none" start_char="4029" end_char="4030">by</TOKEN>
<TOKEN id="token-36-20" pos="word" morph="none" start_char="4032" end_char="4034">the</TOKEN>
<TOKEN id="token-36-21" pos="word" morph="none" start_char="4036" end_char="4043">normally</TOKEN>
<TOKEN id="token-36-22" pos="word" morph="none" start_char="4045" end_char="4052">doubtful</TOKEN>
<TOKEN id="token-36-23" pos="word" morph="none" start_char="4054" end_char="4063">mainstream</TOKEN>
<TOKEN id="token-36-24" pos="punct" morph="none" start_char="4064" end_char="4064">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="4067" end_char="4188">
<ORIGINAL_TEXT>During the summer of 2019, a Virginia nursing home from was dealing with a deadly respiratory outbreak of unknown origins.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="4067" end_char="4072">During</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="4074" end_char="4076">the</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="4078" end_char="4083">summer</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="4085" end_char="4086">of</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="4088" end_char="4091">2019</TOKEN>
<TOKEN id="token-37-5" pos="punct" morph="none" start_char="4092" end_char="4092">,</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="4094" end_char="4094">a</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="4096" end_char="4103">Virginia</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="4105" end_char="4111">nursing</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="4113" end_char="4116">home</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="4118" end_char="4121">from</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="4123" end_char="4125">was</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="4127" end_char="4133">dealing</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="4135" end_char="4138">with</TOKEN>
<TOKEN id="token-37-14" pos="word" morph="none" start_char="4140" end_char="4140">a</TOKEN>
<TOKEN id="token-37-15" pos="word" morph="none" start_char="4142" end_char="4147">deadly</TOKEN>
<TOKEN id="token-37-16" pos="word" morph="none" start_char="4149" end_char="4159">respiratory</TOKEN>
<TOKEN id="token-37-17" pos="word" morph="none" start_char="4161" end_char="4168">outbreak</TOKEN>
<TOKEN id="token-37-18" pos="word" morph="none" start_char="4170" end_char="4171">of</TOKEN>
<TOKEN id="token-37-19" pos="word" morph="none" start_char="4173" end_char="4179">unknown</TOKEN>
<TOKEN id="token-37-20" pos="word" morph="none" start_char="4181" end_char="4187">origins</TOKEN>
<TOKEN id="token-37-21" pos="punct" morph="none" start_char="4188" end_char="4188">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="4190" end_char="4282">
<ORIGINAL_TEXT>That Greenspring Retirement Center was besieged with rapid coughs turning into viral deaths..</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="4190" end_char="4193">That</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="4195" end_char="4205">Greenspring</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="4207" end_char="4216">Retirement</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="4218" end_char="4223">Center</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="4225" end_char="4227">was</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="4229" end_char="4236">besieged</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="4238" end_char="4241">with</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="4243" end_char="4247">rapid</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="4249" end_char="4254">coughs</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="4256" end_char="4262">turning</TOKEN>
<TOKEN id="token-38-10" pos="word" morph="none" start_char="4264" end_char="4267">into</TOKEN>
<TOKEN id="token-38-11" pos="word" morph="none" start_char="4269" end_char="4273">viral</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="4275" end_char="4280">deaths</TOKEN>
<TOKEN id="token-38-13" pos="punct" morph="none" start_char="4281" end_char="4282">..</TOKEN>
</SEG>
<SEG id="segment-39" start_char="4285" end_char="4350">
<ORIGINAL_TEXT>Close by at Fort Deitich, a different kind of event was occurring.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="4285" end_char="4289">Close</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="4291" end_char="4292">by</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="4294" end_char="4295">at</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="4297" end_char="4300">Fort</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="4302" end_char="4308">Deitich</TOKEN>
<TOKEN id="token-39-5" pos="punct" morph="none" start_char="4309" end_char="4309">,</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="4311" end_char="4311">a</TOKEN>
<TOKEN id="token-39-7" pos="word" morph="none" start_char="4313" end_char="4321">different</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="4323" end_char="4326">kind</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="4328" end_char="4329">of</TOKEN>
<TOKEN id="token-39-10" pos="word" morph="none" start_char="4331" end_char="4335">event</TOKEN>
<TOKEN id="token-39-11" pos="word" morph="none" start_char="4337" end_char="4339">was</TOKEN>
<TOKEN id="token-39-12" pos="word" morph="none" start_char="4341" end_char="4349">occurring</TOKEN>
<TOKEN id="token-39-13" pos="punct" morph="none" start_char="4350" end_char="4350">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="4352" end_char="4396">
<ORIGINAL_TEXT>The deadly germ research was shut down at Ft.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="4352" end_char="4354">The</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="4356" end_char="4361">deadly</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="4363" end_char="4366">germ</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="4368" end_char="4375">research</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="4377" end_char="4379">was</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="4381" end_char="4384">shut</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="4386" end_char="4389">down</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="4391" end_char="4392">at</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="4394" end_char="4395">Ft</TOKEN>
<TOKEN id="token-40-9" pos="punct" morph="none" start_char="4396" end_char="4396">.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="4398" end_char="4613">
<ORIGINAL_TEXT>Dietrich over safety concerns.. the United States was not in danger, public statements said.. but details were not released due to national security.. In 2020, it was revealed as to what the serious violations were..</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="4398" end_char="4405">Dietrich</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="4407" end_char="4410">over</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="4412" end_char="4417">safety</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="4419" end_char="4426">concerns</TOKEN>
<TOKEN id="token-41-4" pos="punct" morph="none" start_char="4427" end_char="4428">..</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="4430" end_char="4432">the</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="4434" end_char="4439">United</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="4441" end_char="4446">States</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="4448" end_char="4450">was</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="4452" end_char="4454">not</TOKEN>
<TOKEN id="token-41-10" pos="word" morph="none" start_char="4456" end_char="4457">in</TOKEN>
<TOKEN id="token-41-11" pos="word" morph="none" start_char="4459" end_char="4464">danger</TOKEN>
<TOKEN id="token-41-12" pos="punct" morph="none" start_char="4465" end_char="4465">,</TOKEN>
<TOKEN id="token-41-13" pos="word" morph="none" start_char="4467" end_char="4472">public</TOKEN>
<TOKEN id="token-41-14" pos="word" morph="none" start_char="4474" end_char="4483">statements</TOKEN>
<TOKEN id="token-41-15" pos="word" morph="none" start_char="4485" end_char="4488">said</TOKEN>
<TOKEN id="token-41-16" pos="punct" morph="none" start_char="4489" end_char="4490">..</TOKEN>
<TOKEN id="token-41-17" pos="word" morph="none" start_char="4492" end_char="4494">but</TOKEN>
<TOKEN id="token-41-18" pos="word" morph="none" start_char="4496" end_char="4502">details</TOKEN>
<TOKEN id="token-41-19" pos="word" morph="none" start_char="4504" end_char="4507">were</TOKEN>
<TOKEN id="token-41-20" pos="word" morph="none" start_char="4509" end_char="4511">not</TOKEN>
<TOKEN id="token-41-21" pos="word" morph="none" start_char="4513" end_char="4520">released</TOKEN>
<TOKEN id="token-41-22" pos="word" morph="none" start_char="4522" end_char="4524">due</TOKEN>
<TOKEN id="token-41-23" pos="word" morph="none" start_char="4526" end_char="4527">to</TOKEN>
<TOKEN id="token-41-24" pos="word" morph="none" start_char="4529" end_char="4536">national</TOKEN>
<TOKEN id="token-41-25" pos="word" morph="none" start_char="4538" end_char="4545">security</TOKEN>
<TOKEN id="token-41-26" pos="punct" morph="none" start_char="4546" end_char="4547">..</TOKEN>
<TOKEN id="token-41-27" pos="word" morph="none" start_char="4549" end_char="4550">In</TOKEN>
<TOKEN id="token-41-28" pos="word" morph="none" start_char="4552" end_char="4555">2020</TOKEN>
<TOKEN id="token-41-29" pos="punct" morph="none" start_char="4556" end_char="4556">,</TOKEN>
<TOKEN id="token-41-30" pos="word" morph="none" start_char="4558" end_char="4559">it</TOKEN>
<TOKEN id="token-41-31" pos="word" morph="none" start_char="4561" end_char="4563">was</TOKEN>
<TOKEN id="token-41-32" pos="word" morph="none" start_char="4565" end_char="4572">revealed</TOKEN>
<TOKEN id="token-41-33" pos="word" morph="none" start_char="4574" end_char="4575">as</TOKEN>
<TOKEN id="token-41-34" pos="word" morph="none" start_char="4577" end_char="4578">to</TOKEN>
<TOKEN id="token-41-35" pos="word" morph="none" start_char="4580" end_char="4583">what</TOKEN>
<TOKEN id="token-41-36" pos="word" morph="none" start_char="4585" end_char="4587">the</TOKEN>
<TOKEN id="token-41-37" pos="word" morph="none" start_char="4589" end_char="4595">serious</TOKEN>
<TOKEN id="token-41-38" pos="word" morph="none" start_char="4597" end_char="4606">violations</TOKEN>
<TOKEN id="token-41-39" pos="word" morph="none" start_char="4608" end_char="4611">were</TOKEN>
<TOKEN id="token-41-40" pos="punct" morph="none" start_char="4612" end_char="4613">..</TOKEN>
</SEG>
<SEG id="segment-42" start_char="4616" end_char="4756">
<ORIGINAL_TEXT>Also in September 2019, there was a rapid rise of Pneumonia deaths among young people nationwide across America … they were blamed on vaping.</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="4616" end_char="4619">Also</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="4621" end_char="4622">in</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="4624" end_char="4632">September</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="4634" end_char="4637">2019</TOKEN>
<TOKEN id="token-42-4" pos="punct" morph="none" start_char="4638" end_char="4638">,</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="4640" end_char="4644">there</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="4646" end_char="4648">was</TOKEN>
<TOKEN id="token-42-7" pos="word" morph="none" start_char="4650" end_char="4650">a</TOKEN>
<TOKEN id="token-42-8" pos="word" morph="none" start_char="4652" end_char="4656">rapid</TOKEN>
<TOKEN id="token-42-9" pos="word" morph="none" start_char="4658" end_char="4661">rise</TOKEN>
<TOKEN id="token-42-10" pos="word" morph="none" start_char="4663" end_char="4664">of</TOKEN>
<TOKEN id="token-42-11" pos="word" morph="none" start_char="4666" end_char="4674">Pneumonia</TOKEN>
<TOKEN id="token-42-12" pos="word" morph="none" start_char="4676" end_char="4681">deaths</TOKEN>
<TOKEN id="token-42-13" pos="word" morph="none" start_char="4683" end_char="4687">among</TOKEN>
<TOKEN id="token-42-14" pos="word" morph="none" start_char="4689" end_char="4693">young</TOKEN>
<TOKEN id="token-42-15" pos="word" morph="none" start_char="4695" end_char="4700">people</TOKEN>
<TOKEN id="token-42-16" pos="word" morph="none" start_char="4702" end_char="4711">nationwide</TOKEN>
<TOKEN id="token-42-17" pos="word" morph="none" start_char="4713" end_char="4718">across</TOKEN>
<TOKEN id="token-42-18" pos="word" morph="none" start_char="4720" end_char="4726">America</TOKEN>
<TOKEN id="token-42-19" pos="punct" morph="none" start_char="4728" end_char="4728">…</TOKEN>
<TOKEN id="token-42-20" pos="word" morph="none" start_char="4730" end_char="4733">they</TOKEN>
<TOKEN id="token-42-21" pos="word" morph="none" start_char="4735" end_char="4738">were</TOKEN>
<TOKEN id="token-42-22" pos="word" morph="none" start_char="4740" end_char="4745">blamed</TOKEN>
<TOKEN id="token-42-23" pos="word" morph="none" start_char="4747" end_char="4748">on</TOKEN>
<TOKEN id="token-42-24" pos="word" morph="none" start_char="4750" end_char="4755">vaping</TOKEN>
<TOKEN id="token-42-25" pos="punct" morph="none" start_char="4756" end_char="4756">.</TOKEN>
</SEG>
<SEG id="segment-43" start_char="4758" end_char="4826">
<ORIGINAL_TEXT>Health officials at that the time didn’t know what was causing them..</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="4758" end_char="4763">Health</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="4765" end_char="4773">officials</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="4775" end_char="4776">at</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="4778" end_char="4781">that</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="4783" end_char="4785">the</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="4787" end_char="4790">time</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="4792" end_char="4797">didn’t</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="4799" end_char="4802">know</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="4804" end_char="4807">what</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="4809" end_char="4811">was</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="4813" end_char="4819">causing</TOKEN>
<TOKEN id="token-43-11" pos="word" morph="none" start_char="4821" end_char="4824">them</TOKEN>
<TOKEN id="token-43-12" pos="punct" morph="none" start_char="4825" end_char="4826">..</TOKEN>
</SEG>
<SEG id="segment-44" start_char="4830" end_char="4937">
<ORIGINAL_TEXT>A NEW JERSEY mayor claimed he had COVID in November 2019.. the media at the time called his claim unfounded.</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="4830" end_char="4830">A</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="4832" end_char="4834">NEW</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="4836" end_char="4841">JERSEY</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="4843" end_char="4847">mayor</TOKEN>
<TOKEN id="token-44-4" pos="word" morph="none" start_char="4849" end_char="4855">claimed</TOKEN>
<TOKEN id="token-44-5" pos="word" morph="none" start_char="4857" end_char="4858">he</TOKEN>
<TOKEN id="token-44-6" pos="word" morph="none" start_char="4860" end_char="4862">had</TOKEN>
<TOKEN id="token-44-7" pos="word" morph="none" start_char="4864" end_char="4868">COVID</TOKEN>
<TOKEN id="token-44-8" pos="word" morph="none" start_char="4870" end_char="4871">in</TOKEN>
<TOKEN id="token-44-9" pos="word" morph="none" start_char="4873" end_char="4880">November</TOKEN>
<TOKEN id="token-44-10" pos="word" morph="none" start_char="4882" end_char="4885">2019</TOKEN>
<TOKEN id="token-44-11" pos="punct" morph="none" start_char="4886" end_char="4887">..</TOKEN>
<TOKEN id="token-44-12" pos="word" morph="none" start_char="4889" end_char="4891">the</TOKEN>
<TOKEN id="token-44-13" pos="word" morph="none" start_char="4893" end_char="4897">media</TOKEN>
<TOKEN id="token-44-14" pos="word" morph="none" start_char="4899" end_char="4900">at</TOKEN>
<TOKEN id="token-44-15" pos="word" morph="none" start_char="4902" end_char="4904">the</TOKEN>
<TOKEN id="token-44-16" pos="word" morph="none" start_char="4906" end_char="4909">time</TOKEN>
<TOKEN id="token-44-17" pos="word" morph="none" start_char="4911" end_char="4916">called</TOKEN>
<TOKEN id="token-44-18" pos="word" morph="none" start_char="4918" end_char="4920">his</TOKEN>
<TOKEN id="token-44-19" pos="word" morph="none" start_char="4922" end_char="4926">claim</TOKEN>
<TOKEN id="token-44-20" pos="word" morph="none" start_char="4928" end_char="4936">unfounded</TOKEN>
<TOKEN id="token-44-21" pos="punct" morph="none" start_char="4937" end_char="4937">.</TOKEN>
</SEG>
<SEG id="segment-45" start_char="4939" end_char="5055">
<ORIGINAL_TEXT>"I was definitely feeling sick when I was there, and fought my way through it," he told NJ Advance Media on Thursday.</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="punct" morph="none" start_char="4939" end_char="4939">"</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="4940" end_char="4940">I</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="4942" end_char="4944">was</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="4946" end_char="4955">definitely</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="4957" end_char="4963">feeling</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="4965" end_char="4968">sick</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="4970" end_char="4973">when</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="4975" end_char="4975">I</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="4977" end_char="4979">was</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="4981" end_char="4985">there</TOKEN>
<TOKEN id="token-45-10" pos="punct" morph="none" start_char="4986" end_char="4986">,</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="4988" end_char="4990">and</TOKEN>
<TOKEN id="token-45-12" pos="word" morph="none" start_char="4992" end_char="4997">fought</TOKEN>
<TOKEN id="token-45-13" pos="word" morph="none" start_char="4999" end_char="5000">my</TOKEN>
<TOKEN id="token-45-14" pos="word" morph="none" start_char="5002" end_char="5004">way</TOKEN>
<TOKEN id="token-45-15" pos="word" morph="none" start_char="5006" end_char="5012">through</TOKEN>
<TOKEN id="token-45-16" pos="word" morph="none" start_char="5014" end_char="5015">it</TOKEN>
<TOKEN id="token-45-17" pos="punct" morph="none" start_char="5016" end_char="5017">,"</TOKEN>
<TOKEN id="token-45-18" pos="word" morph="none" start_char="5019" end_char="5020">he</TOKEN>
<TOKEN id="token-45-19" pos="word" morph="none" start_char="5022" end_char="5025">told</TOKEN>
<TOKEN id="token-45-20" pos="word" morph="none" start_char="5027" end_char="5028">NJ</TOKEN>
<TOKEN id="token-45-21" pos="word" morph="none" start_char="5030" end_char="5036">Advance</TOKEN>
<TOKEN id="token-45-22" pos="word" morph="none" start_char="5038" end_char="5042">Media</TOKEN>
<TOKEN id="token-45-23" pos="word" morph="none" start_char="5044" end_char="5045">on</TOKEN>
<TOKEN id="token-45-24" pos="word" morph="none" start_char="5047" end_char="5054">Thursday</TOKEN>
<TOKEN id="token-45-25" pos="punct" morph="none" start_char="5055" end_char="5055">.</TOKEN>
</SEG>
<SEG id="segment-46" start_char="5057" end_char="5081">
<ORIGINAL_TEXT>After returning home Nov.</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="5057" end_char="5061">After</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="5063" end_char="5071">returning</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="5073" end_char="5076">home</TOKEN>
<TOKEN id="token-46-3" pos="word" morph="none" start_char="5078" end_char="5080">Nov</TOKEN>
<TOKEN id="token-46-4" pos="punct" morph="none" start_char="5081" end_char="5081">.</TOKEN>
</SEG>
<SEG id="segment-47" start_char="5083" end_char="5298">
<ORIGINAL_TEXT>21 from the convention, Melham said a doctor diagnosed his worsening symptoms — including a 102-degree fever, chills, hallucinations and a sore throat that ended up lasting for three weeks — as a bad case of the flu.</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="5083" end_char="5084">21</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="5086" end_char="5089">from</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="5091" end_char="5093">the</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="5095" end_char="5104">convention</TOKEN>
<TOKEN id="token-47-4" pos="punct" morph="none" start_char="5105" end_char="5105">,</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="5107" end_char="5112">Melham</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="5114" end_char="5117">said</TOKEN>
<TOKEN id="token-47-7" pos="word" morph="none" start_char="5119" end_char="5119">a</TOKEN>
<TOKEN id="token-47-8" pos="word" morph="none" start_char="5121" end_char="5126">doctor</TOKEN>
<TOKEN id="token-47-9" pos="word" morph="none" start_char="5128" end_char="5136">diagnosed</TOKEN>
<TOKEN id="token-47-10" pos="word" morph="none" start_char="5138" end_char="5140">his</TOKEN>
<TOKEN id="token-47-11" pos="word" morph="none" start_char="5142" end_char="5150">worsening</TOKEN>
<TOKEN id="token-47-12" pos="word" morph="none" start_char="5152" end_char="5159">symptoms</TOKEN>
<TOKEN id="token-47-13" pos="punct" morph="none" start_char="5161" end_char="5161">—</TOKEN>
<TOKEN id="token-47-14" pos="word" morph="none" start_char="5163" end_char="5171">including</TOKEN>
<TOKEN id="token-47-15" pos="word" morph="none" start_char="5173" end_char="5173">a</TOKEN>
<TOKEN id="token-47-16" pos="unknown" morph="none" start_char="5175" end_char="5184">102-degree</TOKEN>
<TOKEN id="token-47-17" pos="word" morph="none" start_char="5186" end_char="5190">fever</TOKEN>
<TOKEN id="token-47-18" pos="punct" morph="none" start_char="5191" end_char="5191">,</TOKEN>
<TOKEN id="token-47-19" pos="word" morph="none" start_char="5193" end_char="5198">chills</TOKEN>
<TOKEN id="token-47-20" pos="punct" morph="none" start_char="5199" end_char="5199">,</TOKEN>
<TOKEN id="token-47-21" pos="word" morph="none" start_char="5201" end_char="5214">hallucinations</TOKEN>
<TOKEN id="token-47-22" pos="word" morph="none" start_char="5216" end_char="5218">and</TOKEN>
<TOKEN id="token-47-23" pos="word" morph="none" start_char="5220" end_char="5220">a</TOKEN>
<TOKEN id="token-47-24" pos="word" morph="none" start_char="5222" end_char="5225">sore</TOKEN>
<TOKEN id="token-47-25" pos="word" morph="none" start_char="5227" end_char="5232">throat</TOKEN>
<TOKEN id="token-47-26" pos="word" morph="none" start_char="5234" end_char="5237">that</TOKEN>
<TOKEN id="token-47-27" pos="word" morph="none" start_char="5239" end_char="5243">ended</TOKEN>
<TOKEN id="token-47-28" pos="word" morph="none" start_char="5245" end_char="5246">up</TOKEN>
<TOKEN id="token-47-29" pos="word" morph="none" start_char="5248" end_char="5254">lasting</TOKEN>
<TOKEN id="token-47-30" pos="word" morph="none" start_char="5256" end_char="5258">for</TOKEN>
<TOKEN id="token-47-31" pos="word" morph="none" start_char="5260" end_char="5264">three</TOKEN>
<TOKEN id="token-47-32" pos="word" morph="none" start_char="5266" end_char="5270">weeks</TOKEN>
<TOKEN id="token-47-33" pos="punct" morph="none" start_char="5272" end_char="5272">—</TOKEN>
<TOKEN id="token-47-34" pos="word" morph="none" start_char="5274" end_char="5275">as</TOKEN>
<TOKEN id="token-47-35" pos="word" morph="none" start_char="5277" end_char="5277">a</TOKEN>
<TOKEN id="token-47-36" pos="word" morph="none" start_char="5279" end_char="5281">bad</TOKEN>
<TOKEN id="token-47-37" pos="word" morph="none" start_char="5283" end_char="5286">case</TOKEN>
<TOKEN id="token-47-38" pos="word" morph="none" start_char="5288" end_char="5289">of</TOKEN>
<TOKEN id="token-47-39" pos="word" morph="none" start_char="5291" end_char="5293">the</TOKEN>
<TOKEN id="token-47-40" pos="word" morph="none" start_char="5295" end_char="5297">flu</TOKEN>
<TOKEN id="token-47-41" pos="punct" morph="none" start_char="5298" end_char="5298">.</TOKEN>
</SEG>
<SEG id="segment-48" start_char="5300" end_char="5465">
<ORIGINAL_TEXT>"I have never been sicker in my entire life," Melham said, though he acknowledged that he did not have the respiratory problems often associated with the coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="punct" morph="none" start_char="5300" end_char="5300">"</TOKEN>
<TOKEN id="token-48-1" pos="word" morph="none" start_char="5301" end_char="5301">I</TOKEN>
<TOKEN id="token-48-2" pos="word" morph="none" start_char="5303" end_char="5306">have</TOKEN>
<TOKEN id="token-48-3" pos="word" morph="none" start_char="5308" end_char="5312">never</TOKEN>
<TOKEN id="token-48-4" pos="word" morph="none" start_char="5314" end_char="5317">been</TOKEN>
<TOKEN id="token-48-5" pos="word" morph="none" start_char="5319" end_char="5324">sicker</TOKEN>
<TOKEN id="token-48-6" pos="word" morph="none" start_char="5326" end_char="5327">in</TOKEN>
<TOKEN id="token-48-7" pos="word" morph="none" start_char="5329" end_char="5330">my</TOKEN>
<TOKEN id="token-48-8" pos="word" morph="none" start_char="5332" end_char="5337">entire</TOKEN>
<TOKEN id="token-48-9" pos="word" morph="none" start_char="5339" end_char="5342">life</TOKEN>
<TOKEN id="token-48-10" pos="punct" morph="none" start_char="5343" end_char="5344">,"</TOKEN>
<TOKEN id="token-48-11" pos="word" morph="none" start_char="5346" end_char="5351">Melham</TOKEN>
<TOKEN id="token-48-12" pos="word" morph="none" start_char="5353" end_char="5356">said</TOKEN>
<TOKEN id="token-48-13" pos="punct" morph="none" start_char="5357" end_char="5357">,</TOKEN>
<TOKEN id="token-48-14" pos="word" morph="none" start_char="5359" end_char="5364">though</TOKEN>
<TOKEN id="token-48-15" pos="word" morph="none" start_char="5366" end_char="5367">he</TOKEN>
<TOKEN id="token-48-16" pos="word" morph="none" start_char="5369" end_char="5380">acknowledged</TOKEN>
<TOKEN id="token-48-17" pos="word" morph="none" start_char="5382" end_char="5385">that</TOKEN>
<TOKEN id="token-48-18" pos="word" morph="none" start_char="5387" end_char="5388">he</TOKEN>
<TOKEN id="token-48-19" pos="word" morph="none" start_char="5390" end_char="5392">did</TOKEN>
<TOKEN id="token-48-20" pos="word" morph="none" start_char="5394" end_char="5396">not</TOKEN>
<TOKEN id="token-48-21" pos="word" morph="none" start_char="5398" end_char="5401">have</TOKEN>
<TOKEN id="token-48-22" pos="word" morph="none" start_char="5403" end_char="5405">the</TOKEN>
<TOKEN id="token-48-23" pos="word" morph="none" start_char="5407" end_char="5417">respiratory</TOKEN>
<TOKEN id="token-48-24" pos="word" morph="none" start_char="5419" end_char="5426">problems</TOKEN>
<TOKEN id="token-48-25" pos="word" morph="none" start_char="5428" end_char="5432">often</TOKEN>
<TOKEN id="token-48-26" pos="word" morph="none" start_char="5434" end_char="5443">associated</TOKEN>
<TOKEN id="token-48-27" pos="word" morph="none" start_char="5445" end_char="5448">with</TOKEN>
<TOKEN id="token-48-28" pos="word" morph="none" start_char="5450" end_char="5452">the</TOKEN>
<TOKEN id="token-48-29" pos="word" morph="none" start_char="5454" end_char="5464">coronavirus</TOKEN>
<TOKEN id="token-48-30" pos="punct" morph="none" start_char="5465" end_char="5465">.</TOKEN>
</SEG>
<SEG id="segment-49" start_char="5468" end_char="5553">
<ORIGINAL_TEXT>ABC NEWS reported that intelligence was looking at a spreading virus in November 2019.</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="5468" end_char="5470">ABC</TOKEN>
<TOKEN id="token-49-1" pos="word" morph="none" start_char="5472" end_char="5475">NEWS</TOKEN>
<TOKEN id="token-49-2" pos="word" morph="none" start_char="5477" end_char="5484">reported</TOKEN>
<TOKEN id="token-49-3" pos="word" morph="none" start_char="5486" end_char="5489">that</TOKEN>
<TOKEN id="token-49-4" pos="word" morph="none" start_char="5491" end_char="5502">intelligence</TOKEN>
<TOKEN id="token-49-5" pos="word" morph="none" start_char="5504" end_char="5506">was</TOKEN>
<TOKEN id="token-49-6" pos="word" morph="none" start_char="5508" end_char="5514">looking</TOKEN>
<TOKEN id="token-49-7" pos="word" morph="none" start_char="5516" end_char="5517">at</TOKEN>
<TOKEN id="token-49-8" pos="word" morph="none" start_char="5519" end_char="5519">a</TOKEN>
<TOKEN id="token-49-9" pos="word" morph="none" start_char="5521" end_char="5529">spreading</TOKEN>
<TOKEN id="token-49-10" pos="word" morph="none" start_char="5531" end_char="5535">virus</TOKEN>
<TOKEN id="token-49-11" pos="word" morph="none" start_char="5537" end_char="5538">in</TOKEN>
<TOKEN id="token-49-12" pos="word" morph="none" start_char="5540" end_char="5547">November</TOKEN>
<TOKEN id="token-49-13" pos="word" morph="none" start_char="5549" end_char="5552">2019</TOKEN>
<TOKEN id="token-49-14" pos="punct" morph="none" start_char="5553" end_char="5553">.</TOKEN>
</SEG>
<SEG id="segment-50" start_char="5555" end_char="5689">
<ORIGINAL_TEXT>""The timeline of the intel side of this may be further back than we’re discussing," the source said of preliminary reports from Wuhan.</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="punct" morph="none" start_char="5555" end_char="5556">""</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="5557" end_char="5559">The</TOKEN>
<TOKEN id="token-50-2" pos="word" morph="none" start_char="5561" end_char="5568">timeline</TOKEN>
<TOKEN id="token-50-3" pos="word" morph="none" start_char="5570" end_char="5571">of</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="5573" end_char="5575">the</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="5577" end_char="5581">intel</TOKEN>
<TOKEN id="token-50-6" pos="word" morph="none" start_char="5583" end_char="5586">side</TOKEN>
<TOKEN id="token-50-7" pos="word" morph="none" start_char="5588" end_char="5589">of</TOKEN>
<TOKEN id="token-50-8" pos="word" morph="none" start_char="5591" end_char="5594">this</TOKEN>
<TOKEN id="token-50-9" pos="word" morph="none" start_char="5596" end_char="5598">may</TOKEN>
<TOKEN id="token-50-10" pos="word" morph="none" start_char="5600" end_char="5601">be</TOKEN>
<TOKEN id="token-50-11" pos="word" morph="none" start_char="5603" end_char="5609">further</TOKEN>
<TOKEN id="token-50-12" pos="word" morph="none" start_char="5611" end_char="5614">back</TOKEN>
<TOKEN id="token-50-13" pos="word" morph="none" start_char="5616" end_char="5619">than</TOKEN>
<TOKEN id="token-50-14" pos="word" morph="none" start_char="5621" end_char="5625">we’re</TOKEN>
<TOKEN id="token-50-15" pos="word" morph="none" start_char="5627" end_char="5636">discussing</TOKEN>
<TOKEN id="token-50-16" pos="punct" morph="none" start_char="5637" end_char="5638">,"</TOKEN>
<TOKEN id="token-50-17" pos="word" morph="none" start_char="5640" end_char="5642">the</TOKEN>
<TOKEN id="token-50-18" pos="word" morph="none" start_char="5644" end_char="5649">source</TOKEN>
<TOKEN id="token-50-19" pos="word" morph="none" start_char="5651" end_char="5654">said</TOKEN>
<TOKEN id="token-50-20" pos="word" morph="none" start_char="5656" end_char="5657">of</TOKEN>
<TOKEN id="token-50-21" pos="word" morph="none" start_char="5659" end_char="5669">preliminary</TOKEN>
<TOKEN id="token-50-22" pos="word" morph="none" start_char="5671" end_char="5677">reports</TOKEN>
<TOKEN id="token-50-23" pos="word" morph="none" start_char="5679" end_char="5682">from</TOKEN>
<TOKEN id="token-50-24" pos="word" morph="none" start_char="5684" end_char="5688">Wuhan</TOKEN>
<TOKEN id="token-50-25" pos="punct" morph="none" start_char="5689" end_char="5689">.</TOKEN>
</SEG>
<SEG id="segment-51" start_char="5691" end_char="5818">
<ORIGINAL_TEXT>"But this was definitely being briefed beginning at the end of November as something the military needed to take a posture on.""</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="punct" morph="none" start_char="5691" end_char="5691">"</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="5692" end_char="5694">But</TOKEN>
<TOKEN id="token-51-2" pos="word" morph="none" start_char="5696" end_char="5699">this</TOKEN>
<TOKEN id="token-51-3" pos="word" morph="none" start_char="5701" end_char="5703">was</TOKEN>
<TOKEN id="token-51-4" pos="word" morph="none" start_char="5705" end_char="5714">definitely</TOKEN>
<TOKEN id="token-51-5" pos="word" morph="none" start_char="5716" end_char="5720">being</TOKEN>
<TOKEN id="token-51-6" pos="word" morph="none" start_char="5722" end_char="5728">briefed</TOKEN>
<TOKEN id="token-51-7" pos="word" morph="none" start_char="5730" end_char="5738">beginning</TOKEN>
<TOKEN id="token-51-8" pos="word" morph="none" start_char="5740" end_char="5741">at</TOKEN>
<TOKEN id="token-51-9" pos="word" morph="none" start_char="5743" end_char="5745">the</TOKEN>
<TOKEN id="token-51-10" pos="word" morph="none" start_char="5747" end_char="5749">end</TOKEN>
<TOKEN id="token-51-11" pos="word" morph="none" start_char="5751" end_char="5752">of</TOKEN>
<TOKEN id="token-51-12" pos="word" morph="none" start_char="5754" end_char="5761">November</TOKEN>
<TOKEN id="token-51-13" pos="word" morph="none" start_char="5763" end_char="5764">as</TOKEN>
<TOKEN id="token-51-14" pos="word" morph="none" start_char="5766" end_char="5774">something</TOKEN>
<TOKEN id="token-51-15" pos="word" morph="none" start_char="5776" end_char="5778">the</TOKEN>
<TOKEN id="token-51-16" pos="word" morph="none" start_char="5780" end_char="5787">military</TOKEN>
<TOKEN id="token-51-17" pos="word" morph="none" start_char="5789" end_char="5794">needed</TOKEN>
<TOKEN id="token-51-18" pos="word" morph="none" start_char="5796" end_char="5797">to</TOKEN>
<TOKEN id="token-51-19" pos="word" morph="none" start_char="5799" end_char="5802">take</TOKEN>
<TOKEN id="token-51-20" pos="word" morph="none" start_char="5804" end_char="5804">a</TOKEN>
<TOKEN id="token-51-21" pos="word" morph="none" start_char="5806" end_char="5812">posture</TOKEN>
<TOKEN id="token-51-22" pos="word" morph="none" start_char="5814" end_char="5815">on</TOKEN>
<TOKEN id="token-51-23" pos="punct" morph="none" start_char="5816" end_char="5818">.""</TOKEN>
</SEG>
<SEG id="segment-52" start_char="5821" end_char="6043">
<ORIGINAL_TEXT>As of December 17, 2019, a total of 2506 hospitalized cases have been reported across 50 states, the District of Columbia, and two U.S. territories, and the Centers for Disease Control and Prevention.. all blamed on vaping.</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="5821" end_char="5822">As</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="5824" end_char="5825">of</TOKEN>
<TOKEN id="token-52-2" pos="word" morph="none" start_char="5827" end_char="5834">December</TOKEN>
<TOKEN id="token-52-3" pos="word" morph="none" start_char="5836" end_char="5837">17</TOKEN>
<TOKEN id="token-52-4" pos="punct" morph="none" start_char="5838" end_char="5838">,</TOKEN>
<TOKEN id="token-52-5" pos="word" morph="none" start_char="5840" end_char="5843">2019</TOKEN>
<TOKEN id="token-52-6" pos="punct" morph="none" start_char="5844" end_char="5844">,</TOKEN>
<TOKEN id="token-52-7" pos="word" morph="none" start_char="5846" end_char="5846">a</TOKEN>
<TOKEN id="token-52-8" pos="word" morph="none" start_char="5848" end_char="5852">total</TOKEN>
<TOKEN id="token-52-9" pos="word" morph="none" start_char="5854" end_char="5855">of</TOKEN>
<TOKEN id="token-52-10" pos="word" morph="none" start_char="5857" end_char="5860">2506</TOKEN>
<TOKEN id="token-52-11" pos="word" morph="none" start_char="5862" end_char="5873">hospitalized</TOKEN>
<TOKEN id="token-52-12" pos="word" morph="none" start_char="5875" end_char="5879">cases</TOKEN>
<TOKEN id="token-52-13" pos="word" morph="none" start_char="5881" end_char="5884">have</TOKEN>
<TOKEN id="token-52-14" pos="word" morph="none" start_char="5886" end_char="5889">been</TOKEN>
<TOKEN id="token-52-15" pos="word" morph="none" start_char="5891" end_char="5898">reported</TOKEN>
<TOKEN id="token-52-16" pos="word" morph="none" start_char="5900" end_char="5905">across</TOKEN>
<TOKEN id="token-52-17" pos="word" morph="none" start_char="5907" end_char="5908">50</TOKEN>
<TOKEN id="token-52-18" pos="word" morph="none" start_char="5910" end_char="5915">states</TOKEN>
<TOKEN id="token-52-19" pos="punct" morph="none" start_char="5916" end_char="5916">,</TOKEN>
<TOKEN id="token-52-20" pos="word" morph="none" start_char="5918" end_char="5920">the</TOKEN>
<TOKEN id="token-52-21" pos="word" morph="none" start_char="5922" end_char="5929">District</TOKEN>
<TOKEN id="token-52-22" pos="word" morph="none" start_char="5931" end_char="5932">of</TOKEN>
<TOKEN id="token-52-23" pos="word" morph="none" start_char="5934" end_char="5941">Columbia</TOKEN>
<TOKEN id="token-52-24" pos="punct" morph="none" start_char="5942" end_char="5942">,</TOKEN>
<TOKEN id="token-52-25" pos="word" morph="none" start_char="5944" end_char="5946">and</TOKEN>
<TOKEN id="token-52-26" pos="word" morph="none" start_char="5948" end_char="5950">two</TOKEN>
<TOKEN id="token-52-27" pos="unknown" morph="none" start_char="5952" end_char="5954">U.S</TOKEN>
<TOKEN id="token-52-28" pos="punct" morph="none" start_char="5955" end_char="5955">.</TOKEN>
<TOKEN id="token-52-29" pos="word" morph="none" start_char="5957" end_char="5967">territories</TOKEN>
<TOKEN id="token-52-30" pos="punct" morph="none" start_char="5968" end_char="5968">,</TOKEN>
<TOKEN id="token-52-31" pos="word" morph="none" start_char="5970" end_char="5972">and</TOKEN>
<TOKEN id="token-52-32" pos="word" morph="none" start_char="5974" end_char="5976">the</TOKEN>
<TOKEN id="token-52-33" pos="word" morph="none" start_char="5978" end_char="5984">Centers</TOKEN>
<TOKEN id="token-52-34" pos="word" morph="none" start_char="5986" end_char="5988">for</TOKEN>
<TOKEN id="token-52-35" pos="word" morph="none" start_char="5990" end_char="5996">Disease</TOKEN>
<TOKEN id="token-52-36" pos="word" morph="none" start_char="5998" end_char="6004">Control</TOKEN>
<TOKEN id="token-52-37" pos="word" morph="none" start_char="6006" end_char="6008">and</TOKEN>
<TOKEN id="token-52-38" pos="word" morph="none" start_char="6010" end_char="6019">Prevention</TOKEN>
<TOKEN id="token-52-39" pos="punct" morph="none" start_char="6020" end_char="6021">..</TOKEN>
<TOKEN id="token-52-40" pos="word" morph="none" start_char="6023" end_char="6025">all</TOKEN>
<TOKEN id="token-52-41" pos="word" morph="none" start_char="6027" end_char="6032">blamed</TOKEN>
<TOKEN id="token-52-42" pos="word" morph="none" start_char="6034" end_char="6035">on</TOKEN>
<TOKEN id="token-52-43" pos="word" morph="none" start_char="6037" end_char="6042">vaping</TOKEN>
<TOKEN id="token-52-44" pos="punct" morph="none" start_char="6043" end_char="6043">.</TOKEN>
</SEG>
<SEG id="segment-53" start_char="6046" end_char="6246">
<ORIGINAL_TEXT>A report in September 2019 talked about interesting symptoms of the vaping epidemic.. Respiratory symptoms reported by patients included shortness of breath, pain associated with breathing and a cough.</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="word" morph="none" start_char="6046" end_char="6046">A</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="6048" end_char="6053">report</TOKEN>
<TOKEN id="token-53-2" pos="word" morph="none" start_char="6055" end_char="6056">in</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="6058" end_char="6066">September</TOKEN>
<TOKEN id="token-53-4" pos="word" morph="none" start_char="6068" end_char="6071">2019</TOKEN>
<TOKEN id="token-53-5" pos="word" morph="none" start_char="6073" end_char="6078">talked</TOKEN>
<TOKEN id="token-53-6" pos="word" morph="none" start_char="6080" end_char="6084">about</TOKEN>
<TOKEN id="token-53-7" pos="word" morph="none" start_char="6086" end_char="6096">interesting</TOKEN>
<TOKEN id="token-53-8" pos="word" morph="none" start_char="6098" end_char="6105">symptoms</TOKEN>
<TOKEN id="token-53-9" pos="word" morph="none" start_char="6107" end_char="6108">of</TOKEN>
<TOKEN id="token-53-10" pos="word" morph="none" start_char="6110" end_char="6112">the</TOKEN>
<TOKEN id="token-53-11" pos="word" morph="none" start_char="6114" end_char="6119">vaping</TOKEN>
<TOKEN id="token-53-12" pos="word" morph="none" start_char="6121" end_char="6128">epidemic</TOKEN>
<TOKEN id="token-53-13" pos="punct" morph="none" start_char="6129" end_char="6130">..</TOKEN>
<TOKEN id="token-53-14" pos="word" morph="none" start_char="6132" end_char="6142">Respiratory</TOKEN>
<TOKEN id="token-53-15" pos="word" morph="none" start_char="6144" end_char="6151">symptoms</TOKEN>
<TOKEN id="token-53-16" pos="word" morph="none" start_char="6153" end_char="6160">reported</TOKEN>
<TOKEN id="token-53-17" pos="word" morph="none" start_char="6162" end_char="6163">by</TOKEN>
<TOKEN id="token-53-18" pos="word" morph="none" start_char="6165" end_char="6172">patients</TOKEN>
<TOKEN id="token-53-19" pos="word" morph="none" start_char="6174" end_char="6181">included</TOKEN>
<TOKEN id="token-53-20" pos="word" morph="none" start_char="6183" end_char="6191">shortness</TOKEN>
<TOKEN id="token-53-21" pos="word" morph="none" start_char="6193" end_char="6194">of</TOKEN>
<TOKEN id="token-53-22" pos="word" morph="none" start_char="6196" end_char="6201">breath</TOKEN>
<TOKEN id="token-53-23" pos="punct" morph="none" start_char="6202" end_char="6202">,</TOKEN>
<TOKEN id="token-53-24" pos="word" morph="none" start_char="6204" end_char="6207">pain</TOKEN>
<TOKEN id="token-53-25" pos="word" morph="none" start_char="6209" end_char="6218">associated</TOKEN>
<TOKEN id="token-53-26" pos="word" morph="none" start_char="6220" end_char="6223">with</TOKEN>
<TOKEN id="token-53-27" pos="word" morph="none" start_char="6225" end_char="6233">breathing</TOKEN>
<TOKEN id="token-53-28" pos="word" morph="none" start_char="6235" end_char="6237">and</TOKEN>
<TOKEN id="token-53-29" pos="word" morph="none" start_char="6239" end_char="6239">a</TOKEN>
<TOKEN id="token-53-30" pos="word" morph="none" start_char="6241" end_char="6245">cough</TOKEN>
<TOKEN id="token-53-31" pos="punct" morph="none" start_char="6246" end_char="6246">.</TOKEN>
</SEG>
<SEG id="segment-54" start_char="6248" end_char="6326">
<ORIGINAL_TEXT>Other symptoms included fever, nausea, vomiting and diarrhea, the release said.</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="word" morph="none" start_char="6248" end_char="6252">Other</TOKEN>
<TOKEN id="token-54-1" pos="word" morph="none" start_char="6254" end_char="6261">symptoms</TOKEN>
<TOKEN id="token-54-2" pos="word" morph="none" start_char="6263" end_char="6270">included</TOKEN>
<TOKEN id="token-54-3" pos="word" morph="none" start_char="6272" end_char="6276">fever</TOKEN>
<TOKEN id="token-54-4" pos="punct" morph="none" start_char="6277" end_char="6277">,</TOKEN>
<TOKEN id="token-54-5" pos="word" morph="none" start_char="6279" end_char="6284">nausea</TOKEN>
<TOKEN id="token-54-6" pos="punct" morph="none" start_char="6285" end_char="6285">,</TOKEN>
<TOKEN id="token-54-7" pos="word" morph="none" start_char="6287" end_char="6294">vomiting</TOKEN>
<TOKEN id="token-54-8" pos="word" morph="none" start_char="6296" end_char="6298">and</TOKEN>
<TOKEN id="token-54-9" pos="word" morph="none" start_char="6300" end_char="6307">diarrhea</TOKEN>
<TOKEN id="token-54-10" pos="punct" morph="none" start_char="6308" end_char="6308">,</TOKEN>
<TOKEN id="token-54-11" pos="word" morph="none" start_char="6310" end_char="6312">the</TOKEN>
<TOKEN id="token-54-12" pos="word" morph="none" start_char="6314" end_char="6320">release</TOKEN>
<TOKEN id="token-54-13" pos="word" morph="none" start_char="6322" end_char="6325">said</TOKEN>
<TOKEN id="token-54-14" pos="punct" morph="none" start_char="6326" end_char="6326">.</TOKEN>
</SEG>
<SEG id="segment-55" start_char="6328" end_char="6412">
<ORIGINAL_TEXT>But the cases displayed "no clear infectious cause and all required hospitalization."</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="word" morph="none" start_char="6328" end_char="6330">But</TOKEN>
<TOKEN id="token-55-1" pos="word" morph="none" start_char="6332" end_char="6334">the</TOKEN>
<TOKEN id="token-55-2" pos="word" morph="none" start_char="6336" end_char="6340">cases</TOKEN>
<TOKEN id="token-55-3" pos="word" morph="none" start_char="6342" end_char="6350">displayed</TOKEN>
<TOKEN id="token-55-4" pos="punct" morph="none" start_char="6352" end_char="6352">"</TOKEN>
<TOKEN id="token-55-5" pos="word" morph="none" start_char="6353" end_char="6354">no</TOKEN>
<TOKEN id="token-55-6" pos="word" morph="none" start_char="6356" end_char="6360">clear</TOKEN>
<TOKEN id="token-55-7" pos="word" morph="none" start_char="6362" end_char="6371">infectious</TOKEN>
<TOKEN id="token-55-8" pos="word" morph="none" start_char="6373" end_char="6377">cause</TOKEN>
<TOKEN id="token-55-9" pos="word" morph="none" start_char="6379" end_char="6381">and</TOKEN>
<TOKEN id="token-55-10" pos="word" morph="none" start_char="6383" end_char="6385">all</TOKEN>
<TOKEN id="token-55-11" pos="word" morph="none" start_char="6387" end_char="6394">required</TOKEN>
<TOKEN id="token-55-12" pos="word" morph="none" start_char="6396" end_char="6410">hospitalization</TOKEN>
<TOKEN id="token-55-13" pos="punct" morph="none" start_char="6411" end_char="6412">."</TOKEN>
</SEG>
<SEG id="segment-56" start_char="6415" end_char="6505">
<ORIGINAL_TEXT>In October 2019, the Wuhan Games could have been a way the virus spread all over the world.</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="6415" end_char="6416">In</TOKEN>
<TOKEN id="token-56-1" pos="word" morph="none" start_char="6418" end_char="6424">October</TOKEN>
<TOKEN id="token-56-2" pos="word" morph="none" start_char="6426" end_char="6429">2019</TOKEN>
<TOKEN id="token-56-3" pos="punct" morph="none" start_char="6430" end_char="6430">,</TOKEN>
<TOKEN id="token-56-4" pos="word" morph="none" start_char="6432" end_char="6434">the</TOKEN>
<TOKEN id="token-56-5" pos="word" morph="none" start_char="6436" end_char="6440">Wuhan</TOKEN>
<TOKEN id="token-56-6" pos="word" morph="none" start_char="6442" end_char="6446">Games</TOKEN>
<TOKEN id="token-56-7" pos="word" morph="none" start_char="6448" end_char="6452">could</TOKEN>
<TOKEN id="token-56-8" pos="word" morph="none" start_char="6454" end_char="6457">have</TOKEN>
<TOKEN id="token-56-9" pos="word" morph="none" start_char="6459" end_char="6462">been</TOKEN>
<TOKEN id="token-56-10" pos="word" morph="none" start_char="6464" end_char="6464">a</TOKEN>
<TOKEN id="token-56-11" pos="word" morph="none" start_char="6466" end_char="6468">way</TOKEN>
<TOKEN id="token-56-12" pos="word" morph="none" start_char="6470" end_char="6472">the</TOKEN>
<TOKEN id="token-56-13" pos="word" morph="none" start_char="6474" end_char="6478">virus</TOKEN>
<TOKEN id="token-56-14" pos="word" morph="none" start_char="6480" end_char="6485">spread</TOKEN>
<TOKEN id="token-56-15" pos="word" morph="none" start_char="6487" end_char="6489">all</TOKEN>
<TOKEN id="token-56-16" pos="word" morph="none" start_char="6491" end_char="6494">over</TOKEN>
<TOKEN id="token-56-17" pos="word" morph="none" start_char="6496" end_char="6498">the</TOKEN>
<TOKEN id="token-56-18" pos="word" morph="none" start_char="6500" end_char="6504">world</TOKEN>
<TOKEN id="token-56-19" pos="punct" morph="none" start_char="6505" end_char="6505">.</TOKEN>
</SEG>
<SEG id="segment-57" start_char="6507" end_char="6663">
<ORIGINAL_TEXT>Athletes who participated from other nations—both U.S. allies like France and Italy and adversaries like Iran—have reported suffering from COVID-19 symptoms.</ORIGINAL_TEXT>
<TOKEN id="token-57-0" pos="word" morph="none" start_char="6507" end_char="6514">Athletes</TOKEN>
<TOKEN id="token-57-1" pos="word" morph="none" start_char="6516" end_char="6518">who</TOKEN>
<TOKEN id="token-57-2" pos="word" morph="none" start_char="6520" end_char="6531">participated</TOKEN>
<TOKEN id="token-57-3" pos="word" morph="none" start_char="6533" end_char="6536">from</TOKEN>
<TOKEN id="token-57-4" pos="word" morph="none" start_char="6538" end_char="6542">other</TOKEN>
<TOKEN id="token-57-5" pos="unknown" morph="none" start_char="6544" end_char="6555">nations—both</TOKEN>
<TOKEN id="token-57-6" pos="unknown" morph="none" start_char="6557" end_char="6559">U.S</TOKEN>
<TOKEN id="token-57-7" pos="punct" morph="none" start_char="6560" end_char="6560">.</TOKEN>
<TOKEN id="token-57-8" pos="word" morph="none" start_char="6562" end_char="6567">allies</TOKEN>
<TOKEN id="token-57-9" pos="word" morph="none" start_char="6569" end_char="6572">like</TOKEN>
<TOKEN id="token-57-10" pos="word" morph="none" start_char="6574" end_char="6579">France</TOKEN>
<TOKEN id="token-57-11" pos="word" morph="none" start_char="6581" end_char="6583">and</TOKEN>
<TOKEN id="token-57-12" pos="word" morph="none" start_char="6585" end_char="6589">Italy</TOKEN>
<TOKEN id="token-57-13" pos="word" morph="none" start_char="6591" end_char="6593">and</TOKEN>
<TOKEN id="token-57-14" pos="word" morph="none" start_char="6595" end_char="6605">adversaries</TOKEN>
<TOKEN id="token-57-15" pos="word" morph="none" start_char="6607" end_char="6610">like</TOKEN>
<TOKEN id="token-57-16" pos="unknown" morph="none" start_char="6612" end_char="6620">Iran—have</TOKEN>
<TOKEN id="token-57-17" pos="word" morph="none" start_char="6622" end_char="6629">reported</TOKEN>
<TOKEN id="token-57-18" pos="word" morph="none" start_char="6631" end_char="6639">suffering</TOKEN>
<TOKEN id="token-57-19" pos="word" morph="none" start_char="6641" end_char="6644">from</TOKEN>
<TOKEN id="token-57-20" pos="unknown" morph="none" start_char="6646" end_char="6653">COVID-19</TOKEN>
<TOKEN id="token-57-21" pos="word" morph="none" start_char="6655" end_char="6662">symptoms</TOKEN>
<TOKEN id="token-57-22" pos="punct" morph="none" start_char="6663" end_char="6663">.</TOKEN>
</SEG>
<SEG id="segment-58" start_char="6665" end_char="6789">
<ORIGINAL_TEXT>Some Iranian athletes died from COVID-19, including some who were in Wuhan, according to news reports not verified by Tehran.</ORIGINAL_TEXT>
<TOKEN id="token-58-0" pos="word" morph="none" start_char="6665" end_char="6668">Some</TOKEN>
<TOKEN id="token-58-1" pos="word" morph="none" start_char="6670" end_char="6676">Iranian</TOKEN>
<TOKEN id="token-58-2" pos="word" morph="none" start_char="6678" end_char="6685">athletes</TOKEN>
<TOKEN id="token-58-3" pos="word" morph="none" start_char="6687" end_char="6690">died</TOKEN>
<TOKEN id="token-58-4" pos="word" morph="none" start_char="6692" end_char="6695">from</TOKEN>
<TOKEN id="token-58-5" pos="unknown" morph="none" start_char="6697" end_char="6704">COVID-19</TOKEN>
<TOKEN id="token-58-6" pos="punct" morph="none" start_char="6705" end_char="6705">,</TOKEN>
<TOKEN id="token-58-7" pos="word" morph="none" start_char="6707" end_char="6715">including</TOKEN>
<TOKEN id="token-58-8" pos="word" morph="none" start_char="6717" end_char="6720">some</TOKEN>
<TOKEN id="token-58-9" pos="word" morph="none" start_char="6722" end_char="6724">who</TOKEN>
<TOKEN id="token-58-10" pos="word" morph="none" start_char="6726" end_char="6729">were</TOKEN>
<TOKEN id="token-58-11" pos="word" morph="none" start_char="6731" end_char="6732">in</TOKEN>
<TOKEN id="token-58-12" pos="word" morph="none" start_char="6734" end_char="6738">Wuhan</TOKEN>
<TOKEN id="token-58-13" pos="punct" morph="none" start_char="6739" end_char="6739">,</TOKEN>
<TOKEN id="token-58-14" pos="word" morph="none" start_char="6741" end_char="6749">according</TOKEN>
<TOKEN id="token-58-15" pos="word" morph="none" start_char="6751" end_char="6752">to</TOKEN>
<TOKEN id="token-58-16" pos="word" morph="none" start_char="6754" end_char="6757">news</TOKEN>
<TOKEN id="token-58-17" pos="word" morph="none" start_char="6759" end_char="6765">reports</TOKEN>
<TOKEN id="token-58-18" pos="word" morph="none" start_char="6767" end_char="6769">not</TOKEN>
<TOKEN id="token-58-19" pos="word" morph="none" start_char="6771" end_char="6778">verified</TOKEN>
<TOKEN id="token-58-20" pos="word" morph="none" start_char="6780" end_char="6781">by</TOKEN>
<TOKEN id="token-58-21" pos="word" morph="none" start_char="6783" end_char="6788">Tehran</TOKEN>
<TOKEN id="token-58-22" pos="punct" morph="none" start_char="6789" end_char="6789">.</TOKEN>
</SEG>
<SEG id="segment-59" start_char="6792" end_char="6902">
<ORIGINAL_TEXT>Dr Li Wenliang was an active user of Weibo, China’s Twitter-like social media platform, over the past 10 years.</ORIGINAL_TEXT>
<TOKEN id="token-59-0" pos="word" morph="none" start_char="6792" end_char="6793">Dr</TOKEN>
<TOKEN id="token-59-1" pos="word" morph="none" start_char="6795" end_char="6796">Li</TOKEN>
<TOKEN id="token-59-2" pos="word" morph="none" start_char="6798" end_char="6805">Wenliang</TOKEN>
<TOKEN id="token-59-3" pos="word" morph="none" start_char="6807" end_char="6809">was</TOKEN>
<TOKEN id="token-59-4" pos="word" morph="none" start_char="6811" end_char="6812">an</TOKEN>
<TOKEN id="token-59-5" pos="word" morph="none" start_char="6814" end_char="6819">active</TOKEN>
<TOKEN id="token-59-6" pos="word" morph="none" start_char="6821" end_char="6824">user</TOKEN>
<TOKEN id="token-59-7" pos="word" morph="none" start_char="6826" end_char="6827">of</TOKEN>
<TOKEN id="token-59-8" pos="word" morph="none" start_char="6829" end_char="6833">Weibo</TOKEN>
<TOKEN id="token-59-9" pos="punct" morph="none" start_char="6834" end_char="6834">,</TOKEN>
<TOKEN id="token-59-10" pos="word" morph="none" start_char="6836" end_char="6842">China’s</TOKEN>
<TOKEN id="token-59-11" pos="unknown" morph="none" start_char="6844" end_char="6855">Twitter-like</TOKEN>
<TOKEN id="token-59-12" pos="word" morph="none" start_char="6857" end_char="6862">social</TOKEN>
<TOKEN id="token-59-13" pos="word" morph="none" start_char="6864" end_char="6868">media</TOKEN>
<TOKEN id="token-59-14" pos="word" morph="none" start_char="6870" end_char="6877">platform</TOKEN>
<TOKEN id="token-59-15" pos="punct" morph="none" start_char="6878" end_char="6878">,</TOKEN>
<TOKEN id="token-59-16" pos="word" morph="none" start_char="6880" end_char="6883">over</TOKEN>
<TOKEN id="token-59-17" pos="word" morph="none" start_char="6885" end_char="6887">the</TOKEN>
<TOKEN id="token-59-18" pos="word" morph="none" start_char="6889" end_char="6892">past</TOKEN>
<TOKEN id="token-59-19" pos="word" morph="none" start_char="6894" end_char="6895">10</TOKEN>
<TOKEN id="token-59-20" pos="word" morph="none" start_char="6897" end_char="6901">years</TOKEN>
<TOKEN id="token-59-21" pos="punct" morph="none" start_char="6902" end_char="6902">.</TOKEN>
</SEG>
<SEG id="segment-60" start_char="6904" end_char="7048">
<ORIGINAL_TEXT>He posted his last words on February 1: "Today the nucleic acid test result turns positive," he wrote of the test that confirmed he had Covid-19.</ORIGINAL_TEXT>
<TOKEN id="token-60-0" pos="word" morph="none" start_char="6904" end_char="6905">He</TOKEN>
<TOKEN id="token-60-1" pos="word" morph="none" start_char="6907" end_char="6912">posted</TOKEN>
<TOKEN id="token-60-2" pos="word" morph="none" start_char="6914" end_char="6916">his</TOKEN>
<TOKEN id="token-60-3" pos="word" morph="none" start_char="6918" end_char="6921">last</TOKEN>
<TOKEN id="token-60-4" pos="word" morph="none" start_char="6923" end_char="6927">words</TOKEN>
<TOKEN id="token-60-5" pos="word" morph="none" start_char="6929" end_char="6930">on</TOKEN>
<TOKEN id="token-60-6" pos="word" morph="none" start_char="6932" end_char="6939">February</TOKEN>
<TOKEN id="token-60-7" pos="word" morph="none" start_char="6941" end_char="6941">1</TOKEN>
<TOKEN id="token-60-8" pos="punct" morph="none" start_char="6942" end_char="6942">:</TOKEN>
<TOKEN id="token-60-9" pos="punct" morph="none" start_char="6944" end_char="6944">"</TOKEN>
<TOKEN id="token-60-10" pos="word" morph="none" start_char="6945" end_char="6949">Today</TOKEN>
<TOKEN id="token-60-11" pos="word" morph="none" start_char="6951" end_char="6953">the</TOKEN>
<TOKEN id="token-60-12" pos="word" morph="none" start_char="6955" end_char="6961">nucleic</TOKEN>
<TOKEN id="token-60-13" pos="word" morph="none" start_char="6963" end_char="6966">acid</TOKEN>
<TOKEN id="token-60-14" pos="word" morph="none" start_char="6968" end_char="6971">test</TOKEN>
<TOKEN id="token-60-15" pos="word" morph="none" start_char="6973" end_char="6978">result</TOKEN>
<TOKEN id="token-60-16" pos="word" morph="none" start_char="6980" end_char="6984">turns</TOKEN>
<TOKEN id="token-60-17" pos="word" morph="none" start_char="6986" end_char="6993">positive</TOKEN>
<TOKEN id="token-60-18" pos="punct" morph="none" start_char="6994" end_char="6995">,"</TOKEN>
<TOKEN id="token-60-19" pos="word" morph="none" start_char="6997" end_char="6998">he</TOKEN>
<TOKEN id="token-60-20" pos="word" morph="none" start_char="7000" end_char="7004">wrote</TOKEN>
<TOKEN id="token-60-21" pos="word" morph="none" start_char="7006" end_char="7007">of</TOKEN>
<TOKEN id="token-60-22" pos="word" morph="none" start_char="7009" end_char="7011">the</TOKEN>
<TOKEN id="token-60-23" pos="word" morph="none" start_char="7013" end_char="7016">test</TOKEN>
<TOKEN id="token-60-24" pos="word" morph="none" start_char="7018" end_char="7021">that</TOKEN>
<TOKEN id="token-60-25" pos="word" morph="none" start_char="7023" end_char="7031">confirmed</TOKEN>
<TOKEN id="token-60-26" pos="word" morph="none" start_char="7033" end_char="7034">he</TOKEN>
<TOKEN id="token-60-27" pos="word" morph="none" start_char="7036" end_char="7038">had</TOKEN>
<TOKEN id="token-60-28" pos="unknown" morph="none" start_char="7040" end_char="7047">Covid-19</TOKEN>
<TOKEN id="token-60-29" pos="punct" morph="none" start_char="7048" end_char="7048">.</TOKEN>
</SEG>
<SEG id="segment-61" start_char="7050" end_char="7112">
<ORIGINAL_TEXT>"The dust has settled, and the diagnosis is finally confirmed."</ORIGINAL_TEXT>
<TOKEN id="token-61-0" pos="punct" morph="none" start_char="7050" end_char="7050">"</TOKEN>
<TOKEN id="token-61-1" pos="word" morph="none" start_char="7051" end_char="7053">The</TOKEN>
<TOKEN id="token-61-2" pos="word" morph="none" start_char="7055" end_char="7058">dust</TOKEN>
<TOKEN id="token-61-3" pos="word" morph="none" start_char="7060" end_char="7062">has</TOKEN>
<TOKEN id="token-61-4" pos="word" morph="none" start_char="7064" end_char="7070">settled</TOKEN>
<TOKEN id="token-61-5" pos="punct" morph="none" start_char="7071" end_char="7071">,</TOKEN>
<TOKEN id="token-61-6" pos="word" morph="none" start_char="7073" end_char="7075">and</TOKEN>
<TOKEN id="token-61-7" pos="word" morph="none" start_char="7077" end_char="7079">the</TOKEN>
<TOKEN id="token-61-8" pos="word" morph="none" start_char="7081" end_char="7089">diagnosis</TOKEN>
<TOKEN id="token-61-9" pos="word" morph="none" start_char="7091" end_char="7092">is</TOKEN>
<TOKEN id="token-61-10" pos="word" morph="none" start_char="7094" end_char="7100">finally</TOKEN>
<TOKEN id="token-61-11" pos="word" morph="none" start_char="7102" end_char="7110">confirmed</TOKEN>
<TOKEN id="token-61-12" pos="punct" morph="none" start_char="7111" end_char="7112">."</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
