<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="ukr">
<DOC id="L0C049PJU" lang="ukr" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="2322" raw_text_md5="ecb7a727bfc9abfdd7380fba7dd2b9cf">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="74">
<ORIGINAL_TEXT>Researchers find coronavirus was circulating in Italy earlier than thought</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="11">Researchers</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="13" end_char="16">find</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="18" end_char="28">coronavirus</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="30" end_char="32">was</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="34" end_char="44">circulating</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="46" end_char="47">in</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="49" end_char="53">Italy</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="55" end_char="61">earlier</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="63" end_char="66">than</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="68" end_char="74">thought</TOKEN>
</SEG>
<SEG id="segment-1" start_char="78" end_char="311">
<ORIGINAL_TEXT>ROME (Reuters) - The new coronavirus was circulating in Italy in September 2019, a study by the National Cancer Institute (INT) of the Italian city of Milan shows, signaling that it might have spread beyond China earlier than thought.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="78" end_char="81">ROME</TOKEN>
<TOKEN id="token-1-1" pos="punct" morph="none" start_char="83" end_char="83">(</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="84" end_char="90">Reuters</TOKEN>
<TOKEN id="token-1-3" pos="punct" morph="none" start_char="91" end_char="91">)</TOKEN>
<TOKEN id="token-1-4" pos="punct" morph="none" start_char="93" end_char="93">-</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="95" end_char="97">The</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="99" end_char="101">new</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="103" end_char="113">coronavirus</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="115" end_char="117">was</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="119" end_char="129">circulating</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="131" end_char="132">in</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="134" end_char="138">Italy</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="140" end_char="141">in</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="143" end_char="151">September</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="153" end_char="156">2019</TOKEN>
<TOKEN id="token-1-15" pos="punct" morph="none" start_char="157" end_char="157">,</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="159" end_char="159">a</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="161" end_char="165">study</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="167" end_char="168">by</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="170" end_char="172">the</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="174" end_char="181">National</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="183" end_char="188">Cancer</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="190" end_char="198">Institute</TOKEN>
<TOKEN id="token-1-23" pos="punct" morph="none" start_char="200" end_char="200">(</TOKEN>
<TOKEN id="token-1-24" pos="word" morph="none" start_char="201" end_char="203">INT</TOKEN>
<TOKEN id="token-1-25" pos="punct" morph="none" start_char="204" end_char="204">)</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="206" end_char="207">of</TOKEN>
<TOKEN id="token-1-27" pos="word" morph="none" start_char="209" end_char="211">the</TOKEN>
<TOKEN id="token-1-28" pos="word" morph="none" start_char="213" end_char="219">Italian</TOKEN>
<TOKEN id="token-1-29" pos="word" morph="none" start_char="221" end_char="224">city</TOKEN>
<TOKEN id="token-1-30" pos="word" morph="none" start_char="226" end_char="227">of</TOKEN>
<TOKEN id="token-1-31" pos="word" morph="none" start_char="229" end_char="233">Milan</TOKEN>
<TOKEN id="token-1-32" pos="word" morph="none" start_char="235" end_char="239">shows</TOKEN>
<TOKEN id="token-1-33" pos="punct" morph="none" start_char="240" end_char="240">,</TOKEN>
<TOKEN id="token-1-34" pos="word" morph="none" start_char="242" end_char="250">signaling</TOKEN>
<TOKEN id="token-1-35" pos="word" morph="none" start_char="252" end_char="255">that</TOKEN>
<TOKEN id="token-1-36" pos="word" morph="none" start_char="257" end_char="258">it</TOKEN>
<TOKEN id="token-1-37" pos="word" morph="none" start_char="260" end_char="264">might</TOKEN>
<TOKEN id="token-1-38" pos="word" morph="none" start_char="266" end_char="269">have</TOKEN>
<TOKEN id="token-1-39" pos="word" morph="none" start_char="271" end_char="276">spread</TOKEN>
<TOKEN id="token-1-40" pos="word" morph="none" start_char="278" end_char="283">beyond</TOKEN>
<TOKEN id="token-1-41" pos="word" morph="none" start_char="285" end_char="289">China</TOKEN>
<TOKEN id="token-1-42" pos="word" morph="none" start_char="291" end_char="297">earlier</TOKEN>
<TOKEN id="token-1-43" pos="word" morph="none" start_char="299" end_char="302">than</TOKEN>
<TOKEN id="token-1-44" pos="word" morph="none" start_char="304" end_char="310">thought</TOKEN>
<TOKEN id="token-1-45" pos="punct" morph="none" start_char="311" end_char="311">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="315" end_char="508">
<ORIGINAL_TEXT>The World Health Organization has said the new coronavirus and COVID-19, the respiratory disease it causes, were unknown before the outbreak was reported in Wuhan, central China, late last year.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="315" end_char="317">The</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="319" end_char="323">World</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="325" end_char="330">Health</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="332" end_char="343">Organization</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="345" end_char="347">has</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="349" end_char="352">said</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="354" end_char="356">the</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="358" end_char="360">new</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="362" end_char="372">coronavirus</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="374" end_char="376">and</TOKEN>
<TOKEN id="token-2-10" pos="unknown" morph="none" start_char="378" end_char="385">COVID-19</TOKEN>
<TOKEN id="token-2-11" pos="punct" morph="none" start_char="386" end_char="386">,</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="388" end_char="390">the</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="392" end_char="402">respiratory</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="404" end_char="410">disease</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="412" end_char="413">it</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="415" end_char="420">causes</TOKEN>
<TOKEN id="token-2-17" pos="punct" morph="none" start_char="421" end_char="421">,</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="423" end_char="426">were</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="428" end_char="434">unknown</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="436" end_char="441">before</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="443" end_char="445">the</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="447" end_char="454">outbreak</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="456" end_char="458">was</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="460" end_char="467">reported</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="469" end_char="470">in</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="472" end_char="476">Wuhan</TOKEN>
<TOKEN id="token-2-27" pos="punct" morph="none" start_char="477" end_char="477">,</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="479" end_char="485">central</TOKEN>
<TOKEN id="token-2-29" pos="word" morph="none" start_char="487" end_char="491">China</TOKEN>
<TOKEN id="token-2-30" pos="punct" morph="none" start_char="492" end_char="492">,</TOKEN>
<TOKEN id="token-2-31" pos="word" morph="none" start_char="494" end_char="497">late</TOKEN>
<TOKEN id="token-2-32" pos="word" morph="none" start_char="499" end_char="502">last</TOKEN>
<TOKEN id="token-2-33" pos="word" morph="none" start_char="504" end_char="507">year</TOKEN>
<TOKEN id="token-2-34" pos="punct" morph="none" start_char="508" end_char="508">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="510" end_char="617">
<ORIGINAL_TEXT>But it has said "the possibility that the virus may have silently circulated elsewhere cannot be ruled out."</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="510" end_char="512">But</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="514" end_char="515">it</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="517" end_char="519">has</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="521" end_char="524">said</TOKEN>
<TOKEN id="token-3-4" pos="punct" morph="none" start_char="526" end_char="526">"</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="527" end_char="529">the</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="531" end_char="541">possibility</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="543" end_char="546">that</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="548" end_char="550">the</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="552" end_char="556">virus</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="558" end_char="560">may</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="562" end_char="565">have</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="567" end_char="574">silently</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="576" end_char="585">circulated</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="587" end_char="595">elsewhere</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="597" end_char="602">cannot</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="604" end_char="605">be</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="607" end_char="611">ruled</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="613" end_char="615">out</TOKEN>
<TOKEN id="token-3-19" pos="punct" morph="none" start_char="616" end_char="617">."</TOKEN>
</SEG>
<SEG id="segment-4" start_char="620" end_char="770">
<ORIGINAL_TEXT>The WHO said on Monday it was reviewing the results from Italy and additional information published there at the weekend and was seeking clarification.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="620" end_char="622">The</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="624" end_char="626">WHO</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="628" end_char="631">said</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="633" end_char="634">on</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="636" end_char="641">Monday</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="643" end_char="644">it</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="646" end_char="648">was</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="650" end_char="658">reviewing</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="660" end_char="662">the</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="664" end_char="670">results</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="672" end_char="675">from</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="677" end_char="681">Italy</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="683" end_char="685">and</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="687" end_char="696">additional</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="698" end_char="708">information</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="710" end_char="718">published</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="720" end_char="724">there</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="726" end_char="727">at</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="729" end_char="731">the</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="733" end_char="739">weekend</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="741" end_char="743">and</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="745" end_char="747">was</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="749" end_char="755">seeking</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="757" end_char="769">clarification</TOKEN>
<TOKEN id="token-4-24" pos="punct" morph="none" start_char="770" end_char="770">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="773" end_char="823">
<ORIGINAL_TEXT>Italy’s first COVID-19 patient was detected on Feb.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="773" end_char="779">Italy’s</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="781" end_char="785">first</TOKEN>
<TOKEN id="token-5-2" pos="unknown" morph="none" start_char="787" end_char="794">COVID-19</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="796" end_char="802">patient</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="804" end_char="806">was</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="808" end_char="815">detected</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="817" end_char="818">on</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="820" end_char="822">Feb</TOKEN>
<TOKEN id="token-5-8" pos="punct" morph="none" start_char="823" end_char="823">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="825" end_char="890">
<ORIGINAL_TEXT>21 in a small town near Milan, in the northern region of Lombardy.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="825" end_char="826">21</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="828" end_char="829">in</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="831" end_char="831">a</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="833" end_char="837">small</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="839" end_char="842">town</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="844" end_char="847">near</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="849" end_char="853">Milan</TOKEN>
<TOKEN id="token-6-7" pos="punct" morph="none" start_char="854" end_char="854">,</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="856" end_char="857">in</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="859" end_char="861">the</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="863" end_char="870">northern</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="872" end_char="877">region</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="879" end_char="880">of</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="882" end_char="889">Lombardy</TOKEN>
<TOKEN id="token-6-14" pos="punct" morph="none" start_char="890" end_char="890">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="893" end_char="1161">
<ORIGINAL_TEXT>The Italian researchers’ findings, published by the INT’s scientific magazine Tumori Journal, show 11.6% of 959 healthy volunteers enrolled in a lung cancer screening trial between September 2019 and March 2020 had developed coronavirus antibodies well before February.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="893" end_char="895">The</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="897" end_char="903">Italian</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="905" end_char="915">researchers</TOKEN>
<TOKEN id="token-7-3" pos="punct" morph="none" start_char="916" end_char="916">’</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="918" end_char="925">findings</TOKEN>
<TOKEN id="token-7-5" pos="punct" morph="none" start_char="926" end_char="926">,</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="928" end_char="936">published</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="938" end_char="939">by</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="941" end_char="943">the</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="945" end_char="949">INT’s</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="951" end_char="960">scientific</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="962" end_char="969">magazine</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="971" end_char="976">Tumori</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="978" end_char="984">Journal</TOKEN>
<TOKEN id="token-7-14" pos="punct" morph="none" start_char="985" end_char="985">,</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="987" end_char="990">show</TOKEN>
<TOKEN id="token-7-16" pos="unknown" morph="none" start_char="992" end_char="995">11.6</TOKEN>
<TOKEN id="token-7-17" pos="punct" morph="none" start_char="996" end_char="996">%</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="998" end_char="999">of</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="1001" end_char="1003">959</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="1005" end_char="1011">healthy</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="1013" end_char="1022">volunteers</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="1024" end_char="1031">enrolled</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="1033" end_char="1034">in</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="1036" end_char="1036">a</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="1038" end_char="1041">lung</TOKEN>
<TOKEN id="token-7-26" pos="word" morph="none" start_char="1043" end_char="1048">cancer</TOKEN>
<TOKEN id="token-7-27" pos="word" morph="none" start_char="1050" end_char="1058">screening</TOKEN>
<TOKEN id="token-7-28" pos="word" morph="none" start_char="1060" end_char="1064">trial</TOKEN>
<TOKEN id="token-7-29" pos="word" morph="none" start_char="1066" end_char="1072">between</TOKEN>
<TOKEN id="token-7-30" pos="word" morph="none" start_char="1074" end_char="1082">September</TOKEN>
<TOKEN id="token-7-31" pos="word" morph="none" start_char="1084" end_char="1087">2019</TOKEN>
<TOKEN id="token-7-32" pos="word" morph="none" start_char="1089" end_char="1091">and</TOKEN>
<TOKEN id="token-7-33" pos="word" morph="none" start_char="1093" end_char="1097">March</TOKEN>
<TOKEN id="token-7-34" pos="word" morph="none" start_char="1099" end_char="1102">2020</TOKEN>
<TOKEN id="token-7-35" pos="word" morph="none" start_char="1104" end_char="1106">had</TOKEN>
<TOKEN id="token-7-36" pos="word" morph="none" start_char="1108" end_char="1116">developed</TOKEN>
<TOKEN id="token-7-37" pos="word" morph="none" start_char="1118" end_char="1128">coronavirus</TOKEN>
<TOKEN id="token-7-38" pos="word" morph="none" start_char="1130" end_char="1139">antibodies</TOKEN>
<TOKEN id="token-7-39" pos="word" morph="none" start_char="1141" end_char="1144">well</TOKEN>
<TOKEN id="token-7-40" pos="word" morph="none" start_char="1146" end_char="1151">before</TOKEN>
<TOKEN id="token-7-41" pos="word" morph="none" start_char="1153" end_char="1160">February</TOKEN>
<TOKEN id="token-7-42" pos="punct" morph="none" start_char="1161" end_char="1161">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1164" end_char="1356">
<ORIGINAL_TEXT>A further SARS-CoV-2 antibodies test was carried out by the University of Siena for the same research titled "Unexpected detection of SARS-CoV-2 antibodies in the pre-pandemic period in Italy".</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1164" end_char="1164">A</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1166" end_char="1172">further</TOKEN>
<TOKEN id="token-8-2" pos="unknown" morph="none" start_char="1174" end_char="1183">SARS-CoV-2</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1185" end_char="1194">antibodies</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1196" end_char="1199">test</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1201" end_char="1203">was</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1205" end_char="1211">carried</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1213" end_char="1215">out</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1217" end_char="1218">by</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1220" end_char="1222">the</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1224" end_char="1233">University</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1235" end_char="1236">of</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1238" end_char="1242">Siena</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1244" end_char="1246">for</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1248" end_char="1250">the</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1252" end_char="1255">same</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1257" end_char="1264">research</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1266" end_char="1271">titled</TOKEN>
<TOKEN id="token-8-18" pos="punct" morph="none" start_char="1273" end_char="1273">"</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1274" end_char="1283">Unexpected</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="1285" end_char="1293">detection</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="1295" end_char="1296">of</TOKEN>
<TOKEN id="token-8-22" pos="unknown" morph="none" start_char="1298" end_char="1307">SARS-CoV-2</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="1309" end_char="1318">antibodies</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="1320" end_char="1321">in</TOKEN>
<TOKEN id="token-8-25" pos="word" morph="none" start_char="1323" end_char="1325">the</TOKEN>
<TOKEN id="token-8-26" pos="unknown" morph="none" start_char="1327" end_char="1338">pre-pandemic</TOKEN>
<TOKEN id="token-8-27" pos="word" morph="none" start_char="1340" end_char="1345">period</TOKEN>
<TOKEN id="token-8-28" pos="word" morph="none" start_char="1347" end_char="1348">in</TOKEN>
<TOKEN id="token-8-29" pos="word" morph="none" start_char="1350" end_char="1354">Italy</TOKEN>
<TOKEN id="token-8-30" pos="punct" morph="none" start_char="1355" end_char="1356">".</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1359" end_char="1556">
<ORIGINAL_TEXT>It showed that four cases dating back to the first week of October were positive for antibodies, meaning they had got infected in September, Giovanni Apolone, a co-author of the study, told Reuters.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1359" end_char="1360">It</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1362" end_char="1367">showed</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1369" end_char="1372">that</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1374" end_char="1377">four</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1379" end_char="1383">cases</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1385" end_char="1390">dating</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1392" end_char="1395">back</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1397" end_char="1398">to</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1400" end_char="1402">the</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1404" end_char="1408">first</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1410" end_char="1413">week</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1415" end_char="1416">of</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1418" end_char="1424">October</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1426" end_char="1429">were</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1431" end_char="1438">positive</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1440" end_char="1442">for</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1444" end_char="1453">antibodies</TOKEN>
<TOKEN id="token-9-17" pos="punct" morph="none" start_char="1454" end_char="1454">,</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1456" end_char="1462">meaning</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1464" end_char="1467">they</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1469" end_char="1471">had</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1473" end_char="1475">got</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1477" end_char="1484">infected</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1486" end_char="1487">in</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1489" end_char="1497">September</TOKEN>
<TOKEN id="token-9-25" pos="punct" morph="none" start_char="1498" end_char="1498">,</TOKEN>
<TOKEN id="token-9-26" pos="word" morph="none" start_char="1500" end_char="1507">Giovanni</TOKEN>
<TOKEN id="token-9-27" pos="word" morph="none" start_char="1509" end_char="1515">Apolone</TOKEN>
<TOKEN id="token-9-28" pos="punct" morph="none" start_char="1516" end_char="1516">,</TOKEN>
<TOKEN id="token-9-29" pos="word" morph="none" start_char="1518" end_char="1518">a</TOKEN>
<TOKEN id="token-9-30" pos="unknown" morph="none" start_char="1520" end_char="1528">co-author</TOKEN>
<TOKEN id="token-9-31" pos="word" morph="none" start_char="1530" end_char="1531">of</TOKEN>
<TOKEN id="token-9-32" pos="word" morph="none" start_char="1533" end_char="1535">the</TOKEN>
<TOKEN id="token-9-33" pos="word" morph="none" start_char="1537" end_char="1541">study</TOKEN>
<TOKEN id="token-9-34" pos="punct" morph="none" start_char="1542" end_char="1542">,</TOKEN>
<TOKEN id="token-9-35" pos="word" morph="none" start_char="1544" end_char="1547">told</TOKEN>
<TOKEN id="token-9-36" pos="word" morph="none" start_char="1549" end_char="1555">Reuters</TOKEN>
<TOKEN id="token-9-37" pos="punct" morph="none" start_char="1556" end_char="1556">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1560" end_char="1723">
<ORIGINAL_TEXT>"This is the main finding: people with no symptoms not only were positive after the serological tests but also had antibodies able to kill the virus," Apolone said.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="punct" morph="none" start_char="1560" end_char="1560">"</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1561" end_char="1564">This</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1566" end_char="1567">is</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1569" end_char="1571">the</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1573" end_char="1576">main</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1578" end_char="1584">finding</TOKEN>
<TOKEN id="token-10-6" pos="punct" morph="none" start_char="1585" end_char="1585">:</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1587" end_char="1592">people</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1594" end_char="1597">with</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1599" end_char="1600">no</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1602" end_char="1609">symptoms</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1611" end_char="1613">not</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1615" end_char="1618">only</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1620" end_char="1623">were</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1625" end_char="1632">positive</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1634" end_char="1638">after</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1640" end_char="1642">the</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1644" end_char="1654">serological</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1656" end_char="1660">tests</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1662" end_char="1664">but</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1666" end_char="1669">also</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1671" end_char="1673">had</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1675" end_char="1684">antibodies</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1686" end_char="1689">able</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1691" end_char="1692">to</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="1694" end_char="1697">kill</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="1699" end_char="1701">the</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="1703" end_char="1707">virus</TOKEN>
<TOKEN id="token-10-28" pos="punct" morph="none" start_char="1708" end_char="1709">,"</TOKEN>
<TOKEN id="token-10-29" pos="word" morph="none" start_char="1711" end_char="1717">Apolone</TOKEN>
<TOKEN id="token-10-30" pos="word" morph="none" start_char="1719" end_char="1722">said</TOKEN>
<TOKEN id="token-10-31" pos="punct" morph="none" start_char="1723" end_char="1723">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1726" end_char="1907">
<ORIGINAL_TEXT>"It means that the new coronavirus can circulate among the population for a long time and with a low rate of lethality, not because it is disappearing, only to surge again," he said.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="punct" morph="none" start_char="1726" end_char="1726">"</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1727" end_char="1728">It</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1730" end_char="1734">means</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1736" end_char="1739">that</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1741" end_char="1743">the</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1745" end_char="1747">new</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1749" end_char="1759">coronavirus</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1761" end_char="1763">can</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1765" end_char="1773">circulate</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1775" end_char="1779">among</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1781" end_char="1783">the</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1785" end_char="1794">population</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1796" end_char="1798">for</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1800" end_char="1800">a</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1802" end_char="1805">long</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1807" end_char="1810">time</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1812" end_char="1814">and</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1816" end_char="1819">with</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1821" end_char="1821">a</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="1823" end_char="1825">low</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1827" end_char="1830">rate</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="1832" end_char="1833">of</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="1835" end_char="1843">lethality</TOKEN>
<TOKEN id="token-11-23" pos="punct" morph="none" start_char="1844" end_char="1844">,</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="1846" end_char="1848">not</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="1850" end_char="1856">because</TOKEN>
<TOKEN id="token-11-26" pos="word" morph="none" start_char="1858" end_char="1859">it</TOKEN>
<TOKEN id="token-11-27" pos="word" morph="none" start_char="1861" end_char="1862">is</TOKEN>
<TOKEN id="token-11-28" pos="word" morph="none" start_char="1864" end_char="1875">disappearing</TOKEN>
<TOKEN id="token-11-29" pos="punct" morph="none" start_char="1876" end_char="1876">,</TOKEN>
<TOKEN id="token-11-30" pos="word" morph="none" start_char="1878" end_char="1881">only</TOKEN>
<TOKEN id="token-11-31" pos="word" morph="none" start_char="1883" end_char="1884">to</TOKEN>
<TOKEN id="token-11-32" pos="word" morph="none" start_char="1886" end_char="1890">surge</TOKEN>
<TOKEN id="token-11-33" pos="word" morph="none" start_char="1892" end_char="1896">again</TOKEN>
<TOKEN id="token-11-34" pos="punct" morph="none" start_char="1897" end_char="1898">,"</TOKEN>
<TOKEN id="token-11-35" pos="word" morph="none" start_char="1900" end_char="1901">he</TOKEN>
<TOKEN id="token-11-36" pos="word" morph="none" start_char="1903" end_char="1906">said</TOKEN>
<TOKEN id="token-11-37" pos="punct" morph="none" start_char="1907" end_char="1907">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1910" end_char="2073">
<ORIGINAL_TEXT>The WHO said it would contact the paper’s authors "to discuss and arrange for further analyses of available samples and verification of the neutralization results".</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1910" end_char="1912">The</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1914" end_char="1916">WHO</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1918" end_char="1921">said</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1923" end_char="1924">it</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1926" end_char="1930">would</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1932" end_char="1938">contact</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1940" end_char="1942">the</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1944" end_char="1950">paper’s</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1952" end_char="1958">authors</TOKEN>
<TOKEN id="token-12-9" pos="punct" morph="none" start_char="1960" end_char="1960">"</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1961" end_char="1962">to</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1964" end_char="1970">discuss</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1972" end_char="1974">and</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1976" end_char="1982">arrange</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1984" end_char="1986">for</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1988" end_char="1994">further</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1996" end_char="2003">analyses</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="2005" end_char="2006">of</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="2008" end_char="2016">available</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="2018" end_char="2024">samples</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="2026" end_char="2028">and</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="2030" end_char="2041">verification</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="2043" end_char="2044">of</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="2046" end_char="2048">the</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="2050" end_char="2063">neutralization</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="2065" end_char="2071">results</TOKEN>
<TOKEN id="token-12-26" pos="punct" morph="none" start_char="2072" end_char="2073">".</TOKEN>
</SEG>
<SEG id="segment-13" start_char="2076" end_char="2318">
<ORIGINAL_TEXT>Italian researchers told Reuters in March that they reported a higher than usual number of cases of severe pneumonia and flu in Lombardy in the last quarter of 2019 in a sign that the new coronavirus might have circulated earlier than thought.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="2076" end_char="2082">Italian</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="2084" end_char="2094">researchers</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="2096" end_char="2099">told</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="2101" end_char="2107">Reuters</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="2109" end_char="2110">in</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="2112" end_char="2116">March</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="2118" end_char="2121">that</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="2123" end_char="2126">they</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="2128" end_char="2135">reported</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="2137" end_char="2137">a</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="2139" end_char="2144">higher</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="2146" end_char="2149">than</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="2151" end_char="2155">usual</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="2157" end_char="2162">number</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="2164" end_char="2165">of</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="2167" end_char="2171">cases</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="2173" end_char="2174">of</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="2176" end_char="2181">severe</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="2183" end_char="2191">pneumonia</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="2193" end_char="2195">and</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="2197" end_char="2199">flu</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="2201" end_char="2202">in</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="2204" end_char="2211">Lombardy</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="2213" end_char="2214">in</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="2216" end_char="2218">the</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="2220" end_char="2223">last</TOKEN>
<TOKEN id="token-13-26" pos="word" morph="none" start_char="2225" end_char="2231">quarter</TOKEN>
<TOKEN id="token-13-27" pos="word" morph="none" start_char="2233" end_char="2234">of</TOKEN>
<TOKEN id="token-13-28" pos="word" morph="none" start_char="2236" end_char="2239">2019</TOKEN>
<TOKEN id="token-13-29" pos="word" morph="none" start_char="2241" end_char="2242">in</TOKEN>
<TOKEN id="token-13-30" pos="word" morph="none" start_char="2244" end_char="2244">a</TOKEN>
<TOKEN id="token-13-31" pos="word" morph="none" start_char="2246" end_char="2249">sign</TOKEN>
<TOKEN id="token-13-32" pos="word" morph="none" start_char="2251" end_char="2254">that</TOKEN>
<TOKEN id="token-13-33" pos="word" morph="none" start_char="2256" end_char="2258">the</TOKEN>
<TOKEN id="token-13-34" pos="word" morph="none" start_char="2260" end_char="2262">new</TOKEN>
<TOKEN id="token-13-35" pos="word" morph="none" start_char="2264" end_char="2274">coronavirus</TOKEN>
<TOKEN id="token-13-36" pos="word" morph="none" start_char="2276" end_char="2280">might</TOKEN>
<TOKEN id="token-13-37" pos="word" morph="none" start_char="2282" end_char="2285">have</TOKEN>
<TOKEN id="token-13-38" pos="word" morph="none" start_char="2287" end_char="2296">circulated</TOKEN>
<TOKEN id="token-13-39" pos="word" morph="none" start_char="2298" end_char="2304">earlier</TOKEN>
<TOKEN id="token-13-40" pos="word" morph="none" start_char="2306" end_char="2309">than</TOKEN>
<TOKEN id="token-13-41" pos="word" morph="none" start_char="2311" end_char="2317">thought</TOKEN>
<TOKEN id="token-13-42" pos="punct" morph="none" start_char="2318" end_char="2318">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
