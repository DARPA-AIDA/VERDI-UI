<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04ATQH" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="2996" raw_text_md5="947591fe3f85f90f217a0ed54923a480">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="81">
<ORIGINAL_TEXT>Frank Cuesta, sobre el origen del coronavirus: "En agosto ya estaba pasando algo"</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="5">Frank</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="7" end_char="12">Cuesta</TOKEN>
<TOKEN id="token-0-2" pos="punct" morph="none" start_char="13" end_char="13">,</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="15" end_char="19">sobre</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="21" end_char="22">el</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="24" end_char="29">origen</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="31" end_char="33">del</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="35" end_char="45">coronavirus</TOKEN>
<TOKEN id="token-0-8" pos="punct" morph="none" start_char="46" end_char="46">:</TOKEN>
<TOKEN id="token-0-9" pos="punct" morph="none" start_char="48" end_char="48">"</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="49" end_char="50">En</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="52" end_char="57">agosto</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="59" end_char="60">ya</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="62" end_char="67">estaba</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="69" end_char="75">pasando</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="77" end_char="80">algo</TOKEN>
<TOKEN id="token-0-16" pos="punct" morph="none" start_char="81" end_char="81">"</TOKEN>
</SEG>
<SEG id="segment-1" start_char="86" end_char="115">
<ORIGINAL_TEXT>Frank Cuesta acudió de nuevo a</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="86" end_char="90">Frank</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="92" end_char="97">Cuesta</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="99" end_char="104">acudió</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="106" end_char="107">de</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="109" end_char="113">nuevo</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="115" end_char="115">a</TOKEN>
</SEG>
<SEG id="segment-2" start_char="118" end_char="141">
<ORIGINAL_TEXT>Es la mañana de Federico</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="118" end_char="119">Es</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="121" end_char="122">la</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="124" end_char="129">mañana</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="131" end_char="132">de</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="134" end_char="141">Federico</TOKEN>
</SEG>
<SEG id="segment-3" start_char="144" end_char="217">
<ORIGINAL_TEXT>, en esRadio, para anunciar el estreno inminente de las nuevas entregas de</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="punct" morph="none" start_char="144" end_char="144">,</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="146" end_char="147">en</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="149" end_char="155">esRadio</TOKEN>
<TOKEN id="token-3-3" pos="punct" morph="none" start_char="156" end_char="156">,</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="158" end_char="161">para</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="163" end_char="170">anunciar</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="172" end_char="173">el</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="175" end_char="181">estreno</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="183" end_char="191">inminente</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="193" end_char="194">de</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="196" end_char="198">las</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="200" end_char="205">nuevas</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="207" end_char="214">entregas</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="216" end_char="217">de</TOKEN>
</SEG>
<SEG id="segment-4" start_char="220" end_char="229">
<ORIGINAL_TEXT>Wild Frank</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="220" end_char="223">Wild</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="225" end_char="229">Frank</TOKEN>
</SEG>
<SEG id="segment-5" start_char="232" end_char="310">
<ORIGINAL_TEXT>, su programa documental en Dmax, este domingo a las nueve y media de la noche.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="punct" morph="none" start_char="232" end_char="232">,</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="234" end_char="235">su</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="237" end_char="244">programa</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="246" end_char="255">documental</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="257" end_char="258">en</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="260" end_char="263">Dmax</TOKEN>
<TOKEN id="token-5-6" pos="punct" morph="none" start_char="264" end_char="264">,</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="266" end_char="269">este</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="271" end_char="277">domingo</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="279" end_char="279">a</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="281" end_char="283">las</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="285" end_char="289">nueve</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="291" end_char="291">y</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="293" end_char="297">media</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="299" end_char="300">de</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="302" end_char="303">la</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="305" end_char="309">noche</TOKEN>
<TOKEN id="token-5-17" pos="punct" morph="none" start_char="310" end_char="310">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="312" end_char="462">
<ORIGINAL_TEXT>Frank conversó con Federico Jiménez Losantos e Isabel González de los más diversos temas, entre ellos la gran influencia de los míticos documentales de</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="312" end_char="316">Frank</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="318" end_char="325">conversó</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="327" end_char="329">con</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="331" end_char="338">Federico</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="340" end_char="346">Jiménez</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="348" end_char="355">Losantos</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="357" end_char="357">e</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="359" end_char="364">Isabel</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="366" end_char="373">González</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="375" end_char="376">de</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="378" end_char="380">los</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="382" end_char="384">más</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="386" end_char="393">diversos</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="395" end_char="399">temas</TOKEN>
<TOKEN id="token-6-14" pos="punct" morph="none" start_char="400" end_char="400">,</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="402" end_char="406">entre</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="408" end_char="412">ellos</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="414" end_char="415">la</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="417" end_char="420">gran</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="422" end_char="431">influencia</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="433" end_char="434">de</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="436" end_char="438">los</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="440" end_char="446">míticos</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="448" end_char="459">documentales</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="461" end_char="462">de</TOKEN>
</SEG>
<SEG id="segment-7" start_char="465" end_char="485">
<ORIGINAL_TEXT>El Hombre y la Tierra</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="465" end_char="466">El</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="468" end_char="473">Hombre</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="475" end_char="475">y</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="477" end_char="478">la</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="480" end_char="485">Tierra</TOKEN>
</SEG>
<SEG id="segment-8" start_char="488" end_char="519">
<ORIGINAL_TEXT>de Félix Rodríguez de la Fuente.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="488" end_char="489">de</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="491" end_char="495">Félix</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="497" end_char="505">Rodríguez</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="507" end_char="508">de</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="510" end_char="511">la</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="513" end_char="518">Fuente</TOKEN>
<TOKEN id="token-8-6" pos="punct" morph="none" start_char="519" end_char="519">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="521" end_char="563">
<ORIGINAL_TEXT>De hecho, las nuevas entregas se subtitulan</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="521" end_char="522">De</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="524" end_char="528">hecho</TOKEN>
<TOKEN id="token-9-2" pos="punct" morph="none" start_char="529" end_char="529">,</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="531" end_char="533">las</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="535" end_char="540">nuevas</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="542" end_char="549">entregas</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="551" end_char="552">se</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="554" end_char="563">subtitulan</TOKEN>
</SEG>
<SEG id="segment-10" start_char="566" end_char="584">
<ORIGINAL_TEXT>El Legado de Félix.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="566" end_char="567">El</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="569" end_char="574">Legado</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="576" end_char="577">de</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="579" end_char="583">Félix</TOKEN>
<TOKEN id="token-10-4" pos="punct" morph="none" start_char="584" end_char="584">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="588" end_char="685">
<ORIGINAL_TEXT>Pero además de eso, Frank Cuesta abordó el pánico por la actual epidemia de coronavirus en España.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="588" end_char="591">Pero</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="593" end_char="598">además</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="600" end_char="601">de</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="603" end_char="605">eso</TOKEN>
<TOKEN id="token-11-4" pos="punct" morph="none" start_char="606" end_char="606">,</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="608" end_char="612">Frank</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="614" end_char="619">Cuesta</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="621" end_char="626">abordó</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="628" end_char="629">el</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="631" end_char="636">pánico</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="638" end_char="640">por</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="642" end_char="643">la</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="645" end_char="650">actual</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="652" end_char="659">epidemia</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="661" end_char="662">de</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="664" end_char="674">coronavirus</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="676" end_char="677">en</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="679" end_char="684">España</TOKEN>
<TOKEN id="token-11-18" pos="punct" morph="none" start_char="685" end_char="685">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="687" end_char="833">
<ORIGINAL_TEXT>Y asegura, de hecho, haber presenciado sus inicios en Tailandia hace ya unos meses, en pleno 2019, y que lleva campando sin control desde entonces.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="687" end_char="687">Y</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="689" end_char="695">asegura</TOKEN>
<TOKEN id="token-12-2" pos="punct" morph="none" start_char="696" end_char="696">,</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="698" end_char="699">de</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="701" end_char="705">hecho</TOKEN>
<TOKEN id="token-12-5" pos="punct" morph="none" start_char="706" end_char="706">,</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="708" end_char="712">haber</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="714" end_char="724">presenciado</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="726" end_char="728">sus</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="730" end_char="736">inicios</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="738" end_char="739">en</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="741" end_char="749">Tailandia</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="751" end_char="754">hace</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="756" end_char="757">ya</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="759" end_char="762">unos</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="764" end_char="768">meses</TOKEN>
<TOKEN id="token-12-16" pos="punct" morph="none" start_char="769" end_char="769">,</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="771" end_char="772">en</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="774" end_char="778">pleno</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="780" end_char="783">2019</TOKEN>
<TOKEN id="token-12-20" pos="punct" morph="none" start_char="784" end_char="784">,</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="786" end_char="786">y</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="788" end_char="790">que</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="792" end_char="796">lleva</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="798" end_char="805">campando</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="807" end_char="809">sin</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="811" end_char="817">control</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="819" end_char="823">desde</TOKEN>
<TOKEN id="token-12-28" pos="word" morph="none" start_char="825" end_char="832">entonces</TOKEN>
<TOKEN id="token-12-29" pos="punct" morph="none" start_char="833" end_char="833">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="836" end_char="881">
<ORIGINAL_TEXT>"Esto puede ser por el pangolín por una razón.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="punct" morph="none" start_char="836" end_char="836">"</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="837" end_char="840">Esto</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="842" end_char="846">puede</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="848" end_char="850">ser</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="852" end_char="854">por</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="856" end_char="857">el</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="859" end_char="866">pangolín</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="868" end_char="870">por</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="872" end_char="874">una</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="876" end_char="880">razón</TOKEN>
<TOKEN id="token-13-10" pos="punct" morph="none" start_char="881" end_char="881">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="883" end_char="1085">
<ORIGINAL_TEXT>Nosotros sabemos que se pillan una media de cincuenta a cien pangolines todas las semanas que salen a Vietnam o China", dijo a raíz de su habitual actividad luchando contra el tráfico ilegal de animales.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="883" end_char="890">Nosotros</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="892" end_char="898">sabemos</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="900" end_char="902">que</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="904" end_char="905">se</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="907" end_char="912">pillan</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="914" end_char="916">una</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="918" end_char="922">media</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="924" end_char="925">de</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="927" end_char="935">cincuenta</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="937" end_char="937">a</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="939" end_char="942">cien</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="944" end_char="953">pangolines</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="955" end_char="959">todas</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="961" end_char="963">las</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="965" end_char="971">semanas</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="973" end_char="975">que</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="977" end_char="981">salen</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="983" end_char="983">a</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="985" end_char="991">Vietnam</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="993" end_char="993">o</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="995" end_char="999">China</TOKEN>
<TOKEN id="token-14-21" pos="punct" morph="none" start_char="1000" end_char="1001">",</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="1003" end_char="1006">dijo</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="1008" end_char="1008">a</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="1010" end_char="1013">raíz</TOKEN>
<TOKEN id="token-14-25" pos="word" morph="none" start_char="1015" end_char="1016">de</TOKEN>
<TOKEN id="token-14-26" pos="word" morph="none" start_char="1018" end_char="1019">su</TOKEN>
<TOKEN id="token-14-27" pos="word" morph="none" start_char="1021" end_char="1028">habitual</TOKEN>
<TOKEN id="token-14-28" pos="word" morph="none" start_char="1030" end_char="1038">actividad</TOKEN>
<TOKEN id="token-14-29" pos="word" morph="none" start_char="1040" end_char="1047">luchando</TOKEN>
<TOKEN id="token-14-30" pos="word" morph="none" start_char="1049" end_char="1054">contra</TOKEN>
<TOKEN id="token-14-31" pos="word" morph="none" start_char="1056" end_char="1057">el</TOKEN>
<TOKEN id="token-14-32" pos="word" morph="none" start_char="1059" end_char="1065">tráfico</TOKEN>
<TOKEN id="token-14-33" pos="word" morph="none" start_char="1067" end_char="1072">ilegal</TOKEN>
<TOKEN id="token-14-34" pos="word" morph="none" start_char="1074" end_char="1075">de</TOKEN>
<TOKEN id="token-14-35" pos="word" morph="none" start_char="1077" end_char="1084">animales</TOKEN>
<TOKEN id="token-14-36" pos="punct" morph="none" start_char="1085" end_char="1085">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1087" end_char="1172">
<ORIGINAL_TEXT>"La segunda semana de agosto se dejó de pillar, y también de murciélago y de musaraña.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="punct" morph="none" start_char="1087" end_char="1087">"</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1088" end_char="1089">La</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1091" end_char="1097">segunda</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1099" end_char="1104">semana</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1106" end_char="1107">de</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1109" end_char="1114">agosto</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1116" end_char="1117">se</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1119" end_char="1122">dejó</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1124" end_char="1125">de</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1127" end_char="1132">pillar</TOKEN>
<TOKEN id="token-15-10" pos="punct" morph="none" start_char="1133" end_char="1133">,</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1135" end_char="1135">y</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1137" end_char="1143">también</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1145" end_char="1146">de</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1148" end_char="1157">murciélago</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="1159" end_char="1159">y</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="1161" end_char="1162">de</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="1164" end_char="1171">musaraña</TOKEN>
<TOKEN id="token-15-18" pos="punct" morph="none" start_char="1172" end_char="1172">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1174" end_char="1221">
<ORIGINAL_TEXT>No hemos encontrado ni un cargamento, cosa rara.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1174" end_char="1175">No</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1177" end_char="1181">hemos</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1183" end_char="1192">encontrado</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1194" end_char="1195">ni</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1197" end_char="1198">un</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1200" end_char="1209">cargamento</TOKEN>
<TOKEN id="token-16-6" pos="punct" morph="none" start_char="1210" end_char="1210">,</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1212" end_char="1215">cosa</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1217" end_char="1220">rara</TOKEN>
<TOKEN id="token-16-9" pos="punct" morph="none" start_char="1221" end_char="1221">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1223" end_char="1321">
<ORIGINAL_TEXT>Te estoy hablando del mes de agosto", dijo sobre los primeras pistas de que algo estaba ocurriendo.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1223" end_char="1224">Te</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1226" end_char="1230">estoy</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="1232" end_char="1239">hablando</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="1241" end_char="1243">del</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="1245" end_char="1247">mes</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="1249" end_char="1250">de</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="1252" end_char="1257">agosto</TOKEN>
<TOKEN id="token-17-7" pos="punct" morph="none" start_char="1258" end_char="1259">",</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="1261" end_char="1264">dijo</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="1266" end_char="1270">sobre</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="1272" end_char="1274">los</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="1276" end_char="1283">primeras</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="1285" end_char="1290">pistas</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="1292" end_char="1293">de</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="1295" end_char="1297">que</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="1299" end_char="1302">algo</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="1304" end_char="1309">estaba</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="1311" end_char="1320">ocurriendo</TOKEN>
<TOKEN id="token-17-18" pos="punct" morph="none" start_char="1321" end_char="1321">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1323" end_char="1452">
<ORIGINAL_TEXT>Frank se preguntó en esRadio "¿cómo puedes coger cien pangolines a la semana y salir de las mismas zonas y luego dejar de hacerlo?</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="1323" end_char="1327">Frank</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="1329" end_char="1330">se</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="1332" end_char="1339">preguntó</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="1341" end_char="1342">en</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="1344" end_char="1350">esRadio</TOKEN>
<TOKEN id="token-18-5" pos="punct" morph="none" start_char="1352" end_char="1353">"¿</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="1354" end_char="1357">cómo</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="1359" end_char="1364">puedes</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="1366" end_char="1370">coger</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="1372" end_char="1375">cien</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="1377" end_char="1386">pangolines</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="1388" end_char="1388">a</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="1390" end_char="1391">la</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="1393" end_char="1398">semana</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="1400" end_char="1400">y</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="1402" end_char="1406">salir</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="1408" end_char="1409">de</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="1411" end_char="1413">las</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="1415" end_char="1420">mismas</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="1422" end_char="1426">zonas</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="1428" end_char="1428">y</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="1430" end_char="1434">luego</TOKEN>
<TOKEN id="token-18-22" pos="word" morph="none" start_char="1436" end_char="1440">dejar</TOKEN>
<TOKEN id="token-18-23" pos="word" morph="none" start_char="1442" end_char="1443">de</TOKEN>
<TOKEN id="token-18-24" pos="word" morph="none" start_char="1445" end_char="1451">hacerlo</TOKEN>
<TOKEN id="token-18-25" pos="punct" morph="none" start_char="1452" end_char="1452">?</TOKEN>
</SEG>
<SEG id="segment-19" start_char="1454" end_char="1455">
<ORIGINAL_TEXT>".</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="punct" morph="none" start_char="1454" end_char="1455">".</TOKEN>
</SEG>
<SEG id="segment-20" start_char="1458" end_char="1649">
<ORIGINAL_TEXT>De modo que, según Frank Cuesta, "en agosto ya pasaba algo ahí"… pero China no anunció el coronavirus hasta mucho, mucho después, sugiriendo que allí sí se detectó pero no se advirtió a nadie.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="1458" end_char="1459">De</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="1461" end_char="1464">modo</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="1466" end_char="1468">que</TOKEN>
<TOKEN id="token-20-3" pos="punct" morph="none" start_char="1469" end_char="1469">,</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="1471" end_char="1475">según</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="1477" end_char="1481">Frank</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="1483" end_char="1488">Cuesta</TOKEN>
<TOKEN id="token-20-7" pos="punct" morph="none" start_char="1489" end_char="1489">,</TOKEN>
<TOKEN id="token-20-8" pos="punct" morph="none" start_char="1491" end_char="1491">"</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="1492" end_char="1493">en</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="1495" end_char="1500">agosto</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="1502" end_char="1503">ya</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="1505" end_char="1510">pasaba</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="1512" end_char="1515">algo</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="1517" end_char="1519">ahí</TOKEN>
<TOKEN id="token-20-15" pos="punct" morph="none" start_char="1520" end_char="1521">"…</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="1523" end_char="1526">pero</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="1528" end_char="1532">China</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="1534" end_char="1535">no</TOKEN>
<TOKEN id="token-20-19" pos="word" morph="none" start_char="1537" end_char="1543">anunció</TOKEN>
<TOKEN id="token-20-20" pos="word" morph="none" start_char="1545" end_char="1546">el</TOKEN>
<TOKEN id="token-20-21" pos="word" morph="none" start_char="1548" end_char="1558">coronavirus</TOKEN>
<TOKEN id="token-20-22" pos="word" morph="none" start_char="1560" end_char="1564">hasta</TOKEN>
<TOKEN id="token-20-23" pos="word" morph="none" start_char="1566" end_char="1570">mucho</TOKEN>
<TOKEN id="token-20-24" pos="punct" morph="none" start_char="1571" end_char="1571">,</TOKEN>
<TOKEN id="token-20-25" pos="word" morph="none" start_char="1573" end_char="1577">mucho</TOKEN>
<TOKEN id="token-20-26" pos="word" morph="none" start_char="1579" end_char="1585">después</TOKEN>
<TOKEN id="token-20-27" pos="punct" morph="none" start_char="1586" end_char="1586">,</TOKEN>
<TOKEN id="token-20-28" pos="word" morph="none" start_char="1588" end_char="1597">sugiriendo</TOKEN>
<TOKEN id="token-20-29" pos="word" morph="none" start_char="1599" end_char="1601">que</TOKEN>
<TOKEN id="token-20-30" pos="word" morph="none" start_char="1603" end_char="1606">allí</TOKEN>
<TOKEN id="token-20-31" pos="word" morph="none" start_char="1608" end_char="1609">sí</TOKEN>
<TOKEN id="token-20-32" pos="word" morph="none" start_char="1611" end_char="1612">se</TOKEN>
<TOKEN id="token-20-33" pos="word" morph="none" start_char="1614" end_char="1620">detectó</TOKEN>
<TOKEN id="token-20-34" pos="word" morph="none" start_char="1622" end_char="1625">pero</TOKEN>
<TOKEN id="token-20-35" pos="word" morph="none" start_char="1627" end_char="1628">no</TOKEN>
<TOKEN id="token-20-36" pos="word" morph="none" start_char="1630" end_char="1631">se</TOKEN>
<TOKEN id="token-20-37" pos="word" morph="none" start_char="1633" end_char="1640">advirtió</TOKEN>
<TOKEN id="token-20-38" pos="word" morph="none" start_char="1642" end_char="1642">a</TOKEN>
<TOKEN id="token-20-39" pos="word" morph="none" start_char="1644" end_char="1648">nadie</TOKEN>
<TOKEN id="token-20-40" pos="punct" morph="none" start_char="1649" end_char="1649">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="1651" end_char="1791">
<ORIGINAL_TEXT>Tal y como apuntó Federico Jiménez Losantos, "hubo un médico que sí lo denunció y lo metieron en la cárcel, y después lo sacaron para morir".</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="1651" end_char="1653">Tal</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="1655" end_char="1655">y</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="1657" end_char="1660">como</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="1662" end_char="1667">apuntó</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="1669" end_char="1676">Federico</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="1678" end_char="1684">Jiménez</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="1686" end_char="1693">Losantos</TOKEN>
<TOKEN id="token-21-7" pos="punct" morph="none" start_char="1694" end_char="1694">,</TOKEN>
<TOKEN id="token-21-8" pos="punct" morph="none" start_char="1696" end_char="1696">"</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="1697" end_char="1700">hubo</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="1702" end_char="1703">un</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="1705" end_char="1710">médico</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="1712" end_char="1714">que</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="1716" end_char="1717">sí</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="1719" end_char="1720">lo</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="1722" end_char="1729">denunció</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="1731" end_char="1731">y</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="1733" end_char="1734">lo</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="1736" end_char="1743">metieron</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="1745" end_char="1746">en</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="1748" end_char="1749">la</TOKEN>
<TOKEN id="token-21-21" pos="word" morph="none" start_char="1751" end_char="1756">cárcel</TOKEN>
<TOKEN id="token-21-22" pos="punct" morph="none" start_char="1757" end_char="1757">,</TOKEN>
<TOKEN id="token-21-23" pos="word" morph="none" start_char="1759" end_char="1759">y</TOKEN>
<TOKEN id="token-21-24" pos="word" morph="none" start_char="1761" end_char="1767">después</TOKEN>
<TOKEN id="token-21-25" pos="word" morph="none" start_char="1769" end_char="1770">lo</TOKEN>
<TOKEN id="token-21-26" pos="word" morph="none" start_char="1772" end_char="1778">sacaron</TOKEN>
<TOKEN id="token-21-27" pos="word" morph="none" start_char="1780" end_char="1783">para</TOKEN>
<TOKEN id="token-21-28" pos="word" morph="none" start_char="1785" end_char="1789">morir</TOKEN>
<TOKEN id="token-21-29" pos="punct" morph="none" start_char="1790" end_char="1791">".</TOKEN>
</SEG>
<SEG id="segment-22" start_char="1794" end_char="1922">
<ORIGINAL_TEXT>El problema es que tanto el murciélago como la musaraña o el propio pangolín se usan también "como antes los monos, como cobayas.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="1794" end_char="1795">El</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="1797" end_char="1804">problema</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="1806" end_char="1807">es</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="1809" end_char="1811">que</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="1813" end_char="1817">tanto</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="1819" end_char="1820">el</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="1822" end_char="1831">murciélago</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="1833" end_char="1836">como</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="1838" end_char="1839">la</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="1841" end_char="1848">musaraña</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="1850" end_char="1850">o</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="1852" end_char="1853">el</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="1855" end_char="1860">propio</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="1862" end_char="1869">pangolín</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="1871" end_char="1872">se</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="1874" end_char="1877">usan</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="1879" end_char="1885">también</TOKEN>
<TOKEN id="token-22-17" pos="punct" morph="none" start_char="1887" end_char="1887">"</TOKEN>
<TOKEN id="token-22-18" pos="word" morph="none" start_char="1888" end_char="1891">como</TOKEN>
<TOKEN id="token-22-19" pos="word" morph="none" start_char="1893" end_char="1897">antes</TOKEN>
<TOKEN id="token-22-20" pos="word" morph="none" start_char="1899" end_char="1901">los</TOKEN>
<TOKEN id="token-22-21" pos="word" morph="none" start_char="1903" end_char="1907">monos</TOKEN>
<TOKEN id="token-22-22" pos="punct" morph="none" start_char="1908" end_char="1908">,</TOKEN>
<TOKEN id="token-22-23" pos="word" morph="none" start_char="1910" end_char="1913">como</TOKEN>
<TOKEN id="token-22-24" pos="word" morph="none" start_char="1915" end_char="1921">cobayas</TOKEN>
<TOKEN id="token-22-25" pos="punct" morph="none" start_char="1922" end_char="1922">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="1924" end_char="1942">
<ORIGINAL_TEXT>Para experimentar".</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="1924" end_char="1927">Para</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="1929" end_char="1940">experimentar</TOKEN>
<TOKEN id="token-23-2" pos="punct" morph="none" start_char="1941" end_char="1942">".</TOKEN>
</SEG>
<SEG id="segment-24" start_char="1944" end_char="2141">
<ORIGINAL_TEXT>Y el hecho de que ese animal se usa para todo literalmente: "Del pangolín se usan hasta las escamas para ponerselas en las heridas… Y que se lo comen casi crudo, lo meten unos segundos en agua y ya.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="1944" end_char="1944">Y</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="1946" end_char="1947">el</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="1949" end_char="1953">hecho</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="1955" end_char="1956">de</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="1958" end_char="1960">que</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="1962" end_char="1964">ese</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="1966" end_char="1971">animal</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="1973" end_char="1974">se</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="1976" end_char="1978">usa</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="1980" end_char="1983">para</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="1985" end_char="1988">todo</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="1990" end_char="2001">literalmente</TOKEN>
<TOKEN id="token-24-12" pos="punct" morph="none" start_char="2002" end_char="2002">:</TOKEN>
<TOKEN id="token-24-13" pos="punct" morph="none" start_char="2004" end_char="2004">"</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="2005" end_char="2007">Del</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="2009" end_char="2016">pangolín</TOKEN>
<TOKEN id="token-24-16" pos="word" morph="none" start_char="2018" end_char="2019">se</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="2021" end_char="2024">usan</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="2026" end_char="2030">hasta</TOKEN>
<TOKEN id="token-24-19" pos="word" morph="none" start_char="2032" end_char="2034">las</TOKEN>
<TOKEN id="token-24-20" pos="word" morph="none" start_char="2036" end_char="2042">escamas</TOKEN>
<TOKEN id="token-24-21" pos="word" morph="none" start_char="2044" end_char="2047">para</TOKEN>
<TOKEN id="token-24-22" pos="word" morph="none" start_char="2049" end_char="2058">ponerselas</TOKEN>
<TOKEN id="token-24-23" pos="word" morph="none" start_char="2060" end_char="2061">en</TOKEN>
<TOKEN id="token-24-24" pos="word" morph="none" start_char="2063" end_char="2065">las</TOKEN>
<TOKEN id="token-24-25" pos="word" morph="none" start_char="2067" end_char="2073">heridas</TOKEN>
<TOKEN id="token-24-26" pos="punct" morph="none" start_char="2074" end_char="2074">…</TOKEN>
<TOKEN id="token-24-27" pos="word" morph="none" start_char="2076" end_char="2076">Y</TOKEN>
<TOKEN id="token-24-28" pos="word" morph="none" start_char="2078" end_char="2080">que</TOKEN>
<TOKEN id="token-24-29" pos="word" morph="none" start_char="2082" end_char="2083">se</TOKEN>
<TOKEN id="token-24-30" pos="word" morph="none" start_char="2085" end_char="2086">lo</TOKEN>
<TOKEN id="token-24-31" pos="word" morph="none" start_char="2088" end_char="2092">comen</TOKEN>
<TOKEN id="token-24-32" pos="word" morph="none" start_char="2094" end_char="2097">casi</TOKEN>
<TOKEN id="token-24-33" pos="word" morph="none" start_char="2099" end_char="2103">crudo</TOKEN>
<TOKEN id="token-24-34" pos="punct" morph="none" start_char="2104" end_char="2104">,</TOKEN>
<TOKEN id="token-24-35" pos="word" morph="none" start_char="2106" end_char="2107">lo</TOKEN>
<TOKEN id="token-24-36" pos="word" morph="none" start_char="2109" end_char="2113">meten</TOKEN>
<TOKEN id="token-24-37" pos="word" morph="none" start_char="2115" end_char="2118">unos</TOKEN>
<TOKEN id="token-24-38" pos="word" morph="none" start_char="2120" end_char="2127">segundos</TOKEN>
<TOKEN id="token-24-39" pos="word" morph="none" start_char="2129" end_char="2130">en</TOKEN>
<TOKEN id="token-24-40" pos="word" morph="none" start_char="2132" end_char="2135">agua</TOKEN>
<TOKEN id="token-24-41" pos="word" morph="none" start_char="2137" end_char="2137">y</TOKEN>
<TOKEN id="token-24-42" pos="word" morph="none" start_char="2139" end_char="2140">ya</TOKEN>
<TOKEN id="token-24-43" pos="punct" morph="none" start_char="2141" end_char="2141">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2143" end_char="2166">
<ORIGINAL_TEXT>Es una especie de sushi.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="2143" end_char="2144">Es</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="2146" end_char="2148">una</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="2150" end_char="2156">especie</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="2158" end_char="2159">de</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="2161" end_char="2165">sushi</TOKEN>
<TOKEN id="token-25-5" pos="punct" morph="none" start_char="2166" end_char="2166">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="2168" end_char="2227">
<ORIGINAL_TEXT>Es el mamífero mas castigado del mundo, han acabado con él".</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="2168" end_char="2169">Es</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="2171" end_char="2172">el</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="2174" end_char="2181">mamífero</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="2183" end_char="2185">mas</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="2187" end_char="2195">castigado</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="2197" end_char="2199">del</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="2201" end_char="2205">mundo</TOKEN>
<TOKEN id="token-26-7" pos="punct" morph="none" start_char="2206" end_char="2206">,</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="2208" end_char="2210">han</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="2212" end_char="2218">acabado</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="2220" end_char="2222">con</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="2224" end_char="2225">él</TOKEN>
<TOKEN id="token-26-12" pos="punct" morph="none" start_char="2226" end_char="2227">".</TOKEN>
</SEG>
<SEG id="segment-27" start_char="2229" end_char="2258">
<ORIGINAL_TEXT>Frank de la Jungla denunció en</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="2229" end_char="2233">Frank</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="2235" end_char="2236">de</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="2238" end_char="2239">la</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="2241" end_char="2246">Jungla</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="2248" end_char="2255">denunció</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="2257" end_char="2258">en</TOKEN>
</SEG>
<SEG id="segment-28" start_char="2261" end_char="2284">
<ORIGINAL_TEXT>Es la mañana de Federico</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="2261" end_char="2262">Es</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="2264" end_char="2265">la</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="2267" end_char="2272">mañana</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="2274" end_char="2275">de</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="2277" end_char="2284">Federico</TOKEN>
</SEG>
<SEG id="segment-29" start_char="2287" end_char="2384">
<ORIGINAL_TEXT>que "el problema no es el pangolín, es que se lo han comido y no han dicho lo que estaba pasando".</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="2287" end_char="2289">que</TOKEN>
<TOKEN id="token-29-1" pos="punct" morph="none" start_char="2291" end_char="2291">"</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="2292" end_char="2293">el</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="2295" end_char="2302">problema</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="2304" end_char="2305">no</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="2307" end_char="2308">es</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="2310" end_char="2311">el</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="2313" end_char="2320">pangolín</TOKEN>
<TOKEN id="token-29-8" pos="punct" morph="none" start_char="2321" end_char="2321">,</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="2323" end_char="2324">es</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="2326" end_char="2328">que</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="2330" end_char="2331">se</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="2333" end_char="2334">lo</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="2336" end_char="2338">han</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="2340" end_char="2345">comido</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="2347" end_char="2347">y</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="2349" end_char="2350">no</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="2352" end_char="2354">han</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="2356" end_char="2360">dicho</TOKEN>
<TOKEN id="token-29-19" pos="word" morph="none" start_char="2362" end_char="2363">lo</TOKEN>
<TOKEN id="token-29-20" pos="word" morph="none" start_char="2365" end_char="2367">que</TOKEN>
<TOKEN id="token-29-21" pos="word" morph="none" start_char="2369" end_char="2374">estaba</TOKEN>
<TOKEN id="token-29-22" pos="word" morph="none" start_char="2376" end_char="2382">pasando</TOKEN>
<TOKEN id="token-29-23" pos="punct" morph="none" start_char="2383" end_char="2384">".</TOKEN>
</SEG>
<SEG id="segment-30" start_char="2387" end_char="2637">
<ORIGINAL_TEXT>El asunto lleva tantos meses cociéndose que Frank cree que allí, en Tailandia, en realidad casi todo el mundo ya lo ha pasado en los meses de agosto, septiembre u octubre de 2019, apuntando a que la epidemia lleva en realidad varios meses sin control.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="2387" end_char="2388">El</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="2390" end_char="2395">asunto</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="2397" end_char="2401">lleva</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="2403" end_char="2408">tantos</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="2410" end_char="2414">meses</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="2416" end_char="2425">cociéndose</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="2427" end_char="2429">que</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="2431" end_char="2435">Frank</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="2437" end_char="2440">cree</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="2442" end_char="2444">que</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="2446" end_char="2449">allí</TOKEN>
<TOKEN id="token-30-11" pos="punct" morph="none" start_char="2450" end_char="2450">,</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="2452" end_char="2453">en</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="2455" end_char="2463">Tailandia</TOKEN>
<TOKEN id="token-30-14" pos="punct" morph="none" start_char="2464" end_char="2464">,</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="2466" end_char="2467">en</TOKEN>
<TOKEN id="token-30-16" pos="word" morph="none" start_char="2469" end_char="2476">realidad</TOKEN>
<TOKEN id="token-30-17" pos="word" morph="none" start_char="2478" end_char="2481">casi</TOKEN>
<TOKEN id="token-30-18" pos="word" morph="none" start_char="2483" end_char="2486">todo</TOKEN>
<TOKEN id="token-30-19" pos="word" morph="none" start_char="2488" end_char="2489">el</TOKEN>
<TOKEN id="token-30-20" pos="word" morph="none" start_char="2491" end_char="2495">mundo</TOKEN>
<TOKEN id="token-30-21" pos="word" morph="none" start_char="2497" end_char="2498">ya</TOKEN>
<TOKEN id="token-30-22" pos="word" morph="none" start_char="2500" end_char="2501">lo</TOKEN>
<TOKEN id="token-30-23" pos="word" morph="none" start_char="2503" end_char="2504">ha</TOKEN>
<TOKEN id="token-30-24" pos="word" morph="none" start_char="2506" end_char="2511">pasado</TOKEN>
<TOKEN id="token-30-25" pos="word" morph="none" start_char="2513" end_char="2514">en</TOKEN>
<TOKEN id="token-30-26" pos="word" morph="none" start_char="2516" end_char="2518">los</TOKEN>
<TOKEN id="token-30-27" pos="word" morph="none" start_char="2520" end_char="2524">meses</TOKEN>
<TOKEN id="token-30-28" pos="word" morph="none" start_char="2526" end_char="2527">de</TOKEN>
<TOKEN id="token-30-29" pos="word" morph="none" start_char="2529" end_char="2534">agosto</TOKEN>
<TOKEN id="token-30-30" pos="punct" morph="none" start_char="2535" end_char="2535">,</TOKEN>
<TOKEN id="token-30-31" pos="word" morph="none" start_char="2537" end_char="2546">septiembre</TOKEN>
<TOKEN id="token-30-32" pos="word" morph="none" start_char="2548" end_char="2548">u</TOKEN>
<TOKEN id="token-30-33" pos="word" morph="none" start_char="2550" end_char="2556">octubre</TOKEN>
<TOKEN id="token-30-34" pos="word" morph="none" start_char="2558" end_char="2559">de</TOKEN>
<TOKEN id="token-30-35" pos="word" morph="none" start_char="2561" end_char="2564">2019</TOKEN>
<TOKEN id="token-30-36" pos="punct" morph="none" start_char="2565" end_char="2565">,</TOKEN>
<TOKEN id="token-30-37" pos="word" morph="none" start_char="2567" end_char="2575">apuntando</TOKEN>
<TOKEN id="token-30-38" pos="word" morph="none" start_char="2577" end_char="2577">a</TOKEN>
<TOKEN id="token-30-39" pos="word" morph="none" start_char="2579" end_char="2581">que</TOKEN>
<TOKEN id="token-30-40" pos="word" morph="none" start_char="2583" end_char="2584">la</TOKEN>
<TOKEN id="token-30-41" pos="word" morph="none" start_char="2586" end_char="2593">epidemia</TOKEN>
<TOKEN id="token-30-42" pos="word" morph="none" start_char="2595" end_char="2599">lleva</TOKEN>
<TOKEN id="token-30-43" pos="word" morph="none" start_char="2601" end_char="2602">en</TOKEN>
<TOKEN id="token-30-44" pos="word" morph="none" start_char="2604" end_char="2611">realidad</TOKEN>
<TOKEN id="token-30-45" pos="word" morph="none" start_char="2613" end_char="2618">varios</TOKEN>
<TOKEN id="token-30-46" pos="word" morph="none" start_char="2620" end_char="2624">meses</TOKEN>
<TOKEN id="token-30-47" pos="word" morph="none" start_char="2626" end_char="2628">sin</TOKEN>
<TOKEN id="token-30-48" pos="word" morph="none" start_char="2630" end_char="2636">control</TOKEN>
<TOKEN id="token-30-49" pos="punct" morph="none" start_char="2637" end_char="2637">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="2639" end_char="2725">
<ORIGINAL_TEXT>Lo podría haber pasado él mismo pero también su familia, que han estado enfermos todos.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="2639" end_char="2640">Lo</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="2642" end_char="2647">podría</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="2649" end_char="2653">haber</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="2655" end_char="2660">pasado</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="2662" end_char="2663">él</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="2665" end_char="2669">mismo</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="2671" end_char="2674">pero</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="2676" end_char="2682">también</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="2684" end_char="2685">su</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="2687" end_char="2693">familia</TOKEN>
<TOKEN id="token-31-10" pos="punct" morph="none" start_char="2694" end_char="2694">,</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="2696" end_char="2698">que</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="2700" end_char="2702">han</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="2704" end_char="2709">estado</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="2711" end_char="2718">enfermos</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="2720" end_char="2724">todos</TOKEN>
<TOKEN id="token-31-16" pos="punct" morph="none" start_char="2725" end_char="2725">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="2727" end_char="2779">
<ORIGINAL_TEXT>"En agosto, por allí, ya hemos pasado todos el virus.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="punct" morph="none" start_char="2727" end_char="2727">"</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="2728" end_char="2729">En</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="2731" end_char="2736">agosto</TOKEN>
<TOKEN id="token-32-3" pos="punct" morph="none" start_char="2737" end_char="2737">,</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="2739" end_char="2741">por</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="2743" end_char="2746">allí</TOKEN>
<TOKEN id="token-32-6" pos="punct" morph="none" start_char="2747" end_char="2747">,</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="2749" end_char="2750">ya</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="2752" end_char="2756">hemos</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="2758" end_char="2763">pasado</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="2765" end_char="2769">todos</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="2771" end_char="2772">el</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="2774" end_char="2778">virus</TOKEN>
<TOKEN id="token-32-13" pos="punct" morph="none" start_char="2779" end_char="2779">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="2781" end_char="2801">
<ORIGINAL_TEXT>Hemos pasado catarro.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="2781" end_char="2785">Hemos</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="2787" end_char="2792">pasado</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="2794" end_char="2800">catarro</TOKEN>
<TOKEN id="token-33-3" pos="punct" morph="none" start_char="2801" end_char="2801">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="2803" end_char="2827">
<ORIGINAL_TEXT>Lo cogimos en casa todos.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="2803" end_char="2804">Lo</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="2806" end_char="2812">cogimos</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="2814" end_char="2815">en</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="2817" end_char="2820">casa</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="2822" end_char="2826">todos</TOKEN>
<TOKEN id="token-34-5" pos="punct" morph="none" start_char="2827" end_char="2827">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="2829" end_char="2956">
<ORIGINAL_TEXT>Y ahora, empiezas a dar marchas atrás y piensas qué ha estado pasando desde septiembre, octubre y nadie entonces se dio cuenta".</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="2829" end_char="2829">Y</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="2831" end_char="2835">ahora</TOKEN>
<TOKEN id="token-35-2" pos="punct" morph="none" start_char="2836" end_char="2836">,</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="2838" end_char="2845">empiezas</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="2847" end_char="2847">a</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="2849" end_char="2851">dar</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="2853" end_char="2859">marchas</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="2861" end_char="2865">atrás</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="2867" end_char="2867">y</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="2869" end_char="2875">piensas</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="2877" end_char="2879">qué</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="2881" end_char="2882">ha</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="2884" end_char="2889">estado</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="2891" end_char="2897">pasando</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="2899" end_char="2903">desde</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="2905" end_char="2914">septiembre</TOKEN>
<TOKEN id="token-35-16" pos="punct" morph="none" start_char="2915" end_char="2915">,</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="2917" end_char="2923">octubre</TOKEN>
<TOKEN id="token-35-18" pos="word" morph="none" start_char="2925" end_char="2925">y</TOKEN>
<TOKEN id="token-35-19" pos="word" morph="none" start_char="2927" end_char="2931">nadie</TOKEN>
<TOKEN id="token-35-20" pos="word" morph="none" start_char="2933" end_char="2940">entonces</TOKEN>
<TOKEN id="token-35-21" pos="word" morph="none" start_char="2942" end_char="2943">se</TOKEN>
<TOKEN id="token-35-22" pos="word" morph="none" start_char="2945" end_char="2947">dio</TOKEN>
<TOKEN id="token-35-23" pos="word" morph="none" start_char="2949" end_char="2954">cuenta</TOKEN>
<TOKEN id="token-35-24" pos="punct" morph="none" start_char="2955" end_char="2956">".</TOKEN>
</SEG>
<SEG id="segment-36" start_char="2962" end_char="2991">
<ORIGINAL_TEXT>Crónica Rosa: Con Frank Cuesta</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="2962" end_char="2968">Crónica</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="2970" end_char="2973">Rosa</TOKEN>
<TOKEN id="token-36-2" pos="punct" morph="none" start_char="2974" end_char="2974">:</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="2976" end_char="2978">Con</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="2980" end_char="2984">Frank</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="2986" end_char="2991">Cuesta</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
