<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CA2M" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="2888" raw_text_md5="835a3e16ff37e327df62f9b22d8b5f86">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="90">
<ORIGINAL_TEXT>VIDEO: Does a 2015 italian documentary prove the coronavirus was created in a chinese lab?</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="5">VIDEO</TOKEN>
<TOKEN id="token-0-1" pos="punct" morph="none" start_char="6" end_char="6">:</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="8" end_char="11">Does</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="13" end_char="13">a</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="15" end_char="18">2015</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="20" end_char="26">italian</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="28" end_char="38">documentary</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="40" end_char="44">prove</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="46" end_char="48">the</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="50" end_char="60">coronavirus</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="62" end_char="64">was</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="66" end_char="72">created</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="74" end_char="75">in</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="77" end_char="77">a</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="79" end_char="85">chinese</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="87" end_char="89">lab</TOKEN>
<TOKEN id="token-0-16" pos="punct" morph="none" start_char="90" end_char="90">?</TOKEN>
</SEG>
<SEG id="segment-1" start_char="95" end_char="334">
<ORIGINAL_TEXT>Former Italian Interior Minister Matteo Salvini is demanding answers about the origin of the Chinese coronavirus, particularly in relation to a revived 2015 Italian scientific documentary translated exclusively below by RAIR Foundation USA.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="95" end_char="100">Former</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="102" end_char="108">Italian</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="110" end_char="117">Interior</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="119" end_char="126">Minister</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="128" end_char="133">Matteo</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="135" end_char="141">Salvini</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="143" end_char="144">is</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="146" end_char="154">demanding</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="156" end_char="162">answers</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="164" end_char="168">about</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="170" end_char="172">the</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="174" end_char="179">origin</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="181" end_char="182">of</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="184" end_char="186">the</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="188" end_char="194">Chinese</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="196" end_char="206">coronavirus</TOKEN>
<TOKEN id="token-1-16" pos="punct" morph="none" start_char="207" end_char="207">,</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="209" end_char="220">particularly</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="222" end_char="223">in</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="225" end_char="232">relation</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="234" end_char="235">to</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="237" end_char="237">a</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="239" end_char="245">revived</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="247" end_char="250">2015</TOKEN>
<TOKEN id="token-1-24" pos="word" morph="none" start_char="252" end_char="258">Italian</TOKEN>
<TOKEN id="token-1-25" pos="word" morph="none" start_char="260" end_char="269">scientific</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="271" end_char="281">documentary</TOKEN>
<TOKEN id="token-1-27" pos="word" morph="none" start_char="283" end_char="292">translated</TOKEN>
<TOKEN id="token-1-28" pos="word" morph="none" start_char="294" end_char="304">exclusively</TOKEN>
<TOKEN id="token-1-29" pos="word" morph="none" start_char="306" end_char="310">below</TOKEN>
<TOKEN id="token-1-30" pos="word" morph="none" start_char="312" end_char="313">by</TOKEN>
<TOKEN id="token-1-31" pos="word" morph="none" start_char="315" end_char="318">RAIR</TOKEN>
<TOKEN id="token-1-32" pos="word" morph="none" start_char="320" end_char="329">Foundation</TOKEN>
<TOKEN id="token-1-33" pos="word" morph="none" start_char="331" end_char="333">USA</TOKEN>
<TOKEN id="token-1-34" pos="punct" morph="none" start_char="334" end_char="334">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="336" end_char="528">
<ORIGINAL_TEXT>In what appears to be a coordinated attack, the mainstream media has viciously targeted Salvini for asking reasonable questions, which suggests that he is onto something they would rather bury.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="336" end_char="337">In</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="339" end_char="342">what</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="344" end_char="350">appears</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="352" end_char="353">to</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="355" end_char="356">be</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="358" end_char="358">a</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="360" end_char="370">coordinated</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="372" end_char="377">attack</TOKEN>
<TOKEN id="token-2-8" pos="punct" morph="none" start_char="378" end_char="378">,</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="380" end_char="382">the</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="384" end_char="393">mainstream</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="395" end_char="399">media</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="401" end_char="403">has</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="405" end_char="413">viciously</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="415" end_char="422">targeted</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="424" end_char="430">Salvini</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="432" end_char="434">for</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="436" end_char="441">asking</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="443" end_char="452">reasonable</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="454" end_char="462">questions</TOKEN>
<TOKEN id="token-2-20" pos="punct" morph="none" start_char="463" end_char="463">,</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="465" end_char="469">which</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="471" end_char="478">suggests</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="480" end_char="483">that</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="485" end_char="486">he</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="488" end_char="489">is</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="491" end_char="494">onto</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="496" end_char="504">something</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="506" end_char="509">they</TOKEN>
<TOKEN id="token-2-29" pos="word" morph="none" start_char="511" end_char="515">would</TOKEN>
<TOKEN id="token-2-30" pos="word" morph="none" start_char="517" end_char="522">rather</TOKEN>
<TOKEN id="token-2-31" pos="word" morph="none" start_char="524" end_char="527">bury</TOKEN>
<TOKEN id="token-2-32" pos="punct" morph="none" start_char="528" end_char="528">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="531" end_char="766">
<ORIGINAL_TEXT>In 2015, Italian state broadcaster RAI aired Leonardo, a show dedicated to science, which revealed that Chinese scientists had created a pulmonary "supervirus" from bats and mice "for study purposes" that is capable of attacking humans.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="531" end_char="532">In</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="534" end_char="537">2015</TOKEN>
<TOKEN id="token-3-2" pos="punct" morph="none" start_char="538" end_char="538">,</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="540" end_char="546">Italian</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="548" end_char="552">state</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="554" end_char="564">broadcaster</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="566" end_char="568">RAI</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="570" end_char="574">aired</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="576" end_char="583">Leonardo</TOKEN>
<TOKEN id="token-3-9" pos="punct" morph="none" start_char="584" end_char="584">,</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="586" end_char="586">a</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="588" end_char="591">show</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="593" end_char="601">dedicated</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="603" end_char="604">to</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="606" end_char="612">science</TOKEN>
<TOKEN id="token-3-15" pos="punct" morph="none" start_char="613" end_char="613">,</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="615" end_char="619">which</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="621" end_char="628">revealed</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="630" end_char="633">that</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="635" end_char="641">Chinese</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="643" end_char="652">scientists</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="654" end_char="656">had</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="658" end_char="664">created</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="666" end_char="666">a</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="668" end_char="676">pulmonary</TOKEN>
<TOKEN id="token-3-25" pos="punct" morph="none" start_char="678" end_char="678">"</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="679" end_char="688">supervirus</TOKEN>
<TOKEN id="token-3-27" pos="punct" morph="none" start_char="689" end_char="689">"</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="691" end_char="694">from</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="696" end_char="699">bats</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="701" end_char="703">and</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="705" end_char="708">mice</TOKEN>
<TOKEN id="token-3-32" pos="punct" morph="none" start_char="710" end_char="710">"</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="711" end_char="713">for</TOKEN>
<TOKEN id="token-3-34" pos="word" morph="none" start_char="715" end_char="719">study</TOKEN>
<TOKEN id="token-3-35" pos="word" morph="none" start_char="721" end_char="728">purposes</TOKEN>
<TOKEN id="token-3-36" pos="punct" morph="none" start_char="729" end_char="729">"</TOKEN>
<TOKEN id="token-3-37" pos="word" morph="none" start_char="731" end_char="734">that</TOKEN>
<TOKEN id="token-3-38" pos="word" morph="none" start_char="736" end_char="737">is</TOKEN>
<TOKEN id="token-3-39" pos="word" morph="none" start_char="739" end_char="745">capable</TOKEN>
<TOKEN id="token-3-40" pos="word" morph="none" start_char="747" end_char="748">of</TOKEN>
<TOKEN id="token-3-41" pos="word" morph="none" start_char="750" end_char="758">attacking</TOKEN>
<TOKEN id="token-3-42" pos="word" morph="none" start_char="760" end_char="765">humans</TOKEN>
<TOKEN id="token-3-43" pos="punct" morph="none" start_char="766" end_char="766">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="768" end_char="959">
<ORIGINAL_TEXT>Salvini and other party leaders are demanding to know if there is a connection with the research featured in the 2015 documentary and the Chinese coronavirus, which has wreaked havoc on Italy.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="768" end_char="774">Salvini</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="776" end_char="778">and</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="780" end_char="784">other</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="786" end_char="790">party</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="792" end_char="798">leaders</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="800" end_char="802">are</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="804" end_char="812">demanding</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="814" end_char="815">to</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="817" end_char="820">know</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="822" end_char="823">if</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="825" end_char="829">there</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="831" end_char="832">is</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="834" end_char="834">a</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="836" end_char="845">connection</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="847" end_char="850">with</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="852" end_char="854">the</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="856" end_char="863">research</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="865" end_char="872">featured</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="874" end_char="875">in</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="877" end_char="879">the</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="881" end_char="884">2015</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="886" end_char="896">documentary</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="898" end_char="900">and</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="902" end_char="904">the</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="906" end_char="912">Chinese</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="914" end_char="924">coronavirus</TOKEN>
<TOKEN id="token-4-26" pos="punct" morph="none" start_char="925" end_char="925">,</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="927" end_char="931">which</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="933" end_char="935">has</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="937" end_char="943">wreaked</TOKEN>
<TOKEN id="token-4-30" pos="word" morph="none" start_char="945" end_char="949">havoc</TOKEN>
<TOKEN id="token-4-31" pos="word" morph="none" start_char="951" end_char="952">on</TOKEN>
<TOKEN id="token-4-32" pos="word" morph="none" start_char="954" end_char="958">Italy</TOKEN>
<TOKEN id="token-4-33" pos="punct" morph="none" start_char="959" end_char="959">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="962" end_char="1179">
<ORIGINAL_TEXT>In the scientific documentary, Chinese researchers in a laboratory in Beijing managed to graft a surface protein of a coronavirus found in bats onto a virus that causes SARS (Severe Acute Respiratory Syndrome) in mice.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="962" end_char="963">In</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="965" end_char="967">the</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="969" end_char="978">scientific</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="980" end_char="990">documentary</TOKEN>
<TOKEN id="token-5-4" pos="punct" morph="none" start_char="991" end_char="991">,</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="993" end_char="999">Chinese</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="1001" end_char="1011">researchers</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="1013" end_char="1014">in</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="1016" end_char="1016">a</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="1018" end_char="1027">laboratory</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="1029" end_char="1030">in</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="1032" end_char="1038">Beijing</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="1040" end_char="1046">managed</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="1048" end_char="1049">to</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="1051" end_char="1055">graft</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="1057" end_char="1057">a</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="1059" end_char="1065">surface</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="1067" end_char="1073">protein</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="1075" end_char="1076">of</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="1078" end_char="1078">a</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="1080" end_char="1090">coronavirus</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="1092" end_char="1096">found</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="1098" end_char="1099">in</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="1101" end_char="1104">bats</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="1106" end_char="1109">onto</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="1111" end_char="1111">a</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="1113" end_char="1117">virus</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="1119" end_char="1122">that</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="1124" end_char="1129">causes</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="1131" end_char="1134">SARS</TOKEN>
<TOKEN id="token-5-30" pos="punct" morph="none" start_char="1136" end_char="1136">(</TOKEN>
<TOKEN id="token-5-31" pos="word" morph="none" start_char="1137" end_char="1142">Severe</TOKEN>
<TOKEN id="token-5-32" pos="word" morph="none" start_char="1144" end_char="1148">Acute</TOKEN>
<TOKEN id="token-5-33" pos="word" morph="none" start_char="1150" end_char="1160">Respiratory</TOKEN>
<TOKEN id="token-5-34" pos="word" morph="none" start_char="1162" end_char="1169">Syndrome</TOKEN>
<TOKEN id="token-5-35" pos="punct" morph="none" start_char="1170" end_char="1170">)</TOKEN>
<TOKEN id="token-5-36" pos="word" morph="none" start_char="1172" end_char="1173">in</TOKEN>
<TOKEN id="token-5-37" pos="word" morph="none" start_char="1175" end_char="1178">mice</TOKEN>
<TOKEN id="token-5-38" pos="punct" morph="none" start_char="1179" end_char="1179">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="1181" end_char="1479">
<ORIGINAL_TEXT>It should be noted that SARS was a "114-day epidemic" which "swept 29 countries, affected a reported 8,098 people, [and] left 774 patients dead…" Chinese military surgeon Jiang Yanyong exposed his government’s cover-up of the outbreak that originated in 2002–2003 in the Guangdong Province of China.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="1181" end_char="1182">It</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="1184" end_char="1189">should</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="1191" end_char="1192">be</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="1194" end_char="1198">noted</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="1200" end_char="1203">that</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="1205" end_char="1208">SARS</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="1210" end_char="1212">was</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="1214" end_char="1214">a</TOKEN>
<TOKEN id="token-6-8" pos="punct" morph="none" start_char="1216" end_char="1216">"</TOKEN>
<TOKEN id="token-6-9" pos="unknown" morph="none" start_char="1217" end_char="1223">114-day</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="1225" end_char="1232">epidemic</TOKEN>
<TOKEN id="token-6-11" pos="punct" morph="none" start_char="1233" end_char="1233">"</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="1235" end_char="1239">which</TOKEN>
<TOKEN id="token-6-13" pos="punct" morph="none" start_char="1241" end_char="1241">"</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="1242" end_char="1246">swept</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="1248" end_char="1249">29</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="1251" end_char="1259">countries</TOKEN>
<TOKEN id="token-6-17" pos="punct" morph="none" start_char="1260" end_char="1260">,</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="1262" end_char="1269">affected</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="1271" end_char="1271">a</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="1273" end_char="1280">reported</TOKEN>
<TOKEN id="token-6-21" pos="unknown" morph="none" start_char="1282" end_char="1286">8,098</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="1288" end_char="1293">people</TOKEN>
<TOKEN id="token-6-23" pos="punct" morph="none" start_char="1294" end_char="1294">,</TOKEN>
<TOKEN id="token-6-24" pos="punct" morph="none" start_char="1296" end_char="1296">[</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="1297" end_char="1299">and</TOKEN>
<TOKEN id="token-6-26" pos="punct" morph="none" start_char="1300" end_char="1300">]</TOKEN>
<TOKEN id="token-6-27" pos="word" morph="none" start_char="1302" end_char="1305">left</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="1307" end_char="1309">774</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="1311" end_char="1318">patients</TOKEN>
<TOKEN id="token-6-30" pos="word" morph="none" start_char="1320" end_char="1323">dead</TOKEN>
<TOKEN id="token-6-31" pos="punct" morph="none" start_char="1324" end_char="1325">…"</TOKEN>
<TOKEN id="token-6-32" pos="word" morph="none" start_char="1327" end_char="1333">Chinese</TOKEN>
<TOKEN id="token-6-33" pos="word" morph="none" start_char="1335" end_char="1342">military</TOKEN>
<TOKEN id="token-6-34" pos="word" morph="none" start_char="1344" end_char="1350">surgeon</TOKEN>
<TOKEN id="token-6-35" pos="word" morph="none" start_char="1352" end_char="1356">Jiang</TOKEN>
<TOKEN id="token-6-36" pos="word" morph="none" start_char="1358" end_char="1364">Yanyong</TOKEN>
<TOKEN id="token-6-37" pos="word" morph="none" start_char="1366" end_char="1372">exposed</TOKEN>
<TOKEN id="token-6-38" pos="word" morph="none" start_char="1374" end_char="1376">his</TOKEN>
<TOKEN id="token-6-39" pos="word" morph="none" start_char="1378" end_char="1389">government’s</TOKEN>
<TOKEN id="token-6-40" pos="unknown" morph="none" start_char="1391" end_char="1398">cover-up</TOKEN>
<TOKEN id="token-6-41" pos="word" morph="none" start_char="1400" end_char="1401">of</TOKEN>
<TOKEN id="token-6-42" pos="word" morph="none" start_char="1403" end_char="1405">the</TOKEN>
<TOKEN id="token-6-43" pos="word" morph="none" start_char="1407" end_char="1414">outbreak</TOKEN>
<TOKEN id="token-6-44" pos="word" morph="none" start_char="1416" end_char="1419">that</TOKEN>
<TOKEN id="token-6-45" pos="word" morph="none" start_char="1421" end_char="1430">originated</TOKEN>
<TOKEN id="token-6-46" pos="word" morph="none" start_char="1432" end_char="1433">in</TOKEN>
<TOKEN id="token-6-47" pos="unknown" morph="none" start_char="1435" end_char="1443">2002–2003</TOKEN>
<TOKEN id="token-6-48" pos="word" morph="none" start_char="1445" end_char="1446">in</TOKEN>
<TOKEN id="token-6-49" pos="word" morph="none" start_char="1448" end_char="1450">the</TOKEN>
<TOKEN id="token-6-50" pos="word" morph="none" start_char="1452" end_char="1460">Guangdong</TOKEN>
<TOKEN id="token-6-51" pos="word" morph="none" start_char="1462" end_char="1469">Province</TOKEN>
<TOKEN id="token-6-52" pos="word" morph="none" start_char="1471" end_char="1472">of</TOKEN>
<TOKEN id="token-6-53" pos="word" morph="none" start_char="1474" end_char="1478">China</TOKEN>
<TOKEN id="token-6-54" pos="punct" morph="none" start_char="1479" end_char="1479">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="1482" end_char="1658">
<ORIGINAL_TEXT>According to the documentary, the researchers imagined that the hybrid (a "chimera virus") was suitable for affecting humans, a hypothesis later confirmed by laboratory results.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="1482" end_char="1490">According</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="1492" end_char="1493">to</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="1495" end_char="1497">the</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="1499" end_char="1509">documentary</TOKEN>
<TOKEN id="token-7-4" pos="punct" morph="none" start_char="1510" end_char="1510">,</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="1512" end_char="1514">the</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="1516" end_char="1526">researchers</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="1528" end_char="1535">imagined</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="1537" end_char="1540">that</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="1542" end_char="1544">the</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="1546" end_char="1551">hybrid</TOKEN>
<TOKEN id="token-7-11" pos="punct" morph="none" start_char="1553" end_char="1553">(</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="1554" end_char="1554">a</TOKEN>
<TOKEN id="token-7-13" pos="punct" morph="none" start_char="1556" end_char="1556">"</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="1557" end_char="1563">chimera</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="1565" end_char="1569">virus</TOKEN>
<TOKEN id="token-7-16" pos="punct" morph="none" start_char="1570" end_char="1571">")</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="1573" end_char="1575">was</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="1577" end_char="1584">suitable</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="1586" end_char="1588">for</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="1590" end_char="1598">affecting</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="1600" end_char="1605">humans</TOKEN>
<TOKEN id="token-7-22" pos="punct" morph="none" start_char="1606" end_char="1606">,</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="1608" end_char="1608">a</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="1610" end_char="1619">hypothesis</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="1621" end_char="1625">later</TOKEN>
<TOKEN id="token-7-26" pos="word" morph="none" start_char="1627" end_char="1635">confirmed</TOKEN>
<TOKEN id="token-7-27" pos="word" morph="none" start_char="1637" end_char="1638">by</TOKEN>
<TOKEN id="token-7-28" pos="word" morph="none" start_char="1640" end_char="1649">laboratory</TOKEN>
<TOKEN id="token-7-29" pos="word" morph="none" start_char="1651" end_char="1657">results</TOKEN>
<TOKEN id="token-7-30" pos="punct" morph="none" start_char="1658" end_char="1658">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1661" end_char="1902">
<ORIGINAL_TEXT>Furthermore, this specific coronavirus was shown to attach itself to our respiratory cells, triggering the syndrome and thus the organism can infect humans "directly from bats without going through an intermediate species, such as the mouse".</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1661" end_char="1671">Furthermore</TOKEN>
<TOKEN id="token-8-1" pos="punct" morph="none" start_char="1672" end_char="1672">,</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1674" end_char="1677">this</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1679" end_char="1686">specific</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1688" end_char="1698">coronavirus</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1700" end_char="1702">was</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1704" end_char="1708">shown</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1710" end_char="1711">to</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1713" end_char="1718">attach</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1720" end_char="1725">itself</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1727" end_char="1728">to</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1730" end_char="1732">our</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1734" end_char="1744">respiratory</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1746" end_char="1750">cells</TOKEN>
<TOKEN id="token-8-14" pos="punct" morph="none" start_char="1751" end_char="1751">,</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1753" end_char="1762">triggering</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1764" end_char="1766">the</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1768" end_char="1775">syndrome</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1777" end_char="1779">and</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1781" end_char="1784">thus</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="1786" end_char="1788">the</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="1790" end_char="1797">organism</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="1799" end_char="1801">can</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="1803" end_char="1808">infect</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="1810" end_char="1815">humans</TOKEN>
<TOKEN id="token-8-25" pos="punct" morph="none" start_char="1817" end_char="1817">"</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="1818" end_char="1825">directly</TOKEN>
<TOKEN id="token-8-27" pos="word" morph="none" start_char="1827" end_char="1830">from</TOKEN>
<TOKEN id="token-8-28" pos="word" morph="none" start_char="1832" end_char="1835">bats</TOKEN>
<TOKEN id="token-8-29" pos="word" morph="none" start_char="1837" end_char="1843">without</TOKEN>
<TOKEN id="token-8-30" pos="word" morph="none" start_char="1845" end_char="1849">going</TOKEN>
<TOKEN id="token-8-31" pos="word" morph="none" start_char="1851" end_char="1857">through</TOKEN>
<TOKEN id="token-8-32" pos="word" morph="none" start_char="1859" end_char="1860">an</TOKEN>
<TOKEN id="token-8-33" pos="word" morph="none" start_char="1862" end_char="1873">intermediate</TOKEN>
<TOKEN id="token-8-34" pos="word" morph="none" start_char="1875" end_char="1881">species</TOKEN>
<TOKEN id="token-8-35" pos="punct" morph="none" start_char="1882" end_char="1882">,</TOKEN>
<TOKEN id="token-8-36" pos="word" morph="none" start_char="1884" end_char="1887">such</TOKEN>
<TOKEN id="token-8-37" pos="word" morph="none" start_char="1889" end_char="1890">as</TOKEN>
<TOKEN id="token-8-38" pos="word" morph="none" start_char="1892" end_char="1894">the</TOKEN>
<TOKEN id="token-8-39" pos="word" morph="none" start_char="1896" end_char="1900">mouse</TOKEN>
<TOKEN id="token-8-40" pos="punct" morph="none" start_char="1901" end_char="1902">".</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1908" end_char="1979">
<ORIGINAL_TEXT>The episode that aired on Leonardo seems to fit perfectly with COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1908" end_char="1910">The</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1912" end_char="1918">episode</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1920" end_char="1923">that</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1925" end_char="1929">aired</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1931" end_char="1932">on</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1934" end_char="1941">Leonardo</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1943" end_char="1947">seems</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1949" end_char="1950">to</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1952" end_char="1954">fit</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1956" end_char="1964">perfectly</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1966" end_char="1969">with</TOKEN>
<TOKEN id="token-9-11" pos="unknown" morph="none" start_char="1971" end_char="1978">COVID-19</TOKEN>
<TOKEN id="token-9-12" pos="punct" morph="none" start_char="1979" end_char="1979">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1981" end_char="2097">
<ORIGINAL_TEXT>The ingredients are all there: bats , SARS, acute pneumonia, the virus that attacks humans directly and infects them.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1981" end_char="1983">The</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1985" end_char="1995">ingredients</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1997" end_char="1999">are</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="2001" end_char="2003">all</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="2005" end_char="2009">there</TOKEN>
<TOKEN id="token-10-5" pos="punct" morph="none" start_char="2010" end_char="2010">:</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="2012" end_char="2015">bats</TOKEN>
<TOKEN id="token-10-7" pos="punct" morph="none" start_char="2017" end_char="2017">,</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="2019" end_char="2022">SARS</TOKEN>
<TOKEN id="token-10-9" pos="punct" morph="none" start_char="2023" end_char="2023">,</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="2025" end_char="2029">acute</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="2031" end_char="2039">pneumonia</TOKEN>
<TOKEN id="token-10-12" pos="punct" morph="none" start_char="2040" end_char="2040">,</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="2042" end_char="2044">the</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="2046" end_char="2050">virus</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="2052" end_char="2055">that</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="2057" end_char="2063">attacks</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="2065" end_char="2070">humans</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="2072" end_char="2079">directly</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="2081" end_char="2083">and</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="2085" end_char="2091">infects</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="2093" end_char="2096">them</TOKEN>
<TOKEN id="token-10-22" pos="punct" morph="none" start_char="2097" end_char="2097">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="2099" end_char="2241">
<ORIGINAL_TEXT>The coincidences were enough to warrant question from Lega Party leader, Matteo Salvini, who has asked for clarity from the Italian government.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="2099" end_char="2101">The</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="2103" end_char="2114">coincidences</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="2116" end_char="2119">were</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="2121" end_char="2126">enough</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="2128" end_char="2129">to</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="2131" end_char="2137">warrant</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="2139" end_char="2146">question</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="2148" end_char="2151">from</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="2153" end_char="2156">Lega</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="2158" end_char="2162">Party</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="2164" end_char="2169">leader</TOKEN>
<TOKEN id="token-11-11" pos="punct" morph="none" start_char="2170" end_char="2170">,</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="2172" end_char="2177">Matteo</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="2179" end_char="2185">Salvini</TOKEN>
<TOKEN id="token-11-14" pos="punct" morph="none" start_char="2186" end_char="2186">,</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="2188" end_char="2190">who</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="2192" end_char="2194">has</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="2196" end_char="2200">asked</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="2202" end_char="2204">for</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="2206" end_char="2212">clarity</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="2214" end_char="2217">from</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="2219" end_char="2221">the</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="2223" end_char="2229">Italian</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="2231" end_char="2240">government</TOKEN>
<TOKEN id="token-11-24" pos="punct" morph="none" start_char="2241" end_char="2241">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="2244" end_char="2593">
<ORIGINAL_TEXT>Salvini, along with Giorgia Meloni and the Fratelli d’Itali party, formally requested Prime Minister Giuseppe Conte explore whether the RAI documentary is proof that the SARS-CoV-2 virus that originated in Wuhan was created in a laboratory and escaped the control of Chinese scientists or was used as a bio-terrorist weapon by the Chinese government.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="2244" end_char="2250">Salvini</TOKEN>
<TOKEN id="token-12-1" pos="punct" morph="none" start_char="2251" end_char="2251">,</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="2253" end_char="2257">along</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="2259" end_char="2262">with</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="2264" end_char="2270">Giorgia</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="2272" end_char="2277">Meloni</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="2279" end_char="2281">and</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="2283" end_char="2285">the</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="2287" end_char="2294">Fratelli</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="2296" end_char="2302">d’Itali</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="2304" end_char="2308">party</TOKEN>
<TOKEN id="token-12-11" pos="punct" morph="none" start_char="2309" end_char="2309">,</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="2311" end_char="2318">formally</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="2320" end_char="2328">requested</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="2330" end_char="2334">Prime</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="2336" end_char="2343">Minister</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="2345" end_char="2352">Giuseppe</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="2354" end_char="2358">Conte</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="2360" end_char="2366">explore</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="2368" end_char="2374">whether</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="2376" end_char="2378">the</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="2380" end_char="2382">RAI</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="2384" end_char="2394">documentary</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="2396" end_char="2397">is</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="2399" end_char="2403">proof</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="2405" end_char="2408">that</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="2410" end_char="2412">the</TOKEN>
<TOKEN id="token-12-27" pos="unknown" morph="none" start_char="2414" end_char="2423">SARS-CoV-2</TOKEN>
<TOKEN id="token-12-28" pos="word" morph="none" start_char="2425" end_char="2429">virus</TOKEN>
<TOKEN id="token-12-29" pos="word" morph="none" start_char="2431" end_char="2434">that</TOKEN>
<TOKEN id="token-12-30" pos="word" morph="none" start_char="2436" end_char="2445">originated</TOKEN>
<TOKEN id="token-12-31" pos="word" morph="none" start_char="2447" end_char="2448">in</TOKEN>
<TOKEN id="token-12-32" pos="word" morph="none" start_char="2450" end_char="2454">Wuhan</TOKEN>
<TOKEN id="token-12-33" pos="word" morph="none" start_char="2456" end_char="2458">was</TOKEN>
<TOKEN id="token-12-34" pos="word" morph="none" start_char="2460" end_char="2466">created</TOKEN>
<TOKEN id="token-12-35" pos="word" morph="none" start_char="2468" end_char="2469">in</TOKEN>
<TOKEN id="token-12-36" pos="word" morph="none" start_char="2471" end_char="2471">a</TOKEN>
<TOKEN id="token-12-37" pos="word" morph="none" start_char="2473" end_char="2482">laboratory</TOKEN>
<TOKEN id="token-12-38" pos="word" morph="none" start_char="2484" end_char="2486">and</TOKEN>
<TOKEN id="token-12-39" pos="word" morph="none" start_char="2488" end_char="2494">escaped</TOKEN>
<TOKEN id="token-12-40" pos="word" morph="none" start_char="2496" end_char="2498">the</TOKEN>
<TOKEN id="token-12-41" pos="word" morph="none" start_char="2500" end_char="2506">control</TOKEN>
<TOKEN id="token-12-42" pos="word" morph="none" start_char="2508" end_char="2509">of</TOKEN>
<TOKEN id="token-12-43" pos="word" morph="none" start_char="2511" end_char="2517">Chinese</TOKEN>
<TOKEN id="token-12-44" pos="word" morph="none" start_char="2519" end_char="2528">scientists</TOKEN>
<TOKEN id="token-12-45" pos="word" morph="none" start_char="2530" end_char="2531">or</TOKEN>
<TOKEN id="token-12-46" pos="word" morph="none" start_char="2533" end_char="2535">was</TOKEN>
<TOKEN id="token-12-47" pos="word" morph="none" start_char="2537" end_char="2540">used</TOKEN>
<TOKEN id="token-12-48" pos="word" morph="none" start_char="2542" end_char="2543">as</TOKEN>
<TOKEN id="token-12-49" pos="word" morph="none" start_char="2545" end_char="2545">a</TOKEN>
<TOKEN id="token-12-50" pos="unknown" morph="none" start_char="2547" end_char="2559">bio-terrorist</TOKEN>
<TOKEN id="token-12-51" pos="word" morph="none" start_char="2561" end_char="2566">weapon</TOKEN>
<TOKEN id="token-12-52" pos="word" morph="none" start_char="2568" end_char="2569">by</TOKEN>
<TOKEN id="token-12-53" pos="word" morph="none" start_char="2571" end_char="2573">the</TOKEN>
<TOKEN id="token-12-54" pos="word" morph="none" start_char="2575" end_char="2581">Chinese</TOKEN>
<TOKEN id="token-12-55" pos="word" morph="none" start_char="2583" end_char="2592">government</TOKEN>
<TOKEN id="token-12-56" pos="punct" morph="none" start_char="2593" end_char="2593">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="2596" end_char="2724">
<ORIGINAL_TEXT>The establishment media has reacted swiftly and brutally to reasonable questions regarding the origin of the Chinese coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="2596" end_char="2598">The</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="2600" end_char="2612">establishment</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="2614" end_char="2618">media</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="2620" end_char="2622">has</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="2624" end_char="2630">reacted</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="2632" end_char="2638">swiftly</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="2640" end_char="2642">and</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="2644" end_char="2651">brutally</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="2653" end_char="2654">to</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="2656" end_char="2665">reasonable</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="2667" end_char="2675">questions</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="2677" end_char="2685">regarding</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="2687" end_char="2689">the</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="2691" end_char="2696">origin</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="2698" end_char="2699">of</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="2701" end_char="2703">the</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="2705" end_char="2711">Chinese</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="2713" end_char="2723">coronavirus</TOKEN>
<TOKEN id="token-13-18" pos="punct" morph="none" start_char="2724" end_char="2724">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="2726" end_char="2834">
<ORIGINAL_TEXT>When the media responds in such a matter, the onus is on thinking citizens to push even harder for the truth.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="2726" end_char="2729">When</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="2731" end_char="2733">the</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="2735" end_char="2739">media</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="2741" end_char="2748">responds</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="2750" end_char="2751">in</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="2753" end_char="2756">such</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="2758" end_char="2758">a</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="2760" end_char="2765">matter</TOKEN>
<TOKEN id="token-14-8" pos="punct" morph="none" start_char="2766" end_char="2766">,</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="2768" end_char="2770">the</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="2772" end_char="2775">onus</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="2777" end_char="2778">is</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="2780" end_char="2781">on</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="2783" end_char="2790">thinking</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="2792" end_char="2799">citizens</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="2801" end_char="2802">to</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="2804" end_char="2807">push</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="2809" end_char="2812">even</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="2814" end_char="2819">harder</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="2821" end_char="2823">for</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="2825" end_char="2827">the</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="2829" end_char="2833">truth</TOKEN>
<TOKEN id="token-14-22" pos="punct" morph="none" start_char="2834" end_char="2834">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="2836" end_char="2879">
<ORIGINAL_TEXT>Where there is smoke, there is usually fire.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="2836" end_char="2840">Where</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="2842" end_char="2846">there</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="2848" end_char="2849">is</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="2851" end_char="2855">smoke</TOKEN>
<TOKEN id="token-15-4" pos="punct" morph="none" start_char="2856" end_char="2856">,</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="2858" end_char="2862">there</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="2864" end_char="2865">is</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="2867" end_char="2873">usually</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="2875" end_char="2878">fire</TOKEN>
<TOKEN id="token-15-9" pos="punct" morph="none" start_char="2879" end_char="2879">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="2882" end_char="2884">
<ORIGINAL_TEXT>RAI</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="2882" end_char="2884">RAI</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
