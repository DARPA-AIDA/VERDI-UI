<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C0495A8" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="3822" raw_text_md5="68e264242bfb2f609035a63bbda2458f">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="96">
<ORIGINAL_TEXT>Antivirales para otras infecciones que podrían ser usados también contra el coronavirus COVID-19</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="11">Antivirales</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="13" end_char="16">para</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="18" end_char="22">otras</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="24" end_char="34">infecciones</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="36" end_char="38">que</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="40" end_char="46">podrían</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="48" end_char="50">ser</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="52" end_char="57">usados</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="59" end_char="65">también</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="67" end_char="72">contra</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="74" end_char="75">el</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="77" end_char="87">coronavirus</TOKEN>
<TOKEN id="token-0-12" pos="unknown" morph="none" start_char="89" end_char="96">COVID-19</TOKEN>
</SEG>
<SEG id="segment-1" start_char="100" end_char="107">
<ORIGINAL_TEXT>Medicina</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="100" end_char="107">Medicina</TOKEN>
</SEG>
<SEG id="segment-2" start_char="111" end_char="211">
<ORIGINAL_TEXT>La cantidad de personas infectadas con el nuevo coronavirus COVID-19 continúa aumentando rápidamente.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="111" end_char="112">La</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="114" end_char="121">cantidad</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="123" end_char="124">de</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="126" end_char="133">personas</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="135" end_char="144">infectadas</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="146" end_char="148">con</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="150" end_char="151">el</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="153" end_char="157">nuevo</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="159" end_char="169">coronavirus</TOKEN>
<TOKEN id="token-2-9" pos="unknown" morph="none" start_char="171" end_char="178">COVID-19</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="180" end_char="187">continúa</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="189" end_char="198">aumentando</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="200" end_char="210">rápidamente</TOKEN>
<TOKEN id="token-2-13" pos="punct" morph="none" start_char="211" end_char="211">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="213" end_char="424">
<ORIGINAL_TEXT>Hasta que esté a punto una vacuna o un fármaco para curar la enfermedad, tal vez se podría recurrir a medicamentos que sirven para tratar otras infecciones y cuyo uso en humanos ya ha sido verificado como seguro.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="213" end_char="217">Hasta</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="219" end_char="221">que</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="223" end_char="226">esté</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="228" end_char="228">a</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="230" end_char="234">punto</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="236" end_char="238">una</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="240" end_char="245">vacuna</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="247" end_char="247">o</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="249" end_char="250">un</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="252" end_char="258">fármaco</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="260" end_char="263">para</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="265" end_char="269">curar</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="271" end_char="272">la</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="274" end_char="283">enfermedad</TOKEN>
<TOKEN id="token-3-14" pos="punct" morph="none" start_char="284" end_char="284">,</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="286" end_char="288">tal</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="290" end_char="292">vez</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="294" end_char="295">se</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="297" end_char="302">podría</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="304" end_char="311">recurrir</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="313" end_char="313">a</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="315" end_char="326">medicamentos</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="328" end_char="330">que</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="332" end_char="337">sirven</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="339" end_char="342">para</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="344" end_char="349">tratar</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="351" end_char="355">otras</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="357" end_char="367">infecciones</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="369" end_char="369">y</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="371" end_char="374">cuyo</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="376" end_char="378">uso</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="380" end_char="381">en</TOKEN>
<TOKEN id="token-3-32" pos="word" morph="none" start_char="383" end_char="389">humanos</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="391" end_char="392">ya</TOKEN>
<TOKEN id="token-3-34" pos="word" morph="none" start_char="394" end_char="395">ha</TOKEN>
<TOKEN id="token-3-35" pos="word" morph="none" start_char="397" end_char="400">sido</TOKEN>
<TOKEN id="token-3-36" pos="word" morph="none" start_char="402" end_char="411">verificado</TOKEN>
<TOKEN id="token-3-37" pos="word" morph="none" start_char="413" end_char="416">como</TOKEN>
<TOKEN id="token-3-38" pos="word" morph="none" start_char="418" end_char="423">seguro</TOKEN>
<TOKEN id="token-3-39" pos="punct" morph="none" start_char="424" end_char="424">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="426" end_char="619">
<ORIGINAL_TEXT>Así lo propone una coalición de investigadores europeos para realizar una investigación, cuyas conclusiones se han publicado en la revista técnica "International Journal of Infectious Diseases".</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="426" end_char="428">Así</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="430" end_char="431">lo</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="433" end_char="439">propone</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="441" end_char="443">una</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="445" end_char="453">coalición</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="455" end_char="456">de</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="458" end_char="471">investigadores</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="473" end_char="480">europeos</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="482" end_char="485">para</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="487" end_char="494">realizar</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="496" end_char="498">una</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="500" end_char="512">investigación</TOKEN>
<TOKEN id="token-4-12" pos="punct" morph="none" start_char="513" end_char="513">,</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="515" end_char="519">cuyas</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="521" end_char="532">conclusiones</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="534" end_char="535">se</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="537" end_char="539">han</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="541" end_char="549">publicado</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="551" end_char="552">en</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="554" end_char="555">la</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="557" end_char="563">revista</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="565" end_char="571">técnica</TOKEN>
<TOKEN id="token-4-22" pos="punct" morph="none" start_char="573" end_char="573">"</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="574" end_char="586">International</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="588" end_char="594">Journal</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="596" end_char="597">of</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="599" end_char="608">Infectious</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="610" end_char="617">Diseases</TOKEN>
<TOKEN id="token-4-28" pos="punct" morph="none" start_char="618" end_char="619">".</TOKEN>
</SEG>
<SEG id="segment-5" start_char="622" end_char="862">
<ORIGINAL_TEXT>La reutilización de fármacos contra enfermedades distintas a aquellas para las cuales fueron diseñados es una estrategia que permite ahorrar tiempo y ensayos de seguridad, algo vital cuando se trabaja a contrarreloj para frenar una epidemia.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="622" end_char="623">La</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="625" end_char="637">reutilización</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="639" end_char="640">de</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="642" end_char="649">fármacos</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="651" end_char="656">contra</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="658" end_char="669">enfermedades</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="671" end_char="679">distintas</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="681" end_char="681">a</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="683" end_char="690">aquellas</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="692" end_char="695">para</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="697" end_char="699">las</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="701" end_char="706">cuales</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="708" end_char="713">fueron</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="715" end_char="723">diseñados</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="725" end_char="726">es</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="728" end_char="730">una</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="732" end_char="741">estrategia</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="743" end_char="745">que</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="747" end_char="753">permite</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="755" end_char="761">ahorrar</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="763" end_char="768">tiempo</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="770" end_char="770">y</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="772" end_char="778">ensayos</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="780" end_char="781">de</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="783" end_char="791">seguridad</TOKEN>
<TOKEN id="token-5-25" pos="punct" morph="none" start_char="792" end_char="792">,</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="794" end_char="797">algo</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="799" end_char="803">vital</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="805" end_char="810">cuando</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="812" end_char="813">se</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="815" end_char="821">trabaja</TOKEN>
<TOKEN id="token-5-31" pos="word" morph="none" start_char="823" end_char="823">a</TOKEN>
<TOKEN id="token-5-32" pos="word" morph="none" start_char="825" end_char="836">contrarreloj</TOKEN>
<TOKEN id="token-5-33" pos="word" morph="none" start_char="838" end_char="841">para</TOKEN>
<TOKEN id="token-5-34" pos="word" morph="none" start_char="843" end_char="848">frenar</TOKEN>
<TOKEN id="token-5-35" pos="word" morph="none" start_char="850" end_char="852">una</TOKEN>
<TOKEN id="token-5-36" pos="word" morph="none" start_char="854" end_char="861">epidemia</TOKEN>
<TOKEN id="token-5-37" pos="punct" morph="none" start_char="862" end_char="862">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="864" end_char="978">
<ORIGINAL_TEXT>Desde el punto de vista comercial, la estrategia también sirve para darle nuevos usos a un fármaco ya desarrollado.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="864" end_char="868">Desde</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="870" end_char="871">el</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="873" end_char="877">punto</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="879" end_char="880">de</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="882" end_char="886">vista</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="888" end_char="896">comercial</TOKEN>
<TOKEN id="token-6-6" pos="punct" morph="none" start_char="897" end_char="897">,</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="899" end_char="900">la</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="902" end_char="911">estrategia</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="913" end_char="919">también</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="921" end_char="925">sirve</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="927" end_char="930">para</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="932" end_char="936">darle</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="938" end_char="943">nuevos</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="945" end_char="948">usos</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="950" end_char="950">a</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="952" end_char="953">un</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="955" end_char="961">fármaco</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="963" end_char="964">ya</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="966" end_char="977">desarrollado</TOKEN>
<TOKEN id="token-6-20" pos="punct" morph="none" start_char="978" end_char="978">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="980" end_char="1268">
<ORIGINAL_TEXT>"Por ejemplo, la teicoplanina, la oritavancina, la dalbavancina y la monensina son antibióticos aprobados que han demostrado inhibir coronavirus y otros virus en el laboratorio", explica Denis Kainov, coautor del estudio y profesor en la Universidad Noruega de Ciencia y Tecnología (NTNU).</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="punct" morph="none" start_char="980" end_char="980">"</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="981" end_char="983">Por</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="985" end_char="991">ejemplo</TOKEN>
<TOKEN id="token-7-3" pos="punct" morph="none" start_char="992" end_char="992">,</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="994" end_char="995">la</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="997" end_char="1008">teicoplanina</TOKEN>
<TOKEN id="token-7-6" pos="punct" morph="none" start_char="1009" end_char="1009">,</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="1011" end_char="1012">la</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="1014" end_char="1025">oritavancina</TOKEN>
<TOKEN id="token-7-9" pos="punct" morph="none" start_char="1026" end_char="1026">,</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="1028" end_char="1029">la</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="1031" end_char="1042">dalbavancina</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="1044" end_char="1044">y</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="1046" end_char="1047">la</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="1049" end_char="1057">monensina</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="1059" end_char="1061">son</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="1063" end_char="1074">antibióticos</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="1076" end_char="1084">aprobados</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="1086" end_char="1088">que</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="1090" end_char="1092">han</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="1094" end_char="1103">demostrado</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="1105" end_char="1111">inhibir</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="1113" end_char="1123">coronavirus</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="1125" end_char="1125">y</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="1127" end_char="1131">otros</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="1133" end_char="1137">virus</TOKEN>
<TOKEN id="token-7-26" pos="word" morph="none" start_char="1139" end_char="1140">en</TOKEN>
<TOKEN id="token-7-27" pos="word" morph="none" start_char="1142" end_char="1143">el</TOKEN>
<TOKEN id="token-7-28" pos="word" morph="none" start_char="1145" end_char="1155">laboratorio</TOKEN>
<TOKEN id="token-7-29" pos="punct" morph="none" start_char="1156" end_char="1157">",</TOKEN>
<TOKEN id="token-7-30" pos="word" morph="none" start_char="1159" end_char="1165">explica</TOKEN>
<TOKEN id="token-7-31" pos="word" morph="none" start_char="1167" end_char="1171">Denis</TOKEN>
<TOKEN id="token-7-32" pos="word" morph="none" start_char="1173" end_char="1178">Kainov</TOKEN>
<TOKEN id="token-7-33" pos="punct" morph="none" start_char="1179" end_char="1179">,</TOKEN>
<TOKEN id="token-7-34" pos="word" morph="none" start_char="1181" end_char="1187">coautor</TOKEN>
<TOKEN id="token-7-35" pos="word" morph="none" start_char="1189" end_char="1191">del</TOKEN>
<TOKEN id="token-7-36" pos="word" morph="none" start_char="1193" end_char="1199">estudio</TOKEN>
<TOKEN id="token-7-37" pos="word" morph="none" start_char="1201" end_char="1201">y</TOKEN>
<TOKEN id="token-7-38" pos="word" morph="none" start_char="1203" end_char="1210">profesor</TOKEN>
<TOKEN id="token-7-39" pos="word" morph="none" start_char="1212" end_char="1213">en</TOKEN>
<TOKEN id="token-7-40" pos="word" morph="none" start_char="1215" end_char="1216">la</TOKEN>
<TOKEN id="token-7-41" pos="word" morph="none" start_char="1218" end_char="1228">Universidad</TOKEN>
<TOKEN id="token-7-42" pos="word" morph="none" start_char="1230" end_char="1236">Noruega</TOKEN>
<TOKEN id="token-7-43" pos="word" morph="none" start_char="1238" end_char="1239">de</TOKEN>
<TOKEN id="token-7-44" pos="word" morph="none" start_char="1241" end_char="1247">Ciencia</TOKEN>
<TOKEN id="token-7-45" pos="word" morph="none" start_char="1249" end_char="1249">y</TOKEN>
<TOKEN id="token-7-46" pos="word" morph="none" start_char="1251" end_char="1260">Tecnología</TOKEN>
<TOKEN id="token-7-47" pos="punct" morph="none" start_char="1262" end_char="1262">(</TOKEN>
<TOKEN id="token-7-48" pos="word" morph="none" start_char="1263" end_char="1266">NTNU</TOKEN>
<TOKEN id="token-7-49" pos="punct" morph="none" start_char="1267" end_char="1268">).</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1271" end_char="1685">
<ORIGINAL_TEXT>Kainov y sus colaboradores argumentan que estos y otros medicamentos antivirales de amplio espectro de los cuales ya se ha verificado que no provocan efectos secundarios demasiado fuertes en el ser humano, son buenos candidatos para tratar la enfermedad causada por el nuevo coronavirus, al menos hasta que se compruebe la validez de nuevos medicamentos orientados específicamente contra él y que sean más eficaces.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1271" end_char="1276">Kainov</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1278" end_char="1278">y</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1280" end_char="1282">sus</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1284" end_char="1296">colaboradores</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1298" end_char="1307">argumentan</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1309" end_char="1311">que</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1313" end_char="1317">estos</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1319" end_char="1319">y</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1321" end_char="1325">otros</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="1327" end_char="1338">medicamentos</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="1340" end_char="1350">antivirales</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="1352" end_char="1353">de</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="1355" end_char="1360">amplio</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="1362" end_char="1369">espectro</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="1371" end_char="1372">de</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="1374" end_char="1376">los</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="1378" end_char="1383">cuales</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="1385" end_char="1386">ya</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="1388" end_char="1389">se</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="1391" end_char="1392">ha</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="1394" end_char="1403">verificado</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="1405" end_char="1407">que</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="1409" end_char="1410">no</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="1412" end_char="1419">provocan</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="1421" end_char="1427">efectos</TOKEN>
<TOKEN id="token-8-25" pos="word" morph="none" start_char="1429" end_char="1439">secundarios</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="1441" end_char="1449">demasiado</TOKEN>
<TOKEN id="token-8-27" pos="word" morph="none" start_char="1451" end_char="1457">fuertes</TOKEN>
<TOKEN id="token-8-28" pos="word" morph="none" start_char="1459" end_char="1460">en</TOKEN>
<TOKEN id="token-8-29" pos="word" morph="none" start_char="1462" end_char="1463">el</TOKEN>
<TOKEN id="token-8-30" pos="word" morph="none" start_char="1465" end_char="1467">ser</TOKEN>
<TOKEN id="token-8-31" pos="word" morph="none" start_char="1469" end_char="1474">humano</TOKEN>
<TOKEN id="token-8-32" pos="punct" morph="none" start_char="1475" end_char="1475">,</TOKEN>
<TOKEN id="token-8-33" pos="word" morph="none" start_char="1477" end_char="1479">son</TOKEN>
<TOKEN id="token-8-34" pos="word" morph="none" start_char="1481" end_char="1486">buenos</TOKEN>
<TOKEN id="token-8-35" pos="word" morph="none" start_char="1488" end_char="1497">candidatos</TOKEN>
<TOKEN id="token-8-36" pos="word" morph="none" start_char="1499" end_char="1502">para</TOKEN>
<TOKEN id="token-8-37" pos="word" morph="none" start_char="1504" end_char="1509">tratar</TOKEN>
<TOKEN id="token-8-38" pos="word" morph="none" start_char="1511" end_char="1512">la</TOKEN>
<TOKEN id="token-8-39" pos="word" morph="none" start_char="1514" end_char="1523">enfermedad</TOKEN>
<TOKEN id="token-8-40" pos="word" morph="none" start_char="1525" end_char="1531">causada</TOKEN>
<TOKEN id="token-8-41" pos="word" morph="none" start_char="1533" end_char="1535">por</TOKEN>
<TOKEN id="token-8-42" pos="word" morph="none" start_char="1537" end_char="1538">el</TOKEN>
<TOKEN id="token-8-43" pos="word" morph="none" start_char="1540" end_char="1544">nuevo</TOKEN>
<TOKEN id="token-8-44" pos="word" morph="none" start_char="1546" end_char="1556">coronavirus</TOKEN>
<TOKEN id="token-8-45" pos="punct" morph="none" start_char="1557" end_char="1557">,</TOKEN>
<TOKEN id="token-8-46" pos="word" morph="none" start_char="1559" end_char="1560">al</TOKEN>
<TOKEN id="token-8-47" pos="word" morph="none" start_char="1562" end_char="1566">menos</TOKEN>
<TOKEN id="token-8-48" pos="word" morph="none" start_char="1568" end_char="1572">hasta</TOKEN>
<TOKEN id="token-8-49" pos="word" morph="none" start_char="1574" end_char="1576">que</TOKEN>
<TOKEN id="token-8-50" pos="word" morph="none" start_char="1578" end_char="1579">se</TOKEN>
<TOKEN id="token-8-51" pos="word" morph="none" start_char="1581" end_char="1589">compruebe</TOKEN>
<TOKEN id="token-8-52" pos="word" morph="none" start_char="1591" end_char="1592">la</TOKEN>
<TOKEN id="token-8-53" pos="word" morph="none" start_char="1594" end_char="1600">validez</TOKEN>
<TOKEN id="token-8-54" pos="word" morph="none" start_char="1602" end_char="1603">de</TOKEN>
<TOKEN id="token-8-55" pos="word" morph="none" start_char="1605" end_char="1610">nuevos</TOKEN>
<TOKEN id="token-8-56" pos="word" morph="none" start_char="1612" end_char="1623">medicamentos</TOKEN>
<TOKEN id="token-8-57" pos="word" morph="none" start_char="1625" end_char="1634">orientados</TOKEN>
<TOKEN id="token-8-58" pos="word" morph="none" start_char="1636" end_char="1650">específicamente</TOKEN>
<TOKEN id="token-8-59" pos="word" morph="none" start_char="1652" end_char="1657">contra</TOKEN>
<TOKEN id="token-8-60" pos="word" morph="none" start_char="1659" end_char="1660">él</TOKEN>
<TOKEN id="token-8-61" pos="word" morph="none" start_char="1662" end_char="1662">y</TOKEN>
<TOKEN id="token-8-62" pos="word" morph="none" start_char="1664" end_char="1666">que</TOKEN>
<TOKEN id="token-8-63" pos="word" morph="none" start_char="1668" end_char="1671">sean</TOKEN>
<TOKEN id="token-8-64" pos="word" morph="none" start_char="1673" end_char="1675">más</TOKEN>
<TOKEN id="token-8-65" pos="word" morph="none" start_char="1677" end_char="1684">eficaces</TOKEN>
<TOKEN id="token-8-66" pos="punct" morph="none" start_char="1685" end_char="1685">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1689" end_char="1708">
<ORIGINAL_TEXT>Un atajo provisional</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1689" end_char="1690">Un</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1692" end_char="1696">atajo</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1698" end_char="1708">provisional</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1712" end_char="2015">
<ORIGINAL_TEXT>La ventaja de reutilizar para otra enfermedad un medicamento ya en uso contra otras es que ya se conocen todos los detalles que rodean el desarrollo del medicamento, desde los pasos de síntesis química y los procesos de fabricación hasta la información sobre las diferentes fases de las pruebas clínicas.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1712" end_char="1713">La</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1715" end_char="1721">ventaja</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1723" end_char="1724">de</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1726" end_char="1735">reutilizar</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1737" end_char="1740">para</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1742" end_char="1745">otra</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1747" end_char="1756">enfermedad</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1758" end_char="1759">un</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1761" end_char="1771">medicamento</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1773" end_char="1774">ya</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1776" end_char="1777">en</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1779" end_char="1781">uso</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1783" end_char="1788">contra</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1790" end_char="1794">otras</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1796" end_char="1797">es</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1799" end_char="1801">que</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1803" end_char="1804">ya</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1806" end_char="1807">se</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1809" end_char="1815">conocen</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1817" end_char="1821">todos</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1823" end_char="1825">los</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1827" end_char="1834">detalles</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1836" end_char="1838">que</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1840" end_char="1845">rodean</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1847" end_char="1848">el</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="1850" end_char="1859">desarrollo</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="1861" end_char="1863">del</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="1865" end_char="1875">medicamento</TOKEN>
<TOKEN id="token-10-28" pos="punct" morph="none" start_char="1876" end_char="1876">,</TOKEN>
<TOKEN id="token-10-29" pos="word" morph="none" start_char="1878" end_char="1882">desde</TOKEN>
<TOKEN id="token-10-30" pos="word" morph="none" start_char="1884" end_char="1886">los</TOKEN>
<TOKEN id="token-10-31" pos="word" morph="none" start_char="1888" end_char="1892">pasos</TOKEN>
<TOKEN id="token-10-32" pos="word" morph="none" start_char="1894" end_char="1895">de</TOKEN>
<TOKEN id="token-10-33" pos="word" morph="none" start_char="1897" end_char="1904">síntesis</TOKEN>
<TOKEN id="token-10-34" pos="word" morph="none" start_char="1906" end_char="1912">química</TOKEN>
<TOKEN id="token-10-35" pos="word" morph="none" start_char="1914" end_char="1914">y</TOKEN>
<TOKEN id="token-10-36" pos="word" morph="none" start_char="1916" end_char="1918">los</TOKEN>
<TOKEN id="token-10-37" pos="word" morph="none" start_char="1920" end_char="1927">procesos</TOKEN>
<TOKEN id="token-10-38" pos="word" morph="none" start_char="1929" end_char="1930">de</TOKEN>
<TOKEN id="token-10-39" pos="word" morph="none" start_char="1932" end_char="1942">fabricación</TOKEN>
<TOKEN id="token-10-40" pos="word" morph="none" start_char="1944" end_char="1948">hasta</TOKEN>
<TOKEN id="token-10-41" pos="word" morph="none" start_char="1950" end_char="1951">la</TOKEN>
<TOKEN id="token-10-42" pos="word" morph="none" start_char="1953" end_char="1963">información</TOKEN>
<TOKEN id="token-10-43" pos="word" morph="none" start_char="1965" end_char="1969">sobre</TOKEN>
<TOKEN id="token-10-44" pos="word" morph="none" start_char="1971" end_char="1973">las</TOKEN>
<TOKEN id="token-10-45" pos="word" morph="none" start_char="1975" end_char="1984">diferentes</TOKEN>
<TOKEN id="token-10-46" pos="word" morph="none" start_char="1986" end_char="1990">fases</TOKEN>
<TOKEN id="token-10-47" pos="word" morph="none" start_char="1992" end_char="1993">de</TOKEN>
<TOKEN id="token-10-48" pos="word" morph="none" start_char="1995" end_char="1997">las</TOKEN>
<TOKEN id="token-10-49" pos="word" morph="none" start_char="1999" end_char="2005">pruebas</TOKEN>
<TOKEN id="token-10-50" pos="word" morph="none" start_char="2007" end_char="2014">clínicas</TOKEN>
<TOKEN id="token-10-51" pos="punct" morph="none" start_char="2015" end_char="2015">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="2018" end_char="2522">
<ORIGINAL_TEXT>Poner a prueba contra una nueva dolencia medicamentos ya en uso contra otras o incluso medicamentos de los que se comprobó que no provocan efectos secundarios graves en el ser humano pero que fracasaron al no poder tratar la enfermedad para la que fueron originalmente diseñados, brinda valiosas oportunidades de obtener con rapidez fármacos utilizables contra una nueva, gracias a que buena parte de la inversión económica y el trabajo iniciales ya están hechos, tal como razonan los autores del estudio.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="2018" end_char="2022">Poner</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="2024" end_char="2024">a</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="2026" end_char="2031">prueba</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="2033" end_char="2038">contra</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="2040" end_char="2042">una</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="2044" end_char="2048">nueva</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="2050" end_char="2057">dolencia</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="2059" end_char="2070">medicamentos</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="2072" end_char="2073">ya</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="2075" end_char="2076">en</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="2078" end_char="2080">uso</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="2082" end_char="2087">contra</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="2089" end_char="2093">otras</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="2095" end_char="2095">o</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="2097" end_char="2103">incluso</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="2105" end_char="2116">medicamentos</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="2118" end_char="2119">de</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="2121" end_char="2123">los</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="2125" end_char="2127">que</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="2129" end_char="2130">se</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="2132" end_char="2139">comprobó</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="2141" end_char="2143">que</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="2145" end_char="2146">no</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="2148" end_char="2155">provocan</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="2157" end_char="2163">efectos</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="2165" end_char="2175">secundarios</TOKEN>
<TOKEN id="token-11-26" pos="word" morph="none" start_char="2177" end_char="2182">graves</TOKEN>
<TOKEN id="token-11-27" pos="word" morph="none" start_char="2184" end_char="2185">en</TOKEN>
<TOKEN id="token-11-28" pos="word" morph="none" start_char="2187" end_char="2188">el</TOKEN>
<TOKEN id="token-11-29" pos="word" morph="none" start_char="2190" end_char="2192">ser</TOKEN>
<TOKEN id="token-11-30" pos="word" morph="none" start_char="2194" end_char="2199">humano</TOKEN>
<TOKEN id="token-11-31" pos="word" morph="none" start_char="2201" end_char="2204">pero</TOKEN>
<TOKEN id="token-11-32" pos="word" morph="none" start_char="2206" end_char="2208">que</TOKEN>
<TOKEN id="token-11-33" pos="word" morph="none" start_char="2210" end_char="2219">fracasaron</TOKEN>
<TOKEN id="token-11-34" pos="word" morph="none" start_char="2221" end_char="2222">al</TOKEN>
<TOKEN id="token-11-35" pos="word" morph="none" start_char="2224" end_char="2225">no</TOKEN>
<TOKEN id="token-11-36" pos="word" morph="none" start_char="2227" end_char="2231">poder</TOKEN>
<TOKEN id="token-11-37" pos="word" morph="none" start_char="2233" end_char="2238">tratar</TOKEN>
<TOKEN id="token-11-38" pos="word" morph="none" start_char="2240" end_char="2241">la</TOKEN>
<TOKEN id="token-11-39" pos="word" morph="none" start_char="2243" end_char="2252">enfermedad</TOKEN>
<TOKEN id="token-11-40" pos="word" morph="none" start_char="2254" end_char="2257">para</TOKEN>
<TOKEN id="token-11-41" pos="word" morph="none" start_char="2259" end_char="2260">la</TOKEN>
<TOKEN id="token-11-42" pos="word" morph="none" start_char="2262" end_char="2264">que</TOKEN>
<TOKEN id="token-11-43" pos="word" morph="none" start_char="2266" end_char="2271">fueron</TOKEN>
<TOKEN id="token-11-44" pos="word" morph="none" start_char="2273" end_char="2285">originalmente</TOKEN>
<TOKEN id="token-11-45" pos="word" morph="none" start_char="2287" end_char="2295">diseñados</TOKEN>
<TOKEN id="token-11-46" pos="punct" morph="none" start_char="2296" end_char="2296">,</TOKEN>
<TOKEN id="token-11-47" pos="word" morph="none" start_char="2298" end_char="2303">brinda</TOKEN>
<TOKEN id="token-11-48" pos="word" morph="none" start_char="2305" end_char="2312">valiosas</TOKEN>
<TOKEN id="token-11-49" pos="word" morph="none" start_char="2314" end_char="2326">oportunidades</TOKEN>
<TOKEN id="token-11-50" pos="word" morph="none" start_char="2328" end_char="2329">de</TOKEN>
<TOKEN id="token-11-51" pos="word" morph="none" start_char="2331" end_char="2337">obtener</TOKEN>
<TOKEN id="token-11-52" pos="word" morph="none" start_char="2339" end_char="2341">con</TOKEN>
<TOKEN id="token-11-53" pos="word" morph="none" start_char="2343" end_char="2349">rapidez</TOKEN>
<TOKEN id="token-11-54" pos="word" morph="none" start_char="2351" end_char="2358">fármacos</TOKEN>
<TOKEN id="token-11-55" pos="word" morph="none" start_char="2360" end_char="2370">utilizables</TOKEN>
<TOKEN id="token-11-56" pos="word" morph="none" start_char="2372" end_char="2377">contra</TOKEN>
<TOKEN id="token-11-57" pos="word" morph="none" start_char="2379" end_char="2381">una</TOKEN>
<TOKEN id="token-11-58" pos="word" morph="none" start_char="2383" end_char="2387">nueva</TOKEN>
<TOKEN id="token-11-59" pos="punct" morph="none" start_char="2388" end_char="2388">,</TOKEN>
<TOKEN id="token-11-60" pos="word" morph="none" start_char="2390" end_char="2396">gracias</TOKEN>
<TOKEN id="token-11-61" pos="word" morph="none" start_char="2398" end_char="2398">a</TOKEN>
<TOKEN id="token-11-62" pos="word" morph="none" start_char="2400" end_char="2402">que</TOKEN>
<TOKEN id="token-11-63" pos="word" morph="none" start_char="2404" end_char="2408">buena</TOKEN>
<TOKEN id="token-11-64" pos="word" morph="none" start_char="2410" end_char="2414">parte</TOKEN>
<TOKEN id="token-11-65" pos="word" morph="none" start_char="2416" end_char="2417">de</TOKEN>
<TOKEN id="token-11-66" pos="word" morph="none" start_char="2419" end_char="2420">la</TOKEN>
<TOKEN id="token-11-67" pos="word" morph="none" start_char="2422" end_char="2430">inversión</TOKEN>
<TOKEN id="token-11-68" pos="word" morph="none" start_char="2432" end_char="2440">económica</TOKEN>
<TOKEN id="token-11-69" pos="word" morph="none" start_char="2442" end_char="2442">y</TOKEN>
<TOKEN id="token-11-70" pos="word" morph="none" start_char="2444" end_char="2445">el</TOKEN>
<TOKEN id="token-11-71" pos="word" morph="none" start_char="2447" end_char="2453">trabajo</TOKEN>
<TOKEN id="token-11-72" pos="word" morph="none" start_char="2455" end_char="2463">iniciales</TOKEN>
<TOKEN id="token-11-73" pos="word" morph="none" start_char="2465" end_char="2466">ya</TOKEN>
<TOKEN id="token-11-74" pos="word" morph="none" start_char="2468" end_char="2472">están</TOKEN>
<TOKEN id="token-11-75" pos="word" morph="none" start_char="2474" end_char="2479">hechos</TOKEN>
<TOKEN id="token-11-76" pos="punct" morph="none" start_char="2480" end_char="2480">,</TOKEN>
<TOKEN id="token-11-77" pos="word" morph="none" start_char="2482" end_char="2484">tal</TOKEN>
<TOKEN id="token-11-78" pos="word" morph="none" start_char="2486" end_char="2489">como</TOKEN>
<TOKEN id="token-11-79" pos="word" morph="none" start_char="2491" end_char="2497">razonan</TOKEN>
<TOKEN id="token-11-80" pos="word" morph="none" start_char="2499" end_char="2501">los</TOKEN>
<TOKEN id="token-11-81" pos="word" morph="none" start_char="2503" end_char="2509">autores</TOKEN>
<TOKEN id="token-11-82" pos="word" morph="none" start_char="2511" end_char="2513">del</TOKEN>
<TOKEN id="token-11-83" pos="word" morph="none" start_char="2515" end_char="2521">estudio</TOKEN>
<TOKEN id="token-11-84" pos="punct" morph="none" start_char="2522" end_char="2522">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="2525" end_char="2736">
<ORIGINAL_TEXT>Los investigadores revisaron la información sobre el descubrimiento y el desarrollo de agentes antivirales de amplio espectro, que son medicamentos que atacan a los virus de dos o más familias virales diferentes.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="2525" end_char="2527">Los</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="2529" end_char="2542">investigadores</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="2544" end_char="2552">revisaron</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="2554" end_char="2555">la</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="2557" end_char="2567">información</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="2569" end_char="2573">sobre</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="2575" end_char="2576">el</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="2578" end_char="2591">descubrimiento</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="2593" end_char="2593">y</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="2595" end_char="2596">el</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="2598" end_char="2607">desarrollo</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="2609" end_char="2610">de</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="2612" end_char="2618">agentes</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="2620" end_char="2630">antivirales</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="2632" end_char="2633">de</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="2635" end_char="2640">amplio</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="2642" end_char="2649">espectro</TOKEN>
<TOKEN id="token-12-17" pos="punct" morph="none" start_char="2650" end_char="2650">,</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="2652" end_char="2654">que</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="2656" end_char="2658">son</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="2660" end_char="2671">medicamentos</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="2673" end_char="2675">que</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="2677" end_char="2682">atacan</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="2684" end_char="2684">a</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="2686" end_char="2688">los</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="2690" end_char="2694">virus</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="2696" end_char="2697">de</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="2699" end_char="2701">dos</TOKEN>
<TOKEN id="token-12-28" pos="word" morph="none" start_char="2703" end_char="2703">o</TOKEN>
<TOKEN id="token-12-29" pos="word" morph="none" start_char="2705" end_char="2707">más</TOKEN>
<TOKEN id="token-12-30" pos="word" morph="none" start_char="2709" end_char="2716">familias</TOKEN>
<TOKEN id="token-12-31" pos="word" morph="none" start_char="2718" end_char="2724">virales</TOKEN>
<TOKEN id="token-12-32" pos="word" morph="none" start_char="2726" end_char="2735">diferentes</TOKEN>
<TOKEN id="token-12-33" pos="punct" morph="none" start_char="2736" end_char="2736">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="2738" end_char="2952">
<ORIGINAL_TEXT>Han encontrado 31 medicamentos que ya demostraron ser seguros para el uso humano y que son candidatos a utilizarse para la profilaxis y el tratamiento contra la nueva enfermedad por coronavirus, denominada COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="2738" end_char="2740">Han</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="2742" end_char="2751">encontrado</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="2753" end_char="2754">31</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="2756" end_char="2767">medicamentos</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="2769" end_char="2771">que</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="2773" end_char="2774">ya</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="2776" end_char="2786">demostraron</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="2788" end_char="2790">ser</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="2792" end_char="2798">seguros</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="2800" end_char="2803">para</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="2805" end_char="2806">el</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="2808" end_char="2810">uso</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="2812" end_char="2817">humano</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="2819" end_char="2819">y</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="2821" end_char="2823">que</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="2825" end_char="2827">son</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="2829" end_char="2838">candidatos</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="2840" end_char="2840">a</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="2842" end_char="2851">utilizarse</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="2853" end_char="2856">para</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="2858" end_char="2859">la</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="2861" end_char="2870">profilaxis</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="2872" end_char="2872">y</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="2874" end_char="2875">el</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="2877" end_char="2887">tratamiento</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="2889" end_char="2894">contra</TOKEN>
<TOKEN id="token-13-26" pos="word" morph="none" start_char="2896" end_char="2897">la</TOKEN>
<TOKEN id="token-13-27" pos="word" morph="none" start_char="2899" end_char="2903">nueva</TOKEN>
<TOKEN id="token-13-28" pos="word" morph="none" start_char="2905" end_char="2914">enfermedad</TOKEN>
<TOKEN id="token-13-29" pos="word" morph="none" start_char="2916" end_char="2918">por</TOKEN>
<TOKEN id="token-13-30" pos="word" morph="none" start_char="2920" end_char="2930">coronavirus</TOKEN>
<TOKEN id="token-13-31" pos="punct" morph="none" start_char="2931" end_char="2931">,</TOKEN>
<TOKEN id="token-13-32" pos="word" morph="none" start_char="2933" end_char="2942">denominada</TOKEN>
<TOKEN id="token-13-33" pos="unknown" morph="none" start_char="2944" end_char="2951">COVID-19</TOKEN>
<TOKEN id="token-13-34" pos="punct" morph="none" start_char="2952" end_char="2952">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="2955" end_char="3138">
<ORIGINAL_TEXT>Los investigadores también han comprobado que recientemente se han iniciado investigaciones clínicas sobre cinco candidatos a medicamentos para tratar el virus causante de la COVID-19.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="2955" end_char="2957">Los</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="2959" end_char="2972">investigadores</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="2974" end_char="2980">también</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="2982" end_char="2984">han</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="2986" end_char="2995">comprobado</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="2997" end_char="2999">que</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="3001" end_char="3013">recientemente</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="3015" end_char="3016">se</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="3018" end_char="3020">han</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="3022" end_char="3029">iniciado</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="3031" end_char="3045">investigaciones</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="3047" end_char="3054">clínicas</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="3056" end_char="3060">sobre</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="3062" end_char="3066">cinco</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="3068" end_char="3077">candidatos</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="3079" end_char="3079">a</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="3081" end_char="3092">medicamentos</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="3094" end_char="3097">para</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="3099" end_char="3104">tratar</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="3106" end_char="3107">el</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="3109" end_char="3113">virus</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="3115" end_char="3122">causante</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="3124" end_char="3125">de</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="3127" end_char="3128">la</TOKEN>
<TOKEN id="token-14-24" pos="unknown" morph="none" start_char="3130" end_char="3137">COVID-19</TOKEN>
<TOKEN id="token-14-25" pos="punct" morph="none" start_char="3138" end_char="3138">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="3140" end_char="3162">
<ORIGINAL_TEXT>(Fuente: NCYT Amazings)</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="punct" morph="none" start_char="3140" end_char="3140">(</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="3141" end_char="3146">Fuente</TOKEN>
<TOKEN id="token-15-2" pos="punct" morph="none" start_char="3147" end_char="3147">:</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="3149" end_char="3152">NCYT</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="3154" end_char="3161">Amazings</TOKEN>
<TOKEN id="token-15-5" pos="punct" morph="none" start_char="3162" end_char="3162">)</TOKEN>
</SEG>
<SEG id="segment-16" start_char="3167" end_char="3249">
<ORIGINAL_TEXT>Copyright © 1996-2020 Amazings® / NCYT® | (Noticiasdelaciencia.com / Amazings.com).</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="3167" end_char="3175">Copyright</TOKEN>
<TOKEN id="token-16-1" pos="unknown" morph="none" start_char="3177" end_char="3177">©</TOKEN>
<TOKEN id="token-16-2" pos="unknown" morph="none" start_char="3179" end_char="3187">1996-2020</TOKEN>
<TOKEN id="token-16-3" pos="unknown" morph="none" start_char="3189" end_char="3197">Amazings®</TOKEN>
<TOKEN id="token-16-4" pos="punct" morph="none" start_char="3199" end_char="3199">/</TOKEN>
<TOKEN id="token-16-5" pos="unknown" morph="none" start_char="3201" end_char="3205">NCYT®</TOKEN>
<TOKEN id="token-16-6" pos="unknown" morph="none" start_char="3207" end_char="3207">|</TOKEN>
<TOKEN id="token-16-7" pos="punct" morph="none" start_char="3209" end_char="3209">(</TOKEN>
<TOKEN id="token-16-8" pos="unknown" morph="none" start_char="3210" end_char="3232">Noticiasdelaciencia.com</TOKEN>
<TOKEN id="token-16-9" pos="punct" morph="none" start_char="3234" end_char="3234">/</TOKEN>
<TOKEN id="token-16-10" pos="unknown" morph="none" start_char="3236" end_char="3247">Amazings.com</TOKEN>
<TOKEN id="token-16-11" pos="punct" morph="none" start_char="3248" end_char="3249">).</TOKEN>
</SEG>
<SEG id="segment-17" start_char="3251" end_char="3280">
<ORIGINAL_TEXT>Todos los derechos reservados.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="3251" end_char="3255">Todos</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="3257" end_char="3259">los</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="3261" end_char="3268">derechos</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="3270" end_char="3279">reservados</TOKEN>
<TOKEN id="token-17-4" pos="punct" morph="none" start_char="3280" end_char="3280">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="3283" end_char="3367">
<ORIGINAL_TEXT>Depósito Legal B-47398-2009, ISSN 2013-6714 - Amazings y NCYT son marcas registradas.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="3283" end_char="3290">Depósito</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="3292" end_char="3296">Legal</TOKEN>
<TOKEN id="token-18-2" pos="unknown" morph="none" start_char="3298" end_char="3309">B-47398-2009</TOKEN>
<TOKEN id="token-18-3" pos="punct" morph="none" start_char="3310" end_char="3310">,</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="3312" end_char="3315">ISSN</TOKEN>
<TOKEN id="token-18-5" pos="unknown" morph="none" start_char="3317" end_char="3325">2013-6714</TOKEN>
<TOKEN id="token-18-6" pos="punct" morph="none" start_char="3327" end_char="3327">-</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="3329" end_char="3336">Amazings</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="3338" end_char="3338">y</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="3340" end_char="3343">NCYT</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="3345" end_char="3347">son</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="3349" end_char="3354">marcas</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="3356" end_char="3366">registradas</TOKEN>
<TOKEN id="token-18-13" pos="punct" morph="none" start_char="3367" end_char="3367">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="3369" end_char="3442">
<ORIGINAL_TEXT>Noticiasdelaciencia.com y Amazings.com son las webs oficiales de Amazings.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="unknown" morph="none" start_char="3369" end_char="3391">Noticiasdelaciencia.com</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="3393" end_char="3393">y</TOKEN>
<TOKEN id="token-19-2" pos="unknown" morph="none" start_char="3395" end_char="3406">Amazings.com</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="3408" end_char="3410">son</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="3412" end_char="3414">las</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="3416" end_char="3419">webs</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="3421" end_char="3429">oficiales</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="3431" end_char="3432">de</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="3434" end_char="3441">Amazings</TOKEN>
<TOKEN id="token-19-9" pos="punct" morph="none" start_char="3442" end_char="3442">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="3445" end_char="3501">
<ORIGINAL_TEXT>Todos los textos y gráficos son propiedad de sus autores.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="3445" end_char="3449">Todos</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="3451" end_char="3453">los</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="3455" end_char="3460">textos</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="3462" end_char="3462">y</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="3464" end_char="3471">gráficos</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="3473" end_char="3475">son</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="3477" end_char="3485">propiedad</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="3487" end_char="3488">de</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="3490" end_char="3492">sus</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="3494" end_char="3500">autores</TOKEN>
<TOKEN id="token-20-10" pos="punct" morph="none" start_char="3501" end_char="3501">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="3503" end_char="3639">
<ORIGINAL_TEXT>La reproducción está permitida solo si se incluye el crédito de la fuente (NCYT Amazings) y un enlace dofollow hacia la noticia original.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="3503" end_char="3504">La</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="3506" end_char="3517">reproducción</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="3519" end_char="3522">está</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="3524" end_char="3532">permitida</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="3534" end_char="3537">solo</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="3539" end_char="3540">si</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="3542" end_char="3543">se</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="3545" end_char="3551">incluye</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="3553" end_char="3554">el</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="3556" end_char="3562">crédito</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="3564" end_char="3565">de</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="3567" end_char="3568">la</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="3570" end_char="3575">fuente</TOKEN>
<TOKEN id="token-21-13" pos="punct" morph="none" start_char="3577" end_char="3577">(</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="3578" end_char="3581">NCYT</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="3583" end_char="3590">Amazings</TOKEN>
<TOKEN id="token-21-16" pos="punct" morph="none" start_char="3591" end_char="3591">)</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="3593" end_char="3593">y</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="3595" end_char="3596">un</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="3598" end_char="3603">enlace</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="3605" end_char="3612">dofollow</TOKEN>
<TOKEN id="token-21-21" pos="word" morph="none" start_char="3614" end_char="3618">hacia</TOKEN>
<TOKEN id="token-21-22" pos="word" morph="none" start_char="3620" end_char="3621">la</TOKEN>
<TOKEN id="token-21-23" pos="word" morph="none" start_char="3623" end_char="3629">noticia</TOKEN>
<TOKEN id="token-21-24" pos="word" morph="none" start_char="3631" end_char="3638">original</TOKEN>
<TOKEN id="token-21-25" pos="punct" morph="none" start_char="3639" end_char="3639">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="3642" end_char="3818">
<ORIGINAL_TEXT>Excepto cuando se indique lo contrario, la traducción, la adaptación y la elaboración de texto adicional de este artículo han sido realizadas por el equipo de Amazings® / NCYT®.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="3642" end_char="3648">Excepto</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="3650" end_char="3655">cuando</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="3657" end_char="3658">se</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="3660" end_char="3666">indique</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="3668" end_char="3669">lo</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="3671" end_char="3679">contrario</TOKEN>
<TOKEN id="token-22-6" pos="punct" morph="none" start_char="3680" end_char="3680">,</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="3682" end_char="3683">la</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="3685" end_char="3694">traducción</TOKEN>
<TOKEN id="token-22-9" pos="punct" morph="none" start_char="3695" end_char="3695">,</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="3697" end_char="3698">la</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="3700" end_char="3709">adaptación</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="3711" end_char="3711">y</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="3713" end_char="3714">la</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="3716" end_char="3726">elaboración</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="3728" end_char="3729">de</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="3731" end_char="3735">texto</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="3737" end_char="3745">adicional</TOKEN>
<TOKEN id="token-22-18" pos="word" morph="none" start_char="3747" end_char="3748">de</TOKEN>
<TOKEN id="token-22-19" pos="word" morph="none" start_char="3750" end_char="3753">este</TOKEN>
<TOKEN id="token-22-20" pos="word" morph="none" start_char="3755" end_char="3762">artículo</TOKEN>
<TOKEN id="token-22-21" pos="word" morph="none" start_char="3764" end_char="3766">han</TOKEN>
<TOKEN id="token-22-22" pos="word" morph="none" start_char="3768" end_char="3771">sido</TOKEN>
<TOKEN id="token-22-23" pos="word" morph="none" start_char="3773" end_char="3782">realizadas</TOKEN>
<TOKEN id="token-22-24" pos="word" morph="none" start_char="3784" end_char="3786">por</TOKEN>
<TOKEN id="token-22-25" pos="word" morph="none" start_char="3788" end_char="3789">el</TOKEN>
<TOKEN id="token-22-26" pos="word" morph="none" start_char="3791" end_char="3796">equipo</TOKEN>
<TOKEN id="token-22-27" pos="word" morph="none" start_char="3798" end_char="3799">de</TOKEN>
<TOKEN id="token-22-28" pos="unknown" morph="none" start_char="3801" end_char="3809">Amazings®</TOKEN>
<TOKEN id="token-22-29" pos="punct" morph="none" start_char="3811" end_char="3811">/</TOKEN>
<TOKEN id="token-22-30" pos="unknown" morph="none" start_char="3813" end_char="3818">NCYT®.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
