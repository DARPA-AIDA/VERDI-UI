<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="spa">
<DOC id="L0C04CVHM" lang="spa" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="3737" raw_text_md5="37ae4235cb62cb0f1fbd2ff3bafd34ae">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="76">
<ORIGINAL_TEXT>Is India failing the contact tracing test in its battle against coronavirus?</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="2">Is</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="4" end_char="8">India</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="10" end_char="16">failing</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="18" end_char="20">the</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="22" end_char="28">contact</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="30" end_char="36">tracing</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="38" end_char="41">test</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="43" end_char="44">in</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="46" end_char="48">its</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="50" end_char="55">battle</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="57" end_char="63">against</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="65" end_char="75">coronavirus</TOKEN>
<TOKEN id="token-0-12" pos="punct" morph="none" start_char="76" end_char="76">?</TOKEN>
</SEG>
<SEG id="segment-1" start_char="80" end_char="224">
<ORIGINAL_TEXT>States that did the least testing among contacts of confirmed cases were among those with the highest rates of positive cases among those tested.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="80" end_char="85">States</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="87" end_char="90">that</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="92" end_char="94">did</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="96" end_char="98">the</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="100" end_char="104">least</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="106" end_char="112">testing</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="114" end_char="118">among</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="120" end_char="127">contacts</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="129" end_char="130">of</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="132" end_char="140">confirmed</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="142" end_char="146">cases</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="148" end_char="151">were</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="153" end_char="157">among</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="159" end_char="163">those</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="165" end_char="168">with</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="170" end_char="172">the</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="174" end_char="180">highest</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="182" end_char="186">rates</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="188" end_char="189">of</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="191" end_char="198">positive</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="200" end_char="204">cases</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="206" end_char="210">among</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="212" end_char="216">those</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="218" end_char="223">tested</TOKEN>
<TOKEN id="token-1-24" pos="punct" morph="none" start_char="224" end_char="224">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="226" end_char="237">
<ORIGINAL_TEXT>(Photo: PTI)</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="punct" morph="none" start_char="226" end_char="226">(</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="227" end_char="231">Photo</TOKEN>
<TOKEN id="token-2-2" pos="punct" morph="none" start_char="232" end_char="232">:</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="234" end_char="236">PTI</TOKEN>
<TOKEN id="token-2-4" pos="punct" morph="none" start_char="237" end_char="237">)</TOKEN>
</SEG>
<SEG id="segment-3" start_char="241" end_char="398">
<ORIGINAL_TEXT>On May 30, the Indian Journal of Medical Research (IJMR) published the Indian Council of Medical Research’s (ICMR) first analysis of India’s SARS-CoV-2 cases.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="241" end_char="242">On</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="244" end_char="246">May</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="248" end_char="249">30</TOKEN>
<TOKEN id="token-3-3" pos="punct" morph="none" start_char="250" end_char="250">,</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="252" end_char="254">the</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="256" end_char="261">Indian</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="263" end_char="269">Journal</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="271" end_char="272">of</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="274" end_char="280">Medical</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="282" end_char="289">Research</TOKEN>
<TOKEN id="token-3-10" pos="punct" morph="none" start_char="291" end_char="291">(</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="292" end_char="295">IJMR</TOKEN>
<TOKEN id="token-3-12" pos="punct" morph="none" start_char="296" end_char="296">)</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="298" end_char="306">published</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="308" end_char="310">the</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="312" end_char="317">Indian</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="319" end_char="325">Council</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="327" end_char="328">of</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="330" end_char="336">Medical</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="338" end_char="347">Research’s</TOKEN>
<TOKEN id="token-3-20" pos="punct" morph="none" start_char="349" end_char="349">(</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="350" end_char="353">ICMR</TOKEN>
<TOKEN id="token-3-22" pos="punct" morph="none" start_char="354" end_char="354">)</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="356" end_char="360">first</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="362" end_char="369">analysis</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="371" end_char="372">of</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="374" end_char="380">India’s</TOKEN>
<TOKEN id="token-3-27" pos="unknown" morph="none" start_char="382" end_char="391">SARS-CoV-2</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="393" end_char="397">cases</TOKEN>
<TOKEN id="token-3-29" pos="punct" morph="none" start_char="398" end_char="398">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="400" end_char="546">
<ORIGINAL_TEXT>The team of scientists tested over a million people and found more than 40,000 positive cases between January 22 and April 30 all over the country.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="400" end_char="402">The</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="404" end_char="407">team</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="409" end_char="410">of</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="412" end_char="421">scientists</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="423" end_char="428">tested</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="430" end_char="433">over</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="435" end_char="435">a</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="437" end_char="443">million</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="445" end_char="450">people</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="452" end_char="454">and</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="456" end_char="460">found</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="462" end_char="465">more</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="467" end_char="470">than</TOKEN>
<TOKEN id="token-4-13" pos="unknown" morph="none" start_char="472" end_char="477">40,000</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="479" end_char="486">positive</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="488" end_char="492">cases</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="494" end_char="500">between</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="502" end_char="508">January</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="510" end_char="511">22</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="513" end_char="515">and</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="517" end_char="521">April</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="523" end_char="524">30</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="526" end_char="528">all</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="530" end_char="533">over</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="535" end_char="537">the</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="539" end_char="545">country</TOKEN>
<TOKEN id="token-4-26" pos="punct" morph="none" start_char="546" end_char="546">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="549" end_char="692">
<ORIGINAL_TEXT>Data shows India is falling far behind in contact tracing, even though it has emerged as the most important route to contain the virus’s spread.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="549" end_char="552">Data</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="554" end_char="558">shows</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="560" end_char="564">India</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="566" end_char="567">is</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="569" end_char="575">falling</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="577" end_char="579">far</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="581" end_char="586">behind</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="588" end_char="589">in</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="591" end_char="597">contact</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="599" end_char="605">tracing</TOKEN>
<TOKEN id="token-5-10" pos="punct" morph="none" start_char="606" end_char="606">,</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="608" end_char="611">even</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="613" end_char="618">though</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="620" end_char="621">it</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="623" end_char="625">has</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="627" end_char="633">emerged</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="635" end_char="636">as</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="638" end_char="640">the</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="642" end_char="645">most</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="647" end_char="655">important</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="657" end_char="661">route</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="663" end_char="664">to</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="666" end_char="672">contain</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="674" end_char="676">the</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="678" end_char="684">virus’s</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="686" end_char="691">spread</TOKEN>
<TOKEN id="token-5-26" pos="punct" morph="none" start_char="692" end_char="692">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="696" end_char="801">
<ORIGINAL_TEXT>Data shows younger people and men were slightly more likely to get tested than they were to test positive.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="696" end_char="699">Data</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="701" end_char="705">shows</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="707" end_char="713">younger</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="715" end_char="720">people</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="722" end_char="724">and</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="726" end_char="728">men</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="730" end_char="733">were</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="735" end_char="742">slightly</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="744" end_char="747">more</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="749" end_char="754">likely</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="756" end_char="757">to</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="759" end_char="761">get</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="763" end_char="768">tested</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="770" end_char="773">than</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="775" end_char="778">they</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="780" end_char="783">were</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="785" end_char="786">to</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="788" end_char="791">test</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="793" end_char="800">positive</TOKEN>
<TOKEN id="token-6-19" pos="punct" morph="none" start_char="801" end_char="801">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="803" end_char="893">
<ORIGINAL_TEXT>Overall, the age groups of 20-29 and 30-39 have the highest burden of the disease in India.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="803" end_char="809">Overall</TOKEN>
<TOKEN id="token-7-1" pos="punct" morph="none" start_char="810" end_char="810">,</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="812" end_char="814">the</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="816" end_char="818">age</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="820" end_char="825">groups</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="827" end_char="828">of</TOKEN>
<TOKEN id="token-7-6" pos="unknown" morph="none" start_char="830" end_char="834">20-29</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="836" end_char="838">and</TOKEN>
<TOKEN id="token-7-8" pos="unknown" morph="none" start_char="840" end_char="844">30-39</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="846" end_char="849">have</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="851" end_char="853">the</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="855" end_char="861">highest</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="863" end_char="868">burden</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="870" end_char="871">of</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="873" end_char="875">the</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="877" end_char="883">disease</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="885" end_char="886">in</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="888" end_char="892">India</TOKEN>
<TOKEN id="token-7-18" pos="punct" morph="none" start_char="893" end_char="893">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="895" end_char="1027">
<ORIGINAL_TEXT>This is in stark contrast to the experience of developed countries; in the UK, for example, the median positive case is 61 years old.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="895" end_char="898">This</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="900" end_char="901">is</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="903" end_char="904">in</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="906" end_char="910">stark</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="912" end_char="919">contrast</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="921" end_char="922">to</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="924" end_char="926">the</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="928" end_char="937">experience</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="939" end_char="940">of</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="942" end_char="950">developed</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="952" end_char="960">countries</TOKEN>
<TOKEN id="token-8-11" pos="punct" morph="none" start_char="961" end_char="961">;</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="963" end_char="964">in</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="966" end_char="968">the</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="970" end_char="971">UK</TOKEN>
<TOKEN id="token-8-15" pos="punct" morph="none" start_char="972" end_char="972">,</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="974" end_char="976">for</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="978" end_char="984">example</TOKEN>
<TOKEN id="token-8-18" pos="punct" morph="none" start_char="985" end_char="985">,</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="987" end_char="989">the</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="991" end_char="996">median</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="998" end_char="1005">positive</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="1007" end_char="1010">case</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="1012" end_char="1013">is</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="1015" end_char="1016">61</TOKEN>
<TOKEN id="token-8-25" pos="word" morph="none" start_char="1018" end_char="1022">years</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="1024" end_char="1026">old</TOKEN>
<TOKEN id="token-8-27" pos="punct" morph="none" start_char="1027" end_char="1027">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1031" end_char="1196">
<ORIGINAL_TEXT>Until now, there has been no way to know who exactly is being tested, and what proportion of those persons deemed eligible by ICMR’s testing criteria is being tested.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1031" end_char="1035">Until</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1037" end_char="1039">now</TOKEN>
<TOKEN id="token-9-2" pos="punct" morph="none" start_char="1040" end_char="1040">,</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1042" end_char="1046">there</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1048" end_char="1050">has</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1052" end_char="1055">been</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1057" end_char="1058">no</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1060" end_char="1062">way</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1064" end_char="1065">to</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1067" end_char="1070">know</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1072" end_char="1074">who</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1076" end_char="1082">exactly</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1084" end_char="1085">is</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1087" end_char="1091">being</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1093" end_char="1098">tested</TOKEN>
<TOKEN id="token-9-15" pos="punct" morph="none" start_char="1099" end_char="1099">,</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1101" end_char="1103">and</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1105" end_char="1108">what</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1110" end_char="1119">proportion</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1121" end_char="1122">of</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1124" end_char="1128">those</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1130" end_char="1136">persons</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1138" end_char="1143">deemed</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1145" end_char="1152">eligible</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1154" end_char="1155">by</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1157" end_char="1162">ICMR’s</TOKEN>
<TOKEN id="token-9-26" pos="word" morph="none" start_char="1164" end_char="1170">testing</TOKEN>
<TOKEN id="token-9-27" pos="word" morph="none" start_char="1172" end_char="1179">criteria</TOKEN>
<TOKEN id="token-9-28" pos="word" morph="none" start_char="1181" end_char="1182">is</TOKEN>
<TOKEN id="token-9-29" pos="word" morph="none" start_char="1184" end_char="1188">being</TOKEN>
<TOKEN id="token-9-30" pos="word" morph="none" start_char="1190" end_char="1195">tested</TOKEN>
<TOKEN id="token-9-31" pos="punct" morph="none" start_char="1196" end_char="1196">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1199" end_char="1412">
<ORIGINAL_TEXT>The new data shows that asymptomatic family members of confirmed cases formed the largest portion of those tested for whom information was available, and made up an even larger proportion of those testing positive.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1199" end_char="1201">The</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1203" end_char="1205">new</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1207" end_char="1210">data</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1212" end_char="1216">shows</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1218" end_char="1221">that</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1223" end_char="1234">asymptomatic</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1236" end_char="1241">family</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1243" end_char="1249">members</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1251" end_char="1252">of</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1254" end_char="1262">confirmed</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1264" end_char="1268">cases</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1270" end_char="1275">formed</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1277" end_char="1279">the</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1281" end_char="1287">largest</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1289" end_char="1295">portion</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1297" end_char="1298">of</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1300" end_char="1304">those</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1306" end_char="1311">tested</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1313" end_char="1315">for</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1317" end_char="1320">whom</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1322" end_char="1332">information</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1334" end_char="1336">was</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1338" end_char="1346">available</TOKEN>
<TOKEN id="token-10-23" pos="punct" morph="none" start_char="1347" end_char="1347">,</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1349" end_char="1351">and</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="1353" end_char="1356">made</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="1358" end_char="1359">up</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="1361" end_char="1362">an</TOKEN>
<TOKEN id="token-10-28" pos="word" morph="none" start_char="1364" end_char="1367">even</TOKEN>
<TOKEN id="token-10-29" pos="word" morph="none" start_char="1369" end_char="1374">larger</TOKEN>
<TOKEN id="token-10-30" pos="word" morph="none" start_char="1376" end_char="1385">proportion</TOKEN>
<TOKEN id="token-10-31" pos="word" morph="none" start_char="1387" end_char="1388">of</TOKEN>
<TOKEN id="token-10-32" pos="word" morph="none" start_char="1390" end_char="1394">those</TOKEN>
<TOKEN id="token-10-33" pos="word" morph="none" start_char="1396" end_char="1402">testing</TOKEN>
<TOKEN id="token-10-34" pos="word" morph="none" start_char="1404" end_char="1411">positive</TOKEN>
<TOKEN id="token-10-35" pos="punct" morph="none" start_char="1412" end_char="1412">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1415" end_char="1598">
<ORIGINAL_TEXT>The next biggest categories were symptomatic contacts of confirmed cases and those hospitalised with Severe Acute Respiratory Illness who were then tested for Covid and found positive.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1415" end_char="1417">The</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1419" end_char="1422">next</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1424" end_char="1430">biggest</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1432" end_char="1441">categories</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1443" end_char="1446">were</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1448" end_char="1458">symptomatic</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1460" end_char="1467">contacts</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1469" end_char="1470">of</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1472" end_char="1480">confirmed</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1482" end_char="1486">cases</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1488" end_char="1490">and</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1492" end_char="1496">those</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1498" end_char="1509">hospitalised</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1511" end_char="1514">with</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1516" end_char="1521">Severe</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1523" end_char="1527">Acute</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1529" end_char="1539">Respiratory</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1541" end_char="1547">Illness</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1549" end_char="1551">who</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="1553" end_char="1556">were</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1558" end_char="1561">then</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="1563" end_char="1568">tested</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="1570" end_char="1572">for</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="1574" end_char="1578">Covid</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="1580" end_char="1582">and</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="1584" end_char="1588">found</TOKEN>
<TOKEN id="token-11-26" pos="word" morph="none" start_char="1590" end_char="1597">positive</TOKEN>
<TOKEN id="token-11-27" pos="punct" morph="none" start_char="1598" end_char="1598">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1601" end_char="1899">
<ORIGINAL_TEXT>Given that symptomatic contacts and asymptomatic family members of confirmed cases accounted for 65 per cent of all positive cases between them for which data was available, contact tracing would have been the most important measure that states could undertake to quickly identify and isolate cases.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1601" end_char="1605">Given</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1607" end_char="1610">that</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1612" end_char="1622">symptomatic</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1624" end_char="1631">contacts</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1633" end_char="1635">and</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1637" end_char="1648">asymptomatic</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1650" end_char="1655">family</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1657" end_char="1663">members</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1665" end_char="1666">of</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1668" end_char="1676">confirmed</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1678" end_char="1682">cases</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1684" end_char="1692">accounted</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1694" end_char="1696">for</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1698" end_char="1699">65</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1701" end_char="1703">per</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1705" end_char="1708">cent</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1710" end_char="1711">of</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1713" end_char="1715">all</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1717" end_char="1724">positive</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1726" end_char="1730">cases</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1732" end_char="1738">between</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1740" end_char="1743">them</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1745" end_char="1747">for</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="1749" end_char="1753">which</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="1755" end_char="1758">data</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="1760" end_char="1762">was</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="1764" end_char="1772">available</TOKEN>
<TOKEN id="token-12-27" pos="punct" morph="none" start_char="1773" end_char="1773">,</TOKEN>
<TOKEN id="token-12-28" pos="word" morph="none" start_char="1775" end_char="1781">contact</TOKEN>
<TOKEN id="token-12-29" pos="word" morph="none" start_char="1783" end_char="1789">tracing</TOKEN>
<TOKEN id="token-12-30" pos="word" morph="none" start_char="1791" end_char="1795">would</TOKEN>
<TOKEN id="token-12-31" pos="word" morph="none" start_char="1797" end_char="1800">have</TOKEN>
<TOKEN id="token-12-32" pos="word" morph="none" start_char="1802" end_char="1805">been</TOKEN>
<TOKEN id="token-12-33" pos="word" morph="none" start_char="1807" end_char="1809">the</TOKEN>
<TOKEN id="token-12-34" pos="word" morph="none" start_char="1811" end_char="1814">most</TOKEN>
<TOKEN id="token-12-35" pos="word" morph="none" start_char="1816" end_char="1824">important</TOKEN>
<TOKEN id="token-12-36" pos="word" morph="none" start_char="1826" end_char="1832">measure</TOKEN>
<TOKEN id="token-12-37" pos="word" morph="none" start_char="1834" end_char="1837">that</TOKEN>
<TOKEN id="token-12-38" pos="word" morph="none" start_char="1839" end_char="1844">states</TOKEN>
<TOKEN id="token-12-39" pos="word" morph="none" start_char="1846" end_char="1850">could</TOKEN>
<TOKEN id="token-12-40" pos="word" morph="none" start_char="1852" end_char="1860">undertake</TOKEN>
<TOKEN id="token-12-41" pos="word" morph="none" start_char="1862" end_char="1863">to</TOKEN>
<TOKEN id="token-12-42" pos="word" morph="none" start_char="1865" end_char="1871">quickly</TOKEN>
<TOKEN id="token-12-43" pos="word" morph="none" start_char="1873" end_char="1880">identify</TOKEN>
<TOKEN id="token-12-44" pos="word" morph="none" start_char="1882" end_char="1884">and</TOKEN>
<TOKEN id="token-12-45" pos="word" morph="none" start_char="1886" end_char="1892">isolate</TOKEN>
<TOKEN id="token-12-46" pos="word" morph="none" start_char="1894" end_char="1898">cases</TOKEN>
<TOKEN id="token-12-47" pos="punct" morph="none" start_char="1899" end_char="1899">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1902" end_char="2001">
<ORIGINAL_TEXT>Yet, there was large variation between states in the number of contacts of a positive person tested.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1902" end_char="1904">Yet</TOKEN>
<TOKEN id="token-13-1" pos="punct" morph="none" start_char="1905" end_char="1905">,</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1907" end_char="1911">there</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1913" end_char="1915">was</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1917" end_char="1921">large</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1923" end_char="1931">variation</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1933" end_char="1939">between</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1941" end_char="1946">states</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1948" end_char="1949">in</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1951" end_char="1953">the</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1955" end_char="1960">number</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1962" end_char="1963">of</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1965" end_char="1972">contacts</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1974" end_char="1975">of</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1977" end_char="1977">a</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1979" end_char="1986">positive</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1988" end_char="1993">person</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1995" end_char="2000">tested</TOKEN>
<TOKEN id="token-13-18" pos="punct" morph="none" start_char="2001" end_char="2001">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="2003" end_char="2168">
<ORIGINAL_TEXT>Smaller states were, as expected, able to test more people, but many high burden states such as Maharashtra and Delhi are testing too few contacts per confirmed case.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="2003" end_char="2009">Smaller</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="2011" end_char="2016">states</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="2018" end_char="2021">were</TOKEN>
<TOKEN id="token-14-3" pos="punct" morph="none" start_char="2022" end_char="2022">,</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="2024" end_char="2025">as</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="2027" end_char="2034">expected</TOKEN>
<TOKEN id="token-14-6" pos="punct" morph="none" start_char="2035" end_char="2035">,</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="2037" end_char="2040">able</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="2042" end_char="2043">to</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="2045" end_char="2048">test</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="2050" end_char="2053">more</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="2055" end_char="2060">people</TOKEN>
<TOKEN id="token-14-12" pos="punct" morph="none" start_char="2061" end_char="2061">,</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="2063" end_char="2065">but</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="2067" end_char="2070">many</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="2072" end_char="2075">high</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="2077" end_char="2082">burden</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="2084" end_char="2089">states</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="2091" end_char="2094">such</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="2096" end_char="2097">as</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="2099" end_char="2109">Maharashtra</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="2111" end_char="2113">and</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="2115" end_char="2119">Delhi</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="2121" end_char="2123">are</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="2125" end_char="2131">testing</TOKEN>
<TOKEN id="token-14-25" pos="word" morph="none" start_char="2133" end_char="2135">too</TOKEN>
<TOKEN id="token-14-26" pos="word" morph="none" start_char="2137" end_char="2139">few</TOKEN>
<TOKEN id="token-14-27" pos="word" morph="none" start_char="2141" end_char="2148">contacts</TOKEN>
<TOKEN id="token-14-28" pos="word" morph="none" start_char="2150" end_char="2152">per</TOKEN>
<TOKEN id="token-14-29" pos="word" morph="none" start_char="2154" end_char="2162">confirmed</TOKEN>
<TOKEN id="token-14-30" pos="word" morph="none" start_char="2164" end_char="2167">case</TOKEN>
<TOKEN id="token-14-31" pos="punct" morph="none" start_char="2168" end_char="2168">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="2170" end_char="2236">
<ORIGINAL_TEXT>Among the major states, Karnataka cast the widest net for contacts.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="2170" end_char="2174">Among</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="2176" end_char="2178">the</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="2180" end_char="2184">major</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="2186" end_char="2191">states</TOKEN>
<TOKEN id="token-15-4" pos="punct" morph="none" start_char="2192" end_char="2192">,</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="2194" end_char="2202">Karnataka</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="2204" end_char="2207">cast</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="2209" end_char="2211">the</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="2213" end_char="2218">widest</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="2220" end_char="2222">net</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="2224" end_char="2226">for</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="2228" end_char="2235">contacts</TOKEN>
<TOKEN id="token-15-12" pos="punct" morph="none" start_char="2236" end_char="2236">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="2239" end_char="2400">
<ORIGINAL_TEXT>Most worryingly, states that did the least testing among contacts of confirmed cases were among those with the highest rates of positive cases among those tested.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="2239" end_char="2242">Most</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="2244" end_char="2253">worryingly</TOKEN>
<TOKEN id="token-16-2" pos="punct" morph="none" start_char="2254" end_char="2254">,</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="2256" end_char="2261">states</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="2263" end_char="2266">that</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="2268" end_char="2270">did</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="2272" end_char="2274">the</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="2276" end_char="2280">least</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="2282" end_char="2288">testing</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="2290" end_char="2294">among</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="2296" end_char="2303">contacts</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="2305" end_char="2306">of</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="2308" end_char="2316">confirmed</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="2318" end_char="2322">cases</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="2324" end_char="2327">were</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="2329" end_char="2333">among</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="2335" end_char="2339">those</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="2341" end_char="2344">with</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="2346" end_char="2348">the</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="2350" end_char="2356">highest</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="2358" end_char="2362">rates</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="2364" end_char="2365">of</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="2367" end_char="2374">positive</TOKEN>
<TOKEN id="token-16-23" pos="word" morph="none" start_char="2376" end_char="2380">cases</TOKEN>
<TOKEN id="token-16-24" pos="word" morph="none" start_char="2382" end_char="2386">among</TOKEN>
<TOKEN id="token-16-25" pos="word" morph="none" start_char="2388" end_char="2392">those</TOKEN>
<TOKEN id="token-16-26" pos="word" morph="none" start_char="2394" end_char="2399">tested</TOKEN>
<TOKEN id="token-16-27" pos="punct" morph="none" start_char="2400" end_char="2400">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2402" end_char="2554">
<ORIGINAL_TEXT>For instance, Maharashtra tested just two contacts for each confirmed case, yet 13 per cent of those contacts that they tested turned out to be positive.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2402" end_char="2404">For</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2406" end_char="2413">instance</TOKEN>
<TOKEN id="token-17-2" pos="punct" morph="none" start_char="2414" end_char="2414">,</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2416" end_char="2426">Maharashtra</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2428" end_char="2433">tested</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2435" end_char="2438">just</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2440" end_char="2442">two</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2444" end_char="2451">contacts</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2453" end_char="2455">for</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2457" end_char="2460">each</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2462" end_char="2470">confirmed</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2472" end_char="2475">case</TOKEN>
<TOKEN id="token-17-12" pos="punct" morph="none" start_char="2476" end_char="2476">,</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2478" end_char="2480">yet</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2482" end_char="2483">13</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2485" end_char="2487">per</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="2489" end_char="2492">cent</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="2494" end_char="2495">of</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="2497" end_char="2501">those</TOKEN>
<TOKEN id="token-17-19" pos="word" morph="none" start_char="2503" end_char="2510">contacts</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="2512" end_char="2515">that</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="2517" end_char="2520">they</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="2522" end_char="2527">tested</TOKEN>
<TOKEN id="token-17-23" pos="word" morph="none" start_char="2529" end_char="2534">turned</TOKEN>
<TOKEN id="token-17-24" pos="word" morph="none" start_char="2536" end_char="2538">out</TOKEN>
<TOKEN id="token-17-25" pos="word" morph="none" start_char="2540" end_char="2541">to</TOKEN>
<TOKEN id="token-17-26" pos="word" morph="none" start_char="2543" end_char="2544">be</TOKEN>
<TOKEN id="token-17-27" pos="word" morph="none" start_char="2546" end_char="2553">positive</TOKEN>
<TOKEN id="token-17-28" pos="punct" morph="none" start_char="2554" end_char="2554">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2557" end_char="2673">
<ORIGINAL_TEXT>On the other hand, Karnataka tested 47 contacts for each confirmed case, and only 1 per cent of them tested positive.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2557" end_char="2558">On</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2560" end_char="2562">the</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2564" end_char="2568">other</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2570" end_char="2573">hand</TOKEN>
<TOKEN id="token-18-4" pos="punct" morph="none" start_char="2574" end_char="2574">,</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2576" end_char="2584">Karnataka</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2586" end_char="2591">tested</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2593" end_char="2594">47</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2596" end_char="2603">contacts</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="2605" end_char="2607">for</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="2609" end_char="2612">each</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="2614" end_char="2622">confirmed</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2624" end_char="2627">case</TOKEN>
<TOKEN id="token-18-13" pos="punct" morph="none" start_char="2628" end_char="2628">,</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="2630" end_char="2632">and</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="2634" end_char="2637">only</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="2639" end_char="2639">1</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="2641" end_char="2643">per</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="2645" end_char="2648">cent</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="2650" end_char="2651">of</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="2653" end_char="2656">them</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="2658" end_char="2663">tested</TOKEN>
<TOKEN id="token-18-22" pos="word" morph="none" start_char="2665" end_char="2672">positive</TOKEN>
<TOKEN id="token-18-23" pos="punct" morph="none" start_char="2673" end_char="2673">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2675" end_char="2843">
<ORIGINAL_TEXT>This can only mean that high burden states that are testing few contacts of each confirmed case will need to cast the net far wider to discover the true extent of cases.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2675" end_char="2678">This</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2680" end_char="2682">can</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2684" end_char="2687">only</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2689" end_char="2692">mean</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2694" end_char="2697">that</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2699" end_char="2702">high</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2704" end_char="2709">burden</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2711" end_char="2716">states</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2718" end_char="2721">that</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="2723" end_char="2725">are</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="2727" end_char="2733">testing</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="2735" end_char="2737">few</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="2739" end_char="2746">contacts</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="2748" end_char="2749">of</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="2751" end_char="2754">each</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="2756" end_char="2764">confirmed</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="2766" end_char="2769">case</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="2771" end_char="2774">will</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="2776" end_char="2779">need</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="2781" end_char="2782">to</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="2784" end_char="2787">cast</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="2789" end_char="2791">the</TOKEN>
<TOKEN id="token-19-22" pos="word" morph="none" start_char="2793" end_char="2795">net</TOKEN>
<TOKEN id="token-19-23" pos="word" morph="none" start_char="2797" end_char="2799">far</TOKEN>
<TOKEN id="token-19-24" pos="word" morph="none" start_char="2801" end_char="2805">wider</TOKEN>
<TOKEN id="token-19-25" pos="word" morph="none" start_char="2807" end_char="2808">to</TOKEN>
<TOKEN id="token-19-26" pos="word" morph="none" start_char="2810" end_char="2817">discover</TOKEN>
<TOKEN id="token-19-27" pos="word" morph="none" start_char="2819" end_char="2821">the</TOKEN>
<TOKEN id="token-19-28" pos="word" morph="none" start_char="2823" end_char="2826">true</TOKEN>
<TOKEN id="token-19-29" pos="word" morph="none" start_char="2828" end_char="2833">extent</TOKEN>
<TOKEN id="token-19-30" pos="word" morph="none" start_char="2835" end_char="2836">of</TOKEN>
<TOKEN id="token-19-31" pos="word" morph="none" start_char="2838" end_char="2842">cases</TOKEN>
<TOKEN id="token-19-32" pos="punct" morph="none" start_char="2843" end_char="2843">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2846" end_char="3006">
<ORIGINAL_TEXT>Moreover, for 44 per cent of those who tested positive, and 57 per cent of those tested in all, their links to known cases were either not known or not recorded.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2846" end_char="2853">Moreover</TOKEN>
<TOKEN id="token-20-1" pos="punct" morph="none" start_char="2854" end_char="2854">,</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2856" end_char="2858">for</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2860" end_char="2861">44</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2863" end_char="2865">per</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2867" end_char="2870">cent</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2872" end_char="2873">of</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2875" end_char="2879">those</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="2881" end_char="2883">who</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2885" end_char="2890">tested</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2892" end_char="2899">positive</TOKEN>
<TOKEN id="token-20-11" pos="punct" morph="none" start_char="2900" end_char="2900">,</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="2902" end_char="2904">and</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="2906" end_char="2907">57</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="2909" end_char="2911">per</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="2913" end_char="2916">cent</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="2918" end_char="2919">of</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="2921" end_char="2925">those</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="2927" end_char="2932">tested</TOKEN>
<TOKEN id="token-20-19" pos="word" morph="none" start_char="2934" end_char="2935">in</TOKEN>
<TOKEN id="token-20-20" pos="word" morph="none" start_char="2937" end_char="2939">all</TOKEN>
<TOKEN id="token-20-21" pos="punct" morph="none" start_char="2940" end_char="2940">,</TOKEN>
<TOKEN id="token-20-22" pos="word" morph="none" start_char="2942" end_char="2946">their</TOKEN>
<TOKEN id="token-20-23" pos="word" morph="none" start_char="2948" end_char="2952">links</TOKEN>
<TOKEN id="token-20-24" pos="word" morph="none" start_char="2954" end_char="2955">to</TOKEN>
<TOKEN id="token-20-25" pos="word" morph="none" start_char="2957" end_char="2961">known</TOKEN>
<TOKEN id="token-20-26" pos="word" morph="none" start_char="2963" end_char="2967">cases</TOKEN>
<TOKEN id="token-20-27" pos="word" morph="none" start_char="2969" end_char="2972">were</TOKEN>
<TOKEN id="token-20-28" pos="word" morph="none" start_char="2974" end_char="2979">either</TOKEN>
<TOKEN id="token-20-29" pos="word" morph="none" start_char="2981" end_char="2983">not</TOKEN>
<TOKEN id="token-20-30" pos="word" morph="none" start_char="2985" end_char="2989">known</TOKEN>
<TOKEN id="token-20-31" pos="word" morph="none" start_char="2991" end_char="2992">or</TOKEN>
<TOKEN id="token-20-32" pos="word" morph="none" start_char="2994" end_char="2996">not</TOKEN>
<TOKEN id="token-20-33" pos="word" morph="none" start_char="2998" end_char="3005">recorded</TOKEN>
<TOKEN id="token-20-34" pos="punct" morph="none" start_char="3006" end_char="3006">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="3008" end_char="3091">
<ORIGINAL_TEXT>ICMR data shows that the number with "unspecified" modes of transmission is growing.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="3008" end_char="3011">ICMR</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="3013" end_char="3016">data</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="3018" end_char="3022">shows</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="3024" end_char="3027">that</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="3029" end_char="3031">the</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="3033" end_char="3038">number</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="3040" end_char="3043">with</TOKEN>
<TOKEN id="token-21-7" pos="punct" morph="none" start_char="3045" end_char="3045">"</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="3046" end_char="3056">unspecified</TOKEN>
<TOKEN id="token-21-9" pos="punct" morph="none" start_char="3057" end_char="3057">"</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="3059" end_char="3063">modes</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="3065" end_char="3066">of</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="3068" end_char="3079">transmission</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="3081" end_char="3082">is</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="3084" end_char="3090">growing</TOKEN>
<TOKEN id="token-21-15" pos="punct" morph="none" start_char="3091" end_char="3091">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="3094" end_char="3363">
<ORIGINAL_TEXT>This is in stark contrast to, say, South Korea where the percentage of patients who test positive after being identified through contact tracing and placed under self-quarantine is near 80 per cent, according to Korea’s Centers for Disease Control and Prevention (KCDC).</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="3094" end_char="3097">This</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="3099" end_char="3100">is</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="3102" end_char="3103">in</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="3105" end_char="3109">stark</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="3111" end_char="3118">contrast</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="3120" end_char="3121">to</TOKEN>
<TOKEN id="token-22-6" pos="punct" morph="none" start_char="3122" end_char="3122">,</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="3124" end_char="3126">say</TOKEN>
<TOKEN id="token-22-8" pos="punct" morph="none" start_char="3127" end_char="3127">,</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="3129" end_char="3133">South</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="3135" end_char="3139">Korea</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="3141" end_char="3145">where</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="3147" end_char="3149">the</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="3151" end_char="3160">percentage</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="3162" end_char="3163">of</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="3165" end_char="3172">patients</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="3174" end_char="3176">who</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="3178" end_char="3181">test</TOKEN>
<TOKEN id="token-22-18" pos="word" morph="none" start_char="3183" end_char="3190">positive</TOKEN>
<TOKEN id="token-22-19" pos="word" morph="none" start_char="3192" end_char="3196">after</TOKEN>
<TOKEN id="token-22-20" pos="word" morph="none" start_char="3198" end_char="3202">being</TOKEN>
<TOKEN id="token-22-21" pos="word" morph="none" start_char="3204" end_char="3213">identified</TOKEN>
<TOKEN id="token-22-22" pos="word" morph="none" start_char="3215" end_char="3221">through</TOKEN>
<TOKEN id="token-22-23" pos="word" morph="none" start_char="3223" end_char="3229">contact</TOKEN>
<TOKEN id="token-22-24" pos="word" morph="none" start_char="3231" end_char="3237">tracing</TOKEN>
<TOKEN id="token-22-25" pos="word" morph="none" start_char="3239" end_char="3241">and</TOKEN>
<TOKEN id="token-22-26" pos="word" morph="none" start_char="3243" end_char="3248">placed</TOKEN>
<TOKEN id="token-22-27" pos="word" morph="none" start_char="3250" end_char="3254">under</TOKEN>
<TOKEN id="token-22-28" pos="unknown" morph="none" start_char="3256" end_char="3270">self-quarantine</TOKEN>
<TOKEN id="token-22-29" pos="word" morph="none" start_char="3272" end_char="3273">is</TOKEN>
<TOKEN id="token-22-30" pos="word" morph="none" start_char="3275" end_char="3278">near</TOKEN>
<TOKEN id="token-22-31" pos="word" morph="none" start_char="3280" end_char="3281">80</TOKEN>
<TOKEN id="token-22-32" pos="word" morph="none" start_char="3283" end_char="3285">per</TOKEN>
<TOKEN id="token-22-33" pos="word" morph="none" start_char="3287" end_char="3290">cent</TOKEN>
<TOKEN id="token-22-34" pos="punct" morph="none" start_char="3291" end_char="3291">,</TOKEN>
<TOKEN id="token-22-35" pos="word" morph="none" start_char="3293" end_char="3301">according</TOKEN>
<TOKEN id="token-22-36" pos="word" morph="none" start_char="3303" end_char="3304">to</TOKEN>
<TOKEN id="token-22-37" pos="word" morph="none" start_char="3306" end_char="3312">Korea’s</TOKEN>
<TOKEN id="token-22-38" pos="word" morph="none" start_char="3314" end_char="3320">Centers</TOKEN>
<TOKEN id="token-22-39" pos="word" morph="none" start_char="3322" end_char="3324">for</TOKEN>
<TOKEN id="token-22-40" pos="word" morph="none" start_char="3326" end_char="3332">Disease</TOKEN>
<TOKEN id="token-22-41" pos="word" morph="none" start_char="3334" end_char="3340">Control</TOKEN>
<TOKEN id="token-22-42" pos="word" morph="none" start_char="3342" end_char="3344">and</TOKEN>
<TOKEN id="token-22-43" pos="word" morph="none" start_char="3346" end_char="3355">Prevention</TOKEN>
<TOKEN id="token-22-44" pos="punct" morph="none" start_char="3357" end_char="3357">(</TOKEN>
<TOKEN id="token-22-45" pos="word" morph="none" start_char="3358" end_char="3361">KCDC</TOKEN>
<TOKEN id="token-22-46" pos="punct" morph="none" start_char="3362" end_char="3363">).</TOKEN>
</SEG>
<SEG id="segment-23" start_char="3366" end_char="3587">
<ORIGINAL_TEXT>In several key states, including Bihar, Andhra Pradesh, Odisha and Rajasthan, the transmission details of the vast majority of persons tested where they are suspected to have contracted the infection from is not available.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="3366" end_char="3367">In</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="3369" end_char="3375">several</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="3377" end_char="3379">key</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="3381" end_char="3386">states</TOKEN>
<TOKEN id="token-23-4" pos="punct" morph="none" start_char="3387" end_char="3387">,</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="3389" end_char="3397">including</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="3399" end_char="3403">Bihar</TOKEN>
<TOKEN id="token-23-7" pos="punct" morph="none" start_char="3404" end_char="3404">,</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="3406" end_char="3411">Andhra</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="3413" end_char="3419">Pradesh</TOKEN>
<TOKEN id="token-23-10" pos="punct" morph="none" start_char="3420" end_char="3420">,</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="3422" end_char="3427">Odisha</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="3429" end_char="3431">and</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="3433" end_char="3441">Rajasthan</TOKEN>
<TOKEN id="token-23-14" pos="punct" morph="none" start_char="3442" end_char="3442">,</TOKEN>
<TOKEN id="token-23-15" pos="word" morph="none" start_char="3444" end_char="3446">the</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="3448" end_char="3459">transmission</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="3461" end_char="3467">details</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="3469" end_char="3470">of</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="3472" end_char="3474">the</TOKEN>
<TOKEN id="token-23-20" pos="word" morph="none" start_char="3476" end_char="3479">vast</TOKEN>
<TOKEN id="token-23-21" pos="word" morph="none" start_char="3481" end_char="3488">majority</TOKEN>
<TOKEN id="token-23-22" pos="word" morph="none" start_char="3490" end_char="3491">of</TOKEN>
<TOKEN id="token-23-23" pos="word" morph="none" start_char="3493" end_char="3499">persons</TOKEN>
<TOKEN id="token-23-24" pos="word" morph="none" start_char="3501" end_char="3506">tested</TOKEN>
<TOKEN id="token-23-25" pos="word" morph="none" start_char="3508" end_char="3512">where</TOKEN>
<TOKEN id="token-23-26" pos="word" morph="none" start_char="3514" end_char="3517">they</TOKEN>
<TOKEN id="token-23-27" pos="word" morph="none" start_char="3519" end_char="3521">are</TOKEN>
<TOKEN id="token-23-28" pos="word" morph="none" start_char="3523" end_char="3531">suspected</TOKEN>
<TOKEN id="token-23-29" pos="word" morph="none" start_char="3533" end_char="3534">to</TOKEN>
<TOKEN id="token-23-30" pos="word" morph="none" start_char="3536" end_char="3539">have</TOKEN>
<TOKEN id="token-23-31" pos="word" morph="none" start_char="3541" end_char="3550">contracted</TOKEN>
<TOKEN id="token-23-32" pos="word" morph="none" start_char="3552" end_char="3554">the</TOKEN>
<TOKEN id="token-23-33" pos="word" morph="none" start_char="3556" end_char="3564">infection</TOKEN>
<TOKEN id="token-23-34" pos="word" morph="none" start_char="3566" end_char="3569">from</TOKEN>
<TOKEN id="token-23-35" pos="word" morph="none" start_char="3571" end_char="3572">is</TOKEN>
<TOKEN id="token-23-36" pos="word" morph="none" start_char="3574" end_char="3576">not</TOKEN>
<TOKEN id="token-23-37" pos="word" morph="none" start_char="3578" end_char="3586">available</TOKEN>
<TOKEN id="token-23-38" pos="punct" morph="none" start_char="3587" end_char="3587">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="3589" end_char="3691">
<ORIGINAL_TEXT>This could either mean widespread community transmission, or poor recording on the part of authorities.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="3589" end_char="3592">This</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="3594" end_char="3598">could</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="3600" end_char="3605">either</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="3607" end_char="3610">mean</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="3612" end_char="3621">widespread</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="3623" end_char="3631">community</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="3633" end_char="3644">transmission</TOKEN>
<TOKEN id="token-24-7" pos="punct" morph="none" start_char="3645" end_char="3645">,</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="3647" end_char="3648">or</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="3650" end_char="3653">poor</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="3655" end_char="3663">recording</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="3665" end_char="3666">on</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="3668" end_char="3670">the</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="3672" end_char="3675">part</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="3677" end_char="3678">of</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="3680" end_char="3690">authorities</TOKEN>
<TOKEN id="token-24-16" pos="punct" morph="none" start_char="3691" end_char="3691">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="3693" end_char="3733">
<ORIGINAL_TEXT>Either way, it is a worrisome indication.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="3693" end_char="3698">Either</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="3700" end_char="3702">way</TOKEN>
<TOKEN id="token-25-2" pos="punct" morph="none" start_char="3703" end_char="3703">,</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="3705" end_char="3706">it</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="3708" end_char="3709">is</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="3711" end_char="3711">a</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="3713" end_char="3721">worrisome</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="3723" end_char="3732">indication</TOKEN>
<TOKEN id="token-25-8" pos="punct" morph="none" start_char="3733" end_char="3733">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
